optimal algorithm approximate nearest neighbor searching fixed dimensions arya hong kong university science technology hong kong david mount university maryland college park maryland nathan netanyahu dept mathematics computer science bar ilan university ramat gan israel 
ruth silverman university maryland college park maryland university district columbia washington dc angela wu american university washington dc preliminary version appeared proceedings fifth annual acm siam symposium discrete algorithms pp 

arya supported hk 
part research conducted author visiting max planck institut informatik saarbr cken germany 
mount supported national science foundation ccr 
netanyahu supported part national research council nasa goddard 
silverman supported national science foundation ccr 
author addresses arya department computer science hong kong university science technology clear water bay kowloon hong kong 
mail arya cs ust hk 
mount department computer science institute advanced computer studies university maryland college park maryland 
mail mount cs umd edu 
netanyahu dept mathematics computer science bar ilan university ramat gan israel 
mail nathan macs ac il 
performed author center automation research university maryland space data computing division nasa goddard space flight center 
silverman department computer science university district columbia washington dc center automation research university maryland college park maryland 
mail ruth umd edu 
wu department computer science information systems american university washington dc 
mail american edu 
permission digital hard copies part personal classroom granted fee provided copies distributed profit direct commercial advantage copies show notice page initial screen display full citation 
copyrights components owned acm honored 
abstracting credit permitted 
copy republish post servers redistribute lists component works requires prior specific permission fee 
permissions may requested publications dept acm broadway new york ny usa fax permissions acm org 
arya consider set data points real dimensional space distances measured minkowski metric 
nearest neighbor searching preprocess data structure query point closest point reported quickly 
positive real data point approximate nearest neighbor distance factor distance true nearest neighbor 
show possible preprocess set points dn log time dn space query point approximate nearest neighbor computed cd log time cd factor depending dimension 
general show integer approximations nearest neighbors computed additional kd log time 
categories subject descriptors data data structures analysis algorithms problem complexity algorithms problems information storage retrieval information search retrieval general terms algorithms theory additional key words phrases nearest neighbor searching post office problem closest point queries approximation algorithms box decomposition trees priority search 


nearest neighbor searching problem set data points metric space task preprocess points query point data point nearest reported quickly 
called closest point problem post office problem 
nearest neighbor searching important problem variety applications including knowledge discovery data mining fayyad pattern recognition classification cover hart duda hart machine learning cost salzberg data compression gersho gray multimedia databases flickner document retrieval deerwester statistics devroye wagner 
high dimensional nearest neighbor problems arise naturally complex objects represented vectors numeric features 
assume metric space real dimensional space assume distances measured minkowski lm distance metric 
integer lm distance points pd qd inr defined th root pi qi limiting case equivalent max pi qi 
metrics known manhattan euclidean max metrics respectively 
assume distance points computed time 
note root need computed comparing distances 
framework strong include nearest neighbor applications noted applications fit framework computing nearest neighbor strings distance function edit distance number single character changes 
obviously problem solved dn time simple brute force optimal algorithm approximate nearest neighbor searching search 
number methods proposed provide relatively modest constant factor improvements partial distance computation bei gray projecting points single line friedman guan kamel lee chen 
focus methods data structures stored main memory 
considerable literature nearest neighbor searching databases 
example see berchtold berchtold lin roussopoulos white jain 
uniformly distributed point sets expected case performance achieved algorithms simple decompositions space regular grids 
rivest cleary provided analyses methods 
bentley weide yao analyzed grid method distributions satisfying certain bounded density assumptions 
results generalized friedman bentley finkel showed space log query time achievable expected case kd trees 
methods suffer dimension increases 
constant factors hidden asymptotic running time grow fast depending metric 
sproull observed empirically measured running time kd trees increase quite rapidly dimension 
arya mount narayan showed significantly larger arises applications boundary effects mildly decrease exponential dimensional dependence 
perspective worst case performance ideal solution preprocess points log time data structure requiring space queries answered log time 
dimension possible sorting points binary search answer queries 
dimension possible computing voronoi diagram point set fast planar point location algorithm locate cell containing query point 
example see de berg edelsbrunner preparata shamos 
dimensions larger worstcase complexity voronoi diagram grows 
higher dimensional solutions sublinear worst case performance considered yao yao 
clarkson showed queries answered log time space 
notation hides constant factors exponential agarwal matou sek generalized providing tradeoff space query time 
showed exponential factors query time eliminated giving algorithm log query time space 
fixed dimension greater known method achieves simultaneous goals roughly linear space logarithmic query time 
apparent difficulty obtaining algorithms efficient worst case respect space query time dimensions higher suggests alternative approach finding approximate nearest neighbors worth considering 
consider set data points query point say point isa approximate nearest neighbor dist dist true nearest neighbor words relative arya error true nearest neighbor 
generally approximate nearest neighbor data point relative error true kth nearest neighbor 
define sequence approximate nearest neighbors query point sequence distinct data points ith point sequence approximation ith nearest neighbor assume fixed constants independent include asymptotic results indicate dependency values 
approximate nearest neighbor problem considered bern 
proposed data structure quadtrees uses linear space provides logarithmic query time 
approximation error factor algorithm fixed function dimension 
arya mount proposed randomized data structure achieves polylogarithmic query time expected case nearly linear space 
algorithm approximation error factor arbitrary positive constant fixed preprocessing time 
strengthen results significantly 
main result stated theorem 
theorem 
consider set data points constant cd dn log time possible construct data structure size dn minkowski metric rd approximate nearest neighbor reported cd log time 
ii generally rd sequence approximate nearest neighbors computed cd kd log time 
case single nearest neighbor fixed space query times theorem asymptotically optimal algebraic decision tree model computation 
space log time required distinguish possible outcomes query point coincides data points 
claims optimality factor cd 
number results showing significantly storage possible improve dimensional dependencies query time 
clarkson showed query time reduced log log space ratio furthest pair interpoint distances 
chan showed factor log removed space complexity 
kleinberg showed possible eliminate exponential dependencies dimension query time log space 
indyk motwani independently kushilevitz ostrovsky rabani announced algorithms eliminate exponential dependencies dimension yielding query time log dn space dn notation hides constant factors depending exponentially dimension 
important practical aspects theorem 
space requirements completely independent asymptotically optimal parameter settings dn storage needed just store data points 
applications optimal algorithm approximate nearest neighbor searching large small important consideration 
second preprocessing independent metric implying data structure built queries answered error bound minkowski metric 
contrast mentioned methods require data structure rebuilt metric changes 
fact setting cause algorithm compute true nearest neighbor provide bounds running time trivial dn log time bound needed search entire tree search algorithm 
unfortunately exponential factors query time imply algorithm practical large values empirical evidence section shows constant factors smaller bound theorem distributions tested 
algorithm provide significant improvements brute force search dimensions high relatively small average error 
number important applications nearest neighbor searching range dimensions 
algorithms preprocessing queries deterministic easy implement 
data structure hierarchical decomposition space call balanced box decomposition bbd tree 
tree log height subdivides space regions complexity defined axis aligned hyperrectangles fat meaning ratio longest shortest sides bounded 
data structure similar balanced structures box decomposition bern callahan kosaraju new elements included purposes nearest neighbor searching practical efficiency 
space recursively subdivided collection cells dimensional rectangle set theoretic difference rectangles enclosed 
node tree associated cell implicitly associated set data points lying cell 
leaf cell associated single point lying bounding rectangle cell 
leaves tree define subdivision space 
tree nodes built dn log time 
intuitive overview approximate nearest neighbor query algorithm 
query point locating leaf cell containing query point log time simple descent tree 
enumerating leaf cells increasing order distance query point 
call priority search 
cell visited distance point associated cell computed 
keep track closest point seen far 
example shows cells subdivision 
cell numbered distance query point 
denote closest point seen far 
soon distance current leaf cell exceeds dist illustrated dotted circle follows search terminated reported approximate nearest neighbor reason point located subsequently visited cell close violate claim approximate nearest neighbor 
example shown search terminates just prior visiting cell 
case true nearest neighbor point belongs cell visited 
show auxiliary heap priority search performed time log times arya fig 

algorithm overview 
number leaf cells visited 
show number cells visited search depends intuitive explanation details lemma 
consider leaf cell visited cause algorithm terminate 
denote distance cell denote closest data point encountered far terminate know distance 
see 
seen leaf cell diameter associated data point necessarily closer provides lower bound sizes leaf cells seen 
fact cells fat simple packing argument provide upper bound number cells encountered 
easy matter extend algorithm enumerate data points approximately increasing distance query point 
particular show simple generalization search strategy allows enumerate sequence approximate nearest neighbors additional kd log time 
show consequence results callahan kosaraju data structure generalized handle point insertions deletions log time update 
rest organized follows 
section introduce bbd tree data structure algorithm construction analyze structure 
section establish essential properties bbd tree nearest neighbor algorithm 
section query algorithm nearest neighbor problem section generalization enumerating approximate nearest neighbors 
section experimental results 

bbd tree 
section introduce balanced box decomposition tree bbd tree primary data structure algorithm 
general class geometric data structures hierarchical decomposition space ddimensional rectangles sides orthogonal coordinate axes 
main feature bbd tree combines data structure important features data structures 
optimal algorithm approximate nearest neighbor searching consider optimized kd tree friedman 
data structure recursively subdivides space hyperplane orthogonal coordinate axes partitions data points evenly possible 
consequence descends path tree cardinality points associated nodes path decreases exponentially 
contrast consider quadtree data structures decompose space regions hypercubes generally rectangles aspect ratio ratio length longest side shortest side bounded constant 
include see samet structures clarkson feder greene vaidya callahan kosaraju bern 
important feature data structures descends path trees geometric size associated regions space defined example length longest side associated rectangle decreases exponentially 
bbd tree spatial decomposition achieves exponential cardinality geometric size reduction descends tree 
bbd tree similar balanced structures spatial decomposition rectangles bounded aspect ratio 
particular bern eppstein teng schwarz smid snoeyink callahan kosaraju observed unbalanced trees described earlier combined auxiliary balancing data structures centroid decomposition trees chazelle dynamic trees sleator tarjan topology trees frederickson achieve desired combination properties 
auxiliary data structures considerable complexity 
show possible build single balanced data structure need complex auxiliary data structures 
major difference earlier version arya 
principal difference bbd tree data structures listed node bbd tree associated simply dimensional rectangle generally set theoretic difference rectangles enclosed 
note region decomposed rectangles simple hyperplane cuts resulting rectangles generally bounded aspect ratio 
show bbd tree set data points constructed dn log time nodes 
describing construction algorithm definitions 
rectangle mean fold product closed intervals coordinate axes 
ith length rectangle length ith interval 
size rectangle length longest side 
define box rectangle aspect ratio ratio longest shortest sides bounded constant concreteness assume 
node bbd tree associated region space called cell 
particular define cell box set theoretic difference boxes enclosed 
cell defined outer box optional inner box 
cell associated set data points lying cell 
cells considered closed points lie boundary cells may assigned cell 
size cell size outer box 
arya important concept restricts nature inner boxes property called stickiness 
consider cell outer box bo inner box bi 
intuitively box bi sticky bo face sufficiently far touching corresponding face bo 
precise consider closed intervals xi yi xo yo yi xi denote width inner interval 
say xi yi xo yo distances inner interval outer interval xi xo yo yi inner box bi sticky outer box bo intervals bi sticky corresponding interval bo 
see 
equivalent condition stickiness arises considering regular grid copies bi centered bi 
observe bi sticky bo rectangle grid lies entirely bo disjoint interior bo 
see lower right box 
maintain property cells inner box sticky outer box 
stickiness needed various technical reasons discussed 
particular prohibits situations large number inner boxes nested extremely close outer wall cell 
situations possible prove bounds search time 
sticky bo bi sticky fair split low high child child bi bo bi fig 

stickiness fair splits shrinking 
shrink outer child inner child overview construction process bbd tree constructed repeated application operations fair splits simply splits shrinks 
operations described detail intuitively represent different ways subdividing cell smaller cells called children 
fair split partitions cell axis orthogonal hyperplane 
children called low child high child depending coordinates splitting coordinate greater coordinate splitting plane 
see 
shrink partitions cell disjoint subcells uses box called shrinking box hyperplane splitting 
partitions cell children lying inside inner child lying outside outer child 
see 
operations performed invariants hold 
boxes satisfy aspect ratio bound 
parent inner box box lies entirely children 
operation shrink inner box lies inner child shrink 
optimal algorithm approximate nearest neighbor searching inner boxes sticky enclosing outer boxes 
observe fair splits performed may generally possible guarantee points partitioned evenly 
tree resulting fair splits may balanced 
fairness split refers aspect ratio bound balance point partition 
intuitively shrink operation remedies shortcoming providing ability rapidly zoom regions data points highly clustered 
note split really special case shrink shrinking box sides common outer box 
reasons making distinction 
splitting necessary technical reasons maintaining invariants 
reason largely practical 
determining point lies shrinking box requires comparisons general 
hand determining side splitting hyperplane point lies requires comparison 
example dimension represents savings 
see programming tricks incrementally updating distances efficient splitting 
bbd tree constructed judicious combination fair split shrink operations 
recall set data points denote hypercube containing points root bbd tree node associated cell associated set entire set recursive construction algorithm cell subset data points associated cell 
stage algorithm determines subdivide current cell splitting shrinking partitions points child nodes 
repeated number associated points practically small constant called bucket size node leaf tree 
node data point consider question apply splitting shrinking 
mentioned splitting preferred simplicity fact consecutive splits geometric size associated cell decreases constant factor 
splitting guarantee point set partitioned evenly see shrinking provide 
simple strategy assume proving results splits shrinks applied alternately 
imply geometric size number points associated node decrease exponentially descend constant number levels tree 
practical approach implementation perform splits exclusively long cardinalities associated data sets decrease constant factor constant number splits 
condition violated shrink performed 
experience shown shrinking occasionally needed particular data sets arise highly clustered distributions critical efficiency search cases 
determined perform split shrink splitting plane shrinking box computed method described 
assume done time proportional number points associated current node 
splitting plane shrinking box known store information current node create link arya children nodes tree partition associated data points children 
data points lie boundary splitting surface points distributed children final partition possible 
recurse children 
partitioning points presenting details splitting plane shrinking box computed describe points partitioned 
employ technique partitioning multidimensional point sets due vaidya 
assume data points associated current node stored separate doubly linked lists sorted coordinate axes 
coordinates point stored 
consider list ith coordinate 
entry doubly linked list contains pointer point coordinate storage cross link instance point list sorted coordinate indices taken modulo 
point deleted list deleted lists time traversing cross links 
point associated exactly node stage construction total space needed store lists dn 
initial lists containing data points built dn log time sorting data points coordinates 
partition points enumerate points associated current node testing side splitting plane shrinking box lies 
label point accordingly 
dn time easy partition sorted lists sorted lists 
nodes level associated disjoint subsets follows total partition nodes level dn 
show tree log depth 
follow total spent partitioning entire construction algorithm dn log 
sorted lists needed efficiency process needed 
complete description construction algorithm suffices describe splitting plane shrinking box computed show done time linear number points associated node 
algorithms tasks midpoint algorithm algorithm borrowing term 
midpoint algorithm conceptually simpler implementation assumes manipulations exclusive integer division integer logarithm performed coordinates data points 
contrast algorithm assumptions somewhat complex 
midpoint algorithm variant described earlier version arya middle interval algorithm variant algorithm callahan kosaraju developed independently 
midpoint algorithm midpoint algorithm characterized restricting types rectangles arise construction 
define midpoint box box arise recursive application rule starting initial bounding hypercube optimal algorithm approximate nearest neighbor searching midpoint splitting rule 
midpoint box longest side sides having length smallest coordinate index 
split identical boxes hyperplane passing center orthogonal ith coordinate axis 
see 
seen binary variant standard quadtree splitting rule samet 
split midpoint time cyclically repeating sequence orthogonal hyperplanes 
midpoint algorithm uses midpoint boxes bbd tree 
easy verify midpoint box aspect ratio 
assume scaled unit hypercube length side midpoint box nonnegative power ith length endpoints side multiples follows bo bi midpoint boxes bi bo bi sticky bo ith length bo long bi aligned smaller power 
need take special care enforce stickiness 
nice consequence midpoint boxes boxes contained hierarchically 
implies inner boxes lie entirely side fair split shrink 
perform fair split simply perform midpoint split 
shrinking operation complicated 
shrinking performed part global operation called centroid shrink produce new nodes tree shrinking nodes splitting node 
nc denote number data points associated current cell 
goal centroid shrink decompose current cell constant number subcells containing nc data points 
giving description simplified approach centroid shrink quite show fix 
midpoint boxes centroid shrinking fig 

midpoint construction midpoint boxes centroid shrinking 
apply midpoint split outer box cell creating cells 
cells contain nc data points done 
centroid shrink degenerates single split 
take cell containing larger number points apply midpoint split 
repeat process splitting cell majority points arriving cell contains nc points 
see 
outer box cell shrinking box shrink operation 
intermediate splits arya creation box simply discarded generate new nodes bbd tree 
observe prior split box nc data points shrinking box contains nc points 
nc points inside shrinking box nc points outside shrinking box 
problems construction 
problem 
number midpoint splits needed procedure terminates generally bounded function nc data points tightly clustered 
problem 
resulting shrinking box necessarily contain inner box original cell required shrink operation 
remedy problem need accelerate decomposition algorithm points tightly clustered 
just repeatedly splitting combine operations shrinking tight enclosing midpoint box splitting box 
sorted coordinate lists determine minimum bounding rectangle necessarily box current subset data points time 
applying midpoint split compute smallest midpoint box contains rectangle 
claim done time assuming model computation exclusive integer floor powers integer logarithm computed point coordinates 
omit proof see section procedure really needed results 
see bern eppstein teng solution problem technique 
apply split operation minimal enclosing midpoint box 
minimality enclosing midpoint box follows split produce nontrivial partition point set 
nc nc repetitions shrink split combination succeeded reducing number remaining points nc 
remedy problem replace single stage shrink described simple approach stage decomposition shrinks splits shrinks 
suppose applying centroid shrink cell contains inner box bi 
compute minimum enclosing rectangle data points sure includes bi 
done easily time minimum enclosing rectangle data points 
apply iterated shrinking splitting combination encounter split separates bi box containing majority remaining points 
denote box just split 
see 
create shrinking node shrinking box outer child contains points lying outside inner child consists splitting node box containing bi side box containing majority data points side 
continue centroid shrinking procedure child cell contains majority points 
cell inner box procedure correctly compute desired shrinking node 
nodes created illustrated 
final result centroid shrink box lower left 
note illustrates general case 
example split separates bi majority need shrinking node 
remaining cells decomposed recursively 
note optimal algorithm approximate nearest neighbor searching cells contains nc data points 
bi bi fig 

midpoint construction centroid shrinking inner box 
bi shrink lemma 
parent node associated nc points assuming points stored coordinate sorted lists split centroid shrink performed dnc time 
proof 
centroid shrink clearly complex operations analysis 
making copy point lists described earlier dnc time 
consider split finding centroid box 
time compute minimal enclosing midpoint box splitting plane box 
letting denote number points box denote number points smaller side split show eliminate points dj time 
suppose splitting ith coordinate 
walking ith list inward ends determine subsets partition smaller time 
remove points subset list remove lists dj time traversing cross links 
lists contain data points larger subset size sorted order 
pass list iteration 
finding minimum enclosing box split nontrivial split eliminates points consideration 
letting denote time complete processing subset points see ignoring constant factors dnc time initial copying final point partitioning running time recurrence 
nc max dj 
easy induction argument shows nc dnc total running time operation dnc 
compute splitting plane shrinking box dnc time 
alternate splits shrinks shrinking reduces number points cell constant factor follows resulting tree height log 
arguments earlier follows entire tree constructed dn log time 
split arya middle interval algorithm section middle interval algorithm constructing splitting planes shrinking boxes 
require stronger model computation needed previous algorithm 
algorithm advantage offering greater degree flexibility choice splitting planes 
empirical experience shown flexibility provide significant constant factor improvements space query time highly skewed point distributions 
middle interval algorithm allows splitting plane chosen central strip current outer box 
need maintain stickiness aspect ratio bound choice splitting plane somewhat complicated 
algorithm basic structure algorithm previous section 
describe important differences 
consider perform fair split cell 
bo denote outer box current cell 
inner box split bo hyperplane perpendicular longest side passing center bo 
easy see general hyperplane perpendicular longest side splitting side ratio partition bo boxes satisfy aspect ratio bound 
practice alternative choices worthwhile produce data point partition reduce height tree 
inner box bi care taken splitting hyperplane intersect interior bi stickiness violated splitting 
consider projection bi longest side bo 
projection fully covers longest side bo consider second longest side bo finding bi fully cover side 
side exist bi bo 
observe stickiness projected interval properly contain central third side 
projection bi lies partially central third side select splitting plane central third passing face bi see 
projection bi lies entirely third 
case split edge center strip see 
bi fig 

middle interval algorithm fair split 
easy see operation preserves stickiness 
show lemma aspect ratio preserved 
optimal algorithm approximate nearest neighbor searching lemma 
cell consisting outer box bo inner box bi satisfying aspect ratio bound child boxes produced middle interval split algorithm satisfy bound 
proof 
observe longest side child boxes greater longest side bo 
consider cases longest side bo split second side bo split 
case shortest side child side split clearly aspect ratio increase splitting 
shortest side child splitting side construction third length parent longest side implying third length longest side 
second case longest side bo split 
construction implies projection bi dimension fully covers side 
follows bi bo longest side length size 
hypothesis bi satisfies aspect ratio bound suffices show side child long shortest side bi 
concreteness suppose high child contains bi 
clearly high child satisfies condition 
low child differs high child dimension dimension split 
xo xi xc denote lengths bo bi low child respectively dimension 
assert bi overlaps middle interval bo 
follows xi xo size bo size bi contradicting hypothesis bi satisfies aspect ratio bound 
bi overlaps middle interval splitting plane passes face bi implying distance bi low side low child xc 
bi sticky bo follows xc xi 
completes proof 
computing centroid shrink complicated approach previous section applied 
recall goal decompose current cell constant number cells contains fraction data points 
done repeatedly applying fair splits recursing cell containing majority remaining points number points falls original 
problems arose previous section arise 
problem solved exactly way centroid shrink generally produce nodes tree shrink box containing old inner box split separating inner box majority points shrink new inner box 
solve problem need eliminate possibility performing constant number splits succeeding nontrivially partitioning remaining points 
idea compute minimal box encloses data points inner box may part current cell 
achieving minimality stickiness difficult denotes minimum rectangle necessarily box encloses data points inner box suffices construct box contains rectangle size constant factor larger size box computed splits sufficient generate nontrivial partition turn implies nontrivial partition point set partition separating arya inner box majority points 
box satisfy stickiness conditions sticky current outer box inner box exists sticky construction box proof lemma 
lemma 
cell minimum bounding rectangle enclosing subset data points inner box cell inner box time possible construct box contained cell outer box contains longest side constant factor larger longest side ii cell inner box exists sticky iii sticky cell outer box 
proof 
bo denote cell outer box 
recall size rectangle length longest side 
observe size constant factor size bo bo 
assume size factor size bo 
attempt optimize constant 
construct applying series expansions consider cell inner box 
bi box 
hypothesis contains bi 
expand side encloses intersection bo regular grid copies bi surrounding bi 
see 
note bi sticky bo expansion necessarily lie bo 
subsequent expansions cause stickiness respect bi violated 
may increase longest side factor size size bo 
bo satisfies aspect ratio bound size side length side bo 
bo fig 

middle interval algorithm minimal box 
expand form hypercube 
lmax denote size side length lmax expanded lmax 
see 
lmax length side bo expansion contained bo 
expansion increase length longest side consider sticky bo 
expand violating sides meets corresponding side bo 
see 
expanded rectangle 
side length corresponding side bo follows expansion double length side 
particular may expanded direction dimension directions 
longest optimal algorithm approximate nearest neighbor searching side lmax shortest side lmax 
satisfies aspect ratio bound 
establishes 
construction satisfies properties ii iii 
size times size expansion steps easily performed time 
lemma solves problem 
centroid shrinking box computed essentially previous section 
repeatedly compute enclosing box described 
perform splits nontrivially partitioning point set 
note trivial split performed time partitioning needed 
recurse larger half partition 
process repeated number points decreases factor 
spite added complexity operation generates new nodes tree 
partitioning data points handled exactly previous algorithm 
entire construction performed dn log time 
final modifications concludes description construction algorithm bbd tree 
necessary perform final modifications tree describing nearest neighbor algorithm 
split shrink said trivial children contains data points 
possible tree construction algorithms generate trivial splits shrinks shown constant number consecutive trivial partitions 
hard see contiguous sequence trivial splits shrinks replaced single trivial shrink 
may assume data points lie inner box shrinking node simply remove inner box affecting subdivision 
constructing bbd tree replace sequence trivial splits shrinks single trivial shrink 
done time simple tree traversal 
able assume leaf contains data point generally case leaf nodes resulting trivial shrinks 
claim associate data point empty leaf cell borrowing point inner box 
furthermore claim done data point associated leaf cells 
see consider borrowing procedure 
nontrivial split shrink node recursively borrows point children passes parent 
parent trivial shrink uses points empty leaf child passes tree 
consecutive trivial shrinks splits grandparent nontrivial procedure succeeds borrowing different data point empty leaf 
summary characterization bbd tree 
theorem 
set data points rd ino dn log time construct binary tree having nodes representing hierarchical decomposition rd cells satisfying stickiness properties earlier height tree log general levels descent tree number points associated nodes decreases arya factor 
ii cells bounded aspect ratio levels descent tree sizes associated cells decrease factor 
iii leaf cell associated data point contained cell contained inner box cell 
data point associated leaf cells 
proof 
assume construction centroid shrinks alternated fair splits 
construction time space property iii follow earlier discussion section 
see observe centroid shrink introduces new levels tree alternate fair splits follows levels number points decreases factor 
ii note decrease size cell decrease size dimensions 
fair splits performed fourth level tree split decreases longest side factor follows splits levels tree size decreases factor 
bbd tree results construction quite similar tree described earlier version arya 
main differences centroid shrinking incorporated tree centroid shrink operation cells associated internal nodes tree bounded complexity 
properties significantly simplify implementation data structure 
size reduction property mentioned theorem ii important applications bbd trees geometric approximation problems arya mount mount 
know maintain bbd tree directly point insertion deletion auxiliary data structure topology tree frederickson dynamic tree sleator tarjan represent unbalanced box decomposition tree possible support data point insertions deletions log time 
see callahan kosaraju details 
somewhat practical approach insertion deletion achieve log amortized time insertion deletion rebuilding unbalanced subtrees ideas trees rivest 
key fact arbitrarily unbalanced subtree box decomposition tree possible replace balanced subtree representing underlying spatial subdivision time linear size subtree 
example done building topology tree subtree frederickson 

essential properties describing nearest neighbor algorithm enumerate important properties bbd tree relevant nearest neighbor searching 
justified 
recall cell rectangle difference rectangles contained 
recall leaf cells bbd tree form subdivision space 
cells subdivision satisfy properties 
optimal algorithm approximate nearest neighbor searching bounded occupancy cell contains constant number data points possibly zero 
points lie boundary cells assigned cells 
existence nearby data point cell contains data points points associated cell 
data point lying cell outer box associated cell 
done way data point associated different cells 
point location point cell subdivision containing determined log time 
packing constraint number cells size intersect open ball radius bounded function independent 
ball mean locus points distance point chosen minkowski distance metric 
distance enumeration cells define distance point cell closest distance part cell 
cells subdivision enumerated order increasing distance nearest cells enumerated md log time 
properties immediate consequences construction 
particular leaf cell contains point point associated different cells 
property follows simple descent tree 
lemma establishes property established 
proof lemma critical aspect ratio bound stickiness property introduced earlier 
lemma 
packing constraint bbd tree set data points rd number leaf cells size intersect minkowski lm ball radius proof 
aspect ratio bound smallest side length box size 
say set boxes disjoint interiors pairwise disjoint 
show maximum number disjoint boxes side length overlap minkowski ball radius minkowski ball radius enclosed axis aligned hypercube side length 
tightest fit realized case ball hypercube equal 
densest packing axis aligned rectangles side length realized regular grid cubes side length exactly 
interval length intersect intervals length follows number grid cubes overlapping cube side length upper bound number boxes side length overlap minkowski ball radius argument applied immediately outer boxes leaf cells disjoint leaves contained inner boxes 
complete proof show replace set leaf cells size overlap minkowski ball equal number disjoint boxes necessarily part spatial subdivision size overlap ball 
apply argument disjoint boxes 
arya bo fig 

packing constraint 
leaf cell size inner box inner box size inner box overlap ball take outer box cell set 
cases inner box contribute leaf set overlapping cells 
hand consider leaf cell formed difference outer box bo inner box bi size bi bi overlap ball 
bo inner box convexity boxes balls follows point boundary bi lies ball 
denote point 
see 
neighborhood intersects interiors bi 
stickiness know congruent copies bi surrounding bi lie entirely bo interiors disjoint bo 
clearly box containing boundary box contained bo 
box lying immediately 
take box replace set 
box disjoint bi size equal size bi overlaps ball 
leaf cells disjoint interiors inner box follows replacement box disjoint replacement boxes 
applying argument disjoint replacement boxes completes proof 
remaining property consider enumeration boxes increasing order distance point assume query point 
method simple variant priority search technique kd trees arya mount 
recall method 
algorithm maintains priority queue nodes bbd tree priority node inversely related distance query point cell corresponding node 
observe cell complexity compute distance time 
initially insert root bbd tree priority queue 
repeatedly carry procedure 
extract node highest priority queue node closest query point 

descend subtree visit leaf node closest query point 
cell consists difference dimensional rectangles determine child cell closer query point time 
simply recurse path closer children reaching desired leaf 
descend path leaf node visited compute distance cell associated sibling insert sibling optimal algorithm approximate nearest neighbor searching fig 

priority search 
priority queue 
example subtrees initially queue 
select closest descend tree leaf enqueuing siblings way 
straightforward proof correctness relies invariant set leaves descended nodes stored priority queue forms subdivision set unvisited leaves 
proved arya mount 
node tree visited enqueued 
nodes heap extract minimum log time 
step tree descent processed time time compute distances query point child cells plus time insert sibling priority queue 
assume fibonacci heap fredman tarjan priority queue amortized time insertion 
bbd tree log height processing internal node takes time leaf priority search determined log time 
time needed enumerate nearest cells query point md log 
property established 
implementing data structure stated number practical compromises worth mentioning 
observed size priority queue typically small suffices standard binary heap see cormen somewhat sophisticated fibonacci heap 
worth observing splitting nodes processed quite bit efficiently shrinking nodes 
shrinking node requires processing time determine query point lies inner box determine distance query point inner box 
possible show splitting nodes containing inner box processed time independent dimension 
takes arithmetic comparison determine side splitting plane query point lies 
furthermore minkowski metric possible incrementally update distance parent box children split performed 
construction arya called incremental distance computation described arya mount 
intuitively observation minkowski metric suffices maintain sum appropriate powers coordinate differences query point nearest point outer box 
split performed closer child distance parent child distance differs contribution single coordinate splitting dimension 
resulting improvement running time significant value higher dimensions 
reason shrinking performed sparingly needed guarantee balance bbd tree 

approximate nearest neighbor queries 
section show answer approximate nearest neighbor queries assuming data structure satisfying properties previous section 
query point rd recall output algorithm data point distance factor greater true nearest neighbor distance 
applying point location algorithm determine cell containing query point enumerate leaf cells subdivision increasing order distance recall leaf cell associated data point contained outer box cell 
cell visited process computing distance data points maintaining closest point encountered far 
denote point 
search terminates distance current cell exceeds dist 
reason subsequent point encountered closer dist approximate nearest neighbor 
follows enumerate nearest cells md log time 
establish total query time apply bound number cells visited 
lemma 
number leaf cells visited nearest neighbor algorithm cd minkowski metric 
proof 
denote distance query point leaf cell cause algorithm terminate 
know cells encountered far distance query point 
closest data point encountered far terminate dist 
claim cell seen far size suppose cell visited 
cell distance overlaps ball radius centered diameter cell minkowski metric times longest side length general times longest side lm metric 
cell associated data point lying outer box cell search encountered data point distance contradicts hypothesis closest point seen far 
optimal algorithm approximate nearest neighbor searching number cells visited termination bounded number cells size overlap ball radius property know number cells function bounds derived lemma number cells combining results previous sections established theorem 
extra factor differentiating cd theorem cd lemma due processing time compute distance query point visited node tree 

approximate nearest neighbors 
section show generalize approximate nearest neighbor procedure problem computing approximations nearest neighbors query point 
recall point isa approximate jth nearest neighbor point distance factor times distance true jth nearest neighbor 
answer approximate nearest neighbors query sequence distinct data points pk pj approximation th nearest neighbor algorithm simple generalization single nearest neighbor algorithm 
locate leaf cell containing query point enumerate cells increasing order distance maintain closest data points encountered search say storing balanced binary search tree sorted distance 
rk denote distance th closest point far rk fewer distinct points seen far 
search terminates soon distance current cell exceeds rk 
reason subsequently visited data point closer rk data point distance rk approximate kth nearest neighbor 
data points closer query point 
easy verify sorted sequence data points seen far solution approximate nearest neighbors query 
running time analyzed 
lemma 
recalling cd lemma algorithm visits cd leaf cells 
proof 
bound number leaf cells visited algorithm recall property point associated cells 
data points reported search contributed leaf cells visited search 
claim algorithm encounters cd leaf cells 
argument straightforward generalization lemma 
consider set visited leaf cells contribute point final answer 
denote distance cell set cause termination 
kth closest point encountered far 
lemma dist cells seen far size contributed point closer final result follows applying lemma 
complete proof recall algorithm spends log time process leaf cell time log log determine arya point nearest points encountered far add set combining earlier remarks section establishes theorem ii 

experimental results 
order establish practical value algorithms implemented ran number experiments number different data sizes point sets sampled number different distributions 
implementation differed slightly description previous sections 
preprocessing perform partitioning asymptotically efficient method described section storing points sorted dimensions 
opted simpler technique applying standard partitioning algorithm quicksort see cormen 
affect structure resulting tree splits unbalanced preprocessing may take longer dn log time 
hand save factor invocation coordinate accessed partition 
second sophisticated algorithms accelerating shrinking operation 
just performed repeated splits 
observed unusually high preprocessing times data sets tested 
mentioned earlier splitting generally preferred shrinking smaller factors involved 
splitting shrinking may result trees size greater height greater log 
implementation performed shrinking sequence consecutive splits failed reduce fraction points half 
distributions tested shrinking nodes generated 
highly clustered distributions relatively small fraction shrinking observed ranging total nodes tree 
part explains simple data structures kd trees perform point distributions 
arya mount incremental distance calculation described section speed distance calculations node 
experimented schemes selecting splitting planes 
midpoint split rule described section variant middle interval rule described section 
rule called fair split rule inspired term introduced callahan kosaraju 
box determine sides split violating aspect ratio bound 
subset data points define spread points dimension difference maximum minimum coordinates dimension 
sides split select dimension points maximum spread split dimension 
splitting hyperplane orthogonal dimension positioned points evenly distributed side subject aspect ratio bound 
ran experiments data structures additional comparison implemented optimized kd tree friedman 
cut planes placed median orthogonal coordinate axis having maximum spread 
kd tree guaranteed logarithmic depth guaranteed bound aspect ratios resulting cells ratios range higher uncommon 
know optimal algorithm approximate nearest neighbor searching prior suggesting kd tree approximate nearest neighbor queries termination condition section applied 
box decomposition tree prove upper bounds execution time query processing 
similarity data structure expect running times similar typical point distributions experiments bear 
experience showed adjusting bucket size maximum number points allowed leaf cell affects search time 
flexible kd tree fair split rule selected bucket size restricted midpoint split rule bucket size produced somewhat better results 
experiments run sun sparc running solaris 
experiment consisted data points dimension averages computed query points 
query points taken measuring cpu times due greater variations cpu time caused varying system loads 
query computed nearest neighbor metric 
noted query points data points taken distribution 
typical preprocessing times ranged cpu seconds 
higher running times evident highly clustered data sets midpoint split rule 
shrinking needed cases 
contrast optimized kd tree running time independent data distribution preprocessing times uniformly cpu seconds 
distributions tested distributions tested listed 
correlated gaussian correlated laplacian point distributions chosen model data applications speech processing 
point distributions formed grouping output autoregressive sources vectors length autoregressive source uses recurrence generate successive outputs xn xn wn wn sequence zero mean independent identically distributed random variables 
correlation coefficient taken experiments 
point generated selecting coordinate corresponding uncorrelated distribution gaussian laplacian remaining coordinates generated equation 
see information 
clustered distributions designed model data sets clustering 
clustered gaussian distribution points clustered small number randomly chosen cluster center points 
clustered segments distribution points clustered small number randomly chosen orthogonal line segments 
uniform 
coordinate chosen uniformly interval 
gaussian 
coordinate chosen gaussian distribution zero mean unit variance 
laplace 
coordinate chosen laplacian distribution zero arya mean unit variance 
correlated gaussian 
wn chosen marginal density xn normal variance unity 
correlated laplacian 
wn chosen marginal density xn laplacian variance unity 
clustered gaussian 
points chosen uniform distribution gaussian distribution standard deviation centered point 
clustered segments 
orthogonal line segments sampled hypercube follows 
line segment random coordinate axis xk selected point sampled uniformly hypercube 
line segment intersection hypercube line parallel xk passing equal number points generated uniformly length line segment plus gaussian error standard deviation 
clustered segments distribution trials run newly generated cluster centers trial involving query points 
query points sampled uniform distribution 
show results uniform distribution extreme cases correlated laplacian clustered segments distributions 
results distributions generally varied uniform case correlated laplacian 
query time experiment recorded number different statistics 
subset statistics starting query time 
measured average cpu time average number floating point operations query 
floating point operations called floats arithmetic operation involving point coordinates distances 
felt provides reasonable machine independent measure algorithm running time 
comparison cpu times floating operations shows relatively agreement 
ran experiments values ranging exact nearest neighbor increments 
results uniform correlated laplacian clustered segments distributions shown figures 
note axis logarithmic scale cases 
floats kd tree fair split midpoint split time sec epsilon epsilon kd tree fair split midpoint split fig 

floating point operations cpu time versus uniform distribution 
floats floats optimal algorithm approximate nearest neighbor searching kd tree fair split midpoint split time sec epsilon epsilon kd tree fair split midpoint split fig 

floating point operations cpu time versus correlated laplacian distribution 
kd tree fair split midpoint split time sec epsilon epsilon kd tree fair split midpoint split fig 

floating point operations cpu time versus clustered segments distribution 
empirical running times distributions suggest little significant practical advantage bbd tree kd tree 
feel kd tree enhanced improvements described allowing approximation errors incremental distance calculations priority search data structure nearest neighbor searching data sets 
perform badly circumstances especially data distribution clustered low dimensional subspaces clustered segments distribution 
low dimensional clustering uncommon practice 
inspection program statistics shown explains 
distribution kd tree produced large number cells high aspect ratios 
optimized kd tree cuts dimension greatest spread produce cells skinny dimensions data distributed long remaining dimensions 
skinny cells violate packing constraint critical analysis 
query point distribution differs data point distribution skinny cells may visited search 
uniformly distributed query points chosen 
contrast forced bounded aspect ratios midpoint splitting rule allowing shrinking 
result sort binary form arya quadtree 
highly clustered distributions clustered segments results trees order magnitude larger bbd tree size depth 
variants bbd trees took advantage shrinking produce reasonably small trees cells bounded aspect ratio 
shown running times significantly better kd tree distribution 
average distance error issue involves actual performance algorithm respect distance errors 
user supplies upper bound allowable distance error data structure may find points closer 
computed true nearest neighbor line computed actual relative error ratio distance point reported algorithm true nearest neighbor minus 
resulting quantity averaged query points called average relative error simply average error 
shown uniform correlated laplacian distributions 
distributions showed similar behavior 
results show large values average error committed typically order magnitude smaller 
theoretical justification phenomenon better average case performance may interest applications average error large number queries interest suggests interesting topic study 
average error kd tree fair split midpoint split average error epsilon epsilon kd tree fair split midpoint split fig 

average error uniform correlated laplacian distribution versus 
related statistic algorithm succeeds finding true nearest neighbor function 
algorithm manages locate true nearest neighbor surprisingly large number instances relative large values 
show plotted fraction instances algorithm fails return true nearest neighbor distributions 
results shown 
dependence dimension question involves constant factors depend dimension 
lemma define cd argue minkowski metrics nearest neighbor reported cd log time 
factor fraction optimal algorithm approximate nearest neighbor searching kd tree fair split midpoint split fraction epsilon epsilon kd tree fair split midpoint split fig 

fraction nearest neighbors missed uniform correlated laplacian distributions versus 
cd bounds number leaf cells visited algorithm 
factor crude worst case bound ignores number important practical issues 
get accurate sense sort factors expected practice ran experiment measure number cells visited algorithm varies function 
sought analytical explanation results 
chose relatively behaved case consider experiments uniformly distributed points unit hypercube metric 
negligible differences various data structures uniformly distributed data evidenced ran experiments kd tree bucket size 
considered dimensions varying values varying 
considered data sets size data set averaged results queries 
plot relationship logarithm base number leaf cells visited versus dimension shown 
shows number cells significantly smaller huge values predicted formula 
example dimension formula provides unusable bound plot shows number cells roughly distribution 
cells epsilon cells dimension epsilon epsilon fig 

number cells visited versus dimension 
dim dim dim dim dim dim dim dim arya provide informal analytical justification empirical results 
follow general structure analysis friedman bentley finkel 
large uniformly distributed data sets reasonable model decomposition unit hypercube regular grid hypercubes hypercube side length roughly ignoring boundary effects expected side length nearest neighbor ball random query point algorithm need visit leaf cell overlaps shrunken nearest neighbor ball side length 
easy see expected number intervals width overlapped randomly placed interval width 
follows number grid cubes width overlapped randomly placed cube width follows fixed dimension linear relationship expected logarithm number cells logarithm 
relationship evidenced 
note axes logarithmic scale 
boundary effects probably play role empirically observed values somewhat smaller predicted formula arya 
summary experiments number drawn experiments 
moderate dimensions significant savings running time achieved computing approximate nearest neighbors 
cases improvements running time order factors exact case common 
clustered data sets significant improvements seen smaller values 
algorithm average error significantly smaller predicted user supplied bound 
high implying relative error tolerated average relative errors typically true nearest neighbor half time 
distributions relatively little difference running time effective performance different splitting rules kd tree upper bounds search time proved 
bbd tree retains efficiency kd tree cases robust highly clustered data sets kd tree performance worse 
dependencies dimension lower bounds theorem 

showed bbd tree approximate nearest neighbor queries set points answered cd log time cd constant depending dimension 
data structure uses optimal dn space built dn log time 
algorithms simple especially midpoint splitting rule easy implement 
empirical studies indicate performance number different point distributions 
results approximate nearest neighbor searching preprocessing independent different levels optimal algorithm approximate nearest neighbor searching precision provided data structure 
constant factors query time grow exponentially dimension constant factors space preprocessing time grow linearly shown algorithms generalized enumerate approximate nearest neighbors additional kd log time 
auxiliary data structures possible handle point insertions deletions log time 
somewhat simplified version bbd tree implemented 
software available web www cs umd edu mount ann 
number important open problems remain 
improving constant factors query time 
practical appeal data structure optimal dn size large data sets important question lower bounds established approximate nearest neighbor searching data structures size 
question approximate kth nearest neighbor computed time polylogarithmic acknowledgments michiel smid helpful comments 
reviewers number useful comments suggestions 
agarwal matou sek comput 


ray shooting parametric search 
siam arya mount 
algorithms fast vector quantization 
storer cohn eds proc 
dcc data compression conference pp 

ieee press 
arya mount 
approximate nearest neighbor queries fixed dimensions 
proc 
th acm siam sympos 
discrete algorithms pp 

arya mount 
approximate range searching 
proc 
th annu 
acm sympos 
comput 
geom 
pp 

arya mount narayan 
accounting boundary effects nearest neighbor searching 
proc 
th annu 
acm sympos 
comput 
geom 
pp 

arya mount netanyahu silverman wu 
optimal algorithm approximate nearest neighbor searching fixed dimensions 
proc 
th acm siam sympos 
discrete algorithms pp 

bei 
gray 
improvement minimum distortion encoding algorithm vector quantization 
ieee transactions communications 
bentley weide yao 
optimal expected time algorithms closest point problems 
acm transactions mathematical software 
berchtold hm keim kriegel 

cost model nearest neighbor search high dimensional data space 
proc 
annu 
acm sympos 
principles database syst 
pp 

berchtold keim kriegel 

tree index structure high dimensional data 
proc 
nd vldb conference pp 

bern 
approximate closest point queries high dimensions 
inform 
process 
lett 

bern eppstein teng 

parallel construction quadtrees quality triangulations 
proc 
rd workshop algorithms data struct volume lecture notes computer science pp 

springer verlag 

optimal algorithm closest pair maintenance 
proc 
th annu 
acm sympos 
comput 
geom 
pp 

arya callahan kosaraju 
decomposition multi dimensional applications nearest neighbors body potential fields 
proc 
th ann 
acm sympos 
theory comput 
pp 

callahan kosaraju 
algorithms dynamic closest pair body potential fields 
proc 
th acm siam sympos 
discrete algorithms pp 

chan 
approximate nearest neighbor queries revisited 
proc 
th annu 
acm sympos 
comput 
geom 
pp 

chazelle 
theorem polygon cutting applications 
proc 
rd annu 
ieee sympos 

comput 
sci 
pp 

clarkson 
fast algorithms nearest neighbors problem 
proc 
th ann 
ieee sympos 

comput 
sci 
pp 

clarkson 
randomized algorithm closest point queries 
siam journal computing 
clarkson 
algorithm approximate closest point queries 
proc 
th annu 
acm sympos 
comput 
geom 
pp 

cleary 
analysis algorithm finding nearest neighbors euclidean space 
acm transactions mathematical software 
cormen leiserson rivest 
algorithms 
mit press cambridge ma 
cost salzberg 
weighted nearest neighbor algorithm learning symbolic features 
machine learning 
cover hart 
nearest neighbor pattern classification 
ieee trans 
inform 
theory 
de berg van kreveld overmars schwarzkopf 
computational geometry algorithms applications 
springer verlag berlin 
deerwester furnas landauer harshman 
indexing semantic analysis 
amer 
soc 
inform 
sci 

devroye wagner 
nearest neighbor methods discrimination 
krishnaiah kanal eds handbook statistics volume 
north holland 
duda hart 
pattern classification scene analysis 
john wiley sons ny 
edelsbrunner 
algorithms combinatorial geometry volume eatcs monographs theoretical computer science 
springer verlag heidelberg west germany 

rate distortion performance dpcm schemes autoregressive sources 
ieee transactions information theory may 
fayyad piatetsky shapiro smyth uthurusamy 
advances knowledge discovery data mining 
aaai press mit press 
feder greene 
optimal algorithms clustering 
proc 
th annu 
acm sympos 
theory comput 
pp 

flickner sawhney niblack ashley huang dom gorkani hafner lee petkovic steele yanker 
query image video content qbic system 
ieee computer 
frederickson 
data structures line updating minimum spanning trees applications 
siam comput 

frederickson 
data structure dynamically maintaining rooted trees 
proc 
th acm siam sympos 
discrete algorithms pp 

fredman tarjan 
fibonacci heaps uses improved network optimization algorithms 
journal acm 
friedman baskett 
algorithm finding nearest neighbors 
ieee trans 
comput 

optimal algorithm approximate nearest neighbor searching friedman bentley finkel 
algorithm finding best matches logarithmic expected time 
acm transactions mathematical software 
rivest 
trees 
proc 
th acm siam sympos 
discrete algorithms pp 

gersho gray 
vector quantization signal compression 
kluwer academic boston ma 
guan kamel 
equal average hyperplane partitioning method vector quantization image data 
pattern recognition letters 
indyk motwani 
approximate nearest neighbors removing curse dimensionality 
proc 
th annu 
acm sympos 
theory comput 

appear 
kleinberg 
algorithms nearest neighbor search high dimension 
proc 
th annu 
acm sympos 
theory comput 
pp 

kushilevitz ostrovsky rabani 
efficient search approximate nearest neighbor high spaces 
proc 
th annu 
acm sympos 
theory comput 

appear 
lee 
chen 

fast closest codeword search algorithm vector quantisation 
iee proc vis 
image signal process 

lin faloutsos 
tv tree index structure high dimensional data 
vldb journal 

point location arrangements hyperplanes 
information computation 
mount netanyahu silverman wu 
chromatic nearest neighbor searching query sensitive approach 
proc 
th canad 
conf 
comput 
geom 
pp 

preparata shamos 
computational geometry 
springer verlag new york ny 
rivest 
optimality elias algorithm performing best match searches 
information processing pp 

north holland publishing 
roussopoulos kelley vincent 
nearest neighbor queries 
proc 
acm sigmod conf 
management data pp 

samet 
design analysis spatial data structures 
addison wesley reading ma 
schwarz smid snoeyink 
optimal algorithm line closest pair problem 
algorithmica 
sleator tarjan 
data structure dynamic trees 
comput 
syst 
sci 

sproull 
refinements nearest neighbor searching 
algorithmica 
vaidya 
log algorithm nearest neighbors problem 
discrete comput 
geom 

white jain 
similarity indexing ss tree 
proc 
th ieee internat 
conf 
data engineering pp 

yao yao 
general approach dimensional geometric queries 
proc 
th ann 
acm sympos 
theory comput 
pp 

