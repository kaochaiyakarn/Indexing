letter communicated bartlett mel emergence phase shift invariant features decomposition natural images independent feature subspaces hyv rinen patrik hoyer helsinki university technology laboratory computer information science fin hut finland olshausen field applied principle independence maximization sparse coding extract features natural images 
leads emergence oriented linear filters simultaneous localization space frequency resembling gabor functions simple cell receptive fields 
article show principle independence maximization explain emergence phase shift invariant features similar complex cells 
new kind emergence obtained maximizing independence norms projections linear subspaces independence simple linear filter outputs 
norms projections independent feature subspaces indicate values invariant features 
fundamental approach signal processing design statistical generative model observed signals 
approach useful modeling properties neurons primary sensory areas 
modeling visual data simple linear generative model olshausen field showed principle maximizing sparseness underlying image components explain emergence gabor filters resemble receptive fields simple cells mammalian primary visual cortex 
maximizing sparseness context equivalent maximizing independence image components comon bell sejnowski olshausen field 
show article principle explain emergence shift invariant features principal properties complex cells 
method feature subspaces kohonen model response complex cell norm projection input vector image patch linear subspace equivalent classical energy models 
maximize independence norms projections energies 
obtain features localized neural computation massachusetts institute technology hyv rinen patrik hoyer space oriented bandpass selective scale frequency simple cells gabor analysis 
contrast simple linear filters obtained features show emergence phase invariance limited shift translation invariance 
phase invariance means response depend fourier phase stimulus response white bar black bar bar edge 
limited shift invariance means near maximum response elicited identical bars edges slightly different locations 
properties closely parallel properties distinguish complex cells simple cells 
maximizing independence equivalently sparseness norms projections feature subspaces allows emergence exactly invariances encountered complex cells indicating fundamental importance image data 
independent component analysis image data basic models consider express static monochrome image linear superposition features basis functions bi bi si si stochastic coefficients different image 
crucial assumption si nongaussian mutually independent 
type decomposition called independent component analysis ica comon bell sejnowski hyv rinen oja alternative viewpoint sparse coding olshausen field 
estimation model equation consists determining values si bi sufficient number observations images practice image patches 
restrict basic case bi form invertible linear system 
invert system si wi wi denote inverse filters wi wi denotes dot product 
wi identified receptive fields model simple cells si activities image patch 
olshausen field showed model estimated input data consisting patches natural scenes obtained filters wi principal properties simple cells localized oriented bandpass 
van hateren van der schaaf compared quantitatively obtained filters wi measured single cell recordings macaque cortex match parameters 
emergence phase shift invariant features decomposition independent feature subspaces addition essentially linear simple cells important class cells complex cells 
complex cells share mentioned properties simple cells principal distinguishing properties phase invariance limited shift invariance hubel wiesel pollen preferred orientation frequency 
note invariance respect shift global fourier phase equivalent different properties phase computed local fourier transform 
distinguishing property complex cells receptive fields larger simple cells difference quantitative consequence 
details see heeger pollen mel ruderman archie 
date attempts formulate statistical model explain emergence properties visual complex cells 
simple see ica equation directly modeling complex cells 
due fact model activations neurons si linearly reconstruct image true complex cells due principal properties phase invariance shift invariance 
responses complex cells give phase exact position stimulus linear function equation 
see von der malsburg nonlinear reconstruction image complex cell responses 
purpose article explain emergence phase features modification ica model 
modification combining technique multidimensional independent component analysis cardoso principle invariant feature subspaces kohonen 
describe developed techniques 
invariant feature subspaces 
classical approach feature extraction linear transformations filters 
presence feature detected computing dot product input data feature vector 
example wavelet gabor fourier transforms models simple cells linear features 
problem linear features necessarily lack invariance respect transformations spatial shift change local fourier phase pollen kohonen 
kohonen developed principle invariant feature subspaces approach representing features invariances 
principle states may consider invariant feature linear subspace feature space 
value invariant higher order feature square norm projection data point subspace typically spanned lower order features 
hyv rinen patrik hoyer feature subspace linear subspace represented set orthogonal basis vectors say wi dimension subspace 
value feature input vector wi 
simplicity notation terminology distinguish clearly norm square norm article 
fact equivalent computing distance input vector general linear combination basis vectors filters wi feature subspace kohonen 
graphical depiction feature subspaces 
kohonen showed principle combined competitive learning techniques lead emergence invariant image features 
multidimensional independent component analysis 
multidimensional independent component analysis cardoso linear generative model equation assumed 
contrast ordinary ica components responses si assumed mutually independent 
assumed si divided couples triplets general tuples si inside tuple may dependent dependencies different tuples allowed 
tuple si corresponds basis vectors bi 
call subspace spanned set basis vectors independent feature subspace 
general dimensionality independent subspace need equal assume simplicity 
model simplified additional assumptions 
components si independent define uncorrelated unit variance 
fact linear dependencies inside tuple dependent components removed linear transformation 
second assume data whitened sphered accomplished example pca comon 
whitening conventional preprocessing step ordinary ica basis vectors bi orthogonal comon hyv rinen oja ignore finite sample effects 
assumptions imply bi orthonormal take bi wi ordinary ica whitened data 
particular independent subspaces orthogonal whitening 
facts follow directly proof comon applies due assumptions 
emergence phase shift invariant features graphical depiction feature subspaces 
dot products input data set basis vectors taken 
subspaces basis vectors 
dot products squared sums taken inside feature subspaces 
obtain squares norms projections feature subspaces considered responses subspaces 
square roots may taken normalization 
scheme represents features go simple linear filters possibly obtaining invariance respect transformations input example shift phase invariance 
subspaces underlying vectors wi may learned principle maximum sparseness coincides maximum likelihood generative model 
hyv rinen patrik hoyer denote number independent feature subspaces sj set indices si belonging subspace index assume data consist observed image patches ik express likelihood data model follows ik wi det pj wi ik sj pj function arguments wi ik sj gives probability density inside jth tuple si matrix containing filters wi columns 
term det appears expression probability density transformation giving change volume produced linear transformation see pham jutten 
dimensional probability density pj 
specified advance general definition multidimensional ica cardoso 
combining invariant feature subspaces independent subspaces 
invariant feature subspaces embedded multidimensional independent component analysis considering probability distributions tuples si spherically symmetric depend norm 
words probability density pj 
tuple index expressed function sum squares si sj 
simplicity assume pj 
equal subspaces 
means logarithm likelihood data observed image patches ik model expressed log ik wi log wi ik log det sj sj pj si sj gives probability density inside jth tuple si 
recall allows consider wi orthonormal implies log det zero 
shows likelihood equation function norms projections ik subspaces indexed spanned orthonormal basis sets wi sj 
norm projection visual data emergence phase shift invariant features practically subspace supergaussian distribution need choose probability density model sparse olshausen field supergaussian hyv rinen oja 
example probability distribution log sj sj considered multidimensional version exponential field 
scaling constant normalization constant determined give probability density compatible constraint unit variance si irrelevant 
see estimation model consists finding subspaces norms projections whitened data subspaces maximally sparse distributions 
introduced independent feature subspace analysis natural generalization ordinary ica 
fact projections subspaces reduced dot products projections dimensional subspaces model reduces ordinary ica provided addition independent components assumed symmetric distributions 
expected norms projections subspaces represent higher order invariant features 
exact nature invariances specified model emerge input data prior information independence 
independent feature subspace analysis applied natural image data identify norms projections sj responses complex cells 
individual filter vectors wi identified receptive fields simple cells interpreted hierarchical model complex cell response computed simple cell responses si manner similar classical energy models complex cells hubel wiesel pollen heeger 
noted model specify particular basis invariant feature subspace 
learning independent feature subspaces 
learning independent feature subspace representation simply achieved gradient ascent log likelihood equation 
due whitening constrain vectors wi orthogonal unit norm ordinary ica constraints usually speed convergence 
stochastic gradient ascent log likelihood obtained wi wi wr sj hyv rinen patrik hoyer index subspace wi belongs nonlinear function incorporates information sparseness norms projections 
example choose distribution equation positive constant ignored 
step equation vectors wi need variety methods perform see hyv rinen oja karhunen oja wang 
learning rule equation considered modulated nonlinear hebbian learning 
subspace contains wi just onedimensional learning rule reduce learning rules ordinary ica hyv rinen oja closely related bell sejnowski cardoso laheld karhunen 

difference general case hebbian term divided function output complex cell sj wr ifwe assume terminology energy models 
words hebbian term modulated top feedback signal 
addition modulation neurons interact form feedback 
experiments test model patches natural images input data ik estimated model independent feature subspace analysis 
data methods 
data obtained pixel image patches random locations monochrome photographs depicting wildlife scenes animals meadows forests 
images taken directly available world wide web 
mean gray scale value image patch dc component subtracted 
data low pass filtered reducing dimension data vector principal component analysis retaining principal components largest variances 
data whitened zero phase whitening filter means multiplying data covariance data pca see bell sejnowski 
preprocessing steps essentially similar olshausen field van hateren van der schaaf 
likelihood equation observations maximized constraint orthonormality filters whitened space averaged version learning rule equation ordinary gradient likelihood stochastic gradient 
fact data contained dimensional subspace meant basis vectors wi formed orthonormal system subspace original space necessitate www address www cis hut fi projects ica data images emergence phase shift invariant features linear filter sets associated feature subspaces model complex cells estimated natural image data 
group filters spans single feature subspace whitened data 
changes learning rule 
density chosen equation 
algorithm initialized bell sejnowski wi middle columns identity matrix 
tried random initial values yielded qualitatively identical results localized filter set initial value considerably improves convergence method especially avoiding filters getting stuck local minima 
initialization led incidentally weak topographical organization filters 
computations took hours single risc processor 
experiments different dimensions sj subspaces single run subspaces dimension 
results show dimensional subspaces results similar dimensions 
results 
shows filter sets feature subspaces complex cells subspace dimension chosen 
results shown zero phase whitened space 
note due orthogonality filters equal basis vectors 
filters look qualitatively similar original whitened space 
difference original space filters sharper concentrated higher frequencies 
hyv rinen patrik hoyer typical stimuli experiments figures 
middle column shows optimal gabor stimulus 
parameters varied time 
top row varying phase 
middle row varying location shift 
bottom row varying orientation 
linear filters associated single complex cell approximately orientation frequency 
locations identical close 
phases differ considerably 
feature subspace considered generalization quadrature phase filter pair classical energy models pollen enabling cell selective orientation frequency invariant phase somewhat invariant shifts 
filters pair greatly enhances shift invariance feature subspace 
fact subspace dimension obtained approximately quadrature phase filter pairs 
demonstrate quantitatively properties model compared responses representative feature subspace associated linear filters different stimulus configurations 
optimal stimulus feature subspace computed set gabor filters 
stimulus parameters changed time see response changes parameters held constant optimal values 
typical depicted 
investigated parameters phase orientation location shift 
shows results typical feature subspace 
linear filters spanning feature subspace shown 
optimal stimulus values feature subspace represented results values departures optimal values 
responses arbitrary units 
different phases ranging emergence phase shift invariant features responses elicited feature subspace underlying linear filters different stimuli stimuli 
arbitrarily chosen filters spanning feature subspace 
effect varying phase 
upper rows absolute responses linear filters simple cells stimuli different phases 
bottom row response feature subspace complex cell 
effect varying location shift 
effect varying orientation obtained 
bottom row response curve feature subspace comparison absolute values responses associated linear filters shown plots hyv rinen patrik hoyer 
similarly obtained different locations location moved direction perpendicular preferred orientation shift units arbitrary different orientations ranging 
response curve feature subspace shows clear invariance respect phase location note response curve location consists approximately gaussian envelope observed complex cells von der heydt 
contrast invariance orientation observed 
responses linear filters hand show invariances respect parameters fact necessary consequence linearity filters pollen von der heydt 
feature subspace shows desired properties phase invariance limited shift invariance contrasting properties underlying linear filters 
see results hold population feature subspaces computed response curves feature subspaces comparison underlying linear filters 
optimal stimuli separately computed feature subspaces 
contrast results computed optimal stimuli separately linear filter facilitates quantitative comparison 
response values normalized maximum response subspace linear filter equal 
shows responses typical feature subspaces typical linear filters shows median responses population feature subspaces linear filters percentiles 
figures responses varying phases 
top row shows absolute responses linear filters bottom row corresponding results feature subspaces depicted 
figures show phase invariance strong property feature subspaces minimum response usually thirds maximum response 
figures show results location shift 
clearly receptive field typical feature subspace larger invariant typical linear filter 
orientation figures depict corresponding results showing orientation selectivity approximately equivalent linear filters feature subspaces 
see invariances respect translation especially phase orientation selectivity hold population feature subspaces general 
discussion approach closely related adaptive subspace selforganizing map kohonen competitive learning invariant feature subspace representation similar 
twodimensional subspaces emergence filter pairs phase invariance limited shift invariance shown kohonen emergence phase shift invariant features typical response curves feature subspaces underlying linear filters parameter optimal stimulus varied 
top row responses absolute values linear filters simple cells 
bottom row responses feature subspaces complex cells 
effect varying phase 
effect varying location shift 
effect varying orientation 
emergence shift invariance kohonen conditional restricting consecutive patches come nearby locations image giving input data temporal structure smoothly changing image sequence 
similar developments ldi 
contrast hyv rinen patrik hoyer statistical analysis properties population feature subspaces corresponding results linear filters comparison 
plots solid line gives median response population cells filters subspaces dashed lines give percent percent percentiles responses 
stimuli 
top row responses absolute values linear filters simple cells 
bottom row responses feature subspaces complex cells 
effect varying phase 
effect varying location shift 
effect varying orientation 
theories formulated explicit image model showing emergence possible patches random independently selected locations proves information static images explain properties complex cells 
provided model emergence phase shift invariant features principal properties visual complex cells principle maximization independence comon barlow field explain simple cell properties olshausen field 
maximizing independence equivalently sparseness linear filter outputs model gives simple cell properties 
maximizing independence norms projections linear subspaces complex cell properties emerge 
provides evidence fundamental importance dependence reduction strategy sensory information processing 
fact closely related fundamental objectives minimizing code length reducing redundancy emergence phase shift invariant features barlow field olshausen field 
remains seen framework account movement related binocular chromatic properties complex cells simple cell model success respect van hateren ruderman 
extending model include overcomplete bases olshausen field may useful purposes 
barlow 

unsupervised learning 
neural computation 
barlow 

computational goal neocortex 
koch davis eds large scale neuronal theories brain 
cambridge ma mit press 
bell sejnowski 

independent components natural scenes edge filters 
vision research 
cardoso 

multidimensional independent component analysis 
proc 
icassp seattle wa 
cardoso laheld 

equivariant adaptive source separation 
ieee trans 
signal processing 
comon 

independent component analysis new concept 
signal processing 
field 

goal sensory coding 
neural computation 
ldi 

learning invariance transformation sequences 
neural computation 
heeger 

normalization cell responses cat striate cortex 
visual neuroscience 
hubel wiesel 

receptive fields binocular interaction functional architecture cat visual cortex 
journal physiology 
hyv rinen oja 

fast fixed point algorithm independent component analysis 
neural computation 
hyv rinen oja 

independent component analysis general nonlinear hebbian learning rules 
signal processing 
karhunen oja wang 

class neural networks independent component analysis 
ieee trans 
neural networks 
kohonen 

self organizing maps 
berlin springer verlag 
kohonen 

emergence invariant feature detectors self organizing map 
biological cybernetics 
mel ruderman archie 

translation invariant orientation tuning visual complex cells derive computations 
journal neuroscience 
olshausen field 

emergence simple cell receptive field properties learning sparse code natural images 
nature 
olshausen field 

sparse coding overcomplete basis set strategy employed 
vision research 
hyv rinen patrik hoyer pham jutten 

separation mixture independent sources maximum likelihood approach 
proc 
eusipco pp 

pollen 

visual cortical neurons localized spatial frequency filters 
ieee trans 
systems man cybernetics 
van hateren ruderman 

independent component analysis natural image sequences yields spatiotemporal filters similar simple cells primary visual cortex 
proc 
royal society ser 

van hateren van der schaaf 

independent component filters natural images compared simple cells primary visual cortex 
proc 
royal society ser 

von der heydt 

form analysis visual cortex 
ed cognitive neurosciences pp 

cambridge ma mit press 
von der malsburg 

recognition images complex cell responses 
proc 
society neuroscience meeting 
received september accepted may 
