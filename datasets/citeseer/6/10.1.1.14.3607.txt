memory coherence shared virtual memory systems studies memory coherence problem de signing implementing shared virtual memory loosely coupled multiprocessors 
classes algorithms ing problem 
prototype shared virtual memory apollo ring implemented algorithms 
theoretical practical results show memory coherence problem solved efficiently loosely coupled multiprocessor 
benefits virtual memory go saying high performance sequential computer ex today incorporates 
virtual memories useful hard believe parallel architectures benefit 
easily imagine virtual memory incorporated shared memory parallel machine memory hierar chy need different sequential machine 
hand loosely coupled multi processor physical memory distributed implementation obvious knowledge implementation exists 
shared virtual memory described pro vides virtual address space shared processors loosely coupled multiprocessor system shown graphically 
shared memory exists virtually 
application programs way traditional virtual memory course processes run different processors parallel 
permission copy fee part material granted provided copies distributed direct commercial advantage acm copyright notice title publication date appear notice copying permission association computing machinery 
copy republish requires fee permission 
acm kai li paul hudak department computer science yale university new haven ct shared virtual memory describe pages data physical memories disks conventional virtual memory system pages data physical memories individ ual processors 
data naturally migrate processors demand 
furthermore just conventional memory pages processes shared vir tual memory 
approach provides natural efficient form process migration processors distributed system normally difficult feature implement effect subsuming notion remote procedure call 
cpu memory cpu memory shared virtual memory shared virtual memory mapping 
cpu memory main difficulty building shared virtual memory solving memory coherence problem 
problem similar arises conventional caches see survey particular schemes shared memory multiprocessors 
concentrate memory coherence prob lem shared virtual memory 
number algorithms axe analyzed compared 
gorithms implemented local area network apollo workstations 
experimental results non trivial parallel programs demonstrate ity shared virtual memory loosely coupled systems apollo network 
success suggests research supported part nsf mcs dcr 
radically different viewpoint architectures exploit total processing power memory ca systems far unified way traditional message passing approach 
design choices memory design goals require shared virtual memory coherent 
memory coherent value returned read operation value written write operation address 
coherence maintained shared virtual memory satisfies single constraint processor allowed update piece data processor updating reading 
allows processors read piece data long processor updating form known readers writers problem 
design choices greatly influence implementation shared virtual memory granular ity memory units strategy maintaining coherence 
granularity size memory units coherently maintained important consideration shared vir tual memory 
discuss section criteria choosing granularity 
typical loosely coupled multiprocessor system send ing large packets data say bytes expensive sending small ones say bytes 
usually due typical software protocols overhead virtual memory layer operating system 
fact relatively large memory units feasible 
hand larger memory unit greater chance contention 
memory contention oc processors attempt write location shared memory system processors attempt write different locations memory unit 
clever memory alloca tion strategies minimize contention arranging con current memory accesses locations different memory units strategy lead inefficient memory space introduce inconvenience pro grammer 
possibility contention pushes relatively small memory units 
suitable compromise granularity typical page conventional virtual memory implementation 
page sizes today computers vary typically bytes bytes 
choosing size memory unit advantages 
experience shown sizes suitable respect contention previous argument impose undue commu overhead long page fit packet 
addition choice allows existing page fault schemes hardware mechanisms allow single instructions trigger page faults trap appropriate fault handlers 
done setting access rights pages way memory accesses violate memory coherence cause page fault memory coherence problem solved modular way page fault handlers 
part justification page size granularity course memory sequential programs generally high degree locality 
memory parallel programs may behave differ sequential ones single process remains sequential program exhibit high degree locality 
contention parallel processes piece data depends algorithm course common goal designing parallel algorithms mini contention optimal performance 
memory coherence strategies helpful consider spectrum strategies may choose solve memory coherence prob lem 
strategies may classified way deals page synchronization page ownership shown table 
page synchronization basic approaches page synchronization invalidation writeback 
invalidation approach processor write fault fault handler copy true page containing memory location invalidate copies page change access page write return faulting instruction 
return ing processor owns page proceed write operation read write operations page ownership relinquished processor 
writeback approach processor write fault fault handler write copies page return faulting instruction 
sense approach ideal supports broadest tion sharing simulates centralized shared memory note write shared page generate fault writing processor update copies 
clearly doing updates expensive algorithms writeback appropriate loosely coupled 
consider indicated table 
page ownership ownership page handled statically dynamically 
static approach page owned processor 
means processors full write access page negotiate owning processor gener ate write fault time need update page 
page synchronization method page ownership strategy dynamic static distributed manager centralized manager fixed dynamic okay invalidation appropriate writeback appropriate appropriate appropriate appropriate table spectrum solutions memory coherence problem 
writeback approach expensive solution existing loosely coupled multiprocessors furthermore constraining desired modes par computation 
consider dynamic ownership strategies indicated table 
strategies maintaining dynamic page ownership subdivided classes centralized dis tributed 
refer process controls page manager centralized distributed managers 
distributed managers fur ther classified fixed dynamic referring distribution ownership data described 
resulting combinations strategies shown table marked inappropriate combi nations involving writeback synchronization static page ownership 
consider remaining choices 
mentioned earlier page size granularity allows hardware page protection mechanisms cause fault invalid memory occurs resolve memory coherence problems page fault handlers 
algorithms solving memory ence problem manifested fault handlers servers processes handle remote requests fault ing processors page tables operate 
sections investigate algo rithms 
centralized manager algorithms monitor centralized manager algorithm centralized manager similar monitor consist ing data structure procedures provide mutually exclusive access data structure 
cen manager resides single processor main tains table called info entry page entry having fields 
owner field contains single processor owns page processor write access 

copy set field lists processors copies page 
allows invalidation operation performed broadcast 

lock field synchronizing requests page described shortly 
processor page table called ptable fields access lock 
table keeps information accessibility pages local processor 
algorithm page fixed owner manager knows owner owner page sends copy processors requesting read copy 
long read copy exists page writable invalidation operation causes invalidation messages sent processors contain ing read copies 
monitor style algorithm easy see successful writer page truth page 
processor finishes read write request confirmation message sent manager indicate completion request 
info table ptable page locks 
synchronize local page faults fault handler operations remote fault requests server operations 
process processor waiting page locking mechanism prevents processor sending request 
remote request page arrives processor accessing page table entry locking mechanism queue request entry released 
algorithm characterized fault handlers servers read fault handler lock ptable lock am manager lock info lock info copy set info copy set manager node receive page info owner unlock info lock ask manager read access send confirmation manager ptable access read unlock ptable lock read server lock ptable lock am owner ptable access read send copy unlock ptable lock am manager lock info lock info copy set info copy set request node ask info owner send copy request node receive confirmation request node unlock info lock write fault handler lock ptable lock am manager lock info lock invalidate info copy set info copy set unlock info lock ask manager write access send confirmation manager ptable access write unlock ptable lock write server lock ptable lock am owner send copy ptable access nil unlock ptable lock am manager lock info lock invalidate info copy set info copy set ask info owner send request node receive confirmation request node unlock info lock confirmation message indicates completion request manager manager give page 
locking mecha nism data structure manager synchronizes multiple requests different processors 
centralized manager plays role helping processors locate page consider number messages locating page measure complexity theorem worst case number messages lo cate page centralized manager algorithm 
algorithm uses messages ing page requires confirmation message fault appears non manager processor 
eliminating confirmation operation motivation improvement algorithm 
improved centralized manager gorithm primary difference improved centralized manager algorithm previous syn page ownership moved indi vidual owners eliminating confirmation operation manager 
locking mechanism processor deals multiple local requests remote requests 
manager answers ques tion page owner longer synchronizes requests 
accommodate changes data structure manager change 
specifically manager longer maintains copy set information page lock longer needed 
information owner ship page kept table called owner entry ptable processor fields access lock copy set 
copy set field entry valid processor holds page table owner page 
fault handlers servers algorithm follows read fault handler lock ptable lock am manager receive page owner ask manager read access ptable access read unlock ptable lock read server lock ptable lock am owner ptable copy set ptable copy set request node ptable access read send am manager lock forward request owner unlock unlock ptable lock write fault handler lock ptable lock am manager receive page owner ask manager write access invalidate ptable cow set ptable access write ptable copy set unlock ptable lock write server lock ptable lock am owner send ptable copy set ptable access nil am manager lock forward request owner owner request node unlock manager lock unlock ptable lock synchronization responsibility orig inal manager moved individual processors func tionality synchronization remains 
ex ample consider scenario processors trying write page owned third processor 
request arrives manager request forwarded 
paging complete suppose manager receives request forwards 
received page request queued finishes paging 
receive access page turn 
performance shared virtual memory improved decentralizing synchronization large bottleneck manager processor respond page fault 
distributed manager algorithms centralized manager algorithms described pre vious section manager shared virtual memory 
clearly centralized manager potential bottleneck 
section consider ing managerial task individual processors 
fixed distributed manager algo rithm fixed distributed manager scheme processor predetermined subset pages manage 
primary difficulty scheme choosing appropri ate mapping pages processors 
straight forward approach distribute pages evenly fixed manner processors 
example suppose pages shared virtual memory appropriate mapping function defined number processors 
general definition mod number pages segment 
defined function distributes manager segments 
approach suitable hashing function 
approach manager proces sor responsible pages specified static mapping function fault occurs page faulting processor asks processor true page owner proceeds centralized manager algorithm 
experiments shown fixed distributed manager algorithm substantially superior central ized manager algorithms parallel program exhibits high rate page faults 
difficult find static distribution function fits applications 
function possible find pathological case produces performance better centralized scheme 
investigate possibility distributing man dynamically 
broadcast distributed manager gorithm obvious way eliminating centralized manager broadcast mechanism 
strategy processor manages precisely pages owns faulting processors send broadcasts network find true owner page 
owner table eliminated completely information ownership stored processor ptable addition access copy set lock fields owner field 
precisely read fault occurs faulting processor sends broadcast read request true owner page responds adding page copy set field sending copy page sim write fault occurs faulting processor sends broadcast write request true owner page gives ownership sends back page copy set 
requesting processor receives page copy set invalidate copies 
processors fairly balanced algorithm processor broadcasts message processors respond request ignoring 
communications subsystem potential bottleneck 
dynamic distributed manager gorithm heart dynamic distributed manager algorithm attempt keep track ownership pages processor local ptable 
owner field replaced field prob owner value conceivable provide default mapping function clients may override supplying mapping 
way map tailored data structure application expected behavior concurrent memory 
nil probable owner page 
information contains necessarily correct times incorrect provide sequence processors true owner 
initially prob owner field entry processors set default processor considered initial owner pages 
job page fault handlers servers maintain field program runs 
algorithm page fixed owner manager 
processor page fault sends request processor indicated prob owner field page 
processor true owner proceed centralized manager algorithm 
forward request processor indicated prob owner field 
centralized algorithm read fault results making copy page write fault results making copy invalidating copies changing ownership page 
prob owner field updated processor receives invalidation request processor relinquishes ownership page processor forwards page fault request 
cases prob owner field changed new owner page 
case prob owner changed original requesting processor true owner near 
algorithm follows read fault handler lock ptable lock ask ptable prob owner read access ptable rob owner reply node ptable access read unlock ptable lock read server am owner lock ptable lock ptable copy set ptable copy set request node ptable access read send ptable copy set ptable copy set ptable prob owner request node unlock ptable lock forward request ptable rob owner ptable prob owner request node write fault handler lock ptable lock ask ptable prob owner write access page invalidate ptable copy set ptable prob owner self ptable access write ptable copy set unlock ck write server am owner lock ptable lock ptable access nil send ptable copy set ptable rob owner request node unlock ptable lock forward request ptable prob owner ptable prob owner requesting node invalidate server ptable access nil ptable prob owner request node critical questions prob owners forwarding requests eventually arrive true owner forwarding requests needed 
der answer questions convenient view prob owners page directed graph gp ep set processor numbers 
edge ep prob owner page processor induction number page faults prove lemma lemma distinguished node points prob owner graph 
uniqueness page ownership expressed lemma exactly node ep 
proof outline initially page owner 
possible place edge gen erated line write fault handler 
order execute line request line com 
replying request write server prob able owner changed requesting processor 
done lock 
receiving queue auto matically serializes arriving messages owner reply requesting node 
theorem page fault processor eventually reaches true owner page 
proof 
ot lemmas prob owner graph page acyclic edge owner 
furthermore processor forwards page fault request processor processor knowledge ownership processor node path theorem guarantees correctness prob owner graph fault progress 
fault han servers locking mechanisms guarantee atom city operations easy see correct ness algorithm 
worst case number forwarding messages theorem theorem processors shared virtual memory take messages locate page 
proof lemmas worst case occurs prob owner graph linear chain ep vl 
vn vn vn vn case fault processor vl generate forwarding messages finding true owner vn 
note worse case situation occurs pro cessors know true owner 
note fault vl time forwarding message vl blocked due locking fault handler vl soon vi receives ownership 
case take messages locate page 
extreme state best case performance better previous theorem exists prob owner graph page fault sequence total number messages locating different owners page proof situation exists prob owner graph chain caused worst case formance theorem 
interesting worst case single fault situation coincident best case fault situation parallel systems performance contention high important 
immediate question arises worst case performance faults page 
answer note general problem eas ily reduced set union find problem 
upper bound unions finds problem shown 
read page faults write page faults compress traversing paths easy see abstraction algorithm reduced set union problem find operations 
theorem upper bound respect problem theorem processor shared virtual memory dynamic distributed manager algorithm worst ease number messages locating owners single page nn fork corollary dynamic distributed manager gorithm processors page upper bound total number messages locating owners page pp contending processors processor set 
important corollary says algo rithm degrade processors added system degrades logarithmically processors contend page 
dynamic distributed manager fewer broadcasts previous algorithm initialization broad cast processors know true owner page 
theorem gives upper bound case theorem broadcast request broadcast validation upper bound total number messages locating owner page page faults differ ent processors 
proof shown transition prob owner graph broadcast 
fault uses message locate page fault uses messages 
theorem suggests possibility improv ing algorithm enforcing broadcast message true owner page page faults page 
case counter needed entry page table maintained owner 
interestingly algorithm functionally equivalent broadcast distributed manager algorithm equivalent unmodified dy namic distributed manager algorithm 
algorithm follows read fault handler lock ptable lock ask ptable prob owner read access ptable rob owner reply node ptable access read unlock ptable lock read server am owner lock ptable lock ptable copy set ptable copy set request node ptable access read ptable counter ptable counter send ptable copy set ptable copy set ptable prob owner request node unlock ptable jock forward request ptable prob owner prob owner request node write fault handler lock ptable lock ask ptable prob owner write access invalidate ptable prob owner self ptable access write ptable copy set unlock ptable lock write server am owner lock ptable lock ptable access nil send ptable copy set 
ptable counter ptable rob owner request node unlock ptable lock forward request ptable prob owner ptable prob owner request node invalidate ptable counter size ptable copy set broadcast invalidation invalidate ptable copy set invalidate server ptable access nil ptable rob owner request node note counter invalidation procedure broadcast invalidation message sent depends number copies page reaches value adjusted experimentally improve system performance 
average considering cost broadcast message algorithm takes little messages locate page broadcast request broadcast invalidation 
refinement distribution copy sets note previous algorithm copy set page invalidation operation induced write fault 
location set unimportant long algorithm invalidate read copies page correctly 
note copy set field processor contains processor copied page processor copy set fields page subsets original copy set 
facts suggest refinement previous algo rithms copy set data associated page stored tree processors rooted owner 
fact tree bidirectional edges directed root formed copy set fields edges di leaves formed prob owner fields 
tree faults follows read fault collapses path tree prob owner fields owner 
write fault invalidates copies tree inducing wave invalidation operations starting owner propagating processors copy set turn send invalidation requests processors copy seas 
algorithm modified version orig inal dynamic distributed manager algorithm read fault handler lock ptable lock ask ptable prob owner read access ptable prob owner reply node ptable access read unlock ptable lock read server ptable access nil lock ptable lock ptable copy set ptable copy set request node ptable access read send unlock ptable lock forward request ptable prob owner ptable prob owner request node write fault handler lock ptable lock ask ptable rob owner write access invalidate ptable copy set ptable prob owner self ptable access write ptable copy set unlock ptable lock write server am owner lock ptable lock ptable access nil send ptable copy set rob owner request node unlock ptable lock forward request ptable prob owner prob owner request node invalidate server ptable access nil invalidate ptable copy set ptable access nil ptable prob owner ptable copy set distributing copy sets manner improve system performance important ways 
ml propagation invalidation messages usually faster divide effect 
copy set tree perfectly balanced invalidation process take time proportional log read copies 
faster invalidation response shortens time write fault 
secondly importantly read fault needs find single processor necessarily owner holds copy page 
recall lock owner page synchro concurrent write faults page 
similar lock needed processors having read copies page synchronize sending copies page presence read write faults 
details may algorithm 
refinement applied fore going distributed manager algorithms particularly useful multiprocessor lacking broadcast facility 
experimental results implemented prototype shared virtual memory modifying aegis operating system ring net apollo workstations 
system run parallel programs number processors 
improved centralized manager algorithm dynamic distributed manager algorithm fixed distributed manager algorithm implemented tal purposes 
section results run ning parallel programs 
program implements parallel jacobi algo rithm solving dimensional pde 
specifi cally solve equation ax sparse matrix experiments 
number processes created partition problem number rows matrix 
sparse represented explicitly matrix implicitly index value pairs 
vectors stored shared virtual memory processes access freely regard location 
program simpler results usual message passing style programmer perform data movements explicitly iteration 
second program parallel sorting specifi cally block odd merge split algorithm 
data blocks stored large array shared virtual memory recursively spawned processes access freely 
data movement implicit program straightforward 
third program parallel matrix multiplication ab 
matrices stored shared virtual memory 
number processes created partition problem number columns matrix ini tially matrices stored processor paged processors demand processes processors 
figures show number forwarding requests locating true pages iteration pde program dynamic distributed manager improved centralized manager 
dynamic distributed manager obviously outperforms centralized 
prob owner fields usually give correct hints short period time number processors sharing page small centralized manager case page fault non manager processor needs forwarding request locate owner page 
shows speedup curve pde pro gram 
note program experiences better linear speedup 
data structure problem greater size physical memory single pro cessor program run processor ooo forward requests number processors dynamic distributed manager algorithm coo forward requests number processors centralized manager algorithm sj number processors speedups pde large amount paging physical memory disk 
shared virtual memory hand distributes data structure individual physical mem cumulative size large inhibit disk paging 
clear example shared virtual memory exploit combined physical memories multiprocessor system 
shows speedup curve pde program case data structure problem larger physical memory processor 
curve similar generated similar experiments cm architecture viewed hardware implementation shared virtual memory 
best curve published experiments cm program efforts costs approaches comparable 
parallel sorting loosely coupled multiprocessor generally difficult included paint bright picture 
speedup curve paral lel merge split sort elements shown 
theory communication costs algorithm yield linear speedup 
mat ters worse curve obtained trying best strategy number processors 
example merge split sorting running pro gram processor blocks running program processors shows speedup curve matrix multi plication program ab square matrices 
speedup curve close linear program exhibits high degree localized computation 
general feel results indicate shared virtual memory practical loosely coupled architecture apollo ring 
details algorithmic experimental aspects shared virtual memory may 
io number processors speedups pde number processors speedup merge split sort number nodes speedup matrix multiplication discussed classes algorithms solving memory coherence problem centralized manager dis tributed manager variations 
centralized algorithm straightforward easy implement may communications bottleneck central manager read write page faults 
fixed distributed manager algorithm bottleneck average processor needs messages locate owner 
dynamic distributed manager algorithm variations desirable features 
theorem states fewer broadcasts reduce worst case number messages locating page little worst cast centralized manager 
refinement distributing copy sets 
generally speaking dynamic distributed manager algorithms outperform methods number processors sharing page short period time small case 
performance dynamic distributed manager algorithms theory prac tice feasible implementation large scale multiprocessor 
general experiments unoptimized prototype indicate implementing shared virtual memory useful practical 
wish john ellis invaluable suggestions helpful discussions early stage 
people particular andrew mark brown butler lampson roy levin mike schroeder larry stewart chuck thacker helpful questions suggestions summer 
wish professor alan perlis continual help inspiration 
ll feautrier 
new solution problems systems 
ieee trans actions computers december 
bitton dewitt menon 
taxonomy parallel sorting 
acm computing sur september 
peter denning 
modeling program behavior 
proceedings spring joint computer conference pages afips press 
peter denning 
working sets past 
ieee transactions software engineering se january 
robert fowler 
decentralized object finding ing forwarding addresses 
phd thesis university washington 
steven frank 
tightly coupled multiprocessor sys tem speeds memory access times 
electronics january 
james goodman 
cache memory re duce processor memory traffic 
proceedings loth annual symposium computer architecture pages june 
hoare 
monitors operating system structuring concept 
communications acm october 
jones schwarz 
experience multi processor systems status report 
acm computing surveys june 
kai li 
shared virtual memory loosely coupled multiprocessors 
phd thesis yale university 
preparation 
paterson 
unpublished manuscript 
leach levine hamilton nelson 
architecture integrated local network 
ieee journal selected areas communications 
katz eggers wood perkins sheldon 
implementing cache consistency pro tocol 
proceedings pth annual symposium computer architecture pages june 
alan smith 
cache memories 
acm computing surveys september 
alfred spector 
multiprocessing architectures local computer networks 
ph thesis stan cs stanford university august 
tang 
cache system design tightly cou multiprocessor system 
proceedings national computing conference pages 
robert jan van leeuwen 
worst case analysis set union algorithms 
journal acm april 
chuck thacker private communications 
yen yen fu 
data coherence problem system 
ieee transactions computers january 
