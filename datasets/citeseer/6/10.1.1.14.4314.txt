market resource allocation grid computing model simulation michael schroeder dept computing city university london uk ck soi city ac uk resource allocation important aspect grid computing 
approach uses market mechanisms allocate resources 
review literature market resource allocation grid computing classifying approaches model state pre emptive non pre emptive 
existing market approaches take granted markets improvement 
investigate circumstances resource allocation continuous double auctions proportional share protocol respectively outperforms conventional round robin approach 
answer question develop justify model clients servers market simulation results 
factors studied include amount load system number resources different degrees resource heterogeneity communication delays 
background interest computational grids provide transparent access largescale distributed computational resources 
important problem environments efficient allocation computational resources 
past years economic approaches resource allocation developed question arises applied resource allocation grid 
satisfy basic requirements grid setting naturally decentralised decisions consume provide resources taken locally clients service providers currency provides incentives service providers contribute resources clients act afford waste resources due limited budget 
number systems built market mechanism allocate computational resources 
inherent assumption market approach se better adhoc allocation depends factors demand supply communication delays bandwidth server speeds investigates circumstances market mechanisms lead improvements 
define model involved actors marketplace protocols ensuring assumptions backed observed established distributions 
discrete event simulations implement model compare performance different resource allo cation protocols 
enables model type number resources 
parameters determining message delays processing delays task creation number speed servers adjusted providing rich parameter space 
introduce model results review existing approaches 
distinguish resource allocation strategies criteria state vs model allocations current snapshot system state state expensive obtain model predicts system state may inaccurate model predictive 
pre emptive vs non pre emptive tasks assigned hosts non pre emptive stay migrate turns stage advantageous leave machine pre emptive 
state non pre emptive strategies 
statebased non pre emptive strategies easy implement lead results 
widely adopted 
market mechanisms provide way representing system state balancing load value resources achieve efficient match supply demand 
systems price match offers bids employ sophisticated auction protocols 
spawn popcorn cpm examples systems employ auctions 
spawn cpm de centralised popcorn cpm deal resource accounting 
pursues different approach avoiding communication overhead auctions uses brokering ongoing negotiation 
prices periodically fixed fees migration data transport services 
achieve efficiency system organised hierarchy brokers exchange information directions 
systems allows true task migration 
spawn deal allocation divide conquer applications allow tasks send subtasks remote machines 
state pre emptive strategies 
environment dynamic may advantageous task migrate launched 
operating systems researchers investigated allocation resources optimised mobility 
mobile agents add degree flexibility tasks agents decide move global pattern load balancing emerging 
system provides market resource control mobile agents 
allocate resources agents system uses electronic cash banking system set resource managers 
pricing mechanism second price auction 
model strategies 
model approaches resource allocation rarer involve challenging problems obtain initial model adapt model time passes 
area operating systems researchers explored approach distributions cpu load expected process lifetime decide migrate tasks 
model approach challenger 
implements load balancing market approach money 
job created request bids containing priority value information estimate duration sent agents network 
bids giving estimated time complete job machine 
important parameters major impact system performance message delay errors estimating job completion time 
learning behaviour introduced order deal problems 
model strategy nimrod resource broker 
nimrod resource management system scheduling computations globally distributed resources varying quality service 
system economic driven environment supports various market protocols commodity market model posted pricing bargaining 
predicts performance resources system resource capability measurements load profiling 
described systems implement market strategy objective improve performance merely try market approach 
bank client accounts server accounts initiate payment send task query return query result process task query emp events task arrival event resource update event task price adjustment event update resource information client send task server endowment speed factor speed task generation poisson 
res 
units ru total comp 
size sc task deadline td input file size sd return result availability avail price task unit background load poisson output file size sd task price bid comp 
size sc bg res 
units alloc bg model marketplace execute task approach important underpin implementation theoretical considerations simulations justifying market approach 
involve computation communication simple round robin allocation 
hand round robin may handle heterogeneity resources speed bandwidth 
consequence important examine circumstances market approaches perform better 
answer question develop simulation model including actors protocols explore simulation determining broad constraints markets improvement 
simplicity consider statebased non pre emptive strategies 
actors model model represents electronic marketplace distributed computational resources 
shown main actors model assumed distributed internet clients servers electronic marketplace emp 
clients generate tasks require computational resources execution 
servers provide resources advertise sell electronic marketplace 
clients 
fixed number clients system 
client generates tasks rate modelled poisson arrival process 
poisson processes chosen suitable describing user session arrivals internet 
poisson arrival process exponential inter arrival distribution 
density function inverse mean time task creations 
tasks 
task created client characterised size computation task units sizes input output files bytes market protocols price bid may deadline weight assume execution task spread arbitrarily large fraction resource 
consider case dependencies tasks 
task pre emption possible task migrate server execution started 
task memory requirements considered model 
servers 
fixed number servers system provide cpu resources clients charge policy marketplace 
assume server resource consisting resource units ru 
allows model time shared resources resource unit corresponds time share resource space shared resources unit corresponds cpu 
assume task execute resource units parallel unit split allocated different tasks 
enable modelling resources different speed introduce speed fac tor machine resource unit need unit simulation time second execute task unit 
constant number resource units allocated task size tion execution equal machine 
background load 
introduce background load servers resources load generated tasks outside control emp 
assume poisson distribution arrivals background tasks size number resource units allocated background task arrives time resource units available put queue 
background tasks waiting queue started immediately resources available 
scheduling policy 
different ways scheduling resource units tasks allocated emp 
consider cases number resource units allocated number resource units available 
allocate available resource units server task 
number allocated units may increase decrease task execution due changes background load prior ity 
allocate fraction currently available resource proportional task price bid relation sum price bids server including bid task 
allocated share may increase decrease task execution due arrivals departures tasks changes background load prior ity electronic marketplace emp 
electronic marketplace emp provides facilities servers advertise resources 
parameters published include number resource units price task unit resource speed 
clients agents provides means search suitable resource negotiate price 
currently processing delays clients servers requests neglected results real world experiments available 
communication model 
actors systems distributed internet communication delays need considered 
experimental results communication delay network link considered distributed random variable 
observation supported 
simulation model communication delay data transfer determined latency bandwidth network link size transmitted data 
experiments simplifying assumptions network topology actors different nodes nodes connected network links equal 
furthermore messages size 
model distributed variable mean standard deviation protocols different resource allocation protocols discussed round robin protocol rr continuous double auctions protocol cda proportional share protocol psp 
cda chosen studied scenario requires double auction protocol protocols english vickrey auctions 
furthermore continuous auction transactions carried immediately bids offers change 
scenario preferable protocols transactions carried periodic intervals clearinghouse auction 
protocol arriving task wait auction need avoid der minimise response time 
reason examining psp protocol similar policies proposed scheduling tasks computational clusters 
proportional share scheduling resource split task allocated resource shares proportional price bids 
psp protocol improve cda certain situations high network latency high resource heterogeneity 
cda psp greedy sense task assigned best possible resource available time 
compare rr far simpler information load speed resources allocation decisions 
adequate certain situations 
describe sequence interactions actors protocols common 
different steps shown 
describe protocols 
server registration resources 
interactions emp take place servers need register resource offers 
include parameters number resource units available speed factor price task unit price adjusted task background task starts completes execution server 
depends linearly server utilisation server unloaded set minimum reservation price full load server asks maximum price changed server updates resource offer emp 
client task creation query emp 
tasks created exponential distribution interarrival time task objects generated 
task query object contains necessary information query emp computation size minimum price task unit initially requested maximum price task unit task deadline task id ref erence client 
task data object represents input parameters task 
sent client server case successful query 
creation task task query object sent emp step remains appropriate resource step 
emp process task query 
task query arrives emp processed immediately 
suitable resource available task price bid high resource taken query result sent back client step 
resource considered unavailable task completes execution server 
exception psp protocol tasks share resource 
match task wait emp suitable resource available task deadline passed 
cda psp mechanism task price adjustment provided allows task query objects linearly increase price bid regular time intervals order served eventually 
aspect protocol simulations 
server task execution 
receiving query result emp client sends task data object server step 
server executes task number resource units allocated emp step 
round robin cda second resource scheduling policy 
task executed effective speed note vary task execution 
duration execution known priori 
completion resource information emp updated step result task sent client step 
arrives deadline bank transfer client server account initiated step 
server penalised receives 
note accounting relevant results reported 
round robin protocol round robin protocol pricing 
incoming task queries matched available resource offer meets task constraints usually best 
purpose iterator cycles list server resource offers 
arrival task query object list resource offers searched resource satisfies task constraints size price deadline search starts current position iterator 
case success resource offer taken 
result returned iterator incremented 
iterator incremented resource offer considered 
step repeated resource offers checked match 
query successful result sent task client 
task query object remains emp suitable resource available 
resource available task query objects emp processed order arrival resource offer taken elements checked match 
continuous double auction protocol aim continuous double auction protocol cda allocate best possible resource arriving task prioritise tasks price bid 
task query object arrives emp protocol searches available resource offers returns occurrence best match cheapest fastest resource satisfies task constraints 
resource available tasks waiting highest price bid processed 
proportional share protocol proportional share protocol psp second resource scheduling policy 
amount resources allocated task depends price bid relation sum price bids tasks executing server including bid task 
task query object arrives marketplace resource offers checked order find resource fastest execute task meets task constraints size price effective execution speed deadline maximised depends background load sum price bids server 
time task background task starts completes execution server tasks need rescheduled 
tasks resource shares change execution speeds 
events effective execution speed task determined 
effective execution speed server needs calculated 
current effective execution speed task mined 
deter results aim compare performance market protocols round robin 
full exploration large parameter space scope 
focus examples demonstrate advantages market resource allocation 
chosen parameter values characteristic cluster settings homogeneous resources negligible communication delays grid settings heterogeneous resources significant com munication delays 
resource scheduling policies resource share arriving tasks may vary background load prioritised 
prioritisation background load motivated pc application local user supposed unaffected tasks allocated marketplace 
linux machine achieved assigning low priority incoming tasks nice command 
consider different scenarios incoming tasks equally important tasks different priorities 
simulation parameters simulations set default parameters section 
experiment parameters varied parameters remain fixed 
total length simulation run set time units 
time tasks generated client 
time units measurements 
ensure system reaches steady state 
initial period number tasks statistically expected generated interval time units considered result 
allow tasks complete additional final margin time units provided 
eliminate randomness results measurement repeated times different random seeds 
point diagrams error bars confidence interval mean shown 
simulated scenarios matter clients system 
client generation tasks 
tasks computation size 
tasks different sizes treated equally protocols different sizes change result 
task deadlines task input file size output file size set zero 
default value task price bids 
servers system 
servers resource size speed factor 
servers generate background tasks having computation size 
background task started allocated resource unit time 
servers simple pricing strategy lower utilisation lower price 
price task unit unloaded server 
full load 
inter arrival time tasks client average load tasks system total server capacity 
similarly inter arrival time background tasks servers completion time completion time identical tasks completion time vs load total load cda psp rr completion time identical tasks server number server number cda psp rr left variation load server number identical task scenario identical tasks different server speeds cda psp rr min 
server speed av 
server speed completion time identical tasks network latency network latency cda psp rr left variation server speeds network latency identical task scenario set value results average background load capacity server 
leads average total load system 
experiment communication delay set zero 
experiments parameters varied st load system nd number servers rd resource heterogeneity th network latency 
experiments identical task scenario set experiments tasks price bid 
mean completion time tasks metric minimised protocols 
metric considered utility function client lower metric higher utility 
variation load 
left mean completion time different protocols shown total load half background load varied total resource capacity system 
cda provides best results range values 
round robin performs worse resources allocated arbitrarily cda selects cheapest available resource task case loaded fastest 
difference highest load round robin completion time higher cda psp performs cda long load low 
reason selects fastest available resources tasks 
high load mean completion time higher 
psp allocates arriving tasks servers busy 
delays tasks executing 
variation server number 
right number servers system varied load background load ratios kept constant 
protocols mean completion time goes increased 
reason weighted completion time weighted tasks vs load total load cda psp rr weighted completion time weighted tasks different server speeds cda psp rr min 
server speed av 
server speed left variation load server speeds weighted task scenario size market shortage resources amount resources offered stable 
cda performs best observed range values 
high server number psp approaches performance tasks execute resource time 
round robin performs worse completion time higher explained indifferent allocation resources 
variation resource heterogeneity 
examine protocols cope different degrees heterogeneity server resources see left 
speed factors servers evenly distributed minimum maximum choice maximum value ensures resource capacity system constant average speed factor 
experiment parameter varied range 
cda tasks select fastest resources selecting cheapest result lower performance 
performance round robin degrades heterogeneity increased 
consider speed load choice resources 
mean com time higher identical resources 
cda degradation 
psp performance improves mean completion time lower identical resources 
reason tasks choose faster resources execute high speed 
variation network latency 
far communication delay clients servers emp neglected 
right shows performance different protocols mean communication delay varied 
standard deviation set sharp rise mean completion time observed round robin cda latency increased 
resources released need advertised emp 
remain idle communication delays leading shortage available resources system 
psp rise slower 
reason tasks allocated immediately arrival waiting servers available 
resources communication delay avoiding shortage 
experiments weighted task scenario weighted task scenario examined protocols perform generated tasks different priorities 
tasks assigned weights uniform distribution 
task price bids set tasks select resources allow fastest execution 
metric mean weighted completion time mean task weights times completion times 
metric corresponds utility function client 
cda variation load 
left shows mean weighted completion time tasks priorities total load system varied 
cda psp perform equally load low better round robin 
load increased cda performs best difference protocols larger load mean round robin psp higher cda load increased gap wider due prioritisation tasks 
reason psp performs round robin load high 
variation resource heterogeneity 
right server speed varied way left 
round robin degrades increased heterogeneity higher identical resources 
cda degrades slightly psp improves performs better cda 
market protocols cope better resource heterogeneity round robin 
gain larger identical task scenario due prioritisation tasks 
assumed market mechanisms better conventional approaches 
developed simulation model compared performance market resource allocation protocols roundrobin approach 
explored scenarios examples 
summarise cluster homogeneous resources typical lab linux machines continuous double auction protocol cda perform best 
load low differences protocols small computationally expensive round robin protocol sufficient 
situation choice resources different quality load case computational grid results round robin worse protocols 
due allocation fastest possible resources prioritisation tasks high weights 
continuous double auction protocol cda perform best cases 
high number resources performance proportional share protocol psp comparable 
psp benefits scenario high resource heterogeneity may outperform cda 
better cope situations communication delays large comparison computational size task typical grid settings 
negative side concurrent execution tasks server results longer individual completion times sequential execution 
leads poor performance load high 
results examples limited independent tasks 
consider scenarios tasks dependencies deadlines pre emption 
performance market protocols compared conventional strategies perform better round robin 
furthermore plan carry experiments real grid environment order verify simulation model 
ferguson nikolaou sairamesh yemini 
economic models allocating resources computer systems 
market control paradigm distributed resources allocation 
world scientific 
waldspurger hogg huberman kephart stornetta 
spawn distributed computational economy 
ieee trans 
software engineering 
nisan london regev 
globally distributed computation internet popcorn project 
proc 
th int 
conf 
distributed computing systems amsterdam netherlands 
ieee 
zenger 
economic dynamic load distribution large workstation network 
proc 
nd int 
euro par conf volume pages lyon france 
springer 
buyya 
compute power market market oriented grid 
proc 
st int 
conf 
cluster computing grid ccgrid 
ieee 
abramson buyya giddy 
computational economy grid computing implementation nimrod resource broker 
generation computer systems fgcs journal october 
kotz rus 
market resource control mobile agents 
proc 
nd int 
conf 
autonomous agents usa 
acm press 
chavez moukas maes 
challenger multi agent system distributed resource allocation 
proc 
st int 
conf 
autonomous agents marina del ray ca usa 
acm press 
tuomas sandholm 
distributed rational decision making 
gerhard weiss editor multi agent systems 
mit press 
harchol balter downey 
exploiting process lifetime distributions dynamic load balancing 
acm transactions computer systems 
floyd paxson 
difficulties simulating internet 
ieee acm trans 
networking 
schroeder 
restart method 
preliminary results efficiency improvements interactions web agents 
proc 
workshop infrastructure mas agents 
wilkinson 
power process 
workshop parallel emergent distributed computing reading uk may 
mit press 
ali buyya 
libra economy driven job scheduling system clusters 
proc 
th intl 
conf 
high performance computing asia pacific region hpc asia bangalore india december 
waldspurger 
lottery stride scheduling flexible proportional share resource management 
phd thesis department electrical engineering computer science massachusetts institute technology ma usa 
