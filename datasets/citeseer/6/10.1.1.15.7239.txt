guided region prefetching cooperative hardware software approach wang doug burger kathryn mckinley steven reinhardt charles dept computer science dept computer sciences dept eecs univ massachusetts amherst university texas austin university michigan despite large caches main memory access latencies cause significant performance losses applications 
numerous hardware software prefetching schemes proposed tolerate latencies 
software prefetching typically provides better prefetch accuracy hardware limited prefetch instruction overheads compiler limited ability schedule prefetches sufficiently far advance cover level cache latencies 
hardware prefetching effective hiding large latencies generates useless prefetches consumes considerable memory bandwidth 
propose cooperative hardware software prefetching scheme called guided region prefetching grp uses compiler generated hints encoded load instructions regulate aggressive hardware prefetching engine 
compare grp sophisticated pure hardware stride prefetcher scheduled region prefetching srp engine 
srp grp show best performance respective gains prefetching srp incurs extra memory traffic nearly bandwidth requirements 
grp achieves performance close srp mere eighth extra prefetching traffic increase prefetching 
grp hardware software collaboration combines accuracy program analysis performance potential aggressive hardware prefetching bringing performance gap versus perfect cache 
modern order processors tolerate latencies multicycle level cache hits level cache misses result level hits 
hundreds cycles result dram accesses tolerated causing significant performance degradations 
spec benchmarks running modern high performance microprocessor half time spent stalling loads level cache 
observe similar results simulations subset spec benchmarks sphinx speech recognition application 
compares performance system realistic memory hierarchy versus perfect cache perfect cache leftmost stacked bar benchmark 
benchmarks sorted size gap realistic system perfect cache geometric mean performance gap 
summary results show performance afforded grp prefetching scheme displayed rightmost bar benchmark 
tolerate latencies researchers proposed large number software hardware prefetching schemes 
classes prefetch solutions distinct advantages drawbacks 
pure software prefetching typically highly accurate incurs runtime overhead issue prefetches sufficiently far advance load hide main memory access latencies 
hardware schemes prefetch spatial regions pointer chains recurring patterns :10.1.1.55.4004
schemes hide main memory access time consume substantial amounts memory bandwidth 
additional traffic need degrade uniprocessor performance increases power consumption degrade performance multiprocessors 
chip bandwidth dominant limiter scalability chip multiprocessors prefetch schemes consume bandwidth inefficiently practical 
schemes throttle prefetching accuracy drops threshold opportunities issuing useful prefetches 
propose cooperative hardware software prefetch framework called guided region prefetching grp 
grp sophisticated compiler analysis produce rich set load hints including presence absence spatial locality pointer structures indirect array accesses 
runtime hardware engine triggered cache misses generates prefetches compiler hints 
grp benefits compiler analysis application patterns traditional software prefetching compiler required generate schedule individual prefetch addresses 
hardware generates prefetches run far ahead missing 
compiler guides hardware need struggle deduce complex pattern matching prior accesses stored large tables 
previously proposed techniques grp hardware prefetching engine keeps uniprocessor bus contention low prefetching memory bus idle keeps cache pollution low loading prefetches lru set cache 
compiler support prefetching hardware effective improving performance consumes bandwidth 
grp compiler informs hardware application patterns enabling hardware prefetch effective 
evaluate compiler hints mark loads hints spatial prefetch spatial region load size lines fetch spatial pointer prefetch pointer load cache line recursive prefetch pointer data structure recursively 
size hints compiler encode variable size region specifies prefetch enclosing loop bounds fixed value 
compiler generates indirect prefetching instructions trigger prefetching set indirection array 
cooperative grp hardware software interface improves high performance previously proposed scheduled region prefetching srp spec benchmarks match performance srp rest 
table shows summary grp results geometric mean 
show grp grp var grp fix variable size region prefetching 
prefetching mean ipc crafty mesa apsi gzip gap ammp mgrid traffic performance gap speedup increase perfect prefetching stride prefetching srp grp fix grp var table summary prefetching performance traffic performance benchmark suite lower perfect level cache 
stride prefetching sherwood design provides speedup prefetching 
srp uses compiler analysis outperforms stride prefetching consumes excessive memory bandwidth increase system prefetching 
grp provides near equivalent performance srp substantially traffic increase prefetching 
reduction traffic saves power amenable multiprocessor systems additional traffic directly affect performance 
srp grp incur gap versus perfect 
review related section showing pursue balance aggressive prefetching efficient memory bandwidth 
section describes hardware grp hardware prefetching engine uses hints 
section describes compiler analysis detail 
section evaluates degree grp engine bring performance benchmarks close perfect cache keeping memory traffic increases small 
section compares performance grp stride prefetching 
conclude section grp eliminates main memory accesses source performance loss spec benchmarks sphinx 
simply requires memory bandwidth benefit sophisticated software hardware cooperation 
related section focus pertinent aspects large body literature software hardware data prefetching small number previously proposed hybrid schemes 
software prefetching relies non binding prefetch instructions bring indicated block memory cache vpr bzip twolf parser mcf processor performance sphinx applu equake art swim average perfect perfect base grp load instruction 
conceptually latency load instruction hidden inserting prefetch effective address instruction stream sufficiently far advance load 
compiler inserts prefetches known loads software prefetch accuracy typically high 
practice compiler faces key challenges data prefetching selection scheduling 
prefetch instructions occupy instruction cache space pipeline slots data cache ports compiler select subset loads generate prefetches 
accurate compiletime identification loads cause cache misses runtime complex requiring knowledge hardware parameters cache block size capacity associativity sophisticated code analysis determine volume data accessed particular block 
compiler faces difficult challenge issuing prefetches sufficiently early hide memory latency early useful data needlessly evicted 
find point compiler estimate cache latencies run time instruction execution rates 
compiler constrained schedule prefetch compute effective address 
constraint significant arrays limits compiler greedy pointer prefetching 
jump pointers bypass limitation identifying records links ahead structure require sophisticated analysis dynamic updates addition jump pointer object 
approaches prefetch pointer arguments call sites decouple prefetches main program separate thread context 
converse approach hardware prefetching hardware predicts prefetch addresses observing program runtime behavior 
prefetches incur overhead processor hardware need selective issuing prefetch operations 
shows simple dynamic prioritization techniques eliminates memory bandwidth contention cache pollution problems 
compiler hardware direct knowledge memory key challenge hardware prefetching determining reasonable set predicted addresses prefetch targets 
hardware prefetching suffers relative software prefetching accuracy predictions may wrong coverage addresses may require compiler scope predict 
hardware prefetchers exploit spatial locality prefetching subsequent blocks cache 
sophisticated schemes detect non unit strided access patterns chen baer prediction table rpt palacharla kessler strided stream buffers 
approaches exploit pointer access sequences correlation markov prefetching broader class patterns dead block information 
approach involves decoupling data structure traversal computation specialized pointer traversal hardware dedicated pre execution hardware 
researchers proposed memory side prefetching reduce latencies prefetches 
pertinent previous papers 
predictor directed stream buffering proposed sherwood unifies strided stream buffers markov prefetching single consistent hardware prefetching framework 
section compare grp scheme strided stream buffers scheme markov predictor consumes state practical 
second propose stateless approach pointer prefetching foregoing explicit identification pointer traversal patterns simply prefetching referenced memory value reasonably interpreted memory address 
hardware schemes stateless 
find benchmarks grp spatial hints usually performs better pointer prediction pointer hints 
hardware schemes forced trade coverage accuracy vice versa focus structured access patterns predicted high accuracy coverage structured access patterns consume significant amounts bandwidth incorrect prefetches attempt cover structured 
relative strengths weaknesses hardware software prefetching complementary suggest combined hardware software approach 
ideal scheme exploit compiler knowledge patterns channel convey information hardware prefetching engine generate schedule appropriate prefetches dynamic information regarding cache events resource availability 
limited previous area exploited prefetching restricted classes access patterns provided interface overly general complex 
conservative side software select number contiguous blocks prefetch chen baer compiler supply address stride information augment prediction table 
dubois trap handler trigger prefetching similar information 
karlsson prefetch arrays enable hardware engine perform generalized variant greedy jump pointer prefetching 
zhang torrellas compiler mark blocks memory belonging contiguous spatially local regions containing indirection pointers 
scheme requires additional bits main memory significant support memory controller 
fully programmable prefetch engines provide flexibility require significant memory system support demonstrated required compiler support realistic 
grp combines advantages software hardware prefetching scheme simple effective 
conveys sophisticated compiler analysis associating range hints prefetch queue prefetch access bank state prefetch engine cache controller rambus controller prefetch engine organization rambus channel rambus channel cache loads aggressive simple general hardware prefetcher uses necessary 
pertinent compiler analysis communicated hardware requiring extensive static lookahead software guarantees high instruction overhead 
subsequent sections describe hardware engine software hints analysis necessary hardware balance prefetch coverage accuracy 
hardware prefetching engine grp hardware prefetching engine builds scheduled region prefetching design lin 
extend original design capabilities 
add support aggressive prefetching pointer data structures 
second add ability prefetch indirect array software control 
scheduled region prefetching scheduled region prefetching srp aggressively exploits spatial locality attempting prefetch large kb memory regions cache 
negative effects aggressive prefetching memory bus contention cache pollution addressed directly reducing priority prefetches memory bus request scheduling replacement decisions respectively 
prefetching schemes maintain high prefetch accuracy avoid degrading performance srp identify access prefetch candidates liberally degrading uniprocessor performance 
shows memory system srp engine forms experimental baseline 
access central component srp prefetching engine 
forwards requests memory controller controller indicates memory channels idle 
forwards prefetch requests outstanding demand misses cache 
demand misses encounter contention prefetches memory controller issued prefetch candidates buffered prefetch queue 
status holding registers track outstanding accesses regardless type 
cache prefetching engine allocates new entry prefetch queue representing aligned memory region containing accessed block 
prefetch queue entry contains base address region bit vector indicating prefetch candidate blocks region index field identifies block region prefetch 
region engine initializes bit vector identify blocks cache sets index field indicate prefetch candidate block block 
adds new entries head queue giving priority older typically relevant entries 
queue fixed size experiments old entries fall bottom 
region queue clears bit corresponding block sets index field prefetch candidate block new block moves prefetch bit vector entry head queue 
base region size kb cache block size bytes resulting bit vector bit index field 
controller prefetches candidates deallocates entry 
access practically eliminates performance loss useless prefetches due bandwidth contention prefetching pollute cache generating heavy prefetch stream 
address issue placing prefetched data lowest priority position replacement scheme 
controller puts prefetched data lru position pertinent cache set moves block mru position referenced explicitly cpu 
result useless prefetches way associative cache displace nth useful data cache 
way set associative cache experiments 
drawback controller occasionally replaces potentially useful prefetches referenced previous shows effect insignificant 
final optimization queue issues prefetches dram banks needed page open 
scheduled region prefetching highly effective exploiting spatial locality improve performance 
shortcomings addressed grp 
srp provide direct support non spatial patterns 
add pure hardware pointer prefetching mechanism address issue see section 
add indirect array scheme requires compiler support see section 
spec benchmarks find spatial prefetching works pointer schemes pointer intensive benchmarks regular layout programmers memory allocation patterns pointer data structures 
second srp produce amounts excess memory traffic 
useless traffic reduce uniprocessor performance due srp prioritization techniques consumes energy cause contention useful prefetches may reduce performance multiprocessor environment 
compiler hints spatial pointer accesses gain low bandwidth high accuracy 
describe grp hardware modifications hints section compiler analysis section 
hardware prefetching pointer structures discussed section hardware prefetching pointer structures challenging 
complex hardware recognize pointer traversal patterns store pointer correlations base grp pointer prefetching scheme greedily generates prefetch fetched value falls ranges legitimate heap memory addresses 
grp implementation performs simple base bounds check start addresses heap 
alpha isa pointers aligned byte entities engine check values byte cache block 
controller identifies datum possible pointer value describe similar efficient pointer test bit masks apply prefetching challenging ia environment 
code loop spatial indirect pointer recursive pointer size table compiler hints representative loops translates virtual address physical address forwards address srp prefetch queue allocates entry prefetch 
pointer dereferences frequently exhibit spatial locality sets bits entry prefetch bit vector indicating block containing prefetch address immediate successor prefetches data structures span cache blocks 
generalize mechanism chase recursive pointers scanning prefetched lines addresses generating additional prefetches 
grp incorporating compiler prefetch hints section describes compiler hints grp improve precision spatial pointer prefetching 
grp compiler annotates load instructions hints predicting spatial pointer prefetches useful 
study compiler conveys hints unused alpha floating point load opcodes 
memory system propagates load hint bits memory hierarchy resulting request 
table presents hints shows typical representative code snippets 
summarize changes hardware hint describe pointers recursive pointers indirection hardware detail 
spatial hint indicates exhibit spatial locality 
grp initiates spatial prefetch marked spatial 
size hint combined loop upper bound indicates cache lines prefetch 
indirect hint indicates program array index second array 
indirect grp generates sets prefetches base address index values 
pointer hint indicates structure contains pointers program follow 
grp scans returned block pointer values generates prefetches values 
recursive pointer hint indicates structure contains pointers program recursively follows pointers 
recursive pointer grp scans returned data pointer values generates prefetches addresses continues generating prefetches subsequent levels recursive data structure 
experiments 
grp pointer recursive pointer grp uses mechanism pointer recursive pointer hints 
grp applies mechanism pointer hint grp applies repeatedly resulting prefetched lines recursive pointer hints 
implement grp pointer recursive pointer hints adding bit counter prefetch queue entries control pointer recursive pointer prefetching uniformly 
grp initializes counter pointers sets value recursive pointers sets value 
difference pointer recursive pointer prefetching initial counter value 
grp fetches pointer hinted missing line starts pointer prefetching engine returned line 
engine checks counter 
zero stops queuing prefetches 
decrements counter queues prefetches pointers returned line 
prefetch cache blocks pointer statistics typical structure size spec benchmarks bytes cache block configuration 
blocks sufficient cover structure alignment 
engine terminates level pointers levels recursive prefetching 
grp variable size region prefetching grp default prefetches fixed region size srp 
spatial reuse span default region size prefetching wastes bandwidth 
enhanced grp allow compiler control region sizes singly nested loops 
compiler computes loop upper bound primary induction variable conveys bound hardware special instruction 
compiler encodes coefficient spatial loop 
prefetch engine uses bound coefficient calculate region size loop bound coefficient value 
grp indirect array benchmarks spec suite vpr bzip incur significant number misses due indirect array forma 
amenable spatial prefetching values clustered determined statically 
pointer prefetching ineffective desired addresses computed contained memory pointers 
specialized extension grp targets patterns 
single indirect prefetch instruction conveys element size sizeof index array address prefetching engine 
prefetch engine reads cache block containing word block generates prefetch address adding scaled value 
grp forwards addresses prefetch queue pointer prefetching scheme 
currently assume index array element size sizeof typical systems element size included instruction necessary 
scheme distinct mechanisms proposed information encoded separate instruction hint existing load 
explicit prefetch instruction adds overhead number instructions small generates prefetches index cache block indirection array 
alternate mcf terminate recursion levels simulation tractable 
implementation single instruction prior loop nest set base address additional hint bit loads trigger indirect prefetches 
approach reduce execution overhead cost limiting application prefetching single indirection array concurrently base address indirect hint pair 
compiler analysis framework section describes analyses classes hints spatial size indirect pointer recursive pointer guide prefetching engine 
implement analyses scale compiler generate hints automatically fortran codes 
spatial locality analysis arrays grp compiler predicts misses truly spatial locality examining arrays fortran spatial pointer accesses structures compiler uses locality analysis mark spatial hint annotation compiler back augments special load instruction spatial hint 
prefetch engine prefetches misses marked spatial prefetch misses spatial marks 
describe array analysis spatial pointer analysis 
augment prior statically detects spatial locality extending dependence testing 
dependence testing finds induction variables detects spatial dimension row column fortran accessed function index variable inner outer nesting level 
dependence testing detects locality affine subscription expressions linear functions loop induction variables 
approach marks inner outer loop spatial locality 
typical array spatial locality accessed spatial dimension innermost loop 
example mark assuming column major fortran storage 
compiler marks arrays spatial locality crosses larger distances deep nest nests inter nest reuse 
level cache size upper bound distance spatial reuse mark assuming level cache sufficient set associativity avoid conflict misses exploit reuse 
compiler determines loop bounds step sizes compute reuse distances accurately compile time 
arrays spatial intra inter nest locality computes reuse distances 
marks array spatial locality known distance level cache size 
compiler know reuse distances statically due symbolic loop bounds uncertain executions paths estimates reuse distance nesting level loop 
compiler conservative reuse distance unknown mark spatial spatial reuse innermost enclosing loop 
analysis works fortran arrays heap arrays array elements referenced subscript expressions 
handle heap arrays analysis 
buf heap array type 
addition detecting obvious spatial reuse buf loop induction variable compiler able find spatial reuse buf constants 
spatial locality analysis pointer dereferences prefetch pointer show spatial locality illustrated compiler performs loop induction variable integer 

fortran array buf buf malloc 
buf malloc buf 
heap array generate spatial hints recognize induction variables including pointers induction variable recognition perform dependence testing dependence testing loop generate basic spatial hints memory loop array spatial reuse enclosing innermost loop mark compute reuse distance applicable reuse distance level cache size mark loop induction pointer mark propagate spatial hints loop induction pointers memory loop induction pointer mark spatial marked spatial mark spatial new hints generated algorithm generating spatial hints recognition pointers repeatedly incremented constant 
type primary type 
treat pointer special integer insert spatial hints constant small 
analysis cache misses shows spatial reuses code covered regular spatially local array cases 
summarizes algorithm generating spatial hints arrays spatial pointer accesses 
part algorithm inserts spatial hints arrays loop induction pointers second part propagates spatial hints uses loop induction pointers 
algorithm intra procedural flow insensitive marks enclosed loops 
indirect analysis compiler detects marks indirect array accesses 
particular looks access pattern form constants loop induction variable 
dependence testing detects spatial reuse standard way 
add simple analysis detects sequentially accessed array index array example generates indirect prefetch primary type structure induction pointer struct struct struct 

recursive pointer generate pointer hints field access pointer field structure accessed loop mark field access pointer field access updates recurrent pointer mark field access recursive pointer array marked spatial points heap array mark pointer algorithm generating pointer recursive pointer hints instruction address base address array described section 
variable size region analysis compiler detects marks array singly nested loops variable size region prefetching 
array access pattern compiler encodes bit value closest reserve encoding value region prefetching 
compiler marks upper bound loop induction variable hints control region size described section 
pointer recursive pointer analysis spatial locality compiler improve accuracy hardware pointer prefetching restricting misses load field structure contains pointer recursive field 
mark field pointer pointer field structure accessed loop 
mark pointer update recursive updates loop object data type 
example updated field points structure type struct idiom analysis simply identifies pointer updates loop field type marks recursive pointer updates 
mark pointer accesses spatial hint arrays pointers 
example shows array buf access pattern results spatial hint compiler 
furthermore buf points heap array compiler marks pointer hint 
grp address prefetch pointed array 
algorithm generate pointer recursive pointer hints shown 
complementary spatial marking algorithm pointers shown 
ipc gap vpr twolf parser mcf sphinx equake art mean benchmark mem insts spatial pointer recursive ratio indirect gzip swim mgrid applu vpr mesa art mcf equake crafty ammp parser gap bzip twolf apsi sphinx table number compiler hints benchmark experimental evaluation section compare performance benefits srp grp unified stride prefetching spec cpu benchmarks additional benchmark 
demonstrate grp provides compelling balance higher performance increased memory traffic prefetching techniques 
demonstrate effectiveness compiler generated size information sensitivity results compiler heuristic computing useful distance spatial locality 
conclude discussion characteristics remaining benchmarks grp eliminate main memory accesses significant loss performance 
experimental methodology scale compiler infrastructure inserts prefetch hints 
performs number scalar optimizations constant propagation common subexpression elimination 
compiles fortran code alpha assembly code memory hints annotated comments 
post process annotated assembly code generate binaries containing compiler hinted instructions 
simulate program binaries version sim scheduled region prefetching srp added simulator 
added grp hardware pointer prefetching mechanisms modified simulator accept compiler hints schedule prefetches accordingly binaries contain hints 
performance gains pointer prefetching perfect base pointer recursive srp srp pointer alpha isa configure simulator ghz way issue entry ruu reorder buffer order core way split level caches unified way mb level cache 
cache hierarchy combined effective mhz channel rambus memory system 
latencies cycles respectively 
cache contains 
srp prefetching queue size uses lifo scheduling 
stride predictor uses way history table entries 
entries streaming buffers sharing history table 
simpoint tool set select representative starting point program initialization phase 
simulate instructions point 
spec cpu fortran benchmarks scale infrastructure able compile correctly plus sphinx speech recognition application 
table lists benchmarks statistics memory instructions number type compiler hints generated 
second column contains total number static memory instructions 
columns show number instructions compiler marks spatial pointer 
note compiler mark instruction spatial pointer 
column lists fraction static memory operations hints column shows static number indirect prefetch instructions 
results crafty subsequent results rate negligible 
comparison stride prefetching srp grp section effects hardware pointer recursive pointer prefetching 
show explicit pointer prefetching generally subsumed aggressive spatial prefetching srp grp 
compare stride prefetching srp grp 
grp uses compiler analysis including variable region sizes 
section compares variable fixed region sizes finds variable sizes decrease bandwidth requirements programs 
apply pointer prefetching benchmarks unsurprisingly little effect fortran benchmarks 
benchmarks show significant performance improvement notably boost equake increase mcf improvement sphinx shown 
equake performance gain pointer structure traversal expected 
stems prefetching arrays pointers ipc gzip gap twolf vpr bzip parser mcf sphinx mean performance gains region prefetching stride prefetching integer benchmarks heap arrays 
similarly mcf performance gain comes loop sequentially resets field object heap array 
pointer prefetching happens prefetch objects accessed 
pointer prefetching outperforms srp twolf sphinx 
cases srp performs better pointer recursive prefetching 
applying srp pointer prefetching gives little benefit degrades performance due higher bandwidth consumption result fewer successful prefetches 
grp pointer recursive hints shows performance gains similar srp benchmarks lower average memory traffic show performance srp grp stride prefetching integer floating point benchmarks respectively 
cases average srp grp perform better stride prefetching 
benchmarks srp improves performance perfect 
swim better srp due lower traffic 
due indirect prefetching grp faster srp bzip 
outperforms srp art ammp 
mcf parser ipc grp srp 
typical reason compiler misses locality outside loops 
detect indirect benchmarks indirect prefetching shows significant speedups vpr bzip 
vpr indirect show high spatial locality 
srp performs grp additional traffic 
bzip benchmarks srp perform 
indirect prefetching gap perfect reduced memory traffic srp 
terms performance memory traffic grp variable region size grp var fixed region size grp fix differ benchmarks mesa bzip 
table shows mesa bzip strategies deliver roughly performance grp var results traffic grp fix discuss section 
sphinx grp var lower performance grp fix benefits traffic reduction 
compiler guarantee spatial locality chooses small prefetch regions misses opportunities 
prefetching accuracy coverage memory traffic srp grp provide comparable performance srp consumes bandwidth grp 
shows perfect base stride srp grp grp traffic region size distribution var fix mesa bzip sphinx table grp var versus grp fix normalized memory traffic prefetch schemes 
srp increases memory traffic factor times prefetching 
grp generates mean additional traffic compared prefetching versus srp increase 
grp eliminates total memory traffic seventeen benchmarks compared srp benchmarks 
traffic stride prefetching grp stride prefetching achieves performance improvement grp 
compared grp fix grp grp var cuts memory traffic significantly benchmarks showing traffic 
table lists benchmarks traffic increase compared prefetching columns 
subsequent columns show distribution prefetching requests region sizes regions blocks produced 
observe grp var prefetches additional block region size cases due poor spatial locality 
table shows prefetching accuracies coverage prefetching techniques implemented 
percentage reduction misses metric coverage 
average srp provides best coverage worst accuracy 
stride prefetching trades lowest coverage highest accuracy 
grp obtains best worlds accuracy closer stride prefetching coverage closer srp 
normalized traffic reflect absolute bandwidth consumption benchmark list actual memory traffic bytes benchmark table 
average srp consumes memory bandwidth prefetching system 
grp stride prefetching produce increase memory requests respectively 
ipc normalized traffic mesa apsi ammp mgrid applu equake art swim mean mesa performance gains region prefetching stride prefetching floating point benchmarks apsi gzip gap ammp mgrid vpr twolf bzip parser mcf normalized traffic benchmark base stride srp grp rate traffic coverage accuracy traffic coverage accuracy traffic coverage accuracy traffic mesa apsi gzip gap ammp mgrid vpr twolf bzip parser mcf sphinx applu equake art swim average sphinx applu table prefetching accuracy coverage memory traffic equake art swim mean perfect base stride srp grp stride srp grp benchmark grp performance gap causes ratio swim transpose array access art bandwidth transpose heap array access mcf tree traversal ammp linked list traversal bzip indirect array twolf linked list random pointers sphinx hash table lookup table level characteristics compiler sensitivity explored sensitivity results compiler policy implementing aggressive variants scheme described section 
aggressive policy marks spatial reuse distance greater cache size 
conservative scheme marks spatial reuse sits innermost loop 
compared default grp policy aggressive policy degrades performance increases traffic additional 
conservative scheme shows little effect memory traffic compared grp causes moderate performance losses benchmarks applu art equake reduces performance average benchmark suite 
remaining misses benchmarks show gap greater grp perfect 
list table description key causes misses obtained analyzing source 
accurate prefetching coupled indirect accesses pointer prefetching grp able bring bzip ammp 
swim low ipc due pathological array conflicts 
prevent benchmark manually applying loop distribution loop permutation 
observe art bandwidth bound 
grp reduces traffic increases performance srp performance gap large 
larger caches wider channels improve art appreciably 
sphinx hash table lookup usually touches small number adjacent hash slots short loop 
prefetches occur simply late tolerate latencies 
mcf twolf contain heavy traversals short linked lists tree data structures making poor matches grp pointer prefetching spatially schemes 
purely compiler prefetching techniques difficulty managing large latencies modern main memories 
previous shows aggressive hardware prefetching addresses issue effectively applications spatial locality cost potentially significant increases memory bandwidth 
number processors chip increases bandwidth increasingly precious 
shows cooperative approach analysis hardware aggressive prefetching provides benefits comparable aggressive hardware prefetching lower traffic 
compiler techniques identify accesses clearly possess spatial locality 
information attempt schedule software prefetches resulting complications providing timely prefetches minimizing instruction overhead system simply passes access pattern information hardware prefetching engine 
engine generates prefetches cache low overhead 
compared pure hardware prefetching compiler analysis saves bandwidth avoiding useless prefetches addresses little locality 
extend hardware prefetching engine address pointer applications aggressively prefetching datum appears pointer 
spatial locality see significant traffic benefits having compiler indicate pointer recursive pointer loads 
spec benchmarks aggressive spatial locality analysis subsumes pointer prefetches benchmarks due spatially local layouts pointer connected objects 
sphinx chose sparse irregular pointer behavior benefits little pointer prefetching 
remains seen phenomenon dominate benchmarks researchers show importance greedy pointer hardware prefetching 
solely spatial indirect hints grp compiler hardware prefetch framework eliminates related stalls spec suite comparatively modest increases traffic 
remaining benchmarks limited memory system performance bandwidth bound art contain irregular linked lists tree traversals mcf twolf memory side prefetching may help 
rest spec suite grp approach eliminates physical memory accesses performance bottleneck making significantly efficient system bandwidth similarly aggressive prefetch engines 
acknowledgments supported nsf itr ccr nsf ccr aci ccr nsf research instrumentation eia defense advanced research projects agency contracts intel research council ibm university partnership award gifts ibm alfred sloan research fellowships 
alexander kedem 
distributed predictive cache design high performance memory system 
second international symposium high performance computer architecture feb 
patel davidson 
data prefetching dependence graph precomputation 
proceedings th annual international symposium computer architecture pages 
architecture language implementation group university massachusetts amherst 
scale compiler infrastructure 
cs umass edu scale 
burger austin 
simplescalar tool set version 
technical report computer sciences department university wisconsin june 
mckinley 
data flow analysis software prefetching linked data structures java 
proceedings international conference parallel architectures compiler techniques pages barcelona spain sept 
mckinley 
simple effective array prefetching java 
acm java grande pages seattle wa nov 
callahan kennedy porterfield 
software prefetching 
proceedings fourth international conference architectural support programming languages operating systems pages santa clara ca apr 
carr mckinley tseng 
compiler optimizations improving data locality 
proceedings sixth international conference architectural support programming languages operating systems pages san jose ca oct 
reeves 
generalized correlation hardware prefetching 
technical report ee cornell university feb 
chen baer 
reducing memory latency non blocking prefetching caches 
proceedings fifth international conference architectural support programming languages operating systems pages boston ma oct 
chen baer 
effective hardware data prefetching 
ieee transactions computers may 

chen 
effective programmable prefetch engine highperformance processors 
proceedings th international symposium microarchitecture ann arbor michigan nov 
collins wang tullsen hughes 
lee shen 
speculative precomputation long range prefetching loads 
proceedings th international symposium computer architecture pages june 
jordan grunwald 
stateless content directed data prefetching mechanism 
proceedings tenth annual international conference architectural support programming languages operating systems pages san jose ca october 
dahlgren dubois 
fixed adaptive sequential prefetching shared memory multiprocessors 
proceedings international conference parallel processing pages st charles il 
dahlgren 
effectiveness hardware stride sequential prefetching shared memory multiprocessors 
international symposium high performance computer architecture pages raleigh nc jan 
ghosh martonosi malik 
precise analysis program transformations caches arbitrary associativity 
proceedings eighth international conference architectural support programming languages operating systems pages san jose ca oct 

integrated hardware software scheme shared memory multiprocessors 
proceedings international conference parallel processing pages st charles il 
hughes adve 
memory side prefetching linked data structures 
technical report uiucdcs university urbana may 
huh burger 
exploring design space 
proceedings international conference parallel compilation techniques pages sep 
joseph grunwald 
prefetching markov predictors 
proceedings th annual international symposium computer architecture pages 
jouppi 
improving direct mapped cache performance addition small fully associative cache prefetch buffers 
proceedings th international symposium computer architecture pages seattle wa june 
karlsson dahlgren 
prefetching technique irregular accesses linked data structures 
sixth international symposium high performance computer architecture page toulouse france jan 
kim yeung 
design evaluation compiler algorithms pre execution 
proceedings tenth international conference architectural support programming languages operating systems pages san jose ca oct 
levy 
architecture software controlled data prefetching 
proceedings th international symposium computer architecture pages toronto canada may 

lai fide 
dead block prediction correlating prefetchers 
proceedings th international symposium computer architecture july 

lee 
hon reddy 
overview sphinx speech system 
ieee transactions acoustics speech signal volume pages 

lin reinhardt burger 
reducing dram latencies integrated memory hierarchy design 
proceedings th international symposium high performance computer architecture pages jan 
lipasti schmidt 
software prefetching pointer call intensive environments 
proceedings th annual ieee acm international symposium pages nov 
luk mowry 
compiler prefetching recursive data structures 
proceedings seventh international conference architectural support programming languages operating systems pages cambridge ma oct 

luk 
tolerating memory latency software controlled pre execution simultaneous multithreading processors 
proceedings th international symposium computer architecture pages june 
mckinley carr tseng 
improving data locality loop transformations 
acm transactions programming languages systems july 
mowry lam gupta 
design evaluation compiler algorithm prefetching 
proceedings fifth international conference architectural support programming languages operating systems pages boston ma oct 
palacharla kessler 
evaluating stream buffers secondary cache replacement 
proceedings th international symposium computer architecture pages chicago il apr 
roth sohi 
dependence prefetching linked data structures 
proceeding eighth international conference architectural support programming languages operating systems pages 
roth sohi 
effective jump pointer prefetching linked data structures 
proceedings th international symposium computer architecture pages atlanta ga may 
sherwood calder 
basic block distribution analysis find periodic behavior simulation points applications 
proceedings international conference parallel architectures compilation techniques pages barcelona spain sept 
sherwood calder 
predictor directed stream buffers 
proceedings rd international symposium microarchitecture pages monterey california dec 
dubois 
hybrid compiler hardware prefetching multiprocessors low overhead cache traps 
proceedings international conference parallel processing pages bloomington il aug 
smith 
cache memories 
computing surveys sept 
lee torrellas 
user level memory thread correlation prefetching 
proceedings th international symposium computer architecture pages may 
srinivasan lebeck 
load latency tolerance dynamically scheduled processors 
journal instruction level parallelism 

compiler assisted data prefetch controller 
proceedings international conference computer design austin tx 
wolf lam 
data locality optimizing algorithm 
proceedings sigplan conference programming language design implementation pages toronto canada june 
wu 
efficient discovery regular stride patterns irregular compiler prefetching 
proceedings sig plan conference programming language design implementation pages berlin germany june 

yang lebeck 
push vs pull data movement linked data structures 
proceedings acm international conference supercomputing pages may 
zhang torrellas 
speeding irregular applications shared memory multiprocessors memory binding group prefetching 
proceedings nd international symposium computer architecture pages santa margherita ligure italy june 
