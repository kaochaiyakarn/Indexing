marc fabri leeds metropolitan university school computing isle research group fabri lmu ac uk www lmu ac uk ies comp staff fabri hobbs moore 
emotive signals virtual worlds hci conference proceedings london september emotive signals virtual worlds outline experimental study investigating facial expressions emotion means non verbal communication collaborative virtual environments cves 
premise incorporating emotional channel alongside conventional informational content user experience may enriched 
established detailed knowledge facial expressions effectively efficiently visualised cves 
effectiveness demonstrated recognition rates emotions efficiency established reduced feature set sufficient build core set facial expressions 
keywords virtual reality avatars emotion facial expression 

humans communicate face toface frequently bodies complement repeat contradict substitute regulate said 
held non verbal signals important verbal information particularly respect communicating changing moods emotional states 
findings psychology neurology suggest emotions important factor decision making problem solving cognition intelligence general 
socially active humans usually informal understanding emotion different emotions 
formal research tradition investigated nature emotion systematically 
major figures scientific research contributed notably philosopher rene descartes biologist charles darwin 
permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission 
proceedings volume th british hci conference london september british hci group dave hobbs university bradford school informatics hobbs bradford ac uk david moore leeds metropolitan university school computing isle research group moore lmu ac uk ekman universal facial expressions corresponding emotions surprise anger fear happiness disgust sadness 
categorisation widely accepted held expression extent recognition emotions innate basis cultures 
naturally developed skill read facial expressions considered highly beneficial communication cves inhabitants usually represented humanoid embodiments referred avatars 
avatar provide direct feedback particular user actions degree attention interactive abilities inhabitants effective interaction device 
believe emotionally expressive virtual face interlocutor avatar aid communication process provides information difficult mediate 

expressive avatars visual representations cve users remain relatively simple rudimentary 
particular virtual environments poor terms emotional cues convey 
accordingly need sophisticated ways reflect emotions virtual embodiments pointed repeatedly 
thalmann sees direct relation quality user representation ability interact environment 
observations show avatars primitive expressive abilities may engender strong emotional responses people cve system 
appears avatar readily take personal role increasing sense community feeling 
potentially genuine representation underlying individual visually social context 
aim research project investigate simple distinctive visual clues mediate emotional social state cve user 
whilst currently concentrating face channel conveying emotions seen wider context entire humanoid representation user principle act communication device cf 
gestures posture respectively 

emotion human face offer comprehensive description visible muscle movement face ekman friesen established facial action coding system facs 
informed major body highly detailed anatomical studies human faces 
facial expression high level description facial motions decomposed certain muscular activities relaxation contraction called action units aus 
facs identifies action units separately various combinations capable characterising human expression 
au corresponds action produced single muscle group related muscles 
au example inner contraction central muscle 

modelling virtual face interest modelling animating human face strong computer graphics community 
platt badler developed muscle model animated face 
initial approach developed modelling anatomical nature muscles elastic nature human skin detail 
approach described feature complex realistic simulation human physiology 
whilst approach new intentionally limit controllable features animated face see 
argued sufficient may fact preferable allows distinctive essential characteristics facial expression established 
eyebrows upper lower eyelids eyes mouth corners lips controllable features virtual head clearly parameters allow representation possible facial expressions 
necessary entire set facs action units reproduced achieve level detail envisaged current face model 
evidence human perception system recognise physical characteristics particular facial expressions visual stimuli experimental head model designed show merely distinctive facial clues 
donath warns face highly expressive adept reading level detail facial rendering potentially provoke interpretation various social messages 
messages unintentional face arguably hindering communication helping 
particularly distinctive faces may convey emotions efficiently normal faces detail regularly taken advantage 
purpose intended experiments relevant action units applied virtual head effectiveness terms cognition acceptance tested 
shows representation anger photograph alongside corresponding virtual head expression 
corresponding anger expressions 
experimental study purpose experimental establish reduced set action units proposed sufficient convey universal emotions avatars cve 
facial expressions emotion different ways natural photographs animated virtual heads 
factors sub levels universal expressions emotion neutral 
subjects took part experiment female male age average age 
classified facial expressions facs 
repeated measures design subject shown photographs corresponding virtual head images random order 
emotion categories represented variations 
variations defined differences representation emotion differences intensity 
subjects performance results experiments logged automatically 
data collected facial expression emotion consisted type stimulus material expression depicted facial areas emotion category expected emotion category picked subject 
post test questionnaire collected quantitative qualitative data complementing data collected recognition task 
results statistical analysis mann whitney test significance level suggested recognition rates photographs significantly higher virtual heads 
significant result attributable totally disgust category stood having low score virtual faces result photographs disgust excluding category removed significance difference 
surprise fear happiness neutral showed slightly better non significant results photographs anger sadness categories virtual faces scored little better significantly natural counterparts 
exception disgust category recognition successful virtual head directly corresponding photograph 
constructed avatar faces identified distinctive shown 
recognition rates varied significantly subjects 
achieved better results virtual natural images 
lower scoring subjects fail recognise virtual heads 
error analysis errors subjects assigning expressions categories analysed detail 
majority confusion errors related category disgust frequently confused anger 
examining results virtual heads anger picked twice disgust 
faces showing disgust subjects felt unable select category picked don know suggested alternative emotion example aggressiveness irritation self 
error analysis reveals fear mistaken surprise tendency observed studies 
emotions share similar visual characteristics ekman provides indicators distinguish person afraid surprised 
usually involve context timing fear inspiring event factors perceivable image 
similarly context seeing unfolding emotion time improved recognition rates 
suggests situations facial expression animated displayed context recognition rates higher 

discussion study shown recognition guaranteed expressions variations particular emotion category 
surprisingly critical issues similar identified social psychology 
firstly accepted categories exist emotions vary intensity inevitably subjective element recognition 
modelling animating facial features ambiguity interpretation minimised focussing emphasising distinctive visual clues particular emotion 
secondly context plays crucial role emotion expression recognition 
effective accurate mediation emotion closely linked situation related communicative signals 
reliable interpretation facial expressions independently context displayed 
anticipated confusion emotions avoided facial expression emotion operates interactive animated setting cve 
likewise emotion recognition real time vr setting consider effects timing display interpretation emotion 
example showing surprise period say minute send confusing contradictory signals 
certain emotions confused notably disgust anger 
particularly case virtual head expressions 
wang observed similar link emotions showing photographs faces children 
younger children aged tended group certain emotions older children typically ability differentiate correctly 
view findings may indicate adults surprise fear disgust anger happiness sadness neutral distinctive facial expression category differentiate emotions day day social interaction limited clues provided virtual head observers revert back experience instinct manner categorising 
necessary investigate possibility 
experimental provided strong evidence creating virtual face representations facs model limited number facial features allow emotions effectively portrayed visually gives rise recognition rates comparable corresponding photographs 
consequence top scoring expressions shown may provide sound basis building emotionally expressive avatars represent agents human users cves 

original virtual head geometry copyright 
photographs permission 

knapp nonverbal communication human interaction rinehart winston 
morris collett marsh gestures origin distribution jonathan cape 
facial expression recogn pragmatics cognition picard affective computing mit press dam sio error emotion reason human brain avon books 
ekman friesen emotion human face pergamon press 
reading faces window soul press 
ekman facial expressions power eds handbook cognition emotion john wiley sons 

thalmann role virtual humans virtual environment technology interfaces earnshaw 
eds 
frontiers human centred comp springer fleming animating facial features expressions charles river media 
dumas interface cooperative cve manchester uk thalmann thalmann nvc interface cves virtual reality 
durlach slater presence shared virtual environments virtual bt workshop presence uk coulson expressing emotion body movement aisb proceedings ekman friesen facial action coding system consulting psychologists press 
platt badler animating facial expression acm siggraph parke parameterized modeling facial animation ieee computer graphics applications terzopoulos waters analysis synthesis facial image sequences physical anatomical models pattern analysis machine intelligence dittrich facial motion recognition emotions psych 
ge donath mediated faces nehaniv dautenhahn 
eds cognitive technology instruments mind affective expressions machines chi proceedings ekman friesen pictures facial affect cd university california poggi pelachaud emotional meaning expression animated faces paiva 
ed 
affective interactions springer wang recognition emotion chinese australian children cross cultural psychology 
