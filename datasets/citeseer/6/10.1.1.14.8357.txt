exploiting diverse knowledge sources maximum entropy named entity recognition andrew borthwick john sterling eugene agichtein ralph grishman computer science department new york university broadway th floor new york ny usa sterling grishman cs nyu edu describes novel statistical named entity proper name recognition system built maximum entity framework 
ing framework maximum entropy ory utilizing flexible object architecture system able ily diverse range knowledge sources making tagging decisions 
knowledge sources include capitalization features lexical features features current section text headline main body dictionaries single multi word terms 
purely statistical system contains hand generated patterns achieves result com best statistical systems 
combined handcoded systems system achieves scores exceed highest com scores far published 
named entity recognition simplest common message understanding tasks 
ob identify categorize members certain categories proper names corpus 
specific test bed sub ject seventh message un conference muc task identify names falling cat egories person organization location date time percentage monetary amount 
describes new system called max imum entropy named entity mene pro 
working frame maximum entropy theory utilizing flexible object architecture system able extraordinarily diverse range knowledge sources making tagging decision 
knowledge sources include capitalization fea tures lexical features features indicating current section text 
broad array dictionaries useful single multi word terms names names rate suffixes automatically handles cases words dictionary 
required manual editing downloaded web simply obvious lists entered hand 
system built shelf knowledge sources contained hand generated patterns achieved result comparable best statistical systems 
experiments showed combined handcoded sys tems nyu university manitoba mene able generate scores exceeded highest scores far reported system muc evaluation 
appropriate training data believe system highly portable domains languages achieved results upper case english 
feel plenty avenues explore enhancing sys tem performance english language newspaper text 
maximum entropy tokenization test corpus set muc tags define name categories task hand problem named entity recognition reduced problem assigning tags token 
particular tag set tags states start continue unique 
addition ken tagged indicate part named entity 
instance tag phrase jerry lee lewis flew paris son start person continue person location unique approach essentially sekine 
tags muc form space fu tures maximum entropy formulation problem 
maximum entropy solution similar problem allows computa tion space possible futures space possible histories history maximum entropy conditioning data enables decision space futures 
named entity problem reformulate terms finding probability associated token index test corpus inf derivable ht corpus relative token computation dependent set features hopefully helpful making prediction 
current modeling efforts computational lin restrict features binary functions history 
stance features capitalized true location start current token capitalized binary function returns true current token history token tag trying determine initial capitalized letter 
set features training data maximum entropy estimation process produces model feature gi associated parameter ai 
allows compute conditional probability follows berger ff maximum entropy estimation technique guar feature gi expected value gi model equal em expectation gi training corpus 
words gi pme gi empirical probability pme probability assigned model 
complete discussions applied computational linguistics including description estimation procedure berger della pietra 
additional useful introductions examples applica tions jaynes 
authors remarked useful thing maximum entropy modeling allows modeler concentrate find ing features characterize problem letting estimation routine worry signing relative weights features 
system architecture histories futures mene consists set perl modules forms wrapper publicly available toolkit computes val ues parameters equation pair training files created mene 
mene flex due object treatment essential components maximum entropy system histories futures features borthwick 
history objects mene act containers list history views 
history view classes represent different type information history object 
features attempt de termine fire history request appropriate history view object history object query history view object determine firing conditions satisfied 
note history views generally hold information limited window current token 
current token denoted model holds information tokens wl history views ones 
views window objects hand trivial piece data integer indicating members space represent 
features features implemented binary valued functions query history objects deter mine fire 
sections look mene feature classes turn 
binary features mene features binary valued output binary features features sociated history view considered token 
examples token begins capitalized letter token digit number 
equation gives example binary feature 
binary history views mene binary features similar bbn nymble system bikel exceptions nymble feature significant non sentence capitalization 
didn include believing mene judgments surrounding lex content 
nymble features non overlapping 
cap feature took precedence initial cap feature 
features history space fea ture activates subset space feature shown model yield results included features arid features 
consequently mene allows features fire overlapping cases 
stance mene initial cap features ac histories clinton ibm nymble feature active clinton cap feature take precedence ibm initial internal cap feature take precedence 
lexical features create lexical history view tokens compared vocabulary vocabulary indices recorded 
train ing corpus define vocabulary tokens count 
words vocabulary assigned distinguished un known index 
lexical feature example view token person unique correctly predicts jones subtle feature picked mene pre word location unique 
domain muc training data avi ation disasters weak indicator real 
example feature mene constructor hand coded system probably regard risky incorporate 
feature conjunction weak features allow mene pick names systems discussed features automati cally acquired system attain high level performance features 
encouraging lexical features dependent external knowledge source lin guistic intuition completely portable new domains 
section features new york times articles constituted muc test training corpora composed distinct sections including date preamble text 
section features activate sections current token 
ex ample feature section view preamble person unique activation example clinton warns hus sein 
note headline preamble feature fire words 
course feature prediction correct clinton hussein 
section features establish background prob ability occurrence different futures 
instance nyu evaluation system value assigned feature predicts current section main body text times stronger feature predicts person unique section 
sys tem predicts default 
hand preamble contains headline author information feature predicting weaker cases 
times strong organization start zation instance 
dictionary features multi word dictionaries key element mene 
entry mene dictionary consists term tokens long 
ies case sensitive dictionary dictionary basis 
pre processing step summarizes information dictionary token token basis assigning token fol lowing tags dictionary start continue unique 
british dictionary dictionary feature see phrase british flight start 
table lists ies mene muc evaluation 
example dictionary feature name dictionary view unique son start example richard nixon assuming richard name dictionary 
note similar case overlapping bi nary features don worry words appearing dictionary commonly sense 
leave dangerous looking names april name nary name feature fires april lexical date dictionary features april fire assuming april date exceeded april son start person unique expect lexical feature high value outweigh name dictionary feature 
confirmed test runs instance april tagged name including case dictionary names corporate names corporate names suffixes colleges universities number data source entries www com www com corporate names processed perl script www utexas edu world univ alpha corporate suffixes tipster resource dates times hand entered state abbreviations www usps gov world regions www yahoo com death ron brown april similar plane crash thought somewhat tricky month followed specific date 
note system isn foolproof dan dictionary word appeared nary appear training corpus included vocabulary ap pear test corpus probably 
external system features nyu official entry muc evaluation mene took output enhanced version traditional hand coded proteus named entity tagger entered muc grishman 
addition subsequent evaluation university manitoba lin 
krupka hausman shared outputs systems training corpora various test corpora 
output sent standard muc output col didn special processing 
systems incorporated mene simply history views step process 
system output tokenized mene tokenizer cross system tokenization dis resolved 

tag assigned token sys tem noted 
tag tags mentioned person start loca tion continue result futures pro duced external systems external system histories mene 
table dictionaries mene example feature examples john april exxon motorola exxon motorola new york university college incorporated ag wednesday april est 
ny ca africa central america caribbean pacific rim proteus system iew person start person start example richard nixon case proteus correctly tagged richard 
important note mene features predict different pre external system 
seen process mene learns errors external system 
example evaluation system feature predicted person unique tag son unique proteus higher weight feature predicted person start person unique 
words proteus dency chop multi word names word 
mene learned easy override proteus way 
fact analysis dif ferences proteus output mene proteus output turned significant number instances mene extended contracted name boundaries way 
proper training data mene pinpoint selectively correct weaknesses handcoded system 
compound features mene currently direct ability learn com pound features patterns history side lexical feature activates single word instance 
sort pattern ability comes system multiple features firing 
predict york name new york location features firing predicts location token new 
predicts location york 
possible compound fi tures behave differently ously firing atomic features 
integrated model ad hoc manner nal system features constructed features essentially query external system history section history simultaneously ine fire 
particular feature fire proteus predicts person start current sec tion main body text son start 
allows mene assign lower proteus prediction preamble vs predic tion main body text 
proteus hand coded systems accurate main body text headline type material 
compound feature gave system slightly higher performance got just section features external system fea tures separately 
reasonable adding ability han dle fully general compound features feature fires features fire improve system performance limited experi ment 
addition allowing predict futures multi word patterns promising combinations features distinguishing capitalization head line vs main body text 
unfortunately experiment wait deploy sophisticated method feature selection discussed section 
feature selection features chosen simple method 
possible features classes want included model put feature pool 
stance want lexical features model activate range token token vocab size futures add 

lexical features pool 
term comes fact include words vocabulary plus unknown word 
pool select features fire times training corpus 
note algorithm entirely free human inter 
modeler selected classes features mene select relevant features train features proper weightings 
deviate basic algorithm ways 
exclude features activate sort default value history view 
history views sort default value display vast majority 
instance name dictionary tory view say current token name cases 
adding features activate token question name include features acti token name 
feature activated token name theoretically harmful practical disadvantages 
feature probably redundant frequency name dictionary hit constrained equation frequency non hit implicitly constrained 
secondly fea ture fire nearly token slow run time performance 
maximum entropy models designed han dle feature overlap high degree lap requires iterations maximum en tropy estimation routine lead numer ical difficulties 

features predict fire times included model 
experiments showed doing impact performance reduced size model 

way reducing model size lexical features activate token token excluded predict 
previous heuristic idea features predicting named entities useful features predicting default 
note method feature selection probably break tried incorporate gen eral compound features model described previous section 
model currently features trained articles text 
considered pairs features potential compound features compound features build atomic fea tures undoubtedly yield unacceptable slow model performance 
clearly sophisticated feature selection routine ones berger berger required case 
decoding viterbi search having trained features model assigned proper weight values features decoding marking new piece text fairly simple process 
tokenize text 

compute history views looking words dictionary checking output external systems checking words capitalized 
article text token text check fea ture see fires combine values firing features equation 
give conditional probability futures token article 
run viterbi search find highest probability legal path lattice conditional probabilities 
viterbi search necessary simply highest probability assigned token result incompatible assign ments 
instance assignment person start location consecutive tokens valid 
viterbi search finds highest probabil ity path tokens second follow defined table invalid transitions similar approach sekine 
results mene maximum entropy training algorithm gives reasonable performance moderate sized training corpora information sources allowing really shine training data information sources added 
table shows mene performance muc dry run cor pus consisted articles topic aviation disasters 
systems shown trained articles domain training corpus consisted words system turned tokens 
note smooth progression scores data added system 
note combined mene weakest sys tems mene proteus manitoba outperform strongest single system 
top score combining systems strong result 
different set data muc formal run data accuracy human taggers preparing answer key tested discovered measure marsh 
don human performance measures dry run test set attained result competitive human 
series runs examine systems performed different amounts train ing data 
experiments summarized ta ble 
note systems result systems mene manitoba ma proteus pr mene mene proteus mene manitoba ma iq pr iq pr ma pr ma iq table combined systems unseen data muc dry run test set achieved adding articles formal run test corpus basic article training data 
addition outstanding performance fig ure number shows mene responsiveness training material 
drawn data 
mene needs articles tagged training data get ac performance 
secondly minimum amount training data needed mene improve external system 
pro manitoba system number articles show tion performance 
system stronger start mene required arti cles show improvement 
note anomaly comparing article columns 
proteus shows small gain shows deterioration 
articles added system tagged nyu guess tagged carefully rest data tagged bbn science applications international saic 
mene run uppercase data 
achieved measure mene system mene proteus system 
matches best currently published result bikel domain caps data 
hand scored lower caps bbn identifinder muc formal evaluation reasons probably similar ones discussed section comparison mixed case performances miller borthwick 
put little effort optimizing mene systems mene mene proteus ii mene manitoba mene pr ma iq ii table systems performances different numbers articles type corpus believe room improvement 
experiment stripped fea tures lexical features till achieved measure 
features rely external knowledge sources automatically generated result strong indicator mene portability 
muc formal evaluation involved shift topic communicated pants training data focused air line disasters test data missile rocket launches 
mene fared poorly data domain data quoted achieving measure mene proteus system mene system 
fourth highest score twelve participants evaluation feel necessary view number cross domain portability result indicator system unseen data training domain 
believe system allowed train mis rocket launch articles performance articles better 
mene test results discussion formal run borthwick 
related successfully applied tasks computational linguistics 
solid comparable benchmarks adwait ratnaparkhi university pennsylvania 
achieved state art results applying parsing ratnaparkhi part speech tagging ratnaparkhi sentence boundary detection reynar rat 
applied language modeling rosenfeld ma chine translation berger resolution kehler 
applied named entity recognition muc confer ence borthwick mikheev grover 
note part speech tagging ways similar task named entity recogni tion 
ratnaparkhi tagger similar mene features look surrounding word lexical context system dic 
hand system looks word suffixes prefixes case unknown words haven tried mene looks output looking previous tags making decision 
implicitly requirement futures output consistent attempt directly building consistency feature directly model effect results 
muc conference interesting systems statistical techniques language technology group university ed mikheev grover bbn miller 
comparisons ltg system difficult hybrid model text passed stage pro cess involved maximum entropy half system recall came non statistical phases 
ltg system demon superior performance formal run rel ative mene proteus hybrid system vs isn clear advan tage came superior handcoded rules statistical techniques system easily broken separate components mene proteus 
possible tighter system integration statistical hand coded components responsible ltg relative advantage note mene proteus ap pears advantage ltg terms portability 
currently experimenting porting mene japanese instance ex combined pre existing japanese handcoded system isn clear done ltg system 
avenues research look tighter multi system integration methods won compromise mene essential portability 
table gives comparison bbn hmm identifinder miller nyu mene mene proteus systems different training test sets 
sure mene proteus hurt badly evaluation time switch aviation disaster articles mis conditions trained official training data tested dry run domain organization trained data tested dry run run official muc data identifinder mene mene proteus table comparison bbn nyu statistical systems rocket launch articles suspect may due identifinder greater quantity quality training data 
bbn words training data 
quality advan tage may come selecting sentences larger corpus annotators tag chosen increase variety training data 
mene compared training number articles test ing domain data identifinder edge 
speculate due dynamic updating identifinder vocabulary ing person organization names recog gives system sort long ce resolution lacking mene 
addition bbn hmm system pre dicts named entities consecutive pairs words single words done mene type name bigram language model 
decoding process viterbi algorithm chooses sequence names yields highest joint probability names words features associated word 
comparing maximum entropy hmm approaches named entity recognition hopeful turn better method 
ire think possible identifinder current advantage neutral ized simply adding just mentioned features mene 
hand harder time seeing mene strengths inte hmm system 
clear instance wide variety dictionaries added identifinder system combined handcoded system done system ltg 
mene new feel immature system 
started october system described place mid february 

believe push score mene system higher rating long range resolution mene output 
missing large number acronyms picked dynamically building entities mene tagged pulling data new class feature 
key element missing current system set general compound fea tures discussed require sophisticated feature selection algo rithm 
elements systems krupka hausman absence mene probably ex plains reason mene sys tem failed perform state art 
intend add elements mene near test hypothesis 
believe demonstrated useful results 
mene highly portable demonstrated result upper case english text current state results compa purely statistical english ne system aware miller 
shown result run ning mene lexical features learns training corpus porting mene done little effort appropriate training data provided isn necessary provide dictionaries generate acceptable result 
working port japanese ne demonstrate mene flexibility 
believe results combining mene systems 
hypothesize sufficient training data handcoded system benefit having output passed mene final step 
mene opens new avenues ration different organizations focus different aspects problem recognition maximum entropy system acting ar 
mene offers prospect achieving high performance little effort 
mene starts fairly high base score just speculate mene user construct hand coded system focused mene weaknesses skipping areas mene strong 
imagine user acquiring licenses different systems generating training data combining mene system 
shown ap proach yield performance competitive human tagger 
acknowledgments troy writing viterbi search routine 
adam berger harry 

compar ison criteria maximum entropy minimum divergence feature selection 
nancy ide editors proceedings third conference empirical methods natural lan guage processing pages 
association computation linguistics june 
adam berger stephen della pietra vin cent della pietra 

maximum entropy approach natural language processing 
compu tational linguistics 
daniel bikel scott miller richard schwartz ralph weischedel 

nymble high performance learning name finder 
fifth con ference applied natural language processing 
andrew borthwick radu florian kishore pa 

system architecture mene strongly influenced architecture maximum entropy language model jointly devel oped authors ibm watson labs yorktown heights new york summer 
andrew borthwick john sterling eugene agichtein ralph grishman 

nyu description mene named entity system muc 
proceedings seventh message understanding conference muc 
stephen della pietra vincent della pietra john lafferty 

inducing features ran dom fields 
technical report cmu cs carnegie mellon university 
ralph grishman 

nyu system syntax 
proceedings message understanding conference 
morgan november 
edwin jaynes 

probability theory logic science 
manuscript book 
available bayes wustl edu may andrew kehler 

probabilistic coreference information extraction 
empirical methods natural language processing volume august 
george krupka kevin hausman 

description tm extrac tor system muc 
proceedings seventh message understanding conference muc 
dekang lin 

collocation statistics formation extraction 
proceedings sev message understanding conference muc 
elaine marsh dennis 

muc evaluation technology overview re sults 
proceedings seventh message un conference muc 
andrei mikheev claire grover 

ltg de scription ne recognition system muc 
proceedings seventh message un conference muc april 
scott miller michael crystal fox lance richard schwartz rebecca stone ralph weischedel annotation group 

algorithms learn extract information bbn description sift sys tem muc 
proceedings seventh message understanding conference muc april 
adwait ratnaparkhi 

maximum entropy model part speech tagging 
conference empirical methods natural language pro cessing pages 
university nia may adwait ratnaparkhi 

linear observed time statistical parser maximum entropy models 
conference empirical methods natural language processing 
university penn june 
adwait ratnaparkhi 

simple maximum entropy models natural language processing 
technical report institute research cognitive science university penn may jeffrey reynar adwait ratnaparkhi 

maximum entropy approach identifying sen tence structures 
fifth conference applied natural language processing pages april 
eric sven 

maximum en tropy modeling toolkit release beta 
www mnemonic com software february 
includes documentation overview maxent modeling 
ronald rosenfeld 

adaptive statistical lan guage modeling maximum entropy approach 
ph thesis carnegie mellon university 
cmu technical report cm cs 
satoshi sekine ralph grishman shin 

decision tree method finding classifying names japanese texts 
proceedings sixth workshop large corpora 
