parametric nonparametric methods statistical evaluation human id algorithms ross beveridge kai bruce draper givens computer science department statistics department colorado state university colorado state university fort collins fort collins reviews major issues associated statistical evaluation human identification algorithms emphasizing comparisons algorithms set sample images 
general notation developed common performance metrics defined 
simple success failure evaluation methodology recognition rate depends binomially distributed random variable recognition count developed conditions model appropriate discussed 
nonparametric techniques introduced including bootstrapping 
applied estimating distribution recognition count single set sampled probe images bootstrapping noted equivalent parametric binomial model 
bootstrapping applied recognition rate resampled sets images problematic 
specifically sampling replacement form image probe sets shown introduce conflict assumptions required bootstrapping way recognition rate computed 
part overcome difficulty bootstrapping different nonparametric monte carlo method introduced utility illustrated extended example 
method permutes choice gallery probe images 
answer questions 
question recognition rate vary comparing images individuals taken different days camera 
question observed difference recognition rates distinct algorithms significant relative variation 
important general features nonparametric methods illustrated monte carlo study 
broad limits resampling generates sample distributions statistic interest 
second careful choice appropriate statistic subsequent estimation distribution domain specific hypotheses may readily formulated tested 
due part feret evaluations protocol comparing human identification algorithms human face recognition algorithms formulated standardized :10.1.1.140.8914
section review formulation establish mathematical notation needed address questions statistical evaluation 
formalization essential far gives working evaluation common frame 
taken encompassing inevitably aspects central current evaluation tasks missing 
section introduces compact notation describing populations samples 
notation summarized convenience table 
introduces critical image sets evaluation training set gallery probe set 
section reviews human identification algorithms developed performance depends firstly trained secondly gallery images provided 
section reviews similarity matrix may pre computed human identification algorithms subsequently efficiently conduct virtual experiments 
section formally defines recognition rate median rank median censored rank distinct performance evaluation metrics 
section introduces simple binomial model outcomes testing recognition algorithms applied human identification data 
assumptions underlying model discussed practical significance violating assumptions common scenarios 
show binomial model formulate test hypotheses form algorithm performing better algorithm 
specifically mcnemar test provided simple direct test algorithms tested common data paired testing 
mcnemar test example comparing pca ica face recognition algorithms feret data 
section introduces nonparametric techniques resampling 
particular bootstrapping table 
notation summary symbol usage target population images people recognized 
th image person 
finite set images available performance evaluation sampled population 
th image person training images typically gallery images typically probe images typically algorithm algorithm trained algorithm trained exemplars 
union gallery probe sets set experiments th image person 
similarity relation pairs images 
pairwise similarity matrix 
probe image gallery image 
gallery images sorted decreasing similarity image 
th element 
recognition rate algorithm probe set rank correct match probe image 
rank censored maximum value 
median censored rank probe set success indicator function algorithm applied probe image 
th randomly selected probe image sequence 
random sequence probe images results indicator function applied 
probability event 
assumptions underlying briefly discussed 
section observed applying bootstrapping particularly simple dataset consisting collection success failure outcomes leads back binomial model developed section 
section provides detailed example monte carlo resampling procedure permuting choice gallery probe images 
context difficulty direct application bootstrapping circumvented 
section illustrates advantages nonparametric methods relative traditional parametric methods 
illustrates sample distributions relevant statistics may obtained directly need know exact distribution data 
second freedom provides wide latitude develop domain specific statistics greatly simplify direct statement interesting hypotheses 
words formalize general hypothesis algorithm performing better algorithm precise manner desired provide interpretable result 
data denote target population images goal characterize algorithm performance 
denote elements subscripts meaning th image th person 
double subscripting highlights distinction images single person images different people 
practice evaluators access sampled population finite set 
example evaluating algorithms frontal face images feret data set contains images people 
generalization rests judgment nature sampling process giving rise evaluating algorithms subsets interest training set gallery set probe set distinction differs common binary distinction machine learning speaks training test data 
match distinction training validation test machine learning 
usage essentially identical training test data machine learning 
gallery contains exemplars people recognized 
direct correlate common machine learning nomenclature 
cases may set 
words algorithm may trained set images trained algorithm may set match probe images 
need case 
example feret tests algorithms typically trained different set images gallery 
actual performance algorithm rated relative images matched images 
example performance perfect probe set image image 
words probe image matched different image person th person 
follows disjoint problem trivial 
case typically contains image person 
said relate algorithm performance measures sections follow 
algorithms algorithm behave depends trained quality exemplars 
instance class algorithms principal components analysis pca algorithm defined part training part gallery 
example training phase pca algorithm uses images define subspace operate nearest neighbor classifier 
gallery provides exemplars people recognized 
example pca algorithm images projected subspace exemplars novel probe images compared nearest neighbor classifier 
types face recognition algorithms usage differ algorithms utilized manner 
algorithm dependency indicated subscripting algorithm trained gallery 
similarity matrices commonly recognition algorithms may characterized similarity matrix represents information perform classification 
similarity mea sure function similarity rank gallery images relative specific probe image 
best match probe image gallery image condition similarity relation satisfy perform function induce complete order set images practice ties may arise 
long ties rare probably safe impose arbitrary choices ignore problem 
similarity measure gives rise ties gives rise weak order complete order turn leaves performance measures recognition rate ill defined 
cases similarity derived distance measure 
example pca algorithm may define similarity follows city block distance images measured pca subspace 
small constant prevents similarity measure undefined zero 
feret studies extensive fact algorithm fixed training similarity assigned pair images constant 
algorithm experiments may conducted virtual fashion 
illustrate feret studies results utilized training set gallery probe sets :10.1.1.140.8914
algorithm run union gallery probe sets tests run similarity information cached similarity matrix 
formally feret studies pooled set images corresponding similarity matrix short description partitions table 
probe sets conjunction single gallery set compare algorithm performance 
exact images sets enumerated lists available 
site overlap sets terms people common images common 
images probe set included 
overlap probe sets unusual 
probe sets disjoint case table 
feret evaluations 
set images description images taken facial expressions neutral versus 
images taken facial expression 
subjects taken time 
subjects taken time harder subset dup subjects taken different illumination 
training images roughly percent percent dup intersection null set 
matrix useful ways 
done feret studies allows different virtual experiments conducted running algorithms 
supports quickly executing thousands virtual experiments associated required nonparametric statistical techniques bootstrapping 
nonparametric techniques may compute recognition rates algorithms subject thousands different choices gallery probe images 
experiments conducted running recognition algorithm cases repetition computationally tractable 
unfortunately variances performance associated changes training data investigated trick precomputing similarity matrix breaks 
algorithm variants trained different sets typically yield different similarity matrices 
example pca algorithm requires new subspace projection constructed new set training images 
performance measures recognition rate recognition rate common measure evaluate performance 
step defining recognition rate defining means successfully recognize probe image may done follows 
probe image sort gallery images decreasing similarity yielding list 
gallery image closest probe image closest gallery image generalizing th closest gallery image 
algorithm successfully recognizes th person probe image closest gallery image index equals index 
plain english algorithm successfully recognizes person probe image top ranked gallery image person 
success criterion may expressed form indicator function 
algorithm correctly recognizes probe image requirement image person appear may relaxed algorithm said succeed image person appears closest gallery images 
gives rise family indicator functions fixed choice recognition rate probe set size event tie typically specified 
methods pca distances measured high dimensional subspaces double floating point arithmetic ties seldom considered 
easily imagine algorithms ties require explicit treatment 
deeper question differences meaningful questions easily answered general case dealt specific choices imagery analysis techniques employed resemble statistical methods set 
rank censored rank alternative choosing definition recognition rate scoring algorithm succeeding failing report rank algorithm succeeds probe image 
sorted list gallery images defined gallery image sequence person probe image index equals index 
rank successful match obvious rank measure evaluating performance probe image point differences large rank values don matter missing may considered bad missing line thinking gives rise censored rank example censored rank clamp placed probe image matches gallery image person rank implies probe image matched gallery image person rank value greater equal censored rank defined relative single probe recognition rate defined set probes additional summary statistic chosen single value censored rank characterize performance probe set 
statistic median choice gives rise median censored rank median median censored rank exemplifies statistics traditional parametric techniques limited value probability distribution typically understood parameterized form see section 
algorithm testing bernoulli trials recognition algorithms considered deterministic 
follows presumption distance images fully defined algorithm trained training imagery risk stating obvious succeeds fails random uncertain 
consider happens applied collection probe images drawn random larger population possible probe images 
denote th randomly selected probe image suppose population drawn property words equation states probability algorithm recognizing randomly selected probe image 
provide intuition model relate selection probe images classic simple experiment 
jar containing mix red switch double single subscripting images intentional 
single subscript emphasizes index refers placement collection randomly selected images 
clearly random sampling means known 
green marbles 
reach jar select marble random record marble green 
place marble back jar 
times conducting bernoulli trials number recorded random variable described binomial distribution 
distribution parameterized number marbles drawn fraction marbles green 
equation marble drawing experiment analogous equation marble drawn green obvious jar marbles probability randomly selected marble green ratio green marbles total number marbles 
likewise randomly selected probe images 
fraction probe images population possible probe images correctly recognized algorithm 
fraction dictates indicator function behave sequence independently selected probe images 
characterizes recognition rate defined equation behaves 
restating equation rank follows directly assumptions binomially distributed random variable appropriateness binomial model binomial model extremely simple aspects consideration warranted 
discussion may help eliminate areas concern 
sampling replacement terms mathematically correctness model difference sampling replacement sampling replacement fundamental 
concern human identification experiments sample probe images replacement 
question arises model built assumption sampling replacement may experiments sampling done replacement 
concern little practical significance 
assumes target population large relative sample size probability sampling instance twice low difference sampling replacement negligible 
case norm human identification experiments number samples probe images smaller population attempting draw statistical inferences performance recognition algorithm 
people harder recognize question individual people harder automated algorithm recognize 
concern success failure model 
answer hinges assumes sampling 
sampling probe images done independently random sampled population representative target population fact people harder recognize irrelevant 
easily imaging situations true 
helpful way illustrate binomial model proposed applies know individuals harder recognize extend marble example 
selecting marble jar consider selecting cabinet 
selection operates selecting drawer random selecting marble drawer random 
assume different different fractions green red marbles 
experiment true marble drawn green marble drawn drawer drawer selected random experiment equivalent experiment marbles poured single jar mixed marble selected jar 
equivalent earlier experiment 
marbles th drawer probability drawing green marble randomly selected drawer weighted average probabilities drawer marble drawn green finish analogy consider person probe set corresponds drawer image person corresponds marble drawer 
people unequal probabilities successfully recognized unconditional probability correctly recognizes randomly selected probe image 
long representative problem probe image person outcome outcome table 
hypothetical summary paired recognition data suitable mcnemar test 
means algorithm correctly identified probe represents failure 
cause argument equally applied sampling 
course individual drawer attributes known elementary sampling techniques show powerful tests estimators ones propose constructed 
unreasonable human identification context assume known eliminate distinction probe gallery sets considered estimable 
hypothesis testing binomial model binomial model simple natural approach comparison performance algorithms mc test 
test suitable paired data example data generated testing trained algorithms gallery probe sets 
imagine cases comparison independent datasets 
case standard statistical methods comparing population proportions 
applied 
paired data applying recognition algorithms say set gallery probe images naturally summarized table 
outcomes tabulated labeled ss sf fs ff ss means algorithms succeed sf means succeeds fails 
probes hypothetical example correctly identified algorithms incorrectly identified algorithms 
recognition rate 
clearly comparison algorithms boils comparing relative frequencies sf fs 
paired success failure trials mcnemar test mcnemar test begins discarding cases outcome ss ff 
remaining outcomes sf fs sign test 
null hypothesis probabilityof observing equal observing 
denote number times observed denote number times observed 
interested sided version test loss generality consider alternative hypothesis fails 
mismatched outcome sf fs equally favor 
mismatches favor mismatches favor 
probability value rejecting favor 
illustrating mcnemar test comparing pca ica example binomial evaluation methodology compare recognition rates principal components analysis pca independent components analysis ica faces feret face data base 
example short summary results 
results comparing pca ica feret data set table 
algorithms compared measuring probe image matches nearest gallery image 
comparison rank 
distance measure norm pca cosine ica recommended 
columns table indicate gallery probe set respectively 
number correctly recognized images total number images shown rational number percentage pca ica algorithm 
count possible outcome paired tests shown 
possible outcomes ss pca ica algorithm recognize image 
sf pca algorithm recognizes images ica algorithm 
fs ica algorithm recognizes images pca algorithm 
ff algorithms fail recognize image 
value null hypothesis shown experiments 
value indicated binomial model tests indicate pca algorithm significantly better ica probe set 
simplicity binomial model strength binomial model comparing recognition algorithms relative simplicity 
confident quickly understand nature model perform tests mcnemar order check statistical significance observed difference recognition performance 
said model weaknesses 
weakness binomial model reliance assumptions may may reasonable experiment 
assumptions violated significant errors ensue turn lead false 
discussed circumstances violating assumption example sampling replacement significant practical concern 
circumstances violated assumption may lead erroneous results 
troubling easy researchers modest statistical training distinguish cases 
nonparametric methods generally bootstrapping specifically computer intensive nonparametric methods free limiting assumptions distributions 
attractive feel comfortable binomial model 
arguably informative data derived recognition experiments binary data arranged simple contingency table analyzed mcnemar test 
example median censored rank statistic isn suitable analysis 
simple binomial model conditional gallery relevant unconditional 
words usually wish draw relative performance algorithms generalized single small number gallery set testing 
reasons turn attention flexible nonparametric techniques 
methods represent means directly estimating probability distributions statistics interest 
examining monte carlo method estimate probability distribution functions recognition rate subject variation choice probe gallery images set individuals feret data set 
ross terry boult conducted related type non parametric sampling test technique called balanced replicate resampling 
section briefly describes bootstrapping general illustrates bootstrapping particularly simple problem bootstrapping distribution success failure counts sampling set succeeded failed values obtained running algorithm single probe table 
performance pca ica 
probe sets ordered easiest hardest 
pca ica paired outcomes mcnemar gallery probe set corr total pct corr total pct ss sf fs ff test value set 
particularly simple illustration observe form resulting distribution known precisely binomial distribution discussed 
bootstrapping general bootstrapping procedure proceed follows 
sample size larger population 
statistic estimating quantity interest 
example population median sample median 
bootstrapping allows estimate probability distribution function 
course distribution median known general statistics distributions difficult determine analytically exemplified 
distribution estimated repeatedly drawing formed selecting elements independently completely random replacement 
value associated statistic computed denote repeated times 
normalized histogram resulting values approximation probability distribution function 
careful thorough bootstrapping efron 
bootstrapping performance measures fixed terms human identification recognition rates particular bootstrapping applied problem estimating probability distribution recognition rate fixed training gallery sets 
consider success indicator function equation 
probe set size representative larger population sample success failure outcomes algorithm may expressed sequence recognition rate sample th element sequence 
bootstrap statistic generate compute normalized histogram values bootstrap distribution 
course application bootstrapping recognition rate problem somewhat pointless shown analytically binomially distributed random variable 
bootstrapping case amounts monte carlo approximation integral exact value equation 
related statistics distribution easily known 
example consider bootstrapping determine probability median censored rank statistic defined section equation 
procedure draw say original probe set 
pseudo probe sets compute value normalized histogram resulting values represents bootstrap distribution median censored rank 
permuting gallery probe choices example evaluation methods left choice gallery fixed 
performance variability due variations gallery measured 
designing experiments easier amount variation seen practical circumstances galleries vary 
applications evaluation studies accounting variation gallery imagery appropriate 
summary monte carlo study designed compare pca pca lda algorithms varying choices gallery probe images 
algorithm descriptions data preprocessing steps omitted exact nature algorithms data important methodology illustrated 
details may 
study assumes null hypothesis person gallery images exchangeable son probe images 
assumption evaluation results seen actual experiment distributionally equivalent obtained hypothetical experiment different probe gallery images people 
considering outcomes hypothetical experiments straightforward derive null distribution test statistic interest 
initially design bootstrapping study difficulties described led favor different monte carlo method 
different method generates samples contain instance person permuting choice gallery probe images 
research question associated data related questions give rise study 
variation recognition rate expected comparing gallery images individuals taken day probe images taken day 

algorithm perform significantly better relative variance induced perturbing gallery probe images 
arrived choice imagery noting complete feret database includes source images subject facing directly camera 
distinct individuals represented 
people images images 
precise people images pair taken single day second pair different day 
images taken day subject instructed pick facial expression image second people image person appropriate testing questions posed 
training algorithms consider arguably difficult case precluding overlap training test data 
decided imagery people images training 
consequently pca algorithm trained images 
keeping common practice feret evaluation top percent eigenvectors retained 
lda algorithm trained surprise readers note instruction 
specifically subjects coached sort expression adopt example smile happy sad 
incorrect assume expressions different 
images partitioned classes class person 
additional details regarding data preprocessing algorithm training appear day day expression expression person 
table 
illustrating organization test images organized person day facial expression 
order investigate recognition rate varies different choices probe images gallery images permute assignment images 
research question concerns algorithm performance probe gallery images taken different days monte carlo process preserve multiple day separation property 
easily done process best explained test data shown table 
describing monte carlo technique explain bootstrapping study 
bootstrapping recognition rate difficult obvious way perform bootstrapping image data table sampling population people replacement 
sampling replacement critical component bootstrapping order properly infer generalization larger population people 
went road steps encountering difficulty 
sampling replacement individuals appear multiple times duplicates cause problem scoring methodology 
see clearly necessary go level deeper sampling methodology 
individual selected remains select pair images testing gallery image probe image 
sake illustration assume individual duplicated times assume moment gallery image selected random columns probe image columns possible selection chances individual duplicated times pairs ordered gallery image probe image 
intent bootstrapping pair selected example recognition score pertain specifically pairing 
easily happen probe image close gallery image strict adherence bootstrapping requirements dictates near match ignored algorithm scored set nearest gallery images 
clearly scoring defined 
making change alters measure attempting characterize option 
match counted happen normal application recognition rate defined bootstrapping assumptions violated 
immediately obvious preserve recognition rate scoring protocol simultaneously satisfy needs bootstrapping 
matter certainly closed consider alternatives 
moment problem represents significant obstacle successful application bootstrapping turn energies monte carlo approach require sampling replacement 
permuting probe gallery choices nonparametric techniques idea monte carlo approach generate sampling distribution statistic interest repeatedly computing statistic different datasets equivalent 
approach key assumption gallery images individual exchangeable probe images 
true example exchangeable statistic interest recognition rate samples obtained permuting choice gallery probe images exchangeable options people 
done going list people selecting random gallery image day probe image illustrated table 
unbalanced sample columns equally represented 
balanced sampling easily obtained permuting personal identifiers fixed pattern samples columns illustrated table 
guarantees equal sampling columns 
experiments balanced sampling 
section discusses empirical difference little presents example 
id id 

table 
illustrating unbalanced balanced sampling 
sampling strategies permute choices gallery probe images 
tables column integer indicating person second column gallery image third column probe image 
distributions confidence intervals recognition rate mentioned virtual experiments randomly selected probe gallery sets may run running recognition algorithms distance matrix computed 
done test images algorithms 
pca distance 

pca distance 

pca angle normalized image vectors distance measure 

pca mahalanobis distance 

lda distance 

lda distance 

lda angle normalized image vectors distance measure 

lda soft weighted variant distance 
variants fully described 
eigth uses weighted distance measure proposed zhao 
essentially norm modification dimension scaled associated lda eigenvalue raised power test 
rank recognition rate distributions pca lda variants 
balanced sampling described simulate experiments different combinations probe gallery images selected 
trials recognition rate recorded 
values generate sample distribution distribution recognition rates represents approximation probability distribution larger population possible probe gallery images 
figures show distributions pca lda algorithm variants rank explain recognition rate labels axis images probe sets 
means recognition rates possible recognition rate runs increments avoid problem unequal allocation samples histogram bins histogram bins units wide 
fashion distributions relatively smooth order unimodal 

confidence intervals pca mahalanobis distance 
looking pca algorithm variants clear ranking mahalanobis distance followed distance followed remaining 
take shortly question refine question relative performance variants 
looking lda algorithm variants things stand 
little difference 
second clustering recognition rates slightly lower pca algorithm angle clearly worse pca mahalanobis distance 
simplest approach obtaining sided confidence intervals percentile method 
example centered confidence interval determined coming ends accumulated probability exceeds side 
best done sampled version histogram bin width equal shows confidence intervals obtained manner just described ranks keep readable confidence intervals pca algorithm mahalanobis distance shown 
keep mind pointwise intervals rank adjusted multiple comparisons 
plots elaborations cms plots commonly feret evaluation notable exception intervals single curves shown 
distributions confidence intervals call attention differences pca mahalanobis distance distance measures 
example overlapping confidence intervals shown drawn conclude significant difference pca versus pca mahalanobis distance 
section show direct discriminating ways approach questions simply looking see confidence intervals overlap somewhat misleading 
hypothesis testing better question typically asked algorithm perform better algorithm 
gives rise sided test form 
formally hypothesis tested associated null hypothesis recognition rate algorithm higher algorithm recognition rates identical algorithms 
establish probability new statistic introduced measures signed difference recognition rates monte carlo method find distribution may find distribution words gallery probe sets selected randomized procedure times difference computed time 
shows distributions pca algorithm pairs distance measures mahalanobis minus minus minus angle 
differences mahalanobis minus minus distribution highly skewed respect zero 
mahalanobis minus case equal zero times 
minus case equal zero times 
third comparison angle distribution centered closely zero 
case equal zero times 
distributions may test 
table shows probabilities observed differences 
high confidence may rejected favor comparisons third 
observe probabilities derive directly ratio stated 
glance appear wise carry possible pairwise tests doing invites false associations 
common practice rejecting probability level implies mistakenly reject times 
multiple comparison procedures employed remedy problem full analysis variance provide richer model inference 
plan pair analysis 
rank distribution recognition rate difference 
alg 
alg 
mah 
angle table 
probability rank observed difference recognition rate 
variance model monte carlo inferential paradigm provide complete analysis experimental data 
lieu procedure looking individual performance measures making small set salient pairwise tests reasonable strategy 
balanced versus unbalanced sampling section indicated sampling may done balanced unbalanced fashion 
distinction matter context 
shows result comparison recognition rate probability distribution pca algorithm mahalanobis distance obtained balanced versus unbalanced sampling 
distinction appear matter distributions essentially indistinguishable 
distributions essentially unchanged unbalanced sampling compared balanced 
needed fully explore implications alternative sampling methods definitions balanced versus unbalanced sampling introduced distinction appears matter little 

distributions obtained balanced versus unbalanced sampling 
framework making statistical comparisons different human face recognition algorithms statistical evaluation methods developed 
parametric method equates success failure algorithms probe images bernoulli trials 
method simple captures variation arising size sample number probe images tested 
precisely captures uncertainty associated estimating true probability algorithm succeeds finite number samples 
second method nonparametric monte carlo sampling technique samples space possible gallery probe sets 
method approximates probability distribution statistic recognition rate difference recognition rate 
desire practice know algorithms behave changes gallery probe sets methodology arguably interesting 
method illustrated examples comparing known algorithm types literature 
example shows feret data test conditions specified standard pca classifier performs recognition better ica classifier 
second example shows standard pca classifier performs recognition better pca followed lda classifier 
cases literature suggesting results come way 
needed better understand results 
part larger effort understand certain common face recognition algorithms behave de better statistical evaluation methodologies comparing algorithms 
web site developed report progress 
source code pca algorithm pca followed lda algorithm available site 
supported defense advanced research projects agency contract dabt 
bartlett lades independent component representations face recognition 
spie symposium electronic imaging science technology conference human vision electronic imaging iii san jose ca 
beveridge draper givens 
nonparametric statistical comparison principal component linear discriminant subspaces face recognition 
proceedings ieee conference pattern recognition machine intelligence page appear december 
beveridge 
evaluation face recognition algorithms web site data section 
cs colostate edu 
cochran 
sampling 
wiley sons new york 
cohen 
empirical methods ai 
mit press 
devore peck 
statistics exploration analysis data edition 
brooks cole 
efron gong 
look bootstrap jackknife cross validation 
american statistician 
ifa 
statistical tests uva nl service statistics html 
website 
bruce draper ross beveridge kai 
pca vs ica comparison feret data set 
ieee conference computer vision pattern recognition page submitted 
turk pentland 
face recognition eigenfaces 
proc 
ieee conference computer vision pattern recognition pages june 
kirby sirovich 
application karhunen loeve procedure characterization human faces 
ieee trans 
pattern analysis machine intelligence january 
phillips moon rizvi rauss :10.1.1.140.8914
feret evaluation methodology face recognition algorithms 
pami october 
ross terry boult 
efficient evaluation classification recognition systems 
ieee computer vision pattern recognition page appear december 
wendy beveridge 
analyzing pca face recognition algorithms eigenvector selection distance measures 
second workshop empirical evaluation computer vision dublin ireland july 
zhao chellappa krishnaswamy 
discriminant analysis principal components face recognition 
wechsler philips bruce fogelman soulie huang editors face recognition theory applications pages 
zhao chellappa phillips 
subspace linear discriminant analysis face recognition 
umd 

