linear segmentation segment significance min yen kan judith klavans kathleen mckeown department computer science center research information access columbia university new york ny usa min klavans kathy cs 
columbia edu new method discovering segmental discourse structure document categorizing segment function importance 
segments determined zero sum weighting scheme occurrences noun phrases pronominal forms retrieved document 
segment roles calculated distribution terms segment 
results evaluation terms precision recall surpass earlier approaches 
identification discourse structure extremely useful natural language processing applications automatic text summarization information retrieval ir 
example summarization agent chose summarize discourse segment separately 
segmentation document blocks topically similar text assist search engine choosing retrieve highlight segment query term occurs 
topical segmentation program achieves increase precision recall comparable previous 
addition segmenting system labels function discovered discourse material supported national science foundation 
nsf iri columbia university center research information access 
segments relevance 
identifies segments contribute detail main topic input segments summarize key points segments contain important information 
evaluated segment classification part summarization system utilizes highly pertinent segments extract key sentences 
investigated applicability system general domain news articles 
generally longer articles usually page limit tended prior segmentation markings consisting headers bullets excluded 
concentrated corpus shorter articles averaging roughly words length wall street journal linguistic data consortium collection line economist 
constructed evaluation standard human segmentation judgments test output 
segmenter linear segmentation purposes discourse structure identification follow formulation problem similar hearst zero segment boundaries various paragraph separations identify topical text segments 
segmentation linear hierarchical marcu yaari input article divided linear sequence adjacent segments 
segmentation methodology distinct phases executed sequentially 
describe phases detail 
weigh score terms segment links 
segmenter architecture extracting useful tokens task determining segmentation bre depends fundamentally extracting useful topic information text 
extract categories information reflect topical content text referred terms remainder 
proper noun phrases 
common noun phrases 
personal possessive pronouns 
order find types terms tag text part speech pos information 
methods investigated assigning pos tags text running specialized tagging program simple pos table lookup 
chose assign tags time efficiency reasons segmentation task preprocessing stage optimized pos table favor high recall term types possible 
resulting system faster initial prototype approach magnitude slight decline precision statistically significant 
large system requires accurate tags segmentation cost tagging issue tagging lookup 
pos table lookup nyu comlex grishman 
simplifying comlex categories reflect information important term types flattened multi category words jump single category strategy motivated give high term recall jump maps np term type 
pos tags assigned retrieve occurrences noun phrases searching document simple regular expression noun noun expression captures simple noun phrase complements 
complex noun phrases leap wine napa valley captured different phrases leap wine napa valley 
deliberately regular expression powerful capture noun phrases possible emphasis high np recall 
retrieving terms post processing phase combines related tokens 
possessive pronouns merge possessive appropriate personal pronoun mine noun phrases noun phrases heads 
example noun phrases red wine wine text subsume occurrences red wine occurrences wine condition wine headed phrases white wine 
perform thresholding filter irrelevant words guidelines set justeson katz 
frequency threshold occurrences determine topicality discard pronouns noun phrases occur 
weighting term occurrences extracted terms evaluated arrive segmentation 
length single term noun phrase pronominal form distribution occurrences link related occurrences 
proximity metric relatedness 
occurrences term occur sentences link single unit repeat larger units built 
idea simpler interpretation notion lexical chains 
morris hirst proposed notion chain semantically related words thesaurus chose repetition stem word 
categories terms noticed linking distance differs depending type term question proper nouns having maximum allowable distance pronominal forms having 
proper nouns generally refer entity regardless number intervening sentences 
common nouns shorter scope single token repeatedly refer different instances class 
personal pronouns scope closely expected anaphoric referring expression referent def different active discourse 
term occurrences linked dropped consideration 
link length linking distance refers number sentences allowed intervene occurrences term 
assigning weights links established weighting assigned 
paragraph level boundaries considered previous step label paragraph positional relationship term link 
describe categories paragraph labeling illustrate 
front paragraph link begins 
paragraph link occurs front paragraph 
rear paragraph link just stopped occurring paragraph 
link remaining paragraphs 
paras sents wine ix type zt term wine occurrences type 
tried semantically cluster terms miller 
wordnet edge counting determine relatedness suggested hearst 
results showed minor improvement precision tenfold increase execution time 
shows algorithm developed far operating term wine 
term appears total times shown numbers central row 
occurrences grouped term links joined bottom type line labels paragraph paragraph relations 
see possible term multiple front rear paragraphs illustrated term occurrences separated disparate links 
categories paragraph labeling mentioned term types assign different segmentation score listed table values derived training discussed section 
term type paragraph type link respect term front rear link length proper np common np pronouns table overview weighting linking scheme segmenter star red scores 
noun phrases assume term point new topic may start youmans vocabulary management profile 
similarly term longer rear paragraphs topic may closed 
observation may direct vocabulary presumably strong marker topic change 
paragraphs link persists indicate topic continues see negative score assigned paragraphs 
apply paragraph labeling pronoun forms rationale applies modifications 
majority pronoun referents occur pronoun anaphoric opposed weigh front boundary heavily place emphasis rear 

zero sum normalization iterate weighting process described term total scores assigned come numerical score indication paragraphs beh topical boundary 
higher numerical score higher likelihood paragraph new topical segment 
question threshold 
paras sents wine ix type score sum balance zero sum weighting zero 
term wine links score assignment paragraphs 
solve problem zero sum weights individual term 
sum total scores assigned front rear paragraphs previously assigned score evenly distribute remaining link paragraphs negative sum 
ensures net sum weight assigned weighting term sums zero weighting entire article sums zero 
cases link paragraphs exist term perform zero summing take scores assigned small minority cases 
process weighting followed zero summing shown extending wine example indicated score zero lines 
respect individual paragraphs summed score results positive negative total 
positive score indicates boundary new topical segment negative score indicates continuation segment 
zero sum weighting problem finding threshold trivial data normalized value zero 
finding local maxima examination output indicated long medium length documents zero sum weighting yield results 
documents investigated documents short length words observed multiple consecutive paragraphs positive summed score single true boundary 
cases take maximal valued paragraph clusters positive valued paragraphs segment boundary 
sense paragraphs short length distribution words segmentation values paragraphs 
longer length documents expect phenomenon occur process skipped 
finding local maxima arrive finalized segment boundaries 
algorithm training come weights segmentation algorithm establish position criteria segment relevance calculations split corpus articles sets fold cross validation training intentionally keeping economist articles set check domain specificity 
training phase consisted running algorithm range different parameter settings determine optimal settings 
tried total group settings variables front rear weights linking length settings common nouns proper nouns pronoun forms term types 
results run compared standard user segmentation judgments discussed section 
results noted sizable group settings approximately produce close optimal results 
group settings identical cross validation training runs believe algorithm fairly robust safely conclude constructing extensive training testing corpus 
segment significance segments determined go 
illustrated segments utilized information retrieval automatic summarization applications treating segments individual documents 
approach loses information cohesiveness text unit 
searching framework processing segments sub documents independent entities 
enables ask parallel set general questions concerning segments differ segment contributes document 
portion deal instances questions decide text segment important 
decide type function segment serves 
questions related said define task finding segment significance 
show stage sequential approach attempts task context article 
assessing segment significance respect specific query quite different 
segment significance segmented calculate determine text segment importance segment function architecture segment importance labeled segments informally segment importance defined degree segment presents key information article 
method calculating metric section 
apply variant salton information retrieval metric term frequency inverse document frequency tf idf noun phrases tokens algorithm 
intuitively segment containing noun phrases segments document central text segment contains noun phrases segment 
call metric tf base importance sf segment frequency segments term occur segment distribution noun phrases document 
note exactly analogous idf compute inverse segment frequency isf looking segments noun phrases occur text segments characterized local noun phrases 
higher scores tf sf metric indicate central segment equate segment importance 
calculates tf sf score noun phrase term term occurrence information segment boundaries provided segmentation program 
segment importance derived merely summing term tf sf score track segments noun phrase occurs 
needed decide coverage noun phrase segment 
illustrate segment coverage example hypothetical segments 
assert terms segment equivalent show segment better coverage noun phrases taken appear segments noun phrase cover segments 
seg seg seg seg seg seg segment np coverage calculate coverage iterates occurrences terms segment increments score 
increment depends number terms previously seen fall segment 
series determine score occurrence term segment added segment coverage score second occurrence adds third forth 
normalize sum tf sf scores terms coverage score calculate segment importance segment 
segment importance current system sum numbers range important maximally important 
summarize algorithm calculating segment importance 
segment tf sf calculation tf sf sum tf sf np term tf sf max tf sf segments coverage calculations coverage sum coverage np term coverage coverage max coverage segments seg tf sf coverage segment importance segment functions contrasting segment importance examines prominence segment versus segment turn examine segment function looks role segment discourse structure 
currently classify segments types summary segments summary segment contains summary article 
assume segment functions overview article near article position segment document determining factors 
empirical study summary segments segments highest segment importance segments occur article 
addition importance rating highest segments 
anecdotal segments material draws reader main body article known field journalism anecdotal leads 
similarly closing remarks clever comments effect convey content 
attempts try detect segments restricted scope segments article 
empirical evidence suggests domain journalistic text single person introduced anecdotal segment relate interesting fact narrative 
person mentioned outside segment purpose relating limited scope segment 
accordingly looks proper noun phrase occurs candidate segment segments 
segment labeled anecdotal selected summary segment 
method worked remarkably data need address cases anecdotal material complex nature 
example anecdotal material woven texts documents 
support segments segments default segment type 
currently assign segment summary anecdotal segment deemed support segment 
related segment significance large body done assessing importance passages assignment discourse functions 
chen examine problem audio summarization domain speech instances emphasized speech determine demarcate important phrases 
similar terms demarcate segments nature problem different 
frequency terms text versus emphasized speech audio forces different approaches taken 
singhal salton examined determining paragraph connectedness vector space model similarity metrics approach may extend segment level 
considering problem angle discourse approaches focused shorter units multi paragraph segments rhetorical structure theory marcu may able scale associate rhetorical functions segments 
attempt bring fields solve problem segment importance function 
wsj economist total precision recall precision recall precision recall av avg avg avg avg avg monte carlo hypergeometric texttiling segmenter human judges table evaluation results precision recall scales evaluation interjudge agreement statistically significant observable 
segmentation evaluation segmentation algorithm web segmentation evaluation facility gather segmentation judgments 
articles corpus segmented human judges majority opinion segment boundaries computed evaluation standard klavans 
human judges achieved average agreement majority opinion seen table 
passonneau show surprisingly low agreement result evaluators divided regard segments localized prefer split large boundaries 
verified task defined testing strong correlation markings human judges 
test inter judge reliability cochran test discussed passonneau 
high correlation judges indicating modeling task feasible results showed chance average judges segment marks agreed chance 
calculated kappa correlation statistic corrects random chance agreement 
kappa values range showing complete negative correlation indicating complete positive correlation 
surprisingly calculations showed weak level nt judges avg 
calculations significance showed results generally significant level indicating computed segmenter performance completing fold cross validation test cases 
examining segmenter results show significant improvement initial algorithm hearst called texttiling precision recall 
step compare segmenting algorithm systems yaari okumura honda 
different baselines compare 
applied monte carlo simulation segments paragraph breaks probability 
executed baseline times article averaged scores 
informed baseline produced applying distribution calculates probability number successes sampling replacement 
example distribution gives expected number red balls drawn sample balls urn containing total balls red 
allow number segments apply segmentation pick segments paragraphs 
comparing results table see correct number segments difficult determine 
texttiling performance falls baseline average segmenter outperforms 
notice performance algorithm tex tiling quoted low comparison reports 
believe due weak level agreement judges training testing evaluation corpus 
wide range performance hints variation segmentation algorithms may experience faced different kinds input 

segment significance evaluation mentioned previously segments segment type assessments integrated key sentence extraction program klavans 
directed sentence extraction differs similar systems focus high recall processing retrieved sentences discard unimportant sentences clauses 
system location sentence summary segment input feature deciding key sentences standard features title words tf idf weights words sentence occurrences communication verbs 
task evaluation modules showed combining segmentation information yielded markedly better results 
instances segmentation able identify certain key sentences features failed find sentences 
improvement recall directly achieved adding segment significance output increasing system recall 
system built precision priority precision system dropped believe effects adding segmentation information valuable 
improvements current system categorized lines modules 
segmentation applying machine learning techniques beeferman learn weights high priority 
feel shared resources segmentation evaluation established aid comprehensive cross method study help alleviate problems significance small scale evaluations discussed klavans 
purposes evaluation constructed web software tool allows users annotate document segmentation markings 
propose initiating distributed cross evaluation text segmentation system component store share user automatic markings 
judging segment function plan perform direct assessment accuracy segment classification 
want expand ref definition types segment function include distinctions difference document segment borders reynar 
help situations input consists multiple articles continuous stream kanade 

shown multi paragraph text segmentation model discourse structure addressing dual problems computing topical text segments subsequently assessing significance 
demonstrated new algorithm performs linear topical segmentation efficient manner linguistic principles 
achieve increase accuracy recall levels prior hearst 
evaluation corpus exhibited weak level agreement judges believe correlates low level performance automatic segmentation programs compared earlier published works hearst 
additionally describe original method evaluate segment significance part metric combines measure segment generality statistical approaches classification segment function empirical observations 
evaluation metric established utility means extracting key sentences summarization 
authors slava katz insights insistence quality helped push part research forward 
indebted susan lee university california 
berkeley providing empirical validation segment significance key sentence extraction system 
due yaari bar university helping hunt additional segmentation corpora 

anonymous reviewers columbia natural language group members careful critiques led careful evaluation techniques 
supported barzilay elhadad 
lexical chains text summarization 
proceedings intelligent scaleable text summarization workshop acl madrid 
beeferman berger lafferty 
text segmentation exponential models 
proceedings second conference empirical methods natural language processing 
carletta 
assessing agreement classification tasks kappa statistic 
computational linguistics vol 
pp 
chen 
emphasis automatically summarize spoken discourse 
proceedings ieee int 
conference acoustics speech signal processing vol 
pp 

cochran 
comparison percentages matched samples 
vol 
pp 

macleod meyers 

comlex syntax building computational lexicon procedings th int conference computational linguistics coling 
hearst 
multi paragraph segmentation expository text proceedings nd annual meeting association computational linguistics 
hearst 
texttiling segmenting text multi paragraph subtopic passages computational linguistics voi pp 

justeson katz 
technical terminology linguistic properties algorithm identification text 
natural language engineering vol 
pp 

klavans mckeown kan lee 
resources evaluation summarization techniques 
proceedings st int conference language resources evaluation spain may 
kanade 
spot lt segmenting news videos topics 
proceedings digital library initiative project wide workshop carnegie mellon university pp 

kozima 
text segmentation similarity words 
proceedings th annual meeting association computational linguistics pp 

marcu 
rhetorical parsing natural language texts 
proceedings th annual meeting association computational linguistics pp 
miller beckwith fellbaum gross miller 
wordnet line lexical database 
journal lexicography vol 
pp 

morris hirst 
lexical coherence computed thesaural relations indicator structure text 
computational linguistics vol 
pp 
okumura honda 
word sense disambiguation text segmentation lexical cohesion 
procedings th int 
conference computational linguistics coling pp 

passonneau litman 
intention segmentation human reliability correlation linguistic cues 
proceeding st annual meeting association computation linguistics pp 

reynar 
automatic method finding topic boundaries proceedings nd annual meeting association computational linguistics student session las cruces new mexico 
salton 
automatic text processing transformation analysis retrieval information computer 
addison wesley reading massachusetts 
singhal salton 
automatic text browsing vector space model 
proceedings dual technologies applications conference pp 

yaari 
segmentation expository text hierarchical agglomerative clustering 
advances nlp bulgaria 
youmans 
new tool discourse analysis vocabulary management profile 
language vol 
pp 

