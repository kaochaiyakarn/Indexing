optimized query execution large search engines global page ordering large web search engines answer thousands queries second interactive response times 
major factor cost executing query lengths inverted lists query terms increase size document collection range megabytes 
address issue ir database researchers proposed pruning techniques compute approximate term ranking functions scanning full inverted lists 
years search engines incorporated new types ranking techniques exploit aspects hyperlink structure web popularity page obtain improved results 
focus question techniques efficiently integrated query processing 
particular study pruning techniques query execution large engines case global ranking pages provided pagerank method addition standard term approach 
describe pruning schemes case evaluate efficiency experimental search engine web pages 
results show significant potential benefit techniques 
decade web grown size pages 
due supported nsf career award nsf ccr new york state center advanced technology telecommunications polytechnic university equipment sun microsystems intel 
permission copy fee part material granted provided copies distributed direct commercial advantage vldb copyright notice title publication date appear notice copying permission large data base endowment 
copy republish requires fee special permission endowment 
proceedings th vldb conference berlin germany long torsten suel cis department polytechnic university brooklyn ny suel poly edu cis poly edu explosion size users increasingly depend web search engines locating relevant information 
large number web pages topics interest main challenges search engine provide ranking function identify useful results relevant pages 
major search engines need answer thousands queries second collections pages 
search engines require significant computing resources typically provided large clusters hundreds thousands servers scale just number queries amount data needs analyzed query order provide answer 
better understand challenge look basic structure current search engines 
engines information retrieval tools inverted index index structure allows efficient retrieval documents containing particular word term 
inverted index consists inverted lists inverted list contains ids documents collection contain particular word sorted document id measure plus additional information number occurrences document exact positions occurrences context title anchor text 
simplest class queries implemented inverted index boolean queries 
query apple orange pear documents containing apple orange word pear implemented intersecting list document ids inverted lists apple orange merging result inverted list pear 
course state art search engines limited boolean queries problems boolean queries provide ranking results problem result size common queries may millions documents 
problem overcome applying ranking function assigns numeric score document query term techniques cosine measure hyperlink analysis traffic data 
size document collection increases inverted lists common words long 
inverted list smaller entire document collection terabyte page collection indexed large engine results lists sizes range multiple megabytes may traversed query 
general doubling collection size results doubling amount data scanned query 
second problem typically stays go boolean classes ranked queries 
particular engines perform ranking applying ranking function result boolean keywords 
restriction low average number keywords query web search queries efficient types queries traditional ir systems amount data scanned disk huge scales linearly size collection 
problem motivated number pruning techniques attempt compute approximate certain classes ranking functions scanning entire inverted lists search terms typically inverted lists promising documents near 
focused term ranking functions 
current search engines rely heavily hyperlink analysis traffic data user feedback ranking addition term techniques 
large amount research link ranking techniques little published efficiently integrate link traffic techniques query processing engines realistic size 
attempt take step closing gap 
particular interested optimizing query performance measured query throughput latency large web search engine term link ranking appropriate pruning techniques scale collection size 
describe techniques perform initial experimental evaluation research prototype engine pages built group 
section gives technical background 
section describes contributions section discusses related 
proposed techniques described section experimental results section 
preliminaries section provide background ranking search engines 
assume document collection web pages crawled available disk 
different words occur collection 
typically text string appears separating symbols spaces commas interpreted valid potential word 
indexes inverted index collection consists set inverted lists list contains posting occurrence word posting contains id document word occurs byte approximate position document possibly information context title large bold font anchor text word occurs 
postings inverted list sorted document ids enables compression list measure described 
boolean queries implemented unions intersections lists phrase searches new york answered looking positions words 
refer details :10.1.1.51.7802
term ranking common way perform ranking ir systems comparing words terms contained document query 
precisely documents modeled unordered sets words ranking function assigns score document respect current query frequency query word page higher score multiple occurrences collection rare words significant length document long documents advantage context occurrence higher score word occurs title bold face 
formally ranking function function query consisting set search terms assigns document score system returns documents highest score 
different functions proposed techniques limited particular ranking function long certain conditions met described 
experiments version cosine measure defined frequency term document entire collection respectively :10.1.1.51.7802
compute top documents suffices assign score docu ments contain query word union inverted lists 
note general suffice score documents intersection document containing query words multiple times title may score higher longer document containing query words 
large search engines default semantic due reasons involving user expectations collection size preponderance short queries 
focus case 
authors proposed techniques identify guess top documents scoring documents lists see overview older :10.1.1.112.869:10.1.1.55.2172:10.1.1.18.3272
typically techniques reorder inverted lists documents terminate search inverted lists high scoring documents scored 
link ranking techniques current major engines perform ranking solely term techniques 
general ranking performed combination term link techniques plus factors user feedback line preprocessing spam identification cluster analysis 
large amount research focused ranking techniques techniques hyperlink graph structure web identify interesting pages relationships pages 
important technique pagerank technique underlying google search engine assigns global importance measure page web proportional number importance pages linking :10.1.1.109.4049
number approaches proposed see perform link ranking query time preprocessing step :10.1.1.120.3875:10.1.1.167.4587:10.1.1.12.1400:10.1.1.21.6917
integrating term factors despite large amount link ranking published efficiently integrate techniques large search engine 
particularly interested pagerank techniques precompute global ranking function documents independent query query time combined term results 
argued query dependent link analysis give better results global techniques pagerank allow precomputation attractive reasons efficiency simplicity 
brin page possible advantages architecture original google engine contains essentially simple term pruning technique idea fancy hits :10.1.1.109.4049
natural way build combined ranking function add term score suitably normalized score derived pagerank 
approach suggested follow experiments 
formally consider ranking functions forms fact discussed logarithm value returned pagerank computation raw value input function 
adding terms perform query dependent normalization assigns approximately weight term link contribution derived mean highest term link values inverted list 
note search engines score may depend distance query words document words occurring close getting higher score 
formally adds third term purpose choosing maximum value mean highest discount effect outliers 
value chosen larger value due larger data set 
depends query terms 
deal ing case open problem research 
search engine architecture answering thousands queries second terabyte collection requires equivalent small supercomputer current major engines large clusters servers connected high speed lans sans 
basic ways partition inverted index structure nodes local index organization node builds complete index subset documents altavista inktomi global index organization node contains complete inverted lists subset words 
scheme advantages disadvantages space discuss see 
assume local index organization ideas apply global index 
number machines case containing index subset documents 
machine acts query integrator receives queries users broadcasts merges returned results proper ranking sent back user see details :10.1.1.122.203
way top answer query top ask results machine 
documents randomly assigned machines may top return results order determine global top relevant pruning techniques efficient small values fact proposed methods implemented incremental fashion machine returns top top top results soon discovered computation query integrator ask top results request additional values obtain top top nodes needed 
contributions study optimized query processing search engines locally partitioned inverted index ranking function combines term techniques global page ordering obtained link analysis user feedback offline preprocessing 
particular describe pruning techniques significantly improve query throughput response times large document collections 
perform preliminary experimental evaluation search engine prototype nodes web pages built research group real query trace excite search engine 
experiments show limits benefits proposed techniques terms query throughput response time varying levels concurrency 
addition hybrid schemes replication conjunction partitioning better performance 
significance believe interesting angles 
query processing efficiency important issue large search engines addressed published literature 
increasing efficiency say factor allows major engine run hundreds thousands fewer machines 
significant differences query execution efficiency major engines different proprietary index organizations query execution schemes 
problem scaling collection size load important context intranet enterprise search larger organizations multinational companies federal agencies query load smaller significant requiring small cluster machines 
note pruning schemes ones propose particularly attractive peak times query load significantly larger average adapt load continuous online fashion 
appears search engines techniques dealing high loads modifying query execution details published 
second believe results interesting context ongoing discussion different approaches link analysis particular issues vs online techniques global vs topic specific vs query specific techniques :10.1.1.120.3875:10.1.1.167.4587:10.1.1.31.1768:10.1.1.12.1400
results indicate global precomputed ordering highly desirable performance point view allows optimized index layout pruning 
clear query specific online approaches really superior terms results methods possibly efficiently implemented corrective measures top strong global ordering pagerank index layout pruning 
limitations loose ends number important issues address left 
firstly focus query throughput response time experiments try bypass issue result quality course important 
fixing particular ranking function combines cosine measure pagerank method believe reasonable approach ranking :10.1.1.109.4049
attempt compute approximate function efficient manner 
techniques assume particular ranking function savings obtained experimental evaluation clearly depend choice function 
function weighs score higher link score approach give little benefit standard ap cases intranet collection sizes may larger tb size google collection 
note issue really limited link techniques includes approaches user feedback offline text analysis arrive global ordering 
proach 
appears google toolbar link scores significant impact ranking 
intend investigate savings obtained pruning finely tuned ranking function involving factors term context title font size anchor text search engine prototype 
hand plan evaluate techniques trec web data set order explore trade efficiency result quality terms precision recall 
problems research impact distances terms document topic specific link analysis techniques :10.1.1.12.1400
addition loose ends experimental evaluation plan resolve 
includes experiments keywords results deterministic pruning incremental query integrator effects significantly increasing collection size single node analysis impact query characteristics number terms selectivity correlation 
intend include results longer journal version 
discussion related background indexing query execution ir search engines refer basics parallel search engine architecture refer :10.1.1.109.4049:10.1.1.51.7802
discussions comparisons local global index partitioning schemes performance 
large amount focused link ranking analysis schemes see small sample 
previous pruning techniques top queries divided fairly disjoint sets literature 
ir community researcher studied pruning techniques fast evaluation vector space queries 
early described 
relevant techniques persin zobel sacks davis follow study effective early termination pruning schemes cosine measure idea sorting postings inverted lists contribution score document :10.1.1.18.3272
scheme proposed partition inverted list partitions somewhat reminiscent scheme subsection purpose achieving compression index integrate global page ordering :10.1.1.18.3272
lot top queries database community see survey formal analysis schemes :10.1.1.112.869
originally motivated queries multimedia databases retrieve images 
stated ir terms algorithms assume postings inverted lists sorted contributions accessed sorted order 
algorithms proposed assume document encountered inverted lists efficiently compute complete score performing lookups inverted lists 
gives better pruning sorted access search engine context may efficient results random lookups disk 
schemes random lookups cases lists sorted :10.1.1.112.869
variety previous pruning schemes objectives assumptions different 
example ir focused queries large numbers terms query concerned main mem ory consumption cpu resources evaluating cosine measure :10.1.1.18.3272
assumes random lookups feasible 
schemes precise compute approximate top results precomputation reduce lengths stored inverted lists 
note previous performs ranking union intersection inverted lists 
results increased cpu evaluating cosine measure schemes store precomputed floating point scores part inverted lists 
hand union help pruning schemes allowing lower bound total score document seen lists assuming score zero 
approach uses ideas schemes aware previous considering integration global page ordering pagerank pruning methods 
original google architecture brin page discuss optimization called fancy hits stores term occurrences special contexts title bold face anchortext separate smaller structure quickly scanned documents :10.1.1.109.4049
special contexts modeled vector space model increasing weights appropriately approach closely related described subsection 
note give detail fancy hits know types pruning schemes current google engine :10.1.1.109.4049
knowledge major engines scan entire inverted lists queries 
exception aware previous large scale study query throughput large engines web query loads 
pruning techniques describe different pruning techniques study 
recall global ordering web pages associated global score page 
experiments pagerank ordering pages numbered important important real valued scores produced iterative computation 
global ordering 
simplicity situation may different highly distributed environments limited bandwidth 
describe techniques case query terms 
subtle issue utilize output pagerank computation 
initially tried raw pagerank score 
distribution values extremely skewed different values contain logarithms part cosine measure 
distribution logarithm pagerank value closer term values shown 
decided logarithm input normalization procedure refers logarithm raw value 
note pagerank scores returned google toolbar conjectured logarithmic nature 
base logarithm matter due subsequent normalization give higher relative importance term global scores modifying normalization 
distributions raw pagerank log pagerank term scores subset collection left right 
values factor highest score inverted list pagerank scores skewed 
cosine measure defined section threshold limit term document length normalization define total score document respect query mean highest pagerank values documents inverted list term mean highest term cosine values choose experiments global mean values entire collection machines requires additional precomputation allows simple merging results query integrator 
note way pagerank score preprocessed normalized course impact performance 
particular raw pagerank score logarithm perform normalization mean top pagerank impact result queries significant pruning pagerank possible 
queries document significant normalized pagerank containing keywords due extreme skew values 
contradict observation pagerank displayed google toolbar strong influence query results 
normalize average values top results decided primarily pagerank queries heuristic get great performance benefits loss precision 
logarithm raw pagerank value terms important ranking query results 
naive pruning heuristic heuristic assume inverted lists sorted descending order pagerank scores documents easily achieved global rank document id indexing 
pruning heuristic called simply scans inverted lists finds pages contain query terms 
indexes sorted pagerank pages highest pagerank contain query terms 
scoring pages top returned 
technique may provide best way approximate ranking function interested reasons 
case nique considered reasonable upper bound efficiency gain obtained pruning cost essentially identifying pages lists 
second case tech moderate multiple technique seen reasonable baseline start 
note sorting pagerank leaving term values completely unsorted sort list term value leave pageranks unsorted 
approach similar earlier approaches purely term ranking perform ranking function 
require additional data structures matching postings different lists slow computation 
separating large term values approach motivated fancy hits approach brin page persin :10.1.1.109.4049:10.1.1.18.3272
discussed previous pruning techniques queries sort postings list contribution final score 
case combining term link scores equation natural approach sort postings list combination term scores 
example queries terms strict upper bound query terms correlated 
sort list term value plus half pagerank contribution adding values lists get complete document score 
intuitively introduce strong correlation lists encounter documents early lists 
problems simple idea 
formulation depends number terms query 
things complicated normalization equation clear combination term link scores sort cleanly separate contributions due different terms 
second postings ordered document id need additional data structures match postings different lists list compression effective 
decided go simpler scheme partitions list parts term value 
precisely short list containing postings list highest term value cosine measure longer list containing postings 
short list called fancy list inspired contains postings lists sorted pagerank :10.1.1.109.4049
intuition document scoring high fancy lists close longer lists 
utilize structure subsequent heuristics 
better pruning heuristic heuristic called fancy extension new structure 
process fancy lists 
documents occurring lists compute complete score keep top results 
maintain structures documents occur second fancy list respectively 
simultaneously scan longer lists 
find document occurring longer lists document longer list occurred fancy list evaluate score con sider inclusion top results 
terminate encountering documents intersection 
reliable pruning technique fancy approach previous section heuristic guarantee correct top results 
describe technique fancy lists stops safely determine obtained top results 
periodically perform check traversing longer lists processing fancy lists described 
pagerank score document encountered longer lists note subsequent documents lower pagerank 
largest term values longer lists respectively 
postings larger term values located fancy lists 
note current th largest total score values purge documents top decide documents encountered top test fails empty return top current results 
note similar scheme applied postings sorted pagerank subsection 
observed negligible performance gains top queries decided investigate variant 
probabilistic pruning techniques studied unreliable techniques take similar perspective reliable pruning technique 
particular scan longer list maintain sets candidate documents encountered fancy lists top appear list sufficient term score 
scanning small portion longer lists pageranks encountered usually small document top anymore 
point assign document probability total score larger current value basic assumptions underlying document collection particular independence pagerank term values upper bound correlation terms 
simple statistics distribution term values list document encountered estimate unknown value larger difference known part document score 
procedure terminates probability having top correct results goes threshold say note statistics kept form histogram zipf parameter inverted list value distribution correlations estimated hashing techniques similar 
fancy list organization implemented crude version idea terminate scan number candidates drops fixed threshold refer technique number remaining candidates 
full implementation technique left 
note cases useful perform limited number random accesses resolve remaining candidates 
techniques principle applicable index organization subsection 
fact implemented general technique assuming term independence simple histogram upperbound term distributions basic index organization 
benefits case extremely limited 
experimental results experimental evaluation different approaches 
describe machine setup data sets preprocessing steps 
subsection contains results exhaustive baseline method pruning technique subsection 
subsection gives results fancy scheme 
subsection evaluates reliable pruning techniques fancy list organization 
subsection summarizes results techniques 
results point single node search engine 
subsection gives results node search engine architecture query integrator frontend 
due space constraints include small sample main results 
experimental setup hardware experiments set dell gx machines ghz pentium gb memory gb seagate st hard disks connected switched fast ethernet 
node disk index structure 
software data sets experiments run search engine prototype named currently developed research group 
document collection consisted web pages crawled web crawler october 
pages distinct set contains significant number duplicates due pages repeatedly downloaded crawl interruptions 
crawl started homepages universities performed breadth manner 
observed crawl quickly find pages significant pagerank value 
total uncompressed size data tb 
efficient implementation pagerank compute global ranks scores 
data set distributed nodes fairly random fashion node receiving pages gb uncompressed data 
indexing took hours disk resulting inverted lists sorted pagerank stored berkeley db highly compressed form compression macros available part system :10.1.1.51.7802
queries terms taken trace queries issued excite search engine december 
experiments removed queries stopwords approach relatively better queries frequent words 
fancy lists implemented separate berkeley db database 
note delete postings included fancy lists longer lists basic index 
allowed experiment different sizes fancy lists having rebuild basic index consequence basic index slightly larger needed 
stored position information post subject interval accesses server may cause reordering strict breadth 
ings needed simple ranking functions consider 
removing postings improved compression macros increase query throughput 
confident index query execution implementations fairly optimized high performance 
evaluation methodology compare performance various techniques single node search engine 
show selected results machines query integrator 
cost technique usually stated terms average number kb blocks scanned query investigate translates query throughput latency achieved various degrees concurrency 
quality techniques measured relative ranking function approximating reliable pruning technique zero error 
con sider measures 
error measure means technique consider returns exactly top results ranking function queries 
error loose measure means documents returned top belong top typically report results strict note cases small interest parallel search engine need correct top node determine global top particular retrieving top results nodes suffices reliably determine global top probability assuming random allocation documents nodes 
performance baseline set experiments compared approaches baseline pruning compute top results scanning complete inverted lists inverted lists differ significantly size case binary search approach kicks automatically 
return top results documents intersection figures show throughput average latency achieved various levels concurrency number queries allowed executed concurrently node 
expected throughput improves degree concurrency average latency soon starts increase significantly cpu shared active queries 
note case queries cosine measure essentially computational overhead simple list intersection plot cost intersection cosine evaluation identical 
see methods achieve significantly higher throughput lower latency baseline method 
obtain throughput queries second half second latency concurrency level baseline method top table average number kb block accesses node query 
limited queries second 
throughput increases latency decreases optimum degree concurrency increases expected smaller disk accesses 
number queries second average latency query top degree concurrency query throughput second 
top degree concurrency average latency query 
decrease values smaller limited additional benefit 
blocks inverted list retrieved shown table implying disk time dominated seek times 
note baseline method scans mb compressed postings data mb uncompressed data query sin gle node documents 
figures show heuristic performs identifying top correct results 
example returns correct top document top queries correctly identifies results top queries 
hand results returned really belong 
results drop results best mixed 
get great performance benefits come significant error rate 
hope error rate significantly reduced move fancy list organization 
error rate error rate respectively 
top error rate loose different top error rate strict different performance fancy schemes look fancy scheme 
shows number blocks scanned query various values sizes fancy list 
see cost increases moderately length fancy lists primarily due extra cost scanning lists 
consider caching effects simply count number blocks accessed program berkeley db automatically takes care caching 
shown figures fancy schemes achieve significantly lower error rates blocks blocks pruning length fancy list average cost query fancy schemes length fancy lists varied postings 
plot results case choose fancy lists list length points located axis average list length relative 
cost plotted ratio number blocks accessed fancy baseline scheme 
schemes 
particular fancy list length fancy obtains correct top results queries 
note fancy obtained correct top result queries query set fancy lists length point plotted 
see choosing lengths fancy lists percentage total list length leads better error bounds compared fixed length organization cost 
error rate top top top top top top top top top length fancy list error rate loose measure different values different lengths fancy lists 
reliable pruning look cost reliable pruning technique different fancy list lengths shown 
note length determine top results cost baseline method zero error rate top top top top top top top top top length fancy list error rate strict measure different values different lengths fancy lists 
error method reliable 
blocks dp blocks pruning top top top length fancy list ratio number blocks accessed reliable pruning baseline scheme different different lengths fancy lists 
ran experiments scheme due space limitations include detailed plots 
cases inferior fancy schemes terms cost error tradeoff shown summary plot 
comparison various methods gives comparison various methods case top queries 
identify clusters results axis reliable pruning technique outperforms fancy schemes located right 
left reliable scheme clusters fancy fancy lower cost higher error reliable pruning 
right schemes strictly worse 
top schemes marginally faster fancy higher error 
fact say fancy outperform cost error 
best schemes appear reliable pruning fancy moderate values comparison various pruning techniques 
technique parameter setting plotted point showing cost disk blocks axis loose error axis 
shown clusters points corresponding different basic methods 
point identified technique fancy length fancy lists 
performance machines look performance best schemes run queries entire set pages partitioned machines query integrator separate machine merges results 
particular plot results baseline scheme reliable pruning fancy list length fancy fancy list length fancy fancy list length results top queries 
concurrency level case total number queries allowed active query integrator time 
number queries second pruning rp fancy fancy fancy degree concurrency query throughput second machines 
average latency query seconds pruning rp fancy fancy fancy degree concurrency query latency seconds machines 
note reliable pruning query integrator asks number results nodes query minimum allowed query integrator determine top number precomputed query ease experimentation 
unrealistic shortcut reliable pruning scheme implemented incremental manner query integrator ask top results receiving top results extra overhead 
fact reliable pruning technique improved query integrator asks minimum number results needed particular node 
shown figures throughput limited queries second baseline method 
reliable pruning get throughput queries second latency second concurrency level aggressive method fancy achieve queries second concurrency level error rate fancy strict fancy loose fancy strict fancy loose top errors fancy machines 
looking error rate fancy schemes get pleasant surprise 
fancy scheme obtain exactly top correct results queries error rate lower fancy 
due prior observation usually need correct top top node determine global top correctly 
finish remarks scaling problem size obtained conclusive results 
ran experiments techniques single node collection sizes pages 
observed significant changes error rate increase query cost 
partly due fact chose lengths fancy lists fixed percentage list lengths better decrease percentage collection size grows 
search engines particularly interested question total index size issue better build complete index entire collection node subset nodes forward query node subset partition index broadcast nodes 
answer open pruning techniques hope resolve measuring throughput latency significantly larger indexes 
zhang help simulation results yen yu chen providing pagerank values 
anh moffat 
vector space ranking effective early termination 
proc 
th annual sigir conf 
research development information retrieval pages september 
anh moffat 
compressed inverted files reduced decoding overheads 
proc 
st annual sigir conf 
research development information retrieval pages 
arasu cho garcia molina raghavan 
searching web 
acm transactions internet technologies june 
baeza yates ribeiro neto ziviani 
distributed query processing partitioned inverted files 
proc 
th string processing information retrieval symposium spire september 
baeza yates ribeiro neto 
modern information retrieval 
wesley 
borodin roberts rosenthal 
finding authorities hubs link structures world wide web 
th int 
world wide web conference 
brewer 
lessons giant scale services 
ieee internet computing pages august 
brin page :10.1.1.109.4049
anatomy large scale hypertextual web search engine 
proc 
seventh world wide web conference 
broder 
resemblance containment documents 
compression complexity sequences se quences pages 
bruno gravano marian 
evaluating top queries web accessible databases 
proc 
th annual int 
conf 
data engineering 
buckley 
optimization inverted vector searches 
proc 
th annual sigir conf 
research development information retrieval pages 
mckinley lu 
evaluating performance distributed architectures information retrieval variety workloads 
ieee transactions information systems january 
chakrabarti dom gibson kleinberg raghavan rajagopalan 
automatic resource list compilation analyzing hyperlink structure associated text 
proc 
th int 
world wide web conference may 
chaudhuri gravano 
optimizing queries multimedia repositories 
data engineering bulletin 
fagin 
combining fuzzy information multiple systems 
proc 
acm symp 
principles database systems 
fagin 
combining fuzzy information overview 
sig mod record june 
fagin carmel cohen maarek 
static index pruning information retrieval systems 
proc 
th annual si gir conf 
research development information retrieval pages september 
fagin lotem naor 
optimal aggregation algorithms middleware 
proc 
acm symp 
principles database systems 
balke 
optimizing queries image databases 
proc 
th int 
conf 
large data base pages 
balke 
efficient multi feature queries heterogeneous environments 
proc 
ieee int 
conf 
information technology coding computing april 
harman candela 
retrieving records gigabyte text statistical ranking 
journal american society information science august 
haveliwala 
topic sensitive pagerank 
proc 
th int 
world wide web conference may 
jeong omiecinski 
inverted file partitioning schemes multiple disk systems 
ieee transactions parallel distributed systems 
kleinberg 
authoritative sources hyperlinked environment 
proc 
th acm siam symposium discrete algorithms pages january 
lempel moran 
stochastic approach link structure analysis salsa tkc effect 
proc 
th int 
world wide web conference may 
lempel moran 
optimizing result prefetching web search engines segmented indices 
proc 
th int 
conf 
large data bases august 
lu 
scalable distributed architectures information retrieval 
phd thesis univ massachusetts may 
melnik raghavan yang garcia molina 
building distributed full text index web 
proc 
th int 
world wide web conference may 
najork wiener 
breadth search crawling yields high quality pages 
th int 
world wide web conference 
ramakrishna 
query processing issues image multimedia databases 
proc 
th annual int 
conf 
data engineering pages march 
page brin motwani winograd 
pagerank citation ranking bringing order web 
technical report stanford university 
persin zobel sacks davis :10.1.1.18.3272
filtered document retrieval frequency sorted indexes 
journal american society information science may 
richardson domingos 
intelligent surfer probabilistic combination link content information pagerank 
advances neural information processing systems 

search engines web dynamics 
computer networks 
shkapenyuk suel 
design implementation high performance distributed web crawler 
proc 
int 
conf 
data engineering february 
suel mathur wu zhang long shanmugasundaram 
peer peer architecture scalable web search information retrieval 
international workshop web databases webdb june 
tomasic garcia molina 
performance inverted indices distributed text document retrieval systems 
proc 
nd int 
conf 
parallel distributed information systems pdis 
turtle flood 
query evaluation strategies optimizations 
information processing management november 
wimmers haas roth 
fagin algorithm merging ranked results multimedia middleware 
fourth ifcis int 
conf 
cooperative information systems pages september 
witten moffat bell :10.1.1.51.7802
managing gigabytes compressing indexing documents images 
morgan kaufmann second edition 
wong lee 
implementations partial document ranking inverted files 
information processing management september 
