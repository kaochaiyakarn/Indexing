design parallel distributed web search engine orlando dipartimento di informatica universita ca venezia italy istituto cnuce cnr pisa italy dipartimento di informatica universita di pisa italy describes architecture mose search engine scalable parallel distributed engine searching web 
mose speci cally designed eciently exploit parallel architectures clusters workstations 
modular scalable architecture easily adjusted ful ll bandwidth requirements application hand 
task parallel data parallel approaches exploited mose order increase throughput eciently communication storing computational resources 
collection html documents benchmark conducted preliminary experiments cluster smp linux pcs 
due explosion number documents available online today web search engines main means initiating navigation interaction internet 
largest index today hundreds millions multi lingual web pages containing millions distinct terms 
bigger necessarily better people looking web unusual usual information prefer search engines largest web coverage 
forced main commercial compete increasing indexes 
cost indexing searching grows size data ecient algorithms scalable architectures exploited order manage enormous amount information high throughputs 
parallel processing enabling technology eciently searching retrieving information web 
mose parallel distributed able achieve high throughput eciently exploiting low cost cluster linux smps 
architecture allows system scaled size data collection throughput requirements 
orts directed increasing query processing throughput 
think system inputs output 
input stream queries submitted users 
input read database contains index document collection 
process query stream retrieving index mose submitted july relevant documents 
set put output stream 
main parallelization strategies task parallel 
various queries processed independently consider query processing embarrassingly parallel problem 
exploit processor farm structure mechanism balance load scheduling queries set identical workers implementing sequential 
data parallel 
input database partitioned 
query processed parallel data parallel tasks accessing distinct partition database 
query processing case slightly heavier previous case 
data parallel task fact retrieve partition locally relevant 
nal output obtained combining partial outputs choosing globally result relevant 
task data parallel 
combination strategies 
processor farm workers turn parallelized data parallel approach 
farming structure balance parallel workers 
modular architecture mose allowed experiment strategies 
third parallelization strategy combines task data parallelism achieved best performances due better exploitation memory hierarchies 
organized follow 
section introduces information retrieval ir principles surveys related 
section describes mose components discusses parallelism exploitation shows mose modular scalable architecture adjusted ful ll bandwidth requirements 
encouraging experimental results obtained cluster linux smps shown section section draws 
ir principles typical see composed spidering system set internet agents parallel visit web gather documents interest ir core constituted indexer builds index collection gathered documents query analyzer accepts user queries searches index documents matching query return documents understandable mose submitted july spider indexer query analyzer web collect 
index web 
typical organization 
form 
query results returned users sorted rank kind relevance judgment concept largely linked users taste 
ranking performed basis ir model allows represent documents queries measure similarity 
general size indexed collection grows high precision number relevant documents retrieved total number documents retrieved preferred expense recall parameter number relevant documents retrieved total number relevant documents collection words users usually look rst tens results relevance top results important total number relevant documents retrieved 
order high precision computational eciency usually adopt simple weighted boolean ir model enriched highly ective ranking algorithms consider hyper textual structure web documents due compactness adopt inverted list il organization index 
il stores relations term documents contain 
main components il index lexicon lexicographically ordered list interesting terms contained collection postings lists lists associated term lexicon containing documents contain large scale google inktomi fast exploit clusters low cost workstation running engines unfortunately papers regard architecture design developments done competitive companies publish technical details 
hand researchers investigated parallel distributed ir systems focused collections homogeneous documents 
lin zhou implemented distributed ir system cluster workstations lu simulated interesting distributed ir system terabyte collection investigated various distribution replication strategies impact retrieval eciency ectiveness 
mose submitted july 
subcollection index subcollection index subcollections indexing indexer indexer index index docs docs spiders 
indexing phase 
mose structure ir core mose composed indexer query analyzer qa modules 
brie surveys indexing issues focus attention qa functionalities carried pools parallel processes query brokers local searchers lss 
mose parallel distributed implementation exploits data parallel technique known document partitioning spidering phase returns subcollections documents similar sizes 
subcollections indexed independently concurrently parallel indexers see 
result indexing phase set di erent indexes containing disjoint sets documents 
indexes taken charge data parallel qa task resolve user queries collection 
qa uses lss 
run front workstation fetch user queries shared message queue 
fetched query broadcast associated lss workers possibly running di erent workstations 
lss satisfy query distinct return qb submitted query rst relevant documents contained subcollection 
qb waits 
results chooses documents highest ranks 
results returned requesting user 
shows logic structure mose architecture 
qb associated lss implements data parallel worker concurrently serve user queries 
order manage concurrently queries better exploit lss bandwidth introduced qa 
system performances furthermore increased replicating qa copies 
parallelization strategies depicted section realized choosing appropriate values pure task parallel approach mose submitted july qb qb qb ls ls ls qb qb qb ls ls ls qa qa 
structure mose query analyzer 
corresponds 
choosing obtain pure data parallel implementation 
hybrid task data parallel strategy nally obtained 
indexer 
indexer purpose building index gathered web documents 
indexing algorithm parallel version sort algorithm ecient large collections due compromise memory usage index built full text word 
lexicon compressed exploiting common pre xes lexicographically ordered terms shared pre coding postings lists compressed local bernoulli technique mose parallel indexer exploits master worker paradigm standard unix communication mechanisms message queues 
subcollection web documents indexed independently concurrently di erent workstations current indexer implementation exploits parallelism smp architecture 
master process scans subcollection sends document le set unique document identi er worker processes self scheduling basis 
workers independently read assigned document disk indexes 
documents processed workers write local indexes disk signal completion master 
point master merges local order create single index subcollection 
distributed implementation indexer easily derived require processing nodes eciently access disk resident subcollection single node access merging phase 
query broker 
qb loops performing actions receipt broadcasting queries 
independently mechanism submitted july accept user queries cgi fast cgi php asp user queries inserted message queue shared 
load balancing accomplished means self scheduling policy free access shared queue get rst available query 
query fetched qb broadcasts lss means mpi asynchronous communication 
receipt merge results 
qb nondeterministically receives results lss lists ordered rank pairs document identi er associated rank value nal list results highest ranks obtained simple merging algorithm 
answers returning 
list results nally returned cgi script originating query transforms document identi ers urls short associated builds dynamic html page returned requesting user 
local searcher 
lss implement ir engine mose 
query received ls parses searches lexicon terms query 
performance term searching important system fully optimized 
ecient binary search algorithm purpose shared pre coding technique code variable length terms lexicographically ordered lexicon wasting space minimizing size lexicon important small lexicon maintained core obvious repercussions searching times 
ls exploit unix mmap function map lexicon memory 
function allows ls share lexicon ls run workstation process subcollection 
term query lexicon associated posting list retrieved disk decompressed written stack 
ls processes bottomup query boolean operators operands available top stack 
boolean operators processed top stack stores nal list results 
results highest ranks selected linear time exploiting max heap data structure results communicated qb submitted query 
experimental results conducted experiments cluster smp linux pcs interconnected switched fast ethernet network 
pc equipped mhz processors mbytes ram ultra scsi ii disk 
indexed multi lingual html documents contained cds web track trec conference built monolithic mose submitted july number task parallel vs wss ls queries ws wss time microseconds number lss task parallel vs hybrid ls queries tp tp dp 
results experiments conducted 
index partitioned 
monolithic index contains distinct terms size gbytes gbytes compression partitions partitioned index occupy gbytes 
queries testing come actual query log le provided italian web search experimented task parallel tp hybrid tp dp con gurations mose 
mapped single workstation lss placed machines 
independently con guration index partitions introduced 
reports average elapsed times inverse throughput required process queries tp case function number exploited 
curves plotted refer cases lss mapped smp machines 
see placed smp machines showing ecacy sharing mechanisms 
hand increase number di erence exploiting machines increases 
observe useful employ available processors 
compares tp solution hybrid tp dp 
testing conditions experiment 
case hybrid con guration lss associated partition index placed workstation order allow lss share lexicon data structure 
better performance hybrid approach evident 
superlinear speedups obtained tp dp tests 
mose submitted july derive exploitation memory hierarchies particular bu er cache virtualize accesses disk resident posting lists 
parallel distributed architecture mose discussed designed order eciently exploit low cost clusters workstations 
reported results preliminary experiments conducted smp workstations 
results highlighted greater performances resulting exploiting hybrid task data parallelization strategy pure task parallel 
lot important issues plan investigate near 
important performing accurate testing mose larger clusters document collections order analyze greater detail scalability di erent parallelization strategies 
fastest interconnection network myrinet tested 
interested study query locality ectiveness caching results supervised document partitioning strategies aimed reducing number index partitions needed satisfy query 

brin page 
anatomy large scale hypertextual web search engine 
www computer networks vol 
pages april 

witten mo bell 
managing gigabytes compressing indexing documents images 
morgan kaufmann publishers 

fast search transfer asa 
fast search server white 
technical report fast search transfer asa december 

macleod martin nordin phillips 
strategies building distributed information retrieval systems 
information processing management 

martin macleod russell foster 
case study caching strategies distributed full text retrieval system 
information processing management 

burkowski 
retrieval distributed text database utilizing parallel process document server 
proc 
intern 
symp 
databases parallel distributed systems ireland july 

lin zhou 
parallelizing intensive applications workstation cluster case study 
computer architecture news december 

lu 
scalable distributed architectures information retrieval 
phd thesis university massachussets amherst 

mckinley lu 
evaluating performance distributed architectures information retrieval variety workload 
ieee transactions information systems 
mose submitted july 
