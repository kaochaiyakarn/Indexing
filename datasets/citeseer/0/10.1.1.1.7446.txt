ieee transactions pattern analysis machine intelligence published automatic analysis multimodal group actions meetings iain member ieee daniel perez member ieee bengio member ieee guillaume student member ieee mark barnard student member ieee dong zhang 
bengio barnard zhang idiap ch investigates recognition group actions meetings 
framework employed group actions result interactions individual participants 
group actions modelled different hmm approaches observations provided set audio visual features monitoring actions individuals 
experiments demonstrate importance interactions account modelling group actions 
shown visual modality contains useful information predominantly audio events motivating multimodal approach meeting analysis 
index terms statistical models multimedia applications numerical signal processing computer conferencing asynchronous interaction 
automatic analysis meetings emerging domain research diverse range speech vision multimodal technologies 
sample applications include structuring browsing querying meeting databases facilitation remote meetings 
speech predominant modality communication meetings speech processing techniques including speech recognition speaker identification topic detection dialogue modelling actively researched meeting context :10.1.1.23.5135
visual processing tracking people focus attention examined 
place analysis text gestures facial expressions audio visual multimodal processing tasks identified meeting scenario 
important advances date approaches automatic meeting analysis limited application known technologies extract information individual participants speech gaze identity 
perspective overlooks potential defining new tasks group nature meetings 
producing accurate speech transcripts identifying participants recognising visual gestures important tasks ultimate goals automatic meeting analysis summarisation meeting series high level agenda items 
summarisation meeting level reflect action group simply actions authors idiap research institute rue du cp ch martigny switzerland 
individual participants 
intuitively true information meetings created interactions participants greater simple sum parts 
automatic analysis people interaction constitutes rich research area 
domains meetings growing interest automatic understanding group behaviour interactions defined individuals playing exchanging similar complementary roles handshake dancing couple children game :10.1.1.132.3753
previous relied visual information statistical models studied specific scenarios surveillance outdoor scenes workplaces indoor group entertainment 
cases interactions composed primitive tasks various degrees complexity performed individual selected small sets actions intuitively relevant 
main hypothesis cases behaviour people interaction constrained behaviour modelling constraints amounts modelling interactions 
little done date automatic analysis multimodal group interactions meetings group behaviour meetings actively studied years social psychologists 
develop technologies capable analysing meetings automatically insight gained body 
specific example research analysed mechanisms significance turn patterns group discussions 
employ statistical framework automatic meeting analysis modelling interactions participants 
actions individual participants measured variety audio visual features 
multimodal feature sequences modelled order recognise actions belonging group termed meeting actions 
particular set meeting actions defined turn events 
experiments extract range audio visual features participant including speech activity pitch speaking rate head hand blobs model participant interactions hidden markov models hmms 
current experiments aim investigate multi modal group natures actions models combine streams information audio visual individuals different ways including early integration hmms multi ieee transactions pattern analysis machine intelligence published stream hmms coupled hmms asynchronous hmms 
background approach section ii reviews related field social psychology 
section iii presents computational framework automatic meeting analysis modelling multimodal group actions 
experiments section iv directions section ii 
meeting analysis social psychology perspective automatic meeting analysis research domain large body literature group interactions exists field social psychology 
literature gives valuable insight nature value information meetings 
summarise aspects social psychology approach relevant proposed computational perspective 
social psychology concerns study manner personality attitudes motivations behaviour individual influence influenced social groups 
social psychology studies phenomena systematic manner employs variety assessment methodologies ranging self report measures observational measures physiological measures 
identify structured observational approach described particular relevance computational framework 
restricting scope focus studies small group discussions relate type meetings currently investigating 
observational approaches group behaviour measured observer analyst 
analyst observe overtly covertly may external internal group 
automatic analysis meetings fits observational paradigm machine functions observer analyst 
specifically structured observational measures improve objectivity analysis defining particular categorisation coding system group behaviour 
categories coding system generally considered mutually exclusive non overlapping exhaustive covering entire meeting duration 
way meeting annotated continuous sequence lexical labels 
structured approaches commonly hypotheses group behaviour probed quantifying specific aspects group 
distinction different coding systems process versus task 
process coding system interaction process analysis ipa proposed designed measure group progresses phases communication evaluation control decision tension reduction reintegration 
system system multiple level observation groups process system attitudes individuals group 
mcgrath task example task system 
categories cover system basis lexicon ipa process shows solidarity shows tension release agrees gives suggestion gives opinion gives orientation asks orientation asks opinion asks suggestion disagrees shows tension shows mcgrath task planning tasks creativity tasks tasks decision making tasks cognitive conflict tasks mixed motive tasks contests performances table alternative coding systems group discussions social psychology 
broad task types generate choose negotiate execute translate specific group tasks 
extension mcgrath task proposed include information sharing gathering tasks 
lexica defined ipa mcgrath task coding systems table coding systems measure individuals interact group group acts 
group behaviours direct relevance potential applications meeting browser 
illustrate gives specific example ipa categories relate potential meeting agenda topics concludes brief functional problems communication evaluation control decision tension reduction reintegration separated enlarged informal agenda topics form skeleton major events meeting 
relating computational framework clear automatic analysis meetings considered case structured observational measurement 
context meeting analysis task defined recognition continuous non overlapping sequence lexical entries analogous approach taken speech continuous gesture recognition :10.1.1.51.6538
coding system provides alternative lexicon meeting events meeting viewed different perspectives labelling number different coding systems parallel 
particular focus group discussion research morphology group interaction investigates patterns individuals participation time 
analysis give insight issues interpersonal trust cognitive load interactions patterns dominance influence 
shown turn patterns meetings predicted simulated simple probabilistic models 
ieee transactions pattern analysis machine intelligence published evident speaking turns characterised predominantly audio information significant information non verbal cues 
examined instance participants coordinate speaking turns variety multimodal cues gaze speech backchannels changes posture 
research shown general visual information help disambiguate audio information modalities discrepant participants appear influenced visual audio cues 
summarising discussion social psychological literature group research provides valuable background information automatic meeting analysis 
current context seen definition lexicon coding system group events allows interactions meetings analysed systematic manner turn behaviour provides rich task analysis audio dominant modality meetings significant information conveyed visual modality motivating multimodal approach 
iii 
automatic meeting analysis computational framework preceding discussion see meetings analysed sequence group actions result individuals interacting series multimodal cues 
motivated view section describes computational framework automatic meeting analysis involves components set multimodal group actions set individual actions model interactions 
multimodal group actions task implementing framework define set relevant group actions 
actions belong meeting particular individual refer meeting actions 
model meeting continuous sequence exclusive events taken set meeting actions 
vn 
note model unambiguous exclusive exhaustive events provides tractable computational framework assumptions reflect reality 
instance events non overlapping implied defined temporal boundaries exist 
reality events characterised soft natural transitions specifying boundaries certain level precision little meaning 
addition real events perfectly unambiguous observers see 
modelling inaccuracies necessarily limitations depending particular application assessment methodology 
insight type group actions meetings gained coding systems described table apparent computational framework requires constrained definition meeting actions social psychology recognition actions feasible state art technology 
discussed section ii turn provides rich basis analysing people interact group discussions 
simplest level segmenting meeting speaker turns useful structuring speech transcripts browsing retrieval 
analysis speaker turns provide insight participants inherent latency responding degree role group interest particular topics 
moving simple speaker turns turn may analysed higher level defining actions may span individual speaker turns distinguishing series monologues group discussion 
turns purely speech presentations white board usage group note defined visual cues gaze gestures taken account 
article propose illustrative set meeting actions high level multimodal turns including monologue participant speaks continuously interruption presentation participant front room presentation projector screen white board participant front room talks notes white board discussion participants engage discussion group note participants write notes 
specifically meeting assumed participants define set meeting actions recognise monologue monologue monologue monologue presentation white board discussion note 
natural actions participants play exchange similar opposite complementary roles 
example monologue person speaks group participants listen direct gaze speaker notes 
discussion multiple participants take relatively short turns speaking movement expected 
set actions define note group event majority participants take notes concurrently 
intuitively expected action indicate periods important information conveyed 
value segmenting meeting set meeting actions evident example facilitate browsing meeting archive allowing user search segments interest archive presentations monologues particular person quickly navigate parts meeting playback see simple demonstration corpus ieee transactions pattern analysis machine intelligence published 
experiments recognise set meeting actions section iv 
similar manner lexica meeting actions defined provide alternative views meeting 
actions non overlapping set meeting actions rich multi layer views meetings built applying parallel sets meeting actions meeting 
example lexica tasks brainstorming information sharing decision making interest level group high neutral low 
research recognising emotion speech recognising interest level posture recognising hot spots regions high involvement emphasis meetings detecting agreement disagreement meetings suggests automatic recognition high level concepts may feasible 
individual actions interesting useful sets meeting actions defined system recognise practice depends define measure constituent individual behaviour 
example presentation intuitively characterised individual cues speech activity location gaze 
similarly brainstorming involve short approximately distributed speaker turns individual note white board characteristic set speech keywords 
pertinence particular individual actions different meeting actions somewhat speculative clear examples useful individual actions measured recognised state art audio visual multimodal processing techniques 
individual actions may fully recognised just measured 
example individual actions including sitting standing raising hands nodding shaking heads recognised 
recognised individual actions value annotations browsing indexing direct measurements individual actions observable features recognition group level meeting actions goal 
experiments article investigate approach 
denote observation sequence feature vectors 
ot ot vector multimodal features time specifically experiments article investigate set audiovisual features including location speech activity pitch energy speaking rate participant location orientation participant head hands location moving objects presentation white board regions 
features described detail section iv 
note focus current article features directly recognise group actions investigated recognition individual actions feature set 
general set features broken multiple feature streams participant second modality define feature vector ni ni number features individual modality handle case participant independent features presentation area speech activity article replicating values consider features corresponding single individual define notation 
number modalities corresponding audio visual frame index 
similarly consider feature vector single modality individuals define number participants consider set features accordingly define sequences observations way 
instance lth sequence observations represented features modality individuals 
interaction model order model meeting actions propose model interactions individuals 
considering interactions sequences events rely successful approaches currently model temporal sequences events statistical framework 
context general idea estimate type event vj parameters distribution corresponding sequences observations sequence observations correspond event vj 
known solution efficiently model distributions hidden markov models hmms 
hmms success numerous sequence recognition tasks including speech recognition video segmentation sports event recognition broadcast news segmentation 
hmms introduce state variable qt factor joint distribution sequence observations state simpler distributions emission distributions ot qt transition distributions qt qt 
factorisation yields efficient training algorithms expectation maximisation algorithm em select set parameters model corresponding event vj maximise likelihood observation sequences follows arg max ol 
success hmms applied sequences events careful design sub models distributions corresponding lexical units phonemes words letters events 
current framework lexical units defined set meeting actions vj specific hmm created action vj 
training set observation sequences representing meetings know corresponding labelling necessarily precise alignment create new hmm sequence concatenation ieee transactions pattern analysis machine intelligence published sub model hmms corresponding sequence meeting actions 
new hmm trained em effect adapting sub model hmm accordingly 
new sequence observation features meeting available objective obtain optimal sequence sub model hmms representing meeting actions generated observation sequence 
approximation done efficiently wellknown viterbi algorithm 
hmms model various kinds sequences observations problems fact better described multiple streams observations corresponding sequence events 
setup closely corresponds case stream represent individual actions participant meeting objective analysing interactions individuals terms meeting actions 
solutions multiple stream setup proposed literature 
simplest merge observations related streams large stream frame frame model single hmm explained 
solution called early integration 
note cases streams represent information collected different frame rates audio video streams instance sampling sampling streams necessary order align streams common frame rate 
notation introduced section iii early integration solution creation model event vj arg max 
complex option multi stream approach case stream modelled separately hmm 
instance consider modalities separate streams create model event vj modality arg max 
similarly consider individuals separate streams create model event vj individual arg max 
new meeting needs analysed special hmm created recombining single stream hmm likelihoods various specific temporal points 
depending recombination points various solutions appear 
models recombined state underlying system equivalent making hypothesis streams state synchronous independent state 
solution implemented efficiently shown robustness various stream dependent noises 
case multiple modality streams emission probability combined observations streams state model corresponding event vj time estimated qt qt similarly case multiple individual streams emission probability combined observations streams state model corresponding event vj time estimated qt qt 
see solution searching best path hmm state combination states single stream hmms powerful recombination strategy enables form asynchrony states stream consider hmm states include possible combinations single stream hmm states 
unfortunately total number states model exponential number streams quickly intractable 
intermediate solution call composite hmm considers combinations states action 
model action vj hmm contains possible combinations states corresponding action vm stream hmm total number states remains exponential tractable number states stream remains low case number streams case 
underlying hypothesis intermediate solution streams action synchronous state synchronous 
multi stream models typically employed separate streams audio visual features multi modal tasks different frequency sub bands speech recognition 
modelling group interactions streams represent individual participants 
interesting advantage models trained variable numbers participants meetings decode meetings previously unseen number participants 
resulting decoding algorithm complexity linear number participants 
approaches combine multiple streams information proposed literature general suffer underlying training decoding algorithm complexity exponential number streams 
instance coupled hidden markov models chmms model concurrent streams audio video stream concurrent hmms transition probability distribution state variable stream depends value state variable stream previous time step formally respectively state variables streams chmms model transitions follows qt qt rt rt rt qt 
unfortunately note solution forces topology single stream 
ieee transactions pattern analysis machine intelligence published exact training algorithm model quickly intractable extended streams case meetings 
approximate algorithm relaxes requirement visit transition termed heads algorithm proposed tractable small number streams 
approach asynchronous hidden markov models models joint probability streams combining order account possible asynchrony useful temporarily stretch compress stream respect ones 
instance group action recognition task individual start playing role rest group 
able stretch individual streams specific points yield performance improvement 
approach promising results streams currently proposed training algorithm quickly intractable extended streams 
case modality streams audio video ahmm representing event vj models joint distribution streams maximising likelihood observation sequences follows arg max 
introducing state variable qt classical hmms synchronisation variable providing alignment streams factor joint distribution simpler distributions transition distribution qt qt joint emission distribution qt audio distribution qt distribution models fact joint distribution time emit qt 
factorisation yields efficient training decoding algorithms number streams limited 
apart models investigated current article models interest include layered hmms dynamic bayesian networks dbns 
layered hmms composed layers takes observation previous layer generates observation layer 
experiments layered hmms recognise group actions recognised individual actions directly features current 
dynamic bayesian networks dbns generalisation hmms applied success meeting recognition task described article audio modality 
iv 
experiments section describes experiments recognise multimodal meeting actions turn events discussed section iii 
sub sections describe collection multi modal database meeting actions detail experimental configuration results 
count train set test set discussion monologue white board action presentation note fig 

histogram showing occurrences meeting actions train test sets 
data collection data collected instrumented meeting room dimensions contains meeting table 
room equipped fully synchronised multi channel audio video recording facilities 
audio acquisition high quality miniature lapel microphones simultaneously recorded khz bit resolution 
microphones identical close talking lapel microphones attached meeting participants table top microphone arrays 
video acquisition closed circuit television cameras output pal quality video signals recorded separate video digital video tape 
camera fitted adjustable lens field view 
full details hardware setup 
scripted meeting approach taken collect required audio visual data meeting action recognition experiments ensure adequate examples actions included facilitate annotation training testing 
ergodic markov model generate meeting scripts 
meeting action corresponded state markov model self loop transition probabilities governing relative duration action 
transition probabilities tuned hand ensure generated action sequences durations realistic 
illustrate relative occurrences different actions shown train test sets described 
average meeting contained actions 
generation meeting script action durations normalised random time minutes drawn distribution order constrain total time approximately minutes 
disjoint sets meeting participants drawn local research staff population 
set person meeting scripts generated described 
participants meeting chosen random set people 
scripted meeting action key role played single participant monologues presentations white boards allocated random participants 
meeting script assigned topic random small set ieee transactions pattern analysis machine intelligence published participant lapel microphone microphone array meeting table projector screen fig 

meeting recording configuration 
camera equipment rack whiteboard topics favourite movie 
dedicated monitored scripted action durations meeting recording silent gestures prompt transitions actions script 
behaviour participants actions natural unconstrained 
meeting room configuration recordings illustrated 
cameras acquired front view participants including table region note 
third wide view camera looked top participants white board projector screen 
seating positions participants allocated randomly constraint participants white board sat seats closest front room exploited analysis 
participants wore lapel microphones element circular equi spaced microphone array cm diameter centrally located meeting table 
total meeting recordings collected participant sets having meetings resulting approximately hours multi channel audio visual meeting data 
recording consists video channels twelve audio channels 
data available public distribution 
feature extraction observation vectors formed range audio visual features measure actions individuals 
consist audio features audio features extracted different sources microphone array participant 
microphone array signals speech activity estimated different locations seats locations corresponding presentation white board 
locations fixed vectors measured site describing approximately people standing seated 
speech activity computed steered response power coming location srp phat measure continuous bounded value indicates activity particular location 
streams srp phat features able determine location active 
obtained speech silence segmentation location technique described 
segmentation stored order compute features feature 
lapel signals computed additional acoustic features 
acoustic features energy pitch speaking rate computed speech segments setting default value zero silence segments 
pitch computed sift algorithm speaking rate obtained combination estimators energy calculated short term ms hamming windowed segment 
features extracted lapel signals current equally extracted output microphone array beamformer participant see related research investigating developing beamforming tracking algorithms multiple people meeting room 
audio features downsampled match hz rate chosen video 
consecutive frames merged keeping maximum value srp phat features median value acoustic features 
visual features visual features extracted standard methods image regions enclosing seated participants head shoulders workspace table whiteboard presentation screen area 
cameras looking people table gaussian mixture models gmms skin color rgb space extract head hand forearm blobs 
component gmm estimated faces arms people training set included indian latin american individuals 
skin pixels classified thresholding skin likelihood 
morphological postprocessing step performed inside image regions enclosing typical head locations workspace extract blobs 
person detected head blob represented vertical position centroid normalized average centroid computed meeting duration 
additionally hand blobs characterized features horizontal normalized centroid eccentricity angle respect horizontal :10.1.1.51.6538
hand blob extraction identification especially difficult due free patterns meetings 
instance discussion current speaker introduce considerable self occlusion moving hands occlude face participants cross arms clasp hands listening 
view opted represent hand blob information described features right blob participants training test set right handed 
rough person motion feature computed average individual motions head arms blobs motion ieee transactions pattern analysis machine intelligence published fig 

blob extraction multicamera meeting room 
top row images shows frame cameras bottom row shows detected skin blobs left right moving blobs centre 
modality participants feature audio visual individual seat speech activity white board speech activity presentation speech activity speech pitch speech energy speaking rate head blob vertical centroid hand blob horizontal centroid hand blob eccentricity hand blob angle combined motion white board presentation blob computed centroid difference consecutive frames 
note tracking performed tradeoff potential benefits feature extraction additional computational cost multi part tracker remains seen 
wide view camera moving blobs detected background represented quantised horizontal position 
fixed background image errors feature extraction due sudden variations camera response occur frequently 
adaptive background subtraction improve robustness 
typical result blob extraction shown different camera views 
final set visual features consists features seated participant plus whiteboard screen camera 
gives total audio visual features extracted frame rate hz 
experimental configuration experiments different feature subsets defined audio table ii break features streams 
audio features trained equation 
visual visual features trained equation 
individual participants audio visual features 
consists features plus features replicated participant stream 
separate streams trained equation 
specific features streams summarised table ii 
note streams individual participants fact correspond different seating locations independent actual participant identities 
models hmm systems mentioned section iii combine streams different ways early integration single hmm trained features equation 
participant multi stream multi stream hmm combining streams ieee transactions pattern analysis machine intelligence published individual participants streams trained equation 
decoding schemes investigated state level synchrony equation action level synchrony implemented composite model actions 
participant coupled coupled hmm combining streams individual participants 
chmm model initialised independently trained streams retrained extension heads algorithm arbitrary number streams 
decoding action sequence streams constrained action level synchrony 
audio visual multi stream multi stream hmm combining audio video streams equations 
decoding schemes investigated state level synchrony equation action level synchrony implemented composite model action models 
audio visual coupled coupled hmm combining audio video streams initialised trained similar manner participant chmm 
decoding action sequence streams constrained synchrony 
audio visual hmm combining audio video streams equation 
constrain complexity maximum allowed asynchrony streams seconds compared state duration average action duration 
models hyper parameters including number emitting states model range number gmm components state range insertion penalty decoding selected fold cross validation train set 
ahmm distributions state audio distribution gmm joint audiovisual distribution gmm visual emission probability distribution binomial distribution 
case audio stream sampled hz better allow form asynchrony video stream 
experiments implemented torch machine learning library publicly available 
results discussion results table iii terms action error rate aer frame error rate fer 
aer equivalent word error rate automatic speech recognition asr 
defined sum insertion extra actions recognised change occurred deletion actions omitted substitution actions occurred detected labelled incorrectly errors divided total number actions ground truth times 
action error rate metric appropriate determining correct sequence events important determining precise temporal boundaries 
case due natural ill defined transitions meeting actions 
fer percentage incorrectly labelled frames include main reasons necessary verify temporal alignment recognised events reasonable reasons statistical significance see discussion significance 
note frame error rate enforces strict temporal boundaries harsh measure boundaries inherently ill defined 
results varied random initialisation procedure em training exaggerated low number training examples 
variation occurred results mean standard deviation runs 
results note corpus browsed resulting automatic transcriptions 
significance results due small number actions training testing sets worth discussing significance results 
standard deviations quoted give idea various models robust initial conditions statistical significance tests assess model better ones similar different test data 
standard proportion test assuming binomial distribution targets normal approximation done similar cases 
terms action error rates confidence differentiate best models audio early integration audio visual combinations participant action level synchrony participant coupled note best terms fer 
terms frame error rates high number test frames results statistically significantly different level instance best model audio visual asynchronous statistically significantly better second best early integration 
consider action error rate appropriate measure experiments base discussion reliable frame error rate results 
single streams help analyse results confusion matrices randomly chosen single run visual streams shown tables iv 
clear audio predominant modality set meeting actions investigated basically speaking turns reflected audio results 
relevant information visual features able give discrimination events 
expected visual features allow presentation white board recognised 
interesting fact give reasonable discrimination discussion may attributed note action error rates really proportions percentages greater 
test assess word error rates asr 
hand test reasonable frame error rates defined proportions 
ieee transactions pattern analysis machine intelligence published model action error rate frame error rate audio visual individual participants early integration audio visual multi stream state audio visual multi stream action audio visual coupled action audio visual asynchronous participant multi stream state participant multi stream action participant coupled action table iii action error frame error rates percent lower better test set various hmm architectures modelling meeting actions 
initialisation procedure introduced variation results values mean standard deviation runs 
constraints synchrony state level action level indicated increased motion participants 
see modality isolation capable distinguishing periods jointly characterised audio silence visual gestures 
table vi shows single participant streams able give discrimination events actions essentially occur group level individual streams contain insufficient information distinguish reliably 
particular individual streams able distinguish monologues 
behaviour improved accurate gaze features reliable indicator silent participants focus attention monologues 
early integration examining different combination approaches note early integration gives significantly better frame error rates approaches apart audio visual ahmm 
improvement audio results comes improved recognition shown confusion matrix table vii 
result highlights benefit multi modal approach modality isolation able reliably recognise note combination achieves perfect results action 
improvement see results reduction monologue discussion insertion deletion errors 
extra monologues results inserted middle discussions seen motion video stream helps discriminating discussion monologues 
audio visual multi stream coupled ahmm models separate audio visual streams multi stream hmm chmm ahmm give results terms action error rate 
see frame error rate ahmm system significantly better stream isolation 
demonstrates importance modelling feature level correlation modalities disregarded case multi stream hmm lesser extent coupled hmm models correlation streams 
comparing systems appropriate multiple stream models 
state synchrony action synchrony see significant asynchrony audio visual streams 
confirmed closeness results audio visual ahmm early integration hmm 
participant multi stream coupled multi stream combination participant streams performs better stream isolation significantly lower early integration approach 
action synchronous multi stream results demonstrate significant improvement achieved allowing asynchrony participants 
small improvement coupled hmm multi stream hmm performance lower early integration approach highlighting need model feature level correlation participants 
summary summarising discussion observations results benefit multi modal approach modelling group actions meetings 
important model correlation behaviour different participants 
significant asynchrony audio visual modalities actions resolution investigated frame rate 
evidence asynchrony participants acting group actions 
findings appeal intuition individuals act group audio visual cues causal effect behaviour group members 
final results lead hypothesise ahmm participant streams provide powerful model group actions highlighting need seek tractable training algorithm case multiple streams significant asynchrony 
ieee transactions pattern analysis machine intelligence published disc mono mono mono mono note pres white del disc mono mono mono mono note pres white ins table iv confusion matrix recognised meeting actions audio including discussions disc monologues mono note note presentations pres white boards white insertion errors ins deletion errors del 
zero values represented empty cells 
columns rows show desired obtained labels respectively 
application real meeting data disc mono mono mono mono note pres white del disc mono mono mono mono note pres white ins table confusion matrix recognised meeting actions video 
disc mono mono mono mono note pres white del disc mono mono mono mono note pres white ins table vi confusion matrix recognised meeting actions individual participant 
disc mono mono mono mono note pres white del disc mono mono mono mono note pres white ins table vii confusion matrix recognised meeting actions early integration system 
meeting corpus experiments necessarily constrained facilitate training testing 
verify robustness technique natural data hour real meeting recorded analysis 
features extracted meeting actions recognised best models differing numbers streams early integration state synchronous multi stream model audio visual streams coupled hmm participant streams 
model parameters ones previous experiments tuning 
objectively assess ability system recognise meeting actions effort produce groundtruth transcription meeting 
observing data ieee transactions pattern analysis machine intelligence published apparent reality obvious draw absolute distinction actions monologues discussions 
opted approach evaluation 
sequence recognised actions verified independent observers familiar system 
subjects played back meeting recordings real time judged correctness recognised action corresponding time interval proposing new action label appropriate 
subjects participated experiment 
second step decision taken third person authors actions disagreement pair observers 
classification results shown table viii 
models difficulties people automatic algorithms arise ambiguity existing actions originally defined non overlapping monologues discussions due temporal occurrence actions note participants middle discussion 
highlighting difficulty subjectivity task analysis suggests system provides segmentation reasonable human observer value applications browsing indexing 
apparent research needs address ill defined nature actions real data 
directions approach automatic meeting analysis considers meeting sequence group level events termed meeting actions 
meeting actions result interactions individual participants inherently multimodal nature 
illustrative set meeting actions high level turn behaviour defined 
actions recognised experiments range audio visual features extracted participant modelled different hmm approaches 
best results achieved audio visual asynchronous hmm system gave action error rate confirming importance modelling interactions individuals advantage multimodal approach 
experiments article shown successful recognition set turn meeting actions scope recognise sets high level meeting actions group level interest 
achieve goal ongoing investigating richer feature sets gaze recognition individual actions different means modelling multimodal interactions participants 
involve collection larger natural meeting corpus development flexible assessment methodologies 
vi 
authors acknowledge invaluable advice jean carletta human communication research centre edinburgh university regarding small group research social psychology 
acknowledge colleagues idiap assistance data collection evaluation results real meetings 
supported swiss national science foundation national centre competence research interactive multimodal information management im 
funded european projects multimodal meeting manager lava learning adaptable visual assistants swiss federal office education science 
kubala rough ready meeting recorder browser acm computing surveys 
morgan baron edwards ellis janin shriberg stolcke meeting project icsi proc :10.1.1.23.5135
human language technology conference san diego ca march 
waibel ries schaaf schultz yu zechner advances automatic meeting record creation access proc 
ieee icassp salt lake city ut may 
renals ellis audio information access meeting rooms proc 
ieee icassp 
waibel schultz malkin stiefelhagen yang smart smart meeting room task isl proc 
ieee icassp 
cutler rui gupta zhang liu silverberg distributed meetings meeting capture broadcasting system proc 
acm multimedia conference 
bobick intille davis baird pinhanez campbell ivanov schutte wilson perceptually interactive immersive story environment presence teleoperators virtual environments vol 
august 
johnson hogg acquisition interaction behaviour models proc 
ieee int 
conference computer vision pattern recognition june 
jebara pentland action reaction learning automatic visual analysis synthesis interactive behaviour proc 
international conference vision systems january 
oliver rosario pentland bayesian computer vision system modeling human interactions ieee transactions pattern analysis machine intelligence vol 
august 
nevatia multi agent event recognition proc 
ieee int 
conference computer vision vancouver july 
interaction process analysis method study small groups 
addison wesley 
mcgrath groups interaction performance 
prentice hall 
mcgrath group research annual review psychology vol 
pp 

carletta simulation small group discussion 
parker speaking turns small group interaction contextsensitive event sequence model journal personality social psychology vol 
pp 

fay carletta group discussion interactive dialogue serial monologue influence group size psychological science vol 
pp 

bengio perez moore wellner bourlard modeling human interactions meetings proceedings international conference acoustics speech signal processing icassp april 
rabiner 
juang fundamentals speech recognition 
prentice hall 
morris hagen bourlard multi stream adaptive evidence combination noise robust asr speech communication 
dupont luettin audio visual speech modeling continuous speech recognition ieee transactions multimedia vol 
pp 
september 
brand oliver pentland coupled hidden markov models complex action recognition proceedings ieee cvpr 
ieee transactions pattern analysis machine intelligence published model number recognised actions classification rate early integration audio visual multi stream state participant coupled action table viii action classification rates percent higher better best hmm models hour real meeting 
constraints synchrony state level action level indicated appropriate multiple stream models 
bengio asynchronous hidden markov model audio visual speech recognition advances neural information processing systems nips becker thrun obermayer eds mit press 
merriam webster online dictionary www com 
forsyth measurement social psychological research www people vcu edu methods measure htm 
cohen system multiple level observation groups 
free press 
ward marshall applying task classification natural meetings tech 
rep cs oregon graduate institute 
starner pentland visual recognition american sign language hmms proc :10.1.1.51.6538
int 

auto 
face gesture recognition zurich 
hansen ward coordinating turn gaze proceedings international conference spoken language processing icslp 
mcmahon role audible visible back channel responses interpersonal communication journal personality social psychology vol 
pp 

rosenthal rogers finkelstein decoding discrepant nonverbal cues journal personality social psychology vol 
pp 

idiap data distribution mmm idiap ch 
kwon chan hao lee emotion recognition speech signals proc 
eurospeech geneva sept 
improved emotion recognition large set statistical features proc 
eurospeech geneva sept 
picard automated posture analysis detecting learner interest level proc 
cvpr workshop computer vision pattern recognition human computer interaction madison wisconsin june 

shriberg spotting hotspots meetings human judgments prosodic cues proc 
eurospeech geneva sept 
shriberg relationship dialogue acts hot spots meetings proc 
virgin islands dec 
kennedy ellis pitch emphasis detection characterization meeting recordings proc 
virgin islands dec 
ostendorf shriberg detection agreement vs disagreement meetings training unlabeled data proc 
hlt naacl conference edmonton may 
action recognition meeting scenarios global motion features proceedings workshop performance evaluation tracking surveillance march 
zhang perez bengio modelling individual group events meetings layer hmm framework idiap rr idiap 
wilcox hidden markov model framework video segmentation audio image features proceedings icassp vol 
seattle pp 

xie 
chang sun structure analysis soccer video hidden markov models icassp 
ller content video indexing tv broadcast news hidden markov models proceedings icassp phoenix pp 

dempster laird rubin maximum likelihood incomplete data em algorithm journal royal statistical society vol 
pp 

viterbi error bounds convolutional codes asymptotically optimum decoding algorithm ieee transactions information theory pp 

oliver horvitz garg layered representations learning inferring office activity multiple sensory channels proceedings international conference multimodal interfaces october 
potamianos neti luettin matthews audio visual automatic speech recognition overview issues visual audio visual speech processing perrier eds mit press 
brand coupled hidden markov models modeling interacting processes tr mit media lab vision modeling november 
renals dynamic bayesian networks meeting structuring proc 
ieee int 
conf 
acoustics speech signal processing icassp montreal may 
moore idiap smart meeting room idiap communication 
high accuracy low latency technique talker localization environments 
phd thesis brown university providence ri usa 
silverman robust localization rooms microphone arrays ward eds ch 
pp 
springer 
moore segmenting multiple concurrent speakers microphone arrays idiap rr idiap martigny switzerland 
submitted publication 
sift algorithm fundamental frequency estimation ieee transactions audio vol 
pp 

morgan combining multiple estimators speaking rate proceedings ieee international conference acoustics speech signal processing icassp 
moore microphone array speech recognition experiments overlapping speech meetings proceedings international conference acoustics speech signal processing april 
perez 
particle filter multi camera speaker tracking proceedings september 
jones rehg statistical color models application skin detection int 
computer vision vol 
pp 
jan 
stauffer adaptive background mixture models real time tracking proc 
ieee cvpr ft collins pp 

bengio mari torch modular machine learning software library idiap rr idiap martigny switzerland 
www torch ch 
perez barnard bengio bourlard automatic annotation meeting databases proceedings international conference image processing icip 
www itl nist gov div handbook prc section prc htm 
ieee transactions pattern analysis machine intelligence published mation retrieval 
iain received 
queensland university technology qut brisbane 
completed phd research concentration speech audio video technology qut 
joined idiap research institute april currently senior researcher 
research interests include microphone array speech enhancement audio visual speaker localisation tracking multimodal event recognition application speech processing multimedia infor daniel perez received degree electronic engineering university mexico degree electrical engineering national university mexico ph degree electrical engineering university washington seattle 
joined idiap research institute january senior researcher 
interests include computer vision multimodal signal processing multimedia information retrieval 
bengio senior researcher statistical machine learning idiap research institute supervises phd students postdoctoral fellows working areas machine learning support vector machines time series prediction mixture models large scale problems speech recognition multi modal face voice person authentication asynchronous sequence processing brain computer interfaces text mining 
obtained phd computer science universite de montreal spent post doctoral years cnet research center france telecom telecommunications montreal 
worked researcher economic financial academic research center applying learning algorithms finance 
joining idiap research director labs private research center mobile telecommunications 
current interests include theoretical applied aspects learning algorithms 
guillaume earned sc 
computer science telecommunications institut national des telecommunications int france 
spent years member digital television team national institute standards technology nist usa 
joined idiap research institute switzerland phd student 
interests include microphone array processing audio source localization speaker tracking multimodal processing 
mark barnard completed bachelor computing mathematical sciences university western australia 
worked research assistant phd student idiap research institute martigny switzerland 
main area research detection recognition events multimodal data sequences currently focused event detection annotation sporting videos 
dong zhang obtained 
automatic control electrical engineering beijing institute technology 
computer vision pattern recognition institute automation chinese academy sciences 
joined microsoft research asia research development area multimedia retrieval 
phd student idiap research institute switzerland 
research interests include machine learning computer vision multimedia systems 
