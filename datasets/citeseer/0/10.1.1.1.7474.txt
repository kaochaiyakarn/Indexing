reinforcement learning spider web ciently jason rennie com andrew mccallum mccallum com school computer science carnegie mellon university pittsburgh pa just research henry street pittsburgh pa consider task exploring web order find pages particular kind particular topic 
task arises construction search engines web knowledge bases 
argues creation cient web spiders best framed solved reinforcement learning branch machine learning concerns optimal sequential decision making 
strength reinforcement learning provides formalism measuring utility actions give benefit 
algorithm learning value function maps hyperlinks discounted reward naive bayes text classifier 
experiments real world spidering tasks show threefold improvement spidering ciency traditional breadth search fold improvement reinforcement learning immediate reward 
spiders agents explore hyperlink graph web purpose finding documents populate search engine 
information extraction techniques improve spiders vital elements automated creation web knowledge bases 
extensive spidering key obtaining high coverage major web search engines altavista published proceedings icml workshop machine learning text data analysis hotbot 
goal general purpose search engines provide search capabilities web aim find distinct web pages possible 
goal lends strategies breadth search 
hand task find pages particular kind particular topic case increasingly popular class domain specific search engines intelligent spider try avoid hyperlinks lead topic areas concentrate links lead documents interest 
similarly goal locate documents populating topic specific knowledge base ort wasted hyperlink 
describes research cient web spidering 
argue creation cient web spiders best framed solved reinforcement learning branch machine learning concerns optimal sequential decision making 
strength reinforcement learning provides formalism measuring utility actions give immediate benefit give benefit 
reinforcement learning agents represent delayed benefit learning mapping available action scalar value indicating sum discounted rewards expected executing action 
discount rewards valuable sooner rewards encouraging ciency 
current reinforcement learning spider learn mapping text neighborhood hyperlink expected discounted number relevant pages result hyperlink 
mapping text scalar performed casting regression classification gama specifically discretize scalar values finite number bins naive bayes classify text corresponding finite number classes value assigned particular hyperlink weighted average values top ranked bins 
research cient spidering part larger project created cora domain specific search engine indexes computer science research papers mccallum computer science departments labs far finding research papers postscript format 
papers converted plain text run specially trained hidden markov model automatically find title authors forward backward papers resolved 
information available searchable public web interface www cora com 
cora cient spidering significant concern 
majority pages computer science department web sites contain links research papers courses homework schedules admissions information 
avoiding branches neighborhoods departmental web graphs significantly improve ciency increase number research papers finite amount crawling time 
driven webkb project craven focus automatically populating knowledge base information available world wide web 
system ontology consisting object classes relations interest location ceo locatedin cer training set consisting labeled instances classes relations web pages labeled class web page pairs labeled relation 
system aims extract automatically new instances classes relations web 
system extract instances locate web documents containing appropriate information 
spidering important 
spidering ciently increase size attainable knowledge base face ubiquitous limitations time computation network bandwidth 
spider locate web page listing chief executive 
report experiments performed data sets taken cora webkb domains 
experiments show reinforcement learning highly ective framework spidering problem 
cases reinforcement learning outperforms traditional spidering breadth search factor 
data sets find explicitly modeling reward provides significant benefit 
nature benefit depends somewhat context 
case cora reward providing documents spidering run modeling reward provides benefit half run hyperlinks leading immediate reward discovered 
webkb task spidering run contains single reward document common reinforcement learning goals achievement decisions reward 
result approach explicitly models predicts reward find desired documents ciently 
webkb experiments modeling reward increases ciency factor 
reinforcement learning term reinforcement learning refers framework learning optimal decision making rewards punishment kaelbling di ers supervised learning learner told correct action particular state simply told bad selected action expressed form scalar reward 
task defined set states set actions state action transition function reward function 
time step learner called agent selects action result reward new state 
goal reinforcement learning learn policy mapping states actions maximizes sum reward time 
infinite horizon discounted model reward time geometrically discounted sum discount rewards received 
accordingly policy define value state reward received time steps starting state policy 
optimal policy written maximizes value states order learn optimal policy learn value function specific correlate called value selecting action state optimal policy 
expressed 
define optimal policy terms selecting state action highest expected reward arg max 
seminal bellman shows optimal policy straightforwardly dynamic programming 
spidering reinforcement learning aid understanding reinforcement learning relates spidering consider common reinforcement learning task mouse exploring maze find pieces cheese 
agent receives immediate reward finding piece cheese actions moving grid squares maze 
state position mouse locations cheese pieces remaining consumed cheese consumed provide reward 
note agent receives immediate reward finding maze square containing cheese order act optimally choose actions considering rewards 
spidering task topic documents immediate rewards pieces cheese 
action particular hyperlink 
state set topic documents remaining set hyperlinks discovered 
state include current position page visited agent crawler jump known url 
number available actions large dynamic depends documents spider visited far 
mouse leap square long visited bordering square 
key feature spidering reinforcement learning proper framework environment presents situations delayed reward 
practical approximations problem apply reinforcement learning spidering way practically solved 
unfortunately state space huge difficult generalize 
encapsulates documents remaining set hyperlinks available actions 
immediately apparent construct metric compare di erent states 
action space large number distinct hyperlinks web considering 
need simplifying assumptions order problem tractable aid generalization 
note defining exact solution terms optimal policy making assumptions explicit better understand inaccuracies introduced select areas improve performance 
simplifying assumptions disregard state capture relevant distinctions actions words neighborhood corresponding hyperlink 
disregarding state generalize states determine single value action assigning set words hyperlink generalize di erent hyperlinks comparing text 
function mapping bagof words scalar discounted sum reward learning perform cient spidering involves remaining sub problems obtaining training data consisting bag words value pairs learning mapping training data 
described subsections 
obtaining training data calculating values choices gather training data 
agent learn experience line currently train agent line collections documents hyperlinks 
training sets know state transition functions reward functions knowledge obtain bag words value pairs estimate function unexplored portion web 
recall value hyperlink discounted sum rewards received optimal policy traversing hyperlink question 
text related hyperlink question example unordered list words anchor headers page title associated hyperlink 
calculating values tasks single goal single reward dynamic programming produces hyperlink value equal reward discounted distance goal 
calculation done directly running full dynamic programming 
rewards process complicated 
trying fully represent exponentially sized state space applying dynamic programming aim calculate optimal sequence directly set value discounted sum sequence 
calculate optimal sequence directly maintaining fringe hyperlinks available pages sequence far greedily traversing reward closest fringe 
initially fringe contains hyperlink value currently calculating 
choosing fringe represents fact spider required select hyperlink page visited choose hyperlinks aware fringe 
note furthermore fringe calculation pages reachable initial hyperlink practice testing time agent explored hyperlinks able jump 
see greedy search reasonable consider assigning values hyperlinks yields reward yields reward reveals gold mine hyperlinks gives reward 
imagine spider hyperlinks possible actions 
follows sequence rewards 

rewards 

value ciency better choice 
fact rl domains moving immediate reward take agent gold mine alternative actions available cost best follow hyperlink yields immediate reward 
choose mandates policy perfect function predictor 
causes nearer rewards valuable greedy search appropriate way determine optimal action sequence 
mapping text values calculated values hyperlinks training data learn generalized obtainable shorter sequence actions 
value function maps hyperlinks scalar values 
mapping cient generalize unseen hyperlinks 
represent value function collection naive bayes text classifiers performing mapping casting regression problem classification gama discretize discounted sum reward values training data bins place text neighborhood hyperlinks bin corresponding values hyperlinks neighborhood text training documents naive bayes text classifier 
new hyperlink find naive bayes yields probabilistic class membership bin neighborhood text hyperlink 
value associated bin set average values associated training hyperlinks assigned bin 
value new hyperlink estimated weighted average bin value probabilistic class memberships weights 
gives method naive bayes function approximator 
introduce naive bayes text classifier 
approaching task text classification bayesian learning framework assume text data generated parametric model training data calculate maximum posteriori estimates model parameters 
equipped estimates classify new test documents bayes rule turn generative model calculate posterior probability class generated test document question 
classification simple matter selecting probable class document words 
classifier parameterizes class separately document frequency word frequencies 
class document frequency relative classes written 
class modeled multinomial words 
word vocabulary indicates frequency classifier expects word occur documents class represent document unordered collection words 
classify new document model naive bayes assumption words document occur independently class document furthermore independently position 
assumption classification straightforward 
calculate probability class evidence document select class expression maximum 
write ik kth word document expand application bayes rule word independence assumption ik 
learning parameters classification accomplished set labeled training documents estimate word probability parameters count word occurrences class frequency occurs documents class 
supplement laplace smoothing primes estimate count avoid probabilities zero 
define count number times word occurs document define document class label 
estimate probability word class 
class frequency parameters set way indicates number classes 
empirically large number training documents naive bayes job classifying text documents lewis complete presentations naive bayes text classification provided mitchell mccallum nigam experimental setup august completely mapped documents hyperlinks web sites computer science departments brown university cornell university university pittsburgh university texas 
comprises cora data set includes documents hyperlinks 
target pages reward computer science research papers 
identified high precision hand coded algorithm checks sections 
webkb data set includes web pages complete web sites companies 
companies selected randomly pool companies webkb knowledge base 
target page includes information directors 
page located hand giving total target pages 
advantage choosing data sets extremely di erent properties 
cora task find large number target pages single spidering run rewards may connected web page 
accurately identifying immediate rewards important 
webkb graph hand contains single target page 
order locate single reward spider traverse path hyperlinks 
path spider compare values hyperlinks distinguishing reward important 
di erent types neighborhood text regression classification task 
call neighborhood text associate hyperlink bags words separate vocabularies full text page hyperlink located anchor text hyperlink portions url 
second call related neighborhood text associate hyperlink bags words separate vocabularies headers title words anchor text hyperlink directories filenames url hyperlink small set words immediately hyperlink 
note choices neighborhood text hand selected learned way 
ongoing experimenting types neighborhood text examine ect spidering performance 
experiment describe perform series runs department data set 
spider trained data departments companies tested web remaining 
comparison results spiders form learning 
breadth spider follows hyperlinks order finds fifo action queue 
optimal spider full knowledge spidering graph follows path nearest reward 
rl immediate spider uses binary classification regression 
bin includes hyperlinks value hyperlinks point directly target pages 
second bin includes hyperlinks 
value approximator perfect spider perform breadth search hyperlink points directly target page 
note probabilistic classification provides intermediate values text class 
weaker form regression representing reward multi binned classifier estimated value reward hyperlink high shares features hyperlinks 
rl spider uses reward described section performs regression classifying bins varying amounts reward 
experimented bins 
example bin classifier maps immediate reward hyperlinks bin hyperlinks second bin hyperlinks third bin remaining hyperlinks fourth bin 
main di erence rl immediate rl rl bins representing reward hyperlinks 
example bin rl spider second bin represents hyperlinks point web page hyperlinks 
hand rl immediate distinguishes immediate reward hyperlinks hyperlinks 
results results experiments performed spider adequately able parse navigate html frames 
previous versions spider capability results may di er somewhat results previous 
top shows results di erent spiders cora data set 
notice times progress reinforcement learning spiders research papers breadthfirst 
measure performance number hyperlinks followed research papers 
reinforcement learning performs significantly ciently requiring exploration hyperlinks comparison breadth requires 
represents factor increase spidering ciency 
percent research papers percent hyperlinks followed cora spidering full page optimal rl bins rl immediate bins breadth percent hyperlinks followed cora spidering full page optimal rl bins rl immediate bins breadth top comparison spiders cora dataset full page neighborhood text results averaged departments 
reinforcement learning spiders retrieve quarters research papers third page expansions breadth requires 
note rl performs better rl immediate earliest stages spidering 
bottom close near origin top 
note rl spider performs better rl immediate spider reward correctly select alternative branches give immediate reward 
rl locates target documents quickly 
early period important applications spidering require sample target pages retrieved 
bottom shows closeup early part run 
average rl takes significantly time rl immediate find papers ciently avoiding average extra page downloads performed rl immediate 
papers percent research papers percent hyperlinks followed cora spidering optimal rl full page rl immediate full page rl related rl immediate related breadth percent research papers percent hyperlinks followed cora spidering optimal rl full page rl immediate full page rl related rl immediate related breadth close spidering performance results full page related neighborhood text 
note skewed scales 
bottom displays results locating research papers 
top displays results stages spidering 
spiders related neighborhood text retrieve research papers quickly spiders full page neighborhood text 
rl immediate spider performs somewhat better rl spider 
system uncovered links give immediate reward followed rl immediate spider recognizes accurately 
average rl immediate able identify immediate reward links recall bin rl achieves recall 
similar phenomenon seen comparing spidering performance di erent notions neighborhood text 
bottom shows early stages spidering spider related neighborhood text performs better full page text 
spidering continues top roles reversed full page spiders perform better 
mentioned rl immediate full page spider achieves recall 
related version spider achieves recall classifying research hyperlinks 
hand related spider achieves greater accuracy due high recall score classification hyperlinks 
results lead believe high recall classifying research hyperlinks leads better performance middle stages spidering 
time spider hyperlinks point research papers 
better identify hyperlinks readily follows 
early stages spidering identifying reward hyperlinks important rl spiders related text better task quickly able find paths research hyperlinks spidering task 
applications benefit cient spidering require retrieval fraction topic documents venture say related better choice neighborhood text full page 
attempting learn optimal domain specific definition neighborhood text potential area research 
examined results spidering runs explore workings internal engine classifier regressor 
analysis gives insight spidering performance leads interesting experiments 
classification accuracy underlying classifier rl immediate bin classifier generally better rl bin better classification accuracy rl bin spider bin rl immediate averages accuracy bin bin average respectively 
accuracy directly tie spidering performance bin performs bin hint added complexity classification problem bins benefits bins increased di culty order spidering performance benefits 
interestingly considers bin classification task bin rl spider mapping labels rl spiders labels rl immediate spider achieves increased classification accuracy 
bin rl classifier bin task achieve accuracy 
bin classifier achieve accuracy 
compared rate achieved bin classifier 
conjecture increased accuracy bin task may increase spidering performance 
table spidering performance webkb data 
spider pct links followed optimal rl bins rl bins rl bins rl immediate breadth turn webkb data set reward sparse expect reward important 
table shows results di erent spiders webkb data 
hoped spider uses distinctions reward achieves best results far 
average bin rl spider able locate cer page traversing hyperlinks 
twice cient rl immediate follows average hyperlinks locating target page 
contrast breadthfirst follows average hyperlinks finding page 
note bin classifier performs better bin 
tradeo flexibility classifier regressor classification accuracy 
experiments bin classifier result worse performance roughly equivalent rl immediate spider average available hyperlinks locating target page 
better features methods improving classifier accuracy shrinkage mccallum allow sensitive multi bin classifier better 
order provide window successful bin classification value function table shows predictive words class ranked weighted log odds ratio bin rl spider column top immediate refers class containing immediate rewards column bottom refers class representing amount reward 
parenthesized label indicates part hyperlink neighborhood aerial beckman burr brown names data 
table predictive words rl bins immediate board url url information url executive link directors link team link beckman url board link url management link step url url bb link head annual url annual head link report head near inside url step applications url url aerial head employment url burr head position head brown head open head sales url administration head clp url near elk url region head doc url near elk head near datasheet url sl url word note predictive words immediate class directly relevant page lists directors 
induce class annual reports pages commonly include hyperlinks listing 
step class includes words concerning employment product releases 
common include link annual report pages 
point described experiments classifier regressor built partitioning hyperlink values 
semantics hyperlink neighborhood text necessarily correspond hyperlink value 
may advantageous build classifier regressor classes textual semantics 
achieve set classes statistical clustering url refers text url 
head indicates header title words 
link refers anchor text 
near indicates text shortly hyperlink 
methods described hofmann puzicha believe modification vastly improve classification accuracy result improve spidering performance 
related studies researched spidering framework defining optimal behavior 
arachnid menczer system uses collection agents finding information web 
agent competes limited computational resources mutating proportionally success finding relevant documents 
information gathering experiments demonstrated encyclopedia britannica tree synthetic data 
contrast spider roots optimal decision theory searches unstructured pages real web 
cho introduce heuristic metric pagerank valuing web page linkage properties 
show pagerank ective spidering metric locating pages high pagerank counts back link counts 
metrics perform poorly task locate pages relevant particular topic query 
research focuses exactly aspect creating framework locate web documents related particular topic 
additionally systems reinforcement learning non spidering web tasks 
webwatcher joachims browsing assistant helps user find information recommending hyperlinks choose 
restricts action space hyperlinks current page 
webwatcher uses combination supervised reinforcement learning learn value word hyperlink 
user centric strives find method learning optimal decision policy locating relevant documents hyperlink selection unlimited 
laser boyan search engine automatically optimizes number parameters achieve improved retrieval performance 
cmu cs web test bed evaluation user selection links laser 
finds incorporating html markup tfidf weighting scheme improves retrieval performance 
utilizing markup may ective improving spidering performance 
results provide strong evidence reinforcement learning excellent framework perform web spidering 
experimental results data sets show fold improvement spidering ciency traditional breadth search 
find modeling reward particularly important reward sparse 
occurs important problem classes spider trying locate proportionately small number target pages large web graph webkb spider half run target pages cora 
cases explicitly modeling reward provides fold increase ciency 
areas mentioned 
particular currently improving classifier accuracy rl performs immediate spider cases dense immediate rewards 
additionally plan investigate value function criteria relax current assumptions 
kamal nigam seymore mark craven insightful discussions feedback earlier drafts 
bellman bellman 
dynamic programming 
princeton university press princeton nj 
boyan justin boyan dayne freitag thorsten joachims 
machine learning architecture optimizing web search engines 
aaai workshop internet information systems 
cho cho hector garcia molina lawrence page 
cient crawling url ordering 
computer networks isdn systems www volume 
craven mark craven dan dipasquo dayne freitag andrew mccallum tom mitchell kamal nigam sean slattery 
learning extract symbolic knowledge world wide web 
proceedings th national conference artificial intelligence aaai 
hofmann puzicha thomas hofmann jan puzicha 
statistical models occurrence data 
technical report ai memo artificial intelligence laboratory mit february 
joachims joachims freitag mitchell 
webwatcher tour guide world wide web 
proceedings ijcai 
kaelbling leslie pack kaelbling michael littman andrew moore 
reinforcement learning survey 
journal artificial intelligence research pages may 
lewis david lewis 
naive bayes independence assumption information retrieval 
ecml 
mccallum nigam andrew mccallum kamal nigam 
comparison event models naive bayes text classification 
aaai workshop learning text categorization 
www cs cmu edu mccallum 
mccallum andrew mccallum ronald rosenfeld tom mitchell andrew ng 
improving text shrinkage hierarchy classes 
icml pages 
mccallum andrew mccallum kamal nigam jason rennie seymore 
building domain specific search engines machine learning techniques 
aaai spring symposium intelligent agents cyberspace 
www cs cmu edu mccallum 
menczer menczer 
arachnid adaptive retrieval agents choosing heuristic neighborhoods information discovery 
icml 
mitchell tom mitchell 
machine learning 
mcgraw hill new york 
gama luis joao gama 
regression classification algorithms 
intelligent data analysis 
