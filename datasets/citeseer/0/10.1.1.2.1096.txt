remembrance streams past overload sensitive management archived streams chandrasekaran eecs department uc berkeley cs berkeley edu studies data stream management systems combine real time data streams historical data access incoming streams archived data simultaneously 
significant problem systems cost fetching historical data inhibits processing live data streams 
solution reduce cost accessing archive retrieving reduced summarized sampled version historical data 
propose new summarization sampling techniques framework multiple resolutions summarization sampling generated efficiently 
query engine select appropriate level summarization depending resources currently available 
central research problem studied generate multiple representations archived data eagerly data arrival lazily query time hybrid fashion 
concrete techniques approach tied specific data reduction technique random sampling 
tradeoffs approaches studied analytically experimentally 

queries posed data stream management system dsms distinguished classes see :10.1.1.11.8839
consists queries archived disk data system query posed 
traditional database literature largely focused supporting historical queries 
second class consists queries live network data enters system query posed 
live queries subject research continuous query cq processing 
cq engines traditional databases adequately addressed problem supporting queries access combination funded part nsf itr iis si ibm faculty partnership award program research funds intel microsoft uc micro program 
permission copy fee part material granted provided copies distributed direct commercial advantage vldb copyright notice title publication date appear notice copying permission large data base endowment 
copy republish requires fee special permission endowment proceedings th vldb conference toronto canada michael franklin eecs department uc berkeley franklin cs berkeley edu disk live data 
third class hybrid queries focus 
representative examples hybrid queries scenario freeway embedded sensors record information passing cars 
query load freeway single stream query accesses window data begins history continues perform running count increase number cars ashby exit bay bridge rush hour 
compute value fifteen minutes till rush hour query join query live data combined different portions history cars observed pass ashby exit choose seen exit hour day week 
count total numbers match condition today number hybrid queries accessing different portions archive increases number random disk accesses 
dramatic improvements computation power network bandwidth witnessed cost interleaving random disk accesses processing live network data substantial 
costs effect ability query processor run multiple hybrid queries cause fall increasingly processing live data 
dsms design query classification tempting reuse solutions developed traditional dbmss cq engines address problem approaches developed systems handle overload inapplicable inadequate workloads hybrid queries 
historical queries typically real time near real time requirements allowing traditional databases option postponing computation case overload data warehousing 
possible hybrid engine query processing coupled arrival live data 
suspending query causes fall live data 
applications time sufficiently reduced load execute postponed queries 
indexing techniques combined batched support fast simultaneous inserts reads historical data 
correct index available query pushes away point system overloaded address happens 
admission control network called hand proposed cq engines way directly deal overload 
dropping network data unsuitable solution hybrid query workloads reasons 
disk access significant bottleneck hybrid query workloads processing network data 
dropping network data confront root problem 
second importantly dropped network data lost forever unavailable hybrid queries 
key immediately precisely addressing overload hybrid query processor retrieve reduced version data disk 
wealth literature exists area data reduction henceforth abbreviated dr including sampling summarization aggregates histograms compression 
propose new dr method focuses architectural issues allowing dsms exploit variety pre existing techniques handle overload 
particular concentrate efforts designing mechanisms storage system generate multiple resolutions data reduced random sampling windowed aggregation 
query engine select appropriate level summarization depending resources currently available 
focusing solution architectural issues concerning storage system dr methods query engine allow dsms considerable flexibility handling overload 
example query engine employ various responses overload ranging constant rate data reduction reduction live data age historical data 
dsms free applications varying degrees information fidelity results ranging sophisticated statistical guarantees 
solution ft view section abstraction design hybrid query processing engine point portions system modify handle overload 
shows principal components hybrid query engine network interface executor disk 
network interface reads data network responsible making data directly available executor writing disk 
queries run executor access live data directly network interface historical data disk 
order handle disk overload modifications system 
disk accesses reads writes controlled special access method called overload sensitive stream capture archive reduction access method oscar 
oscar organizes data disk fashion possible trade os quality data scanned 
example oscar store multiple versions stream disk version representing different choice trade quality size data 
oscar access method scan appropriate version query time 
second modification system informing oscar degree data reduction desired query scans historical data 
require queries associate scan module historical data reduction user defined function udfs 
data scanned disk passes scan module leaf query plan udf communicates back oscar degree data reduction required 
oscar uses feedback control quality data returned scan 
focus design handling udfs random sampling windowed aggregation 
supporting classes udfs subject discussed section 
solution ft view contributions section summarize contributions 
contribution identification disk overload key problem support hybrid queries simultaneously access disk network data accompanying observation load shedding unsuitable solution address problem 
second propose overload sensitive stream capture archive reduction oscar access method interface variety user defined data reduction functions udfs retrieve reduced versions archive correspondingly fewer os 
third concrete oscar designs udfs random sampling windowed aggregation 
designs differ perform generating multiple resolutions archived data 
describe implementation oscar designs udfs random sampling telegraphcq 
tradeoffs designs studied analytically experimentally emphasis effects real file system operating system behavior solutions 
rest organized follows 
section discuss related 
section describe oscar udfs interaction detail example 
section different oscar designs udfs sampling windowed aggregation 
section describe implementation mechanisms sampling dr schemes telegraphcq 
section demonstrates compares performance benefits various storage schemes 
discuss section conclude section 
related data reduction admission control optimized disk access areas extensively research database community 
section discuss representative relevant discussing applicability overload hybrid query workloads 
cover related applied problem disk overload 
converting random sequential important area related literature fast inserts reads traditional databases 
saving random os key theme database systems research goal avoiding random os favor sequential led proposal various extent storage systems 
indexes effectively reduce random data clustered 
difficult ensure clustered organization data presence continually growing streams batching writes live data disk offers approximation 
approaches reduce impact disk accesses suffer shortcomings 
solutions require periodic reorganization disk order batches coalesce larger ones 
second feasible maintain indexes attribute stream queries known ahead time indexes maintained system inefficient query hand 
approaches increase extent system scale address problem overload delay problem 
postponing query processing time lower load works situations involving historical queries typically real time near real time requirements 
traditional database option postponing computation case overload example business day 
examples seen data warehousing 
option hybrid engine query processing coupled arrival live data 
suspending query causes fall live data 
high data rate applications unclear periods lower load 
shed load network cq engines archive revisit stream data admission control network pipe proposed dealing overload 
stated previously solution suited hybrid query workloads reasons 
workloads involving hybrid queries disk access significant bottleneck main memory processing live data dropping data network pipe directly address current cause overload disk access 
second importantly data dropped network lost queried hybrid queries 
data reduction dr wealth literature proposing different dr techniques 
aims complement efforts providing framework techniques plugged dsms 
techniques require special modifications executor restrict focus sampling windowed aggregation 
techniques dual advantage requiring simpler enhancements executor allowing range application specific responses problem overload 
previous looked ways store data disk multiple resolutions order tradeoff disk os accuracy 
share goals attempting define architectural solution encompass wider range dr techniques extension queries 

solution ft view section expand overview solution section revealing detail oscar udf 
shows solution specific disk organization udf 
oscar discuss important component solution overload sensitive stream capture archive reduction access method oscar 
oscar organizes data disk fashion allows reduced versions retrieved order save os 
data ideally retrievable reduction level matching savings os practice finite number reduction levels oscar provide exactly matching savings 
levels 
disk logically appears additional copies stream containing original data respectively 
actual content disk invisible executor shall show section example logical view physically implemented copies stream disk 
ft view solution order organize data disk allow access multiple levels reduction oscar controls disk accesses network interface executor 
perform modifications archive eagerly network interface calls insert method write incoming data disk lazily executor subsequently calls read method 
different approaches perform data arrival time query time split phases 
show approach chosen influences physical implementation logical view disk 
reduction udf second important part solution udfs 
physical scan historical data associated udf notifies oscar degree reduction required 
udf piece user code takes data scanned disk continuously returns values representing degree reduction desired scan 
example udf performs random sampling returns value indicates fraction data dropped scan 
implement windowed aggregation udf returns time interval indicates size window aggregation performed 
udf shown uniform random sampler returns drops data passing 
udf considerably sophisticated 
example age udf determine reduction level age tuples section archive scanned demand increasingly higher fidelity data 
udf determine level reduction current load system 
udf maintain internal state tuples seen perform sophisticated statistical analyses desired approximation levels output control 
putting hybrid live historical query specified associating archived stream clause query udfs registered system 
example scan module archived stream associated uniform random sampler drops input 
level reduction specified udf equal levels reduction oscar directly satisfy 
oscar best reads copy reduction 
save os scan module choose drop data wishes achieve original target reduction original 

oscar access method section various oscar designs support udfs sampling windowed aggregation 
section discuss actual implementation different sampling udfs telegraphcq 
oscar designs random sampling section different oscar designs enable variety sampling udfs reduce overload caused disk accesses hybrid query engine 
shown solutions perform actions different points system eager data driven mechanism performing data arrival 
lazily modifying archive query time 
random method splits data arrival query execution 
different mechanisms sampling dr eager approach discuss eager data driven approach exploits fact random disk os expensive disk space 
action method keep non reduced copy stream disk 
copy referred primary 
addition set copies increasing levels reduction 
number levels reduction copies specified time stream created changed time 
oscar writes copy incoming data primary randomly sampling data different pre determined levels populate various copies 
executor scans tuples continuously feeds values returned udf back oscar 
oscar uses values continuously identify needed switch scan copy data granularity closest finer desired coarseness 
shows example technique action 
stream copy addition primary reduction level 
data arrival step oscar populates primary incoming data copy half data 
udf example specifies uniform sample rate reduction level 
query time step oscar reads data copy primary 
note reduces os 
scan module drop data scanned copy achieve desired reduction original 
lazy approach section discuss lazy query driven technique performs executor 
way design method maintain multiple copies stream pre determined levels populate demand 
solution problematic 
increases implementation complexity offering significant new insight cost trade offs respect eager solution 
understand increased implementation complexity consider shows approach action stream copies 
different hybrid queries caused different copies filled arbitrarily 
copy sequences extents tuples followed holes corresponding portions archive accessed hybrid queries 
arbitrary order holes filled potentially unknown sizes tuples fill longer simple heap file store copies extent storage structure copy stream 
effect eager filling pre defined copies database postgresql extent storage method requiring implemented scratch 
solution require managing data structure continuously directs scan smallest possible copy filling copies demand 
reasons developed solution uses simpler storage structure heap file original stream reduced copy 
resulting design different mirror eager solution 
describe solution case udf 
presence multiple udfs solution just repeated parallel multiple copies 
technique data arrival time oscar simply streams complete copy arriving data disk 
query time oscar randomly marks tuples scanned dead reduction rates returned udf 
tuples query plan 
periodic process copies remaining live tuples new location disk 
incoming tuples written original copy 
subsequent disk accesses different query udf directed new smaller copy incur fewer os 
result oscar marking tuples copy dead 
moving copy just tuples copy compacts place 
reduction level portion copy low new query udf new query switches scanning original modifications archive 
fraction accesses switch original crosses preset threshold copy deleted process repeated 
illustrates approach 
step oscar writes data disk 
query time step assume sampling udf requires reduction data 
tuples marked dead original 
step copies remaining live tuples new location disk 
query shown step uses udf stream 
time udf requests reduction original data 
satisfied entirely scanning copy 
removed original data constructing copy 
retrieve current copy 
remaining tuples purged copy subsequent pass 
action hybrid approach solutions described previous sections perform significant amounts data arrival order enable sampled access disk data 
depending query data workloads exacerbate degree overload 
method discuss section fixes problem spreading burden phases improving performance reads writes 
technique single copy stream disk divided separate runs batches run corresponding fixed number blocks 
data source writes arriving tuples uniformly random blocks current run 
blocks current run fills entire set blocks run flushed disk new run created inserting new tuples 
query time oscar begins scan new run blocks uses latest value returned udf read corresponding fraction blocks new run 
tuples block sorted timestamp merge sort employed retrieve original order tuples different blocks run 
action shows example technique action 
stream defined runs size blocks assume tuple block ease visualization 
udf specifies level reduction 
oscar reads exactly block run 
comparison solutions having discussed basic algorithms briefly compare analytically 
section compare experimentally 
table summarizes analytically computed costs oscar designs strawman performs sampling executor modify archive saves os 
seen maintains original data fact pays higher insertion cost maintaining extra copies hope saving os query time 
pays low cost read 
hand performs time scans archive 
original write costs subsequent read costs restricted minimum possible 
require additional 
fact removes tuples copy asset 
solution modified allow purge tuples original limit size archive 
hybrid solution low write read costs os write time solution os read time close minimum possible os 
analytical plots order better visualize formulae table analytically compute plot write read rates various oscar designs 
parametrize eager hybrid oscar designs follows 
assume copies addition original stream reduction levels 
determines function table 
hybrid solution assume run length blocks 
determine values parameters analytical formulae ran tests implementation oscar telegraphcq 
measured size disk stream strawman described containing tuples blocks bytes 
size index entry bytes approximate zero 
blocks 
measured time took populate strawman tuples seconds 
parameters displays generated plot shows analytically computed time mechanism replicate modify randomize time seconds cost writes cost reads copy copy eager lazy lazy storage design hybrid strawman time insert tuples ran count query entire strawman archive took seconds 
measurement computed time take query data different values reduction level different oscar designs 
shows plot generated values 
second reads lazy design assumed occur vacuuming 
order st read nd read post vac strawman blocks stream ar min reduction level tuples size index entry size block run length copies stream different oscar designs write stream 
seen hybrid solution pays cost strawman requiring little data insertion time 
lazy solution takes time strawman hybrid solution prior vacuuming 
contains additional copy receives incoming data doubling write cost 
eager solution computed take time sum sizes copies twice size original stream 
cost writing stream eager solution strawman 
th block min reduction level tuples th run reduction level copies closest table costs storage mechanisms reduce visual clutter group designs similar identical performance 
performance strawman independent reduction level 
seen query pays high price modify lazy solution 
second query performs strawman 
vacuuming lazy solution matches hybrid solution best possible performance 
cost eager solution step function solution offer savings commensurate granularities pre stored copies 
lower cost pre vacuuming lazy solution 
comparable slightly higher cost relative post vacuum version lazy solution 
time seconds eager lazy st read lazy nd read straw man lazy post vacuum hybrid reduction level time query tuples different reduction levels analysis performance system write reads occur simultaneously follows 
disk bottleneck available disk bandwidth queries insertion process rate access disk 
total time insertion increase proportion number disk accesses queries rate 
shall see section reality quite different disk elevator algorithm linux ext file system removes contention writes reads guaranteeing minimum latency 
operation system unfairly schedules write process realize queries performing sequential analysis hybrid oscar design emerges best solution offers low insert reduces os exactly rate demanded udf 
windowed aggregation section described storage schemes udfs 
section discuss mechanism supporting summary techniques grouped averages 
propose solutions similar lazy modify eager methods described section 
techniques storing multiple copies data different degrees summarization 
main difference sampling decisions reduction tuple basis 
observation leads key insight supporting windowed aggregation udfs case abstracted away query window tuples summarized 
results query written replicas 
drive rest discussion example udf stream stock ticker data 
example windowed aggregation udf hour data return tuple distinct stock symbol containing average value symbol hour 
udf tumbling window grouped average query 
eager approach oscar writes complete copy data disk reduced versions data 
number versions specified stream creation time windowed aggregation queries populate 
copies added removed time 
example consider stock ticker udf 
assume stream created additional copies copy stores hourly averages copy daily averages stock data grouped symbol 
oscar writes individual records master copy stream disk 
addition populates additional copies triggered historical queries tumbling window continuous queries 
trigger approach requires purely historical copy copies populated 
copy populated grouped average query triggered hour executes previous hour data 
copy populated similar query triggered day 
cq approach hand permanently running grouped average continuous queries window hour window day 
case new query uses udf described requires hourly averages scan copy reduce overload 
lazy approach single copy complete data disk additional reduced copy udf 
data arrival oscar simply writes complete data disk 
query time data scanned disk passed query udf 
result dr query passed user query 
results written back disk new temporary location disk 
tuples encoded information time window corresponds 
process combine data original tuples temp location create new copy replacing original tuples scanned udf summarized version temp copy 
queries access new copy 
modifications copy place 
case reduction level copy low certain query case original scanned 
summary design eager lazy oscar mechanisms udfs windowed aggregation essentially random sampling 
differ details accommodate different properties input output udfs 

implementation telegraphcq implemented oscar designs udfs telegraphcq cq extension postgresql 
implementation closely follows description section describe experiences specific building telegraphcq postgresql 
rest section discuss implementation hybrid queries telegraphcq custom free space map built modify implementation stream copies special tuple format 
running hybrid queries telegraphcq describe changes telegraphcq run hybrid queries 
include addition access method retrieves archived streams modifications symmetric join operator allow executor combine network disk data properly 
access method underlying oscar consists append heap file clustered timestamp sparse btree timestamp attribute 
design allows efficient archiving scans hybrid queries 
streaming systems assume incoming streams timestamp order modulo maximum finite skew handled reorder buffer 
append timestamp clustered heap file allows efficient inserts 
hybrid queries shown section require access increasing timestamp order tuples timestamp greater certain historical value 
btree efficiently locate starting point sequential scan heap file retrieve tuples 
second change telegraphcq support hybrid queries executor uses eddy stems implement main memory symmetric joins 
telegraphcq supports sliding window band joins stems maintain limited main memory window input stream 
order extend mechanism disk data force eddy coordinate rate data access network disk queries access network disk 
prevents disk scan rate arrival live data periods low data arrival rate 
changes postgresql discuss implementation details relating postgresql components data structures 
postgresql vacuum modes inapplicable streaming scenario implement scratch 
full vacuuming mode requires lock entire relation 
clearly unsuitable unbounded streams blocks read write accesses stream potentially unbounded time 
full destroys original ordering tuples compaction relation heap files 
matter relations care preserving ordering tuples stream timestamp described section 
vacuum mode called lazy compact relation removes dead tuples place 
heap file save os scans 
vacuum mode performs index maintenance postgresql removes index entries tuples soon marked dead executor 
index deletion operation performed postgresql expensive invoking fast path query time executor severely impacts performance system 
move index maintenance 
free space map key data structure implementing vacuuming free space map fsm records available space page 
postgresql free space map soft state worse possibly stale 
implement free space map uses fast judy arrays record stream pages atleast dead tuple need processed free space available page determine pages compact 
miscellaneous implementation details stream copies multi copy streams lazy eager solutions implemented straightforward manner 
copy stored append heap file index timestamp attribute described section 
creation destruction write read calls stream conducted wrapper functions responsible managing copies 
tuple format discuss unique tuple attribute requirements 
recall section copy stream exist uniform level reduction 
different portions stream reduced different levels run time reduction levels demanded udf 
allow oscar decide copy satisfy certain query add implicit attribute tuple stream called indicates level reduction tuple 
overhead byte header telegraphcq tuple reduced sample tuples block rate store granularity disk block header 

performance section test central thesis reducing os disk scans essential tool hybrid engines wish support high insert rates presence numerous hybrid queries 
describe setup experiments section 
section examine insertion times different oscar designs sampling udfs absence queries 
section look query times schemes absence concurrent insertions 
section study performance simultaneous queries data archiving 
summarize results section 
experimental setup section explain data query workload describe hardware software environment experiments 
data query workloads addition oscar designs described sampling udfs measure performance strawman sampling takes place executor 
tried variants hybrid solution run lengths blocks respectively 
solution replicated original stream additional copies reduction levels 
referred eager lazy hybrid plot legends 
suffixes indicate different states parametrizations eager hybrid solutions 
describe tuples populate streams queries 
input data strawman eager hybrid oscar designs input tuples schema float timestamp int dummy attribute 
explained section input tuples additional attribute type float 
value attribute set entry indicating data 
timestamp attribute tuples streams set network interface time entry 
queries experiments focus oscar executor simple count landmark queries query section hybrid join queries query section 
shall see section behavior os affects processing live data way applicable join queries 
execution environment machine os experiments run linux box kernel mhz pentium iii processor kb cache size 
machine mb ram gb swap space 
underlying file system ext 
seagate cheetah es disk scsi ultra interface dedicated experiments 
response time disk ms peak data transfer rate mbps internal buffer mb 
observed raw throughput file system lower mbps 
postgresql settings initialized postgresql buffer pool frames 
size frame disk pages bytes 
buffer replacement policy lru 
modified invoked demand execute periodically 
allows generate repeatable observations 
disabled logging access disk store database 
acceptable real systems write log records separate disk 
inserting archive section experiment measures insertion performance streams oscar designs strawman 
perform test measured time took insert tuples stream oscar design 
data generated online program piped data 
total overhead generated data generator half second negligible 
insertion tuples flush buffer pool sync filesystem buffers ensure measure complete cost write disk relation 
time seconds storage design eager lazy pre vac lazy post vac hybrid hybrid hybrid strawman insertion times tuples shows time taken insert data various schemes 
solutions marked hybrid legend write stream rate strawman 
slight differences attributed different amounts wasted space different runs streams 
run size increases wasted space increasing size stream written disk 
lazy plot little slower strawman hybrid solutions extra attribute results increased total os 
tuple payload increases overhead disappear approach performance strawman 
cost replication eager sub linear total size original stream copies 
due amortization overhead processing wrapper clearing house 
results strawman better eager lazy oscar designs 
shall see section strawman performs poorly query time overload overload oscar intended solve 
terms absolute bandwidth insertion rates lower supported disk 
network interface bottleneck disk 
shall see shortly multiple queries disk accesses rapidly problem 
querying archive section experiment measures time taken count query entire archive oscar designs strawman 
repeat test different reduction levels study response different designs overload 
shows results experiment 
strawman uniformly takes seconds scans number blocks irrespective reduction level 
size tuple bytes strawman runs near peak mbps disk bandwidth available application level 
reduction levels query stream lazy st read plot greatest cost schemes 
pays write cost addition read cost buffers 
reduction method continues pay twice cost strawman tuple page 
second pass stream write cost paid cost solution drops strawman 
vacuuming performed copy smaller original fraction equal reduction level 
cost subsequent scans drop dramatically fraction 
eager lazy st read lazy nd read lazy post vac hybrid hybrid hybrid strawman time seconds reduction level query time different reduction levels cost query design drops reduction level 
slightly expensive post vacuuming version method reduce os granularities pre stored copies 
different hybrid alternatives offer interesting results 
earlier theoretical analysis expect hybrid solutions improving query times reduction level increases 
improvement realized hybrid design run length 
reduction levels hybrid shows improvement performance 
hybrid better strawman 
reason pre fetching buffering file system 
hybrid design run length low reduction levels hybrid blocks read close disk file system ends performing sequential read picking exactly required blocks 
result cases hybrid solution performs better strawman 
putting insertions queries section test central hypothesis disk accesses significant impact insertion process hybrid stream query processor 
conduct test measure time taken insert tuples stream presence simultaneous count queries streams previously tuples inserted 
vary measure effect increasing number simultaneous queries 
query rates higher insertion rates see sections queries complete insertions completed 
maintain constant number simultaneous queries start new query stream previous completes 
measuring insertion rate tell insertion performance artificially inflated queries scheduled 
readings measure corresponding number queries completed time took insert tuples 
figures show measurements reduction measured values reduction levels trends similar 
figures show insertion time total queries completed time varying number simultaneous queries reduction 
show corresponding figures reduction 
analyze figures 
absence archived queries strawman populate stream seconds 
increase number queries insertion time increases reach archived queries stabilizes seconds 
looking corresponding numbers see total number completed queries increases single query queries stabilizes 
number increase decrease significantly increasing number simultaneous queries 
pattern observed oscar designs 
curious phenomenon explained looking disk elevator algorithm system 
algorithm sets separate latency limits reads writes 
means hybrid queries affect write process certain limit 
initially insertion process see section 
increasing number queries disk bandwidth available insertion process reduces reducing performance 
disk subsystem saturated reads write process affected 
write throughput stays constant certain number simultaneous queries 
read bandwidth shared concurrent queries matter total number completed queries stays fixed 
figures suggest strawman total number simultaneous queries increased past early system run rate data arrival 
queries running rate single query able reach completion time takes insert tuples 
represents bound number simultaneous hybrid queries system starts fall 
stream lazy figures performs marginally poorer strawman solution prior vacuuming respect insertion times number completed scans 
sizes tuples larger solutions explained section 
real savings mechanism kicks stream 
size archive reduced quarter total number completed scans increases correspondingly 
overhead network interface amortized original new copy write performance lazy solution largely unaffected pre vacuum version 
method eager higher insertion times expected 
cost extra writes sub linear size stream increase insertion time significant 
number completed queries post time seconds eager lazy pre vac lazy post vac hybrid hybrid hybrid straw man number simultaneous queries insertion time tuples reduction queries completed number simultaneous queries queries completed tuples insertion reduction queries seconds reduction level queries completed sec simultaneous queries lazy solution 
slightly lower solution offer performance improvement steps reduction levels pre stored copies 
hybrid solutions insert performance approximately strawman 
query time hybrid solutions display interesting behavior 
explained section reduction hybrid hybrid essentially performing sequential scans pre fetching buffering file system 
performance numbers similar strawman 
hybrid hand save physical os leading higher queries completed 
look figures 
show insertion time number queries completed reduction 
insertion rates largely mentioned effect disk scheduler 
note scale different number completed queries increases slightly straw time seconds eager lazy pre vac lazy post vac hybrid hybrid hybrid straw man number simultaneous queries insertion time tuples reduction queries completed number simultaneous queries queries completed tuples insertion reduction queries seconds reduction level queries completed sec simultaneous queries man actions independent reduction level 
slight increase corresponds available bandwidth till disk saturates 
true modify solution 
post vacuum version significantly higher completed queries greater reduction level 
eager version slightly better tracks reduction level exactly eager solution offers reduction preset rates 
hybrid design offers interesting results 
reduction hybrid continues perform sequential scan reads contiguous blocks 
hybrid reading fewer blocks 
showing improved performance number completed queries decreases 
reason lies os process scheduler 
os guesses query performing sequential system happens blocks accessed tively blocks apart gets scheduled 
number physical os saved hybrid sufficient overcome scheduling bias 
hybrid save physical os skips blocks time completed queries compared reduction 
ran tests reduction levels 
figures note log scale axis give flavor results showing number queries completed seconds different reduction levels 
eager solution stops providing improved performance reduction level smallest copy 
lazy solution hybrid continue support queries greater reduction levels 
summary results section summarize results performance study 
behavior file system prevents directly proving central hypothesis processing live data suffers increasing number hybrid live historical queries 
hand results shown figures demonstrate performance benefits different oscar designs hybrid queries presence overload 
strawman samples executor excellent write performance poorly overloaded 
oscar designs hybrid solution offers benefit 
low write costs offers excellent savings different reduction levels provided run length suitably large prevent interference file system os process scheduler 
lazy approach better response overload hybrid solution 
eager solution performs long desired reduction levels close pre stored copies 
performance results underscore additional important point os kernel various policies tremendous effect benefits lack thereof storage level solutions 
example pre fetching buffering file system os process scheduler cause hybrid oscar design show widely different behavior depending size runs 
global level disk scheduling algorithm platform experiments limited interference read write accesses disk 

interesting done area supporting hybrid stream queries 
avenue area overload handling extension framework include classes data reduction 
provide overload handling index access methods just oscar scan disk access 
currently engaged studying framework making run time decisions indexes updated data arrival handling resulting holes indexes get built 
challenges hybrid query include intelligent buffer management exploit predictable access patterns longrunning windowed queries 
current techniques shared computation stream queries rely queries processing tuple time 
possible hybrid queries access different portions archive new needed 

random disk accesses dsms processes hybrid queries detrimental effect performance system 
sufficiently high load system fall processing stream 
propose systems support means deliver reduced versions historical data queries ease disk load system 
propose overload sensitive stream capture data reduction oscar access method achieve 
discuss different designs oscar handle data reduction random sampling windowed aggregation 
describe implementation telegraphcq doing experimental results validating thesis 

carney monitoring streams new class data management applications vldb madden continuously adaptive continuous queries sig mod motwani query processing approximation resource management data stream management system 
cidr 
tatbul load shedding data stream manager vldb 
chandrasekaran telegraphcq continuous dataflow processing uncertain world 
cidr 
telegraphcq source code telegraph cs berkeley edu judy arrays sourceforge project judy sourceforge net mehrotra 
progressive approximate aggregate queries multi tree structure 
sigmod 
design implementation logstructured file system acm tocs manku motwani approximate frequency counts data streams vldb 
efficient dr methods line association rule discovery 
read multi resolution relational data model 
vldb chaudhuri dayal overview data warehousing olap technology 
sigmod record zsu issues data stream management 
sig mod record muth 
log structured history data access method 
vldb overmars design dynamic data structures 
lncs barbara new jersey data reduction report 
data engineering bulletin september hellerstein informix control online query processing 
data min 
knowl 
discov 
raman state modules adaptive query processing 
icde 
chen niagaracq scalable continuous query system internet databases 
sigmod 
chandrasekaran franklin 
streaming queries streaming data 
vldb 
