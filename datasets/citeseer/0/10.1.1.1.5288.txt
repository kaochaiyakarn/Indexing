interactive deduplication active learning sunita sarawagi sunita iitb ac iit bombay deduplication key operation integrating data multiple sources 
main challenge task designing function resolve pair records refer entity spite various data inconsistencies 
existing systems hand coded functions 
way overcome tedium hand coding train classifier distinguish duplicates non duplicates 
success method critically hinges able provide covering challenging set training pairs bring subtlety deduplication function 
non trivial requires manually searching various data inconsistencies records spread apart large lists 
design learning deduplication system uses novel method interactively discovering challenging training pairs active learning 
experiments real life datasets show active learning significantly reduces number instances needed achieve high accuracy 
investigate various design issues arise building system provide interactive response fast convergence interpretable output 
crucial step integrating data multiple sources detecting eliminating duplicate records refer entity 
process called deduplication 
large customer oriented organizations merge long lists names addresses partially overlapping sets customers 
area deduplication necessary construction web portals integrate data various pages possibly created distributed manner millions people 
examples portals citeseer cora integrate citations titles parsed extracted personal publisher webpages :10.1.1.17.1607
main challenge task finding function resolve records refer entity spite errors inconsistencies data 
motivate difficulty manually designing deduplication function examples bibliography domain 
illustrative example citations illustration citeseer citation database citeseer 
nj nec com cs 
entries show duplicates permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
sigkdd edmonton alberta canada copyright acm 
anu iitb ac iit bombay examples ones escaped detection citeseer manually tuned deduplication function :10.1.1.17.1607:10.1.1.17.1607
domain knowledge know citations duplicates author title year published fields match 
citations come large spectrum formats making specific codification knowledge difficult 
show example duplicate citations book just groups citations book citeseer collapse duplicates breiman friedman stone 
classification regression 
wadsworth belmont ca 
leo breiman jerome friedman richard olshen charles stone 
classification regression trees 
wadsworth brooks cole 
example brings non triviality author match 
individual author names multi author list hard separate orders names reversed names missing abbreviated 
matching conference names get tricky seen duplicates agrawal srikant 
fast algorithms mining association rules large databases 
vldb 
rakesh agrawal ramakrishnan srikant 
fast algorithms mining association rules proc 
th int conference large databases santiago chile september 
vldb straightforward abbreviation booktitle second citation 
year field errors commonplace citation appear 
difficulty lack explicit structure input data sources 
citations come segmented author title conference fields 
typically automated program segmentation 
program perfect job introducing kind inconsistency 
natural approach forget matching individual entries simply attempt count number common words 
example show citations duplicates large number common words 
balakrishnan seshan katz improving reliable transport handoff performance cellular wireless networks acm wireless networks december 
balakrishnan seshan amir katz improving tcp ip performance wireless obtained searching citations keyword breiman citeseer citeseer nj nec com cs breiman submit search citations cs networks proc 
st acm conf 
mobile computing networking november 
contrast citations duplicates spite having significantly fewer common words title 
johnson laird philip 

mental models 
cambridge mass harvard university press 
johnson laird 
mental models cognitive science language inference consciousness 
cambridge university press 
state art existing systems deduplication hand coded rules compute extent match individual attributes combine match scores thresholds conditions 
way reducing tedium hand coding relegate task finding deduplication function machine learning algorithm :10.1.1.39.4336:10.1.1.39.5567
algorithm takes input training examples consisting pairs duplicates non duplicates 
second input collection various kinds simple domain specific matching functions various attributes provided domain expert 
learning algorithm examples automatically find best way combining thresholding attribute similarity scores 
limitations learning approach success learning method crucially hinges able provide covering challenging set duplicates non duplicates bring subtlety deduplication function 
finding examples hard requires user manually quadratic search large records lists confusing record pairs spread far apart 
surprisingly harder finding interesting set non duplicates confused duplicates existing training set 
non duplicates abound hard find effectively counter simple minded deduplication function inferred existing training set 
contribution designed learning deduplication system alias allows automatic construction deduplication function novel method interactively discovering challenging training pairs 
key insight simultaneously build redundant functions exploit disagreement discover new kinds inconsistencies duplicates dataset 
active learning methods rely similar insight selecting instances labeling large pool unlabeled instances :10.1.1.20.8521:10.1.1.119.2797
ordinary learner trains static training set active learner actively picks subsets instances labeled provide highest information gain learner 
approach difficult task bringing potentially confusing record pairs automated learner 
user perform easy task labeling selected pairs records duplicate 
designed active learning algorithm meet design goals interactive response fast convergence high accuracy 
system outputs active learning led interactive alias suppression deduplication function easy interpret efficient evaluate deployed large record lists 
required evaluating various non obvious design tradeoffs arise current active learning methods practical setting 
experiments real life datasets show approach reduces number labeled training pairs orders magnitude reach certain accuracy 
labeling pairs selected interactively system learnt deduplication function achieve peak accuracy randomly chosen set pairs achieve pairs 
outline main parts 
part section description alias interactive deduplication system 
second part starting section covers main novelty system mechanism selecting informative sets pairs foundations lie active learning 
section presents experimental evaluation effectiveness active learning easing deduplication task 
section discusses related 
appear section 
architecture shows design alias system deduplication 
primary inputs system 
database records original set records duplicates need detected 
data attributes 
ad textual numeric 
goal system find subset pairs cross product labeled duplicates 

initial training pairs optional small seed training records arranged pairs duplicates non duplicates 

similarity functions set nf functions computes similarity match records subset attributes 
examples functions edit distance soundex text fields absolute difference integer fields 
common functions added default data type 
impossible totally obviate expert domain knowledge designing specific matching functions 
functions coded native language system case loaded dynamically 
functions set highly redundant unrelated automated learner wil perform nontrivial task finding right way combining get final deduplication function 
rough outline main steps 
step map initial training records pair format mapper module 
mapper module takes input pair records computes nf similarity functions returns result new record nf attributes 
duplicate pair assign class label pairs assign class label 
step get mapped training dataset lp lp instances 
input 
create pairs lp labeled data 
create pairs dp unlabeled data 
initial training set lp 
loop user satisfaction train classifier select set instances dp labeling 
empty exit loop 
collect user feedback labels add remove dp 

output classifier design working alias interactive deduplication system 
initialize learning component system 
details component deferred section 
step map unlabeled record list mapper invoked pair records generate unlabeled list mapped records dp 
size large quadratic size cross product intolerable 
section discuss avoid proper indexing part dashed boundaries 
describe interactive active learning session dp user tutor 
learner chooses set dp subset user configurable parameter typically instances benefit labeling 
details deferred section 
user shown set instances current prediction learner 
user corrects mistakes learner 
newly labeled instances added training dataset lp active learner retrained 
user inspect trained classifier evaluate performance known test dataset 
happy learner trained far active learner select set instances 
process continues loop user happy learnt model 
iteration user aids learner providing new labeled data 
useful side effect user inspecting model prediction iteration discover newer sources discrepancies errors data decide modify similarity functions add new ones 
output system deduplication function new list records identify subset pairs cross product duplicates 
example sample deduplication function learnt decision tree shown section 
indexing component data set large quadratic size problematic need able provide interactive response user active learning 
support ways reducing number pairs generated 
grouping possible find easy grouping windowing function guaranteed bring duplicates 
examples grouping functions year publication citation entries letter name address lists 
pairs formed records group 
similar windowing ideas exploited :10.1.1.46.6676
sampling active learning phase learning deduplication function may need entire set records sampling appears natural recourse cases 
simple random sampling cases number duplicates sampling diminish duplicate pairs 
example records duplicate random sample data contain average just duplicates 
propose alternative grouped sampling approach hinges able find grouping function 
approach sample units group individual records 
indexing option support index fields predicates similarity function attribute evaluated efficiently 
example predicate similarity function form fraction common words text attributes evaluated efficiently creating inverted index words text attribute 
clearly done easily possible similarity functions 
edit distance example hard index similarity function 
cases possible approximate similarity function function equal predicate retrieves records transformed looser predicate form predicate evaluated index filtered exact match 
example show inverted index ngrams text field lower bound edit distance function :10.1.1.21.3112:10.1.1.14.5630
ideas earlier exploit similarity functions modify active learning mechanism described previous section takes input materialized pairs dp chooses subset labeling :10.1.1.34.4329
need modify require time 
possible design active learners output predicates characterize pairs selected learner 
predicates evaluated indices qualifying pairs materialized passed learner instances 
just rough outline approach 
space discuss topic 
defer details 
main focus study efficacy active learning deduplication 
learning component core learning component system classifier addition usual task training model examples predicting labels unknown instances needs support active learning discussed section 
need consider criteria choosing classifier accuracy interpretability training efficiency 
evaluate popular classification methods decision trees tree naive bayes nb support vector machines svms criteria 
accuracy classification problem particularly challenging deduplication datasets severely skewed class distribution fraction duplicate pairs non duplicates 
concern highly skewed data choosing appropriate metric evaluating classifiers 
accuracy misleading metric cases 
example case just duplicates trivial classifier labels pairs non duplicates yield accuracy classifier identifies duplicates correctly misclassifies non duplicates 
choose metrics evaluation recall precision 
recall fraction duplicates correctly classified precision fraction correct instances labeled duplicate 
ideally evaluate methods recall precision separately single metric combine universally acceptable single number 
need single number ease plotting 
known measure information retrieval community called measure harmonic mean precision recall values pr 
case value recall 
second case 

measure considered weighted accuracy weighted accuracy yield high values accuracy precision extremely poor 
example duplicates non duplicates classifier confusion matrix weighted accuracy precision just 
measure 
report recall precision values addition measure critical points 
interpretability second important concern choosing classifiers final deduplication rule easy human understand interpret tune 
necessary domain expert cover limitations training data tune function needed 
decision trees suited criteria 
model trained deployed finding duplicates large lists records 
cases afford generate quadratic cartesian product mapped pairs 
discussed earlier section wish analyze deduplication function learnt classifier construct appropriate similarity indices grouping functions 
need classifier decision tree predicates simple conjuncts disjuncts individual similarity functions classifiers svms naive bayes combine similarity functions complicated ways 
possible post process classifier naive bayes extract indexable predicates shown 
efficient training want method fast train interactive active learning phase iteration need retrain classifier larger training dataset 
fortunately training data size large case criteria easily met classifiers 
active learning active learner starts limited labeled large unlabeled pool instances 
labeled set forms training data initial preliminary classifier 
goal seek unlabeled pool instances labeled help strengthen classifier fastest possible rate 
criteria picking instances 
initial classifier sure predictions unlabeled instances unsure 
unsure instances fall classifier confusion region 
confusion region large training data small 
classifier reduce confusion seeking predictions uncertain instances 
intuition forms basis major criteria active learning selecting instances classifier built current training set uncertain 
give example show selecting instances uncertainty help reduce classifier confusion 
example consider simple learner separating points different classes positive negative straight line shown 
assume set points separable single point line 
initial training set consists positive point star negative point circle picked randomly line 
rest points squares unlabeled 
confusion region region unlabeled point left right effect reducing confusion 
selected active learning 
points ones classifier uncertain varying degree 
point region assume probability negative inversely proportional distance simplicity assume coordinate coordinate 
coordinate probability class negative pr pr negative size confusion margin reduce positive size decrease 
expected reduction size confusion region adding training set pr pr achieves maximum value point prediction classifier maximum uncertainty 
including training set size uncertain region reduce half matter label 
point say close negative boundary far positive boundary reduce confusion true label positive example active learning separating points line 
probability small current training data 
expected reduction confusion point uncertain instance 
example noticed instance learner unsure instance expected reduction confusion largest 
instances prediction learner strong confidence effect learner 
theoretical justification approximating expected reduction confusion formally version space prediction uncertainty appear :10.1.1.20.8521:10.1.1.16.4036
example simple case classes completely separable classifier 
reallife data noisy picking instances uncertainty need sure picking erroneous outlying instances 
gain instances representative large number unlabeled instances extreme outlying instance 
ensure second criteria important representativeness instance 
rest section discuss quantify notions uncertainty section representativeness instance section 
techniques discussed distillation various methods active learning proposed explanation particular design rationale :10.1.1.13.8629:10.1.1.20.8521:10.1.1.16.4036:10.1.1.119.2797:10.1.1.112.8094
accompany design decision justifications chosen approach experiments real life datasets citation database address database 
details experimental setup section 
uncertainty score instance major ways evaluating uncertainty prediction instance 
intuitive method measuring uncertainty separator classifiers svms regression inversely proportional distance instance separator :10.1.1.16.4036
similarly bayesian classifiers posterior probabilities classes estimate certainty :10.1.1.13.8629
decision trees typically uncertainty derived error leaf instance falls 
experiments uncertainty scores decision trees naive bayes satisfactory returning informative instances 
classifier independent way deriving uncertainty instance measuring disagreement predictions gets committee classifiers 
committee built member classifiers slightly different similar accuracy training data 
different members provide redundant ways classification 
sure duplicate non duplicate get prediction members 
uncertain ones get different labels adding training set disagreement members lowered iteration 
uncertainty predictions committee quantified various ways 
entropy fraction committee members predicted classes 
methods creating committees different ways creating committees 
randomizing model parameters common method creating committees making small perturbations parameters model trained training data 
perturbations sampling distribution particular training parameter expected follow 
previous approaches show perturb parameters naive bayes classifier hidden markov model :10.1.1.13.8629
propose mechanism randomizing decision tree classifiers 
tree construction selecting attribute splitting deterministically choosing attribute highest information gain randomly pick information gain close range best 
secondly picking threshold split continuous attribute picking midpoint range information gain remains unchanged pick point uniformly randomly range 
partitioning training data second method creating committees partitioning training dataset various ways including disjoint overlapping partitioning 
disjoint partitioning experiments due limitation training data early phase active learning 
fold overlapping partitioning committee size partition training dataset disjoint sets 
dn train th committee dataset di 
way member gets trained th fraction data 
attribute partition training data sparse number attributes surplus method constructing committee partitioning attribute set various ways 
data partitioning approach disjoint partitioning attributes constructing model removed attribute set constructing model 
constructing models attributes exhaust accuracy training data reduces drastically 
surprisingly method 
second approach removed topmost attribute earlier model 
applicable decision trees 
comparing different methods creating committee compare different methods creating committee members datasets settings described section 
axis different rounds active learning select instance round equal number training instances axis accuracy current classifier total unlabeled data dp 
find datasets randomized parameter method performs best followed attribute partitioning 
data partitioning relatively worse accuracy accuracy attribute partition randomize parameter data partition rounds active learning bibliography data attribute partition randomize parameter data partition rounds active learning address data comparing different methods creating committees aggregate accuracy address dataset bibliography dataset number committee members change aggregate accuracy varying number committee members initial stages available training data partitioning small 
contrary attribute partitioning gets worse stages training set gets larger complex redundancy available attributes diminishes 
cases removing topmost split attributes subsequent trees significantly weaker 
number committee members committee size taken input argument 
study effect active learning 
plot committee size versus area accuracy curve formed active learning committee size 
area measured summing accuracy values round 
interestingly find performance classifier sensitive number committee members 
implies committee size kept fairly small hurting accuracy 
representativeness instance real life data noisy 
uncertain instance outlier 
uncertain instance representative larger number unlabeled instances greater impact classifier outlying instance 
important factor representative instance underlying data distribution 
main challenge incorporating representativeness factor figuring combine uncertainty factor 
different methods proposed 
approach explicitly measures representativeness instance estimating density points clustering unlabeled instances :10.1.1.13.8629
instances scored weighted sum density uncertainty value highest scoring instances selected 
method requires tune parameters distance function clustering number clusters weights tradeoff uncertainty representativeness 
second common approach relies sampling preserve underlying data distribution :10.1.1.20.8521
candidate unlabeled instance weighted uncertainty value 
instances active learning selected weighted sampling 
chose experimented different variations approach starting sampling full sampling 
sampling simply pick highest uncertainty instances 
weighted sampling entire unlabeled set 
intermediate approach pick top kn instances uncertainty weighted random sampling select kn instances 
corresponds sampling kn total data size corresponds full sampling 
default 
show accuracy change active learning sampling schemes different base classifiers decision trees tree discriminative classifier naive bayes nb generative classifier 
trees find sampling schemes comparable 
notice real benefit accounting representativeness naive bayes classifier 
expected generative classifiers maintaining input data distribution important discriminative classifiers 
theoretical analysis phenomenon 
final algorithm system picking instances labeling 
experimental evaluation evaluation figures chosen active learning approach 
experiments datasets bibliography dataset consists citation entries obtained citeseer searching frequently referred authors 
data consisted citations duplicates careful manual searching 
pair format led instances duplicates instances positive accuracy accuracy full sampling partial sampling sampling rounds active learning bibliography data decision tree full sampling partial sampling sampling rounds active learning bibliography data naive bayes comparing different sampling schemes incorporating representative instances 
input lp current training data number committees dp unlabeled instances 
train classifiers 
cn lp randomizing choice parameters classifier 

unlabeled instance dp find prediction 
yn members 
compute uncertainty entropy predictions 

return instances weighted sampling instances weight 
algorithm active learning selecting instances labeling class 
raw data underlying structure 
segmented text record fields author title year page number rest citeseer scripts 
address dataset consists names addresses customers local telephone city india 
data attributes lastname firstname address address pin 
address fields follow meaningful breakup address 
records duplicates manual search 
pair format led instances duplicates skewness 
similarity functions designed similarity functions datasets 
text attribute functions ngrams match ngrams size fraction overlapping words approximate edit distance described :10.1.1.39.4336:10.1.1.39.5567
integer fields year total time sec address dataset bibliography dataset rounds active learning running time 
page special number match tolerated shift 
attributes get wrongly segmented neighboring field created new text fields concatenating neighboring fields defined text matching functions 
special function designed null matches attribute 
distinguish cases attributes match nulls attributes mismatch null 
classification methods classification methods decision tree classifier mlc naive bayes classifier svmtorch support vector machine classifier svm 
experiments performed processor pentium iii server running linux redhat mb ram 
experiments obtained averaging runs different seeds random number generator gets deployed different stages algorithm discussed section 
defaults defaults different parameters algorithm set best option experiments previous section 
default classification method decision trees 
number committees set 
committees created parameter randomization instances selected partial sampling 
initial training set consisted exact duplicate clear non duplicate 
round active learning instance selected labeling 
accuracy classifier round active learning measured entire unlabeled dataset 
running time plot total running time increasing rounds active learning datasets 
graph establishes time round active learning limited seconds 
address dataset takes longer unlabeled instances 
datasets experiment small performance enhancements discussed section 
topic ongoing research 
evaluating active learning different base classifiers plot performance active learning different classification methods 
graphs show decision trees provide best accuracy 
legend show precision recall values round active learning 
trees dominate svms turn dominate nb precision recall values 
trees show larger fluctuation accuracy initial stages 
accuracy accuracy decision tree svm naive bayes rounds active learning bibliography data decision tree svm naive bayes rounds active learning address data comparing performance different classification methods active learning 
expected decision trees known unstable classifiers 
address dataset svms better initial stages active learning training data small loose 
imply fixed training set svms worse trees 
graphs evaluating classifier capability return meaningful uncertainty values accuracy 
svms known excel accuracy uncertainty value measured distance svm separator meaningful 
trees turn better combined metric 
news trees offer advantages interpretability discussed section 
example show final tree output bibliography data 
output easy interpret tune 
comparing active learning random selection evaluate performance active learning comparing speed convergence peak accuracy random selection number accuracy accuracy optimal active learning random rounds active learning bibliography data optimal active learning random rounds active learning address data speed convergence active learning random selection optimal selection instances 
graphs show lines active learning random optimal selection 
discuss comparison active learning random 
datasets active learning shows clear superiority random selection 
just instances available active learning able achieve peak accuracy bibliography address dataset 
accuracy improve instances 
number instances selected randomly achieve accuracy just respectively bibliography address datasets 
fact achieve peak accuracy random selection needs instances address data instances bibliography data 
interesting observation experiments selected instances duplicates form total data sets jump fraction duplicates original unlabeled pool 
mean primary gain active learning due correcting extreme skewness original data 
particular set instances important 
performed second experiment randomly selecting instances time keeping number duplicates active learning 
yielded average accuracy bibliography data address dataset 
numbers important 
confirm original intuition manually collecting large number duplicates achieve high accuracy proper care taken selecting confusing set non duplicates go 
hard number large easy know non duplicate misclassified duplicate existing training set 
comparison optimal selection important question close active selection method absolute best method 
designed optimal method knows labels instances unlabeled set dp oracle 
round active learning picks instance follows 
instance dp add correct label current training data train classifier cx 
compute accuracy ax cx predicting instances dp 
pick instance accuracy ax highest 
best algorithm design time category algorithms 
guarantee give best subset instances fixed training size just ensures optimality step pick instance time 
plot accuracy optimal approach 
datasets notice chosen criteria instance selection close accuracy provided optimal approach unrealistically assumes labels known 
major difference optimal smooth monotonic active learning accuracy fluctuates 
legend part show precision recall values round 
metrics separately active learning close optimal approach 
related renewed interest database community data cleaning problem comprising aspects including data segmentation deduplication outlier detection standardization schema mapping :10.1.1.21.7984
specific problem deduplication concentrated performance aspects assuming deduplication function input user :10.1.1.46.6676:10.1.1.23.9685
problem deduplication long relevant library cataloging see survey 
concentrate hand coding deduplication functions bibliography domain 
deduplication problem interest statistics community organizations census bureau :10.1.1.39.4336:10.1.1.39.5567
effort spent designing domain specific similarity functions census datasets 
learning approach restricted conventional classification logistics regression naive bayes 
similarity functions inspired literature 
systems address difficulty collecting covering set training instances start 
approach learning deduplication function interactively bears resemblance interactive relevance feedback refine queries text multimedia content 
relevance feedback goal learn relevance function cases boils learning appropriate weights weighted distance function 
key difference relevance feedback active learning type examples shown user collecting feedback 
relevance feedback systems user shown top relevant answers round active learning fast convergence rests showing user uncertain answers 
section discussed various ways doing active learning 
active learning applied domains past including text classification information extraction :10.1.1.13.8629:10.1.1.16.4036
believe attempts active learning solving large scale practically motivated problem 
deduplication key operation integrating data multiple sources time consuming labor intensive domain specific operation 
alias novel approach easing task limiting manual effort simple domain specific attribute similarity functions interactively labeling small number record pairs 
careful evaluation number non obvious design tradeoffs ensure active learning process practical effective provide interactive response user 
final deduplication function designed easy interpret efficient apply large datasets 
find active learning requires orders magnitude fewer pairs labeled random selection 
experiments show starting highly skewed unlabeled pool duplicates surprisingly able selectively sample fold duplicates non duplicates making skew 
specific set non duplicates pick important 
number non duplicates picked active selection accuracy drops half 
find chosen approach close optimal approach 
include extensive running time evaluation design better similarity indices aiding users designing attribute similarity functions 
acknowledgments project funded ministry information technology india project mobile agents collaborative distributed applications 
acknowledge help national informatics providing address dataset dr rao support encouragement project 
argamon engelson dagan 
committee sample selection probabilistic classifiers 
journal artificial intelligence research 
borkar deshmukh sarawagi 
automatic text segmentation extracting structured records 
proc 
acm sigmod international conf 
management data santa usa 
buckley salton allan 
effect adding relevance information relevance feedback environment 
proc 
sigir pages 
burges 
tutorial support vector machines pattern recognition 
data mining knowledge discovery 
chaudhuri narasayya sarawagi 
efficient evaluation queries mining predicates 
proc 
th int conference data engineering icde san jose usa april 
cohen richman 
learning match cluster entity names 
acm sigir workshop mathematical formal methods information retrieval 
cohn atlas ladner 
improving generalization active learning 
machine learning 
bengio 
svmtorch support vector machines large scale regression problems 
journal machine learning research 
software available www idiap ch learning svmtorch html 
freund seung shamir tishby 
selective sampling query committee algorithm 
machine learning 
galhardas florescu shasha simon 
declarative data cleaning language model algorithms 
proc 
th int conference large databases vldb pages rome italy 
gravano panagiotis jagadish :10.1.1.46.6676
approximate string joins database free 
proc 
th int conference large databases vldb rome italy 
hernandez stolfo :10.1.1.46.6676
real world data dirty data cleansing merge purge problem 
data mining knowledge discovery 

identifying merging related bibliographic records 
master thesis mit 
iyengar apte zhang 
active learning adaptive resampling 
ramakrishnan stolfo bayardo editors th acm sigkdd international conference knowledge discovery data mining kdd pages aug 
acm press 
kohavi sommerfield dougherty 
data mining mlc machine learning library 
tools artificial intelligence pages 
ieee computer society press available www sgi com tech mlc 
lawrence giles bollacker :10.1.1.17.1607
digital libraries autonomous citation indexing 
ieee computer 
liere tadepalli 
active learning committees text categorization 
proceedings aaai th conference american association artificial intelligence pages providence 
aaai press menlo park 
mccallum nigam reed rennie seymore 
cora computer science research search engine 
cora whizbang com 
mccallum nigam ungar 
efficient clustering high dimensional data sets applica tion matching 
knowledge discovery data mining pages 
mccallum nigam :10.1.1.13.8629
employing em pool active learning text classification 
shavlik editor proceedings icml th international conference machine learning pages madison 
morgan kaufmann publishers san francisco 
mitchell 
machine learning 
mcgraw hill 
monge elkan 
field matching problem algorithms applications 
proceedings second international conference knowledge discovery data mining kdd 
navarro 
guided tour approximate string matching 
acm computing surveys 
quinlan 
programs machine learning 
morgan kaufman 
software available www cse unsw edu au quinlan tar gz 
raman hellerstein 
wheel interactive data cleaning system 
proc 
th int conference large databases vldb pages rome italy 
sarawagi editor 
ieee data engineering special issue data cleaning 
www research 
microsoft com research db dec issue 
htm december 
schohn cohn 
active learning support vector machines 
proc 
th international conf 
machine learning pages 
morgan kaufmann san francisco ca 
seung opper sompolinsky 
query committee 
computational theory pages 

cleanup deduplication international bibliographic database 
information technology libraries 
tong koller 
support vector machine active learning applications text classification 
journal machine learning research nov 
winkler 
matching record linkage 
editor business survey methods pages 
new york wiley 
available www census gov 
winkler 
state record linkage current research problems 
rr www census gov srd papers pdf rr pdf 
zadrozny elkan 
learning making decisions costs probabilities unknown 
proceedings seventh international conference knowledge discovery data mining kdd 
zhang oles 
probability analysis value unlabeled data classification problems 
proc 
th international conf 
machine learning pages 
morgan kaufmann san francisco ca 
