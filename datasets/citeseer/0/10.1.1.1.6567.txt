dynamic hmm line segmentation sequential data jens kohlmorgen fraunhofer ida 
berlin germany jek fraunhofer de steven fraunhofer ida 
berlin germany fraunhofer de propose novel method analysis sequential data exhibits inherent mode switching 
particular data non stationary time series dynamical system switches multiple operating modes 
approaches method processes data incrementally training internal parameters 
hmm dynamically changing number states line variant viterbi algorithm performs unsupervised segmentation classification data fly method able process incoming data real time 
main idea approach track segment changes probability density data sliding window incoming data stream 
usefulness algorithm demonstrated application switching dynamical system 
abrupt changes occur di erent real world systems example speech industrial processes financial markets physiological signals eeg meg 
methods analysis time varying dynamical systems important issue application areas 
introduced annealed competition experts method time series nonlinear switching dynamics related approaches 
brief review models see 
di erent approach respects 
segmentation depend predictability system 
merely estimate density distribution data track changes 
particularly improvement systems data hard predict example eeg recordings financial data 
second line method 
incoming data stream processed incrementally keeping computational ort limited fixed www fraunhofer de jek upper bound algorithm able perpetually segment classify data streams fixed amount memory cpu resources 
possible continuously monitor measured data real time long sampling rate high 
main reason achieving high line processing speed fact method contrast approaches involve training iterative adaptation parameters 
optimizes segmentation fly means dynamic programming results automatic correction fine tuning previously estimated segmentation bounds 
segmentation algorithm consider problem continuously segmenting data stream line simultaneously labeling segments 
data stream supposed sequential temporal structure follows supposed consist consecutive blocks data way data points block originate underlying distribution 
segmentation task performed unsupervised fashion priori labels segmentation bounds 
pdfs features segmentation consider 
incoming data stream analyzed 
sequence passed pre processing step filtering subsampling long done fly case line scenario 
step processing useful exploit idea dynamical systems theory embed data higher dimensional space aims reconstruct state space underlying system 

parameter called embedding dimension called delay parameter embedding 
dimension vectors mn 
idea embedding measured data potentially non linear projection systems state phase space 
case embedding higher dimensional space help resolve structure data property exploited scatter plots 
embedding step perform sub sampling embedded data order reduce amount data real time processing 
want track density distribution embedded data estimate probability density function pdf sliding window length standard density estimator multivariate gaussian kernels purpose centered data points window exp 
kernel width smoothing parameter value important obtain representation underlying distribution 
propose choose proportional mean distance nearest neighbors averaged sample set 
reported application process data hz hz including display ghz pc matlab linux expect su cient large number applications 
case notation time indices refer subsampled data 
denote specific vector valued point denote vector valued variable 
similarity pdfs sampled data points compute pdf eq 
compute new pdf new incoming data point 
order quantify di erence functions squared norm called integrated squared error ise dx calculated analytically mixtures gaussians case pdfs estimated data windows exp exp exp hmm line case discuss line variant necessary introduce hmm respective line algorithm 
data sequence obtain corresponding sequence pdfs eq 

construct hidden markov model hmm pdfs represented state set states hmm 
state define continuous observation probability distribution exp observing pdf state initial state distribution hmm uniform distribution number states 
state priori equally probable 
hmm transition matrix ij determines probability switch state state aim find representation sequence pdfs terms sequence small number representative pdfs call prototypes exhibits small number prototype changes 
define way transitions state times transitions states ij completes definition hmm 
note hmm free parameters known viterbi algorithm applied hmm order compute optimal state sequence prototype pdfs generated sequence pdfs 
state sequence represents segmentation aiming 
compute state sequence ciently compute terms costs log probabilities computing maximum likelihood function compute minimum cost function log yields optimal state sequence 
way replace products sums avoid numerical problems 
addition simplify computation special case particular hmm architecture results algorithm time step compute cost optimal state sequence subject constraint ends state time call constrained optimal sequences paths unconstrained optimum path 
iteration formulated follows short hand denoting kronecker delta function initialization induction min termination min 
regularization constant log subsumes free hmm parameters interpreted transition cost switching new state path 
optimal prototype sequence minimal costs complete series pdfs determined step obtained logging updating paths states iteration choosing minimal costs eq 

line algorithm order turn segmentation algorithm line algorithm restrict incremental update eq 
uses pdfs states past data points 
neglect stage memory cpu resources limited 
suppose processed data 
new data point arrives time generate new embedded vector sampled initial data points embedding new pdf sampled embedded vectors pdf window new hmm state 
readily compute distances new pdf previous pdfs eq 

similarly simple straightforward update costs paths optimal state sequence possible neglect consider potential paths contained new pdf prototype previous segments 
case simply reuse paths 
line update time restricted paths henceforth denote tilde performed follows dw 

compute cost new state time compute min update 
previous optimal segmentations don need keep complete matrix repeatedly compute minimum developed algorithm computes appropriate value hyperparameter sample set 
due limited space algorithm forthcoming publication 
states 
store update history optimal segmentations 

update compute states obtained far get compute min get cost optimal path min 
line case algorithm shows update equations costs paths 
associated state sequences logged simultaneously computation 
note done just storing sequence switching points path 
need keep full matrix update column su cient 
far incremental version segmentation algorithm 
algorithm needs amount memory cpu time increasing new data point 
order limit resources fixed amount remove old pdfs old hmm states point 
propose discarding states time indices smaller equal time path associated eq 
exhibits switch back state pdf currently considered state result min operation eq 

algorithm simply done setting case allows discard corresponding old paths addition initialization clause eq 
ignored cut path kept compute part 
assume min eq 

explanation follows switch back eq 
indicates new data distribution established path ends pdf state old distribution routes path states represent new distribution means lower costs despite incurred additional transition 
vice versa newly obtained pdf properly represent previous mode justifies assumption 
ect proposed cut strategy discard paths pdfs old modes allow find optimal pdf prototype current segment 
cut conditions occur shortly mode changes data cause removal hmm states pdfs old modes 
mode change takes place incoming data sequence states discarded 
need set fixed upper limit number candidate paths pdfs simultaneously consideration limited resources available 
limit reached switches detected successively discard oldest path pdf stored result choosing suboptimal prototype segment 
ultimately continuous discarding enforces change prototypes time steps switching induced data 
bu er size large possible 
case bu er overflow condition recorded segmentation allows identify artificial 
labeling algorithm labeling algorithm required identify segments represent underlying distribution similar pdf prototypes 
labeling algorithm generates labels segments assigns identical labels segments similar respect 
propose relatively simple line clustering scheme prototypes expect prototypes obtained underlying distribution separated prototypes result segmentation algorithm 
assign new label segment distance associated prototype preceding prototypes exceeds certain threshold assign existing label closest preceding prototype 
written newlabel min initialization newlabel 
denotes enumeration segments obtained far denotes mapping index corresponding pdf prototype 
note segmentation algorithm replace number pdf prototypes segmentation bounds line processing order optimize segmentation time new data 
relabeling segments changed necessary update step labeler 
hyperparameters developed algorithm computes suitable value sample set 
refer forthcoming publication 
application illustrate approach application time series switching dynamics mackey glass delay di erential equation dx dt 
eq 
describes high dimensional chaotic system originally introduced model blood cell regulation 
example stationary operating modes established di erent delays respectively 
dynamics operates stationary mode certain number time steps chosen random referring sub sampled data step size 
randomly switches modes uniform probability 
procedure repeated times generates switching chaotic time series stationary segments 
added relatively large amount measurement noise series zero mean gaussian noise standard deviation standard deviation original series 
line segmentation algorithm applied noisy data processing performed line full data set available case 
scalar time series embedded fly sub sampled data pdf window size 
algorithm processed data points second ghz pc matlab linux including display ongoing segmentation observe re adaptation past segmentation bounds labels new data available 
mode mode mode mode labels bounds actual modes line segmentation data segmentation switching mackey glass time series noise bottom operates di erent modes top 
line segmentation algorithm middle receives data points mode information yields correct segmentation bounds 
line labeler assigns labels desired presumably due fact segments short noisy 
final segmentation shown fig 

surprisingly bounds segments perfectly recovered noisy data set 
exceptions third segment right noticeably shorter original mode segment middle split algorithm 
split sense compares data visible change signal characteristics point delay parameter modified 
change recorded algorithm operates unsupervised way 
line labeling algorithm correctly assigns single labels modes assigns labels segments mode chaotic 
probably due small sample sizes segments combination large amount noise data 
discussion line method unsupervised segmentation identification sequential data particular non stationary switching dynamics 
hmm number states varies dynamically ect way incoming data processed 
contrast approaches processes data line potentially real time training parameters 
method provides updates segmentation time new data point arrives 
ect past segmentation bounds labels automatically re adapted new incoming data points processed 
number prototypes labels identify segments fixed determined algorithm 
expect useful applications method fields complex non stationary dynamics plays important role physiology eeg meg climatology industrial applications finance 
bellman 

dynamic programming princeton university press princeton nj 
bengio frasconi 

input output hmm architecture 
advances neural information processing systems eds 
tesauro touretzky leen morgan kaufmann 
bengio 

markovian models sequential data 
neural computing surveys www icsi berkeley edu jagota ncs 
bishop 

neural networks pattern recognition oxford univ press ny 


learning non stationary conditional probability distributions 
neural networks 
kehagias petridis 

time series segmentation predictive modular neural networks 
neural computation 
kohlmorgen muller pawelzik 

identification nonstationary dynamics physiological recordings biol cybern 
kohlmorgen appear 
pawelzik kohlmorgen muller 

hidden markov mixtures experts application eeg recordings sleep 
theo biosci 
mackey glass 

oscillation chaos physiological control system 
science 
packard crutchfield farmer shaw 

geometry time series 
phys rev letters 
pawelzik kohlmorgen muller 

annealed competition experts segmentation classification switching dynamics 
neural computation 
rabiner 

tutorial hidden markov models selected applications speech recognition proceedings ieee 
ghosh 

structurally adaptive modular networks non stationary environments 
ieee tr 
neural networks 
