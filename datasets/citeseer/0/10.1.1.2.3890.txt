adaptable distributed query processing architecture zhou beng chin ooi lee tan wee tok department computer science national university singapore science drive singapore traditionally distributed query optimization techniques generate static query plans compile time 
optimality plans depends parameters selectivities operations transmission speeds workloads servers difficult estimate unpredictable runtime 
query processor dynamically adjust plans runtime system performance satisfactory 
introduce new highly adaptive distributed query processing architecture 
architecture quickly detect fluctuations selectivities operations transmission speeds workloads servers accordingly change operation order distributed query plan execution 
implemented prototype telegraph system 
experimental study shows mechanism adapt changes environment approach optimal plan execution 
key words distributed dbs query processing query optimization multi join adaptive query processing large scale distributed system difficult find optimal plan query 
query processor may accurate corresponding author 
tel fax email addresses comp nus edu sg zhou comp nus edu sg beng chin ooi comp nus edu sg lee tan comp nus edu sg wee tok 
preprint submitted elsevier science statistics participating relations stored nodes selectivities operations 
transmission speeds workloads processing servers may fluctuate runtime 
lot efforts adaptive query processing address problem 
mainly focused centralized processing environments 
cases data sources geographically distributed query engine inherently distributed 
furthermore obvious number queries size data single server handle limited 
need design distributed query engine adapts changing environment runtime 
design new distributed query processing architecture called swap scalable adaptable query processor 
system builds goes straightforward adaptation eddies stems centralized adaptive query processing mechanisms deployed telegraph project reorder operations distributed query plan runtime :10.1.1.34.8546
swap deploys multiple eddies harness horizontal vertical parallelism processing sites 
types parallelism eddy site providing adaptivity operations running locally 
reordering operations swap realized dynamically changing orders tuples routed processing sites fluctuations selectivities operations transmission speeds workloads servers 
result swap approach optimal plan terms response time 
swap fix tuple routing order operations distributed query plan operates different traditional static plan 
develop algorithm generate distributed plan 
implemented prototype swap telegraph system 
experimental study shows swap effectively handle unpredictable factors runtime adapt distributed query plan optimality 
rest organized follows 
section introduce background challenges 
details query execution mechanisms swap section 
section scheme construct distributed query plan swap multi join queries 
experimental results section 
reviewed related section 
conclude section agenda 
background challenges section background discuss challenges designing adaptive distributed query processor 
background pieces telegraph project 
eddy tuple routing operator interposed data sources query operators selections joins :10.1.1.34.8546
eddy operator continuously pushes tuples queue query operators query operators may return result tuples eddy operator 
adjusting routing orders tuples operators tuple routing scheme eddy able adaptively approach optimal order operations runtime 
authors introduced tuple routing schemes back pressure effect lottery routing scheme enable eddy observe operator behavior cost selectivity accordingly route tuples operator order approaching optimal plan 
idea back pressure effect follows operators higher costs take time finish processing tuple consume tuples slowly lower costs 
results larger input queue sizes high cost operators 
fixing lengths operators input queues eddy operator forced route tuples operator lower cost routing higher costs 
lottery routing scheme operator assigned number tickets 
operator gets ticket tuple routed looses ticket returns tuple eddy 
number tickets roughly estimate selectivity operator 
selective operator tickets holds 
operators vie tuple operator tickets higher probability win tuple 
combining back pressure effect lottery routing scheme eddy generally routes tuples faster selective operator routing slower selective ones 
extends eddies splitting symmetric join operator order operators called stems 
stem viewed half symmetric join operator 
implemented indexed repository built tuples base relation particular attribute 
stem created attribute base relation addressed join predicates 
example way equi join evaluated stem operators implemented hash table built joining attribute base relations 
tuples arriving base relation built stem probe relations stems get join results 
ed single site processing fig 

centralized eddy 
site boundaries eddy multi site processing exposing normally hidden data structures example hash tables stems enable eddies control normally hidden physical operations build probe join algorithm 
probing stems different orders join ordering join algorithm spanning tree cyclic queries adapted 
stem provides shared data structure data table regardless number access methods join algorithms 
facilitates access method adaptation avoiding redundant competition access methods 
example execution plan way join example operations located single site data sources remote data sources 
join operators equi joins 
figures rounded rectangles denote stems 
tuples sources routed eddy operator processing operators 
internal data structure stem operator hash table built joining attributes 
see stem shared join operations 
tuples inserted hash table stem probe hash tables stems 
order stems probed determined routing schemes stated 
tuples routed similarly 
challenges distributed query engine operators may executed multiple sites 
kinds parallelism distributed query plan exploited processing sites horizontal intra operator vertical pipelined parallelism 
horizontal parallelism different sites running independently different partitions data 
vertical parallelism sites running pipelined manner results operations running site may piped site processing 
turns vertical parallelism offers greater opportunities adaptivity 
consider example shall running example illustrate mechanisms swap 
suppose want evaluate way join residing different sites site site site respectively 
assume join operations evaluated site site respectively 
form different pipelined query plans corresponding different join order 
route tuples site evaluate results piped site join plan corresponds executing join operations order plan route tuples site pipe results site 
corresponds determine best plan essentially operation ordering problem 
choice order consider selectivities costs distributed operations network transmission speeds workloads processing servers 
believe traditional query optimization inadequate static query plan fixes order tuples routed unable adapt inaccurate estimations runtime changes 
need robust query processing schemes dynamically adjust join order fly characteristics queries data system resources runtime 
naive strategy serves purpose extend mechanism eddies placing eddy operator single server connecting operators data sources eddy matter located 
query plan way join query running example method shown 
eddy located server data source sites alternative site 
eddy dynamically reorder distributed operations 
centralized eddy architecture suffers problem scalability reliability large communication overhead eddy operator bottleneck query processing 
swap targets solving problems 
query execution mechanism swap new query submitted server server coordinator query 
coordinator site compiles query chooses sites processing query determines degree parallelism operations required query 
algorithm described section employed generate distributed query plan 
runtime swap adapts operation orders join algorithms access methods spanning trees cyclic queries fly 
choices join algorithms access methods spanning trees done adaptive capability provided stems 
optimizer needed choose distribution operations 
assume execution operator placement determined optimizer traditional static query optimization techniques postpone making choices adaptive 
adopt simple scheme follows place selection operations tables residing sites estimate output sizes selections table join operation joining tables site join operation table selections output size smaller 
join operation executed site containing tables 
subsections assume query plan set look query plan processed swap 
shall consider vertical parallelism horizontal parallelism 
defer discussion distributed query plan generated section 
scheme vertical parallelism particular layout query operations kinds parallelism processing sites vertical parallelism horizontal parallelism 
shall focus vertical parallelism subsection discuss horizontal parallelism 
vertical parallelism sites running pipelined manner output site piped site 
result tuple output answer gone sites 
result tuple said gone site component tuples gone site 
interesting problem output site may choice routed sites different order 
recall running example mentioned section 
result tuples site possible routing order site site site site site site correspond join orders choice order balance workloads servers minimizing cost communication system resources 
fixing order scheme routing decision runtime potentially balance workloads servers minimize communication cost response time 
centralized eddy operator illustrated scheme employs multiple eddies site 
query plan sample query scheme shown 
eddy operator processing site 
rounded squares stems evaluate join operations 
choose site transmit results site eddy operator site continuously measures selectivities st la ed ro ra ed ra ro ra validating mask allowing bits validating mask ite rm ite ite validating mask allowing bits allowing bits ed la rm rs ra la allowing bits validating mask fig 

example scheme vertical parallelism 
la denotes local access operator ra denotes remote access operator 
operations transmission speeds workloads site site 
exact mechanisms introduced 
done distributed manner site making decision transmission results 
realize framework identified issues eddy efficiently collect statistics remote sites routing decisions intermediate result tuples 
routing order tuples fixed kind mechanisms facilitate routing tuples 
system efficiently process intermediate result tuples received remote sites 
sub subsections shall solutions issues 
collecting statistics making routing decisions swap remote output ro operator transmit intermediate results local site remote site processing 
ro connects ra remote access operator corresponding remote site 
ro operator continuously sends intermediate results local site corresponding ra operator 
example attach ro eddy site transmits output tuples site corresponding ra operator site 
site needs choose routing order results site running example collect statistical information candidate remote sites appropriate routing decision 
situation extend functionality ro operator sends local result tuples collects statistics corresponding remote site 
extended version ro operator called remote meta operator rmo 
sense rmo statistical information collects forms local abstraction operations running remote site 
example site needs choose site site transmit results 
attach eddy site 
statistics collected local eddy determine rmo route results 
look kind statistics rmo collect remote site 
stated appropriate decision know selectivities transmission speeds workloads candidate remote sites 
adapt parameters back pressure effect introduced centralized eddy :10.1.1.34.8546
words remote site transmission speed slow workload high consumes tuples slowly corresponding rmo consumes tuples slowly local eddy 
forces local eddy route result tuples rmo connects faster remote site 
estimate parameter selectivity remote site know result tuples remote site generates number tuples receives rmo 
remote site send number back corresponding rmo 
scheme works follows 
remote site eddy routes tuple output operator ro rmo check tuple contains data fetched ra connected rmo 
tells ra result tuple generated 
ra operator accumulates number result tuples generated number reaches threshold sends number integer back corresponding rmo 
threshold tunable system parameter determines sparingly information sent 
clearly tradeoff transmission overhead responsiveness system 
higher threshold lower transmission overhead responsive system 
look example 
eddy routes result tuple ro operator detect tuple contains data fetched ra connected rmo left rmo eddy 
eddy tells ra module result tuple generated 
ra accumulates number reaches threshold sends number corresponding rmo 
dotted curves indicate flow information 
similar processing performed site 
compute transmission overhead sites arose mechanism sizeof int threshold bytes selectivity site receiving tuples site number tuples sent site 
rmo collect statistical information eddy needs able information determine correct join order 
adopt lottery routing scheme implemented original eddy implementation :10.1.1.34.8546
lottery routing scheme query operators return result tuples eddy eddy calculate tickets routing decision 
order lottery routing scheme context rmo mimics actions ordinary query operators returning virtual tuples eddy 
virtual tuples typical data tuples 
fact contain data zero data length 
number virtual tuples rmo returns eddy equals number receives remote site corresponds number result tuples remote site generates 
eddy point view rmo ordinary query operator continuously fetches tuples eddy returns tuples eddy 
virtual tuples calculate tickets rmo lottery scheme 
lottery routing scheme number tickets held rmo roughly estimate selectivities operations corresponding remote site 
example tickets held left rmo eddy reflect selectivities operations running site 
sense rmo virtual tuples generates form local abstraction operations running remote site 
lottery routing scheme adaptively decision site transmit intermediate results selectivities candidate remote sites 
combining back pressure effect lottery routing scheme generally route tuples site lower selectivity faster transmission speed lighter workload 
note combination telegraph tuple passing operators message message header indicating message type 
virtual tuples tuple messages message body 
virtual tuples sent bulk eddy 
message sent bundle virtual tuples rmo receives statistical message remote site 
lottery routing scheme distinguish slow site selective site 
slow site consumes tuples slowly selective fast site consume tuples fast 
intuition site lower selectivity eliminate larger number irrelevant tuples site faster transmission speed lighter workload finish processing earlier 
routing kind sites speed processing 
decisions scheme done distributed way sites making decisions transmission results 
addition routing strategies incorporated proposed processing architecture 
example authors proposed routing strategies incorporated system extending rmo collect statistical information remote sites 
main contribution building new processing architecture consider incorporation 
routing tuples case vertical parallelism final result tuple undergone processing sites 
execute query efficiently effectively avoid types routing tuples redundant routing void routing 
redundant routing occurs tuples routed site void routing occurs tuples routed site operations routing tuples relation site example 
operation site involves tuples refer kind routing void routing 
prevent kinds routing know pieces information tuple routing history sites tuple routed tuple possible stations tuple routing history sites tuple routed 
record tuple routing history associate tuple bit vector called global footprint length equals number participating sites 
bit global footprint corresponds participating site 
turning bit setting global footprint means tuple routed corresponding site 
tuple completed local processing site corresponding bit global footprint set 
joining tuples global footprint new tuple result global footprints 
note extra constraint routing tuples 
order minimize communication overhead tuples fully processed local operations routed rmo ro operator 
result tuples remote site sent back processing significantly increase communication overhead 
example tuple associated global footprint bits corresponding processing sites 
consider tuple site global footprint set retrieved ready transmitted site site 
efficiently store second piece information mentioned tuple possible stations attach rmo ro compact descriptor contains bit vectors 
bit vectors length global footprint 
indicates type terms global footprint tuples routed rmo ro indicates bits valid 
tuple global footprint matches rmo ro tuple routed rmo ro 
illustrate 
bit vectors drawn rmo ros 
ith bit bit vectors corresponds site consider left rmo eddy indicates tuples fully processed site routed site routed rmo 
corresponding indicates second bits valid 
global footprint tuple retrieved site set ready transmitted 
tuple routed left rmo bits says need consider bits match global footprint tuple 
example consider ro attached eddy 
result tuples site routed ro fully processed site site undergone site 
consider bits tuple global footprint bits turned 
possible scenarios site retrieves local tuple 
case retrieval tuple initially global footprint 
valid bits match global footprint tuple prevented routed site wanted void routing 
site receives tuple site 
initially arrival global footprint tuple 
matching tuple resultant tuple rs global footprint recall ed global footprints joining tuples 
eddy detects tuple fully processed site turns bit rs global footprint making 
rs routed site 
site receives intermediate result tuple site 
initial global footprint tuple means fully processed site site table storage overhead affiliated data structures structure size expression global footprint tuples sites sites rmo ro sites rmo ro bytes bytes bytes processed site 
matches tuple resultant tuple global footprint 
fully processed site eddy turns bit global footprint resulting vector 
match bits ro prevented routed site prevent redundant routing 
fact global footprint means tuple fully processed sites answer tuple output user 
table summarizes storage overhead auxiliary data structures 
table tuples denotes number tuples loaded system processing 
number rmo ro site sites number processing sites 
total number operators sites rmo ro sites see section tuples transmitted sites 
simple example site route intermediate result tuples site 
rmo ro sites practice 
shall defer discussion bit vectors initialized section algorithm generate distributed query plan 
processing intermediate results centralized processing framework eddies stems processor store intermediate join results 
example possible routing order tuples inserted stem probe stem intermediate join tuples rs probe stem case intermediate join tuples rs stored processor 
new tuple received probe stems get final result tuples 
intermediate tuples rs stored new tuple needs probe intermediate tuples 
reasons centralized eddies stems store intermediate tuples probing hash table fast operation storing intermediate tuples may require lot memory 
distributed processing context considerations 
storing intermediate results remote site may incur high communication overhead 
example store site intermediate result tuples rs site new tuple sent site probe stems site 
tuple match tuples stem site guarantee tuple match tuples site 
contrary store intermediate result tuples rs site just newly received tuple probe rs tuples stored locally 
tuples join need transmitted site probe stem choose store intermediate result tuples processing site 
hand storing intermediate results gives rise problem 
scheme processing sites may receive different types intermediate tuples 
example site receives types tuples site site 
different site tuples relation site results may sub query running single site 
example joins running site st st join results portion relation relation similarly sub queries running site 
number sub queries site related number possible global footprint tuples routed site 
evaluate number sub queries efficiently solution adopt multi query processing scheme proposed cacq 
applying techniques cacq scenario result creating separate stem type intermediate result tuples 
sub query running site require different operators result overheads maintain lot query information necessary queries different operations 
situation scheme different cacq queries require operations queries cacq may require different operations 
avoid unnecessary overhead adopt approach 
stem types tuples containing data particular relation involved join operation 
example stem intermediate tuples sent site site tuples built stem fields base relation way sub queries require tuples undergo operators need maintain sub query completion information additional tuple routing information done cacq 
scheme horizontal parallelism data sources fragmented multiple sites natural horizontally parallelize operations 
scheme different sites exploit intra operator parallelism independently perform operation different partitions data 
horizontally parallelization scheme swap processing site eddy manage required operators running 
eddy number operators operating different fragments source data 
complete results obtained performing union operation output processing sites 
complete results may processed intermediate results output user final answers 
eddies horizontally parallelized sites running independently provide adaptivity operations running sites need introduce extra mechanism 
example relation running example fragmented sites site site execution scheme swap illustrated 
operators site site changed 
operators site replicated site site site site running horizontally parallelized manner 
eddies sites running independently 
alert reader may note left rmo eddy corresponds remote sites remote site 
reasonable mechanism rmo example choose join order need eddy distinguish sites site site refine definition rmo ro ra case horizontal parallelism 
rmo ro connected ra operators horizontally parallelized stream partner vice versa 
rmo ra ro ra pair encapsulates distribution operations corresponding communications flow details collection statistics remote sites 
separates distribution details local eddies operators 
feature eases development system 
modifications need added existing centralized system 
furthermore rmo ro send tuples partition information partitioned tables 
example partitioned join attribute rmo connected site site send tuple join attribute value site site accordingly 
tuple sent sites 
la st rm ed ed la ra ite ro ra rm ite ra ite st ed ra la ro ra ed rs la ite fig 

example scheme horizontal parallelism 
la denotes local access operator ra denotes remote access operator 
cyclic queries note discussions examples focus acyclic queries 
cyclic queries traditional query optimizer statically choose spanning tree create join operations spanning tree 
remaining predicates enforced selection operations 
author addressed issue making choice spanning trees adaptive centralized processing environment 
done adaptively changing order tuples routed stems 
distributed processing context join operations involved cycle evaluated single site spanning tree adapted centralized processing context 
join operations running multiple sites spanning tree chosen statically current scheme 
note arguing adapting spanning trees 
fact plan explore ro ra 
focus acyclic queries 
query plan generation multi join queries discussion assumed distributed join plan available operations set various processing sites 
see swap works distributed query plan different traditional plan 
swap fix tuple routing order processing sites find candidate routing orders result tuples site accordingly add rmo ra ro ra operators transmit tuples sites 
section scheme generate distributed plan supports horizontal vertical parallelism 
query plan generation done preparatory phase swap involves steps 
step query parsed query parse tree 
join graph jg generated 
jg essentially undirected graph nodes represent relations edge exists relations join predicate 
example jg 
relations join predicate exists 
second step optimizer selects processing sites degree parallelism operations 
result distributed extension join graph called distributed join graph djg 
step communication operators rmo ro ra pairs added djg produce distributed query plan 
subsections introduce djg properties algorithm generate djg jg 
algorithm incorporate communication operators query plan 
distributed join graph second step preparatory phase optimizer annotates join graph step reflect processing sites degree parallelism operations 
address operator placement problem just simple strategy mentioned section 
annotated join graph nodes labeled residing sites corresponding relations edges labeled processing sites 
note join operation assigned processing site 
example annotated join graph 
superscripts relation names locations relations 
example join graph djg annotated join graph distributed query plan fig 

example join graph distributed join graph distributed plan 
relations located site join operation relations performed site 
shall refer maximum connected sub graph annotated join graph sub query edges label operations performed single site 
example subgraph involving relations corresponds subquery similarly subgraph involving relations forms subquery 
note sub query single node join graph sub query relation access 
ease presentation assume site processes exactly sub query 
fact treat multiple sub queries running site separately setting plan run separately site 
annotated join graph converted distributed join graph djg 
djg acyclic directed graph nodes represent sub queries edges represent cooperation relations nodes 
djg transformed annotated join graph 
note kinds nodes djg self contained node node self contained relations involved sub query located 
circular nodes selfcontained nodes 
sub query run site located site 
node subquery self contained node 
self contained nodes may evaluated parallel 
partial node node partial node relations involved sub query located nodes 
sub query involving relations contains join operations run site located site 
sub query forms partial node djg 
partial nodes cooperate nodes partial nodes self contained nodes pipelined manner corresponds vertical parallelism 
node outgoing edge pointing partial node relation involved operations contained result part joining result relations result filters 
example node outgoing edge pointing node relation contained result node part joining result involved join operation executed node 
see direction edge indicates direction tuple transmission 
note address fragmentation relations 
stated previous section relation fragmented sites operations assigned resident sites parallelized resident sites mechanism addressed section 
scenario represented djg replicating node parallelized 
simplicity scenario relation located single site 
algorithm describes scheme transform annotated join graph djg 
annotated join graph described adjacency list variable edge list variable edge labels nodes edges variable site 
output djg represented adjacency list 
algorithm creates djg empty edge set initializes auxiliary variables lines 
performs breadth traversal input annotated join graph create djg lines 
lines operations visiting node added corresponding node djg 
lines creates necessary edges incurred visiting node djg 
line adds avoid subsequent duplicate visits line adds fifo queue process adjacent nodes 
properties djg generate final query plan need incorporate communication operators 
edge djg add rmo ro ra pair connected sites 

example algorithm djg transforming annotated join graph distributed join graph create djg empty edge set self contained node processing site list visited nodes fifo queue 
add arbitrary node 
enqueue add local access operation node corresponding site djg isempty dequeue continue add local access operation node djg corresponding site add join operation node corresponding site edge djg site edge site site edge site site add site edge adjacency list resulting djg 
change node site edge djg partial node endif add enqueue endfor return djg possible route intermediate result tuples site site site 
edge node node add rmo ro ra pair transmit tuples site site 
final distributed plan shown bit vectors shown 
set algorithm consider possible routing paths leaving impossible ones avoid redundant routing void routing stated subsection 
look algorithm incorporate communication operators produce distributed query plan interesting properties djg algorithm 
property self contained node outgoing edges 
self contained node involves operations relations located 
djg partial node incoming edge node called predecessor path node node ancestor descendant obviously self contained nodes predecessor ancestors 
property descendants self contained nodes contain partial nodes 
proven noting predecessor say partial node 
self contained node predecessor 
process continued reaches self contained node 
means partial node path originated self contained node 
property means traverse nodes djg traversing descendants self contained nodes 
property partial node tuples routed predecessors routed 
partial node joins intermediate results predecessors local relations 
tuples routed predecessors operations property observation observation ancestors node predecessors route intermediate result tuples tuples routed predecessors 
symmetrically node route intermediate result tuples ancestors processed tuples 
incorporating communication operators ready describe algorithm set processing plan 
algorithm gives algorithmic description setup processing plan djg 
algorithm routine algorithm 
brevity address set regular operators la stems algorithm straightforward focus newly introduced operators rmo ro ra 
setup algorithm assumes input graph represented adjacency list variable la created access local source 
stem created site source attribute appears join predicates evaluated site 
algorithm setup djg setting distributed plan self contained node pre null pre array predecessors anc null anc array lists ancestors list visited nodes fifo queue 
add enqueue isempty dequeue pre anc anc ancestors ancestors predecessor 
anc add anc anc endfor add enqueue endfor endfor adjacent list input djg 
shown line algorithm begins self contained node traverse djg 
lines set predecessor ancestors self contained node property null 
line line traverses current self contained node descendants breadth way 
completeness traversal property 
lines set predecessor ancestors node lines create necessary output operators ro rmo visited nodes current node due observation avoid routing node results ancestors vice versa 
processing line line current iteration adding current node visited list fifo queue new iteration started 
applying algorithm node necessary output operators created 
algorithm creates module pair ro ra rmo ra transmit tuples site site creates accordingly 
part algorithm self explanatory lines 
note node ro rmo transmit tuples algorithm creating output operators transmit tuples site site output module pointing return output modules output module remote node remote node tuples routed may need route nodes vice versa 
endfor replace existing ro module rmo module add rmo module outputting add ro module outputting endif add ra module connect set bits corresponding pre clear bit corresponding create bits set sites choose transmit result tuples sites reverse 
need create transmission relationship nodes node code segment lines 
running setup algorithm operators created 
illustrate final query plan example query arrows represent transmission directions created transmission operators 
experiments section describe experimental setup results various experiments conducted evaluate proposed swap 
horizontal parallelism eddy runs independently site 
similar running eddy single site context focus evaluation swap vertical parallelism 
experiments performed machines interconnected lan 
running example vertical parallelism relations residing different sites machines site site site respectively 
queries submitted fourth site 
main table configuration processing sites 
name cpu memory operating system site ms windows xp pro 
site ms windows site ms windows xp pro 
configuration processing sites listed table 
cardinalities relations respectively 
relations attribute values attribute uniformly distributed 
changing range attribute control selectivities joins 
example cardinalities value ranges relations calculate average number tuples value relation 
multiplying product numbers overlapped range get cardinality join result 
experiments run site site respectively 
choose relatively large cardinality relation better show effect choice tuple routing orders 
choice processing sites case may optimal affect validity experiments 
explicitly stated joins implemented symmetric pipelined hash joins stems 
implemented prototype swap java code telegraph system 
instance distributed version telegraph server running processing site 
network communication java nio package provides efficient unblocking api 
virtual tuple transmission adopt aggressive approach network allows transmission transmit virtual tuple immediately accumulate number needed transmit 
learning static characteristics set experiments compare performance swap static plans characteristics static 
static plans implemented employing fixed join ordering employing ro ra pair operators rmo ra pair operators runtime adaptivity supported 
way comparing static plans evaluate effectiveness swap overhead introducing virtual tuple mechanism rmo 
experiments subsection running query way join study swap learn selectivities operations 
fig 

performance static selectivity fig 

percent tuples routed way experiment fix selectivity respect change selectivity version 
transmission speeds workloads processing sites 
scenario best static plan version experiment evaluate reverse true second case 
evaluating case may increase join size processed may reduce join size case 
shows response time different schemes cases 
see response time swap scheme close best static plan cases worst static plan took time complete 
implies swap effective shows overhead swap significant 
shows nearly tuples routed optimal order cases swap 
shows percentage tuples routed back pressure effect ticket routing scheme 
see selectivities larger equal nearly tuples routed back pressure effect 
operators accumulate positive tickets ticket routing scheme applied 
effectiveness back pressure effect case due fact sites higher selectivities may take time finish sites lower selectivities 
contrary selectivities tuples mainly routed ticket routing scheme 
second experiment study swap adapts transmission speeds sites 
experiment joins implemented index joins facilitate changing selectivities 
fix selectivities joins 
site slow connection processing sites 
simulate slow transmission speed output modules take ms send tuple site slow connection 
situation best static plan send tuples site perform fig 

effect routing strategies fig 

performance static transmission speed fig 

different selectivity fig 

percent tuples routed site join relation route resulting tuples site perform remaining join operation 
resulting response time schemes 
shows swap turns outperform optimal static plan slightly 
transmission speed site slow site lightly loaded 
best static plan time memory site may filled join results waiting output site 
moment site process tuples site idle 
swap exploit idle time sending tuples site 
way site utilize idle time evaluate join sending result tuples site produce final answers 
result inspires experiment see swap outperform best static plan selectivities joins varied 
shows response time schemes selectivities joins varied 
see response time schemes increases linearly line swap grows slowly 
shows change percentage tuples routed site fig 

performance static workload fig 

performance adapting fluctuations selectivity selectivities joins varied swap 
selectivities nearly tuples routed site 
operations site eliminate tuples sent site slow transmission speed 
selectivities higher tuples routed way 
site eliminate fewer tuples selectivities higher 
selectivities approach nearly number tuples going way 
tuples going site transmitted times slow connection going site need transmitted slow connection completion time way due pipelined effect 
experiment subsection study swap learn static workloads processing sites 
simulate high workload created thread ran spin loop may cost lot cpu cycles 
experiment site overloaded site 
selectivities joins 
best static plan perform 
see swap approaches optimal static plan 
adapting fluctuations set experiments study swap adapts fluctuation selectivity transmission speeds workloads servers 
running query previous set experiments 
consider fluctuation selectivity 
tuples relation selectivity selectivity 
remaining tuples toggle fig 

performance adapting fluctuations transmission speed fig 

performance adapting fluctuations workloads servers ties joins 
stated benefits adaptive scheme changing selectivities operators dramatic :10.1.1.34.8546
benefits larger operators changing selectivity dramatic 
shows performance static plans compared swap 
hope swap outperforms static plans 
query tuples best join order remaining tuples best join order static plans employed join order unable adapt change selectivities resulting poorer performance 
swap hand cope change selectivities adapt best join order runtime 
second study swap adapts fluctuation transmission speeds servers 
experiment fix selectivities sites 
initially connection site slow connection site fast 
seconds sites swap transmission speeds 
output operators take ms send tuple slow connection 
shown swap efficient static plans reasons similar logic earlier experiments static plans perform best limited time period swap optimal time 
similar experiment done studying adaptivity swap workload fluctuations servers 
experiment created delay threads overloaded site 
selectivities sites fixed 
initially site overloaded site normal workload 
seconds toggle workload sites 
results shown indicate swap superior static plans 
superiority attributed swap ability adapt tuple routing orders workload fluctuations midst processing 
related survey adaptive query processing 
ripple join xjoin online dynamic reordering examples efforts developing adaptive operators 
exchange operator proposed encapsulate parallelism parallel query processing system 
address adaptive issues 
direction explored adapt query plan runtime 
mainly focused problems delays initial data arrival proposed mechanism utilize idle time process parts query plan scrambling plan 
addressed problem inaccurate unavailable statistics query optimization re optimizing plan statistics data collected runtime 
authors proposed algorithms adaptively order pipelined filters runtime minimize processing costs 
focused centralized processing problem 
cacq continuous query engine adaptive query processing mechanism eddies efficiently execute multiple continuous queries simultaneously 
key features cacq include grouped filters stems 
flux introducing adaptivity parallel query processing 
scheme operators horizontally distributed cluster 
flux provides load balancing online repartitioning data shipping states corresponding operators 
horizontal parallelism supported 
scheme harness horizontal vertical parallelism 
clearly incorporate load balancing capabilities flux scheme 
preliminary idea reported 
independent effort distribute eddy mechanism proposed 
authors focused study practical routing policies 
assume efficient distributed processing architecture eddies exists 
hand focuses complementary problem developing new practical distributed processing architecture eddies 
tuple routing strategies proposed incorporated architecture 
simple distributed eddy mechanism proposed viewed special case swap system 
scheme routing decision done inside individual operator corresponds case attaches different eddy operator eddy multiple operators swap 
maintaining routing information making routing decisions costly task scheme duplicated operator operators running node swap eddies maintain routing information operations executing site 
example table approach sites expressions operators significantly increase storage overhead 
approach expected scale large number operations highly possible distributed system supporting millions queries 
furthermore tightly coupling routing strategy individual operators complicate development operators 
novel distributed query processing architecture adaptively learn selectivity transmission speeds workloads processing servers 
properties change runtime system adapt behavior accordingly approach optimal plan 
runtime decisions distributed manner 
highly scalable 
routing strategies easily incorporated extensions 
addition proposed scheme applicable parallel query processing 
furthermore proposed architecture applied building emerging general data stream processors 
systems known suffer fluctuations data characteristics system changes exactly problems addressing 
current result step research agenda 
plan pursue issues 
studying choice operation allocation degree parallelism adaptive 
basic approach continuously measure system state initiate operator migration necessary 
main challenge maintain shape query plan process operator migration 
second study extension proposed architecture multiple queries 
direction adaptivity provided system enhance query engine support qos management user 
includes defining qos properties problem system adapts behavior runtime maintain qos requirements 
project 
telegraph cs berkeley edu 
franklin tomasic urhan scrambling query plans cope unexpected delays proceedings fourth international conference parallel distributed information systems pp 

avnur hellerstein eddies continuously adaptive query processing proceedings acm sigmod international conference management data pp :10.1.1.34.8546

babu motwani widom adaptive ordering pipelined stream filters proceedings acm sigmod international conference management data pp 

graefe encapsulation parallelism volcano query processing system proceedings acm sigmod international conference management data pp 

haas hellerstein ripple joins online aggregation proceedings acm sigmod international conference management data pp 

hellerstein franklin chandrasekaran deshpande hildrum madden raman shah adaptive query processing technology evolution ieee data engineering bulletin 
ives florescu friedman levy weld adaptive query execution system data integration proceedings acm sigmod international conference management data pp 

kabra dewitt efficient mid query re optimization sub optimal query execution plans proceedings acm sigmod international conference management data pp 

krishnamurthy boral zaniolo optimization nonrecursive queries chu eds proceedings th international conference large data bases august kyoto japan proceedings morgan kaufmann pp 

madden shah hellerstein raman continuously adaptive continuous queries streams proceedings acm sigmod international conference management data pp 

raman deshpande hellerstein state modules adaptive query processing proceedings th international conference data engineering pp 

raman raman hellerstein online dynamic reordering vldb journal 
shah hellerstein chandrasekaran franklin flux adaptive partitioning operator continuous query systems proceedings th international conference data engineering pp 

tian dewitt tuple routing strategies distributed eddies proceedings th vldb conference berlin germany pp 

urhan franklin xjoin reactively scheduled pipelined join operator ieee data engineering bulletin 
zhou adaptive distributed query processing proceedings vldb phd workshop 
located th international conference large data bases vldb 

