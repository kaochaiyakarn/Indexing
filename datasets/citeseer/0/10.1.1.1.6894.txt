compressing large boolean matrices reordering techniques david johnson labs research research att com kumar johns hopkins university cs jhu edu large boolean matrices basic representational unit variety applications notable examples interactive visualization systems mining large graph structures association rule mining 
designing space time efficient scalable storage query mechanisms large matrices challenging problem 
lossless compression strategy store access large matrices efficiently disk 
approach viewing columns matrix points high dimensional hamming space formulating appropriate optimization problem reduces solving instance traveling salesman problem space 
finding solutions large tsp high dimensional hamming spaces challenging little explored problem readily exploit geometry avoid need examine inter city distances instances large standard tsp codes run main memory 
multifaceted approach adapts classical tsp heuristics means instance partitioning sampling may independent interest 
instances derived interactive vi shankar krishnan labs research research att com permission copy fee part material granted provided copies distributed direct commercial advantage vldb copyright notice title publication date appear notice copying permission large data base endowment 
copy republish requires fee special permission endowment 
proceedings th vldb conference toronto canada johns hopkins university cs jhu edu suresh venkatasubramanian labs research suresh research att com telephone call data obtain significant improvement access time standard techniques visualization application significant improvements compression 
consider problems visualizing large complex threedimensional geometric model real time walkthrough frames update 
order need determine quickly parts model seen region space cell bounding current location 
major phone access data tells numbers call numbers 
manage data develop graph models communities interest 
large volumes data describing various purchases people infer association rules large database 
problems basic unit data large disk resident matrix ones zeros 
case rows correspond transitions view cells columns primitives typically collections triangles visible moving cell 
matrices large having order hundreds thousands rows columns 
representing querying efficiently non trivial problem 
second case rows columns individual customers entry matrix represents call person 
third case rows customers columns products 
general problem store data efficiently access information corresponding row problem 
sets binary relation store efficiently set retrieved efficiently 
viewed matrix sufficiently dense representing adjacency matrix plausible 
scale impractical solution 
reasonable option applications interest tends sparse sparse graph representation 
maintain list elements 
done ways explicitly enumerate elements maintain pointers data structure note scales involved approaches require offline storage application element kb average size yielding gb needed storage approach nearly gb storage second assuming rows 
tradeoffs approaches explicit enumeration wasteful space due replication data elements means updates hard 
second approach may require making seeks list comparison approach access relatively efficient 
organization proposed solution exploits superior access time approach efficient space usage second 
describe simple example section go detail sections 
survey related section 
detailed experimental study follows section 
problem formulation start brief example illustrate approach 
consider relation depicted table 
relation defined sets 
wished retrieve disk distinct seeks extract entries perform seek scan entire list retaining relevant entries assume rows laid sequentially disk 
suppose able reorder ids relation looked table 
note row relevant entries clustered fact retrieved single seek scan wasted disk access 
definition 
run row matrix maximal sequence non zero entries 
going back table row runs 
reordering see table run 
run requires single seek define cost measure relation 
definition 
cost runs matrix sum number runs rows 
reordering problem stated problem matrix reordering 
binary matrix find matrix obtained permuting columns minimizes runs 
note minimizing runs speeds access time shall see may significantly decrease space needed store matrix 
special case matrix reordering problem solved efficiently question optimum value runs equals number rows contain non zeros 
equivalent asking matrix studied property 
definition consecutive ones property 
matrix said consecutive ones property columns permuted resulting matrix nonzero elements row appear consecutively 
booth lueker showed matrix linear time algorithm determines consecutive ones property produces desired permutation 
relation consecutive ones property reorder columns disk elements row accessed single seek 
general possible minimizing number runs matrix consecutive ones property hard theorem 
matrix reordering np hard 
proof 
demonstrate reduction hamiltonian path gt 
undirected graph construct boolean matrix rows edges columns vertices entry corresponding vertex edge adjacent 
row exactly 
consider edge 
adjacent column order contributes cost total run cost contributes 
pair consecutive vertices share edge reduce unit maximum run cost 
table example relation sets 
table relation reordering columns hamiltonian path exists reordering columns yielding matrix runs 
reordering cost 
setting theorem holds 
matrix reordering related traveling salesman problem manner 
recall hamming space vector space binary vectors sum vectors component wise sum taken gf 
space norm defined vi corresponding hamming metric dh 
tour hamming distance space order points visited cost tour sum distances adjacent points tour 
space denote cost shortest tour visits points 
view column point hamming space easy relate runs cost minimum tour 
theorem 
runs proof sketch 
note run contributes units tour transition transition 
runs row contribute unit 
sum contributions tour particular dimension row obtain quantity equal twice number runs row 
traveling salesman heuristics traveling salesman problem np hard instances metric distance functions 
best polynomial time approximation guarantee known instances proved christofides algorithm 
running time infeasible applications significantly faster heuristics known perform practice typically getting closer optimal promised bound 
commonly considered heuristics nn starting arbitrary point move nearest neighbor repeat 
point nearest neighbor current point tour pick nearest neighbor 
opt start nn tour 
pick edges delete edges resulting tour lower cost 
repeat 
opt similar opt edges broken tour reconstructed different ways 
lin kernighan sophisticated algorithm perform opt moves arbitrarily large highly structured way keeps worst case running time polynomial 
random euclidean instances studied nn typically gets optimal implementations opt opt lin kernighan described get respectively 
instances study lin kernighan performed distance calculations run effectively sophisticated heuristics ruled 
hand results heuristics closer euclidean instances 
opt better nn test lin kernighan offered little improvement 
restricting algorithms allow quantify realistic range solution quality tradeoffs 
reason distance calculations play key role running time opposed case euclidean instances example expensive 
high dimensional hamming space vector thousands non zero entries computing distance points require thousands operations compared just euclidean distance dimensions may individually expensive involving multiplications square roots add 
high dimensional euclidean spaces projected smaller number dimensions standard embedding methods discuss detail help hamming spaces 
implementations opt mitigate somewhat computing list nearest neighbors city caching distances 
data structure guide search improving moves suggested lin kernighan constructed speed computation nn tour 
unfortunately know way construct data structure looking inter city distances prohibitively expensive large problem large data structure instance may fit main memory result substantial additional costs terms disk resort classic technique dealing large tsp splitting tour tsp instance computing tour entire input partition cities sets compute tour part concatenate partial tours 
neighbor list construction quadratic input size approach speed tsp computation process presumably cost decrease quality combined tour 
general break input pieces solve tsp piece glue pieces 
addition speeding individual tsp calculations approach reducing size instance feasible run partial input completely core allowing ignore disk access issues 
quality tours generated approach depend just number pieces partition constructed 
ideally cities close sets partition 
geometric instances standard approach partition space cities located contiguous regions rectangles dimensional case done efficiently quite effective leading slight worsening tour quality increases 
unfortunately obvious way similarly exploit geometry high dimensional hamming space instances 
structure instances exploitable implicit explicit 
structure exists seen experiments report power instance simply partitioning instance input order cities going set yields substantially better results random partition 
instance visualization application constructed walkthroughs model initial ordering cities certain extent reflects implicit geometry model 
general may instance form reflects implicit structure useful generic partitioning procedure find structure exists run relatively quickly instance fit memory 
devised scheme enabled essentially match effectiveness original order partition 
methods possible full study alternatives scope 
approach reduces problem finding ordering cities partitioning contiguous blocks size roughly reordering problem turn solved combination clustering solution smaller tsp 
classical clustering algorithms generate partition directly doesn algorithms yield clusters widely varying size 
schema approach looks 
compute centers input bigger 

determine order centers tsp 

center reorder points associated cluster form tour account identity clusters side 

concatenate tours 
step performed pass input step 
step performed sorting phase small grouping algorithm employs passes 
step computing centers clustering algorithms designed points spaces hamming spaces 
addition size instances requires streaming clustering methods 
various methods possible birch streaming algorithm guha 
take related approach computes centers pick uniform random sample points input data subsets points equally 
assign point sample point closest 
determine closest neighbors construct bit vector vp length vp center closest neighbors 
vp vp vp denotes norm vr abuse notation refer sample point cluster points assigned 
center vs vp 
normalize vs vs set vs 
intuitively vector vs signature cluster representing clusters appear viewed clusters close see clusters way placed close 
notice dropped restriction large cluster swamp vs normalized rendering neighbourhood information useless 
parameter way compromising fixing contribution signature making large 
implementation fix arbitrarily 
parameter set 
step determining order centers define vs vs 
compute tour metric 
best multiple runs iterated lin kernighan variant lin kernighan 
step reordering points cluster sl sr adjacent points tour generated step 
consider point second nearest neighbour sl place set 
second nearest neighbour sr place set 
case holds place set depending vp vsl vp smaller 
points sorted respect measure vp vsl points sorted respect vp 
output order cluster 
intuition points similar sl appear closer order sl sr vice versa 
sampling reduce instance size drawback partitioning scheme divide parts fit main memory may case large required nearest neighbor computation simply construct true nn tour 
partition problem incurring additional penalties tour length constrain codes way 
basic issue potential distances need computed appealing approach discard large proportion edges unimportant concentrate sample kn supposedly edges 
implementations nn opt opt take sparse graph input consisting list edge true distance pairs default length distance pair cities represented list 
find tours respect revised distance metric depending quality sparse graph fairly tours original instance 
default length typically meaning algorithms hard non edges subject short tour possible 
note approach introduces second tradeoff fixed memory size choosing smaller value means room edges city possibly better tours 
tour quality depend quality sparse graph construct 
obviously edges included graph connect relatively near cities 
standard approach computing near neighbors large high dimensional data sets perform embedding nice space reduce dimension projections means 
resulting set points approximately preserve distances original set near neighbor calculations performed efficiently 
problems approach 
hamming spaces harder approximate euclidean spaces 
kushilevitz ostrovsky rabani algorithm computing approximate nearest neighbors hamming spaces algorithm requires space polynomial impractical 
result charikar suggests hamming metric amenable embedding undergoing severe distortion 
furthermore noted dimensionality reduction associated distortion distance measurements useful distances separated informally difference point nearest neighbor farthest neighbor large 
high dimensional data sets case table demonstrates example data sets 
resolve issue exploit distance compression causes hindrance approximate methods 
define bm ball radius times distance nearest neighbor 
assume exists point fraction points space lie ball 
intuitively larger separated points 
fix point sample points constant probability points lies 
probability success amplified sampling log points 
repeated wish compute near neighbors points twice nearest neighbour distance away merely sample log points take points sample closest algorithm sketched 
boosting parameter increase probability finding true near neighbors 
algorithm runs passes input 
input set points distance metric parameters 
output point set near neighbors 
scan sample uniformly set ck points 
find closest points output set 
algorithm algorithm note scheme sample potential neighbors near neighbor want retain 
preserves certain standard quality neighbor set number neighbors increases 
keeps time construct sparse subproblem fixed independent number subproblems 
means total time construct subproblems way partition grows linearly adding tradeoff mix 
discuss options cover directions research 
practice factor 
related known example reordering improve compression burrows wheeler transform 
buchsbaum idea column reordering improve table compression 
separate buchsbaum reorderings computing tsps 
tsp expensive compute distance function distance columns reflects improvement compression achieved gzip compression routine columns compressed separately 
tsp arising application smaller cities raise running time memory constraint issues chief concern 
connection tsp number runs context reconstructing dna sequences probes tests involved smaller instances 
variants consecutive ones property data mining identify interesting patterns market basket data 
vast body research mining association rules repre sented terms boolean matrix extensive survey scope 
cohen examines problem computing approximate near neighbors large hamming space different measure called intersection union metric 
managing large amounts disk resident data efficiently real time walkthroughs dimensional geometric databases studied problem computer graphics 
preliminary reordering done 
mentions tsp heuristics describe focuses mainly data management visualization aspects large scale walkthrough problem 
cortes proposed developed graph structures determine communities interest order detect patterns calls groups customers patterns interest detecting fraud telephone service 
experiments detailed experimental evaluation reordering strategy 
start experimental framework 
data power rows consist transitions visibility regions columns objects 
entry matrix object regions defined transition 
data comes model power plant walkthrough system developed 
city similar data set obtained model city atlanta 
phone data set consists sampling call data major rows correspond callers columns callees data anonymized 
table summarizes basic properties data set 
sparsity rows columns avg 
entries row power city phone table statistics data sets 
data characteristics demonstrate distance compression discussed section 
sampled points random data sets computing complete list distances points set calculated size fraction number points site 
table record average values 
power city phone table aggregate data distribution statistics data set column indicates fraction points average lie ball radius twice nearest neighbour distance point second column times value 
platform experiments run cpu sgi mhz processors gb main memory 
code sampling written compiled cc gcc 
auxiliary scripts managing data written ksh perl awk 
computing tours johnson mcgeoch implementation survey local search methods tsp 
validation primary measure quality runs number runs reordered matrix 
report cost reduction achieved fraction identity ordering 
mentioned earlier secondary benefit reordering improvement compression yields long runs get placed 
test claim known compression scheme studied johnson review methods compressing bitmaps 
codecs designed 
details works refer reader moffat zobel 
compression schemes designed compress sequences integers integers small 
sparse representation row boolean matrix sequence column ids small 
consider sequence 
xn 
offset mapping offset convert sequence form 
xn xn 
run starting column id matrix represented times efficient method known run length encoding represent run pair 
slightly better method called sided run length encoding exploits fact runs encoded simultaneously 
sequence integers represented sequence length th sequence length th sequence advantage approach intervals interspersed large numbers resulting sequence 
evaluate algorithms offset transform row compress row 
total compressed size sum compressed sizes row 
happen best compression scheme original input different best scheme reordering 
cases best results determine compression ratios 
table summarizes cost input data measures 
offset runs power city phone table different cost measures data 
reporting results report relative improvement achieved respect identity ordering 
situations tours generated sampling compute smaller instances tours generated full instance typically pieces small 
term sample refer tours generated sampling full refer tours generated exact distance computations 
times reported seconds 
performance algorithm start start finish evaluation schemes data sets 
results reported section reflect best choice parameters various stages computation pipeline independent running time goal verify null hypothesis reordering effect false 
table summarizes results achieved 
runs compression power city phone table relative improvement reorder respect identity ordering 
cases get substantial improvement reordering data 
worth mentioning case phone compression achieved small reduce input data set extremely sparse having average entries row 
scheme interpreted performing run length encoding doing run length encoding start ids tuple 
data sets best approach independent time obtained splitting data set fewest number subproblems individually fit memory computing full tours tours looking entire subproblem 
general best tours obtained opt occasional situations true 
power best split comes city 
data set phone small fit entirely memory 
closer look approach undertake detailed study various parameter choices reordering strategy affect running time resulting cost 
number subproblems sampling number subproblems input split prior tour computation constrained tsp algorithm 
order run core needs able fit sampled sparse graph entire subproblem main memory 
number neighbours computed point subproblem inversely related size piece 
illustrate performance tours varies number pieces 
table illustrates improvement runs achieved cases opt tour construction algorithm 
notice cases sampling yields better results number subproblems increases allows sample edges sparse graph input point 
number subproblems power sample power full city sample city full phone sample phone full table relative improvement runs number subproblems increases 
data set full tour computed value subproblem fits memory 
partitioning computing tour full instance better 
table illustrates important partition fewest number subproblems allow subproblem fit memory 
case phone entire input fits memory partitioning degrades performance 
time object best strategy clearly compute full tours subproblems pos sible 
significantly slower sampling quadratic distance computations 
table compares running times sampling full instance approaches notice sampling performed tsp cost small 
tour algorithms algorithms compute tours nn opt opt 
described section opt opt perform local refinements tour generated nn general full instances opt achieves better compression opt turns improves nn 
tradeoff time spent optimizing improvement obtained 
table summarizes relative improvement time needed improvements algorithms 
numbers reflect best case settings parameters show time computing tsp 
table indicates case euclidean tsps nn tour approximation best answer achieve 
times reported nn overestimates include time spent constructing neighbour lists opt opt phases tour construction 
interestingly construct tours sampled instances case opt opt better nn 
reasons discussed section tour construction algorithm deal occasional infinite edge sparse graph 
result nn give best cost solution 
example way partition city 
instance improvement achieved nn comparison achieved opt opt finding starting order finding starting order crucial component successful reordering 
start table comparing cost random reordering cost achieved reorder 
best case settings data sets 
random identity reorder power phone city table initial ordering matters random orderings bad 
table suggests initial orderings case power phone quite 
phone initial ordering close random 
coincidence strong spatial structure way elements power power city phone sampling full sampling full sampling full sampling tsp total sampling tsp total sampling tsp total table time taken seconds reorder number tour pieces varies power phone city time runs time runs time runs nn opt opt table relative performance tsp heuristics seconds 
running times include sampling time 
times measured cumulative opt takes output nn input 
measure opt time phone running opt better quality solution takes seconds running opt 
phone generated 
note phone run entirely main memory need partitioned prior reordering effect outcome 
sequel results power city 
experiment checks efficacy clustering 
evaluate quality reordering computed clustering strategy section 
clustering strategy independent input comparisons respect random ordering 
observe reordered input slightly better original input 
identity clustering power city table improvement quality ordering generated clustering relative random ordering new order generated clustering partition input compute tours manner described 
results optimal combination settings 
table presents results comparison results obtained clustering parameter settings 
reordering reordering order clustering power city table evaluation improvement due clustering reordering phase relative random ordering important note clustering strat egy oblivious input ordering 
words merely clustering data able recreate locality preserving properties original input 
arbitrary input set initial clustering phase generate initial order greatly improve effectiveness tour computation phase reordering process 
final experiment randomly reordered power random ordering starting order reorder 
run reduction obtain best possible settings way split opt improvement obtained clustering 
demonstrates value starting order 
discussion conclude section review major findings 
tsp reordering yields significant benefits terms access cost measured runs terms compression 
input large fit entirely main memory effective strategy break pieces small fit memory compute tours piece opt 
time constraint memory limited sampling way generate tours reasonably small amount time 
best strategy smaller pieces pick neighbours 
improvement achieved partitioning sampling function ordered original input better input ordering better output 
initial clustering step tries group points clusters near effective creating starting order partition 
type algorithm compute tour matters somewhat traditionally observed tsps 
nn tours close worse tours opt opt choice method amount time willing spend 
directions research papers concerned handle outof memory problems concentrated just instances applications 
hope confirm wider applicability approach 
example larger instances phone application exist provide new challenges total number phone numbers millions thousands studied 
study association rule applications example data sets rows correspond documents columns key words vice versa 
addition algorithmic questions worthy study 
best results obtained partitioning largest subproblems feasible run opt full subproblems doing 
true general 
need partition subproblems get small opt subdivision penalty severe better solve sparse versions subproblems way partition 
question quality sampled subproblems 
allowed fixed sampling time create subproblem independent size 
allowed fixed amount time create sparse subproblems 
mean sparse subproblems edges large lower average quality improvement results grows lessened disappear 
particular applications application specific sampling techniques generate better sparse graphs 
example phone application exploit community interest ideas cortes get neighbors column preferentially sampling columns corresponding phone numbers call called column number columns correspond numbers numbers call 
ted johnson providing code compression lyle mcgeoch modifications tsp codes handle hamming metrics 
divesh srivastava useful discussions pointers related 
cohen wilson zhang hoff hudson baker brooks manocha mmr integrated massive model rendering system geometric image acceleration 
proc 
acm symposium interactive graphics pp 

alizadeh karp physical mapping chromosomes combinatorial problem molecular biology 
proc 
rd acm siam symp 
discrete algorithms pp 

beyer goldstein ramakrishnan shaft nearest neighbor meaningful 
lecture notes computer science 
booth lueker testing consecutive ones property interval graphs graph planarity tree algorithms 
comp 
syst 
sci 

charikar impossibility dimension reduction 
proc 
th ieee symp 
foundations computer science pp 

buchsbaum caldwell church fowler muthukrishnan engineering compression massive tables experimental approach 
proc 
th acm siam symp 
discrete algorithms society industrial applied mathematics pp 

buchsbaum fowler giancarlo improving table compression combinatorial optimization 
acm 
burrows wheeler lossless data compression system 
tech 
rep dec src 
krishnan cohen venkatasubramanian johnson kumar high fidelity walkthrough large virtual environments 
submitted 
christofides worst case analysis new heuristic travelling salesman problem 
tech 
rep graduate school industrial administration cmu 
cohen datar fujiwara gionis indyk motwani ullman yang finding interesting associations support pruning 
knowledge data engineering 
cortes pregibon computational methods dynamic graphs 
journal computational graphical statistics 
funkhouser sequin teller management large amounts data interactive building walkthroughs 
computer graphics symposium interactive graphics mar zeltzer ed vol 
pp 

garey johnson computers intractability 
freeman 
gionis mannila fragments order 
proc 
th acm conf 
knowledge discovery data mining 
guha meyerson mishra motwani callaghan clustering data streams theory practice 
ieee trans 
knowl 
data eng 
johnson mcgeoch traveling salesman problem case study local optimization 
john wiley sons ch 

johnson performance measurements compressed bitmap indices 
proc 
th intnl 
conf 
large databases vldb 
kushilevitz ostrovsky rabani efficient search approximate nearest neighbor high dimensional spaces 
proc 
th acm symp 
theory computing pp 

lin kernighan effective heuristic algorithm traveling salesman operations research 
moffat zobel parameterised compression sparse bitmaps 
research development information retrieval pp 

huang ruan tan 
walking large virtual environment real time 
proc 
th intnl 
conf 
large databases vldb 
teller fowler funkhouser hanrahan partitioning ordering large radiosity computations 
proceedings siggraph orlando florida july july glassner ed computer graphics proceedings annual conference series acm siggraph acm press pp 

isbn 
zhang ramakrishnan livny birch efficient data clustering method large databases 
proceedings acm sigmod international conference management data acm press pp 

