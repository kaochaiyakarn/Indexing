file system logging versus clustering performance comparison margo seltzer keith smith harvard university hari balakrishnan jacqueline chang sara venkata padmanabhan university california berkeley log structured file system lfs introduced received attention potential order magnitude improvement file system performance 
early research results showed small file performance scale processor speed cleaning costs kept low allowing lfs write effective bandwidth maximum 
showed presence synchronous disk operations degrade performance cleaning overhead prohibitive transaction processing workloads reducing performance 
showed addition clustered reads writes berkeley fast file system ffs competitive lfs large file handling software development environments approximated andrew benchmark 
seemingly inconsistent results caused confusion file system research community 
presents detailed performance comparison bsd log structured file system bsd fast file system 
ignoring cleaner overhead results show order magnitude improvement performance claimed lfs applies meta data intensive activities specifically creation files kilobyte deletion files kilobytes 
small files systems provide comparable read performance lfs offers superior performance writes 
large files megabyte larger performance file systems comparable 
ffs tuned writing large file write performance approximately better lfs read performance worse 
ffs optimized reading large file read write performance comparable lfs 
lfs ffs suffer performance degradation due cleaning disk fragmentation respectively 
find active ffs file systems function approximately maximum performance years 
examine lfs cleaner performance transaction processing environment find cleaner overhead reduces lfs performance disk full 
challenge building high performance file systems disk system efficiently 
large caches reduce read traffic little reduce write traffic critical issue write performance 
achieving efficient writes disk implies writing data large contiguous units 
central idea logstructured file systems aggressively caching data applying database logging techniques disk writes sequential 
early log structured file systems focused build file systems 
key issues providing efficient reads file system written sequentially maintaining large contiguous regions disk 
seminal logstructured file systems showed conventional file system structures implemented lfs combination segmented log cleaner process garbage collector maintain large contiguous regions disk space 
main focus design log structured file systems derivation efficient algorithms segment cleaning 
performance results reported long term cleaning summaries number segments cleaned average utilization cleaned segments micro benchmarks demonstrated strengths lfs 
seltzer discussed design modifications necessary incorporate lfs bsd framework 
performance analysis focused areas covered rosenblum ousterhout emphasis workloads stressed cleaning capabilities lfs 
concluded clustering modifications ffs competitive lfs reading writing large files software development environments characterized andrew benchmark cleaning overhead lfs degraded transaction processing performance general applicability lfs competitiveness ffs warranted investigation 
part investigation analyzing performance lfs ffs focusing areas pose greatest challenges system 
focus main issues validating bsd lfs implementation comparing performance sprite lfs interaction file size performance sequential access impact disk fullness cleaning overhead transaction processing workload impact free space fragmentation ffs performance 
section compare bsd implementation lfs sprite implementation lfs validate measuring representative implementation log structured file system 
section examine performance function file size 
section examine performance file systems transaction processing environment special attention lfs cleaning performance function disk fullness 
section discuss effect disk fragmentation ffs performance 
section summarizes study 
overview ffs bsd fast file system described terms bitmap keeps track free space cylinder groups correspond collections cylinders provide regions allocation clustering 
information arranged disk terms units blocks partial blocks called fragments contiguous ranges blocks called clusters 
principle placing related files inodes cylinder group provides high degree locality allocating blocks contiguously clusters provides opportunity large sequential reads writes 
practice potential problems ffs 
operations affect file system meta data creating deleting files require large number operations synchronous 
example takes potentially distinct operations create new file inode new file directory containing new file directory inode data new file inode bitmap block bitmap synchronous 
second potential problem ffs block allocator take special measures preserve large free extents 
file systems long time may sufficiently fragmented impossible find large clusters blocks 
challenges facing ffs summarized reducing number synchronous behavior writes avoiding file system fragmentation 
overview lfs contrast ffs lfs avoids multiple write synchronous write problems batching large numbers writes large contiguous writes 
maintain large contiguous regions free space disk called segments 
lfs uses generational garbage collector called cleaner regenerate large free extents 
available disk space cleaner coalesce free space produce clean segments 
cleaner run idle periods interfere normal file access periods high activity may necessary run cleaner concurrently normal file accesses 
depending file access patterns cleaning potentially expensive degrade system performance 
lfs key issue cost cleaning 
validation bsd lfs system study operating system implementations fast file system ffs bsd log structured file system bsd lfs improved study seltzer 
specifically read ahead code ffs lfs largely rewritten 
fragments added lfs 
algorithm writing blocks disk lfs modified files spanning multiple segments written lower numbered blocks written 
new file system number blocks segment blocks zero written segment segment 
lfs file writing algorithm modified files written segments order entered cache 
affect write performance improves read performance files read creation order 
show bsd lfs faithful implementation log structured file system run benchmarks described rosenblum ousterhout compared results reported sprite lfs 
hardware configurations shown table 
benchmark section scale sprite measurements performance critical components match bsd configuration 
table shows relevant parameters scale factors 
discussion refer file systems rosenblum studied sprite logstructured file system sprite lfs default sun file system clustering effect sun ffs file systems studied bsd log structured file system bsd lfs bsd fast file system clustering effect bsd ffs bsd fast file system 
rosenblum tests kb file system lfs implementation kb file system ffs implementations 
deduced rotdelay parameter sun ffs file system benchmark configurations bsd sprite cpu parameters cpu sparcstation ii sun mhz mhz spec int disk parameters disk type dsp wren iv rpm sector size bytes bytes sectors track cylinders tracks cylinder track buffer kb kb average seek ms maximum bus bandwidth mb sec mb sec table benchmark configuration 
sprite column describes benchmark configuration rosenblum ousterhout study 
set disk block indicating system optimized writing 
similarly optimized bsd ffs file systems writing setting rotdelay equal disk blocks 
tests section examine interaction performance rotdelay detail 
rosenblum micro benchmarks evaluate performance sprite lfs 
tests measures small file performance specifically meta data operations creating deleting files reading small files 
kilobyte files created read creation order deleted 
shows results benchmark file systems 
rosenblum create delete tests lfs limited processor speed sun ffs limited disk bandwidth 
measurements disk cpu utilization show lfs uses cpu creates deletes 
ffs uses 
lfs results tests scaled cpu scale factor sun ffs results scaled average access scale factor 
log structured file systems provide order magnitude performance improvement fast file systems create phase benchmark 
files small aspect benchmark dominated performance meta data operations lfs provides superior performance batches operations 
read test performance limited disk bandwidth scale sprite lfs sun ffs bandwidth scale factor 
sprite benchmarks bsd benchmarks read performance lfs ffs comparable 
bsd lfs file system outperforms sprite lfs due larger track buffers bsd disk 
block inodes read disk files described inodes resident track buffer 
sprite track buffers eighth size cache file data 
parameter sprite bsd scale cpu specint disk bandwidth avg access os second table scale factors sprite bsd comparison 
order validate bsd implementation lfs scale factors compare measurements different systems 
average accesses second average seek plus half rotation 
delete test lfs systems outperform ffs systems order magnitude due meta data updates bsd lfs outperforms sprite lfs factor 
sprite lfs delete performance 
delete processing lfs requires steps 

remove directory entry 

read inode 

update appropriate segment usage information reflect kilobyte longer 

increment version number inode map 
disk required reading directories file inode blocks 
create case expect test limited cpu 
cpu processing required deletes greater required creates amount data written deletes required creates 
sprite lfs results indicate cpu saturated create test explain sprite lfs delete performance exceeds create performance 
expect deletes occur close memory speed single write benchmark write empty directories inode map segment usage table 
consistent bsd lfs results 

validation bsd lfs small file performance 
sprite lfs results scaled compensate performance different processors disks systems 
lfs create delete tests scaled cpu scale factor ffs create delete tests average access scale factor read tests bandwidth scale factor 
bsd lfs create performance approximately worse bsd processor cpu bound bandwidth scale factor half cpu scale factor 
bsd lfs read performance dominates sprite lfs due larger tracks track buffers 
explain sprite lfs delete performance 
sprite lfs bsd lfs sunos ffs bsd ffs bsd ffs create read delete files second rosenblum second benchmark evaluates performance large file test consists passes megabyte test file 

create file sequentially writing kb units 

read file sequentially kb units 

write kb data randomly kb units 

read kb data randomly kb units 

re read file sequentially kb units 
summarizes results file systems 
sequential benchmarks lfs random write test scaled bandwidth scale factor remaining random tests scaled average access time scale factor 
bsd lfs sprite lfs display nearly identical performance write tests 
read tests bsd lfs displays superior performance due aggressive read ahead clustered sequential read file read kb clusters read ahead invoked clusters individual blocks 
read ahead algorithm improves bsd lfs reread performance degrades random read performance 
file written randomly blocks segment sorted 
kilobyte requests consist logical blocks read ahead invoked second 
validation bsd lfs large file performance 
sprite lfs sequential read write random write results sun ffs sequential read write re read results scaled bandwidth scale factor 
random read sun ffs random write results scaled average access scale factor 
bsd lfs implementation offers write performance equivalent sprite lfs 
bsd lfs outperforms sequential reads due aggressive clustering read ahead 
read ahead policy responsible degraded performance random reads bsd lfs 
sprite lfs bsd lfs sunos ffs bsd ffs bsd ffs seq write seq read rand write rand read re read bandwidth mb sec blocks 
additionally logically sequential kilobyte units written buffer cache flushed disk kilobyte units blocks allocated contiguously disk 
sequential re read bsd lfs read clusters disk layout 
random read case combination readahead kilobyte size kilobyte block size worst case configuration read ahead 
random kilobyte reads block reads file system 
assume reading random kilobyte units containing blocks 
read block sequential read ahead triggered 
block read file system detects sequential access triggers read ahead operation block 
unfortunately block read block requiring seek 
sequential access read ahead invoked block 
result perform readahead want kilobyte units perform read ahead want reading kilobytes kilobyte unit 
phenomenon explains low random read performance bsd lfs 
sprite lfs read numbers consistent implementation performs read ahead 
bsd lfs random read performance inferior sprite lfs benchmarks analyzed remaining sections trigger phenomenon described 
tpc benchmark discussed section benchmark performs random size equal file system block size file system identify pattern sequential access 
rosenblum set high sun ffs expect performance comparable bsd ffs performance 
consistent results sequential write performance 
understand performance test deduce rotdelay setting rosenblum benchmarks 
typically rotdelay set optimize write performance disk revolution lost successive contiguous blocks 
sun ffs obtains approximately possible disk bandwidth writing sequentially 
consistent rotdelay block 
bsd ffs disks sufficiently faster rotdelay blocks avoid missing rotation write 
yields write performance slightly third maximal bandwidth consistent measurements 
similarity performance bsd lfs demonstrates bsd lfs equivalently performing implementation logstructured file system 
write performance sprite generally outperforms sprite reading due aggressive read ahead clustered sun ffs faithful implementation bsd ffs 
clustering modifications bsd reimplementation modifications described mcvoy 
points established compare performance bsd lfs bsd ffs clustering enhancements 
remainder lfs mean bsd lfs ffs mean bsd ffs 
sequential performance function file size comparative benchmark examines sequential read write performance file systems range file sizes 
data set consists megabytes data decomposed appropriate number files file size measured 
case small files directory lookup time dominates processing overhead files divided subdirectories containing files 
case large files mb files whichever generates data 
phases benchmark create files created issuing minimal number writes create file appropriate size 
file sizes megabytes means test program operation 
larger files os issued megabyte portions 
read file read creation order 
operations identical size create test 
write file rewritten creation order 
delete files deleted 
lfs measurements represent performance cleaner set tests file size run newly created file system 
ffs measurements represent empty file system performance new file system created file size files previous tests deleted data set created 
configurations yield optimal operating conditions file systems 
test results shown provide lfs performance ffs measurements 
cases set kilobytes maximum transfer size supported controller rotdelay parameter varies 
system rotdelay blocks provides optimal write performance rotdelay zero produces optimal read performance 
second write written write completes track buffer caches read data rotdelay unnecessary 
show results rotdelay settings 
measurements shown confidence intervals plus minus percent reported number 
create performance shows performance create phase sequential benchmarks 
lfs buffers large number writes writing data disk file creates benchmark occur asynchronously 
contrast time creat system call returns ffs guarantees file created exist system crash 
journaling file systems avoid synchronous writes ffs logging meta data operations auxiliary data structure replacing multiple random synchronous os single sequential 
files small create test measures ability systems 
create performance 
speed meta data operations dominates small files blocks kb lfs performance times better ffs 
write bandwidth system limiting factor systems perform comparably 
lfs ffs ffs file size kb throughput mb sec perform meta data operations files large create test measures write performance file systems 
expected asynchronous creation sequential writes lfs yield superior performance ffs small files 
order magnitude performance improvement advertised lfs demonstrated create benchmark file size kilobyte 
kilobyte megabyte range superiority lfs degrades factor kilobytes factor kilobytes performance megabyte 
created files large megabyte performance systems comparable 
lfs ffs systems approximately disk bandwidth losing rotation kilobyte request 
ffs achieves approximately disk bandwidth losing blocks thirds rotation kilobyte writes 
read performance shows read performance lfs ffs function log file size 
region kilobytes file systems show low bandwidth steady growth 
read performance 
files kb performance comparable file systems 
kb files composed multiple clusters seek penalties rise 
range kb mb lfs performance dominates ffs seeking cylinder groups distribute data evenly 
lfs ffs ffs file size kb throughput mb sec transfer size disk memory increases 
track buffer hide disk latency file read results separate command device 
dip performance sixteen kilobytes due fact os required read ahead operative 
region kb kb performance file systems improves approaches kb maximum size 
files larger kb occupy cluster see performance dip operation added 
ffs performance declines steeply lfs 
factors 
ffs leaves gap clusters size controlled rotdelay parameter 
rotdelay non zero new file allocated blocks placed gaps left previously created files 
file sizes greater kb files ffs increasingly fragmented 
lfs suffer fragmentation blocks file allocated contiguously 
ability achieve superior write performance ffs create test precisely limiting factor read case 
second factor indirect blocks files kb larger 
drop pronounced ffs ffs begins allocation new cylinder group indirect block added 
lfs continues allocating blocks sequentially 
third parameter adversely affect ffs read performance test creates files 
ffs cpc cylinders cycle parameter specifies number rotationally equivalent positions considered disk allocation 
block allocated preferred location selected 
location unavailable ffs attempt find cpc rotationally equivalent positions 
exactly correct allocating blocks existing file 
creating new files preferred block set block cylinder group 
file created block longer available 
ideally file allocated contiguously cpc nonzero file allocated block rotationally equivalent block cylinder group 
accessing blocks succession requires full rotation 
disk geometry today disks scsi exposed determining accurate value cpc virtually impossible 
numbers reported cpc zero 
large files file systems approach mb sec bandwidth achievable scsi bus 
overwrite performance test mb data written files created create phase benchmark 
results shown 
test ffs need perform allocation blocks reused lfs mark blocks dead create new segments 
files smaller cluster maximum size supported controller typically kb sequential layout lfs dominates 
performance drop systems kb due cluster size 
lfs ffs lose disk rotation pair files files allocated contiguously disk systems issue separate requests write 
track buffers hide effect reading diminish effect writing 
rotdelay gap alleviates problem introduces performance penalty fragmenting files blocks allocated gaps 
bsd file system enhanced new reallocation algorithm coalesces fragmented files created 
long term effects policy thoroughly investigated enable functionality test 
large files greater kb rotation ffs saves ffs lfs accounts performance improvement 

overwrite performance 
main difference overwrite test create test ffs need perform synchronous disk operations lfs invalidate dead blocks overwritten 
result performance systems closer lfs dominating files kb ffs dominating larger file sizes 
lfs ffs ffs file size kb throughput mb sec delete performance final phase benchmark consists delete phase 
test writes little data results expressed deleted files second 
asynchronous behavior lfs meta data operations provides order magnitude performance improvement small files 
sudden drop performance occurs indirect blocks required 
file exceeds direct blocks indirect block retrieved disk order free blocks ffs mark dead lfs 
large file sizes asynchronous deletes lfs provide times performance ffs 
benchmark summary summarize benchmarks lfs offers order magnitude performance improvement performing meta data operations creates deletes small medium sized files 
deletes lfs maintains performance superiority large file sizes deleting times rate ffs 
read write create bandwidth large files comparable systems 
ffs provides slightly better write performance rotdelay parameter adjusted avoid missing entire rotation lfs provides slightly better 
delete performance 
case creates delete performance measure metadata update performance asynchronous operation lfs gives order magnitude performance advantage ffs 
file size increases synchronous writes significant lfs provides factor better performance 
lfs ffs ffs file size kb files second log scale performance reading effort distribute data cylinder groups done ffs 
files smaller cluster size read performance comparable systems 
lfs provides better write performance clustering multiple small writes large contiguous ones results available bandwidth 
benchmarks shortcomings 
file systems optimal circumstances accesses sequential access order identical create order request stream single user cleaning required lfs ffs operates empty disk 
section presents demanding workload tpc transaction processing benchmark 
transaction processing performance lfs designed unix time sharing workload speculation ability convert small random os large sequential ones ideal transaction processing 
seltzer measured modified tpc implementation cleaning overhead severely limited performance 
disk full benchmark configuration 
section examine performance benchmark range file system utilizations file system utilization affect cleaning cost 
benchmark configuration identical described section file systems configured kilobyte block size match block size database indexing structures 
tpc benchmark simulates application 
files benchmark described table 
transaction account record read randomly balance updated balances associated teller branch records updated history file size description account mb byte records branch kb byte records teller kb byte records history kb append bytes transaction table file specifications tps tpc database 
system capable supporting tps scaled benchmark database allow experimentation disk utilization 
record written 
implementation supports full concurrency control ran version test minimize synchronization overhead concentrate disk behavior 
updates database logged non log residing separate disk 
application maintains mb block cache user virtual memory 
branch teller files small memory resident 
contrast account file large internal pages tree index structure memory resident 
file system activity generated transaction random read block account file followed random write user level cache file system order room newly retrieved account block 
newly retrieved account block left cache evicted 
sets results shown 
top line indicates performance lfs absence cleaner 
performance measured lowest utilization projected utilizations lfs quickly run disk space cleaner running 
second line graph shows ffs performance function file system utilization 
expected ffs shows performance fluctuation disk fuller 
exception history file disk write benchmark merely overwrites existing disk block allocation fullness disk irrelevant 
data point represents average iterations standard deviation 
absence cleaner lfs provides approximately better performance ffs 
performance difference attributed lfs ability perform random writes sequential writes 
lfs case dirty pages evicted user level buffer cache copied file system cache 
dirty blocks remain cache number dirty blocks exceeds write threshold lfs triggers disk write 
current system configuration triggering occurs blocks accumulated representing transactions 
transactions progress rate limited time required randomly read account records disk 
read copy page read kernel user cache evict page user cache copying kernel 
system copies take approximately ms ms average seek ms average rotational delay ms transfer time random read requires ms throughput transactions second 
segment flushed 
data blocks caused indirect blocks account file segment contains data blocks indirect blocks inode block segment summary total approximately kb 
bandwidth numbers section write kb rate mb sec total time seconds 
processing transactions requires ms yielding transactions second measurement 
calculation ffs simpler throughput limited performance random reads writes 
random requires ms seek ms rotation ms copy ms transfer total ms yielding throughput transactions second measurement 
cleaner changes results substantially 
file system utilization lfs performance comparable ffs yielding performance degradation due cleaner 
disk full impact increases approximately degradation observed 
news performance comparable ffs unfortunate result performance advantage lfs lost file system utilization 

transaction processing performance 
lfs potentially provide dramatically improved performance cleaner runs performance comparable ffs 
performance largely independent disk utilization steady state cleaning overhead dominated segment read time 
lfs cleaner lfs cleaner ffs disk utilization percent transactions second understand lfs performance examine operation cleaner interaction benchmark 
steady state segment lfs requires cleaner produce clean segment 
insensitive response time wished clean efficiently run benchmark disk filled clean restart benchmark 
produce best possible throughput presence cleaner 
discussed earlier lfs fills segments rate transactions kb transactions segment 
simplicity call database mb disk system mb 
requires segments transactions seconds cleaning lfs rate 
seconds elapsed lfs clean 
wish clean entire disk read segments write new ones 
assume optimistically read segments full bus bandwidth mb sec write thirds disk bandwidth mb sec missing rotation kb transfer 
cleaning process take seconds read seconds write total seconds 
utilization best case throughput presence cleaner transactions second 
measured performance 
unfortunately lfs clean optimal rate described 
transaction response unacceptably slow cleaner stopped minutes clean 
secondly calculations assumed disk read sequentially 
selection segments rosenblum cost benefit algorithm guarantee collections segments cleaned contiguous disk 
thirdly history file benchmark grows bytes transaction file system utilization increases test run 
cleaning requires multiple segments cached memory processing limit number segments cleaned simultaneously 
lfs clean maximal rate clean rate permits perform segment reads writes near optimal speed 
utilization able read dirty segments produce clean segment 
reading megabyte requires random seek ms rotation ms mb transfer ms total ms segment read 
rewriting segment requires seek rotation transfer requires ms total ms write seconds clean segment 
steady state cleaning done transactions 
throughput cleaner transactions second takes seconds execute transactions seconds clean yielding seconds tps 
measured number 
argued lfs loses performance writes indirect blocks frequently approximately seconds benchmarking environment 
current bsd lfs write policy assumes number dirty buffers cache exceeds write threshold point kernel triggers segment write generating clean buffers essential uses aggressive policy writing dirty buffers disk 
dirty indirect blocks cached benchmark number dirty data blocks allowed accumulate cache reduced segment writes occur frequently 
suboptimal benchmark believe flushing indirect blocks data blocks correct default policy 
effects free space fragmentation ffs performance lfs ffs rely allocation contiguous disk blocks achieve high levels performance 
results section obtained newly created empty file systems shortage contiguous extents free space 
real systems extended periods time months years file system expect find ideal arrangement free space 
lfs ffs deal reality different ways cause performance overhead respective file systems 
lfs relies cleaner process garbage collect old segments creating large regions free space clean segments 
cleaner imposes overhead performance lfs 
section discusses overhead context transaction processing workload 
contrast ffs assumptions layout free space file system 
ffs uses free space available disk contiguous 
fact block allocation policy ffs remained unchanged clustering added 
ffs may allocate contiguous blocks file contiguous free space available 
lfs cleaner may adversely effect performance 
fragmentation free space ffs may increase time file system utilization 
fragmentation degrade performance ffs ages 
assess risk studied collection ffs file systems file servers division applied science harvard university period months examine performance ffs file systems real workloads differs performance empty ffs file systems typically benchmarking 
data collection collected data file systems file servers 
file servers running sunos 
operating system substantially different bsd operating system study file systems nearly identical 
bsd ffs clustering enhancements originally implemented sunos 
data collection consisted daily snapshots recorded file system study 
snapshot summary file system meta data including information size configuration file system age size location file map locations free blocks file system 
interest brevity presentation limited representative file systems 
remaining file systems study demonstrated behavior similar 
important attributes file systems summarized table 
name server size mb age months ncg bpg descriptions cnews das news news articles software glan virtual installed software sources staff das news system administrators accounts usr speed user accounts usr course accounts st year grad accounts white user accounts theory table file system summary ffs fragmentation study 
file systems kilobyte block size rotdelay 
age column indicates file system age november 
subtract months obtain age study 
ncg bpg columns indicate number cylinder groups number file system blocks cylinder group respectively 
data analysis separate study performed extensive analysis snapshot data 
examining data conjunction ffs block allocation algorithm provided variety interesting information characterizing layout ffs file systems 
important results summarized 
evaluation ffs block allocation algorithm showed new file created ffs attempts allocate space starting cylinder group 
free block cylinder group allocated block new file 
ffs attempts extend file constraints rotdelay parameters 
practice means file grows uses free blocks order cylinder group 
file systems non zero rotdelay may occasionally skip blocks dictated parameter 
file systems studied rotdelay zero 
allocation pattern free space cylinder group tends unevenly distributed free space located cylinder group 
furthermore free space near cylinder group fragmented free space near 
uneven distribution free space combined ffs block allocation algorithm causes small files fragmented larger files 
small file created ffs allocates space starting cylinder group 
space highly fragmented resulting fragmented file 
space larger files allocated cylinder group large file able take advantage clustered free space cylinder group 
data collected snapshots showed block files allocated twelve different file systems allocated consecutive blocks file system 
contrast blocks allocated block files contiguous 
amount fragmentation file critical importance primary factors determining file system performance reading writing file 
performance tests sunos file systems studied active feasible run benchmarks 
meta data snapshots reconstruct file systems disk test machine 
allowed file systems analyzed quiescent environment easier study performance comparable empty file systems 
discussion term original file system refer actual file systems file servers test file system copied file system file systems reproduced test machine 
benchmarks described section run sparcstation megabytes memory running bsd lite 
details system summarized table 
order approximate original file systems configurations closely possible test file systems created values rotdelay 
test file systems configured number cylinder groups corresponding original file systems 
different sized cylinders original test ffs fragmentation benchmark configuration cpu parameters cpu sparcstation mhz disk parameters disk type fujitsu exa rpm sector size bytes sectors track cylinders tracks cylinder track buffer kb average seek ms table fragmentation benchmark configuration 
disks impossible precisely duplicate size cylinder groups slightly larger cylinder groups created test file system 
extra blocks cylinder group marked allocated test file system 
file system benchmarks rely creation new files important characteristic original file systems reproduce arrangement free space 
details precise mapping allocated blocks files directory hierarchy important little impact layout performance newly created files 
meta data copied snapshots original file systems free space bitmap cylinder group 
resulting test file system contained root directory data utilize free blocks original file system 
benchmarks section compare reconstructed file systems comparable empty file systems 
created manner described free space bitmaps modified 
create read phases sequential benchmark analyze performance file systems 
minor modification benchmark program tests 
creating files directory benchmark creates files directory 
configuration stresses file system cpu reduces processing overhead finding directory entries causes ffs create directories distributed cylinder groups 
results show performance different file sizes kilobytes kilobytes megabyte different dates spread month measurement period 
test results file size tested throughput reading creating copied file systems compared throughput corresponding empty file system 
graphs show performance test file systems percentage throughput corresponding empty file system 
disk utilization percentage total blocks allocated file system displayed 
ultimately performance benchmarks depends layout test files 
files laid contiguously disk read 
effect fragmentation ffs performance 
graphs display performance test file systems percentage performance comparable empty ffs disk 
utilization file system test date shown 
benchmarks run snapshots file systems taken th day designated months october snapshots cnews staff taken th 
file systems exhibit little deterioration time period performing empty file system performance 
changes occur correlate utilization cnews staff white usr 
see correlation file system age performance degradation 
cnews snapshot date month jan apr jul oct relative performance staff snapshot date month jan apr jul oct relative performance usr read create read create read create fs utilization snapshot date month jan apr jul oct glan snapshot date month jan apr jul oct usr snapshot date month jan apr jul oct white read create read create read create fs utilization snapshot date month jan apr jul oct relative performance written quickly 
contrast files blocks scattered disk perform 
achieving optimal file layout requires contiguous free space file system 
causes free space fragmented degrade performance file system 
factors may contribute fragmentation free space ffs high file turnover high utilization file system age 
news partition cnews example file system high turnover 
repository netnews articles files file system extremely small high rate file turnover 
cause free space rapidly fragmented 
hypothesis supported fact approximately weeks january copy file system cnews reported disk space examination file system showed free blocks megabytes free space file system fragments 
surprisingly january tests cnews exhibited greatest performance differences file systems 
test cases performance empty cnews file system 
single greatest performance difference tests kb write test cnews 
test achieved empty file system performance 
contrast glan file system little file turnover 
store sources binaries various software packages 
files file system created deleted new software installed existing software upgraded 
surprisingly glan performed better file systems 
fifteen tests copies glan achieved performance empty glan file system 
second factor contributes fragmentation high disk utilization 
highly utilized file system free blocks clustered 
effect disk utilization file system performance demonstrated file systems 
nearly large changes utilization accompanied inverse changes performance see cnews staff particularly noticeable correlation 
performance drops file systems full performance regained removing fraction files 
third parameter affecting ffs fragmentation age file system 
file system light workload little file turnover years cumulative effect small changes comparable high file turnover younger file system 
data provides evidence phenomenon inconclusive 
oldest file systems cnews staff file systems performance copied file systems performance empty file system 
discussed part cnews performance attributed usage pattern age 
test cases performed poorly staff file system tests date performed staff younger file systems 
department file systems turnover approximately years 
disks replaced data dumped restored 
informal poll indicated turnaround fairly typical coincides irs regulations concerning equipment depreciation 
file size performance graphs indicate performance differences different file sizes tested 
largest differences copied file systems empty file systems occur kb test 
kb kb sensitive file system age utilization turnover rate 
file systems ran read create tests file sizes different dates total tests 
tests kb file size performed corresponding empty file system bandwidth 
points january cnews partition 
excluding january tests cnews generally worse test tests file size kb test case achieved performance april write test glan 
tests kb files performed empty file system throughput 
remaining 
variety reasons performance differences different file sizes 
file sizes suffer increased fragmentation free space copied file systems 
noticeable kb files circumstances kb kb tests 
large size kb files allows ffs perform read ahead smaller file sizes 
read ahead helps offset cost fragmentation initiating read possibly accompanying seek data needed 
ffs benefits read ahead kb file perform predictive reading different files 
empty file system file disk track buffer file cylinder group begins track accessed rapidly 
copied file system seek required access block file 
seek initiated benchmark program issued corresponding read system call 
kb file benchmark demonstrate phenomenon ffs changes new cylinder group allocating twelve blocks file 
empty copied file systems seek required move file 
fragmentation free space little impact kb test case 
benchmark creates directories containing files 
directory placed different cylinder group 
block size kb file systems kb test case read write blocks data cylinder group seek different cylinder group start directory 
kb test spends larger portion time performing seeks test sizes 
increased fragmentation copied file systems means files directory typically spread empty file system 
large number seeks cylinder groups amount overhead introduced fragmentation smaller impact performance kb test case 
benchmark summary performance tests real world file systems indicate justification concerns performance impact fragmentation ffs 
concerns mitigated results tests 
greatest performance differences real file system empty file systems showed far smaller differences especially large files 
baker half bytes transferred disk come files mb size 
measured performance differences files tests large files performed better copied file systems 
worth noting greatest performance differences real empty file systems occurred file system demonstrates worst case behavior way 
cnews file system holds small rapidly replaced files 
file system suffered unusual fragmentation failure right large performance differences noted 
difficult imagine file system incur greater fragmentation penalty 
results show comparison ffs lfs easy 
ffs performance modified substantially tweaking parameters rotdelay cpc 
meta data operations bottleneck lfs provides superior performance ffs 
creating files kilobyte deleting files kb lfs provides order magnitude performance improvement 
improvement comes part lfs disk layout part asynchronous implementation operations 
alternatives providing asynchronous meta data operations including journaling file systems ordering updates 
ordered update approach ganger reports factor improvement ffs meta data update performance 
lfs cleaner overhead ignored ffs runs new file system file system regions performance dominance 
lfs order magnitude faster small file creates deletes 
systems comparable creates large files half megabyte 
systems comparable reads files kilobytes 
lfs read performance superior kilobytes megabytes ffs comparable 
lfs write performance superior files kilobytes 
ffs write performance superior files larger kilobytes 
cleaning overhead degrade lfs performance transaction processing environment 
fragmentation degrade ffs performance year period environments file systems news partition 
done 
effects cleaning lfs environments fully understood 
trace analysis indicates network workstations environment may sufficient idle time cleaning accomplished penalty 
availability file system benchmark source code trace data available freely 
send electronic mail margo das harvard edu 
acknowledgments people helped possible 
carl staelin kirk mckusick provided considerable help maintaining systems berkeley janusz ran data gathering scripts months john ousterhout originally suggested offered advice criticism ken lutz produced disk specifications amazing diane tang larry mcvoy john wilkes david patterson useful suggestions presentation 
baker hartman kupfer shirriff ousterhout measurements distributed file system proceedings th symposium operating system principles pacific grove ca october 
blackwell harris seltzer heuristic cleaning algorithms lfs proceedings usenix technical conference new orleans la january 
ganger patt metadata update performance file systems proceedings usenix symposium operating system design implementation monterey ca november 
howard kazar menees nichols satyanarayanan sidebotham west scale performance distributed file system acm transaction computer systems february 
lieberman hewitt real time garbage collector lifetimes objects communications acm 
mckusick joy leffler fabry fast file system unix acm transactions computer systems august 
mcvoy kleiman extent performance unix file system proceedings summer usenix anaheim ca june 
rosenblum ousterhout lfs storage manager proceedings summer usenix anaheim ca june 
rosenblum ousterhout design implementation log structured file system acm transactions computer systems february 
seltzer bostic mckusick staelin design implementation bsd log structured file system proceedings winter usenix january san diego ca 
seltzer transaction support log structured file system proceedings ninth international conference data engineering vienna austria april 
smith seltzer file layout file system performance harvard division applied sciences technical report 
transaction processing performance council tpc benchmark standard specification associates ca august 
