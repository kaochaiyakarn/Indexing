learning continuous time markov chains sample executions sen mahesh viswanathan gul agha department computer science university illinois urbana champaign agha cs uiuc edu continuous time markov chains ctmcs important class stochastic models model analyze variety practical systems 
algorithm learn synthesize ctmc model sample executions system 
apart theoretical interest expect algorithm useful verifying black box probabilistic systems compositionally verifying stochastic components interacting unknown environments 
implemented algorithm effective learning ctmcs underlying practical systems sample runs 

stochastic models continuous time markov chains ctmcs widely model practical software systems analyze performance reliability 
building complex software system ctmcs generated higher level specifications queueing networks stochastic process algebra stochastic petri nets 
models quantitative evaluation reliability performance example determine throughput production lines calculate average failure time systems find reliability performance bottlenecks system 
model validated performance reliability requirements system implemented 
model carefully validated implementation may conform model 
potential sources error bugs introduced translating design system code second estimated values various parameters constructing stochastic model may differ considerably actual values deployed system 
catch potential post implementation problems testing performance reliability performed running system large number times real environment checking reliability problems performance bottlenecks 
difficult achieve complete coverage testing despite evident importance practice testing fails guarantee full correctness deployed system 
approach tries leverage benefits formal analysis usually done design phase phase learning model sample executions system formally verifying learnt model design specification 
approach fruitfully model check unknown black box systems learn unknown environments assist compositional verification systems 
efforts apply non deterministic discrete systems extended general stochastic systems 
machine learning algorithms grammatical inference successfully applied pattern recognition speech recognition natural language processing domains algorithms literature learn real time stochastic models typically model systems formal verification 
address problem presenting algorithm execution traces possibly obtained running deployed system testing system infers ctmc model generated traces observed distribution 
learned ctmc existing probabilistic model checking performance evaluation tools analysis helping find bugs post implementation phase 
learning algorithm may potentially perform automatic compositional verification stochastic systems 
closely related learn continuous time hidden markov models performance evaluation 
fix size continuous time hidden markov model learning 
restrictive system modelled continuous time hidden markov model size 
approach restriction 
algorithm show correctly identifies ctmc model limit samples drawn distribution generated ctmc 
technical difficulty talking samples drawn ctmc traditionally ctmcs unlabeled runs sequences states traversed traces 
problem samples drawn implementation get ting information uniquely identifies states expensive impractical lead construction large model collapse equivalent states 
address difficulty introduce model edge labeled continuous time markov chain ctmc edges labeled finite set alphabet traces sequences edge labels learning algorithm 
algorithm state merging paradigm introduced 
samples provided learning algorithm construct call prefix tree continuous time markov chain 
markov chains simplest ctmc consistent samples 
algorithm progressively generalizes model produces models additional behaviors merging pairs states equivalence sample evidence 
traces complete state information original ctmc states statistical information samples distinguish states 
key algorithmic insight determining statistical tests conclude equivalence states confidence 
candidate states tested equivalence algorithm done carefully chosen order ensure algorithm runs time polynomial sample size 
algorithm terminates tested possible merges 
algorithms learn limit show algorithm learns correct ctmc sufficiently large sample 
proof algorithm learns limit relies novel method bound error probability statistical tests 
ctmc algorithm learns may smaller implementation merges potentially equivalent states generates reachable portion implementation 
particularly beneficial context formal verification running time space requirements verification algorithms depend size reachable portion model 
implemented algorithm java experimented learning example systems encountered practice 
rest organized follows 
give preliminary definitions notations section followed learning algorithm section 
section prove learned ctmc converges original ctmc limit 
report initial experimental results section conclude section 
preliminaries recall basic concepts related ctmcs 
presentation material slightly non standard consider ctmcs labels edges states 
follows assume ap finite set atomic propositions describing reliability performance constraints 
definition edge labeled continuous time markov chain ctmc tuple finite set states finite alphabet edge labels initial state partial function maps state alphabet state function returns positive real called rate associated transition 
assume defined 
ap function assigns state set atomic propositions valid defined deterministic sense state alphabet state reached edge labeled unique exists 
intuitively probability moving state state edge labeled time 
probability corresponds cumulative probability exponential distribution rate 
state alphabet competition transitions 
precisely transition random time sampled exponential distribution rate 
transition corresponding lowest sampled time taken 
probability move state state edge time units time sampled transition corresponding minimum total rate transition state taken 
words probability leaving state time units 
distribution minimum time edges exponential rate 
see probability moving state edge probability staying state time units times probability edge probability edge state define paths probability space path starting state finite infinite sequence corresponding sequence states path th state path time spent state maximal path starting state path starting infinite finite length set maximal paths starting state denoted path set maximal paths ctmc denoted path taken path initial state 
ak finite sequence sequence states 
initial state denote state sequence corresponding 

non empty intervals 
denotes cylinder set consisting paths path smallest algebra path contains cylinders 

probability measure unique measure inductively defined path prob 
prob 
sk sk inf sup 
learning edge labeled ctmcs learning problem considered falls category stochastic grammatical inference 
stochastic grammatical inference samples taken stochastic language 
samples stochastic language learned finding statistical regularity samples 
parameters different distributions determining language estimated relative frequencies samples 
learning algorithms shown learn stochastic language limit number samples tends infinity learned language language generated sample 
algorithms essentially follow technique build prefix tree automata stores exactly samples test merge possibly equivalent states 
algorithm learning edge labeled ctmcs 
consider issue generate reason behaviors visible execution traces finite length traditionally behaviors assumed infinite length 
concepts algorithm 
algorithm proof correctness appears section 

generating samples consider problem learning ctmc examples generated simulating system investigation 
way ctmc formally defined section behaviors maximal executions maximal executions typically infinite 
creates technical difficulty samples appropriate learning 
overcome problem define finitary version ctmc called finitary edge labeled continuous time markov chains ctmc ctmc non zero stopping probability state 
allows generate reason behaviors finite length 
important note ctmc merely technical tool 
primary goal learn underlying ctmc shall see proposition achieve learning ctmc effort specific value stopping probability influence correctness result 
formal definition ctmc definition finitary edge labeled continuous time markov chain ctmc pair ctmc denotes stopping probability state exists trivial surjection finite sequence path ctmc starting state iff path necessarily maximal starting set paths starting state denoted path 
th state path time spent th state defined similarly denoted respectively field corresponding ctmc defined analogously ctmc path state probability ctmc exhibits path prob ctmc extend ctmc associating known probability say stopping probability 
ctmc obtained simulated get multi set finite samples treat multi set examples learning 
algorithm assume finite multi set examples ctmc extended known stopping probability ctmc goal learn multi set examples 
note implemented system seen software program example generated way 
initial state program 
add example sequence 
set probability 
probability return current sequence example 
probability execute instruction program 
execution instruction takes time results change state add example sequence 

definitions define notations concepts describe learning algorithm 
ctmc extend definition follows empty string xa defined xa undefined example string 
pr denote set xy pr set prefixes multi set examples pr set pr 
exists example 
define number pr minus number counts number examples prefix number examples prefix length length example 

words denotes time spent state reached define follows xa note gives estimate state gives estimate 
multi set examples construct prefix tree ctmc defined follows 
definition prefix tree ctmc multiset examples ctmc 
pr 
empty string 
xa xa 




stopping probability associated ctmc generated examples 
ctmc consistent examples sense example corresponding path ctmc learning algorithm proceeds generalizing initial guess merging equivalent states 
formal definition states equivalent 
definition ctmc relation said stable relation exists exists conversely exists exists states ctmc said equivalent stable relation correctness learning algorithm crucially depends fact merging equivalent states results ctmc generates distribution 
state prove formally simple observation equivalent states 
lemma ctmc path starting iff path starting prob prob 
proof path starting sequence states state continuing inductively construct sequence states path starting furthermore know prob prob 
paths starting argument symmetric 
definition ctmc initial states respectively said equivalent path path path prob prob 
ctmc minimal ctmc defined quotient respect equivalence relation states 
formally minimal ctmc 
equivalence classes respect 
equivalence class 
iff 

observe defined way defined 
proposition ctmc equivalent minimal ctmc corresponding proof proof straightforward consequence definition minimal ctmc relies observation path sequence states visited iff furthermore probabilities 
conclude section observation equivalent ctmc stopping probability associated ctmc define probability space set paths 
proposition proposition shows ctmc construct smaller equivalent ctmc merging equivalent states providing mathematical justification algorithm 
proposition ctmc stopping probability probability spaces defined 
skip proof proposition interests space 
point important consequences proposition 
learn ctmc stopping probability generate samples system underlying ctmc equivalent terms distribution traces generate 
second specific value stopping probability plays role proving correctness learning algorithm 
may effect terms length traces produced number traces needed learn 
right choice stopping probability determined empirical constraints working 

learning algorithm algorithm input multi set examples confidence level output ctmc compatible merge exit loop endif return 
algorithm learn ctmc algorithm ctmc learning described constructs prefix tree ctmc multi set examples assume states ordered lexicographic order 
number states algorithm tries merge pairs states equivalent quadratic loop algorithm tries merge states 
order 
states equivalent merged method merge 
smallest state block merged states represent block 
merge state resulting ctmc may non deterministic 
equivalence implies successor equivalent corresponding successor means successors get merged 
ensure method described invoked removes non determinism sequence merges 
merge probabilities rates re computed state information available state 
algorithm stops merging possible 
lexicographic ordering aa ab ba bb aaa 
algorithm input output ctmc merge return 
removes non determinism observations proposition suggest algorithm correct test equivalence states 
case built experimental data 
approximately check equivalence states recursively statistical hypothesis testing 
say states compatible denoted means equal statistical uncertainty similarly 
decision compatibility function compatible described 
algorithm compatible input output boolean return false return false xa ya return false compatible return false endfor return true 
compatible checks states approximately equivalent check performed function described uses statistical hypothesis testing 
function checks means exponential distributions different 
exponential distributions means want check fact fact equivalent checking fact 
statistical terms call null hypothesis denoted alternate hypothesis denoted 
test hypothesis draw samples say 
exponential distribution mean samples say 
exponential distribution mean estimate respectively 
ratio check follows say 
random samples random variables 
exponential distribution mean similarly 
random samples random variables 
exponential distribution mean shown methods moment generating function random variables distributions respectively 
implies ratio distribution degrees freedom 
assuming holds distribution 
introduce random variables experimental value gives random sample random variable random variable distribution degrees freedom 
chebyshev inequality get prob prob mean standard deviation 
get prob calculate probability observation called value value prob prob similarly value value prob prob calculated value cases say evidence reject null hypoth equivalent say reject 
algorithm input output boolean return false return 
checks estimated exponential means different parameter calculating check performed function see hoeffding bounds similar 
method checks means bernoulli distributions statistically different 
tries tries bernoulli distribution mean tries tries bernoulli distribution mean say statistically log note possible tests multinomial test compare means bernoulli distributions 
algorithm input output boolean return false return log 
checks estimated bernoulli means different 
complexity worst case running complexity algorithm cubic sum length samples 
experiments running time grows linearly sum length sample lengths 
parameter influences size sample needed converging right model 
exact dependence sample size open problem needs investigation 

learning limit order prove correctness algorithm need show ctmc learning algorithm produces eventually equivalent model generate samples 
proof proceeds steps 
show learning algorithm eventually usually called structurally complete sample 
structurally complete sample multi set traces traces visit reachable state transition 
formally state target ctmc trace states visited trace produced reachable transition trace traversed observe structurally complete structurally complete 
second step proof involves showing keep adding samples structurally complete set eventually learn right ctmc steps show algorithm learn target ctmc limit 
thing observe ctmc finite structurally complete sample set 
structurally complete sample set ctmc stopping probability 
observe prob finite nonzero 
probability samples generated tends increases 
string eventually generated sample learning algorithm eventually structurally complete 
main challenge proof correctness show structurally complete sample eventually learn right ctmc follows simply assume refer sample mean structurally complete 
observe structurally complete sample right ctmc results merging equivalent states 
check compatibility exact equivalence errors algorithm result check compatibility states 
types errors context 

type error compatibility returns false states equivalent 
type ii error compatibility returns true states equivalent goal reduce errors possible 
show goes infinity global contribution errors tend zero 
observe number states grow fast 
number states target ctmc number merges performed algorithm giving correct ctmc 
recall value tests performed functions 
global type error bounded error negligible independent size kt small constant making small ensure learning algorithm merges equivalent states 
errors learning algorithm confined resulting merging inequivalent states 
absence type errors learning algorithm outputs ctmc states form partition target ctmc upper bound type ii errors probability error occurs comparing states target ctmc probability merging non equivalent states get type ii error 
show tends sample size grows know algorithm eventually errors 
observe probability merging pair states bounded probability returning true actual means different 
order show learning algorithm eventually gives right answer need show probability error means different tends 
consider procedures separately bound error 
case assume 
recall mean standard deviation say observation provides evidence 
prob prob rr rr prob rr rr distribution 
chebyshev inequality know prob rr rr prob prob rr rr observe rr rr plugging values observe tends 
case 
random variable mean bernoulli trials mean mean bernoulli trials mean recall say observation variable observation log try bound probability happens 
observe var var var prob prob 
chebyshev inequality var var observe grow linearly increases kt needed order eliminate type errors bounded tends grows 
var tends grows 
vanishes proving limit type ii errors eliminated 

tool experiments implemented learning algorithm java sub component tool vesta verification statistical analysis 
tool takes multi set examples generated simulation system having unknown ctmc model 
examples tool learns underlying ctmc value 
learned model verification csl formulas statistical model checker vesta model checkers prism tested performance tool ctmc models 
ctmc model performed discrete event simulation get large number examples learned ctmc examples 
checked learned ctmc equivalent original ctmc generated examples 
learned ctmc equivalent original ctmc experiments provided number samples large 
experiments assumed set atomic propositions state available osl cs uiuc edu vesta 
assumed show working statistical tests 
take atomic propositions consideration learning faster atomic propositions sufficient distinguishing certain states 
report results experiments performed pentium iii ghz laptop mb sdram 
symmetric ctmc ctmc carefully selected contains states 
probability edges labeled states total rates transitions take place states different 
distinguish states comparison total rates required 
similar case states 
hand total rates states probability edges different distinguish states 
true states 
example shows effectiveness functions learning 
ctmc generate samples learn ctmc samples ctmc learned original ctmc 
symmetric ctmc triple modular redundant system example ctmc representing model triple modular redundant system tmr 
example taken 
ignore atomic propositions true state show effectiveness statistical test 
generated samples discrete event simulation ctmc assume samples coming actual running system 
plot average number states learned ctmc time taken learning number samples learning 
number states converges sample large 
time taken learning grows linearly number samples 
samples algorithm learns ctmc seconds 
small number samples due lack sufficient information algorithm tends generalize resulting number states learned ctmc tandem queuing network practical example considered cox queue sequentially composed queue 
example taken 
denotes capacity queues algorithm learned ctmc model states 
number samples required case learn underlying ctmc quite large 
particular experiment suggests learning underlying ctmc large systems may require large number samples 
effective technique verify approximate model learnt small number samples 
model learnt approximate result verification approximate 
suggests confidence verification quantified reasonably 
quantification remains open problem 

novel machine learning algorithm learn underlying edge labeled continuous time markov chains deployed stochastic systems know model hand 
important aspect learning algorithm learn formal stochastic model traces generated testing executing deployed system 
learnt ctmc verify deployed systems existing probabilistic model checking tools 
check learnt model bisimilar model specification 
allows check deployed system correctly implements specification respect set formulas provide implementation algorithm various tools 
limitations may scale systems having large underlying ctmc model 
needs develop techniques perform approximate verification model learnt 
accuracy verification technique increase increase number samples 
difficult part developing approach correctly quantify confidence accuracy verification 
technique verification black box systems practical approach exist testing discrete event simulation 
supported part darpa task award darpa afosr muri award onr motorola motorola rps ant 
benefitted considerably collaboration number samples number states number samples 
learning tmr learning verify framework verifying infinite state systems 
tom brown giving feedback previous version 
angluin 
learning regular sets queries counterexamples 
infor 
comp 
baier hermanns katoen 
model checking continuous time markov chains transient analysis 
computer aided verification cav volume lncs pages 
springer 
baier katoen hermanns 
simulation continuous time markov chains 
th international conference concurrency theory concur volume lncs pages 
springer 
balbo conte marsan 
modelling generalized stochastic petri nets 
john wiley sons 
baum petrie soules weiss 
maximization technique occuring statistical analysis probabilistic functions markov chains 
annals mathematical statistics 
carrasco oncina 
learning stochastic regular grammars means state merging method 
international colloquium grammatical inference applications volume lncs 
springer 
giannakopoulou pasareanu 
learning assumptions compositional verification 
tools algorithms construction analysis systems tacas volume lncs pages 
gold 
language identification limit 
information control 
peled yannakakis 
adaptive model checking 
tools algorithms construction analysis systems tacas volume lncs pages 

performance computer communication systems model approach 
wiley 
hermanns herzog katoen 
process algebra performance evaluation 
theoretical computer science 
hermanns katoen meyer 
tool model checking markov chains 
software tools technology transfer 
hermanns meyer 
multiterminal binary decision diagrams represent analyse continuous time markov chains 
workshop numerical solution markov chains 

compositional approach performance modelling 
cambridge university press 
hogg craig 
mathematical statistics 
macmillan new york ny usa 
dupont 
stochastic grammatical inference multinomial tests 
grammatical inference algorithms applications volume lecture notes artificial intelligence 
springer 
kwiatkowska norman parker 
prism probabilistic symbolic model checker 
computer performance evaluation modelling techniques tools tools volume lncs pages 
nelson 
applied life data analysis 
wiley 
oncina garcia 
inferring regular languages polynomial update time 
pattern recognition image analysis volume series machine perception artificial intelligence pages 

ron singer tishby 
learnability usage acyclic probabilistic finite automata 
journal computer system sciences 
sen viswanathan agha 
statistical model checking black box probabilistic systems 
th conference computer aided verification cav lncs appear 
springer july 
stewart 
numerical solution markov chains 
princeton 
wei wang towsley 
continuous time hidden markov models network performance evaluation 
performance evaluation september 
younes kwiatkowska norman parker 
numerical vs statistical probabilistic model checking empirical study 
tools algorithms construction analysis systems tacas volume lncs 
springer 

