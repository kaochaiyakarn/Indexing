differential evolution simple efficient adaptive scheme global optimization continuous spaces rainer storn kenneth price tr march new heuristic approach minimizing possibly nonlinear non differentiable continuous space functions 
means extensive testbed includes de jong functions demonstrated new method converges faster certainty adaptive simulated annealing annealed nelder mead approach reputation powerful 
new method requires control variables robust easy lends parallel computation 
international computer science institute center street berkeley ca suite fax 
mail storn icsi berkeley edu 
leave siemens ag sn ring muenchen germany 
fax email rainer storn siemens de 
owl circle ca community net 
problems involve global optimization continuous spaces ubiquitous scientific community 
general task optimize certain properties system choosing system parameters 
convenience system parameters usually represented vector 
standard approach optimization problem begins designing objective function model problem objectives incorporating constraints 
especially circuit design community methods need objective function 
methods formulating problem simpler usually inferior techniques full objective function 
consequently restrict optimization methods fully objective function 
cases objective function designed transform optimization problem minimization task 
limit investigation minimization problems 
objective function nonlinear non differentiable direct search approaches methods choice 
best known algorithms nelder mead hooke jeeves genetic algorithms evolutionary algorithms truly continuous counterparts genetic algorithms 
heart direct search method strategy generates variations parameter vectors 
variation generated decision accept newly derived parameters 
basic direct search methods greedy criterion decision 
greedy criterion new parameter vector accepted reduces value objective function 
greedy decision process converges fairly fast runs risk trapped local minimum 
inherently parallel search techniques genetic evolutionary algorithms built safeguards 
running vectors simultaneously superior parameter configurations help vectors escape local minima 
method parameter vector local minimum simulated annealing 
annealing relaxes greedy criterion occasionally permitting uphill move 
moves potentially allow parameter vector climb local minimum 
number iterations increases probability accepting uphill move decreases 
long run leads greedy criterion 
direct search methods lend annealing just random walk simplest case evolutionary algorithm 
attempts anneal direct searches method nelder mead genetic algorithms 
users generally demand practical optimization technique fulfill requirements 
method find true global minimum regardless initial system parameter values 
second convergence fast 
third program minimum control parameters easy 
search fast easy sure fire technique developed method simple performs extremely wide variety test problems 
inherently parallel lends computation network computers processors 
basic strategy employs difference randomly selected parameter vectors source random variations third parameter vector 
rigorous description new optimization method call differential evolution 
problem formulation consider system real valued properties 
constitute objectives system optimized 
additionally may real valued constraints 
describe properties system need optimized shall degraded 
example may wish design mobile phone dual objectives maximizing transmission power minimizing noise audio amplifier simultaneously keeping battery life certain threshold 
properties represent objectives optimized constraint 
properties system dependent real valued parameters 

case mobile phone parameters resistor capacitor values 
technical systems realizability requires jl jh 
usually restrictions incorporated collection mp constraints 
optimization system means vary dimensional parameter vector 
properties optimized constraints mp met 
optimization task reformulated minimization problem min represents function property calculated optimization constraint preservation represented minimization 
functions combined single objective function usually computed weighted sum max 
weighting factors define importance associated different objectives constraints normalize different physical units 
optimization task restated min min max formulation guarantees local minima pareto critical points including possibly multiple global minima pareto points theoretically 
objective function true region realizability convex general apply technical problems 
method differential evolution differential evolution de novel parallel direct search method utilizes np parameter vectors 
np 
population generation np doesn change minimization process 
initial population chosen randomly known system 
rule assume uniform probability distribution random decisions stated 
case preliminary solution available initial population generated adding normally distributed random deviations nominal solution nom crucial idea de new scheme generating trial parameter vectors 
de generates new parameter vectors adding weighted difference vector population members third member 
resulting vector yields lower objective function value predetermined population member newly generated vector replaces vector compared 
comparison vector need part generation process mentioned 
addition best parameter vector best evaluated generation order keep track progress minimization process 
extracting distance direction information population generate random deviations results adaptive scheme excellent convergence properties 
tried variants de promising subsequently greater detail 
scheme de variant de works follows vector np trial vector generated np integer mutually different 
integers chosen randomly interval np different running index real constant factor controls amplification differential variation fig 
shows dimensional example illustrates different vectors play part de 
np parameter vectors generation newly generated parameter vector minimum fig dimensional example objective function showing contour lines process generating scheme de 
order increase diversity parameter vectors vector formed acute brackets denote modulo function modulus certain vector elements identical elements elements acquire original values choosing subgroup parameters mutation similiar process known crossover evolution theory 
idea illustrated fig 

starting index randomly chosen integer interval 
integer drawn interval probability pr cr cr crossover probability constitutes control variable de scheme 
random decisions anew trial vector aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa aaaa parameter vector containing parameters 
fig 
illustration crossover process 
order decide new vector shall population member generation compared vector yields smaller objective function value set old value retained 
scheme de basically scheme de works way de generates vector best introducing additional control variable idea provide means enhance greediness scheme incorporating current best vector best feature useful non critical objective functions 
fig 
illustrates vector generation process defined 
construction decision process identical de 
np parameter vectors generation newly generated parameter vector minimum best best fig dimensional example objective function showing contour lines process generating scheme de 
competing minimization methods order compare de method global minimizing strategies looked approaches source code readily available known powerful capable coping nonlinear non differentiable functions 
methods particular interest 
annealed version nelder mead strategy appealing adaptive scheme generating random parameter deviations 
annealing part switched fast converging direct search method remains especially useful non critical objective functions 
basic control variables starting temperature tf temperature reduction factor nv number random variations temperature level 
second method interest adaptive simulated annealing asa claims converge quickly outperform genetic algorithms de jong test suite 
asa provides dozen control variables turned just temperature ratio scale trs temperature anneal scale tas significant impact minimization process 
compare asa de de 
research wrote annealed version hooke jeeves method tested monte carlo methods np parallel vectors differential mutation scheme de 
approaches worked quickly turned competitive 
testbed function testbed contains de jong test functions plus additional functions distinctive difficulties global minimizer de jong function sphere considered simple task serious minimization method 
minimum 
second de jong function rosenbrock saddle just parameters reputation difficult minimization problem 
minimum 
third de jong function step necessary incorporate constraints imposed objective function 
implemented min max formulation 
minimum 
step function exhibits plateaus pose considerable problem minimization algorithms 
modified fourth de jong function quartic function designed test behavior minimization algorithm presence noise 
original de jong function random variable produced gaussian noise having distribution 
function appears flawed definite global minimum exists 
response problem followed suggestion chose random variable uniform distribution bounded 
contrast original version de jong quartic function included inside summation just adding summation result 
change difficult minimize 
functional minimum expectation fifth de jong function ij mod global minimum function 
parabola sgn 
sgn 
defines paraboloid axes parallel coordinate axes 
set holes increase depth closer approaches origin 
minimization algorithm goes strictly downhill captured holes 
minimum griewangk function cos test function local minima difficult find true minimum 
zimmermann problem finding minimum poses special problem minimum located corner constrained region defined 
polynomial fitting problem integer polynomial degree coefficients chebychev polynomial degree 
chebychev polynomials defined recursively difference equation integer initial conditions solution polynomial fitting problem course polynomial oscillates argument 
outside tube polynomial rises steeply direction high positive ordinate values 
polynomial fitting problem roots electronic filter design challenges optimization procedure forcing find parameter values grossly different magnitudes common technical systems 
test suite employed 
weighted sum squared errors order transform constrained optimization problem objective function minimized 
starting values parameters drawn randomly interval 
test results tried optimize algorithms experimenting find control settings provided fastest smoothest convergence 
table contains choice control variable settings minimization algorithm test function averaged number function evaluations nfe required find global minimum 
asa de de tf nv nfe trs tas nfe np cr nfe np cr nfe 
table averaged number function evaluations nfe required finding global minimum 
hyphen indicates stands applicable 
corresponding field number function evaluations contains hyphen global minimum 
number enclosed parentheses test runs provided global minimum 
executed test runs randomly chosen initial parameter vectors test function minimization 
global minimum defined minimization task completed final value obtained accuracy better chose value indicate global minimum value case 
differential evolution method de minimizing continuous space functions introduced shown superior adaptive simulated annealing asa annealed nelder mead approach 
de technique converge functions test function suite 
problems asa find minimum de usually converged faster especially difficult cases 
de inherently parallel significant speedup obtained algorithm executed parallel machine network computers 
especially true real world problems computing objective function requires significant amount time 
despite promising results de infancy probably improved 
research include mathematical convergence proof exists simulated annealing 
theoretically sound analysis determine de converges great interest 
annealed version de combination de optimization approaches practical unanswered 
important practical applications gain knowledge choose control variables de 

brayton sangiovanni vincentelli survey optimization techniques integrated circuit design proc 
ieee pp 


optimization circuits large number parameters archiv 
band heft pp 

storn optimization dr dobb journal may pp 


garside optimisation methods pascal edward arnold publ 

goldberg genetic algorithms search optimization machine learning addison wesley 

rechenberg evolutionsstrategie optimierung technischer systeme nach prinzipien der biologischen evolution 
frommann holzboog stuttgart 

voigt fuzzy evolutionary algorithms technical report tr icsi ftp icsi berkeley edu 

simulated annealing practice versus theory 
comput 
modelling vol 
pp 


rosen genetic algorithms fast simulated comparison 
comput 
modelling vol 
pp 


press teukolsky vetterling flannery numerical recipes cambridge university press 

price genetic annealing dr dobb journal oct pp 


algorithmen zur optimierung von zur diss 
am inst 
fuer und der univ stuttgart 

martini minimizing multimodal functions continuous variables simulated annealing algorithm acm trans 

software march pp 


griewangk generalized descent global optimization vol 
pp 


zimmermann operations research oldenbourg 

rabiner gold theory applications digital signal processing prentice hall englewood cliffs 

