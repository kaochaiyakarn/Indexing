cluster scalable network services armando fox steven gribble chawathe eric brewer paul gauthier university california berkeley inktomi fox gribble brewer cs berkeley edu gauthier inktomi com identify fundamental requirements scalable network services incremental scalability overflow growth provisioning availability fault masking 
argue clusters commodity workstations interconnected high speed san exceptionally suited meeting challenges internet server workloads provided software infrastructure managing partial failures administering large cluster reinvented new service 
propose general layered architecture building cluster scalable network services encapsulates requirements reuse service programming model composable workers perform transformation aggregation caching customization tacc internet content 
performance implementation simplicity architecture tacc programming model exploit base weaker acid data semantics results trading consistency availability relying soft state robustness failure management 
architecture shelf infrastructural platform creating new network services allowing authors focus content service composing tacc building blocks implementation 
discuss real implementations services architecture transend web distillation proxy deployed uc berkeley dialup ip population hotbot commercial implementation inktomi search engine 
detailed measurements transend performance substantial client traces anecdotal evidence transend hotbot experience support claims architecture 
design goals create computing system capable meeting requirements large computer utility 
systems run continuously reliably days week hours day capable meeting wide service demands 
system ultimately comprehensive able adapt unknown requirements framework general capable evolving time multics normally viewed operating system multics multiplexed information computer service originally conceived infrastructural computing service surprising goals stated similar 
primary obstacle deploying multics absence network infrastructure place 
network applications exploded popularity part easier manage evolve desktop application counterparts eliminate need software distribution simplify customer service bug tracking avoiding difficulty dealing multiple platforms versions 
basic queueing theory shows large central virtual server efficient cost utilization collection smaller servers standalone desktop systems represent degenerate case server user 
support argument network computers 
network services remain difficult deploy fundamental challenges scalability availability cost effectiveness 
scalability mean load offered service increases incremental linear increase hardware maintain user level service 
availability mean service available despite transient partial hardware software failures 
cost effectiveness mean service economical administer expand potentially comprises workstation nodes 
observe clusters workstations fundamental properties exploited meet requirements commodity pcs unit scaling allows service ride leading edge cost performance curve inherent redundancy clusters mask transient failures embarrassingly parallel network service workloads map networks workstations 
developing cluster software administering running cluster remain complex 
primary contributions design analysis implementation layered framework building network services addresses complexity 
new services framework shelf solution scalability availability problems focus content service developed 
lower layer handles scalability availability load balancing support bursty offered load system monitoring visualization middle layer provides extensible support caching transformation mime types aggregation information multiple sources personalization service large number users mass customization 
top layer allows composition transformation aggregation specific service accelerated web browsing search engine 
pervasive design implementation strategies observation data manipulated network service tolerate semantics weaker acid 
combine ideas prior tradeoffs availability consistency soft state robust fault tolerance characterize data semantics network services refer base semantics basically available soft state eventual consistency 
addition demonstrating base simplifies implementation architecture programming model service authoring fit base semantics maps cluster service framework 
validation real services framework reflects implementation real network services today transend scalable transformation caching proxy berkeley dialup ip users connecting bank modems inktomi search engine commercialized hotbot performs millions queries day database web pages 
inktomi search engine aggregation server initially developed explore cluster technology han dle scalability availability requirements network services 
commercial version hotbot handles queries day full text database web pages 
incrementally scaled nodes provides high availability extremely cost effective 
inktomi predates framework describe differs respects 
strongly influenced framework design validate particular design decisions 
focus detailed discussion transend provides web caching data transformation 
particular real time datatype specific distillation refinement inline web images results latency reduction factor giving user responsive web surfing experience modest image quality degradation 
transend developed uc berkeley deployed dialup ip users deployed similar community uc davis 
remainder section argue clusters excellent fit internet services provided challenges describe cluster software development 
section describe proposed layered architecture building new services programming model creating services maps architecture 
show transend hotbot map architecture hotbot justify specific design decisions architecture 
sections describe transend implementation measured performance including experiments scalability fault tolerance properties 
section discusses related continuing evolution summarize observations contributions section 
advantages clusters particularly area internet service deployment clusters provide primary benefits single larger machines smps incremental scalability high availability cost performance maintenance benefits commodity pc elaborate turn 
scalability clusters suited internet service workloads highly parallel independent simultaneous users grain size typically corresponds cpu seconds commodity pc 
workloads large clusters dwarf power largest machines 
example inktomi hotbot cluster contains nodes processors gb physical memory hundreds commodity disks 
wal mart uses cluster teradata processors terabytes online storage 
furthermore ability grow clusters incrementally time tremendous advantage areas internet service deployment capacity planning depends large number unknown variables 
incremental scalability replaces capacity planning relatively fluid scaling 
clusters correspondingly eliminate upgrade throw current machine related investments replace larger 
high availability clusters natural redundancy due independence nodes node busses power supply disks merely matter software mask possibly multiple simultaneous transient faults 
natural extension capability temporarily disable subset nodes upgrade place hot upgrade 
capabilities essential network services users come expect hour uptime despite inevitable reality hardware software faults due rapid system evolution 
commodity building blocks final set advantages clustering follows commodity building blocks high low volume machines 
obvious advan tage cost performance memory disks nodes track leading edge example changed building block time grew hotbot cluster time picking reliable high volume previous generation commodity units helping ensure stability robustness 
furthermore commodity vendors compete service particularly pc hardware easy get high quality configured nodes hours 
contrast large smps typically lead time days cumbersome purchase install upgrade supported single vendor harder get help difficulties arise 
simple matter software tie collection possibly heterogeneous commodity building blocks 
summarize clusters significant advantages scalability growth availability cost 
fundamental advantages easy realize 
challenges cluster computing number areas clusters disadvantage relative smp section describe challenges influenced architecture propose section 
administration administration serious concern systems nodes 
leverage ideas prior describes unified monitoring reporting framework data visualization support effective tool simplifying cluster administration 
component vs system replication commodity pc cluster usually powerful support entire service probably support components service 
component level system replication allows commodity pcs serve unit incremental scaling provided software naturally decomposed loosely coupled modules 
address challenge proposing architecture component circumscribed functional responsibilities largely interchangeable components type 
example cache node run disk available worker performs specific kind data compression run significant cpu cycles available 
partial failures component level replication leads directly fundamental issue separating clusters smps need handle partial failures ability survive adapt failures subsets system 
traditional workstations smps face issue machine 
shared state smps clusters shared state 
done emulate global shared state software distributed shared memory improve performance reduce complexity avoid minimize need shared state cluster 
concerns partial failure shared state lead focus sharing semantics required network services 
base semantics believe design space network services partitioned data semantics service demands 
extreme traditional transactional database model acid properties atomicity consistency isolation durability providing strongest semantics highest cost complexity 
acid guarantees regarding availability preferable acid service unavailable function way relaxes acid constraints 
acid semantics suited internet commerce transactions billing users maintaining user profile information personalized services 
internet services primary value user necessarily strong consistency durability high availability data stale data temporarily tolerated long copies data eventually reach consistency short time dns servers reach consistency entry timeouts expire 
soft state regenerated expense additional computation file exploited improve performance data durable 
approximate answers stale data incomplete soft state delivered quickly may valuable exact answers delivered slowly 
refer data semantics resulting combination techniques base basically available soft state eventual consistency 
definition data semantics strictly acid base 
base semantics allow handle partial failure clusters complexity cost 
pioneering systems grapevine base reduces complexity service implementation essentially trading consistency simplicity systems bayou allow trading consistency availability base provides opportunities better performance :10.1.1.40.8955
example acid requires durable consistent state partial failures base semantics allows avoid communication disk activity postpone convenient time 
practice simplistic categorize service acid base different components services demand varying data semantics 
directories yahoo 
maintain database soft state base semantics keep user customization profiles acid database 
transformation proxies interposed clients servers transform internet content fly transformed content base data regenerated computation service bills user session billing certainly delegated acid database 
focus services acid component manipulate primarily base data 
web servers search aggregation servers caching proxies transformation proxies examples services framework supports superset services providing integrated support requirements :10.1.1.21.1584
show base semantics greatly simplify implementation fault tolerance availability permit performance optimizations framework precluded acid 
cluster scalable service architecture section propose system architecture model building scalable network services clusters 
architecture attempts address challenges cluster computing challenges deploying network services exploiting clusters strengths 
view contributions follows proposed system architecture scalable network services exploits strengths cluster computing exemplified cluster servers transend hotbot 
separation content network services services implementation encapsulating scalable network service sns requirements high availability scalability fault tolerance reusable layer narrow interfaces 
programming model composition stateless worker modules new services 
model maps system architecture numerous existing services wide area network fe fe fe ms ms ms system area network ws ws ws graphical monitor manager user profile db worker pool worker api architecture generic sns 
components include front ends fe pool workers may caches user profile database graphical monitor fault tolerant load manager functionality logically extends manager stubs ms worker stubs ws 
map directly 
detailed measurements production service instantiates architecture validates performance reliability claims 
remainder section review benefits challenges cluster computing propose network service architecture exploits observations allows encapsulation sns requirements 
describe programming model minimizes service development effort allowing implementation new services entirely higher layers 
proposed functional organization sns observations lead software component block diagram generic sns shown 
physical workstation network workstations supports software components component diagram confined node 
general components tasks naturally parallelizable replicated scalability fault tolerance 
measurements section argue performance demands non replicated components significant implementation large class services practical bottlenecks bandwidth system bandwidth system area network san 
front ends provide interface sns seen outside world server 
shepherd incoming requests matching appropriate user profile customization database queueing service workers 
front ends maximize system throughput maintaining state simultaneous outstanding requests replicated scalability availability 
worker pool consists caches service specific modules implement actual service data transformation filtering content aggregation type module may instantiated zero times depending offered load 
customization database stores user profiles allow mass customization request processing 
service service specific code workers human interface tacc modules including device specific presentation user interface control service tacc transformation aggregation caching customization api composition stateless data transformation content aggregation modules uniform caching original post aggregation data transparent access customization database sns scalable network service support incremental absolute scalability worker load balancing overflow management front availability fault tolerance mechanisms system monitoring logging scalable network service layered model manager balances load workers spawns additional workers offered load fluctuates faults occur 
necessary may assign machines overflow pool set backup machines desktops harnessed handle load bursts provide smooth transition incremental growth 
overflow pool discussed section 
graphical monitor system management supports tracking visualization system behavior asynchronous error notification email pager temporary disabling system components hot upgrades 
system area network provides low latency highbandwidth interconnect switched mb ethernet myrinet 
main goal prevent interconnect bottleneck system scales 
separating service content implementation reusable sns support layer layered software models allow layers isolated allow existing software layer reused different implementations 
observe components architecture grouped naturally layers functionality shown sns scalable network service implementation tacc transformation aggregation caching customization service 
key contributions architecture reusability sns layer ability add simple stateless building blocks tacc layer compose service layer 
discuss tacc section 
sns layer describe provides scalability load balancing fault tolerance high availability comprises front ends manager san monitor 
scalability components sns architecture may replicated fault tolerance high availability replication achieve scalability 
offered load system saturates capacity component class instances component launched incrementally added nodes 
duties replicated components largely independent nature internet services workload means amount additional resources required linear function increase offered load 
components independent dependence shared non replicated system components san resource man ager possibly user profile database 
measurements section confirm large systems shared components bottleneck 
static partitioning functionality front ends workers reflects desire keep workers simple possible localizing front ends control decisions associated satisfying user requests 
addition managing network state outstanding requests front encapsulates service specific worker dispatch logic accesses profile database pass appropriate parameters workers notifies user service specific way constructing html page describing error workers fails provides user interface profile database forth 
division responsibility allows workers remain simple stateless allows behavior service defined entirely front 
workers analogous processes unix pipeline front analogous interactive shell 
centralized load balancing load balancing controlled centralized policy implemented manager 
manager collects load information workers synthesizes load balancing hints policy periodically transmits hints front ends local scheduling decisions hints 
load balancing overflow policies left system operator 
describe experiments load balancing overflow section 
decision centralize distribute load balancing intentional load balancer fault tolerant ensure performance bottleneck centralization easier implement reason behavior load balancing policy 
section discuss evolution led design decision implications performance fault tolerance scalability 
prolonged bursts incremental growth assume defined average load arriving traffic follows poisson distribution burstiness demonstrated ethernet traffic file system traffic web requests confirmed traces web traffic discussed 
addition internet services experience relatively rare prolonged bursts high load landing pathfinder mars web site served hits day period 
bursts uninterrupted operation critical 
architecture includes notion overflow pool absorbing bursts 
overflow machines dedicated service normally workers running manager spawn workers overflow machines demand unexpected load bursts arrive release machines burst 
institutional corporate setting overflow pool consist workstations individuals desktops 
worker nodes interchangeable workers need know running dedicated overflow node load balancing handled externally 
addition absorbing sustained bursts ability temporarily harness overflow machines eases incremental growth overflow machines recruited unusually time purchase dedicated nodes service 
soft state fault tolerance availability technique constructing robust entities relying cached soft state refreshed periodic messages peers enormously successful wide area tcp ip networks arena transient component failure fact life :10.1.1.39.7251
correspondingly sns components operate manner monitor process peer fault tolerance component fails peers restarts different node necessary cached stale state carries surviving components failure 
component restarted gradually rebuilds soft state typically listening multicasts components 
give specific examples mechanism section 
timeouts additional fault tolerance mechanism infer certain failure modes detected 
condition caused timeout automatically resolved workers lost san partition restarted visible nodes manager performs necessary actions 
sns layer reports suspected failure condition service layer determines proceed report error fall back simpler task require failed worker 
narrow interface service specific workers allow new services reuse facilities manager front ends provide narrow api shown manager stubs worker stubs communicating workers manager graphical system monitor 
worker stub provides mechanisms workers implement required behaviors participating system supplying load data assist manager load balancing decisions reporting detectable failures operation 
worker stub hides fault tolerance load balancing multithreading considerations worker code may facilities operating system need thread safe fact crash system 
minimal restrictions worker code allow worker authors focus content service shelf code transend implement worker modules 
manager stub linked front ends provides support implementing dispatch logic selects worker type needed satisfy request dispatch logic independent core load balancing fault tolerance mechanisms variety services built set workers 
tacc programming model internet services having encapsulated sns requirements separate software layer require programming model building services higher layers 
focus particular subset services transformation aggregation caching customization internet content tacc 
transformation operation single data object changes content examples include filtering transcoding re rendering encryption compression 
aggregation involves collecting data objects collating prespecified way example collecting listings cultural events prespecified set web pages extracting date event information composing result dynamically generated culture week page 
initial implementation allows unix pipeline chaining arbitrary number stateless transformations aggregations results general programming model subsumes transformation proxies proxy filters custom confused process pairs different fault tolerance mechanism hard state processes discussed 
process peers similar fault tolerance mechanism explored early worm programs robin hood fault tolerance detect fact killed start new copy program milliseconds 
way kill ghosts kill simultaneously difficult deliberately crash system ized information aggregators search engines 
selection workers invoke particular request service specific controlled outside workers example collection workers convert images pairs encodings correctly chosen sequence transformations general image conversion 
customization represents fundamental advantage internet traditional wide area media television 
online services including wall street journal los angeles times net deployed personalized versions service way increase loyalty quality service 
mass customization requires ability track users keep profile data user content profiles differs services 
customization database traditional acid database maps user identification token ip address cookie list key value pairs user service 
key strength tacc model appropriate profile information automatically delivered workers input data particular user request allows workers reused different services 
example image compression worker run set parameters reduce image resolution faster web browsing different set parameters reduce image size bit depth handheld devices 
composable customizable workers powerful building block developing new services discuss experience tacc continuing evolution section 
caching important recomputing storing data cheaper moving internet 
example study uk national web cache shown small cache mb reduce load network infrastructure largest isp singapore saved telecom charges web caching 
tacc model caches store post transformation post aggregation content intermediate state content addition caching original internet content 
existing services subsumed tacc model fit 
section describe 
example hotbot search engine collects search results number database partitions results 
transformation involves converting input data form 
transend graphic images scaled filtered lowpass filter tune specific client reduce size 
key strength architecture ease composition tasks affords considerable flexibility transformations aggregations service perform requiring workers understand service specific dispatch logic load balancing programs unix pipeline need understand implementation pipe mechanism 
claim large number interesting services implemented entirely service tacc layers relatively services benefit direct modification sns layer specific low level performance needs 
section describe experience adding functionality tacc service layers 
service implementation section focuses implementation transend scalable web distillation proxy compares hotbot 
goals section demonstrate component shown maps layered architecture discuss relevant implementation details trade offs provide necessary context measurements report section 
transend sns components front ends transend runs cluster sparcstation machines interconnected switched mb ethernet connected dialup ip pool single mb segment 
transend front presents interface client population 
thread assigned arriving tcp connection 
request processing involves fetching web data caching subsystem internet cache pairing request user customization preferences sending request preferences pipeline distillers transend lossy compression workers perform appropriate transformation returning result client 
alternatively appropriate distilled representation available cache sent directly client 
large thread pool allows front sustain throughput maximally exploit parallelism despite large number potentially long blocking operations associated task provides clean programming model 
production transend runs single front threads 
load balancing manager client side javascript support balances load multiple front ends masks transient front failures mechanisms round robin dns commercial routers 
internal load balancing transend uses centralized manager responsibilities include tracking location distillers spawning new distillers demand balancing load distillers class providing assurance fault tolerance system tuning 
argue centralized opposed distributed manager easier change load balancing policy reason behavior section discusses fault tolerance implications decision 
manager periodically beacons existence ip multicast group components subscribe 
ip multicast provides level indirection relieves components having explicitly locate 
front task distiller manager stub code contacts manager locates appropriate distiller spawning new necessary 
manager stub caches new distiller location requests 
worker stub attached distiller accepts queues requests behalf distiller periodically reports load information manager 
manager aggregates load information distillers computes weighted moving averages piggybacks resulting information beacons manager stub 
manager stub front caches information beacons uses lottery scheduling select distiller request 
cached information provides backup system continue operate slightly stale load data manager crashes 
eventually fault tolerance mechanisms discussed section restart manager system returns normal 
allow system scale load increases manager automatically spawn new distiller unused node detects excessive load distillers particular class 
spawning load balancing policies described detail section mechanism adjusting bursts load overflow nodes system current implementation distiller load characterized terms queue length distiller optionally weighted expected cost distilling item 
manager resort starting temporary distillers set overflow nodes 
burst distillers may 
fault tolerance crash recovery original prototype manager information distillers kept hard state log file crash recovery protocols similar acid databases 
resilience crashes process pair fault tolerance primary manager process mirrored secondary role maintain current copy primary state take primary tasks detects primary failed 
scenario crash recovery seamless state secondary process date 
moving entirely base semantics able simplify manager greatly increase confidence correctness 
transend state maintained manager explicitly designed soft state 
distiller starts registers manager existence discovers subscribing known multicast channel 
distiller crashes de registering manager detects broken connection manager crashes restarts distillers detect beacons new manager re register 
timeouts backup mechanism infer failures 
state soft periodically explicit crash recovery state mirroring mechanisms required regenerate lost state 
similarly front require special crash recovery code reconstruct state receives beacons manager 
soft state watcher process needs detect peer alive mirroring peer state cases able restart peer take peer duties 
broken connections timeouts loss beacons infer component failures restart failed process 
manager distillers front ends process peers manager reports distiller failures manager stubs update caches distillers running 
manager detects restarts crashed front 
front detects restarts crashed manager 
process peer functionality encapsulated manager stub code 
simply linking stub front ends automatically recruited process peers manager 
user profile database service interface transend allows user register series customization settings html forms java javascript combination applet 
actual database implemented freely available performance adequate needs user preference reads frequent writes reads absorbed cache front 
cache nodes transend runs harvest object cache workers separate nodes 
harvest suffers functional performance deficiencies resolved 
collection harvest caches treated siblings default siblings queried request cache service time increase load increases cache nodes added 
scalability improved fault tolerance manager stub manage number separate cache nodes single virtual cache hashing key space separate caches automatically re hashing cache nodes added removed 
second modified harvest allow data injected allowing distillers scaling jpeg image factor dimension reducing jpeg quality results size reduction kb kb 
user interface manipulating preferences 
worker stub store post transformed intermediate state data large virtual cache 
interface cache node separate tcp connection required cache request 
repair deficiency due complexity harvest code result measurements reported section slightly pessimistic 
caching transend optimization 
cached data thrown away cost performance cache nodes workers job management base data 
datatype specific distillers second group workers distillers perform transformation aggregation 
result able leverage large amount shelf code distillers 
built parameterizable distillers transend scaling lowpass filtering jpeg images shelf jpeg library gif jpeg conversion followed jpeg degradation perl html marks inline image distillation preferences adds extra links distilled images users retrieve original content adds toolbar page allows users control various aspects transend operation 
user interface transend controlled html distiller direction user preferences front 
distillers took approximately hours implement debug optimize 
pathological input data occasionally causes distiller crash process peer fault tolerance guaranteed sns layer means don worry eliminating possible bugs corner cases system 
graphical monitor extensible tcl tk graphical monitor presents unified view system single virtual entity 
components system report state information monitor multicast group allowing multiple monitors run geographically dispersed locations remote management 
monitor page email system operator serious error occurs example stops receiving reports component 
benefits visualization just cosmetic immediately detect looking visualization panel state system component currently causing bottleneck cache time distillation queueing chose approach discovering jpeg representation smaller faster operate images produces aesthetically superior results 
delay interconnect resources system figures interest 
transend exploits base distinguishing acid vs base semantics design service components greatly simplifies transend fault tolerance improves availability 
user profile database acid exploits aspect base semantics manipulating application data web content implementation system components 
stale load balancing data load balancing data manager stub slightly stale updates manager arrive seconds apart 
stale data load balancing overflow decisions improves performance helps hide faults cached data avoids communicating source 
timeouts recover cases stale data causes incorrect load balancing choice 
example request sent worker longer exists request time worker chosen 
standpoint performance show measurements slightly stale data problem practice 
soft state advantages soft state improved performance avoiding blocking commits trivial recovery 
transformed content cached regenerated original may cached 
approximate answers users transend request objects named object url user preferences derive distillation parameters 
system heavily loaded perform distillation return somewhat different version cache user clicks reload button get distilled representation asked system sufficient resources perform distillation 
required distiller temporarily permanently failed system return original content 
cases approximate answer delivered quickly useful exact answer delivered slowly 
hotbot implementation section highlight principal differences implementations transend hotbot original inktomi basis hotbot predates layered model scalable server architecture uses ad hoc generalized mechanisms places 
front ends service interface hotbot runs mixture single multiple cpu sparcstation server nodes interconnected myrinet 
front ends hotbot run threads node handle presentation customization results user preferences browser type 
presentation performed form dynamic html tcl macros 
load balancing hotbot workers statically partition search engine database load balancing 
worker handles subset database proportional cpu power query goes workers parallel 
failure management workers transend hot bot worker nodes interchangeable worker uses local disk store part database 
original inktomi nodes cross mounted databases multiple nodes reach database partition 
node nodes automatically take responsibility data maintaining data availability graceful degradation performance 
component transend hotbot load balancing application layer service layer failure management worker placement user profile acid database caching table main differences transend hotbot 
database partitioning distributes documents randomly acceptable lose part database temporarily hotbot moved model raid storage handles disk failures fast restart minimizes impact node failures 
example nodes loss machine results database dropping documents significantly larger search engines alta vista 
success fault management hotbot exemplified fact february hotbot physically moved berkeley san jose moving half cluster time changing dns resolution middle 
various parts database unavailable different times move service useful user feedback indicated people affected transient changes 
user profile database expect commercial systems real database acid components 
hotbot uses informix primary backup failover user profile ad revenue tracking database front linking informix sql client 
hotbot data base transend timeouts recover stale cluster state data 
summary dynamic queue lengths worker nodes composable tacc workers worker dispatch logic html java script ui centralized fault tolerant process peers fe caches bound nodes berkeley db read caches harvest caches store pre web data static partitioning read data fixed search service application dynamic html generation html ui distributed node workers bound nodes parallel informix server integrated cache searches incremental delivery transend implementation quite closely maps layered architecture section hotbot implementation differs distributed manager static load balancing data partitioning workers tied particular machines 
careful separation responsibility different components system layering components architecture implementation complexity manageable 
measurements transend implementation took measurements transend cluster sun sparc ultra workstations connected mb switched ethernet isolated external load network traffic 
probability html gif jpg data size bytes distribution content lengths html gif jpeg files 
spikes left main gif jpeg distributions error messages mistaken image data file name extension 
average content lengths html bytes gif bytes jpeg bytes 
measurements requiring internet access access mb switched ethernet network connecting workstation outside world 
subsections analyze size distribution burstiness characteristics transend expected workload describe performance throughput critical components cache nodes data transformation workers isolation report experiments stress transend fault tolerance responsiveness bursts scalability 
traces playback engine performance tests trace data gathered intended user population uc berkeley dialup ip users may connected bank modems 
modems connection internet passes single mb ethernet segment placed tracing machine running ip packet filter segment month half unobtrusively gathered trace approximately anonymized requests 
gif html jpeg far common mime types observed traces respectively implemented distillers cover common cases 
data distiller exists passed unmodified user 
illustrates distribution sizes occurring mime types 
content accessed web small considerably kb average byte transferred part large content kb 
means users modems spend time transferring large files 
goal transend eliminate bottleneck distilling large content smaller useful representations data kb transferred client unmodified distillation small content rarely results size reduction 
reveals number interesting properties individual data types 
gif distribution plateaus data sizes kb correspond icons bullets data sizes kb correspond photos cartoons 
kb distillation threshold exactly separates classes data deals correctly 
show distinction distribution falls rapidly kb mark 
order realistically stress test transend created high performance trace playback engine 
engine generate requests constant dynamically tunable rate faithfully play back trace timestamps trace file 
fine grained control amount nature load offered implementation experimentation 
tasks bucket tasks bucket tasks bucket burstiness time burstiness fundamental property great variety computing systems observed time scales 
traces show offered load implementation contain bursts shows request rate observed user base hour hour minute time interval 
hour interval exhibits strong hour cycle overlaid shorter timescale bursts 
hour minute intervals reveal finer grained bursts 
described section architecture allows arbitrary subset machines managed overflow pool temporary prolonged periods high load 
overflow pool absorb bursts shorter time scales 
argue possible administrative avenues managing overflow pool 
select average desired utilization level dedicated worker pool 
observe daily cycle amounts drawing line picking number tasks sec fraction black line desired utilization level 

select acceptable percentage time system resort overflow pool 
amounts drawing line fraction columns cross line percentage 
measured average number requests distiller class handle number tasks picked step dictates distillers need dedicated non overflow pool 
distiller performance seconds bucket seconds bucket time second bucket time number requests second traced dialup ip users showing burstiness different time scales 
hours minute buckets req avg req max 
hr min second buckets req avg req peak 
min sec req avg req peak 
system behaving distillation images computationally expensive task performed transend 
measured note utilization level necessarily predicted certain acceptable percentage vice versa 
avg 
distillation latency average distillation latency vs gif size gif data gathered dialup ip trace 
performance distillers timing distillation latency function input data size calculated approximately items dialup ip trace file 
shows gif distiller approximately linear relationship distillation time input size large variation distillation time observed particular data size 
slope relationship approximately milliseconds kilobyte input 
similar results observed jpeg html distillers html distiller far efficient 
cache partition performance gif size bytes detailed performance analysis harvest caching system 
summarize results average cache hit takes ms service including network os overhead implying maximum average service rate partitioned cache instance requests second 
tcp connection tear overhead attributed ms service time 
cache hits take ms service implying cache hit rate low variation 
penalty time fetch data internet varies widely ms seconds 
implies cache occur dominate latency system effort expended minimize cache rate 
supplement results ran number cache simulations explore relationship user population size cache size cache hit rate lru replacement 
observed size user population greatly affects attainable hit rate 
cache hit rate increases monotonically function cache size plateaus level function user population size 
user population observed traces approximately people month period gigabytes cache space total partitioned instances gave hit rate 
similarly observed cache size increasing size user population increases hit rate cache due increase locality users point sum users working sets exceeds cache size causing cache hit rate fall 
results deduce capacity single front limited high cache penalties 
number simultaneous outstanding requests front equal number requests arriving second average service time request 
high cache penalty implies large 
tcp connections client front front cache partition thread context maintained front outstanding request implying front ends vulnerable state management context switching overhead 
example offered loads requests second front observed outstanding requests open tcp connections distiller queue length distiller queue length distiller started time seconds distiller distiller distiller started started started distiller died distiller died distiller started active thread contexts time 
result front spends time kernel reported top utility load 
eliminating overhead subject ongoing research 
self tuning load balancing distiller started distiller distiller distiller distiller distiller offered load distiller distiller distiller distiller distiller distiller started time seconds distiller queue lengths observed time load system fluctuates distillers manually brought 
enlargement 
transend uses queue lengths distillers metric load balancing 
queue lengths grow due increased load moving average queue length maintained manager starts increasing average crosses configurable threshold manager spawns new distiller absorb load 
threshold maps greatest delay user willing tolerate system high load 
allow new distiller stabilize system spawning mechanism disabled seconds parameter represents tradeoff stability rate spawning distillers user perceptible delay 
shows variation distiller queue lengths time 
system bootstrapped front manager 
demand spawning distiller observed soon load offered 
increasing load distiller queue gradually increased manager decided spawn second distiller reduced queue length distiller balanced load distillers seconds 
continued increase load caused third distiller start reduced balanced queue lengths seconds 
shows enlarged view graph 
experiment manually killed distillers causing load remaining distiller rapidly increase 
manager immediately reacted started new distiller 
seconds manager discovered system loaded started distiller causing load stabilize 
ran experiment noticed rapid oscillations queue lengths 
inspection revealed front manager stubs periodically received distiller queue length reports making load balancing decisions stale data 
repair changed manager stub keep running estimate change distiller queue lengths successive reports estimates sufficient eliminate oscillations 
data reflects modified load balancing functionality 
scalability demonstrate scalability system needed eliminate bottlenecks limit load offer overhead associated having large number open file descriptors bottleneck mb ethernet connecting cluster internet 
prepared trace file repeatedly requested fixed number jpeg images approximately kb size distributions observed section 
images remain resident cache partitions eliminating cache penalty resulting buildup file descriptors front 
recognize non zero cache penalty introduce additional network stable storage computational burden system result increase amount state front mentioned section limits performance single front 
hand turning caching distilled images force system re distill image time requested respect measurements pessimistic relative system normal mode operation 
strategy experiment follows 
minimal instance system front distiller manager fixed number cache partitions 
experiments repeatedly requested subset images cache effectively tested 

increase offered load system component saturates distiller queues grow long front ends accept additional connections 

add resources system eliminate saturation cases system automatically overflow nodes run workers record amount resources added function increase offered load measured requests second 

continue saturated resource run hardware adding saturated resource longer results linear close improvement performance 
table presents results experiment 
requests second offered load exceeded capacity single available distiller manager automatically spawned additional distiller subsequent distillers necessary 
requests second ethernet segment leading front saturated requiring new front spawned 
unable test system rates higher requests second cluster machines hosting distillers front ends playback engines 
observe nearly perfectly linear growth system scaled range distiller handle approximately requests second mb ethernet segment front handle approximately requests second 
unable saturate front cache parti believe tcp connection setup processing overhead dominating factor 
efficient tcp implementation fast sockets may alleviate limitation investigation needed 
requests second front ends distillers element saturated distillers distillers distillers fe ethernet distillers distillers distillers fe ethernet distillers table results scalability experiment tions fully saturate interior san experiment 
draw result commodity mb san linear scaling limited primarily bandwidth system bandwidth inside system 
run transend sparc single ultra class machine suffice serve entire dialup ip population uc berkeley users officially surfed trace 
ultimately scalability system limited shared centralized components system user profile database manager san 
experience database manager close saturation 
main task manager steady state accumulate load announcements distillers multicast information front ends 
conducted experiment test capability manager handle load announcements 
distillers created machines 
distillers generated load announcement packet manager half second 
manager easily able handle aggregate load announcements second 
distiller capable processing front requests second manager computationally capable sustaining total number distillers equivalent requests second 
number nearly orders magnitude greater peak load seen uc berkeley modem pool comparable modest sized isp 
similarly hotbot acid database parallel informix server ad revenue tracking user profiles serve requests second significantly greater hotbot load 
hand san saturation potential concern communication intensive workloads transend problem optimizing component placement specific network topology technology workload important topic research 
preliminary exploration transend behaves san saturates repeated scalability experiments mb switched ethernet 
network driven closer saturation noticed unreliable multicast traffic dropped ability manager balance load ability monitor report system conditions 
possible solution problem addition utility network isolate control traffic data traffic allowing system gracefully handle avoid san saturation 
possibility higher performance san interconnect myrinet microbenchmark run hot bot implementation measured mbytes pairs traffic nodes far greater traffic experienced normal system suggesting myrinet support systems tens nodes 
discussion previous sections detailed measurements scalable network service implementation confirmed effectiveness layered architecture 
section discuss interesting novel aspects architecture reflect potential applications research compare efforts 
extensibility new workers composition goals system easily extensible tacc service layers making easy create workers chain 
html jpeg distillers consist entirely shelf code took afternoon write 
debugging pathological cases html distiller spread period days system masked transient faults bypassing original content faulting distiller deduce existence bugs noticing monitor display html distiller restarted times period hours 
aspect extensibility ease new services added composing workers modifying service presentation interface 
discuss examples new services various stages construction indicating changed tacc service layers 
services share common features amenable implementation framework compute intensive transformation aggregation computation parallelizable granularity cpu seconds substantial value added mass customization data manipulated base semantics restrict discussion services implemented proxy model transparent interposition computation web clients web servers 
applications prototyped transend 
keyword filtering keyword filter aggregator simple lines perl 
allows users specify perl regular expression customization preference 
regular expression applied html delivery 
simple example filter marks occurrences chosen keywords large bold red typeface 
bay area culture page service retrieves scheduling information number cultural pages web results single comprehensive calendar upcoming events bounded dates stored part user profile 
service implemented single aggregator tacc layer composed unmodified transend service layer delivering benefits distillation automatically 
service exploits base approximate answers semantics application layer extremely general layout independent heuristics extract scheduling information cultural pages 
time heuristics spuriously pick non date text accompanying non descriptions events service useful users simply ignore spurious results 
early experience services suggest sns architecture may promising platform deploying certain kinds simple network agents 
transend metasearch metasearch service similar bay area culture page content sources internet 
content dynamically produced aggregator accepts search string user queries number popular search engines top results single result page 
commercial metasearch engines exist transend metasearch engine implemented pages perl code roughly hours inherits scalability fault tolerance high availability sns layer 
anonymous rewebber just anonymous remailer chains allow email authors anonymously disseminate content anonymous rewebber network allows web authors anonymously publish content 
rewebber described implemented week tacc architecture 
rewebber workers perform encryption decryption user profile database maintains public key information anonymous servers cache stores decrypted versions frequently accessed pages 
encryption decryption distinct pages requested independent users computationally intensive highly parallelizable service natural fit architecture 
real web access pdas smart phones extended transend support graphical web browsing usr palmpilot typical thin client device 
previous attempts provide web browsing devices severe limitations imposed small screens limited computing capability programming environments virtually fallen back simple text browsing 
ability architecture move complexity service workers client allows approach problem different perspective 
built transend workers output simplified markup scaled images ready spoon fed extremely simple browser client knowledge client screen dimensions font metrics 
greatly simplifies clientside code html parsing layout image processing necessary side benefit smaller efficient data representation reduces transmission time client 
economic feasibility improved quality service provided transend interesting question additional cost required operate service 
performance data pentium pro server able support modems subscribers assuming subscriber modem ratio 
amortized year marginal cost user amazing cents month 
include savings isp due cache hit rate observed cache experiments eliminate equivalent lines transend installation reduces operating costs month 
expect server pay months 
argument ignored cost administration nontrivial believe administration costs transend minimal run transend berkeley essentially administration feature upgrades bug fixes performed bringing service 
related content transformation proxy filtering fly compression particularly popular proxy mechanism originally intended users security firewalls 
mechanism shield clients effects poor especially wireless networks perform filtering anonymization perform value added transformations content including transcoding gif conversion application level stream personalized agent services web browsing 
fault tolerance high availability worm programs early example process peer fault tolerance 
tandem computer explored related mechanism process pair fault tolerance secondary backup process ran parallel primary maintained mirror primary internal state processing message traffic primary allowing immediately replace primary event failure 
tandem advocated simple building blocks ensure high availability 
open group project plans build scalable highly available web servers fault tolerance toolkit called cords project progress 
base grapevine important early example trading consistency simplicity bayou explored trading consistency availability application specific ways providing operational spectrum acid base distributed database :10.1.1.40.8955
soft state provide improved performance increase fault tolerance robustness explored wide area internet context ip packet routing multicast routing wireless tcp optimizations tcp snoop lessons learned areas strongly influenced design philosophy tacc server architecture :10.1.1.39.7251
load balancing scaling webos exploited extensibility client browsers java javascript enhance scalability network services dividing labor client server 
note system preclude fact benefits exploiting intelligence computational resources client transend user interface coarse grained load balancing 
discussed expect utility centralized highly available services continue increase occur growth path provided linear incremental scalability sns sense 
past adaptation distillation described distillation dynamically tuned match behavior user network connection successfully demonstrated adaptation network changes combining original www proxy prototype event notification mechanisms developed welling badrinath plan leverage mechanisms provide adaptive solution web access wireless clients 
investigated proposed architecture works outside internet server domain 
particular believe write intensive services writes carry hard state strong consistency desired commerce servers file systems online voting systems 
programming model tacc services embryonic 
plan develop defined programming environment sdk encourage colleagues author services system 
previous research operating systems support busy internet servers identified inadequacies os implementations set abstractions available applications 
plan investigate similar issues related specifically cluster middleware services motivated observations section 
proposed layered architecture cluster scalable network services 
identified challenges cluster computing showed architecture addresses challenges 
architecture reusable authors new network services write compose stateless workers transform aggregate cache customize tacc internet content shielded software complexity automatic scaling high availability failure management 
argued large class network services get base weaker acid data semantics results combination trading consistency availability exploiting soft state performance failure management 
discussed depth design implementation cluster scalable network services transend distillation web proxy hotbot search engine 
extensive client traces conducted detailed performance measurements transend 
gathering measurements scaled transend ultra workstations serving web requests second demonstrated single workstation sufficient serve needs entire modem uc berkeley dialup ip bank 
class cluster scalable network services identified substantially increase value internet access users remaining cost efficient deploy administer believe cluster value added network services important internet service paradigm 
acknowledgments benefited detailed perceptive comments reviewers especially shepherd hank levy 
randy katz eric anderson detailed readings early drafts david culler ideas tacc potential model cluster programming 
ken lutz eric fraser configured administered test network transend scaling experiments performed 
cliff frost uc berkeley data communications networks services group allowed collect traces berkeley dialup ip network worked deploy promote transend berkeley 
undergraduate researchers anthony benjamin ling andrew huang implemented various parts transend user profile database user interface 
ian goldberg david wagner helped debug transend especially implementation rewebber 
anderson david patterson 
extensible scalable monitoring clusters computers 
proc 
large installation system administration lisa xi appear 
anderson case networks workstations 
ieee micro february 
yang ibarra smith 
scalability issues high performance digital libraries world wide web proceedings adl forum research technology advances digital libraries ieee washington may badrinath welling 
framework environment aware mobile applications 
international conference distributed computing systems may appear balakrishnan seshan amir katz 
improving tcp ip formance wireless networks 

st acm conference mobile computing networking berkeley ca november 
bartlett 
nonstop kernel 
proc 
th sosp operating systems review december rob barrett paul maglio daniel 
personalize web 
proc 
chi 
berkeley home ip service faq 
ack berkeley edu modems hip hip faq html 
birrell grapevine exercise distributed computing 
communications acm feb 
bowman harvest scalable customizable discovery access system 
technical report cu cs department computer science university colorado boulder august tim bray 
measuring web 
proc 
www paris may 

rfc dns support load balancing april 
brooks mazer miller 
application specific proxy servers stream transducers 
proc 
www boston may 
www org pub conferences www papers 
chankhunthod danzig neerdaels schwartz worrell 
hierarchical internet object cache 
proceedings usenix annual technical conference january 
clark 
policy routing internet protocols 
internet request comments may cisco systems 
local director 
www cisco com warp public index html 

overview multics system 
afips conference proceedings fall joint computer conference 
www com html crovella bestavros 
explaining world wide web traffic self similarity 
tech rep tr computer science department boston university october 
danzig hall schwartz 
case caching file objects inside internetworks 
proceedings sigcomm 
september 
deering estrin farinacci jacobson :10.1.1.39.7251
liu wei 
architecture wide area multicast routing 
proceedings sigcomm university college london london september 
demers petersen spreitzer terry theimer welch :10.1.1.40.8955
bayou architecture support data sharing mobile users 
fox brewer 
reducing www latency bandwidth requirements real time distillation 
proc 
www paris may 
fox gribble brewer amir 
adapting network client variation demand dynamic distillation 
proceedings asplos vii boston october 
ian goldberg david wagner eric brewer 
privacy enhancing technologies internet 
proc 
ieee spring compcon ian goldberg david wagner 
taz servers rewebber network enabling anonymous publishing world wide web 
unpublished manuscript may available www cs berkeley edu daw cs 
gray 
transaction concept virtues limitations 
proceedings vldb 
cannes france september 
gribble manku brewer 
self similarity file systems measurement applications 
unpublished available www cs berkeley edu gribble papers papers html 
inside web pc 
byte magazine march 
independent jpeg group 
jpeg library 
inktomi inktomi technology hotbot 
may 
www inktomi com html 
internet engineering task force 
hypertext transfer protocol 
rfc march 
kaashoek engler ganger wallach 
server operating systems 
proceedings sigops european workshop september 
keleher cox zwaenepoel 
lazy release consistency software distributed shared memory 
proceedings th annual symposium computer architecture 
may 
keleher cox zwaenepoel 
treadmarks distributed shared memory standard workstations operating systems 
proceedings winter usenix conference january 
leland taqqu willinger wilson 
self similar nature ethernet traffic extended version 
ieee acm transactions network february 
li 
shared virtual memory loosely coupled microprocessors 
phd thesis yale university september 
enhanced services world wide web mobile wan environment 
university helsinki cs technical report 
april 
bruce mah 
empirical model network traffic 
proc 
infocom kobe japan april 
richer rosen 
new routing algorithm arpanet 
ieee transactions communications com pp 
may 

internet report 
morgan stanley equity research april 
www mas com misc inet html mockapetris dunlap 
development domain name system 
acm sigcomm computer communication review 
jeffrey mogul 
operating systems support busy internet servers 
proceedings hotos orcas island washington may 
myrinet gigabit second local area network 
ieee micro vol february pp 

national laboratory applied network research 
squid internet object cache 
squid nlanr net 
national aeronautics space administration 
mars pathfinder mission home page 
jpl nasa gov default html 
netscape communications 
netscape proxy automatic configuration 
home netscape com eng mozilla unix html proxies 
nokia communicator press release 
available www club nokia com support press html 
ousterhout 
tcl tk toolkit 
addison wesley 
open group research institute 
scalable highly available web server project 
www osf org ri htm eric raymond ed 
new hackers dictionary 
cambridge ma mit press 
www org jargon jargon html 
resnick iacovou suchak bergstrom 
grouplens open architecture collaborative filtering netnews 
proceedings conference computer supported cooperative chapel hill nc 
rodrigues anderson 
high performance local area communication fast sockets 
proc 
winter usenix anaheim ca 
jacques 
perceptual image quality concept measurement 
philips journal research 
sah brown brewer 
programming internet server side tcl audience 
proceedings tcl july 

worm programs early experience distributed system 
cacm march 
sato 
delegate server 
documentation available www edu cii src delegate doc manual txt 
schilit bickmore 
device independent access world wide web 
proc 
www santa clara ca april 
selberg etzioni 
metacrawler service 
www metacrawler com html 
mazer brooks 
pan browser support annotations meta information world wide web 
proc 
www paris may 
www conf inria fr html papers overview html singapore isp 
caching effort customers 
www com sg cache proxy smith 
uk national web cache state art 
proc 
www paris may 
www conf inria fr html papers overview html robotics palm pilot home page www usr com palm 
waldspurger weihl 
lottery scheduling flexible proportional share resource management 
proceedings osdi november 
yahoo www yahoo com kao ping yee 
mediator service 
www org 
yoshikawa chun vahdat anderson culler 
smart clients build scalable services 
proceedings winter usenix january 

proxy filtering mechanism mobile environment 
ph thesis proposal department computer science columbia university march 
