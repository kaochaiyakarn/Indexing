multiagent systems survey machine learning perspective peter stone manuela veloso labs research computer science department park ave room carnegie mellon university florham park nj pittsburgh pa research att com veloso cs cmu edu www research att com www cs cmu edu appear autonomous robotics volume number 
july 
distributed artificial intelligence dai existed subfield ai decades 
dai concerned systems consist multiple independent entities interact domain 
traditionally dai divided sub disciplines distributed problem solving dps focuses information management aspects systems branches working common goal multiagent systems mas deals behavior management collections independent entities agents 
survey mas intended serve field organizational framework 
series general multiagent scenarios 
scenario issues arise described sampling techniques exist deal 
techniques exhaustive highlight multiagent systems build complex systems 
options exist techniques biased machine learning approaches 
additional opportunities applying machine learning mas highlighted robotic soccer appropriate test bed mas 
survey focus exclusively robotic systems prior research non robotic mas applies robotic systems 
robotic mas including issue discussed 
extending realm social world include autonomous computer systems awe prospect 
possible necessary ad field artificial intelligence ai 
past years ai techniques robust complex 
mention just exciting successes car steered way united states alvinn system 
meeting daunting challenges ai researchers earned right start examining implications multiple autonomous agents interacting real world 
fact rendered examination indispensable 
self steering car surely 
may able drive individually autonomous vehicles meet highway know behaviors interact 
multiagent systems mas emerging subfield ai aims provide principles construction complex systems involving multiple agents mechanisms coordination independent agents behaviors 
generally accepted definition agent ai russell norvig purposes article consider agent entity robot goals actions domain knowledge situated environment 
way acts called behavior intended general theory agency 
ability consider coordinating behaviors autonomous agents new field advancing quickly building pre existing field distributed artificial intelligence dai 
dai existed subfield ai decades 
traditionally dai broken sub disciplines distributed problem solving dps mas bond gasser 
main topics considered dps information management issues task decomposition solution synthesis 
example constraint satisfaction problem decomposed entirely independent subproblems solved different processors 
solutions synthesized solution original problem 
mas allows subproblems constraint satisfaction problem different prob lem solving agents interests goals 
furthermore domains multiple agents type including autonomous vehicles human agents studied 
survey mas intended field 
reader come away appreciation types systems possible build mas conceptual framework organize different types possible systems 
article organized series general multiagent scenarios 
scenario issues arise described sampling techniques exist deal 
techniques exhaustive highlight multiagent systems build complex systems 
inherent complexity mas interest machine learning techniques help deal complexity wei sen sen 
different systems exist illustrate similar mas techniques systems biased machine learning ml approaches 
furthermore effort highlight additional opportunities applying ml mas 
survey focus exclusively robotic systems prior research non robotic mas applies robotic systems 
robotic mas referred multi robot systems including issue discussed 
possible ways divide mas survey organized main di agent heterogeneity amount communication agents 
simplest multiagent scenario homogeneous non communicating agents full range possible multiagent sys tems highly heterogeneous communicating agents considered 
multiagent scenario single example domain appropriate purpose illustration 
extensively studied domain predator prey pursuit domain benda mas issues arise 
toy domain 
article complex domain robotic soccer order illustrate full power mas 
article organized follows 
section introduces field mas listing strong points presenting taxonomy 
body article sections presents various multiagent scenarios illustrates pursuit domain describes existing field 
domain facilitates study multiagent issues advocated test bed section 
section concludes 
multiagent systems obvious questions type technology advantages offer alternatives 
circumstances useful 
foolish claim mas designing complex systems 
useful approach situations particularly appropriate 
goal section underscore need usefulness mas giving characteristics typical domains benefit 
extensive discussion see bond gasser 
important reason mas designing system domains require 
particular different people organizations different possibly conflicting goals propri information multiagent system needed handle interactions 
organization wants model internal affairs single system organizations give authority single person build system represents different organizations need systems reflect capabilities priorities 
example consider manufacturing scenario produces tires production nuts order build single system automate certain aspects production process internals companies modeled 
want relinquish information control system designer representing 
just companies involved agreement reached companies involved mas necessary 
feasible solution allow various companies create agents accurately represent goals interests 
combined multiagent system aid techniques described article 
example domain requires mas hospital scheduling decker 
domain actual case study requires different agents represent interests different people hospital 
hospital employees different interests nurses want minimize patient time hospital ray operators want maximize throughput machines 
different people evaluate candidate schedules different criteria represented separate agents interests considered 
domains conceivably systems distributed possible reasons mas 
having multiple agents speed system operation providing method parallel computation 
instance domain easily broken components independent tasks handled separate agents benefit mas 
furthermore parallelism mas help deal limitations imposed time bounded reasoning requirements 
parallelism achieved assigning different tasks abilities different agents robustness benefit multiagent systems redundant agents 
control responsibilities sufficiently shared different agents system tolerate failures agents 
domains degrade gracefully particular need feature mas single entity processor agent controls entire system crash single failure 
multiagent system need implemented multiple processors provide full robustness failure agents distributed machines 
benefit multiagent systems scalability 
inherently modular easier add new agents multiagent system add new capabilities monolithic system 
systems capabilities parameters need change time agents benefit advantage mas 
programmer perspective modularity multiagent systems lead simpler program ming 
tackling task centralized agent programmers identify subtasks assign control subtasks different agents 
difficult problem splitting single agent time different parts task solves 
choice multiagent system single agent system mas simpler option 
course domains naturally approached omniscient perspective global view central ized control parallel actions possible action uncertainty decker 
single agent systems cases 
multiagent systems useful fundamental problems social sci ences life sciences cao including intelligence decker :10.1.1.16.3358
wei put deeply inevitably coupled interaction wei 
fact proposed best way develop intelligent machines start creating social machines 
theory socio biological theory primate intelligence evolved need deal social interactions 
reasons mas apply generally arguments favor multi robot systems particular 
tasks require robots particular places robot scouting team robots advantage single robot take advantage geographic distribution 
single robot sense world single vantage point multi robot system observe act locations simultaneously 
argued jung zelinsky multi robot systems exhibit benefits single robot systems terms performance cost ratio heterogeneous robots subset capabilities necessary accomplish task simpler robots presumably expensive engineer single monolithic robot capabilities bundled 
reasons mas summarized table 
domains require parallelism robustness scalability taxonomy table reasons multiagent systems simpler programming study intelligence geographic distribution cost effectiveness taxonomies previously related field distributed artificial intelligence dai 
example decker presents dimensions dai decker 
agent granularity coarse vs fine 
heterogeneity agent knowledge redundant vs specialized 
methods distributing control benevolent vs competitive team vs hierarchical static vs shifting roles 
communication possibilities blackboard vs messages low level vs high level content 
dimensions multiagent systems coarse agent granularity high level communication 
dimensions vary ranges 
fact remaining dimensions prominent article degree heterogeneity major mas dimension methods distributing control appear major issues 
parunak taxonomy mas application perspective 
perspective important characteristics mas system function agent architecture degree heterogeneity reactive vs deliberative system architecture communication protocols human involvement 
useful contribution dimensions divided agent system characteristics 
overviews dai mas include lesser durfee durfee bond gasser 
existing surveys specific multi robot systems 
dudek pre sented detailed taxonomy multiagent robotics dimensions including robot size various communication parameters reconfigurability unit processing 
cao taxonomy problems solutions axes group architecture resource conflicts ori cooperation learning geometric problems 
specifically consider competitive multi robot scenarios 
article contributes taxonomy encompasses mas detailed chronicle existing systems fit taxonomy 
taxonomy article organized important aspects agents opposed domains degree heterogeneity degree communication 
communication agent aspect degree agents communicate communicate communication protocols available considered 
aspects agents mas touched heterogeneity communication framework 
example degree different agents play different roles certainly important mas issue framed scenario heterogeneous non communicating agents arises scenarios 
domain issues discussed separately section 
combinations heterogeneity communication homogeneous non communicating agents heterogeneous non communicating agents homogeneous communicating agents heterogeneous com agents considered article 
approach article categorize issues reflected literature 
issues apply earlier scenarios articles come 
hand issues arise earlier scenarios apply scenarios 
mentioned scenarios degree differ complex 
primary purpose taxonomy framework considering analyzing challenges arise mas 
survey designed useful researchers way separating issues arise result decisions homogeneous versus heterogeneous agents communicating versus non communicating agents 
multiagent scenarios issues arise summarized table 
tech niques currently exist address issues described detail sections 
single agent vs multiagent systems studying categorizing mas consider obvious alternative centralized single agent systems 
centralized systems single agent decisions act remote slaves 
purposes survey single agent system thought centralized system domain allows multiagent approach 
single agent system multiple entities actuators robots 
entity sends perceptions receives actions single central process single agent central process 
central agent models entities single self section compares single agent multiagent approaches 
homogeneous non communicating agents reactive vs deliberative agents local global perspective modeling agents states affect homogeneous communicating agents distributed sensing communication content single agent systems heterogeneous non communicating agents benevolence vs competitiveness stable vs evolving agents arms race modeling goals actions knowledge resource management interdependent actions social conventions roles heterogeneous communicating agents understanding planning communicative acts benevolence vs competitiveness negotiation resource management schedule coordination commitment decommitment collaborative localization changing shape size table issues arising various scenarios reflected literature 
general agent single agent system models environment interactions 
course agent part environment purposes article agents considered extra environmental components 
independent entities goals actions knowledge 
single agent system entities recognized agent 
agents world modeled having goals just considered part environment 
point emphasized agents part environment explicitly modeled having goals actions domain knowledge see 
environment sensors effectors agent goals actions domain knowledge general single agent framework 
agent models environment interactions 
agents exist considered part environment 
multiagent systems multiagent systems differ single agent systems agents exist model goals actions 
fully general multiagent scenario may direct interaction agents communication 
interaction viewed environmental stimuli inter agent communication separate environment 
individual agent perspective multiagent systems differ single agent systems signif environment dynamics determined agents 
addition uncertainty may inherent domain agents intentionally affect environment unpredictable ways 
multiagent systems viewed having dynamic environments 
illustrates view agent part environment modeled separate entity 
may number agents different degrees heterogeneity ability communicate directly 
fully general case depicted eliminating communication heterogeneity homogeneous non communicating mas section 
possibilities agent heterogeneity inter agent communication considered time sections 
section arrive back fully general case considering agents interact directly 
environment agent goals actions domain knowledge sensors effectors agent goals actions domain knowledge fully general multiagent scenario 
agents model goals actions domain knowledge may differ indicated different fonts 
may interact directly communicate indicated arrows agents 
organization existing sections different mas techniques previously published 
extensive exhaustive list field 
space permit exhaustive coverage 
mentioned intended illustrate techniques exist deal issues arise various multiagent scenarios 
possible ml approaches emphasized 
multiagent scenarios considered order homogeneous non communicating agents heterogeneous non communicating agents homogeneous communicating agents heterogeneous communicating agents 
scenarios research issues arise techniques deal additional ml opportunities 
issues may appear scenarios discussed scenario apply 
addition existing learning approaches described sections entitled issues techniques previously unexplored learning opportunities apply multiagent scenarios 
scenario promising opportunities ml researchers 
existing ml techniques directly applied multiagent scenarios delimiting part domain involves single agent 
multiagent learning concerned learning issues arise multiagent aspect domain 
described wei multiagent learning learning done agents possible agents wei 
type learning emphasized sections entitled learning opportunities purpose illustration scenario accompanied suitable instantiation tor prey pursuit domain 
predator prey pursuit domain predator prey pursuit domain referred pursuit domain appropriate illustration mas studied wide variety approaches different instantiations illustrate different multiagent scenarios 
involves agents moving world particularly appropriate abstraction robotic mas 
pursuit domain complex real world domain toy domain helps concepts 
discussion domain full range complexities characteristic real world domains see section 
pursuit domain introduced benda 
years researchers studied variations original formulation 
section single instantiation domain 
care taken point parameters varied 
pursuit domain usually studied predators prey 
traditionally predators blue prey red black grey respectively 
domain varied different numbers predators prey 
goal predators capture prey surround move unoccupied position 
capture position shown 
world edges fewer predators capture prey trapping edge corner 
possible criterion capture orthogonal game toroidal world capture predators see predators communicate prey moves randomly prey stays put time simultaneous movements particular instantiation pursuit domain 
predators black prey grey 
arrows top predators indicate possible moves 
predator occupies position prey 
typically players allowed occupy position 
depicted predators prey move discrete grid world square spaces 
move adjacent square turn 
possible variations include grids shapes spaces instance hexagons continuous worlds 
square game players may allowed move diagonally just horizontally 
size world may vary infinite plane small finite board edges 
world pictured toroidal world predators prey move board come back 
parameters game specified players move simultaneously turns world predators see predators communicate 
original formulation domain subsequent studies prey moves randomly turn moves random direction staying certain probability order simulate slower predators 
possible allow prey actively try escape capture 
discussed section research done effect room improvement 
parameters varied pursuit domain summarized table 
definition capture size shape world legal moves simultaneous sequential movement table variable parameters pursuit domain visible objects range predator communication prey movement pursuit domain purposes illustration simple understand flexible illustrate variety scenarios 
possible actions predators prey limited goal defined 
terms reasons mas table pursuit domain necessarily require mas 
certain instantiations parallelism robustness simpler programming offered mas 
pursuit domain single agent approach possible agent observe positions predators decide move 
prey moves randomly intentionally associated agent 
considered part environment shown 
possible consider dps approaches pursuit domain breaking task subproblems solved predator 
approaches described model predators independent agents common goal 
comprise multiagent system 
environment pursuit domain just single agent 
agent controls predators prey considered part environment 
multiagent scenarios new instantiation pursuit domain de agent fined 
purpose illustrate different scenarios concrete framework 
domain issues survey focus agent capabilities 
point view system designer characteristics domain important 
moving agent categorization field range domain characteristics considered 
relevant domain characteristics include number agents amount time pressure real time domain new goals arrive dynamically cost communication cost failure user involvement environmental uncertainty 
characteristics self explanatory need mention 
respect cost failure example domain high cost failure air traffic control rao georgeff :10.1.1.37.7970
hand directed improvisation domain considered hayes roth low cost failure 
domain entertainment agents accept improvisation suggestions 
idea agents afraid mistakes just words flow hayes roth 
multiagent systems include humans agents 
case designer consider issue communication human computer agents sanchez 
example user involvement user feedback information filtering domain ferguson 
decker distinguishes different sources uncertainty domain 
transitions domain non deterministic agents know actions agents agents know outcomes actions 
domain characteristics summarized table 
table domain characteristics important designing mas number agents amount time pressure real time 
dynamically arriving goals 
cost communication cost failure user involvement environmental uncertainty decker priori domain actions agents outcomes agent actions homogeneous non communicating multiagent systems homogeneous non communicating multiagent systems agents internal structure including goals domain knowledge possible actions 
procedure selecting actions 
differences agents sensory inputs actual actions take situated differently world 
homogeneous non communicating multiagent pursuit homogeneous non communicating version pursuit domain having agent con predators identical agent predator 
agents identical capabilities decision procedures may limited information internal state sensory inputs 
may able predict actions 
pursuit domain homogeneous agents illustrated 
framework stephens merx propose simple heuristic behavior agent local information 
define capture positions positions adjacent prey 
propose local strategy predator agent determines capture position closest moves position 
predators see aim different capture positions 
course problem heuristic predators may move capture position blocking approach 
strategy successful serves basis comparison control strategies distributed central discussed section 
agent agent agent agent pursuit domain homogeneous agents 
identical agent predator 
agents may amount limited information agents internal states 
predators identical easily predict actions knowledge sensory input 
prediction useful agents move simultaneously base actions predators time step 
vidal durfee analyze situation recursive modeling method rmm 
rmm discussed detail basic idea predator bases move predicted move predator vice versa 
resulting reasoning recurse indefinitely important agents bound amount reasoning terms time terms levels recursion 
vidal durfee limited rationality rmm algorithm designed take considerations account 
levy rosenschein game theoretical approach pursuit domain 
payoff function allows selfish agents cooperate 
requirement model predator full information location predators 
game model mixes game theoretical cooperative non cooperative games 
korf takes approach agent try greedily maximize local utility 
introduces policy predator attractive force prey repulsive force predators 
predators tend approach prey different sides 
policy successful especially diagonal agents move diagonally orthogonally hexagonal hexagonal grid games 
korf draws explicit cooperation rarely necessary useful pursuit domain broadly view additional support theory coordination cooperation natural man systems viewed emergent property interaction greedy agents maximizing particular utility functions presence environmental constraints 
korf altruism occurs nature certainly benevolent agents mas shown 
korf claim pursuit domain easily solved local greedy heuristics true point studying pursuit domain 
fortunately haynes sen show korf heuristics certain instantiations domain see section 
general homogeneous mas general multiagent scenario homogeneous agents different agents identi cal structure sensors effectors domain knowledge decision functions different sensor input effector output 
say situated differently environment decisions regarding actions take 
having different effector output necessary condition mas agents act unit essentially single agent 
order realize difference output homogeneous agents different sensor input 
act identically 
scenario consider non communicating agents assume agents commu directly 
illustrates homogeneous non communicating multiagent scenario indicating agents goals actions domain knowledge representing identical fonts 
goals actions domain knowledge goals actions domain knowledge goals actions domain knowledge mas homogeneous agents 
sensor input effector output agents differ represented different arrow styles 
agents goals actions domain knowledge identical indicated identical fonts 
issues techniques restrictive multiagent scenarios issues deal 
techniques provided representative examples ways deal issues 
issues techniques learning opportunities discussed summarized table 
reactive vs deliberative agents designing agent system important determine sophisticated agents rea 
reactive agents simply retrieve pre set behaviors similar reflexes maintaining internal state 
hand deliberative agents behave thinking searching space behaviors maintaining internal state predicting effects actions 
issues techniques reactive vs deliberative agents local global perspective modeling agents states affect homogeneous non communicating learning opportunities reactive behaviors formation maintenance 
balch arkin deliberative behaviors pursuit :10.1.1.110.3459
levy rosenschein mixed reactive deliberative behaviors 
sahota rao georgeff local knowledge better :10.1.1.37.7970:10.1.1.37.7970
roychowdhury limited recursive modeling method rmm 
durfee don model just pay attention reward 
schmidhuber stigmergy 
goldman rosenschein holland learning behaviors foraging homing mataric enable actions sensor data agent sensor data table issues techniques learning opportunities homogeneous mas reflected literature :10.1.1.29.5356:10.1.1.30.848
line reactive deliberative agents somewhat blurry agent internal state cer reactive bases actions predicted actions agents deliberative 
describe system extreme mix reactive deliberative reasoning 
balch arkin homogeneous reactive non communicating agents study formation maintenance autonomous robots 
robots goal move military formation diamond column wedge 
periodically come obstacles prevent robots moving straight line 
passing obstacle robots adjust order regain formation 
agents reactively convert sensory data includes positions robots motion vectors avoiding obstacles avoiding robots moving goal location formation maintenance 
actual robot motion simple weighted sum vectors 
deliberative spectrum pursuit domain levy rosenschein mentioned 
agents assume act service goals 
game theoretic techniques find equilibrium points decide act 
agents clearly deliberative considering search actions simply retrieving 
existing systems techniques mix reactive deliberative behaviors 
example oasis system reasons reactive follow goal directed plans rao georgeff :10.1.1.37.7970
example reactive deliberation sahota 
name implies mixes reactive deliberative behavior agent reasons reactive behavior follow constraint choose actions rate hz 
reactive deliberation developed robotic soccer platform barman 
reactive deliberation explicitly designed mas designed real time control dynamic environments extendible multiagent scenarios 
local global perspective issue consider building multiagent system sensor information available agents 
feasible domain give agents global perspectives world may effective limit local views 
roychowdhury consider case multiple agents sharing set identical resources learn adapt resource usage policies roychowdhury 
agents identical communicate global view current resource usage move simultaneously resource 
see partial picture world different agents different resources preferable effect 
better performance agents knowledge occasionally summarized ignorance bliss modeling agents states durfee provides example ignorance mentioning explicitly title ignorance knowing just coordinate referring resource usage saying applies limited recursive modeling method rmm 
rmm agents explicitly model belief states agents including know beliefs 
agents knowledge rmm recurse indefinitely 
information obtained reasoning agent thinks agent thinks agent thinks 
endless reasoning lead inaction 
durfee contends coordination possible potential knowledge ignored 
illustrating concept pursuit domain vidal durfee durfee goes detail offers generally applicable methodology durfee 
point rmm model internal state agent order predict actions 
agents know goals structure homogeneous may know actions 
missing pieces information internal states deliberative agents sensory inputs agents 
model agents ubiquitous issue mas 
complex multiagent scenarios sections agents may model internal states agents goals actions abilities 
may useful build models agents environment agent modeling done universally 
form multiagent rl defined agents model agents schmid huber 
consider parts environment affect policies sensed objects 
agents pay attention reward receive policy check point policies return successful ones 
schmidhuber shows agents learn cooperate modeling 
affect communication possible agents interact directly 
exist environment agents affect indirectly ways 
sensed agents may able change state agent example pushing 
agents affect types stigmergy holland 
active stigmergy occurs agent alters environment affect sensory input agent 
example robotic agent leave marker agents observe 
goldman rosenschein demonstrate effective form active stigmergy agents heuristically alter environment order facilitate unknown plans agents 
second passive stigmergy involves altering environment effects agent actions change 
example agent turns main water valve building effect agent subsequently turning kitchen altered 
holland illustrates concept passive stigmergy robotic system designed model behavior ant colony confronted dead ants nest 
ant colony tends periodically pick dead ant carry short distance drop 
behavior appears random hours dead ants clustered small number heaps 
time fewer fewer large piles dead ants pile 
ants behave homogeneously case evidence communicate explicitly ants manage cooperate achieving task 
holland models situation number identical robots small area pucks scattered 
robots programmed reactively move straight turning walls pushing pucks 
point robots back turn away leaving pucks cluster 
robots communicate able collect pucks single pile time 
effect occurs robot approaches existing pile directly adds pucks carrying pile turns away 
robot approaching existing pile take puck away pile time desired result accomplished 
ants robots passive stigmergy affect behavior 
similar scenario deliberative robots explored mataric 
case robots learning learn behaviors including foraging pucks homing mataric 
robots learn independent policies dealing high dimensional state space aid progress estimators give intermediate rewards aid boolean value predicates condense states 
mataric robots actively affect observation robot learning follow robot base action relative location robot 
learning opportunities addition existing learning approaches described previously unexplored learning opportunities apply homogeneous non communicating systems see table 
unexplored learning opportunity apply domains homogeneous non communicating agents learning enable actions 
inspired concept stigmergy agent may try learn take actions directly help current situation may allow similar agents effective 
typical rl situations delayed reward encourage agents learn achieve goals directly propagating local reinforcement back past states actions kaelbling 
action leads reward agent acting agent may way reinforcing action 
techniques deal problem useful building multiagent systems 
terms modeling agents room improvement situation agent know internal state sensory inputs agent 
information known rmm determine actions agents 
information directly available useful agent learn 
function agent sensor data include restricted view agent agent sensor data useful function learn 
effectively learned agent limited rmm predict agent actions 
heterogeneous non communicating multiagent systems point considered agents homogeneous 
adding possibility neous agents multiagent domain adds great deal potential power price added complexity 
agents heterogeneous number ways having different goals having different domain models actions 
important heterogeneous agent systems agents benevolent competitive 
different goals may friendly goals may actively try inhibit 
degree heterogeneity mas measured information theoretic way balch social entropy 
heterogeneous non communicating multiagent pursuit exploring general multiagent scenario involving heterogeneous non communicating agents con sider scenario instantiated pursuit domain 
previous scenario predators controlled separate agents 
longer necessarily identical agents goals actions domain knowledge may differ 
addition prey inherently goals different predators modeled agent 
pursuit domain heterogeneous agents shown 
haynes colleagues done various studies heterogeneous agents pursuit domain 
agent pursuit domain heterogeneous agents 
goals actions may differ agents 
prey may modeled agent 
evolved teams predators equipped predators case bases competitively evolved predators prey 
agent haynes genetic programming gp evolve teams predators 
evolving predator agents single evolutionary pool combining teams test performance individual population team agents specifically assigned different predators 
predators evolve cooperate 
evolution teammates possible way absence communication domain 
place communicating planned actions predators evolve know act knowing actions 
separate study haynes case reasoning allow predators learn cooper ate 
identical agents controlling predators 
predators move si closest capture positions 
predators try occupy position remain stationary cases deadlock arise 
deadlock occurs agents store negative case avoid try different actions 
keeping track agents act way deadlock situations predators build different case bases heterogeneous agents 
time predators learn stay way approaching prey 
haynes sen explore possibility evolving predators prey try improve behaviors 
working toroidal world starting predator behaviors korf greedy heuristic evolved gp predators evolve prey behave effectively randomly 
think continuing process lead repeated improvement predator prey behaviors convergence prey behavior emerges succeeds prey simply moves constant straight line 
allowed re adjust linear prey behavior predators unable reliably capture prey 
haynes sen conclude korf greedy solution pursuit domain relies random prey movement guarantees locality movement 
may greedy solutions deal different types prey behavior discovered 
predator domain retains value researchers mas 
agent agent agent haynes sen convince reader pursuit domain worth studying evolutionary results satisfying 
mentioned intuitively expect predators able adapt linearly moving prey 
example operate toroidal world single predator place prey line movement remain 
remaining predators surround prey leisure 
fact predators unable re evolve find solution suggests predator evolution performed optimally slightly capable agents agents able reason past world states lead interesting study 
study competitive evolution pursuit domain started haynes sen intriguing open issue 
general heterogeneous mas general multiagent scenario heterogeneous non communicating agents depicted 
homogeneous case see agents situated differently environment causes different sensory inputs necessitates different actions 
scenario agents significant differences 
may different goals actions domain knowledge indicated different fonts 
order focus benefits complexity heterogeneity assumption communication retained section 
goals actions domain knowledge goals actions domain knowledge goals actions domain knowledge general heterogeneous mas scenario 
agents goals actions domain knowledge may differ indicated different fonts 
assumption direct interaction remains 
issues techniques communication numerous issues homogeneous agent scenario section arise scenario 
touched context pursuit domain 
issues existing techniques deal learning opportunities described summarized table 
issues techniques heterogeneous non communicating benevolence vs competitiveness learning opportunities stable vs evolving agents arms race credit assignment modeling goals actions knowledge credit assignment competitive scenarios resource management interdependent actions behaviors blend team social conventions prediction actions roles dynamic role assumption game theory iterative play 
mor rosenschein sandholm crites minimax 
littman competitive evolution 
rosin belew haynes sen grefenstette daley stone deduce intentions abilities observation 
huber durfee wang autoepistemic reasoning ignorance 
model team individual role 
tambe social reasoning depend goal game theory 
sichman demazeau gas deal paradox resource worse 
glance hogg arora sen multiagent rl adaptive load balancing 
schaerf focal points emergent conventions 
walker wooldridge agents filling different roles 
prasad tambe balch stone veloso table issues techniques learning opportunities heterogeneous mas reflected literature 
benevolence vs competitiveness important issues consider designing multiagent system different agents benevolent competitive 
different goals agents benevolent willing help achieve respective goals goldman rosenschein 
hand agents may selfish consider goals acting 
extreme agents may involved zero sum situation actively oppose agents goals order achieve 
people consider selfish agents claiming effective building real systems biologically plausible 
course agents goals help people rarely consider agents help achieve different goals apparent reason agents cooperate usually best interest 
seen pursuit domain korf advocates greedy agents minimize distance prey similarly levy rosenschein game theory study predators cooperate despite maximizing utilities 
advocates selfish agents point nature justification claiming animals altruistic act self interest korf 
hand provides detailed chronicle explanation apparent altruism nature usually explainable kin selection cooperation human societies 
altruism exists situations may animal agent interest cooper ate agents 
mor rosenschein illustrate possibility context prisoner dilemma 
prisoner dilemma agents try act maximize individual rewards 
actively thwart zero sum game place inherent value receiving reward 
prisoner dilemma constructed agent choices defect cooperate 
matter agent agent receives higher reward defects 
agents cooperate better defect 
play agent better defecting 
mor rosenschein show agents come repeatedly iterated prisoner dilemma cooperative behavior emerge 
effect agent serve self interest establishing reputation cooperative 
coming cooperative agent benefit sense trust cooperate defecting 
repeated play cooperation emerge selfish agents prisoner dilemma 
prisoner dilemma agents selfish inherently competitive specific stances willing act 
agents competitive zero sum games cooperation longer sensible 
instance littman considers zero sum game players try reach opposite ends small discrete world 
players block trying move space 
littman introduces variant learning called minimax designed markov games opposed markov decision processes 
competitive agents learn probabilistic policies deterministic policy completely opponent 
issue benevolence willingness cooperate vs competitiveness comes repeatedly systems described 
third dimension added categorization mas addition degrees heterogeneity communication issue 
stable vs evolving agents important characteristic consider designing multiagent systems agents stable evolving 
course evolving agents useful dynamic environments 
particularly competitive agents allowing evolve lead complications 
systems competitive evolving agents said technique called competitive evolution 
systems evolve benevolent agents said cooperative evolution 
evolution predator prey agents haynes sen qualifies competitive evolution 
robotic soccer domain presents opportunity cooperative competitive evolution 
team partitioned opaque transition reinforcement learning rl stone implements coop evolution 
individual soccer playing agents learn ball passing policies simultaneously eventually creating compatible set policies 
grefenstette daley conduct preliminary study competitive cooperative evolution domain loosely related pursuit domain 
domain robots move continuously stationary food appears randomly world 
cooperative task robots food order capture 
competitive task domain agents try reach food grefenstette daley 
problem contend competitive cooperative evolution possibility arms race 
competing agents continually adapt specialized ways stabilizing behavior 
course dynamic environment may feasible desirable evolve stable behavior 
applying rl iterated prisoner dilemma sandholm crites find learning agent able perform optimally fixed opponent 
agents learning stable solution 
issue competitive evolution credit assignment problem 
performance agent improves necessarily clear improvement due improvement agent behavior negative change opponent behavior 
similarly agent performance gets worse blame credit belong agent opponent 
way deal credit assignment problem fix agent evolving switch 
method encourages arms race 
rosin belew technique interesting method maintaining diversity genetic populations evolve agents play tictactoe nim simple version go 
agent turn evolve executes standard genetic algorithm ga generation 
individuals tested individuals competing population technique called competitive fitness sharing maintain diversity 
technique individuals agent population credit beating opponents individuals agent population beaten individuals agent population 
specifically reward individual beating individual individuals agent population beat individual promise people building systems competitive evolution 
modeling goals actions knowledge divided number competitive fitness sharing shows case homogeneous agents useful agents model internal states agents order predict actions 
heterogeneous agents problem modeling complex 
goals actions domain knowledge agents may unknown need modeling 
communication agents forced model strictly observation 
huber durfee consider case coordinated motion control multiple mobile robots assumption communication prohibitively expensive 
agents try deduce plans observing actions 
particular robot tries destinations robots watching move 
plan recognition type useful competitive domains knowing opponent goals intentions significantly easier defeat 
addition modeling agents goals observation possible learn actions 
observer system wang allows agent incrementally learn preconditions effects planning actions observing domain experts 
observing time agent experimentally refine model practicing actions 
modeling agents may useful reason true false known 
reasoning called autoepistemic rea 
just rmm useful modeling states homogeneous agents neous scenario 
tambe takes step studying agents learn models teams agents 
air combat domain agents rmm try deduce opponents plan observable actions 
example fired missile may visible observation preparatory maneuver commonly firing indicate missile launched 
teams agents involved situation complicated 
case opponent actions may sense context team maneuver 
agent role team modeled tambe 
reason modeling agents useful agents depend achieving goals 
game theory agents cooperate depending utility estimation may actions require cooperation successful execution 
example robots may needed successfully push box pursuit domain agents may needed capture opponent 
sichman demazeau analyze case conflicting mutual models different dependent agents arise dealt 
resource management heterogeneous agents may interdependent actions due limited resources needed agents 
example domains include network traffic problems different agents send information network load balancing computer processes users limited amount computing power share 
interesting network traffic problem called paradox studied multiagent gas glance hogg 
paradox phenomenon adding resources network getting worse performance 
particular ga representation represent differ ent parts sample network usage dependent resource costs agents sharing network reasoning separately path network achieve global optimal perfor mance glance hogg 
ga representation improved system able find globally optimal traffic flow arora sen 
rl mentioned having applied robotic soccer domain applied network traffic flow scenario stone 
adaptive load balancing studied multiagent problem allowing different agents decide processor time 
rl heterogeneous agents achieve reasonable load balance central control communication agents schaerf 
agents keep track long job takes scheduled resource incentive explore untried processors processors poorly past 
social conventions current multiagent scenario allow communication interesting done heterogeneous agents reach agreements coinciding choices necessary 
humans able reach tacit agreements illustrated scenario imagine friend need meet today 
arrived paris yesterday unable get touch set time place 
essential meet today 
go 
vohra posed question audience roughly people aaai fall symposium active learning roughly people wrote prior communication go eifel tower noon 
communicating people able coordinate actions 
apparently features seen obvious choices 
context mas define focal point method 
discuss phe cultural programmed preferences allowing agents meet communicating 
propose equal agents need meet choose rare extreme options 
coming pre analysis options focal point method conventions emerge time agents biased options chosen example frequently past walker wooldridge 
roles agents similar goals organized team 
agent plays separate role team 
benevolent team agents provide method assigning different agents different roles 
assignment obvious agents specific thing 
domains agents flexible interchange roles 
prasad study design agents initiate extend design steam pump 
different situations different agents effective initiation extension 
supervised learning technique help agents learn roles fill different situations 
steam tambe allows team agents fill switch roles dynamically 
particularly critical agent fails agent able replace role team carry mission 
similarly concept room agreement stone veloso allows agents seamlessly switch roles 
allowed evolve independently group agents filling different roles domain behavior 
balch investigates methods encouraging behavioral diversity team agents 
learning opportunities investigation issues techniques heterogeneous non communicating mul scenario learning approaches described 
obvious ml applications scenario described summarized table 
challenge system builders evolving agents dealing credit assignment prob lem 
different agents evolving time changes agent fitness due behavior due behavior 
agents evolve effectively reasonable idea change behavior beneficial detrimental 
methods objective fitness measurement needed testing various evolution techniques 
competitive especially zero sum situations difficult provide adequate performance measurements time 
agents improve drastically improve amount actual results remain 
possible way problem test agents past agents order measure improvement 
solution ideal current agent may adapted current opponent past opponents 
reliable measurement method valuable contribution ml mas 
cooperative situations agents ideally learn behave way help 
unfortunately existing ml techniques focus exploring behaviors help agent personal deficiencies 
interesting contribution method introducing learning space bias behaviors blend behaviors agents 
techniques described section modeling agents neous non communicating scenario 
true just knowledge agent current situation ability predict actions 
example reason useful deduce mobile robot goal location path goal may predicted collision avoided 
room improvement existing techniques new techniques allow agents predict actions 
context teams agents mentioned agents suited different roles different situations 
dynamic environment flexible agents effective switch roles dynamically 
example agent finds position easily perform useful action usually considered part current role may switch roles leave old role available agent 
challenging possible approach problem enable agents learn roles assume situations 
dynamic role assumption particularly opportunity ml researchers mas 
homogeneous communicating multiagent systems point considered mas agents communicate directly 
admittedly communication viewed simply part agent interaction environment 
just agents considered special parts environment purposes survey communication agents considered extra environmental 
aid communication agents coordinate effectively able point 
scenario consider homogeneous agents communicate 
homogeneous communicating multiagent pursuit pursuit domain communication creates new possibilities predator behavior 
prey acts pursuit domain agents communicate 
predators freely exchange information order help capture prey effectively 
current situation illustrated 
agent agent pursuit domain homogeneous communicating agents 
predators communicate 
recall local strategy defined stephens merx predator simply moved closest capture position instantiation domain predators see prey 
communication possible define possible strategy predators stephens merx 
distributed strategy agents homogeneous communicate insure moves different capture position 
particular predator farthest prey chooses capture position closest announces approach position 
farthest predator chooses closest capture position remaining 
simple protocol encourages predators close prey different sides 
distributed strategy effective local policy require communication 
situations succeed 
agent agent agent general communicating mas multiagent scenario homogeneous communicating agents depicted 
homogeneous non communicating case agents identical situated differently environment 
scenario agents communicate directly indicated arrows connecting agents 
practical point view communication broadcast posted blackboard interpret targeted point point agent specific agent 
goals actions domain knowledge goals actions domain knowledge goals actions domain knowledge mas homogeneous communicating agents 
sensor input effector output agents differ 
information transmitted directly agents indicated arrows agents 
communication broadcast transmitted point point 
issues techniques communication raises issues addressed multiagent systems 
cases addressed literature heterogeneous communicating agents 
section consider limited number issues addressed homogeneous communicating agents indicated table 
communication related issues addressed section devoted hetero communicating multiagent systems 
issues techniques distributed sensing communication content homogeneous communicating mas learning opportunities active sensing matsuyama query propagation distributed traffic mapping moukas maes state vs goal communication balch arkin stone veloso communicate table issues techniques homogeneous communicating multiagent systems reflected literature :10.1.1.110.3459
distributed sensing cooperative distributed vision project matsuyama aims construct monitor broad visual scene dynamic dimensional scene understanding multiple cameras stationary mobile robots 
example consider problem tracking individual car cameras mounted urban intersections 
car leaves camera range enters needs way identifying images representing car probably looks different cases driving away camera 
project combines active sensing ability shift attention area higher uncertainty interest communication multiple sensing agents 
distributed sensing project system moukas maes 
cars collect propagate traffic information help decide best route location 
example car driving direction query oncoming vehicle traffic conditions road 
propagating queries vehicles original car build map traffic conditions different routes goal 
communication content important issue communicating agents communicate 
distributed sensing applications mentioned agents communicated regarding sensed states world 
possible agents share information regarding individual goals 
multi robot applications balch arkin study effects allowing agents com states goals 
agents communicated goal information performed slightly better communicated state information 
conditions exhibited far superior behavior compared non communicating agents 
observed allowing agents communicate internal state information effective robotic soccer domain stone veloso 
application opponent ball locations communicated agents know whereabouts 
learning opportunities demonstrated communicating state information advantageous mas domains bandwidth considerations allow constant complete exchange information 
addition communications delayed opposed instantaneous may obsolete arriving intended destinations 
cases may possible agents learn communicate agents observed affects utterances group performance 
heterogeneous communicating multiagent systems scenario examined section included agents differ number ways including sensory data goals actions domain knowledge 
heterogeneous multiagent systems complex powerful 
full power mas realized adding ability heterogeneous agents communicate 
fact combining communication heterogeneity introduces possibility having multiagent system turn system essentially equivalent single agent system 
sending sensor inputs receiving commands agent agents control single agent 
case control longer distributed 
heterogeneous communicating multiagent pursuit allowing heterogeneity communication pursuit domain opens new control ties 
current situation illustrated 
agent agent pursuit domain heterogeneous communicating agents 
agents fully heterogeneous able communicate 
tan uses communicating agents pursuit domain conduct interesting multiagent learning experiments 
instantiation domain prey agents predators limited vision may know prey 
predators help informing sensory input 
tan shows help exchanging reinforcement episodes control policies 
stephens merx strategy succeeds requires communication distributed approach section central strategy 
central strategy effectively single agent system 
predators transmit sensory inputs central agent decides predators move transmits decision back agent agent agent 
case really intelligent controlling agent 
benda original presentation pursuit domain consider full range communication possibilities 
consider possible organizations predators pair exchange data exchange data goals control 
tradeoff lower communication costs better decisions described 
communication costs come form limited bandwidth consumption reasoning time 
way frame tradeoff cost freedom communication cost time increases freedom decreases 
osawa suggests predators move phases 
increasing order cost decreasing freedom autonomy communication negotiation con trol osawa 
predators making sufficient progress prey strategy move expensive strategy 
close prey efficiently effectively 
general mas fully general multiagent scenario appears 
scenario allow agents heterogeneous degree homogeneity full heterogeneity 
goals actions domain knowledge goals actions domain knowledge goals actions domain knowledge general communicating mas scenario 
agents heterogeneous degree 
information transmitted directly agents indicated arrows agents 
communication broadcast transmitted point point 
issues techniques heterogeneous communicating agents choose communicate cases choose homogeneous minimize heterogeneity issues discussed pre vious scenarios apply 
studied issues communication protocols theories commitment 
discussed context heterogeneous non communicating mas scenario issue benevolence vs competitiveness complicated current con text 
issues existing techniques deal described summarized table 
issues techniques heterogeneous communicating learning opportunities understanding planning communicative acts evolving language benevolence vs competitiveness effects speech acts global dynamics negotiation communication utility truthfulness resource management schedule coordination commitment utility commitment decommitment collaborative localization changing shape size language protocols kif genesereth fikes kqml finin cool 
fox grounding meaning shared experience 
jung zelinsky legacy systems integration 
jennings wittig language learning 
grand cliff speech acts 
cohen levesque lux steiner learning social behaviors 
mataric reasoning truthfulness :10.1.1.29.5356:10.1.1.30.848
rosenschein zlotkin sandholm lesser multiagent learning 
tan wei training agents functions track driving :10.1.1.55.8066
clouse minimize need training 
potter cooperative evolution 
bull contract nets electronic commerce 
sandholm lesser market systems :10.1.1.42.237
huberman clearwater bayesian learning negotiation model 
zeng sycara market methods distributed constraints 
parunak generalized partial global planning gpgp 
decker lesser lesser learning choose coordination methods :10.1.1.32.8351
sugawara lesser query response information networks 
sycara division independent tasks 
parker internal social collective role commitments 
castelfranchi commitment states potential pre actual planning states 
haddadi belief desire intention bdi model oasis 
rao georgeff bdi commitments intentions :10.1.1.37.7970
rao georgeff room agreements :10.1.1.37.7970:10.1.1.37.7970
stone veloso coalitions 
zlotkin rosenschein shehory kraus sandholm lesser fusing uncertain sensor data 
fox grabowski inter component communication metamorphic robots 
table issues techniques learning opportunities heterogeneous communicating multiagent systems reflected literature 
understanding communicating multiagent systems particularly domains agents built different de signers set language protocol agents interacting 
independent aspects protocols information content message format coordination conventions 
existing protocols levels kif content genesereth fikes kqml mes sage format finin cool coordination fox 
lot research done refining communication protocols 
challenge arises symbolic communication agents making sure sym grounded similarly internal representations different agents 
approach related social conventions discussed section possible shared past experiences ground symbolic representation 
technique heterogeneous multi robot vacuum cleaning task jung zelinsky 
industrial multiagent systems archon jennings wittig successfully legacy systems 
applied different industrial settings archon successfully allows independently developed heterogeneous computer systems communicate order create collaborative process control systems 
creatures grand cliff multiagent computer game sophisticated biological models 
agents ability grow learn including simple verb object language interactions human user agents environment 
planning communicative acts agent transmits information agent effect just action 
planning framework define preconditions effects communicative acts 
combined model agents effect communication act alter agent belief state agent agents 
theory communication action called speech acts cohen levesque lux steiner 
mataric adds learning dimension idea speech acts 
starting foraging behavior men tioned mataric agents learn choose set social behaviors includes broadcasting listening mataric 
learning extended reinforcement received direct rewards obtained agent rewards obtained agents 
communication planning action possibility arises communicating tion order satisfy particular goal 
instance agent may want agent believe true 
making true agent just say true 
exam ple sandholm lesser analyze framework agents allowed decommit agreements agents paying penalty agents 
consider case agent truthful decommitment hoping agent decommit 
situations agents consider communications believe rosenschein zlotkin 
benevolence vs competitiveness studies involving competitive agents described heterogeneous non communicating sce see section 
current scenario examples competitive agents 
similar tan multiagent rl pursuit domain tan wei competing learners :10.1.1.55.8066
agents compete earn right control single system wei 
highest bidder pays certain amount allowed act receives reward results action 
learning approach time benevolent agents explore interesting idea having agent teach agent communication clouse 
starting trainer moderate expertise task learner rewarded mimicking trainer 
furthermore trainer recommend learner action take situation direct learner reward state 
eventually learner able perform task guidance 
training useful concept research driven goal reducing role human trainer 
opposed process shaping system designer develops simple behaviors slowly builds complex ones populations appropriately seeded competitive evolution reduce amount designer effort 
potter grefenstette illustrate effect domain described robots compete stationary pellet food 
subpopulations rules gas seeded effective different situations 
specialized subpopulations rules corresponding shaped behaviors tend emerge 
gas evolve separate communicating agents control different legs robot cooperative evolution bull 
negotiation drawing inspiration competition human societies researchers designed negotiating multiagent systems law supply demand 
contract nets framework smith agents goals self interested limited reasoning resources 
bid accept tasks agents perform tasks proper resources subcontract agents 
agents pay contract tasks shop lowest bidder 
multiagent issues arise contract nets sandholm lesser :10.1.1.42.237:10.1.1.42.237
similar spirit implemented multiagent system controls air temperature different rooms building huberman clearwater 
person set thermostat temperature 
depending actual air temperature agent room tries buy hot cold air room excess 
time agent sell excess air current temperature rooms 
modeling loss heat transfer room agents try buy sell best possible prices 
market regulates provide equitable usage shared resource 
zeng sycara study competitive negotiation scenario agents bayesian learning techniques update models bids counter bids negotiation process 
system parunak uses market methods distributed constraint prob lems 
designers different points supply chain negotiate characteristics design buying selling characteristics propagating resulting constraints 
resource management example multiagent resource management design characteristics desired agent may consume resources 
similarly generalized partial global planning gpgp allows heterogeneous agents post con straints commitments task time local schedulers coordinate aid centralized agent decker lesser :10.1.1.32.8351
proposed general multiagent ar chitecture gpgp contains components local agent scheduling multiagent coordination organizational design detection diagnosis lesser heterogeneous communicating multiagent system applied diagnosis local area network agents learn choose different coordination strategies current situation sugawara lesser 
sophisticated coordination methods require fewer network time resources may lead tasks failing executed redundant actions multiple agents 
retsina sycara uses classes heterogeneous communicating agents deliver information response specific user queries information networks 
retsina able satisfy information requests multiple users searching multiple information sources considering network constraints resource limitations information agents 
retsina implement distributed network applications including financial portfolio manager personal information manager meeting scheduler satellite visibility forecaster 
alliance learning variant alliance parker communication heterogeneous robots help divide independent tasks robots 
emphasis fault ance agents broadcast task currently working 
communication fails multiple robots temporarily try task eventually realize conflict observation move different task 
alliance robots learn evaluate abilities respect specific tasks order efficiently divide tasks team 
commitment decommitment agents communicate may decide cooperate task amount time 
doing commitments 
committing agent involves agreeing pursue goal possibly manner regardless serves interests 
commitments systems run smoothly providing way agents trust obvious get self interested agents commit reasonable way 
theory commitment decommitment commitment terminates consequently drawn considerable attention 
castelfranchi defines types commitment internal commitment agent binds social commitment agent commits agent collective commitment agent agrees fill certain role 
setting alarm clock example internal commitment wake certain time 
commitment states planning states potential cooperation pre commitment commitment haddadi 
agents means ends analysis plan goals terms com opportunities 
conducted model called belief desire intention bdi 
bdi popular technique modeling agents 
agents domain knowledge beliefs goals desires modeled intentions goals currently trying achieve methods trying achieve 
bdi model build system air traffic control oasis rao georgeff implemented testing parallel human operators retain full control airport sydney australia :10.1.1.37.7970:10.1.1.37.7970:10.1.1.37.7970
aircraft represented controlling agent deals global sequencing agent 
oasis mixes reactive deliberative actions agents break planned sequences coming situations demand immediate reaction 
agents control beliefs desires commitments regarding intentions 
room agreements stone veloso form commitment communi agents 
able synchronize safe communication environment agents agree protocols task decompositions dynamic periods restricted communication 
dy namic periods agents rely follow agreement 
groups agents may decide commit 
usual agent agent commitment scenarios certain situations agents may want form tions zlotkin rosenschein 
conducted game theory framework agents consider utility joining coalition bound try advance utility mem bers exchange reciprocal consideration 
shehory kraus distributed algorithm task allocation coalitions needed perform tasks efficient single agents 
sandholm lesser vehicle routing domain illustrate method agents form valuable coalitions intractable discover optimal coalitions 
collaborative localization localization common challenge autonomous robots 
robotic tasks robot know situated world act effectively 
common approach localization markov localization robot maintains probabilistic belief current position observations map environment 
extended approach multiple robots fox 
robot detects robot current belief position detected relative position increase data available effort localize 
approach successfully implemented homogeneous robots robots different sensors 
millibots grabowski smallest scale components heterogeneous commu multi robot system able perform collaborative localization mapping 
millibot robot dimensions roughly specialized subset sensors collect data environment 
order maintain localization millibots group stay points robots 
periodically move new location replaced robot group move 
sensing robots broadcast sensory data larger robot acts team leader 
team leader fuse data exploring robots send back tasks accomplish 
changing shape size deployable robot inter robot metamorphic capabilities particularly ambitious project involving heterogeneous communicating robots 
goal create robot change shape size reconfiguring components splitting parts joining back 
project far focussed considerable challenge creating necessary hardware components casta discuss need wireless inter component communication support docking remote sensing 
learning opportunities possible ways current scenario enhance mas ml techniques 
heterogeneous communicating multiagent scenario clear need pre define language communication protocol agents 
interesting alternative allow agents learn communicate interpret 
example agent small language utterances small set meanings mapping 
agents learn say interpret hear 
possible result efficient communications need understandable agents agents humans 
considering communications speech acts agents allowed learn effects speech global dynamics system 
domains low bandwidth large time delays associated communication utility communicating moment learned 
addition allowed learn communicate agents avoid reliably communication agent says turns true believed readily 
commitment act agent goals benefits disadvantages 
system builders may want allow agents learn commit 
learning opportunities scenario summarized table 
robotic soccer multiagent domains mentioned course survey including design planning entertainment games air traffic control air combat personal assistants load balancing robotic leg control 
section single domain embodies multiagent issues 
robotic soccer particularly domain studying mas 
originated mackworth gaining popularity years international competitions place kim kitano asada kitano veloso 
subject official ijcai challenge kitano 
evaluate different mas techniques direct manner teams implemented different techniques play 
pursuit domain serves purposes illustration robotic soccer complex interesting general test bed mas 
predators prey pursuit domain complex simulate real world 
robotic soccer game real world complexities retained 
key aspect soccer complexity need agents control control ball passive part environment 
overview robotic soccer played real robots simulator 
robotic soccer system dynamo system sahota 
sahota built vs version game 
robotic issues studied real world instantiation issues studied simulation 
particularly simulator purpose soccer server developed noda pictured 
simulator realistic ways players vision limited players communicate posting blackboard visible players players controlled separate processes player teammates opponents player limited stamina actions sensors noisy play occurs real time 
simulator provides domain supports users wish build agents 
furthermore teams agents evaluated playing standard teams 
simulator competition teams world kitano continues purpose currently 
robotic soccer satisfies decker criteria dai test beds decker 
mas robotic soccer main goal test bed facilitate trial evaluation ideas promise real world 
wide variety mas issues studied simulated robotic soccer 
fact mas soccer server system issues listed table feasibly studied soccer simulator 
advantages robotic soccer test bed mas summarized table 
table advantages simulated robotic soccer mas test bed complex realistic easily accessible embodies mas issues direct comparisons possible multiagent ml opportunities homogeneous non communicating mas studied robotic soccer fixing behavior opposing team populating team studied identical mute players 
keep homogeneous agent scenario opponents modeled agents 
context players reactive deliberative degree 
extremely reactive agent simply look ball move straight shooting possible 
extreme players may may knowledge part team 
hand players model enabling deliberative reasoning approach ball move different part field order defend receive pass 
players modeling may reason affect behav iors inherently dynamic environment 
possible study relative merits local global perspectives world 
robots global views help overhead camera soccer server comes equipped omniscient mode permits global views 
simulated robotic soccer usually approached problem requiring local sensing 
heterogeneous non communicating mas studied robotic soccer domain 
player teammates global goal opponents opposite goal player benevolent competitive time 
ity combination collaborative adversarial reasoning major feature domain 
teams learning course single game games issues evolving agents including arms race credit assignment problem arise 
soccer server stamina resource assigned individual agent 
team level stamina important resource management agents tired team ineffective 
team advantage distribute running different agents 
trying collaborate players actions usually interdependent execute successful pass passer receiver execute appropriate actions 
modeling purpose coordination helpful 
addition opponents actions predicted proactive measures taken render ineffective 
social conventions programmed notions agent pass agents play defense help coordination 
room agreement stone veloso example social conventions team 
communication allowed players reliable method filling different team roles needed soccer team defender forward 
flexible teamwork structure stone veloso method 
homogeneous communicating mas studied fixing behavior opposing team allowing teammates communicate 
distributed sensing studied context due large amount hidden state inherent soccer server 
moment particular agent see small portion world 
communicating teammates get complete picture world 
particularly important soccer server choose communication content carefully 
players limited hearing frequency utterance cause subsequent important information go 
heterogeneous communicating mas appropriate scenario study context robotic soccer 
agents heterogeneous communicate full potential domain realized scenario 
players sending messages language order understand 
especially single channel low bandwidth communication environment modeled soccer server agents plan communicative acts 
opponents understand language planned utterance affect knowledge teammates opponents 
utility communication carefully considered possibility lying order fool opponent arises 
addition low bandwidth creates condition sending message may prevent messages getting 
heterogeneous non communicating scenario agents teammates adversaries reason benevolent competitive 
negotiation protocols may useful robotic soccer domain different agents different sensory perspectives different opinions course action best team 
real time environment timing important team play including simple pass 
resource management terms timing action coordination crucial 
protocols needed commitment team plays passer receiver pass play agree execute pass 
complex team plays set plays players may need commit participate 
issue arises single adhere committed play may react pressing situations ignore commitment 
agent unsure position environment take cues agents observation communication exhibiting collaborative localization 
terms reasons mas table robotic soccer systems usually require separate agents controlling separate players benefit parallelism robustness simpler programming mas 
systems players onboard sensors necessarily multiagent single agent access players sensory inputs 
competitions stipulate rules robots controlled separate agents 
teams controlled separate agents 
teams theoretically controlled single agent stand gain mas 
processing sensory inputs different players separately multiple agents control players parallel contending different tasks field 
player position defend goal preparing offensive attack 
players need controlled agent go tasks parallel 
furthermore agents fails reason happens real robotic systems agents attempt compensate continue playing 
empirically easier program single agent player control entire team centrally 
demonstrated mas issues summarized table studied robotic soccer 
review research conducted domain 
describe research conducted early years organized robotic soccer workshops served foundations popularity domain 
second review research dedicated robotic soccer workshops held conjunction international competitions contemporary robotic soccer related research 
foundations producing natural language commentary real time input soccer system andre ai research related soccer 
soccer analyzed human soccer games 
looking triggers terminations events player running ball passed soccer aims announce important events redundancy 
robotic soccer introduced interesting promising domain ai research vision interface conference june mackworth 
dynamite working robotic soccer sys tem barman sahota described time 
ground breaking system robotic soccer served inspiration basis authors robotic soccer domain dynamite test bed designed capable supporting robots team done vs scenario 
uses overhead camera color detec tion provide global sensory information robots 
dynamite introduce decision making strategy called reactive deliberation choose hard wired behaviors sa 
subsequently rl approach high level sensory predicates choose hard wired behaviors ford 
asada developed robots equipped board sensing capabilities 
robots learning easy missions rl training technique learn hit stationary ball goal 
contribution construction state action spaces reduce complexity learning task asada 
opposed action dependent features rl create feature space prior learning states clustered learning best action take state 
contribution combination low level behaviors shooting avoiding opponent learned rl asada 
building learned behaviors different behavior levels layered learning previously learned control strategies produce new replaces original 
minimax learning markov games applied simulated soccer game littman :10.1.1.135.717
version domain simpler soccer server having states actions hidden information 
player team moves grid world ball possessed players 
minimax players learn optimal probabilistic policies maneuvering past ball 
authors conducted machine learning experiments simulator closely sim sahota simulates dynamite robots mentioned 
memory learning allow player learn shoot pass ball stone veloso :10.1.1.1.5959
neural networks teach player shoot moving ball particular parts goal stone veloso :10.1.1.1.5959
training small region field agent able learn successfully time approach moving ball score areas field 
experiments served basis initial learning experiments soccer server stone veloso :10.1.1.1.5959
early learning experiment soccer server player learned shoot pass matsubara 
agent bases decision positions ball teammate 
competition years research reported section confirmed potential robotic soccer ai research domain justified value having large scale competitions research perspective 
starting competitions held pre robocup continuing great deal robotic soccer related research 
dedicated robotic soccer workshops held conjunction competitions scientific forums 
subsection review robotic soccer research 
robot hardware research inspired competitions devoted building robot hardware suit able challenging environment achim hong hsia kim shim 
emphasis hardware approaches varies greatly 
research focuses fast robust visual perception environment sargent cheng zelinsky han veloso 
research focuses automatic calibration vision pa rameters shen veloso uther response need vision systems various lighting conditions conditions competitions lab 
vision alternative approach laser range finder localization environment gutmann 
research focuses robot path planning crowded dynamic environments han kim chung stone 
path planning particularly challenging non holonomic robots move straight direction facing curved paths starting current location direction 
omnidirectional robots simplify path planning considerably consider direction facing constraint price 
addition robots developed specifically competitions robots created ex special soccer related skills 
mizuno nomad robot dribble shoot soccer ball moves smoothly open space 
sony legged robots fujita walk legs 
basis exclusively legged robot soccer competition veloso 
honda humanoid robots hirai demon kicking real soccer ball performing penalty shot shooting robot 
demonstration indicates feasibility robocup long term goal having humanoid robot soc cer competition real soccer field kitano 
soccer server accessories addition soccer playing agent development soccer server substrate dimensional visualization real time natural language commentary education research 
shows dimensional visualization tool included soccer server software 
space converts dimensional image dimensional image changing camera angle rendering images real time 
research challenge addressed soccer server producing natural language com games proceed 
researchers aim provide low level descriptions action example announcing team possession ball high level analysis play example commenting team strategies different teams 
systems soccer server include rocco andre mike matsubara byrne binsted 
multiagent control robotic soccer strategy robotic soccer domain inspired different approaches building organizing teams agents 
research applying existing programming methodologies robotic soccer domain 
team gamma noda built nakashima logic programming language essentially multi threaded multi environment version prolog 
implements dynamic sub sumption architecture allowing agents override behaviors different ways current envi ronment behavior context 
team de la rosa built programming methodology agent oriented programming shoham 
research introduces new multiagent control methodologies applies robotic soc cer 
example robotic soccer team implementation programming method drogoul 
focuses organizational issues multiagent tasks analyzing interdependencies low level skills facilitating formation groups inter dependencies 
temporary organizations formed contract net framework smith 
example player ball contract player place particular location receive pass 
approach differs cmunited small robot team veloso stone uses strategic positioning attraction repulsion spar 
agents position autonomously agent ball decides autonomously pass negotiation involved enabling players act quickly possible 
scerri presents multi layered approach robotic soccer 
hierar approach involve learning behaviors 
approach different abstraction layers deal different granularities sensory input 
example low level move ball behavior ball precise location high level defend behavior call go ball knows ball defensive half field 
samba control architecture uses behavior layers reactive layer defines action maps sensory input actuator output task layer selects action maps 
isis tambe role approach robotic soccer steam tambe 
steam defines team behaviors invoked dynamically 
formation approach positioning agents soccer field matsumoto 
dynamic formations flexible positions player positions static team formation change dynamically 
researchers recognize importance decomposing soccer task different roles coradeschi karlsson ch ng padgham 
approach dynamically changing roles developed soccer simulator soccer server balch 
balch uses behavioral diversity measure encourage role learning rl frame finding providing uniform reinforcement entire team effective providing local reinforcements individual players 
definitions robotic soccer positions involve fixed locations agent locate default gutmann matsumoto 
contrast room agreement described flexible positions allow players adjust locations roles stone veloso 
ranges flexibility defined priori part room agreement 
observational reinforcement learning allows agents learn positions dy distribution past ball locations game 
similar approach described inoue 
learning approach teammate opponent capabilities learned repeated trials specific actions sen 
research conducted soccer simulator ball possession player eliminating necessity fine ball control 
player assigned efficiency range execution actions passing tackling dribbling corresponding probability action succeed 
agents know abilities teammates opponents 
learn estimate repeated trials 
agents base action decisions learned parameters 
layered learning stone implemented simulated robotic soccer domain 
layered learning general purpose machine learning paradigm complex domains learning mapping directly agents sensors actuators intractable 
hierarchical task decomposition lay ered learning allows learning level hierarchy learning level directly affecting learning higher level 
rl stone mentioned learned layers layered learning implementation 
learning approaches described learn portions agent behavior 
aspects created manually 
contrast entirely learned soccer behaviors created 
uther veloso extension grid world soccer game described littman :10.1.1.135.717
square grid locations world defined lattice hexagons 
action space increased geometric constraints altered 
added complexity necessitates development generalized trees allow agents learn successful policies uther veloso 
possible agents learn straight sensors actuators littman simulation smaller state space soccer server agents hidden state 
robocup robocup competitions included team created genetic program ming koza 
cases goal learn entirely agent sensors actuators soccer server 
attempt luke eventually scaled successful team created manually created low level skills :10.1.1.36.1280
year darwin united andre teller entered entirely learned team 
survey description field mas 
designed serve tion people unfamiliar field organizational framework system designers 
framework series increasingly complex powerful scenarios 
simplest sys tems homogeneous non communicating agents 
second scenario involves heterogeneous non communicating agents 
third deals homogeneous communicating agents 
general mas scenario involves communicating agents degree heterogeneity 
multiagent scenario introduces new issues complications 
mas literature tech niques systems address issues 
summarizing wide range existing useful directions 
survey machine learning approaches sized 
domain requires different approach research perspective ideal domain em bodies issues possible 
robotic soccer useful domain study mas 
systems wide variety agent heterogeneity communication abilities studied 
addition collaborative adversarial issues combined real time situation 
aid research complex domains field mas continue advance spread popularity designers real systems 
mas active field open issues 
continuing research dedicated conferences workshops international conference multiagent systems wei sen sen aaa 
mas appears dai conferences workshops distributed wei 
survey provides framework reader situate existing 
keith decker astro teller anonymous reviewers helpful comments suggestions 
aaai 
proceedings international conference multi agent systems icmas menlo park ca june 
aaai press 
victor general chair 
achim peter stone manuela veloso 
building dedicated robotic soccer system 
proceedings iros workshop robocup pages osaka japan november 

refinement soccer agents positions reinforcement learning 
hiroaki kitano editor robocup robot soccer world cup pages 
springer verlag berlin 
david andre astro teller 
evolving team darwin united 
minoru asada hiroaki kitano editors robocup robot soccer world cup ii 
springer verlag berlin 
elisabeth andre gerd herzog thomas rist 
simultaneous interpretation real world image sequences natural language description system soccer 
proc 
th ecai pages munich 
elisabeth andre gerd herzog thomas rist 
generating multimedia presentations robocup soccer games 
hiroaki kitano editor robocup robot soccer world cup pages 
springer verlag berlin 
arora sandip sen resolving social dilemmas genetic algorithms 
adaptation coevolution learning multiagent systems papers aaai spring symposium pages menlo park ca march 
aaai press 
aaai technical report ss 
minoru asada hiroaki kitano editors 
robocup robot soccer world cup ii 
lecture notes artificial intelligence 
springer verlag berlin 
minoru asada noda koh hosoda 
purposive behavior acquisition real robot vision reinforcement learning 
proc 
mlc colt machine learning computer learning theory workshop robot learning pages 
minoru asada noda koh hosoda 
coordination multiple behaviors acquired vision reinforcement learning 
proc 
ieee rsj gi international conference intelligent robots systems pages 
minoru asada noda koh hosoda 
action sensor space categorization robot learning 
proc 
ieee rsj international conference intelligent robots systems iros pages 
balch arkin 
communication reactive multiagent robotic systems 
autonomous robots 
tucker balch ronald arkin 
motor schema formation control multiagent robot teams 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
tucker balch 
behavioral diversity learning robot teams 
phd thesis college computing georgia institute technology 
tucker balch 
social entropy information theoretic measure robot team diversity 
autonomous robots 
issue 
mihai mark fox 
cool language describing coordination multi agent systems 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
barman little mackworth pai sahota wilkinson zhang 
dynamo real time experiments multiple mobile robots 
intelligent vehicles symposium pages tokyo july 
benda jagannathan 
optimal cooperation knowledge sources empirical investigation 
technical report bcs boeing advanced technology center boeing computing services seattle washington july 
kim binsted 
character design soccer commentary 
minoru asada hiroaki kitano editors robocup robot soccer world cup ii 
springer verlag berlin 
alan bond les gasser 
analysis problems research dai 
alan bond les gasser editors readings distributed artificial intelligence pages 
morgan kaufmann publishers san mateo ca 
bull fogarty 
evolution multi agent systems evolving communicating classifier systems gait robot 
stephanie forrest editor proceedings sixth international conference genetic algorithms pages san mateo ca july 
morgan kaufman 
cao alex fukunaga andrew kahng 
cooperative mobile robotics antecedents directions 
autonomous robots 
cristiano castelfranchi 
commitments individual intentions groups organizations 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
gordon cheng alexander zelinsky 
real time vision processing soccer playing mobile robot 
hiroaki kitano editor robocup robot soccer world cup pages 
springer verlag berlin 
simon ch ng lin padgham 
roles teamwork framework architecture 
applied artificial intelligence 
jeffery clouse 
learning automated training agent 
gerhard wei sandip sen editors adaptation learning multiagent systems 
springer verlag berlin 
philip cohen hector levesque 
communicative actions artificial agents 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
silvia coradeschi lars karlsson 
role decision mechanism teams reactive coordinating agents 
hiroaki kitano editor robocup robot soccer world cup pages 
springer verlag berlin 
kerstin dautenhahn 
getting know artificial social intelligence autonomous robots 
robotics autonomous systems 
ll 
de la rosa oller 
soccer team agent oriented programming 
robotics autonomous systems october 
keith decker victor lesser 
designing family coordination algorithms 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
keith decker 
distributed problem solving survey 
ieee transactions systems man cybernetics september 
keith decker 
environment centered analysis design coordination mechanisms 
phd thesis university massachusetts 
keith decker 
distributed artificial intelligence testbeds 
hare jennings editors foundations distributed artificial intelligence pages 
wiley interscience 
keith decker 
personal correspondence may 
keith decker 
task environment centered simulation 
carley gasser editors simulating organizations computational models institutions groups 
aaai press mit press 
proceedings th international workshop distributed artificial intelligence bandera texas october 
drogoul anne 
applying agent oriented methodology design artificial organizations case study robotic soccer 
autonomous agents multi agent systems 
gregory dudek michael jenkin evangelos milios david wilkes 
taxonomy multi agent robotics 
autonomous robots 
edmund durfee victor lesser daniel corkill 
trends cooperative distributed problem solving 
ieee transactions knowledge data engineering march 
edmund durfee 
computer really needs know learned 
proceedings tenth national conference artificial intelligence philadelphia pa 
morgan kaufman 
edmund durfee 
ignorance knowing just coordinate 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
maier sarit kraus jeffrey rosenschein 
coordination communication experimental validation focal point techniques 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
ferguson grigoris 
multiagent learning adaptation information filtering market 
adaptation coevolution learning multiagent systems papers aaai spring symposium pages menlo park ca march 
aaai press 
aaai technical report ss 
tim finin don mckay rich fritzson robin 
kqml information knowledge exchange protocol 
editors knowledge building knowledge sharing 
ohmsha ios press 
roger ford craig boutilier kanazawa 
exploiting natural structure reinforcement learning experience robot soccer playing 
unpublished manuscript 
dieter fox wolfram burgard hannes kruppa sebastian thrun 
probabilistic approach collaborative multi robot localization 
fujita 
open architecture robot entertainment 
proceedings international conference autonomous agents pages marina del rey ca february 
genesereth fikes 
knowledge interchange format version manual 
technical report logic computer science department stanford university 
glance tad hogg 
dilemmas computational societies 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
claudia goldman jeffrey rosenschein 
emergent coordination cooperative rules 
proceedings twelfth national conference artificial intelligence pages philadelphia pa 
morgan kaufman 
robert grabowski luis navarro paredis pradeep khosla 
heterogeneous teams modular robots mapping exploration 
autonomous robots 
issue 
stephen grand dave cliff 
creatures entertainment software agents artificial life 
autonomous agents multi agent systems 
john grefenstette robert daley 
methods competitive cooperative evolution 
adaptation coevolution learning multiagent systems papers aaai spring symposium pages menlo park ca march 
aaai press 
aaai technical report ss 

gutmann herrmann nebel topor 
cs freiburg team 
minoru asada editor proceedings second robocup workshop pages paris france july 
haddadi 
pragmatic theory interactions 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
han manuela veloso 
reactive visual control multiple non holonomic robotic agents 
proceedings international conference robotics automation leuven belgium may 
wong gie han seung min tae yong sung kwan 
path planning visual served multiple mobile robots genetic algorithms 
proceedings micro robot world cup soccer tournament pages korea november 
ieee robotics automation society 
barbara hayes roth lee robert van gent 
multiagent collaboration directed improvisation 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
thomas haynes sandip sen evolving behavioral strategies predators prey 
gerhard wei sandip sen editors adaptation learning multiagent systems pages 
springer verlag berlin 
thomas haynes roger wainwright sandip sen dale 
strongly typed genetic programming evolving cooperation strategies 
stephanie forrest editor proceedings sixth international conference genetic algorithms pages san mateo ca july 
morgan kaufman 
thomas haynes kit lau sandip sen learning cases compliment rules conflict resolution multiagent systems 
adaptation coevolution learning multiagent systems papers aaai spring symposium pages menlo park ca march 
aaai press 
aaai technical report ss 
kazuo hirai 
development honda humanoid robot 
presentation cmu robotics institute seminar november 
url www honda jp home hpr news robot 
holland 
multiagent systems lessons social insects collective robotics 
adaptation coevolution learning multiagent systems papers aaai spring symposium pages menlo park ca march 
aaai press 
aaai technical report ss 
sun gi hong tae eom il kwon jeong choi jin ho shin ju jang lee 
development soccer playing robots control cooperation strategy 
proceedings micro robot world cup soccer tournament pages korea november 
ieee robotics automation society 
tien hsia michael 
development micro robot system playing soccer games 
proceedings micro robot world cup soccer tournament pages korea november 
ieee robotics automation society 
marcus huber edmund durfee 
deciding commit action observation coordination 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
bernardo huberman scott clearwater 
multi agent system controlling building environments 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
inoue samuel 
learning system formation pass play 
poster session iros workshop robocup november 
jennings wittig 
archon theory practice 
gasser editors distributed artificial intelligence theory praxis pages 
kluwer academic press 
david jung alexander zelinsky 
grounded symbolic communication heterogeneous cooperating robots 
autonomous robots 
issue 
leslie pack kaelbling michael littman andrew moore 
reinforcement learning survey 
journal artificial intelligence research may 
yoon kim jin chung 
path planning multi mobile robots dynamic environment 
proceedings micro robot world cup soccer tournament pages korea november 
ieee robotics automation society 
kim kuk won ko gon kim su ho lee cho 
multiple micro robots playing robot soccer game 
proceedings micro robot world cup soccer tournament pages korea november 
ieee robotics automation society 
jong kim editor 
proceedings micro robot world cup soccer tournament korea november 
hiroaki kitano kuniyoshi noda minoru asada hitoshi matsubara osawa 
robocup challenge problem ai 
ai magazine spring 
hiroaki kitano milind tambe peter stone manuela veloso silvia coradeschi osawa hitoshi matsubara noda minoru asada 
robocup synthetic agent challenge 
proceedings fifteenth international joint conference artificial intelligence pages san francisco ca 
morgan kaufmann 
hiroaki kitano minoru asada noda hitoshi matsubara 
robocup robot world cup 
crossroads february 
hiroaki kitano editor 
robocup robot soccer world cup springer verlag berlin 
richard korf 
simple solution pursuit games 
working papers th international workshop distributed artificial intelligence pages february 
john koza 
genetic programming 
mit press 
victor lesser 
multiagent systems emerging ai 
acm computing surveys september 
victor lesser 
reflections nature multi agent coordination implications agent architecture 
autonomous agents multi agent systems 
ran levy jeffrey rosenschein 
game theoretic approach pursuit problem 
working papers th international workshop distributed artificial intelligence pages february 
michael littman 
markov games framework multi agent reinforcement learning 
proceedings eleventh international conference machine learning pages san mateo ca 
morgan kaufman 
sean luke charles jonathan gary jackson james hendler 
evolving soccer softbot team coordination genetic programming 
hiroaki kitano editor robocup robot soccer world cup pages berlin 
springer verlag 
andreas lux donald steiner 
understanding cooperation agent perspective 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
mackworth 
seeing robots 
basu li editors computer vision systems theory applications pages 
world scientific press singapore 
maja mataric 
interaction intelligent behavior 
mit eecs phd thesis mit ai lab august 
maja mataric 
learning behave socially 
third international conference simulation adaptive behavior 
hitoshi matsubara noda kazuo 
learning cooperative actions multi agent systems case study pass play soccer 
adaptation coevolution learning multiagent systems papers aaai spring symposium pages menlo park ca march 
aaai press 
aaai technical report ss 
hitoshi matsubara ian frank tanaka ishii noda nakashima 
automatic soccer commentary robocup 
minoru asada hiroaki kitano editors robocup robot soccer world cup ii 
springer verlag berlin 
akihiro matsumoto 
decision making characteristics interaction multi agent robotics soccer 
hiroaki kitano editor robocup robot soccer world cup pages 
springer verlag berlin 
takashi matsuyama 
cooperative distributed vision 
proceedings international workshop cooperative distributed vision kyoto japan october 
mizuno muraoka 
building possible dribble shoot 
proceedings iros workshop robocup november 
mizuno kawamoto muraoka 
method applied soccer behaviors proper feedback feedforward control 
hiroaki kitano editor robocup robot soccer world cup pages 
springer verlag berlin 
mor jeffrey rosenschein 
time prisoner dilemma 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
moukas pattie maes 
distributed collection system traffic information 
url www media mit edu projects 
sandip sen correlating internal parameters external performance learning soccer agents 
gerhard wei editor distributed artificial intelligence meets machine learning pages 
springer verlag 
nakashima noda 
organic programming multi agents 
victor lesser editor proceedings international conference multi agent systems page san francisco ca 
mit press 
andr casta wei min shen peter 
deployable robots inter robot metamorphic capabilities 
autonomous robots 
issue 
noda hitoshi matsubara kazuo ian frank 
soccer server tool research multiagent systems 
applied artificial intelligence 
noda 
team gamma agent programming 
hiroaki kitano editor robocup robot soccer world cup pages 
springer verlag berlin 
ei ichi osawa 
metalevel coordination strategy reactive cooperative planning 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
lynne parker 
heterogeneous multi robot cooperation 
phd thesis massachusetts institute technology 
lynne parker 
life long adaptation heterogeneous multi robot teams response continual variation individual robot performance 
autonomous robots 
issue 
van dyke parunak allen ward john sauter 
systematic market approach distributed constraint problems 
proceedings third international conference multi agent systems pages 
van dyke parunak 
applications distributed artificial intelligence industry 
hare jennings editors foundations distributed artificial intelligence pages 
wiley interscience 

generalised proof theory multi agent autoepistemic reasoning 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
dean 
neural network perception mobile robot guidance 
kluwer academic publishers 
mitchell potter kenneth de jong john grefenstette 
coevolutionary approach learning sequential decision rules 
stephanie forrest editor proceedings sixth international conference genetic algorithms pages san mateo ca july 
morgan kaufman 
prasad victor lesser susan lander 
learning organizational roles heterogeneous multi agent system 
adaptation coevolution learning multiagent systems papers aaai spring symposium pages menlo park ca march 
aaai press 
aaai technical report ss 
andrew price andrew jennings john 
robocup omnidirectional perspective 
hiroaki kitano editor robocup robot soccer world cup pages 
springer verlag berlin 
anand rao michael georgeff 
bdi agents theory practice 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
matt 
origins virtue human instincts evolution cooperation 
viking press april 
juha 
playing soccer modifying combining primitive reactions 
hiroaki kitano editor robocup robot soccer world cup pages 
springer verlag berlin 
jeffrey rosenschein gilad zlotkin 
rules encounter 
mit press 
christopher rosin richard belew 
methods competitive evolution finding opponents worth beating 
stephanie forrest editor proceedings sixth international conference genetic algorithms pages san mateo ca july 
morgan kaufman 
roychowdhury arora sandip sen effects local information group behavior 
adaptation coevolution learning multiagent systems papers aaai spring symposium pages menlo park ca march 
aaai press 
aaai technical report ss 
stuart russell peter norvig 
artificial intelligence modern approach 
prentice hall englewood cliffs nj 
michael sahota alan mackworth rod barman stewart 
real time control soccer playing robots board vision dynamite testbed 
ieee international conference systems man cybernetics pages 
michael sahota 
reactive deliberation architecture real time intelligent control dynamic environments 
proceedings twelfth national conference artificial intelligence pages 
michael sahota 
user guide 
url www cs ubc ca nest lci soccer january 
alfredo sanchez azevedo john leggett 
exploring issues agent user interfaces 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
tuomas sandholm robert crites 
multiagent learning semi competitive domain 
gerhard wei sandip sen editors adaptation learning multiagent systems 
springer verlag berlin 
tuomas sandholm victor lesser 
coalition formation bounded rational agents 
proceedings fourteenth international joint conference artificial intelligence pages los angeles ca 
morgan kaufman 
tuomas sandholm victor lesser 
issues automated negotiation electronic commerce extending contract net framework 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
tuomas sandholm victor lesser 
advantages leveled commitment contracting protocol 
proceedings thirteenth national conference artificial intelligence pages menlo park california 
aaai press 
randy sargent bill bailey carl witty anne wright 
dynamic object capture fast vision tracking 
ai magazine spring 
paul scerri 
multi layered behavior system controlling robocup agents 
hiroaki kitano editor robocup robot soccer world cup pages 
springer verlag berlin 
andrea schaerf yoav shoham moshe tennenholtz 
adaptive load balancing study multi agent learning 
journal artificial intelligence research 
jurgen schmidhuber 
general method multi agent reinforcement learning unrestricted environments 
adaptation coevolution learning multiagent systems papers aaai spring symposium pages menlo park ca march 
aaai press 
aaai technical report ss 
sandip sen editor 
adaptation coevolution learning multiagent systems papers aaai spring symposium menlo park ca march 
aaai aaai press 
aaai technical report ss 
onn shehory sarit kraus 
task allocation coalition formation autonomous agents 
proceedings fourteenth international joint conference artificial intelligence pages los angeles ca 
morgan kaufman 
wei min shen cho ali erdem sheila tejada 
building integrated mobile robots soccer competition 
proceedings international conference robotics automation 
sik shim jin jung soo kim choi han jong kim 
designing distributed control architecture cooperative multiagent systems 
proceedings micro robot world cup soccer tournament pages korea november 
ieee robotics automation society 

robocup construction intelligent navigation system 
hiroaki kitano editor robocup robot soccer world cup pages 
springer verlag berlin 
yoav shoham 
agent oriented programming 
technical report cs computer science dept stanford university 
jaime sichman yves demazeau 
exploiting social reasoning deal agency level 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
reid smith 
contract net protocol high level communication control distributed problem solver 
ieee transactions computers december 
larry stephens matthias merx 
effect agent control strategy performance dai pursuit problem 
proceedings th international workshop distributed artificial intelligence bandera texas october 
peter stone manuela veloso 
beating defender robotic soccer memory learning continuous function 
david touretzky michael mozer michael hasselmo editors advances neural information processing systems pages cambridge ma 
mit press 
peter stone manuela veloso 
collaborative adversarial learning case study robotic soccer 
adaptation coevolution learning multiagent systems papers aaai spring symposium pages menlo park ca march 
aaai press 
aaai technical report ss 
peter stone manuela veloso 
machine learning soccer server 
proceedings iros workshop robocup pages osaka japan november 
peter stone manuela veloso 
task decomposition dynamic role assignment low bandwidth communication real time strategic teamwork 
artificial intelligence june 
peter stone 
layered learning multiagent systems winning approach robotic soccer 
intelligent robotics autonomous agents 
mit press 
sugawara victor lesser 
line learning coordination plans 
coins technical report university massachussetts computer science department 
sugawara victor lesser 
learning coordination plans distributed os environments 
victor lesser editor proceedings international conference multi agent systems page san francisco ca 
mit press 
sycara decker williamson zeng 
distributed intelligent agents 
ieee expert december 
milind tambe ali erdem kaminka ion muslea marcelo 
explicit model teamwork robocup 
hiroaki kitano editor robocup robot soccer world cup pages 
springer verlag berlin 
milind tambe 
recursive agent agent group tracking real time dynamic environment 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
milind tambe 
tracking dynamic team activity 
proceedings thirteenth national conference artificial intelligence menlo park california 
aaai press 
milind tambe 
flexible teamwork 
journal artificial intelligence research 
ming tan 
multi agent reinforcement learning independent vs cooperative agents 
proceedings tenth international conference machine learning pages 
minoru asada koh hosoda 
behavior coordination mobile robot modular reinforcement learning 
proc 
ieee rsj international conference intelligent robots systems iros pages 
william uther manuela veloso 
generalizing adversarial reinforcement learning 
proceedings aaai fall symposium model directed autonomous systems 
manuela veloso peter stone 
individual collaborative behaviors team homogeneous robotic soccer agents 
proceedings third international conference multi agent systems pages 
manuela veloso william uther 
sony legged robot team 
minoru asada hiroaki kitano editors robocup robot soccer world cup ii 
springer verlag berlin 
manuela veloso william uther fujita minoru asada hiroaki kitano 
playing soccer legged robots 
proceedings iros intelligent robots systems conference victoria canada october 
manuela veloso enrico hiroaki kitano editors 
robocup robot soccer world cup iii 
springer verlag berlin 
appear 
jose vidal edmund durfee 
recursive agent modeling limited rationality 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
adam walker michael wooldridge 
understanding emergence conventions multi agent systems 
proceedings international conference multi agent systems icmas pages menlo park california june 
aaai press 
wang 
planning learning operators 
proceedings third international conference ai planning systems may 
gerhard wei sandip sen editors 
adaptation learning multiagent systems 
springer verlag berlin 
gerhard wei 
distributed reinforcement learning 
robotics autonomous systems 
gerhard wei 
ecai workshop learning distributed artificial intelligence 
call papers 
matsumoto 
omni directional autonomous robots cooperating team play 
hiroaki kitano editor robocup robot soccer world cup pages 
springer verlag berlin 
zeng katia sycara 
bayesian learning negotiation 
adaptation coevolution learning multiagent systems papers aaai spring symposium pages menlo park ca march 
aaai press 
aaai technical report ss 
gilad zlotkin jeffrey rosenschein 
coalition cryptography stability mechanisms coalition formation task oriented domains 
proceedings twelfth national conference artificial intelligence pages menlo park california august 
aaai press 

