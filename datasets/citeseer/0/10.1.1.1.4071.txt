tampere university technology publications klapuri signal processing methods automatic transcription music thesis degree doctor technology due permission public examination criticism tampere university technology th march clock noon 
tampere isbn issn copyright klapuri 
rights reserved 
part may reproduced stored retrieval system transmitted form means electronic mechanical photocopying recording prior permission author 
klapuri tut fi www cs tut fi signal processing methods automatic transcription music developed thesis 
music transcription understood process analyzing music signal write parameters sounds occur 
applied notation traditional musical notation symbolic representation gives sufficient information performing piece available musical instruments 
recovering musical notation automatically acoustic signal allows musicians reproduce modify original performance 
principal application structured audio coding midi representation extremely compact retains identifiability characteristics piece music important degree 
scope thesis automatic transcription harmonic melodic parts real world music signals 
detecting labeling sounds percussive instruments drums attempted presence allowed target signals 
algorithms proposed address distinct subproblems music transcription 
main part thesis dedicated multiple fundamental frequency estimation estimation concurrent musical sounds 
subproblem addressed musical meter estimation 
rhythmic aspects music refers estimation regular pattern strong weak beats piece music 
multiple estimation different algorithms proposed 
methods iterative approach prominent sound estimated sound cancelled mixture process repeated residual 
method derived pragmatic manner acoustic properties musical sound mixtures 
estimation stage algorithm proposed utilizes frequency relationships simultaneous spectral components assuming ideal harmonicity 
cancelling stage new processing principle spectral smoothness proposed efficient new mechanism separating detected sounds mixture signal 
method derived known properties human auditory system 
specifically assumed peripheral parts hearing modelled bank bandpass filters followed half wave rectification compression subband signals 
shown basic structure allows combined time domain periodicity frequency domain periodicity extraction 
derived algorithm higher order unresolved harmonic partials sound processed collectively need detect estimate individual partials 
consequence method works reasonably accurately short analysis frames 
computational efficiency method calculating frequency domain approximation summary autocorrelation function physiologically motivated representation sound 
proposed multiple estimation methods operate single time frame arrive approximately error rates 
motivated method superior short analysis frames 
hand pragmatically oriented method complete sense includes mechanisms suppressing additive noise drums estimating number concurrent sounds analyzed signal 
musical interval chord identification tasks algorithms outperformed average trained musicians 
musical meter estimation method proposed performs meter analysis jointly different time scales temporally atomic tatum pulse level tactus pulse level corresponds tempo piece musical measure level 
acoustic signals arbitrary musical genres considered 
initial time frequency analysis new technique proposed measures degree musical accent function time different frequency ranges 
followed bank comb filter resonators perform feature extraction estimating periods phases pulses 
features processed probabilistic model represents primitive musical knowledge performs joint estimation tatum tactus measure pulses 
model takes account temporal dependencies successive estimates enables causal noncausal estimation 
simulations method worked robustly different types music improved state art methods 
problem detecting beginnings discrete sound events acoustic signals onset detection separately discussed 
keywords acoustic signal analysis music transcription fundamental frequency estimation musical meter estimation sound onset detection 
ii preface carried institute signal processing tampere university technology finland 
wish express gratitude professor jaakko astola making possible start working transcription problem help advice contribution bringing expertise motivated people lab world 
am grateful invaluable encouragement support couple years 
thesis probably exist 
members past audio research group part making motivating enjoyable working community 
especially wish tuomas antti nen antti sepp nen timo friendship humour designing algorithms fun 
wish staff acoustic laboratory helsinki university technology special help 
especially wish karjalainen lim ki setting example researchers persons 
financial support tampere graduate school information science engineering foundation emil edist ti nokia foundation gratefully acknowledged 
wish parents klapuri encouragement path education system brother advice research 
go dear wife support love understanding intensive stages putting 
express gratitude lord jesus christ foundation life situations 
believe god created image put similar desire create things example transcription systems context 
looking nature elegance best sense mathematician uses word aware father quite orders magnitude ahead engineering 
tampere march klapuri god called fellowship son jesus christ lord 
cor 
iii iv contents 
preface 
iii contents 
list publications 
vii abbreviations 
ix 
terminology 
decomposition music transcription problem 
modularity music processing human brain 
role internal models 
mid level data representations 
humans transcribe music 
scope purpose thesis 
relation auditory modeling 
main results thesis 
multiple estimation system 
multiple estimation system ii 
musical meter estimation sound onset detection 
outline thesis 
musical meter estimation 
previous 
methods designed primarily symbolic input midi 
methods designed acoustic input 
summary 
method proposed publication 
results criticism 
approaches single estimation 
harmonic sounds 
taxonomy estimation methods 
spectral location type estimators 
time domain periodicity analysis methods 
harmonic pattern matching frequency domain 
shortcoming spectral location type estimators 
spectral interval type estimators 
unitary model pitch perception 
periodicity time domain amplitude envelope 
unitary model pitch perception 
attractive properties unitary model 
auditory model multiple estimator 
analysis unitary pitch model frequency domain 
auditory filters step unitary model 
exponential filters 
compression half wave rectification subbands step model 
periodicity estimation channel summing steps model algorithm proposed 
auditory model multiple estimator 
harmonic sounds resolved vs unresolved partials 
overview proposed modifications 
degree 
assumptions underlying definition 
model parameters 
reducing computational complexity 
multiple estimation iterative estimation cancellation 
multiple estimation results 
previous approaches multiple estimation 
historical background related 
approaches multiple estimation 
perceptual grouping frequency partials 
auditory model approach 
emphasis knowledge integration blackboard architectures 
signal model probabilistic inference 
data adaptive techniques 
approaches 
problem oriented approach multiple estimation 
basic problems estimation music signals 
noise suppression 
predominant estimation 
bandwise estimation 
harmonic selection 
determining harmonic summation model 
cross band integration estimation inharmonicity factor 
coinciding frequency partials 
diagnosis problem 
resolving coinciding partials spectral smoothness principle 
identifying harmonics coincide 
criticism 


multiple estimation 
musical meter estimation 

models 
utilizing longer term temporal features multiple estimation 
music transcription solved problem 
bibliography 
appendices 
author contribution publications 
errata 
publications 
vi list publications thesis consists publications earlier unpublished results 
publications referred text 
klapuri number theoretical means resolving mixture harmonic sounds proc 
european signal processing conference greece 
klapuri sound onset detection applying psychoacoustic knowledge proc 
ieee international conference acoustics speech signal processing phoenix arizona 
klapuri multipitch estimation sound separation spectral smoothness principle proc 
ieee international conference acoustics speech signal processing salt lake city utah 
klapuri astola efficient calculation physiologically motivated representation sound proc 
th ieee international conference digital signal processing santorini greece 
klapuri multiple fundamental frequency estimation harmonicity spectral smoothness ieee trans 
speech audio proc 
klapuri astola automatic estimation meter acoustic musical signals tampere university technology institute signal processing report tampere finland 
vii viii abbreviations acf autocorrelation function 
asa auditory scene analysis 
casa computational auditory scene analysis 
dft discrete fourier transform 
defined page em expectation maximization 
erb equivalent rectangular bandwidth 
defined page 
fundamental frequency 
defined page 
fft fast fourier transform 
flex exponential filter 
defined page 
full wave odd th law compression 
defined page 
half wave rectification 
defined page 
idft inverse discrete fourier transform 
midi musical instrument digital interface 
explained page 
mpeg moving picture experts group 
rounded exponential filter 
defined page 
summary autocorrelation function 
defined page 
snr signal noise ratio 
ix transcription music defined process analyzing acoustic musical signal write parameters sounds constitute piece music question 
traditionally written music uses note symbols indicate pitch onset time duration sound played 
loudness applied musical instruments specified individual notes determined larger parts 
example traditional musical notation shown fig 

representational sense music transcription seen transforming acoustic signal symbolic representation 
written music primarily performance instruction representation music 
describes music language musician understands produce musical sound 
point view music transcription viewed discovering recipe reverse engineering source code music signal 
applied notation necessarily need traditional musical notation symbolic representation adequate gives sufficient information performing piece available musical instruments 
guitar player example finds convenient read chord symbols characterize note combinations played general manner 
case electronic synthesizer resynthesis midi file example appropriate representation 
musical score allow reproducing piece music making musically meaningful modifications 
changes symbols score cause meaningful changes music high abstraction level 
example possible change arrangement way playing musical style instrumentation change add remove instruments piece 
relaxing effect exercise performing varying music quite different thing merely passively listening piece music amateur musician knows 
contribute kind active attitude music driving motivations thesis 
applications music transcription include structured audio coding 
midi representation extremely compact retains identifiability characteristics piece music important degree 
structured audio coding sound source parameters need encoded bandwidth stays kbit see mpeg document iso 
object representation able utilize fact music redundant levels 
searching musical information melody piece 
music analysis 
transcription tools facilitate analysis music man 
excerpt traditional musical notation score 

musical instrument digital interface 
standard interface exchanging performance data parameters electronic musical devices 
agement archives 
music changing instrumentation applying effects certain parts selectively extracting certain instruments 
interactive music systems generate accompaniment singing playing line real time rap row 
music related equipment light effects music signal 
person musical education usually able transcribe polyphonic music sounds playing simultaneously 
richer polyphonic complexity musical composition transcription process requires musical ear training knowledge particular musical style playing techniques instruments involved 
skilled musicians able resolve rich polyphonies accuracy flexibility computational transcription systems fall clearly humans performance 
automatic transcription polyphonic music subject increasing research interest years 
topic explored mainly individual researchers 
transcription problem ways analogous automatic speech recognition received comparable academic commercial interest 
larger scale research projects undertaken stanford university moo cha university michigan pis ste university tokyo kas massachusetts institute technology haw mar tampere university technology kla vii pau vir cambridge university hai dav university london bel abd 
doctoral theses topic prepared moo pis maher mah mel hawley haw god rossi ros sterian ste bello bel hainsworth hai hai 
complete review analysis previous chapter 
despite number solve problem practically applicable general purpose transcription system exist time 
proposals achieved certain degree accuracy transcribing limited complexity polyphonic music kas mar ste tol dav bel 
typical limitations target signals number concurrent sounds limited fixed interference drums percussive instruments allowed 
relatively high error rate systems reduced practical applicability 
degree success real world music cd recordings previously demonstrated goto got 
system aims extracting melody bass lines complex music signals 
commercial transcription systems released ara hut inn mus sev see bui comprehensive list 
accuracy programs limited 
surprisingly transcription single voice singing solved problem indicated fact accuracy voice input functionalities score writing programs comparable humans see cla comparative evaluation available monophonic transcribers 
tracking pitch monophonic musical pas 
polyphonic refers signal sounds occur simultaneously 
word monophonic refer signal note sounding time 
terms monaural signal stereo signal refer single channel channel audio signals respectively 

aim ear training music develop faculty discriminating sounds recognizing musical intervals playing music ear 
sage practically solved problem quantization continuous track pitch estimates note symbols discrete pitch timing turned difficult problem target signals particularly singing 
efficient musical knowledge necessary order guess score performed pitch track vii 
general idea automatic music transcription system patented ale 
terminology terms defined going 
pitch perceptual attribute sounds defined frequency sine wave matched target sound psychoacoustic experiment ste 
matching accomplished consistently human listeners sound pitch har 
fundamental frequency corresponding physical term defined periodic nearly periodic sounds 
classes sounds fundamental frequency defined inverse period 
ambiguous situations period corresponding perceived pitch chosen 
melody series single notes arranged musically meaningful succession bro 
chord combination simultaneous notes 
chord consonant depending harmonious pitch intervals component notes 
harmony refers part musical art science deals formation relations chords bro 
harmonic analysis deals structure piece music regard chords consists 
term musical meter rhythmic aspects music 
refers regular pattern strong weak beats piece music 
perceiving meter characterized process detecting moments musical stress acoustic signal filtering underlying periodicities discovered ler cla 
perceived periodicities pulses different time scales constitute meter 
meter estimation certain time scale place example person taps foot music 
timbre sound colour perceptual attribute closely related recognition sound sources answers question sounds han 
timbre explained simple acoustic property concept traditionally defined exclusion timbre quality sound listener tell sounds loudness pitch dissimilar ans 
human timbre perception facility accurate consequently sound synthesis important area music technology roa tol 
decomposition music transcription problem automatic transcription music comprises wide area research 
useful problem decomposing smaller subproblems 
section different strategies doing proposed 
modularity music processing human brain human auditory system reliable acoustic analysis tool existence 
reasonable learn structure function possible 
modularity certain kind observed human brain 
particular certain parts music cognition functionally neuro anatomically rest auditory cog nition ter 
main sources evidence studies patients neurological imaging experiments healthy subjects 
accidental brain damage adult age may selectively affect musical abilities speech related abilities vice versa 
studies brain damaged patients revealed internal structure music cognition system 
shows functional architecture colleagues derived case studies specific music impairments brain damaged patients 
breakdown pattern different patients studied representing specific music cognition tasks model fig 
inferred assumption specific impairment may due damaged processing component box broken flow information arrow components 
detailed line argument underlying model 
fig 
acoustic analysis module assumed common acoustic stimuli just music perform segregation sound mixtures distinct sound sources 
subsequent entities carry pitch organization temporal organization 
viewed parallel largely independent subsystems supported studies patients suffer difficulties deal pitch variations temporal variations vice versa bel 
music performance perception selectively lost 
musical lexicon characterized containing representations musical phrases person heard lifetime 
cases patient recognize familiar music process musical information adequately 
pitch organization tonal encoding interval analysis emotion expression analysis contour analysis vocal plan formation acoustic input acoustic analysis musical lexicon rhythm analysis singing tapping temporal organization meter analysis 
functional modules music processing facility human brain proposed 
parts related music processing reproduced 
model derived case studies specific impairments musical abilities brain damaged patients 
see text details 
main weakness studies brain damaged patients relatively small number cases 
common auditory disorder global sense applies types auditory events 
model fig 
example inferred approximately patients 
particularly disturbing model fig 
corresponds predict established tradition music theory music analysis ler deu 
neuroimaging experiments healthy subjects provide important source evidence concerning modularity localization cognitive functions 
particular known speech sounds higher level speech information preferentially processed left auditory cortex musical sounds preferentially processed right auditory cortex 
interestingly musical tasks involve specifically processing temporal information temporal synchrony duration processing associated left hemisphere 
bella suggest music pitch organization takes place primarily right hemisphere temporal organization left auditory cortex bel 
concluded ter relative asymmetry hemispheres bound informational sound content acoustic characteristics signals 
rapid temporal information common speech accurate processing spectral pitch information important music 
functional imaging positron emission tomography examine response human auditory cortex spectral temporal variation 
experiment amount temporal spectral variation acoustic stimulus parametrized 
result responses increase temporal variation weighted left responses increase melodic spectral variation weighted right 
authors review different types evidence support relative specialization auditory hemispheres left auditory cortex specialized better temporal resolution right auditory cortex better spectral resolution 
review additional evidence imaging experiments healthy adult subjects come basically ter 
computational transcription systems rhythm pitch analyzed separately different data representations kas mar dav got 
typically better time resolution applied rhythm analysis better frequency resolution pitch analysis 
studies justified technical artefact 
structure transcription systems determined merely pragmatic considerations 
example temporal segmentation performed prior pitch analysis order allow sizing positioning analysis frames pitch analysis typically computationally demanding stage kla dav 
role internal models large vocabulary speech recognition systems critically dependent language models represent linguistic knowledge speech signals rab jel jur 
models primitive nature example merely occurrence probabilities different word sequences gram models complex implementing part ofspeech tagging words syntactic inference sentences 
information equally important automatic transcription rich musical material 
probabilities different notes occur concurrently sequentially straightforwardly estimated large databases written music exist electronic format kla cla 
complex rules governing music readily available theory music composition information quantified computational models tem 
way transcription problem sources knowledge available 
pre stored internal models constitute source information addition incoming acoustic waveform 
uni directional flow information fig 
realistic sense represents data driven view information flows bottom information observed acoustic waveform combined provide meaningful auditory cues passed higher level processes interpretation 
top processing utilizes internal high level models input signals prior knowledge concerning properties dependencies sound events ell 
approach information flows top analysis performed order justify cause change predictions internal model 
transcription systems applied models sound source models analysis kas mar god systems readily enable replacing certain prior distributions musically informed ones got dav 
temperley proposed comprehensive rule system modelling cognition basic musical structures important step quantifying higher level rules govern musical structures tem 
detailed previous chapter 
utilizing diverse sources knowledge analysis raises issue integrate information meaningfully 
automatic speech recognition probabilistic methods successful respect rab jel jur 
statistical methods allow representing uncertain knowledge learning examples 
probabilistic models turned fundamental common ground integrating knowledge diverse sources 
discussed sec 

mid level data representations efficient way transcription problem called mid level representations 
auditory perception may viewed hierarchy representations acoustic signal conscious percept comprehended sentence language ell 
music transcription musical score viewed high level representation 
intermediate abstraction level indispensable symbols score readily visible acoustic signal transcription acoustic signal directly done dav 
advantage defined mid level representation system acts interface separates task computing mid level representation higher level inference follows 
fundamental mid level representation human hearing signal auditory nerve 
know little exact mechanisms brain wider consensus mechanisms physiological peripheral parts hearing 
precise auditory models exist able approximate signal auditory nerve moo 
great advantage important part analysis takes place peripheral stage 
mid level representations different music transcription systems reviewed chapter summary table page 
auditory models representation sinusoid tracks popular choice 
introduced sec 

excellent review mid level representations audio content analysis ell 
humans transcribe music 
approach transcription problem study conscious transcription process human musicians inquire transcription strategies 
aim determine sequence actions processing steps leads transcription result 
concrete questions involved 
piece processed pass listened times 
duration elementary audio chunk taken consideration time 
forth 
hainsworth conducted interviews musicians order find transcribe hai personal communication 
report transcription proceeds sequentially increasing detail 
global structure piece noted form 
includes implicit detection style instruments rhythmic context 
secondly dominant melodic phrases bass lines transcribed 
phase inner parts examined 
heard help context generated earlier stages applying gained musical knowledge individual 
chordal context cited aid transcribing inner parts 
suggests harmonic analysis early part process 
musical instrument aid means reproducing notes comparison original able heads mental rehearsal 
hai hainsworth points certain characteristics described method 
process sequential concurrent 
secondly relies human ability attend certain parts sonic spectrum selectively ignoring 
thirdly information early stages inform ones 
possibility feedback stages lower levels considered hai 
scope purpose thesis thesis concerned automatic transcription harmonic melodic parts real world music signals 
detecting labeling sounds percussive drum instruments attempted interested reader referred pau gou 
presence drum instruments allowed 
number concurrent sounds restricted 
automatic recognition musical instruments addressed thesis interested reader referred mar bro 
algorithms proposed address different subproblems music transcription 
main part thesis dedicated considered core music transcription problem multiple fundamental frequency estimation 
term refers estimation fundamental frequencies concurrent musical sounds 
corresponds closely acoustic analysis module fig 

different algorithms proposed multiple estimation 
derived principles human auditory perception described chapter 
oriented pragmatic problem solving introduced chapter 
algorithm originally proposed 
musical meter estimation subproblem addressed 
corresponds meter analysis module fig 

contrary flow information fig 
meter estimation algorithm utilize analysis results multiple algorithm 
meter estimator takes raw acoustic signal input uses filterbank emulation perform time frequency analysis 
done reasons 
multiple estimation algorithm computationally complex meter estimation done faster real time 
secondly meter estimation benefits relatively time resolution ms fourier transform frame filterbank emulation multiple estimator works adequately ms frames longer 
drawbacks basic decision discussed sec 

musical meter estimation multiple estimation complementary 
musical meter estimator generates temporal framework divide input signal musically meaningful temporal segments 
musical meter perform time quantization musical events assumed segment boundaries 
multiple estimator turn indicates notes active time able decide exact times individual note events 
imagine time frequency plane time flows left right different arranged ascending order vertical axis 
top plane multiple estimator produces horizontal lines indicate probabilities different notes active function time 
meter estimator produces framework vertical grid lines decide onset offset times discrete note events 
metrical information utilized adjusting positions lengths analysis frames applied multiple estimation 
practical advantage multiple estimation performed number discrete segments need performed continuous manner larger number overlapping time frames 
positioning multiple analysis frames metrical boundaries minimizes interference sounds occur concurrently event beginnings ends coincide metrical boundaries 
strategy producing transcription demonstrations available kla 
focus thesis bottom signal analysis methods 
models top processing considered proposed meter estimation method utilizes primitive musical knowledge performing analysis 
title signal processing methods indicates emphasis laid acoustic signal analysis part 
models oriented statistical methods vii rule inference tem artificial intelligence techniques mar 
relation auditory modeling lot carried model human auditory system moo 
unfortunately important parts human hearing located central nervous system studied indirectly 
psychoacoustics science deals perception sound 
psychoacoustic experiment relationships acoustic stimulus resulting subjective sensation studied presenting specific tasks questions human listeners ros kar 
aim thesis develop practically applicable solutions music transcription problem propose models human auditory system 
proposed methods ultimately justified practical efficiency psychoacoustic plausibility ability model phenomena human hearing 
role auditory modeling help practical goal solving transcription problem 
time reliable transcription system ears brain trained musician 
motivated methods turned successful ones audio content analysis 
chapters effort examine proposed methods light psychoacoustics 
difficult see important processing principle human hearing merely unimportant detail 
departures psychoacoustic principles carefully discussed 
important recognize musical notation primarily concerned mechanical sound production perception 
pointed scheirer sch note symbols representational elements music perception innate transcription facility brain 
task music transcription differs fundamentally trying predict response music arises human listener 
readers interested problem doctoral thesis scheirer excellent starting point sch 
ironically perceptual intentions music directly oppose transcription 
bregman pays attention fact music wants listener accept simultaneous sounds single coherent sound striking properties 
human auditory system tendency segregate sound mixture physical sources orchestration called oppose tendencies bre 
example synchronous onset times harmonic pitch relations knit sounds able represent higher level forms expressed atomic sounds separately 
human perception handles entities single object music may recruit large number harmonically related sounds hard transcribe separate adding complexity human listener 
main results thesis original contributions thesis publications chapter contains earlier unpublished results 
main results briefly summarized 
multiple estimation system publications constitute entity 
publication partially results derived 
method proposed deal coinciding frequency components mixture signals 
partials harmonic sound coincide frequency partials sounds overlap spectrum 
main results algorithm derived identifies partials coincide 
weighted order statistical filter proposed order filter coinciding partials sound observed 
sample selection probabilities different harmonic partials set estimated reliability 
method applied transcription polyphonic piano music 
processing principle proposed finding separating spectra concurrent musical sounds 
principle spectral smoothness observation partials harmonic sound usually close amplitude critical band 
words spectral envelopes real world sounds tend smooth function frequency 
contributions publication 
theoretical empirical evidence show importance smoothness principle resolving sound mixtures 
sound separation possible certain degree priori knowledge sound sources involved 
known properties peripheral hearing humans med shown spectral smoothing takes specific form human hearing 
algorithms varying complexity described implement new principle 
method proposed estimating concurrent musical sounds single time frame 
method complete sense included mechanisms suppressing additive noise drums estimating number concurrent sounds analyzed signal 
main results multiple estimation performed reasonably accurately compared trained musicians single time frame long term temporal features 
taken iterative estimation cancellation approach possible detect couple prominent rich polyphonies 
algorithm proposed uses frequency relationships simultaneous spectral components group sound sources 
ideal harmonicity assumed 
method proposed suppressing noisy signal components due drums 
method proposed estimating number concurrent sounds input signals 
multiple estimation system ii publication chapter thesis constitute entity 
computational efficiency method proposed chapter part results 
publication concerned perceptually motivated representation sound called summary autocorrelation function 
algorithm proposed calculates approximation frequency domain 
main results individual spectral bin fourier transform computed time time proportional analysis frame length complex fourier transform wideband input signal 
number distinct subbands calculating need defined 
algorithm implements model subband centered discrete fourier spectrum sample approaching continuous density subbands chapter example subbands 
bandwidths subbands need changed 
chapter thesis novel multiple estimation method proposed 
method derived known properties human auditory system 
specifically assumed peripheral parts hearing modelled bank bandpass filters ii half wave rectification compression time domain signals subbands 
main results practically applicable multiple estimation method derived 
particular method works reasonably accurately short analysis frames 
shown half wave rectification subbands amounts combined periodicity frequency domain periodicity extraction 
higher order unresolved partials harmonic sound processed collectively 
estimation detection individual higher order partials robust avoided 
musical meter estimation sound onset detection publication proposed method onset detection detection beginnings discrete sound events acoustic signals 
main contributions technique described cope sounds exhibit onset imperfections amplitude envelope rise 
psychoacoustic model intensity coding applied order find parameters allow robust detection onsets wide range input signals 
method musical meter analysis proposed 
analysis performed jointly different time scales temporally atomic tatum pulse level tactus pulse level corresponds tempo piece musical measure level 
main contributions proposed method works robustly different types music improved state art methods simulations 
technique proposed measuring degree musical accent function time 
technique partially ideas 
confirmed earlier result scheirer sch comb filter resonators suitable metrical pulse analysis 
different periodicity estimation methods evaluated result comb filters best terms simplicity vs performance 
probabilistic models proposed encode prior musical knowledge regarding wellformed musical meters 
models take account dependencies pulse levels implement temporal tying successive meter estimates 
outline thesis thesis organized follows 
chapter considers musical meter estimation problem 
review previous area 
followed short publication novel method meter estimation proposed 
technical details simulation results described 
short discuss achieved results 
chapter introduces harmonic sounds different approaches taken estimation fundamental frequency isolated musical sounds 
model human pitch perception introduced benefits point view estimation discussed 
chapter elaborates pitch model introduced chapter proposes previously unpublished method estimating multiple concurrent musical sounds 
chapter presents background material serves 
chapter reviews previous approaches multiple estimation 
core problem music transcription chapter seen potential approaches music transcription general 
chapter serves problem solving oriented method multiple estimation 
method originally published complete sense includes mechanisms suppressing additive noise estimating number concurrent sounds input signal 
needed order process real world music signals 
publications sec 

epilogue sec 
presents criticism method 
chapter summarizes main discusses 
musical meter estimation chapter reviews previous musical meter estimation serves publication 
concept musical meter defined sec 

meter analysis essential part understanding music signals innate cognitive ability humans musical education 
virtually anybody able hands music unusual see year old child time music 
point view music transcription meter estimation amounts temporal segmentation music certain criteria 
musical meter hierarchical structure consisting pulse sensations different levels time scales 
thesis metrical levels considered 
prominent level tactus referred foot tapping rate beat 
terminology ler word beat refer individual elements pulse 
musical meter illustrated fig 
dots denote beats sequence dots corresponds particular pulse level 
period pulse mean time duration successive beats phase time beat occurs respect piece 
tatum pulse name stemming temporal atom bil 
period pulse corresponds shortest durational values music incidentally encountered 
durational values exceptions integer multiples tatum period onsets musical events occur approximately tatum beat 
musical measure pulse typically related harmonic change rate length rhythmic pattern 
ambiguous metrical levels relatively defined span metrical hierarchy important levels 
tempo piece defined rate tactus pulse 
order meter sense musically pulse periods slowly varying beat larger levels coincide beat smaller levels 
concept phenomenal accent important meter analysis 
phenomenal accents events give emphasis moment music 
beginnings discrete sound events especially onsets long pitch events sudden changes loudness timbre harmonic changes 
lerdahl jackendoff define role phenomenal accents meter perception compactly saying moments musical stress raw signal serve cues listener attempts extrapolate regular pattern ler 
automatic estimation meter applications 
temporal framework facilitates cut paste operations editing music signals 
enables synchronization light effects video electronic instruments drum machine 
disc application metrical information mark boundaries rhythmic loop tatum tactus measure time seconds 
musical signal metrical levels illustrated reprinted 
musical meter estimation synchronize percussive audio tracks 
meter estimation symbolic midi data required time quantization indispensable subtask score typesetting keyboard input 
previous automatic meter analysis originated algorithmic models tried explain human listener arrives particular metrical interpretation piece meter explicitly spelled music lee 
early models performed meter estimation symbolic data artificial impulse pattern musical score ste lon lee pov 
brief models seen set rules define musical accent infer natural meter 
rule system proposed lerdahl jackendoff ler complete described verbal terms 
extensive comparison early models lee lee augmented desain honing des 
table lists characteristic attributes meter analysis systems 
systems classified main categories type input process 
algorithms designed symbolic midi input process acoustic signals 
column evaluation material gives specific idea musical material systems tested 
defining characteristic different systems aim meter analysis 
algorithms analyze meter time scales tactus level 
produce useful side information quantization onset offset times musical events 
columns approach mid level representation computation table attempt summarize technique achieve analysis result 
arbitrarily different approaches discerned set rules employing probabilistic model third deriving analysis methods mainly signal processing domain 
mid level representations refer data representations input final analysis result 
column computation summarizes strategy applied search correct meter possible meters 
methods designed primarily symbolic input midi rosenthal proposed system processes realistic piano performances form midi files 
system attempted emulate human rhythm perception including meter perception ros 
notable approach auditory functions taken account 
preprocessing stage notes grouped melodic streams chords information utilized 
rosenthal applied set rules rank prune competing meter hypotheses conducted beam search track multiple hypotheses time 
beam search strategy originally proposed pulse tracking allen dannenberg 
parncutt proposed detailed model meter perception systematic listening tests par 
algorithm computes salience different metrical pulses quantitative model phenomenal accents pulse salience 
apart rule models straightforward signal processing oriented approach taken brown performed metrical analysis musical scores autocorrelation function bro 
scores represented time domain signal sampling rate musical meter estimation table characteristics meter estimation systems input aim approach mid level representation computation evaluation material rosenthal midi meter time rule preprocessing stage notes multiple hypothesis tracking piano performances quantization model auditory organization grouped streams chords beam search brown score meter dsp initialize signal zeros assign autocorrelation function classical scores note duration values onset times periods estimated large kolen midi meter dsp initialize signal zeros network oscillators example analyses straight assign unity values note onsets period phase locking forward reimplement parncutt score meter rule phenomenal accent model individual match isochronous pattern accents artificial synthesized patterns accent listen events event parameters length loud modeling ing tests ness timbre pitch temperley midi meter time rule apply discrete time base assign viterbi cost functions event occur example analyses music types sleator quantization event closest ms time frame rence event length meter regularity source code available dixon midi tactus rule midi parameters midi events 
find periods histogram midi files expressive music audio heuristic audio compute amplitude phases multiple agents beam search audio files sharp attacks extract onset times source code available raphael midi tactus time probabilistic onset times viterbi map estimation example analyses audio quantization generative model expressive performances cemgil kap midi tactus time probabilistic onset times sequential monte carlo methods balance polyphonic piano performances pen quantization generative model score complexity vs tempo continuity beatles songs clave pattern goto audio meter dsp fourier spectra onset components time multiple tracking agents beam search pieces pop music muraoka reliability frequency range histogram periodicity analysis time signature pre stored drum patterns scheirer audio tactus dsp amplitude envelope signals find periods bank comb pieces strong beat subbands filters phases filter states music types source code available audio tactus probabilistic compute loudness curve maximum likelihood estimation qualitative report music con swing extract onset times weights exhaustive search stant tempo sharp attacks audio meter dsp rms energies octave subbands periodicity transform examples music constant tempo gouyon audio tatum dsp compute amplitude envelope find periods histogram drum sequences extract onsets times weights phases matching isochronous pattern duration constant tempo klapuri audio meter dsp degree accentuation function find periods bank comb filters audio signals music types probabilistic time frequency ranges viterbi back phases filter back states rhythmic pattern matching hz individual note represented impulse position note onset time weighted duration note 
pitch information 
large kolen associated meter perception resonance proposed entrainment oscillator adjusts period phase incoming pattern impulses located onsets musical events lar 
part larger project modeling cognition basic musical structures temperley sleator proposed meter estimation algorithm arbitrary midi files tem 
algorithm implementing preference rules verbally described ler produced metrical hierarchy output 
dixon proposed rule system track tactus pulse expressive midi performances dix 
introduced simple onset detector system applicable audio signals 
methods works quite midi files types problems audio files contain sharp attacks 
source codes temperley dixon systems publicly available testing 
cemgil kappen developed probabilistic generative model event times expressive musical performances cem 
model infer hidden continuous tempo variable quantized ideal note onset times observed noisy onset times midi file 
tempo tracking time quantization performed simultaneously balance smoothness tempo deviations versus complexity resulting quantized score 
model elegant drawback processes onset times events ignoring duration pitch loudness information 
ways similar bayesian model independently proposed raphael demonstrated acoustic input rap 
methods designed acoustic input goto muraoka meter tracking system works reasonable accuracy audio signals got 
popular music time signature considered 
system operates real time architecture multiple agents track alternative meter hypotheses 
beat positions larger levels inferred detecting certain drum sounds got chord changes got 
gouyon proposed system estimating tatum pulse percussive audio tracks constant tempo gou 
authors computed inter onset interval histogram applied way mismatch method maher mah find tatum temporal atom best explained multiple harmonic peaks histogram 
straightforward probabilistic model estimate tempo swing audio signals lar 
input model provided onset detector differentiating estimated loudness curve 
scheirer proposed method tracking tactus pulse music signals kinds provided strong beat sch 
important scheirer approach detect discrete onsets sound events middle step performed periodicity analysis directly half wave rectified differentials subband power envelopes 
periodicity subband analyzed bank comb filter resonators 
source codes scheirer system publicly available testing 
important way categorize meter estimators determine systems extract discrete events 
swing characteristic musical rhythms commonly jazz 
swing defined lar systematic slight delay second fourth quarter beats 
onset times middle step 
meter estimator ways similar scheirer method difference periodicity transform periodicity analysis bank comb filters set 
summary summarize earlier meter estimation concentrated symbolic midi data typically analyzed tactus pulse 
systems lar dix cem rap immediately extended process audio signals employing onset detector extracts beginnings discrete acoustic events audio signal 
authors dix rap introduced onset detector 
onset detection methods proposed auditory model moe subband power envelopes support vector machines dav neural networks mar independent component analysis abd complex domain unpredictability 
meter estimator originally developed symbolic data extended system usually robust diverse acoustic material classical vs rock music fully utilize acoustic cues indicate phenomenal accents music signals 
basic problems meter estimator needs address successful 
degree musical accentuation function time measured 
case audio input initial time frequency analysis closely related problem onset detection 
systems measure accentuation continuous manner sch set extract discrete events got gou lar 
secondly periods phases underlying metrical pulses estimated 
methods detect discrete events middle step inter onset interval histograms purpose dix got gou 
thirdly system choose metrical level corresponds tactus specially designated pulse level 
may take place implicitly prior distribution pulse periods par applying rhythmic pattern matching got 
tempo halving doubling symptom failing 
method proposed publication aim method proposed estimate meter acoustic musical signals levels tactus tatum measure pulse levels 
target signals restricted particular music type main genres including classical jazz music represented validation database 
overview method shown fig 

time frequency analysis part new technique proposed aims measuring degree accentuation music signals 
technique robust diverse acoustic material seen synthesis generalization earlier state art methods got sch 
brief preliminary analysis conducted quite large number subbands measuring degree spectral change channels 
adjacent bands combined arrive smaller number accent signals periodicity analy sis carried 
approach advantage frequency resolution suffices detect harmonic changes periodicity analysis takes place wider bands 
combining certain number adjacent bands prior periodicity analysis improves analysis accuracy 
interestingly combining channels periodicity analysis ana musical meter estimation periodicity channels optimal choice large number bands preliminary time frequency analysis channels leads reliable analysis 
periodicity analysis accent signals performed bank comb filter resonators similar scheirer sch 
illustrates energies comb filters function feedback delay period energies shown types artificial signals impulse train white noise signal 
important notice resonators rational number relations period impulse train samples show response 
turned important meter analysis 
case autocorrelation function example integer multiples come order achieve meter estimation performance explicit postprocessing step enhancing necessary autocorrelation function progressively decimated summed original autocorrelation function 
music signal analysis vc comb filter resonators filter states probabilistic model pulse periods phase model periods phases meter 
overview meter estimation method 
intermediate data representations accent signals vc band metrical pulse strengths resonator period time 
reprinted 
energy normalized energy energy delay samples delay samples normalized energy delay samples delay samples 
output energies comb filter resonators function feedback delay period energies shown impulse train period length samples left white noise signal right 
upper panels show raw output energies lower panels energies specific normalization 
reprinted 
combine ended comb filters different period estimation algorithms evaluated mentioned enhanced autocorrelation enhanced yin method de cheveign kawahara dec different types comb filter resonators sch banks resonators lar 
important observation period estimation methods performed equally thorough optimization 
suggests key problems meter estimation measuring phenomenal accentuation modeling higher level musical knowledge finding exactly correct period estimator 
bank comb filter resonators chosen complex best performing algorithms 
comb filters serve feature extractors probabilistic models 
model estimate period lengths metrical pulses different levels 
model estimate corresponding phases see fig 

probabilistic models encode prior musical knowledge regarding formed musical meters 
brief models take account dependencies different pulse levels tatum tactus measure additionally implement temporal tying successive meter estimates 
shown evaluation section leads reliable temporally stable meter tracking 
results criticism method proposed quite successful estimating meter different kinds music signals improved state art methods simulations 
similarly human listeners computational meter estimation easiest tactus pulse level 
measure pulse period estimation done equally robustly estimating phase straightforward 
appears due basic decision multiple analysis employed prior meter analysis 
measure pulse typically related harmonic change rate information potentially lead significantly better meter estimation measure pulse level 
tatum pulse turn phase estimation represent problem deciding period difficult humans proposed method 
critical elements meter estimation system appear initial time frequency analysis part measures musical accentuation function time implicit internal model represents primitive musical knowledge 
needed provide robustness diverse classical rock electronic music 
needed achieve temporally stable meter tracking fill parts meter implied musical surface 
challenge part develop model generic various genres example jazz classical music 
model proposed describes sufficiently low level musical knowledge generalize different genres 
musical meter estimation approaches single estimation multitude different methods determining fundamental frequency monophonic acoustic signals especially speech signals 
extensive reviews earliest methods rab hes methods hes dec gom 
comparative evaluations different algorithms rab hes dec 
sense list previous methods 
aim chapter introduce main principles different methods built understandable overview research area 
multiple estimators reviewed done separately chapter 
pre postprocessing mechanisms considered interested reader referred hes tal gom 
fundamental frequency measurable physical counterpart pitch 
sec 
pitch defined frequency sine wave matched target sound human listeners 
loudness duration timbre pitch basic perceptual attributes characterize sound events 
importance pitch hearing general indicated fact auditory system tries assign pitch frequency kinds acoustic signals 
sinusoids periodic signals pitch noise signals various kinds consistently matched sinusoid certain frequency 
steeply lowpass highpass filtered noise signal example pitch heard spectral edge 
amplitude modulating random noise signal causes pitch percept corresponding modulating frequency 
sounds bells plates vibrating membranes pitch waveform clearly periodic spectra show regular structure 
complete review zoo pitch effects hou har 
auditory system strongly inclined single frequency value summarize certain aspects sound events 
computational models pitch perception attempt replicate phenomenon med hou 
case estimation algorithms scope restricted periodic nearly periodic sounds concept fundamental frequency defined 
algorithms target signals limited called harmonic sounds 
discussed 
harmonic sounds harmonic sounds defined sounds spectral structure dominant frequency components approximately regularly spaced 
illustrates harmonic sound time frequency domains 
time ms frequency hz 
harmonic sound illustrated time frequency domains 
example represents trumpet sound fundamental frequency hz fundamental period ms 
fourier spectrum shows peaks integer multiples fundamental frequency 
amplitude magnitude db approaches single estimation ideal harmonic sound frequencies partials harmonics integer multiples 
case real world sound production mechanisms partial frequencies exact integral ratios general structure spectrum similar fig 

stretched strings example frequencies partials obey formula hf fundamental frequency harmonic index partial number inharmonicity factor fle 
shows spectrum vibrating piano string ideal harmonic frequencies indicated spectrum 
inharmonicity phenomenon appears higher order partials shifted upwards frequency 
structure spectrum general similar fig 
sound belongs class harmonic sounds 
inharmonicity due stiffness real strings contributes restoring force string tension 
consequence strings dispersive meaning different frequencies propagate different velocities string 
illustrates deviation frequency ideal harmonic position moderate inharmonicity value substituted 
shows example sound belong class harmonic sounds nearly periodic time domain clear pitch 
western music mallet instruments case point instruments produce pitched sounds harmonic 
sound fig 
represents family instruments 
methods proposed thesis mainly concerned harmonic sounds assuming ideal harmonicity operate quite reliably sounds illustrated fig 

limitation severe western music 
frequency hz 
spectrum vibrating piano string hz 
ideal harmonic locations numbered indicated marks spectrum 
inharmonicity phenomenon non ideal harmonicity shifts th harmonic partial position th ideal harmonic 
magnitude db deviation hz harmonic index 
deviation partial frequency ideal hf hz moderate inharmonicity factor calculate amplitude time ms magnitude db table lists western musical instruments produce harmonic sounds 
family mallet instruments commonly contemporary music 
taxonomy estimation methods frequency hz 
sound fundamental frequency hz illustrated time frequency domains 
right panel frequencies dominant spectral components shown relation 
table western musical instruments produce harmonic sounds 
produced sounds instrument family instruments involved harmonic harmonic string instruments piano strings violin reed instruments brass instruments trumpet english french horn flute bass flute organ pipe organs pipes reed pipes human voice singing voiced phonemes mallet drums drums tom toms drums estimation algorithms differ technical details regard information calculations 
single obvious way calculating acoustic signal perfectly periodic may background noise 
problem model level assumptions algorithms explicitly stated making difficult compare different algorithms combine advantages 
categorization model level analysis various methods 
psychoacoustics computational models pitch perception traditionally classified place models temporal models 
excellent competing theories supporting evidence har 
convincing attempt unify theories unitary model meddis colleagues med 
case practical estimation methods different categorization useful 
algorithms grouped look frequency partials harmonic spectral locations observe spectral intervals frequency intervals partials 
underlying idea categories understood looking fig 
described detail subsections 
algorithms measure periodicity time approaches single estimation domain signal belong category 
algorithms measure periodicity fourier spectrum belong category 
algorithms measure periodicity amplitude envelope represent tradeoff classes described sec 

models human pitch perception kind spectral locations spectral intervals important hearing 
representative variants category introduced analyzed order describe properties advantages 
spectral location type estimators time domain periodicity analysis methods time domain autocorrelation function acf algorithms frequently estimators see bro tal 
pointed karjalainen tol acf estimators close model level similarities cepstrum estimators nol continuum 
evident calculating acf time domain signal xn discrete fourier transform dft inverse idft idft dft xn 
definition cepstrum analogous obtained replacing second power logarithm function 
difference acf estimators quantitative 
raising magnitude spectrum second power emphasizes spectral peaks relation noise hand aggravates spectral peculiarities target sound 
applying logarithm function causes opposite 
acf estimators reported relatively noise immune sensitive formant structures speech especially strongest formant may mislead algorithm rab tal 
contrary cepstrum estimators perform relatively poorly noise exotic sounds rab 
tradeoff suggest generalized autocorrelation function second power replaced real valued exponent case tol 
acf cepstrum detectors implicit realizations model emphasizes frequency partials harmonic locations magnitude spectrum 
seen writing acf terms fourier spectrum real valued input signal cos length transform frame 
formula equivalent 
illustrates calculations case corresponds true period example sound 
squared magnitude spectrum components weighted spectral locations summed 
call acf cepstrum methods spectral location type estimators 
conceptually simple accurate estimation method proposed de cheveign kawahara dec 
algorithm called yin acf certain modifications 
novelty method specific normalization autocorrelation function reduces number free parameters increasing 
dec method thoroughly evaluated compared previous power weights frequency hz 
solid line illustrates power spectrum trumpet sound 
dashed line shows weights cos acf calculation corresponds fundamental period example sound 
curves displaced vertically clarity 
methods large database speech signals 
usability method music transcription evaluated vii publication 
autocorrelation methods closely related methods average absolute difference signal delayed version 
interesting generalization methods proposed applied state space embedding searching time delay signal resembles ter 
harmonic pattern matching frequency domain way weighting frequency components spectral locations perform explicit pattern matching frequency domain 
bro brown proposed method input sound analyzed simulating th octave filterbank 
leads spectral representation frequency components logarithmically spaced 
log frequency domain partials harmonic sound spacing independent sound 
example distance second third harmonic partial ln regardless 
consequence estimation performed cross correlating vector filterbank energies ideal harmonic pattern unity values assigned harmonic positions zeros 
maximum cross correlation function indicates position fundamental frequency 
maximum likelihood spectral pattern matching estimator proposed rodet dov 
authors set sinusoidal partials represent spectrum input sound sought best explained observed partials 
done bayesian manner gaussian functions centered multiple hypothesized represent likelihood observing partials candidate 
supplementary non harmonic noisy spectral components separately modeled 
completely different interesting spectral pattern matching approach twoway mismatch method maher mah 
method chosen minimize discrepancies observed frequency components harmonic frequencies generated trial values 
mismatch measure calculated average frequency differences observed partial nearest neighbour predicted harmonic frequencies 
combined mismatch measure calculated averaging frequency differences predicted harmonic frequency nearest neighbour observed partials 
approaches single estimation shortcoming spectral location type estimators major shortcoming spectral location oriented estimation methods able handle non ideal harmonic sounds appropriately 
described sec 
partials real physical assumed exactly harmonic spectrum positions 
spectrum piano sound fig 
illustrates situation 
inharmonicity big concern speech processing immediately met analyzing musical sounds wide frequency band 
methods described section advantageous respect 
spectral interval type estimators spectrum autocorrelation method variants successfully estimators see lah kun 
idea derived observation periodic non sinusoidal signal periodic magnitude spectrum period 
simplest form autocorrelation function positive frequencies length magnitude spectrum calculated 
information equation bases calculations fundamentally different time domain acf cepstrum detector 
frequency components certain spectral interval support corresponding 
means spectrum arbitrarily shifted affecting output value 
different kinds preprocessing done spectrum periodicity analysis 
example compress magnitude spectrum logarithm function remove spectral trend highpass kun 
apply bank bandpass prior periodicity analysis lah 
building calculations intervals frequency partials works better sounds exhibit 
intervals remain constant stable locations partials shift cumulatively seen fig 

interesting difference spectral location spectral interval approaches methods prone errors halving errors doubling 
example consider time domain acf estimator spectral location type method 
time domain signal periodic half rate twice fundamental period harmonic partials sound match locations harmonics times lower sound 
case frequency domain acf estimator spectral interval type method magnitude spectrum periodic double rate shows periodicity half rate 

refers process convolving sequence magnitude spectrum samples impulse response specified filter 
rectify lowpass amplitude amplitude amplitude time ms time ms time ms unitary model pitch perception periodicity time domain amplitude envelope previous sections algorithms introduced measure periodicity time domain signal periodicity fourier spectrum 
third fundamentally different approach measure periodicity time domain amplitude envelope 
successful estimators principle especially developed attempt model human auditory system med hou tol 
idea derived observation signal frequency component exhibits periodic fluctuations beating time domain amplitude envelope 
partials alternatingly amplify cancel 
rate beating depends frequency difference frequency components 
case harmonic sound frequency interval corresponding dominates fundamental beat visible amplitude envelope signal 
illustrates beating phenomenon set harmonic partials sound hz fundamental frequency 
amplitude envelope signal obtained applying half wave rectification lowpass filtering signal time domain 
half wave rectification operation defined 
seen fig 
rectification generates spectral components zero frequency 
represent spectrum amplitude envelope 
amplitude envelope obtained lowpass filtering rectified signal 
fundamental period signal ms clearly visible resulting signal 
approaches single estimation frequency hz frequency hz frequency hz 
reading top signal containing harmonics sound hz signal half wave rectification signal rectification lowpass filtering 
response lowpass filter shown dashed line 
magnitude magnitude magnitude analyzing periodicity amplitude envelope leads type estimator 
principle rectification lowpass filtering allows elegant tradeoff spectral location spectral interval type information 
achieved tuning cutoff frequency lowpass filter fig 

cutoff frequency lowpass filter risen filter passes spectral components original narrowband signal subsequent periodicity analysis acf computation example utilizes spectral location spectral interval information 
spectrum rectification contains partials frequencies correspond spectral locations partials input signal spectral intervals partials 
human hearing tradeoff types information achieved kind representation 
described detail 
unitary model pitch perception meddis colleagues proposed computational model human pitch perception periodicity amplitude envelope analyzed outputs bank bandpass filters med 
roots model early lic 
simulation experiments model shown single model name unitary capable reproducing wide range phenomena human pitch perception reconciling discrepancies competing psychoacoustic theories mentioned sec 

convenience model referred simply unitary model 
unitary model consists processing steps med 
acoustic input signal passed bank bandpass filters represent frequency selectivity inner ear 
bands channels approximately uniformly distributed logarithmic frequency scale 
typically filters partly overlapping applied 

signal channel compressed half wave rectified lowpass filtered 

periodicity estimation channels carried calculating short time autocorrelation functions 

acf estimates linearly summed channels obtain summary autocorrelation function defined st rt rt autocorrelation function time subband maximum value st typically determine time delay lag corresponds pitch period time steps algorithm correspond peripheral parts hearing produce signal auditory nerve 
wide consensus concerning general properties processing steps signal auditory nerve directly measured 
steps controversial represent processing takes place central nervous system directly observable 
particularly acf periodicity estimation subject criticism nervous units implement acf see har experimental evidence contradicts acf kae 
authors admit acf necessarily exact mechanism auditory system uses 
med write model remains neutral exact mechanism temporal infor mation extracted activity auditory nerve fibers activity fibers modelled amplitude envelopes 
processing chain successful reproducing phenomena human hearing model prevails better 
viable substitute acf despite attempts bra 
envelope periodicity practice analyzed subbands results combined 
applies unitary pitch model practical extraction methods 
noted analyzing periodicity time domain signal fourier spectrum subchannels summing sense equivalent performing periodicity analysis directly wideband signal 
attractive properties unitary model unitary model number properties particularly attractive point view estimation 
furthermore properties stem widely accepted processing steps produce signal traveling auditory nerve 
properties discussed 
model provides plausible way weighting spectral location spectral interval type information estimation 
half wave rectification operation retains spectral components input signal center frequency bandpass filter channel additionally generates spectrum amplitude envelope zero frequency addition harmonic distortion generated integer multiples discussed 
spectrum represent spectral location type information spectral components amplitude envelope correspond intervals partials input signal described sec 

subsequent acf computation performs pattern matching spectrum illustrated fig 

magnitude response lowpass filter illustrated fig 
determines balance types information 
unitary model lowpass filter common subbands typically designed pass signal components khz smooth transition band signal components khz increasingly attenuated 
consequence overlaps bandpass filters channels khz 
secondly envelope periodicity models perform implicit spectral smoothing amplitude beating caused frequency partials determined smaller amplitudes 
illustrated fig 

spectrum harmonic sound considered neighboring harmonics contribute beating fundamental rate 
magnitude beating determined smaller amplitudes individual higher amplitude harmonic partials filtered 
phenomenon known human hearing partial harmonic sound raises clearly partials perceptually segregated stands independent sound bre 
feature turned vital importance multiple estimation described sec 

third property envelope periodicity models phase sensitive aggregating beating caused combination frequency partials 
advantageous multiple estimation frequency components arising physical source phase locked 
music applies brass approaches single estimation reed instruments human voice 
usefulness feature computational multiple estimation empirically validated 
role compression step model amounts spectral whitening spectral flattening generates harmonic distortion components odd multiples discussed detail sec 

authors omit compression altogether perform spectral whitening preprocessing step inverse linear prediction filtering tol normalizing powers outputs bandpass filterbank ell 
amplitude min summary signal time ms 
illustration beating caused sinusoidal signals 
sinusoids represent multiples fundamental hz 
lowest curve shows linear sum 
note magnitude beating sinusoid 
beating frequency frequency difference 
auditory model multiple estimator aim chapter investigate principles unitary pitch model introduced sec 
utilized practical multiple estimation 
novel method proposed estimates concurrent musical sounds single time frame 
computational efficiency method algorithm proposed 
accuracy method specific modifications unitary model originally proposed 
sec 
detailed frequency domain analysis unitary pitch model 
serves background material paves way algorithm 
sec 
auditory model multiple estimator 
method analysis unitary model sec 

chapter kept mind aim propose model human auditory system issue discussed sec 

approximations modifications proposed unitary model ultimately justified fact result practically applicable multiple estimation algorithm obtained 
analysis unitary pitch model frequency domain summary autocorrelation function unitary pitch model turned useful mid level representation see sec 
tasks multiple estimation sound separation computational auditory scene analysis dec tol wan ell ros 
computational complexity calculating high due acf calculations subbands number varies different implementations 
limited usability model practical applications 
proposed method calculating approximation frequency domain 
concretely algorithm achieves compute spectral line fourier transform dft st time complex fourier spectrum input sound 
length transform frame order growth notation common usage cor 
individual spectral lines allow computationally efficient multiple estimation described sec 

thing achieved algorithm removes need define number distinct subbands 
algorithm implements model subband centered discrete fourier spectrum sample approaching continuous density subbands 
bandwidths channels need changed 
exactly opposite approach tol computationally efficient version unitary pitch model proposed reducing number subbands 
multiple estimation method successful evaluated 
presentation condensed due page limit 
background material facilitates understanding 
starting point algorithm perform calculation phases see sec 
frequency domain 
inevitably leads frame processing 
serious problem acf calculations involved conventional calculations practice performed frame frame basis allow fft acf computations ell represents exception 
auditory model multiple estimator look processing steps unitary pitch model detail 
particular emphasis laid steps unitary model bank bandpass filters ii compression rectification lowpass filtering subbands 
mentioned previous chapter performing mentioned nonlinear operations specific subbands leads number attractive properties point view estimation 
steps studied depth 
time domain compression discussed included 
auditory filters step unitary model cochlea organ inner ear transforms sound pressure level variations neural impulses auditory nerve 
frequency analysis essential part process 
frequency components complex sound perceived separately coded independently auditory nerve distinct nerve fibers provided frequency separation sufficiently large moo 
auditory frequency analyzer usually modeled bank overlapping linear bandpass filters called auditory filters 
combination information channels takes place central nervous system 
concept critical band closely related auditory filters 
term coined fletcher fle 
fletcher experiment illustrated 
measured threshold detecting sinusoidal signal presence bandpass noise centered signal frequency 
power spectral density noise held constant noise bandwidth varied 
detection threshold increased function noise bandwidth certain point 
fletcher labeled bandwidth critical band suggested frequency analysis inner ear modeled bank bandpass filters called auditory filters 
noise components masking proportion power output filter captures target signal 
auditory filters studied masking phenomenon 
masking refers situation audible sound inaudible presence louder sound 
particular distance spectral components critical bandwidth easily masks 
situation thought components go auditory filter channel auditory nerve 
frequency separation larger components coded separately audible 
making certain assumptions auditory filters possible measure bandwidth shape power response 
noise method originally suggested patterson pat illustrated fig 

wide band noise signal spectral notch mask sinusoidal tone 
notch centered tone threshold detecting sinusoid function width notch measured 
main assumptions 
auditory filter captures sinusoidal signal centered signal frequency reasonably symmetric linear frequency scale secondly masking due part noise leaks auditory channel sides 
detection threshold level known directly proportional masking noise level pat amount noise leaking channel shape auditory filter deduced 
placing noise bands sides ensured signal heard neighbouring auditory filters frequency listening 
power noise bandwidth signal level frequency hz shape auditory filters approximated simple mathematical expressions free parameters 
patterson suggested different formulas pat 
convenient express formulas terms new frequency variable normalization center frequency facilitates comparison filters different center frequencies 
seen measures normalized deviation center frequency 
squared magnitude response rounded exponential filter suggested pat parameter determines bandwidth filter 
response illustrated fig 

models proposed expense parameters magnitude response function 
unitary model exact shape auditory filter response critical sense look complex functions 
model completely sufficient purposes spread wide largely response implemented computationally efficiently gammatone filters sla 
bandwidths auditory filters conveniently expressed equivalent rectangular bandwidth erb concept 
erb filter defined bandwidth perfect rectangular filter unity response integral squared magnitude response specified filter 
integral squared response obtained substituting integrating right half response multiplying result auditory model multiple estimator notch bandwidth noise noise signal frequency hz 
illustration fletcher experiment 
see text details 
idea noise method determine shape auditory filter response pat 
panels power spectral density noise constant signal level varied 
power fc pg epg relative frequency relative frequency 
squared magnitude response rounded exponential filter 
db moore measured erb values auditory filters wide range center frequencies noise method gla 
erb values described linear function center frequency fc center frequency bandwidth hertz units 
shorthand notation uc refer erb value auditory filter refer corresponding center frequency filter 
setting erb values equal variable filters calculated uc result response filter center frequency fully determined 
center frequencies filters auditory filterbank typically assumed uniformly distributed critical band scale 
frequency related scale derived integrating inverse yields log 
expression frequency hertz gives critical band scale 
intuitively means auditory filters densely distributed low frequencies erb values smaller 
exactly power responses filters sum flat response range center frequencies 
varies hz khz hearing range varies 
intuitively means approximately critical bands auditory filters fit range hearing auditory filters non overlapping rectangular shape 
exponential filters algorithm derived certain family filters called exponential flex filters 
shape response filters differs somewhat filters 
point view unitary pitch model exact shape response critical important characteristics auditory filters approximately uniformly distributed critical band scale bandwidths number filters large adjacent filters overlap significantly 
requirements suffice fully define response exponential filters 
filters implement flat unity response center frequency filter 
ii slope attenuation away center frequency defined asymptotic attenuation rounded exponential filters 
attenuation filters follows slope away center frequency factor insignificant large values 
iii erb value filters defined corresponding filter 
pg pg 
fc exponential filter response illustrated fig 
written frequency variable defined variable requirement ii 
stems flex exp uc parameter half width top determined requiring erb bandwidths flex filters equal parameter integral squared flex response obtained integrating piecewise right half multiplying 
equation integrating relative frequency relative frequency 
solid line shows squared magnitude response exponential flex filter 
dashed line shows response rounded exponential filter flex dg dg obtain flex filter written db dg exp dg pg epg terms frequency variable simply substitute flex exp 
please note gives squared magnitude response flex filter 
shorthand notation power response refer corresponding discrete magnitude response flex filter center frequency fc erb bandwidth uc 
bank exponential bandpass filters applied unitary model 
flex fc uc exp fc uc fc uc hc flex hc auditory model multiple estimator compression half wave rectification subbands step unitary model unitary pitch model originally described med output auditory filter processed hair cell model 
human hearing sound enters inner ear travels pressure wave cochlea 
hair cells elements transform resulting mechanical movement neural impulses 
hair cell model med dynamic system described terms differential equations med 
pointed authors hair cells unitary pitch model equally modeled cascade compression half wave rectification lowpass filtering med see med 
approach followed 
previous implementations compression omitted see ell tol 
done task compression carried means preprocessing 
compression half wave rectification discussed separately 
thought cascade full wave th law compression performed followed rectification 
full wave odd th law compression defined transfer characteristic 
specific form compression employed matches sufficiently measured compression hair cells see med analytically tractable numerically safe 
happens frequency domain narrowband signal compressed 
nonlinear operation course frequency response 
consider narrowband input center frequency spectral band narrowband means bandwidth small compared turn implies variations slow compared signal output full wave th xt cos ct xt cos ct yt law compressor expressed dav yt vm cos ct odd coefficient cvm gamma function 
output vth law compressor consists signal frequency input narrowband signal odd multiples 
envelope modulated vth power input envelope mth cvm harmonic phase modulated times input phase modulation 
expression applies reasonably accurately subband signals outputs auditory filterbank 
subband signals sufficiently narrowband satisfy assumptions lowest channels 
subband signals imagined having modulated center frequencies 
denote xc time domain signal output auditory filter centered frequency discrete fourier transform signal denoted discrete fourier transform vth xc dft xc law compressed signal denoted comp dft xc 
auditory filter fourier spectrum compressed signal approximated comp kfs uc 
scalar transform length sampling rate 
approximation gets accurate gets small large values moderate compression levels approximation sufficiently accurate 
scaling factor calculated standard deviation subband signal amplitude virtual carrier sinusoidal signal standard deviation approximation straightforwardly verified experimentally 
auditory filter scaling factor tends normalize standard deviation subband signal unity sense compression omitted sound spectrum appropriately preprocessed whitened auditory filterbank 
done tol 
ellis turn took approach normalizing outputs auditory filters energies ell 
distortion spectrum odd multiples accurately modeled done 
moderate compression levels magnitude small compared auditory filter furthermore subsequent lowpass filter eliminates distortion spectrum 
seen having important role unitary pitch model 
scaling subbands seen purely simply inspired way performing spectral whitening 
fact model derived time domain th law compression important 
form spectral whitening convenient provides single parameter determine degree applied whitening 
interestingly gets small values spectrum due scaling subbands approach white spectrum pink spectrum 
standard deviations measured critical bands approximately logarithmically spaced bandwidths linearly proportional center frequency 
reasons spectral whitening considered advantageous inverse linear prediction filtering 
non linear half wave rectification operation defined core part unitary model 
dav shown input zero mean gaussian random process xt approximate expression power spectral density output yt xt half wave written auditory model multiple estimator dc component 
power spectrum half wave rectified narrowband signal centered frequency bandwidth dav 
power spectral density input unit impulse function 
approximation involved expression higher order convolution terms omitted due small powers 
shown dav leads error output variance 
illustrates magnitude spectrum output half wave case input process narrow band rectangular spectrum 
noted assume narrowband signal interest 
narrowband signal centered output spectrum consists dc component original power spectrum scaled convolution original power spectrum produces spectral components centered zero frequency twice input center frequency 
principle generates spectral components bands centered integer multiples upper limit bands small power dav 
unitary pitch model phases play important role approximation derived power spectral densities sufficient 
terms complex valued discrete fourier spectra approximation xn kk short time fourier transform time domain signal xn rectification xn kk short time fourier transform rectified time domain signal 
denote approximation spectrum approximation standard deviation time domain signal rectification xn context signals interest composed limited number sinusoidal 
deriving approximations straightforward trivial standard analyses dav 
interested reader referred chapter cited book 
components satisfy gaussianity assumption 
despite approximation turned quite accurate easily verified experimentally 
certain complications arise time domain signal xn windowed prior rectification 
time domain windowing violates stationarity assumption model 
problem easily circumvented performing windowing convolution frequency domain computing convolved fourier spectrum window function 
time domain achieved simply applying windowing usual computing term square root window function obtain place convolution term 
technical details relatively unimportant point view analysis 
xc time domain signal output auditory filter centered frequency complex spectrum xc rectification approximated denoted convolution term xc convenience 
unbiased estimate standard deviation xc obtained gives power signal xc channel spectral whitening included writing scaling factors different channels calculated substituting 
weighting term square stems definition 
compression half wave rectification subband signals lowpass filtered mentioned subsection 
traditionally fixed lowpass filter hlp different channels addition dc component subband signals removed 
exactly filter typically implements bandpass response db cutoff frequencies hz khz 
consequence dc term omitted spectrum output channel expressed 
convolution terms may appear contradictory 
remembered merely approximations 
approximation precise 
auditory model multiple estimator hlp hlp 
periodicity estimation channel summing steps unitary model autocorrelation function acf equal inverse fourier transform power spectrum 
fourier transform rc autocorrelation function rc subband obtained rc hlp 
practice spectra non overlapping lowest channels approximated xc hlp 
approximation valid channels hz interested reproducing nuances artefacts unitary pitch model channels 
point view harmonic sounds lowest channels usually contain significant frequency component case magnitude small see 
lp summary autocorrelation function calculated summing channel acf estimates 
fourier transform inverse linear operations sum rc frequency domain obtain fourier transform sk rc perform single inverse fourier transform obtain summary autocorrelation function 
approximation terms squared summed separately 
follows approximated hlp 
bandpass filters typically designed power responses sum unity mentioned 
case function formula written slowly varying hlp xc compression modeling scaling factor corresponding frequency bin approximation obtained computing standard deviation subband signal band centered frequency bin substituting value hlp algorithm computes time channels center fre lp ok fs standard deviations needed compute practice really available 
spectra xc need calculated 
discussion follow convenient denote express parts hlp 
note whitened power spectrum input wideband signal 
inverse fourier transform obtain approximation summary autocorrelation function idft 
idft linear operation decomposed terms idft hlp idft hlp 
described fig 
page idft performs implicit pattern matching power spectrum 
pattern matching performed harmonic locations whitened power spectrum input wide band signal similarly conventional acf see fig 

pattern matching performed channel sum power spectra amplitude envelopes subband signals 
envelope spectra contain frequency components correspond frequency intervals original spectrum 
described sec 
explicitly visible definition 
types information spectral location information spectral interval information kept approximately separate accumulated separately bands 
summary autocorrelation function value represents weight period candidate strength pitch sensation pitch period candidate 
lag corresponding maximum typically considered pitch period 
discussion referred amplitude envelope spectrum subband addition contains distortion spectrum centered frequency idft operation collects frequency components bands 
shows example power spectrum artificial 
principle computed weighted average vicinity practice difference negligible 
auditory model multiple estimator power nel signal power spectrum shown left panel 
reasons believe distortion spectrum centered play significant role unitary model deserve detailed analysis 
lowpass filter hlp attenuates distortion spectrum channels hz 
described sec 
higher channels important envelope related term bandwidth wider typically contain dense sets frequency partials 
secondly channels hz contain harmonic partials harmonic index see small low pitched sounds 
partials significant inharmonicity observed spectrum centered consists frequency components ideal harmonic position fig 

case idft pattern matcher picks generated spectral peaks zero frequency role distortion spectrum merely quantitative emphasize information represented band zero frequency 
situation complicated significant inharmonicity observed lower channels case peaks occur harmonic locations idft match 
algorithm proposed publication concerned term consists sum envelope spectra different channels seen 
spectrum turn calculated convolving subband spectrum xc 
easy see calculating computationally demanding large number subbands 
algorithm proposed computes fixed channels center frequencies fs time linearly proportional length wideband fourier spectrum input 
means frequency bin computed time spectrum mentioned chapter consequences lead computationally efficient unitary model estimator 
basic idea algorithm described compute estimate constant time arithmetic operations 
need initialize iteratively calculate frequency hz power frequency hz 
left power spectrum xc artificial subband signal hz fundamental frequency 
center frequency auditory filter fc hz simplicity rectangular response auditory filter 
right power spectrum defined corresponding power spectrum left 
magnitude magnitude type type ii channels update rules proposed 
results obtain spectral line update rules family exponential flex filters similar rules derived filter magnitude response piecewise representable exponential functions exp case flex filter 
starting point deriving update rules xc decomposed xc hc hc response flex filter centered fc written hc 
frequency hz frequency hz 
thick curves panels illustrate basic types convolved response 
responses hc hc shown dotted dashed lines respectively 
equation convolution spectrum zk common filtered varying convolved response hc 
illustrated convolved response basic types depending tops flex responses overlap 
types consist parts fig 
form exponential function exp update rules proposed observation 
imagine computed value certain channel sum parts convolved response separately known 
take part example 
sum part neighbouring channel obtained shifting part upwards spectrum integrating part 
integral directly obtained multiplying sum channel constant smaller causes old values gradually leak sum adding new spectral components come integral 
way sum updated iteratively spectrum 
detailed formulas computing estimates 
important doing iterative calculations performed numerical errors auditory model multiple estimator cumulate calculations 
computations briefly introduced lead linear distribution subband center frequencies center frequency channel cfs desired channel distribution uniform critical band scale defined 
problem easily circumvented 
arbitrary distribution center frequencies simulated weighting outputs linearly distributed channels accordingly 
possible channel density sufficiently high case 
uniform distribution channels critical band scale simulated weighting outputs linearly distributed channels uc bandwidth uc computed 
spectrum channel consists frequency bands centered zero frequency centered computed separately algorithm described 
calculations band centered zero frequency described band centered ignored 
clearly stated mentioned errata page 
band centered computed exactly way simply changing zk interested spectrum amplitude envelope centered zero frequency detail 
convenience denote hlp ideal lowpass filter cutoff frequency zero valued phase response 
contains amplitude envelope spectrum centered zero frequency distortion spectrum centered vc hlp auditory model multiple estimator section analysis applied order obtain practically applicable multiple estimation tool music signals 
method whitened wide band spectrum amplitude envelope spectra 
main difference compared unitary model acf calculations idft power spectrum replaced suitable technique 
context practical estimation accuracy counts 
human auditory system multiple estimation 
unitary pitch model turn successfully simulates qualitative properties human pitch perception suggesting model works way similar physiological counterpart 
natural pursue accurate multiple estimation recruiting unitary model 
attempted monophonic signals kla polyphonic mixtures unpublished 
authors reported direction mar dec tol wu 
turned unitary model accurate multiple estimator 
analyze unitary model fails practical multiple estimation tasks 
modifications proposed remove shortcomings 
overview modifications sec 

backgrounding signal model concept introduced subsection 
sections discuss proposed modifications detail 
computational efficiency considered sec 

extending single estimator multiple case described magnitude magnitude sec 

critical band scale harmonic sounds resolved vs unresolved partials rest chapter consider specifically harmonic sounds 
local model assumed time domain signal harmonic sound xt pt critical band scale 
partials harmonic sound critical band scale see 
upper panel shows harmonics hz 
lower panel hz 
dotted vertical lines indicate boundaries adjacent critical bands erb bandwidths auditory filters positions 
amplitude frequency phase th ap harmonic partial respectively number partials 
parameters assumed time invariant analysis frame 
note assume perfect harmonicity frequencies obey specific expression 
basic notion harmonic sound involves certain assumptions 
described verbally sec 
stated exactly needed sec 

concept resolved vs unresolved harmonic components important 
resolved harmonics refer partials resolved separate auditory channels output auditory filters dominated harmonic partial 
unresolved harmonics turn go channel neighbouring partials frequencies individual partials resolved hou moo 
shows partials harmonic sound critical band scale scale 
seen lowest harmonics resolved separate auditory channels higher harmonics 
situation change significantly varied 
critical band range corresponds frequencies hz khz 
pitch perception spectral locations partials important resolved harmonics spectral intervals important higher unresolved harmonics 
stands reason spectral interval information appears beating amplitude envelopes occur channels comprise resolved partial 
secondly precise frequencies amplitudes resolved partials available central auditory system case unresolved partials go auditory model multiple estimator channel neighbouring harmonics 
simple psychoacoustic experiments support view spectral location information important low order resolved partials 
example pitch harmonic sound change significantly numbered harmonics removed 
odd numbered harmonics removed pitch doubles remaining harmonics correspond times higher sound 
suggests spectral locations affect perception pitch 
case higher order harmonics involved spectral intervals dominate impossible say numbered odd numbered series harmonics higher pitch 
kla carried small psychoacoustic experiment determine limit human auditory system spectral locations harmonic partials 
total subjects pair harmonic sounds composed set successive harmonics set successive numbered harmonics 
subjects asked sounds higher pitch 
cases series partials lower harmonics subjects perceived clear octave difference 
higher octave difference disappeared subjects selected odd series higher probability 
spectral location dependency disappeared 
cases sound hz order presentation randomized 
unitary model terms correspond spectral location information respectively 
discussion important interpretation term represents mainly resolved harmonics term represents mainly unresolved harmonics 
interpretation maintained analysis previous section terms xc interpreted oriented resolved unresolved partials respectively 
obvious argument fact amplitude envelope beating rate significant components occur partials go auditory channel case unresolved harmonics 
interpreted represent mainly resolved partials mainly unresolved partials 
overview proposed modifications modifications proposed directed steps unitary model 
acf calculations replaced technique called harmonic selection complex subband weighting applied combining results bands 
described sec 
steps unitary model matter dispute psychoacoustics point view practical estimation attractive properties unitary model stem steps 
harmonic selection defined principle set selected spectral components computing salience candidate spectrum 
word salience refer calculated weight likelihood candidate 
word likelihood carries probabilistic connotation word salience 
multiple estimation desirable minimize interference occurring sounds robust partials hypothesized candidate compute salience ignore spectrum partials 
cases usage spectrum problematic salience calculations get confused occurring sounds inter weight relations different sounds cause unpredictable combination effects 
general principle harmonic selection originally proposed parsons par comprehensive review previous harmonic selection harmonic cancellation methods dec 
time domain harmonic selection implemented bank comb filters measuring energies outputs filters 
comb filter characterized certain feedback delay feedback gain output comb filter feedback delay written xn 
illustrates power response comb filter corresponding hz comparison weights acf calculation shown delay analogous fig 
page 
estimating energy output performed squaring summing time domain equivalent summing power spectrum filtered signal 
implement harmonic selection comb filter response directly frequency domain 
resolved harmonics frequency bin represent harmonic partial fundamental frequency candidate fs selected spectrum power response frequency hz frequency hz 
left panel shows weights cos acf calculation lag corresponds hz lag ms 
right panel shows power response comb filter feedback delay corresponding hz feedback gain 
argmax kp pk max pk 
defines range vicinity ideal harmonic frequency pk maximum assumed indicate partial scalar represents spacing successive period estimates constant sampling lag values analogous acf 
set defined fixed partial index spectral components belong range candidate ranges adjacent period candidates overlap frequency bin 
selected frequency bins compute salience function replaces 
function represents contribution resolved harmonics auditory model multiple estimator salience period candidate function computed kp parameter function determines weights different harmonics sum side effect determines upper limit partials considered resolved included sum weight approaches zero large 
sum extended arbitrarily large values lower order harmonics expected reside approximately harmonic positions spectrum 
seen subsection degree partial parameter function depending frequency partial fundamental frequency applying weights represents fundamental departure unitary model 
noted summing occurs auditory channels 
resolved harmonics definition located distinct channels 
hearing resolved harmonics separately coded auditory nerve task central auditory system recombine information partials harmonic sound perceived coherent 
conceivable complex weighting take place resolved harmonics pitch calculations 
comparison write salience function replaced 
unity weight assigned partials harmonic positions spectrum provided partials locations powers summed unity weights cutoff frequency lowpass filter suitable cos lp hlp lot evidence pitch perception harmonic sounds resembles spectral pattern matching process especially lower order partials resolved separate auditory channels gol wig ter har 
process take form lowpass filtering followed acf calculation happens complex manner central nervous system 
salience function assumption frequencies amplitudes individual resolved partials available central auditory system processes parameters way wishes 
particular necessity stick acf 
important note lowpass filter hlp weight function model different things 
filter hlp models response hair cells transform mechanical vibration neural impulses inner ear 
weights turn model pattern matching process assumed take place 
consider low pitched sound hz 
polyphonic music frequency range hz khz heavily occupied sounds 
blindly picking components harmonic positions weighting equally robust 
implicit spectral smoothing mechanism described sec 
partly prevent stealing partials sounds mechanism involved amplitude envelope related part high pitched sound khz turn lowest important harmonic partials resolved separate auditory channels 
generate beating frequencies rejected lowpass filter 
practice hz detected poorly 
central nervous system 
principle filter hlp included hair cell response bypassed acts lowpass filter hlp omitted 
important modification magnitude spectrum power spectrum 
modification due simplicity accuracy 
second power stems acf computations particular reason maintain 
contrary discussed usually advantageous generalized acf exponent 
karjalainen suggest value tol 
matter fine tuning important unity value simplicity 
part represents mainly unresolved harmonics discussed previous subsection 
replaced salience function harmonic selection applied manner analogous described 
salience function defined max lp real valued constant obtained substituting 
note magnitude spectra different channels power spectra 
modification due reasons part 
defined contains amplitude envelope spectrum centered zero frequency distortion spectrum centered secondly frequency bin selected vicinity fundamental frequency computed efficiently algorithm leads efficient implementation described sec 

individual frequency bins channel suffice represent salience contribution unresolved harmonics fundamental frequency candidate fs 
complete argument sec 
intuitive description 
note single frequency bin retains desirable properties unitary pitch model described sec 

represents spectral interval oriented information regarding fundamental frequency fs 
magnitude reveals amount amplitude envelope beating rate subband beating turn due frequency components interval channel fundamental frequency neighbouring harmonics contribute beating rate magnitude high 
secondly due manner amplitude beating formed see fig 
page retains property implicit spectral smoothing 
thirdly phase dependent computed complex fourier spectrum 
harmonics sound phase locked linear phase phase difference pair neighbouring harmonics approximately constant magnitude beating fundamental rate larger 
salience period candidate defined analogously 
maximum indicate fundamental period 
corresponding fundamental frequency fs represents detected mixture signal 
exten auditory model multiple estimator sion multiple estimation described sec 

degree subsection concerned coefficient 
coefficient interpreted degree harmonic fundamental period candidate salience function calculated selecting frequency components nearby harmonic spectral locations weighting magnitudes summing 
weighting different partials motivated fact spectral locations partials important case resolved partials discussed sec 

boundary resolved unresolved partials sharp speak degree 
measured 
partials harmonic sound depends harmonic index partial 
seen estimating number partials go auditory channel harmonic number frequency interval partials determined quite accurately fundamental frequency erb bandwidth auditory channel harmonic estimated substituting pf 
ratio estimate number partials pf going auditory channel harmonic pf pf 
seen pf grows linearly function harmonic index 
note simple ratio gets values unity inter partial interval larger erb value 
propose model degree proportional inverse pf pf scalar unknown parameter experimentally 
apart saying represents degree function exact psychoacoustic interpretation 
merely practical 
note ratio excluding gets values unity lowest harmonics meaning auditory channels partials contain partials 
neighbouring channels affect simplicity measure limiting maximum value ratio unity value 
function controls contribution partial salience function illustrates values harmonics fundamental frequency values 
seen contribution partial salience function decreases function harmonic index arbitrarily interesting note contribution partial salience function increases function occurs weighting function explicitly included 
described single frequency bin selected represent salience contribution unresolved harmonics fundamental frequency candidate channel decomposition weight harmonic index 
values harmonic values 
curves bottom correspond values hz hz hz khz respectively 
applied value scalar 
calculated summing convolution spec convolved response channel fixed fundamental frequency ck corresponding term remains different channels 
term varies channel index seen ck hc small compared bandwidth hc hc hc overlap lot convolution power transmission convolved response high 
bandwidth increases linearly function ck center frequency see power transmission increases frequency 
ck consequence contribution harmonic series sound salience function increases function harmonic index hand fixed subband power response decreases increasing increasing funda ck mental frequency 
description express average spectral density convolved response jc channel centered fundamental frequency kf jc hc kf fs frequency bin corresponding note denominator represents erb value bandwidth flex response channel normalization bandwidth important order compensates effect merely due fact erb values increase frequency 
average spectral density convolved response power transmission acts weight individual harmonic partials reside particular channel 
value pf represents implicit weight affects salience contribution partial function illustrates harmonics fundamental frequency values 
curves obtained substituting pf 
seen salience contribution increases harmonic index saturates unity 
consequence function represents mainly unresolved partials 
upper limit harmonic index needs set 
practice significant harmonic components observed khz sense consider subbands center frequencies 
reasonable functions pf sum approximately auditory model multiple estimator weight unity harmonic series sound harmonics contribute little salience function contribute salience function implementing smooth transition resolved unresolved partials 
thin solid line fig 
illustrates degree function harmonic index dashed line shows pf function sum drawn thicker line 
seen functions sum approximately unity harmonic series sound 
lowest harmonics high pitched sounds sum clearly exceeds unity value 
modeled limited values unity 
additional boost lowest harmonics high pitched sounds turned feature high pitched sounds typically harmonic components altogether boost compensates 
table shows pseudocode algorithm computes salience function algorithm nice properties 
computationally complex safe consider harmonics period candidate due fact weight quite small 
partial index fixed number elements sets different altogether number period candidates transform length 
complexity algorithm order fixed number partials considered 
secondly selected frequency components affect salience candidate spectrum 
provides robustness ok harmonic index 
function pf harmonic values 
function reflects contribution harmonics salience function curves top correspond values hz hz hz khz respectively 
normalized power harmonic index weight harmonic index weight harmonic index weight harmonic index 
thin solid line shows function harmonic index dashed line shows pf sum functions indicated thick solid line 
values hz hz hz khz left right respectively 
table algorithm computing salience function compute saliences fundamental period candidates max stepsize fs pk harmonic selection find maximum amplitude specified range cumulate partial amplitudes term represents degree see term due compression modeling see pk pk argmax polyphony 
thirdly lower order partials selected ideal spectral locations appropriate sounds exhibit inharmonicity 
algorithm require unrealistic frequency resolution spectral band extremely narrow relation center frequency lowest harmonics considered 
matter psychoacoustic plausibility leads algorithm works accurately relatively short analysis frames 
assumptions underlying definition aim subsection describe assumptions underlie definition 
particular purpose explain individual frequency bins channel represent contribution unresolved partials salience fundamental frequency fs 
assumptions question exactly assumed input signals harmonic sounds 
class sounds defined merely verbally examples sec 

show making certain assumptions input signals amplitudes unresolved harmonics fundamental frequency subband estimated single frequency bin consider model time domain signal xt harmonic sound 
power spectral density signal written unit impulse function set defined include positive auditory model multiple estimator tive indexes negative indexes express negative frequencies signal xt passed critical band auditory filter squared magnitude response defined output filter denoted hc signal model written xc hc xc 
hc half wave rectification applied subband signal xc power spectral density resulting rectified signal yc approximated yc hc fi hc hc variance subband signal xc denote convolution term expression fi hc 
hc examples power spectra illustrated fig 
page 
xc necessary assumption concerning input harmonic sounds frequency interval adjacent harmonics remains approximately constant critical band 
assumption reasonable kind inharmonicity consider dispersive strings 
sounds exhibit inharmonicity spectral intervals slowly varying function frequency see 
assumed piecewise constant sufficiently narrow bands 
assumption single spectral line subband calculated constant subband 
hc secondly know higher order unresolved harmonics human auditory system distinguish amplitudes individual harmonic components 
rough spectral shape components perceived approximately level measure critical band distinct sound source 
harmonic raises clearly partials usually perceptually segregated stands independent sound 
feature hearing modeled unitary pitch model discussed sec 

computational analysis sounds useful spectral smoothness assumption similar human hearing 
specifically assume partial amplitudes critical band centered frequency fc approximated single level 
due differences approximations exact power spectrum defined 
approximation 
reason notation vc pa hc measure ac uc erb bandwidth 
assume spectral smoothness 
argument requires elaboration 
suffices consider musical instruments specifically 
generally known high quality synthesis harmonic sounds achieved employing time varying level measure critical band 
musical instrument construction point view turn harmonic raises partials perceptually segregated perceived belong complex 
unwanted effect typically avoided instrument design 
spectrum musical sounds depends physical sound production mechanism 
instruments seen consist acoustically coupled parts vibrating source string air column sympathetic resonator guitar body piano 
theoretically possible vibrating source vibration modes frequencies playing sinusoid certain frequency nearby string ros 
commonly excitation signal vibrating system resembles transient signal impulse train resulting spectrum individual harmonic stands 
string spectrum vibration corresponds fourier transform shape displaced string just released fle 
vibration spectrum filtered frequency response coupled body resonator 
musically undesirable resonator sharp resonance modes formants usually resonator strongly damped acoustic energy efficiently smooth spectrum making spectral smoothness assumption written hc hc solved 
hc hc noted frequencies individual unresolved partials known 
bands contain unresolved components partial density sufficiently high sample squared frequency response exact spectral positions hc harmonics insignificant 
words harmonics inter partial distance distributed response sampling interval gets smaller hc exact sampling positions matter approaches limit 
regard spectral smoothness speech singing signals important borderline case 
lowest formants vowel sounds higher formants dun ste 
comparison values auditory filters channels khz vary 
value bandpass filter defined ratio center frequency db bandwidth filter 
higher qvalue filter sharper shape magnitude response 
auditory model multiple estimator 
hc hc frequencies individual partials need known 
single frequency bin suffices represent level partials fundamental frequency subband course result depends validity assumptions approximation half wave rectified signal 
klapuri described assumptions estimate parameters unresolved harmonic components sound separation system unpublished time 
resynthesis perceptual quality achieved higherorder unresolved partials described model assumptions 
provided input sound sinusoidal partials constant intervals channel easy see convolution term contains partials multiples mf integer necessary extend harmonic selection components picked summed 
fact amplitudes ac predict approximate magnitudes spectral lines substituting written hc hc mf mf mf hc hc hc mf hc mf hc hc see difference select sum harmonically related partials sum mf hc mf hc mf 
hc hc sum right hand side equation merely amounts complicated weighting individual spectrum line weighting turned com pletely unnecessary 
purpose analysis motivate frequency bin channel represent contribution unresolved partials salience fundamental frequency candidate channels 
discussed sec 
single frequency bin retains desirable properties unitary pitch model 
convenience rewrite definition magnitude frequency hz 
magnitude response filter hlp applied 
due narrowband nature characteristics filter khz important 
max 
lp note equation values directly estimate magnitudes individual partials ac 
magnitudes partials omit implicit weighting individual harmonics pf described previous subsection figs 

appropriate definition represent mainly unresolved harmonics 
turn interpreted represent mainly unresolved harmonics 
filter hlp omitted 
described sec 
rectified signal contains significant dc component order remove filter hlp typically implements bandpass response db cutoffs hz khz 
highpass characteristics filter important 
term contains amplitude envelope spectrum centered zero frequency distortion spectrum centered illustrates frequency response applied butterworth filter order transition band db cutoff hz 
scaling factor free parameter determined subsection 
model parameters salience different fundamental period candidates 
nice property model contains free parameters 
important parameter remains determined relative weight parts note parts include unknown scaling factor 
numerical ranges parts matched order terms appropriate effect suffices balance levels relation absolute numerical range important 
simplicity fix consider free parameter 
important parameter value th law compression 
thirdly widths subbands uc important tunable parameter model 
applied scalar bandwidths uc uc 
words factor scales defined critical bandwidths effect bandwidths having modify parts 
parameters experimentally simulations 
musical instrument samples randomized acoustic database accuracy estimation auditory model multiple estimator method material evaluated different parameter values 
database comprised total individual recorded samples different musical instruments database 
random mixtures sounds generated instrument random note playing range restricting pitch octaves hz hz 
desired number simultaneous sounds allotted mixed equal mean square levels 
acoustic input fed estimation method estimated ms time frame ms onset sounds 
sampling rate khz 
polyphonic mixtures predominant estimation accuracy criterion parameter selection 
predominant estimation estimate defined correct matches correct component sounds 
words estimated 
correct defined deviate pitch musical note 
multiple estimation estimation component sounds considered sec 

note experiments computed set comprised lag values hz hz 
requires computing obtain 
complexity computing proportional frame length complexity algorithm high ok cardinality set 
computational efficiency main concern 
solution overcomes leads efficient algorithm described subsection 
dimensional search conducted find values parameters values considered 
values considered 
weighting factor varied continuous manner combination result experiments combination performed best values fixed 
value combination dsp applications square root efficient compute see 
additionally advantageous zero padding time domain prior fourier transform obtain 
resolution bound resolution fourier spectrum seen 
frequency resolution needed analyze low pitched sounds required accuracy 
zeros padded ms analysis frame twice length prior fourier transform 
note resolution tied fourier spectrum resolution 
shows estimation error rate proposed method function weight factor parameters fixed 
panel left shows estimation error rate isolated sounds monophonic signals panel right shows predominant estimation performance sound mixtures 
point view estimation general interesting graph left monophonic case shows importance spectral location spectral interval information estimation 
appropriate balance achieves accuracy 
error rate value parameter error rate 
predominant estimation performance function parameter isolated sounds left note mixtures right 
vertical line shows selected parameter value 
hand types information moderately successful 
value leads error rates monophonic sounds leads error rates monophonic sounds 
polyphonic mixtures spectral location oriented term appears relatively important 
part illusory due definition predominant estimation task 
higher happens high pitched sound 
part successful detecting achieves low error rate 
component sounds estimated term important 
task considered sec 

summarize parameter important 
fortunately performance varies slowly function finding exactly correct value critical 
unfortunate aspect best value depends somewhat frame size zero padding factor 
illustrated cases ms frame zero padding performs 
ms frame zero padding performs 
effect important fixed different values different analysis frame sizes 
table shows predominant estimation rates proposed method different polyphonies different analysis frame sizes 
random sound mixtures allotted polyphony average predominant estimation error rate calculated 
proposed method successful predominant estimation taken diversity acoustic material considered 
reducing computational complexity mentioned previous subsection computational complexity proposed auditory model multiple estimator value parameter table predominant estimation error rates proposed method 
analysis number concurrent sounds polyphony frame size ms ms ms method ok logk high 
complexity computing term due fourier transform part due algorithm table number period candidates consider 
complexity computing period candidates ok mentioned previous subsection 
common order growth notation complexity cor 
ok subsection solution described reduces complexity ok logk important multiple estimation longer analysis frames typically required single estimation 
due relatively higher partial density sound mixtures 
computational efficiency achieved proposing candidate generation scheme able produce constant small number period candidates set sub candidate corresponding maximum preserved subset sub follows needs evaluated sub order find single best candidate 
estimation general small number candidates usually easily generated difficult part choose correct estimate 
algorithm table turned suitable purpose candidate generation 
words evaluate part 
demanding computationally 
constant number local maxima selected constitute set sub candidate period values refined evaluating vicinity sub done calculating set defined 
value replaced value corresponds maximum set refined period values stored set sub part evaluated sub comprises period candidates 
importance refining step omit maximization evaluate positions sub evaluated different values selecting number local maxima constitute set sub sub preserve maximum set 
observed polyphonies method evaluated simultaneous sounds 
candidate generation step theoretically interesting consequence 
method able find sounds resolved harmonics missing 
practice happens harmonics fifteen missing 
known case humans hear faint usually ambiguous pitch percept hou 
limitation method theoretical relevance importance whatsoever practical multiple estimation tasks 
usual cases missing harmonic component handled problems 
note set values considered computing table way restricted 
sampling need uniform known frequency scale 
simplicity assumed sampling lag values acf sampling rate constant table 
shows resolutions basic sampling schemes function musical note vicinity resolution hz musical note 
resolution different sampling scales 
circles indicate inter note intervals hz musical notes tempered musical scale 
crosses illustrate difference hz note comparison note sample longer period 
acf resolution depends sampling rate khz 
dots show resolution fourier spectrum constant shown transform length resolution measured 
musical notes correspond fundamental frequencies hz khz respectively 
seen fourier spectrum acf resolution equal resolution logarithmic musical scale closest human hearing 
resolution acf general natural fourier spectrum 
accuracy improvement achieved non uniform sampling computing difference simple acf type sampling negligible 
non uniform scale set consider table large couple hundreds different values 
uniform acf type sampling 
multiple estimation iterative estimation cancellation music transcription typically sufficient find correct polyphonic mixtures 
goal find component sounds prominent sounds 
simple way extending described estimation method multiple estimation pick local maxima function single global maximum 
straightforward approach moderately successful 
analysis frame size ms technique leads error rate sound polyphonies meaning average fundamental frequencies correctly estimated 
basic problems multiple estimation predominant estimator detects correct highest weight assigned half twice correct value 
effect detected cancelled harmonics deciding 
describe iterative multiple estimation method consists main steps 
described estimation method find mixture sig auditory model multiple estimator nal 
followed cancellation detected sound estimation iteratively repeated residual 
depending number extract estimation step repeated times cancellation step times 
estimation part described cancellation procedure remains 
denote period sound detected iteration effect cancelled mixture signal performing cancellation separately parts 
algorithm implements cancellation part table 
algorithm performs harmonic selection way table considers period value amplitudes harmonics parameters sinusoidal partials estimated estimate magnitude spectrum vicinity partials 
magnitude spectra partials detected sounds cumulated xd represents resolved harmonics detected sounds 
residual magnitude spectrum xr obtained subtracting xd initial magnitude spectrum constraining resulting negative values zero 
mechanism cancellation affects estimation part iterations residual spectrum xr mixture spectrum calculating table pseudocode algorithm computes residual spectrum xr effect resolved harmonics detected sounds cancelled mixture spectrum estimated period detected sound denoted iteration initialize spectrum detected sounds resolved partials xd residual spectrum zero phase xr max xd pk harmonic selection table quadratic interpolation ser vicinity estimate frequency amplitude time invariant sinusoidal partial assumed underlie local maximum estimate fourier spectrum vicinity assumed sinusoidal component weight see take absolute values add result pk pk argmax xr xr xr xd table 
iteration xr 
certain characteristic algorithm table important deserves special mentioning 
adding partials detected sound xd weighted modeled way estimation part table 
consequence higher order partials entirely removed mixture spectrum residual xr calculated 
principle important order corrupt sounds remain residual spectrum detected coming iterations 
example consider low pitched sound hz 
frequency components positions harmonics sound removed mixture spectrum residual severely corrupted 
parameters harmonics reliably estimated th partial 
described weighting limits effect cancellation important harmonics sound 
principle weights tables completely independent need matched pair way 
interpretation weights cases logical values 
table interpretation subtract resolved harmonics frequencies individual unresolved partials known 
part cancellation somewhat complicated 
backgrounding analysis sec 
results applied 
computed convolutions spectra different channels cancelling effect detected period achieved cancelling effect different channels cancellation procedure assumption detected sound consists partials constant inter harmonic frequency intervals channel 
case sound causes peaks positions integer easily seen looking definition mk assuming peak position due detected sound effect detected sound multiples mk predicted approximated value values different channels computed obtain 
expression predicting mk 
order avoid evaluating integrals prediction formula formulated terms magnitude spectra 
hc mk cmk mk 
hc ck derivation formula similar 
addition assumptions piecewise constant inter partial intervals spectral smoothness linear phases assumed 
linear phases assumed sound sources practice resulting error sufficiently small 
approximations appear contradictory 
difference due fact 
defined difference includes amplitude envelope spectrum zero frequency distortion spectrum auditory model multiple estimator derived starting point 
difference stems asymmetry mentioned footnote page 
approximations usable 
effect detected sound period convolution spectra different channels estimated 
values different channels known discussed effect assumed limited vicinity positions mk integer effect detected sound taken account period decided 
efficiently implemented follows 
having detected period iteration data structures produced compute vector detected period channels lp denotes rounding nearest integer 
note analogous recalculating part detected period maximization omitted candidate generation procedure described previous subsection 
summing bandwise terms stored vector represents level unresolved harmonics detected sound different channels algorithm modifications compute 
parallel compute vector detected period channels ck hc 
comparison decomposition seen equivalent computing unity value substituted place practice values efficiently obtained side product computing initialize translate spectrum window function frequencies take absolute values scale spectra maxima correspond unity add spectra 
data structures computed step cancel effect detected sound coming iterations 
iteration calculated simply 
iterations formula replaces 
formula part equals 
second part subtracts amount predicted due detected sounds 
example consider second iteration formula integer multiple period detected iteration value unity 
case quantity represents amount predicted due detected sound 
value unity part subtracts amount cumulated part zero 
ck li mk li max lp ck ck ck ck table multiple estimation error rates proposed iterative method 
performance estimator proposed shown 
method proposed method method proposed publication analysis frame size number concurrent sounds polyphony ms ms ms ms ms ms cancellation procedures computationally demanding 
noted part calculated small subset candidate values sub practical implementations data structures li computed fly reduce memory usage 
multiple estimation results simulations run validate proposed auditory model multiple estimation method 
acoustic database 
consists samples different sources mcgill university master samples collection university iowa website studio online irc independent recordings acoustic guitar 
altogether different musical instruments comprising brass reed instruments strings piano guitar 
total number samples randomly mixed generate test cases 
instruments excluded data set represent harmonic sounds see sec 
proposed method admittedly reliably instruments 
sampling rate khz 
sound mixtures generated instrument random note playing range restricting pitch octaves hz hz 
desired number simultaneous sounds allotted mixed equal mean square levels 
acoustic signal fed proposed multiple method estimated single time frame ms onset sounds 
number concurrent sounds number extract acoustic mixture signal 
parameters system fixed parameter varied size analysis frame described sec 

correct estimate defined deviate half semitone true value making round correct note western musical scale 
errors smaller significant point view music transcription 
error rate computed number erroneous estimates divided number 
mixture signals generated polyphony error rates averaged 
table shows multiple estimation results proposed method 
set values applied computing table uniform constant see auditory model multiple estimator table 
computing candidate generation procedure sub applied cases see sec 

values bring additional performance improvement 
computing fourier spectrum analysis window zero padded length samples ms 
general impression proposed auditory model method accurate able handle diversity acoustical material involved 
example error rate voice polyphonies ms analysis window meaning sounds correctly estimated average 
increasing polyphony error rate grows gradually method break point 
particularly attractive feature proposed method works accurately relatively short analysis frames 
comparison rows table show results algorithm proposed fair say algorithm breaks analysis frame shorter ms 
ms frame size method proposed significantly better 
superiority auditory model approach short analysis frames due fact method attempt resolve individual higher order partials represented collectively amplitude envelope spectrum 
attractive feature method proposed comprises free parameters 
parameters tuned determines balance parts degree compression scaling factor subband widths completely free sense deduced known psychoacoustic quantities 
illustrates error cumulation iterative estimation cancellation process 
bars represent error rates function number concurrent sounds 
different shades gray bar indicate error cumulation iteration errors occurred iteration bottom errors iteration top 
seen error rate approximately doubles analysis frame shortened ms ms 
difference ms ms frames big 
shows error rate proposed method function target sounds system 
number concurrent sounds polyphony error rate ms frame polyphony error rate ms frame polyphony ms frame polyphony 
multiple estimation error rates proposed algorithm 
bars represent error rates different shades gray error cumulation iteration 

accuracy method compared trained musicians 
error rate error rate fundamental frequency hz 
multiple estimation error rate proposed method function target sounds 
number concurrent sounds experiment 
experiment 
error rate value hz example computed counting number sounds hz detected method dividing number sounds hz system 
seen low pitched high pitched sounds incorrectly estimated 
musical sounds ends typically difficult handle due irregularity 
method remains incomplete sense mechanisms suppressing additive noise estimating number concurrent sounds 
considered chapter 
method proposed chapter comprises directions potential improvement explored 
example expectation values different balanced way 
possible method preference high low verified 
details method necessarily optimal ones examples working solutions 
matter research optimize details 
auditory model multiple estimator previous approaches multiple estimation chapter different approaches single estimation reviewed 
aim multiple estimation find component sounds mixture signal 
instance algorithm proposed chapter 
complexity multiple estimation problem significantly higher single estimation 
intuition developed comparing spectrum harmonic sound mixture harmonic sounds fig 

multiple estimation closely related sound separation 
algorithm able estimate sound presence sounds effect organizing respective spectral components sound sources bre 
regardless organization takes place prior estimation vice versa closely related 
multiple estimation raises number problems need addressed single estimation 
name examples concurrent sounds certain relationships may cause non existing sound detected root chord absence 
partials concurrent sounds coincide frequency case parameters partials directly estimated spectrum 
practical music transcription tasks number concurrent sounds estimated 
diversity approaches taken multiple estimation wider single estimation 
aim chapter review previous area 
historical background related music signals viewed home ground multiple estimation way speech signals principal target signals single estimation 
multiple algorithms designed purpose transcribing polyphonic music 
attempts date back built system transcribing voice compositions moo 
continued chafe cha 
time problem independently studied pis 
advances maher mah de cheveign dec 
early systems suffered severe limitations regard pitch range relationships simultaneous sounds polyphony restricted concurrent sounds 
attempts higher polyphony limiting carefully modeled instrument haw ros allowing errors occur output kat 
music transcription systems recruited motivated analysis power db frequency hz frequency hz 
example spectrum harmonic sound left mixture harmonic sounds right 
power db previous approaches multiple estimation principles kas ste god models human auditory periphery mar dec god tol bayesian inference techniques kas got dav processing architectures artificial intelligence domain mar god got sparse coding methods vir abd 
areas examined detail sec 

mentioned multiple estimation sound source separation closely linked 
human auditory system effective separating recognizing individual sound sources mixture signals 
cognitive function called called auditory scene analysis asa 
computational modeling asa subject increasing interest bregman put influential describing principles mechanisms psychology asa humans bre 
doctoral theses various aspects computational asa casa prepared mel cooke coo brown bro ellis ell 
overviews field ros coo 
point view multiple estimation research casa produced practical methods models peripheral parts hearing unitary pitch model described chapter med 
partly due fact casa general concerned types sound sources practice related noise speech sounds 
separation speech interfering speech sounds important special area sound separation 
early problem done parsons par weintraub wei 
concentrated utilizing pitch information carry task 
wang colleagues focused pitch information speech segregation wan hu 
multipitch tracking algorithm noisy speech wu 
consonants main carriers information speech signals speech voiced part time 
multiple estimation appropriate separating singing interfering singing parsons reports normal speech separated process form intelligible gives illusion preserving recovered talker consonants 
despite valid observation techniques prevail noise robust speech recognition 
missing data approach separation oriented approach noise robust speech recognition limited voiced parts bar coo 
line research attempts identify regions represent target speech closely connected casa general 
okuno nakatani applied microphones utilize directional information harmonicity separating simultaneous speakers nak 
approaches multiple estimation difficult categorize multiple estimation methods single taxonomy 
methods complex typically combine processing principles 
consequence single dimension function appropriate basis categorization 
main viewpoints problem discerned aim subsection introduce 
table lists characteristic attributes different multiple estimation methods 
list methods intended complete 
attempt select representative examples main viewpoints problem 
comprehensive historical overview estimation methods music see hai 
table mid level representations refer data representations acoustic previous approaches multiple estimation main viewpoint kashino sterian de cheveign martin goto davy abdallah unpublished perceptual grouping partials auditory modeling auditory modeling signal model signal model sparse coding sparse coding mid level representations table characteristics multiple estimation methods knowledge applied computation evaluation material sinusoidal tracks partial grouping harmonicity onset timing musical chord note relations statistics chord transitions sound sources tone memory timbre model space automatic tone modeling sinusoidal tracks partial grouping harmonicity onset offset timing low partial support partial gap partial density unitary pitch model subchannel signals simplified unitary pitch model log lag correlogram auditory model synchrony strands features estimated spectral power distribution analysis frame bayesian probability network conceptually blackboard model evaluation grouping likelihoods multiple hypothesis tracking harmonicity implicit knowledge human pitch perception iterative estimation cancellation harmonicity implicit knowledge human pitch perception efficient version unitary pitch model iteration enhancing partial grouping harmonicity musical rules governing tonal music implicit knowledge human pitch perception heuristics grouping cues strands harmonicity onset offset timing time frequency proximity common movement musical detect utilize recurrent melodic phrases metrical predictions stream formation pitch timbre proximity signal model multiple notes note partials gaussian spectrum centered harmonic positions tone models estimated prior distributions parameter values musical frequency ranges melody bass temporal continuity bass melody time domain signal signal model multiple notes notes may partials represented time localized sinusoids non white residual noise prior distributions parameter values magnitude spectrogram sources constant spectrum time varying gain magnitude spectrogram sources constant spectrum time varying gain simple source mixing model cost function minimizes reconstruction error preserving sparseness sources temporal continuity gains simple source mixing model reconstruction error minimization favouring sparseness sources statistical evaluation random mixtures acoustic samples instruments max polyphony short example cases polyphony sample synthesis fixed instrumentation statistical evaluation synthetic perfectly periodic sounds pitch range octave max polyphony example cases musical chords mixed speech signals noisy clean statistical evaluation shown blackboard architecture example transcription cases piano performances voice bach chorales th century counterpoint style blackboard architecture short example cases acoustic data sample midi synthesizer max polyphony maximum posteriori map estimation expectation maximization em algorithm bayesian model variable dimension markov chain monte carlo mcmc sampling posterior likelihoods algorithm combines projected gradient descent multiplicative step modified quasi newton optimizer gradient ascent inference sources maximumlikelihood learning gains detection melody bass lines predominant real world cd recordings example cases results shown polyphonies demo signals real world cds drum transcription midi synthesis keyboard music max polyphony input final analysis result 
front kind transform input data accessible form complex reasoning takes place 
column titled knowledge applied lists types knowledge utilized performing analysis 
music signals diverse sources knowledge available relating physical sound production music theory human auditory perception example 
column computation summarizes actual computations carried data representations knowledge 
evaluation column gives idea target material system 
methods described detail 
provided improve readability remembered cited papers really put single label 
perceptual grouping frequency partials casa usually viewed stage process incoming signal decomposed elementary time frequency components organized respective sound sources 
provided successful conventional estimation method measure separated component sounds practice estimation takes place part organization process 
organization part complicated mentioned processing stages 
important step forward area discover set perceptual cues promote grouping time frequency components sound source human listeners 
cues measurable acoustic features elementary time frequency components 
bre bregman points cues proximity time frequency harmonic frequency relationships synchronous changes parameters components spatial proximity direction arrival 
shows spectrogram mixture harmonic sounds cello sound sound 
mentioned cues visible 
partials frequency hz time 
time frequency representation mixture harmonic sounds cello sound hz setting ms sound hz setting 
cello sound start ms sound exhibit synchronous frequency modulation 
partials sound harmonic relationships due inharmonicity phenomenon described sec 
perfect harmonicity assumed 
features effectively auditory system order hear sounds 
example coinciding partials seen frequency band hz 
temporally continuous sinusoidal components sinusoidal tracks elementary components mentioned features measured kas ste vir 
reliable extraction components real world music signals easy may 
pioneering area done mca serra ser continued authors dep rod goo ver lev vir 
motivated representations mid level representation god 
kashino brought bregman ideas music scene analysis proposed new ideas music transcription kas 
front system plane method extract sinusoidal tracks input signal 
clustered note hypotheses applying subset mentioned perceptual cues 
harmonicity rules onset timing rules implemented 
types knowledge integrated system 
timbre models identify source note pre stored tone memories resolve coinciding frequency components 
chordal analysis performed probabilities notes occur chord 
chord transition probabilities encoded trigram models markov chains 
computations bayesian probability network integrate knowledge simultaneous bottom analysis temporal tying top processing chords predict notes notes predict components 
evaluation material comprised different instruments polyphonies simultaneous sounds 
stands elegant complete transcription systems 
kashino addressed problem source identification source stream formation information priori kas 
phd sterian tightly focused implementing perceptual grouping principles purpose music transcription ste 
sinusoidal partials mid level representation 
extracted picking peaks successive time frames modal distribution applying kalman filtering estimate temporally continuous sinusoidal tracks 
sterian represented perceptual grouping rules set likelihood functions evaluated likelihood observed partials hypothesized grouping 
distinct likelihood functions defined take account onset offset timing harmonicity low partial support partial gap partial density see ste definitions concepts 
product likelihood functions criterion optimal grouping 
exhaustive search possible groupings possible multiple hypothesis tracking strategy find suboptimal solution 
new partial new competing hypotheses formed promising hypotheses tracked time 
evaluation results small test set concurrent sounds 
brown auditory model front extract synchrony strands grouping cues extracted god 
system introduced detail sec 

nakatani okuno spatial proximity cue previous approaches multiple estimation cues separate voiced sections simultaneous speakers nak 
deterministic way encoding partial grouping principles proposed klapuri vir 
auditory model approach unitary pitch model meddis 
see chapter strong influence estimation research general med 
bregman theory primarily concerned psychology auditory perception unitary model addresses peripheral largely physiological parts hearing 
multipitch estimation sound mixtures addressed research direction inspired 
method proposed chapter belongs category 
de cheveign kawahara extended unitary model multiple case 
proposed system pitch estimation followed cancellation detected sound estimation repeated residual signal dec 
iterative approach multiple estimation originally proposed de cheveign dec comprehensive review previous harmonic selection harmonic cancellation models 
dec cancellation performed channel selection concurrent vowel identification model meddis med performing cancellation filtering 
addition computationally exhaustive joint estimator proposed concurrent sounds simultaneously estimated 
evaluation results artificial perfectly periodic data set proposed iterative approach successful 
karjalainen developed computationally efficient version unitary pitch model applied multiple estimation musical sounds tol 
pitch computations frequency bands bands original model main characteristics model preserved 
practical robustness addressed flattening spectrum incoming sound inverse warped linear prediction filtering generalized acf method see sec 
periodicity estimation 
extension multiple estimation achieved cancelling summary autocorrelation function produced model 
resulting enhanced summary autocorrelation function picked iterative estimation cancellation 
method relatively accurate described sufficient detail exactly implementable tol 
statistical evaluation method 
karjalainen proposed iterative approaches multiple estimation sound separation described simplified auditory model kar 
emphasis knowledge integration blackboard architectures mentioned content analysis audio signals faceted process involves acoustic data internal models bre ell 
meaningful integration various processing principles turned difficult 
list requirements flexible extendable system architecture comprises analysis algorithms data types different kinds integrated system 
encapsulated architecture individual algorithms collaborate compete explicit knowledge 
architecture relatively easy add remove processing modules 
blackboard trumpet sound sinusoid signal spectrum representation hierarchy read write knowledge sources activate scheduler 
overview blackboard architecture reprinted kla 
system able handle uncertain data alternative explanations evolve side side 
blackboard systems originally developed field artificial intelligence meet mentioned architectural needs nii rus 
illustrates main components blackboard architecture 
name blackboard refers metaphor group experts working physical blackboard solve problem 
blackboard hierarchy data representations different abstraction levels 
representations audio content analysis proposed kla ell 
state analysis completely encoded hypotheses blackboard 
data common number autonomous knowledge sources processing algorithms manipulate data requested 
control component decides knowledge source activated 
design part largely determines blackboard system integrating functional entities knowledge sources car 
mar martin proposed system transcribing piano performances voice bach chorales 
system auditory model log lag correlogram ellis ell front blackboard model employed knowledge physical sound production rules governing tonal music garbage collection heuristics 
support raised frame frame basis combined longer term power envelope information create note hypotheses 
musical rules favoured certain intervallic relations 
knowledge sources consisted precondition action pairs cf 
structure 
time step control component evaluated preconditions knowledge sources priority order executed precondition satisfied 
model brown particularly designed facilitate integration auditory organization principles described sec 
competition god 
system quite complex equally introduced section 
applied auditory front produced synchrony strands represented dominant time frequency components different bands coo 
grouped sound events extracting features strand applying bregman organization principles 
sound events grouped respective sources event streams computing pitch timbre proximities successive sounds 
musical meter information predict events occur melodic pattern induction predict events recurrent patterns 
model evaluated showing previous approaches multiple estimation control segregate melodic lines polyphonic music resolve interleaved melodies 
transcription accuracy main goal 
important note blackboard architecture merely conceptual model primarily concerned implementation actual algorithms 
provide computational model knowledge integration 
models especially dynamic bayesian networks mur powerful modeling tools 
statistical methods solid common ground integrating diverse types knowledge acoustic data internal models models served example speech recognition 
kashino blackboard architecture backgrounding conceptual model applied bayesian networks carry quantitative integration task 
proposed blackboard architecture related inference techniques kla 
signal model probabilistic inference possible state multiple estimation problem terms signal model parameters estimated 
consider model dav yt cos nt sin nt number simultaneous sounds mn number partials sound fundamental frequency sound encode amplitude phase individual partials 
term residual noise component 
principle parameters right hand side equation estimated observation yt possible prior knowledge parameter distributions 
pointed davy dav problem bayesian sense lot prior knowledge concerning music signals 
davy godsill elaborated signal model accommodate time varying amplitudes non ideal harmonicity non white residual noise dav 
likelihood function observing yt model parameters defined 
prior distributions parameters carefully selected 
input signal segmented excerpts note transitions occur 
parameters signal model estimated time domain separately segment 
main challenge approach actual computations 
sufficiently realistic signal model parameter space huge posterior distribution highly multimodal strongly peaked 
davy godsill variable dimension markov chain monte carlo sampling posterior reporting innovative spent finding heuristics fast exploration parameter space dav 
inefficient system reported robustly polyphonies simultaneous sounds 
goto proposed method models short time spectrum music signal weighted mixture tone models got 
tone model consists fixed number harmonic components modeled gaussian distributions centered integer multiples spectrum 
goto derived computationally feasible expectation maximization em algorithm iteratively updates tone models weights leading maximum posteriori estimate 
temporal continuity considered tracking weights multiple agent architecture 
goto algorithm successfully track mel bass lines cd recordings real time 
algorithm utilized prior knowledge typical frequency ranges melody bass lines favoured temporal continuity trajectories 
system goto relatively complex core em algorithm easily implement got 
algorithm estimates weights typically predominant simulations exactly claimed goto 
goto signal model resembles rodet monophonic estimation dov 
data adaptive techniques data adaptive systems parametric model knowledge sources 
source signals estimated data 
typically assumed sources refer notes harmonic spectra 
real world signals performance independent component analysis poor 
placing certain restrictions sources data adaptive techniques applicable realistic cases 
restrictions independence sources sparseness means sources assumed inactive time 
added temporal continuity constraint sparse coding paradigm vir 
signal model power spectrogram input time frequency static power spectrum source time varying gains sources 
term represents error spectrogram 
iterative optimization algorithm estimates non negative minimization cost function takes account reconstruction error sparseness temporal continuity 
algorithm separate pitched drum instruments real world music signals vir vir 
abdallah plumbley applied sparse coding analysis music signals abd 
input data represented magnitude spectrograms sources magnitude spectra leading source mixing model essentially 
authors proposed algorithm sources obtained gradient ascent inference time varying gains maximum likelihood learning 
results promising shown example case synthesized bach piece simultaneous sounds 
case system learned spectra note spectra 
authors strong structure music certain kinds music sparse coder learn detect notes way music polyphonic 
need bring prior musical knowledge problem fact musical notes approximately harmonic spectra abd approaches important line research pursued okuno nakatani demonstrated effective direction arrival information segregating simultaneous speakers nak 
system nak designed segregate continuous previous approaches multiple estimation streams harmonic sounds voiced sections simultaneous speakers 
multiple agents deployed trace harmonic sounds stereo signals 
detected sounds cancelled input signal residual update parameters sound create new agents new sounds detected 
periodicity transform method example mathematical approach multiple estimation set 
algorithm finds set basis elements data fixed basis fourier transform example 
authors proposed residue driven sound separation algorithm periodic component time estimated cancelled mixture signal process repeated residual 
approach bears close resemblance iterative method de cheveign dec 
neural networks different subproblems music transcription mar 
mar author proposes system combination auditory model adaptive oscillators neural networks 
unitary pitch model process input signal med 
adaptive oscillators similar lar track partials output channel 
order track harmonically related partials oscillators interconnected oscillator nets candidate musical note 
neural network trained individual note order recognize corresponding note occurs time 
results obtained evaluation set real synthesized piano performances 
basic problem encountered slow synchronization adaptive oscillators caused problems especially low notes 
potentially successful approach applications focus modeling specific musical instrument 
done haw ros kla piano music considered 
problem oriented approach multiple estimation chapter serves publications 
proposes complete multiple estimation system sense includes mechanisms suppressing additive noise estimating number concurrent sounds input signal 
problems addressed chapter solved order perform automatic transcription real world music signals 
publications turn different principles proposed deal coinciding frequency partials 
harmonic components coincide frequency partials sounds overlap spectrum 
problem particular importance music described sec 

solution proposed introduced sec 
solution proposed introduced sec 

system described 
methods chapter represent pragmatic approach multiple estimation 
problem decomposed smaller subproblems solutions sought 
various sources error analyzed techniques dealing sought 
practice turned effective ways improving transcription system 
principles chapter applied chapter 
noted system described developed earlier 
method chapter respects elegant advantage constitutes explicit implementation basic mechanisms needed successful multiple estimation 
implementation quite instructive understanding acoustic musical constraints problem auditory point view 
system quite flexible regard testing different system parameters configurations 
basic problems estimation music signals fundamental frequency estimation music signals ways challenging speech signals 
music pitch range wide sounds produced different musical instruments vary lot spectral content 
inharmonicity phenomenon taken account 
robustness presence interference drums percussive instruments addressed 
typically harmonic sounds playing concurrently harmonic components different sounds coincide frequency 
hand dynamic time varying properties speech signals complex average music signal 
values music temporally stable speech 
difficult track simultaneous speakers perform music transcription voice vocal music 
basic problems multiple estimation classified categories grouping problem 
mixture harmonic sounds possibly contaminated noise spectral components organized sound sources 
issue discussed length sec 

due inharmonicity phenomenon see sec 
components harmonic sound simply assumed reside ideal harmonic positions spectrum 
problem oriented approach multiple estimation computing saliences weights see sec 
different candidates partials sound 
term harmonic summation model refer function calculates salience hypothesized candidate parameters amplitudes frequencies phases harmonic partials 
complicated wide pitch range variation musical instrument timbres 
noise robustness 
case drums percussive instruments signal ratio zero db time time 
coinciding frequency partials 
western polyphonic music rule exception partials harmonic sound overlap partials concurrent sounds 
suffice merely group partials sound sources individual partials need shared sources 
proposed solutions problems introduced sections 
section looks noise robustness problem 
sections address partial grouping problem sections address salience computation 
section describes methods resolve coinciding partials 
estimating number concurrent sounds discussed method purpose 
technical details described original publications 
exception predominant estimation described detail publications originally done kla included thesis 
noise suppression definition noise subjective depends application 
viewpoint performing multiple estimation music signals partials harmonic sounds considered additive noise suppressed 
practice non harmonic parts mainly due drums percussive instruments 
noise suppression extensively studied domain speech processing 
speech enhancement typically assumption background noise characteristics slowly varying compared target speech signal 
enables stage approach noise spectrum estimated longer period time secondly spectrum noisy speech signal weighted suppress noise component mixture signal var sta 
standard methods optimal wiener filtering spectral subtraction widely 
advances mar gus wol 
music sounds drums percussive instruments transient short duration making difficult estimate noise spectrum longer period time due non stationarity noise suppression algorithm proposed estimates removes noise independently analysis frame 
preprocessing method proposed goals 
suppresses additive noise flattens spectral shape target harmonic sounds 
signal model assumed method power spectral density observed acoustic signal 
difficult impossible theory 
drum sounds typically occur repeatedly music 
power frequency hz frequency hz 
example signal contains harmonic sounds drum sound snr db 
left panel shows scaled power spectrum signal right panel shows warped magnitude spectrum log output power spectrum vibrating system fundamental frequency measured example guitar string 
factor represents frequency response body musical instrument convolutive noise filters signal vibrating source 
elimination referred spectral whitening 
term represents power spectrum additive noise 
additive model assumes signal noise uncorrelated 
elimination achieved publication applying magnitude warping equalizes allows additive noise linearly subtracted result 
power spectrum magnitude warped ln scaling factor adaptively calculated analysis frame scale level additive noise floor numerically close unity 
amplitudes important frequency partials vibrating system turn assumed noticeably additive noise floor 
illustrates scaled power spectrum harmonic sounds drum sound magnitude warping 
seen left panel noise floor unity value scaling spectral peaks significantly 
follows function applied additive noise goes linear magnitude warping transform spectral peaks go logarithmic transform 
warped spectrum shown right panel 
illustrates magnitude warping transform input scaled different ways 
seen magnitude warping close linear function small ln problem oriented approach multiple estimation warped magnitude output input input 
illustration magnitude warping transform ln gets values zero left zero right 
warped magnitude input values 
nice consequence additive noise remains additive warping additive noise suppressed applying specific spectral subtraction moving average calculated logarithmic frequency scale linearly subtracted exactly local averages calculated octave bands constraining minimum bandwidth hz lowest bands 
bandwidths subsequent calculations motivated frequency resolution human auditory system practical experiments generated mixtures musical sounds noise 
response strongly compressed logarithmic transform subsequent processing takes place warped magnitude scale 
additionally estimated additive noise component captures significant amount convolutive noise additive logarithmic transform 
estimated spectral average linearly subtracted resulting negative values constrained zero 
resulting preprocessed spectrum subsequent multiple estimator 
preprocessed spectrum denoted discrete domain 
sake notation 
shows magnitude warped spectrum spectral subtraction 
right hand panel fig 
example kind noise suppressed input spectrum functions input subsequent multiple computations 
predominant estimation shows overview multiple estimation method proposed 
core part method predominant estimation module computes saliences different candidates presence harmonic sounds noise 
term predominant estimation defined sec 
refers task finding harmonic sounds mixture signal 
initially rule possibility algorithm reveal component simultaneously 
turned algorithm assigns second highest salience candidate corresponds half frequency hz frequency hz 
magnitude warped spectrum subtracting estimated noise spectrum 
example signal fig 


magnitude warping closely related law compression ln ln input assumed get values zero value decide linear logarithmic compression 
warped magnitude acoustic mixture signal noise suppression predominant estimation estimate number concurrent sounds iterate spectral smoothing detected sound store remove detected sound mixture 
block diagram multiple estimator described reprinted 
twice firstly detected correct observed auditory model method described sec 

best solution symptom cancel detected sound mixture spectrum repeat estimation step residual 
leads iterative estimation cancellation structure shown fig 

predominant algorithm explaining derived 
aim subsection describe line thought involved decisions led particular algorithm 
processing proposed method takes place preprocessed spectrum see sec 
time frame input signal 
longer term temporal processing considered phase information ignored 
bandwise estimation proposed predominant estimator calculates saliences different candidates independently different frequency bands combines results determine global saliences 
primary motivation attempting bandwise estimation achieve robustness presence interfering sounds 
estimation performed separate frequency bands interference noise band leak estimates bands 
provides flexibility bandwise results combined enables detection due noise observable limited frequency range 
issue addressed bandwise processing partial grouping problem 
single time frame long term temporal features available partial grouped frequencies 
higher harmonics may deviate expected spectral positions case intervals constant 
assume spectral intervals piecewise constant sufficiently narrow bands 
utilize spectral intervals partials group distinct frequency bands combine results bands manner takes inharmonicity account 
third reason resort bandwise processing important principle human auditory perception med bre hou moo 
illustrates magnitude responses frequency bands bandwise estimation takes place 
sake algorithmic flexibility calculations performed frequency domain 
advantage bandwise operation achieved problem oriented approach multiple estimation single fast fourier transform local regions spectrum separately processed 
harmonic selection defining characteristic proposed algorithm salience hypothesized candidate calculated frequency components considered belong corresponding sound 
principle harmonic selection discussed sec 
originally proposed parsons par 
mechanism select partials differs considerably sec 
basic idea 
selected partials spectrum computations provides robustness sound mixtures 
bandwise saliences different candidates computed follows 
vector saliences band corresponds fundamental frequency frame size sampling rate 
preprocessed spectrum described sec 
additionally filtered response bandpass filter band responses shown fig 

frequency components bins band denoted lowest bin band number bins band 
bandwise saliences calculated finding series th lb fn sn fs zb kb kb kb kb kb lb frequency components band maximizes frequency hz 
magnitude responses frequency bands bandwise estimation takes place 
band comprises octave region spectrum constraining minimum bandwidth hz reprinted 
lb max zb kb zb kb zb kb kb number equidistant partials band function harmonic summation model see sec 
remains specified 
set contains different offsets series partials 
offset varied find maximum stored lb different offsets tested series higher harmonic partials may shifted due inharmonicity 
problem finding partials belong candidate solved defining group equidistant partials maximizes function constitutes sought group partials 
salience candidate band defined value function partials 
illustrates calculations single harmonic sound band frequency hz 
harmonic selection reprinted 
hz hz 
arrows indicate series frequency components maximizes true corresponding case 
values offset restricted physically realistic subset exact limit critical constant inharmonicity factor determine maximum allowable offset ideal harmonic positions 
extreme case harmonic partial band inharmonicity allowed partial selected ideal harmonic position spectrum 
consequence spectral interval oriented harmonic selection reduces special case spectral location information harmonic selection 
determining harmonic summation model remaining problem determine function computes salience candidate magnitudes selected harmonic components 
fn sn denote fundamental frequency corresponding denote set equidistant frequency bins band maximizes candidate function stage process 
starting point function estimates perceived loudness set partials band second step function parametrized machine learning find parameters time function gives highest salience correct 
set candidate band contains partial loudness partials estimated xb power spectral density input signal band frequency partial note expression background model continuous power spectrum replaced noise suppressed discrete spectrum 
exponent performs power spectrum compression model loudness perception moo sum approximates integral excitation pattern caused partials critical band scale 
coefficient fn df xb sk xb 
inharmonicity allowed lowest partials described previous subsection sec 

consequently frequency bands contain partials certain candidate problem oriented approach multiple estimation fn df inter partial interval partial critical band scale 
mapping linear frequency scale critical band scale 
illustrates spectral area summed critical band time 
note model loudness simplified limit effect lowest partials critical band partials 
turns equal fk fk erb value auditory filter centered constant scalar omitted 
note equivalent concept defined page 
order simplify replace fk bandwidths sk estimator see fig 

coefficient replaced written simplified form subsequent step formula parametrized machine learning techniques find optimal values parameters 
parametrized formula variable place kb 
closely related seen 
replaced discrete preprocessed spectrum xb preprocessing step involves compression allows omit exponent 
parametrization zb parameters learned lb posed machine learning problem requires definition task performance measure experience learn mit 
task assigned algorithm estimate isolated musical sounds 
performance measure percentage cases maximum lb different bands corresponded true sound question 
learning algorithm access cor critical band scale 
partials harmonic sound hz scale 
dotted vertical lines indicate boundaries adjacent critical bands 
expression measures area stepwise curve separately band 
xb kb 
noted formula considered estimating loudness partials due described departures original model 
loudness model starting point precise modeling loudness interest 
center frequency bands hz rect sounds attempted improve measure success changing values coefficients results values learned 
second order polynomial trained perform significantly better order model taken 
function computes salience lb candidate frequency band fundamental frequency hz lb max cmn zb kb cmn defined 
fundamental frequency hz cross band integration estimation inharmonicity factor shows calculated salience vectors lb different bands isolated piano tones 
vectors arranged increasing band center frequency order 
expected maximum salience usually assigned true provided harmonic partial band 
inharmonicity phenomenon appears panels fundamental frequencies show rising trend function band center frequency 
bandwise saliences combined yield global estimate 
straightforward summation salience vectors accumulate appropriately estimates different bands may match sounds seen fig 

overcome inharmonicity factor estimated taken account 
different inharmonicity models implemented mentioned fle 
simulations performance difference negligible 
model adopted 
global saliences obtained summing squared bandwise saliences lb problem oriented approach multiple estimation center frequency bands hz 
bandwise calculated saliences lb piano tones 
vectors displaced vertically clarity 
true sounds hz hz left right panels respectively indicated dashed vertical lines reprinted 
selected different bands curve determined 
search possible values inharmonicity factor conducted highest ln corresponding stored output 
squaring bandwise saliences prior summing provide robustness noisy cases pitch may detectable limited frequency range 
weighting different bands estimated signal noise ratios attempted 
described method yields inharmonicity factors see detected sounds side product 
illustrates measured inharmonicity factors different notes upright piano 
measured data agrees fletcher piano fle pp 
coinciding frequency partials described predominant estimator operates reliably cases concurrent harmonic sounds 
method able estimate component simultaneously iterative estimation cancellation procedure shown fig 
applied 
partials detected predominant completely removed mixture spectrum 
kind partial grouping appropriate coinciding partials spectral components due coinciding partials need shared corresponding sounds 
partials detected sound completely removed coinciding partials sounds deleted subtraction procedure 
iterations sound remaining residual spectrum may corrupted correctly analyzed iterations follow 
addition described issue coinciding partials sounds bring noise salience calculations 
problem severe causes errors predominant estimation 
aim section introduce different techniques deal coinciding partials 
method proposed able resolve coinciding partials certain degree inharmonicity factor fundamental frequency hz 
measured inharmonicity factors piano strings 
value fletcher fle middle register piano indicated dashed horizontal line 

practice coinciding partials need exactly frequencies 
partials considered coincide frequency difference smaller width spectrum time domain analysis window 
introduced sec 

mechanism applied final system publication 
method introduced sec 
originally proposed oriented avoiding coinciding partials sound observed 
diagnosis problem sinusoidal partials amplitudes phase difference coincide frequency amplitude resulting sinusoid calculated 
amplitudes roughly equivalent partials may amplify cancel depending phases 
amplitudes significantly larger usually case close maximum 
condition harmonic partial sound coincides harmonic sound written hfs fs fr fundamental frequencies sounds 
ideal harmonicity assumed valid important classes sound sources lower order harmonics instruments considered 
common factors integers reduced obtain integer numbers 
implies partials sounds coincide fundamental frequencies sounds rational number relationships 
furthermore fundamental frequencies sounds relationship pth harmonic sound coincides th fr pq pk harmonic qk sound evident hfs equals pair pk qk holds 
sound overlaps partials sound common frequency bands 
important principle governing western music paying attention pitch relations intervals simultaneously played notes 
simple harmonic relations eq 
favoured ones 
smaller values closer harmonic relation sounds perfectly play 
instance fundamental frequencies relationships constitute basic major chord fundamental cies relationships constitute basic minor chord 
har monic relations common music worst cases handled general 
partly explains multiple estimation particularly difficult music 
western music arranges notes quantized logarithmic scale fundamental frequency note hz standard piano keyboard example 
scale logarithmic surprisingly produce different harmonic relationships derived substituting small integers kla 
table shows basic musical intervals 
seen realizable relationships deviate little harmonic ideals amount error small disturbing average human listener 
feasible frequency analysis resolution coinciding partials appears perfect fn 
scale called twelve tone equal tempered scale 
problem oriented approach multiple estimation resolving coinciding partials spectral smoothness principle amplitudes phases coinciding frequency partials deduced sum 
making certain assumptions concerning involved musical sounds possible resolve component partials certain degree 
method purpose proposed introduced 
consider preprocessed spectrum concurrent harmonic sounds fig 

sounds relationships consequence partials sound coincide third harmonic lower pitched sound 
predicted coinciding partials randomly cancel amplify low frequencies higher frequencies summary amplitudes approach maximum spectral envelope higher sound 
cases fig 
lower sound usually detected captures power higher pitched sound 
general sounds able steal energy sounds detected 
removing partials sounds completely effectively corrupt sounds 
table basic musical intervals 
interval name size semitones ideal relationship deviation ideal relationship octave perfect fifth perfect fourth major third minor third major second minor second magnitude frequency hz 
preprocessed spectrum containing sounds relation reprinted 

described principles generalize western music 
extensive analysis music utilizes relationships cause partials concurrent sounds coincide sounds blend better set 
draws interesting connection applied musical instruments musical scales different cultures 
magnitude frequency hz 
dots spectrum illustrate spectral envelope lower pitched sound estimated 
example signal fig 

algorithm revealing underlying magnitudes coinciding partials imitating mechanisms human auditory system 
described sec 
unitary pitch model performs implicit spectral smoothing especially unresolved harmonic partials 
adjacent harmonic partials cause amplitude beating alternatingly amplify cancel fundamental frequency rate 
magnitude beating determined smaller amplitudes 
amplitude envelope harmonic sound considered consequence single higher amplitude harmonic partials filtered 
described smoothing mechanism isolated separate algorithm amounts nonlinear filtering spectral envelope detected sound magnitudes harmonic partials sound 
different smoothing algorithms described evaluated 
simplest replaces amplitude ah harmonic partial minimum amplitudes harmonic neighbour ah min ah ah 
interestingly simple operation efficient estimating spectra harmonic sounds polyphonic musical signals 
considering fig 
job estimating spectral envelope lower pitched sound 
illustrates amplitudes lower pitched sound estimated example 
sophisticated accurate algorithms exist described 
physical terms described approach understood relying assumption spectral envelopes musical sounds smooth relatively slowly varying function frequency 
assumption discussed page 
estimated magnitudes subtracting detected sound mixture spectrum 
compared case partials completely removed safer 
estimated magnitudes recalculate refined salience candidate question subdue noise caused coinciding partials sounds 
spectral smoothness principle purposes 
identifying harmonics coincide approach deal coinciding partials proposed 
method identifying harmonic partials corrupted problem oriented approach multiple estimation coinciding partials sounds 
partials weight making observations concerning hypothesized harmonic sound mixture signal 
starting point method assumption harmonic sound fundamental frequency occurs music quite probable harmonic sounds ri fundamental frequencies integers occur simultaneously 
due principles western music discussed sec 

reasonable assume values binding fundamental frequencies equally probable small values general probable large values 
consequence partials interfering sound ri equally probable overlap subset pth partial set pth fs ri pq fri partial denoted pk 
denote probability interfering sound ri overlaps subset sound probability assumed sets mentioned 
likelihood individual harmonic partial coincide partials sounds equal different harmonics likelihood proportional probability sets partial belongs overlapped 
calculated number subsets harmonic belongs 
easy prove number integers divide integer defined divide integer integer perfect harmonicity assumed 
dh dh dh da method utilizes analysis order reliable observations harmonic sound polyphonic musical signals 
fundamental observation course hypothesized sound exists mixture signal 
reduced question individual harmonics sound appear spectrum 
types outlier partials harmonics valid represent hypothesized sound 
harmonics may due coinciding partials sounds harmonics may missing target sound 
weighted order statistical filter kuo ast proposed able filter outlier values 
sample selection probabilities filter set relative trustworthiness different harmonics 
th sample selection probability probability sample set selected output filter kuo 
complete description method 
method extensively transcription system piano music described kla 
method applied multiple estimation method 
spectral smoothing algorithm utilizes statistical dependencies subsets achieves slight improvement 
criticism multiple estimation method described chapter certain major weakness 
iterative cancellation detected sounds performed separating spectra sounds frequency domain 
estimation separation individual higherorder harmonic partials done reliably 
smoothing mechanism partly saves day prevents completely removing higher order partials destroying corresponding frequency range mixture spectrum 
frequency domain separation depends critically resolution spectrum 
consequence described method requires relatively long analysis frame perform 
method proposed chapter advantageous respect uses different mechanism estimate cancel higher order unresolved partials 
result method chapter achieves better accuracy particularly shorter time frames seen table page 
method advantages compared chapter 
mentioned chapter 
problem oriented approach multiple estimation multiple estimation main part thesis deals multiple estimation considered core music transcription problem 
different methods proposed purpose 
derived unitary pitch model chapter originally published oriented pragmatic problem solving 
obtained results indicate multiple estimation performed reasonably accurately level single time frame 
variety musical sounds priori knowledge sound sources necessary improve performance 
method described represents complete multiple estimation system sense includes mechanisms suppressing additive noise estimating number concurrent sounds input signal 
provides explicit implementation basic mechanisms needed multiple estimation 
method described chapter accurate particular operates reliably short analysis frames 
comparative evaluation methods table page 
performance advantage method described chapter due principle higher order unresolved harmonic partials processed collectively estimation separation individual higher order partials attempted 
author quite surprised efficiency combined spectral location spectral interval information basically directly model half wave rectification 
proposed multiple estimation methods iterative estimation approach 
method described separates spectra detected sounds mixture method described chapter separate cancels effect detected sounds mixture signal 
reason resort iterative approach find technique led comparable degree accuracy 
particularly attractive property iterative approach couple prominent detected rich polyphonies 
probability error increases rapidly course iteration described appears partly due inherent characteristics problem sounds mixture signal difficult detect remain residual till iterations 
sounds prominent usually detected 
frame level multiple estimation accuracy get substantially better bottom signal analysis techniques 
methods converge close error rate auditory model method superior short analysis frames performance methods comparable human listeners described 
substantial performance improvements expected utilizing longer term acoustic features constructing internal models sound sources models 
discussed sec 

musical meter estimation proposed musical meter estimator fairly successful estimating meter different types music signals 
drawn comparing obtained results systems publication informally meter results generated drum track original piece 
mentioned sec 
pitch information utilized meter estimation 
basic decision contradicts know human cognition music main reasons 
proposed meter analysis computationally efficient compared multiple analysis 
secondly meter estimator benefits relatively time resolution adequately provided multiple estimators 
disadvantage ignoring pitch information meter analysis measure pulse level reliable 
measure pulse correlates harmonic changes pitch information probably improve accuracy 
despite criticism simulation results indicate meter large part musical material analyzed resorting multiple analysis 
important elements successful meter estimator turned measuring degree musical accentuation function time modeling primitive musical knowledge governs musically meaningful meter abstractions 
models scope thesis restricted bottom signal analysis methods 
mentioned sec 
information equally important automatic transcription real world musical material 
accuracy proposed multiple methods comparable trained humans musical chord identification tasks accuracy methods inferior transcription continuous musical pieces 
largely due fact proposed methods include internal language model music consider individual analysis frame separately apart context 
temporal continuity musical sounds melodic phrases taken account 
brief program performs multiple estimation understand music 
demonstrations transcription continuous musical pieces described musically agnostic system available kla 
straightforward efficient ways representing knowledge 
example consider experiment 
represented combinations occurring notes bit numbers call chord unigrams 
unigrams 
bit signifies presence absence pitch classes total midi songs collected cut segments note onsets offsets occur 
harmonic content segment represented corresponding unigram 
probability occurrence unigram computed pieces averaged pieces 
results interesting probable unigrams single notes pitch classes different major triad chords minor triads minor seventh chords 
described kind brute force statistical approach advantages 
estimated prior probabilities different combinations rate likelihoods competing hypotheses transcription system 
secondly described estimation 
pitch class example represents notes different octaves play harmonic role 
principle notes hz hz hz considered equivalent called octave equivalence 
twelve pitch classes procedure involves heuristic parameters rules 
thirdly musical expertise employed system knows major minor triad chords building blocks western harmony 
new music types addressed simply re estimating unigram probabilities different training material 
described experiment chord unigrams merely example probabilistic approach modeling 
similar formulations proposed temporal continuity melodies harmonic progression example 
readily collected statistics published kru pp 

complex rules governing western music music theory 
temperley proposed comprehensive rule system models cognition basic musical structures tem 
system automatic analysis midi files 
point view music transcription remaining challenge transform rule models probabilistic models able evaluate likelihoods candidate analyses transcription process 
utilizing longer term temporal features multiple estimation sec 
perceptual cues listed promote grouping time frequency components sound source human listeners 
cues facilitate auditory organization analysis sound mixtures 
proposed multiple estimators utilize cues extensively harmonic frequency relationships partials spectral smoothness amplitude values 
contrast certain important feature utilized synchronous changes time frequency components 
example components belonging sound typically set simultaneously may exhibit synchronous frequency modulation vibrato amplitude modulation components may common fate synchronously ascending frequencies 
cues commonly real world music signals 
straightforward way utilizing longer term temporal features multiple estimation 
proposed multiple estimation methods perform analysis single time frame 
analysis frames relatively short ms case auditory model method 
hanning windowing account meaningful compute salience vectors milliseconds 
consider calculating difference temporally successive salience vectors quite typical musical situation long duration notes playing background top static harmonic background sequence shorter notes melody played 
new sound sets appears peak differential salience long duration notes pop past frames 
words differential includes freshly sound point view differential salience polyphony virtually case 
described principle model synchronous changes cues 
clear peak differential salience vector occurs exactly partials certain change synchronously 
example sounds playing sounds exhibits vibrato sound vibrato comes differential salience 
peaks corresponding vibrato sound successive salience vectors different positions practical implementation merely picking maxima salience vectors reasonable inspect differential ence pick peaks weighted sum 
point view psychoacoustics know auditory nerve response strong onset sound steadily falls lower adaptation level sound continues playing med 
differential salience depart basic principle able model perceptual effect synchronous changes cues auditory organization 
music transcription solved problem 
important fact music transcription difficult 
problem best comparable automatic speech recognition studied years practically applicable 
music transcription development probably faster computational power available borrow theoretical methods approaches speech recognition 
problem really finding fast computers discovering mechanisms principles humans listening music 
modelling perception difficult world live complex things humans create complex music just example human brain complex 
claims quick solution polyphonic transcription problem single mechanism solves problem mistaken 
human brain combines large number processing principles heuristics 
searching years decades arriving say skilled musician accuracy flexibility 
certain factor may crucially change prediction regarding time needed release accurate general purpose music transcriber 
generative nature music versus speech 
development speech recognition systems constantly confronted problem amount targeted carefully annotated training data limited 
synthetic speech valid training speech recognizer 
music transcription problem stems combinatorics sounds different instruments occur varying combinations musical pieces 
dynamic variability complexity single sound event high speech sounds reasons argue synthetic music valid training music transcriber 
principle astronomical amounts training data generated acoustic measurements isolated musical sounds available combinations generated mixing effects added 
exact annotation immediately available 
availability training data helps away frustrating part algorithm development parameter optimization 
free designing methods 
quite transcription problem solved simply training huge neural network example 
space possible algorithms models may larger think 
interesting part explore space meaningful efficient way necessary ingredients successful transcription system 
people different disciplines needed pursuit including signal processing acoustics computer science music linguistics experimental psychology 

concept music defined principle called music 
scope general purpose transcriber limited signal types commonly regarded music 

singing transcribing melody significantly easier recognizing lyrics 
bibliography abd abdallah plumbley probability metadata event detection music ica conditional density model proc 
th international symposium independent component analysis blind signal separation nara japan april 
abd abdallah plumbley sparse coding music signals submitted neural computation 
sound labs music composer transcription software 
url www com ale alexander daniel apparatus detecting fundamental frequencies polyphonic music united states patent application publication pub 
nov 
allen dannenberg tracking musical beats real time proc 
international computer music conference san francisco 
ara transcription software 
url www dti ne jp araki ans american national standards institute ansi 
terminology 
american national standards institute new york 
ast astola fundamentals nonlinear digital filtering 
crc press 
bar barker cooke green robust asr clean speech models evaluation missing data techniques connected digit recognition noise proc 
eurospeech aalborg denmark 
bel bella music selective impairments music recognition brain damage journal new music research 
bel bello automated analysis simple polyphonic music knowledge approach ph thesis univ london 
bil bilmes timing essence perceptual computational techniques representing learning reproducing expressive timing percussive rhythm sc 
thesis massachusetts institute technology 
bra braun auditory laminar structure appears adapted extraction evidence implications double critical bandwidth hearing res 
bra braun inferior colliculus candidate pitch extraction multiple support statistics bilateral spontaneous emissions hearing res 

bre bregman auditory scene analysis 
mit press cambridge massachusetts 
bro brown 
computational auditory scene analysis representational approach ph thesis dept comp 
sci univ sheffield 
bro brown cooke perceptual grouping musical sounds computational model new music research 
bro brown zhang musical frequency tracking methods conven bibliography tional narrowed autocorrelation acoust 
soc 
am 
bro brown musical fundamental frequency tracking pattern recognition method acoust 
soc 
am 
bro brown determination meter musical scores autocorrelation acoust 
soc 
am 
bro brown feature dependence automatic identification musical instruments acoust 
soc 
am 
bro brown ed new shorter oxford english dictionary 
oxford university press new york 
bui group network list wav midi conversion audio transcription software 
url www org html car carver lesser evolution blackboard control architectures massachusetts amherst university technical report oct 
cem cemgil kappen desain honing tempo tracking tempogram representation kalman filtering journal new music res 
cem cemgil kappen monte carlo methods tempo tracking rhythm quantization journal artificial intelligence research 
cha chafe mont rush intelligent editor digital audio recognition musical constructs 
computer music journal spring 
cha chafe jaffe source separation note identification polyphonic music proc 
ieee international conf 
acoust speech signal processing tokyo 
cha chafe jaffe techniques note identification polyphonic music proc 
ieee international conference acoustics speech signal processing tokyo 
cla martens de de mayer auditory model transcriber singing sequences proc 
international conference music information retrieval paris france oct 
cla clarke rhythm timing music psychology music deutsch ed academic press 
cla classical archives llc classical archives archive classical music 
url www com coo cooke 
modelling auditory processing organisation ph thesis dept comp 
sci univ sheffield 
coo cooke brown separating simultaneous sound sources issues challenges models fundamentals speech synthesis speech recognition keller ed wiley pp 

coo cooke ellis auditory organization speech sources listeners computational models speech communication 
coo cooke green robust automatic speech recognition missing unreliable acoustic data speech communication 
cor cormen leiserson rivest algorithms 
mit press cambridge massachusetts 
dav davy godsill detection abrupt spectral changes support vector machines 
application audio signal segmentation proc 
ieee international conference acoustics speech signal processing orlando florida may 
dav davy godsill bayesian harmonic models musical signal analysis bayesian statistics vii bernardo berger dawid smith eds oxford university press 
dav davenport root theory random signals noise ieee press 
dec de cheveign separation concurrent harmonic sounds fundamental frequency estimation time domain cancellation model auditory processing acoust 
soc 
am 
dec de cheveign kawahara multiple period estimation pitch perception model speech communication 
dec de cheveign kawahara comparative evaluation estimation algorithms proc 
eurospeech copenhagen denmark 
dec de cheveign kawahara yin fundamental frequency estimator speech music acoust 
soc 
am april 
dep ph 
garc rodet tracking partials additive sound synthesis hidden markov models proc 
ieee international conference acoustics speech signal processing minneapolis minnesota 
dep ph 
lie extraction spectral peak parameters short time fourier transform modeling windows proc 
ieee workshop applications signal processing audio acoustics new paltz new york 
des desain honing computational models beat induction rule approach journal new music research 
deu deutsch ed psychology music 
academic press san diego 
dix dixon automatic extraction tempo beat expressive performances new music research 
dov rodet estimation fundamental frequency musical sound signals proc 
ieee international conf 
acoust speech signal processing 
dov rodet 
fundamental frequency estimation tracking maximum likelihood harmonic matching hmm proc 
ieee international conference acoustics speech signal processing 
dun dunn methods measuring vowel formant bandwidths acoust 
soc 
am 
duxbury bello davies sandler complex domain onset detection musical signals proc 
th int 
conference digital audio effects london uk sep 
ell ellis rosenthal mid level representations computational auditory scene analysis proc 
workshop computational auditory scene analysis intl 
joint conf 
artif 
intell montreal aug 
bibliography ell ellis prediction driven computational auditory scene analysis ph thesis mit media laboratory cambridge massachusetts 
klapuri musical instrument recognition cepstral coefficients temporal features proc 
ieee international conference acoustics speech signal processing istanbul turkey june 
comparison features musical instrument recognition proc 
ieee workshop applications signal processing audio acoustics new paltz new york oct 
fitzgerald coyle sub band independent subspace analysis drum transcription proc 
th int 
conference digital audio effects dafx hamburg germany 
fle fletcher auditory patterns reviews modern physics 
fle fletcher physics musical instruments 
nd ed 
springer verlag new york 
gla moore derivation auditory filter shapes data hearing research 
god computational model perceptual organization polyphonic music ph thesis dep 
comp 
sc univ sheffield 
god brown blackboard architecture computational auditory scene analysis speech communication 
gom mez klapuri melody description extraction context music content processing journal new music research 
gol goldstein optimum processor theory central formation pitch complex tones acoust 
soc 
am 
goo goodwin adaptive signal models theory algorithms audio applications ph thesis univ california berkeley 
got goto muraoka music understanding beat level real time beat tracking audio signals working notes ijcai workshop computational auditory scene analysis pp 

got goto muraoka beat tracking multiple agent architecture real time beat tracking system audio signals proc 
second international conference multiagent systems pp 
got goto muraoka real time rhythm tracking audio signals chord change detection musical decisions proc 
ijcai workshop computational auditory scene analysis pp 

got goto robust predominant estimation method real time detection melody bass lines cd recordings proc 
ieee international conf 
acoust speech signal processing istanbul turkey june 
got goto predominant estimation method real world musical audio signals map estimation incorporating prior knowledge tone models proc 
workshop consistent reliable acoustic cues sound analysis aalborg denmark sep 
gou gouyon herrera exploration techniques automatic labeling audio drum tracks instruments proc 
workshop current directions compu ter music barcelona spain 
gou gouyon herrera cano pulse dependent analyses percussive music proc 
aes nd international conference virtual synthetic entertainment audio espoo finland june 
gus gustafsson martin jax vary psychoacoustic approach combined acoustic echo cancellation noise reduction ieee trans 
speech audio proc 
july 
hai hainsworth analysis musical audio polyphonic transcription st year report dept eng univ cambridge 
hai hainsworth macleod physiologically motivated approach music transcription poster digital music research network launch day dec th 
hai hainsworth techniques automated analysis musical audio ph thesis cambridge univ appear 
han handel timbre perception auditory object identification hearing handbook perception cognition moore ed academic press san diego california 
har hartmann pitch periodicity auditory organization acoust 
soc 
am 

haw hawley structure sound ph thesis mit media laboratory cambridge massachusetts 
hes hess pitch determination speech signals 
springer verlag berlin heidelberg 
hes hess pitch voicing determination advances speech signal processing furui mohan sondhi ed marcel dekker new york 
hou pitch identification discrimination complex tones harmonics acoust 
soc 
am jan 
hou pitch perception hearing handbook perception cognition moore ed academic press san diego california 
hu hu wang monaural speech segregation pitch tracking amplitude modulation technical report osu tr dept comp 
inf 
sci ohio state university march 
hut hutchinson transcription software 
url www com html inn innovative music systems transcription software 
url www net university iowa university iowa musical instrument samples iowa city iowa 
url music uiowa edu mis html irc studio online paris france 
url fr iso iso iec sec information technology coding audiovisual objects part audio subpart structured audio 
international organization standardization 
url web media mit edu eds mpeg sa pdf jel jelinek statistical methods speech recognition 
mit press cambridge massa bibliography 
jur jurafsky martin speech language processing 
prentice hall new jersey 
inen lim ki karjalainen timbral effects inharmonicity instrument tones acoustics research letters online july 
kae psychophysical evidence autocorrelation theory auditory temporal processing acoust 
soc 
am oct 
kae exploring temporal mechanism involved pitch unresolved harmonics acoust 
soc 
am aug 
kar karjalainen 
espoo finland ja 
report finnish communication acoustics 
kar karjalainen separation speech signals iterative multipitch analysis prediction proc 
th european conf 
speech communication technology eurospeech vol 
budapest hungary sep 
kas kashino tanaka sound source separation system ability automatic tone modeling proc 
international computer music conference tokyo pp 
kas kashino kinoshita tanaka organization hierarchical perceptual sounds music scene analysis autonomous processing modules quantitative information integration mechanism proc 
international joint conf 
artificial intelligence montr 
kas kashino murase sound source identification system ensemble music template adaptation music stream extraction speech communication 
kat inokuchi music system computer music journal winter 
kla klapuri automatic transcription music sc 
thesis tampere univ technology 
kla klapuri wide band pitch estimation natural sound sources th audio eng 
soc 
convention preprint munich germany 
kla klapuri pitch estimation multiple independent time frequency windows proc 
ieee workshop applications signal processing audio acoustics new paltz new york oct 
kla klapuri automatic transcription musical recordings proc 
consistent reliable acoustic cues workshop ellis cooke chairs aalborg denmark sep 
kla klapuri 
means integrating audio content analysis algorithms th audio engineering society convention preprint amsterdam netherlands 
kla klapuri automatic transcription music proc 
stockholm music acoustics conference stockholm sweden aug 
kla klapuri automatic transcription music demonstrations 
url www cs tut fi 
kla lesser ipus blackboard architecture framework computational auditory scene analysis proc 
computational auditory scene analysis workshop international joint conference artificial intelligence montreal quebec 
kru krumhansl cognitive foundations musical pitch 
oxford university press new york 
kun suzuki robust method measurement fundamental frequency autocorrelation log spectrum proc 
ieee international conf 
acoust speech signal processing 
kuo statistical analysis optimization stack filters ph thesis acta electrical engineering series 
lah spectral autocorrelation method measurement fundamental frequency noise corrupted speech ieee trans 
acoust speech signal processing assp 
lar large kolen resonance perception musical meter 
connection science 
lar estimating tempo swing beat locations audio recordings proc 
workshop applications signal processing audio acoustics new paltz new york oct 
lee lee rhythmic interpretation simple musical sequences perceptual model musical structure cognition cross howell west eds academic press london 
lee lee perception metrical structure experimental evidence model representing musical structure howell west cross eds academic press london 
ler lerdahl jackendoff generative theory tonal music 
mit press cambridge ma 
lev levine audio representation data compression compressed domain processing ph thesis univ stanford 
lic duplex theory pitch perception 
lon longuet higgins lee perception musical rhythms perception 
mah maher approach separation voices composite music signals ph thesis univ illinois urbana 
mah maher evaluation method separating digitized signals audio eng 
soc 
mah maher fundamental frequency estimation musical signals way mismatch procedure acoust 
soc 
am 

mar sonic transcription polyphonic piano music neural networks proc 
workshop current research directions computer music barcelona nov 
bibliography mar martin noise power spectral density estimation optimal smoothing minimum statistics ieee trans 
speech audio proc 
july 
mar neural networks note onset detection piano music proc 
international computer music conference teborg sweden sep 
mar martin blackboard system automatic transcription simple polyphonic music mit media laboratory perceptual computing section technical report 
mar martin automatic transcription simple polyphonic music robust front processing mit media laboratory perceptual computing section technical report 
mar martin sound source recognition theory computational model ph thesis mit media laboratory cambridge massachusetts 
mca speech analysis synthesis sinusoidal representation proc 
ieee trans 
acoust speech signal processing 
med meddis simulation mechanical neural transduction auditory receptor acoust 
soc 
am 
med meddis hewitt virtual pitch phase sensitivity computer model auditory periphery 
pitch identification acoust 
soc 
am 

med meddis hewitt virtual pitch phase sensitivity computer model auditory periphery 
ii phase sensitivity acoust 
soc 
am 

med meddis hewitt modeling identification concurrent vowels different fundamental frequencies acoust 
soc 
am 

med meddis unitary model pitch perception acoust 
soc 
am 

mel event formation separation musical sound phd thesis center computer research music acoustics stanford university 
mit mitchell machine learning 
mcgraw hill series computer science 
moe computer system automatic detection perceptual onsets musical signal technology emotion ed genova dist pp 

moo segmentation analysis continuous musical sound digital computer ph thesis dept music stanford university 
moo transcription musical sound computer computer music journal pp 
nov 
moo moore ed hearing handbook perception cognition nd edition 
academic press san diego california 
moo moore frequency analysis masking hearing handbook perception cognition moore ed academic press san diego california 
moo moore psychology hearing 
academic press london 
moo moore baer 
model prediction thresholds loudness partial loudness audio eng 
soc april 
mur murphy dynamic bayesian networks probabilistic graphical models jordan ed appear 
url www ai mit edu papers pdf mus music recognition team recognition system transcription software 
url www com smm programs nak nakatani okuno harmonic sound stream segregation localization application speech stream segregation speech communication 
nii nii 
blackboard model problem solving evolution blackboard architectures ai magazine 
nol noll cepstrum pitch detection acoust 
soc 
am 
manning source separation transcription polyphonic music proc 
international colloquium new music research ghent belgium 
okuno nakatani listening simultaneous speeches speech communication 
mcgill university master samples compact disk 
mcgill university montreal quebec canada 
par parsons separation speech interfering speech means harmonic selection acoust 
soc 
am 
par parncutt perceptual model pulse salience metrical accent musical rhythms music perception summer 
pat patterson auditory filter shapes derived noise stimuli acoust 
soc 
am march 
pat patterson moore auditory filters excitation patterns representations frequency resolution frequency selectivity hearing moore ed pp 

academic press london 
pau klapuri conventional periodic grams transcription drum sequences proc 
ieee international conferences multimedia expo baltimore usa 
pau klapuri model event labeling transcription percussive audio signals proc 
th international conference digital audio effects london uk sep 
music perception recognition handbook cognitive neuropsychology rapp ed hove psychology press pp 

coltheart modularity music processing nature neuroscience july 
pis predicting musical pitch component frequency ratios acoust 
soc 
am 
pis computational model music transcription ph thesis univ bibliography michigan ann arbor 
pov perception temporal patterns music perception 
rab rabiner cheng rosenberg comparative performance study pitch detection algorithms ieee trans 
acoust speech signal processing assp 
rab rabiner juang fundamentals speech recognition 
prentice hall englewood cliffs new jersey 
rap raphael modeling interaction accompaniment proc 
th meeting fwo research society foundations music research ghent belgium oct 
rap raphael automated rhythm transcription proc 
international symposium music information retrieval indiana oct pp 

roa roads computer music tutorial 
mit press cambridge massachusetts 
rod rodet musical sound signal analysis synthesis sinusoidal residual elementary waveform models proc 
ieee time frequency time scale workshop univ warwick coventry uk 
ros rosenthal machine rhythm computer emulation human rhythm perception ph thesis massachusetts institute technology 
ros rosenthal okuno editors computational auditory scene analysis 
lawrence erlbaum associates mahwah new jersey 
ros rossi identification de sons de piano ph thesis universit de france 
ros science sound 
addison wesley publishing reading massachusetts 
row rowe machine 
mit press cambridge massachusetts 
rus russell norvig 
artificial intelligence modern approach 
prentice hall 
nen probabilistic modelling note events transcription monophonic melodies sc 
thesis tampere university technology march 
sch scheirer bregman music perception auditory scene analysis proc 
international conference music perception cognition montreal society music perception cognition pp 

sch scheirer tempo beat analysis acoustic musical signals acoust 
soc 
am 

sch scheirer music listening systems ph thesis massachusetts institute technology june 
ser serra system sound analysis transformation synthesis deterministic plus stochastic decomposition ph thesis stanford university 
ser serra musical sound modeling sinusoids plus noise musical signal processing roads pope de poli eds swets zeitlinger publishers 
set tuning timbre spectrum scale 
springer verlag london 
set periodicity transforms ieee trans 
signal processing 
set meter periodicity musical performance journal new music research 
sev seventh string software transcribe 
transcription software 
url www demon uk sla slaney efficient implementation patterson auditory filter bank apple computer technical report perception group advanced technology group apple computer 
sta stahl fischer quantile noise estimation spectral subtraction wiener filtering proc 
ieee international conference acoustics speech signal processing istanbul turkey 
ste steedman perception musical rhythm metre perception 
ste sterian model segmentation time frequency images musical transcription ph thesis university michigan 
ste stevens psychophysics 
john wiley sons new york 
ste stevens acoustic phonetics 
mit press cambridge massachusetts 
tal robust algorithm tracking speech coding synthesis paliwal eds science 
tem temperley sleator modeling meter harmony preference rule approach computer music journal spring 
tem temperley cognition basic musical structures 
mit press cambridge ma 
ter terhardt pitch harmony acoust 
soc 
am may 
ter terhardt stoll pitch complex signals theory tests examples predictions acoust 
soc 
am march 
ter terhardt stoll algorithm extraction pitch pitch salience complex tonal signals acoust 
soc 
am march 
ter robust pitch determination nonlinear state space embedding proc 
ieee international conference acoustics speech signal processing orlando florida may 
ter auditory cortex functions brain research reviews appear 
tol lim ki karjalainen evaluation modern sound synthesis methods 
espoo finland helsinki university technology laboratory acoust 
audio sig 
proc 
report 
tol karjalainen computationally efficient multipitch analysis model ieee trans 
speech audio processing nov 
var vary hess 
teubner bibliography stuttgart 
ver verma levine meng transient modeling synthesis flexible analysis synthesis tool transient signals proc 
international computer music conference thessaloniki greece sep 
ver verma perceptually audio signal model application scalable audio compression ph thesis stanford university 
vii klapuri probabilistic model transcription single voice melodies proc 
finnish signal processing symposium tampere finland may 
vir klapuri separation harmonic sound sources sinusoidal modeling proc 
ieee international conference acoustics speech signal processing istanbul turkey 
vir audio signal modeling sinusoids plus noise sc 
thesis tampere university technology 
vir sound source separation sparse coding temporal continuity objective international computer music conference singapore 
vir music content analysis demonstrations 
url www cs tut fi html lim ki virtual musical instruments natural sound physical models organized sound aug 
wan wang brown separation speech interfering sounds oscillatory correlation ieee trans 
neural networks may 
wei weintraub computational model separating simultaneous talkers proc 
ieee international conference acoustics speech signal processing tokyo 
wig pattern transformation model pitch acoust 
soc 
am 
wol wolfe godsill efficient alternatives suppression rule audio signal enhancement eurasip applied signal proc sep 
wu wu wang brown multi pitch tracking algorithm noisy speech proc 
ieee international conference acoustics speech signal processing orlando florida may 
belin spectral temporal processing human auditory cortex cerebral cortex oct 
belin structure function auditory cortex music speech trends cognitive sciences jan 
pachet gouyon automatic extraction drum tracks polyphonic music signals proc 
nd int 
conference web delivering music darmstadt germany 
zwicker psychoacoustics facts models 
springer series information sciences springer verlag berlin heidelberg 
appendices author contribution publications publications done author 
algorithm derived implemented author 
prof astola helped finding way modelling half wave rectification unitary model pointing treatment nonlinear analog devices dav 
meter estimation method designed implemented author 
sc 
antti contributed significantly mathematical formulation description probabilistic model 
prof astola helped final formulation model 
errata addition errors publications 
publication sec 
statement predominant pitch estimation algorithm capable finding correct pitches certainty voice polyphonies certainty voice polyphonies 
erroneous statement error rate calculated number errors number test cases polyphony 
calculating predominant pitch estimation error rates simply number errors number test cases 
error annoying change way 
error rates evaluation section table correct 
publication equation change forthcoming considerations xc discussed separately 
notation refers standard deviation signal subband misleading 
better notation course 
equation hc hc appendices hc hc change forthcoming considerations described sec 
squared magnitudes 
erroneous formula gives complex conjugate eq 
equation distortion spectrum centered dropped 
explicitly stated dropping distortion spectrum mentioned earlier denoted notation thesis referring spectrum distortion spectrum dropped spectrum centered zero frequency retained 
publication equation table pseudocode core algorithm seventh row algorithm lb lb expressed frequency bin units hertz units 
table pseudocode core algorithm second row algorithm equations read lb kb kb kb kb kb kb kb kb pow pow publication klapuri number theoretical means resolving mixture harmonic sounds proc 
european signal processing conference greece 
number theoretical means resolving mixture harmonic sounds number theoretical method developed purpose analyzing mixture harmonic sounds 
method properties prime numbers non linear filtering 
shown number theoretical approach vital importance order detect observe harmonic sounds musical polyphonies 
method verified applying automatic transcription piano music 
multiple fundamental frequency tracking unexplored area research case algorithms proposed robust commercially applicable operate real time 
published efforts multipitch tracking field automatic transcription music 
days performance transcription systems limited polyphonic signals 
discuss spectral properties mixture harmonic sounds demonstrate single pitch tracking algorithms appropriate polyphonic signals 
attempt establish number theoretical method detect observe harmonic sounds polyphonic signals 
concern multiple fundamental frequency tracking observing features harmonic sounds polyphonic signals 
feature sound harmonic sound consists series frequency partials harmonics 
appear peaks frequency spectrum constant frequency intervals lowest partial frequency called fundamental frequency sound 
denote harmonic sounds uppercase letters consistently roles sound observed interference presence sound ri interfering sounds 
denote harmonic partials sound hj braces denote sets set harmonics 
denote feature sound single harmonic partial separate different features subscript characters example frequency loudness onset time respectively 
substance harmonic sound series equidistant sinusoid partials observation harmonic sound rely klapuri signal processing laboratory tampere university technology box fin tampere finland tel fax mail cs tut fi harmonic partials matter time frequency domain 
basic problem resolving mixture harmonic sounds methods measuring frequency amplitude contours phases sinusoid partials signal 
separating mixture harmonic sounds problematic specific reasons 

difficult organize sinusoid partials due fundamental frequencies harmonic series different sounds extend common frequency bands 

amplitude envelopes phases sinusoids deduced sum overlap share frequency 
proposition 
harmonic hj sound harmonic hi interfering sound fundamental frequency sound positive integer numbers 
proof 
condition harmonic sound overlapped harmonic hi interfering sound expressed 
common factors reduced expressed calculated integers proposition 
fundamental frequencies harmonic sounds respectively nth harmonic sound overlaps mth harmonic sound integer proof 
substituting rewrite condition harmonic hj sound overlapped harmonic hi interfering sound true pair nk mk easy see equation overlaps harmonics common frequency bands 
case detecting observing difficult theoretically ambiguous 
case separately discussed 
certain principles western music important principle governing music paying attention frequency relations intervals simultaneously played notes 
notes harmonic relation fundamental frequencies satisfy small integers 
smaller values closer harmonic relation sounds perfectly play 
western music arranges notes quantized logarithmic scale fundamental frequency note hz standard piano keyboard example 
scale logarithmic surprisingly produce different harmonic intervals derived equation substituting small integers realizable musical intervals deviate little ideals amount error little practically disturb human ear 
feasible frequency analysis resolution overlapping harmonics sounds harmonic relation perfect 
instance fundamental frequencies notes basic major chord relations 
proposition harmonic partials notes overlapped notes chord 
case partials third note signal absence 
demonstrates algorithms designed detection observation single harmonic sound straightforwardly applied resolving musical contents 
need rethink kernel collect information sound harmonics 
prime number harmonics prime number harmonics 
sound share desired common property derived definition prime numbers divisible 
important consequence give starting point organizing frequency partials due fundamental frequencies 
proposition 
harmonic sound overlap prime number harmonic sound provided fun frequency integer overlaps prime number harmonics overlaps harmonics fundamental frequency mentioned relation proof 
proved assuming prime number harmonics overlapped harmonics showing case sound overlaps harmonics sound fundamental frequencies sounds respectively 
denote arbitrary prime number pi condition prime number harmon ics overlapped harmonics hj expressed solved order prime number equal satisfy integer implies substituting get equation holds harmonics overlapped nth harmonic proposition 
dealing outlier values denote set prime harmonics hp prime set features prime harmonics hp prime type feature fixed 
proposition prime number harmonics sound considered independent pieces evidence existence sound features deduced harmonics 
set representative features hp prime kinds outliers irrelevant values respect true feature sound 
prime harmonics disturbed interfering sounds may totally lacking values outliers vary somewhat value outliers single clearly deviated values invalid represent true feature majority representatives reliable majority prime number harmonics missing corrupted independent interfering sound 
motivation design filter pick estimated feature set inde pendent representatives hp prime drop irrelevant values 
class median order statistic filters prompted fact particularly effective dealing kind data characterized 
filters depend sorting set representatives 
overestimated outlier values map ends sorted set reliable samples sorted smallest largest value 
trivial way estimate feature sound median hp prime 
weighted order statistic wos filters defined 
allow convenient tailoring filter sample selection probabilities 
th sample selection probability probability sample hj set hj selected output filter 
denote sample selection probabilities filter 
generalization result remaining shortcoming proposed procedure utilizes prime number harmonics 
degrades usability algorithm sensitive tonal content sound 
proceed model defect removed advantages set prime number harmonics preserved 
denote wos filter picks estimated feature sound set features harmonics 
written hj 
denote set con tains mth harmonic sound starting harmonic proposition proved interfering sound overlaps harmonic observing sound overlaps mth harmonic exactly subset em requirements filter exactly expressed follows 
number interfering sounds contribute limited probability corrupted harmonic chosen output time filter utilize harmonics observed sound equally possible applicable robust different kinds sounds 
requirements achieved finding sample selection probabilities ps filter selection probabilities largest subsets em sum limit probability 
largest sets subsets prime sets em 
excluded case harmonics overlapped discussed separately 
set expressed finding ps minimizing problem denotes total number detectable harmonics observed sound 
assume fundamental frequencies interfering sounds ri equally probable 
assumption values binding equation equally probable follows equally probable choose overlap subset em relative trustworthiness single harmonics hj equals probability sets em hj belongs overlapped 
calculated min max ps represents probability interfering sound overlap subset em number subsets em harmonic hj belongs 
easily proved number integers divide 
integer defined divide integer da holds integer 
selection probabilities ps harmonics probability trustworthy 
write ps form ps defined 
mj rewrite requirements feature filter set defined contain numbers harmonics hj belong largest subsets em 
set simply contains numbers left side sums selection probabilities harmonics largest subsets 
right side summation goes selection probabilities harmonics equal unity 
equation solved 
problem solvable root real 
root earlier discussed value 
selection probabilities ps calculated substituting equation scaling sum ps unity 
arrive selection probabilities ps interfering sounds may contribute probability overlapped harmonic exists output 
important property algorithm flexibly tradeoff requirements filter put emphasis robustness filter presence interfering sounds equally filter utilizes harmonics observed sound vice versa 
illustrates selection probabilities 

harmonics 
reduced observation feature harmonic sound presence interfering harmonic sounds measuring features harmonics sound applying weighted order statistic filter yield estimate 
design procedure find wos filter implements calculated selection 
feature subtraction principle algorithm discussion observation features harmonic sound presence harmonic sounds assumption observed sound totally overlapped interfering sound fundamental frequency basic idea solution problem compensate effect interfering sound properties robustly extracted presence procedure interfering sound totally overlapped develop algorithm subtract remove compensate revealed properties lower sound proceed determine properties sound laid bare interfering sound 
subtraction process depends feature inspection general form 
algorithm evaluation algorithm evaluated verified applying computer program purpose transcribe polyphonic piano music 
program allowed study piano notes sufficient amount represent different tone colours produced instrument 
require program transcribe rich polyphonic musical signals played instrument determine fundamental frequencies sounds signals 
test cases transcription done knowledge polyphony transcribed signals fixed constant set parameters 
range fundamental frequencies restricted extend hz hz octaves piano keys fit 
acoustic upright piano simulations 
transcription proceeds detecting potential note candidates spectrum resolving new method 
naturally potential note candidates truly played notes 
call true notes notes truly played recorded signals false notes appear note candidates played 
goodness algorithm justified ability indicate truly existing sound signal loudness true notes raise clearly loudness false ones 
candidates time segment scaled values 
certain note combinations separately played fed transcriber review ability resolve rich musical polyphonies 
results table 
type tests consonant chords played octaves 
second test groups adjacent notes piano keyboard played octave 
third groups random notes allotted allowed range played 
tests average true false notes calculated recorded 
worst cases loudness false notes gets closest true notes recorded 
polyphony number notes test indicated 
table relative true false notes 
test type polyp 
averages worst case min true max false min true max false chords groups random chosen classical compositions played excerpts posed transcription system test practical transcription efficiency 
relative loudness threshold segregate true false notes 
weaker candidates discarded false notes 
results table 
piece played computer electric piano 
effect notes having roughly equal playing loudness absence cross resonance noise noticed results 
table transcription results loudness limit 
composition notes total typical polyphony missing erroneous notes extra notes elise elise ii half half finding exact fundamental frequencies sounds analyzed signals proved successful cases 
assumed quantized closest legal notes 
problem resolving rich musical polyphonies motivation developing new methods 
simulations illustrate current system works certain error limits notes polyphony 
especially increase polyphony brings levels weakest true note strongest false note closer system totally break rich polyphonies 
conclude number theoretical analysis sound mixture key robust detection harmonic sounds interference 
kashino kinoshita tanaka 
application bayesian probability network music scene analysis 
proceedings int 
joint conference artificial intelligence casa workshop martin 
blackboard system automatic transcription simple polyphonic music 
mit media laboratory perceptual computing section technical report 

speech analysis synthesis sinusoidal representation 
ieee trans 
assp pp 

garc rodet 
tracking partials additive sound synthesis hidden markov models 
ieee trans 
assp 
serra 
musical sound modeling sinusoids plus noise 
roads pope poli eds 
musical signal processing 
swets zeitlinger publishers 
astola 
fundamentals nonlinear digital filtering 
crc press llc 

statistical analysis optimization stack filters 
tech thesis acta electrical engineering series 
koblitz 
course number theory cryptography 
springer berlin 
klapuri 
automatic transcription music 
msc thesis tampere university technology 
publication klapuri sound onset detection applying psychoacoustic knowledge proc 
ieee international conference acoustics speech signal processing phoenix arizona 
ieee 
reprinted permission proc 
ieee international conference acoustics speech signal processing 
personal material permitted 
permission reprint republish material creating new collective works resale redistribution servers lists reuse copyrighted component works obtained ieee 
sound onset detection applying psychoacoustic knowledge system designed able detect perceptual onsets sounds acoustic signals 
system general regard sounds involved robust different kinds signals 
achieved assuming regularities positions onsets 
method proposed determine beginnings sounds exhibit onset imperfections amplitude envelope rise monotonically 
mentioned system described utilizes band wise processing psychoacoustic model intensity coding combine results separate frequency bands 
performance system validated applying detection onsets musical signals ranged rock classical big band recordings 

onset detection plays important role computational segmentation analysis acoustic signals 
greatly facilitates cut paste operations editing audio recordings 
onset information may audio video synchronization timing passed analysis recognition example acoustic supervision system 
term onset detection refer detection beginnings discrete events acoustic signals 
percept onset caused noticeable change intensity pitch timbre sound 
fundamental problem design onset detection system distinguishing genuine onsets gradual changes modulations take place ringing sound 
reason robust detection onsets proved hard attain significantly limiting set application signals 
lot research related onset detection carried years 
systems set solve problem onset detection 
systems aim higher level information perceived beat musical signal case long term autocorrelations regularities remove single errors tune sensitivity low level detection process 
propose mathematical method cope sounds exhibit onset imperfections amplitude envelope rises complex track easily produces erroneous extra onsets incorrect time value 
propose application psychoacoustic models intensity coding enable determine system parameters klapuri signal processing laboratory tampere university technology box fin tampere finland cs tut fi apply wide variety input signals 
allows processing priori knowledge signal contents separate tuning parameters 
realized system validated applying detection onsets musical signals 
done mainly reasons 
musical signals introduce rich variety sounds wide range pitches timbres 
different combinations backgrounding sounds readily available 
second verifying contents musical signal somewhat easier case environmental sounds 
concept perceivable onset better defined 
noted algorithm limited musical signals regularities rhythmic properties musical signals utilized detection process 
system performs reliably input signals ranged rock music classical big band recordings drums 

system overview earliest onset detection systems typically tried process amplitude envelope signal see 
effective proposals evolved band wise processing 
scheirer clearly point fact onset detection algorithm follow human auditory system treating frequency bands separately combining results 
earlier system bilmes way direction system high frequency low frequency band effective 
scheirer describes psychoacoustic demonstration beat perception shows certain kinds signal simplifications performed affecting perceived rhythmic content musical signal 
signal divided frequency bands corresponding bands noise signal controlled amplitude envelopes musical signal noise signal rhythmic percept significantly original signal 
hand hold band case original signal recognizable simplified form 
overview onset detection system 
utilizes band wise processing principle motivated 
loudness signal normalized db level model loudness proposed moore 
filterbank divides signal non overlapping bands 
band detect onset components determine time intensity 
final phase onset components band wise processing source scale signal level db see fig 
combine results yield onsets onsets 
system overview 
amplitude envelope extraction filterbank onset component detection combined yield onsets 
psychoacoustic models onset component detection time intensity determination combining results important filterbank provide input models 
choose bank nearly critical band filters covers frequencies hz khz 
lowest required filters band pass filters 
remaining eighteen third octave band pass filters 
subsequent calculations done band time 
reduces memory requirements algorithm case long input signals assumed parallel processing desired 
output filter full wave rectified decimated factor ease computations 
amplitude envelopes calculated convolving band limited signals ms half hanning raised cosine window 
window performs energy integration human auditory system preserving sudden changes masking rapid modulation 

calculation onset components onset component detection determine component time intensity 
processing frequency band 
algorithms picking potential onset candidates amplitude envelope function literature 
despite number variants practically calculation order difference function signal amplitude envelopes maximum rising slope onset onset component 
simulations turned order difference function reflects loudness sound maximum values fail precisely mark time onset 
due reasons 
especially low sounds may take time come point amplitude maximally rising point crucially late physical onset sound leads incorrect cross band association higher frequencies 
second onset track sound monotonically increasing sev eral local maxima order difference function near physical onset see plots dashed line 
took approach effectively handles problems 
calculating order difference function dt denotes amplitude envelope function 
set zero signal minimum audible field 
divide order difference function amplitude envelope function get order relative difference function amount change relation signal level 
differentiating logarithm amplitude envelope 
log dt relative difference function detect onset components determine time 
relevant perceived increase signal amplitude relation level amount increase prominent quiet signal 
moore smallest detectable change intensity approximately proportional intensity signal 
weber fraction constant 
relationship holds intensities db db absolute threshold 
function equivalent frequency reduced division 
detect onset components simple peak picking operation looks peaks global threshold relative difference function 
relative difference function effectively solves abovementioned problems detecting onset times low sounds earlier importantly handling complicated onset tracks oscillations onset track sound matter relative terms amplitude started rising 
clarify plotted absolute relative difference functions onset piano sound 
benefits discussed seen clearly 
intensity onset component dashed line dt solid line log dt denotes amplitude envelope function 

onset piano sound 
order absolute dashed relative solid difference functions amplitude envelopes different frequency bands 
simultaneously occurring sounds combine linear summation 
determining intensity detected onset component assume level backgrounding sounds momentarily steady take increase level due sound 
asked intensity picked order difference function multiplied band center frequency intensity needed onset components combined yield onsets signal 
appropriate point time pick intensity early onset determined occur 
scan forward point amplitude envelope starts decreasing determine intensity point maximum slope maximum value onset point amplitude stops increasing 
intensities determined onset components band check drop components closer ms intense component 
remaining ones accepted 

combining results bands final phase combine onset components separate bands yield onsets signal 
purpose implemented model loudness proposed moore baer 
input implementation vector sound intensities third octave bands hz khz program calculates loudness signal 
optimize computational efficiency procedure slightly simplified model making shape excitation pattern intensity spread adjacent critical bands independent sound pressure level 
accelerated computations remarkably significant difference estimated loudness values sound intensity levels 
onsets signal calculated follows 
onset components different bands sorted time order regarded sound onset candidates 
onset candidate assigned loudness value calculated collecting onset components ms time window candidate feeding intensities corresponding frequency bands loudness model moore candidates couple contributing onset components different bands minimum level background noise level bands input model 
repeating procedure onset candidate yields vector candidate function times illustrated popular music signal 
onset estimated procedure corresponded perceived onsets listening tests 
turned robust detection onsets diverse kinds signals achieved simple peak picking operation looks onset candidates global threshold value final drop onset candidates loudness falls threshold 
drop candidates close ms louder candidate 
equally loud close candidates middle median chosen abandoned 
remaining onset candidates accepted true ones 
value final db signals average normalized db level 
loudness db share wav 
loudness onsets function time 
genuine onsets quite easily discerned 

validation experiments procedure verified testing performance detecting onsets musical signals 
signals selected comprise large variation musical instruments wide dynamic pitch range 
signals drums included 
goal include representative excerpts different musical genres ranging jazz rock classical big band music 
approximately second excerpts sampled performance 
periods carefully inspected onset times marked 
excerpts onset detection system results compared manual transcription 
simulation cases computed set parameter values thresholds separate tailoring simulation case 
algorithm explained 
higher level rhythmic properties regularities musical signals utilized detection 
interesting note limitations detection system resemble human perception 
define pseudo onset sound exists signal detected human listener signal short segments times 
objective listening test arranged regard undetected pseudo onset errors 
turned detection achieved giving rise erroneous extra onsets due gradual changes modulations ringing sounds 
onset detection results different musical signals summarized table 
total number onsets number undetected onsets number erroneous extra onsets 
measure correctness rightmost column calculated total undetected extra correct 
total detailed discussion case follows 
classical piano etude op 
trivial case 
onsets fell threshold notes low pitched played softly masked notes 
di orient blue represents difficult case 
piece polyphonic employs dynamic pitch range acoustic guitar 
shortest inter note intervals fifteenth second 
results achieved partly table summary onset detection results 
signal worth notice contents onsets unde total noise instruments 
extra correct acoustic piano acoustic guitar police singing el guitar drums el 
guitar distorted piano drums double bass miller big band bach chamber ensemble vivaldi symphony orchestra beethoven symphony orchestra police rock music genre dominated loudness singing electric drums 
onset detection success resembles results derived rock pieces 
moments singing produced double onsets combinations ps produce onset 
occurred inside ms time window fused 
electric guitar taken band performance night earth 
excerpt played distorted sound accompanying instruments 
case illustrates situations rough sounds handled 
del soul classified fusion jazz selected excerpt resembles popular music 
various included detected trouble 
miles davis introduces selection jazz band instruments trumpet tenor alto piano double bass gentle drums 
brass instrument onsets soft double bass consistently detected 
glen miller mood dominated big band brass instruments performing orchestra 
occurred clarinet melody partly masked louder instruments 
bach brandenburg sampled performance munich chamber ensemble comprises strings brass instruments 
worth notice onsets detected moments strings carrying rhythm played tying consecutive notes 
sharp contrast robust detections symphony orchestra performances turned resolved poorly 
vivaldi seasons beethoven symphony examples table 
clear discrepancy human perception due type instruments involved detected smaller ensembles 
causes supposed 
firstly individual physical sound sources followed symphony orchestra resulting onsets derive sources smoothed 
secondly revealed certain hammond organ solo strong amplitude modulation middle frequencies confuses system 
human auditory system special ability ignore loud amplitude modulation inconsistent con frequencies structure 

discussed problems arise detection sound onsets 
system described builds relative difference function application psychoacoustic models intensity coding 
done framework band wise processing idea 
experimental results show system exhibits significant generality regard sounds signal types involved 
achieved higher level logic grouping onsets 
system introduces thresholds need experimentally deduced psychoacoustic metrics 
thresholds common input signals 
shortcomings method lies inability deal strong amplitude modulation met classical ensembles certain instrumental sounds 
general proposed system able discern genuine onsets gradual changes modulations sounds 
case musical signals additional higher level analysis significantly improve accuracy system 

computer system automatic detection perceptual onsets musical signal 
antonio ed 
technology emotion pp 

genova 
bilmes timing essence perceptual computational techniques representing learning reproducing expressive timing percussive rhythm 
msc thesis massachusetts technology 
schloss automatic transcription percussive music acoustic signal high level analysis 
ph thesis stanford university 
report stan 
scheirer tempo beat analysis acoustic musical signals 
machine listening group mit media laboratory 
goto muraoka beat tracking multiple agent architecture real time beat tracking system audio signals 
proceedings second international conference multiagent systems pp 
goto muraoka real time beat tracking system audio signals 
proceedings international computer music conference pp september 
chafe jaffe mont smith source separation note identification polyphonic music 
stanford university department music report stan 
moore baer model prediction thresholds loudness partial loudness 
audio eng 
soc vol 
pp 

april todd 
auditory primal sketch multiscale model rhythmic grouping 
journal new music research pp 

moore 
ed 
hearing 
handbook perception cognition nd edition 
academic press 
publication klapuri multipitch estimation sound separation spectral smoothness principle proc 
ieee international conference acoustics speech signal processing salt lake city utah 
ieee 
reprinted permission proc 
ieee international conference acoustics speech signal processing 
personal material permitted 
permission reprint republish material creating new collective works resale redistribution servers lists reuse copyrighted component works obtained ieee 
multipitch estimation sound separation spectral smoothness principle klapuri tampere university technology box fin tampere finland cs tut fi processing principle proposed finding pitches separating spectra concurrent musical sounds 
principle spectral smoothness human auditory system separates sounds partly assuming spectral envelopes real sounds continuous 
theoretical experimental evidence vital importance spectral smoothness resolving sound mixtures 
algorithms varying complexity described successfully implement new principle 
validation experiments random pitch sound source combinations analyzed single time frame 
number simultaneous sounds ranged database comprising sung vowels musical instruments 
usage specific straightforward smoothing operation corrected approximately half pitch errors occurred system identical smoothness principle 
random voice mixtures pitch error rate reduced 

pitch perception plays important part human hearing understanding sounds 
acoustic environment human listeners able perceive pitches simultaneous sounds efficient pitch hear sound mixture 
computational modeling function multipitch estimation relatively little explored comparison availability algorithms single pitch estimation monophonic speech signals 
days computational multipitch estimation mpe fallen clearly humans accuracy flexibility 
attempts field automatic transcription music limited regard number simultaneous sounds pitch range variety sound sources involved 
years progress taken place 
martin proposed system utilized musical knowledge transcribing voice piano compositions 
kashino describe model able handle different instruments 
goto system designed extract melody bass lines real world musical recordings 
psychoacoustic knowledge succesfully utilized models brown cooke de kawahara 
purely mathematical approaches proposed 
multipitch estimation auditory scene analysis intimately linked 
pitch sound determined getting confused occurring sounds pitch information organize simultaneous spectral components sources production 
vice versa spectral components source separated mixture mpe reduces iterate mixture spectrum signal remove nant pitch partials estimation spectral mixture store pitch smoothing fig 

experimental framework system switched modes 
straightforward iterative approach 
spectral smoothness model 
single pitch estimation 
mpe systems explicitly refer human auditory scene analysis principles 
human hearing perceptual organization spectral components depend certain acoustic cues 
components may associated source closeness time frequency harmonic concordance synchronous changes frequency amplitude components spatial proximity case multisensor input 
purpose propose new efficient mechanism computational mpe auditory organization 
spectral smoothness refers expectation spectral envelopes real sound sources tend continuous 
bregman points principle human hearing mentioning spectral smoothness promotes integration frequency partials source single higher intensity partial perceived independent sound 
smoothness traditionally included auditory organization cues 
presents evidence importance spectral smoothness human computational mpe 
different algorithms described implement principle 
validation experiments performed experimental model spectral smoothness utilized different ways completely ignored 
acoustic database comprised sung vowels pitch range musical instruments 
mpe performed single time frame random pitch sound source combinations number simultaneous sounds ranging 
including spectral smoothness principle calculations significant improvement simulations 
example pitch error rate random voice mixtures dropped musical voice mixtures 
result mpe performed quite accurately wide pitch range priori knowledge sound sources involved 

experimental framework shows overview system acts experimental framework 
system switched modes 
straightforward iterative mpe model denoted branch described earlier 
consists main parts applied iterative succession 
part predominant pitch estimation finds pitch prominent sound interference harmonic noisy sounds 
output gives fundamental frequency inharmonicity factor precise frequencies amplitudes harmonic partials sound 
second part spectrum detected sound linearly subtracted mixture 
repeated residual signal 
spectral smoothness model obtained locating additional module estimation subtraction stages 
denoted branch fig 

aim spectral smoothing algorithm pitch information produce appropriate estimate spectrum separated sound subtracted mixture 
need module strongly motivated observations 
predominant pitch estimation algorithm capable finding correct pitches certainty voice polyphonies 
probability error increases rapidly course iteration 
indicates initial estimate sound spectrum predominant pitch algorithm accurate remove correctly mixture 

diagnosis straightforward iterative system simulations run analyze behaviour straightforward iterative estimation separation approach branch 
random mixtures sounds generated instrument random note playing range restricting pitch octaves hz hz 
desired number sounds allotted mixed equal mean square levels 
iterative process evoked requested extract pitches acoustic mixture signal 
general impression iterative approach works reliably 
important observation immediately distribution remaining errors analyzed 
shows errors function musical intervals occur erroneously transcribed sound mixtures 
appears error rate strongly correlated certain pitch relations 
exactly straightforward estimation subtraction approach fail cases fundamental frequencies simultaneous sounds simple rational number relations called harmonic relations 
indicated corresponding bars fig 

coinciding sinusoidal partials turned coinciding frequency partials different sounds algorithm fail 
sounds harmonic relation lot partials coincide share frequency 
firstly detected sound removed coinciding harmonics remaining sounds removed subtraction procedure 
cases particularly iterations remaining sound gets corrupted correctly analyzed coming iterations 
sinusoidal partials amplitudes errors interval semitones fig 

distribution pitch estimation errors function musical intervals occur erroneously transcribed sound mixtures 
phase difference coincide frequency amplitude resulting sinusoid calculated 
amplitudes roughly equivalent partials may amplify cancel depending amplitudes significantly larger usually case approaches maximum 
fundamental frequency relations condition harmonic partial sound coincides harmonic sound written fs fr fundamental frequencies sides represent frequencies partials 
common factors integers reduced yields integer numbers 
implies partials sounds coincide fundamental frequencies sounds rational number relations 
furthermore fundamental frequencies sounds relation mth harmonic mk sound coincides nth hfs fr mn harmonic nk sound common frequency bands integer evident hfs equals pair mk nk eq 
holds 
important principle governing music paying attention pitch relations intervals simultaneously played notes 
simple harmonic relations eq 
favoured ones 
western music arranges notes quantized logarithmic scale surprisingly produce different harmonic intervals derived substituting small integers eq 

harmonic relations common music worst cases handled general 
explains mpe particularly difficult music 

solution argumentation difficulties caused harmonic pitch relations classified categories 
partials sound may erroneously removed separated 
causes 
second fundamental frequencies certain relations may non existent ghost sound appear example root pitch chord 
causes insertion errors extraneous pitch detections 
solution problems intuitive magnitude db frequency hz fig 

illustration spectral smoothness principle 
logarithmic magnitude spectrum containing sounds lower detected 
spectrum high pass remove spectral envelope 
efficient valid spectra detected sounds smoothed subtracting mixture 
consider logarithmic magnitude spectrum mixture fig 

harmonic partials sound coincide third harmonic lower pitched sound detected 
predicted eq 
coinciding partials detected sound tend higher magnitudes ones 
sound spectrum smoothed thin slowly decreasing horizontal curve fig partials rise smooth spectrum remain residual subtraction 
way sound removed detected 
properly applied mechanism treat ghost sounds 
psychoacoustic knowledge applied design smoothing operation simple glance 
matter fact simply smoothing amplitude envelope thin horizontal curve fig subtraction mixture sense reduce pitch error rate simulations 
spectral smoothing human auditory system take form lowpass filtering 
nonlinear mechanism cuts single higher amplitude partials 
brief description human auditory processing order reveal exact mechanism appropriate smoothing process 
meddis hewitt proposed computer model human auditory periphery aims reproducing widest range phenomena human pitch perception 
algorithm consists main steps 
input signal passed bank bandpass filters 
band signal rectified lowpass filtered extract amplitude envelope signal 
periodicity resulting signal detected calculating autocorrelation function estimates channels 
final phase estimates linearly summed channels get summary autocorrelation function maximum value points global pitch 
amplitude envelope calculation channels performs implicit spectral smoothing 
harmonic sound considered neighbouring harmonic partials cause amplitude beating alternatingly amplify cancel fundamental frequency rate 
magnitude beating caused sinusoidal partials determined smaller amplitudes 
spectrum harmonic sound considered minimum amplitude property filters single higher amplitude harmonic partials 
smoothing algorithms computer implementation implicit smoothing human auditory system isolated separate module 
algorithm simply goes harmonic partials sound replaces amplitude ah partial minimum amplitudes partial neighbour 
interestingly performing simple operation spectral smoothing module fig 
corrects errors straightforward iterative model 
example error rate random voice mixtures reduces 
efficient algorithm designed focusing role smoothing algorithm 
cut single clearly higher amplitude partials 
equation surely bases estimate values 
robustness method improved imitating calculations human auditory system bandlimited frequency channels 
second algorithm calculates moving average amplitudes harmonic partials 
octave wide hamming window centered harmonic partial weighted mean mh amplitudes partials window calculated 
smooth spectrum illustrated thin horizontal curve fig 

original amplitude value ah replaced minimum original averaged amplitude 
values illustrated thick horizontal curve fig 

straightforward algorithm designed 
example random voice mixtures average pitch error rate dropped 
final slight improvement method utilizing statistical dependency mth ah min ah ah ah min ah mh harmonic partials explained sec 

third algorithm applies multistage filter consists steps 
numbers 
harmonic partials harmonic collected octave wide window 
surrounding partials classified groups harmonics share common divisor put group 
third estimates harmonic calculated inside groups manner second algorithm 
step estimates different groups averaged weighting group mean distance harmonic problem category ghost sounds solved noticing likelihood predominant pitch re estimated new smooth spectrum calculated 
example case clarifies erroneous sound may arise joint effect problem solved 
harmonic sounds played fundamental frequencies spectra sounds match second third harmonics non existent sound fundamental frequency erroneously credited observed partials appears ghost sound 
harmonic amplitudes ghost sound smoothed likelihood re estimated irregularity spectrum decreases level smooth spectrum likelihood remains low 
table pitch error rates different smoothing algorithms 
applied smoothing algorithm random mixtures voices 
simulations results lot simulations run verify importance proposed spectral smoothness principle compare described algorithms 
table gives pitch error rates different spectral smoothing algorithms 
algorithms listed top order introduced 
row gives results straightforward iterative estimation separation approach smoothing 
label smooth refers simple smoothing amplitude envelope help mentioned sec 

min refers minimum algorithm implemented eq 

smooth min second algorithm eq 

stat min third algorithm utilizing statistical dependencies partials 
random mixtures generated way described sec 

musical mixtures different pitch relations favoured statistical profile discovered krumhansl classical western music 
simulations pitch estimation took place single ms time frame ms onsets sounds 
correct pitch defined ate half semitone correct value 
important observation spectral smoothing remarkable improvement mpe accuracy 
third algorithm slightly consistently best far complicated 
second algorithm simple implement achieves performance 
shows multipitch estimation results different polyphonies stat min algorithm 
bars represent error rates function polyphony error rate random voice polyphonies average 
different shades grey bar indicate error cumulation iteration errors occurred iteration bottom 
system works reliably exhibits graceful degradation increasing polyphony abrupt breakdown point 
predicted analysis sec 
musical mixtures generally difficult resolve 
difference big indicating spectral smoothing works 

musical mixtures voices smooth min st smooth min nd stat min rd spectral smoothness principle proposed efficient new mechanism mpe sound separation 
idea corrected approximately half errors occurring identical system smoothness principle 
result mpe performed quite accurately wide pitch range priori knowledge sound sources involved 
underlying assumption spectral pitch error rate random mixtures pitch error rate polyphony polyphony fig 

pitch error rates multipitch estimation different polyphonies 
bars represent error rates different shades gray error cumulation iteration 
envelopes natural sounds continuous hold smoothing operation done noticeable loss information mpe viewpoint 

bregman 
auditory scene analysis mit press 
rabiner cheng rosenberg 

comparative performance study pitch detection algorithms ieee trans 
acoust speech signal processing vol assp 
klapuri 

automatic transcription music msc thesis tampere university technology 
martin 

automatic transcription simple polyphonic music robust front processing massachusetts institute technology media laboratory perceptual computing section technical report 
kashino kinoshita tanaka 

organization hierarchical perceptual sounds music scene analysis autonomous processing modules quantitative information integration mechanism proc 
international joint conf 
artificial intelligence montr goto 

robust predominant estimation method real time detection melody bass lines cd recordings proc 
ieee international conf 
acoust speech signal processing istanbul turkey 
brown cooke 

perceptual grouping musical sounds computational model new music research 
brown 

blackboard architecture computational auditory scene analysis speech communication 
de cheveign kawahara 

multiple period estimation pitch perception model speech communication 


periodicity transforms ieee trans 
signal processing vol 

klapuri holm 

robust multipitch estimation analysis manipulation polyphonic musical signals 
proc 
cost conference digital audio effects italy 
meddis hewitt 

virtual pitch phase sensitivity computer model auditory periphery 
pitch identification acoust 
soc 
am 

krumhansl 

cognitive foundations musical pitch oxford university press new york 
musical mixtures publication klapuri astola efficient calculation physiologically motivated representation sound proc 
th ieee international conference digital signal processing santorini greece 
ieee 
reprinted permission proc 
th ieee international conference digital signal processing 
personal material permitted 
permission reprint republish material creating new collective works resale redistribution servers lists reuse copyrighted component works obtained ieee 
efficient calculation physiologically motivated representation sound klapuri jaakko astola tampere university technology box fin tampere finland cs tut fi algorithm proposed calculates computationally efficient approximation certain physiologically motivated representation sound called summary autocorrelation function 
representation useful tasks sound separation multiple period estimation computational auditory scene analysis 
computationally complex practical applications 
relatively fast algorithm described proposes approximation summary autocorrelation function achieved precision applications 

human auditory system amazingly efficient analyzing complex acoustic environments 
enables perceive recognize simultaneously occurring sounds easily sounds separately 
performing analysis acoustic signals algorithms important data representations 
analysis viewed hierarchy representations acoustic signal conscious percept 
usually directly deduced acoustic input intermediate mid level representations indispensable 
know little exact mechanisms brain wider consensus mechanisms physiological peripheral part hearing 
precise auditory models exist able calculate certain fundamental mid level representations hearing signal auditory nerve 
correlogram widely accepted generic valid mid level representations 
models physiology hearing plus psychoacoustic mechanisms calculated follows 
input signal passed bank bandpass filters represent frequency selectivity inner ear 

signal frequency channel half wave rectified lowpass filtered 

periodicity estimation channels done calculating short time autocorrelation functions acf 

periodicity estimates aggregated channels obtain summary autocorrelation function defined st rt rt autocorrelation function time frame frequency channel calculations produce dimensional volume dimensions time ii frequency iii acf lag 
correlogram proved generic efficient mid level representation audio analysis easy see computationally complex data intensive number frequency channels different models varies 
data easily solved analyses performed marginal functions rough spectral envelope rt summary autocorrelation function 
rough spectral envelope forms basis sound source recognition speech recognition efficient methods exist calculate 
remains computational nightmare valuable tasks sound separation multiple period estimation computational auditory scene analysis 
particular models db 
dashed line flex solid line filter responses function shown reproduce wide range characteristics human pitch perception 
propose efficient method calculate approximation frequency domain 
approximation achieved noted sound synthesis indicate perceptually relevant data highest peak indicating pitch period 
analysis applications precision approximation far sufficient 

auditory filterbank auditory frequency analyzer usually modeled bank overlapping linear bandpass filters 
equivalent rectangular bandwidths erb auditory filters measured listening tests calculated erb 
center frequency bandwidth herz units 
important characteristics auditory filterbank auditory filters approximately uniformly distributed logarithmic frequency scale bandwidths eq 
number filters large adjacent filters overlap 
exact shape response individual filters modeled rounded exponential filters relative distance center frequency parameter determining bandwidth filter 
response illustrated dashed line fig 

pg epg fc 
fast approximation starting point performing described correlogram calculations efficiently analyze calculation phases frequency domain 
inevitably leads processing 
serious problem autocorrelation function calculations involved con calculations practice performed core idea fast approximation observation frame frame basis allow fft acf computations 
denote complex valued discrete fourier transform length frame acoustic input signal 
discrete frequency variable efficient iterative update rules exist calculate vc vc 
need initialize vc iteratively calculate vc channels update rules described 
spectrum calculations calculated straightforwardly eq 
frequency domain manner faster conven particular value computations proceed tional calculations fast way shown 
update rules exist certain family bandpass fil phase band pass filtering 
filtering linear ters exponential filters defined 
bandpass filter hc equivalent multiplying frequency response filter xc hc phase rectification lowpass filter 
bank exponential bandpass filters center frequencies erb bandwidths bank filing 
non linear operation essentially important part correlogram model 
narrowband signal xc centered fc generates spectral components bands centered zero frequency fc integer multiples fc upper limit see standard analyses 
ters hc considered rest follows 
channel index goes size time frame 
center frequency filter channel filter corresponding positive frequency sample 
erb bandwidths channel shown desirable properties due fre obtained eq 
frequency sample units quency bands centered zero frequency fc higher frequency components called harmonic distortion spectrum unnecessary cause inevitable aliasing discrete signals 
calculate spectrum wc rectified signal channel aliasing distortion spectrum rejected 
shown spectral region generated band zero frequency scaled version spectrum generated squaring signal harmonic distortion spectrum ignored causes error smaller center frequency 
spectrum fc output turn input narrowband signal xc model spectrum rectified signal channel xc 
wc wc real valued 
desired distribution frequency bands linear different channels sum eq 
weighted correspond arbitrary distribution channels weights corresponding distribution 
define exponential flex filter unity response center frequency followed exponentially decaying magnitude response away center frequency 
response illustrated fig 

slope attenuation filter hc exp vc spectrum squared time domain signal written lowpass filtered pass band zero frequency fc standard deviation signal channel easy verify approximation 
parameter half width top solved requiring erb bandwidths flex filters equal parameter writing squaring time domain equivalent convolution fre integrals squares responses equal quency domain write hc hc fc 
vector complex conjugate 
phase channel periodicity extraction 
solve pc wc function eq 
written wc hc exp wc wc 
convolved response relation function calculation time domain equivalent calculating square absolute value fourier spectrum channel calculated convolution shown eq 

denote terms eq 
transform signal 
fourier transform rc ofthe autocorrelation function rc rectified signal frequency channel obtained convolved response channel rc xc 
phase channel aggregation periodicity estimates 
summary autocorrelation function calculated time domain eq 

fourier transform inverse linear operations sum rc frequency domain obtain fourier transform sk rc perform single inverse fourier transform obtain summary autocorrelation function 

observation leads fast implementation frequency domain calculations essentially faster conventional ones 
include computationally intensive operation spectral convolution obtain spectrum rectified signal vc 
jc hc hc 
substituting eqs 
eq 
observing spectrum conjugate symmetric real signals limit sum positive frequencies write eq 
jc 
term common frequency channels 
term jc varies channel 
conjugate symmetry applies need calculate eq 
assume convolved response jc different types depending tops flex responses overlap shown fig 

type wc type ii 
general form consisting parts denoted fig 

type type ii 
different types convolved responses 
convolved response defined piecewise jc jc jc ka ka kb kb kd kd ke ke formula parts convolved response jc calculated substituting flex response eq 
eq 

resulting expressions types part denote type type ii 
formulae jc exp wc jc exp wc jc jc exp wc jc exp wc discrete boundaries ka kb kc kd ka wc kb wc kb wc kd wc kd wc ke wc formulas limits kb kd different response types seen 
sum eq 
written example calculated kb jc ka 
update formulas calculate efficiently part calculated iteratively constant time simple operations 
update rules similar different parts suffices thoroughly explain part part illustrated fig 

part algorithm calculate eq 
fixed multiply exp vc add jc kb kb subtract 
update rules calculate initializations 
calculate eq 
set determine type response calculate corresponding boundary values ka kb iterative calculation step 
store current boundaries step 
set calculate corresponding new response type boundaries 
step 
set real number determined 
step 
add new value remember captured kb step 
recall subtract old value cumulative sum step 
return step 
update rules embodied algorithm illustrated fig 

rule increases sum multiplied factor exp making old values exponentially leak sum get away center frequency 
secondly boundary kb changes new value included sum eq 

third rule sample removed sum case boundary ka changes 
know exactly factors sample multiplied belonging sum calculated value factor sample included sum 
cumulative effect repeated multiplying values exp exp ka ka kb kb exp vc kb kb jc kb kb kb ka ka efficiently solved cumulative sum 
values remain solved 
emphasized constants time frames need initialized 
writing reveals value lead exact update rule exist wc slope attenuation changes function approximation derived starting value realizes slope attenuation current wc 
reading eq 

step force attenuation caused successive multiplications reach db level exactly distance ideal response force db bandwidth convolved response ideal 
ideal db point writing easily solved 
find center frequency boundary kb assuming response type value got eq 

realized attenuation point successive multiplications denoted value ab ka jc ka exp jc ka jc exp jc wc jc jc exp ab calculated integrating yielding ab ln wc 
formula works desired db bandwidth obtained correction term desired attenuation divided realized 
part similar 
update rules applied values drop sum 
iteration simply slope attenuation part twice steeper part new values added ka changes 
part calculations analogous part numerical reasons essentially important start calculate decreasing values update rules analogous part values determined procedure 
part exact update rules written types convolved response 
level top type ii decreases bandwidth wc itis numerically advantageous perform calculations decreasing values starting 
response type may change way 
initializations 
set determine type type response calculate boundaries kb kd initialize eqs 

iterative updating response type need take drop values boundaries kb kd change 
type ii previous type ii set solved exactly writing response type ii previous type set 
adding new values subtracting dropping values relatively easy summing area flat 
response vc obtained summing different parts shown eq 


including original spectrum eq 
spectrum signal channel added calculating acf spectrum eq 

easier 
spectra non overlapping terms eq 
squared independently summed 
fact terms squared summed late eq 

follows eq 
sum different bands 
channel density high channel distribution usually designed bands sum unity eq 
spectra need calculated 
log ab wc exp vc jc ka ka jk exp vc jc exp jc wc wc jc vc xc xc xc xc 
precision approximation illustrates spectral densities ideal convolved response jc thick curve iteratively calculated response thin curve close ideal error thick broken curve 
due iterative calculations bandwidth tends smaller desired left side center frequency vice versa 
error part zero separate plateaus error seen parts 
db hz 
spectral densities ideal convolved response thick realized response thin error lower curve 
signal noise ratios ideal response approximation calculated jc snr log jc difference ideal realized response 
snr values essentially independent center frequency frame length depend db db db db values wc wc wc respectively 
level error stays db level ideal response gets smaller type ii eq 
level error relation ideal gets higher 
simulation results shown precision spectrum order 
sample eq 
coincides different parts convolved responses frequency channels surrounding 
sample gets weighted parts resulting precision 
ec jc 
computational complexity complexity conventional way calculating correlogram km number frequency channels sum orders bandpass lowpass filters applied stands acf calculations fft 
method fft inverse ok log complex operations 
bandpass filtering rectifying signal bands calculate ok complex iterative process value 
complexity max log practical safe value max frequency sample corresponding khz 
reasonable selections max complexity max log significantly smaller log 
ellis prediction driven computational auditory scene analysis phd thesis mit 
moore ed 
hearing 
handbook perception cognition nd edition academic press 
duda lyon slaney correlograms separation sounds proc 
ieee asilomar conf 
signals sys 
computers 
meddis hewitt virtual pitch phase sensitivity computer model auditory periphery 
pitch identification 
acoust 
soc 
am 
june 
wang brown separation speech interfering sounds oscillatory correlation ieee trans 
neural networks vol 
may 
klapuri multipitch estimation sound separation spectral smoothness principle proc 
ieee international conf 
acoust speech signal processing 
patterson moore auditory filters excitation patterns representations frequency resolution moore ed frequency selectivity hearing academic press london 
davenport root theory random signals noise ieee press 
publication klapuri multiple fundamental frequency estimation harmonicity spectral smoothness ieee trans 
speech audio proc 
ieee 
reprinted permission ieee trans 
speech audio processing 
personal material permitted 
permission reprint republish material creating new collective works resale redistribution servers lists reuse copyrighted component works obtained ieee 
ieee transactions speech audio processing vol 
november multiple fundamental frequency estimation harmonicity spectral smoothness new method estimating fundamental frequencies concurrent musical sounds described 
method iterative approach fundamental frequency prominent sound estimated sound subtracted mixture process repeated residual signal 
estimation stage algorithm proposed utilizes frequency relationships simultaneous spectral components assuming ideal harmonicity 
subtraction stage spectral smoothness principle proposed efficient new mechanism estimating spectral envelopes detected sounds 
techniques multiple fundamental frequency estimation performed quite accurately single time frame long term temporal features 
experimental data comprised recorded samples musical instruments different sources 
multiple fundamental frequency estimation performed random sound source pitch combinations 
error rates mixtures ranging simultaneous sounds respectively 
musical interval chord identification tasks algorithm outperformed average trained musicians 
method works robustly noise able handle sounds exhibit 
inharmonicity factor spectral envelope sound estimated fundamental frequency 
index terms acoustic signal analysis fundamental frequency estimation music music transcription pitch perception 
pitch perception plays important part human hearing understanding sounds 
acoustic environment human listeners able perceive pitches simultaneous sounds efficient pitch acoustically separate sound mixture 
computational methods multiple fundamental frequency estimation received attention algorithms available estimating single voice speech signals 
generally admitted algorithms appropriate multiple case 
sound certain pitch reliably matched adjusting frequency sine wave arbitrary amplitude 
pitch perceptual attribute sounds 
corresponding physical term defined periodic nearly periodic sounds 
classes sounds closely manuscript received november revised april 
supported graduate school tampere university technology foundation emil edist ti nokia foundation 
associate editor coordinating review manuscript approving publication dr sean 
author institute signal processing tampere university technology fin tampere finland mail cs tut fi 
digital object identifier tsa klapuri ieee related pitch defined inverse period time shift time domain signal shows high correlation 
cases fundamental period candidate closest subjective pitch period regarded correct 
musical signals natural candidates problem multiple estimation way speech signals natural candidates single estimation 
automatic transcription music aims extracting pitches onset times durations notes constitute piece 
multiple algorithms designed purpose transcribing polyphonic music sounds playing simultaneously 
attempts date back built system transcribing voice compositions 
continued chafe 
advances maher 
early systems suffered severe limitations regard pitch ranges relationships simultaneous sounds polyphony restricted concurrent sounds 
relaxation constraints attempted allowing errors occur transcription limitation carefully modeled instrument 
transcription systems recruited motivated analysis principles sophisticated processing architectures extended application area computational auditory scene analysis general 
kashino integrated signal analysis temporal musical predictions applying bayesian probability network 
martin utilized musical rules transcribing voice piano compositions 
front processing system performed log lag correlogram model human auditory periphery described 
goto introduce system works reasonably accurately real world complex musical signals finding melody bass lines 
multiple estimation closely related auditory scene analysis algorithm find sound get confused occurring sounds effect doing auditory scene analysis 
human auditory system accurate performing task imitation processing principles common inspired systems general relatively successful 
brown cooke built computational models human auditory processes addressed auditory grouping streaming musical sounds common acoustic properties 
brown proposed blackboard architecture integrate evidence different auditory organization principles demonstrated klapuri multiple fundamental frequency estimation harmonicity spectral smoothness model segregate melodic lines polyphonic music 
unitary model pitch perception proposed meddis hewitt strong influence estimation research 
karjalainen suggested simplified version unitary pitch model applied multiple estimation musical sounds 
de cheveign kawahara integrated model concurrent vowel identification model meddis hewitt developed approach estimation followed cancellation detected sound iterative estimation residual signal 
straightforward version iterative approach earlier proposed de cheveign :10.1.1.13.3300
periodicity transform method proposed bears close resemblance de purely mathematically formulated :10.1.1.13.3300
dynamic approach residue driven processing taken nakatani okuno 
system designed segregate continuous streams harmonic sounds voiced sections simultaneous speakers 
multiple agents deployed trace harmonic sounds input signals sounds subtracted input signal residual update parameters sound create new agents new sounds detected 
basic problems multiple estimator solve addition confronted single estimation 
calculated likelihoods weights different candidates affected presence occurring sounds 
achieve multiple algorithms typically decompose incoming signals smaller elements selectively calculate weight candidate 
example methods trace sinusoidal components group sound sources individual attributes harmonic relationships synchronous changes components 
algorithms apply comb filtering time domain select harmonically related components :10.1.1.13.3300
systems employed auditory models break incoming sound subchannel signals perform periodicity analysis channels 
second place correct detected highest weights assigned half twice correct value 
effect detected cancelled harmonics deciding 
algorithms perform manipulating calculated weights directly 
methods estimate spectrum detected sound subtract mixture iterative fashion process joint estimation cancellation pursuit :10.1.1.13.3300
scheme similar analysis synthesis techniques parametric coding example sinusoidal components detected modeled subtracted input order minimize residual signal 
aim propose multiple analysis method operates level single time frame applicable sound sources diverse kinds 
automatic transcription music seen important application area im wide pitch range varying tone colors particular need robustness presence harmonic noisy sounds 
overview proposed system illustrated fig 

method operates iteratively estimating removing prominent mixture signal 
term predominant estimation refers crucial stage prominent sound estimated presence harmonic noisy sounds 
achieve harmonic frequency relationships simultaneous spectral components group sound sources 
algorithm proposed able handle sounds 
sounds frequencies partials harmonics exact integer ratios 
subsequent stage spectrum detected sound estimated subtracted mixture 
stage utilizes spectral smoothness principle refers expectation spectral envelopes real sounds tend slowly varying function frequency 
words amplitude harmonic partial usually close amplitudes nearby partials sound 
estimation subtraction steps repeated residual signal 
review discussion earlier iterative approaches multiple estimation :10.1.1.13.3300
psychoacoustic evidence favor iterative approach 
motivation practical engineering applications psychoacoustics seen essential base analysis principles 
proposed algorithm able resolve couple prominent rich polyphonies 
reliable estimation carried cases signal corrupted high levels additive noise wide frequency bands missing 
non ideal sounds exhibit handled 
applications facilitated comprise transcription tools musicians transmission storage music compact form new ways searching musical information 
organized follows 
section ii describe different elements algorithm fig 

include preprocessing harmonicity principle smoothing detected sounds estimation number concurrent sounds 
section iii describe experimental results compare performance methods human listeners 
section iv summarize main discuss 
ii 
proposed multiple estimation method section look necessary elements required multiple estimation task illustrated fig 

section ii describe preprocessing stage necessary achieve robustness additive noise handle sounds uneven spectral shapes 
main principle harmonic relationships discussed section ii 
section ii describe smoothing algorithm needed subtract detected sound mixture remaining sounds corrupted 
subsection propose mechanism control stopping iterative estimation cancellation process 
ieee transactions speech audio processing vol 
november fig 

overview proposed multiple estimation method 
preprocessing calculations proposed system take place frequency domain 
discrete fourier transform calculated hamming windowed frame acoustic input signal sampled khz rate quantized bit precision 
frame lengths ms ms simulations 
may long speech processing point view long musical chord identification tasks 
tasks pitch range wide mixtures low sounds produce dense sets frequency partials precision required distinguish adjacent notes see appendix 
preprocessing spectrum actual multiple analysis important factor performance system 
provides robustness additive noise ensures sounds varying spectral shapes handled 
signal model assumed proposed system discrete power spectrum incoming acoustic signal power spectrum vibrating system fundamental frequency measured 
factor represents frequency response operating environment body musical instrument filters signal vibrating source 
elimination referred pre whitening 
term represents power spectrum additive noise 
music signals additive interference mainly due transient sounds drums percussive instruments 
principle additive noise suppressed performing spectral subtraction power spectral domain 
effect turn suppressed highpass log magnitude spectrum 
confirming reports earlier authors noise reduction systems cascade produce appropriate results 
successful noise suppression achieved applying magnitude warping equalizes allowing additive noise linearly subtracted result 
power spectrum magnitude warped term defined :10.1.1.117.6291
frequency indices correspond frequencies hz khz respectively determined frequency range utilized multiple estimator 
exact formula calculating critical general idea represented 
reasonable assumptions 
amplitudes important frequency partials additive noise secondly assumed majority frequency components correspond additive noise floor spectral peaks case scales input spectrum level additive noise stays close unity spectral peaks vibrating system noticeably unity 
follows additive noise goes linear magnitude warping transform spectral peaks go logarithmic transform 
response efficiently flattened logarithmic transform subsequent processing takes place warped magnitude scale 
additive noise suppressed applying specific spectral subtraction 
moving average calculated logarithmic frequency scale linearly subtracted exactly local averages calculated octave bands constraining minimum bandwidth hz lowest bands 
bandwidths subsequent calculations motivated frequency resolution human auditory system practical experiments generated mixtures musical sounds noise 
logarithmic frequency scale clearly advantageous linear scale balances amount spectral fine structure different 
estimated spectral average linearly subtracted resulting negative values constrained zero preprocessed spectrum passed multiple estimator 
harmonicity principle section predominant estimation part algorithm described 
process proposed organizes mixture spectra utilizing harmonic relationships frequency components assuming ideal harmonicity 
fundamentally different approaches estimation proposed 
category algorithms measures periodicity time domain signal 
methods typically calculating time domain autocorrelation function cepstrum representation 
shown theoretically equivalent matching pattern frequency partials harmonic positions sound spectrum 
explicit way building idea perform harmonic pattern matching frequency domain 
category algorithms measures periodicity frequency domain observing intervals frequency partials sound 
spectrum autocorrelation method variants successfully estimators 
interesting difference klapuri multiple fundamental frequency estimation harmonicity spectral smoothness time domain frequency domain periodicity analysis methods methods prone errors halving errors doubling 
time domain signal periodic half rate twice fundamental time delay spectrum periodic double rate 
third motivated group algorithms measures periodicity amplitude envelope time domain signal frequency channels 
major shortcoming earlier proposed methods handle sounds appropriately 
case real physical harmonic partials exact integral ratios 
example stretched strings frequency partial obeys fundamental frequency inharmonicity factor 
equation means partials assumed harmonic spectrum positions gradually shifted upwards spectrum 
great concern speech processing important analyzing musical sounds wide frequency band 
rest capital letter denote fundamental frequency lower case letter denote simply frequency 
proposed predominant estimation method works calculating independent estimates separate frequency bands combining results yield global estimate 
helps solve difficulties inharmonicity 
higher harmonics may deviate expected spectral positions intervals constant 
assume spectral intervals piecewise constant narrow frequency bands 
utilize spectral intervals step process calculates weights different separate frequency bands combines results manner takes inharmonicity account 
advantage bandwise processing provides robustness flexibility case badly corrupted signals fragment frequency range 
steps described 
bandwise estimation preprocessed spectrum analyzed bands distribute approximately logarithmically hz khz illustrated fig 

band comprises octave region spectrum constraining minimum bandwidth hz 
band subject weighting triangular frequency response shown fig 

overlap adjacent bands making response sum unity lowest bands 
response band denoted non zero frequency components defined frequency indices lowest frequency component band number components band 
fig 

magnitude responses frequency bands bandwise estimation takes place 
band algorithm calculates weight vector frequency indices 
note index corresponds fundamental frequency number samples time domain analysis frame sampling rate 
resolution weight vector preprocessed spectrum bandwise weights calculated finding series frequency components band maximizes sum offset series partials sum number partials sum normalization factor 
normalization factor needed varies different values form determined training isolated musical instrument samples varying noise conditions 
offset varied find maximum stored different offsets tested series higher harmonic partials may shifted due inharmonicity 
upper panel fig 
illustrates calculations single harmonic sound band hz hz 
arrows indicate series frequency components maximizes true 
values offset restricted physically realistic subset exact limit critical constant inharmonicity factor determine maximum allowable offset ideal harmonic positions 
harmonic index approximated follows fundamental partial exactly harmonic spectral position set considered highest partials 
words algorithm combines spectral positions lowest harmonic partials spectral intervals higher partials 
frequency band assumed contain harmonic partial sound fundamental frequency corresponding index inharmonicity allowed 
set reduces special case ieee transactions speech audio processing vol 
november fig 

calculation bandwise weight vectors 
follows case weights equal frequency limits band 
algorithm detailed table lower panel fig 
shows entire weight vector calculated band signal upper panel 
seen preprocessed spectrum appears corresponding band twice narrower copy octave range exactly harmonic partial band second partial 
lower candidates series higher band inharmonicity allowed 
case true hz assigned highest weight 
important property calculations selected frequency samples contribute weight spectrum 
occurring sounds affect weight extent partials overlap sound estimated solution overlapping partials section ii 
harmonic selection provides robustness sound mixtures long rely detection single partials case 
harmonic selection originally proposed parsons multiple algorithms described section integration weights subbands fig 
shows calculated weight vectors different bands isolated piano tones weight vectors arranged increasing band center frequency order 
expected maximum weight usually assigned true provided harmonic partial band 
inharmonicity phenomenon appears figs 
rising trend fundamental frequency 
bandwise weights combined yield global estimate 
straightforward summation weight vectors accumulate appropriately estimates different bands may match sounds seen fig 

overcome inharmonicity factor estimated taken account 
different inharmonicity models implemented mentioned 
simulations performance difference negligible 
model adopted 
global weights obtained summing squared bandwise weights selected different bands ac table algorithm calculating weights different band 
see text definition symbols cording curve determined 
search possible values conducted highest corresponding stored output 
squaring bandwise weights prior summing provide robustness presence strong interference pitch may perceptible limited frequency range 
global weights inharmonicity factors need calculated fundamental frequency indices set fundamental frequency indices collected bandwise weight vectors possible advantageous sound perceptible generally high weight bands 
selecting couple maxima band preserves correct fundamental frequency candidates 
maximum global weight determine true 
robust selec klapuri multiple fundamental frequency estimation harmonicity spectral smoothness fig 

bandwise calculated weights piano tones hz hz 
vectors displaced vertically clarity 
true pitches tones indicated dashed vertical lines 
tion candidates inspecting spectral smoothness highest global weights 
reason smoothing module fig 
storing 
module described detail section iii 
sake discussion section ii assume maximum global score determines predominant 
spectral smoothness principle iterative estimation separation method capable making robust predominant detections polyphonic signals 
inharmonicity factor precise frequencies harmonic partial detected sound produced 
natural strategy extending algorithm multiple estimation remove partials detected sound mixture apply predominant algorithm iteratively residual spectrum 
detected sounds separated frequency domain 
sinusoidal partial sound removed mixture spectrum stages 
estimates frequency amplitude partials obtained 
assumed parameters remain constant analysis frame 
second parameters spectrum vicinity partials estimated linearly subtracted mixture spectrum 
initial estimates frequency amplitude sinusoidal partial sound produced predominant detection algorithm 
efficient techniques estimating precise values proposed 
method widely adopted apply hamming windowing zero padding time domain calculate fourier spectrum quadratic interpolation spectrum partial 
second problem estimating spectrum vicinity partial equivalent translating magnitude spectrum original analysis window frequency sinusoidal partial 
hamming window zero padding sufficient perform subtraction adjacent frequency bins 
problem coinciding frequency partials issue addressed algorithm problem coinciding frequency partials 
illustrate problem simulations run iterative procedure randomly generated mixtures 
fig 
shows errors function musical intervals occur erroneously transcribed sound mixtures see appendix 
cases iterative approach works reliably 
important observation distribution errors fig 
analyzed 
error rate strongly correlated certain relations 
noted straightforward estimation subtraction approach fail cases fundamental frequencies simultaneous sounds simple rational number relations called harmonic relations 
indicated corresponding bars fig 

coinciding frequency partials different sounds cause algorithm fail partials coincide frequency 
sound detected removed coinciding harmonics remaining sounds corrupted subtraction procedure 
iterations remaining sound corrupted correctly analyzed iterations follow 
sinusoidal partials amplitudes phase difference coincide frequency amplitude resulting sinusoid calculated amplitudes roughly equivalent partials may amplify cancel depending amplitudes significantly greater usually case approaches maximum 
assuming ideal harmonicity straightforward prove harmonic partials sounds coincide fundamental frequencies sounds rational number relations 
harmonic indices coinciding partials partial sound coincides partial sound 
important principle western music pay attention pitch relationships simultaneously played notes 
simple harmonic relationships favored ones order sounds blend better 
harmonic relationships ieee transactions speech audio processing vol 
november fig 

distribution estimation errors function musical intervals occur erroneously transcribed sound mixtures 
common music worst cases handled general 
solve problem spectra detected sounds smoothed subtracting mixture 
consider preprocessed spectrum sound mixture fig 

harmonic partials sound coincide third harmonic sound predicted coinciding partials randomly cancel amplify low frequencies higher frequencies summary amplitudes approach maximum spectral envelope higher sound 
spectrum lower pitched sound smoothed thin slowly decreasing horizontal curve fig 
coinciding partials higher frequencies rise smooth spectrum remain residual subtraction 
particular solves common case dense harmonic series lower pitched sound matches partials higher pitched sound 
detecting higher pitched sound common case minority harmonics lower pitched sound deleted 
noted simply smoothing amplitude envelope thin curve fig 
sound subtracting mixture result lower error rates 
successful smoothing algorithm applying psychoacoustic knowledge 
full motivation approach scope 
algorithm calculates moving average amplitudes harmonic partials sound 
octave wide triangular weighting window centered harmonic partial weighted mean amplitudes partials window calculated 
smooth spectrum illustrated thin horizontal curve fig 

original amplitude value replaced minimum original values illustrated thick curve fig 

performing straightforward smoothing operation subtracting sound mixture reduces error rates significantly 
improvement smoothing method utilizing statistical dependency harmonic fig 

illustration spectral smoothness principle 
preprocessed spectrum containing sounds relation 
different smoothing operations estimate spectral envelope lower pitched sound 
results indicated thin thick horizontal curves 
partial previously explained section 
algorithm applies multistage filter steps 
indices harmonic partials harmonic collected octave wide window 
surrounding partials classified groups harmonics share common divisor put group starting smallest prime factors 
third weighted mean harmonic calculated inside groups manner described 
step estimates different groups averaged weighting group mean distance harmonic recalculation weights smoothing described principle smoothing provides efficient solution common class errors 
class errors fundamental frequencies specific relationships may cause detection nonexistent sound root musical chord absence 
instance harmonic sounds fundamental frequencies played spectra sounds match second third harmonic partial sound fundamental frequency frequency may erroneously estimated predominant calculations observed partials 
problem solved applying smoothing ordered search selecting candidate indices calculated predominant algorithm see section ii 
candidate highest global weight taken spectrum smoothed 
weight candidate recalculated smoothed harmonic amplitudes 
described case nonexistent sound irregularity spectrum decreases level smooth spectrum significantly weight remains low 
recalculated weight drops second highest weight klapuri multiple fundamental frequency estimation harmonicity spectral smoothness candidate processed continued 
highest recalculated global weight determines 
computational load applying smoothing recalculation select candidates negligible recalculation procedure consider value 
estimating number concurrent sounds mechanism needed controls stopping iterative estimation sound separation process 
leads estimation number concurrent sounds polyphony 
difficulty task comparable finding values 
studied musicians ability identify number concurrently sounding voices polyphonic textures 
report polyphonies test subjects underestimated number voices half cases 
statistical experimental approach taken solve problem 
random mixtures concurrent harmonic sounds generated sounds mcgill university master samples collection 
mixtures contaminated pink noise random drum sounds roland mk ii drum machine 
signal noise ratio varied db db 
behavior iterative multiple estimation system investigated artificial mixtures known polyphonies 
investigation decided split estimation task stages 
stage detects harmonic sounds input second estimates number concurrent sounds test indicated 
best single feature indicate presence harmonic sounds global weight winning candidate iteration 
best compound feature consists terms related signal noise ratio snr input signal discrete power spectrum input signal power spectrum estimated noise obtained applying inverse transform frequency indices 
signal determined contain harmonic sounds greater fixed threshold 
analysis frame determined contain harmonic sounds model estimate number sounds 
maximum global weight iteration best single feature controlling iteration stopping 
weight values affected snr getting smaller noise 
bias explicitly corrected resulting measure long value stays fixed threshold sound detected iteration accepted valid estimate iteration continued 
snr related terms different roles different signs 
iii 
results experimental setup simulations run validate proposed methods 
acoustic database consisted samples different sources 
mcgill university master samples collection independent recordings acoustic guitar available development phase system 
order verify results generalize outside data sets samples university iowa website studio online added final evaluation set 
altogether different musical instruments comprising brass reed instruments strings piano guitar 
introduce different sound production mechanisms variety spectra 
average pieces instruments different playing styles instrument 
total number samples 
randomly mixed generate test cases 
instruments excluded data set spectrum quite different extremely 
system admittedly handle sounds reliably 
sound mixtures generated different schemes 
random mixtures generated instrument random note playing range restricting pitch octaves hz hz 
desired number simultaneous sounds allotted mixed equal mean square levels 
musical mixtures generated similar manner favoring different pitch relationships statistical profile discovered krumhansl classical western music 
brief octave relationships frequent followed consonant musical intervals smallest probability occurrence intervals 
general musical mixtures difficult resolve see section ii 
acoustic input fed multiple algorithm estimated single time frame 
stated number extract polyphony mixture signal 
informative evaluate multiple estimator polyphony estimator separable tasks methods implement polyphony estimation 
configuration parameters system fixed stated 
correct estimate defined deviate half semitone true value making round correct note western musical scale 
errors smaller significant point view music transcription 
methods put results perspective methods baseline simulations 
method yin isa ieee transactions speech audio processing vol 
november state art monophonic estimator speech music signals 
naturally method baseline single analysis 
algorithm designed reliable individual analysis frames thoroughly tested compared methods 
original implementation authors employed parameters left intact absolute threshold value improve performance 
method referred tk multiple estimator proposed karjalainen 
implementation carefully prepared original code authors warped linear prediction part algorithm 
thorough testing carried verify implementation 
original parameters applied 
reported authors method handle spectral pitch khz 
method best detecting octave range hz hz 
simulations follow mixtures tk method restricted contain hz khz 
bound specified case simulation results follow 
experimental results experiment different estimators compared 
experiment predominant estimate firstly detected defined correct matches correct component sounds 
single match possible required error measure 
error rate calculated amount predominant errors divided number random sound mixtures number notes note mixtures 
estimation performed single ms time frame ms onset sounds 
fig 
shows error rates predominant estimation different polyphonies 
results proposed system systems 
proposed system error rates generally getting close note polyphonies 
surprisingly increasing number concurrent sounds appears help lower error rate detecting correctly 
due fact acoustic database contains small percentage irregular sounds simple model 
high flute tones high string tones 
sound mixtures contain clear sound appears predominant 
yin method achieves error rate isolated notes 
method intended multiple estimation fair comparison polyphonic signals 
single estimators algorithm converges error rate note mixtures 
tk method quite reliable single pitch signals works robustly polyphony 
method hz predominant detection accuracy comes close proposed system higher polyphonies 
partly due relatively higher random guess rate 
second experiment performance multiple estimation explored detail 
multiple estimation fig 

error rates detecting potential sound function predominant estimation algorithm polyphony 
appropriate error measure note error rate ner metric 
ner defined sum error divided number transcription 
errors types substitution errors 
defined errors detected estimated value differs 
deletion errors occurred number detected smaller number 
insertion errors occurred number detected exceeds 
substitution deletion errors counted number correctly estimated 
insertion errors counted number excessive estimates 
results multiple estimation different polyphonies shown fig 

number concurrent sounds extract mixture signal polyphony known 
insertion deletion errors occur 
random musical sound mixtures generated described schemes estimator requested find number single ms time frame ms onset sounds 
fig 
bars represent ner function polyphony 
seen ner random sound polyphonies average 
different shades gray bar indicate error cumulation iteration errors occurred iteration bottom errors iteration top 
general impression system works reliably exhibits graceful degradation increasing polyphony 
results musical mixtures slightly worse random mixtures see section ii difference great 
indicates spectral smoothing principle works resolving harmonically related pitch combinations 
analysis error cumulation reveals errors occurred iteration account approximately half errors polyphonies probability error increases rapidly course iteration 
indicating subtraction process perfectly conducted listening tests suggest feature problem symptom algorithms 
mixtures sound difficult perceive spectrum virtually hidden sounds 
method tk note error rates mixtures ranging sounds klapuri multiple fundamental frequency estimation harmonicity spectral smoothness fig 

note error rates multiple estimation proposed algorithm polyphony known 
bars represent error rates different shades gray error cumulation iteration 
respectively range hz khz 
octave range hz hz corresponding error rates 
complexity problem error rates low 
table ii gives error rates different system configurations 
different processing elements disabled order evaluate importance 
case system kept fixed 
test mechanisms accommodate inharmonicity disabled 
mechanism bandwise weight calculations case offset constrained value corresponds ideal harmonicity 
mechanism integration phase 
inharmonicity factor constrained zero leading straightforward summing squared weight vectors 
resulting performance degradation due bandwise calculations 
second test spectral smoothing algorithm switched section ii version leaves harmonic series intact 
smoothing operation significant improvement multiple estimation accuracy polyphonies single note case noticeable effect performance 
results polyphony signals known 
fig 
shows statistical error rate multiple estimation system polyphony estimated analysis frame described section ii 
results shown different polyphony estimation thresholds thresholds left right panels respectively 
depending application overestimating underestimating number concurrent sounds may harmful 
music transcription system example extraneous notes output disturbing 
frame level estimates processed higher level usually advantageous produce note candidates 
general proposed polyphony estimation method operates robustly 
estimation threshold tuned avoid extraneous detections monophonic signals polyphony underestimated higher polyphonies 
hand avoided table ii error rates different system configurations polyphony signals known fig 

error rates different polyphony estimations strategies 
extraneous appear monophonic signals 
characteristic problem see report mentioned section ii 
sounds rich polyphonies usually difficult distinguish 
table iii shows influence shortening analysis frame 
significant difference ms ms frame sizes partly caused fact applied technique able resolve required accuracy 
irregularities sounds vibrato difficult handle short frames 
time frame shortened ms ms error rate method tk increased approximately hz hz limits polyphonies 
error rates tk essentially fig 

performance clearly worse proposed method polyphony known obvious drawback proposed method accuracy depends length analysis frame 
basic reason linear frequency resolution spectral methods suffice low frequency resolution autocorrelation methods proportional inverse frequency closer logarithmic frequency resolution musical scales human hearing 
despite differences reliable multiple estimation general require longer time frames single estimation 
fig 
shows ner different types levels additive noise polyphony known 
pink noise generated band hz khz 
instrument interference generated randomizing drum samples roland mk ii drum machine 
test set comprised bass drum hi hat ieee transactions speech audio processing vol 
november table iii error rates different analysis frame lengths fig 

error rates additive pink noise left panel interfering percussive sounds right panel 
noise types error rates clean signal noisy signals snr db db db 
polyphony known 
sounds 
signal noise ratio adjusted analysis frame ratio defined noise sum harmonic sounds 
snr point view individual sounds worse higher polyphonies 
ms frame applied 
comparison human performance listening tests conducted measure human pitch identification ability particularly ability trained musicians transcribe polyphonic sound mixtures 
detailed analysis results scope article 
summary main findings reviewed 
test stimuli consisted computer generated mixtures simultaneously sounds reproduced sampled grand piano sounds mcgill university master samples collection 
number occurring sounds varied 
interval highest lowest pitch individual mixture wider semitones order task feasible subjects absolute pitch rare ability able name pitch sound tone 
mixtures generated pitch ranges registers low hz hz middle hz hz high hz hz 
total test comprised stimuli 
task write musical intervals pitch relations sound mixtures 
absolute pitch values asked number sounds mixture 
test resembles musical interval chord identification tests part basic musical training western countries 
fig 

chord error rates human listeners curves proposed algorithm bars different stimulus categories 
lowest curve represents skilled subjects middle curve average subjects highest curve clearly weakest subjects 
labels categories consist number signifies polyphony letter tells pitch range 
total subjects participated test 
trained musicians sense having taken years ear training music 
subjects students university level 
advanced musicians possessing absolute pitch exceptional pitch identification abilities 
subject amateur musician similar musical ability students 
fig 
shows results listening test 
chord error rates cer plotted different stimulus categories 
cer percentage sound mixtures pitch identification errors occurred 
labels categories consist number signifies polyphony letter tells pitch range 
letter refers middle high low register 
performance curves averaged different groups 
lowest curve represents skilled subjects middle curve average subjects highest curve clearly weakest subjects 
cer directly compared ner fig 

cer metric demanding accepting sound mixtures pitches correctly identified 
adopted unambiguously process musicians answers pitch intervals 
sake comparison stimuli performance criteria listening test evaluate proposed computational model 
instances generated category included fig 
software randomized samples listening test 
fed described multiple system 
cer metric performance measure 
results illustrated bars fig 

general impression skilled subjects perform better computational model 
performance differences high low registers quite revealing 
devised algorithm able resolve combinations low sounds ability human listeners 
due frequency resolution applied 
hand aim ear training music develop faculty discriminating sounds recognizing musical intervals playing music ear aid written music 
klapuri multiple fundamental frequency estimation harmonicity spectral smoothness human listeners perform relatively high register 
due efficient temporal features onset asynchrony different decay rates high piano tones 
available single time frame multiple algorithm 
iv 
shows multiple estimation performed reasonably spectral cues harmonicity spectral smoothness need additional long term temporal features 
variety musical sounds prior knowledge type sound sources involved necessary adaptation internal source instrument models presumably enhance performance 
primary problem multiple estimation appears associating partials correctly individual sources production 
harmonicity principle applied manner flexible accommodate realistic amount inharmonicity sound production constraining prevent erroneous groupings 
contrasted complexity needed handling inharmonicity harmonic summation model calculating weights amplitudes grouped partials simple embodied 
spectral smoothing approach proposed efficient new mechanism multiple estimation spectral organization 
principle corrected approximately half errors occurring system identical smoothness principle 
attractive property iterative estimation separation approach couple prominent detected rich polyphonies 
probability error increases rapidly course iteration basis listening tests suggested part due inherent characteristics problem 
iteration estimation sound detected accounts approximately half errors polyphonies 
main drawback method requires relatively long analysis frame order operate reliably low pitched sounds 
largely due fact processing takes place frequency domain sufficiently fine frequency resolution required harmonic series low pitched sounds 
described method applied automatic transcription continuous music cd recordings 
demonstration signals provided 
contrary musical chord identification task accuracy comparable trained musicians 
possibilities explored areas development 
integration multiple time frames improve performance 
independent multiple estimation time frame important feature extraction account real experience represented human listener 
analogous case speech recognition models words language improve performance higher level features music expected improve music estimation transcription tasks 
table iv basic musical intervals appendix western music typically uses tempered musical scale 
notes arranged logarithmic scale fundamental frequency note notes standard piano keyboard range term semitone refers interval adjacent notes measure musical intervals 
relation notes semitone apart tempered scale logarithmic surprisingly accurately generate rational number relations 
table iv lists basic musical intervals corresponding ideal rational number relations 
intervals approximate simple rational number relationships called harmonic consonant intervals opposed intervals 
bregman auditory scene analysis perceptual organization sound 
cambridge ma mit press 
rabiner cheng rosenberg comparative performance study pitch detection algorithms ieee trans 
acoust speech signal processing vol 
assp pp 

hess pitch voicing determination advances speech signal processing 
de cheveign kawahara comparative evaluation estimation algorithms proc 
eurospeech copenhagen denmark pp 

hartmann pitch periodicity auditory organization acoust 
soc 
amer vol 
pp 

transcription musical sound computer comput 
music pp 
nov 
chafe jaffe source separation note identification polyphonic music proc 
ieee int 
conf 
acoust speech signal processing tokyo pp 

maher evaluation method separating digitized signals audio eng 
soc vol 
pp 

inokuchi music system comput 
music vol 
pp 

hawley structure sound ph dissertation mit media laboratory cambridge ma 
rossi identification de sons de piano ph thesis universite de france 
rosenthal okuno eds computational auditory scene analysis 
mahwah nj lawrence erlbaum 
kashino kinoshita tanaka organization hierarchical perceptual sounds music scene analysis autonomous processing modules quantitative information integration mechanism proc 
int 
joint conf 
artificial intelligence montr qc canada 
ieee transactions speech audio processing vol 
november martin automatic transcription simple polyphonic music robust front processing massachusetts institute technology media laboratory perceptual computing section tech 
rep 
ellis prediction driven computational auditory scene analysis ph thesis mit media laboratory cambridge massachusetts 
goto robust predominant estimation method real time detection melody bass lines cd recordings proc 
ieee international conf 
acoust speech signal processing istanbul turkey june 
brown cooke perceptual grouping musical sounds computational model new music res vol 
pp 

brown blackboard architecture computational auditory scene analysis speech commun vol 
pp 

meddis hewitt virtual pitch phase sensitivity computer model auditory periphery pitch identification acoust 
soc 
amer vol 
pp 

meddis unitary model pitch perception acoust 
soc 
amer vol 
pp 

karjalainen computationally efficient multipitch analysis model ieee trans 
speech audio processing vol 
pp 
nov 
de cheveign kawahara multiple period estimation pitch perception model speech commun vol 
pp 

meddis hewitt modeling identification concurrent vowels different fundamental frequencies acoust 
soc 
amer vol 
pp 

de cheveign separation concurrent harmonic sounds fundamental frequency estimation time domain cancellation model auditory processing acoust 
soc 
amer vol 
pp 

periodicity transforms ieee trans 
signal processing vol 
pp 

nakatani okuno harmonic sound stream segregation localization application speech stream segregation speech commun vol 
pp 

parsons separation speech interfering speech means harmonic selection acoust 
soc 
amer vol 
pp 

verma perceptually audio signal model application scalable audio compression ph dissertation stanford university 
rabiner 
juang fundamentals speech recognition 
englewood cliffs nj prentice hall 
hermansky morgan 
hirsch recognition speech additive convolutive noise rasta spectral processing proc 
ieee int 
conf 
acoustics speech signal processing minneapolis minnesota 
klapuri automatic transcription musical recordings proc 
consistent reliable acoustic cues workshop aalborg denmark sep 
robust algorithm tracking speech coding synthesis paliwal eds science 
brown zhang musical frequency tracking methods conventional narrowed autocorrelation acoust 
soc 
amer vol 
pp 

klapuri qualitative quantitative aspects design periodicity estimation algorithms proc 
european signal processing conference tampere finland sept 
rodet estimation fundamental frequency musical sound signals proc 
ieee int 
conf 
acoust speech signal processing pp 

brown musical fundamental frequency tracking pattern recognition method acoust 
soc 
amer vol 
pp 

spectral autocorrelation method measurement fundamental frequency noise corrupted speech ieee trans 
acoust speech signal processing vol 
assp pp 

suzuki robust method measurement fundamental frequency autocorrelation log spectrum proc 
ieee int 
conf 
acoust speech signal processing pp 

pitch perception hearing handbook perception cognition moore ed 
san diego ca academic 
fletcher physics musical instruments nd ed 
new york springer verlag 
klapuri wide band pitch estimation natural sound sources proc 
th audio eng 
soc 
convention munich germany 
rodet musical sound signal analysis synthesis sinusoidal residual elementary waveform models proc 
ieee time frequency time scale workshop coventry aug 
klapuri multipitch estimation sound separation spectral smoothness principle proc 
ieee int 
conf 
acoust speech signal processing pp 

voice polyphonic music homogeneous timbres music perception vol 
pp 
summer 
mcgill university master samples montreal qc canada mcgill university 
university iowa musical instrument music uiowa edu online studio fr online krumhansl cognitive foundations musical pitch 
new york oxford univ press 
de cheveign kawahara yin fundamental frequency estimator speech music acoust 
soc 
amer vol 
april 
automatic transcription music demonstrations klapuri www cs tut fil online klapuri born finland 
received sc 
degree information technology tampere university technology tut tampere finland june 
currently pursuing postgraduate degree 
tut institute signal processing 
research interests include automatic transcription music audio content analysis signal processing 
publication klapuri astola automatic estimation meter acoustic musical signals tampere university technology institute signal processing report tampere finland 
revised version report appear ieee trans 
speech audio processing klapuri astola analysis meter acoustic musical signals ieee 
personal material permitted 
permission reprint republish material creating new collective works resale redistribution servers lists reuse copyrighted component works obtained ieee 
automatic estimation meter acoustic musical signals klapuri antti jaakko astola tampere university technology institute signal processing fin tampere finland tel fax mail cs tut fi method estimates basic pattern beats piece music musical meter 
analysis performed jointly different time scales temporally atomic tatum pulse level tactus pulse level corresponds tempo piece musical measure level 
acoustic signals arbitrary musical genres considered 
initial time frequency analysis new technique proposed measures degree musical accent function time different frequency ranges 
followed bank comb filter resonators perform feature extraction estimating periods phases pulses 
features processed probabilistic model represents primitive musical knowledge uses low level observations perform joint estimation tatum tactus measure pulses 
model takes account temporal dependencies successive estimates enables causal noncausal estimation 
method validated manually annotated database musical signals various genres 
method works robustly different types music improves state art methods simulations 
keywords acoustic signal analysis music musical meter estimation music transcription 
meter analysis essential part understanding music signals innate cognitive ability humans musical education 
perceiving meter characterized process detecting moments musical stress accents acoustic signal filtering underlying periodicities discovered 
example tapping foot music indicates listener abstracted metrical information music able predict beat occur 
musical meter hierarchical structure consisting pulse sensations different levels time scales 
metrical levels considered 
prominent level tactus referred foot tapping rate beat 
terminology word beat refer individual elements pulse 
musical meter illustrated fig 
dots denote beats sequence dots corresponds particular pulse level 
period pulse mean time duration successive beats phase time beat occurs respect piece 
tatum pulse name stemming temporal atom 
period pulse corresponds shortest durational values music incidentally encountered 
durational values exceptions integer multiples tatum period onsets musical events occur approximately tatum beat 
musical measure pulse typically related harmonic change rate length rhythmic pattern 
ambiguous metrical levels relatively defined span metrical hierarchy important levels 
tempo piece defined rate tactus pulse 
order meter sense musically pulse periods beat larger levels coincide beat smaller levels 
concept phenomenal accent important meter analysis 
phenomenal accents events give emphasis moment music 
beginnings discrete sound events especially onsets long pitch events sudden changes loudness timbre harmonic changes 
lerdahl jackendoff define role phenomenal accents meter perception compactly saying moments musical stress raw signal serve cues listener attempts extrapolate regular pattern 
automatic estimation meter applications 
temporal framework facilitates cut paste operations editing music signals 
enables synchronization light effects video electronic instruments drum machine 
disc application metrical information mark boundaries rhythmic loop synchronize percussive audio tracks 
meter estimation symbolic midi data required time quantization indispensable subtask score typesetting keyboard input 
tatum tactus measure time seconds fig 

musical signal metrical levels illustrated 

musical instrument digital interface 
standard interface exchanging performance data parameters electronic musical devices 
previous automatic meter analysis originated algorithmic models tried explain human listener arrives particular metrical interpretation piece meter explicitly spelled music 
early models performed meter estimation symbolic data artificial impulse pattern musical score 
brief models seen set rules define musical accents infer natural meter 
rule system proposed lerdahl jackendoff complete described verbal terms 
extensive comparison early models lee augmented desain honing 
parncutt proposed detailed quantitative perceptual model systematic listening tests 
brown performed metrical analysis musical scores autocorrelation function notes weighted durations 
large kolen associated meter perception resonance proposed entrainment oscillator adjusts period phase incoming pattern impulses located onsets musical events 
rosenthal aimed emulating human rhythm perception realistic piano performances midi files 
notable system auditory organization functions taken account grouping notes streams chords 
rosenthal applied set rules rank prune competing meter hypotheses conducted beam search track multiple hypotheses time 
beam search strategy originally proposed pulse tracking allen dannenberg 
temperley proposed meter estimation algorithm arbitrary midi files implementing preference rules verbally described 
dixon proposed rule system track tactus pulse expressive midi performances introduced simple onset detector system applicable audio signals 
source codes temperley dixon systems publicly available 
cemgil kappen developed probabilistic generative model timing deviations expressive musical performances :10.1.1.13.3300
model infer hidden continuous tempo variable quantized ideal note onset times observed noisy onset times midi file 
tempo tracking time quantization performed simultaneously balance smoothness tempo deviations versus complexity resulting quantized score 
similar probabilistic bayesian model independently proposed raphael 
goto muraoka meter tracking system works reasonable accuracy audio signals 
popular music considered 
system operates real time architecture multiple agents track alternative meter hypotheses 
beat positions larger levels inferred detecting certain drum sounds chord changes 
gouyon proposed system detecting tatum pulse percussive audio tracks constant tempo 
straight forward probabilistic model estimate tempo swing audio signals 
scheirer proposed method tracking tactus pulse music signals kind provided strong beat 
important scheirer approach detect discrete onsets sound events middle step performed periodicity analysis directly half wave rectified differentials subband power envelopes 
source codes scheirer system publicly available 
meter estimator resembles scheirer method difference periodicity transform periodicity analysis bank comb filters 
summary earlier meter estimation concentrated symbolic midi data typically analyzed tactus pulse 
systems immediately extended process audio signals employing onset detector extracts beginnings discrete acoustic events audio signal :10.1.1.13.3300
authors introduced onset detector 
onset detection methods proposed subband energies auditory model support vector machines neural networks independent component analysis unpredictability 
meter estimator originally developed symbolic data extended system usually robust diverse acoustic material classical vs rock music fully utilize acoustic cues indicate phenomenal accents music signals 
basic problems meter estimator address successful 
degree musical accentuation function time measured 
case audio input initial time frequency analysis closely related problem onset detection 
systems measure accentuation continuous manner extract discrete events 
secondly periods phases underlying metrical pulses estimated 
methods detect discrete events middle step interval histograms purpose 
thirdly system choose metrical level corresponds tactus specially designated pulse level 
may take place implicitly prior distribution pulse periods rhythmic pattern matching 
tempo halving doubling symptom failing 
proposed method aim develop method estimating meter acoustic musical signals tactus tatum measure pulse levels 
target signals limited particular music type main genres including classical music represented validation database 
particular motivation utilize metrical information signal analysis classification 
swing characteristic musical rhythms commonly jazz 
swing defined systematic slight delay second fourth quarter beats 
music signal analysis vc probabilistic comb filter model resonators pulse periods periods filter states phase model phases meter fig 

overview meter estimation method 
intermediate data representations accent signals vc metrical pulse strengths exactly music transcription 
overview method shown fig 
analysis part new technique proposed aims measuring degree accentuation acoustic signals 
technique robust diverse acoustic material seen synthesis generalization earlier state art methods 
feature extraction pulse period phase analysis performed comb filter resonators similar scheirer 
followed probabilistic model tactus tatum measure pulses jointly estimated temporal continuity estimates modelled 
time instant periods pulses estimated act inputs phase model 
probabilistic models encode prior musical knowledge lead reliable temporally stable meter tracking 
causal noncausal algorithms 
organized follows 
section ii describe different elements system 
section iii experimental results compare proposed method systems 
section iv summarize main discuss 
ii 
meter analysis model section describe different parts meter estimation method illustrated 
subsection describe time frequency analysis part produces measure musical accent function time 
subsection comb filter resonators introduced 
subsections describe probabilistic models estimate periods phases pulse levels 
calculation accent signals phenomenal accent types mentioned observed time frequency representation signal 
analysis model human auditory system theoretically better manage obtain performance advantage model similar 
computational complexity models impractical 
time frequency plane representation data reduction take place discard information irrelevant meter analysis 
big step forward respect taken combine scheirer demonstrated perceived rhythmic content music types remains subband power envelopes preserved modulate white noise signal 
number approximately subbands reported suffice 
scheirer proposed method periodicity analysis carried subbands results combined bands 
scheirer method successful problem applies primarily music strong beat 
harmonic changes classical vocal music go easily unnoticed subband envelopes 
detect harmonic changes note beginnings passages approximately logarithmically distributed subbands needed leads dilemma resolution sufficient distinguish harmonic changes measuring periodicity narrow subband separately appropriate 
power envelopes individual narrow bands guaranteed reveal correct metrical periods show periodicity individual events may occupy different frequency bands 
overcome problem consider state ofthe art system goto muraoka 
detect narrowband frequency components sum power differentials frequency ranges onset detection periodicity analysis takes place 
advantage harmonic changes detected periodicity analysis takes place wider bands 
continuum approaches 
tradeoff adjacent subbands combined periodicity analysis stage bandwise periodicity analysis results combined 
propose method seen synthesis approaches scheirer goto acoustic input signals sampled khz rate bit resolution normalized zero mean unity variance 
discrete fourier transforms calculated successive ms time frames hanning windowed overlap 
frame triangular response bandpass filters simulated 
filters uniformly distributed equivalent rectangular bandwidth critical band scale hz khz 
power band calculated stored xb frame index band index exact number subbands critical 
potential ways measuring degree change power envelopes critical bands 
humans smallest detectable change intensity approximately proportional intensity signal amount increase prominent quiet signal 
weber fraction perceptually approxi mately constant 
relationship holds intensities db db absolute threshold 
reasonable normalize differential 
smooth connected style playing perceptible gaps left notes 

case center frequencies approximately tone apart distance notes output input fig 

law compression getting values starting lowest curve 
power power 
leads equal measures spectral change seen approximation differential loudness perception loudness steady sounds proportional sum log powers critical bands 
logarithm differentiation operations represented flexible form 
numerically robust way calculating logarithm law compression performs nonlinear mapping values zero values zero 
constant close linear close logarithmic transformation illustrated fig 
value employed value range dt xb xb dt ln xb ln xb yb ln xb yb valid 
achieve better time resolution compressed power envelopes yb interpolated factor adding zeros samples 
leads sampling rate hz 
sixth order butterworth lowpass filter lp hz cutoff frequency applied smooth compressed interpolated power envelopes 
resulting smoothed signal denoted zb differentiation zb performed follows 
half wave rectified differential zb calculated zb zb zb maps negative values zero essential differentiation useful 
weighted average zb differential zb formed ub zb lp zb factor lp roughly compensates fact differential lowpass filtered signal small amplitude 
value slight consistent positive impact performance system 
illustrates described dynamic compression weighted differentiation steps artificial subband power signal xb motivated purely practical application point view interesting note graphs fig 
bear considerable resemblance response meddis auditory nerve model acoustic stimulation 
adjacent bands linearly summed get xb ub time time fig 

illustration dynamic compression weighted differentiation steps artificial signal 
upper panel shows xb lower panel shows ub signals call accent sig cm vc ub 
accent signals serve middle level representation musical meter estimation 
represent degree musical accent function time frequency channels leading noted combining adjacent bands stage primarily issue computational complexity improves analysis accuracy 
prototypical meter estimation system thoroughly investigate effect different values surprisingly turned extreme values optimal large number initial channels channels leads reliable meter estimation 
system parameters re estimated case ensure merely symptom parameter couplings 
form calculating accent signals flexible varying representation similar scheirer obtained setting 
representation roughly similar goto obtained setting 
fixed values 
bank comb filter resonators periodicity accent signals analyzed estimate salience weight different metrical pulse period candidates 
resembles idea vc vc computation midi data 
different period estimation algorithms evaluated 
enhanced autocorrelation enhanced yin method de cheveign kawahara different types comb filter resonators banks 
defined time interval events certain range pitch 
considered factor musical accentuation 
phase locking resonators 
enhancing refers postprocessing step needed final method explained 
important observation period estimation methods performed equally thorough optimization 
suggests key problems meter estimation measuring phenomenal accentuation modeling higher level musical knowledge finding exactly correct period estimator 
period estimation method selected complex best performing algorithms earlier 
bank comb filter resonators constant originally proposed tactus tracking scheirer 
comb filters exponentially decaying impulse response half time refers delay response decays half initial value 
output comb filter delay input vc rc rc vc feedback gain calculated selected half time fr seconds short react tempo changes long reliably estimate pulse periods seconds length 
scheirer seconds attempt track measure pulse 
comb filters implement frequency response frequencies unity response maximum attenuation peaks power comb filter feedback gain calculated integrating squared impulse response yields 
bank resonators applied getting values max max corresponds seconds 
computational complexity resonator input sample resonator filterbank requires order operations second computationally demanding real time application 
instantaneous energies comb filter channel time calculated 
normalized obtain energy accent signal calculated squaring applying leaky integrator resonator half time resonators 
normalization applied compensate differences power responses different proposed normalization advantageous preserves unity response peak frequencies time removes dependent trend white noise input 
shows resonator energies max rc sc vc vc energy normalized energy normalized energies sc types artificial input vc impulse train white noise signal 
important notice resonators relations period impulse train samples show response 
case autocorrelation function example integer multiples come explicit postprocessing step enhancing necessary generate responses lags achieve meter estimation performance 
step needed comb filter resonators 
function represents saliences different metrical pulses time obtained sc 
function acts observation probabilistic model estimates pulse periods 
tatum period estimation discrete power spectrum calculated max max emphasis removes spectral trend window function half hanning cos max max 
frequencies hz discarded rationale calculating discrete fourier transform dft definition pulse periods integer multiples tatum period 
function contains information tatum conveniently gathered tatum frequency candidate 
gouyon histogram maher way mismatch procedure purpose 
idea find tatum period best explains harmonically related peaks histogram 
noted observation spectrum zero phase meaning phases pulses different metrical levels estimated energy delay samples delay samples normalized energy delay samples delay samples fig 

resonator energies impulse train period length samples left white noise right 
upper panels show energies lower panels normalized energies sc max source information 
discussed subsection phases estimated states comb filters periods solved 
probabilistic model pulse periods period lengths metrical pulses estimated independently phases reasonable compute phase winning periods 
proposed method finds periods phases see fig 

estimating phases trivial search problem largely completed period lengths 
musical meter assumed static duration piece 
estimated causally successive time instants temporal tying successive estimates 
dependencies different metrical pulse levels taken account 
requires prior musical knowledge encoded probabilistic model 
period estimation hidden markov model describes simultaneous evolution processes constructed 
observable variable vector instantaneous energies resonators denoted sn 
unobservable processes tatum tactus measure periods 
corresponding hidden variables tatum period tactus period measure period mnemonic notation recall tatum temporally atomic pulse level tactus pulse called beat musical measure pulse related harmonic chord change rate 
convenience qn jkl denote meter state equivalent hidden state process time homogenous firstorder markov initial state distribution transition probabilities qn qn observable variable conditioned current state observation densities sn qn joint probability density state sequence qn observation sequence written qn qn sn qn term qn qn decomposed qn qn 
qn qn qn reasonable assume qn qn tactus period tatum period give additional information regarding measure period 
assume hidden variables time give additional information regarding follows written qn qn 
assumptions decomposed sim fig 

hidden markov model temporal evolution tatum beat measure pulse periods 

described modeling assumptions lead structure represented directed acyclic graph 
arrays graph represent conditional dependencies variables 
circles denote hidden variables observed variable marked boxes 
tactus pulse central role meter perception chance variables drawn depend 
assumption valid variables permuted 

estimation state conditional observation likelihoods remaining problem find reasonable estimates model parameters probabilities appear 
ignore time simplicity 
state conditional observation likelihoods sq estimated database musical recordings musical meter hand labeled 
data limited size compared number parameters estimated 
estimation state densities different jkl impossible discrete hidden variables take hundreds different values 
making series assumptions arrive approximation sq sq jkl sk sl 
appendix presents derivation underlying assumptions detail 
intuitive rationale truly existing tactus measure pulse appears peak lag corresponds pulse period 
analogously tatum period appears peak frequency corresponds inverse period 
product values correlates approximately linearly likelihood observation meter 

estimation transition initial probabilities term decomposed likelihood ratio 
term represents transition probabilities successive period estimates second term represents relation dependencies simultaneous periods independent actual frequencies occurrence practice tends integer multiple 
similarly write 
transition probabilities successive period estimates obtained follows 
number possible transitions large reasonable estimates obtained counting occurrences 
transition probability modeled product prior probability certain period term describes tendency periods slowly varying function hand labeled data way 
relation dependencies simultaneous periods modeled follows 
model terms implements normal distribution function logarithm ratio successive period values 
follows likelihood large changes period higher long periods period doubling halving equally probable 
gaussian mixture density form parameter monitoring performance system simulations 
distribution illus fig 

prior probabilities tactus period lengths measured actual data authors 
component weights sum unity component means common variance 
function models relation dependencies simultaneous suggested parncutt apply parameter periods independent actual frequencies occurrence 
lognormal distribution model prior densities exact weight values critical designed realize tendency binary ternary integer relationships concurrent pulses 
example quite probable tactus period consists tatum scale shape parameters periods multiples respectively 
tactus period values music lower weights 
distribution estimated counting occurrences dif shown fig 

weights obtained assigning ferent period lengths hand labeled database see sec 
iii values musical intuition 
dynamic fitting log normal distribution histogram data 
range weights raising common shows period length histograms corre power varied 
value sponding lognormal distributions tactus measure performed best small scale simulations selected 
tatum periods 
scale shape parameters tatum small adjustments values 
measure periods respectively 
estimated 
finding optimal sequence period estimates obtain estimate unobserved state vari fig 

likelihood function describes tendency periods slowly varying 
ln exp exp ln mb ma mc measure period length seconds fig 

period length histograms corresponding lognormal distributions tatum tactus measure pulses 
fig 

distribution gx models relation dependencies simultaneous periods see 
gx gx wl gx likelihood likelihood likelihood likelihood tatum tactus ables observed front data model parameters 
finding sequence state variables qn observed front data computed viterbi algorithm widely applied speech recognition 
seek sequence period estimates argmax denotes joint probability density hidden observed variables defined 
viterbi decoding need define quantity jkl max qn jkl best score single path time takes account observations ends state occurs respect piece 
periods phases completely define meter time principle phase measure pulse determines phase levels 
qn jkl induction compute formed meter measure level beat coincide jkl sn qn jkl beat lower metrical levels 
determining phase measure pulse difficult turned require max qn jkl qn pattern recognition techniques tactus phase estimation straightforward robust 
propose causal model meter estimate qn time determined state best partial path model tactus measure phases estimated separately parallel models 
tatum pulse phase point time 
noncausal estimate seeing complete estimation needed tactus phase 
sequence observations computed backward scheirer proposed state vectors comb filters decoding determine phase tactus pulse 
equiva max 
jkl inequality due pruning path candidates evaluating subset best path candidates time instant resulting path necessarily global optimum 
practice difference small 
evaluating possible path candidates computationally demanding 
apply suboptimal strategy evaluate predefined number promising path candidates time instant 
selection promising candidates greedy selection strategy 
second select independently best candidates tatum tactus measure periods 
number candidates safe simulations 
selection maximizing selecting best candidates need compute observation likelihoods meter candidates different combinations tatum tactus measure periods 
done eq results stored data vector 
transition probabilities computed eq 
stored matrix 
data structures viterbi algorithm 
lent latest outputs resonator delay resonators channels consequently output matrix channel index phase index takes values estimation place time convenience denote output matrix pulse period notation refer individual elements matrix acts observation phase estimation time fig 
shows example observation matrix tactus phase estimation place seconds piece 
signals different channels outputs comb filter corresponds estimated tactus period seconds 
output matrix contains latest seconds output signals indicated rectangle 
correct phase value marked dashed line 
discussed sec 
ii comb filters implement harmonic frequency response outputs show clear periodicity period separate hidden markov models evaluated parallel tactus phase measure phase 
joint estimation attempted 
models similar differ state conditional observation densities defined 
models observable variable phase estimation phases pulses estimated successive time instants periods decided points 
refer estimated periods tatum tactus measure pulses time respectively 
corresponding phases pulses expressed temporal anchors time values nearest beat unit output matrix resonator corresponds pulse period 
hidden variable phase pulse values hidden state process time homogenous order markov initial state distribution transition probabilities observable variable conditional current state state jkl max sn rc rc channel time seconds fig 

rectangle indicates observation matrix tactus phase estimation time period 
dashed line shows correct phase case 
conditional observation densities remaining problem find reasonable estimates model parameters 
state conditional observation likelihoods pr tactus pulse approximated pr 
likelihood proportional weighted sum resonator outputs channels 
exact weights different channels critical 
band summing intuitively meaningful earlier 
emphasizing low frequencies motivated stable bass rule stated lerdahl jackendoff improved robustness phase estimation simulations 
purpose estimating measure pulse phase formula state conditional observation likelihoods analogous derived different channels weighted delayed complex manner 
turned pattern matching form necessary analyze music time scale estimate measure phase output matrix simple formula exists 
case system access pitch content incoming piece points harmonic change serve cues estimating measure phase straightforward manner 
remains proved 
estimation higher level metrical pulses audio data earlier attempted goto muraoka resorted pattern matching straightforward chord change detection 
method reliable 
vector hn constructed pr hn ck mod mod denotes modulus division 
scalars ck weights resonator outputs channels delays weights typical pattern energy fluctuations measure period estimated maximum hn indicates measure phase 
universally applicable patterns ck ck leading corresponding vectors hn values matrices appendix patterns characterized motion low frequency event high intensity event 
pattern summarized low loud loud second low loud 
patterns combined single vector perform phase estimation whichever pattern matches better data max hn hn 
state conditional observation likelihoods defined pr 
pattern matching approaches evaluated 
particular attempted sample times tactus beats train statistical classifiers choose beat corresponds measure beat see elaboration idea 
methods basically equivalent described straightforward implement performed slightly worse 
transition probabilities successive phase estimates modeled follows 
phase estimates beat occurrence times conditional probability ties successive estimates assumed normally distributed function prediction error measures deviation predicted beat occurence time previous beat time period common noted periods may elapse initial state distribution assumed uniformly distributed causal noncausal computation phase performed viterbi algorithm described sec ii fifteen phase candidates winning tactus winning measure period generated second 
candidates selected greedy manner picking local maxima corresponding probability values stored vector transition probabilities successive estimates computed 
sound onset detection events detecting beginnings discrete acoustic events uses 
interest event occurs metrical beat exact timing event respect ideal metrical position 
musical pieces events triplets entity tatum periods exceptionally divided parts grace notes pitch events occur bit metrically stable event 
onset detector front systems designed symbolic midi input enable process acoustic signals 
robust onset detection achieved accent signal computed setting 
local maxima represent onset candidates value points reflects likelihood discrete event occurred 
simple peak picking algorithm fixed threshold level distinguish genuine onsets changes modulations take place ringing sound 
exp mod pr vn vn vn table statistics evaluation database 
pieces annotated metrical pulses genre tatum tactus measure classical electronic dance hip hop rap jazz blues rock pop soul funk unclassified total iii 
results section look performance proposed method simulations 
results compared systems 
distribution errors analyzed importance different processing elements validated 
experimental setup table shows statistics database evaluate accuracy proposed meter estimation method methods 
musical pieces collected cd recordings downsampled single channel stored hard disc khz sampling rate bit resolution database created purpose musical signal classification general balance genres informal estimate people listen 
metrical pulses manually annotated approximately minute long excerpts selected represent piece 
tactus measure pulse annotations musician tapped pieces 
tapping signal recorded tapped beat times detected semiautomatically 
tactus pulse annotated total pieces 
measure pulse reliably marked listening pieces 
particular annotation measure pulse attempted classical music musical scores 
tatum pulse annotated author listening pieces annotated tactus pulse determining integer ratio tactus tatum period lengths 
integer ratio interpolate tatum beats tapped tactus beats 
evaluating meter estimation system trivial 
issue addressed depth goto muraoka 
suggested longest continuous correctly estimated segment basis measuring performance 
means inaccuracy middle piece leads performance 
longest continuous sequence correct pulse estimates piece sought compared length segment analyzed 
ratio lengths determines performance rate piece averaged pieces 
prior meter analysis algorithms consideration second build period order theoretically possible estimate correct period immediately evaluation segment 
taken care input material involve tempo discontinuities 
specifically interval tapped beat times pulse period change time successive beats 
tempo fluctuations naturally allowed 
correct period estimate defined deviate annotated correct phase deviate annotated beat time times annotated period length 
precision requirement suggested appropriate inaccuracies manually tapped beat times allow meaningful comparison precision 
measure pulse period phase requirements tightened measure period lengths large accurate evaluation possible necessary seen 
tatum pulse tactus phase phase correct tactus phase correct period considered separately 
performance rates different criteria correct pulse estimate time accepted period phase correct 
accept pulse estimate accepted phase correct period matches times annotated 
period doubling halving accepted factor change continuous sequence 
correct meter estimation takes place wrong metrical level chosen tactus pulse 
period correct pulse estimate accepted period correct 
phase ignored 
tactus interpreted tempo estimation performance 
single best number characterize performance pulse estimator 
investigated meter estimation results 
observed temporal continuity producing correct estimates important 
secondly phase errors disturbing 
third period doubling halving disturbing 
tapping consistently twice fast slow matter 
selecting correct metrical level cases ambiguous human listener especially case tatum pulse 
summary appears accept criterion gives single best number characterize performance system 
systems put results perspective methods baseline simulations 
essential principle continuous sequence correct estimates evaluation gives somewhat pessimistic picture absolute performance 
methods scheirer dixon different systems represent state art tactus pulse estimation source codes publicly available 
implementations parameter values original authors 
scheirer method parameter tuning slightly improved results 
dixon developed system primarily midi input table tactus estimation performance different methods 
method continuity required individual estimates correct accept period correct correct accept period correct causal noncausal scheirer dixon dixon table meter estimation performance proposed method 
method pulse continuity required individual estimates correct accept period accept correct correct period correct causal tatum tactus measure noncausal tatum tactus measure provided simple front analyzing acoustic signals 
third system denoted dixon developed independent onset detector described sec 
ii prior dixon tactus analysis 
systematic phase errors compensated methods 
experimental results table tactus tracking performance proposed causal noncausal algorithms compared methods 
observation noticed methods maintain temporal continuity acceptable estimates 
reason performance rates percentages individual acceptable estimates right half table 
dixon method difficulties choosing correct metrical level tactus performs accept criterion equipped new onset detector 
proposed method outperforms previous systems accuracy temporal stability 
table shows meter estimation performance proposed causal noncausal algorithms 
human listeners meter estimation easiest tactus pulse level 
measure pulse period estimation done robustly estimating phase difficult 
reason large part material rhythmic patterns elapse measure period system difficulties choosing 
case phase errors beat displaced half period accepted performance rate essentially tactus 
phase errors disturbing accepted 
tatum pulse turn deciding period difficult 
temporally atomic pulse rate typically comes occasionally making temporally stable analysis hard attain 
method halve period hypoth classical electr 
dance hip hop rap jazz rock pop soul funk fig 

performance different musical genres 
accept continuity required percentages shown tatum white tactus gray measure black pulses 
occurrence rate occurrence rate rapid event sequence occurs 
appears performance rates method able produce consistent tatum period time alternates double 
degrades temporally continuous rate accept rate individual estimates 
produced errors disturbing listening results 
shows accept continuity required performance rates different musical genres 
classical music proposed method moderately successful tactus rate outperforms performance methods material 
may suggest pitch analysis needed analyze meter classical music 
jazz music complexity musical rhythms higher average task harder 
temporal precision proposed method illustrated 
measured time deviation accepted phase estimates annotated beat times 
deviation expressed relation annotated period length 
histogram shows distribution deviation values 
noted tapping absolutely accurate histogram reflects inaccuracies 
measure pulse histogram quite exactly times narrower copy tactus 
absolute time deviations roughly suggesting due tapping 
dashed line right hand side relative deviation relative deviation fig 

relative occurrence frequencies different phase deviations phase 
deviation measured relation period length tactus left measure pulse right 
occurrence rate ratio estimated period period fig 

histogram period estimation errors tatum tactus measure pulses left right respectively 
table meter estimation performance different system configurations require continuity accept gram shows histogram deviations times period accepted measure pulse 
confused phase estimates accepted 
higher precision required measure phase 
shows histograms ratio estimated period annotated period measured 
seen period estimation errors half double correct period 
case phase ignored tatum tactus measure period estimates correct half double period 
fact measure pulse annotated classical music explains measure period estimation rate higher tactus 
importance different parts table gives performance rates different system configurations 
different elements proposed model disabled order evaluate importance 
case system kept fixed 
baseline method noncausal system table 
test dependencies different pulse levels broken non informative flat distribu tion gx 
slightly degrades performance cases 
second test dependencies temporally successive estimates broken non informative distribution transition probabilities successive period phase estimates respectively 
degrades temporal stability estimates considerably collapses performance rates longest continuous correct segment evaluation 
third case types dependencies broken 
system performs moderately indicating initial time frequency analysis method comb filter resonators provide high level robustness 
individual estimates accept method tatum tactus measure tatum tactus measure 
baseline 
joint estim 

temporal proc 

iv 
method described successfully estimate meter acoustic musical signals 
musical genres diverse types processed common system configuration parameter values 
musical material relatively low level acoustic information need model higher level auditory functions sound source separation multipitch analysis 
similarly human listeners computational meter estimation easiest tactus pulse level 
measure pulse period estimation done equally robustly estimating phase straightforward 
pattern recognition techniques pitch analysis needed analyze music time scale 
tatum pulse turn phase estimation difficult deciding period difficult humans computational algorithm 
temporally atomic pulse rate typically comes occasionally 
causal processing difficult necessary halve tatum hypothesis rapid event sequence occurs 
critical elements meter estimation system appear initial time frequency analysis part measures musical accentuation function time implicit internal model represents primitive musical knowledge 
needed provide robustness diverse classical rock electronic music 
needed achieve temporally stable meter tracking fill parts meter implied musical surface 
challenge part develop model generic various genres example jazz classical music 
proposed model describes sufficiently low level musical knowledge generalize different genres 
method enables causal noncausal processing model 
backward decoding strategy viterbi algorithm acts satisfying counterpart phenomenon called revision human perception 
revision refers manner interpretation previous material affected happens 
backward decoding successive time instants computationally demanding gives retrospective estimate history point 
appendix derivation observation densities appendix presents derivation underlying assumptions estimation state conditional observation likelihoods sq assume realizations independent realizations violates dependencies model significantly simplifies computations possible obtain reasonable estimates 
furthermore tatum information clearly visible spectrum resonator outputs ps spectrum 
assume components conditionally independent state write ps max psk ps reasonably safe simplifying assumptions 
assume height lags corresponding period signal depend particular period periods 
second value lag period signal independent true periods domi nated fact period corresponds particular lag 
written sq jkl ps denotes probability value tactus pulse period denotes probability value tactus pulse period 
conditional probability distributions tactus measure tatum distributions approximated discretizing value range calculating histogram values cases annotated metrical pulse period 
defining ps equation written psk scalar function depend approximated histograms tactus measure tatum terms form represented single discrete histogram 
modeled order polynomials 
terms depend linearly value term depends linearly value write 
histograms accurately modeled polynomials bring performance advantage simple linear model 
psk psl psl ps ps ps ps sq jkl sk sl max psk psl psk ps ps max psk sq jkl max appendix numerical values matrices sec 
ii ck channel determines row delay column 
row correspond lowest frequency channel 
lerdahl jackendoff generative theory tonal music 
mit press cambridge massachusetts 
clarke rhythm timing music psychology music deutsch ed academic press 
bilmes timing essence perceptual computational techniques representing learning reproducing expressive timing percussive rhythm sc 
thesis massachusetts institute technology 
lee perception metrical structure experimental evidence model representing musical structure howell west cross eds academic press london 
steedman perception musical rhythm metre perception pp 

longuet higgins lee perception musical rhythms perception pp 

lee rhythmic interpretation simple musical sequences perceptual model musical structure cognition cross howell west eds academic press london 
perception temporal patterns music perception pp 

desain honing computational models beat induction rule approach journal new music research vol 
pp 

parncutt perceptual model pulse salience metrical accent musical rhythms music perception vol 
pp 
summer 
brown determination meter musical scores autocorrelation acoust soc am pp 

large kolen resonance perception musical meter 
connection science pp 

rosenthal machine rhythm computer emulation human rhythm perception ph thesis massachusetts institute technology 
allen dannenberg tracking musical beats real time proc international computer music conference san francisco 
temperley cognition basic musical structures 
mit press cambridge massachusetts 
dixon automatic extraction tempo beat expressive performances new music research pp 

goto muraoka music understanding beat level real time beat tracking audio signals working notes ijcai workshop computational auditory scene analysis pp 

goto muraoka real time rhythm tracking audio signals chord change detection musical decisions proc ijcai workshop computational auditory scene analysis pp 

goto muraoka issues evaluating beat tracking systems ijcai workshop issues ai music pp 

gouyon herrera cano pulse dependent analyses percussive music proc aes nd international conference virtual synthetic entertainment audio espoo finland june pp 

maher fundamental frequency estimation musical signals way mismatch procedure acoust soc am pp 

scheirer tempo beat analysis acoustic musical signals acoust soc am pp 

meter periodicity musical performance journal new music research vol 

cemgil kappen monte carlo methods tempo tracking rhythm quantization journal artificial intelligence research pp 

raphael automated rhythm transcription proc 
international symposium music information retrieval indiana oct pp 

estimating tempo swing beat locations audio recordings proc workshop applications signal processing audio acoustics new paltz new york oct pp 

klapuri sound onset detection applying psychoacoustic knowledge proc ieee international conference acoustics speech signal processing phoenix arizona pp 

computer system automatic detection perceptual onsets musical signal technology emotion ed genova dist pp 

davy godsill detection abrupt spectral changes support vector machines 
application audio signal segmentation proc ieee interna tional conference acoustics speech signal processing orlando florida may pp 

neural networks note onset detection piano music proc international computer music conference teborg sweden sep 
abdallah plumbley probability metadata event detection music ica conditional density model proc th international symposium independent component analysis blind signal separation nara japan april 
duxbury bello davies sandler complex domain onset detection musical signals proc th int conf digital audio effects london uk sep 
klapuri multiple fundamental frequency estimation harmonicity spectral smoothness ieee trans speech audio processing pp 
nov 
klapuri conventional periodic ngrams transcription drum sequences proc 
ieee international conference multimedia expo baltimore maryland july 
meddis hewitt virtual pitch phase sensitivity computer model auditory periphery 
pitch identification acoust soc am pp 

moore derivation auditory filter shapes noise data hear res vol 
pp 

moore ed hearing handbook perception cognition nd edition 
academic press 
meddis simulation mechanical neural transduction auditory receptor acoust soc am pp 
march 
de cheveign kawahara yin fundamental frequency estimator speech music acoust soc 
am 
pp 
april 
van resonance perception musical pulse journal new music research vol 
pp 

rabiner juang fundamentals speech recognition 
prentice hall new jersey 
sepp nen computational models musical meter recognition sc 
thesis tampere university technology tampere finland 
