low level information extraction bayesian network approach remco bouckaert xm nz remco cs waikato ac nz mountain information technology computer science department university waikato new zealand article contribution information extraction bayesian network learning motivated practical information extraction tasks 
shown information extraction tasks approached classification problem text split tokens token assigned class 
hidden markov models popular formalism task deal tokens having set attributes single 
new algorithm task various bayesian networks architectures deals multiple attributes token 
experiments suggest bayesian networks architectures perform better naive bayes problem domain 
hopefully article helps making bayesian networks accessible information extraction community 

information extraction task finding specific pieces information unstructured documents 
generally known internet contains large amounts unstructured documents information extraction tasks performed publicized large organizations publishing companies government departments airplane manufacturers enormous amount unstructured documents 
exploding amount information captured increasing number documents task finding information required harder harder 
popularity extensible markup language xml publishing industry indicates aspects document captured structured format assists making documents accessible queries information gathering tasks 
large collection documents tend written large variety people styles 
task creating structured document unstructured big challenge 
structuring documents split subtasks determine high level structure determine sections headings part section table determine low level structure know piece text contains affiliation determine individual elements affiliation example institute street address post box city zipcode state country 
context high low level structure retrieval information extraction task finding part text contains particular pieces information 
information extraction successfully applied areas job advertisement collection internet scientific article collection internet datamining medline internet repository medical related documents gene interactions world wide web consortium 
extensible markup language xml 
www org xml urls mentioned article accessed available april 
xml industry support 
xml org html job search find jobs employment careers flip dog com 
www com tor kristian 
datamining medline gene interactions 
www org examples internet information extraction applications 
perform information extraction tasks completely unstructured documents understanding content completely impossible 
quite way go document understanding simpler task considered 
article concentrate low level structure discovery assuming high level extraction done 
commercial packages available support information extraction regular expression parsing suite 
come fancy graphical user interfaces support entering regular expressions cumbersome format perl syntax 
practice considerable effort required regular expressions task domain knowledge needs encoded 
tends cumbersome task domain knowledge general readily available 
approaches hidden markov models undertaken approaches limited effort required learn markov model 
new approach proposed observation information extraction cases interpreted classification task dimensionality tokens reduced 
token word sequence words assigned class lower dimensional attributes calculated token 
example address recovery example just mentioned word classified institute street address post box city zipcode state country 
bayesian networks particular networks restricted specific network architectures suited task :10.1.1.30.9978:10.1.1.43.7564
article introduce bayesian networks terminology notations remainder article 
algorithm performing subtask structure extraction document 
case studies show properties algorithm real world problems 
finish concluding remarks directions research 

bayesian networks informally bayesian network consists graph set local probability distributions nodes graph 
graph directed uni trier de hp 
bayesian network representing hmm 
acyclic directed paths starting node 
direction arrows graph interpreted causal influences alternative name causal network lot alternative names 
bayesian network represents probability distribution nodes graph perform interesting calculations particular classification 

terms definitions define terms phrases formally 
set variables 
uk 
classification variable normally identified variable interested predicting outcome values variables 
variables attribute variables 
graph pair set nodes set pairs called edges edges directed edges called arrows undirected edges called lines 
path graph sequence nodes 
vk vi vi directed cycle path vk 
directed acyclic graph dag set nodes directed graph directed cycles 
bayesian network set variables pair bs bp bs dag bp set conditional probability tables vi set probability tables spans probability distributions vi distribution calculate interesting queries 
particular set variables observed values set variables probability configuration calculated 
naive bayes bayesian network 
uk efficient algorithms 
hidden markov model hmm state space 
sk observation space 
om triple 
si initial probability states 
qt sj qt si transition probability state sj previous state 
ot oj qt si probability observation oj generated state qt si 
illustrates hmm interpreted special case bayesian network node token node state 
probability tables defined qi qi oi qi 

naive bayes classifier naive bayes classifier bayes network structure classification variable outgoing arrows attribute variables arrows added 
network structure called naive bayesian network 
shows network structure bayesian network represents naive bayes classifier 
structure static need perform structural learning probability tables need assessed 

tan classifier tree augmented naive bayes tan classifier naive bayesian network extra arrows :10.1.1.30.9978:10.1.1.43.7564
structure classifier node removed tree structure nodes incoming arrows non classifier nodes 
structure learned starting naive bayes network hill climbing quality measure onwards details follow section 
number incoming arrows node restricted classifier node node 

ban classifier bayes network augmented naive bayes ban classifier naive bayesian network extra arrows structure classifier node removed full bayesian network :10.1.1.30.9978:10.1.1.43.7564
structure learned starting naive bayes network hill climbing onwards restricting number incoming arrows 

gbn classifiers general bayesian network gbn classifier classifier restrictions structure network 
starting empty structure hill climbing learn structure 

information extraction retrieve low level structure sentence need broken tokens 
tokens need assigned class 
hmms applied success task 
power hmms lies account set tokens classify 
problem hidden markov models learning transition probabilities 
typically single property token taken account hmm generalizations conditional random fields maximum entropy markov models overcome problem 
token assigned properties easily captured single variable 
examples token uppercase contains digits number characters token 
natural calculate set properties tokens 
hmms deal situation 
bayesian networks suited task desirable property account neighborhood 
may sufficient just attribute position values middle attributes previous token available 
shows bayesian network illustrating 
thing left learn bayesian network structure attribute nodes 

bayesian network learning general learning bayesian network bs bp consists steps learning structure bs learning probability tables bp article learn bs search space network structures performed network assigned measure quality data 
various measures exist class attributes tokens 
calculating attributes tokens ci ai 
ai ai 
ai ai 
ai oi bayesian minimum description length information criterion approaches 
measures behave larger datasets remainder bayesian approach taken 
approach maximizes probability network structure bs data decomposed prior network structure bs product quality measures ui nodes parents bs bs ui 
customary prefer network structure extra information structure problem domain available assume bs constant discarded 
decomposition finding network structure reduces finding parent sets node expression ui needs optimized 
caveat network structure acyclic graph adding arrow tested cycles appear 
simple way prevent ordering nodes allow arrows lower ordered nodes higher ordered ones 
structure learning algorithm assumption node hill climbing parent set 
algorithm hill climbing assuming ordering arrow added acyclicity test needs performed making efficient 
information extraction tasks encounter data missing 
consequently conditional probability tables estimated directly data structure network known 
data missing em algorithm generalization baum welch algorithm hmms applied 

markov blanket classifiers initial structure network empty naive bayes major impact quality oi oi learned network :10.1.1.30.9978:10.1.1.43.7564
suggests putting bit effort analyzing initial structure may pay 
reason naive bayes network performs better empty initial structure guaranteed node effect classifier node small 
observation suggests initial network node markov blanket set parents children parents children classifier node may starting structure nodes markov blanket influence classification 
problem left finding network designing algorithm efficiently finds network 
number networks ways select set parents times ways select children remaining nodes times ways assign remaining nodes parents children classifier node jn exponential number models consider 
practical alternative learn network structure starting empty network apply test node markov blanket classifier node 
add arrow node classifier node 
guarantee acyclicity arrow classifier node attribute node added tested attribute node ancestor classifier node 
arrow added pointing classifier node points attribute node 
resulting bayesian network called markov blanket classifier 

optimizations reduce learning times prevent overfitting bound maximum number parents provided algorithms 
note result ban classifier restriction having parent reduce tan 
effort done provide sophisticated learning algorithms straightforward hill climbing reduce learning time 
obviously way network better quality quality measure missed 

case study affiliations sub problem converting scientific documents written various authors uniform xml format extraction affiliations authors 
start simple set heuristic rules applied 
rules form position token country 
algorithm gain understanding problem domain assisted creating training data 
conventional technology business environment comfortable easy integrate existing systems maintainable 
affiliations property items separated commas allows simple token definition text commas start affiliation string token 
start description attributes calculated token experimental setup follows results discussed 

description data token attributes calculated position mid 
indicates position token affiliation 

indicates token keywords university hospital limited institute foundation pharmaceuticals universidad 

indicates token keywords department division laboratory branch section school unit program programme 

indicates token keywords street st court lane ln road rd rue st avenue ave av drive dr highway way parkway boulevard blvd piazza plaza room floor building suite 

indicates token matches regular expression bp bo 

indicates token part list cities 

indicates token matches sa 
indicates token part list countries 

indicates token part list countries 

counts number words token 

indicates token contains number 
classifier provided attributes token plus attributes previous token token 
token previous token attributes set zero position attribute set 
classes institute department city street country zip state 
note class token contains zipcode city happens regularly affiliation provided comma zipcode city 
total attributes 
affiliations sourced articles pharmaceutical publisher 
total affiliations providing tokens dataset 
affiliations mixed affiliations provide summary affiliation example hospital medical center division infectious diseases cincinnati ohio usa provide full postal address example university melbourne exercise physiology metabolism laboratory department physiology vic australia 
labeling initially performed automatically simple set rules 
dataset manually cleaned cases relabeled 

experimental set table 
average accuracy percentage affiliation extraction std dev 
brackets 
max parents naive markov naive markov naive tan ban ban ban algorithms run times fold cross validation fold cross validation tends give indication algorithm behaves new data 
misclassification leads manual clean action classification accuracy model customary precision recall criteria taken quality measure 
particular application accuracy justified measure maximize suitable text classification problems 
algorithms implemented java weka 
algorithms compared test known somewhat elevated type error setting conveniently available weka 
table shows results 
column shows maximum number parents node network structure naive bayes initialized networks brackets 
columns show classification accuracy averaged runs fold cross validation numbers shown calculated total runs algorithm 
columns labeled naive naive bayes network initial network structure columns labeled markov markov blanket optimization 

discussion bound number parents node set zero class assigned majority class dataset predictor case classification accuracy shows table 
bound set initial network naive bayes network arrows added get result naive bayes classifier 
classification accuracy tends increase increase bound levels 
particular naive bayes worse network structure complex naive bayes significance level double tailed test 
general algorithm outperforms algorithm expected due larger search space algorithm visits 
comes cost increased learning time 
table shows ranking algorithms number times algorithms significantly better double tailed test level minus number times algorithms significantly worse 
confirms markov optimization useful learning classifiers markov optimized networks outperform networks optimization bottom table 
algorithm heuristic rules currently part production system classification rate 
table shows learning algorithms significantly outperformed rule 
claim designing better rules better result obtained 
automatically learned models attributes experience gained rule algorithm time effort required design algorithm easily offset time effort required apply automatically learned model 

case study citations subproblem document conversion citation extraction 
consider sentences contain complete citations 
goal retrieve citation information instance authors title date journal string 
case easy affiliation problem define tokens characters separate items interest 
example authors title separated spaces full stops volume issue separated braces 
approach taken define tokens words token separator attribute 
table 
ranking affiliation data algorithm search max parents zation total wins losses naive markov markov naive naive markov markov naive naive markov naive markov naive naive markov markov markov naive naive markov 
description data tokens attributes generated position mid 
indicates position token citation 

indicates characters upper case alphabetical 

indicates characters lower case alphabetical 

indicates characters alphabetical 

indicates word starts uppercase alphabetical character continues remainder lower case alphabetical characters 

indicates characters digits 

indicates digit 

indicates length characters 
separator dot comma colon semi colon question mark space 
separator character current token 
note affiliation case domain specific attributes generated 
target class values journal authors number date organisation volume title note pages editor edition institution chapter publisher address wrapper 
value wrapper categories example text indicate publication part book citation article 
approach extract authors year information citation matching database 
motivation creating dataset different class attribute having values authors title date wrapper 
values authors title date mapped value wrapper 
data training testing tex bibliography archive typesetting archive quite omissions example page numbers punctuation reasonably accurate bibtex processing realistic reflection author provided manuscripts 
bibliography items typeset plain bibtex style updated insert tags class information 
ascii text extracted generated postscript file normalization characters applied attributes calculated perl script 
resulting dataset cases attributes 

experimental set runs folds cross validation generate test results 
table shows results row contains dataset full full set values class truncated valued class class added class previous token provided dataset extending dataset attributes 
column shows algorithm table columns averaged results folds structure learned collections bibtex downloaded ira uka de bibliography index html table 
average accuracy percentage citation extraction std dev 
brackets 
dataset full full class truncated truncated class max parents naive tan ban ban ban 
discussion table shows max parents prominent class full class truncated class 
network structure sophisticated max parents naive bayes max parents better 
algorithm outperforms cases due larger search space 
resulting classification accuracies shown table encouraging considering attributes calculated tokens standard contain domain specific information attributes affiliation classification problem 
classification accuracy increases acceptable levels class previous token added 
suggests citation identification may assisted classifying tokens single task hmms independent 
dynamic bayesian networks similar hmms define network structure token dependencies previous tokens attributes span distribution attribute class variables sequence tokens 
benefit hmms allow flexible network structures allowing handling multiple attributes token 
efficient algorithms exist calculating configuration class values highest probability attributes tokens cn 
cn 
xn 

practical problems affiliation identification citation parsing demonstrated bayesian networks help perform information extraction tasks 
handcrafted algorithm part production system developed traditional software engineering techniques outperformed terms classification accuracy development time 
problems allowed handling information extraction task classification task tokenizing input generate various attributes tokens input classification algorithm 
defining standard attributes numeric upper case citation problem produce reasonable results putting effort definition attribute gives useful classification accuracy 
new bayesian networks architecture markov blanket classifier introduced 
architecture allows learning network structure standard algorithms post processing learned network ensure variable impact classification 
experiments suggest performance better plain bayesian networks comparable networks initialized naive bayes network 
observation bayesian networks help information extraction tasks hopefully inspires research area may exploit available rich theory graphical models 
case study citation classification shown classification accuracy token increases considerably class previous token added 
dynamic bayesian networks similar hmms define network structure token dependencies previous tokens attributes span distribution attribute class variables sequence tokens 
research applying dynamic bayesian networks information extraction looks highly promising 
anonymous referees useful hints pointers related 
blake merz 
uci repository machine learning databases 
irvine ca university california department information computer science 

www ics uci edu mlearn mlrepository html bouckaert 
properties bayesian belief network learning algorithms 
uncertainty artificial intelligence proceedings tenth conference 

buntine 
operations learning graphical models 
journal artificial intelligence research cheng greiner 
comparing bayesian network classifiers 
proceedings th conference uncertainty artificial intelligence uai 
morgan kaufmann publishers august 

bibliography extraction hidden markov models technical report cs tr february department computer science university cooper herskovits 
bayesian method induction probabilistic networks data 
machine learning dietterich 
approximate statistical tests comparing supervised classification learning algorithms 
neural computation dean kanazawa 
probabilistic temporal reasoning 
aaai 
ding gravano shivakumar 
computing geographical scopes web resources 
th international conference large databases vldb cairo egypt september 
www northernlight com html freitag mccallum 
information extraction hmms shrinkage 
proceedings workshop machine learning information extraction aaai orlando fl july friedman geiger goldszmidt 
bayesian network classifiers 
machine learning heckerman geiger chickering 
learning bayesian networks combination knowledge statistical data 
machine kruger giles coetzee glover flake lawrence 
building new niche search engine 
ninth international conference information knowledge management cikm washington dc november lafferty mccallum pereira 
conditional random fields probabilistic models segmenting labeling sequence data 
icml lauritzen spiegelhalter 
local computations probabilities graphical structures applications expert systems discussion 
journal royal statistical society lawrence bollacker giles nec research institute 
researchindex neci scientific literature digital library 
citeseer nj nec com lawrence giles bollacker 
digital libraries autonomous citation indexing 
ieee computer volume number pp 
leek 
information extraction hidden markov models 
master thesis uc san diego mccallum freitag pereira 
maximum entropy markov models information extraction segmentation 
icml muslea 
extraction patterns information extraction tasks survey 
proceedings workshop machine learning information extraction aaai pag 
orlando florida pearl probabilistic reasoning intelligent systems networks plausible inference morgan kaufmann 
sebastiani 
machine learning automated text categorization 
acm computing surveys witten frank 
data mining practical machine learning tools techniques java implementations 
morgan kaufmann san francisco www cs waikato ac nz ml yang evaluation statistical approaches text categorization 
journal information retrieval pp 
