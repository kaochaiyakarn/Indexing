vehicle tracking line fusion color shape features kai george gu ronald miller computer vision laboratory university nevada reno nv vehicle design department ford motor mi gu cs edu ford com real time road vehicle tracking method 
tracker builds statistical models target color shape feature spaces continuously evaluates feature spaces computing similarity score probabilistic distributions target model 
similarity scores final location target determined fusing potential locations different feature spaces 
proposed method evaluated real data illustrating performance 
aim reducing injury accident severity sensing area active research automotive manufacturers suppliers universities 
developing board automotive driver assistance systems aiming alert driver driving environments possible collision vehicles attracted lot attention 
systems robust reliable vehicle detection tracking critical steps driver assistance collision avoidance 
focus problem road vehicle tracking optical sensors 
past vehicle detection review road vehicle detection methods optical sensors 
tracking moving objects moving camera challenging topic computer vision 
difficulties caused continuous changing camera position variation appearance target motion alteration illumination conditions background 
particular car required react road situations real time adds constraint tracker tracking algorithm computationally inexpensive 
various tracking algorithms proposed literature including approaches optical flow templates local features kalman filters contours 
mean shift algorithm adopted efficient tracking technique 
nonparametric gradient climbing method mean shift analyze arbitrarily structured feature spaces hard fit analytical models 
compared tracking methods exhaustively search neighborhood predicted location target mean shift optimal search fast target localization 
predict search region effectively mean shift combined kalman filter 
improve ability mean shift tracking respect scale changes scale selection mechanism introduced lindeberg theory 
mean shift past track moving targets sequences flir imagery human bodies non rigid objects 
success failure tracking algorithm depends lot degree tracked object distinguished surroundings 
particular set features tracking algorithm represent object tracked plays major role tracking performance 
trackers mentioned color information form visual feature space probability models built 
color information sufficient road vehicle tracking 
competing having similar colors target may appear background quite 
color target tracked varies due light changes road conditions 
example car goes tunnel turns dark grey despite original color due drastic illumination changes 
tracker solely color information situation 
hand tracking suffer cues color shape information vehicle shape remains rigid motion 
consequently robust tracking performance gained switching shape information color information reliable opposite 
proposes robust mean shift vehicle tracker line feature space evaluation decision fusion mechanism embedded 
tracker represents target color shape information adapts representation proper feature space line decision rule 
statistical representations model vehicle vehicle candidates acquired different feature spaces vertical edge horizontal edge diagonal edge color hsv hue saturation value representation 
mean shift analysis employed feature space derive potential position target 
done finding target having similar statistical distribution model feature space 
final target location determined fusing candidate locations 
candidate location weighted similarity target model corresponding feature space 
proposed tracking algorithm evaluated video sequences taken reno nevada 
results illustrate robust tracking performance real time 
ii 
tracking algorithm tracking algorithm takes major steps perform road vehicle tracking 
different features extracted input frame 
feature space mean shift estimator finds potential target position corre sponding statistical model 
target location determined dynamically fusing tracking outputs feature spaces 
feature spaces assume promising features tracking form best feature space 
space target model statistical distributions similar 
best feature space tracking needs adapt time appearances target background keep changing due fact target camera moving 
color shape provide important information describe vehicle 
separate probabilistic model target built feature spaces hsv color space vertical edge space horizontal edge space diagonal edge space 
proposed framework general support additional feature spaces motion texture features 
ability feature spaces characterize target reliably varies time time 
characterizing vehicle appearance shape features quite robust illumination changes fail target partially occluded 
hand color information helps tracker distinguish object time tracker drastic illumination changes appear 
key issue addressed developing automatic mechanism performs line evaluation similar candidate target model feature space combines tracking results similarity scores 
color features input image transformed rgb red green blue color space hsv color space 
hsv space separates hue color saturation concentrated color value brightness 
hue image created hue channel hsv color space 
observed brightness low high hue noisy unstable 
threshold brightness ignore hue pixels extreme brightness values hue values corresponding brightness values greater considered 
shape features achieve real time performance fast feature extraction method adopted extract edge information different directions 
motivation rear views vehicle contain vertical horizontal diagonal edges 
achieve haar feature extraction method introduced detecting human faces adopted study 
computing integral image intermediate representation original image haar features computed rapidly just lookup table see details 
simple rectangle masks extract horizontal vertical diagonal edge information shown 
mean shift estimator feature space different mean shift estimator applied find target potential location 
core mean fig 

basic masks extract haar features 
horizontal edge information vertical edge information diagonal edge information 
shift tracking algorithm computing mean shift vector recursively 
current target centroid location vector yj new target centroid location yj related translation yj yj normal kernel adopted new target centroid location derived yj wi set xi represents pixel locations search window wi corresponding weight assigned pixel 
probabilistic model representations dimensional epanechnikov kernel written ke feature kernel density estimates target model denoted qu target candidates current target centroid location denoted pu expressed pu ke xi xi ke xi xi function features computed color shape features application kronecker delta function 
denominator normalizes probability histogram imposing condition pu represents total number features 
distance measure minimization order find target candidate density distribution similar model need appropriate distance metric measure similarity histogram distributions 
bhattacharyya coefficient near optimal choice due close relation bayes error properties illustrated 
distance bin histogram defined bhattacharyya coefficient pu qu indicate target model distributions respectively 
minimize distance metric bhattacharyya coefficient maximized 
plugging pu qu bhattacharyya coefficient approximated taylor expansion wi pu qu xi qu xi pu assigning weights pixels search window new location target center obtained 
maximization bhattacharyya coefficient achieved mean shift iterator 
target locations different feature spaces fused determine final target location 
discuss fusion strategy subsection 
feature set evaluation decision fusion feature set evaluation fusion procedure illustrated figures respectively 
combine possible target locations different mean shift estimators compute similarity statistical distribution candidate locations model distribution bhattacharyya coefficient 
higher bhattacharyya coefficient model appears target candidate location 
feature space providing highest similarity contribution determining final location target candidate 
normalizing bhattacharyya coefficients interpret values probability model candidate location 
initialize model detecting target tracked top row 
pictures second row illustrate results feature extraction different feature spaces 
left right vertical edge map horizontal edge map diagonal edge map thresholded hue map 
generate statistical distributions model corresponding feature space shown third row 
simply normalized histograms edge magnitude hue information 
example feature evaluation fusion procedure input image 
input frame weighted images shown third row computed statistical models shown second row 
location target estimated mean shift feature spaces 
possible locations target performing mean shift mode seeking weighted images fused determine final location target 
possible locations vertical edge horizontal edge diagonal edge color feature spaces fig 

probability distributions generated model initialization xv yv xh yh xd yd xc yc respectively 
corresponding bhattacharyya coefficients bcv bch bcd bcc 
final center location determined follows bcv xv bcv bch bcd bcc bch xh bcv bch bcd bcc bcd xd bcv bch bcd bcc bcc bcv bch bcd bcc xc bcv yv bcv bch bcd bcc bch yh bcv bch bcd bcc bcd yd bcv bch bcd bcc bcc bcv bch bcd bcc yc fig 

fusing possible target locations input new frame scale model adaptation tracking algorithm iterates image frame video sequence extracting different feature sets described previous subsection 
search window mean shift algorithm updated frames 
selecting feature cue best describes target object scaling done simply modifying radius search window certain fraction 
window size provides largest bhattacharyya coefficient chosen contain target 
statistical representations models tracked different feature spaces need updated target camera moving time 
proper threshold chosen empirically decide model needs adapted certain feature space 
particular computing bhattacharyya coefficients frames values compared threshold 
result comparison statistical distributions model feature spaces updated 
iii 
experiments proposed tracker tested various highway tracking scenarios 
evaluate compare different tracking approaches compared tracking results ground truth formation set video sequences 
tracking performance evaluation objects having rectangular shape rear vehicles position size represented upper left bottom right corners rectangular window enclosing object 
evaluate accuracy tracking compute overlapping ratio rectangular area tracker rectangular area picked human ground truth 
shown assume rectangles represent ground truth tracking results respectively 
overlapping ratio computed fig 

overlapping area tracking result ground truth results section tracking results demonstrate performance proposed algorithm 
video sequences taken reno nevada 
video sequences chosen test tracker challenging conditions including scale changes illumination changes partial occlusion 
sequence compare tracking results ground truth plot overlapping ratio time 
blue truck shown tracked video sequence 
truck driving normal conditions occlusion drastic illumination changes 
size target vehicle changes gradually sequence moves away host vehicle 
shows tracking results feature space separately line fusion 
tracking methods comparable performances tracker line fusion shown orange best performance 
second video sequence contains white van shown 
corresponding overlapping ratios shown 
tracking results show color cue produce results tracker fails track vehicle goes bridge color changes drastically shown 
shows tracking results line fusion 
accuracy tracking color drops due significant illumination changes shape features preserve structure target 
result tracker employs manually initialized model 
tracking line feature fusion tracks target correctly truck brighter successful tracking scale changes 
color merges front 
fig 

video sequence contains scale changes 
fig 

tracking accuracy video sequence individual features line feature fusion 
color shape features maintains high performance shown orange line 
video sequence contains blue shown presents challenges due partial occlusion 
shown shape information sufficient tracking drifts away target vehicle partially visible 
shows results tracking vertical edge information 
combining color shape features tracking successful shown 
line fusion color shape features provides robust approach road vehicle tracking 
shape information compensate color variations due illumination changes color information compensate shape changes due partial occlusion 
iv 
effective road tracking method utilizes shape color information 
color information shape features edges directions build statistical models vehicle appearance feature space 
potential target location feature space mean shift algorithm 
results feature space ranked computing similarity scores model target 
fusion takes place line uses similarity manually initialized model 
tracking color information fails due illumination changes 
tracking line feature fusion 
fig 

video sequence contains drastic illumination changes 
fig 

tracking accuracy video sequence individual features line feature fusion 
manually initialized model 
tracking vertical edge information fails due partial occlusion 
tracking line feature fusion 
fig 

video sequence contain partial occlusions 
fig 

tracking accuracy video sequence individual features line feature fusion 
scores compute final location target 
experimental results demonstrate robust tracking performance various tracking scenarios including scale changes drastic illumination changes partial occlusion 
research plan consider fusing cues texture optical flow 
mean shift algorithm applied separately feature space proposed approach amenable parallel implementation implies real time performance 
research supported ford motor university nevada reno applied research initiative ari part nsf 
haritaoglu davis real time multiple vehicle detection tracking moving vehicle machine vision applications vol 
pp 
september 
alan lipton patil moving target classification tracking real time video darpa image understanding workshop 
eric marchand patrick bouthemy motion obstacle detection tracking car driving assistance int 
conf 
pattern vol 
pp 
canada august 
sun miller road vehicle detection gabor filters support vector machines international conference digital signal processing july greece 
sun miller quantized wavelet features support vector machines road vehicle detection seventh international conference control automation robotics vision december singapore 
sun miller improving performance road vehicle detection combining gabor wavelet features ieee international conference intelligent transportation systems september singapore 
sun miller real time vehicle detection system ieee international workshop application computer vision dec 
sun miller boosting object detection feature selection ieee international conference advanced video signal surveillance 
sun miller evolutionary gabor filter optimization application vehicle detection ieee international conference data mining 
sun miller road vehicle detection optical sensors review ieee international conference intelligent transportation systems 
kung hao liang multiresolution segmentation optical flow fields object tracking applied signal processing vol 
pp 
springer verlag london 
ali ahmad robust vision moving target detection tracking system proceeding image vision computing conference new th th november 
benjamin coifman david beymer jitendra real time computer vision system vehicle tracking traffic surveillance research part vol 
pp 

lou hao yang hu tan vehicle tracking improved ekf asian conference computer vision 
dieter koller joseph weber jitendra malik robust multiple car tracking occlusion reasoning third european conference computer vision pp 
springer verlag 
esther meier frank ade condensation algorithm implement tracking mobile robots third european workshop advanced mobile robots pp 
zurich th th september 
andrea applications contour tracking techniques citeseer ist psu edu html 
comaniciu ramesh peter meer real time tracking non rigid objects mean shift ieee conf 
computer vision pattern recognition vol 
pp 
hilton head island south carolina 
comaniciu ramesh mean shift optimal predication efficient object tracking ieee int 
conf 
image processing vol 
pp 
vancouver canada 
robert collins mean shift blob tracking scale space ieee computer vision pattern recognition vol 
madison wi pp 
june 
niels xin li teresa olson shah target tracking flir imagery mean shift global motion compensation proceedings ieee computer vision visible spectrum hawaii 
human body tracking adaptive background models mean shift analysis ieee international workshop performance evaluation tracking surveillance march 
robert collins liu line selection discriminative tracking features ieee international conference computer vision vol 
nice france pp 
october 
gary computer vision face tracking perceptual user interface ieee workshop 
comp 
vis vol 
pp 
princeton 
paul viola michael jones robust real time object detection second international workshop statistical computational theories vision modeling learning computing sampling vancouver canada july 
quality training sample estimates bhattacharyya coefficient ieee transactions pattern analysis machine intelligence vol 
january 
