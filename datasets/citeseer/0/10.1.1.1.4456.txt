active learning label ranking functions klaus uni paderborn de international graduate school dynamic intelligent systems university paderborn paderborn germany effort necessary construct labeled sets examples supervised learning scenario disregarded applications time consuming expensive procedure 
constitutes major issue classification learning serious problem dealing complex target domain total orders set alternatives 
considering pairwise decomposition constraint classification technique represent label ranking functions introduce novel generalization pool active learning address problem 

increasing shift predetermined static personalized highly adaptive systems affected various areas application 
techniques application flows incorporate user preferences produced efficient systems domains commerce information retrieval design user interfaces langley 
fundamental prerequisite systems consider individuals predefined standard users ability efficiently acquire accurate preference models 
consider special category preference learning problems called label ranking problems 
fundamental objective learn mapping input space set total orders finite priori fixed set alternatives labels 
example suppose set customers represented features age income family status ordered preferences set appearing proceedings st international conference machine learning banff canada 
copyright authors 
car models porsche toyota ford 
learning task consists inducing mapping customers set permutations car models 
employ induced ranking function predict order preference new customers 
contrast classification setting interested top ranked alternative complete preference order 
incorporating additional information build powerful prediction systems instance able preference suggestions situations top ranked alternative currently available reason 
case multiclass classification exist different approaches reduce ranking problems binary classification problems 
straightforward generalization multiclass classification ranking problems decomposed binary classification problems considering pairwise preferences alternatives rnkranz 
pairwise preference problem treated independently binary classification problem predictions means voting procedure 
alternative approach expression ranking problem terms single binary classification problem proposed har peled 

transforming initial ranking problem involves embedding training data higher dimensional space expanding single ranking examples multiple binary classification examples 
approaches consider problem learning ranking function supervised batch learning scenario 
assumed training set examples associated corresponding permutations 
applications assigning permutations examples referred labeling compliance standard notation performed automatically involves human decisions costly interviews 
time consuming expensive task 
constitutes major issue classification learning serious problem dealing complex target domain set permutations ask customer top preference expensive request complete preference order possible alternatives 
superordinate concept active learning refers collection approaches aim reducing labeling effort see section detailed discussion 
consider pool active learning model lewis gale starting small amount labeled examples learning algorithm sequentially selects new examples finite set unlabeled examples requests corresponding permutations 
crucial point selecting informative examples labeled applications possible learn model fewer labeled examples significant loss generalization accuracy comparison conventional batch learning entire set labeled examples 
field kernel machines active learning successfully applied classification problems reduce labeling effort tong koller campbell warmuth 
approaches restricted binary multiclass classification problems extend ranking problems 
propose novel extension active learning ranking problems 
considering pairwise decomposition rnkranz constraint classification technique har peled propose heuristic strategies selection new training examples 
experimental results indicate significant reduction labeling effort 
organized follows subsequent section discusses stated techniques express train ranking functions 
section investigate active learning case ranking problems introduce novel generalization 
section discusses experimental results conducted number synthetic datasets demonstrates benefits approach 
section point related research give 

ranking problems section techniques solve ranking problems 
formally learning problem investigating stated follows training set labeled examples 
xm ym noted refer pool active learning model active learning 
denoting nonempty set symmetric group degree yi yi 
yi yi 
yi 
seek induce function prediction new examples 
words objects learned total orders finite priori fixed set alternatives represented permutations 
permutation interpreted follows alternative precedes alternative preferred representation reasonable assumption order set labels irreflexive anti symmetric detailed discussion see rnkranz 
increase expressivity typically highly accurate base classifiers embed examples input space kernel corresponding kernel feature space denoted feature map sch lkopf smola 

constraint classification constraint classification approach har peled provides framework solve variety complex learning problems ranking multilabel problems binary linear classifiers 
restrict discussion ranking problems linear case endowed canonical dot product avoid lengthy technical presentation 
comment integrate concept kernels 
consider class linear sorting functions wi 
wd denoting weight vectors linear functions returning permutation 
precedes wi wj case equality precedes 
transforming initial ranking problem involves embedding training data higher dimensional space expanding single ranking examples multiple binary classification examples denote embedding nd features 
copied features 
augmented vector remaining features set 
expand set positive binary classification examples rnd set negative examples transformed training set defined union expanded examples xi yi xi yi 
suppose apply arbitrary learning algorithm training set calculates separating hyperplane nd furthermore consider concatenation ndimensional vectors 
wd means define linear sorting function separating hyperplane follows 
linear sorting function correctly arranges alternatives 
constraints consecutive alternatives encoded positive binary examples consistent original ranking training set 
fact ensure consistency case need expansion negative examples 
expansion positive negative examples framework applicable regardless underlying training algorithm exploit fact training set symmetric origin 
case support vector machines class algorithm proposed sch lkopf 
modified straightforward fashion positive set 
modification reasoning parametrization sch lkopf parametrization 
apart theoretical analysis implement constraint classification framework explicitly expanding examples 
efficient store constraints imposed consecutive alternatives original examples expanded examples suitable meta kernel 
furthermore standard technique incorporated place 

pairwise ranking pairwise ranking rnkranz generalization multiclass classification learns separate binary classifier pairs alternatives 
binary classifier hij decides example alternative preferred 
training set hij consists complete set feature vectors 
xm class label example assigned depending precedes vice versa 
predict new ranking determine classifications binary classifiers hij interpret outcome vote alternative possible alternatives sorted descending order respect sum votes 
case ties suboptimal prioritize alternatives smaller indices 
formally strategy stated follows max hij max 
pairwise ranking provides framework applicable assumptions underlying binary classifier 
consider support vector machines base classifiers 
close decision alternatives example close classification boundary necessarily clever strategy assign complete vote 
addition stated standard voting strategy investigate modified strategy approach proposed platt estimate posterior positive class probabilities ij class labels assign partial votes alternatives ij ji 
refer method probabilistic voting 

active learning section introduces novel heuristic active learning criteria constraint classification pairwise decomposition technique 
derive selection criterion constraint classification method version space model binary classification problems consider linearly separable feature space binary classification problem 
note deal noisy linearly nonseparable data elegant way adding constant diagonal elements kernel matrix xi xj ij training set linearly separable loss shawe taylor cristianini 
nonempty set def sign xi yi 
consists normalized weight vectors corresponding linear classifiers feature space separate training set errors called version space mitchell 
view learning search problem version space training example xi yi limits volume version space correspond consistent classifier weight vector satisfy sign xi yi yi xi 
words consistent solutions restricted halfspace boundary hyperplane normal vector yi xi 
fixed feature vector xi class label yi determines orientation halfspace 
intersection halfspaces convex polyhedral cone unit sphere feature space classical result theory convex sets states halfspace containing center mass convex set comprises volume gr 
assume able repeatedly select unlabeled examples correspond restricting hyperplanes passing exactly current center mass version space 
independent actual class label volume version space reduced exponentially terms number labeled examples 
derive practical selection criterion number approximations computationally expensive calculate center mass high dimensional spaces 
center mass approximated center largest radius ball version space 
working normalized set examples approximation corresponds support vector machine 
finite set unlabeled examples choose able find example exactly meets stated criterion 
select unlabeled example restricting hyperplane closest approximation center mass examples minimizing 
precisely argument hold consider augmented convex version space intersection unit ball 
assume requested example labeled larger part current version space remains 
ratio volume reduction approaches closer restricting hyperplane center mass convex set isotropic position halfspace distance center mass contains volume mas vempala 
analogous reasoning margin labeled example considered approximate measure reduction volume lower values correspond higher reduction negative values correspond case smaller part version space remains 
considering best worst case approach obtain minimization maxy selection criterion reformulation criterion binary case 
apart version space model considered tong koller additional theoretical justifications approach campbell 
coming back constraint classification framework notion margin generalized straightforward fashion minimum margin set expanded binary examples har peled definition generalized margin 
margin ranking example respect linear sorting function defined min support vector machine component learner expanded binary training set solve corresponding ranking problem maximizes generalized margin 
definition reduces standard margin ranking problems considered binary classification problems 
straightforward derive upper bound margin ranking example max min min def 
wi wj note bound tight sense exists equality holds wi 
unlabeled example evaluates worst case margin choices straightforward fashion generalize selection new training examples minimum worst case margin classification learning problem learning ranking functions unlabeled examples evaluate request correct ranking corresponding example minimum worst case margin 
different point view select examples yielding approximately maximum worst case volume reduction version space 
pairwise ranking technique conducts expansion binary classification problems considering pairs alternatives 
set independently treated binary problems directly amenable analysis binary version space model 
order derive heuristic selection criterion consider best worst case approach respect minimum binary margin set binary examples corresponding ranking example 
contrast constraint classification framework margins evaluated different binary classifiers 
precisely labeled ranking example consider real valued output binary classifiers hij calculate minimum binary margin 
unlabeled example computationally infeasible consider 
possible permutations evaluate minimum margin set binary examples worst case 
approximate permutation yielding minimum margin predicted permutation unlabeled ranking example 
case probabilistic voting strategy consider analogous best worst case approach respect minimum binary class probabilities 
summarize selection criterion pairwise ranking model calculate predicted rankings unlabeled examples select unlabeled example achieves minimum margin class probability set binary problems 

experiments 
experimental setting evaluate efficiency novel selection criteria conducted number experiments support vector machines chang lin binary linear learners 
due lack suitable real world datasets generated artificial data considering different settings 
linear replicate setting proposed rnkranz field expected utility theory expected utility maximizing agent set 
alternative actions choose 
agent faces problem decision uncertainty alternative yielding utility ij world state 

probability state denoted expected utility alternative ij 
giving rise natural order set alternative actions 
assume set alternatives decreasing order respect expected utility 
assume probability vector 
feature vector ranking example number alternatives set world states fixed utility matrix having independently uniformly distributed entries ij 
probability vector stated decision theoretic scenario gives rise order set alternative actions 
set feature vectors independently drawn uniform distribution rn assigned corresponding permutations generate ranking dataset 
note setting corresponds noise free scenario constraint classification framework feature vector alternative way express corresponding ranking ui ui denoting th row vector 
conducted experiments dataset linear kernel penalty parameter 
minmax setting considers modified nonlinear preference relation generated max ij 
viewed special case pessimistic criterion evaluate worth alternative possibilistic decision framework dubois 
stay consistent stated assumptions feature vector single feature randomly selected set 
problem rbf kernel penalty parameter 
train naive bayes classifier vehicle multiclass dataset uci repository 
example set possible class labels alternatives ordered respect posteriori probabilities assigned naive bayes classifier 
point view consider problem learning qualitative replication order set alternatives induced probabilistic classifier 
setting rbf kernel default value features 
linear minmax scenario fixed number input features 
number alternatives generated different datasets consisting examples dataset originating different utility matrix dataset randomly split training set test set equal size 
scenario sample new data run 
underlying dataset randomly split training set test set equal size run compliance comparable research real world data 
new training examples selected training sets generalization accuracy estimated test sets 
known spearman rank correlation coefficient rank correlation evaluation metric true rankings predicted rankings rank correlation evaluates reversed preference orders identical orders 
rank correlation averaged examples test set 
due space restrictions comment alternative evaluation measures 
addition novel active learning generalization pairwise constraint classification technique investigated random selection new examples baseline strategy approaches 
started randomly selected set labeled examples experiments sequentially selected examples different selection criteria 
rank correlation evaluated rounds results averaged datasets generated settings 

experimental results remember choice kernel optimized respect different techniques 
compare random learning active counterparts separately approach focus quantitative comparison different techniques 
table shows average rank correlations corresponding standard errors mean different numbers labeled examples 
due space restrictions linear minmax scenario detailed results stated number alternatives fixed 
linear active strategies consistently outperform random counterparts choices number alternatives 
substantial increase accuracy case alternatives marginal case constraint classification number alternatives increasing 
contrast pairwise decomposition techniques absolute rise accuracy fixed numbers labeled examples increases number alternatives 
minmax active standard pairwise strategy achieves level accuracy labeled examples independent close random learning examples 
probabilistic pairwise technique substantial increase accuracy active strategy superior random learning slightly outperforms active counterpart 
case constraint classification observed pattern similar setting active learning consistently outperforms random learning 
gain accuracy decreases number alternatives increasing 
active constraint classification learning consistently outperforms random learning 
compared approach pairwise decomposition strategies yield significant decrease labeling effort reduction roughly fold actively learning circa examples yields estimated generalization accuracy randomly learning examples 
classification learning efficiency active learning clearly depends ranking problem 
experiments active learning constraint classification approach consistently outperforms random learning 
active learning standard probabilistic pairwise decomposition yields significant relative reduction labeling effort experiments 
furthermore computational effort solve ranking problem constraint classification technique orders magnitude higher pairwise decomposition techniques 
experiments suggest favorable pairwise decomposition approach actively learning ranking function 

related label ranking model alternative preference models consider different learning scenarios 
field statistical decision theory mathematical economics problem learning preference utility function von neumann morgenstern individual referred preference elicitation 
case objective assign real valued utility scores examples single user preferences ranking functions assign finite preference order example 
generally model examples corre setting strategy table 
experimental results random cc active cc random pw linear active pw random active random cc active cc random pw minmax active pw random active random cc active cc random pw active pw random active constraint classification cc standard pairwise pw probabilistic pairwise 
decision alternatives model finite set alternatives priori fixed examples correspond different individuals 
learning utility function considered regression problem 
field kernel methods crammer singer introduced online algorithm learn utility function ordinal scale order set new examples respect ordinal utility scores 
problem referred ordinal regression investigated batch setting herbrich 

class regression preference models cohen 
propose stage approach preference learning stage learn probabilistic preference function pairs examples stage order set new examples approximately optimal sense 
field active learning principle categories approaches called query learning angluin refers learning model learning algorithm ability generate new examples request corresponding true class labels 
selective sampling learner restricted request labels finite set examples pool model learning algorithm decide request corresponding true labels sequentially single examples stream model 
studied bayesian query committee seung freund approach considers scenario decides request class labels disagreement set gibbs classifiers 

introduced novel extensions pool active learning label ranking problems constraint classification technique pairwise decomposition preferences 
experimental results clearly indicate active learning significantly reduce labeling effort ranking learning 
considering expensive label ranking classification examples benefit active ranking learning evident 
acknowledgments chih len lin helpful suggestions comments 
angluin 

queries concept learning 
journal machine learning 
bertsimas vempala 

solving convex programs random walks 
proceedings th acm symposium theory computing stoc pp 

montreal 
campbell cristianini smola 

query learning large margin classifiers 
proceedings seventeenth international conference machine learning icml pp 

chang lin 

libsvm library support vector machines 
software available www csie ntu edu tw cjlin libsvm 
cohen schapire singer 

learning order things 
journal artificial intelligence research 
crammer singer 

ranking 
advances neural information processing systems pp 

cambridge ma mit press 
dubois prade 

decision theoretic foundation qualitative possibility theory 
european journal operational research 
freund seung shamir tishby 

selective sampling query committee algorithm 
machine learning 
rnkranz 

pairwise preference learning ranking 
proceedings th european conference machine learning pp 

croatia springer verlag 
gr 

partitions mass distributions convex bodies hyperplanes 
pacific math 
har peled roth 

constraint classification new approach multiclass classification ranking 
advances neural information processing systems nips 
herbrich graepel obermayer 

advances large margin classifiers chapter large margin rank boundaries ordinal regression 
cambridge ma mit press 
langley 

machine learning adaptive user interfaces 
proceedings st german annual conference artificial intelligence pp 

lewis gale 

sequential algorithm training text classifiers 
proceedings sigir th acm international conference research development information retrieval pp 

dublin springer verlag 
mitchell 

generalization search 
journal artificial intelligence 
platt 

probabilistic outputs support vector machines comparison regularized likelihood methods 
advances large margin classifiers pp 

cambridge ma mit press 


personalized views personalization 
communications acm 
sch lkopf platt shawe taylor smola williamson 

estimating support high dimensional distribution 
neural computation 
sch lkopf smola 

learning kernels support vector machines regularization optimization 
cambridge ma mit press 
seung opper sompolinsky 

query committee 
proceedings fifth acm workshop learning theory pp 

shawe taylor cristianini 

results margin distribution 
proceedings twelfth annual conference computational learning theory pp 

santa cruz california united states acm press 
tong koller 

support vector machine active learning applications text classification 
proceedings seventeenth international conference machine learning pp 

morgan kaufmann san francisco ca 
von neumann morgenstern 

theory games economic behavior 
princeton university press 
warmuth tsch liao 

active learning drug discovery process 
advances neural information processing systems pp 

