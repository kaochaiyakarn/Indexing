generalization error bounds collaborative prediction low rank matrices nathan tommi jaakkola computer science artificial intelligence laboratory massachusetts institute technology cambridge ma usa tommi mit edu prove generalization error bounds predicting entries partially observed matrix approximating observed entries low rank matrix 
bound number sign configurations matrices result realizable oriented matroids 
collaborative filtering refers general task providing users information items dislike preferences far relate preferences users 
approach contrasts traditional approach predictions features items 
feature approaches accustomed studying prediction methods terms probabilistic post hoc generalization error bounds 
results provide probabilistic bound performance predictor examples terms performance training data 
bounds hold assumptions true model true dependence labels features central assumptions training examples drawn distribution interest 
suggest studying generalization ability collaborative prediction methods 
collaborative prediction indicate objective able predict user preferences items entries unknown target matrix user item ratings observing subset ys entries matrix bounds true average error nm loss xia predictions terms average error observed entries ds ia loss xia making assumptions true nature pref erences assume subset entries observe chosen uniformly random 
strong assumption parallels source assumption feature prediction 
collaborative filtering tasks objective able provide user items overlap top rated items important able correctly predict users ratings items 
note possible derive generalization error bounds objective bounds prediction objective 
arbitrary source distribution target matrix random training set random set observed entries hypothesis predicted matrix training error observed discrepancy ds generalization error true discrepancy correspondence post hoc bounds generalization error standard feature prediction tasks particular generalization error bounds prediction low rank models 
collaborative prediction low rank models fairly straight forward 
low rank matrix sought minimizes average observed error ds 
unobserved entries predicted premise model small number factors influencing preferences user preference vector determined factor applies user 
different methods differ relate real valued entries preferences associated measure discrepancy 
example entries seen parameters probabilistic models entries mean parameters natural parameters maximum likelihood criterion 
loss functions squared error zero loss versus signs entries minimized :10.1.1.141.6972
prior previous results bounding error collaborative prediction matrix assume true target matrix approximated low rank matrix 
corresponds large top singular values remaining singular values 
azar gives asymptotic results convergence predictions true preferences assuming 
drineas analyzes sample complexity needed able predict matrix suggests strategies actively querying entries target matrix 
knowledge analysis generalization error low rank methods assumptions true target matrix 
generalization error bounds related online learning bounds previously discussed collaborative prediction applications prediction done user separately feature method user preferences features :10.1.1.20.378
address collaborative prediction application learning setting standard feature setting 
methods limited learning performed separately user 
shaw taylor discuss assumption free post hoc bounds residual errors low rank approximation 
results apply different setting subset rows fully observed bound different quantity distance rows learned subspace distance predicted entries 
generalization error bound low rank matrices focusing binary labels zero sign agreement loss loss xia sign xia main result theorem 
matrix integer probability choosing subset entries uniformly subsets denote sign distinguishing ternary variant sign 
entries rank kd ds log log prove theorem fix rn index pair chosen uniformly random loss xia bernoulli random variable probability 
entries chosen independently uniformly ds binomially distributed mean chernoff inequality pr ds distribution theorem slightly different chosen repetitions 
mean ds concentrated holds 
consider rank matrices 
noting loss xia depends sign xia consider equivalence classes matrices sign patterns 
number equivalence classes number possible sign configurations matrices rank sign rank sign denotes element wise sign matrix sign ia xia matrices equivalence class random variable ds union bound events ds random variables pr rank kd ds log log log log setting proof theorem rests bounding section 
note equivalence classes defined depend sample set symmetrization argument necessary 
suggest improving bound specific equivalence classes considering sign configurations entries gained refinements 
consider example bounding number specific equivalence classes vc dimension arguments 
nm meaningful sample sizes max hope generalize improvement bound constant factor lost symmetrization arguments 
bounding growth function directly yield improvements specific sample size log nm improvement factor log nm 
sign configurations low rank matrix bound number possible sign configurations rank matrices reals 
matrix rank written product uv count sign configurations get fixed sign uv 
lemma 
proof 
interpreting rows point interpret nonzero column specifying homogeneous hyperplane partitioning points corresponding column sign uv sign uv sign vector specifying classification points hyperplane number possibilities column accounting zero plus number possible classification points rk homogeneous hyperplanes theorem multiplying number possibilities columns bounding yields desired bound 
bound lemma need bound number possible matrices accurately number equivalence classes matrices yielding set possible column vectors sign uv deriving generalization error bounds accustomed bounding number possible classifiers sample set 
need bound number different sample sets number possible samples points rows linearly separated different ways 
consider slightly relaxed equivalence classes known realizable oriented matroid bound known 
definition 
oriented matroid realized rows defined set sign uv number different oriented matroids realizable points 
matrices realizing oriented matroid realize set possible classifications just projections mapping bound applies number equivalence classes matrices yielding identical 
multiplying bound bound number different sign configurations lemma conclude theorem 
logarithm bounding log log proves theorem 
log log 
symmetric state log log 
suggesting true bound log form log nm avoiding term 
note logarithmic term unavoidable best expect lemma 
log proof 
fix matrix rows general position log log exact points general position 
note bound guaranteed sauer lemma exponent overlaps realizable oriented matroids reasons bound theorem loose excessive term able classification vectors 
large number realizable oriented matroids overlap greatly resulting sets overlap greatly 
summing sizes sets deriving theorem ignoring overlaps 
bounding extent overlaps lead tighter bound 
ternary sign configurations point hyperplane arrangements classification purposes concerned binary sign configurations arbitrarily sign 
easily modify theorem bound ternary sign configurations distinguishing zeros positive entries obtaining bound sign configurations interpreted follows oriented matroid specifies configuration points respect possible homogeneous hyperplanes 
consider arrangements labeled points labeled homogeneous hyperplanes arrangement equivalent point arrangement lies side hyperplane corresponding point second arrangements 
low rank matrices combined classifiers rank matrices matrices linear combinations rank matrices 
view matrices functions pairs indexes reals think rank matrices combined classifiers attempt bound vc dimension 
rank matrices written outer product vectors matrix depends signs zeros vectors 
number sign configurations matrices bounded mn vc dimension indicator functions log 
bound vc dimension combination indicator functions low bound vc dimension combinations signs rank matrices order bound vc dimension low rank matrices combinations real valued functions 
able discuss combinations real valued functions quantity accounts complexity function away zero complexity signs function 
standard measure class functions dim class real valued functions vc dimension class subsets conjecture combinations real valued functions low exhibit low conjecture 
dim dim 
fk fi notation indicates possible log factors 
conjecture true indicator functions 
real valued functions metric entropy uniform bound log covering number bounded terms display graceful scaling respect linear combinations 
metric entropy scale sensitive measure meaningful bound entries matrix scale sensitive question note certain conditions metric entropy bounded unlimited convex combinations low real valued functions raised dudley knowledge unresolved 
analyze rank matrices 
bounding threshold matrix number relative sign matrices fp sign lemma 
fp fp mn proof 
fixed consider number possibilities column sign vj pj relative sign matrix 
varying vj negative infinity positive infinity sign sign pij change change uj yielding possible sign vectors sign vj pj fixed sign matrices sign fixed bound number vectors rn yielding different possibilities sign 
sign pattern determines sign patters column sign vj pj extreme positive negative infinity values vj 
sign pattern range attainable sign vectors sign vj pj varying vj determined order signs sign pij flipped vj varies negative infinity positive infinity 
sign sign vj flipped sign vj column pj fixed sign pattern order signs sign vj pj flipped range attainable sign columns determined signs ju ju 
sign matrices sign attainable rn determined location relative hyperplanes ui hyperplanes ju ju 
yielding different range sign matrices corresponds different oriented matroid realized nm hyperplane normals number oriented matroid mn note number classifications distinction hyperplane positive side important 
multiplying number different sign configurations possible number vectors yielding different possibilities yields desired bound mn theorem 
rank matrices reals log 
proof 
consider largest subset shattered shattered different points corresponding index pair seen defining partial matrix rn pij ij shattering corresponds attaining possible sign patterns relative entries filling entries arbitrarily get possible sign patterns relative complete know lemma matrix get mn sign patterns relative dim log mn log mn 
combinations convex combination small class classifiers infinite 
bounds convex combinations inherently scale sensitive bounds finite linear combinations combinatorial case example linear combination indicator functions low vc dimension 
loss functions section considered generalization error bounds zero loss function 
commonly loss functions desirable obtain generalization error bounds general loss functions 
conjecture true bound low rank matrices obtain generalization error bounds bounded monotone loss function low rank matrices 
limited approach requires bounding entries low rank matrix 
calculating covering number bounded entry low rank matrices 
matrices lemma 
exists net bk rank matrix exists matrix xia xia proof 
construct set products matrices rank matrix matrices values factored uv ui va xia xia ui va va va va va ui va va ua arguments similar theorem provide generalization error bound lipschitz bounded loss function approximating matrix matrix union bound 
theorem 
lipschitz continuous loss function values interval matrix integer probability choosing subset entries uniformly subsets entries log rank kd ds lb log proof 
fix consider loss xia random variable chosen uniformly random 
ds average random variables mean bounded zero hoeffding inequality arguments similar theorem pr ds get bound uniform rank consider net matrices guaranteed lemma 
lipschitz continuity ensures net elementwise loss matrices rank exists loss xia loss xia ds ds yielding ds ds 
union bound bad events ds matrices rank bounded matrices setting pr xd ds kb log log get desired bound 
discussion suggest framework studying generalization ability collaborative prediction methods generalization error bound collaborative prediction low rank models 
core component bound combinatorial result number sign configurations low rank matrices proof classic results goodman pollack alon number realizable oriented matroids 
connection machine learning oriented matroids natural oriented matroid viewed possible classification vectors 
statistical machine learning empirical process theory usually satisfied bound size oriented matroid number number different classifications sample set uses sauer lemma obtain 
require bound number oriented matroids number different sample sets 
theory oriented matroids provides bound 
better understanding overlaps realizable oriented matroids number help improve bound 
borrowing results oriented matroids object study sign configurations low rank matrices natural interpretation terms point hyperplane arrangements 
bound logarithm number sign configurations form kn log nm 
bound yields useful bounds generalization error conjecture dependence extraneous true bound form log nm 
type dependence closely matches parametric dimension rank matrices lower bound lemma 
suggest alternative approach bounding number sign configurations low rank matrices considering matrices convex combinations rank matrices bounding 
approach conjecture combined classifiers 
note proving conjecture tighten bounds yield generalization error bounds low rank collaborative prediction general loss functions allow relaxing boundedness assumptions general results combined classifiers 
acknowledgments erik demaine directing oriented matroids john barnett showing bounded entry low rank matrix factorization 
thomas hofmann 
latent semantic models collaborative filtering 
acm trans 
inf 
syst 
benjamin marlin 
modeling user rating profiles collaborative filtering 
nips 
nathan tommi jaakkola 
weighted low rank approximation 
th international conference machine learning 
benjamin marlin richard zemel 
multiple multiplicative factor model collaborative filtering 
appear icml 
yossi azar amos fiat anna karlin frank mcsherry jared 
spectral analysis data 
acm symposium theory computing pages 
petros drineas prabhakar raghavan 
competitive recommendation systems 
acm symposium theory computing 
crammer singer 
ranking 
nips 
sanjoy dasgupta wee sun lee philip long 
theoretical analysis query selection collaborative filtering 
machine learning 
john shawe taylor nello cristianini kandola 
concentration spectral properties 
nips 
gerhard 
counting certain oriented matroids 
phd thesis 
bj las white ziegler editors 
oriented matroids 
cambridge university press nd edition edition 
jacob goodman richard pollack 
upper bounds configurations polytopes discrete computational geometry 
noga alon 
number polytopes configurations real matroids 

dudley 
universal classes metric entropy 
annals probability 
