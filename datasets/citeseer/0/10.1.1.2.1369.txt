ganglia distributed monitoring system design implementation experience matthew univ california berkeley cs berkeley edu brent chun intel research berkeley bnc intel research net david culler univ california berkeley culler cs berkeley edu ganglia scalable distributed monitoring system highperformance computing systems clusters grids 
hierarchical design targeted federations clusters 
relies multicast listen announce protocol monitor state clusters uses tree pointto point connections representative cluster nodes federate clusters aggregate state 
leverages widely technologies xml data representation xdr compact portable data transport data storage visualization 
uses carefully engineered data structures algorithms achieve low node overheads high concurrency 
implementation robust ported extensive set operating systems processor architectures currently clusters world 
presents design implementation evaluation ganglia experience gained real world deployments systems widely varying scale configurations target application domains half years 
years enormous shift high performance computing systems composed small numbers computationally massive devices systems composed large numbers commodity components :10.1.1.109.4049
architectural shift causing designers high performance systems revisit numerous design issues assumptions pertaining scale reliability heterogeneity manageability system evolution time 
clusters de facto building block high performance systems scale reliability key issues independently failing unreliable components need continuously accounted managed time 
heterogeneity previously non issue running single vector supercomputer mpp designed systems grow time scale hardware software base 
manageability paramount importance clusters today commonly consist hundreds thousands nodes 
systems evolve accommodate growth system configurations inevitably need adapt 
summary high performance systems today sharply diverged monolithic machines past face set challenges large scale distributed systems 
key challenges faced high performance distributed systems scalable monitoring system state 
large collection nodes associated computational network demands placed applications failures large scale systems commonplace 
deal node attrition maintain health system monitoring software able quickly identify failures repaired automatically band means rebooting 
large scale systems interactions myriad computational nodes network switches links storage devices complex 
monitoring system captures subset interactions visualizes interesting ways lead increased understanding system macroscopic behavior 
systems scale increasingly distributed bottlenecks arise various locations system 
monitoring system assist providing global view system helpful identifying performance problems ultimately assisting capacity planning 
ganglia scalable distributed monitoring system built address challenges 
provides scalable monitoring distributed systems various points architectural design space including large scale clusters machine room computational grids consisting federations clusters seen application open shared planetary scale application testbed called planetlab 
system hierarchical design targeted federations clusters 
relies multicast listen announce protocol monitor state clusters uses tree point point connections representative cluster nodes federate clusters aggregate state 
leverages widely technologies xml data representation xdr compact portable data transport data storage visualization 
uses carefully engineered data structures algorithms achieve low node heads high concurrency 
implementation robust ported extensive set operating systems processor architectures currently clusters world 
presents design implementation evaluation ganglia distributed monitoring system account experience gained real world deployments systems widely varying scale configurations target application domains 
organized follows 
section describe key challenges building distributed monitoring system relate different points system architecture space 
section architecture ganglia scalable distributed monitoring system high systems 
section describe current implementation ganglia currently deployed clusters world 
section performance analysis implementation account experience gained real world deployments ganglia large scale distributed systems 
section related section conclude 
distributed monitoring section summarize key design challenges faced designing distributed monitoring system 
discuss key characteristics classes distributed systems ganglia currently clusters grids planetary scale systems 
class systems presents different set constraints requires making different design decisions trade offs addressing key design challenges 
ganglia initial design focus scalable monitoring single cluster naturally evolved support classes distributed systems 
computational grids integration globus service mds example 
application planetlab resulted reexamination ganglia original design decisions 
design challenges traditionally high performance computing focused scalability primary design challenge 
architectural shift increasingly distributed loosely coupled systems raised additional set challenges 
new challenges arise result factors increased physical distribution long running distributed services scaling evolution systems time 
increased physical distribution implies multiple independently failing unreliable components 
turn requires designing applications management overheads scale slowly number nodes 
long running distributed services imply need highly available clients service 
turn requires applications robust variety different types failures 
scaling evolution systems time implies hardware software change 
turn requires addressing issues extensibility portability 
key design challenges distributed monitoring systems include scalability system scale gracefully number nodes system 
clusters today example commonly consist hundreds thousands nodes 
grid computing efforts eventually push numbers 
robustness system robust node network failures various types 
systems scale number nodes failures inevitable commonplace 
system localize failures system continues operate delivers useful service presence failures 
extensibility system extensible types data monitored nature data collected 
impossible know priori want monitored 
system allow new data collected monitored convenient fashion 
manageability system incur management overheads scale slowly number nodes 
example managing system require linear increase system administrator time number nodes system increases 
manual configuration avoided possible 
portability system portable variety operating systems cpu architectures 
despite trend linux wide variation hardware software high performance computing 
systems globus facilitate heterogeneous systems 
overhead system incur low node overheads scarce computational resources including cpu memory network bandwidth 
high performance systems particularly important applications enormous resource demands 
distributed systems currently classes distributed systems ganglia clusters grids planetary scale systems 
class systems presents different set constraints requires making different design decisions trade offs addressing key design challenges 
constraints revolve primarily systems physically organized distributed types resources scarce expensive 
design decisions trade offs involve address key design challenges light constraints 
example ganglia currently uses multicast listen announce protocol monitor state single cluster 
approach offers advantages including automatic discovery nodes added removed manual configuration cluster membership lists topologies symmetry node knows entire state cluster 
assumes presence native multicast capability assumption hold internet general relied distributed systems grids require wide area communication 
summarizes classes distributed systems ganglia currently deployed clusters clusters characterized set nodes communicate high bandwidth low latency interconnect myrinet gigabit ethernet 
systems nodes frequently homogeneous hardware operating system network rarely partitions universally system managed single administrative entity 
grids grids characterized set heterogeneous systems federated wide area network 
contrast general internet systems usually interconnected special high speed wide area networks abilene network order get bandwidth required applications 
systems frequently involve distributed management multiple administrative entities 
planetary scale systems planetary scale systems characterized wide area distributed systems geographical extent covers fraction planet 
systems built overlay networks top existing internet 
implications wide area bandwidth nearly abundant compared clusters grids ii network bandwidth cheap iii network experiences congestion partitions frequently cluster grid case 
architecture ganglia hierarchical design targeted federations clusters 
relies multicast listen announce protocol monitor state clusters uses tree point point connections representative cluster nodes federate clusters aggregate state 
cluster ganglia uses heartbeat messages known multicast address basis membership protocol 
membership maintained reception heartbeat sign node available non reception heartbeat small multiple periodic announcement interval sign node unavailable 
node gmond node gmond node gmond 
cluster failover poll node gmond node gmond node gmond 
cluster failover poll poll poll client data connect ganglia architecture 
node monitors local resources sends multicast packets containing monitoring data known multicast address significant updates occur 
applications may send multicast address order monitor application specific metrics 
ganglia distinguishes built metrics application specific metrics field multicast monitoring packets sent 
nodes listen types metrics known multicast address collect maintain monitoring data nodes 
nodes approximate view entire cluster state state easily reconstructed crash 
ganglia federates multiple clusters tree point point connections 
leaf node specifies node specific cluster federated nodes higher tree specify aggregation points 
cluster node contains complete copy cluster monitoring data leaf node logically represents distinct cluster non leaf node logically represents set clusters 
specify multiple cluster nodes leaf handle failures 
aggregation point tree done polling child nodes periodic intervals 
monitoring data leaf nodes aggregation points exported mechanism tcp connection node polled followed read monitoring data 
implementation implementation consists daemons gmond command line program client side library 
ganglia monitoring daemon gmond provides monitoring single cluster implementing listen announce protocol responding client requests returning xml representation monitoring data 
gmond runs node cluster 
ganglia meta daemon hand provides federation multiple clusters 
tree tcp connections multiple daemons allows monitoring information multiple clusters aggregated 
command line program applications publish application specific metrics client side library provides programmatic access subset ganglia features 
monitoring single cluster monitoring single cluster implemented ganglia monitoring daemon gmond 
gmond organized collection threads assigned specific task 
collect publish thread responsible collecting local node information publishing known multicast channel sending periodic heartbeats 
listening threads responsible listening multicast channel monitoring data nodes updating gmond memory storage hierarchical hash table monitoring metrics 
thread pool xml export threads dedicated accepting processing client requests monitoring data 
data stored gmond soft state written disk 
combined nodes multicasting state means new gmond comes existence simply listening announcing 
xml export threads memory storage listening threads collect publish thread gmond gmond multicast channel application application metric data proc kvm xml application ganglia implementation 
speed low overhead gmond uses efficient data structures designed speed high concurrency 
monitoring data collected gmond daemons stored hierarchical hash table uses reader writer locking fine grained locking high concurrency 
concurrency allows listening threads simultaneously store incoming data multiple unique hosts 
helps resolve competition listening threads xml export threads see access host metric records 
monitoring data received xdr format saved binary form reduce physical memory usage 
typical configuration number incoming messages processed multicast channel far outweigh number requests clients xml 
storing data form closer multicast xdr format allows rapid processing incoming data 
multicast listen announce protocol gmond uses multicast listen announce protocol monitor state single cluster 
approach great success previous cluster systems 
main advantages include automatic discovery nodes added removed manual configuration cluster membership lists topologies amenability building systems entirely soft state symmetry node knows entire state cluster 
automatic discovery nodes eliminating manual configuration important allows gmond nodes self configuring reducing management overhead 
amenability soft state approach important allows nodes crash restart consequence gmond 
nodes contain entire state cluster node polled obtain entire cluster state 
important provides redundancy especially important frequency failures large distributed system 
publishing monitoring data gmond publishes types metrics built metrics capture node state user defined metrics capture arbitrary application specific state known multicast address 
built metrics gmond currently collects publishes different metrics depending operating system cpu architecture running 
base metrics include number cpus cpu clock speed cpu user nice system idle load minute averages memory free shared buffered cached total processes running total swap free total system boot time system clock operating system name version architecture mtu 
userdefined metrics hand may represent arbitrary state 
gmond distinguishes built metrics user defined metrics field multicast packets sent 
metrics published multicast channel xdr format portability efficiency 
built metrics collected portable manner defined interfaces proc kvm 
built metrics sent multicast channel efficient manner leveraging static metric lookup table contains static characteristics metric unique key metric value needs sent announcement 
built messages bytes length bytes key bytes value 
metric key sent xdr int metric value type depends specific metric sent 
user defined metrics hand efficient xdr format metric characteristic explicitly defined 
metrics published arbitrary applications command line program 
key xdr int metric value format user defined explicit cpu num xdr short cpu speed xdr int mem total xdr int swap total xdr int 
load xdr float load xdr float load fifteen xdr float 
table example metrics defined gmond metric lookup table 
tables show subsets metric lookup table 
table show representative metrics corresponding xdr key number metric type value format table show details built metric collect announce schedule metric value thresholds metric units binary text conversion details 
attributes metric determine metric gets published multicast channel 
default values built metrics represent trade gmond resource metric time series granularity node cluster initial design point 
values modified compile time accommodate different environments 
metric collected val thresh 
time thresh user defined explicit explicit explicit cpu num cpu speed mem total swap total load load load fifteen table example metric collection schedules value time thresholds defined internal gmond metric lookup table 
collection value thresholds metric lookup table aim reducing resource usage collecting local node data sending multicast traffic significant updates occur 
collected attribute specifies metric collected 
larger values avoid collecting constant number cpus slowly changing metrics 
value thresholds specify metric needs changed value collected order deemed significant 
significant changes sent multicast channel 
timeouts heartbeats time thresholds specify upper bound interval metrics sent 
metrics sent multicast channel bounded random intervals reduce conflicts competing applications avoid synchronization gmond peers 
time thresholds allow applications ascertain message loss multicast channel determine accuracy metric values 
reclaim storage old metrics gmond expires monitoring data timeouts 
monitoring metric uses time limits soft limit max hard limit dmax 
incoming metric timestamped arrival time number seconds elapsed denoted tn gmond performs action soft limit reached 
gmond simply reports tn tmax clients xml attributes 
tn tmax clients immediately aware multicast message delivered value may inaccurate 
exceeding hard limit hand results monitoring data permanently removed gmond hierarchical hash table metric data 
non static built metrics constantly sent multicast channel application specific metrics sent applications may meaningless time application simply exits 
timeouts intended primarily handle types cases 
time nodes died gmond uses explicit heartbeat messages time thresholds 
heartbeat contains timestamp representing startup time gmond instance 
gmond altered timestamp immediately recognized peers having restarted 
gmond responded number time thresholds assumed 
empirically determined thresholds works practical balance quick false positives delayed determination actual downtime 
response new restarted hosts local metric time thresholds reset 
causes metrics published time collected regardless value ensures new restarted hosts quickly populated latest cluster state information 
reset mechanism rarely published metrics known new restarted host unacceptably long period time 
important note time threshold reset mechanism occurs gmond minutes old 
prevents huge multicast storms develop gmond cluster restarted simultaneously 
implementations new members directly bootstrap gmond multicast group 
federation federation ganglia achieved tree point topoint connections representative cluster nodes aggregate state multiple clusters 
node tree ganglia meta daemon periodically polls collection child data sources parses collected xml saves numeric volatile metrics round robin databases section exports aggregated xml tcp sockets clients 
data sources may gmond daemons representing specific clusters daemons representing sets clusters 
data sources source ip addresses access control specified multiple ip addresses failover 
capability natural aggregating data clusters gmond daemon contains entire state cluster 
data collection done periodically polling collection child data sources specified configuration file 
data source identified unique tag multiple ip address tcp port pairs associated equally capable providing data data source 
configuration files specifying structure federation tree simplicity computational grids consisting nodes typically consist small number distinct sites 
collect data child data source ganglia unique data collection thread 
unique thread data source results clean implementation 
small moderate number child nodes overheads having thread data source usually significant 
collected data parsed efficient manner reduce cpu overhead stored visualization historical trends 
xml data parsed efficient combination sax xml parser gnu perfect hash table 
sax parser opposed dom parser reduce cpu overhead reduce physical memory footprint 
hash table avoid large numbers string comparisons handling xml parsing events 
hash table generated gnu collection keys generates hash table hash function collisions 
possible ganglia xml element attribute built metric names comprised set keys generating hash table 
sax xml callback function uses perfect hash function raw string comparisons increased efficiency speed 
xml processed numerical values volatile saved databases 
visualization ganglia uses round robin database store visualize historical monitoring information grid cluster host metric trends different time granularities ranging minutes years 
popular system storing graphing time series data 
uses compact constant size databases specifically designed storing summarizing time series data 
data different time granularities generates graphs plot historical trends metrics versus time 
graphs ganglia exported users php web front 
web front uses com create strict separation content presentation 
allows web site developers easily customize look feel web site damaging underlying content engine 
custom templates created extend functionality web front 
example npaci rocks group created unique template provides visualization cluster pbs queues 
groups chosen directly import xml preexisting web infrastructure 
evaluation experience section quantitative analysis ganglia account experience gained real world deployments production distributed systems 
analysis measure scalability performance overhead 
data obtained example systems concrete 
experience report key observations lessons learned deploying maintaining ganglia production systems 
specifically describe worked describe experiences caused revisit certain design decisions order better support monitoring wide range distributed systems 
systems evaluated production distributed systems table evaluate ganglia representing different point architectural design space different application purposes 
system millennium system advanced applications scientific computing simulation modeling 
millennium cluster uc berkeley computer science department consists approximately smp nodes cpus 
way smp consists mhz pentium iii cpus mb ram gb disks gigabit ethernet myrinet connections 
way smp consists mhz pentium iii cpus gb ram gb disks gigabit ethernet myrinet connections 
nodes millennium connected gigabit ethernet network myrinet network run linux smp kernel 
second system suny buffalo hpc linux cluster currently largest linux cluster educational institution united states 
system primarily acceleration cancer research specifically investigation human genome bioinformatics protein structure prediction large scale computer simulations 
system number nodes number clusters millennium suny ucb cs planetlab table systems evaluated 
system consists approximately dual processor smp nodes 
smp dell dell server 
majority nodes servers contains dual ghz pentium iii cpus 
remaining nodes contain higher speed dual xeon processors 
system includes terabyte emc storage area network san uses extreme networks switches gigabit connectivity nodes 
nodes suny cluster run linux smp kernel 
third system federation clusters uc berkeley computer science department 
clusters variety purposes including computational science engineering global distributed storage systems serving web content 
system consists clusters residing building 
cluster aforementioned node millennium cluster 
second cluster node cluster way smps oceanstore group 
node cluster ibm consisting ghz pentium iii cpus gb ram gb disks 
nodes connected gigabit ethernet network runs linux smp kernel 
third cluster experimental node cluster way smps part project 
node cluster consists mhz itanium cpu gb ram connected gigabit ethernet network 
federation rest cs clusters ganglia concrete example ganglia heterogeneous cpu architectures 
fourth cluster node web server cluster 
node cluster mhz pentium ii mb ram gb disk 
fourth system planetlab open shared application testbed 
planetlab currently consists nodes distributed sites spanning continents north america europe australia 
ganglia point view planetlab site viewed essentially small cluster consisting nodes 
node site dell dell precision 
dell consists ghz pentium iii cpu gb ram gb ultra scsi disks raid configuration dual board gigabit ethernet network interfaces 
dell precision consists ghz pentium cpu gb ram gb disks gigabit ethernet network interface 
local area connectivity site fast gigabit ethernet 
wide area network connectivity vary significantly terms performance financial costs incurred bandwidth usage 
nodes planetlab run kernel linux 
overhead scalability order distributed monitoring system widely meet prerequisites having low performance overhead able scale production size systems 
quantify performed series experiments production distributed systems running ganglia 
performance overhead measured local overhead incurred nodes cpu overhead memory footprint global overhead incurred nodes 
essentially network bandwidth decompose local area wide area 
scalability measured overhead individual nodes quantified overhead scales size system terms number nodes cluster number clusters federated 
local overhead table show local node overheads local monitoring millennium suny planetlab 
data table collected running ps command multiple times obtain process information averaging results 
millennium numbers represent node overheads cluster smp nodes 
suny numbers represent node overheads cluster smp nodes 
planetlab numbers represent overheads incurred typical planetlab site 
measurements shown taken node cluster dell nodes intel research berkeley 
planetlab sites currently consist nodes essentially configuration numbers representative planetlab sites 
system cpu millennium mb mb suny mb mb planetlab mb mb table local node monitoring overheads gmond 
observe local node overheads local monitoring millennium suny planetlab small 
overheads nodes typical planetlab site account cpu suny millennium account just cpu respectively 
virtual memory usage moderate mb mb mb millennium suny planetlab respectively 
vm thread stack allocations small fraction 
physical memory footprints hand small 
millennium gmond mb physical memory footprint corresponding node physical memory capacity 
planetlab gmond physical memory footprint smaller just mb planetlab node total physical memory 
suny physical memory usage observed just mb nodes average kb node 
gmond daemons maintain soft state overhead incurred 
table show local node overheads federation millennium ucb cs clusters planetlab 
data table collected running ps commands multiple times averaging results 
millennium numbers represent local node overhead incurred aggregate data single cluster nodes 
ucb cs clusters numbers represent local node overhead incurred aggregate data clusters nodes nodes nodes nodes respectively 
clusters physically located building 
planetlab numbers represent local node overhead incurred aggregate data clusters spread world nodes 
system cpu millennium mb mb mb ucb cs mb mb mb planetlab mb mb mb table local node overhead aggregation 
data shows local node overheads data millennium ucb cs clusters planetlab scaling effects mainly number sites 
observe system planetlab sites virtual memory usage scaling number sites 
primary reason ganglia thread site uses default mb stack allocated linux pthreads implementation 
physical memory footprints small ranging mb mb 
cpu overhead relatively small ranging planetlab monitoring clusters uc berkeley computer science department 
overhead associated context switches interrupts observed significant current implementation 
primary cause activity aggregation data se writing rrd databases disk generate visualizations monitoring data 
systems measured average activity ranging mb mb millennium ucb cs clusters activity tended clustered distinct intervals time polls site seconds default 
planetlab hand activity continuous polling sites wide area takes varying amounts time rrd databases need written sites 
planetlab observed increase average context switches second ctx sec ctx sec increase interrupts second intr sec intr sec compared running 
resulting context switches interrupts resulted significant slowdowns node running especially interactive jobs 
global overhead table summarize amount network bandwidth consumed ganglia millennium planetlab 
decompose network bandwidth local area monitoring bandwidth wide area federation bandwidth 
accounts multicast packets sent cluster part listen announce protocol 
accounts tcp packets federate data multiple clusters aggregate results 
data monitoring packets collected running tcpdump single node monitoring multicast traffic sent ganglia multicast group 
data federated bandwidth obtained polling node cluster measuring number bits monitoring data dividing number bits ganglia default polling interval seconds compute lower bound bandwidth 
number necessarily lower bound account tcp headers acknowledgments 
difference due extra packets significant average cluster fair amount data 
system monitoring bw node federation bw millennium kbits kbits planetlab kbits kbits table network bandwidth consumed local monitoring federation 
monitoring bandwidth denotes average node bandwidth monitoring single cluster bandwidth gmond 
federation bandwidth denotes total bandwidth aggregating data set clusters bandwidth 
measurements show millennium planetlab bit rates monitoring monitoring data fairly small relative speed modern local area networks 
millennium example uses gigabit ethernet network connect cluster nodes mb bandwidth cluster nodes node aggregating cluster data running 
planetlab site nodes typically connected fast local area network 
hand sites widely varying network connectivity terms network speed underlying pricing structures agreements isps 
week time kbit bit rate implies gb monitoring data sent 
planetary scale system planetlab cost sending large amounts data bandwidth kbits number nodes local area multicast bandwidth monitoring local area multicast bandwidth packets second number nodes local area multicast packets second monitoring local area multicast packets second scalability function cluster size 
memory mb number clusters memory footprint local memory overhead 
bandwidth kbits number clusters wide area bandwidth federation aggregate bandwidth federation 
scalability function number clusters 
public internet non trivial particular sites outside sending data links 
scalability experiments characterize scalability ganglia scale number nodes cluster number sites federated 
measuring scalability single cluster berkeley millennium 
selectively disable ganglia gmond daemons obtain cluster sizes ranging node nodes measure performance overheads 
measuring scalability federated clusters planetlab 
selectively configure poll data subset planetlab sites ranging site sites measure performance overheads 
cases size monitoring output cluster default polling rate provide lower bound amount bandwidth federation 
figures quantify scalability ganglia single cluster showing local area bandwidth consumed function cluster size 
direct consequence native ip multicast observe linear scaling local area bandwidth consumed function cluster size 
observe linear scaling packet rates due native ip multicast opposed point point connections 
bandwidth packet rate cases observe small constant factors partially attributed ganglia thresholds 
nodes example measure local area bandwidth consumed just kbits sec 
gigabit ethernet network kbits amounts just total network bandwidth 
packet rates observed reasonably small scale 
figures plot performance overheads federation function number clusters federated 
data collected running ps command multiple times averaging results 
data collected polling planetlab sites estimating federation bandwidth size monitoring output divided default polling rate described section 
results show virtual memory usage federation scaling linearly number sites 
mentioned earlier linear scaling consequence ganglia thread site gets default mb stack 
vm usage reduced number straightforward ways 
possibility simply reduce default thread stack size ganglia 
polling threads ganglia small fraction stack allocations cause problems immediately result substantially vm usage 
alternative better approach eliminate thread site approach entirely event driven design multiplexing 
approaches result significant reductions vm scaling function sites 
physical memory footprints cpu overheads small negligible federation sizes measured 
observe wide area bandwidth consumed scaling linearly number sites 
surprising simply collects cluster data planetlab sites perform summarization simply collects data 
sites observe ganglia kbits wide area network bandwidth 
mentioned week time works gb data average mb data site 
wide area moving amount data continuous basis potentially result nontrivial costs relative costs hardware site 
clearly case widely distributed system planetlab 
issue grid computing systems link small numbers large clusters research networks abilene 
experience real systems key benefit having system widely deployed users interesting ways exercise functionality stress new interesting ways 
original design decisions ideas time need revisited face new applications system different regimes architectural design space 
mentioned ganglia original design point scalable monitoring single cluster particular clusters running linux operating system 
gone achieve great success 
currently runs clusters world ported different operating systems cpu architectures seen classes distributed systems intended 
way architecture system evolve features needed introduced implementation continually refined keep fast robust 
section experiences real world deployments ganglia try capture evolution 
clusters clusters surprisingly dominant system architecture ganglia deployed date 
domain original design decisions assumptions proved quite reasonable practice 
decision start simple architecture amenable fast robust implementation led scalability robustness low node overheads 
decision multicast listen announce protocol automatic discovery nodes added removed key eliminated manual configuration vastly reduced management overhead 
combined standard software configuration tools reduced barrier entry point conjecture people inclined simply try system cases immediately obtained rich useful functionality users 
simple widely technologies xml data representation xdr data transport 
technologies simple self contained offer variety existing tools leveraged extend ganglia interesting ways 
example exporting xml integrating ganglia information services add query languages indexing building new front ends export ganglia monitoring information straightforward exercises 
ganglia integration globus mds example www com custom frontends ganglia example 
portability different operating systems cpu architectures important 
example success industrial light magic currently uses ganglia monitor render nodes running mix linux tru solaris 
ganglia evolving support broad range clusters terms heterogeneity scale exposed issues significant factors early deployments 
example ganglia initially released clusters nodes fairly rare 
months observed number deployments ganglia exceeded nodes 
suny buffalo hpc cluster example ganglia monitor dell smp nodes 
extrapolating packets rates node cluster imply multicast packet rate packets second just monitoring data 
practice reductions periodic sending rate observe packet rate approximately packets second suny cluster 
clearly cluster scale challenges design choice wanting symmetry nodes multicast protocol 
assumption functional native local area ip multicast proven hold number cases 
number issues arose result early decision implementation decisions 
monitoring data ganglia published flat namespace monitor metric names 
result monitoring naturally hierarchically data awkward 
second ganglia lacks access control mechanisms metric namespace 
straightforward abuse possible publishing metrics ganglia runs virtual memory 
third pushed limits resulting huge amounts activity 
result nodes running experience poor performance especially interactive jobs 
metrics published ganglia originally timeouts associated 
result size ganglia monitoring data simply grow time 
partially addressed latest version ganglia feature coarse grain timeouts 
issues currently investigated subset addressed version ganglia 
planetlab despite designed wide area systems ganglia successfully monitoring planetlab months 
series feedback modifications demonstrated exceptional stability currently operates essentially management overhead 
current degree robustness properties proven valuable deployment include ease installation self configuration individual clusters ability aggregate data multiple sites visualize 
hand important note planetlab really represent significantly different design point compared ganglia original focus clusters connected fast local area networks 
result encountered number issues design implementation 
issues addressed current architecture appropriate modifications require substantial architectural changes 
ganglia current architecture number issues resolved appropriate modifications 
example issue arisen lately ganglia assumption wide area bandwidth cheap aggregating data 
may true abilene network public internet assumption simply hold 
connected sites world widely varying agreements isps bandwidth network pricing ganglia intends support monitoring wide area need judicious network bandwidth 
prototype zlib compression demonstrated reductions bandwidth approximately order magnitude example 
notable issues arisen ganglia deployment planetlab include limitation metrics having fit single ip datagram lack hierarchical namespace lack timeouts monitoring data large overheads incurred lack access control mechanisms monitoring namespace 
issues lack timeouts addressed 
longer term number issues require fundamental changes ganglia architecture 
biggest issue scalability monitoring single cluster multiple clusters wide area 
single cluster known quadratic message load incurred multicast listen announce protocol going scale thousands nodes 
result supporting emerging clusters scale require losing amount example planetlab site university canterbury new zealand currently pays usd gb international data sends part contract isp 
try lowest level 
federation multiple clusters monitoring straightforward aggregation data presents scaling problems 
ganglia deployment planetlab pushed regimes exposed extent 
scalable monitoring thousands clusters wide area require combination summarization locally scoped queries distributed query processing 
self configuration scale require substantial changes original ganglia architecture manual specification federation graph scale 
promising direction leverage distributed hash tables chord pastry tapestry 
related number research commercial efforts centered monitoring clusters handful focus scale 
hierarchical cluster monitoring system uses statically configured hierarchy point point connections gather aggregate cluster data collected custom kernel modules running cluster node 
card hierarchical cluster monitoring system uses statically configured hierarchy relational databases gather aggregate index cluster data 
client server cluster monitoring system uses servers export fixed set node information clients poll servers interpret data 
big brother www com popular commercial client server system distributed monitoring heterogeneous systems 
compared systems ganglia differs key respects 
ganglia uses hybrid approach monitoring inherits desirable properties listen announce protocols including automatic discovery cluster membership manual configuration symmetry time permitting federation hierarchical manner 
second ganglia extensive widely self contained technologies xml xdr facilitate reuse rich sets tools build technologies 
third ganglia simple design principles sound engineering achieve high levels robustness ease management portability 
ganglia demonstrated operation scale measurements production systems 
aware publications characterizing scalability previous systems 
design implementation evaluation ganglia scalable distributed monitoring system high performance computing systems 
ganglia hierarchical design uses multicast listen announce protocol monitor state clusters tree point point connections representative cluster nodes federate clusters aggregate state 
uses careful balance simple design principles sound engineering achieve high levels robustness ease management 
implementation ported extensive set operating systems processor architectures currently clusters world 
measurements production systems quantified ganglia scalability function cluster size number clusters federated 
measurements demonstrate linear scaling effects board constant factors varying levels importance 
measurements production systems show ganglia scales clusters nodes federations sites 
simple extrapolation numbers combined local overhead data suggests ganglia currently capable comfortably scaling clusters consisting hundreds nodes federations comprised clusters wide area 
additional optimizations compression existing architecture help push numbers 
acknowledgments performance measurements suny buffalo node hpc cluster 
providing useful feedback steve wagner providing information ganglia industrial light magic 
supported part national science foundation ri award eia npaci 
elan amir steven mccanne randy katz 
active service framework application realtime multimedia transcoding 
proceedings acm sigcomm conference communications architectures protocols pages 
eric anderson dave patterson 
extensible scalable monitoring clusters computers 
proceedings th systems administration conference october 
thomas anderson david culler david patterson 
case networks workstations 
ieee micro february 
donald becker thomas sterling daniel savarese john charles 
beowulf parallel workstation scientific computation 
proceedings th international conference parallel processing april 
boden cohen 
seitz su 
myrinet gigabit second local area network 
ieee micro february 
eric brewer 
lessons giant scale services 
ieee internet computing july august 
sergey brin lawrence page 
anatomy large scale hypertextual web search engine 
computer networks isdn systems 
rajkumar buyya 
portable scalable monitoring system clusters 
software practice experience 
andrew chien scott mario matt kay louis giannini 
high performance virtual machines clusters supercomputing apis performance 
proceedings th siam conference parallel processing scientific computing march 
brent chun david culler 
rexec decentralized secure remote execution environment clusters 
proceedings th workshop communication architecture applications networkbased parallel computing january 
intel 
paragon xp product overview 
thinking machines 
connection machine cm technical summary 
czajkowski fitzgerald foster kesselman 
grid information services distributed resource sharing 
proceedings th ieee international symposium high performance distributed computing august 
foster kesselman 
globus metacomputing infrastructure toolkit 
international journal supercomputer applications 
foster kesselman tuecke 
anatomy grid enabling scalable virtual organizations 
international journal supercomputer applications 
armando fox steven gribble chawathe eric brewer paul gauthier 
cluster scalable network services 
proceedings th acm symposium operating systems principles october 
matthew harren joseph hellerstein ryan huebsch boon loo scott shenker ion stoica 
complex queries dht peer peer networks 
proceedings st international workshop peerto peer systems march 

meiko cs interconnect elan elite design 
proceedings hot interconnects august 
kessler 
cray new dimension cray research 
proceedings compcon pages february 
john kubiatowicz david bindel yan chen steven czerwinski patrick eaton dennis geels ramakrishna gummadi sean rhea hakim weatherspoon weimer chris wells ben zhao 
oceanstore architecture global scale persistent storage 
proceedings th international conference architectural support programming languages operating systems november 
larry peterson david culler tom anderson timothy roscoe 
blueprint introducing disruptive technology internet 
proceedings st workshop hot topics networks hotnets october 
project 
project web page www org 
uc berkeley project 
project web page www berkeley edu 
uc berkeley millennium project 
millennium project web page www millennium berkeley edu 
sylvia ratnasamy paul francis mark handley richard karp scott shenker 
scalable network 
proceedings acm sigcomm conference communications architectures protocols august 
antony rowstron peter druschel 
pastry scalable distributed object location routing largescale peer peer systems 
proceedings th ifip acm international conference distributed systems platforms november 
matt ron 
highspeed cluster monitoring system 
proceedings cluster september 
ion stoica robert morris david karger frans kaashoek hari balakrishnan 
chord scalable peer peer lookup service internet applications 
proceedings acm sigcomm conference communications architectures protocols september 
michael stumm 
design implementation decentralized scheduling facility workstation cluster 
proceedings nd ieee conference computer workstations pages march 
robbert van renesse kenneth birman werner vogels 
astrolabe robust scalable technology distributed system monitoring management data mining 
acm transactions computer systems 
ben zhao john kubiatowicz anthony joseph 
tapestry infrastructure fault tolerant wide area location routing 
technical report csd university california berkeley computer science division 

