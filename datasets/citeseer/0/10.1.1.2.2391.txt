pruning vocabulary better context recognition madsen lars kai hansen jan larsen informatics mathematical modelling technical university denmark richard building dk lyngby denmark web www imm dtu dk mail rem lkh jl imm dtu dk language independent bag words representations surprisingly effective text classification 
representation high dimensional containing words text categorization 
non consistent words result reduced generalization performance subsequent classifiers ill posed principal component transformations 
communication aim study effect reducing relevant words bagof words representation 
consider new approach neural network sensitivity maps information gain determination term relevancy pruning vocabularies 
reduced vocabularies documents classified latent semantic indexing representation probabilistic neural network classifier 
reducing bag words vocabularies find consistent classification improvement mid size data sets 
study applicability information gain sensitivity maps automated keyword generation 
world wide web unstructured fast growing database 
today search tools leave web users frustration low precision recall 
widely believed machine learning techniques come play important role web search 
ambitious plans launched supporting intelligent web semantic web 
ibm stanford university semantic web platform tap examples machine learning methods coming play making human web navigation easier 
consider web content mining form internet document classification information retrieval ir aspect web mining 
internet documents contain text hyper links meta data images multimedia content classification 
focuses classification text part text categorization 
text categorization process creating supervised automatic text classifier means machine learning techniques 
classifier labels documents corpus dj set classes ck initial set labeled documents 
generic text categorization systems bagof words representation surprisingly effective task 
bag words representation summarize documents term histograms 
main motivation reduction removing semantics easily automated needs minimal user intervention filtering term list 
term list typically contains range terms reduction necessary pattern recognition devices 
latent semantic indexing lsi aka principal component analysis construct low dimensional representations 
lsi furthermore believed reduce synonymy polysemy problems 
synonymy multiple words meaning polysemy single word multiple meanings 
lsi elaborate vector space models successful text classification small medium size databases see human level text classification performance 
training classifiers relatively small databases generalizability key issue 
model adapted set data predict labels test data set 
generalizability general function number training cases effective model dimension 
various methods techniques improve generalization text categorization 
wordnet lexical database containing synonym sets lexical concept classification improvement 
synonymy part wordnet expand text category enhancing accuracy text classifier significantly 
text classification wordnet word meanings attempted 
experiments significant classification accuracy enhancement 
hand words part ofspeech pos showed improve text categorization generalization 
pos tagger analyzes sentences tag words part speech noun verb adverb number punctuation words tagged pos avoiding confusion similar words different meanings 
approach resulted positive effect classification accuracy 
pos tagger extract compound words texts improving classification accuracy 
unlabeled documents categorizing texts improving effect 
unlabeled documents various ways see 
multiple classifiers combined consensus voting scheme classifiers performs better single classifier 
communication aim improve generalizability supervised document classifier pruning document vocabulary ti removing term suited discrimination 
terms posses little generalizable discriminative power regarded noise 
pruning vocabulary task determine discriminative terms training set 
automated vocabulary reduction attempted success previously nearest neighbors classifier :10.1.1.32.9956
method term reduction experiment lsi representation 
estimate term relevance information gain scaled sensitivity computed called split half resampling procedure 
hypothesis sensitivity maps determine terms consistently important general classification relative terms low highly variable sensitivity 
rest article organized follows 
section ii discuss generic bag words approach text categorization vocabulary pruning methods 
section iii explains data sets experiments 
section iv presents results obtained vocabulary pruning 
section concludes methods results 
ii 
methods generic bag words approach documents arranged term document matrix xi number times term occur document dimensionality reduced filtering stemming 
stemming refers process words different endings merged train trained training merged common stem train 
example indicates main problem stemming introduces artificial increased polysemy 
decided live problem stemming vocabularies grow prohibitively large 
common non discriminative words 
removed term list 
addition high low frequency words removed term list 
term document matrix normalized various ways 
experiments different term weighting schemes carried 
term frequency inverse document frequency tfidf weighting consistently term weighting methods method generally 
tfidf normalization resulting elements tfidf tf log dfi dfi document frequency term tf log normalized term frequency 
tf log xi length documents prior predicting content little corpora 
document length solid variable corpora generally valid parameter 
length documents usually normalized prevent influence document length 
frobenius norm length normalize term document matrix 
tfidf tfidf emphasize influence document lengths distribution term standard deviations spam non spam documents email data set illustrated std 
non spam emails std 
spam emails fig 

distribution standard deviation email data set 
distribution spam class non spam class varies lot 
standard deviation discriminator probably general outside data set 
standard deviation classification generalization error 
standard deviation measure classification documents classified correctly 
clearly shows document length prior 
suggested reduced normalized vocabulary sensitivity maps information gain 
reduction factor determines fraction vocabulary removed 
new vocabulary subset full vocabulary sensitivity maps pruning definition class specific sensitivity proposed set samples sk ck fn ck fn posterior probability class feature vector fn 
sk dimensional sensitivity vector class dimensional derivative obtained projection 
split half re sampling procedure invoked determine statistical significance sensitivity 
multiple splits generated original training set classifiers trained splits 
classifier sensitivity map computed 
maps obtained split exchangeable mean map unbiased estimate true sensitivity map squared difference noisy unbiased estimate variance sensitivity map 
repeated re sampling averaging sensitivity map variance estimated 
obtain scaled sensitivity map normalization trough standard deviation 
scaled sensitivity way pruning compared information gain pruning 
information gain term ti defined ck log ck ti ck ti log ck ti ti ck ti log ck ti ti probability term ti appears document ti probability term appear document :10.1.1.32.9956
normalized pruned term document matrix xp reduced feature document matrix pca carried economy size singular value decomposition xp 
orthogonal matrix contains eigenvectors corresponding non zero eigenvalues symmetric matrix diagonal matrix singular values ranked decreasing order matrix contains eigenvectors symmetric matrix xp 
lsi representation obtained projecting document histograms basis vectors 
typically majority singular values small regarded noise 
consequently subset features retained input classification algorithm 
representational potential lsi features illustrated 
wide variety classification algorithms applied text categorization problem see 
extensive experience probabilistic neural network classifiers tested ann toolbox available 
toolbox adapts network weights tunes complexity adaptive regularization outlier detection bayesian ml ii framework requires minimal user intervention 
iii 
data data sets email webkb illustrate test hypothesis 
re samples experiments 
email dataset consists texts emails categories conference job spam 
webkb set pca pca dimension conference job spam fig 

illustration document distribution feature space 
show email corpus projected nd th principal directions 
projection spam class separated classes set conferences jobs show overlap 
contains web pages university computer science departments 
subset pages webkb earlier 
webkb categories project faculty course student 
html tags removed data set 
iv 
results standard performance measure text categorization systems precision recall 
precision measures retrieved entries relevant precision true positive true positive false positive 
recall measures relevant entries compared amount relevant entries collection recall true positive true positive false negative 
measure weights importance precision recall weights precision recall equally precision recall precision recall micro averaging classes rewarded classifiers frequent categories performs 
document belongs classes case collections considered micro averaged precision recall simplifies fraction correct classified documents 
follows measure fraction correct classified documents 
error function defined 
preprocessing documents letters terms converted lowercase removed 
simple stemmer transformed words basic endings common stem 
preliminary experiments indicated reduced feature space projections neural network classifier hidden units sufficient task data shown 
results validated fold split half re sampling cross validation 
neural network term sensitivity function training set 
terms sensitivity high highly variable support generalizability compared terms consistent high medium sensitivity 
empirical distribution mean standard deviations terms sensitivities email set shown 
std mean fig 

mean standard deviation term sensitivity 
relevant terms consistently high sensitivity re sampling split high mean relatively low standard deviation 
terms occupy lower right part plot 
empirical scaled sensitivities zi terms ti determine term relevance 
term relevance determined information gain 
methods quite different distribution estimated term relevance 
distribution term relevance shown email data methods 
relevance measure distributions large tails showing terms posses information 
vocabularies pruned intensively 
scaled sensitivities relevant keywords text categories extracted 
email data highest scores conference category conference deadline neural topic job category research position candidate university edt spam category money remove free simply 
similarly information gain determine relevant keywords email data 
highest scores conference category neural conference science workshop job category university research candidate computational position spam category money free remove business simply 
sets keywords posses high relevancy classes methods find exact keywords 
vocabularies webkb email data pruned increasing reduction factor 
generalization error function shown 

terms 
terms scaled sensitivities information gain fig 

distribution term relevance scores scaled sensitivities information gain email data 
distributions large tails indicating terms posses higher relevancy intensive pruning performed 
terms scaled sensitivity higher terms information gain higher 
generalization error webkb email scaled sensitivities information gain terms fraction vocabulary classification fig 

generalization error pruning vocabulary email webkb data scaled sensitivities information gain term relevance measure 
pruning information gain gives slightly better generalization error scaled sensitivities 
reducing vocabulary information gain optimal email data set 
generalization error reduced 
webkb data set lowest generalization error reducing vocabulary error reduced 
results samples training 
terms generalization classification error rate webkb email data 
removing respectively vocabularies lowest information gain generalization error webkb reduced email data 
removing terms lowest information gain performance slightly better scaled sensitivities term removal 
show learning curves consistently improved range training sets webkb email data fixed reduction respectively original vocabulary 
generalization error webkb email scaled sensitivities information gain terms fraction documents training fig 

learning curves full pruned vocabularies 
learning curves shows decreased generalization error range training set sizes 
webkb pruning methods shows consistent reduced generalization error range training set sizes 
email data pruning decreases generalization error data set training 
data set samples training generalization error reduced 
noise data prevent classification optimization 
pruning vocabulary small fraction original sizes results better generalization range training set sizes somewhat larger effect small training sets 
data sets pruning lowers generalization error approximately 
email set generalization error lowered data training 
noise data set prevents classifier lowering generalization error 
data sets information gain generally slightly better scaled sensitivities determining terms relevant classification 
information gain significantly cheaper compute scaled sensitivities obvious choice methods 
neural network sensitivity maps introduced lsi context recognition framework 
scaled sensitivity information gain compared vocabulary pruning 
mid size data sets methods consistently shown reduction text classification error pruning vocabularies 
methods lower generalization error approximately range training set sizes 
information gain generally better determining relevant vocabulary information resulting slightly better generalization error relative scaled sensitivities 
noted information gain scaled sensitivity useful identifying class specific keywords 
acknowledgment supported european commission sixth framework ist network excellence pattern analysis statistical modelling computational learning pascal contract 

linguistic techniques improve performance automatic text categorization 
proceedings th natural language processing pacific rim symposium pages tokyo jp 
cognitive science laboratory princeton university 
wordnet 
www cogsci princeton edu wn 
basili pazienza 
nlp driven ir evaluating performances text classification task 
bernhard nebel editor proceeding ijcai th international joint conference artificial intelligence pages seattle 
berners lee hendler lassila 
semantic web 
scientific american 
ibm almaden research center 

www almaden ibm com publications 
chakrabarti 
data mining hypertext tutorial survey 
sigkdd sigkdd explorations newsletter special interest group sig knowledge discovery data mining acm 
cmu webkb 
universities data set 
www cs cmu edu afs cs cmu edu project theo www data 
cmu webkb 
subset webkb 
www imm dtu dk rem 
de rodr guez jos mar mez bel az 
wordnet complement training information text categorization 
nicolas editors proceedings nd international conference advances natural language processing bl 
sebastiani 
supervised term weighting automated text categorization 
proceedings sac th acm symposium applied computing pages melbourne 
acm press new york 
deerwester dumais landauer furnas harshman 
indexing latent semantic analysis 
journal american society information science 
furnas deerwester dumais landauer harshman streeter lochbaum 
information retrieval singular value decomposition model latent semantic structure 
th international conference research development information retrieval pages grenoble france 
acm press 
guha mccool 
tap semantic web platform 
computer networks international journal computer telecommunications networking 
hansen nielsen larsen 
modeling text generalizable gaussian mixtures 
international conference acoustics speech signal processing pages 
ieee 
kehagias petridis vassilis 
comparison word sense text categorization classification algorithms 
journal intelligent information systems 
hansen larsen winther 
independent component analysis understanding multimedia content 
bengio larsen bourlard douglas editors proceedings ieee workshop neural networks signal processing xii pages piscataway new jersey 
ieee press 
blockeel 
web mining research survey 
sigkdd sigkdd explorations newsletter special interest group sig knowledge discovery data mining acm pages 
acm press 
larkey croft 
combining classifiers text categorization 
hans peter frei donna harman peter sch ross wilkinson editors proceedings sigir th acm international conference research development information retrieval pages rich ch 
acm press new york 
larsen hansen christiansen 
learning world wide web 
computational statistics data analysis 
larsen hansen probabilistic hierarchical clustering labeled unlabeled data 
international journal knowledge intelligent engineering systems 
lewis gale 
sequential algorithm training text classifiers 
bruce croft van rijsbergen editors proceedings sigir th acm international conference research development information retrieval pages dublin 
springer verlag heidelberg de 
madsen hansen 
part speech enhanced context recognition 
th international conference pattern recognition cambridge uk 
nielsen 
email data set 
www imm dtu dk rem 
nigam mccallum thrun mitchell 
learning classify text labeled unlabeled documents 
proceedings aaai th conference american association artificial intelligence pages madison 
aaai press menlo park 
sebastiani 
machine learning automated text categorization 
acm computing surveys 

dtu artificial neural network toolbox 
mole imm dtu dk toolbox ann 
larsen hansen wulf 
outlier estimation detection application skin lesion classification 
international conference acoustics speech signal processing pages 
hansen larsen wulf 
detection skin cancer classification raman spectra 
accepted ieee transactions biomedical engineering 
strother anderson hansen 
quantitative evaluation functional neuroimaging experiments data analysis framework 
neuroimage 
yiming yang jan pedersen :10.1.1.32.9956
comparative study feature selection text categorization 
douglas fisher editor proceedings icml th international conference machine learning pages nashville 
morgan kaufmann publishers san francisco 
hirsh 
lsi text classification presence background text 
ling liu david grossman editors proceedings cikm th acm international conference information knowledge management pages atlanta 
acm press new york 
sensitivity analysis minimization input data dimension feedforward neural network 
proceedings ieee symposium circuits systems pages 
