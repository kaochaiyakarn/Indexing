general evaluation framework topical crawlers srinivasan srinivasan uiowa edu school library information science department management sciences university iowa iowa city ia menczer fil indiana edu school informatics department computer science indiana university bloomington pant gautam pant uiowa edu department management sciences university iowa iowa city ia 
topical crawlers important tools support applications specialized web portals online searching competitive intelligence 
web mining field matures disparate crawling strategies proposed literature evaluated compared common tasks welldefined performance measures 
presents general framework evaluate topical crawlers 
identify class tasks model crawling applications different nature difficulty 
introduce set performance measures fair comparative evaluations crawlers dimensions including generalized notions precision recall efficiency appropriate practical web 
framework relies independent relevance judgements compiled human editors available public directories 
sources evidence proposed assess crawled pages capturing different relevance criteria 
introduce set topic characterizations analyze variability crawling effectiveness topics 
proposed evaluation framework synthesizes number methodologies topical crawlers literature lessons learned studies conducted group 
general framework described detail illustrated practice case study evaluates public crawling algorithms 
proposed framework effective evaluating comparing differentiating interpreting performance crawlers 
example crawler sensitive popularity topics 
keywords web crawlers evaluation tasks topics precision recall efficiency 

topical crawlers known topic driven focused crawlers important class crawler programs complement search engines 
search engines serve general population web users 
contrast topical crawlers activated response particular information needs 
individual user query time online contact author 
tel fax 
partially supported national science foundation career 
iis kluwer academic publishers 
printed netherlands 
crawl framework tex crawlers community shared interests topical vertical search engines portals 
crawlers underlying search engines designed fetch comprehensive snapshot web possible topical crawlers designed target portions web relevant triggering topic 
crawlers advantage may fact driven rich context topics queries user profiles interpret pages select links visit 
today topical crawlers basis specialized services investment portals competitive intelligence tools scientific repositories 
starting early breadth exhaustive crawlers pinkerton depth crawlers fish search de bra post defining beginnings research area see variety crawling algorithms 
shark search aggressive variant de bra fish search 
crawlers decisions rely heavily link criteria cho :10.1.1.22.3686:10.1.1.22.3686
focused crawler chakrabarti exploit lexical conceptual knowledge provided topic hierarchy 
menczer belew emphasize contextual knowledge topic menczer belew aggarwal chakrabarti including acquired experience menczer belew reinforcement learning menczer rennie mccallum relevance feedback menczer belew :10.1.1.1.8871:10.1.1.1.7474
companion study machine learning issues related crawler algorithms including example role adaptation crawling scalability algorithms menczer 
research issue gathering increasing momentum evaluation topical crawlers 
rich legacy information retrieval research comparing retrieval algorithms non web context offers evaluation methods measures may applied 
dimensions crawler evaluation problem dramatically different design appropriate evaluation strategies valid challenge 
general sense crawler may evaluated ability retrieve pages 
major hurdle problem recognizing pages 
operational environment real users may judge relevance pages crawled allowing determine crawl successful 
conducting evaluations web crawlers challenging 
instance scale web suggests order obtain reasonable notion crawl effectiveness conduct large number crawls involve large number users 
number documents crawl framework tex assessed large compared traditional information retrieval systems 
crawlers typically visit pages 
crawls live web pose serious time constraints 
crawls short lived ones overly burdensome user 
may choose avoid time loads showing user results full crawl limits extent crawl 
may choose indirect methods inferring crawler strengths assessing applications support 
assumes underlying crawlers openly specified prohibits assessment crawlers new 
keeping user evaluation results ideal explore alternative user independent mechanisms assess crawl performance 
distant majority direct consumers information web agents working behalf humans web agents humans 
quite reasonable explore crawlers context parameters crawl time crawl distance may limits human acceptance imposed user experimentation 
analysis web information retrieval literature aggarwal amento ben shaul bharat henzinger chakrabarti chakrabarti chakrabarti henzinger najork wiener silva experience menczer menczer belew menczer belew menczer menczer pant menczer pant menczer indicate general embarking experiment comparing crawling algorithms critical decisions :10.1.1.1.8871:10.1.1.4.6938
impact immediate outcome value study ability comparisons crawler evaluations 
offer general framework crawler evaluation research founded decisions 
goal framework demonstrate application evaluation shelf crawlers 
generic framework distinct dimensions 
dimension regarding nature crawl task addressed section 
includes consideration topics defined seeds target relevant pages identified 
second dimension deals evaluation metrics effectiveness efficiency analysis section 
dimension framework looks topics greater detail examining particular characteristics popularity authoritativeness effect crawler behavior section 
framework means systematically increasing understanding crawler technologies experimentation 
crawl framework tex sections take shelf crawlers compare framework section 
conclude section discussion experiment case study evaluation framework general 

nature crawl tasks crawl task characterized features 
include topic defined mechanism seed pages starting crawl selected location topic relevant target pages relative seed pages 
obviously crawl task seeds link directly pages relevant topic challenging seeds targets separated non trivial link distance 
issues discussed section 

topics descriptions questions built inquiries kind topic sports opens delineates particular domain discourse 
seen various examples aggarwal ben shaul bharat henzinger chakrabarti chakrabarti topics offer handy mechanism evaluating crawlers may examine ability retrieve pages topic :10.1.1.4.6938:10.1.1.4.6938
topics may obtained different sources instance asking users specify 
approach derive topics hierarchical index concepts yahoo open directory project odp chakrabarti menczer pant 
key point note topics equal 
topics opens trade specific sports business respectively 
topic may defined different ways describe 
topic specification plays critical role framework 
start asking hierarchy concepts topics specified 
method leaf node concepts topics menczer 
problem approach selected topics may different levels specificity 
framework control henceforth term relevant pages relevance general refer topical relevance user relevance judgments 
recognize significant difference factors recency influencing 
crawl framework tex depth targets depth targets depth targets root depth depth topic level depth 
illustration topic subtree hierarchical directory 
topic example topic level max depth 
topic nodes labeled depth 
external pages linked nodes depth targets depth 
shaded areas represent target sets corresponding subtrees depth max depth progressively broader interpretations topic 
broader interpretation lighter shade gray includes additional specific targets 
deriving topics concept nodes predefined distance topic level root concept hierarchy 
say topics level odp hierarchy specificity reasonable assume topic level correlated specificity useful simple control parameter characterize specificity set topics 
topic node identified topic keywords formed concatenating node labels root directory tree topic node 
keywords form search criteria provided initial input crawlers 
building topics single nodes take general approach build subtrees maximum depth max depth roots topic level links away root original concept tree 
depth refers height subtree 
illustrates ideas topic subtree max depth built concept hierarchy topic level 
framework subtrees offer systematic way delineate topics 
varying parameter depth max depth possible generate alternative descriptions topic 
descriptions may estimate relevance retrieved pages 
information root topic subtree depth get minimal set topic descriptions 
descriptive text embeds external links anchor text crawl framework tex topic description targets 
illustration topic node open directory dmoz org associated topic keywords description target set 
note keywords correspond category labels path odp root topic node 
abridged example path edges topic level 
topic example leaf node subtopics possible target set corresponds depth 
labels external links page root topic subtree may provide minimal description topic 
note manually edited directory odp textual descriptions external pages written human experts independent authors generate content pages described 
addition information level nodes subtree depth get detailed view topic till leaf nodes subtree involved depth max depth 
single topic may max depth sets descriptions differ level detail 
descriptions higher depths include lower depths 
illustrates concept topic description example corresponding leaf topic depth max depth 
crawl framework tex 
target pages hierarchical concept directories designed assist user offering entry points set conceptually organized web pages 
yahoo directory page newspapers leads usa today new york times web sites news media 
effect may regard resources pointed external links topically relevant target set concept represented directory page usa today new york times may viewed part set target relevant pages concept newspapers 
framework parallel topic descriptions topic target pages differentiated depth topic subtree 
topic described subtree depth relevant target set consists external links root node topic subtree 
example depicted 
target set corresponding topic description depth includes external links topic nodes level 
single topic max depth sets target pages defined set higher depth including sets lower depths 

seed pages specification seed pages crucial aspects defining crawl task 
approach papers chakrabarti ben shaul menczer menczer pant menczer start crawlers pages assumed relevant 
words target pages selected form seeds 
type crawl task mimics query example search mode user provides sample relevant page starting point crawl 
relevant seeds may obtained search engine pant menczer srinivasan 
idea see crawlers able find target pages topic 
assumption implicit crawl task pages relevant tend neighbors menczer davison menczer :10.1.1.1.8871:10.1.1.1.8871
objective crawler stay focused remain neighborhood relevant documents 
alternative way choose seed pages allows define crawl tasks increasing difficulty 
seeds distant target pages prior information available target pages crawl begins 
links important terms particular pages pointed terms likelihood reaching relevant documents path diligenti 
problem realistic quite commonly users crawl framework tex distance depth targets distance distance dist distance dist seeds 
illustration procedure select seed pages starting depth targets moving dist links backwards 
dist increasing dist crawl task difficult see text 
unable specify known relevant page search engines may return relevant pages 
exceptions class tasks rarely considered literature 
effort aggarwal 
somewhat related authors start crawl general points amazon com 
cho 
start crawls general point stanford web site topics primitive roles research 
framework takes general approach provides mechanism control level difficulty crawl task 
may specify distance dist 
links seeds targets 
dist increases challenge faced crawlers 
procedure implements selection seeds seed pages topic 
start depth target pages select set seed pages forward path dist seed target 
get backlinks function submits search engine link query url set identified argument 
search engine returns set backlinks urls pages link url query 
backlinks form new set pages sampled iteration loop 
constrained random subset function guarantees crawl framework tex select seeds dist seeds topics queries sample queries topics dist seed set targets depth repeat dist times sample constrained random subset seed set sample seed set get backlinks sample return constrained random subset seed set seeds 
pseudocode seed page selection procedure 
url randomly selected backlinks page previous iteration 
procedure may return fewer seeds pages set final iteration may contain sufficient urls 
note sample variable set ensure topics search engine queried exactly queries times 
practical limitation number search engine queries queries set high sample equal size depth target set 
way depth targets reachable seed set 
sample targets reachable seeds 
precisely guarantee absence broken links exists path minimum length dist links seed page sample target pages depth 
procedure selecting seed pages illustrated 
observe breadth crawler chance dist visit target seed assuming average fanout links 
crawler starting seeds pages find target dist links away crawling seeds dist pages 
kumar seeds dist reasonable expect non zero recall target pages crawling pages pages 
larger dist values correspond difficult tasks sense breadth crawler visit pages find targets conversely smaller dist values correspond easier tasks 
strategy seeding crawl target pages described earlier corresponds special case dist analysis hold 
known targets seeds crawler capability locate target pages measure performance 
subset known targets form seed set locating remaining targets gauge performance compare difficulty task crawl framework tex dist cases estimate link distance seeds remaining targets 
summary regards crawl task definition framework capitalizes structure hierarchical web directories 
topics defined subtrees hierarchy topic level parameter control specificity topics 
note approach leaf nodes topics special case maximal topic level max depth 
alternative topic descriptions varying extent detail may derived considering different regions topic subtree depth parameter 
target sets relevant pages identifiable depth external resources linked directory pages 
comes seed pages subtree really represents single topic single set seed pages identified topic 
done starting iterative backlink procedure target pages root topic subtree depth 
seed pages chosen barring broken links seed target page dist links away 
varying dist evaluate crawlers problems varying difficulty 
keywords topic selected concatenating node labels root topic node 

crawler evaluation metrics second major dimension general evaluation framework regarding evaluation measures required assess crawlers 
previous section discussed relevant target sets pages may identified 
relevant sets provide convenient basis computing crawler specific recall precision scores 
question remains gauge topical relevance new pages pages retrieved target set 
target sets useful evaluation defined local strategy exploiting direct links directory pages 
need measures gauge relevance new pages retrieved 
second aspect needs addressed 
assuming mechanism assessing page relevance need able summarize reasonable way performance crawler 
ideal world appreciate having single number score differences scores indicate differences value crawlers 
generating single number recall precision score van rijsbergen complicated fact crawlers temporal dimension 
depending crawl framework tex situation performance may need determined different points crawl 
person interested quickly obtaining relevant pages wants crawlers return speedy dividends 
crawler operating establish portal behalf community users high recall high precision critical reasonably large crawl span 
issues considered deciding methods summarize crawler performance 
accordingly section discusses strategies gauging importance new pages target set methods summarizing crawler performance 

background page relevance measures considered literature generally types lexical criteria link criteria 
lexical measures show range sophistication 
cho 
explore simple measure presence single word computer title frequency threshold body page indicate relevant page 
amento 
compute similarity page vector centroid seed documents measures page quality 
chakrabarti 
apply classifiers built positive negative example pages determine page importance 
aggarwal 
adopt generic framework allows user designed plug modules specifying relevance criteria 
modules tests require presence pre specified words particular parts page url 
similarity topic measured page text bharat henzinger words surrounding link chakrabarti may augment primarily link relevance measures :10.1.1.4.6938
degree degree pagerank brin page hubs authorities commonly link page importance measures amento ben shaul bharat henzinger chakrabarti chakrabarti cho :10.1.1.4.6938:10.1.1.4.6938:10.1.1.22.3686
cho 
consider pages pagerank specified threshold relevant query 
kleinberg recursive notion hubs authorities extended 
example edge weights considered important chakrabarti edges connect different sites amento bharat henzinger chakrabarti :10.1.1.4.6938
link quality metrics rely generally reasonable notion links reflecting credibility target pages 
amento 
show indegree authority pagerank effective identifying high quality pages judged human experts 
crawl framework tex literature shows wide variety summarization methods 
just sample 
particular measure page importance cho 
examine percentage important pages retrieved progress crawl 
menczer 
measure search length number pages crawled predetermined fraction important pages visited 
chakrabarti 
compute average harvest rate running average different time slices crawl page relevance assessed classifiers 
aggarwal 
harvest rate similarly defined rate crawled pages satisfy predicate classifier give numeric relevance values page said satisfy predicate relevance value exceeds certain threshold 
najork weiner plot average day top pages retrieved variable 
diligenti 
examine average relevance pages computed sliding window downloads 
rennie mccallum compute percentage relevant pages 
research examined average rank retrieved pages progress crawl menczer 

effectiveness measures variety summarization methods trend analysis typical field creative phase 
expected combined evidence accumulates methods dominate 
second observation summarizing methods analogs precision correspond recall 
instance percentage relevant pages retrieved time cho percentage papers percent hyperlinks followed increases rennie mccallum estimates recall :10.1.1.22.3686:10.1.1.1.7474
similarly harvest rate chakrabarti chakrabarti aggarwal average rank retrieved pages menczer average relevance pages diligenti estimates precision sliding window 
previous experience menczer belew menczer menczer pant menczer study related literature selected framework minimal set measures provides rounded assessment crawler effectiveness 
addition propose performance cost analysis way gauge effectiveness crawlers efficiency 
crawl framework tex table evaluation scheme 
set pages crawled crawler time td target set dd vector representing topic description depth cosine similarity function equation 
relevance assessments recall precision target pages td td td target descriptions dd dd table depicts evaluation scheme 
consists sets crawler effectiveness measures differentiated mainly source evidence assess relevance 
set focuses target pages identified topic row 
example recall measure assesses proportion target set retrieved point time crawl 
second set measures row employs relevance assessments lexical similarity crawled pages target set topic descriptions 
details 
measures dynamic provide temporal characterization crawl strategy 
dynamic plots offer trajectory time displays temporal behavior crawl 
suggest measures framework sufficient provide reasonably complete picture crawler effectiveness may necessary appropriate specific case crawling application experiment 
rationale effectiveness measures target pages targets approximate actual unknown set pages relevant respect topic 
illustration assume target set random sample relevant set recall 
way possible approximate actual recall existing classification directory editors 
rationale effectiveness measures lexical similarity crawled pages target descriptions want assess crawler generalization power 
need source evidence topical relevance independent keywords crawling algorithms 
topic representation crawling evaluation akin data set train test machine learning algorithm 
target descriptions written editors accessible crawlers 
meant describe content pages topic crawl framework tex 
relationship target relevant crawled page sets 
representation topic 
crawler finds page similar topic description reasonable assume page may topically relevant target pages 
assess page relevance topic descriptions topic retrieved pages represented reasonable mutually compatible vector representation scheme 
experiments topics pages represented vectors terms weighted tf idf term frequency inverse document frequency 
details provided section 
topic page vectors respectively similarity may computed cosine designated table pi di tf idf weights term page topic description respectively 
estimating page relevance lexical similarity may approximate recall full crawl set accumulating similarity crawled pages 
ideal crawler achieve point time maximum possible similarity 
recall calculations require division sum similarity relevant pages 
constant crawlers topics may drop calculations 
precision proportion crawl framework tex retrieved pages relevant estimated average similarity score crawled pages 
summary framework allows rounded analysis analogs recall precision performance measures known target set relevant pages topic descriptions assess relevance crawled page 
plotting measures time get dynamic characterization performance 

efficiency crawlers consume resources network bandwidth download pages memory maintain private data structures support algorithms cpu evaluate select urls disk storage store processed text links fetched pages 
obviously complex link selection algorithm greater resources 
order allow fair comparison crawling algorithms framework prescribes tracking cpu time taken crawler page topic ignoring time taken fetching parsing storing routines common crawlers 
impossible control network traffic congestion want benchmark crawler specific operations 
monitored cpu time compare complexity crawling algorithms gauge effectiveness efficiency 

characterization topics third dimension evaluation framework pertains topic characteristics 
information retrieval research understood query characteristics affect performance nelson saracevic kantor beaulieu mitra 
classic study saracevic kantor query characteristics explored larger context included study users search methods 
questions classified expert judges regarding domain subject clarity specificity complexity presupposition 
example number relevant documents retrieved higher questions low clarity low specificity high complexity presuppositions 
beaulieu 
correlated search outcomes query characteristics examining aspects topic type 
mitra 
explore effect query expansion strategies differentiating queries initial retrieval performance 
active research types queries users input search engines spink jansen 
example crawl framework tex spink 
study queries posed excite search engine find language web queries distinctive great terms unique 
topic features seldom explored crawler research 
exception topic features examined order elaborate observed performance provide explanation results 
example chakrabarti 
discuss topics yahoo detail order elaborate crawler mechanisms explore notions cooperative competitive domains 
bharat henzinger differentiate queries evaluate topic distillation system results full topic set special subsets rare popular topics determined retrieval set size altavista 
amento 
experiment set topics somewhat homogeneous representative popular entertainment 
menczer belew test crawlers best topics limited encyclopaedia britannica eb corpus analyze dependence performance depth topics eb subject hierarchy deeper topics specific 
general framework crawler evaluation research seek include consideration topic characteristics hold potential increasing understanding crawler performance 
framework allow look significant correlations positive negative topic characteristics performance 
exploration discussing distinct characteristics topic popularity size discourse set estimated number pages containing topic keywords indexed search engines target cohesiveness target pages link space target authoritativeness average authority score target pages neighbor pages seed target similarity average similarity seed pages target descriptions 
accurate characteristic really inherent characteristic topic depends seeds chosen user 
include seed target similarity analysis part operational definition topic crawlers respond topics provided seed sets 
crawl framework tex 
popularity popularity indicates level interest topic 
popular topics larger numbers interested individuals related web pages discourse units 
instance ibm computers popular topic web crawlers interested property may case crawler differences accentuated pay attention popularity topics 
example crawlers may perform poorly popular topics reliant lexical clues 
topic popularity may estimated size discourse set 
way search topic keywords directly search engine number hits returned estimate 
multiple search engines employed number hits returned may averaged 
recall general framework associate topic subtrees topic node depth max depth 
correspondingly obtain popularity estimates dependent value depth appropriate query representations topic conducting search 
define popularity topic depth pd gd keyword representation topic concatenation node labels root directory node hit set returned search engine response query set trusted search engines gd set subnodes subtopics depth 
look popularity topic restrictive sense excluding keywords subtopic 
max depth interpret topic inclusive sense corresponding topic subtree 
note keywords joined syntax required pd construction non decreasing function topic 

cohesiveness topic cohesiveness estimates closely knit relevant pages topic 
cohesive topic interlinked set relevant pages 
ways measure cohesiveness 
assume typical crawler access search engine find inlinks page measure particularly interested forward links crawler observe locally crawl framework tex crawl 
start target pages topic ones assumed relevant 
cohesiveness obtained examining neighborhood target pages 
forward links target pages count fraction point back target set cd td ou td td ou ou set outlinks page essence measure estimates likelihood reaching target page crawler located target page 
note target sets depth sensitive topic cohesiveness metric 
cohesiveness measure target pages contexts example characterize performance random walk crawler menczer menczer identify web communities flake :10.1.1.1.8871:10.1.1.1.8871
speculate topics high link cohesiveness potentially easier crawler stay vicinity relevant pages 
especially true crawlers localized search strategies 

authoritativeness topic characteristic metric framework pertains authoritativeness 
proposed kleinberg authority page hubs pointing hub points authorities 
kleinberg provides algorithm uses recursive definition directed graph web pages get authority hub scores 
treat target pages topic root set expanded get base set 
expansion done including pages corresponding outlinks root set pages top inlinks root set 
kleinberg algorithm applied graph representation base set 
algorithm converges calculate average authority score target urls ad td td td base set obtained root set convergence authority score page computed base set authority scores normalized average authority score ad call authoritativeness represents concentration authority target pages topic inferred link neighborhood 
target sets different values depth obtain depth sensitive estimates topic authoritativeness 
crawl framework tex 
seed target similarity characteristic included framework seed target similarity 
point explored targets lexically similar seeds may easier reach target pages 
differentiate topics basis average lexical similarity seed pages target descriptions ld dd seed set topic seed page target description dd may reasonable vector representation 
similarity defined cosine vectors see equation 
typically tf idf weighted term vectors 
specific implementation weight representation detailed section 
characteristics seed target similarity depth sensitive 
mentioned metric dependent user specified seeds preceding characteristics properties topic targets controllable user 

case study goal demonstrate application general evaluation framework previous sections experiment comparing shelf crawlers 
case study describe specific implementation framework set choices parameter values decisions related dimensions evaluation crawl task performance measures topic characteristics 
purpose case study claims particular task crawling algorithm simply give example illustrates general framework applied evaluate compare different crawlers defined crawling problem 
crawler designer web information retrieval practitioner apply framework specifically crawling techniques considered task suitable particular application interest 

crawl task crawl task case study motivated applications web pages crawled user waits example refine crawl framework tex results search engine order find fresh hits may indexed search engine 
instance application applet pant menczer 
circumstance number pages crawled severely limited making impossible explore promising links encountered crawl 
model task give crawlers short lifespan pages pages 
challenging interesting problem noted crawlers designed different applications say building index topical search engine appropriately evaluated crawling pages 
open directory hierarchy dmoz org source topics 
key advantages choice odp maintained large number volunteer editors strongly biased commercial content ii data publicly freely available periodic rdf dumps 
identified topics hierarchy topic level max depth 
varying depth generated topic descriptions target sets 
topic node contributes topic description concatenation text descriptions anchor text target urls written odp human editors cf 

sets descriptions sets target pages topic 
experiments described differentiated topic depth 
reason small pages case study limited cpu bandwidth resources experimental setting trade crawl length versus number topics 
topics large number topics achieve statistically significant results believe norm web information retrieval draw believable crawling studies 
addition set keywords defined topic 
keywords associated particular node words odp hierarchy node 
keywords guide crawlers search topical pages 
example best links algorithms selected source page similarity topic representation build keywords 
recall separation topic keywords passed crawler richer topic descriptions evaluation entirely intentional 
keywords representative typical short queries users employ describe information needs 
second richer descriptions written independently expert editors key assessing crawler focus generalization effectiveness 
keywords corresponding dif informatics indiana edu crawl framework tex table ii 
sample topic 
depth additional keywords descriptions targets shown actual descriptions target sets depth inclusive depth descriptions target urls abridged space limitations 
keywords descriptions targets sports disabled wheelchair events regional australia canada hong kong uk com information links wheelchair cartoons 
national wheelchair association 
wheelchair adventures discusses various 
wheelchair sports active 
world wheelchair sports homepage 
medical sports organization 
british commonwealth games brief 
pan american wheelchair games brief history 
wheelchair games brief 
wheelchair page lists 
hamilton wheelchair relay challenge 
com disabled sports program 
far west wheelchair sports events results 
long island wheelchair athletic club 
veterans association florida 
sun sports non profit organization 
bc wheelchair sports association non profit 
canadian wheelchair sports association 
manitoba wheelchair sport association sport 
ontario wheelchair sports association canada 
wheelchair sports association wheel sports nsw wheelchair sport 
new south wales wheelchair sport general 
british wheelchair sports foundation www com www com www com www tripod com sports html www org www com www net br www net pa www net st www com ky www hamilton wheelchair relay www com home net www org www org www com sun www com www ca www sport mb ca wheelchair www org htm www ca www org au www com au wheels www org ferent depths topic root node depth may compute topic popularity described section 
table ii provides example topics case study 
seed selection procedure described section 
backlinks obtained google web api 
api limit queries day set queries 
parameters dist seeds 
iteration procedure select sample backlinks 
barring broken links seed pages lead target page depth links 
crawl framework tex data sets topics keywords targets descriptions seeds case study available online 

evaluation metrics evaluate crawlers case study follow closely performance measures defined table section 
assessing relevance full crawl set topic descriptions target descriptions retrieved pages pre processed removing common words standard stemming algorithm porter 
represented tf idf vectors 
depth dependent topic vectors generated concatenating topic keywords topic descriptions corresponding depth idf calculations done respect pool consisting target descriptions depth topic subtree 
compute tf idf weight term page topic depth follows dd pt ln dd frequency dd set target descriptions topic depth tf idf weights topic vectors computed analogously 
lexical similarity cosine formula equation 

topic characteristics case study limit analysis topic characteristics topic depth 
calculate topic popularity searching topic keywords google search engine google web api 
searches generated inclusive interpretation topic just keywords depth 
topic cohesiveness fully specified discussion section 
topic authoritativeness generating base set add base set top inlinks retrieved google 
due api limitation results query 
apply kleinberg algorithm base set calculate authority score page target set described section 
similarity pages word removal stemming represented tf idf vectors cf 
equation cosine function defined equation similarity calculations 
www informatics indiana edu fil framework crawl framework tex 
crawling algorithms evaluation framework proposed establish state art web crawling algorithms 
difficult choose candidate algorithms evaluate crawlers described literature designed different tasks mind implemented tested different methodologies 
performance assessments find literature anecdotal absence defined tasks consistent evaluation measures sound statistical analyses 
starting point case study consider crawlers various factors known literature ii documented easy reimplement iii represent different understood algorithms iv routinely baseline performers novel versions algorithms proved effective prior research 
study formally comparing different crawlers common evaluation framework believe results important step establishing state art topical crawlers 
hope researchers challenge crawlers outlined evaluate alternative algorithms may produce provably better performance 
illustrates architecture crawling web various algorithms 
crawlers topic keywords seed urls perform basic procedure 
comparison constraint limited resources limit memory available crawler constraining size internal buffer 
buffer crawler temporarily store link data typically frontier links explored 
crawler allowed track maximum max buffer links 
buffer full crawler decide links substituted new ones added 
value max buffer set case study 
crucial details differentiate crawling algorithms process function 
crawler tested breadth crawler simplest strategy crawling 
uses frontier fifo queue crawling links order encounters 
najork wiener shown breadth crawlers effectively retrieve pages pagerank order 
breadthfirst crawler mainly provides baseline performance level help gauge effectiveness sophisticated algorithms 
crawlers variations best search cho :10.1.1.22.3686
basic version bfs frontier crawl framework tex concurrent crawler logic concurrent crawler logic frontier private data web lexical analyzer html parser url utils main frontier private data keywords seed urls url mapping cache databases topics benchmarking history data offline analysis descriptions target urls 
architecture crawling system 
crawling algorithms run concurrently specified modules share common utilities html parser url processing stemmer lexical analysis benchmarking databases cache data collection 
crawler module maintains private data structures limited size 
crawler keywords seeds pages max buffer frontier seeds repeat pages times link process frontier keywords new links visit link push frontier new links maintain frontier max buffer 
pseudocode basic crawling procedure 
crawl framework tex links best link estimation criterion selected crawling 
class crawling algorithms introduced generalize bfs iteration batch top links crawl selected 
bfs proved effective prior research pant menczer 
topic keywords guide crawl 
link selection occurs computing cosine similarity keyword vector source page vector link 
urls best source page similarities selected crawling 
worst links eliminated frontier room newly discovered better ones frontier full 
crawler tested implementation menczer menczer belew menczer belew menczer :10.1.1.1.8871
basic algorithm population agents crawls parallel adaptive keyword vectors neural nets decide links follow 
evolutionary algorithm uses fitness measure similarity local selection criterion reinforcement learning train neural nets predicting links lead best pages textual context source page 
agents visit pages similar internal keyword vectors get chance create offspring 
offspring inherits keywords neural net parent modulo mutations designed internalize features pages led parent success 
algorithm completely distributed interaction distinct agents 
crawler maximally exploit concurrent architecture efficiency 
implementation evaluated includes number novel features designed incorporate certain greedy aspects competitive prior experiments 
details crawlers case study scope article 
refer reader companion menczer algorithms described analyzed greater depth 

performance analysis figures show performance analysis results crawlers evaluation framework effectiveness measures 
results consistent measures prior experiments crawlers 
general observe bfs early stages crawl pays price greedy behavior pant 
bfs eventually catches case target pages outperforms crawlers 
outperformed crawl framework tex average precision description average precision description average precision description bfs bfs breadthfirst pages crawled bfs bfs breadthfirst pages crawled bfs bfs breadthfirst pages crawled average recall description average recall description average recall description bfs bfs breadthfirst pages crawled bfs bfs breadthfirst pages crawled bfs bfs breadthfirst pages crawled 
dynamic plots precision left recall right versus number crawled pages relevance assessments target descriptions depth top center bottom 
performance averaged topics standard errors shown 
bfs crawlers descriptions matches performance bfs target pages 
expected breadthfirst displays worst performance provides baseline measures 
precision recall measures provide complementary information evaluation 
precision captures dynamic textured view behavior different crawling algorithms especially early stages crawls 
recall provides clearer picture difference crawlers asymptotic performance 
note recall decreases increasing depth 
crawl framework tex average targets average precision targets average precision targets bfs bfs breadthfirst pages crawled pages crawled bfs bfs breadthfirst bfs bfs breadthfirst pages crawled average recall targets average recall targets average recall targets bfs bfs breadthfirst pages crawled bfs bfs breadthfirst pages crawled bfs bfs breadthfirst pages crawled 
dynamic plots precision left recall right versus number crawled pages relevance assessments target pages depth top center bottom 
performance averaged topics standard errors shown 
topics number target pages increases quickly depth 
targets visited cf 
target precision represent smaller fraction target set 
intuitive similarity crawled pages topic descriptions decreases inclusive diverse relevant page may similar targets dissimilar 
illustrate performance affected task plots target recall crawlers difficult task dist longer page crawl 
remind reader previous runs done dist page crawls 
crawl framework tex average recall targets bfs breadthfirst pages crawled 
average recall target pages bfs breadth 
topics experiment taken odp leaf categories corresponding maximum topic level depth 
parameter values dist pages max buffer topics 
data menczer 

experiment eventually outperform crawlers difference significant pages menczer 
results draw picture different crawlers effectiveness account computational complexity crawling algorithms 
gauge performance efficiency crawlers shows results performance cost analysis evaluation framework 
focus recall measures target descriptions pages depth 
results quite interesting 
due efficiency breadthfirst displays best performance cost ratio early stages crawl need results really fast simplest strategy may way go 
long run achieves highest performance cost ratio competitive performance efficient concurrency 
bfs crawlers penalized efficient algorithms implemented require frequent sorting synchronization operations menczer 

topic analysis analyze crawler behavior affected different topics consider correlation performance various topic crawl framework tex average recall description cpu time average recall targets cpu time pages crawled bfs bfs breadthfirst pages crawled bfs bfs breadthfirst 
dynamic plots recall relative cpu time relevance assessments target descriptions top target pages bottom depth 
cpu time normalized mean crawlers account differences cpu speeds machines experiments menczer 
performance cpu times averaged topics ratio computed 
crawl framework tex table iii 
rank correlation coefficients crawler recall pages topic characteristics depth 
recall target pages left target descriptions right 
values bold indicate significant correlations confidence level tailed spearman rank correlation test conover 
cases refute null hypothesis monotonic relationship performance topic characteristic 
target pages recall target description recall crawler bfs bfs breadthfirst characteristics defined section 
need pair topic characteristic crawler performance cohesiveness authoritativeness popularity seed similarity measures depth recall levels achieved crawler pages 
distributions measures unknown need distribution free correlation measure spearman rank correlation coefficient 
table iii shows values crawler topic characteristic recall performance target pages target descriptions 
seed target similarity topic characteristic significantly affects performance crawlers 
higher seed target similarity improves performance topic description helps reaching predefined targets 
strong correlation may indicative generally accepted principle web pages tend point lexically similar pages menczer 
mind note topical crawlers bfs bfs exploitative seed target similarity show higher correlation breadthfirst 
topic cohesiveness significant effect target page recall significant influence description performance 
interpret observation arguing cohesive topic may provide paths lexically similar pages identifying target pages may remain non trivial 
topic authoritativeness topic significantly influence crawler breadthfirst 
topical crawler able improve performance reaching targets simply paths leading authoritative crawl framework tex target recall pages data regression regression seed target similarity 
scatter plot target page recall versus 
data point represents page topical crawl 
linear regression shown breadthfirst 
targets attractors inlinks 
consistent observations breadthfirst crawlers effectively retrieve pages high pagerank najork wiener 
topic popularity contradicting effects evaluation measures 
capable exploiting characteristic significant way crawlers tend find pages similar targets fewer actual target pages popular topics 
interpretation large relevant set popular topic easy find relevant pages hard identify relevant subset target set 
illustration correlations data shows scatter plot performance versus seed target similarity comparison linear regressions plotted breadthfirst 
plot evident tends visit relevant target pages starts seeds lexically similar target descriptions 

general framework evaluate topical crawlers 
identified class tasks model crawling applica crawl framework tex tions different nature 
relying web directories topics desired mix specificity inclusiveness easily identified 
framework specifies procedure defining crawling tasks variable difficulty selecting seed pages appropriate distances targets 
goal formal systematic characterization crawl topics tasks foster quantitative experiments may allow researchers better understand differences crawling applications literature 
facilitate endeavor script selects topics open directory number parametric specifications generates files containing topic keywords descriptions target urls various depths seed urls illustrated section freely available terms gnu general public license 
introduced set performance measures evaluate web crawlers defined dimensions precision versus recall relevance criteria target pages versus human compiled target descriptions topic breadth algorithmic efficiency dependence diverse topic characteristics 
demonstrated application framework experiment comparing shelf crawlers 
goal case study illustrate framework compare crawlers defined crawling problem 

limitations important limitation approach underlying general framework dependence availability hierarchical directory topic source 
open directory currently provides public resource directories may open due commercial concerns 
possible extend framework topic contexts offer hierarchical context address aspect 
related limitation framework implicit assumption hierarchical structures effectively mirror space topics 
extent assumption holds unclear 
limitation considered user generated relevance judgments 
framework considers external pages pointed hierarchical directory pages relevant 
manually identified pages appropriately considered topically relevant 
studied topic characteristics popularity cohesiveness independent features 
remains seen interactions 
www informatics indiana edu fil framework crawl framework tex 
implications particular crawling algorithm topic hierarchy framework identify algorithmic parameter settings different topics tasks 
allow example vertical portal customized settings crawling topic needs index update 
absence topic hierarchy appropriate parameter settings may identified range values corresponding suggested topic characteristics popularity cohesiveness 
results case study clearly demonstrate proposed framework effective evaluating comparing differentiating interpreting performance diverse crawlers studied dimensions 
topic analysis give insight behavior crawling algorithms 
particular crawler may able predict performance value topic characteristic sensitivity characteristic 
example shown crawler sensitive popularity topics 
results show topical crawlers considered case study exploitative seed target similarity breadth crawler 
validation hypothesis topical crawlers effectively exploit topical locality davison menczer belew web 
show cohesiveness topics increases crawlers find topically relevant pages 
result finding crawling algorithm may designed look cohesive subspaces topic subspaces expected produce relevant pages effort 

research comprehensive treatment topical crawler evaluation issues date step 
web information retrieval community evaluation framework objective comparative evaluations alternative crawling algorithms advance state art quantitative manner 
emphasized advances require appropriate statistical analyses studies topics order draw believable 
framework allows develop test additional topic characteristics 
research plan explore characteristics recency update frequency topic target pages 
desirable experiment parameters framework achieve better understanding factors affect performance different tasks crawlers 
main emphasis presenting evaluation framework exhaustively explore role parameters dist topic level crawl framework tex max depth 
general nature framework space possible experiments quite large take time topical crawler community identify useful task parameterizations 
endeavor left research goal evaluate crawlers literature design better ones support new generation scalable search tools 
alberto dave eichmann miguel ruiz colleagues support contributions prior 
grateful open directory project editors making data freely available google public web api 
aggarwal yu intelligent crawling world wide web arbitrary predicates 
proc 
th international world wide web conference 
pp 

amento terveen hill authority mean quality 
predicting expert quality ratings web documents 
proc 
rd acm sigir conf 
research development information retrieval 
pp 

beaulieu sheffield interactive experiment trec 
proc 
th text retrieval conference trec 
ben shaul adding support dynamic focused search 
computer networks 
ben shaul maarek pelleg ur adding support dynamic focused search 
computer networks 
bharat henzinger improved algorithms topic distillation hyperlinked environments 
proc 
st acm sigir conf 
research development information retrieval 
pp 

brin page anatomy large scale hypertextual web search engine 
computer networks 
chakrabarti dom raghavan rajagopalan gibson kleinberg automatic resource compilation analyzing hyperlink structure associated text 
computer networks 
chakrabarti joshi pennock structure broad topics web 
de roure iyengar eds proc 
th international world wide web conference 
new york ny pp 
acm press 
chakrabarti accelerated focused crawling online relevance feedback 
de roure crawl framework tex iyengar eds proc 
th international world wide web conference 
new york ny pp 
acm press 
chakrabarti van den berg dom focused crawling new approach topic specific web resource discovery 
computer networks 
cho garcia molina page efficient crawling url ordering 
computer networks 
conover practical nonparametric statistics chapt 
pp 

new york wiley 
davison topical locality web 
proc 
rd international acm sigir conference research development information retrieval 
pp 

de bra post information retrieval world wide web making client searching feasible 
proc 
st international world wide web conference 
diligenti coetzee lawrence giles gori focused crawling context graphs 
proc 
th international conference large databases vldb 
cairo egypt pp 

flake lawrence giles efficient identification web communities 
proc 
th acm sigkdd conference knowledge discovery data mining 
boston ma pp 

henzinger heydon mitzenmacher najork measuring search engine quality random walks web 
proc 
th international world wide web conference 
pp 

maarek pelleg ur shark search algorithm application tailored web site mapping 
proc 
th intl 
world wide web conference 
jansen spink saracevic real life real users real needs study analysis users queries web 
information processing management 
kleinberg authoritative sources hyperlinked environment 
journal acm 
kumar raghavan rajagopalan sivakumar tomkins upfal stochastic models web graph 
proc 
st annual ieee symposium foundations computer science 
silver spring md pp 
ieee computer society press 
menczer arachnid adaptive retrieval agents choosing heuristic neighborhoods information discovery 
proc 
th international conference machine learning 
pp 

menczer complementing search engines online web mining agents 
decision support systems 
menczer lexical semantic clustering web links 
journal american society information science technology 
forthcoming 
menczer belew adaptive information agents distributed textual environments 
proc 
nd international conference autonomous agents 
minneapolis mn pp 

menczer belew adaptive retrieval agents internalizing local context scaling web 
machine learning 
menczer pant ruiz srinivasan evaluating topic driven web crawlers 
kraft croft harper zobel eds crawl framework tex proc 
th annual intl 
acm sigir conf 
research development information retrieval 
new york ny pp 
acm press 
menczer pant srinivasan topical web crawlers evaluating adaptive algorithms 
acm transactions internet technology 
forthcoming 
mitra singhal buckley improving automatic query expansion 
proc 
st acm sigir conf 
research development information retrieval 
pp 

najork wiener breadth search crawling yields high quality pages 
proc 
th international world wide web conference 
nelson effect query characteristics retrieval results trec retrieval tests 
proc 
annual conference canadian association information science 
pant menczer evolve intelligent web crawlers 
autonomous agents multi agent systems 
pant srinivasan menczer exploration versus exploitation topic driven crawlers 
proc 
www workshop web dynamics 
pinkerton finding people want experiences webcrawler 
proc 
st international world wide web conference 
porter algorithm suffix stripping 
program 
rennie mccallum reinforcement learning spider web efficiently 
proc 
th international conf 
machine learning 
pp 
morgan kaufmann san francisco ca 
saracevic kantor study information seeking retrieving 
ii 
users questions effectiveness 
journal american society information science 
silva ribeiro neto ziviani moura link content evidential information belief network model 
proceedings rd international acm sigir conference research development information retrieval 
pp 

spink wolfram jansen saracevic searching web public queries 
journal american society information science 
srinivasan mitchell pant menczer web crawling agents retrieving biomedical information 
proc 
int 
workshop agents bioinformatics 
van rijsbergen information retrieval 
london butterworths 
second edition 
crawl framework tex 
