estimating replicability classifier learning experiments remco bouckaert remco cs waikato ac nz xm nz 
computer science department university waikato hamilton new zealand 
mountain information technology auckland new zealand replicability machine learning experiments measures outcome experiment repeated performed di erent randomization data 
estimator replicability experiment cient 
precisely estimator unbiased lowest variance class estimators formed linear combination outcomes experiments data set 
gathered empirical data comparing experiments consisting di erent sampling schemes hypothesis tests 
factors shown impact replicability experiments 
data suggests sign tests due low replicability 
ranked sum tests show better performance combination sorted runs sampling scheme test gives desirable performance judged type ii error replicability 

machine learning research classifiers relies large extent experimental observations 
widely recognized pitfalls performing experiments 
far research area concentrates undesirable high levels type error situation experiment indicates classifier outperforms reality 
overlooked issue experimental research particular experiment major impact outcome experiment 
ect large experimental designs cases repetition experiment produces outcome :10.1.1.58.4949
appearing proceedings st international conference machine learning ban canada 
copyright author 
try get better insight issue replicability factors experiment influence replicability 
order need practical definition replicability way measure replicability experiment 
established perform experiments various set ups 
section consider number experimental designs 
continue section ways estimate replicability perform theoretical analysis performance 
section presents empirical results measure replicability various experimental set ups 
finish concluding remarks 

machine learning experiments problem want address learning algorithms generate classifiers small data set decision algorithms performs best classification accuracy data set 
general method decision split training set test set train algorithm register classification accuracy way obtain classification accuracies pa pb di erence pa pb gives indication algorithm performs better 
formal way decision apply hypothesis test 
hypothesis test typically requires single outcome unfortunately small datasets split repeatedly training test sets obtain multiple outcomes pb associated di erences pb obtaining sample size experiment components 
firstly sampling scheme obtaining sample 
xn secondly hypothesis test decision sample 
various ways obtain samples perform hypothesis tests 

sampling methods consider di erent sampling schemes 

example illustrating data various sampling schemes 
averaging runs averaging folds averaging sorted runs fold sorted fold run run resampling resampling consist splitting data times randomly selected test set containing fraction data typically training set algorithms learn training set accuracies pb obtained classifying instances accompanying test set giving accuracy di erences pb sample 
resampling accepted way applying test sample 
xn till dietterich due extremely high type error 
nadeau bengio showed problem solved correcting variance 
fold cross validation cross validation splits data approximately equal parts 
learns data part left 
part left test set giving accuracy di erences pb dietterich observed slightly elevated type error cross validation test replicability low :10.1.1.58.4949
data obtain samples repeat fold cross validation times di erent random splits folds runs 
gives rk accuracy di erences 
denote di erence accuracy algorithms ith run jth fold 
trained remaining folds ith run 
obtain sample size accuracy di erences formally setting mod 
average folds averaging folds recommended method weka take result repeated cross validation experiment 
obtain sample value run average di erence results single run data scheme 
average runs averaging folds interpreted improved way doing resampling 
natural extension performing improved way fold cross validation averaging folds average runs 
obtain sample value fold defined average di erence averaging folds runs show high type error applying test :10.1.1.58.4949
average sorted runs averaging runs combines results di erent runs arbitrarily 
gets better estimates fold cross validation experiment sorting results individual fold cross validation experiments average 
way estimate minimum value calculated minimum values folds lowest lowest results folds jth highest value accuracy di erence run sample consisting values defined illustrates di erence data sampling schemes 
shows example fold cross validation outcomes box left half practice fold cross validation appropriate 
data box data scheme 
resampling essentially column required performing split training test data 
cross validation uses run row fold cross validation outcome 
averaging folds runs essentially summing columns rows respectively 
getting sorted means results sorted folds giving table right 
means obtained summing rows 

hypothesis tests experiment want test null hypothesis perform 
formally want test sample 
xn zero mean 
di erent methods test hypothesis slightly di erent assumptions 
consider popular test sign test rank sum test known wilcoxon test 
tests assume outcomes sample mutually independent assumption obviously violated 
hypothesis tests follow similar procedure 
calculate statistic sample 
different tests di erent methods calculating see 
calculate probability value observed assuming true 
choose significance level accept higher 
test indicates outperforms test indicates outperforms paired test assumption underlying paired test outcomes normally distributed 
true mean estimated variance degrees freedom df statistic df distributed students distribution df degrees freedom 
probability data 
xn observed assuming null hypothesis true obtained finding df 
sign test attractiveness sign test simple assumptions underlying distribution sample 
looks signs 
xn statistic number pluses 
accuracies pb occurs quite algorithms perform similarly count half plus 
null hypothesis true probability generating plus minus words 
probability observing pluses comparisons rank sum test sign test rank sum test assumption underlying distribution outcomes rank sum test exploit size values contains potentially valuable information 
rank sum test sorts outcomes absolute value giving set outcomes 
yn 
accuracies outcomes removed sample leaving items 
add ranks outcomes positive statistic mean variance approximately normally distributed 
normally distributed mean variance 

quality experiments essentially methods judge quality experiment type error probability experiment di erence algorithms reality 
theory type error equals significance level chosen hypothesis test assumptions test violated 
practice independence assumption violated resulting elevated type error 
type ii error probability experiment di erence algorithms reality power defined minus type ii error 
power directly controllable type error trade power type error higher power obtained cost higher type error 
exact relation depends experimental design 
replicability experiment measure outcome experiment reproduced 
desirable experiment low type error high power high replicability 
section closer look replicability 

replicability ad hoc definition replicability proposed follows :10.1.1.58.4949
experiment repeated times di erent data set experiment deemed replicable outcome experiments 
outcomes di er replicable 
impression replicability experiment obtained averaging large number say data sets 
definition useful highlighting replicability experiments issue machine learning 
disadvantage replicability measured way compared results doing experiment number times 
replicability defined way distinguish having outcomes di erent outcomes di erent 
increasing number experiments say increases likelihood experiments di er decreases replicability definition :10.1.1.58.4949
definition replicability su er issues 
definition replicability experiment probability runs experiment data set pair algorithms method sampling data produces outcome 
definition applies situation algorithms perform outperforms 
note di erence type error replicability 
algorithms perform type error expresses probability data sets di erence 
replicability expresses error data set 
defining replicability terms probabilities compare replicability di erent experiments di erent experimental set ups number runs 
furthermore experiment produces outcomes higher replicability way produces outcomes 
note replicability lies 
normalized replicability replicability linearly scaled range 
replicability normalized replicability 

simple estimator way determine replicability experiment measure empirically 
need estimator replicability 
simple approach obtain pairs runs experiment data set just interpret outcome bernoulli trial probability outcomes 
outcome experiment data set accept reject 
outcome accept null hypothesis learning algorithms perform accepted 
definition 
outcomes experiments di erent data set estimator replicability indicator function argument true 
write clear context argument lemma unbiased estimator replicability variance proof bias 
constant outside expectation gives 
distributing sum results 

note get substituting gives bias shows unbiased estimator variance var pairs derivation observe pairs follows binomial distribution probability var lemma see appendix rn giving var rn 
advanced estimator simple estimator uses experiment compare independent compare 
likewise pair compared estimate replicability 
fact pairs outcomes estimate replicability fraction pairs outcome 
defines new estimator definition 
define estimator lemma calculate directly counting number accepted tests experiments 
calculated ciently linear time number experiments 
lemma 
tests accepting null hypothesis proof numerator number pairs equal outcomes 
tests accept null hypothesis remaining pairs rejecting pairs pairs non rejecting pairs formed 
gives estimate replicability examine bias variance turns unbiased estimator replicability variance expressed closed form 
theorem unbiased estimator replicability variance 
proof unbiased closely follows lemma 
proof establishing variance technical omitted 
full proof available report version 
unfortunately closed form expression variance hard interpret compare shows variance various values replicability number experiments shows variance equal 
full replicability case variance zero 
values variance indicating cient estimator replicability 
better estimator 
unbiased estimator replicability lower variance experiments 
single database 
consider class estimators linear functions 
definition 
outcomes experiments di erent data set estimator rk rk note class odd 
likewise class demand unbiased put restriction coe cients expressed lemma 

variance upper surface lower surface function replicability 
number tests 
lemma rk unbiased estimator replicability proof property replicability experiment data set definition probability experiments produce outcome 
experiments di erent independent 
probability outcome single experiment accept replicability probability outcomes accept plus probability outcomes reject 
solved giving 
proof rk unbiased estimator replicability rk definition expectation 
equals 
changing order sums get 
note equal outcomes probability accept rejects 
rk summing gives rk equality follows condition estimator unbiased 
consequently 
unbiased lemma theorem proven observing instances noting coe cients add 
theorem var var unbiased table 
type error set power set replicability percentages various sampling methods confidence interval brackets 
source source source source minimum average test sampling scheme type power power power norm replicability rank sum resampling test fold cv data average folds average runs average sorted runs sign test average sorted runs test average sorted runs estimator rk proof determine minimum var rk show realizes minimum 
definition var rk equals rk unbiased rk var minimum dvar rk dk derivatives gives dvar rk dk dk computes rk dk 
write rk write giving 
term dk written dk equals 
dvar rk dk rk 
need distinguish cases 
dvar dk reduces 
equal zero coinciding replicability likewise dvar dk reduces 
var rk reaches optimum means coe cients equal 
sum coe cients 
optimum minimum shows 
summary theorem states cient unbiased lowest variance estimator class unbiased estimators rk 
empirical results establish sampling scheme results acceptable experiments type error power 
look factors impact replicability 
measure type error power algorithm naive bayes implemented weka algorithm implemented weka default parameters compared synthetic data uci data sets 
synthetic data sets generated data sources randomly generated bayesian networks details data sets contained binary variables class probability :10.1.1.58.4949
data sources generate data sets instances 
data source mutually independent variables performance di erence naive bayes allows measure type error 
sources outperforms naive bayes increasing margin average respectively measured instance test sets allows measure power tests 
sampling methods mentioned section performed times folds runs significance level 
table shows results synthetic data numbers brackets indicating confidence interval 
rows rank sum test 
note data average folds runs sampling schemes type error type error desired 
resampling scheme elevated type error fold cross validation scheme 
sorted runs scheme shows appropriate level type error 
comes table 
uci data sets 
nr draws sorted fold cv intervals data set mean norm 
sign test nb vs 

nb vs nn 

vs nn 

rank test nb vs 


nb vs nn 


vs nn 

test nb vs 


nb vs nn 


vs nn 
cost decreased power compared schemes 
table shows minimum average replicability set 
shows resampling fold cv level replicability acceptable 
schemes repeated cross validation show acceptable replicability 
particular sorted runs scheme replicability 
results sign test test similar results rank sum test 
table shows type error power sorted runs sign test test 
figures close ones rank sum test account slightly higher type error lead slightly better power 
replicability sorted runs sign test test 
compared rank sum test sign test performs considerably worse 
explained lack exploiting sizes di erences sample sign test 
replicability test slightly better 
experiments performed sorted runs sampling scheme varying various parameters experiment significance level number runs class probability binary data class cardinality di erent pairs algorithms naive bayes nearest neighbor tree augmented naive bayes decision stump support vector 
space limitations prevent presenting complete set outcomes report experiments resulted type error exceeding significance level sorted runs sampling scheme tests considered 
decreasing class probability increased replicability 
explanation behavior realizing learners tend predict majority class class dominates data 
increasing number runs consistently increased replicability 
appears sorted runs sampling scheme results sample independence assumption heavily violated correction variance degrees freedom required :10.1.1.58.4949
table shows results data sets uci repository sorted runs sampling scheme di erent types tests 
compared naive bayes nearest neighbor nb nn respectively table 
algorithm run times 
middle columns show number times experiment decides null hypothesis acceptable algorithms perform equal data set numbered footnote null hypothesis times accepted dot shown situations indicate perfect replicability 
observation replicability issue non synthetic data sets ects machine learning researchers 
sign test performs worse tests test shows marginally higher replicability rank sum test 
sampling method hypothesis test impact replicability experiment 
anneal arrhythmia audiology autos balance scale breast cancer credit rating ecoli german credit glass heart statlog hepatitis horse colic hungarian heart disease ionosphere iris labor lymphography primary tumor sonar soybean vehicle vote vowel wisconsin breast cancer zoo 

defined replicability machine learning experiments terms probability 
benefit allows comparison di erent experimental designs previous ad hoc definition :10.1.1.58.4949
example replicability measured repeats experiment compared replicability measure repeats 
furthermore threshold ects ad hoc definition definition 
main theoretical result presentation estimator replicability shown unbiased lowest variance class 
estimator gathered empirical data gain new insights experimental designs influence replicability hypothesis test sampling scheme class probability impact replicability 
experiments replicability consistently increased sampling methods draw samples data set 
replicability appears issue synthetic data sets uci data sets 
indicates machine learning researcher data analysts wary interpreting experimental results 
main practical outcome experiments judged replicability sorted runs sampling scheme widely test showed superior properties compared sign test performed marginally better rank sum test 
sorted runs scheme combining accuracy estimates way produces representative sample accuracy di erences learning algorithms 
surprisingly sorted runs sampling schemes scheme set popular schemes considered showed acceptable type errors reasonable power wide range parameters hypothesis tests considered 
consequently experiments sorted runs sampling schemes require variance corrections calibration degrees freedom :10.1.1.58.4949
summary replicability type error power theoretical considerations recommend sorted runs sampling scheme test comparing classifiers small data set 
expect replicability ceases issue larger data sets 
perform larger scale experiments get better insight relation replicability number samples taken experiment data set size 
give better insight relation replicability type ii error 
considered machine learning experiments choose best classifiers data set 
practice classifiers available 
machine learning researchers routinely compare algorithms large number data sets 
leads new replicability issues multiple comparison problems issues require research 
machine learning group waikato university stimulating discussions anonymous reviewers helpful comments 
appendix lemma positive integer np np np proof sketch equation binomial theorem 
second follows observation term sum zero range sum changed absorb sum outside term summation apply binomial theorem 
third equation follows similar line reasoning 
blake merz 
uci repository machine learning databases 
irvine ca university california 
bouckaert :10.1.1.58.4949
choosing learning algorithms calibrated tests 
icml 
dietterich 
approximate statistical tests comparing supervised classification learning algorithms 
neural computation 
graham knuth patashnik concrete mathematics 
addison wesley 
john pat langley 
estimating continuous distributions bayesian classifiers 
uai 
nadeau bengio 
inference generalization error 
advances neural information processing systems mit press 
quinlan 
programs machine learning 
morgan kaufmann publishers san mateo ca 
salzberg 
comparing classifiers pitfalls avoid recommended approach 
data mining knowledge discovery 
witten frank 
data mining practical machine learning tools techniques java implementations 
morgan kaufmann san francisco 
