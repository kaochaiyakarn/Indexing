language task independent text categorization simple language models peng dale schuurmans wang school computer science university waterloo university avenue west waterloo ontario canada ff peng dale cs uwaterloo ca simple method language independent task independent text categorization learning character level gram language models 
approach uses simple information theoretic principles achieves effective performance variety languages tasks requiring feature selection extensive pre processing 
demonstrate language task independence proposed technique experimental results languages greek english chinese japanese text categorization problems language identification authorship attribution text genre classification topic detection 
experimental results show simple approach achieves state art performance case 
text categorization concerns problem automatically assigning text passages paragraphs documents predefined categories 
due rapid explosion texts digital form text categorization important area research owing need automatically organize index large text collections various ways 
techniques currently applied areas including language identification authorship attribution text genre classification topic identification dumais lewis mccallum yang subjective sentiment classification turney 
standard machine learning techniques applied automated text categorization problems naive bayes classifiers support vector machines linear squares models neural networks nearest neighbor classifiers yang sebastiani 
common aspect approaches treat text categorization standard classification problem reduce learning process simple steps feature engineering classification learning feature space 
steps feature engineering critical achieving performance text categorization problems 
features identified reasonable technique learning classifier perform scott 
unfortunately standard classification learning methodology drawbacks text categorization 
feature construction usually language dependent 
various techniques word removal stemming require language specific knowledge design adequately 
purely word level approach language dependent issue 
asian languages chinese japanese identifying words character sequences hard word approach suffer added complexity coping segmentation errors 
second feature selection task dependent 
example tasks authorship attribution genre classification require attention linguistic style markers topic detection systems rely heavily bag words features 
third enormous number possible features consider text categorization problems standard feature selection approaches cope circumstances 
example enormous number features cumulative effect uncommon features important effect classification accuracy infrequent features contribute information common features individually 
consequently throwing away uncommon features usually appropriate strategy domain 
problem feature selection normally uses indirect tests mutual information involve setting arbi thresholds conducting heuristic greedy search find feature sets 
treating text categorization classical classification problem standard approaches ignore fact texts written natural language meaning implicit regularities modeled specific tools natural language processing 
propose straightforward text categorization learning method learning character level gram language models 
simple approach systematically investigated literature 
find surprisingly obtain competitive superior results sophisticated learning feature construction techniques requiring feature engineering pre processing 
fact approach requires language specific task specific pre processing achieve effective performance 
success simple method think due effectiveness known statistical language modeling techniques surprisingly little significant impact learning algorithms normally applied text categorization 
statistical language modeling concerned modeling semantic syntactic lexicographical phonological regularities natural language provide natural foundation text categorization problems 
interesting difference explicitly pre computing features selecting subset arbitrary decisions language modeling approach simply considers character word subsequences occurring text candidate features implicitly considers contribution feature final model 
language modeling approach completely avoids potentially error prone feature selection process 
applying character level language models avoids word segmentation problems arise asian languages achieves language independent method constructing accurate text 
gram language modeling dominant motivation language modeling traditionally come speech recognition language models widely application areas 
goal language modeling predict probability naturally occurring word sequences simply put high probability word sequences occur low probability word sequences occur 
word sequence test corpus quality language model measured empirical perplexity entropy scores corpus perplexity pr jw entropy log perplexity goal minimize measures 
simplest successful approach language modeling gram model 
chain rule probability write probability word sequence pr pr jw gram model approximates probability assuming words relevant predicting pr jw previous words pr jw pr jw straightforward maximum likelihood estimate gram probabilities corpus observed frequency patterns pr jw 
denotes number occurrences specified gram training corpus 
attempt simple gram models capture long range dependencies language attempting directly immediately creates sparse data problems grams length entails estimating probability events size word vocabulary 
quickly overwhelms modern computational data resources modest choices 
heavy tailed nature language zipf law encounter novel grams witnessed training test corpus mechanism assigning non zero probability novel grams central unavoidable issue statistical language modeling 
standard approach smoothing probability estimates cope sparse data problems cope potentially missing grams sort back estimator 
pr jw pr jw pr jw pr jw discount discounted probability normalization constant pr pr discounted probability computed different smoothing techniques including absolute smoothing turing smoothing linear smoothing witten bell smoothing chen goodman 
details smoothing techniques omitted simplicity 
language models described individual words basic unit consider models individual characters basic unit 
remaining details remain case 
difference character vocabulary smaller word vocabulary means normally higher order character level gram model text spanned character model usually spanned word model 
benefits character level model context text classification fold avoids need explicit word segmentation case asian languages captures important morphological properties author writing models typos misspellings common informal texts discover useful inter word inter phrase features greatly reduces sparse data problems associated large vocabulary models 
experiment character level models achieve flexibility language independence 
language models text classifiers approach applying language models text categorization bayesian decision theory 
assume wish classify text category fc jcj natural choice pick category largest posterior probability text 
arg max fpr cjd bayes rule rewritten arg max fpr djc pr arg max fpr djc arg max jw deducing eq 
eq 
assumes uniformly weighted categories prior knowledge pr djc likelihood category computed eq 

likelihood related perplexity entropy eq 
eq 

approach learn separate language model category training data set category 
categorize new text supply language model evaluate likelihood entropy model pick winning category eq 

inference gram text classifier similar naive bayes classifier 
fact gram classifiers straightforward generalization naivebayes uni gram classifier laplace smoothing corresponds exactly traditional naive bayes classifier 
gram language models larger possess advantages naive bayes classifiers including modeling longer context applying superior smoothing techniques presence sparse data 
experimental comparison proceed results text categorization problems different languages 
specifically consider language identification greek authorship attribution greek genre classification english topic detection chinese topic detection japanese topic detection 
sake consistency previous research measure categorization performance accuracy number correctly identified texts divided total number texts considered 
measure performance macro fmeasure average measures categories 
measure combination precision recall yang 
language identification text categorization problem examined language identification useful pre processing step information retrieval 
language identification probably easiest text classification problem significant morphological differences languages absolute turing linear witten bell acc 
mac acc 
mac acc 
mac acc 
mac table results greek authorship attribution character set 
experiments considered chapter bible translated different languages english french german italian latin spanish 
case reserved sentences language testing remainder training 
task bi gram character level models smoothing technique achieved accuracy 
authorship attribution second text categorization problem examined author attribution 
famous example case federalist papers twelve instances claimed written alexander hamilton james madison holmes forsyth 
authorship attribution challenging language identification difference authors subtle different languages 
considered data set consisting texts written different modern greek authors totaling documents 
case texts author training remaining testing 
results different orders gram models different smoothing techniques shown table 
grams absolute smoothing observe accuracy 
result compares favorably accuracy reported linear square fit llsf 
text genre classification third problem examined text genre classification important application information retrieval lee 
considered greek data set consisting texts different styles extracted various sources documents total 
style texts training data remaining testing 
language identification speech harder 
absolute turing linear witten bell acc 
mac acc 
mac acc 
mac acc 
mac table results greek text genre classification results learning gram text classifier shown table 
accuracy obtained bi gram models compares favorably reported deeper nlp analysis 
topic detection fourth problem examined topic detection text heavily researched text categorization problem dumais lewis mccallum yang sebastiani 
demonstrate language independence language modeling approach considering experiments english chinese japanese data sets 
english data english newsgroup data widely topic detection research mccallum rennie 
collection consists non empty documents distributed evenly newsgroups 
newsgroups form categories randomly select documents training set aside remaining testing 
case merely considered text sequence characters learned character level gram models 
resulting classification accuracies reported table 
gram higher order models consistently obtain accurate performance peaking accuracy case gram models witten bell smoothing 
note word level models able achieve accuracy case 
results compare favorably state art result accuracy reported rennie combination svm error correct output coding ecoc 
chinese data chinese topic detection thought challenging english words whitespace delimited chinese text 
fact www ai mit edu newsgroups absolute turing linear witten bell acc 
mac acc 
mac acc 
mac acc 
mac table topic detection results english newsgroup data absolute turing linear witten bell acc 
mac acc 
mac acc 
mac acc 
mac table chinese topic detection results require word segmentation performed preprocessing step classification 
avoid need explicit segmentation simply character level gram classifier 
chinese topic detection considered data set investigated 
corpus case subset trec data set created research chinese text retrieval 
data set suitable text categorization documents clustered groups shared headline indicated sgml tag frequent groups selected chinese text categorization data set 
group documents randomly selected training documents reserved testing 
observe accuracy task bigram chinese characters higher order models 
level performance reported svm approach word segmentation feature selection 
japanese data japanese poses word segmentation issues chinese 
word segmentation thought necessary japanese text categorization avoid need considering character level language models 
consider japanese topic detection data investigated 
data set con absolute turing linear witten bell acc 
mac acc 
mac acc 
mac acc 
mac table japanese topic detection results data set originally created japanese text retrieval research 
data categories 
testing set contains documents distributed unevenly categories minimum maximum documents category 
imbalanced distribution causes difficulty assumed uniform prior categories 
easily remedied fix problem 
obtain experimental results table show accuracy rate problem gram higher order models 
level performance reported uses svm approach word segmentation morphology analysis feature selection 
analysis perplexity test document language model depends factors 
influential factors order gram model smoothing technique 
different choices result different perplexities influence final decision eq 

experimentally assess influence factors 
effects gram order order key factor gram language models 
small model capture context 
large create severe sparse data problems 
extremes result larger perplexity optimal context length 
figures illustrate influence order classification performance language model quality previous experiments absolute smoothing 
note case entropy bits character average entropy testing documents 
curves see order increases classification accuracy increases testing entropy decreases presumably longer context better captures regularities text 
point accu order gram model greek authorship attribution greek genre classification english topic detection chinese topic detection japanese topic detection influence order classification performance order gram model greek authorship attribution greek genre classification english topic detection chinese topic detection japanese topic detection entropy different gram models racy begins decrease entropy begins increase sparse data problems set 
interestingly effect pronounced experiments greek genre classification experiments topic detection language 
sensitivity greek genre case attributed sparse data problem fitting problem genre classification serious problems seen entropy curves 
effects smoothing technique key factor affecting performance language model smoothing technique 
figures show effects smoothing techniques classification accuracy testing entropy chinese topic detection japanese topic detection shown save space 
find cases smoothing technique significant effect text categorization accuracy small vocabulary size greek authorship attribution greek genre english topic detection order gram models absolute turing linear witten bell influence smoothing accuracy greek authorship attribution greek genre english topic detection order gram models absolute turing linear witten bell entropy different smoothing character level gram models 
exceptions greek authorship attribution greek text genre classification turing smoothing effective techniques gives better test entropy 
goal final decision ranking perplexities just absolute values superior smoothing method sense perplexity reduction perspective classical language modeling necessarily lead better decision perspective categorization accuracy 
fact experiments witten bell smoothing turing smoothing gives best results terms classification accuracy 
observation consistent previous research reports smoothing achieves benchmark performance character level text compression bell 
part standard smoothing technique problems obtain comparable performance rankings produce 
relation previous research principle language model perform text categorization eq 

gram models extremely simple effective applications 
example character level gram language models easily applied language non language sequences dna music 
character level gram models widely text compression ppm model bell effective text classification problems teahan harper 
ppm model weighted linear interpolation gram models set benchmark text compression decades 
building adaptive ppm model expensive bell back models relatively simpler 
compression techniques text categorization investigated benedetto authors seek model yields minimum compression rate increase new test document introduced 
method generally effective efficient goodman 
approach evaluate perplexity entropy directly test documents find outcome effective efficient 
previous researchers realized importance gram models designing language independent text categorization systems damashek 
grams features traditional feature selection process deployed classifiers calculating feature vector similarities 
feature selection classical approach critical required procedures word removal language dependent 
approach grams considered features importance implicitly weighted contribution perplexity 
avoid error prone preliminary feature selection step 
extremely simple approach language task independent text categorization character level gram language modeling 
approach evaluated different languages different text categorization problems 
surprisingly observe state art better performance case 
experimentally analyzed influence factors affect accuracy approach part results robust perturbations basic method 
wide applicability simplicity approach immediately applicable sequential data natural language music dna yields effective baseline performance 
currently investigating challenging problems multiple category classification reuters data set lewis subjective sentiment classification turney 
results suggest basic statistical language modeling ideas relevant areas natural language processing commonly perceived 
acknowledgments research supported bell university labs 


linguistic techniques improve performance automatic text categorization 
proceedings sixth natural language processing pacific rim symposium 
bell cleary witten 

text compression 
prentice hall 
benedetto 

language trees zipping 
physical review letters 


gram text categorization 
proceedings rd annual symposium document analysis information retrieval sdair 
chen goodman 

empirical study smoothing techniques language modeling 
technical report tr harvard university 
damashek 

gauging similarity grams language independent categorization text 
science vol 
february dumais platt heckerman sahami 

inductive learning algorithms representations text categorization 
proceedings acm conference information knowledge management cikm nov pp 

goodman 

comment language trees zipping 
unpublished manuscript 
tan tan 

comparative study chinese text categorization methods 
proceedings pricai international workshop text web mining 
holmes forsyth 

federalist revisited new directions authorship attribution 
literary linguistic computing 
kessler nunberg 

automatic detection text genre 
proceedings annual meeting association computational linguistics acl 
lee myaeng 

text genre classification genre revealing subject revealing features 
proceedings acm sigir conference research development information retrieval sigir lewis 

representation learning information retrieval phd thesis computer science univ massachusetts 
mccallum nigam 

comparison event models naive bayes text classification 
proceedings aaai workshop learning text categorization aaai 
rennie 

improving multi class text classification naive bayes 
master thesis 
ai technical report 

scott matwin 

feature engineering text classification 
proceedings sixteenth international conference machine learning icml pp 

sebastiani 

machine learning automated text categorization 
acm computing surveys 
kokkinakis 

automatic text categorization terms genre author 
computational linguistics 
teahan harper 

language models text categorization 
proceedings workshop language modeling information retrieval 
turney 

thumbs thumbs 
semantic applied unsupervised classification reviews 
proceedings th annual conference association computational linguistics acl yang 

evaluation statistical approaches text categorization 
information retrieval pp 

