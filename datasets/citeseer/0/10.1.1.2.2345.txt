fast robust edge localization sony legged robot league thomas fer matthias institut systeme technologie zentrum informatik fb universit bremen 
mail tzi de institut informatik lfg nstliche intelligenz humboldt universit zu berlin 
mail informatik hu berlin de 
presents fast approach edge robocup 
vision system extracts edges field field lines borders goals grid approach processing images 
edges employed robot 
image processing self localization real time sony aibo frame rate camera 
localization method evaluated laser range sensor field border system 
sony legged robot league official leagues robocup 
legged robots specialties league 
robot platform standardized sony aibo ers ers cf 
fig 
permitted systems modification 
sense seen software league possible required construct robots 
characteristic robots completely autonomous external computer field running called game manager referee help players calculations 
main sensor sony aibo camera located head 
head turned axes tilt pan roll camera field view teams league tackle problem directed vision contrast omni vision middle sized league approaches small sized league local vision systems 
degrees freedom color camera sensors movements sensor equipment robots complex robocup far controlled single mhz mips processor mhz ers algorithms image processing self localization highly efficient run real time 
deutsche forschungsgemeinschaft supports priority program cooperating teams mobile robots dynamic environments 
fig 

sony aibo robots ball 
field 
soccer field size approximately cf 
fig 

main sensor robot camera objects robocup field color coded 
colored flags localization pink yellow green goals different color yellow ball orange robocup leagues robots teams wear different colors red blue 
flags real soccer field goal robocup initiative compete human world champion natural thing develop techniques self localization depend artificial clues 
teams participate technical challenges part robocup championship 
self localization colored flags field challenges 
challenge seen preparation remove flags soccer games 
grid line detection localization method relies detection edges differently colored objects field edges goal field edges yellow goal field edges border field edges field lines field cf 
fig 

key idea method extract lines image pixels lines 
approach faster robust lines partially hidden robots due limited opening angle camera 
common preprocessing step vision object recognition color segmentation color tables 
methods directly map colors color classes pixel pixel basis crucial drawbacks 
hand color mapping adapted lighting conditions change hand mapping results loss information membership pixel certain class decision ignoring fig 

detection lines 
types lines field goal field border field line 
scan lines scanned top bottom left right 
white pixels increase channel black pixels decrease channel 
influences surrounding pixels 
researchers try overcome limitations solutions slow real time conditions robot aibo 
key ideas image processing method speed achieved avoiding processing pixels image certain independence lighting conditions reached focusing contrast patterns different color channels 
case aibo channels find pixels edges image horizontal vertical lines having distance pixels scanned left right top bottom method described cf 
fig 

contrast method color classification applied significant decrease channel recognized field darker adjacent surfaces field lines border goals 
decrease brightness detected colors edge checked green white yellow color table cf 
solution problem color tables 
color decrease channel yellow pixel lies edge goal field 
differentiation field line border bit complicated 
cases border bigger size image field line 
far distant border smaller close field line 
reason pixel decrease channel assumed lie ground 
known height rotation camera distance point calculated projecting ground plane 
distance leads expected sizes border field line image 
classification sizes compared distance increase decrease channel image 
projection pixels field plane determine relative position robot cf 
fig 

fig 

projection edge points field plane 
vertically 
horizontally 
self localization edge points approach self localization called monte carlo localization mcl fox :10.1.1.2.342
probabilistic method current location robot modeled density set particles 
particle seen hypothesis robot located position 
particles mainly consist robot pose vector representing robot coordinates rotation 
implementations mcl robots equipped distance sensors laser scanners sonar sensors original :10.1.1.2.342
approaches vision self localization 
self localization robocup different area robots located relatively small field area position robots determined quite precisely allow different robots team communicate objects field follow location rules game 
odometry unreliable robots walk tend push 
aibo equipped sensor narrow opening angle objects usable self localization seen majority 
method takes circumstances account 
monte carlo localization markov localization method requires motion model observation model 
motion model expresses probability certain actions move robot certain relative positions 
observation model describes probability certain measurements certain locations 
localization approach works follows particles moved motion model previous action robot 
probabilities qi determined particles basis observation model current sensor readings 
probabilities called resampling performed moving particles locations samples high probability 
average probability distribution determined representing best estimation current robot pose 
process repeats 
motion model motion model represents effects actions robot pose 
odometry position maintained derived motions performed gaits kicks 
value rough estimate addition random error error assumed depends distance traveled rotation performed self localization 
sample new pose determined odometry error 
note operation involves coordinate transformations rotational components poses 
observation model localization points edges determined system cf 
sect 

pixel edge type field border yellow goal blue goal projecting field relative offset body center robot determined 
note calculation offsets prone errors pose camera determined precisely 
fact farther away point precise distance determined 
precision direction certain point dependent distance point 
information provided edge points 
edge types provide different information field lines oriented field 
lines provide localization information perpendicular orientation field lines help robot find position field 
field lines seen border 
border surrounding field 
provides information cartesian directions quite far away robot 
distance information precise provided field lines 
border seen nearly location field 
goals means determine orientation field field lines border mirror symmetric 
goals seen rarely 
probability distribution pose robot modeled large set particles fact different edges provide different information seen different frequency problem 
reach real time performance aibo robot small set samples employed approximate probability distribution 
small set samples behave individuals part joint distribution 
clarify issue assume situation field mirror symmetric recognition goals determine correct orientation field 
samples located actual fig 

distances edges 
distance visualized thickness dots 
field lines 
border 
goal 
goal 
location robot placed mirror symmetric variant recognition goals discriminate possibilities 
longer period time goal detected border field lines seen 
conditions possible samples wrong side field better match measurements border field lines correctly located ones resulting higher probability wrong position 
estimated pose robot flip orientation alternative seeing goal 
desired behavior quite risky actual soccer games 
avoid problem separate probabilities field lines borders goals maintained particle 
closest model points 
projections pixels determine probabilities sample monte carlo distribution 
positions samples field known determined measurement sample measured points located field position sample correct 
measured points field coordinates calculated closest point real field line corresponding type located 
horizontal vertical angles camera model point determined 
angles model point compared angles measured point 
smaller deviations model point measured point position probable robot really located position 
deviations vertical angle distance judged rigidly deviations horizontal angle direction 
calculating closest point edge field model small number measured points expensive operation performed samples 
model points pre calculated edge type stored dimensional lookup tables resolution cm 
way closest point edge corresponding type determined simple table lookup 
visualizes distances measured points closest model point different edge types 
probabilities 
observation model takes bearings edges account seen ignored robot seen certain edge seen hypothetical position camera pose 
probabilities particles calculated similarities measured angles expected angles 
similarity determined measured angle seen expected angle exp certain pose applying sigmoid function difference angles weighted constant seen exp seen exp seen exp vertical angles seen exp horizontal angles similarity sample certain edge type calculated seen seen exp exp seen exp seen exp calculating probability points edges samples monte carlo distribution costly operation 
single point edge type detected selected image random 
achieve stability resulting image processing problems bad synchronization receiving image corresponding joint angles head change probability sample edge type limited certain maximum 
immediately affect probability distribution 
readings required lower probability resulting higher stability distribution 
position robot changed externally measurements constantly inconsistent current distribution samples probabilities fall rapidly resampling cf 
sect 
take place 
filtered probability certain edge type updated old new point type new old old old old 
probability certain particle product separate probabilities edges field lines border goals resampling field lines border goals resampling step samples moved probabilities 
done steps samples copied old distribution new distribution 
frequency new distribution depends probability sample probable samples copied probable ones improbable samples removed 
second step fact part motion update particles moved locally probability 
probable sample moved 
seen probabilistic random search best position samples randomly moved closer real position robot rewarded better probabilities observation update steps frequent distributions 
samples moved equation trans rnd trans rnd rot rnd rnd returns random numbers range 

typical values trans rot cm drawing observations far observation edge points determine probability robot certain location 
observations generate candidate positions localization place samples certain positions field 
approach follows sensor resetting idea lenser veloso seen small scale version mixture mcl thrun 
single observation uniquely determine location robot candidate positions drawn locations certain measurement 
realize robot equipped table edge type contains large number poses field indexed distance edge corresponding type measured location forward direction 
measurement candidate position drawn constant time set locations provide similar measurements 
entries table assume measurements forward direction resulting poses rotated compensate direction actual measurement 
candidate positions replace samples low probability 
sample replaced drawn probability sample relation average probability samples condition satisfied rnd qi qj case rnd provides random number 
sample replaced new sample probabilities little bit average 
acknowledged measurements seen real candidates position robot 
estimating pose robot pose robot calculated sample distribution steps largest cluster determined current pose calculated average samples belonging cluster 
calculate largest cluster samples assigned grid discretizes space cells 
searched sub cube contains maximum number samples 
samples belonging sub cube estimate current pose robot 
mean components directly determined averaging angles straightforward circularity 
mean angle robot calculated orientation sum direction vectors robot atan sin cos experiments judge performance localization approach different experiments conducted 
measures localization error robot continuously moving 
second evaluates precision reaching certain goal points 
experimental setup able evaluate precision approach self localization method localization required 
gutmann fox analyzed different localization approaches aibo manually controlling robot joystick reached position previously marked stored position marker position calculated robot log file :10.1.1.116.6293
stored perceptions robot allowing test different localization approaches data 
setup experiments little bit different 
able continuously track position robot laser fig 

experimental setup 
laser scanner fixed border field 
robot carries vertical tube back measured laser sensor 
range finder placed border field 
opening angle measured distances height cm goals 
robot experiment equipped tube back high detected laser range finder cf 
fig 

way position robot easily determined searching area significantly closer laser scanner neighboring areas 
shortest distance area plus radius tube distance robot 
angle robot measured exact location robot determined 
experiments robot continuously turning head left right vice versa 
monte carlo localization method samples 
experiment goal experiment judge precision localization approach robot continuously moving 
accomplish robot randomly moved field maximum speed cm joystick 
positions robot calculated robot measured laser scanner stored file 
experiment took minutes resulting approximately measurements 
result average error cm width soccer field length 
measurements error average 
shows path traveled errors 
please note outcome similar results exceptions gutmann fox color marks localization performed experiments small field :10.1.1.116.6293
addition worked log file allowing optimally adjust parameters algorithms monte carlo localization approach needed samples 
fig 

experimental results 
line connects position calculated robot determined laser scanner 
experiment 
second experiment 
experiment goal second experiment evaluate precision reaching certain goal points 
experiment random goal positions robot 
system performed called go point skill reach specified location 
robot move anymore coordinates goal position position calculated robot position measured laser scanner stored file 
experiment positions reached 
results average error goal position position reported laser scanner cm 
goals reached smaller deviations 
go point skill reach goal position precisely 
stops cm early 
average error position measured robot position measured laser sensor smaller cm 
goals reached smaller error 
shows goal positions positions reached robot 
presents approach edge self localization 
vision system extracts edges processing images 
localization method variant known monte carlo localization 
small number samples increases stability localization maintaining separate probabilities different edge types sample 
probabilities adapted slowly 
results fast robust precise self localization robot seen milestone shows self localization color beacons possible 
results show edge localization possible robot field 
experiments show localization method actual robocup games 
recognition edge points quite robust head swing left right back actual soccer games robot track ball 
situation different requires suitable control strategy head posture 
acknowledgments authors members germanteam providing basis research martin tzsch uwe max 

bruce balch veloso 
fast inexpensive color image segmentation interactive robots 
proceedings ieee rsj international conference intelligent robots systems iros volume pages 

dellaert burgard fox thrun 
condensation algorithm robust vision mobile robot localization 
proc 
ieee computer society conference computer vision pattern recognition cvpr 

fox burgard dellaert thrun 
monte carlo localization efficient position estimation mobile robots 
proc 
national conference artificial intelligence 

gutmann 
fox 
experimental comparison localization methods continued 
proc 
ieee rsj international conference intelligent robots systems lausanne switzerland 
epfl 

robert thorsten schmitt sebastian buck michael beetz 
fast imagebased object localization natural scenes 
ieee rsj international conference intelligent robots systems iros lausanne 


fast vision system middle size robots robocup 
th international workshop robocup robot world cup soccer games conferences number lecture notes computer science pages 
springer 

hoffmann tzsch 
real time auto adjusting vision system robotic soccer 
th international workshop robocup robot world cup soccer games conferences lecture notes artificial intelligence 
springer 
appear 

lenser veloso 
sensor resetting localization poorly modeled mobile robots 
proc 
ieee international conference robotics automation icra 

quek 
algorithm rapid computation boundaries run length encoded regions 
pattern recognition journal 

thrun fox burgard 
monte carlo localization mixture proposal distribution 
proc 
national conference artificial intelligence pages 
aaai 

wolf burgard burkhardt 
robust vision localization mobile robots image retrieval system invariant features 
proc 
ieee international conference robotics automation icra 
