mining web sites wrapper induction named entities post processing georgios georgios paliouras constantine spyropoulos institute informatics telecommunications box gr athens greece iit gr department informatics telecommunications university athens buildings athens greece mike di uoa gr 
presents novel method extracting information collections web pages different sites 
method uses standard wrapper induction algorithm exploits named entity information 
introduce idea post processing extraction results resolving ambiguous facts improve extraction performance 
postprocessing involves exploitation additional sources information fact transition probabilities trained bigram model confidence probabilities estimated fact wrapper induction system 
multiplicative model product probabilities considered post processing 
experiments conducted pages describing laptop products collected different sites different languages 
results highlight effectiveness approach 
wrapper induction wi aims generate extraction rules called wrappers mining highly structured collections web pages labeled domainspecific information 
run time wrappers extract information unseen collections fill slots predefined template 
collections typically built querying appropriate search form web site collecting response pages commonly share content format 
central challenge wi community information extraction pages multiple sites including unseen sites single trained system 
pages collected different sites usually exhibit multiple hypertext markup structures including tables nested tables lists current wi research relies learning separate wrappers different structures 
training effective site independent system attractive solution terms scalability domain specific page processed relying heavily hypertext structure 
novel approach web pages different sites 
proposed method relies domain specific named entities identified web pages 
entities embedded web pages xml tags serve page independent common markup structure pages different sites 
standard wi system applied exploit additional textual information 
new system relies page independent named entity markup tags inducing delimiter rules hypertext markup tags vary pages multiple sites 
experimented stalker performs extraction wide range web pages employing special formalism allows specification output multi place schema extraction task 
information extraction pages different sites hard problem due multiple markup structures described single formalism 
suggest stalker single slot extraction extraction isolated facts extraction fields pages different sites 
contribution method post processing system extraction results order disambiguate facts 
applying set single slot extraction rules web page exclude possibility identical overlapping textual matches page different rules 
instance rules extracting instances facts cd rom dvd rom pages describing laptop products may overlap exactly match certain text fragments resulting ambiguous facts 
facts correct choice 
deal issue ambiguous facts sources information explored transitions facts incorporated bigram model prediction confidence values generated wi system 
deciding correct fact information trained bigram model confidence assigned predicted fact 
multiplicative model combines sources information compared components 
rest structured follows section outline architecture approach 
section briefly describes named entity recognition task 
section reviews stalker section discuss stalker proposed approach perform pages different sites 
section discuss issue post processing output stalker system order resolve ambiguous facts 
section presents experimental results datasets soon publicly released 
related section 
conclude section discussing potential improvements approach 
information extraction multiple web sites methodology multiple web sites graphically depicted 
component modules process web page 
named entity recognizer ner identifies domain specific named entities pages multiple sites 
trained wi system applied perform extraction 
extraction results post processed improve extraction performance 
fig 

generic architecture information extraction multiple web sites named entity recognition named entity recognition ner important subtask language engineering applications included muc competitions 
ner best known step task involves identification set basic entity names numerical expressions temporal expressions task aims extract facts form multi place relations ner provides entities fill argument slots 
ner received attention web tasks 
ner order identify basic named entities relevant task reduce complexity fact extraction 
identified entities identified web pages xml tags serve valuable source information wi system follows extracts facts 
entity names ne numerical numex temporal timex expressions laptop domain shown table corresponding examples xml tags 
table 
subset named entities laptop domain entity entity type examples xml tags ne model processor ne type model ne ne type processor intel pentium ne numex capacity speed numex type speed mhz numex numex type capacity gb numex timex duration timex type duration year timex stalker wrapper induction system stalker sequential covering rule learning system performs single slot extraction highly structured web pages 
multi slot extraction linking isolated facts feasible embedded catalog ec tree formalism may describe common structure range web pages 
ec tree constructed manually usually site leaves represent individual facts 
stalker capable extracting information pages tabular organization content pages hierarchically organized content 
extraction rule stalker consists ordered lists linear landmark automata la subclass nondeterministic finite state automata 
list constitutes start rule second list constitutes rule 
ec tree guide extraction page performed applying fact la constitute start rule order appear list 
soon la matches page matching process terminates 
process symmetric rule 
details algorithm 
adapting stalker multi site information extraction ec tree formalism stalker generally applicable describing pages variable markup structure 
different ec trees need manually built different markup structures different extraction rules induced 
seeking single domain specific trainable system having deal page structure separately 
focuses widely approach single slot extraction 
motivation isolated facts accurately identified possible link facts separately second step 
specify task follows fact try induce list iteration rule depicted 
fig 

simplification ec tree 
list iteration rule learned fact applies content page run time ec tree depicted interpretation web page describes laptop products consists list instances fact manufacturer compaq list instances fact list ram instances mb system runtime exhaustively applies rule content page 
simplified ec tree independent particular page structure 
proposed approach relies page independent named entities lead efficient extraction rules 
extraction rule applies exhaustively complete web page constrained ec tree expect extraction bias recall overgeneration extracts fact 
penalty potential loss precision rule applies text regions contain relevant information may return erroneous instances 
seek post processing mechanism capable discarding erroneous instances improving precision 
post processing extraction results single slot systems rule applied independently 
may naturally cause identical overlapping matches different rules resulting multiple ambiguous facts matches 
resolve ambiguities choose correct fact 
choosing correct fact removing shall improve extraction precision 
problem specification adopt post processing approach order resolve ambiguities extraction results system 
formally task described follows 
sequence document tokens tj sj ej fragment sequence sj ej start token bounds respectively 

ij ij tj set instances extracted rules predicted fact associated instance tj 

dt list distinct text fragments tj appearing extracted instances note different 
elements dt sorted ascending order sj 

distinct fragment ti dt exist instances ik il ik ti il ti ambiguous facts ti 

goal associate single fact element list dt 
illustrate problem fragment tj page describing laptops extracted instances ik il ambiguous facts ti 
chosen associated tj 
formulate task hill climbing search resolving ambiguous facts viewed hill climbing search space possible sequences facts associated sequence dt distinct text fragments 
hill climbing search formulated follows 
start hypothetical empty node transition step distinct text fragment tj sorted sequence dt 

step apply set operations choose 
operation associates tj predicted instance ik tj 
weight assigned operation predefined metric 
operation highest weight selected step 

goal search associate single fact distinct fragment sorted list dt return final unambiguous sequence facts dt 
illustrate procedure consider fictitious token table table part page describing laptop products 
table 
part token table page laptops 
instances extracted stalker 
tree possible fact paths extracted instances disambiguation process ghz gb gb ram hard disk capacity start node processor speed hard disk capacity hard disk capacity fact processor speed ram hard disk capacity hard disk capacity fact processor speed ram hard disk capacity table lists instances extracted stalker token table part table 
dt list consists distinct fragments 
table shows possible fact sequences associated dt 
processor speed fact prediction operations apply predicting fact choose ram choose hard disk capacity operations associated weight predefined metric 
assume operation returns higher weight value ram chosen fact 
bold circles tree show chosen sequence facts processor speed ram hard disk capacity attached sequence 
table illustrates final extracted instances disambiguation process 
explore metrics assigning weights choice operations 
confidence values estimated fact wi algorithm 

fact transition probabilities learned bigram model 

product probabilities simple multiplicative model 
selecting correct instance correct fact step discarding results improving precision 
incorrect choice harms recall precision certain fact 
goal disambiguation process improve precision keeping recall unaffected 
estimating fact confidence original stalker algorithm assign confidence values extracted instances 
estimate confidence values calculating value extraction rule fact 
value calculated average precision obtained fold cross validation methodology training set 
methodology training data split equally sized subsets learning algorithm run times 
time pieces training third kept unseen data evaluation induced extraction rules 
pieces acts evaluation set runs final result average runs 
runtime instance extracted single slot rule assigned precision value rule 
example text fragment mhz matched processor speed rule fragment assigned confidence associated processor speed 
key insight confidence values ambiguous facts choose highest estimated confidence 
learning fact transition probabilities extraction domains facts appear fixed order page 
instance page describing laptop products may contain instances processor speed fact appearing immediately instances processor name fact 
training simple bigram model natural way modeling dependencies easily implemented calculating ratios counts maximum likelihood estimation labeled data follows nominator counts transitions fact fact labeled training instances 
denominator counts total number transitions fact facts including self transitions 
calculate starting probability fact probability instance particular fact appearing labeled training pages 
motivation fact transitions ambiguous facts choose highest transition probability preceding fact prediction 
illustrate consider text fragment identified page describing laptops 
assume preceding fact prediction system ram 
transition ram higher probability learned bigram ram choose fact 
ambiguity occurs extracted instance preceding fact prediction available choose fact highest starting probability 
employing multiplicative model simple way combine sources information described multiplicative model assigning confidence value extracted instance ik ti product confidence value estimated transition probability preceding instance 
example table ambiguous facts ram hard disk capacity text fragment table depicts probabilities assigned fact methods described sections multiplicative model 
table 
probabilities assigned ambiguous facts text fragment table gb wi confidence bigram multiplicative ram hard disk capacity wi confidence values ram selected 
bigram probabilities hard disk capacity selected 
experimented model averages probabilities multiplying 
experiments led worse results 
experiments dataset description experiments conducted language corpora greek french english italian describing laptop products 
corpora collected context approximately pages language hand tagged web page annotation tool 
corpus language divided equally sized data sets training testing 
part test corpus collected sites appearing training data 
named entities embedded xml tags pages training test data illustrated table 
separate ner module developed languages project 
total facts hand tagged laptop product domain 
pages collected multiple vendor sites demonstrate rich variety structure including tables lists examples facts name manufacturer name model name processor speed processor ram results goal evaluate effect named entity information extraction performance stalker compare different methods resolving ambiguous facts 
conducted groups experiments 
group evaluated stalker testing datasets language named entities embedded xml tags pages 
table presents results 
evaluation metrics micro average recall micro average precision facts 
row table averages results languages 
table 
evaluation results stalker languages language micro precision micro recall greek french english italian average exhaustive application extraction rule content page resulted expected high recall accompanied lower precision 
named entity information led pure wi system stalker achieve www iit gr skel 
datasets soon available site 
level extraction performance pages variable structure 
trained stalker data embedding named entities pages 
result unacceptably high training time accompanied rules disjuncts overfit training data 
evaluation results testing corpora provided recall precision figures 
second group experiments evaluated post processing methodology resolving ambiguous facts described section 
results illustrated table 
table 
evaluation results resolving ambiguities language micro precision micro recall wi conf 
bigram mult 
wi conf 
bigram mult 
greek french english italian average comparing results table results table conclude 
choosing ambiguous facts methods achieves increase precision accompanied lower decrease recall 
results encouraging difficulty task 

bigram fact transitions choosing ambiguous facts achieves better results confidence values 
simple multiplicative model outperforms slightly single methods 
corroborate effectiveness multiplicative model counted number correct choices post processing methods step hillclimbing process described section 
results illustrated table 
table 
counting ambiguous predictions correct choices language distinct ambiguous corrected corrected corrected ti ti wi conf 
bigram mult 
greek french english italian average column table number distinct text fragments ti defined section pages testing corpus 
second column counts ti ambiguous facts table 
columns count correct choices methods 
conclude simple multiplicative model product bigram probabilities stalker assigned confidence probabilities correct choices methods individually 
related extracting information multiple web sites challenging issue wi community 
cohen fun method learning page independent heuristics web pages 
require input set existing wrappers pages correctly wrap 
cohen component larger system extracts information multiple sites 
common characteristic aforementioned approaches need encounter separately different markup structure training 
contrast approach examine viability trainable systems generalize unseen sites encountering page specific structure 
system exploits shallow linguistic pre processing information 
generalize extraction rules relying lexical units tokens associated shallow linguistic information lemma partof speech tag generalize rules relying named entities involve contiguous lexical units providing higher flexibility wi algorithm 
ontology driven system pages different sites 
rely hand crafted provided ontology regular expressions set heuristics order identify single slot facts document 
hand try induce expressions wrapper induction 
systems mentioned section experiment different corpora easily comparatively evaluated 
methodology extracting information web pages different sites pipeline component modules named entity recognizer standard wrapper induction system postprocessing module disambiguating extracted facts 
experimental results showed viability approach 
issue disambiguating facts important single slot systems web 
instance hidden markov models hmms known learning method performing single slot extraction 
approach single hmm trained fact 
run time hmm applied page viterbi procedure identify relevant matches 
identified matches different hmms may identical overlapping resulting ambiguous facts 
post processing methodology particularly useful hmm extraction tasks 
bigram modeling simplistic approach exploitation dependencies facts 
plan explore higher level interdependencies facts higher order gram models probabilistic fsa learned algorithm 
aim increase number correct choices ambiguous facts improving recall precision 
dependencies facts shall investigated context multi slot extraction 
bottleneck existing approaches labeling process 
despite user friendly annotation tool labeling process tedious timeconsuming error prone task especially moving new domain 
plan investigate active learning techniques reducing amount labeled data required 
hand anticipate labeled datasets benchmarks comparative evaluation current systems 

carrasco oncina learning stochastic regular grammars means state merging method 
grammatical inference applications spain 

ciravegna adaptive information extraction text rule induction generalization 
proceedings th ijcai conference 
seattle 

cohen fan learning page independent heuristics extracting data web pages 
proceedings th international www conference www 
toronto canada 

cohen hurst jensen flexible learning system wrapping tables lists html documents 
proceedings th international www conference 
hawaii usa 

mukherjee extraction techniques mining services web sources ieee international conference data mining city japan 

freitag mccallum information extraction hmms shrinkage 
aaai workshop machine learning information extraction 

kushmerick wrapper induction information extraction phd thesis department computer univ washington 

muc www itl nist gov related pr muc 

muslea active learning multiple views 
phd thesis university southern california 

muslea minton knoblock hierarchical wrapper induction semistructured information sources 
journal autonomous agents multi agent systems 

rabiner tutorial hidden markov models selected applications speech recognition 
proceedings ieee 

sebastiani machine learning automated text categorization acm computing surveys 

seymore mccallum rosenfeld learning hidden markov model structure information extraction 
aaai workshop machine learning information extraction 

paliouras annotating web pages needs web information extraction applications 
poster www budapest hungary may 
