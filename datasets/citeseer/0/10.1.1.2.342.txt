monte carlo localization efficient position estimation mobile robots dieter fox wolfram burgard frank dellaert sebastian thrun school computer science computer science department iii carnegie mellon university university bonn pittsburgh pa bonn germany presents new algorithm mobile robot localization called monte carlo localization mcl 
mcl version markov localization family probabilistic approaches applied great practical success 
previous approaches computationally cumbersome grid approaches represent state space high resolution grids resort extremely coarse grained resolutions 
approach computationally efficient retaining ability represent arbitrary distributions 
mcl applies sampling methods approximating probability distributions way places computation needed 
number samples adapted line invoking large sample sets necessary 
empirical results illustrate mcl yields improved accuracy requiring order magnitude computation compared previous approaches 
easier implement 
decade sensor localization recognized key problem mobile robotics cox borenstein everett feng 
localization version line temporal state estimation mobile robot seeks estimate position global coordinate frame 
localization problem comes flavors global localization position tracking 
second far studied problem robot knows initial position accommodate small errors odometry moves 
global localization problem involves robot told initial position solve difficult localization problem estimating position scratch referred hijacked robot problem engelson 
ability localize locally globally played important role collection mobile robot applications burgard endres kortenkamp bonasso murphy 
majority early focused tracking problem researchers developed highly successful family approaches capable solving localization problems markov localization nourbakhsh powers birchfield simmons koenig kaelbling cassandra kurien burgard :10.1.1.31.7646:10.1.1.31.7646
central idea markov localization represent robot belief probability distribution possible positions bayes rule convolution update belief robot senses moves 
idea probabilistic state estimation goes back kalman filters gelb smith self cheeseman multivariate gaussians represent robot belief 
restrictive nature gaussians basically represent hypothesis annotated uncertainty kalman filters usually applied position tracking 
markov localization employs discrete multi modal representations representing robot belief solve global localization problem 
real valued multi dimensional nature kinematic state spaces approaches approximate belief accurate approximation usually requires prohibitive amounts computation memory 
particular grid methods developed approximate kinematic state space finegrained piecewise constant functions burgard :10.1.1.31.7646:10.1.1.31.7646
reasonably sized environments approaches require memory excess mb highperformance computing 
extreme various researchers resorted coarse grained topological representations granularity order magnitude lower grid approach 
high resolution needed see fox uses localization avoid collisions static obstacles detected sensors approaches inapplicable 
monte carlo localization short mcl 
monte carlo methods introduced seventies rediscovered independently target tracking gordon salmond smith statistical kitagawa computer vision literature isard blake applied dynamic probabilistic networks kanazawa koller russell 
mcl uses fast sampling techniques represent robot belief 
robot moves senses impor tance re sampling rubin applied estimate posterior distribution 
adaptive sampling scheme koller determines number samples fly employed trade computation accuracy 
result mcl uses samples global localization needed sample set size small tracking position robot approximately known 
sampling representation mcl key advantages earlier field 
contrast existing kalman filtering techniques able represent multi modal distributions globally localize robot 

drastically reduces amount memory required compared grid markov localization integrate measurements considerably higher frequency 

accurate markov localization fixed cell size state represented samples discretized 

easier implement 
markov localization section briefly outlines basic markov localization algorithm approach 
key idea markov localization applied great success various sites nourbakhsh powers birchfield simmons koenig kaelbling cassandra kurien burgard fox compute probability distribution possible positions environment :10.1.1.31.7646:10.1.1.31.7646
hx denote position state space robot robot coordinates world centered cartesian frame robot orientation 
distribution bel expresses robot belief position initially bel reflects initial state knowledge robot knows initial position bel centered correct position robot know initial position bel uniformly distributed reflect global uncertainty robot 
robot operates bel incrementally refined 
markov localization applies different probabilistic models update bel action model incorporate movements robot bel perception model update belief sensory input robot motion modeled conditional probability kernel specifying probability measured movement action executed carries robot bel updated general formula commonly markov chains chung bel gamma bel dl term represents model robot kinematics probabilistic component accounts errors odometry 
burgard assume odometry errors distributed normally :10.1.1.31.7646
sensor readings integrated bayes rule 
denote sensor reading likelihood perceiving robot position bel updated rule bel gamma ff bel ff normalizer ensures bel integrates 
strictly speaking update steps applicable environment markovian past sensor readings conditionally independent readings true position robot 
extensions nonmarkovian environments fox easily stipulated mcl approach assume environment markovian pay attention issue 
prior existing approaches mobile robot localization distinguished way represent state space robot 
kalman filter techniques 
earlier approaches robot localization apply kalman filters kalman 
vast majority approaches assumption uncertainty robot position represented unimodal gaussian distribution 
sensor readings assumed map gaussian shaped distributions robot position 
assumptions kalman filters provide extremely efficient update rules shown optimal relative assumptions maybeck 
kalman filter techniques leonard durrant whyte schiele crowley gutmann schlegel proven robust accurate keeping track robot position 
techniques represent multi modal probability distributions frequently occur global localization 
practice localization approaches kalman filters typically require starting position robot known 
addition kalman filters rely sensor models generate estimates gaussian uncertainty unrealistic 
topological markov localization 
overcome limitations different approaches increasingly richer schemes represent uncertainty moving gaussian density assumption inherent vanilla kalman filter 
different methods roughly distinguished type discretization representation state space 
nourbakhsh powers birchfield simmons koenig kaelbling cassandra kurien markov localization landmark corridor navigation state space organized coarse topological structure environment 
coarse resolution state representation limits accuracy position estimates 
topological approaches typically give rough sense robot grid markov localization 
deal multimodal non gaussian densities fine resolution opposed coarser discretization methods grid approaches perform numerical integration evenly spaced grid points burgard fox :10.1.1.31.7646
involves discretizing interesting part state space basis approximation state space density piece wise constant function 
grid methods powerful suffer excessive computational overhead priori commitment size resolution state space 
addition resolution precision represent state fixed 
computational requirements effect accuracy measurements processed real time valuable information state discarded 
burgard begun address problems oct trees obtain variable resolution representation state space 
advantage concentrating computation memory usage needed addresses limitations arising fixed resolutions 
monte carlo localization sample density approximation mcl version sampling importance re sampling sir rubin 
known alternatively bootstrap filter gordon salmond smith monte carlo filter kitagawa condensation algorithm isard blake survival fittest algorithm kanazawa koller russell 
methods generically known particle filters discussion properties doucet 
key idea underlying represent posterior belief bel set weighted random samples particles fs ng 
sample set constitutes discrete approximation probability distribution 
samples mcl type hhx pi hx denote robot position numerical weighting factor analogous discrete probability 
consistency assume pn 
analogy general markov localization approach outlined previous section mcl proceeds phases robot motion 
robot moves mcl generates new samples approximate robot position motion command 
sample generated randomly drawing sample previously computed sample set likelihood determined values 
denote position sample 
new sample generated generating single random sample action observed 
value new sample gamma meters start location fig 
sampling approximation position belief non sensing robot 
shows effect sampling technique starting initial known position bottom center executing actions indicated solid line 
seen sample sets approximate distributions increasing uncertainty representing gradual loss position information due slippage drift 
sensor readings incorporated re weighting sample set way implements bayes rule markov localization 
specifically hl pi sample 
gamma ff sensor measurement ff normalization constant enforces pn 
incorporation sensor readings typically performed phases multiplied various values normalized 
algorithm perform re sampling process efficiently time carpenter clifford 
practice useful add small number uniformly distributed random samples estimation step 
formally legitimate sir methodology rubin accommodate arbitrary distributions sampling long samples weighted appropriately factor long distribution samples generated non zero places distribution approximated nonzero case mcl 
added samples essential rare event robot loses track position 
mcl uses finite sample sets may happen sample generated close correct robot position 
cases mcl unable re localize robot 
adding small number random samples mcl effectively re localize robot documented experimental results section 
robot position robot position robot position fig 
global localization initialization 
fig 
ambiguity due symmetry 
fig 
successful localization 
properties mcl nice property mcl algorithm universally approximate arbitrary probability distributions 
shown tanner variance importance sampler converges zero rate conditions true mcl 
sample set size naturally trades accuracy computational load 
true advantage lies way mcl places computational resources 
sampling proportion likelihood mcl focuses computational resources regions high likelihood things really matter 
mcl online algorithm 
lends nicely time implementation dean boddy zilberstein russell 
time algorithms generate answer time quality solution increases time 
sampling step mcl terminated time 
sensor reading arrives action executed sampling terminated resulting sample set operation 
adaptive sample set sizes practice number samples required achieve certain level accuracy varies drastically 
global localization robot completely ignorant belief uniformly covers full dimensional state space 
position tracking hand uncertainty typically small focused manifolds 
samples needed global localization approximate true density high accuracy needed position tracking 
mcl determines sample set size fly 
koller idea divergence belief sensing determine sample sets 
specifically motion data sensor data incorporated single step sampling stopped sum weights normalization 
exceeds threshold position predicted odometry tune sensor reading individual large sample set remains small 
sensor reading carries lot surprise typically case robot globally uncertain lost track position individual values small sample set large 
approach directly relates known property variance importance sampler function mismatch sampling distribution case distribution approximated weighted sample case tanner 
distributions agree larger variance approximation error 
idea compensate error larger sample set sizes obtain approximately uniform error 
graphical example figures illustrate mcl practice 
shown series sample sets projected generated global localization robot rhino operates office building 
robot globally uncertain samples spread uniformly free space 
shows sample set approximately meter robot motion point mcl disambiguated robot position single symmetry 
meters robot motion ambiguity resolved robot knows majority samples centered tightly correct position shown 
experimental results evaluate utility sampling localization thoroughly tested mcl range real world environments applying different types sensors cameras sonar laser proximity data 
primary results 
mcl yields significantly accurate localization results accurate previous markov localization algorithm consuming order magnitude memory computational resources 
cases mcl reliably localizes robot previous methods fail 

large adaptive sampling performs equally mcl fixed sample sets 
scenarios involving large range different uncertainties global vs local adaptive sampling superior fixed sample sizes 
experiments carried pioneer robots manufactured isr rwi shown 
robots equipped arrays sonar fig 
robots testing rhino minerva robin marian 
sensors laser range finders case minerva shown camera pointed ceiling 
experimental results discussed pre recorded data sets facilitate analysis evaluations performed strictly run time conditions explicitly noted 
fact routinely ran cooperative teams mobile robots mcl localization fox 
comparison grid localization series experiments characterizes different capabilities mcl compares grid markov localization presumably accurate markov localization technique date burgard fox :10.1.1.31.7646
cell size cm sonar laser number samples sonar laser fig 
accuracy grid markov localization different spatial resolutions mcl different numbers samples log scale 
plots localization accuracy grid localization function grid resolution 
results obtained data recorded environment shown 
nicely suited experiments exact data compare different localization approaches including grid markov localization solved global localization problem gutmann 
notice results grid localization shown generated real time 
shown accuracy increases resolution grid sonar solid line laser data dashed line 
grid sizes cm permit updating real time highly efficient selective update schemes fox burgard thrun 
results mcl fixed sample set sizes shown 
results generated realtime conditions 
small sample sets disadvantageous infer large error approximation 
large sample sets disadvantageous processing requires time fewer sensor items processed real time 
optimal sample set size samples 
grid localization reach level accuracy grids cm resolution infeasible best computers 
comparison grid approach resolution cm requires exactly times memory compared mcl samples 
global localization integrating single sensor scan requires seconds grid approach mcl consumes consistently seconds equal conditions 
robot localized globally grid localization updates grid cells selectively described burgard fox approaches equally fast 
vision localization test mcl extreme situations evaluated populated public place 
week exhibition robot minerva employed tour guide smithsonian museum natural history thrun 
aid localization minerva equipped camera pointed ceiling 
shows mosaic museum ceiling constructed method described thrun 
data difficult data set possession robot traveled speeds cm sec 
entered left area center museum crossed cm bump introduced significant errors robot odometry 
shows path measured minerva odometry 
vision information grid localization fails track robot accurately 
computational overhead impossible incorporate sufficiently images 
mcl succeeded globally localizing robot tracking robot position see dellaert :10.1.1.18.8488
shows path estimated mcl technique 
localization error meter system able keep track multiple hypotheses recover localization errors 
grid markov localization system able track long path trajectory 
experiments carried real time conditions grid technique quickly lost track robot position verified case grid approach unlimited computational power 
results document mcl clearly superior previous grid approach 
fig 
ceiling map fig 
odometry information recorded minerva long trajectory fig 
trajectory estimated ceiling map center pixels line images 
adaptive sampling evaluated utility mcl adaptive approach sampling 
particular interested determining relative merit adaptive sampling scheme fixed static sample set experiments earlier version mcl dellaert 
final series experiments applied mcl adaptive fixed sample set sizes data recorded minerva smithsonian museum 
laser range data vision data illustrate mcl works laser range data environments challenging studied 
time lost number samples fixed sample size variable sample size fig 
localization error mcl fixed sample set sizes top adaptive sampling bottom line set experiments tested ability mcl track robot moved museum 
case turned adaptive sampling significant impact tracking ability monte carlo localization 
result surprising tracking position robot concentrated small area 
evaluated influence adapting sample size ability globally localize robot recover extreme localization failure 
manually introduced severe errors data test robustness mcl extreme 
experiments tele ported robot random points time locations 
technically done changing robot orientation sigma degrees shifting sigma cm letting robot know 
perturbations introduced randomly probability meter robot motion 
obviously incidents robot lose position suited test localization extreme situations 
adaptive sampling superior mcl fixed sample sets 
shows comparison 
top curve depicts frequency error larger meter tolerance threshold different sample set sizes 
bottom line gives result adaptive sampling approach 
easy seen adaptive sampling yields smaller error best mcl fixed sample set sizes 
results obtained averaging data collected meters high speed robot motion 
monte carlo localization mcl sample algorithm mobile robot localization 
mcl differs previous approaches uses randomized samples particles represent robot belief 
leads variety advantages previous approaches significant reduction computation memory consumption leads higher frequency robot incorporate sensor data turn implies higher accuracy 
mcl easier implement previous markov localization approaches 
having reason entire probability distributions mcl randomly guesses possible positions way favors positions ones 
adaptive sampling scheme proposed enables mcl adjust number samples proportion amount surprise sensor data 
consequently mcl uses samples tracking robot position increases sample set size robot loses track position forced globally localize robot 
mcl tested thoroughly practice 
empirical results suggest mcl beats previous markov localization methods order magnitude memory computation requirements yielding significantly accurate results 
cases mcl succeeds markov localization fails 
increased efficiency localization applied multi robot scenarios sample sets different robots synchronized robot detects 
experiments conducted robots show robots able localize faster combining sample sets fox 
robots equipped laser range finders cameras detect 
plan apply monte carlo methods problem map acquisition led new statistical frameworks applied large cyclic environments grid representations thrun fox burgard 
acknowledgment research sponsored part nsf darpa contract number rome labs contract number ec contract number ct tmr programme 
borenstein everett feng 
navigating mobile robots systems techniques 
peters 
burgard fox schmidt 
estimating absolute position mobile robot position probability grids 
proc 
aaai 
burgard cremers fox lakemeyer schulz steiner thrun 
interactive museum tour guide robot 
proc 
aaai 
burgard fox cremers 
integrating global position estimation position tracking mobile robots dynamic markov localization approach 
proc 
iros 
carpenter clifford 
improved particle filter non linear problems 
tr dept statistics univ oxford 
chung 
markov chains stationary transition probabilities 
springer 
cox 
experiment guidance navigation autonomous robot vehicle 
ieee transactions robotics automation 
dean boddy 
analysis time dependent planning 
proc 
aaai 
dellaert burgard fox thrun 
condensation algorithm robust vision mobile robot localization 
proc 
cvpr 
dellaert fox burgard thrun 
monte carlo localization mobile robots 
proc 
icra 
doucet 
sequential simulation methods bayesian filtering 
tr cued infeng tr dept engineering univ cambridge 
endres 
field test navigation system autonomous cleaning supermarkets 
proc 
icra 
engelson 
passive map learning visual place recognition 
ph diss dept computer science yale university 
fox burgard thrun cremers 
position estimation mobile robots dynamic environments 
proc 
aaai 
fox burgard kruppa thrun 
monte carlo algorithm multi robot localization 
tr cmu cs carnegie mellon university 
fox burgard thrun 
active markov localization mobile robots 
robotics autonomous systems 
fox 
markov localization probabilistic framework mobile robot localization 
ph diss university bonn germany 
gelb 
applied optimal estimation 
mit press 
gordon salmond smith 
novel approach nonlinear non gaussian bayesian state estimation 
iee procedings 
gutmann schlegel 
amos comparison scan matching approaches self indoor environments 
proc 
euromicro 
ieee computer society press 
gutmann burgard fox konolige 
experimental comparison localization methods 
proc 
iros 

monte carlo techniques prediction filtering non linear stochastic processes 
automatica 
isard blake 
condensation conditional density propagation visual tracking 
international journal computer vision 
kaelbling cassandra kurien 
acting uncertainty discrete bayesian models mobile robot navigation 
proc 
iros 
kalman 
new approach linear filtering prediction problems 
asme journal basic engineering 
kanazawa koller russell 
stochastic simulation algorithms dynamic probabilistic networks 
proc 
uai 
kitagawa 
monte carlo filter smoother nongaussian nonlinear state space models 
journal computational graphical statistics 
koller 
learning approximation stochastic processes 
proc 
icml 
kortenkamp bonasso murphy eds 

mobile robots case studies successful robot systems 
mit press 
leonard durrant whyte 
directed sonar sensing mobile robot navigation 
kluwer academic 
maybeck 
stochastic models estimation control vol 

academic press 
nourbakhsh powers birchfield 
office navigating robot 
ai magazine 
rubin 
sir algorithm simulate posterior distributions 
bayesian statistics 
oxford university press 
schiele crowley 
comparison position estimation techniques occupancy grids 
proc 
icra 
simmons koenig 
probabilistic robot navigation partially observable environments 
proc 
icml 
smith self cheeseman 
estimating uncertain spatial relationships robotics 
cox wilfong eds autonomous robot vehicles 
springer 
tanner 
tools statistical inference 
springer 
thrun burgard cremers dellaert fox rosenberg roy schulte schulz 
minerva second generation mobile robot 
proc 
icra 
thrun fox burgard 
probabilistic approach concurrent mapping localization mobile robots 
machine learning 
zilberstein russell 
approximate reasoning anytime algorithms 
imprecise approximate computation 
kluwer 
