resource management rapid application turnaround enterprise desktop grids derrick kondo andrew chien henri casanova dept computer science engineering san diego supercomputer center university california san diego desktop grids popular platforms high throughput applications due inherent resource volatility difficult exploit applications require rapid turnaround 
efficient desktop grid execution short lived applications attractive proposition claim achievable intelligent resource selection 
propose general techniques resource selection resource prioritization resource exclusion task duplication 
techniques instantiate scheduling heuristics 
evaluate heuristics trace driven simulations representative desktop grid configurations 
find ranking desktop resources clock rates account availability history surprisingly effective practice 
main result heuristic uses appropriate combination resource prioritization resource exclusion task replication achieves performance factor optimal 
cycle stealing systems harness idle cycles desktop pcs workstations date back parc worm shown widespread success popular projects seti home gimps folding home computing cancer sustaining throughput cpu seconds 
successes inspired similar efforts enterprise way maximize return investment desktop resources har material supported national science foundation aci 
sc pittsburgh pennsylvania ieee cycles service large computations 
result numerous academic projects explored developing global computing infrastructure internet local area networks 
addition commercial products emerged 
term computing infrastructures desktop grids systems variety environments focus enterprise setting institution 
challenge efficient utilization desktop grids compute intensive applications resource management 
resource management application scheduling issues thoroughly studied areas parallel grid computing considers resource failures rare events 
contrast desktop grid resources inherently volatile 
due lack resource management application scheduling techniques account resource volatility traditional desktop grids focused applications consist large numbers orders magnitude larger number available resources independent tasks 
performance metric scenario asymptotic task completion rate number tasks completed time unit application execution steady state 
consider parallel applications consist independent nearly identical tasks vary size study applications numbers tasks relatively small comparable number available resources 
numerous interactions industrial companies authors suggest desktop grids enterprise underutilized 
applications workload require relatively rapid turnaround example day time 
result applications consist moderate number individual tasks scenario number resources order magnitude comparable number tasks uncommon 
asymptotic rate application execution time appropriate performance metric 
corresponds different usage desktop grids users wish execute relatively small short lived applications quickly achieve high throughput long period time 
note focuses minimizing execution elapsed time makespan single parallel application trying optimize performance multiple competing jobs 
design called job scheduling strategies promote average job performance fairness jobs belong different users part larger goal context desktop grids outside scope solely focus application scheduling strategies 
note heuristics develop schedule single application provide key elements designing effective job scheduling strategies doing appropriate space sharing jobs selecting resources job deciding task duplication level job 
minimizing makespan parallel application objective numerous research projects parallel computing address specific challenges posed resource selection volatile resources 
particular design various resource selection heuristics support rapid application turnaround 
evaluate heuristics simulations traces real desktop grid running entropia commercial software san diego supercomputer center sdsc 
evaluate heuristics representative desktop grid configurations 
specifically transforming entropia desktop traces model homogeneous cluster multi cluster grid typical internet wide desktop grid 
measure performance heuristics compare resulting makespans optimal compute omniscient scheduler full knowledge traces 
heuristics scheduling techniques resource prioritization resource exclusion task replication 
find simple prioritization techniques perform poorly desktop grid configurations 
find exclusion fixed threshold works platforms distribution clock rates left heavy case sdsc internet wide desktop grids 
develop adaptive heuristic uses prediction application makespan exclude slow resources historical host availability information makespan prediction accurate average 
heuristic makespan prediction usually outperforms sim ple resource exclusion techniques multi cluster homogeneous grids 
modify heuristic replication techniques performance best resulting method factor away optimal schedule significantly better serve fcfs default scheduling strategy current desktop grid systems 
remainder organized follows 
section define scheduling problem outline approach 
section describe experimental methods particular simulation model source trace data performance metrics 
section evaluate resource prioritization heuristics 
section develop heuristics filter resources different criteria 
section augment resource exclusion heuristics replication 
sections discuss related summarize contributions give research directions 
scheduling short lived applications desktop grids problem definition consider problem scheduling application consists independent identical tasks desktop grid 
desktop grid comprises hosts execute application tasks 
hosts individually owned running application tasks cpu owners 
host cpu availability assumed dynamic 
hosts managed master call server way 
server holds input data necessary application tasks 
host available executing application task sends notification server 
server maintains queue available hosts ready queue may choose send task time 
host executing application task cpu unavailable owner uses mouse keyboard owner starts cpu intensive application task suspended resumed host time 
host executing application unavailable due shutdown application task fails restarted scratch host 
consider checkpointing 
application task running host host sends heart beat server minute worst case takes minute server determines task terminated 
assumptions representative real world desktop grid infrastructures xtremweb entropia platform model consider problem scheduling tasks hosts time scheduling tasks completion task application makespan minimized 
case scheduling problem equivalent maximizing steady state performance application number tasks completed time unit steady state start wind phases application executions negligible versus steady state phase 
situation simple come server fcfs strategy application tasks assigned hosts greedy fashion close optimal 
fact strategy existing desktop grid systems 
cumulative number tasks completed tasks tasks tasks time minutes cumulative task completion vs time 
focus short lived applications mean order magnitude case fcfs clearly suboptimal seen 
plots cumulative number completed tasks cumulative throughput time observed fcfs strategy 
results obtained task execute minutes dedicated ghz processor hosts platforms modeled real world desktop grid see section detailed description simulation methodology 
curves initial hump system reaches steady state throughput increases roughly linearly 
cumulative throughput reaches plateau accounts increasingly large fraction application makespan decreases 
ap plication tasks completed minutes application finish minutes passed identical makespan case 
plateau partly due task failures near execution forces tasks restarted new host late computation 
cause plateau known syndrome waiting slowest hosts complete tasks 
see gets large compared plateau significant justifying fcfs strategy 
smaller values clear method resource selection improve performance short lived applications significantly 
section outline different resource selection approaches evaluate contrast rest 
proposed approaches consider general resource selection approaches resource prioritization way resource selection sort hosts ready queue criteria clock rate number cycles delivered past assign tasks best hosts 
prioritization effect number tasks left execute greater number hosts ready queue 
fewer tasks execute ready hosts typically application execution prioritization simple way avoiding picking bad hosts 
resource exclusion fixed threshold simple way select resources excluded hosts run application tasks 
filtering simple criterion hosts clock rates threshold 
distribution resource clock rates skewed slowest hosts significantly impede application completion excluding potentially remove bottleneck 
resource exclusion makespan prediction sophisticated resource exclusion strategy consists removing hosts complete task assigned expected application completion time 
words may possible obtain estimate application reasonably complete host push application execution estimate 
advantage method compared blindly excluding resources fixed threshold sensitive distribution clock rates 
task replication task failures near application unpredictably slow hosts cause major de lays application execution 
problem remedied means replicating tasks multiple hosts reduce probability task failure schedule application faster host 
method drawback wasting cpu cycles problem desktop grid application 
propose instantiations approaches compare simulation 
section detail simulation methodology 
experimental methodology simulation studying resource selection desktop grids direct experimentation allow controlled repeatable experiments 
approach simulations driven traces collected real desktop grid platform 
traces time series cpu availability measurements including failure data obtained month time period host desktop grid running entropia software infrastructure 
traces simulate desktop grid representative grid configurations different host clock rate probability distributions 
simulations implement platform model described section 
simulate execution task parallel applications different numbers tasks different task durations 
simulated execution compute makespan achieved different resource selection heuristics 
performance metric makespan relative optimal makespan 
provide relevant details sections 
availability traces conducted availability measurements month period deployment entropia dc grid san diego supercomputer center sdsc hosts 
continuously submitted short tasks entropia system queue empty host sent task soon available 
note tasks managed entropia virtual machine interfere resource owners fact unaware measurement activities 
compute bound task performed mix floating point integer operations periodically seconds logged computation rates file 
dedicated ghz pentium processor perform operations second 
note entropia virtual machine possible task fraction resource cpu 
procedure able measure kinds availability host availability binary value indicates host reachable desktop grid software corresponds definition availability ii cpu availability percentage value quantifies fraction cpu exploited desktop grid application corresponds definition :10.1.1.22.4887
host unavailable shutdown new task started currently executing task fails 
cpu unavailable cpu availability host available local processes cpu keyboard mouse activity resource owner running task suspended resumed cpu available 
host unavailability implies cpu unavailability 
call interval time host failures availability interval 
active non intrusive measurement methodology possible observe cpu availability just experienced compute intensive desktop grid application 
result method provides detailed information just measuring host availability :10.1.1.22.4887
traces susceptible os idiosyncrasies directly measure effect task failures caused mouse keyboard activity example 
contrast lightweight cpu availability load sensing techniques vulnerable artifacts os inferring task failures traces obtained passive sensors difficult 
number interesting features data reported availability traces solely drive simulations 
note traces revealed overhead incurred entropia system initiating task host order seconds take account simulations 
simulated platform implemented platform model described section hosts availability traces described previous section 
simulations performed traces captured business hours am pm 
shown number studies hosts weekdays business hours exhibit higher user load turn results challenging scheduling problem :10.1.1.22.4887
diversity desktop configurations com pare performance heuristics configurations representative internet single cluster multi cluster desktop grids 
internet desktop grids utilize machines enterprise home settings usually slow hosts fast hosts host speed distribution left heavy 
host cpu statistics collected gimps internet wide project determine distribution clock rates ranged mhz ghz 
projects folding home home show similar distributions 
cumulative percent sdsc lri wisc gimps log clock rate mhz cumulative clock rate distributions real systems simulations 
smaller projects desktop grids limited machines student lab example distribution cpu speeds relatively homogeneous 
model scenario log clock rates machines sdsc yielded narrow normal distribution mean speed ghz standard deviation mhz 
desktop grids focused resources multiple labs 
reports xtremweb student lab lri ghz machines condor cluster wisc mhz machines mhz machines 
configuration specified model multi cluster scenario 
plot cumulative clock rate distribution functions platform scenarios 
distributions ran simulations traces described section transforming host clock speeds accordingly 
simulated applications simulated applications varied number size tasks 
applications tasks roughly half twice number hosts desktop grid respectively reasons discussed section 
experimented tasks exhibit minutes execution time dedicated ghz host 
task sizes corresponding failure rate scheduled set resources business hours 
previously determined failure rate task size random incidence entire trace period 
collected traces chose thousands random points start execution task noted task run completion meet host failure 
task failure rate increases linearly task size minimum minute task maximum minute task 
maximum task size minutes chosen significant number applications complete scheduled business hours single weekday 
experiment particular number tasks task size simulated competing scheduling strategies applications starting different times business hours 
ran experiment starting times obtain statistically significant results true desktop grid fashion xtremweb platform run simulations 
performance metrics application makespan metric compare results achieved different scheduling heuristics wish compare execution time achieved oracle full knowledge host availabilities 
oracle works follows 
determines time host complete task looking availability traces scheduling task soon host available 
selects host completes task repeats process tasks completed 
greedy algorithm results optimal schedule easy see intuitively prove formally 
compare performance heuristics ratio makespan particular heuristic optimal makespan achieved oracle 
resource prioritization examine methods resource prioritization different levels information hosts virtually information historical statistics derived traces host evaluate method sdsc grid trace driven simulation 
pri cr method hosts server ready queue prioritized clock rates 
similarly pri cr pri cr wait sorts hosts clock rates scheduler waits fixed period minutes assigning tasks hosts 
rationale collecting pool ready hosts making task assignments improve host selection 
scheduler stops waiting ratio ready hosts tasks threshold 
threshold ratio experiments 
experimented values fixed waiting period ratio obtained similar results 
method pri history uses history host past performance predict performance 
specifically host scheduler calculates expected operations availability interval operations executed host failures previous weekday trace 
value determine priority queues host placed follows 
expected number operations intervals greater equal number operations application task host placed higher priority queues 
request put low priority queue 
queue hosts prioritized expected operations interval divided expected operations second 
way hosts queue prioritized speed 
shows average makespan algorithms fcfs strategy normalized mean optimal execution time labeled optimal applications tasks 
recall averages obtained distinct experiments 
general trend larger number tasks application closer achieved makespans optimal expected larger number tasks resource selection critical performance greedy method approaches optimal 
see pri cr considerably better performance fcfs applications tasks 
number tasks number available hosts slowest hosts guaranteed excluded computation fcfs slow hosts 
pri cr wait performs poorly small minutes tasks improves surpasses pri cr 
initial waiting period minutes costly task min application takes minutes complete optimal case 
task size increases application execution time penalty incurred waiting client requests lessened hosts request queue application submitted pri cr wait performs identically pri cr better 
provides additional insights pri cr wait largely 
shows number available hosts number tasks scheduled time typical execution 
initially hosts available tasks immediately drops hosts tasks available host gets assigned task 
see usually case far tasks schedule ready hosts far ready hosts tasks schedule 
scenario pri cr wait performs exactly pri cr 
case waiting give algorithm choice selecting resources 
average makespan relative optimal number tasks application optimal fcfs excl pred pri cr excl pred dup pri history excl pred pri cr wait task length minutes dedicated ghz host performance resource prioritization heuristics sdsc grid 
unexpectedly pri history achieves poor performance 
availability interval size terms time terms operations stationary weekdays 
determined error day follows 
host calculated mean number operations interval weekday business hours 
took absolute value difference host mean particular day 
took mean hosts pairs days average prediction error previous day predictor minutes dedicated ghz host 
host speed chosen arbitrarily give human readable number number operations 
process done predicting availability intervals terms time day average error minutes 
tasks experiments hours length prediction errors show expected value operations interval time interval poor predictor supported findings 
summary see pri cr outperforms fcfs consistently resource prioritization leads performance far optimal factor minute tasks 
looking schedules detail noticed slowest hosts significantly limited performance address issue heuristics described section 
number tasks scheduled number tasks number ready hosts time minutes number tasks scheduled left axis hosts available right axis 
resource exclusion prevent slower hosts delaying application completion developed heuristics excluded hosts computation variety criteria 
heuristics host clock rates obtain lower bounds task completion time seen past availability predictor availability 
number ready hosts excluding resources clock rate group heuristics excludes hosts clock rates lower mean clock rate hosts ghz sdsc platform minus factor standard deviation clock rates mhz sdsc platform 
heuristics excl excl excl excl exclude hosts standard deviations mean clock rate 
see excluding hosts standard deviations mean bring substantial benefits relative fcfs pri cr 
usually excl excludes hosts removes slow hosts excludes useful ones exception application tasks equal roughly half number hosts excluding hosts speeds mean leave slightly half hosts filtering case hurt performance 
excl excludes hosts remaining slow hosts hurt application makespan 
average makespan relative optimal number tasks application optimal fcfs pri cr excl excl excl excl task length minutes dedicated ghz host performance heuristics thresholds sdsc grid sdsc platform excl particular threshold yields best performance average excl performs better pri cr applications tasks respectively 
may useful hosts excluded threshold appropriate different clock rate distributions hosts desktop grid 
section propose strate gies sophisticated makespan prediction way filter hosts evaluate compare excl different desktop grid configurations 
makespan predictions avoid pitfalls fixed threshold particular clock rate standard deviation mean case pri develop heuristic scheduler prediction application makespan excludes resources complete task projected completion time 
predict makespan compute average operations completed second host traces compute average hosts call average 
number hosts desktop grid assume hosts speed number tasks size task operations optimal execution time entire application estimated wr 
rationale prediction method optimal schedule encounter task failures 
host unavailability cpu speed main factors influencing application execution time factors accounted addition account granularity tasks completed 
assess quality predictor wr compared optimal execution time predicted time tasks minutes size applications tasks 
average error experiments maximum 
satisfactory accuracy prediction explained fact total computation power grid remains relatively constant individual resources may unpredictable availability intervals discussed previously section 
show computed number operations delivered weekday business hours minute increments aggregated hosts 
coefficient variation operations available minute interval 
relatively low variation aggregate computational power accurate predictions wr possible 
heuristic excl pred uses makespan prediction adaptively changes prediction application execution progresses 
particular heuristic starts makespan computed wr tasks completed recomputes projected makespan 
choose recompute prediction tasks completed reasons 
extreme static prediction computed prone errors due resource availability variations 
extreme recomputing prediction second beneficial create moving target slide prediction back factor tasks completed 
application near completion predicted completion time early risk hosts get excluded 
tasks remaining time pred pred predicted application completion time mean clock rate hosts excl pred heuristic reverts pri cr time 
ensures excl pred switches pri cr clear hosts complete task predicted completion time 
note heuristic waited time pred versus pred switching pri cr result poor resource utilization seen early simulations hosts available excluded time pred 
waiting time pred making task assignments pri cr cause hosts sit needlessly idle 
evaluation different desktop grids average makespan relative optimal number tasks application optimal fcfs excl excl pred task length minutes dedicated ghz host heuristic performance sdsc grid shows excl pred usually performs excl machines sdsc clear advantage excl pred 
particular distribution clock rates sdsc desktop grid excl appears particular threshold yields best performance 
excl pred performs poorly excl application minute tasks 
close inspection traces handful unpredictably slow hosts finish execution past projected makespan task failures slow hosts occurring near application 
application tasks delay hidden tasks keep hosts busy slow hosts finish task execution 
application tasks unpredictably slow unstable hosts get filtered automatically fewer tasks hosts heuristic prioritizes resources clock rate 
reasoning explain excl outperforms excl pred gimps desktop grid see sdsc grid left heavy distribution resource clock rates 
gimps resources applications scheduled fcfs invariably finish weekday business hours period application completion times greater hours extremely slow resources average makespan relative optimal number tasks application optimal lower bound fcfs excl excl pred task length minutes dedicated ghz host heuristic performance gimps grid excl performs best sdsc gimps desktop grids threshold excl inadequate different desktop grid platforms filtering criteria adaptiveness excl pred advantageous scenarios 
particular excl pred performs outperforms excl multi cluster case homogeneous cluster 
excl pred outperforms excl case lri log distributions respectively application tasks see figures 
excl lri desktop grid excludes mhz hosts contribute significantly platform computing power 
relatively homogeneous desktop grid excl unnecessarily filters total computing power fact resources running speeds close mean significantly delay application completion 
hosts excluded excl relatively slow absolute speeds close faster hosts contribute significantly progress application execution 
general longer steady state phase application better excl pred performs respect excl excl excludes useful resources utilized excl pred 
explains excl pred performs better excl applications tasks larger task sizes seen figures 
average makespan relative optimal number tasks application optimal fcfs excl excl pred task length minutes dedicated ghz host heuristic performance lri wisc grid task replication approach reduce application completion delays caused failures loaded hosts extend excl pred task replication 
method call excl pred dup uses excl pred replicates task number ready hosts greater number tasks schedule 
replicating anytime sooner cause host redundant unscheduled tasks hosts cause delay application completion 
refer original task replicated primary task average makespan relative optimal number tasks application optimal fcfs excl excl pred task length minutes dedicated ghz host heuristic performance homogeneous grid replicas called duplicates 
primary tasks scheduled duplicates reduces chance high number duplicates ahead queue prevent primary task scheduled 
duplicates sorted increasing order clock rate host primary task assigned replicas tasks originally assigned slower hosts scheduled earlier 
addition failures near application execution delays caused hosts run unexpectedly slow excl pred filters resources clock rate heuristic susceptible slow hosts 
hosts available completely unloaded cpu time justification clock rate predictor execution time excl pred 
deal delays heuristic excl pred excl pred uses timeout task determine replication occur 
task scheduled timeout occurs task completed predicted makespan 
timeout task replicated primary duplicate tasks prioritized similarly excl pred dup 
shows runtime improvement due excl pred dramatic smaller applications execution time spent near unpredictably slow hosts complete tasks failed tasks successfully finished 
shown simulation logs timeouts effectively reschedule tasks assigned unpredictably slow un stable hosts 
excl pred better excl cases application minute tasks particular application size excl pred equally 
excl pred usually performs similarly excl replicating tasks application effectively deal unstable hosts began execution earlier 
excl pred dup shows little improvement excl pred failures occur near application due relatively slow hosts began task execution point ready hosts tasks 
excl pred dup replication late application lifespan 
contrast excl pred dup excl pred heuristic able deal failures addition unpredictably slow hosts means timeouts performs remarkably execution times factor respect optimal 
desktop configurations sdsc degree improvement heuristic similar 
average makespan relative optimal number tasks application optimal fcfs excl excl pred excl pred dup excl pred task length minutes dedicated ghz host heuristic performance replication sdsc grid surprisingly gain performance due replication excl pred comes little expense resource utilization 
improved performance obtained obtained relatively little replication 
bar labeled waste shows percent replicated tasks relative total including replicated tasks fail complete excl pred application size 
low amount replication required due fact relatively tasks uncompleted near application need replicated 
application number available hosts compared number tasks quite high chance selecting relatively fast host high 
compare performance excl pred dup excl pred excl pred dup uses number replicated tasks excl pred denoted excl pred dup 
example application consisting minute tasks excl pred replicates tasks corresponds waste 
modified excl pred dup replicate task fixed number times tasks replicated percentage waste equivalent excl pred 
corresponding bars shows level replication excl pred far effective reducing application makespan 
average makespan relative optimal number tasks application optimal excl pred excl pred dup waste task length minutes dedicated ghz host performance replication algorithm sdsc grid particular level replication heuristics evaluated excl pred performs closest optimal significantly negatively affecting resource utilization 
obtained confidence intervals application completion time excl pred scheduling applications size trace driven simulation empirical cdf determine confidence intervals application makespans 
example lower confidence intervals application tasks fraction tasks wasted minutes minute minute minute tasks respectively mean application completion times minutes 
confidence intervals user get reasonable estimate application complete 
related desktop systems exist schedulers promote rapid application turnaround geared high throughput applications 
xtremweb uses fcfs schedule tasks resources 
entropia scheduler maintains priority queues allows applications specify constraints resources cpu speed able support mechanisms describe previously 
method achieve rapid application turnaround unclear 
condor lack schedulers short lived jobs 
scheduling research done prediction host load resource selection 
discussed section studies take account task failures caused user reclaiming machine task execution significantly delay application completion 
example failure rate minute task business hours 
studies host load traces susceptible os idiosyncrasies 
batch resource management systems maui scheduler pbs assume relatively dedicated stable computing environment inadequate scheduling applications desktop grids lack extensive mechanisms deal task failures 
scheduling features normally available batch systems backfilling advance reservation mechanisms fairness supported desktop grids 
developed resource selection heuristics achieve performance short lived task parallel applications desktop grids 
heuristics techniques resource prioritization resource exclusion task replication evaluated trace driven simulation grid configurations 
simple prioritization resources usually ineffective utilizing hosts desktop grid prove detrimental application completion time 
consequently investigated methods excluding hosts fixed threshold adaptive threshold prediction application makespan 
fixed threshold excluded certain hosts beneficial desktop grids left heavy distribution clock rates adaptive makespan heuristic performs better configurations multicluster homogeneous desktop grids 
adapted makespan prediction heuristic replication means deal task failures unreliable hosts delayed application completion 
little waste caused replicated tasks new heuristic brings application completion factor optimal application sizes experiments 
surprisingly minimal information clock rates hosts heuristics able improve application makespan drastically 
internet enterprise desktop grids collect store clock rate information scheduling heuristics easily implemented integrated current systems 
plan implement heuristics xtremweb software 
evaluate heuristics system condor mosix enables checkpointing migration tasks 
checkpointing process migration methods deal host volatility investigate methods complement resource prioritization resource exclusion task replication 
design scheduling heuristics scenario multiple applications submitted time 
understanding heuristics affect execution single application results basis supporting multi application online workload consisting short lived high throughput applications 
addition application makespan metrics system performance fairness considered 
acknowledgments authors wish gilles invaluable assistance xtremweb system conduct simulation experiments 
acharya saltz 
utility exploiting idle workstations parallel computation 
proceedings acm rics international conference measurement modeling computer systems pages 
alexandrov schauser 
global web parallel computing infrastructure 
proc 
th ieee international parallel processing symposium ipps april 
arpaci dusseau vahdat liu anderson patterson 
interaction parallel sequential workloads network workstations 
proceedings rics pages may 
barak wheeler mosix distributed operating system load balancing unix volume lecture notes computer science 
springer verlag 
kedem wyckoff 
charlotte metacomputing web 
proc 
th international conference parallel distributed computing systems 
bestavros 
load profiling distributed real time systems 
th international conference distributed computer systems may 
bhagwan savage voelker 
understanding availability 
proceedings iptps 
bolosky douceur ely theimer 
feasibility serverless distributed file system deployed existing set desktop pcs 
proceedings sigmetrics 
london nisan regev 
popcorn project distributed computation internet java 
proc 
th international world wide web conference april 
compute cancer project 
www org 
christiansen schauser wu 
javelin internet parallel computing java 
proceedings sixth acm sigplan symposium principles practice parallel programming 
casanova berman 
heuristics scheduling parameter sweep applications grid environments 
proceedings th heterogeneous computing workshop hcw pages may 
chien calder bhatia 
entropia architecture performance enterprise desktop grid system 
journal parallel distributed computing 
chu levine 
availability locality measurements peer peer file systems 
proceedings scalability traffic control ip networks july 
dinda 
statistical properties host load 
scientific programming 
dinda 
prediction real time scheduling advisor 
proceedings international parallel distributed processing symposium ipdps april 
dinda 
online prediction running time tasks 
cluster computing july 
entropia www entropia com 
eri 
xtremweb generic global computing system 
proceedings ieee international symposium cluster computing grid cc grid may 
fight aids home project 
www 
org 
berkeley open infrastructure network computing 
berkeley edu 
james frey todd tannenbaum miron livny ian foster steven tuecke 
condor computation management agent multi institutional grids 
cluster computing 
petrou rodrigues vahdat anderson 
global layer unix network workstations 
software practice experience july 
great internet prime search gimps 
www mersenne org 

worm programs early experience distributed computation 
communications acm 
kondo casanova 
computing optimal makespan jobs identical independent tasks scheduled volatile hosts 
technical report cs dept computer science engineering university california san diego july 
kondo brooks casanova chien 
characterizing evaluating desktop grids empirical study 
proceedings international parallel distributed processing symposium ipdps april 
litzkow livny mutka 
condor hunter idle workstations 
proceedings th international conference distributed computing systems icdcs 
neri thain livny 
xtremweb condor sharing resources internet connected condor pool 
proceedings ieee international symposium cluster computing grid ccgrid workshop global computing personal devices may 
maui scheduler 
www 
org maui 
mutka livny 
available capacity privately owned workstation environment performance evaluation july 
schopf editors 
grid resource management chapter 
kluwer press 
andy oram editor 
peer peer harnessing power disruptive technologies 
reilly associates sebastopol ca usa 
portable batch system webpage 
www com 
silva silva 
web metacomputing jet 
proc 
acm ppopp workshop java science engineering computation june 
platform computing www 
platform com 
pruyne livny 
worldwide flock load sharing workstation clusters journal generations computer systems 

building studying web volunteer computing systems java 
generation computer systems 
saroiu gummadi gribble 
measurement study peer peer file sharing systems 
mmcn january 
seti home project 

ssl berkeley edu 
shirts pande 
screen savers world unite 
science 
casanova berman 
tunable line parallel tomography 
proceedings supercomputing denver colorado nov 
sullivan bowyer cobb anderson 
new major seti project project data personal computers 
proc 
fifth intl 
conf 

www 
com 
united devices www ud com 
vijay pande 
private communication 
wolski spring hayes 
predicting cpu availability time shared unix systems 
th ieee high performance distributed computing conference hpdc august 
wyckoff johnson jeong 
finding idle periods networks workstations 
technical report cs dept computer science new york university march 

