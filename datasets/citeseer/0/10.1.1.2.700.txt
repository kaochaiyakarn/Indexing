search engine crawler symbiosis adapting community interests gautam pant shannon bradshaw menczer department management sciences university iowa iowa city ia usa email gautam pant shannon bradshaw menczer uiowa edu 
web crawlers nearly decade search engine component create update large collections documents 
typically crawler rest search engine closely integrated 
purpose search engine large collection possible serve general web community close integration may necessary 
search engine caters specific community shared focused interests take advantage integration 
investigate tightly coupled system crawler search engine engage symbiotic relationship 
crawler feeds search engine search engine turn helps crawler better performance 
show symbiosis help system learn community interests serve community better focus 
general purpose search engines typically exhaustive crawlers build update large collections documents 
cost crawling indexing collections amortized millions queries received search engines 
large size dynamic nature diversity web warrant focused solutions allow direct indirect collaboration web searchers similar interests 
solutions may scalable distributable effective efficient 
may lead new ways searching hard imagine centralized exhaustive approach followed current search engines 
web communities focused interests professional casual settings 
example set software engineers workplace may focused interests 
surprising queries search engines day narrow topic 
fact small collection web pages say pages may satisfy needs short period time 
non trivial identify small focused collection larger web representative community current affiliation school informatics computer science department indiana university 
email fil indiana edu interests 
important tweak collection time remains focused current interests community 
collection community search engine indexes may able better serve community 
example owing small size collection search engine kept extremely fresh crawling daily weekly basis 
addition sophisticated information retrieval text mining visualization tools may applied efficient effective larger corpus 
system provide collaboration opportunities users 
purpose search engine large collection possible serve general web community close integration crawler components engine may necessary 
main goal crawler keep coverage freshness search engine index high task informed user interactions 
reason crawler rest search engine typically little communication 
search engines may crawlers focus crawl heuristics similar search engine rank documents 
closely integrate crawling algorithm search engine 
discuss particular web searching model topical focused crawler search engine engage mutually beneficial relationship order cater particular community users 
specifically goal incrementally refine collection broad set topics order focus collection set topics relevant community 
flexibility model allows adaptation drifting interests community 
symbiosis search engine crawler search engine crawler symbiotic system live large server desktop machine 
serving single user set users 
system tightly couples search engine crawler learn user queries search engine past 
learning process involving search engine crawler symbiosis prepare focused collection may better suited queries near 
process repeated daily weekly basis 
queries serve approximation interests set users 
sample queries representative requests 
representative queries capture focused set web documents answering queries near representative query learning opportunity 
topical crawler picks representative query time queries search engine 
search engine responds top hits urls satisfy query urls link top urls 
gives crawler seed set urls 
crawler crawls max pages starting seed set representative query guide note rest term search engine refer search engine components crawler 

max pages crawled query search engine indexes new pages retrieved 
crawler queries search engine representative query steps mentioned repeat 
search loop may continue max iter iterations convergence level threshold theta achieved seed sets consecutive iterations 
new pages iteration added new collection 
iterations repeated representative queries 
current index deleted new collection create new index 
new index search engine answer queries entire process repeats 
new collection foreach query representative queries repeat max iter intersect old seed set seed set theta old seed set seed set seed set search engine query hits new pages crawler query seed set max pages index new pages new collection add new collection new pages clear index index new collection fig 

pseudo code symbiotic process search engine crawler idea symbiotic process crawler exploit existing search engine index order obtain focused collection search engine may better satisfy user queries 
pseudo code illustrating symbiotic process shown 
parameters max pages max iter theta number representative queries fixed resource availability 
example system runs desktop single user may index pages 
hand system runs large server users may desirable index millions pages 
fix maximum number pages indexed max index max pages derived follows max pages max index representative queries representative queries number representative queries 
parameters max iter theta influenced available disk space lead temporary increase size index new collection ready 
number queries representative queries may amount time taken iterations single query 
may restrict total time taken representative queries say hours peak hours day 
process shown new collection indexed size equal max index 
maintain upper bound size index search engine answer user queries 
time time new collection search engine crawler queries queries new pages new collection search engine crawler new pages fig 

creation new index old way looking process temporal sequence 
pseudo code shown may repeated regular intervals create new collections cater queries 
shows index time process described create new index time 
scale time day week month need index freshness time available maximum size collection max index 
implementation currently search engine crawler symbiosis implemented search engine called rosetta naive best crawler 
search engine crawler built specifically application 
independent searching crawling tasks 
want demonstrate symbiotic model picking shelf search engine generic topical crawler 
rosetta architecture describe type indexing retrieval system matter particular approach crawling rosetta search engine particularly suited architecture 
rosetta indexing technique called directed indexing 
technique designed idea topic community web users interested topic find identify evolving body useful information way findings leveraged help informed find need 
rosetta uses hyperlinks contexts created basis indexing retrieving documents 
authors introduced variety ways link information search systems rosetta approach novel way uses combined evidence multiple document determine popularity document isolate words best identify popular queries relevant 
example consider www com web site software 
drawing program microsoft windows platform allows easily draw scratch import modify export images variety formats 
comparative analysis text immediate vicinity link www com yields terms frequently document drawing program windows export pdf eps 
web authors tool useful referenced homepage 
doing indicate simply draw useful useful specific set reasons identified terms listed 
different document tend emphasize features document 
result terms naturally overlap 
particular term document quite searchers term queries information document contains 
rosetta indexes document collection incrementally discovers documents pages gathered crawler 
technique voting mechanism uses terms immediate vicinity hyperlink document 
treats referring page voter permitted vote index term document 
continuing example lists top index terms extracted www com referring pages 
number votes indicates number pages term immediate vicinity link www com 
term votes draw drawing program format illustrations windows pdf eps 
rosetta uses number votes term measure term frequency weighting metric similar tfidf 
combined evidence multiple contexts document referred extremely accurate identifier index terms document better fact measures word document 
addition inherent model measure relative importance documents indexed terms 
number votes index term receives indicates relative value term association particular document number chosen direct readers document versus 
naive best crawler naive best crawler uses cosine similarity page query score urls page 
similarity measure simple term frequency common terms conflated standard stemming algorithm 
crawl frontier unvisited urls kept priority queue score 
time crawler needs fetch page picks best queue 
previous evaluation studies naive best crawler strong competitor algorithms short crawls pages general crawling tasks 
crawler number threads share single crawl frontier 
thread picks best url crawl frontier fetches corresponding page scores unvisited urls page adds urls frontier appropriate positions 
allow crawler spawn threads maximum size frontier set 
order avoid web server requests frontier enforces constraint batch urls fetched different server host names 
due multi threaded nature crawler enforced ethics crawler follow strict best order 
multiple threads crawler behave best crawler related number threads 
best crawler generalized version naive best crawler picks best urls crawl time :10.1.1.1.9512
best perform especially performance measured recall relevant pages 
evaluation want investigate search engine crawler symbiosis capturing community interests 
initial collection search engine may generated bookmark files users doing breadth crawl certain number pages max index retrieved 
community queries portion open directory project odp basis simulation 
particular business commerce category simulate community 
category levels deep hierarchy odp topics sufficiently broad enable simulation community people shared interests individual interests 
business commerce root category sub categories external urls 
assume fictitious community interests lie categories selected 
seed urls simulation selected urls random included categories 
dmoz org bootstrapping search engine real community urls acquired web browser bookmarks members community pool urls listed community resource page kind 
rest refer bookmark urls 
having selected bookmark urls collected pool queries represent individual inquiries community period week days 
odp editors include brief summary url listed category 
summaries derive phrases simulate user queries 
split summaries tokens set words delimiters keeping tokens words processing 
manually filtered tokens remove incoherent groups words representative type errors shallow parsing technique 
process left nearly queries 
queries obtained form query pool simulation follow 
associated query odp category derived 
knowledge available system provide understanding context query evaluation phase 
simulation simulated days search engine crawler system 
initial collection created day breadth crawl retrieved max index pages web starting bookmark urls 
simulate day usage randomly picked queries query pool 
simulated day ran symbiotic process described section queries create new index day 
simulation set max pages maximum pages query iteration parameter pages maximum number iterations max iter number top urls seeds iteration hits 
owing small max iter check convergence current simulation 
real world process may run peak hours overnight new index ready morning 
fact implemented system rosetta search engine naive best crawler takes hours complete process shifting old index new ghz pentium iii ibm thinkpad running windows operating system 
note current rosetta implementation parallelization optimizations ease implementation 
speed process optimization 
performance metrics purpose technology incrementally refine collection broad set topics order focus collection set topics relevant particular community 
test degree system meets objective measured relative performance progressed days simulation 
chose treat system black box measure performance search engine response queries days way user experiences merits system 
judge search engine results hundreds queries days time consuming task 
decided sample daily queries evaluation 
twelve test subjects evaluated queries randomly selected day sample queries evaluation 
test subjects graduate students class information technology awarded extra credit participating study 
asked subjects determine relevance top search results query context query originated 
mentioned earlier context query provided category odp query drawn 
subjects asked browse relevant category order acquire understanding meaning query 
step important real world user submits query search engine specific set circumstances motivated need information 
note search results query different days evaluation going different indexes 
maintained indexes existed days submitted queries sampled day day index 
avoid manual bias evaluation hid information indicated day query originated 
binary relevance assessments obtained subjects computed precision top hits returned search engine query 
average performance measure sample queries day plot mean performance time 
addition black box approach mentioned want evaluate quality collections created crawler 
quantify new collection ability satisfy queries follow 
note precision affected collection quality quality indexing ranking mechanism 
want isolate quality collection created crawler 
gives idea performance crawler 
way measure new collection quality calculating average cosine similarity pages collection representation centroid queries submitted corresponding day 
represent day queries simply concatenate 
note collection created queries submitted system see 
measure average cosine similarity collection queries follows vq vp vq vp collection pages particular day concatenated query text day vq vp tfidf vector representations concatenated queries page respectively vq vp inner product vectors euclidean norm vector results results study measure search engine performance days simulation metric defined section 
depicts values judged test subjects averaged queries day 
initial collection system retrieved approximately relevant documents top search results average 
day cost day fig 

days simulation ratio precision cost gathering maintaining collection day simulation 
error bars correspond standard error 
performance dropped slightly second third days simulation 
reason speculate initially system may overfit collection set queries day possibly day 
seen type behavior systems learn interests users :10.1.1.2.4769
evaluation suggests initial decline performance improves level greater initial collection 
statistical significance preliminary result allow definitive confirmation experiments required extensive evaluations queries longer period time 
significant terms result stronger may appear system achieves level collection third smaller collection day simulation 
size collection decreases approximately pages day approximately pages fifth day 
due crawler focused result interaction search engine 
specifically crawler explores regions web near search results query finds urls encountered crawls queries 
store url collection redundancy information gathered day results reduction size collection 
may negatively affect generalization performance initial phase symbiotic process affords day fig 

relevance collection queries submitted days performance queries occurred day 
significant efficiency gains terms saved disk space crawling indexing time bandwidth 
quantify gain look ratio average precision relative size collection cost 
cost collection equal size collection divided max index pages 
plot indicates perfomance cost perspective symbiotic system lead substantial benefits 
measured cosine similarity collection day queries day 
plots ratio day 
time crawler help search engine able fetch pages lexically similar queries day 
error bars plot extremely small clearly visible 
find significant improvement collection quality simulation period 
analysis queries appeared manually evaluated set queries 
plotted metric repeating queries days appeared 
noticed queries value improved time 
particular queries result time appeared subsequent occurrence system relevant results 
average system relevant results repeating queries time submitted system 
related large size dynamic nature web prompted different efforts build focused search engines :10.1.1.30.6847
attempt build focused search engine approach adaptive changing interests user 
furthermore tightly couples search engine crawler general applied topic 
referential text find web sites categorize pages crawl pages 
despite active referential text variety information retrieval tasks demonstrated effectiveness technique general purpose search 
large growing body topical focused crawlers :10.1.1.43.1111
crawlers variety lexical link cues web pages guide path 
relates collaborative filtering queries submitted users help preparing collection similar queries users 
purpose symbiotic system describe incrementally refine broad collection order bring focus set topics relevant particular community 
experimentation needed strong claims benefits users demonstrates short amount time type symbiotic system developed eliminate irrelevant information initial collection achieve desired focus 
important note system learns behavior users implicitly requiring effort type simple searches doing 
obvious extension integrate crawler engine 
example crawler best strategy tfidf similarity just tf 
generic crawler luxury idf index collection available 
model collection indexed engine previous iteration crawler current iteration generate idf weights improve link scores 
addition crawler tap global information available search engine hubs multiple contexts 
different note proposed symbiotic model distributed larger peer peer search system bring added opportunities identifying connecting communities users 
acknowledgments acknowledge contributions srinivasan kristian hammond rik belew related projects 
go students volunteered help evaluation 
funded part nsf career 
iis fm 

arasu cho garcia molina paepcke raghavan 
searching web 
acm transactions internet technology 

attardi gull sebastiani 
automatic web page categorization link context analysis 
proceedings thai st european symposium telematics hypermedia artificial intelligence 

shoham 
content collaborative recommendation 
communications acm 

bradshaw hammond 
automatically indexing documents content vs 
sixth international conference intelligent user interfaces san francisco ca january 

shannon bradshaw 
directed indexing indexing scientific literature context 
phd thesis northwestern university 

brin page 
anatomy large scale hypertextual web search engine 
computer networks 

chakrabarti dom raghavan rajagopalan gibson kleinberg 
automatic resource compilation analyzing hyperlink structure associated text 
computer networks 

chakrabarti van den berg dom 
focused crawling new approach topic specific web resource discovery 
computer networks 

craswell hawking robertson 
effective site finding link anchor information 
proc 
th annual intl 
acm sigir conf 
research development information retrieval 

giles bollacker lawrence 
citeseer automatic citation indexing system 
proceedings third acm conference digital libraries 

maarek pelleg ur 
shark search algorithm application tailored web site mapping 
www 

mccallum nigam rennie seymore 
automating construction internet portals machine learning 
information retrieval 

menczer belew 
adaptive retrieval agents internalizing local context scaling web 
machine learning 

menczer pant ruiz srinivasan 
evaluating topic driven web crawlers 
proc 
th annual intl 
acm sigir conf 
research development information retrieval 

menczer pant srinivasan 
topical web crawlers evaluating adaptive algorithms 
appear acm trans 
internet technologies 
dollar biz uiowa edu fil papers toit pdf 

menczer street monge jakobsson 
intellishopper proactive personal private shopping assistant 
proc 
st acm int 
joint conf 
autonomous agents multiagent systems aamas 

pant srinivasan menczer 
exploration versus exploitation topic driven crawlers 
www workshop web dynamics 

porter 
algorithm suffix stripping 
program 

salton mcgill 
modern information retrieval 
mcgraw hill 
