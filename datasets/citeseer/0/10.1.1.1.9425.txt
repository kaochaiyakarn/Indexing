case precision sharing krishnamurthy michael franklin joseph hellerstein garrett jacobson dept eecs uc berkeley sharing emerged key idea static adaptive stream query processing systems 
inherent systems tension sharing common avoiding unnecessary 
increased sharing generally led unnecessary 
approach precision sharing aims share aggressively unnecessary 
show adaptive tuple lineage generally applicable precisely shared static dataflows 
show static ordering constraints precision sharing adaptive systems 
report experimental study precision sharing 
data streaming systems support long running continuous queries 
queries concurrently active common streams shared processing attractive 
approaches shared stream processing emerged 
systems niagaracq aurora stream tuples flow static dataflow networks 
contrast idea adaptive query processing led approaches cacq psoup telegraphcq distributed eddies tuples routed adaptive network 
sharing streams classical systems sellis aims limit redundancy due accessing funded part nsf itr iis si iis iis ibm faculty partnership award program research funds intel microsoft uc micro program 
permission copy fee part material granted provided copies distributed direct commercial advantage vldb copyright notice title publication date appear notice copying permission large data base endowment 
copy republish requires fee special permission endowment 
proceedings th vldb conference toronto canada intel research berkeley franklin cs berkeley edu data multiple times different queries illustrate redundancy query example 
sharing queries redundancy waste example queries result sets overlap 
sharing overlapping tuples produced twice redundancy 
attempting avoid redundancy current shared schemes produce data 
shared scheme literature niagaracq produce tuples entire rectangle including useless tuples shaded regions 
appear sharing balance inherent tensions repeated caused applying operation multiple times tuple copies 
wasted caused production removal useless tuples 
existing systems taken tension granted goal show tension fact irreconcilable design implement techniques resolve tension static adaptive dataflows experimentally verify techniques 
precision sharing precision sharing way characterize shared query processing scheme 
show sharing precise possible avoid overheads repeated wasted 
precision sharing applies static adaptive streaming systems orthogonal query optimization 
traditional multiple query optimization schemes 
static shared dataflows show niagaracq static shared plans imprecise 
consider tuple lineage idea adaptive query processing literature 
lineage thought useful highly variable environments insight generally applicable 
specifically show tuple lineage static shared dataflows precise 
call approach tulip tuple lineage plans 
adaptive shared dataflows show cacq shared adaptive dataflow system imprecise 
strategy adaptive precision sharing borrow static world 
show place constraints tuples routed adaptive scheme ensure sharing precise 
approach car constrained adaptive routing 
implemented schemes tulip car telegraphcq system building berkeley 
contributions contributions 
argue tension avoiding overheads repeated wasteful sharing irreconcilable define precision sharing show overheads reduced tandem 

demonstrate general utility tuple lineage adaptive query processing show achieve static precision sharing 

show implement adaptive precision sharing proper operator routing 

validate claims experimentally 
rest organized follows 
briefly describe relevant shared stream processing section 
section define precision sharing explain pitfalls prior art 
followed description tulip section study performance section 
car section followed experiments section 
summary findings section 
shared queries streams section briefly describe major approaches sharing static query plans adaptive dataflows 
sharing studied multiple query optimization literature comparatively shared processing queries data streams related topic pipelined 
noted pipelined join operators natural fit streaming query processors 
reason assume exclusive symmetric join operators rest 
problem limiting choice join operators 
static shared plans approach describe logical extension traditional pipelined query plans shared data stream processing 
set continuous queries processed single static query plan dataflow network relational algebra operators 
shows example static dataflow represents shared queries 
split static shared dataflow example new tuples arrive system driven network operator scheduling policy 
different operators may executed different times paths taken tuple stream various destinations sharing determined entirely sub expressions common individual queries 
model adopted niagaracq aurora stream 
niagaracq describes ways form grouped plans multiple queries 
general approaches optimize individual query look sharing opportunities access plans globally optimize queries produce shared access plan 
approach easier employ niagaracq group plans queries similar structure 
new queries enter system attached existing group signature matches closely 
query signatures merged multiple groups system 
adaptive shared dataflows second approach review idea adaptive tuple routing telegraphcq cacq psoup 
approach set queries decomposed dataflow relational algebra operators 
major differences dataflow adaptive route tuples variety different ways tuples extended carry lineage consisting steering completion vectors operators aware completion vector input tuple words identical tuples different completion vectors may processed differently 
discuss adaptive dataflow technology detail section 
precision sharing section introduce explain importance precision sharing way characterize overheads shared query processing 
show current systems result plans precisely shared 
defining precision sharing terms operations performed tuples shared dataflow 
dynamism static plans generally limited time late binding query parameters 
precision sharing sharing scheme stream inputs properties hold ps tuple processed operation may applied copy 
ps operator shall produce zombie tuple tuple presence absence dataflow effect result query irrespective possible input 
plan satisfy ps suffers redundancy overheads 
plan satisfy ps results wasteful production subsequent elimination zombies 
say plan precisely shared satisfies properties ps ps inputs 
approaches literature assumed reducing redundancy paramount considering side effects 
definition precision sharing lets characterize nature side effects essential limiting unnecessary query processor 
consider examples imprecise sharing join queries presence selections individual sources 
build example studied niagaracq 
imprecise sharing action consider scenario involving queries join streams apply unique selection predicate niagaracq suggests alternate plans queries 
plan uses selection pull share rs join 
see selection pushdown tuples split predicates run separate join groups 
actuality niagaracq combines split operator immediate downstream filters index filter predicates 
separate ease exposition 
represent generic output operator equivalent niagaracq 
split split selection pull selection push imprecise sharing joins selections selection push violates ps ways 
tuple rx passes predicates processed join operators producing identical join tuples 
second tuple inserted twice join operator assuming symmetric hash joins 
note selection push example ps obeyed tuple join operator satisfy query 
selection pull hand violates ps 
example output join operator include rx sx tuple rx fails predicates satisfying query 
tuple rx sx example zombie tuple shows increased sharing cause wasteful 
note plan join operator produces common sub expression redundancy 
operation applied tuple satisfies ps 
seen pull push violate properties precision sharing 
third alternative proposed niagaracq 
variant pull called filtered creates pushes predicate disjunctions ahead join 
example disjunctive predicate pushed join scan plan shown 
split precisely shared filtered pull pull filtered pull plan example satisfies ps 
tuple rx reaches join operator passed predicates 
join tuple rx sx satisfy queries 
filtered pull satisfies ps reasons selection pull 
filtered pull plan example satisfies properties ps ps 
example sharing scheme precise 
surprising experimental simulation results niagaracq generally show plan efficient 
reasonable ask filtered pull plan precisely shared 
turns answer explain section 
filtered pull show filtered pull strategy precisely shared general 
demonstrate example queries join streams apply unique selection predicates notice differences previous example selection predicates filtered pull technique suggests pick plan 
behavior query plan shown split imprecisely shared filtered pull 
respectively de fined 
similarly respectively defined 
filtered pull zombies observe inputs join operator sets join operator produces set 
notice superset desired result 
extra tuples zombies indicated shaded areas inside smaller rectangle 
queries easy see relationship result set commonality waste 
intersection result set commonality larger wasted vice versa 
queries added system situations high commonality high waste easily possible 
show illustration scenario 
lightly shaded areas represent results individual queries 
shaded areas denote zombie tuples produced utility 
cases redundancy waste push pull models expensive 
upshot example spite pushing disjunctions presence sharing join produce unnecessary zombie tuples eliminated dataflow 
queries wasted increase significantly 
example worst case overhead lost precision maximal area region identified output shared join operator 
streams overhead quadratic 
number streams increase overhead sig zombies queries 
fact exponential number participating streams 
see examples section 
disjunctions intermediate results shown filtered pull cause production zombie tuples violating property ps 
show zombies cause inefficiencies participate join producing zombies 
consider happens queries example section involve third stream solution pull strategy reuse shared plan attach join operator 
approach result substantial duplicate join processing significant overlap result sets 
causes appearance ps violation pull schemes previous section 
push plan suffered ps violation resultant plan inefficient 
alternative discard split plan shown input complete zombies shared join exacerbates zombie situation zombies input join cause zombies produced 
tuples ultimately eliminated conjuncts evaluated top plan 
note situation worst case number zombie tuples product cardinality filtered sets source 
sources overhead cubic 
situation effects zombies ameliorated pushing partial disjunction rs st join operators assuming left deep strategy rst join order 
case partial disjunctive predicate 
plan shown 
note plan produces zombies rs join operator violation ps 
addition careful examination plan reveals predicates applied times times 
violation ps 
streams split eliminate zombies disjunctions joined disjunction push scheme increasingly complicated suggesting approach scalable 
suppose executing queries queries 
keeping stated aim share aggressively generating zombies need modify plan produce plan shown 
clearly plan gets increasingly complicated lot spent repeatedly re evaluating predicates predicates potentially evaluated times tuple 
addition violations precision sharing efficient execution split operator easy 
recall actuality split operator combined predicates executed immediately 
predicates built query index split consults route tuples 
predicates involve attribute case index multi dimensional 
section showed standard techniques shared query processing precise 
attempt efficiently reuse common producing useless data exponential number streams involved 
production useless tuples wasteful done eliminate added waste 
tulip tuple lineage plans observations propose tulip tuple lineage plans approach uses tuple lineage static plans achieve precision sharing 
review imprecise static sharing saw section disjunctions intermediate results lead complicated query plans repeated predicate re evaluation 
worse predicates evaluated intermediate results disjuncts conjuncts 
expensive evaluate disjuncts simple predicates base relations 
especially case number queries large 
saw filtered pull approaches cause join operators produce zombies early eliminated 
summarize consider turn problems guide solution 

ps violation push identical tuples reach different upper level join groups build probe operations tuples duplicated 

ps violation filtered pull issue predicate evaluation tuple successful repeated potentially times complex queries 

ps violation pull filtered pull strategies join operators produce zombie tuples subsequently processed eliminated 
problem time expect pushdown competitive upper level join groups activated base tuple 
observation niagaracq 
filtered strategies best way reduce overheads repeated part solution 
problem arises static plans throw away results earlier predicate evaluations 
sense classical non shared systems predicates generally conjuncts presence tuple filter deduce tuple passed conjunct filter 
effect predicate evaluation reuse subsequently problem result discarding information predicate evaluation 
tuple information predicate memoized tuple smart join operator easily avoid producing zombie tuples 
problem analysis ready describe solution 
tuple lineage consider tuple lineage accomplish memoization predicate evaluation 
date tuple lineage profitably adaptive query processing schemes 
insight tuple lineage generally applicable fact useful static dataflows 
described cacq tuples flow system carry lineage information consists steering vector describes operators dataflow visited done visited ready completion vector describes queries system dead tuple tuple satisfy 
cacq distinction parts lineage blurred truth distinct roles 
steering vector entirely tuple routing mechanism 
apart routing infrastructure eddy operator operator contents 
contrast completion vector query sharing mechanism entirely split split queries disjunctions opaque routing fabric eddy non eddy operators 
storage manipulation costs vectors represent major overhead tuple routing schemes 
completion vectors particularly memory consumption bit tuple query results space overhead linear product number queries currently active tuples 
contrast queries question share lot operators steering vector size smaller 
tulip solution having defined notion tuple lineage ready tulip solution 
main tool tuple lineage need completion vector part 
rest refer portion lineage vector 
insight solution problem rete discrimination network pattern match problem time consuming part match step 
avoid performing tests repeatedly rete algorithm stores result match working memory temporary state 
lineage vector tags tuple keeps track queries tuple failed 
grouped filters idea borrowed cacq evaluates multiple similar predicates 
maintains indexes conjunctive predicate clauses registered 
receives new tuple efficiently probes index identify registered clauses fails 
records failures tuple lineage vector 
processing tuple live queries tuple queries get satisfied tuple sent output 
implements disjunction predicates results clause tuple payload 
predicates evaluated exactly 
note doing simple dis join join tulip precision sharing precisely share precisely share junction 
apart disjunction sets things clauses disjunct need re evaluated 
dissimilar index ing strategies disjunctive predicates classical systems 
zombie killing symmetric join eliminate zombies problem need ensure tuples go grouped filters prior entering join symmetric join operator preserves completion vector inner tuples building index join 
outer tuple probes index finds matching inner tuple compute union completion vectors inner outer 
union consists queries operators match discarded 
call operator zombie killing symmetric join 
summarize tulip involves components 
appropriate scheme results filtered pull ups chosen determine join orders 

disjunctions pushed replaced operators 

zombie killing symmetric join operators 
put driving example scenario shares queries 
static query plan tulip model shown 
kinds lineage sensitive operators 
grouped selection filter join zombie killing symmetric join output operator 
similar classic static plans single operator delivers input tuples target queries completion vectors 
consider precision sharing properties approach 
ps satisfied plan perform operation tuple predicate evaluations memoized lineage vectors tuples grouped filters push disjunctions tuple processed twice part join operator 
ps satisfied join operators produce zombie tuples kind 
instructive compare plan equivalent traditional shared plan 
tulip plan example precision sharing easy see plan queries looks similar plan single query 
easy tulip multiple queries 
contrast deal queries streams filtered pull plan gets increasingly complicated 
main insight tulip lineage helps predicate evaluation avoid repetitive computations la rete networks lineage sensitive operators recognize eliminate potential zombie tuples produced 
uses tuple lineage ensure tulip respectively violate properties ps ps 
fact tulip guarantees precision sharing irrespective optimizer decisions join order 
important note precisely shared plans optimal plan necessarily 
optimizer estimates cost plan uses number tuples stage plan determine cost operator accordance cost model 
tulip new set plans emit fewer tuples operators considered plan enumeration 
estimated cost operator slightly higher overhead lineage manipulation 
key issue expected number zombies produced stage 
number estimated optimizer choose tulip plans pursuit optimal solution 
performance tulip section study performance tulip static precision sharing approach compare static schemes described niagaracq 
particular consider filtered pull selection pushdown schemes 
experimental setup experiments performed ghz intel pentium iv processor mb main memory 
implemented tulip telegraphcq system 
shared query optimizer programmatically hook static plans telegraphcq operators 
fairly evaluate static niagaracq plans set system lineage information stored intermediate tuples telegraphcq operators perform unnecessary manipulating lineage 
instance disjunctions filtered pull realized set lineage 
similarly symmetric join operator ignores lineage 
emphasize intermediate data structures niagara measurements space overhead lineage 
static plans shown section split operators separate predicate filters follow suggesting individual predicate evaluated separately 
experiments follow niagaracq approach split operator probes input tuples predicate index implemented 
lets split send tuples plan elements queries passed probe 
top plan output operator query 
tulip implementation telegraphcq intermediate tuples lineage turned 
tulip plans gs filters zombie killing symmetric hash joins output operators manipulate lineage 
implementations output operator tuple available delivery query queueing process managing query connection 
queue shared memory access expensive 
experiments suppress output production 
output processing trivial 
latency computations system call find current time output tuple 
cheaper actual system overheads sending tuple multiple times shared memory 
important see savings zombie elimination come 
telegraphcq operators execute single thread execution process cost operator invocation minimal function call pointer copy 
real savings avoidance unnecessary zombie production elimination 
systems operators invoked different threads aurora savings fewer zombies leads fewer operator invocations turn mean context switching overheads 
fewer overlaps greater overlaps experimental setup query result sets select const const const const experimental setup query template experiments share set queries joins streams individual predicates stream 
queries identical structure correspond queries section 
template queries 
generate queries experiments supplying values constants queries setups 
show visually 
shaded areas represent results queries shaded pieces zombies generated selection pull 
tulip log number zombies eliminated 
shown cases 
fewer overlaps greater overlaps experimental setup zombies setup shown result set query overlaps sets 
precise query result set overlaps queries case queries added system zombies produced shown 
conversely second setup shown result set query overlaps sets 
achieve queries arranged overlap queries farthest apart 
subsequently query added overlaps queries 
query contributes extra zombies effect adding queries steadily reduce number zombies produced shown 
experiments measure average latency results query 
synthetic data generated piped telegraphcq external process 
tuple arriving system timestamped entry telegraphcq wrapper clearinghouse read scan operator 
tuple arrives output operator examine components compute difference current time time originally entered system 
represents latency tuple average latency measured experiments 
consider static approaches studied earlier selection pull spu filtered pull fpu selection push spd tulip 
graphs report spu case dominated fpu 
plans selection pull push predicates source shown multiple predicate case just simple extension 
performance results setup plot average latency result tuples approach number queries shared 
note number queries shown log scale axis 
setups average latency plans small ms queries increases steadily queries added 
approach certain number queries knee graph showing scheme scalability limits 
overheads affect average latencies ps violations repeated tuples intersecting result sets spd various separate join operators 
fpu output processing 
ps violations fpu unnecessary caused production zombies joins removal afterward 
tulip cpu instructions lineage management 
state overhead negligible experiments 
setup fewer overlaps seen fewer queries behavior plans remains similar 
latencies increase steadily ms ms zombies produced spd increase increases 
queries latency fpu jumps ms spd tulip stay ms 
twice queries number zombies increased fold 
fpu zombie overheads slow materially scales queries 
query sets average latency ms seconds 
returning spd tulip queries performance approaches start degrading 
queries added new query causes tuples easily eliminated joins 
tulip slightly expensive spd queries latency ms opposed spd ms 
general sharing advantage results queries shared fewer overlaps 
exactly observe case minimally shared spd scheme better 
repeated overheads spd slightly dominated lineage management tulip 
comprehensively zombie overheads fpu 
setup greater overlaps seen plans behave similarly fewer queries latencies ms 
queries fpu outright winner queries overlap 
queries performance fpu spd degrade fast 
queries added lots tuples overlap causing repeated 
instance output processing spd fpu behave similarly 
new tuples cause repeated join overheads spd overheads resulting zombies fpu 
zombies decrease plateau overheads increase decrease 
queries spd fpu perform 
queries join overheads spd worse leading spd having latency seconds queries opposed seconds fpu shown graph 
contrast tulip scheme performs gracefully degrading performance number queries added 
queries latency tulip ms 
fpu spd schemes comparable overhead ms ms queries 
latency tulip scales times order magnitude queries traditional schemes 
fewer overlaps greater overlaps summary insights performance analysis follows 
overheads repeated unnecessary significant 

setups demonstrate extreme cases favoring traditional approaches fpu spd 

extreme case tulip solution precision sharing performs 
case minimal sharing competitive ideal fpu face high sharing order magnitude better traditional scheme 
experiments demonstrate robustness tulip 
sharing useful tulip gives significant improvements best known approaches 
sharing extra overheads tulip minimal 
suggests tulip capable giving benefits cases staying competitive 
adaptive precision sharing section studying tuple routing cacq adaptive sharing scheme show susceptible violations precision sharing lineage 
just ideas adaptive approach static sharing precise turns techniques static world remove precision sharing violations adaptive approach 
tuple routing cacq explain tuples routed adaptive dataflow described cacq 
show cacq process queries section 
scan modules scheduled bring data system wrappers 
tuples fed eddy adaptively routes tuples slave operators 
static query plans average query latencies cacq eddy stems grouped filter predicates stem operators 
stem state module conceptualized half decoupled symmetric join operator 
join operator streams may decoupled stems cacq tuple routed candidate operators signature set base tuples constituents 
operators set candidates may chosen order routing policy governing choice 
base tuple signature built probed stems respectively 
correctness reasons stems candidates tuples signature destroy atomic build probe property pipelined joins 
described section cacq singleton tuple inserted associated stems routed stems needs joined 
system constraints force tuples built directly associated stems right scanned 
example adaptivity features cacq play role join performed 
show dataflow tuples cacq example 
base tuple goes build output prober probes builds effective tuple dataflow cacq ter probe output operators 
note tuple gets respectively built probed stem 
similarly tuple gets respectively built probed stems 
simplicity assume predicates question expensive cacq orders probe 
sharing single query eddy scheme steering vector tuple indicates done output query 
sharing intermediate tuple eddy satisfy query checking delivering tuples query outputs part cacq eddy responsibilities 
precision sharing violations cacq show cacq violates precision sharing rules 
concerned sharing address considerable benefits adaptive system may volatile scenarios 
zombie production ps violation tuples built stems original base tuples contain record predicate evaluation carry useful lineage 
means producing join tuples way combine lineage probe build eliminate zombies described section 
see recall section description zombie killing symmetric join 
able eliminate matching zombie tuples operator needs perform union lineage vectors outer inner tuples 
cacq inner tuples carry lineage join eliminate zombies violates ps property precision sharing 
explained way problem optimal placement individual selection predicates presence joins 
conventional binary join operator choices explored niagaracq discussed section pushing selections join selection push pulling filtered pull 
internal build probe operations join decoupled shown choices locating selection predicates disjunctions probe build probe build 
cacq build scan performed choices build probe probe routing policy deciding wins adaptive fashion 
unfortunately choices result production zombies 
repeated output processing ps violation output processing cacq done time tuple returns eddy major loop 
intermediate tuple steering vector compared completion requirements query 
tuple satisfies query immediately delivered 
expensive operation especially presence large number queries tuple may processed repeatedly output multiple queries 
violation ps property 
saw section repeated processing tuple outputs multiple queries ps violation drastically hurt performance 
really need way route tuples output operators ready 
car constrained adaptive routing propose alternative cacq constrained adaptive routing car 
show scheme adaptivity benefits cacq satisfies precision sharing 
explained section cacq violates precision sharing producing zombies repeating output processing operations 
hidden constraint build scan causes poor selection placement 
output processing performed unconstrained ad hoc fashion 
root problem multiple constraints satisfied adaptive dataflow 
build probe correctness filters build output done performance 
architecture constraints expressed explicitly ensure correctness performance 
car introduce operator precedence routing mechanism 
approach record precedence relationships operators precedence graph 
cacq mechanism generate set candidate operators tuples routed 
simplest form graph nodes sets operators called candidates edges represent legal transitions node 
tuple routed candidates particular node subject routing policy lottery scheme cacq 
ensures car adaptively respond changes selectivity data rates stems stems operator precedence graph car show operator precedence graph queries 
nodes graph operators stems outputs appear node 
clearly scheme tuples filtered built stems 
enables early recognition elimination zombies preserves ps property 
tuple subject output processing ready 
preserves ps property 
effects adaptivity note fixing predicate placement hurt adaptivity 
order reduce zombies gs filters ought processed builds 
filters question expensive cost join operations reducing zombies may important 
adaptivity cacq allowed efficient join ordering delayed execution expensive filters cost zombies 
contrast car joins ordered efficiently zombies cost early evaluation expensive filters 
presence filter known expensive easy fix car precedence graph revert cacq behavior 
interesting question possible choice adaptively 
clear devise routing policy 
practice simple filters common heuristic reverting cacq presence expensive predicates applications 
main insight approach techniques static world 
purely adaptive approach routing decisions step way 
constraints adaptivity possible ensure predicate placement appropriate precision sharing 
performance car cacq section compare performance cacq car constrained adaptive routing technique described 
experimental setup methodology identical described static plans section 
setups report average latencies query results cacq car figures 
note number queries shown log scale axis 
static case setups average latency cacq car queries small ms increases steadily query addition scalability limits reached 
overheads affect latencies ps violations cacq repeated output processing tuple different queries 
ps violations cacq unnecessary caused production removal zombies 
car cacq cpu instructions involving lineage management 
experiment cacq tuples produced probes stems immediately ready output 
filtering steps fact ps violations causing output processing overheads 
setups performance car comfortably cacq 
just tulip performance car gracefully degrades addition new queries 
fewer overlaps case queries overlaps 
spite production zombies cause cacq latency ms opposed ms car 
shows savings output processing ps preservation car 
queries latency car ms equivalent latency cacq supports queries 
latency car supports times order magnitude queries cacq 
greater overlaps case cacq scales gracefully fewer overlaps 
note case relative overheads zombies drop queries 
behavior cacq observe really damped version car 
queries cacq latency ms opposed ms car 
note cacq support latency ms queries car handles times 
difference setups number zombies 
fewer overlaps production zombies cacq 
comparison static schemes car performs tulip 
queries latency car greater overlap case ms opposed ms tulip 
fewer overlap case ms car opposed tulip 
results surprising difference car tulip cost adaptivity 
choices experiments latency differences observe lets baseline cost adaptivity 
summary experiments indicate 
overheads producing zombies unnecessary significant adaptive dataflows relatively fewer zombies produced 

scheme car approach adaptive precision sharing performs 

scenarios baseline costs adaptivity significant 
shared query processing focused reducing overheads redundancy 
aggressive reduction repeated cause additional wasted postprocessing useless data 
far inherent tension repeated wasted taken granted 
major contributions show tension irreconcilable develop static adaptive techniques balance tension gracefully 
defined precision sharing way characterize sharing scheme repeated wasted 
showed previous shared stream processing led imprecisely shared plans 
armed observations charted strategy static shared plans precise 
insight tuple lineage idea adaptive query processing generally applica fewer overlaps greater overlaps ble 
proposed tulip tuple lineage static plans technique static shared plans precise tuple lineage 
contribution show shared adaptive query processors violate precision sharing 
reversed strategy adopted idea operator ordering static dataflows 
new approach car constrained adaptive routing benefits adaptivity side effects precision sharing 
reported performance study various schemes precise imprecise static adaptive 
experiments show precision sharing approaches significantly outperform competitive schemes different extreme conditions 
avnur 
eddies continuously adaptive query processing 
sigmod pp 


bloom 
space time trade offs hash coding allowable errors 
cacm 
carney 
monitoring streams new class data management applications 
vldb 

chandrasekaran 
streaming queries streaming data 
vldb 

chandrasekaran 
telegraphcq continuous dataflow processing uncertain world 
cidr 

chen 
niagaracq scalable continuous query system internet databases 
sigmod 

chen 
design evaluation alternative selection placement strategies optimizing continuous queries 
icde 


pipelining multi query optimization 
pods 

forgy 
rete fast algorithm pattern object match problem 
artifical intelligence september 
adaptive query plans average query latencies graefe 
dynamic query evaluation plans 
sigmod pp 


krishnamurthy 
telegraphcq architectural status report 
ieee data eng 
bull 
madden 
continuously adaptive continuous queries streams 
sigmod 

mohan 
single table access multiple indexes optimization execution concurrency control techniques 
edbt pp 


motwani 
query processing resource management approximation data stream management system 
cidr 

raman 
state modules adaptive query processing 
icde 

sellis 
multiple query optimization 
acm tods march 
tan 
workload scheduling multiple query processing 
inf 
proc 
letters 
tian 
tuple routing strategies distributed eddies 
vldb pp 



