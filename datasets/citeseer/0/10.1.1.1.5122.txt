spatial computation mihai budiu seth copen goldstein seth cs cmu edu carnegie mellon university describes computer architecture spatial computation sc translation high level language programs directly hardware structures 
sc program implementations completely distributed centralized control 
sc circuits optimized wires expense computation units 
investigate particular implementation sc ash application specific hardware 
assumption computation cheaper communication ash replicates computation units simplify interconnect building system uses simple completely dedicated communication channels 
consequence communication datapath requires arbitration arbitration required accessing memory 
ash relies simple hardware primitives associative structures register files scheduling logic broadcast clocks 
consequence ash hardware fast extremely power efficient 
demonstrate features ash architectures built automatic compilation programs distributed computation respects fundamentally different monolithic superscalar processors asic implementations ash orders magnitude energy compared high superscalar processors average slower performance worst case 
categories subject descriptors arithmetic logic cost performance automatic synthesis optimization simulation algorithms implemented hardware simulation dataflow architectures hybrid systems data flow languages code generation compilers optimization general terms measurement performance design 
keywords spatial computation dataflow machine applicationspecific hardware low power 

von neumann computer architecture proven extremely resilient despite numerous perceived shortcomings 
computer architects continuously enhanced structure central processing unit advantage moore law 
permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
asplos october boston massachusetts usa 
copyright acm 
day superscalar order microprocessors amazing achievements 
scalability superscalar vliw architectures questionable 
attempting increase pipeline width processor current instructions cycle difficult interconnection networks scale 
register file instruction issue logic pipeline forwarding networks grow quadratically issue width making interconnection latency limiting factor 
problem compounded increasing clock rates shrinking technologies currently signal propagation delays inter module wires dominate logic delays 
just distribution clock signal major undertaking 
wire delays factor way scaling power consumption power density reached dangerous levels due increased amounts speculative execution increased logic density wide issue 
design complexity limitation number available transistors grows annually designer productivity grows 
exponentially increasing productivity gap historically covered employing larger larger design verification teams human resources economically hard scale 
research aimed directly problems 
explore spatial computation model computation optimized wires 
previously proposed spatial computation mapping programs evaluate compiler technology developed traditional cmos substrate 
class circuits call spatial arguably large focus attention particular set instances sc structures call application specific hardware ash 
ash requires clocks global signals 
core assumption computation gates cheap cheaper compared cost wires terms delay power area 
ash extreme point space sc architectures ash computation structures shared program operation synthesized different functional unit 
complete compiler cad tool chain bridges software compilation microarchitecture 
applications written high level languages compiled hardware descriptions 
descriptions loaded reconfigurable hardware fabric synthesized directly circuits 
resulting circuits localized communication require broadcast global control self synchronized 
compiler developed automatic fast requires designer intervention exploits instruction level parallelism ilp pipelining 
novel research contributions described compiler tool chain ansi asynchronous hardware suif front cfg optimize convert pegasus optimize async back verilog commercial cad asic layout cash high level simulation circuit simulation section evaluation 
right hand side indicates sections discuss 
low ilp os vm cpu local memory memory ash high ilp computation ash tandem processor implementing applications 
processor relegated low ilp program fragments executing operating system 
qualitative comparison spatial computation architectures superscalar processors circuit level evaluation synthesized circuits program kernels mediabench suite description high level synthesis produces extremely energy efficient program implementations comparable custom hand tuned hardware designs orders magnitude better superscalar processors implementation compiler target dataflow machines 

compiling hardware section presents compilation methods embodied cash compiler compiler ash 
structure cash place complete synthesis tool flow illustrated shows organization 
circuits generated cash handle system calls 
translating application assume partitioning performed part application executed traditional processor rest mapped hardware shown 
processor hardware access global memory space mechanism maintain coherent view memory 
crossing hardware software interface hidden employing stub compiler encapsulates information transmitted interface proposed effectively performing remote procedure calls hw sw interface 
cash cash takes ansi input 
cash represents input program pegasus dataflow intermediate representation ir :10.1.1.1.5122
output cash hardware dataflow machine directly executes input program 
currently cash generates structural verilog description circuits 
cash front suif compiler 
front performs optimizations including procedure inlining loop unrolling call graph computation basic control flow optimizations intraprocedural pointer analysis live variable analysis 
front translates low suif intermediate representation pegasus 
cash performs wealth optimizations representation including scalar memory boolean optimizations 
back performs peephole optimizations generates code 
translation hardware eased maintaining memory layout program data structures implemented classical cpu system heap structure practically identical cash uses stack space needs spill registers 
ash currently uses single monolithic memory purpose see section 
intrinsic spatial computation mandates monolithic memory contrary independent memories suggested example beneficial 
pegasus intermediate representation key technique allowing bridge semantic gap imperative languages asynchronous dataflow static single assignment ssa 
ssa ir imperative programs variable assigned 
seen functional program 
pegasus represents scalar part computation programs ssa 
due space limitations briefly describe pegasus 
see details :10.1.1.1.5122:10.1.1.1.5122
pegasus seamlessly extends ssa representing memory dependences predication forward speculation unified manner 
irs previously combined aspects believe pegasus unify coherent semantically precise representation 
program represented directed graph nodes operations edges indicate value flow example shown 
pegasus leverages techniques compilers predicated execution machines collecting multiple basic blocks hyperblock hyperblock transformed code predication techniques similar 
ssa nodes hyperblocks pegasus uses explicit decoded multiplexor mux nodes example 
decoded mux data inputs predicates 
data inputs reaching definitions 
mux predicates correspond path predicates predicate selects corresponding data input 
predicates mux guaranteed mutually disjoint predicates encoded 
cash uses boolean optimizer simplify predicate computations 
speculation introduced predicate promotion predicates guard instructions side effects weakened true instructions executed unconditionally hyperblock entered 
predication speculation core constructs pegasus 
translating control flow constructs dataflow reducing crit hyperblock portion program control flow graph having single entry point possibly multiple exits 
int squares int sum sum return sum sum sum sum eta merge program representation comprising hyperblocks hyperblock shown numbered rectangle 
dotted lines represent predicate values 
omits token edges memory synchronization 
control dependences 
effectively increase exposed ilp 
note mux nodes natural speculation squashing points discarding data inputs corresponding false predicates computed mis speculated paths 
hyperblocks stitched dataflow graph representing entire procedure creating dataflow edges connecting hyperblock successors 
variable live hyperblock forwarded eta node called gateway 
shown triangles pointing figures 
eta nodes inputs value predicate output 
predicate evaluates true eta node moves input value output predicate evaluates false input value predicate simply consumed generating output 
hyperblock multiple predecessors receives control different points inter hyperblock join points represented merge nodes shown triangles pointing 
shows function uses induction variable accumulate sum squares ofi 
right program pegasus representation consists hyperblocks 
hyperblock initializes sum 
hyperblock represents loop contains merge nodes loop carried values sum hyperblock function epilog containing just return 
back edges hyperblock denote loop carried values example edges hyperblock back edges connect eta merge node 
memory accesses represented explicit load store nodes 
operations side effects call division may generate exceptions predicate input predicate false operation executed 
figures predicate values shown dotted lines 
compiler adds dependence edges called token edges explicitly synchronize operations side effects may commute 
operations memory side effects load store call return token input 
token edges explicitly encode eta ret data flow memory 
operation memory side effects collect tokens potentially conflicting predecessors store set loads 
combine operator purpose 
combine multiple token inputs single token output generates output receives inputs 
noted value dependence graph representation token networks interpreted ssa memory combine operator corresponds function 
tokens encode true output anti dependences may dependences 
devised new algorithms removing redundant memory accesses exploit predicates token edges concert 
show tokens explicitly synthesized hardware signals compile time run time constructs 
currently compiler purely static uses profiling information 
reason profiling incorporated tool chain 
section explains profiling critical cash traditional ilp compilers 
dataflow semantics pegasus precise concise operational semantics pegasus constructs 
run time edge graph holds value empty 
operation begins computing required inputs available 
latches newly computed value output 
computation consumes input values setting input edges produces output value 
semantics static dataflow machine edge hold single value time 
precise semantics useful reasoning correctness compiler optimizations precise specification compiler back ends 
currently cash back ends graph drawing back generates drawings language simulation back generates interpreter graph structure analysis section asynchronous circuits verilog back described section evaluation section 
compiler status core cash handles ansi alloca functions variable number arguments 
constructs relatively easy integrate handling longjmp substantially difficult 
strictly speaking exceptions compiler handle 
recursion handled exactly way software cash allocates stack frames saving restoring live local variables recursive call 
optimization cash uses call graph detect possibly recursive calls avoids saving locals non recursive calls 
asynchronous back newer somewhat complete handle procedure calls floatingpoint computations 
easily handled suitable ip core containing implementations floating point arithmetic 
currently handle procedure calls inlining 
handling function pointers requires chip network call need dynamically route procedure arguments callee circuit dependent run time value pointer 

ash versus superscalar section devoted comparison properties ash superscalar processors 
comparison performed executing programs timing accurate simulators 
parameters see comparison limit study 
study interpreted head head comparison unlimited resource static dataflow machine superscalar processor 
interestingly despite limited resources superscalar capabilities give substantial edge static dataflow model shown 
results may partial explanation demise dataflow model computation popular research subject seventies eighties 
briefly discuss main source parallelism dataflow machines 
dataflow software pipelining consequence dataflow nature ash automatic exploitation pipeline parallelism 
phenomenon studied extensively dataflow literature names dataflow software pipelining loop unraveling 
name suggests phenomenon closely related software pipelining compiler scheduling algorithm vliw processors 
program illustrates phenomenon 
assume multiplier implementation pipelined stages 
show consecutive snapshots circuit executes starting initial snapshot merges contain initial values sum 
implemented tool automatically generate pictures inputs tool pictures generated cash backend execution traces generated execution simulator 
snapshot computation executed iterations consecutive values injected multiplier computation complete iteration 
execution multiplier effectively pipelined 
similar effect achieved statically scheduled computation explicitly software pipelining loop scheduling computation occur iteration ahead 
pipelining occurs automatically compiler intervention superscalar processors resources simultaneously process instructions multiple instances loop body 
practice large loops may dynamically pipelined superscalar due order instruction fetch prevent iterations getting ahead 
maximizing throughput pipelined computation ash requires delay paths different strongly connected components pegasus graph equal 
cash inserts fifo elements achieve transformation closely related pipeline balancing static dataflow machines slack matching asynchronous circuits 
fifo elements correspond reservation stations superscalar designs rotating registers software pipelining 
ash versus superscalar comparing ash superscalar assumptions arithmetic operations latencies computational fabrics merges boolean operations ash latencies proportional log number inputs eta latency addition memory operations ash incur additional cost network arbitration compared superscalar memory hierarchy models identical lsq level cache hierarchy superscalar way order simplescalar simulation pisa instruction set gcc study similar lsq ash superscalar 
exploring synthesis program specific lsq structures 
compiler 
ash simulated high level simulator automatically generated cash shown 
simulate execution libraries ash supply compiler source code instrumented simplescalar ignore execution time order fair comparisons 
naively expect ash execute programs strictly faster superscalar assuming comparable compiler technology benefits unlimited parallelism resource constraints instruction fetch decode dispatch dynamic scheduling 
simulating programs specint assumptions results programs go ijpeg showing improvement ash programs slower 
speed ups ash attributable increased ilp due unlimited number functional units benchmarks instruction cache processor bottleneck 
section investigate slowdowns 
superscalar advantages order understand advantages superscalar processor carried detailed analysis code fragments perform especially poorly ash 
main tool purpose dynamic critical path 
ash dynamic critical path sequence arrival events 
event enables computation node proceed 
events correspond signal transitions graph edges 
dynamic critical path computed tracing edges corresponding arrival events backwards operation executed 
arrival edge input arriving operation 
lenient operations see section arrival edge edge enabling computation output 
inputs may operation may unable compute received acknowledgment signal previous computation case ack arrival event 
despite fact superscalar time multiplex small number computational units mechanisms employs provide clear performance advantages 
brief summary findings 
branch prediction ability superscalar predict branch outcomes changes radically structure dynamic dependences example correctly predicted branch dynamically independent actual branch condition computation 
order commit stage structural hazard processor pipeline bottleneck entire computation branch condition removed critical path 
contrast ash inter hyperblock control transfers speculative 
eta control predicate computation critical path computation overlap branch condition evaluation control intensive code 
code fragments may executed faster processor 
branches testing exceptional conditions introduced statements executed processor branch prediction job handling 
cases especially detrimental ash 
note branch prediction requires global information aggregating information multiple branches challenging implement efficiently spatial computation 
synchronization merge mux operations non zero cost may translate overhead ash 
operations cor sum sum sum sum sum sum sum sum ret ret ret ret ret sum sum sum sum sum sum sum sum snapshots execution circuit 
shaded nodes actively computing indicate current value output latch 
assuming stage pipelined multiplier stage shown assume nodes graphs latencies boolean negation takes zero time units implementation folds inverter destination pipeline stage 
snapshot different values simultaneously multiplier pipeline 
respond labels machine code control flow join points zero execution cost cpu 
phenomenon facet tension synchronization parallelism 
processor uses program counter sequence program ash relies completely distributed control 
merge mux operations simple forms synchronization merge candidate values variable 
fine grained parallelism dataflow requires additional synchronization 
occurs dataflow machine executed interpreter directly mapped hardware 
distance memory superscalar contains limited number load store execution units usually 
flight memory access instructions dynamically scheduled access units get hold unit initiate memory access constant cost 
example processor lsq allows write operations complete essentially zero time 
contrast ash memory access operation synthesized distinct hardware entity 
current implementation uses monolithic memory ash requires network connect operations memory 
network implementation described section 
network requires arbitration limited number memory ports total arbitration cost log number memory operations program 
wire length network grows 
impact complexity memory network somewhat reduced fragmenting memory independent banks connected separate networks plan 
note asymptotic complexity memory behavior decoders selectors memory bits require log stages worst case wire length 
explains memory systems grow intrinsically slower processors speed today memories bound wire delays 
ash addresses shortcomings superscalar processors directly aim solve memory bottleneck problem models computation attack problem trying overlap memory stall time useful computation 
static vs dynamic dataflow ash instance operation may executing time operation single output latch storing result 
contrast superscalar processor may multiple instances instruction flight register renaming mechanism effectively provides different storage element instance flight instruction 
instruction effectively pipelined major changes implementation load operations wait memory access complete initiating new access 
local reorder buffer employed purpose deviates spirit ash 
ash loop unrolling pipelining provide similar results full dynamic dataflow model general performed statically seen instances cpu dynamic renaming outperformed static version code input set 
strict procedures current implementation procedures relies call nodes strict initiate procedure inputs node available 
fact inputs initiating call introduces additional synchronization puts slowest argument computation dynamic critical path 
applicable procedure inlining eliminates problem procedure call network specialized simple point point channels 
contrast superscalar processor procedure invocation decoupled passing arguments put registers stack call simply branch 
code computing procedure arguments need complete procedure body initiated 
fact computation unused procedure argument critical path 
issues discussed fundamental ash 
shortcomings ash attributable policies compiler corrected careful implementation 

layout section describe pegasus translated asynchronous circuits detailed measurements synthesized circuits 
discuss reasons excellent power efficiency circuits 
cab cash asynchronous back asynchronous back cash translates pegasus representations asynchronous circuits 
static dataflow ma sum sum ret register ack source ready data dest signaling protocol data producers consumers 
control circuitry pipeline stage 
delay matched computational unit 
block labeled completion detection block detecting register output stabilized correct value 
chine semantics pegasus translation fairly straightforward 
details process available 
synthesizing scalar computations pegasus representations mapped asynchronous circuits ways 
chosen implement pegasus node separate hardware structure 
ir node implemented pipeline stage circuit style introduced sutherland pipeline stage contains output register hold result stage computation 
edge synthesized channel consisting uni directional signals shown 
data bus transfers data producer consumer 
data ready wire producer consumer indicates data safely consumer 
acknowledgment wire consumer producer indicates value channel 
signaling method called bundled data protocol widely employed asynchronous circuits 
control circuitry driving pipeline stage shown 
gate ller element implements finite state machine control properly alternating data ready acknowledgment signals 
multiple consumers data bus broadcast value channel contains acknowledgment wire consumer 
due ssa form pegasus channel single writer 
need arbitration making data transfer lightweight operation 
important feature implementation complete absence global control structures 
control completely embodied handshaking signals naturally distributed computation 
gives circuits strong datapath orientation making amenable efficient layout 
lenient evaluation form speculative execution employed pegasus executes forward branches simultaneously alleviates im sutherland phase signalling protocol phase signaling signal returns zero initiating new computation cycle 
sample program fragment corresponding pegasus circuit static critical path highlighted 
pact branches may plagued problem unbalanced paths illustrated static critical path entire construct longest critical paths 
short path executed frequently benefits speculation may negated cost long path 
problem occurs machines employ predicated execution 
traditionally problem addressed ways profiling hyperblocks ensure long path executed run time predicated excluding certain hyperblock topologies consideration disallowing predication paths differ widely length 
single pc employ third elegant solution hardware solve problem 
definition lenient operation expects inputs arrive eventually compute output subset inputs 
lenient operators generate result soon possible 
example operation determine output false soon inputs false 
output available inputs implementation ensures lenient operation sends acknowledgment inputs received 
obtain full benefit needs issue early acknowledgments suggested 
asynchronous circuits literature proposed name early evaluation 
forms lenient evaluation design arithmetic units microprocessors example multiplier designs may generate result quickly input zero 
muxes implemented soon selector true corresponding data available mux generates output 
note crucial mux decoded see section order scheme efficiently 
result dynamic critical path implementation 
example multiplication affect critical path 
addition booleans multiplexors predicated operations lenient predicate input 
example load operation receives false predicate input immediately emit arbitrary output actual output irrelevant 
output token receives input token memory dependences transitively implied 
irrelevant lenient evaluation confused short circuit evaluation short circuit evaluation evaluates left operand true evaluates right 
lenient evaluation generates false result soon input known false 
multiplier critical path late acknowledgments may prevent wave computation propagating forward described section 
problem alleviated pipelined multiplier early 
memory access network implementation value token forwarding network 
load produces data value consumed oval node 
store node may depend load token edge load store shown dashed line 
token travels root tree load store queue lsq 
put discarded downstream mux eta node controlled false predicate 
memory access complicated part synthesis process building network load store operations access memory 
illustrates load dependent store access memory network 
current implementation consists hierarchy buses asynchronous arbiters mediate access buses 
memory instructions ready access memory compete buses winners arbitration inject messages travel hierarchy pipelined fashion 
memory operation produce token soon effect guaranteed occur right order respect potentially interfering operations 
network guarantee order message delivery traveling root maintain invariant dependent operation issued operations depends injected requests lsq 
root tree unique serialization point guaranteeing order execution dependent operations 
lsq holds description memory operations execution memory effects completed may perform dynamic disambiguation act small fully associative cache 
section discuss disadvantages implementation 
currently synthesize simple load store queue lsq hold single operation execution completes 
worthwhile notice implementation memory access network spirit ash completely distributed composed entirely pipeline stages control localized stage contains global signals kind 
low level evaluation section measurements detailed lowlevel simulation 
synthesize kernels asics evaluate performance standard data sets 
cab generates synthesizable verilog fpgas targeted principle evaluation 
factors prevent doing commercial fpgas synchronous devices mapping features asynchronous circuits predicated false operation need swing output lines need assert data ready signal see section 
decrease power consumption 
ficient commercial fpgas optimized power probably negate main advantages implementation scheme low power consumption 
kernels mediabench suite generate circuits 
program select hot function see table implement hardware exception benchmarks hot function small selected function callers inlined callee unrolled resulting loop substituted array constants inline constant values 
code simplescalar simulator comparisons 
experimental results entire circuit synthesized cab including memory access network excluding memory circuit 
report data execution kernel ignoring rest program due long simulation times execute kernel invocations program measure cumulative values time energy invocations 
estimate overhead invoking returning kernel aim understand behavior ash cpu ash system 
current back support synthesis floating point computation omit kernels ones rasta benchmarks 
cab back generate verilog representation kernel 
detailed description methodology 
nm standard cell library optimized performance 
structural verilog generated tool flow partially technology mapped cab partially synthesized synopsys design compiler sp 
technology mapped circuits routed silicon ensemble cadence 
currently placement handled completely silicon ensemble operating flat netlist expect cab knowledge circuit structure automatically generate floor plans improve results substantially data collection commercial cad tools pegwit benchmarks failed placement pre placement numbers 
performance benchmarks better pre placement estimate 
simulation performed se 
assume perfect cache mhz cycle time 
synthesize element lsq ash 
compilation time order tens seconds benchmarks completely inconsequential compared hardware synthesis commercial tool chain worstcase program takes cash hour synthesis hours place route 
code expansion terms lines code verilog factor 
results section obtained loop unrolling increase circuit area compilation time 
area shows area required kernels 
area broken computation memory tree memory tree area arbiter circuits mediate access memory hierarchical pipelined buses 
technology minimal risc core synthesized mm multiplier requires mm complete processor die including caches mm shows area kernels substantial certainly affordable especially technologies 
normalizing area placement physical optimizations account factor size performance 
benchmark function lines adpcm adpcm decoder adpcm adpcm coder quan quan gsm short term synthesis filtering gsm short term analysis filtering jpeg jpeg idct jpeg jpeg mpeg mpeg dist pegwit pegwit table embedded benchmark kernels low level measurements size original un processed source lines code 
forg inlined 
silicon real estate mm kernel 
versus object file size require average mm kb gcc generated mips object file 
execution performance shows normalized execution time kernel baseline mhz wide superscalar processor 
simulate vliw expect trends similar superscalar maintains high ipc kernels 
processor perfect cache element lsq 
average ash circuits times slower kernels faster processor 
unlimited amount ilp exploited ash results somewhat disappointing 
analysis ash circuits pointed circuits improved respects main bottleneck current design memory access protocol 
current implementation described section memory operation release token request reached memory token traverse network directions 
improved construction allow operation inject requests network allowing travel order release token dependent operations immediately 
network packet carry information enable lsq buffer order requests execute memory operations original program order 
kind protocol superscalar processors inject requests order load store queue proceed issue memory operations previous ones completed 
kernel slowdown compared wide issue mhz superscalar processor nm 
value indicates identical performance values bigger indicate slower circuits ash 
evaluation impact ideal memory interconnection protocol 
left bar reproduces data 
gauge impact memory network program performance performed limit study behavioral implementation network stage zero latency 
improvement performance shown programs having large memory access networks display significant improvements shows programs perform memory accesses bound memory network round trip time 
numbers obtained assuming value token travel quickly network reality substantially speed token path performance better protocol evaluated 
measure ash performance mips metrics bottom bar labeled mops millions useful arithmetic operations second 
incorrectly speculated arithmetic accounted 
includes auxiliary operations including merge eta mux combine pipeline balancing fifos overhead operations 
speculative execution dominates useful average executed arithmetic operations incorrectly speculated 
programs control operations constitute substantial fraction total number executed operations 
average programs sustain 
compiler control degree speculation varying hyperblock construction algorithm explored trade offs involved 
computational performance ash mediabench kernels expressed millions operations second mops 
energy efficiency synthesized kernels expressed useful arithmetic operations 
power energy power consumption circuits ranges mw mw jpeg average mw 
contrast low power dsp chip technology draws mw 
order quantify energy efficiency normalized metric proposed mops mw equivalently operations 
shows kernels fare perspective 
count useful operations mips metric bottom bar 
energy efficiency cash systems operations nj average 
outliers memory accesses implementation extremely efficient 
comparison shows logarithmic scale energy efficiency microprocessors digital signal processing custom hardware circuits asynchronous microprocessor fpgas 
circuits comparable hardware technologies nm 
ash orders magnitude better superscalar microprocessor orders magnitude better dsp 
compares ash wide low power superscalar modeled wattch aggressive clock gating power reduction drawing dynamic power terms energy delay metric relatively independent execution speed 
ash circuits times better 
dedicated hardware ash media kernels asynchronous microcontroller fpga general purpose dsp microprocessors energy efficiency mops mw op nj energy efficiency computational models comparable technologies 
energy delay ratio ash superscalar 
circuits memory access substantially better order magnitude 
power roughly proportional circuit activity power wasted speculation proportional number speculative operations executed 
currently believe negotiate power performance trade direction expending power increase performance power low increase power acceptable relatively small increase performance 
discussion multiple sources inefficiency implementation superscalar processors account huge difference power energy 
clock distribution network large chip accounts total power budget power spent latches exist asynchronous implementations big clock network huge drivers account substantial fraction power 
pipeline stages ash usually inactive see example 
circuits asynchronous draw static power inactive small technology 
leakage power big issue technologies circuit architecture level techniques applied reduce impact ash 
pentium die excluding caches functional units combined integer floating point mmx take chip area 
remaining devoted entirely mechanisms support computation producing useful results 
point view energy efficiency metric extra activity pure overhead 
suggests power asynchronous processor spent instruction fetch decode 
shows inherent overhead interpreting programs encoded machine code ash pay 
microprocessor asics functional units heavily optimized speed expense power area 
sc replicates functional units trade biased reverse direction 
known dedicated hardware chips vastly energy efficient processors 
algorithms implemented dedicated hardware natural high degree parallelism 
shows time fully automatic tool chain starting programs generate results comparable speed high processors power custom hardware 
confident optimizations including techniques high level compiler transformations better memory access protocol compiler guided floor planning substantially increase ash performance 

related optimizing compilers 
pegasus form dataflow intermediate language idea pioneered dennis 
crux pegasus handling memory dependences excessively inhibiting parallelism 
core ideas tokens express fine grained location synchronization introduced beck 
explicit representation memory dependences program operations suggested numerous times literature pingali dependence flow graph steensgaard adaptation value dependence graphs 
researchers explored extending ssa handle memory dependences 
approaches simple 
integration predication ssa done 
functions loses appealing properties ssa 
hyperblock basic optimization unit algorithm computing block path predicates inspired 
high level synthesis 
substantial amount research hardware synthesis high level languages dialects supports fully cash 
major difference approach vast majority efforts deck projects employ hardware description language hdl 
add constructs reactivity concurrency variable bitwidth order suitable expressing hardware properties remove constructs pointers dynamic allocation recursion correspond natural hardware objects obtaining register transfer efforts impose strict coding discipline order obtain synthesizable program 
numerous research commercial products variants hdl pico hp originally forte design systems cyber nec rt builder originally frontier design xilinx scenic synopsys compilers bach originally occam sharp synopsys verilog originally level design handel compiler cadence ecl esterel compiler spc stanford 
goals closely related chip day project berkeley approach different project starts parallel statechart descriptions employs sophisticated hard macros synthesize synchronous designs automatic clock gating 
contrast start small library standard cells build asynchronous circuits 
reconfigurable computing 
completely different approach hardware design taken research reconfigurable computing relies automatic compilation highlevel languages target reconfigurable hardware 
notable projects prism ii prisc disc napa defacto chimaera rapid pact piperench raw virtual wires systems described compilation term rewriting systems synthesis dataflow graphs 
cash influenced callahan garp compiler 
systems broad scope targeting reconfigurable fabric 
approaches targets true spatial computation model completely distributed computation control 
dataflow machines 
large number dataflow machine architectures proposed built see example survey 
interpreters executing programs described specialized form machine code 
dataflow machines programmed functional languages val id cash principle target traditional dataflow machine 
knowledge efforts translate execution dataflow machines reached completion 
asynchronous circuit design 
traditionally asynchronous synthesis concentrated synthesizing individual controllers 
decade number approaches explored synthesis entire systems 
starting point related synthesis flows high level language usually inherently parallel hoare communicating sequential processes suitable describing parallelism application balsa occam chp 
exception synthesis tends follow step approach high level description translated fashion intermediate representation module ir template technology mapped gates 
optional optimization step may introduced improve performance synthesized circuits 
highlevel specification decomposed smaller specifications dataflow local optimizations techniques applied resulting low level specifications synthesized template fashion 
approach somewhat similar syntax directed flows notable differences 
input language wellestablished imperative sequential programming language handling pointers arrays central approach 
second cash compiler performs extensive analysis optimization steps generating intermediate form 
target implementation intermediate form consists pipelined circuits naturally increase performance compared traditional syntax directed approaches 
spatial computation 
various models related spatial computation investigated research efforts compiling finite sized fabrics studied research systolic arrays raw piperench trips 
remotely related efforts imagine 
unlimited virtualized hardware exploited proposals score 
efforts research distinguished fact targets purely spatial implementations centralized resources control produced detailed evaluation architecture 

investigated particular instance isa class spatial computation models ash application specific hardware 
ash software program translated directly executable hardware form interpretation layer 
synthesized hardware closely reflects program structure definer user relationships program operations translated directly point point communication links connecting arithmetic units 
resulting circuit completely distributed featuring global communication broadcast global register files associative structures resource arbitration accessing global memory 
monolithic memory take advantage freedom provided architecture substantially simplifies completely automatic implementation language programs 
chosen synthesize dynamically self scheduled circuits computations carried availability data fixed schedule 
natural vehicle implementing self scheduled computations provided asynchronous hardware 
detailed investigation run time behavior spatial structures shown distributed nature forces incur non negligible overheads handling control intensive programs 
contrast traditional superscalar processors global structures branch prediction control speculation register renaming efficiently execute control intensive code 
ash complements capabilities traditional monolithic processors promising avenue research investigation hybrid computation models coupling monolithic distributed engine 
circuit level simulations ash shown provides performance implement programs high ilp media kernels 
energy efficiency ash orders magnitude better compared low power dsp processors orders magnitude better general purpose superscalar microprocessors 
compilation methodology ash indicates possible convert deck programs written highlevel imperative sequential language efficient hardware 
believe line research eliminate designer productivity gap decrease power problem allow exploitation promised massive numbers devices available technologies 

research funded part national science foundation 
ccr ccr darpa contracts mda src 
procedure inlining suif pass written tim callahan 
loop unrolling pass written todd mowry 
optimizations implemented pedro 
dan vogel help scripting benchmark management 
wish reviewers helpful comments 

international technology roadmap semiconductors 
public net files sia roadmap design pdf 
agarwal burger 
clock rate versus ipc road conventional microarchitectures 
international symposium computer architecture isca june 
allan reese jones randal lee stephen allan 
software pipelining 
acm computing surveys september 
bharadwaj mark horowitz 
speed power scaling 
ieee journal solid state circuits february 
andrew appel 
ssa functional programming 
acm sigplan notices april 
guido 
system level design 
design automation test europe date pages munich germany march 
arvind robert 
critique multiprocessing von neumann style 
international symposium computer architecture isca pages 
ieee computer society press 
david august wen mei hwu scott mahlke 
framework balancing control flow predication 
international symposium computer architecture isca december 
jonathan babb martin rinard walter lee matthew frank rajeev barua saman amarasinghe 
parallelizing applications silicon 
ieee symposium field programmable custom computing machines fccm 
daniel bailey bradley 
clocking design analysis mhz alpha microprocessor 
ieee journal solid state circuits november 
beck richard johnson keshav pingali 
control flow data flow 
journal parallel distributed computing 
kees van martin rem 
vlsi programming asynchronous circuits low power 
graham birtwistle davis editors asynchronous digital circuit design workshops computing pages 
springer verlag 
summary www cse ttu edu tw cheng courses soc ppt nat lab 
technical note nr 
ur philips research laboratories eindhoven netherlands 
brayton sangiovanni vincentelli 
logic minimization algorithms digital circuits 
kluwer academic publishers boston ma 
garside 
early output logic anti tokens 
international workshop logic synthesis pages may 
david brooks vivek tiwari margaret martonosi 
wattch framework architectural level power analysis optimizations 
international symposium computer architecture isca pages 
acm press 
mihai budiu 
spatial computation 
phd thesis carnegie mellon university computer science department december 
technical report cmu cs 
mihai budiu seth copen goldstein 
compiling application specific hardware 
international conference field programmable logic applications fpl pages montpellier la grande france september 
mihai budiu seth copen goldstein 
optimizing memory accesses spatial computation 
international acm ieee symposium code generation optimization pages san francisco ca march 
mihai budiu seth copen goldstein 
inter iteration scalar replacement presence conditional control flow 
technical report cmu cs carnegie mellon university department computer science 
mihai budiu mishra ashwin bharambe seth copen goldstein 
peer peer hardware software interfaces reconfigurable fabrics 
ieee symposium field programmable custom computing machines fccm pages napa valley ca april 
doug burger todd austin 
simplescalar tool set version 
computer architecture news volume pages 
acm sigarch june 
timothy callahan john wawrzynek 
instruction level parallelism reconfigurable computing 
hartenstein editors international conference field programmable logic applications fpl volume lecture notes computer science estonia september 
springer verlag 
jo cardoso markus 
vc compiler temporal partitioning pact architecture 
international conference field programmable logic applications fpl montpellier la grande france september 
lori carter beth simon brad calder larry carter jeanne ferrante 
predicated static single assignment 
international conference parallel architectures compilation techniques pact october 
lori carter beth simon brad calder larry carter jeanne ferrante 
path analysis renaming predicated instruction scheduling 
international journal parallel programming special issue 
caspi michael chu randy huang joseph yeh andr dehon john wawrzynek 
stream computations organized reconfigurable execution score tutorial 
international conference field programmable logic applications fpl lecture notes computer science 
springer verlag 
steven 
resynthesis peephole transformations optimization large scale asynchronous systems 
dac pages new york june 
acm press 
fred chow raymond lo shin ming liu sun chan mark 
effective representation aliases indirect memory operations ssa form 
international conference compiler construction cc pages april 

high speed way exploit intrinsic computational power silicon 
ieee international solid state circuits conference pages san francisco ca 
ieee catalog number ch 
keith cooper li xu 
efficient static analysis algorithm detect redundant memory operations 
workshop memory systems performance msp berlin germany june 

handel language manual 
flexible platform design design system october 
david culler arvind 
resource requirements dataflow programs 
international symposium computer architecture isca pages 
cytron ferrante rosen wegman zadeck 
efficiently computing static single assignment form control dependence graph 
acm transactions programming languages systems toplas 
ron cytron reid 
efficient accommodation may alias information ssa form 
acm sigplan conference programming language design implementation pldi pages 
acm press 
dally chang 
role custom design asic chips 
design automation conference dac los angeles ca june 
davis zhang camera yeo brodersen 
design environment high throughput low power dedicated signal processing systems 
ieee journal solid state circuits march 
andr dehon 
large scale spatial computing 
third international conference unconventional models computation 
jack dennis 
version data flow procedure language 
lecture notes computer science programming symposium pages 
springer verlag berlin new york 
pedro mary hall park ziegler 
bridging gap compilation synthesis defacto system 
workshop languages compilers parallel computing 
carl ebeling darren paul franklin jason stefan berg 
mapping applications rapid configurable architecture 
ieee symposium field programmable custom computing machines fccm 
edwards 
balsa asynchronous hardware synthesis language 
computer 
brian fields bod mark hill 
slack maximizing performance technological constraints 
international symposium computer architecture isca pages 
david mark gallagher 
memory disambiguation facilitate instruction level parallelism compilation 
phd thesis graduate college university illinois urbana champaign 
emden gansner stephen north 
open graph visualization system applications software engineering 
software practice experience 
www research att com sw tools graphviz 
guang gao 
pipelined code mapping scheme static data flow computers 
phd thesis mit laboratory computer science 
varghese george hui zhang jan rabaey 
design low energy fpga 
international symposium low power design islped pages 
acm press 
ghosh liao 
hardware synthesis 
design automation test europe date pages munich germany march 
gokhale marks 
automatic synthesis parallel programs targeted dynamically reconfigurable logic arrays 
moore luk editors international conference field programmable logic applications fpl pages oxford england august 
springer 
gokhale stone arnold 
stream oriented fpga computing streams high level language 
ieee symposium field programmable custom computing machines fccm pages 
seth copen goldstein mihai budiu 
spatial computing molecular electronics 
international symposium computer architecture isca pages teborg sweden 
seth copen goldstein herman schmit matthew moe mihai budiu srihari reed taylor ronald laufer 
piperench coprocessor streaming multimedia acceleration 
international symposium computer architecture isca pages atlanta ga 
gonzalez horowitz 
supply threshold voltage scaling low power cmos 
ieee journal solid state circuits august 
sumit gupta nick dutt rajesh gupta alex nicolau timothy kam michael shai rotem 
coordinated transformations high level synthesis high performance microprocessor blocks 
design automation conference dac pages 
acm press 
sumit gupta nick kim dutt rajesh gupta alexandru nicolau 
speculation techniques high level synthesis control intensive designs 
design automation conference dac pages 
ho mai horowitz 
wires 
ieee journal april 
hoare 
communicating sequential processes 
hoare jones ed essays computing science prentice hall 

james hoe arvind 
synthesis operation centric hardware descriptions 
ieee acm international conference computer aided design iccad san jose california november 
doug johnson 
programming xilinx fpga 
quarterly journal 
andrew kay yamada sakurai takashi 
hardware synthesis bach system 
ieee international symposium circuits systems iscas orlando 
brian kernighan dennis ritchie 
programming language 
software series 
prentice hall edition 
kung 
systolic architectures 
ieee computer 
monica lam robert wilson 
limits control flow parallelism 
international symposium computer architecture isca 
christopher laurie hendren 
extended ssa numbering introducing ssa properties languages multi level pointers 
international conference compiler construction volume lecture notes computer science pages march 
luciano lavagno ellen 
ecl specification environment system level design 
design automation conference dac pages new orleans la june 
lee potkonjak william mangione smith 
mediabench tool evaluating synthesizing multimedia communications systems 
ieee acm international symposium microarchitecture micro pages 
walter lee rajeev barua matthew frank jonathan babb vivek sarkar saman amarasinghe 
space time scheduling instruction level parallelism raw machine 
international conference architectural support programming languages operating systems asplos pages 
li tim callahan randolph harr jon 
hardware software design embedded reconfigurable architectures 
design automation conference dac 
stan liao steven tjiang rajesh gupta 
efficient implementation reactivity modeling hardware scenic design environment 
design automation conference dac pages 
andrew matthew lines 
pipelined asynchronous circuits 
master thesis california institute technology computer science department 
cs tr 
raymond lo fred chow robert kennedy shin ming liu peng tu 
register promotion sparse partial redundancy elimination loads stores 
acm sigplan conference programming language design implementation pldi pages 
acm press 
john lu keith cooper 
register promotion programs 
acm sigplan conference programming language design implementation pldi pages 
acm press 
scott mahlke richard james mccormick david august wen mei hwu 
comparison full partial predicated execution support ilp processors 
international symposium computer architecture isca pages santa margherita ligure italy may 
acm 
scott mahlke david lin william chen richard hank roger 
effective compiler support predicated execution hyperblock 
international symposium computer architecture isca pages dec 
ken mai tim ron ho william dally mark horowitz 
smart memories modular reconfigurable architecture 
international symposium computer architecture isca june 
martin 
programming vlsi communicating processes delay insensitive circuits 
hoare editor developments concurrency communication ut year programming series pages 
addison wesley 
alain martin mika karl paul prakash catherine wong jonathan chang kevin ko benjamin lee elaine ou james pugh ville james tong 
sub asynchronous microcontroller 
international symposium advanced research asynchronous circuits systems async may 
maruyama 
hdl compiler pipeline processing fpgas 
ieee symposium field programmable custom computing machines fccm 
may occam 
sigplan notices may 
giovanni de micheli 
hardware synthesis models 
design automation test europe date munich germany 
david muller 
theory asynchronous circuits 
international symposium theory switching functions pages 
karl ottenstein robert arthur maccabe 
program dependence web representation supporting control data demand driven interpretation imperative languages 
acm sigplan conference programming language design implementation pldi pages 
keshav pingali beck richard johnson paul 
dependence flow graphs algebraic approach program dependencies 
acm symposium principles programming languages popl volume 
rahul michael smith 
high performance microarchitecture hardware programmed functional units 
ieee acm international symposium microarchitecture micro pages november 
robert reese mitch thornton 
arithmetic logic circuits self timed bit level dataflow early evaluation 
international conference computer design iccd page austin tx september 
carter patel chawathe ross hm 
automated process compiling dataflow graphs hardware 
ieee transactions vlsi february 
scott william dally pez peter mattson john owens 
bandwidth efficient architecture media processing 
ieee acm international symposium microarchitecture micro december 
ray roth dinesh ramanathan 
high level design methodology 
ieee international high level design validation test workshop november 
nagarajan burger 
technology scalable architecture fast clocks high ilp 
workshop interaction compilers computer architecture january 
engels 
programming environment design complex high speed asics 
design automation conference dac pages san francisco june 
klaus schauser seth goldstein 
non strictness lenient programs require 
international conference functional programming languages computer architecture pages 
acm press 
schlansker conte ebcioglu fang thompson 
compilers instruction level parallelism 
ieee computer 
report cross industry task force ilp 
schreiber aditya gupta rau mahlke ra 
rau 
pico npa high level synthesis hardware accelerators 
journal vlsi signal processing 
luc ria sato giovanni de micheli 
synthesis hardware models pointers complex data structures 
ieee transactions vlsi 
greg snider barry richard carter 
attacking semantic gap application programming languages configurable hardware 
acm sigda international symposium field programmable gate arrays fpga pages 
acm press 
donald yuri 
implementing algorithms reconfigurable hardware verilog 
kenneth pocek jeffrey arnold editors ieee symposium field programmable custom computing machines fccm pages los alamitos ca april 
ieee computer society press 
bjarne steensgaard 
sparse functional stores imperative programs 
acm sigplan workshop intermediate representations pages 
ivan sutherland 
turing award lecture 
communications acm june 
steven swanson ken mark 

technical report washington university seattle computer science department january 
shibata miyazaki 
ling 
implementation evaluation compiler virtual hardware system 
international workshop parallel processing pages 
john 
static tokens dataflow automate pipeline synthesis 
international symposium advanced research asynchronous circuits systems async pages heraklion crete greece april 
herv touati mark shand 
library simulation generation xilinx fpga designs 
research compaq com src pamette pdf 

tsai vijaykrishnan irwin 
implications technology scaling leakage reduction techniques 
design automation conference dac san diego ca june 
kees van 
handshake circuits asynchronous architecture vlsi programming volume intl 
series parallel computation 
cambridge university press 
veen van den born 
rc compiler dtn dataflow computer 
journal parallel distributed computing 
arthur veen 
dataflow machine architecture 
acm computing surveys 
mihai budiu seth copen goldstein 
asynchronous dataflow circuits 
international workshop logic ca june 
john von neumann 
draft report 
contract 
ord moore school electrical engineering university pennsylvania philadelphia 
reprinted part randell brian 

origins digital computers selected papers springer verlag berlin heidelberg june 
okamoto 
soc design flow eda tools asic system vendor perspective 
ieee transactions computer aided design december 
agarwal lee smith lam athanas silverman ghosh 
prism ii compiler architecture 
ieee symposium field programmable custom computing machines fccm pages napa valley ca apr 
robert wilson robert french christopher wilson saman amarasinghe jennifer anderson steve tjiang shih wei liao chau wen tseng mary hall monica lam john hennessy 
suif infrastructure research parallelizing optimizing compilers 
acm sigplan notices volume pages december 
niklaus wirth 
hardware compilation translating programs circuits 
ieee computer june 
hutchings 
dynamic instruction set computer 
athanas pocek editors ieee symposium field programmable custom computing machines fccm pages napa ca april 
wittig chow 
fpga processor reconfigurable logic 
arnold pocek editors ieee symposium field programmable custom computing machines fccm pages napa ca april 
alex zhi ye andreas scott hauck banerjee 
chimaera high performance architecture tightly coupled reconfigurable unit 
international symposium computer architecture isca acm computer architecture news 
acm press 
ning zhang bob brodersen 
cost flexibility systems chip design signal processing applications eecs berkeley edu classes ee papers arch design doc spring 
