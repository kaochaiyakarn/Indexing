proceedings auditory visual speech processing tutorial research workshop pp 
st france september joint audio visual speech processing recognition enhancement potamianos neti sabine deligne visual speech information speaker mouth region long viewed source improving robustness naturalness human computer interfaces hci 
information particularly crucial realistic hci environments acoustic channel corrupted result performance traditional automatic speech recognition asr systems falls usability levels 
review general approaches utilize visual speech improve asr acoustically challenging environments directly combines features extracted acoustic visual channels aiming superior recognition performance resulting audio visual asr system 
seeks eliminate noise acoustic features aiming audio visual enhancement resulting improved speech recognition 
number techniques introduced literature bimodal asr enhancement study performance suitable audio visual database 
methods considered recognition experiments demonstrate decision combination audio visual features significantly outperforms simpler feature integration methods audio visual asr 
audio feature enhancement non linear technique successful regression approach 
expected bimodal asr enhancement outperform audio counterparts 

human speech nature bimodal production perception 
example visual modality benefit speech intelligibility noise quantified far back fact humans integrate audio visual stimuli perceive speech demonstrated effect 
visual channel plays major role human human speech communication helps speaker localization contains speech segmental information supplements audio provides complimentary information place articulation 
addition number studies literature quantified fact exists significant correlation lower face movements produced acoustic signal 
motivated facts past years researchers investigating integration visual modality speech channel human hci aiming improving robustness naturalness 
various important hci components speaker identification verification localization speech event detection speech signal separation coding video indexing retrieval text speech shown benefit visual channel 
bulk bimodal speech research starting petajan concentrated field auto ibm watson research center yorktown heights ny usa ibm com matic speech recognition asr 
asr represents crucial hci component traditional audio form significantly lags performance respect human speech perception 
addition lacks robustness acoustic degradation spite number techniques introduced literature compensate noise 
visual speech hand provides source information orthogonal audio input obviously affected acoustic noise 
surprisingly audio visual asr av asr systems utilize speech information channels demonstrated significantly improve asr robustness noise tasks continuous speech recognition lvcsr 
indirect approach improve asr performance noise visual modality investigated means noisy acoustic signal feature enhancement 
number traditional audio enhancement techniques extended incorporate visual speech information starting 
linear non linear methods shown successfully enhance audio features corrupted noise 
review audio visual asr audio feature enhancement compare speech recognition performance number representative techniques suitable audio visual database 
detail section gives brief speech informative visual feature extraction particular emphasis appearance visual front audio visual system 
section devoted av asr various audio visual integration methods discussed framework hidden markov models 
methods grouped general categories feature decision hybrid fusion 
section follows presentation linear non linear approach bimodal audio feature enhancement 
comparative experimental study discussed techniques subsequently section concludes short discussion 

visual front prerequisite performing audio visual asr enhancement successful extraction visual features informative spoken utterance 
various possibilities exist visual front design briefly discussed followed particular implementation system 

taxonomy components visual front visual speech features generally fit categories appearance features shape ones combination 
assume video pixels region interest roi informative spoken utterance 
allow speech classification consider linear transforms roi pixel values resulting proceedings auditory visual speech processing tutorial research workshop pp 
st france september face facial part detection roi extraction example video frame 
left right original frame eleven detected facial parts super imposed face area enhanced frame normalized roi 
feature vectors reduced dimensionality contain relevant speech information 
contrast shape feature extraction assumes information contained contours speaker lips generally face 
category belong geometric type features mouth height width area fourier descriptors lip image moments statistical models shape active shape models parameters lip tracking models 
features categories concatenated joint shape appearance vector joint statistical model learned vectors case active appearance model 
clearly number video pre processing steps required mentioned visual feature extraction techniques commence 
step face facial part detection needed drive roi extraction see fig 
face detection attracted significant interest literature constitutes difficult problem especially cases background head pose lighting varying 
course face detection unnecessary properly head mounted video camera directly provide roi 
hand shape visual features extracted additional step lip possibly face shape estimation required 

audio visual features system visual front employed system produces appearance features operates full face video artificial face markings 
result face detection roi extraction required 
detail video spoken utterance stage statistical face tracking algorithm detect speaker face subsequently locate facial features eleven features depicted fig 
stage normalized face facial feature candidate vectors scored class fisher discriminant projection residual appropriately defined eigenspace 
highest score candidates retained detected faces facial features 
algorithm requires training small number manually annotated faces 
tracking provides mouth location size orientation smoothed time improve robustness 
resulting estimates pixel roi obtained video frame 
contains lower face speaker mouth properly normalized compensate rotation size lighting variations see fig 
subsequently dimensional separable discrete cosine transform dct applied roi dct coefficients retained 
reduce dimensionality improve discrimination speech classes linear discriminant analysis lda projection applied resulting dimensional feature vector 
followed maximum likelihood linear transformation mllt improves maximum likelihood statistical data mod audio msec extra ction msec shift hz feature audio front mean zation video face detection roi extraction processing hz inter hz feature mean zation visual front frames frames block diagram front av asr 
algorithm generates time synchronous dimensional audio feature vectors dimensional visual observations hz rate 
eling 
facilitate audio visual fusion linear interpolation employed synchronizes features hz rate audio counterpart feature mean normalization compensate lighting variations providing visual static features 
fifteen consecutive features concatenated projected rotated means interframe lda mllt combination giving rise dynamic visual features ov dimension lv see fig 
addition visual features time synchronous audio features extracted hz 
mel frequency cepstral coefficients mfcc speech signal computed sliding window msec mean normalized provide static features 
consecutive frames concatenated projected means lda mllt dynamic audio features oa dimension la 

audio visual asr audio visual integration aims combining available speech informative streams bimodal classifier superior performance audio visual recognition 
various information fusion algorithms considered av asr differing basic design speech classification technology adopted terminology 
solely consider traditional hidden markov model hmm approach asr employs acoustic speech classes gaussian mixture densities class conditional probabilities feature observations interest 
number viable alternatives hybrid hmm neural network support vector machine asr architectures possibly speech classes discussed 
adopt broad grouping audio visual integration techniques feature fusion decision fusion methods 
training single classifier form audio visual ones concatenated vector audio visual features appropriate transformation 
contrast decision fusion algorithms utilize single modality audio visual classifier outputs recognize audio visual speech 
typically achieved linearly combining class conditional observation log likelihoods classifiers joint audiovisual score appropriate weights capture reliability single modality data stream 
addition proceedings auditory visual speech processing tutorial research workshop pp 
st france september categories exist techniques combine characteristics 
consider hybrid fusion method see fig 
presentation techniques initially assumes early temporal level audio visual integration hmm state 
called asynchronous models fusion discussed section 

feature fusion audio visual feature fusion techniques include plain feature concatenation feature weighting known direct identification fusion hierarchical discriminant feature extraction dominant motor recording fusion 
seek data data mapping visual features audio space modality features new common space followed linear combination resulting features 
briefly review feature fusion methods 
time synchronous audio visual feature vectors concatenative feature fusion considers oa ov lav lav la lv joint audio visual observation interest 
sequence features assumed generated single stream hmm class conditional observation probabilities os ks ws nl os ms ss speech classes wheres av ks mixture weights ws positive add nl denotes variate normal distribution mean diagonal covariance matrix practice lav large causing inadequate modeling due curse dimensionality insufficient data 
discriminant feature fusion aims remedy applying lda projection concatenated vector projection results lower dimensional representation seeking best discrimination speech classes interest 
lda followed mllt rotation feature vector improve statistical data modeling means 
transformed audio visual feature vector denoted od fig designed dimension audio observation ld la concatenative discriminant feature fusion implementable existing asr systems minor changes due single stream hmms 
required hmm parameters estimated expectation maximization em algorithm available training data 

decision fusion feature fusion techniques result improved asr audio performance explicitly model reliability modality practice varies 
decision fusion framework hand provides mechanism capturing reliabilities borrowing classifier combination theory 
av asr commonly audio visual classifiers combined parallel architecture adaptive combination weights class score level information 
approach derives speech class word sequence linearly combining single modality classifier decisions appropriate weights known separate identification model 
audio front visual front av decision fusion hmm state os hybrid fusion od feature fusion representative techniques fusion categories considered av asr 
case single stream hmms set speech classes states audio classification type likelihood combination considered frame hmm state level modeled means multi stream hmm 
stream hmm state dependent emission audio visual observation vector governed see av hmm states notice implies linear combination log likelihood domain represent probability distribution general 
denote stream exponents weights non negative model stream reliability function modality utterance frame typically set global modality dependent values works investigate dependence hmm state utterance frame 
assume global exponents constrained add 
estimated simple grid search minimize word error rate held set 
alternatively discriminative training 
remaining hmm parameters estimated separately stream em algorithm jointly step 
scheme enforces state synchrony training preferable 

hybrid fusion certain feature fusion techniques example discriminant fusion outperform audio visual asr 
natural utilize od stream multi stream decision integration combining feature decision fusion framework 
consider hybrid approaches generalizing stream hmm av fa dg ors fa dg case obtain stream hmm added stream discriminant features od second case retain stream hmm replacing speech informative visual stream superior discriminant audio visual feature stream 
discussed exponents constrained parameter estimation hmm components performed separately jointly 
schematic representation hybrid fusion depicted fig 

audio visual asynchrony fusion presentation decision hybrid fusion assumed early temporal level hmm states combining stream likelihoods interest see 
asr sequences classes hmm states words need proceedings auditory visual speech processing tutorial research workshop pp 
st france september audio hmm states visual hmm states composite hmm states phone synchronous state asynchronous stream hmm states phone modality 
equivalent product composite hmm 
single stream emission probabilities tied states row column corresponding audio visual state probabilities form 
estimated coarser levels combining stream likelihoods envisioned 
late level integration utterance typically number best hypotheses vocabulary words case isolated word recognition stream log likelihoods independently computed entire utterance 
example late fusion discriminative model combination technique applied av asr 
alternatively phone syllable word boundary provide intermediate 
scheme typically implemented means product hmm discussed 
notice approaches permit asynchrony hmm state sequences streams interest providing means model actual audio visual signal asynchrony observed practice order msec 
product hmm generalization state synchronous multi stream hmm combines stream log likelihoods intermediate level assumed phone 
resulting phone synchronous product hmm allows single stream hmm components asynchrony phone forcing synchrony phone boundaries 
consists composite states cs sg emission scores similar av cs example model depicted fig typical case audio visual stream states phone stream 
notice stream components correspond emission probabilities certain single stream states tied demonstrated fig 
compared corresponding state synchronous multi stream hmm product hmm utilizes number mixture weight mean variance parameters 
hand number transition probabilities composite states larger 
probabilities states factored jc case resulting model referred coupled hmm 

bimodal enhancement audio features addition improving asr visual modality investigated means noisy audio enhancement 
example propose estimating clean audio features linear prediction model coefficients subsequently clean audio signal visual speech information consider estimating features audio visual speech audio channel corrupted noise 
approach proves feasible due fact audio visible speech produced oral facial cavity correlated 
audio feature estimation visual input demonstrated 
clearly audio visual asr audio visual speech enhancement differ aims methodologies expects lead improved recognition performance noisy audio asr system 
furthermore enhancing noisy audio features enable clean audio statistical models asr wide variety noisy environments avoiding statistical model training storage 
interest study effects audio visual speech enhancement asr compare resulting system performance traditional audio visual asr 
section summarize techniques enhancing noisy audio features bimodal data 
method linear algorithm reported 
enhances noisy audio features means linear filter transform applied concatenated vector noisy audio visual features 
similarly filter obtained mean square error mse estimation clean audio feature training data 
interested asr consider problem obtaining enhanced speech enhanced audio features 
linear prediction coefficients audio features system 
second technique introduced non linear 
constitutes extension audio enhancement method known codebook dependent cepstral normalization cdcn visual modality utilized improve estimation correction term applied noisy audio features 
resulting method referred audio visual codebook dependent cepstral normalization avcdcn 
alternative non linear enhancement technique neural networks reported 

linear bimodal enhancement audio features addition speech information audio feature vector oa extracted front section captures environment noise 
hope remove interference produce en audio features denote la joint audio visual speech information captured vector 
resulting enhanced audio features supplied asr system hopefully yielding improved recognition noisy observations oa seek obtain enhanced audio observa tions linear transformation joint audio visual feature vector av matrix av av av av dimen sion lav la columns consisting lav dimensional vectors av fori la estimate matrix av assume addition clean audio feature vectors denoted available number instants training set seek estimate enhancement matrix set euclidean distance sense 
due equivalent solving la mse estimations pav arg min la column matrix av equations proceedings auditory visual speech processing tutorial research workshop pp 
st france september result la systems yule walker equations lav pav lav denotes th element vector pav th element feature vector os gauss jordan elimination solve 

audio visual cdcn audio feature enhancement demonstrated section asr performance linear enhancement approach mediocre recognition improves compared audio asr noisy acoustic observations performance remains inferior av asr means discriminant feature fusion example 
break barrier non linear techniques required 
method avcdcn introduced 
technique inspired cdcn popular audio non linear enhancement approach 
cdcn non linear effect noise clean speech features approximated piece wise constant function 
avcdcn multi sensor extension cdcn integrates audio visual features 
experiments show visual information avcdcn allows significant performance gains cdcn feature fusion av asr hmms trained clean acoustic environment 
cdcn technique seeks compute enhanced audio features expected value observed noisy audio features oa 
fact oa oa non linear function clean audio corrupting noise nt oa nt oa novelty avcdcn visual modality features ov addition traditional acoustic vector oa accurately estimate correction term applied 
oa nt lack knowledge nt approximate sum pre defined codebook audio compensation terms fa computed discussed 
avcdcn yields oa kx fa audio counterpart cdcn defined oa kx fa oa note avcdcn cdcn identical audio compensation codewords avcdcn takes advantage example video frames corpus considered audio visual recognition enhancement large vocabulary continuous speech upper row connected digits lower row 
visual information estimate posterior distribution codewords follows 
codebook posterior distribution computed assuming probability density function pdf mixture gaussians priors means covariances wk mk sk bayes rule wk nl mk sk av pk wk mk sk experiments codebook audio pdf parameters noisy audio visual features estimated stereo training data audio computed minimizing mse oa set fa oa maximum likelihood estimates means covariances noisy audio visual features computed assuming equal priors mk sk mk mk posteriors computed assuming pdf clean audio features mixture gaussians equal priors means covariances maximum likelihood estimates computed standard em algorithm clean audio training data 
cdcn baseline means covariances noisy audio features computed replacing oa 

experiments far discussed number techniques audiovisual asr bimodal enhancement audio features 
proceed report speech recognition experiments suitable audio visual database algorithms 
discuss corpus briefly introduce experimental paradigm adopted subsequent detailed presentation results 

audio visual database contrast abundance audio corpora exist databases suitable bimodal asr research 
small contain subjects address simple recognition tasks small vocabulary asr isolated connected words 
proceedings auditory visual speech processing tutorial research workshop pp 
st france september task set utter 
dur 
sub 
train lvcsr check test train digit check test table corpus partitioning training check held test sets large vocabulary continuous speech lvcsr connected digit digit recognition experiments section number utterances duration hours number subjects shown 
help bridge growing gap audio av asr corpora collected ibm tm audio visual database large corpus suitable audio visual lvcsr 
corpus consists frontal video audio subjects see fig uttering tm training scripts continuous read speech verbalized punctuation dictation style vocabulary 
data collected quiet studio environment 
detail video pixel size interlaced captured color rate hz fields second available resolution lines mpeg encoded relatively high compression ratio 
high quality wideband audio synchronously recorded rate khz signal ratio snr db 
addition lvcsr data collected smaller subject set containing utterances digit connected strings zero oh 
recorded conditions lvcsr set referred digit corpus 

experimental paradigm single stream hmm recognition tasks state left right phone hmms context dependent classes states 
classes obtained means decision trees cluster contexts spanning phones side current phone order better model coarticulation improve asr performance 
digit lvcsr decision trees estimated clean audio corresponding database training set bootstrapping previously developed audio hmm corresponding front provides data class labels forced alignment 
subsequently means clustering estimate audio hmms correspond newly developed trees 
bootstrapping models parameters hmms considered estimated required front ends 
total number resulting context dependent hmm states digit task corresponding phones approximately lvcsr phones 
single stream hmms identical number gaussian mixture components digit lvcsr tasks respectively 
decision trees initial digit lvcsr audio hmms developed proceed estimate parameters single stream hmms model visual audio visual feature sequences number audio channel conditions 
original clean database audio approximately db snr noisy conditions speech babble noise artificially added various snrs considered 
em algorithm iterations training step iteration employing initial audio hmm bootstrapping 
appropriate single number subjects word error rate wer word error rate wer visual asr digit test set depicted rate histogram subjects achieved visual hmms trained speaker independent left multi speaker fashion right 
stream hmms joined form decision hybrid fusion models section stream exponents set global values estimated held sets table 
joint stream hmm training considered 
av asr results reported recognition matched test data snr training 
digit task decoding simple digit word loop grammar unknown string length lvcsr trigram language model 
cases stage stack decoding algorithm employed 
lvcsr results digit recognition multi speaker 
bimodal enhancement audio features stereo pair data consisting noisy audio visual clean audio observations available training sets table 
linear approach section regression matrix computed snr interest applied bimodal input 
recognition performance resulting enhanced audio features compared audio discriminant feature asr 
av cdcn computation pdf characterizing clean speech audio channel training set required 
set audio compensation codewords pdf characterizing noisy audio visual speech noisy audio speech case audio cdcn estimated snr condition 
pdfs noisy speech estimated features output audio visual lda mllt transform avcdcn features output audio lda mllt transform cdcn 
decoding test set acoustic features enhanced avcdcn cdcn posterior probabilities computed features output lda mllt transforms pdfs noisy speech matching snr level consideration 
avcdcn cdcn enhancement strategies evaluated various sizes codebooks number snr levels audio audio visual asr 
benchmarked audio audio visual asr enhancement 
furthermore report recognition experiments lda mllt transforms producing features sent decoder hmms decoder trained clean training data re trained enhanced noisy training data matching snr level consideration 

visual recognition compared traditional acoustic asr clean environment recognition basis visual information performs poorly 
example visual word error rate wer lvcsr task digit 
results improve speaker adaptation maximum likelihood linear regression respectively 
performance varies significantly subjects demon proceedings auditory visual speech processing tutorial research workshop pp 
st france september word error rate wer db gain audio feature fusion av concat 
feature fusion av discr 
decision fusion av ms au vi sep train 
decision fusion av ms au vi joint train 
hybrid fusion av ms au vi av discr 

fusion av prod au vi joint train 
signal noise ratio snr db audio audio visual asr digit test set integration strategies section 
cases wer depicted vs audio channel snr 
effective snr gain product hmm shown reported audio wer db 
hmms trained matched noise conditions 
fig 
wer histogram digit dataset subjects depicted speaker independent multi speaker visual hmms 
clearly visual features provide speech information albeit weak 
course combination audio counterpart interest demonstrated 

audio visual asr experiments proceed investigate visual feature benefit asr 
lvcsr connected digit recognition consider acoustic conditions wide range snrs discussed section compare fusion strategies section terms resulting effective snr gain asr 
measure gain audio wer db considering snr value audio visual wer equals audio wer 
performance integration algorithms digit set summarized fig 
detail compare av asr means feature fusion methods section 
clear fig concatenative discriminative feature fusion significantly improve asr performance low snrs somewhat superior yielding approximate db effective snr gain 
example db snr discriminant fusion av asr results wer representing vast improvement wer 
notice feature fusion fails alter performance high snr range considered 
hand decision audio visual integration means state synchronous stream hmm discussed section consistently improves performance snrs 
particular joint stream training model clearly preferable outperforming separate stream training discriminant feature fusion yielding db effective snr gain 
improvements db obtained hybrid fusion approach section utilizes discriminant audio visual features additional stream hmm 
introducing state asynchrony decision fusion results gains 
jointly trained product hmm achieves approximately db snr gain exhibiting db performance audio asr cleaner word error rate wer db gain audio feature fusion av discr 
decision fusion av ms au vi hybrid fusion av ms au av discr 
signal noise ratio snr db audio audio visual wer lvcsr test set discriminant feature fusion stream hmms decision hybrid fusion various snr levels matched training 
acoustic environment db 
notice db snr product hmm yields wer corresponds improvement discriminant feature fusion audio asr 
remarkably original database audio db best audio visual wer represents wer reduction wer see fig 
large percentage gain due joint estimation product hmm parameters appropriate tying composition product hmm separately trained single stream models achieves inferior wer 
lvcsr performance number fusion techniques summarized fig 
similarly results digit set hybrid fusion outperforms decision integration turn superior discriminant feature fusion audio asr 
simplicity hmm considered hybrid fusion audio visual discriminant features place visual stream 
resulting system achieves approximately db effective snr gain audio asr db 

bimodal enhancement experiments demonstration visual modality benefit asr investigate usefulness enhancement noisy audio features 
simple way quantify benchmarking asr performance resulting enhanced features bimodal asr results reported 
consider linear approach section 
fig demonstrates enhanced audio features significantly outperform noisy audio asr matched training testing fail reach performance system discriminatively combines audio visual features 
investigated audio enhancement technique capture full benefit visual modality asr 
observation holds digit lvcsr tasks 
consider non linear enhancement technique section 
fig shows wer obtained avcdcn audio asr scheme decreases consistently snr values size codebook increased codewords 
plotted obtained audio audio visual asr scheme feature enhancement 
avcdcn outperforms proceedings auditory visual speech processing tutorial research workshop pp 
st france september word error rate wer enhanced audio av discr 
digit task signal noise ratio snr db enhanced av discr 
audio lvcsr task signal noise ratio snr db test set wer noisy audio audio visually linearly enhanced audio discriminant audio visual features depicted audio channel snr connected digit asr left lvcsr right 
word error rate wer au dec av dec avcdcn au dec avcdcn au dec avcdcn au dec avcdcn au dec avcdcn au dec avcdcn au dec signal noise ratio snr db audio asr avcdcn enhanced features various codebook sizes 
plotted audio channel snr 
comparison performance audio audio visual asr discriminant feature fusion depicted 
hmms trained clean data 
audio asr scheme regardless codebook size interestingly discriminant feature fusion codebooks size higher 
fig compares avcdcn cdcn audio audio visual asr schemes codebook size 
fig shows obtained recognition systems trained original clean training data 
fig shows obtained recognition systems retrained noisy training data matching snr level consideration enhancement ii cdcn enhanced avcdcn enhanced noisy training data matching snr level consideration cdcn avcdcn 
systems retrained fig avcdcn performs significantly better cdcn audio audio visual asr schemes 
performance gains obtained avcdcn audio visual asr add avcdcn combined audio visual asr significantly outperforms audio visual asr avcdcn combined audio asr 
retraining systems fig improves performances strategies 
avcdcn better cdcn audio asr scheme 
avcdcn audio visual asr outperforms avcdcn audio asr 
hand performances audio visual asr enhancement cdcn avcdcn similar 

summary discussion provided overview number techniques necessary automatic recognition audio visual speech enhancement noisy audio features basis audio visual observations 
discussed visual front captures speech information video signal shared 
av asr number fusion techniques popular hidden markov model framework 
covered methods integrate speech information feature classification score level hybrid fusion algorithm combines benefits approaches 
addition discussed asynchrony modeling audio visual fusion argued joint training properly tied parameters resulting model 
best technique utilizing product hidden markov model resulted effective snr gain db connected digit recognition 
best achieved gain large vocabulary task somewhat inferior reaching approximately db 
subsequently investigated effects asr enhancing noisy audio features means audio visual speech data 
considered enhancement performed linear filters applied concatenated audio visual feature vectors 
method resulted large improvements asr original noisy audio features small recognition 
compared audio visual discriminant feature fusion enhancement approach fared significantly worse 
discussed generalization cdcn non linear audio enhancement technique benefit availability visual channel 
resulting avcdcn method shown provide significant performance gains cdcn audio audio visual asr schemes 
proceedings auditory visual speech processing tutorial research workshop pp 
st france september word error rate wer hmms trained au dec clean data av dec cdcn au dec cdcn av dec avcdcn au dec avcdcn av dec signal noise ratio snr db word error rate wer hmms retrained au dec matched data av dec cdcn au dec cdcn av dec avcdcn au dec avcdcn av dec signal noise ratio snr db audio audio visual asr means discriminant feature fusion noisy features cdcn avcdcn enhanced features hmms trained clean data hmms trained noisy enhanced features matching snr level consideration 
clearly demonstrates past years progress accomplished capturing integrating visual information speech recognition process 
visual modality utilized mainstream asr systems 
due fact issues practical research nature remain challenging 
practical side things high requirements captured video frame rate size necessary extracting visual speech information capable enhancing asr performance place increased demands cost storage computer processing 
addition lack common large audio visual corpora address wide variety asr tasks conditions environments hinders development audio visual systems suitable particular applications 
research side key issues design audiovisual recognition systems remain open subject investigation 
visual front example face facial feature face shape tracking robust unconstrained speaker pose lighting environment variation constitutes challenging problem 
combining audio visual information number issues relevant decision fusion require study optimal level integrating audio visual log likelihoods optimal function integration robust modeling channel reliability 
utilizing visual modality improved audio feature enhancement investigation avcdcn performance unseen training noise types levels interest 
research issues clearly warranted expected lead improving value audio visual speech design robust natural human computer interaction systems 

authors guillaume roland andrew senior contributing 

eds humans machines 
berlin germany springer 
campbell dodd eds hearing eye ii 
hove united kingdom psychology press publishers 
pollack visual contribution speech intelligibility noise acoustical society america vol 
pp 

macdonald hearing lips seeing voices nature vol 
pp 

summerfield preliminaries comprehensive account audio visual speech perception hearing eye psychology lip reading campbell dodd eds 
london united kingdom lawrence erlbaum associates pp 

massaro stork speech recognition sensory integration american scientist vol 
pp 

rubin quantitative association vocal tract facial behavior speech commun vol 
pp 

barker estimation speech acoustics visual speech features comparison linear nonlinear models proc 
conf 
audio visual speech processing santa cruz ca aug pp 

mason review speech bimodal recognition ieee trans 
multimedia vol 
pp 
mar 
zhang clements automatic applications human computer interfaces eurasip appl 
signal processing vol 
pp 
nov 
davis joint audio visual tracking particle filters eurasip appl 
signal processing vol 
pp 
nov 
de neti senior audio visual intent speak detection human computer interaction proc 
int 
conf 
acoust speech signal processing istanbul turkey june pp 


schwartz jutten separation audio visual speech sources new approach exploiting audio visual coherence speech stimuli eurasip appl 
signal processing vol 
pp 
nov 
feng audiovisual speech coder vector quantization exploit audio video correlation proc 
conf 
audio visual speech processing australia dec pp 

huang liu wang chen wong integration multimodal features video scene classification hmm proc 
works 
multimedia signal processing copenhagen denmark sept pp 

proceedings auditory visual speech processing tutorial research workshop pp 
st france september cohen massaro visual speech synthesis tell visual speech recognition proc 
asilomar conf 
signals systems computers pacific grove ca 
graf photo realistic talking heads image samples ieee trans 
multimedia vol 
pp 
sept 
petajan automatic lipreading enhance speech recognition proc 
global 
conf atlanta ga pp 

lippmann speech recognition machines humans speech commun vol 
pp 

stern 
liu signal processing robust speech recognition automatic speech speaker recognition 
advanced topics 
lee eds 
norwell ma kluwer academic pub ch 
pp 

stern environmental robustness automatic speech recognition proc 
int 
conf 
acoust speech signal processing albuquerque nm pp 

deng jiang huang highperformance robust speech recognition stereo data proc 
int 
conf 
acoust speech signal processing salt lake city ut may pp 

meier waibel see hear integrating automatic speech recognition lip reading proc 
int 
conf 
spoken lang 
processing yokohama japan sept pp 

integration auditory visual parameters hmm asr humans machines stork eds 
berlin germany springer pp 

stork prasad visionary speech looking ahead practical systems humans machines eds 
berlin germany springer pp 

neti potamianos luettin matthews zhou audio visual speech recognition center language speech processing johns hopkins university baltimore md final workshop report oct 
potamianos neti garg senior advances automatic recognition audio visual speech proc 
ieee appear 
jr proakis hansen discrete time processing speech signals 
englewood cliffs nj macmillan publishing 
feng 
schwartz noisy speech enhancement filters estimated speaker lips proc 
europ 
conf 
speech commun 
technol madrid spain sept pp 


schwartz feng audio visual enhancement speech noise acoustical society america vol 
pp 

potamianos neti noisy audio feature enhancement audio visual speech data proc 
int 
conf 
acoust speech signal processing orlando fl may pp 

deligne potamianos neti audio visual speech enhancement avcdcn audio visual codebook dependent cepstral normalization proc 
int 
conf 
spoken lang 
processing denver sept pp 

bregler konig robust speech recognition proc 
int 
conf 
acoust speech signal processing adelaide australia apr pp 

potamianos graf image transform approach hmm automatic lipreading proc 
int 
conf 
image processing vol 
chicago il oct pp 

patterson application affine invariant fourier descriptors lipreading audiovisual speech recognition proc 
int 
conf 
acoust speech signal processing salt lake city ut may pp 

luettin thacker probabilistic models computer vision image understanding vol 
pp 

multiple deformable template approach visual speech recognition proc 
int 
conf 
spoken lang 
processing philadelphia pa oct pp 

chan hmm audio visual speech recognition integrating geometric appearance visual features proc 
works 
multimedia signal processing cannes france oct pp 

dupont luettin audio visual speech modeling continuous speech recognition ieee trans 
multimedia vol 
pp 
sept 
rowley baluja kanade neural networkbased face detection ieee trans 
pattern anal 
machine intell vol 
pp 
jan 
senior face feature finding face recognition system proc 
int 
conf 
audio video biometric person authentication washington dc mar pp 

huang potamianos neti improving audio visual speech recognition infrared headset isca tut 
res 
works 
audio visual speech processing st france sept 
robert schwartz comparing models audiovisual fusion noisy vowel recognition task ieee trans 
speech audio processing vol 
pp 
nov 
heckmann noise adaptive stream weighting audio visual speech recognition eurasip appl 
signal processing vol 
pp 
nov 
pitas support vector machine dynamic network visual speech recognition applications eurasip appl 
signal processing vol 
pp 
nov 
discriminative learning visual data audiovisual speech recognition int 
artificial intell 
tools vol 
pp 

potamianos graf discriminative training hmm stream exponents audio visual speech recognition proc 
int 
conf 
acoust speech signal processing seattle wa may pp 

jain duin mao statistical pattern recognition review ieee trans 
pattern anal 
machine intell vol 
pp 
jan 
bourlard dupont new asr approach independent processing recombination partial frequency bands proc 
int 
conf 
spoken lang 
processing philadelphia pa oct pp 

word dependent acoustic labial weights speech recognition proc 
europ 
tut 
works 
audio visual speech processing rhodes greece sept pp 

nakamura ito shikano stream weight optimization speech lip image sequence audio visual speech recognition proc 
int 
conf 
spoken lang 
processing vol 
iii beijing china oct pp 

chu huang audio visual speech modeling coupled hidden markov models proc 
int 
conf 
acoust speech signal processing orlando fl may pp 

liang pi liu murphy dynamic bayesian networks audio visual speech recognition eurasip appl 
signal processing vol 
pp 
nov 
