finite state approaches web information extraction nicholas kushmerick computer science department university college dublin email nick ucd information agents emerging important approach building generation value added information services 
information agent distributed system receives goal user interface gathers information relevant goal variety sources processes content appropriate delivers results users 
focus second stage generic architecture 
survey variety information extraction techniques enable information agents automatically gather information heterogeneous sources 
example consider agent mediates package delivery requests 
satisfy requests agent need retrieve address information geographic services ask advertising service freight forwarders serve destination request quotes relevant freight forwarders retrieve duties legal constraints government sites get weather information estimate transportation delays information extraction form shallow document processing involves populating database values automatically extracted documents 
past decade researchers developed rich family generic techniques suitable wide variety sources rigidly formatted documents html generated automatically template natural language documents newspaper articles email messages 
chapter view information extraction core enabling technology variety information agents 
focus specifically information extraction tangential albeit important issues agents discover relevant sources verify authenticity retrieved content caching policies minimize communication ensuring freshness 
proceeding observe xml eliminate need automatic information extraction 
terabytes content available numerous legacy services probably export data xml 
second impossible determine correct annotation scheme applications idiosyncratic needs unit currency included extracting prices people names split surname dates sun 
may canonicalized 
reasons expect automatic information extraction continue essential years 
scalability key challenge automatic information extraction 
relevant dimensions 
dimension ability rapidly process large document collections 
systems generally scale regard rely simple shallow extraction rules sophisticated slow natural language processing 
second problematic dimension number distinct sources 
example package delivery agent need request quotes different freight forwarders weather information dozens forecast services challenging scenario source format content differently source require customized set extraction rules 
machine learning domain independent approach scaling second dimension 
chapter focuses machine learning enable adaptive information extraction systems automatically learn extraction rules training data order scale number sources 
general idea adaptive information extraction human expert annotates small corpus training documents fragments extracted learning system generalizes examples produce form knowledge rules reliably extract similar content documents 
human annotated training data expensive assumption underlying adaptive easier annotate documents write extraction rules requires degree programming expertise 
furthermore describe techniques aimed minimizing amount training data required generalization eliminating need manual annotation entirely 
adaptive information extraction research community developed wide variety techniques approaches tailored particular extraction tasks document types 
approaches web information extraction categorized finite state approaches learned extraction knowledge structures formally equivalent possibly stochastic regular grammars automata 
survey prominent examples additional research relates entire wrapper life cycle core learning task section introduces wrapper induction approach adaptive tailored highly regular web documents section describes variety expressive extensions basic wrapper induction framework section explores finite state techniques natural language documents section describes hidden markov models adaptive section discusses approaches wrapper verification maintenance central issues long term lifecycle adaptive systems section describes technique post processing extracted fragments coherent meaningful objects section explains active learning techniques minimize amount manually annotated training data required accurate generalization 
sake brevity describe techniques detail see information ideas 
wrapper induction kushmerick formalized adaptive web information extraction wrapper induction 
kushmerick identified family wrapper classes demonstrated wrappers relatively expressive learn wrappers numerous real world web sites relatively efficient handful training examples cpu seconds example needed learning 
illustrate kushmerick wrapper induction consider example web page shown html encoding content extracted 
example clearly extremely simple exhibits features salient discussion 
kushmerick wrappers consist sequence delimiters strings finding desired content 
simplest case shown content arranged tabular format columns wrapper scans pair delimiters column total delimiters 
notation indicates left hand delimiter th column rk th column right hand delimiter 
case country code wrapper ccwrap lr 
execute wrapper procedure ccwrap lr scans string document scans ahead occurrence 
procedure extracts text positions value column row 
procedure scans extracts text positions value second column row 
process starts extraction terminates missing indicating document 
formalizes ideas left right lr wrapper class 
lr wrapper consists set rk delimiters pair column extracted operational semantics lr provided execlr procedure 
procedure scans document scans ahead occurrence 
procedure extracts text positions value column row 
ccwrap lr scans extracts text positions value second column row 
process repeated columns 
searching rk procedure starts extraction terminates missing indicating document 
definition lr machine learning task automatically construct lr wrapper set training documents 
lr learning relatively efficient delimiters learned independently 
key insight particular candidate valid delimiter impact delimiters 
observation kushmerick describes quadratic time algorithm learning lr wrappers 
algorithm simply enumerates potential values delimiter selecting satisfies constraint guarantees wrapper correctly training data 
kushmerick demonstrates empirically theoretically pac model algorithm requires modest training sample converge correct wrapper 
course just efficient learning algorithm exists mean wrappers useful 
discuss limitations lr class show handle documents complicated formatting 
simple lr class able successfully wrap web sites survey 
html title country codes title body congo br egypt br br spain br body html congo egypt spain procedure ccwrap lr page occurrences rk scan occurrence save position start th attribute scan occurrence rk save position th attribute return extracted country code 
pairs procedure execlr wrapper rk page occurrences rk rk scan occurrence save position bm scan occurrence rk save position em return label bm em bm em 
fig 

fictitious internet site providing information countries telephone country codes example web page html document corresponding content extracted ccwrap lr procedure generates execlr procedure generalization ccwrap lr 
lr means definitive solution web information extraction clearly demonstrates simple techniques remarkably effective 
lr effective simple pages minor complications formatting render lr ineffective 
example consider 
lr class requires value reliably indicates attribute 
may delimiter 
example suppose modified include heading country code list top document 
case delimiter ccwrap lr correctly 
possible show legal value lr wrapper documents modified manner 
kushmerick tackled issues extending lr family additional wrapper classes 
head left right tail hlrt class uses additional delimiters skip potentially confusing text head top tail bottom page 
example head delimiter list skip initial top document enabling correctly 
alternatively open close left right oclr class uses additional delimiters identify entire tuple document uses regular lr strategy mini document extract attribute turn 
ideas combined fourth wrapper class head open close left right tail hoclrt class 
kushmerick explored simple wrappers data formatted simple tabular fashion 
nested left right nlr class extract hierarchically organized data book table contents 
nlr operates lr processing rk possibilities start level continue level return level 
return level just proceed attribute 
nested head left right tail class combines nlr hlrt 
kushmerick developed specialized learning algorithms classes 
demonstrated empirically complexity theory trade expressive power wrapper classes extent efficiently learned 
example classes successfully wrap surveyed sites algorithms learning nlr wrappers take time grows exponentially number attributes pac analysis reveals hoclrt requires substantially training examples converge compared classes 
expressive wrapper classes kushmerick initial investigation lr family wrappers substantial research effort elaborating various alternative wrapper classes deriving efficient learning algorithms 
kushmerick various extended wrapper classes taken consideration numerous limitations 
muslea hsu dung developed various wrapper learning algorithms address shortcomings missing attributes :10.1.1.56.7152:10.1.1.56.7152
complicated pages may involve missing null attribute values 
corresponding delimiters missing simple wrapper process remainder page correctly 
example french commerce site specify country addresses outside france 
multi valued attributes 
simple wrapper classes discussed far assume simple relational model attribute single value non relational structures multi valued attributes natural scenarios 
example hotel guide explicitly list cities served particular chain wasteful binary encoding possible cities 
multiple attribute orderings 
wrappers described far assume attributes delimiters occur fixed ordering variant orderings abound complicated documents 
example movie site list release date title movies prior title movies 
disjunctive delimiters 
wrappers discussed assume single delimiter attribute complicated sites multiple delimiters 
example commerce site list prices bold face sale prices rendered red 
nonexistent delimiters 
wrappers described earlier assume irrelevant background tokens separate content extracted assumption may violated cases 
example department code separated course number strings comp 
problem relevant asian languages words tokenized spaces 
typographical errors exceptions 
real world documents may contain errors errors occur formatting drives extraction simplistic wrapper may fail entire page just small portion badly formatted 
sequential delimiters 
far wrapper classes assumed single delimiter attribute simplest way develop accurate wrapper scan delimiters sequence 
example extract name restaurant review simpler scan scan big position scan font force wrapper scan document single delimiter reliably indicates extracted content 
hierarchically organized data 
kushmerick nested classes step handling non tabular data results largely negative 
complicated scenarios need extraction nested embedded structure 
hsu dung addresses problem learning wrappers correspond expressive class deterministic finite state transducers 
formalism handles requirements just mentioned 
transducer processes document extract single tuple extraction control returns start state second tuple extracted extracted attribute represented pair states state identify start attribute value second identify 
general automaton model states connected arbitrary manner permitting missing attributes skipped states multi valued attributes cycles multiple attribute orderings multiple paths start state 
furthermore state transitions governed expressive rule language allows disjunctive delimiters 
limited form exception processing permitted allowing system recover formatting errors exceptions 
crucially hsu dung describe algorithm efficiently learning wrapper transducers training data 
empirically report wrapper classes handles sites wrapped kushmerick wrapper classes 
muslea identify class wrappers hsu dung tackle issues mentioned :10.1.1.56.7152:10.1.1.56.7152:10.1.1.56.7152
main distinguishing feature muslea wrappers multiple delimiters call landmarks 
insisting exist single delimiter exactly identifies relevant position deep inside document landmark wrappers sequence delimiters jump appropriate position series simple steps 
simple steps usually easier learn enable robust extraction 
second major feature muslea embedded catalog formalization nested data expressive simple hierarchical approach kushmerick 
extraction natural text techniques described far aimed highly regular documents html emitted cgi programs 
research information extraction focused natural free text documents email messages newspaper articles resumes wrapper results relevant structured domains 
investigations shown promising results 
freitag kushmerick explore boosted wrapper induction :10.1.1.23.4524
define class extraction patterns essentially lr class case exactly attributes 
enrich class permitting delimiters contain wild cards token types num specific instances 
example corpus email seminar announcements algorithm learns rule extracting starting time time num num alpha matches document 
time pm 
fragment extracted underlined 
rule basically says find start time look time followed number find time looking dash number colon token alphanumeric token 
simple rule language useful extraction free text 
freitag kushmerick improve performance boosting general technique improving accuracy weak learning algorithm learn rules 
individual rule high precision low recall combined rule set high precision high recall 
result accurate extraction algorithm competitive state art approaches variety free text domains superior 
example boosted wrapper induction performs essentially perfectly task extracting seminar announcement times better competitors attributes speaker name seminar location 
soderland describes related approach finite state techniques information extraction free text :10.1.1.41.8809
soderland extraction rules correspond restricted class regular expressions 
regular expressions serve purposes contextual pattern determining particular fragment extracted delimiters determining precise boundaries target frag ment 
soderland language important designed documents span spectrum unstructured natural text highly structured web pages 
depending degree structure training documents learning algorithm automatically creates appropriate patterns 
example simple extraction sufficiently accurate learning algorithm bother add additional contextual constraints 
example consider extracting price number bedrooms apartment listing documents capitol hill br 
pkg incl 
br upper flr gar 


soderland system learns rules digit br numb parenthesized portions regular expression indicate values extracted 
rule extract content example document 
hidden markov models freitag kushmerick soderland instances generalizing finite state approaches rigidly structured html documents structured documents email newspaper articles :10.1.1.23.4524:10.1.1.41.8809
approaches brittle facility evaluating strength evidence guides extraction decisions 
example suppose held precedes seminar location new document contains typographical error held 
techniques described far binary decisions way uncertain evidence 
hidden markov models principled efficient approach handling sort inherent uncertainty 
hidden markov model hmm stochastic finitestate automaton 
states emit tokens fixed state specific distribution transitions states occur fixed distribution 
hmms attractive computational device efficient algorithms learning model distribution parameters inferring state sequence observed token sequence 
hmms information extraction states associated tokens extracted 
example email seminar announcement corpus hmm contain state start time tokens time tokens speaker name tokens location tokens 
optionally may additional states generate background tokens 
perform extraction standard hmm viterbi decoding algorithm determine state sequence generated observed document extracted fragments simply read path 
hidden markov models successfully numerous researchers variety extraction scenarios 
key challenge efficient general purpose algorithm determining appropriate state topology state state distribution probabilities forced zero permitted positive 
initial generally hand crafted topology states connected manually reasonable way evaluating training corpus 
fig 

snapshots altavista search engine site may 
note presentation content changed 
attempts automatically learn appropriate topology 
general approach greedily search space possible topologies maximizes objective function 
seymore attempt maximize probability training data topology 
approach reasonably efficient potentially misguided goal hmm model training data se perform accurate extraction 
freitag mccallum objective function actual accuracy proposed topology extraction held validation corpus 
approach significantly slower result compact topology better generalization 
wrapper maintenance wrapper learning described earlier ignores important complication 
information agents generally control sources receive data 
described agent wrappers tend relatively brittle invariably rely idiosyncratic formatting details observed learning process 
unfortunately source modifies formatting example user interface observed regularities longer hold wrapper fail 
concrete example shows altavista search engine site redesign 
key challenges wrapper maintenance wrapper verification determining wrapper operating correctly wrapper re induction learning revised wrapper 
second challenge considerably difficult wrapper verification non trivial 
difficulty web sites content extracted formatting regularities may changed verification algorithm distinguish 
example suppose change microsoft stock price checked times stock quote server extracted values img src gif 
intuitively verification algorithm realize relatively values similar indicate trouble third value outlier probably indicates defective wrapper 
kushmerick describes simple accurate algorithm wrapper verification 
algorithm learns probabilistic model data extracted wrapper training period known operating correctly 
model captures various properties training data length fraction numeric characters extracted data 
verify wrapper training period extracted data evaluated learned model estimate probability wrapper operating correctly 
algorithm domain independent tied particular wrapper class learning algorithm treats wrapper black box inspects output 
algorithm handles acyclic xml data just relational data applicable wrapper classes described 
wrapper re induction received attention 
lerman learn probabilistic model extracted data similar substantially expressive kushmerick 
sensitive model enables wrapper re induction follows 
wrapper deemed broken learned model identify probable target fragments new unannotated documents 
training data post processed heuristically remove noise data wrapper induction algorithm 
lerman demonstrate empirically semi supervised approach highly accurate real world extraction scenarios 
post processing extracted content described far highly simplified task assumed involve simply processing document extract particular target fragments 
extraction scenarios information extracted distributed multiple documents attribute value page relevant extracted objects 
example shows simple scenario attribute values re multiple extracted objects values harvested collection hyperlinked documents 
issues handled wrapper classes defined earlier 
example muslea embedded catalog formalism permits extracted fragment shared multiple objects :10.1.1.56.7152
furthermore information extraction community long investigated issue cross document 
approaches require considerable linguistic processing applicable example shown 
jensen cohen address problems proposing language specifying extracted data post processed 
rules express raw extracted data grouped larger composite objects 
jensen cohen argue language sufficiently expressive handle data extracted web sites exporting job product advertisements 
furthermore suggest implement algorithm automatically learning rules examples grouped data 
supervision key bottleneck adaptive information extraction obtaining labeled training data 
machine learning motivated fact cost labeling fig 

complicated extraction task attribute values distributed multiple documents reused objects 
adapted 
documents usually considerably cost writing wrapper extraction rules hand 
labeling documents require considerable domain expertise generally tedious error prone 
approaches described far simply assumes adequate training corpus exists considerable research effort investigated called active learning methods minimizing amount training data required achieve satisfactory level generalization 
basic idea active learning start small amount training data run learning algorithm learned wrapper predict remaining unlabeled documents informative sense helping learning system generalize additional training document 
trivial example corpus contains duplicate documents learner suggest document annotated twice 
example active learning context wrapper induction consider muslea 
basic idea approach information extraction task dual correlations original task dual help system identify useful unlabeled documents 
recall muslea wrapper learning algorithm learns sequence landmarks scanning document start fragment extracted 
alternative way finding position scan backwards document different 
set landmarks 
muslea active learning extensions solves learning tasks parallel available training data 
resulting wrappers applied unlabeled documents 
system asks user label documents wrappers give different answers 
intuitively wrappers agree unlabeled document document useful subsequent learning 
muslea demonstrate active learning version algorithm requires significantly training data obtain level generalization 
example averaged variety challenging extraction tasks error learned wrapper user annotates training documents chosen intelligent manner compared documents chosen randomly 
brin explores different sort extraction task user gives system examples concept 
example learn extract book title author pairs user supply small sample pairs isaac asimov robots dawn charles great expectations 
job extraction system flesh list additional instances possible 
brin algorithm iteratively searches web seed pairs 
finds document contains pair learns information extraction pattern particular pair applies pattern remainder page 
resulting extracted pairs added seeds process iterates 
guarantee process converge extracted pairs correct 
preliminary experiments demonstrated promising results 
crescenzi focus bigger challenge wrapper learning supervision labeled training data 
consider pages online bookstore returned queries asimov 
cases pages formatted way difference content extracted 
intuition crescenzi approach wrapper learned comparing pages finding similarities differences 
similarities correspond common formatting structural elements differences correspond data extracted 
repeatedly replacing differences wild cards noting repetitive structures algorithm learn wrapper corresponds regular grammar need manually labeled training data 
crescenzi report algorithm works variety real world domains 
summary information extraction core enabling technology wide variety management agents 
central challenge information extraction ability scale number variety information sources 
described variety adaptive information extraction approaches machine learning techniques automatically learn extraction rules knowledge training data 
due highly practical nature task approaches described chapter tested various real world examples 
means gap pure research practical usage agent systems smaller glance 
focused particular sub field adaptive information extraction finite state techniques learn extraction knowledge corresponding regular gram mars automata 
addition core adaptive techniques briefly discussed issues related entire information extraction lifecycle 
fundamental open issue adaptive information extraction method determining technique best suited particular extraction task 
today complicated judgment requires considerable expertise experimentation 
ultimately foresee semi automated methodology heterogeneity documents measured various dimensions order predict simplest approach deliver satisfactory performance 
acknowledgments 
bernd thomas helpful discussions 
research supported office naval research sfi science foundation ireland 

bikel miller schwartz weischedel 
nymble high learning name finder 
proc 
conf 
applied natural language processing 

brin 
extracting patterns relations world wide web 
proc 
sigmod workshop databases web 

crescenzi mecca merialdo 
roadrunner automatic data extraction large web sites 
vldb journal pages 

freitag kushmerick 
boosted wrapper induction 
proceedings seventh national conference artificial pages july august 
austin texas 

freitag mccallum 
information extraction hmm structures learned stochastic optimization 
proceedings seventh national conference artificial july august 
austin texas 

hsu dung 
generating finite state transducers semistructured data extraction web 
information systems 

jensen cohen 
grouping extracted fields 
proc 
ijcai workshop adaptive text extraction mining 

kushmerick 
wrapper induction information extraction 
phd thesis university washington 

kushmerick 
regression testing wrapper maintenance 
proc 
national conference artificial intelligence pages 

kushmerick 
wrapper induction efficiency expressiveness 
artificial intelligence 

kushmerick 
wrapper verification 
world wide web journal 

kushmerick weld doorenbos 
wrapper induction information extraction 
pollack editor fifteenth international joint conference artificial intelligence volume pages august 
japan 

leek 
information extraction hidden markov models 
master thesis university california san diego 

lerman minton 
learning common structure data 
proc 
national conference artificial intelligence 

muslea 
extraction patterns information extraction tasks survey 
proc 
aaai workshop machine learning information extraction 

muslea minton knoblock 
hierarchical approach wrapper induction 
proc 
third international conference autonomous agents pages 

muslea minton knoblock 
selective sampling redundant views 
proc 
national conference artificial intelligence 

seymore mccallum rosenfeld 
learning hidden markov model structure information extraction 
proc 
aaai workshop machine learning information extraction 

soderland 
learning information extraction rules semi structured free text 
machine learning 
