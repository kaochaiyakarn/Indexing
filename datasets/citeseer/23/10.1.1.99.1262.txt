architecting dependable systems virtualization matthias ibm zurich research laboratory switzerland mts zurich ibm com propose new methods leveraging virtualization addressing system dependability issues 
combinatorial modeling analyze multiple design choices single physical server host multiple virtual servers 
results show certain conditions regarding reliability hypervisor number vms met virtualization decrease reliability single physical node 
light prevailing ad hoc approach virtualization general inclination move services operating system virtualization layer results point need cautious rigorous approach 
virtualization allows abstracting away real hardware configuration system 
method virtualizing hardware resources computer involves layer software called virtual machine monitor vmm provide illusion real hardware multiple virtual machines vms 
inside vm operating system called guest os applications run vm virtual resources virtual cpu virtual network card virtual ram virtual disks 
vmm hosted directly computer hardware xen host operating system vmware 
introduced virtualization lately enjoyed great surge interest 
improved efficiency flexibility cost savings virtualization storage networking computing resources enables data centers key drivers interest 
address issue virtualization building block enhancing dependability just data centers general settings 
exceptions current solutions space largely ad hoc 
increasingly prevalent tendency think virtualization cure 
suggestions shift runs real machine virtual machine move services networking security currently provided operating system virtual machine monitor commonplace 
contributions 
new ways virtualization addressing system dependability issues 
second combinatorial modeling analyze multiple design choices single physical server host multiple virtual servers quantify reliability impact virtualization 
light prevailing general inclination shift services guest os virtualization layer show shift done carefully adversely affect system reliability 
related bressoud schneider implemented replication protocol tolerant benign faults vmm level 
protocol resolves non determinism logging results non deterministic actions taken primary applying results backups maintain state consistency 
double take uses hardware real time synchronous replication replicate application data multiple vms single physical machine application automatically fail spare machine importing replicated data case outage 
replication done file system level vm technique guest os agnostic 
douceur howell describe vmms ensure vms satisfy determinism enable state machine replication vm level application level 
specifically describe vm virtual disk clock deterministic respect vm execution 
design relieves burden application programmer structure application deterministic state machine 
dunlap describe revirt vm logging replay 
revirt encapsulates os vm logs nondeterministic events affect vm execution uses logged data replay vm execution 
joshi combine vm introspection vm replay analyze os vulnerability application vulnerability activated vm patch applied 
analysis done vulnerability specific predicates provided patch writer 
patch applied predicates vm normal execution detect respond attacks 
identify application running inside vm exploited host 
extension track attacks single host infection detected originator attack hosts compromised host 
virtualization new opportunities dependability commodity operating systems provide level dependability lower desired 
trend hasn seen change decade 
focus shifted designing dependable systems os problems 
virtualization enables design ways 
way encapsulate os applications vm introduce dependability enhancements vmm level transparent guest os applications 
design allows vm treated black box 
example checkpointing recovery done granularity vms processes 
way instrument applications middleware guest os explicit knowledge running virtual opposed physical machine 
example programming languages supporting vms java ocaml checkpointing application state vm level byte opposed native code allow restarting saved state hardware platform different checkpointing done 
virtual machines offer degree flexibility possible obtain physical machines 
mainly vm state files read copied modified saved migrated restored 
section propose various new methods virtualization improving dependability 
coping load induced failures deploying services vms physical machines enables higher flexible resilience load induced failures requiring additional hardware 
load conditions vms seamlessly migrated live migration technology lightly loaded powerful physical machine 
vm creation simple cheap copying file 
response high load conditions easier dynamically provision additional vms utilized physical machines provision additional physical machines 
patch application high availability services typically patch application involves system restart negatively affects service availability 
consider service running inside vm 
virtualization provides way remove faults vulnerabilities run time affecting system availability 
purpose copy vm instantiated patch service level applied copy original vm 
copy restarted patch take effect original vm gracefully shut service requests directed copy vm 
patch applied copy vm copy vm restarted original vm continues regular operation maintaining service availability 
ensure undesirable side effects due patch application copy vm may placed quarantine sufficiently long time observing post patch behavior shutting original vm 
service running inside vm stateful additional techniques combination vm checkpointing vm live migration may retain network connections original vm bring copy date correct checkpoint 
enforcing fail safe behavior average time vulnerability public patch available measured months 
microsoft took average time days issuing critical patches windows security problems reported 
developing patches software component time consuming process need ensure patch introduce new flaws affect dependencies component components system 
cases service administrator simply luxury suspending service immediately critical flaw os running service service publicized patch available 
virtualization prolong availability service possible time ensuring service fail safe 
leverage observation flaw usually accompanied details possible attacks exploiting flaw symptoms exploited flaw 
developing external monitor identifying attack signatures symptoms exploited flaw may done independently patch development 
monitor may developed faster patch monitor may subject stringent testing validation requirements 
consider service run inside vm directly physical machine 
vm external monitor running parallel vm detect symptoms exploited flaw signal vmm crash vm 
alternatively attack signature known monitor identify ongoing attack terminate interaction attack source 
monitor implemented vmm level privileged vm dom xen 
important revert service correct state patch available technique augmented checkpointing mechanism periodically checkpoints state service respect vm 
proactive software rejuvenation rebooting machine easy way software 
downside machine reboot service unavailable reboot process 
vmm convenient layer introducing hooks proactively guest os services running inside vm performance availability preserving way 
periodically vmm instantiate vm clean vm image 
booting vm done original vm continues regular operation maintaining service availability 
mentioned context patch application techniques vm checkpointing live migration may seamlessly transfer network connections service state original vm vm 
possible adjust performance impact rejuvenation procedure original vms performance 
lower impact vmm restrict amount resources devoted booting vm compensate restriction resources allowing time rebooting complete 
view type rejuvenation memory scrubbing technique reclaiming leaked memory recovering memory errors original vm 
importantly periodic rejuvenation offers way proactively recover errors requiring failure detection mechanisms unreliable trigger recovery 
replica diversity fault tolerant replication diversity replicas important ensure replicas fail disruptive event 
deploying replicas combination virtual physical machines physical machines replica diversity enhanced 
deploying replicas virtual machines physical machines opens layer diversity introduced vmm software 
vmm diversity os diversity complement enhance replica diversity additional hardware costs 
flip side vmm replica vms lower replica diversity replicas deployed different operating systems 
fault vmm lead failure replicas 
containment fault containment important aspect dependability 
containment vms running vmm stronger containment processes running os 
better isolate fault effects services running os physical server carve physical server vms running service 
hand fault containment vms strong fault containment physical os application hardware architecture combinatorial model 
non virtualized node machines due covert channels 
cost restriction highly critical space military applications running software components distinct hardware better fault containment running components different vms hardware 
quantifying impact virtualization node reliability section combinatorial modeling perform reliability analysis redundant fault tolerant designs involving virtualization single physical node compare non virtualized case 
consider model multiple vms run concurrently node offer identical service 
derive lower bounds vmm reliability number vms required virtualized node better reliability non virtualized case 
analyze reliability impact moving functionality common vms vms vmm 
additionally analyze reliability redundant execution scheme tolerate corruption vms running physical host compare non virtualized case 
results point need careful modeling analysis design virtualization 
combinatorial modeling markov modeling main methods reliability assessment fault tolerant designs 
chose combinatorial modeling simplicity enables easy elimination hopeless choices early stage design process 
combinatorial modeling system consists series parallel combinations modules 
assumption module failures independent 
real world setting module failures may independent reliability values obtained combinatorial modeling yield upper bounds 
non virtualized nv node reliability assessment consider non virtualized single physical node base case 
model node modules hardware software machine consisting operating system middleware applications node simple se system consisting reliability nv sys rx denotes reliability module 
virtual machine 
machine hardware virtual virtual machine monitor architecture mn combinatorial model 
node vms virtualized node independent identical vms shows physical node consisting type vmm runs directly hardware vmm referred hypervisor virtual machines mi 
vm functionality software machine shown non virtualized case 
vms provide identical service concurrently independently need strong synchronization 
example vm virtual server answering client requests static web content 
node system reliability sys rmi 
sys nv sys gives condition replicated service reliable non virtualized service 
rmi simplicity rmi rm condition rv rm rm inequality immediately yields 
condition hold rv 
means necessary additional coordination mechanism protocol built system compensate reliability lost hypervisor 
absence mechanism protocol simply adding hypervisor layer node decrease node reliability 
second rv rm obvious condition hold 
clear hypervisor reliable individual vm 
interesting question reliable 
shows fixed rm value hypervisor reliable deploying fewer vms 
graph shows fixed values rm rv exits lower bound value virtualized node reliability definitely lower non virtualized node 
example rm rv deploying fewer vms lower node reliability 
useful result practical settings rm rv values may fixed hypervisor guest os application commercial theshelf cots components source code access 
equation sys suggests increas lower bound reliability hypervisor rv reliability virtual machine rm 
lower bound hypervisor reliability physical node independent concur rently operating vms providing identical service 
lower bound number vms reliability virtual machine rm 
lower bound number vms achieve desired reliability physical node independent concurrently operating vms providing identical service rv 
ing number vms node reliability close hypervisor reliability desired 
suppose desire node reliability rv rm 
assume hardware highly reliable rh 
equation inequality rv rm rm rv log rm log rv dividing log rm negative number get log rv log rm inequality gives lower bound number vms required virtualized physical node meet reliability requirement 
practice number vms hosted physical node ultimately limited resources available node 
comparing lower bound number vms possibly hosted provides easy way eliminate certain choices early design process 
shows lower bound different values vm reliability rm increased roughly hy mn configuration functionality implemented vm mn configuration functionality implemented part hypervisor 
moving functionality vms hypervisor reliability fixed 
shows fixed rv rm values higher system reliability rv obtained increasing number vms hosted 
large faced practical difficulty obtaining sufficient diversity ensure vm failures independent 
moving functionality vms hypervisor analyze reliability impact moving functionality vms hypervisor 
system model physical node independent concurrently operating vms providing identical service 
consider functionality implemented inside vm 
vm mi divided components representing rest mi 
shows reliability model node containing vms 
call node configuration 
suppose functionality moved vms substituted component implemented part hypervisor 
new hypervisor consists components old hypervisor shows reliability model node modified hypervisor 
call node configuration 
derive condition reliable 
simplicity assume rm desired condition rc sys rc sys rf rm rf rm rf rf rm rm easy see single vm matter functionality implemented hypervisor vm 
confirm observation substituting inequality 
lower bound reliability functionality moved hypervisor rf lower bound reliability functionality moved hypervisor rf rm rm rm rm reliability functionality implemented vm rf fixed varying rm rm rm reliability functionality implemented vm rf fixed varying 
plot rf rf rm rm figures illustrate rf varies rf increased 
graphs show reliable configuration reliable 
shows rm increases degree reliable increases 
shows degree considerably higher vms hosted physical host 
example modest rm rf values ultra reliable rf respectively 
handful vms hosted physical node better system reliability obtained retaining poorly reliable functionality vm moving functionality hypervisor 
virtualized node vmm level voting consider fault tolerant replication scheme vms providing identical service single physical node 
vmm layer receives client requests forward vms order 
assume service deterministic state machine vm replicas yield result request 
vmm receives results vm replicas 
vmm obtained replies replicas identical result values client request forwards result value corresponding client 
scheme lower bound reliability hypervisor rv reliability virtual machine rm 
plot rm rv tolerate arbitrary failure vm replica similar suggested architecture fault tolerant replication virtualization 
assuming vms fail independently system re liability sys sys rm nv sys gives condition replication scheme reliable non virtualized service 
obtain rm rv rm inequality gives lower bound hypervisor reliability replication scheme better reliability non virtualized case 
shows plot rm rv 
clear graph exists rv value satisfies inequality rm 
words vm reliability os service reliability poor replication scheme node reliability worse hypervisor ultra reliable 
graph shows higher hypervisor reliability larger range vm reliability values replication scheme better reliability non virtualized case 
example rv range vm reliability values accommodated greater range rv 
described new ways leveraging virtualization improving system dependability 
combinatorial modeling provided detailed analysis previously available virtualization affect system dependability 
results show certain conditions regarding reliability hypervisor number vms met introducing virtualization decrease reliability physical node 
light general inclination move services guest os virtualization layer results point need cautious approach 
notwithstanding simplicity modeling technique associated strong assumptions regarding independent module failures exercise points need thorough rigorous modeling assessment context virtualization 
time patch 
blog 
com time patch html 
vmware double take 
www vmware 
com pdf vmware pdf 
friedman 
virtual machine heterogeneous checkpointing 
software practice experience 
barham fraser hand harris ho neugebauer pratt warfield 
xen art virtualization 
proc 
th acm symposium operating systems principles sosp pages october 
bressoud schneider 
hypervisor fault tolerance 
acm trans 
comput 
syst 
clark fraser hand hansen jul pratt warfield 
live migration virtual machines 
proc 
nd symposium networked systems design implementation nsdi may 
douceur howell 
replicated virtual machines 
technical report msr tr microsoft research sep 
dunlap king chen 
revirt enabling intrusion analysis virtual machine logging replay 
sigops operating system review si 
garfinkel rosenblum 
virtual harder real security challenges virtual machine computing environments 
proc 
th workshop hot topics operating systems hotos may 
johnson 
design analysis fault tolerant digital systems 
addison wesley 
joshi king dunlap chen 
detecting past intrusions vulnerability specific predicates 
proc 
th acm symposium operating systems principles sosp pages 
king chen 
backtracking intrusions 
proc 
th acm symposium operating systems principles sosp pages 
king mao chen 
enriching intrusion alerts multi host causality 
proc 
network distributed system security symposium ndss 
reiser hauck schr der 
hypervisor redundant execution single physical host 
proc 
th european dependable computing conference page 
