sliding window query processing data streams thesis university waterloo fulfillment thesis requirement degree doctor philosophy computer science waterloo ontario canada author declaration electronic submission thesis declare am sole author thesis 
true copy thesis including required final revisions accepted 
understand thesis may electronically available public 
ii database management systems dbmss successfully traditional business applications require persistent data storage efficient querying mechanism 
typically assumed data static explicitly modified deleted user application 
database queries executed issued answers reflect current state data 
emerging applications sensor networks real time internet traffic analysis line financial trading require support processing unbounded data streams 
fundamental assumption data stream management system dsms new data generated continually making infeasible store stream entirety 
best sliding window arrived data may maintained meaning old data removed time goes 
furthermore contents sliding windows evolve time sense users ask query receive updated answers time 
dissertation begins observation fundamental requirements dsms dealing transient time evolving static data answering persistent transient queries 
implication requirement data maintenance costs significant effect performance dsms 
additionally traditional query processing algorithms re engineered sliding window model queries may need re process expired data undo previously generated results 
second requirement suggests dsms may execute large number persistent queries time exist opportunities resource sharing similar queries 
purpose dissertation develop solutions efficient query processing sliding windows focusing fundamental properties 
terms transient nature streaming data dissertation insight 
data keep changing time windows slide forward changes random contrary inputs outputs dsms exhibit patterns way data inserted deleted 
shown knowledge patterns leads understanding semantics persistent queries lower window maintenance costs novel query processing query optimization concurrency control strategies 
context persistent nature dsms queries insight proposed solution various queries may need refreshed different times synchronizing refresh schedules similar queries creates opportunities resource sharing 
iii supervisor prof tamer zsu guidance ph studies remaining members examination committee time interest dissertation 
prof alejandro pez ortiz prof kenneth salem departmental members prof paul ward internal external examiner prof jennifer widom external examiner 
financial support dissertation provided bell canada communications information technology ontario natural sciences engineering research council canada nserc sun microsystems canada university waterloo 
implementation prototype system described chapter done 
implementation prototype system chapters done kumar gaurav 
ideas solution chapter developed collaboration david 
iv contents data stream management systems 
problem statement 
contributions scope organization 
survey data stream management data models query languages dsmss 
data models 
semantics persistent queries 
dsms query algebras languages 
dsms query operators 
query operators unbounded streams 
query operators sliding windows 
dsms query processing 
queuing scheduling 
determining tuples expire 
continuous query processing sliding windows 
periodic query processing sliding windows 
dsms query optimization 
cost metrics statistics 
query rewriting adaptive query optimization 
load shedding approximation 
multi query optimization 
update pattern aware modeling processing persistent queries 
update patterns persistent queries 
classification 
discussion 
update pattern aware semantics persistent queries 
defining meaning relations persistent queries 
internal external windows 
windowing output stream persistent query 
impact update pattern awareness periodic query processing 
making dsms query language update pattern aware 
update pattern aware query processing optimization 
update pattern propagation persistent query plans 
update pattern aware physical plan generation 
update pattern aware query optimization 
experiments 
overview 
query 
query 
query 
query 
lessons learned 
indexing time evolving data variable lifetimes 
assumptions motivation 
proposed solution 
double partitioning 
cost analysis 
handling fluctuating stream conditions 
experiments 
implementation details 
optimal values 
performance doubly partitioned indices 
fluctuating stream conditions 
scaling large index sizes 
lessons learned 
multi join processing sliding windows 
sliding window join algorithms 
eager evaluation 
lazy evaluation 
analysis algorithms 
join ordering 
cost formulae 
join ordering heuristic 
experimental results 
vi experimental setting 
validation cost model join ordering heuristic 
relative performance join algorithms 
lessons learned 
sliding window aggregation finding frequent items 
proposed solution 
algorithm description 
analysis 
experimental results 
experimental setup 
accuracy 
space usage 
precision 
lessons learned 
concurrency control periodic queries sliding windows 
motivation assumptions 
data query model 
motivation study concurrency control 
system model 
conflict serializability sliding window queries 
serializability serialization orders 
isolation levels sliding window queries 
transaction scheduler design 
producing lws histories 
optimal ordering read operations 
note queries accessing materialized sub result 
experiments 
implementation details experimental procedure 
percentage aborted transactions 
experiments workload periodic queries 
experiments mixed workload periodic time queries lessons learned 
comparison related 
multi query optimization sliding window aggregates 
preliminaries 
identifying processing similar queries 
vii sliding window aggregates 
aggregates joins 
aggregates selection 
multi query scheduling 
semantics periodic query re execution 
earliest deadline scheduling 
scheduling multiple queries 
hybrid scheduling 
additional sharing overload 
experimental evaluation 
setting 
results low data rate 
results high data rate 
lessons learned 
comparison related 
summary contributions 
directions research 
proof theorem viii list tables summary proposed data stream languages 
classification previous maintenance time evolving data 
explanations symbols chapter 
probing orders global join order 
stream parameters initial heuristic example 
sizes intermediate join results 
stream parameters augmented heuristic example 
stream parameters example fast streams slow streams abbreviations scheduling techniques 
ix list figures finding largest element sliding window 
architecture dsms 
example query plan 
possible execution timelines persistent queries 
dissertation coverage terms dsms application requirements 
dissertation coverage terms query processing strategies 
examples persistent query operators data streams 
query execution negative tuple approach 
query execution direct approach 
sliding window implemented circular array pointers sub windows 
examples running interval basic interval synopses 
equivalent illustrations wave index 
update patterns sliding window operators 
output aggregation query types windows 
processing join internal windows materialized view 
drawbacks periodic query re evaluation 
query plans query annotated update patterns 
storing results weak non monotonic subqueries 
illustration query plans experiments 
processing times query protocol ftp selection predicate 
processing times query protocol telnet selection predicate 
processing times query duplicate elimination source ip address processing times query dupl 
elim 
src 
dest 
ip addr 
pairs 
space consumption query duplicate elimination source ip address space consumption query dupl 
elim 
src 
dest 
ip addr 
pairs processing times query 
processing times query 
example doubly partitioned index showing update time bottom example round robin doubly partitioned index 
structure individual sub index 
relative performance rebuild rebuild rebuild 
update times index partitioning techniques small window size 
probe times index partitioning techniques small window size 
scan times index partitioning techniques small window size 
effect data rate fluctuations index update performance 
update times index partitioning techniques large data set 
probe times index partitioning techniques large data set 
scan times index partitioning techniques large data set 
join order expressed join tree series loops validation join ordering heuristic 
cost nested loops algorithms 
cost hash algorithms 
basic window synopsis storing popular url sub window 
example single execution algorithm 
performance analysis algorithm 
examples query window update sequences dsms 
techniques computing sliding window sums 
assumed system architecture 
serialization graphs ha hb hc hd 
differences results returned tq ha hb hc hd 
update materialized sub result having weak non monotonic update patterns staleness response time inter execution time 
percentage read transactions aborted algorithm 
comparison query staleness serial ws lws ttu 
comparison query inter execution times serial ws lws ttu 
comparison throughput read transactions lws 
comparison time query response times serial ws lws ttu 
comparison time query staleness serial ws lws ttu 
comparison periodic query staleness serial ws lws ttu 
relationship cps ws lws 
possible ways schedule queries 
assumed query processing architecture 
examples rj bij synopses 
example generalized bij synopsis 
semantics periodic query re execution 
execution schedules queries group various scheduling techniques throughput measurements data rate tuples second 
xi average latency measurements data rate tuples second 
throughput measurements data rate tuples second 
average latency measurements data rate tuples second 
example doubly partitioned index showing update time bottom example round robin doubly partitioned index 
xii chapter data stream management systems traditional relational database stores collection tables inherently unordered viewed sets 
data records relatively static assumed valid explicitly modified deleted user application 
queries typically assumed occur frequently data modifications executed posed answers reflect current state database 
goal database management system dbms provide persistent consistent recoverable storage efficient query answering mechanism 
relational model fulfilled needs traditional business applications evidenced commercial success relational dbmss 
requirements number emerging applications fit description 
particularly interesting change data may generated real time form unbounded sequence stream values 
shift trends applications 

networks sensors wireless communication capabilities increasingly ubiquitous 
sensor networks environmental geophysical monitoring road traffic monitoring location tracking surveillance inventory supply chain analysis :10.1.1.12.1378
measurements produced sensors temperature readings may modeled continuous data streams 

world wide web offers multitude line data feeds news sports financial :10.1.1.136.4253
typically third party service merges data multiple sources publishes set output streams users may subscribe 
example queries include moving averages stock prices finding correlations prices stocks 

overwhelming amount transaction log data generated telephone call records point sale purchase credit card transactions web server logs :10.1.1.119.5031
line www com sliding window query processing data streams analysis transaction logs identify interesting customer spending patterns possible credit card fraud 

networking community great deal interest data management system line monitoring analysis network traffic 
specific goals include tracking bandwidth usage statistics purposes traffic engineering routing system analysis customer billing detecting suspicious activity equipment malfunctions denial service attacks 
context data stream composed ip packet headers 
fundamental assumption data stream model new data generated continually fixed order arrival rates may vary applications millions items second internet traffic monitoring items hour temperature humidity readings weather monitoring station 
ordering streaming data may implicit arrival time processing site explicit generation time indicated timestamp appended data item source 
result assumptions data stream management systems dsmss face novel requirements 

computation performed dsms push data driven 
newly arrived stream items continually periodically pushed system processing 
hand dbms employs pull query driven computation model processing initiated query posed 

consequence dsms queries persistent issued remain active system possibly long period time 
means stream updated results produced time goes 
contrast dbms deals time queries issued forgotten results computed current state database 

system conditions may stable lifetime persistent query 
example stream arrival rates may fluctuate query workload may change 

data stream assumed unbounded unknown length 
system point view infeasible store entire stream dsms 
user point view arrived data accurate useful 

new data models query semantics query languages needed dsmss order reflect facts streams ordered queries persistent 
requirements guide design dsms query engine 
superficially similar relational query plans represented trees operators persistent query plans buffers queues sophisticated scheduling algorithms order handle continuously incoming data :10.1.1.58.1029
dsms query plan include blocking operators persistent queries referred literature continuous long running standing queries 
dissertation reserves term continuous query persistent query produces new answers continuously 
contrast periodic query defined persistent query returns new answers periodically 
finding largest element sliding window consume entire input producing results 
third requirement implies dsms adapt changes system conditions possibly re optimizing persistent queries time initiating form load shedding dropping fraction incoming data periods overload 
fourth requirement suggests old data removed archived line processing giving rise various window models 
simplest case fixed window model periodically clears accumulated data 
stream divided non overlapping partitions data kept part stream falls current partition 
major disadvantage model window size varies window begins size zero grows specified size point reset back size zero 
contrast sliding window model expires old items new items arrive 
common types sliding windows count windows store newest items time windows store items generated arrived time units 
response fourth fifth requirements persistent queries sliding windows supported dsms 
illustrate challenges maintaining querying sliding windows consider query may written cql select max stream items having numerical attribute time maintains largest value items seen far 
achieve requires constant space processing time data item stores current maximum value compares values incoming items fly 
consider times maintains largest value sliding window minute 
cql may written select max range min 
example finding largest value sliding window illustrated stream items values shown time axis 
time window spans youngest item arrived 
maximum time 
time youngest item arrives value smaller maximum answer change 
time window slides past oldest item new maximum 
worst case needs store examine data item inside window order update maximum occurs stream sorted decreasing order 
note sliding window version max examine newly arrived items react item expires window 
point worth noting designing dsms may attempt cql stream query language sql syntax proposed described detail section 
sliding window query processing data streams employ existing data management technologies data stream processing 
possibility traditional dbms augmented application layer simulates sliding windows persistent queries data driven processing continually inserting new data removing expired data maintaining query results 
existing techniques incremental maintenance materialized views may helpful order avoid repeated re computation entire result persistent query early persistent queries focused fact 
application approach significantly efficient dsms largely due semantic gap dbms dsms application 
alternative designing dsms involves exploiting relevant features dbms engine triggers novel data types arrays lists sequences time series temporal data :10.1.1.39.4584
triggers sufficiently scalable expressible data stream applications 
furthermore sequence time series temporal extensions potentially handle ordering sliding windows query driven processing model assume data database 
novel requirements data stream processing led number dsms proposals 
academic systems include aurora cape hi fi nile pipes psoup stream telegraphcq :10.1.1.11.8839:10.1.1.78.2092:10.1.1.1.4609
additionally gigascope dsms network monitoring aurora academic systems rise systems product targeted financial trading applications telecommunications systems monitoring government military surveillance tasks :10.1.1.113.2257
dissertation assumes dsms processing data streams system architecture shown 
streaming inputs arrive processing real time 
input monitor regulates input rates dropping data system unable keep 
conceptually data stored partitions working storage containing sliding windows local storage metadata stored relational tables physical location data source schema stream 
users may update tables directly working storage maintained automatically expiring items fall windows persistent queries registered query repository possibly grouped shared processing time queries current state inputs may issued 
query processor communicates input monitor may re optimize query plans response changes workload input rates 
results streamed users materialized system 
users may refine queries latest results ask ad hoc time queries response changes answers persistent queries 
focus dissertation publish subscribe systems designed extend scalability triggers emphasis efficient monitoring large number simple conditions 
contrast workload dsms typically involves somewhat smaller number complicated queries 
extending expressive power triggers publish subscribe systems novel solutions applicable dsmss 
www com expired data may discarded archived line processing 
architecture dsms shaded components dsms storage query processing 
problem statement fundamental differences dsms dbms nature data nature queries 
specifically dbms handles transient queries persistent data dsms processes persistent queries transient data 
important consequences differences 
implications time evolving nature data streams data maintenance costs significant effect performance dsms 
window slides forward new data items inserted old items evicted archived 
implemented care dsms may spend time window maintenance leaving little time query answering 
additionally traditional relational operators reengineered sliding window model expired data items may need order undo previously generated results 
hand persistent nature queries streams means dsms may execute large number queries time 
result multi query optimization suitable approach ensuring scalability 
purpose research develop solutions processing persistent queries sliding windows focusing differences 
terms transient nature streaming data insight offered dissertation data stored dsms keep changing time windows move forward expirations windows output streams queries random 
contrary inputs outputs persistent queries exhibit patterns way data inserted deleted 
shown notion update pattern awareness aims uncovering exploiting patterns leads understanding semantics persistent queries lower window maintenance costs novel query processing optimization strategies new concurrency control models 
example recall observe tuple sliding window query processing data streams example query plan possible execution timelines persistent queries expire oldest 
expiration order sliding window equivalent insertion order window sliding window analogous fifo queue 
words fifo expiration example update pattern 
way exploiting pattern query implement state buffer fifo queue 
way new tuples appended front queue expired tuples guaranteed tail 
consider defined follows 
select max range min range min maintains largest value equi join sliding windows attribute 
illustrated fifo queue may appropriate storing state needed max operator 
output sliding window join satisfy fifo property 
example newly arrived tuple may join tuples window arrived expire 
context persistent nature dsms queries focus research periodic re evaluation persistent queries discussed :10.1.1.11.8839:10.1.1.136.4253:10.1.1.14.3206
may done performance reasons additionally users may find easier deal periodic output continuous output stream 
suppose dsms executes queries call answers refreshed time units answers refreshed time units 
furthermore suppose share computation 
example queries identical length window query longer window re computation refresh query shorter window 
illustrates possible execution sequences 
left computation sharing exploited time units queries due refresh 
right refresh times synchronized 
case computation shared savings processing time may defeated expended updating answer necessary 
novel problem context schedule refresh times set possibly similar queries way minimize total processing time 
contributions scope organization remainder dissertation organized follows 
chapter presents survey data stream management 
chapter deals fundamental property dsms handling time evolving data proposing idea update pattern awareness 
particular contributions chapter follows 
update patterns persistent query operators plans classified types 
classification formulate semantics persistent queries streams sliding windows relations 
semantic issues clarified help update pattern awareness include difference arbitrary updates relational tables insertions deletions caused movement sliding windows relationship sliding windows monotonic queries difference window input stream window output stream impact periodic query processing completeness result 
incorporation update pattern aware semantics cql outlined 
update pattern aware query processing framework introduced implementations operators intermediate state structures depend update patterns inputs outputs 
idea choose query plan simplest update patterns order minimize state maintenance costs simplify operator implementation 
aware query plans shown routinely outperform existing techniques data stream literature order magnitude 
chapter assumes line processing memory resident sliding windows 
chapter extends update pattern awareness accommodate stream warehousing line mining analysis 
update pattern aware index proposed secondary storage time evolving data record specified lifetime system 
index updated periodically inserting batch new data removing expired data 
updates may incur high costs entire data set loaded memory determine items expired deleted 
insight solution described dissertation partition data selected partitions affected updates 
technique shown perform updates twice fast existing sliding window indices 
chapters take closer look important sliding window operators join top aggregation 
chapter contains contributions 
pipelined multi window join algorithms proposed continual periodic join evaluation continual periodic expiration hash tables update pattern aware data structures cluster hash buckets expiration times data items 
second join ordering heuristic developed considering stream arrival rates window lengths expected number join results produced 
chapter presents algorithm incrementally maintaining frequently occurring item types sliding window focus internet traffic analysis 
discussing query evaluation window maintenance dissertation examines concurrency issues arising simultaneous execution queries window slides 
dbms sliding window query processing data streams concurrency control manages way users access data 
example reading record table may done time users sense person change record time 
dsms insertions deletions thought happening automatically windows slide forward 
concurrency control required window may slide forward accessed query 
chapter shows traditional notion conflict serializability insufficient dsms environment proposes stronger isolation levels restrict allowed serialization orders 
update pattern aware transaction scheduler designed proven minimize number aborted transactions ensuring desired isolation level 
insight solution follows fifo property sliding windows new data added old data removed tail middle window accessed concurrent read transactions queries 
chapter addresses second fundamental property dsms handling large number persistent queries 
motivated novel challenges allow resource sharing similar queries re evaluated different frequencies get scheduled different times 
particular contribution chapter follows 
extensible set rules sharing state computation proposed periodic queries aggregation aggregates different window lengths share data structure storing state 
persistent queries modeled periodic tasks scheduled deadlines query scheduler designed basis traditional earliest edf algorithm 
help cost model set subexpression matching rules scheduler synchronizes refresh times similar queries order minimize total query processing time maximize system throughput 
chapter concludes dissertation summary contributions suggestions 
scope dissertation may illustrated ways 
terms targeted applications points speed versus state versus query complexity spectrum labeled 
far left applications process massive amounts raw data real time live network monitoring 
gigascope extent aurora examples dsmss aimed types applications 
fast processing needed order keep data arrival rate 
result amount state available queries may restricted variables possibly stored fast cpu registers 
due extreme conditions queries typically stateless filters simple aggregates fixed windows 
furthermore answers may approximate obtained sampling 
middle point spectrum represents applications require line processing data rates tractable allow complex queries memory resident sliding windows 
representative examples include analysis pre processed network data financial sensor networks representative queries include joins complex aggregation 
cases entire window fit memory summarized limited space consequence queries accessing summary dissertation coverage terms dsms application requirements dissertation coverage terms query processing strategies return approximate answers 
nile stream examples purpose dsmss aimed applications middle spectrum 
right point describes applications large amount streaming data archived disk updated periodically complex analytical queries executed line sliding window residing secondary storage absence real time processing requirements complex queries including sophisticated data mining pattern analysis possible 
particular algorithms allowed multiple passes data 
shown dissertation spans middle right endpoints spectrum 
quad chart organizes contributions dissertation query processing strategies 
chapter introduces update pattern awareness context single query data driven continual processing impact update pattern awareness semantics periodically refreshed queries explained section 
chapter shows operators sliding window join process new tuples continually periodically chapters concentrate periodic processing complex aggregates sliding windows 
multi query optimization scalability respect query workload covered chapter indexing techniques chapter concurrency control solutions chapter designed multi query processing mind 
context centralized versus distributed dsms architectures scope dissertation limited centralized scenario 
applications occupying right point spectrum similar existing data warehousing line analytical processing olap applications emphasis maintenance disk resident sliding windows 
chapter survey data stream management chapter reviews data stream processing 
related surveys include earlier shorter version chapter discussion issues data stream processing context stream system review query processing relational xml streams 
keeping focus dissertation emphasis centralized processing relational queries sliding windows 
brevity discussion related topics omitted 
early stream workflow processing programming languages community 
see survey 
line data mining time series analysis streams sliding windows 
see overview system demonstrations 
application specific dsms issues query processing sensor networks 
see example representative papers 
distributed stream processing 
see example cape spc distributed dsmss extensions telegraphcq system parallel dataflow processing distributed query processing streams distributed tracking approximate stream statistics :10.1.1.145.2345
remainder chapter surveys dsms data models query languages section operator implementation section query processing section query optimization section 
sliding window query processing data streams data models query languages dsmss data models data stream append sequence timestamped items arrive order 
items may arrive bursts stream may modeled sequence sets bags elements set storing elements arrived unit time order specified tuples arrived time 
relation stream models stream individual items take form relational tuples tuples arriving stream schema 
object models cougar tribeca sources item types may instantiations hierarchical data types associated methods 
introduced section stream items may contain explicit source assigned timestamps implicit timestamps assigned dsms arrival 
case timestamp attribute may may part stream schema may may visible users 
stream items may arrive order explicit timestamps pre processed form 
instance propagating header ip packet value partially pre aggregated values may produced summarize length connection ip addresses number bytes transmitted 
gives rise list possible models 
unordered cash register individual items various domains arrive particular order pre processing 
general model 

ordered cash register individual items various domains pre processed arrive known order timestamp order 

unordered aggregate individual items domain pre processed item domain arrives particular order packet tcp connection 

ordered aggregate individual items domain pre processed item domain arrives known order packet tcp connection increasing order connection times 
discussed section unbounded streams stored locally dsms excerpt stream usually interest time 
general may accomplished time decay model referred amnesic fading model 
time decay models discount item stream scaling factor non decreasing time 
exponential polynomial decay examples window models items window full consideration items outside window ignored 
windows may classified criteria 
majority dsms research assumes data streams append processing revision tuples understood replace previously reported presumably erroneous data 
alternatively point view publish subscribe systems data stream may thought sequence events reported continually 
survey data stream management 
direction movement endpoints fixed endpoints define fixed window sliding endpoints forward backward replacing old items new items arrive define sliding window fixed endpoint moving endpoint forward backward define landmark window 
total possibilities endpoints fixed moving forward moving backward 

definition window size logical time windows defined terms time interval physical known count tuple windows defined terms number tuples 
partitioned windows may defined splitting sliding window groups defining separate count window group 
general type predicate window arbitrary predicate specifies contents window packets tcp connections currently open 
predicate window analogous materialized view 

windows windows elastic window model maximum window size queries may need run smaller window boundaries maximum window 
window model maximum window size tuples time units smaller window size endpoint common larger window interest :10.1.1.89.6970

window update interval eager updating advances window arrival new tuple expiration old tuple batch processing lazy updating induces jumping window 
note count window may updated periodically time window may updated number new tuples arrived referred mixed jumping windows 
update interval larger window size result series non overlapping tumbling windows 
consequence unbounded nature data streams dsms data models may include notion change drift underlying distribution assumed generate attribute values stream items details see 
additionally observed practical scenarios stream arrival rates distributions values tend bursty skewed :10.1.1.144.7995
semantics persistent queries answer persistent query time 
monotonic example queries containing simple selection predicates monotonic append stream joins append streams 
see note new tuple arrives satisfies selection join predicate satisfaction condition change time 
monotonic semantics may defined follows assuming time represented set natural numbers 
proven persistent query monotonic respect output sequence non blocking need wait output marker producing results 
sliding window query processing data streams suffices re evaluate query newly arrived items append qualifying tuples result 
consequently answer monotonic persistent query continuous append stream results 
optionally output may updated periodically appending batch new results 
non monotonic queries may produce results cease valid new data added existing data changed deleted 
context time queries current state dbms non monotonic queries negation blocking read entire data set returning results 
context dsmss persistent queries negation non monotonic issued append stream select stream mail messages messages received reply 
semantics non monotonic persistent queries follows 
definition time equal output corresponding time relational query inputs current states streams sliding windows relations referenced results updated periodically reflect state inputs update 
conceptually ways representing answer non monotonic persistent query 
query re executed scratch return complete answer time instant periodically 
second result may materialized view incurs insertions deletions updates time 
third answer may continuous stream contains new results negative tuples correspond deletions result set 
note definition queries sliding windows non monotonic input tuple expires window results generated removed answer set way negative tuples 
presents different definition monotonicity relates non blocking computation independent expiration mechanism 
definition queries non blocking monotonic unbounded streams monotonic sliding windows 
definitions unified chapter 
dsms query algebras languages querying paradigms streaming data proposed literature 
declarative languages sql syntax stream specific semantics described 
similarly object languages resemble sql syntax employ dsms specific constructs semantics may include support streaming data types adts associated methods 
procedural systems construct queries defining data flow various operators 
survey data stream management declarative languages proposed declarative languages cql gsql :10.1.1.11.8839
continuous query language cql stream dsms includes types operators relation relation corresponding standard relational algebraic operators stream relation sliding windows relation stream 
conceptually unbounded streams converted relations way sliding windows query computed current state sliding windows traditional sql query output converted back stream 
relation stream operators istream rstream specify nature output 
istream operator returns stream tuples exist relation current time exist current time minus 
istream suggests incremental evaluation monotonic queries 
returns stream tuples existed relation previous time unit current time 
conceptually analogous generating negative tuples non monotonic queries 
rstream operator streams contents entire output relation current time corresponds generating complete answer non monotonic query 
rstream operator may periodic query evaluation recall lazy updating jumping windows section produce output stream consisting sequence relations corresponding answer different point time 
example query computing join time windows size minute shown range keyword name input stream specifies time sliding window stream rows keyword may define count sliding windows 
select rstream range min range min gsql gigascope stream database network monitoring analysis 
input output operator stream reasons composability 
stream required ordering attribute timestamp packet sequence number 
gsql includes subset operators sql selection aggregation group join streams predicate include ordering attributes form join window 
stream merge operator standard sql included works order preserving union ordered streams 
operator useful network traffic analysis flows multiple links need merged analysis 
landmark windows supported directly sliding windows may simulated user defined functions 
telegraphcq system noteworthy windowing capabilities 
query expressed sql syntax constructed sql set relational operators followed loop construct variable iterates time 
loop contains statement specifies type size window 
stream st start time query 
specify sliding window size run time units loop may appended query 
sliding window query processing data streams st st changing landmark window done replacing constant statement 
changing loop increment condition cause query time units 
output query consists time sequence sets set corresponding answer set query time cf 
rstream 
object languages approach object oriented stream modeling classify stream contents type hierarchy 
method tribeca network monitoring system implements internet protocol layers hierarchical data types 
query language tribeca sql syntax accepts single stream input returns output streams 
supported operators limited projection selection aggregation entire input stream sliding window multiplex demultiplex corresponding union group respectively different sets operators may applied sub streams join input stream fixed window 
object possibility model sources adts cougar system managing sensor data 
type sensor modeled adt interface consists supported signal processing methods 
proposed query language sql syntax includes clause indicates query re execution frequency 
details language available published literature included table 
simple example query runs seconds returns temperature readings sensors third floor building may specified follows 
select floor procedural languages alternative declarative query languages user specify data flow system 
aurora dsms users construct query plans graphical interface arranging boxes corresponding query operators joining directed arcs specify data flow system may re arrange add remove operators optimization phase 
boxes arrows query language aurora accepts streams inputs returns streams output static data sets may incorporated query plans connection points 
total operators algebra order sensitive 
order insensitive operators projection union map applying arbitrary function tuples stream window thereof 
operators require order specification includes ordered field survey data stream management slack parameter 
defines maximum disorder stream slack means tuple stream sorted order positions time units away sorted order 
order sensitive operators buffered sort takes sorted stream slack parameter outputs stream sorted order windowed aggregates user specify advance window re evaluate aggregate binary band join joins tuples timestamps units apart resample generates missing stream values interpolation tuples timestamps new tuple timestamp generated attribute value average tuples values 
summary dsms query languages summary proposed dsms query languages provided table respect allowed inputs outputs streams relations novel operators supported window types fixed landmark sliding supported query re execution frequency continuous periodic 
exception surface syntax dsms query languages similar sql semantics considerably different 
cql allows widest range semantics relation stream operators note cql re uses semantics sql relation relation phase incorporates streaming semantics stream relation relation stream components 
hand gsql tribeca allow streaming output continually periodically outputs entire answer set 
terms expressive power cql closely mirrors sql cql core set operators identical sql 
additionally express wider range windows cql 
gsql tribeca operate stream stream mode may thought restrictions sql focus incremental non blocking computation 
particular gsql tribeca application specific network monitoring designed fast implementation 
gsql stream stream languages result may lost expressive power compared sql extensible user defined functions 
noteworthy attention issues related real time processing buffering order arrivals timeouts 
dsms query operators recall relational operators blocking 
instance prior returning result nested loops join may potentially scan entire inner table compare tuple current outer tuple 
sufficient memory pipelined non blocking equivalently monotonic query may executed data streams 
conceptually operator may thought function consumes inputs streams stores state performs computation response new data outputs stream resampling functions possible maximum minimum weighted average neighbouring data values 
sliding window query processing data streams language allowed allowed novel supported execution system inputs outputs operators windows frequency cql streams streams relation stream sliding continuous stream relations relations stream relation periodic gsql streams streams order preserving landmark periodic gigascope union streams streams resample map fixed landmark continuous aurora relations buffered sort sliding periodic streams sequences fixed landmark continuous telegraphcq relations relations sliding periodic tribeca single streams multiplex fixed landmark continuous stream demultiplex sliding table summary proposed data stream languages results 
discussed standard relational operators supported dsmss implementation considerably different 
query operators unbounded streams operator implementation duplicate preserving projection selection union stateless operators process new tuples fly discarding unwanted attributes projection dropping tuples satisfy selection condition 
example selection stream shown 
note non blocking merge union timestamp column allowed order ensure output produced timestamp order 
non blocking pipelined join shown :10.1.1.10.1375
stores input streams possibly form hash tables arrival inputs state input probed generate new results 
joins streams joins streams static relations straightforward extensions 
arrival input states inputs probed 
new arrivals stream trigger probing relation 
duplicate elimination illustrated maintains list distinct values seen filters duplicates output stream 
shown new tuple value arrives operator probes output list drops new tuple tuple value seen appended output stream 
non blocking aggregation shown 
new tuple arrives new result appended output stream aggregate value changed 
new result understood replace previously reported results 
group may thought general technically means duplicate preserving union stateless operator 
required store order tuples entire input 
survey data stream management examples persistent query operators data streams case aggregation newly arrived tuple may produce new output aggregate value group changed 
time space requirements aggregation depend type function computed 
aggregate distributive disjoint multi sets 
distributive aggregates count sum max min may computed incrementally constant space time tuple 
instance sum evaluated storing current sum continually adding values new tuples arrive 
algebraic computed values distributive aggregates constant space time avg algebraic avg sum count 
algebraic aggregates incrementally computable constant space time 
hand holistic multi sets computing requires space proportional size examples holistic aggregates include top quantile count distinct 
instance multiplicities distinct value seen far may maintained order identify frequent item types point time 
requires space number stream tuples seen far consider stream unique values values occurring twice 
non monotonic queries unbounded streams possible previously reported results removed cease satisfy query 
done appending corresponding negative tuples output stream 
way negation streams may produce results valid time possibly invalidate 
example shown tuple value appended output exist matching tuples time 
negative tuple denoted generated output stream subsequent arrival tuple value sliding window query processing data streams memory requirements joins complex aggregation negation may require unbounded memory executed streams 
computing memory requirements continuous queries studied earlier context enforcing temporal integrity constraints :10.1.1.10.3265
consider unbounded streams 
query may evaluated bounded memory projection preserves duplicates 
preserve duplicates integer suffices maintain count tuples count tuples remove duplicates necessary store flags indicating tuples occurred 
conversely query computable finite memory duplicates 
interestingly computable finite memory duplicates preserved tuple added answer soon arrives 
hand query computable bounded memory duplicates removed integer suffices maintain current minimum value tuples current maximum value tuples exploiting stream constraints way reduce state requirements unblock queries exploit stream constraints 
constraints may take form control packets inserted stream called 
instance punctuation may arrive asserting items henceforth attribute value larger 
punctuation partially unblock group query groups guaranteed change remainder stream lifetime punctuation arrives specifies 
may reduce state required operators joins aggregation synchronize multiple streams source may send punctuation asserting produce tuples timestamp smaller 
called heartbeats 
note constraints may useful precisely adhered times 
example streams nearly synchronized timestamps equi join timestamp attribute performed little space 
approximating unbounded streams limited space recall holistic aggregates may require unbounded memory order return exact results 
alternate solution maintain possibly non uniform sample stream compute approximate aggregates sample 
sampling number algorithms approximating count distinct quantile top queries 
possibility avoid storing frequency counters distinct value seen far periodically evicting counters having low values 
possible approach comput survey data stream management ing top queries long frequently occurring values missed repeatedly deleting re starting counters 
related space reduction technique may approximate quantile computation rank subset values stored corresponding error bounds storing sorted list frequency counters exact quantile calculation 
hashing way reducing number counters need maintained 
stream summaries created hashing referred sketches 
examples include 
flajolet martin fm sketch count distinct queries 
uses set hash functions hj map value integral range log probability pr hj upper bound number possible distinct values 
distinct items stream hash function expected map items bucket items bucket buckets log expected empty 
highest numbered non empty bucket estimate value log fm sketch approximates averaging estimate log largest non zero bit hash function 
count min cm sketch dimensional array counters dimensions associated hash functions call hd mapping stream items integral range 
new tuple arrives value cells array incremented hi estimate count tuples value obtained minimum values cells hi approximate counts compute top queries 
detailed survey stream summarization approximate histograms approximate stream algorithms scope dissertation 
information topics may surveys tutorials 
implementation approximate algorithms gigascope dsms described 
query operators sliding windows sliding window operators process types events arrivals new tuples expirations old tuples orthogonal problem determining tuples expire discussed section 
actions taken arrival expiration vary operators 
new tuple may generate new results join remove previously generated results negation 
furthermore expired tuple may cause removal tuples result aggregation addition new tuples result duplicate elimination negation 
operators explicitly react expired tuples producing new results invalidating existing results perform state purging eagerly duplicate elimination aggregation negation may eagerly lazily join 
sliding window join newly arrived tuples inputs probe state input join unbounded streams 
additionally expired tuples removed sliding window query processing data streams state 
expiration done periodically lazily long old tuples identified skipped processing 
aggregation sliding window updates result new tuples arrive old tuples expire recall 
cases entire window needs stored order account expired tuples selected tuples may removed early expiration guaranteed influence result 
example computing max tuples value need stored tuple window value greater younger timestamp see additional examples reducing memory usage context skyline queries context top queries 
additionally order enable incremental computation aggregation operator stores current answer distributive algebraic aggregates frequency counters distinct values window holistic aggregates 
instance computing count entails storing current count incrementing new tuple arrives decrementing tuple expires 
note contrast join operator expirations dealt immediately upto date aggregate value returned right away 
example recall observe expiration tuple value delayed answer temporarily incorrect soon tuple value expires answer changed 
duplicate elimination sliding window may produce new output input tuple expires 
occurs tuple value produced output stream expires window tuples value window 
alternatively case stream dsms duplicate elimination may produce single result tuple particular value retain output stream long tuple value window alternatives analyzed detail chapter 
cases expirations handled eagerly correct result maintained times 
negation sliding windows may produce negative tuples arrival tuple value causes deletion previously reported result value may produce new results expiration tuples tuple value expires tuple value may need appended output stream 
way implementing duplicate preserving negation follows 
left right inputs stored multiplicities distinct values occurring 
number tuples value respectively 
distinct value output negation operator consists tuples 
new arrival value inserted state buffer corresponding counter incremented 
new tuple appended output stream 
expiration handled eagerly removing old tuple state decrementing 
arrival value inserted state buffer increments 
see implementation sliding window aggregates sql user defined functions 
survey data stream management result tuple value say oldest deleted answer set satisfy negation condition equation 
case negation unbounded streams explicit deletions represented negative tuples 
tuple value expires decremented probed tuple value say youngest appended output stream 
dsms query processing having discussed implementation individual operators section outlines dsms query processing 
dbms declarative queries translated execution plans map logical operators specified query physical implementations 
inputs operator state assumed fit main memory disk processing discussed section 
queuing scheduling dbms operators pull dsms operators consume data pushed plan sources 
queues allow sources push data query plan operators retrieve data needed see discussion calculating queue sizes streaming relational operators classical queueing theory :10.1.1.12.4794
simple scheduling strategy allocates time slice operator operator extracts tuples input queue processes timestamp order deposits output tuples operator input queue 
time slice may fixed dynamically calculated size operator input queue processing speed 
possible improvement schedule tuples processed multiple operators 
general possibly conflicting criteria involved choosing scheduling strategy queue sizes presence bursty stream arrival patterns average maximum latency output tuples average maximum delay reporting answer relative arrival new data :10.1.1.58.1029
determining tuples expire addition dequeuing processing new tuples sliding window operators remove old tuples state buffers possibly update answers discussed section 
expiration individual time window simple tuple expires timestamp falls range window 
new tuple timestamp ts arrives receives timestamp call exp denotes expiration time ts plus window length 
effect tuple window may associated lifetime interval length equal window size 
tuple joins tuple window insertion expiration timestamps ts exp respectively expiration timestamp result tuple set min exp exp 
composite result tuple expires constituent tuples expires windows recall definition 
means various sliding window query processing data streams join results may different lifetime lengths furthermore lifetime join result may lifetime shorter window size 
discussed section negation operator may force result tuples expire earlier exp timestamps generating negative tuples 
stream bounded sliding window expiration time tuple infinity 
count window number tuples remains constant time 
expiration implemented overwriting oldest tuple newly arrived tuple 
operator stores state corresponding output count window join number tuples state may change depending join attribute values new tuples 
case expirations signaled explicitly negative tuples 
continuous query processing sliding windows techniques sliding window query processing state maintenance negative tuple approach direct approach :10.1.1.78.2092
negative tuple approach negative tuple approach window referenced query assigned operator explicitly generates negative tuple expiration addition pushing newly arrived tuples query plan 
window materialized appropriate negative tuples produced 
approach generalizes purpose negative tuples signal expirations explicitly produced negation operator result tuple expires longer satisfies negation condition 
negative tuples propagate query plan processed operators similar way regular tuples cause operators remove corresponding real tuples state illustrated showing aggregation sliding window join processes particular negative tuple generated expiration window stream expirations window treated similarly shown clarity 
observe negative tuple processed operators pipeline aggregation operator may eventually receive number negative tuples corresponding join results original negative tuple participated 
negative tuple approach implemented efficiently hash tables operator state expired tuples looked quickly response negative tuples 
conceptually similar dbms indexing table materialized view primary key order speed insertions deletions 
downside twice tuples processed query tuple eventually expires window generates corresponding negative tuple 
furthermore additional operators labeled window state plan generate negative tuples window slides forward 
note storing local copy tuple operator state may consist pointers tuples 
survey data stream management query execution negative tuple approach direct approach query execution direct approach negation free queries time windows property expiration times base tuples intermediate results determined exp timestamps explained section 
operators access state directly find expired tuples need negative tuples 
direct approach illustrated query deletions window stream illustrated 
new arrival join state buffers expiration performed time processing new tuple 
arrivals time interval may specified user maximum delay reporting new answers operator stores state initiates expiration state buffer 
direct approach incur overhead negative tuples store base windows referenced query 
may slower negative tuple approach queries multiple windows 
straightforward implementations state buffers may require sequential scan insertions deletions 
example state buffer sorted tuple arrival time insertions simple deletions require sequential scan buffer 
hand sorting buffer expiration time simplifies deletions insertions may require sequential scan ensure new tuple ordered correctly insertion order expiration order 
issue dealt chapter 
technical issue direct approach newly arrived tuples may processed immediately operators pipeline state intermediate results may delayed respect inputs 
example tuples timestamps may arrived input streams max operator may processed tuples timestamps remaining tuples stuck operator queues pipeline 
solution guarantee correct results maintains local clock operator sliding window query processing data streams sliding window implemented circular array pointers sub windows corresponding timestamp tuple processed parent 
way local clock max operator expire tuples state prematurely assuming current time 
related problem appears newly arrived tuples dropped early processing satisfy query selection predicate 
case max operator receive new input check old tuples aggregate value may changed result expiration 
local clock approach handle case max operator requests value local clock join requests value local clock selection operator 
selection operator may passed tuples forward local clock correspond timestamp latest tuple seen 
alternate solution selection operator periodically propagate punctuation heartbeat plan passed regular tuples match selection predicate 
punctuation contains timestamp processed tuple tuple satisfy selection condition 
periodic query processing sliding windows query processing windows stored memory reasons efficiency reduced expiration query processing costs user preference users may find easier deal periodic output continuous output stream sliding windows may advanced queries re evaluated periodically specified frequency :10.1.1.11.8839:10.1.1.136.4253
illustrated window modeled circular array sub windows spanning equal time interval time windows minute window slides minute equal number tuples tuple windows tuple window slides tuples 
window update denote process replacing oldest sub window newly arrived data accumulated buffer sliding window forward sub window 
periodic evaluation window aggregates secondary goal sharing state similar aggregates different window sizes summarized 
alternatively queries may re evaluated demand suggested case materialized query result required contain correct results probed query 
survey data stream management examples running interval basic interval synopses storing entire window re computing aggregate new tuple arrives old tuple expires synopsis stored pre aggregates sub window reports updated answers window slides forward sub window 
running synopsis aggregates sum count 
aggregate multi sets 
running synopsis associated parameters time updates sub window size defines longest window covered synopsis bs type aggregate function create synopsis 
time update sliding window 
synopsis stores aggregate values running intervals bs 
compute window size ns time ns suffices calculate ns 
example shown computing sum window size running synopsis sum 
synopsis update takes place time replaces computed 
done efficiently having buffer pre compute incrementally new tuples arrive 
interval synopsis applies distributive aggregates recall section min max 
interval synopsis parameters defined additionally assume power stores values intervals 
particular disjoint intervals length disjoint intervals length interval length bs 
example uses interval synopsis max compute max window size 
maximum values stored disjoint intervals taken general access log intervals required 
update time may dropped interval sliding window query processing data streams expired tuples 
furthermore inserted synopsis 
may pre computed buffer 
interval full value may computed max 
variations interval synopsis proposed 
note algebraic aggregates may computed synopses appropriate distributive aggregates 
instance avg sum count query computing average may sum count synopses provided cover appropriate window length 
holistic aggregates may interval synopsis stores additional information interval 
instance storing frequency counts values occurring interval may quantile top count distinct queries case buffer pre aggregates newest interval maintaining frequency counts new tuples 
alternatively sample sketch may stored interval recall section 
merging individual sketches obtain approximation entire window straightforward instance corresponding entries cm sketch arrays added 
space usage synopsis update times may reduced storing short intervals bottom interval synopsis 
tradeoff intervals accessed probing log resulting structure referred basic interval synopsis 
example shown max query window length 
variations basic interval synopsis proposed :10.1.1.14.3206
note frequency counts sketches stored running synopsis interval basic interval synopsis appropriate intervals subtracted compute answers various window lengths 
problem storing counters sketches way running interval summarizes entire stream certain point 
synopsis may store counts values appeared long time ago may seen 
leads excessive space usage increased computation costs 
additionally sketches size summarizing interval summarizing expected yield better accuracy approximate entire distribution stream 
result complex aggregates assumed interval basic interval synopsis 
disadvantage periodic query evaluation results may stale 
way stream new results new item arrives bound error caused delayed expiration tuples oldest sub window 
shown restricting sizes sub windows terms number tuples powers imposing limit number subwindows size yields space optimal algorithm called exponential histogram eh approximates simple aggregates logarithmic space respect sliding window size :10.1.1.24.7941
variations eh algorithm approximately compute sum variance medians clustering windowed histograms order statistics 
extensions eh algorithm time windows 
survey data stream management query processing windows stored disk traditional database applications secondary storage performance may improved appropriate indices built 
consider maintaining index periodically sliding window stored disk data warehousing scenario new data arrive periodically decision support queries executed line latest portion data 
order reduce index maintenance costs desirable avoid bringing entire window memory update 
done partitioning data localize updates insertions newly arrived data deletion tuples expired window small number disk pages 
example index sliding window partitioned chronologically youngest partition incurs insertions oldest partition needs checked expirations remaining partitions middle accessed 
similar idea grouping objects expiration time appears context clustering large file systems file associated lifetime 
disadvantage chronological clustering records search key may scattered large number disk pages causing index probes incur prohibitively disk os 
way reduce index access costs store reduced summarized version data fits fewer disk pages necessarily improve index update times 
order balance access update times wave index proposed chronologically divides sliding window equal partitions separately indexed clustered search key efficient data retrieval 
example shown window size minutes updated minutes split sub indices 
triangles indicate index directories associated single sub index trees trees data structure appropriate 
rectangles represent data records stored disk 
left window partitioned insertion time 
right equivalent partitioning shown expiration time window size added item insertion time determine expiration time recall section 
illustrated update time inserts newly arrived tuples times expire times time deleting tuples arrived times expired times 
advantage approach sub index affected update instance changes times change times 
tradeoff access times slower multiple sub indices probed obtain answer 
disk indexing time evolving data revisited chapter 
dsms query optimization usually case query may executed number different ways 
dbms query optimizer responsible enumerating possible query execution strategies choosing efficient cost model set transformation rules 
dsms query optimizer responsibility appropriate cost model rewrite sliding window query processing data streams equivalent illustrations wave index rules 
additionally dsms query optimization involves adaptivity load shedding resource sharing similar queries running parallel summarized 
cost metrics statistics traditional dbmss selectivity information available indices choose efficient query plans require fewest disk accesses 
cost metric apply possibly approximate persistent queries processing cost unit time appropriate 
alternatively stream arrival rates output rates query operators known may possible optimize highest output rate find plan takes time output number tuples 
quality service metrics response time may dsms query optimization 
query rewriting adaptive query optimization dsms query languages discussed section introduce rewritings new operators selections time sliding windows commute selections count windows 
rewritings similar relational databases re ordering sequence binary joins order minimize particular cost metric 
join ordering data streams context rate model 
furthermore adaptive re ordering pipelined stream filters studied adaptive materialization intermediate join results considered 
note prevalence notion adaptivity query rewriting operators may need re ordered fly response changes system conditions 
particular cost query plan may change reasons change processing time operator change selectivity predicate change arrival rate stream 
initial efforts adaptive query plans include mid query re optimization query scrambling objective pre operators blocked schedule operators 
increase adaptivity maintaining rigid tree structured query plan eddies approach introduced evaluated extended multi way joins applied continuous queries currently extended consider semantics information attribute correlations routing performs scheduling tuple separately routing operators query survey data stream management plan :10.1.1.12.4794
effect query plan dynamically re ordered match current system conditions 
accomplished tuple routing policies attempt discover operators fast selective operators scheduled 
extension adds queue length third factor tuple routing strategies presence multiple distributed eddies 
important trade resulting adaptivity overhead required route tuple separately 
details adaptive query processing may 
adaptivity involves line reordering query plan may require internal state stored operators migrated new query plan consisting different arrangement operators 
issue state migration query plans studied 
load shedding approximation stream arrival rates may high tuples processed regardless static run time optimization techniques 
case types load shedding may applied random semantic making stream properties service parameters drop tuples believed significant 
example semantic load shedding consider performing approximate sliding window join objective attaining maximum result size 
idea tuples expire tuples expected produce join results dropped case memory limitations inserted join state ignored probing step case cpu limitations 
note objectives possible obtaining random sample join result 
general desirable shed load way minimize drop accuracy 
problem difficult multiple queries operators involved decided query plan tuples dropped 
clearly dropping tuples early plan effective subsequent operators enjoy reduced load 
strategy may adversely affect accuracy queries parts plan shared 
hand load shedding plan shared sub plans evaluated remaining operators specific individual queries may little effect reducing system load 
results problem optimal placement sampling operators multi query plans may special case random load shedding windowed aggregates quality service driven load shedding windowed aggregates 
approximate evaluation expensive user defined functions streams addressed 
load shedding approach employing feedback loop monitor queue lengths discussed 
issue arises context load shedding query plan generation optimal plan chosen load shedding optimal load shedding 
shown case sliding window aggregates queries involving sliding window joins 
sliding window query processing data streams note dropping tuples periods high load possible put aside spill disk process load 
note case periodic re execution persistent queries increasing re execution interval may thought form load shedding 
multi query optimization seen section memory usage may reduced sharing internal data structures store operator state 
additionally context complex queries containing stateful operators joins computation may shared building common query plan :10.1.1.136.4253
example queries belonging group may share plan produces union results needed individual queries 
final selection applied shared result set new answers routed appropriate queries 
interesting trade appears doing similar multiple times doing unnecessary techniques balance trade :10.1.1.1.9425
example suppose workload includes queries referencing join windows having different selection predicate 
shared query plan performs join routes output appropriate queries done joined tuples may satisfy selection predicate unnecessary tuples generated 
hand query performs selection joins surviving tuples join operator shared tuples probed times 
sharing single join operator queries referencing different window sizes discussed 
selection queries possible multi query optimization index query predicates store auxiliary information tuple identifies queries satisfies :10.1.1.12.4794
new tuple arrives processing attribute values extracted matched query index see queries satisfied tuple 
data queries may thought duals cases reducing query processing multi way join query predicate index data tables 
indexing range predicates discussed predicate index multiple attributes 
chapter update pattern aware modeling processing persistent queries motivated section defining characteristic persistent queries streams windows potentially unbounded time evolving nature inputs outputs 
new answers produced response arrival new data older data expire windows slide forward 
furthermore previously reported answers may cease satisfy query point 
update pattern persistent query plan said order results produced deleted time 
chapter analyzes update patterns persistent query plans presents update pattern aware query semantics processing strategies 
discussed section previous update patterns persistent queries distinguishes monotonic non monotonic queries feasible unbounded streams 
update patterns monotonic queries simple results expire 
classification sufficiently precise fails sort non monotonic queries pattern deletions answer sets 
motivate need study update patterns persistent queries precise definition semantics note definition section distinguish time evolving state data streams versus relational tables 
existing research disallows relations continuous query plans assumes relations static lifetime persistent query allows arbitrary updates 
updates tables allowed semantically different changes caused movement sliding windows 
furthermore discussed section existing research offers conflicting viewpoints nature sliding window queries 
definition queries sliding windows non monotonic results eventually expire windows slide forward 
treat sliding window operators join aggregation monotonic 
similarly considers sliding window query processing data streams line incremental aggregation unbounded stream monotonic assuming date answers deleted result 
issue depends knowledge update patterns maintenance operator state 
recall approaches sliding window query processing section 
direct approach eliminates need generating propagating negative tuples may efficient negative tuple approach state buffers scanned sequentially expiration 
order tuples expire known suitable data structures may designed reduce state maintenance overhead 
contributions chapter consist classification update patterns persistent queries applications classification definition precise query semantics evaluation update pattern aware query processing techniques 
particular classification update patterns persistent query plans divides nonmonotonic plans types order highlight differences expiration patterns 
classification formulate semantics persistent queries 
aware definition query semantics addresses issues 
updates relations treated separately expirations sliding windows 
second conflicting viewpoints regarding monotonicity sliding window queries reconciled 
third difference window input stream versus window output stream query analyzed 
fourth shown types queries periodic re evaluation may produce fewer result tuples continuous execution 
update pattern aware semantics persistent queries incorporated cql 
update pattern aware query processor developed branch query plan annotated update patterns physical operator implementations vary nature inputs 
particular operators update pattern aware data structures intermediate state maintenance 
update pattern aware optimization framework goal choosing query plan simplest update patterns order minimize state maintenance costs simplify operator implementation 
tested ip traffic logs update pattern aware query plans significantly outperform existing data stream processing techniques 
remainder chapter section presents classification update patterns persistent queries section uses classification define persistent query semantics section incorporates update pattern aware semantics cql section develops update processing optimization strategies section presents experimental results 
update pattern aware modeling processing persistent queries update patterns persistent queries classification recall section monotonic query plan produces results expire 
hand results non monotonic query plans finite lifetimes 
purpose section analyze nature lifetimes results persistent query plans order identify update patterns 
assume remainder dissertation data streams consist relational tuples fixed schema arriving non decreasing timestamp order additionally order simplify presentation forthcoming classification assume tuple processed instantaneously soon generated 
tuple generated time ts assumed results produces possibly joining tuples arrived previously expired windows generated time ts 
arbitrary query plan satisfies semantics definition point time sliding windows referenced filled 
recall section defined answer set time 
assume time set natural numbers zero tuples may arrive clock tick 
multi set tuples generated input stream time multi set tuples generated input times including 
may contain arbitrary finite number tuples having arbitrary attribute values long values chosen specified attribute domains 
furthermore ps multi set result tuples produced time es multi set result tuples expire time input set ps es tuples produced expired including time respectively 
note tuples may different schema depending set attributes aggregate functions included select clause query 
definitions assumptions relationship abstractly defines evolution 
ps es updated answer obtained previous answer adding new result tuples produced subtracting expired tuples 
relationship individual persistent query operators may divided types determining update patterns complete query plans discussed section 
operator monotonic es 
result produced lifetime unbounded length regardless contents input stream 
operator weakest non monotonic es ps 
expired results exactly produced time ticks ago non decreasing timestamps implicitly assigned system arrival tuples buffered pushed query plans timestamp order 
sliding window query processing data streams irrespective input lifetime result known generation time furthermore lifetimes finite length operator weak non monotonic true ps es es 
result tuple eventually expires expiration times tuples arrived depend tuples arrive 
words lifetime result tuple known generation time lifetimes necessarily length 
operator strict non monotonic ps es es 
results expiration times depend inputs predicted generation time 
discussion classification identifies types non monotonic operators update patterns weakest non monotonic operators having simplest patterns followed weak strict non monotonic operators respectively 
weakest non monotonic operators produce results expire predictable times order generated fifo 
projection selection time window weakest nonmonotonic merge union time windows 
example selection see drops tuples satisfy predicate alter lifetimes surviving tuples initially set window length recall section 
window slides forward oldest tuple value expires window expires output stream order 
weak non monotonic operators may necessarily exhibit fifo behaviour results predictable expiration times 
join time windows illustrated example 
newly arrived tuple stream may join tuples window just arrived expire 
instance old tuple value expires causes expiration produced output tuple value expiration order necessarily fifo expiration time join result minimum expiration times individual tuples participating result recall discussion section 
significance weakest weak non monotonic operators results predictable expiration times types operators compatible direct approach state maintenance section 
hand strict non monotonic operators produce results unpredictable expiration times negative tuples propagated explicitly announce expirations 
example discussed section negation produces negative tuples indicate previously reported results longer satisfy query 
expirations caused movement sliding windows case weakest weak non monotonic operators update pattern aware modeling processing persistent queries update patterns sliding window operators semantics negation operator may possible determine result tuple expire knowing stream tuples arrive 
note results negation time windows expire naturally fall window previously invalidated negative tuple 
duplicate elimination time window may implemented weak strict nonmonotonic 
consider example shown illustrates weak nonmonotonic implementation 
tuple value produced output stream expires window 
order guarantee weak non monotonicity tuple expire result lifetime predicted expiration timestamp 
exist tuples value window 
order maintain correct answer tuples say youngest appended output expire lifetime ends 
note insertion order result different arrival order evidenced newest result tuples values tuples may appended output stream immediately arrive lifetimes output may different lengths 
straightforward implementation weak non monotonic duplicate elimination stores output order filter duplicates entire input instance described result tuple value expires input accessed order determine tuples value window 
shown section suffices store certain subset input larger size stored output guarantee weak non monotonicity provided inputs implies strict non monotonic operators time windows strict non monotonic unbounded streams time windowing produce premature expirations 
sliding window query processing data streams duplicate elimination operator strict non monotonic 
storing subset input possible track multiplicities distinct values input 
type implementation requires negative tuples input stream storage entire input straightforward weak non monotonic implementation means underlying window stored query plan anyway recall section 
furthermore negative tuples produced output stream meaning update patterns implementation duplicate elimination strict non monotonic 
implementation produces new results new tuples arrive seen values 
additionally duplicate tuples cause corresponding counters incremented expired tuples decrement appropriate counters 
negative tuple appended output stream tuple expires input causes corresponding counter zero 
result tuple expire tuples value current window 
means lifetimes result tuples predicted ahead time negative tuples produced output 
strict non monotonic implementation duplicate elimination stream dsms employs negative tuple approach query processing expiration 
note group aggregation operators count windows considered chapter strict non monotonic 
illustrated produces updated aggregate values new tuples arrive old tuples expire 
unknown new value arrive stream change value aggregate 
consequently possible predict expiration time current aggregate value 
terms count windows note oldest tuple expires new tuple arrives stream 
expiration times depend arrival times subsequent tuples negative tuples needed signal expirations 
update pattern aware semantics persistent queries section defines semantics persistent queries help proposed update pattern classification 
starting definition meaning relations persistent queries clarified section 
section divides sliding windows types external internal desired behaviour query monotonic system defines windows inputs due memory constraints 
section motivates proposes alternate definition current result query defines window output stream 
section shows weak strict non monotonic queries produce full answer set re evaluated periodically 
defining meaning relations persistent queries dbms relation unordered multi set tuples schema supports arbitrary insertions deletions updates 
dsms relation may referenced query joined stream sliding window 
relations assumed update pattern aware modeling processing persistent queries static possibility arbitrary updates means finite relations appear difficult deal time sliding windows 
see consider operator joins relation time window call definition insertion table requires window scan order produce new join results 
current output correspond current state input streams relations times 
similarly deletion table requires window scan order undo previously reported join results containing deleted tuple 
negative tuples produced output stream result corresponds current state relation 
result strict non monotonic join time windows weak non monotonic 
update pattern classification solution considers updates relations easier insertions expirations sliding windows treat weakest nonmonotonic 
constraint solution defines non retroactive relation nrr table allows arbitrary updates semantics updates affect previously arrived stream tuples 
consequently join sliding window nrr denoted nrr need scan window processing update nrr incoming stream tuples trigger probing nrr generation new results 
streaming input stored furthermore nrr monotonic second input stream weakest non monotonic time window 
aside simpler implement definition intuitive nature data stored dsmss relations metadata 
example line financial ticker may store table mappings stock symbols names 
case financial ticker updates table stock symbols names deleting row corresponding longer traded previously returned stock quotes need deleted 
similarly adding new stock symbol new involve attempting join stock symbol previously arrived stream tuples prior stock quotes new 
formally update nrr time affects stream tuples arrive time 
restriction context involves deleting row table subsequently adding row having key 
example removed nrr stock quotes deleted result insertion different key appear old stock quotes refer new 
way solve problem involves banning re keys nrr 
note difference streams relations strictly semantic 
possible treat metadata stream insertions retroactive previously arrived tuples traditional relation arbitrary insertions deletions updates affect previously arrived stream tuples 
explained update patterns implementations operators allow retroactive updates complicated 
revised definition semantics persistent queries follows 
persistent query streams possibly bounded sliding windows zero zero relations runs period time produces output 
sliding window query processing data streams definition answer set time nrr nrr state referenced time 
ts timestamp result tuple equivalent output corresponding relational query inputs current states streams sliding windows relations referenced addition result tuple reflect state referenced nrr ts nrr ts ts 
note definition includes situations query arrives processing system maintaining window interest query queries stream queries referencing stream specify shorter windows 
current state sliding window may initially empty grows required size begins slide forward 
appropriate window maintained system definition assumes query start producing answers right away window effect having access historical data arrived query registered 
similar assumption new persistent queries tuples :10.1.1.12.4794:10.1.1.1.4609
internal external windows definition implies sliding window operators non monotonic 
may restrictive windows manage unboundedness input streams 
case fact tuple expires window necessarily imply expires output 
issue may resolved defining types sliding windows time count 
external windows output meant conform definition user application semantics specifically request old results removed result windows slide forward 
operators external windows weakest weak strict non monotonic 
internal windows output meant monotonic 
semantics operator internal windows produces results order case external windows output stream assumed append 
lifetimes results unbounded length 
example internal windows involves join streams 
compared unbounded stream join internal windows allow join executed finite memory producing results matching tuples window size expired tuples removed inputs 
note join internal windows produces output order join external windows illustrated results expire 
furthermore join time windows weakest non monotonic external 
windows update pattern aware modeling processing persistent queries output aggregation query types windows processing join internal windows materialized view time external join weak non monotonic 
join unbounded streams internal time windows monotonic 
internal external windows may grouping aggregation internal windows producing append output stream 
instance outputs expire internal windows 
unbounded external internal windows may defined aggregation streams giving rise types windows internal sliding external sliding internal unbounded external unbounded 
turn defines types semantics aggregate queries shown query sum unbounded stream count window size 
note external windowing causes previously reported aggregate value removed crossed result set new value computed 
note internal windowing apply duplicate elimination negation forcing operators monotonic form violates semantics 
example results deleted expire windows output stream may contain duplicates results satisfy negation predicate 
issue regarding internal windows discussed deals composability operators 
recall operator internal windows produce result stream equivalent operator external windows 
output operator internal windows monotonic state maintained external windows 
state maintained continually removing tuples expired windows 
example illustrates evaluating window join materializing join means expirations windows sliding window query processing data streams reflected materialized sub result weak non monotonic update patterns assuming windows time 
new tuples join old results 
windowing output stream persistent query similar internal windows inputs bound memory requirements query operators size result may bounded windowing output stream 
semantics windowing output persistent query follows 
count output window size answer consists generated results time output window size answer consists results generated time units 
note size input window independent size output window 
example minute window may defined result stream join minute windows 
fact count output window may defined result query time windows vice versa 
instance count output window may query interested values produced aggregate query internal time window recall 
principle output stream type query may windowed 
may sense negation duplicate elimination reason operators incompatible internal windows recall section 
windowed output may contain tuples violate operator semantics 
example output stream distinct operator contains tuples expired sufficiently large window output stream span tuples 
answer produced windowing output typically conform definition weakest non monotonic operators 
see recall result lifetimes weak non monotonic operators length equivalent placing time window size output stream see 
contrast results weak non monotonic operators remain answer set time output window size yields superset results produced accordance definition 
section note output operator may windowed intermediate state maintained definition 
terms means materialized result reflect current state input windows correct window output stream final result stream windowed 
impact update pattern awareness periodic query processing suppose definition modified result persistent query updated periodically reflecting current state inputs times 
assume interval query re executions call smaller size window query consecutive re executions reflect overlapping window states 
periodic evaluation efficient drawbacks 
results generated time ties assumed broken arbitrarily 
semantics count output window may non deterministic 
update pattern aware modeling processing persistent queries drawbacks periodic query re evaluation tuple arrives period re evaluations results generates reported re evaluation 
tuple expires period re evaluations expiration reflected answer set re evaluation 
result tuple produced re evaluations lifetime shorter reported answer set 
effects illustrated results persistent query represented intervals corresponding lifetimes 
suppose consecutive re evaluations query occur times 
time output contains tuple arrived 
arrival reported time re evaluation occurs 
similarly expiration reflected answer time 
short lived tuple result set time arrived time expired 
notably weak strict non monotonic operators suffer missing result problem lifetimes results weakest non monotonic operators equal window size assumed longer 
short lived results generated sliding window join newly arrived tuple joins tuple expire 
occurs duplicate elimination result tuple value expires tuple window expire soon 
context aggregation missing results values aggregate re evaluations sliding window negation introduce short lived results ways 
new result value may generated invalidated shortly tuple value appears 
second tuple value may expire cause old tuple expire value added result 
may argued delayed updating result expected reasonable sideeffect periodic re evaluation missing answers serious 
leads types semantics periodically re evaluated queries 
restore semantics ignore missing results equivalent definition case re evaluation appends newly generated may large number intermediate aggregate values reported value may change new tuple arrives old tuple expires window 
main reason sliding window aggregation efficient executed periodically outlined section 
sliding window query processing data streams results output stream 
restore semantics force output stream include results produced continual re evaluation 
addition appending new results output stream re evaluation short lived results generated re evaluation expired reported subsequent re evaluation 
instance short lived result reported time 
join processing algorithms restore restore semantics chapter 
making dsms query language update pattern aware having proposed clarifications persistent query semantics internal windows output windows restoring lost answers periodic re evaluation section incorporates concepts continuous query language 
specific cql chosen base language extensions may applied languages 
internal external windows represented cql types stream relation operators 
fact notion internal windows generalizes stream relation functions meant produce monotonic output constraints examples 
internal windows may denoted keyword internal example range min internal 
discussed join internal windows monotonic istream operator may omitted internal keyword window specification 
windowing output stream may modeled new relation stream function call 
example query maintains results time window join specified follows analogous range keyword rows clause specify count windows 
select rows stream range min stream range min note windows need declared internal assumes output monotonic may windowed 
advantage operator facilitates optimization strategy periodically re evaluated distributive aggregates nested sub queries 
instance compute sum attribute minute sliding window re evaluated seconds suffices split stream non overlapping second chunks compute sum chunk add sum chunks get final answer 
query requires nested sub query may posed follows assume final output non monotonic meaning latest value aggregate ought returned rstream keyword may omitted count window output declared internal 
select sum select sum stream range sec slide sec internal rows update pattern aware modeling processing persistent queries second interval inner sub query summed produces monotonic output stream operates internal window 
outer query computes sum count window size defined output inner sub query outer window internal final output non monotonic 
note specifying external window inner sub query give syntax error possible window materialized output consists latest aggregate value 
query simplifies 
select sum sum rows stream range sec slide sec type window specified clause operator implies input window internal 
cql allows periodic query re execution slide clause input window specification range min slide sec 
incorporate restore semantics stream functions may added istream restore rstream restore 
example periodically re evaluated join external windows restore semantics specified follows assuming slide interval windows referenced query 
select rstream restore stream range min slide sec stream range min slide sec note restore defined windowing output stream compatible periodic re evaluation 
instance count output window size periodic re evaluation produces results clear newly generated results included output window time 
update pattern aware query processing optimization section presents update pattern aware query processor optimizer 
goal decrease processing times reduce state maintenance overhead 
existing techniques satisfy requirements negative tuple approach performs state maintenance efficiently performs twice processing direct approach incur processing overhead performs state maintenance inefficiently 
technique described section satisfies goals exploiting update patterns query operators 
remainder chapter windows operator state assumed fit main memory 
update pattern propagation persistent query plans step define update patterns persistent query plans update characteristics individual operators 
wk str denote weakest weak strict sliding window query processing data streams non monotonic update patterns respectively 
edges query plan labeled update pattern aware information follows 
edges originating leaf nodes base windows window time str window count 
remaining edges labeled rules update pattern complete query plan label final output edge 

output type unary weakest non monotonic operators nrr input type 

output binary weakest non monotonic operators str inputs str wk inputs wk inputs 

output weak non monotonic operators str inputs str 
output wk 

output strict non monotonic operators str 
rule follows fact weakest non monotonic operators interfere order incoming tuples 
rule applies merge union reorder incoming tuples output patterns correspond whichever input patterns complex 
rule states wk operators produce update patterns complex wk possibly str inputs contain premature expirations 
rule follows fact count windows str operators relations updates retroactive generate results unpredictable expiration times 
example annotated query plan containing selections joins negation windows shown 
possible cql query may produce plans may structure selection conditions window size specifications omitted clarity rstream operator maintain materialized view result 
select rstream exists select rstream equivalent rewritings query depicted 
observe rewritings result different update patterns edges issue revisited context query optimization section 
note update pattern property particular query plan query 
instance possible rewrite plans way optimize away negation operation update patterns may longer strict non monotonic 
update pattern aware modeling processing persistent queries query plans query annotated update patterns update pattern aware physical plan generation query plan annotated update patterns strategies generation physical query plan operator implementations depend update patterns inputs update pattern aware data structures maintaining operator state 
operator implementation recall section straightforward implementation weak non monotonic duplicate elimination stores input output 
update patterns input wk efficient implementation terms time space complexity possible 
idea avoid storing entire input premature expirations guaranteed occur 
tuple output state suffices additionally store youngest tuple distinct value additional state referred auxiliary output state 
new tuple arrives match tuples stored output inserted output state appended output stream 
new tuple duplicate means youngest tuple particular distinct value added auxiliary output state 
output tuple expires auxiliary output state probed youngest tuple distinct value appended output exists 
storing input output space requirement improved operator call twice size output 
duplicate elimination produces output size larger input space efficient naive weak non monotonic implementation 
time overhead inserting expiring tuples lower entire input scanned 
physical operator str update patterns input tuples stored auxiliary state may expire early may possible determine distinct values window access input 
sliding window query processing data streams storing results weak non monotonic subqueries case choices naive implementation weak non monotonic duplicate elimination strict non monotonic implementation outlined section 
produces fewer positive tuples result expire tuples distinct value input generate negative tuples output results expire unpredictable times note input duplicate elimination operator str subsequent operators prepared deal negative tuples anyway 
reasonable heuristic employ strict non monotonic version case 
data structures storing operator state second update pattern aware physical strategy involves suitable data structures maintaining state 
simplest case update patterns state buffer fifo queue count window result selection count window may stored way 
input wk insertion order different expiration order 
observe state buffer sorted insertion time deletions inefficient entire buffer scanned order find expired tuples 
hand sorting expiration time means insertions require sequential scan state buffer 
solution partition state buffer expiration time effectively forming calendar queue stream tuples thought events scheduled expiration times 
individual partitions days calendar queue sorted expiration time operators expire results eagerly insertion time operators lazy expiration 
example illustrated partitions partition sorted expiration time assuming current time window size 
version calendar queue circular array partitions time left partition contain tuples expiration times 
calendar queue may example store left input negation operator left 
total number result tuples positive negative produced variants duplicate elimination depends distribution attribute values stream sizes windows 
example stream contains distinct values window strict non monotonic implementation produce set initial results invalidated long time 
strict non monotonic operator negation count window query plan ahead duplicate elimination 
update pattern aware modeling processing persistent queries maintaining results sub plans str patterns difficult result tuples may expire unpredictable times 
premature expirations rare calendar queue may understanding occasional premature expirations triggered negative tuples require sequential scan partitions 
majority expirations expected occur negative tuples may beneficial employ negative tuple approach implement state buffers hash tables primary key stream schema 
negative tuples generated expiration 
intuition results expire prematurely system may expire results negative tuples data structure easy 
choice techniques depends frequency premature expiration turn depends distribution attribute values inputs 
example inputs negation operator different sets values negation attribute premature expirations happen 
see note negative tuples produced negation operator inputs contain tuple common attribute value recall section 
hand plan count windows expirations signaled negative tuples negative tuple approach exclusively 
exception rule involves aggregation group 
case result consists aggregate values group may stored array indexed group label 
negative tuples necessary 
new aggregate value group produced understood replace old aggregate value group 
update pattern aware query optimization traditional dbmss may multiple ways evaluating persistent query efficient plan may chosen estimating comparing costs set candidate plans dsms specific unit time cost model accounts operator processing state maintenance negative tuple processing applicable 
candidate plans may derived dbms style algebraic rewritings selection push duplicate elimination push join re ordering 
constraint input nrr strict non monotonic possible push negation 
join involving relation nrr incapable processing negative tuples real tuple corresponds negative tuple may deleted updated relation may possible reproduce join results involving negative tuple 
addition novel set rewritings employed update pattern simplification 
idea push operators simple weakest non monotonic update patterns pulls complicated update patterns particularly strict non monotonic 
done minimize number operators adversely affected negative tuples generally reduce update pattern complexity largest possible sub tree plan 
benefits update pattern simplification include able greater flexibility reordering nrr part update pattern simplification consistent relational optimization sliding window query processing data streams rules 
example pushing weakest non monotonic operators coincides predicate push 
similarity suggests update pattern awareness easily incorporated relational optimizers 
difference relational optimizers typically push negation operator negation condition simple predicate reduces cardinality intermediate results 
context update pattern awareness may cases cheaper pull negation operator order decrease burden processing negative tuples 
example plan left may efficient right final materialized result needs deal negative tuples remainder plan uses direct expiration approach update pattern aware data structures section 
course join generates large number results negation predicate reduces cardinality intermediate results plan right may turn costly negative tuples flowing operators 
update pattern aware optimizer consider possibilities 
experiments overview update pattern aware query processor abbreviated upa implemented java 
comparison negative tuple direct approaches implemented referred nt direct respectively 
sliding windows state buffers implemented linked lists fifo queues circular arrays linked lists calendar queues 
testing performed windows xp machine pentium iv ghz processor mb ram 
query inputs consist network traffic data obtained internet traffic archive ita ee lbl gov 
packet trace experiments contains widearea tcp connections lawrence berkeley laboratory rest world september october :10.1.1.144.7995
tuple trace consists fields system assigned timestamp ts expiration timestamp exp recall section session duration protocol type payload size source ip address destination ip address 
furthermore negative tuples contain special flag 
trace may thought single stream broken logical streams destination ip addresses 
simulates different outgoing links queries containing joins 
types query plans tested illustrated shown 
query joins tuples outgoing links source ip address selection predicate protocol ftp protocol telnet 
selective predicate result size approximately equal size inputs produces times results telnet popular protocol type trace 
query tests performance calendar queue may posed follows cql window lengths vary experiments 
update pattern aware modeling processing persistent queries illustration query plans experiments select rstream link range link range 
link source ip address link source ip address link protocol ftp link protocol ftp query selects distinct source ip addresses distinct source destination ip pairs outgoing link test operator calendar queue 
cql may posed follows different window lengths tested 
select rstream distinct source ip address link range 
query performs negation outgoing links source ip address tests possible choices storing results strict non monotonic queries calendar queue negative tuple approach recall section 
select rstream link range 
exists select rstream link range 
link source ip address link source ip address query performs negation outgoing links source ip address joins third link source ip address having protocol ftp 
query essentially composition queries 
rewritings query illustrated tested order show negation pull may efficient situations 
simplicity implementation incoming tuple fully processed tuple scheduled processing 
result stream arrival rates fixed queuing delays caused bursts tuples arriving time ignored discussed context data stream scheduling orthogonal issue :10.1.1.58.1029
sliding window query processing data streams experimental parameters sliding window size lazy expiration interval operators maintain state lazily eager expiration interval operators grouping duplicate elimination negation react expirations immediately number partitions calendar queues hash tables 
depending query window size varies kilobytes megabytes 
terms time corresponds range time units average tuple arriving link time unit 
simplicity lazy expiration interval set percent window size 
increasing interval gives slightly better performance discussed 
furthermore due fixed stream arrival rates eager expiration interval set tuple inter arrival time nt means new arrival input windows triggers window scan determine negative tuples generated 
direct upa new arrival causes probe state operator immediately react expirations 
number state buffer partitions set noted 
reported performance figures correspond average query execution times including processing tuple insertion expiration tuples processed windows filled 
query variants query tested 
illustrates performance variant uses protocol ftp selection predicate recall selective predicate produces fewer results 
window size grows upa nearly twice fast 
direct outperforms nt result size relatively small cost scanning entire result set updates great overhead negative tuples 
performance direct degrades window size grows 
second variant query analyzed uses protocol telnet selection predicate 
result size approximately times large variant 
case direct far slowest expensive scan large result performing expiration 
update pattern aware approach partitions denoted upa initially performs slow window size result size grows 
increasing number partitions denoted upa yields processing times order magnitude faster nt large window sizes 
query illustrates processing times duplicate elimination source ip address graphs processing times duplicate elimination source destination technically expiration procedure delete old tuples control java garbage collection mechanism 
experiments performed java system gc method acts suggestion java perform garbage collection 
expected processing times technique tested increased method called frequently 
garbage collection discussed implementation specific issue 
update pattern aware modeling processing persistent queries processing times query protocol ftp selection predicate processing times query duplicate elimination source ip address processing times query protocol telnet selection predicate processing times query duplicate elimination source destination ip address pairs ip addresses 
produces small results set roughly distinct ip addresses result set approximately times large 
combining operator calendar queue storing result yields significant performance improvements 
upa order magnitude faster 
upa roughly twice fast nt tested default weak non monotonic version duplicate elimination 
furthermore direct performs poorly result size large 
reason upa greater performance advantage result size small size auxiliary output state smaller faster maintain probe recall section 
average space requirements query graphed duplicate elimination source ip address duplicate elimination source destination ip addresses 
selective upa orders magnitude sliding window query processing data streams space consumption query duplicate elimination source ip address space consumption query duplicate elimination source destination ip address pairs space efficient nt direct recall space requirements proportional output size input size 
selective upa significantly space efficient 
query shows running time negation source ip address nt upa employing calendar queue store results negative tuples premature expirations 
upa slightly outperforms nt window sizes roughly kilobytes 
result size small penalty scanning entire result buffer expiring negative tuple lower overhead generating negative tuples 
window size result size grows upa begins perform worse cost expiring negative tuples high 
experiment fraction premature expirations counted explicitly came approximately percent 
fairly high proportion explains upa competitive small window sizes 
query final test evaluates plans query illustrated 
discussed context query negation source ip address produces relatively large number premature expirations works best negative tuple approach 
case upa pulls negation operator recall section uses negative tuple approach operators follow negation query plan 
plan left executed maintaining intermediate state directly maintaining final result negative tuples generated negation operator join operator generate process negative tuples 
plan right negation pushed upa update pattern aware modeling processing persistent queries processing times query processing times query equivalent negative tuple approach plan 
shows processing times query possible approaches negative tuples negation operator pulled negative tuples join pulled denoted nt join negation pushed upa negation pulled 
note nt join outperforms nt negation operator selective join plan costs negative tuple approach 
upa performs best sufficiently large window sizes decrease number negative tuples generated processed 
note nt join optimal small window sizes number negative tuples generated small processing overhead large penalty sub optimal ordering 
join query produced large number results pushing join negation highly sub optimal despite savings negative tuple processing 
hand ordering join pushed optimal upa plan efficient eliminating overhead processing negative tuples negation operator 
lessons learned experiments illustrated advantages update pattern aware query processing compared direct approach performs state maintenance inefficiently negative approach effectively doubles query processing time positive negative tuples processed operator 
query additionally shown power update pattern aware query optimization finding efficient query plans considered relational query optimizer employing standard optimization heuristics 
chapter indexing time evolving data variable lifetimes chapter extends update pattern awareness accommodate dsms applications spool data disk line analysis 
applications consideration chapter monitor data generated sources perform light weight processing fly periodically append new data disk archive 
archive responsible removing expired data facilitating complex line queries expensive done real time 
examples include network traffic analysis archive mined internet service provider isp order discover usage patterns plan changes network infrastructure transaction logging point sale purchase records telephone call logs examined customer behaviour analysis fraud detection networks sensors measure physical phenomena temperature humidity observations discover trends predictions 
recall section previous indexing sliding windows secondary storage wave index partitions data chronologically separate sub indices 
result partition needs accessed loaded memory periodic update 
wave index assumption order data inserted equivalent expiration order means lifetime data item 
explained section assumption weakest non monotonic update patterns holds application maintains time sliding windows materialized results simple queries selection 
may choose store indexed materialized results derived base windows sliding window join 
queries archive compute join materializing join result removes need interested query compute scratch index may interested query efficiently deciding sub expressions materialize orthogonal problem pursued see sliding window query processing data streams equal lifetimes variable lifetimes memory fifo queue calendar queue disk wave index table classification previous maintenance time evolving data extract relevant data processing 
noted section join time sliding window weak non monotonic results may different lifetimes 
addition introducing variable lifetimes way materialized results weak nonmonotonic query plans sources may explicitly assign different lifetimes data generate 
example sensor may produce temperature measurements minutes giving value lifetime minutes replaced new value sensor may report humidity values fifteen minutes 
similarly various sources may polled explicitly different frequencies 
instance humidity sensor may require energy compute transmit new value temperature sensor polled order save battery power 
illustrated table existing storing time evolving data may classified criteria main memory versus secondary storage equal versus variable lifetimes data items 
main memory solutions chapter wave index appropriate disk storage data having equal lifetimes chapter exploits update pattern awareness solve challenging scenarios disk indexing data items having variable lifetimes 
remainder chapter section explains limitations previous section presents solution section experimentally shows advantages proposed solution terms index update access times 
assumptions motivation problem addressed chapter concerns indexing time evolving set data items associated lifetimes index lookups periodic updates may done efficiently 
expiration time item assumed known generation time lifetimes various items may different lengths pre determined upper bound weak nonmonotonic update patterns 
applications generate data unpredictable approximate lifetimes lifetimes length may change response availability storage space strict non monotonic update patterns considered 
new data continually generated sources buffered main memory index updates 
update new items arrived update inserted items lifetimes possible solutions context data streams sliding windows 
previous storing large sliding windows disk avoiding deletions altogether materializing multiple append prefixes window 
underlying assumption lifetimes data items equal window length 
indexing time evolving data variable lifetimes expired deleted 
involves bringing pages memory updating writing back disk 
access types supported probes retrieval items having particular search key value range scans entire index 
probes may performed queries access shared materialized result extract relevant subset data processing 
scans performed complex queries examine entire data set order update answers 
chronologically partitioned index similar wave index illustrated inappropriate disk storage data variable lifetimes 
suppose index partitioned insertion time left 
time accessed order insert new items 
sub indices need scanned order determine records expired longer case items inserted times expire time 
may require large number disk os cause unacceptably slow updates 
similarly partitioning index deletion times right means expired items time may insertions sub index case records inserted times expire times 
sub indices may need read memory index updates 
recall calendar queue conceptually similar wave index chapter store results weak non monotonic queries 
assumption data fit main memory 
calendar queue split expiration time sufficient main memory scenario goal expirations efficient having scan entire result insertions allowed scattered entire result luxury random access main memory 
chapter fact data stored disk means insertions expirations localized small number sub indices order prevent entire index brought main memory update 
proposed solution recall section wave index balances requirements clustering search key efficient probing insertion expiration time updates confined single sub index 
disk indexing time evolving data variable lifetimes involves conflicting requirements clustering search key efficient probing insertion time efficient insertions expiration time efficient deletions 
section propose solution referred doubly partitioned index reconciles constraints 
idea simultaneously partition index insertion expiration times 
double partitioning simple example doubly partitioned index improved variant shortly shown lifetimes data records minutes sliding window query processing data streams example doubly partitioned index showing update time bottom updates performed minutes 
case wave index sub index contains directory search key stores data records disk clustered search key 
ranges insertion expiration times chronologically divided partitions creating total sub indices 
illustrated time sub index stores data items inserted times expire times sub indices may described similarly 
update illustrated bottom takes place time inserts new items deletes expired items 
observe accessed update updates times 
updates times insert delete accessed 
general increasing number partitions leads sub indices accessed updates decreasing index maintenance costs 
flaw chronological partitioning insertion expiration times sub indices may widely different sizes 
recall note time stores items arrived times expire times 
empty time items lifetimes larger 
result sub indices large update costs may dominate maintenance cost 
problem may addressed adjusting intervals spanned sub index 
improved technique referred round robin partitioning illustrated parameters items lifetimes minutes index updates done minutes 
rows intervals underneath sub index correspond insertion time expiration time ranges respectively 
dividing insertion expiration time ranges chronologically round robin partitioning distributes updates roundrobin fashion sub index experiences consecutive insertions expirations 
instance update illustrated bottom takes place time inserts new indexing time evolving data variable lifetimes example round robin doubly partitioned index showing update time bottom tuples expires tuples 
update time inserts new tuples deletes old tuples 
fact consecutive updates spread different sub indices ensures sub indices similar sizes formalized theorem 
shown experimentally section property translates efficient index updates 
theorem constant rate insertion result uniform distribution data lifetimes average variance sub index sizes round robin partitioning lower average variance sub index sizes chronological partitioning 
proof 
see appendix doubly partitioned indices compatible bulk update strategies denoted rebuild 
rebuild updated sub indices completely rebuilt re clustered records search key stored contiguously dynamically sized bucket spanning contiguous disk pages 
sub index allocates multiple fixed size buckets search key usually contiguously 
updates may cause additional buckets created existing buckets deleted empty 
number sub indices number partitions generation insertion times number partitions expiration times furthermore upper bound lifetimes data items time interval consecutive index updates 
algorithm implements round robin doubly partitioned index example figures 
sliding window query processing data streams algorithm round robin doubly partitioned index input number partitions insertion times number partitions expiration times maximum lifetime data item interval consecutive index updates initial stage time assigned insertion time range ig ig ij assigned expiration time range ig ig insert initial result tuples appropriate sub indices periodic update stage time 
sub index expiration time range replace range delete tuples expiration times sub index insertion time range replace range insert new result tuples appropriate sub indices contains stages initial stage periodic update stage 
suppose algorithm starts set data assumed valid time 
initial stage partitions insertion expiration times inserts data records appropriate sub indices builds corresponding sub index directories 
update stage periodically accesses selected sub indices order adjust insertion expiration times span insert delete tuples appropriate sub indices insertion expiration times update corresponding sub index directories 
detailed implementation insertions deletions shown algorithm depends clustering technique rebuild versus 
similarly specific details concerning directory updates omitted algorithm compatible wide range directory data structures 
note lines periodic update stage look sub index range insertion expiration times spans 
way speed lookups indexing time evolving data variable lifetimes maintain meta index time intervals spanned individual sub indices see context data stream processing context traditional spatio temporal indexing 
improvement considered chapter number sub indices doubly partitioned index expected large determining sub indices accessed update expensive 
cost analysis number sub indices accessed update 
choose optimal values respect number sub index accesses suffices minimize yields value chosen perfect square 
increasing increases space requirements sub index requires directory search key leads slower query times index scans probes need access sub indices 
additionally individual sub indices accessed updates increases 
sub indices faster update smaller fraction data need updated decreases 
instance setting figures means sub indices scanned updates increasing means sixteen sub indices accessed 
shown section increasing initially decreases update times eventually breakpoint reached individual sub indices small making splits helpful note breakpoint value expected higher larger data sets 
part maintenance query costs contributed operations done sub index accessed 
fixing rebuild faster query bucket accessed find records search key slower update especially data size grows rebuilding large indices may expensive 
access slower records search key may scattered buckets faster update individual updates costly rebuilding entire sub index 
furthermore total size may larger rebuild pre allocated buckets may full 
handling fluctuating stream conditions round robin partitioning creates sub indices similar sizes amount new data arriving updates change 
worst case data rate may alternate slow bursty periods causing round robin allocation policy create large small 
algorithmic solution case randomize update allocation policy 
practice random fluctuations data rate expected 
furthermore change data rate may persistent index updates short lived consecutive updates 
cases round robin partitioning expected adapt new conditions 
persistent change round robin update allocation ensures updates spread sub indices 
number new sliding window query processing data streams data items increases decreases sub index turn get larger smaller sub indices similar sizes 
chronological partitioning sub index receive number consecutive updates larger smaller 
change short lived better equal sub index sizes 
burst new data inserted large sub index larger 
experiments section contains overview implementation doubly partitioned indices section experimental results 
sections results experiments small data set approximately megabytes corresponds data generated time time units average record generated time unit 
section investigates index performance larger data sets sizes gigabytes data produced time time units average record generated time unit 
experimental findings summarized section 
implementation details doubly partitioned indices rebuild implemented java tested linux pc pentium iv ghz processor gigabytes ram 
comparison chronologically partitioned wave indices implemented recall similar rebuild sub indices updates del similar maintains multiple fixed size buckets key 
del may partitioned insertion time abbreviated ins ins respectively expiration time abbreviated exp exp 
indexing techniques referred abbreviations followed value number sub indices values number partitions insertion expiration times respectively ins rebuild 
test consists initial building stage update stage 
building stage populates index records randomly generated lifetimes search key values generated uniform distribution 
total data size initial stage varies megabyte gigabytes 
periodic updates generated lifetime search key distribution inserted index time removing expired tuples 
update index probe performed retrieving tuples having randomly chosen search key value followed index scan 
average processing time operation reported 
updates performed amount new data generated equals initial data size 
corresponds index update frequency roughly time units relative data rate record time unit 
indexing technique consists array sub indices sub index containing main memory directory implemented linked list sorted search key random access file storing results 
file collection buckets storing tuples indexing time evolving data variable lifetimes structure individual sub index search key sorted expiration time 
individual data records bytes long contain integer search key integer expiration timestamp string abstractly represents contents data 
structure individual sub index del illustrated showing directory offset pointers locations buckets file note may bucket search key case overflow 
count records bucket stored buckets full 
rebuild structured similarly variable size bucket maintained search key 
number simplifications focus experiments relative performance doubly partitioned indices 
bucket sizes adjusted overflow issue studied context skewed distributions orthogonal 
simple strategy implemented allocates bucket size key 
garbage collection empty buckets ignored adds constant amount time maintenance costs indexing technique 
second number search key values fixed order bound length directory 
query times may dominated time takes scan long list handling larger set key values done efficient directory tree orthogonal 
third number tuples bucket del initial distribution key values building stage sub index contains average buckets search key 
value compromise large buckets key wastes space newly allocated buckets fill buckets results slower query times 
optimal values experiment validates result section regarding optimal assignment values value shows normalized update probe sliding window query processing data streams relative performance rebuild rebuild rebuild update times index partitioning techniques small window size scan times rebuild rebuild rebuild index types give similar relative results 
rebuild performs best terms scan probe times difference negligible techniques probe number sub indices obtain query results sub indices roughly equal sizes 
average update time rebuild approximately percent lower techniques number sub indices updated rebuild versus strategies 
notably rebuild updated faster rebuild tuples inside buckets ordered expiration time deletions simple tuples removed front bucket insertions complex bucket scanned 
number insertions determined number partitions lower level technique smaller value wins 
performance doubly partitioned indices doubly partitioned indices compared existing algorithms 
previous experiment partitions considered 
results exp exp omitted techniques incur longer update times ins ins 
insertions expensive deletions buckets sorted expiration time splitting index expiration time forces insertions sub index 
figures show average update probe scan times respectively functions number sub indices 
additionally shows update times doubly partitioned indices chronological partitioning denoted chr order single benefits round robin partitioning 
chronological partitioning outperforms existing strategies factor grows round robin partitioning additionally improving update times percent 
explained section faster update rebuild slower probe scan 
update overhead rebuild relative roughly percent decreases percent large relative savings index probe times rebuild percent 
relatively small data size assumed indexing time evolving data variable lifetimes probe times index partitioning techniques small window size scan times index partitioning techniques small window size experiment roughly megabytes meaning individual sub indices small rebuilt quickly 
additionally buckets particular search key may small number disk accesses buckets scattered file 
probing slightly expensive probing rebuild records search keys bucket 
general rebuild perform probes slightly faster ins ins sub indices techniques similar sizes avoid bad cases probing large sub indices inflates access cost 
increases access times grow sub indices probed separately update times decrease initially growing ins ins 
mentioned section due factors influencing update costs increases amount data updated decreases number individual accesses increases 
reason update costs ins ins start increasing smaller values doubly partitioned techniques existing techniques access sub indices updates doubly partitioned techniques access sub indices 
fixed value rebuild ins lowest space requirements followed ins 
ins incur overhead pre allocating buckets may fill exact space penalty depends bucket allocation strategy orthogonal 
increases techniques require space order store sub index directories 
measure overhead associated doubly partitioned indices chronological roundrobin partitioning tested indices 
update times approximately percent index directories updated files 
probes scans required sequential scan data took approximately amount time index scans order seconds 
doubly partitioned indices incur modest update overhead allow probe times orders magnitude faster sequential scan 
sliding window query processing data streams effect data rate fluctuations index update performance 
fluctuating stream conditions update times index partitioning techniques large data set 
experiment data rate varies randomly factor 
total amount data items generated set approximately previous experiment order enable head head comparison 
average access times slower percent index update times illustrated selected techniques denote rebuild respectively 
darkened portion bar corresponds increase update time caused fluctuating data rate 
doubly partitioned indices adaptable fluctuating data rates ins 
rebuild significantly affected fluctuations larger values ins ins exhibit worst performance small values explained follows 
rebuild round robin partitioning meaning updates scattered sub indices large value means takes longer new data rate take effect sub indices 
hand ins ins chronological partitioning large value means sub indices shorter time spans bursty updates spread faster sub indices 
rebuild ins resilient fluctuations ins simple non adaptive bucket allocation technique 
scaling large index sizes test investigates behaviour proposed techniques indexing large amounts data gigabytes 
average update probe scan times functions shown figures respectively 
doubly partitioned indices times fast update existing techniques 
additionally gap update query times rebuild versus wider 
rebuild percent faster probe percent slower update indexing time evolving data variable lifetimes probe times index partitioning techniques large data set 
scan times index partitioning techniques large data set 
corresponding percentages percent roughly percent respectively 
expected outcome indexing large data set rebuild slower update re cluster larger sub indices slower probe result tuples search key spread multiple buckets possibly multiple disk pages 
difference figures behaviour update times grows 
turning point rebuild update times decrease 
case update times continue drop tested values window size individual sub index sizes larger drop performance caused making sub indices small issue 
lessons learned experiments recommendations regarding best index partitioning strategy 
guidelines depend data size expected number queries executed archive updates 
small window size small number queries choice incurs low update times 
small window size large number queries rebuild works best probe scan times low 
probing times ins ins slightly lower rebuild updating ins slower 
large window size small number queries choice smaller value recommended small window sizes ensure probing times excessively high 
sliding window query processing data streams large window size large number queries rebuild expensive update rebuild rebuild recommended fast probing times crucial 
better balanced choice 
note query workload may fluctuate time may advantageous switch different indexing technique point 
problem similar plan migration context sliding window queries store state 
possible solutions stopping old plan migrating state starting new plan running plans parallel discarding old plan windows roll 
strategies compatible doubly partitioned indices system migrate index type discarding old index building new index maintaining indices parallel old index gradually empties 
chapter multi join processing sliding windows recall chapter persistent queries may executed continuously eagerly periodically lazily 
furthermore recall section operators including join may maintain state eagerly lazily trade lazy expiration requires memory temporarily storing expired tuples 
chapter studies algorithms evaluating equi join sliding windows main memory eager lazy evaluation expiration 
joins important operators dsms facilitate cross referencing similar events multiple input streams occurred window length 
section begins defining multi way join algorithms compatible options 
additionally lazy evaluation variants ensuring restore semantics recall section dealing weakest weak strict non monotonic inputs discussed 
proposed algorithms fully pipelined intermediate results materialized due main memory constraints 
section outlines join ordering heuristics attempt minimize number tuples pipeline 
heuristics unit time cost model context binary sliding window joins 
section discusses experimental results including effects re evaluation expiration strategies processing cost 
multi way hash join unbounded streams proposed extensions sliding windows 
join ordering problem identified context optimizing highest output rate queries unbounded streams ordering sliding window joins discussed 
generally main memory join ordering techniques dbmss push expensive predicates top plan 
table lists symbols chapter meanings 
furthermore explains convention describing join ordering 
example join order sliding window query processing data streams table explanations symbols chapter arrival rate stream tuples unit time sj sliding window corresponding stream tj length jth time window cj number tuples sj vj number distinct values sj bj number hash buckets hash index sj index exists periodic re execution interval concatenation tuples ts timestamp attribute join order expressed join tree series loops expressed join tree left series nested loops right join predicate equality condition common attribute named said ordered ordered second 
brevity parentheses omitted notation represent join order shown 
sliding window join algorithms eager evaluation discussion join algorithms begins simplest case eager re evaluation eager expiration 
assume join conditions equality predicates common attribute streams call means permutations join order possible 
binary sliding window works follows assuming inputs weakest weak non monotonic update patterns negative tuples need 
inputs 
newly arrived tuple inserted state 
expired tuples removed state scanned produce new results involving new tuple 
recall tuple expires exp timestamp older current time case timestamp newly arrived tuple 
observe expiration done scan tuples expired relative timestamp new multi join processing sliding windows table probing orders global join order origin new tuple join order tuple participate join processing 
similar procedure followed newly arrived tuple 
note result tuple assigned expiration timestamp minimum exp timestamps individual tuples 
operator pipeline application attached final output query expire old result tuples 
hand inputs join strict non monotonic window negative tuples 
case negative tuples processed way regular tuples produced output stream 
additionally expiration performed negative tuple arrives corresponding regular tuple deleted 
extending binary join deal inputs straightforward newly arrived tuple expired tuples removed state buffers buffers scanned order prescribed query plan 
example suppose windows call joined plan 
arrival new tuple purged expired tuples probed order 
new tuple arrives probed followed 
similarly arrival new tuple probed 
effect window top join order consists tuple newly arrived tuple join order changes response origin incoming tuple shown table 
global join order defined order followed processing new tuples window 
example global order 
algorithm implements sliding window join eager evaluation expiration 
loss generality global join order sn assumed 
binary join negative tuples remove corresponding regular tuples join state shown algorithm processed subroutine way regular tuples 
negative tuples announce expirations premature ones line may removed expired tuples removed corresponding negative tuples arrive 
hash tables maintained appropriate hash buckets scanned inside subroutine lines entire inputs 
new tuple arrives previously arrived tuple processed new tuple assumed wait queue 
furthermore tuples arrive simultaneously ties may broken arbitrarily line 
order allow lazy expiration algorithm identify ignore expired tuples processing 
accomplished padding join predicates timestamp comparisons summarized algorithm 
timestamp comparisons guarantee newly arrived tuples join expired tuples relative timestamp new tuple sliding window query processing data streams algorithm eager multi way join input sliding windows sn input streams new tuple arrives stream insert new tuple window si remove expired tuples windows si si sn new tuple join order si si sn loop si si si loop si sn sn return 

loops si sn loops si removed 
expiration specified algorithm may performed arbitrary times execution subroutine 
note algorithm applies inputs weakest weak non monotonic update patterns 
possible predict expiration times tuples join state expirations performed eagerly negative tuples 
lazy evaluation recall section lazy re evaluation weak strict non monotonic query plans produce result set continuous evaluation 
context sliding window join newly arrived tuples joining tuples expire may reported short lifetimes falling re execution intervals 
restore multi join processing sliding windows algorithm eager multi way join lazy expiration input sliding windows sn input streams new tuple arrives stream insert new tuple window si si si sn new tuple join order si si sn ts exp loop si si ts exp si ts exp loop si sn sn ts exp return 

loops si sn loops si semantics acceptable possibility re algorithm augmented clean expired tuples re execution 
augmentation correct short lived results expired just re execution need recovered expired tuples need retained processing 
improvements reduce time space requirements lazy join evaluation 
processing time reduced sorting hashing newly arrived tuples attributes fly calling subroutine group new tuples input having value 
reduces number times inputs probed similar traditional block oriented nested loops join 
second space usage may decreased removing tuples expire re evaluation immediately current re evaluation need store tuples re evaluations 
gives rise lazy multi way join outlined algorithm loss generality assume time re execution sliding window query processing data streams algorithm lazy multi way join restore semantics input sliding windows sn input streams time query re executed insert newly arrived tuples stream si group newly arrived tuples si having value val val si si sn remove tuples window si having exp timestamps smaller group tuples value val join order si si sn val loop si si val si val loop si sn sn val return 

loops si sn loops si multi join processing sliding windows begins 
note timestamp comparisons required join processing expired tuples guaranteed removed previous re execution 
case algorithm algorithm relies knowledge expiration times tuples state line compatible strict non monotonic inputs 
lazy multi way join may modified handle strict non monotonic inputs performing expiration eagerly response newly arrived negative tuples evaluating join lazily subroutine 
conforming restore semantics requires changes algorithm 
line changes remove tuples si having exp timestamps smaller tuples expire re execution time join newly arrived tuples produce short lived results 
second subroutine carry timestamp comparisons expired tuples restore short lived results 
algorithm implements restore semantics 
note currently processed tuples having values may different timestamps range algorithm produces superset possible results outer loops smallest timestamp newly arrived tuples join predicate 
lines subroutine verifies base tuples expired relative specific timestamp newly arrived tuple 
way adapt algorithm strict non monotonic input follows 
negative tuple arrives corresponding regular tuple looked deleted right away 
expired tuple exp timestamp corresponding generation timestamp negative tuple 
allows subroutine recover short lived join results 
join processing stage completes line algorithm may garbage collect expired tuples exp timestamps set corresponding negative tuples 
analysis algorithms trade offs involved join algorithms analyzed considering relative costs terms window maintenance join computation 
terms join processing hash join faster nested loops join incurs higher window maintenance costs 
example handling new tuples expensive hash join hash function applied new tuple 
expiration costly bucket probed separately depending update patterns input hash bucket may fifo queue calendar queue simple list discussed section 
additionally tuples value join attribute lazy evaluation efficient eager evaluation 
downside lazy evaluation answers reported user delay recall discussion section 
terms window maintenance eager expiration costly 
instance expiration performed frequently windows hash buckets may contain stale tuples algorithm pay cost accessing 
eager evaluation eager expiration reduces join processing cost eliminating need pad join predicates timestamp comparisons 
context sliding window query processing data streams algorithm lazy multi way join restore semantics time query re executed insert newly arrived tuples stream si group newly arrived tuples si having value val mints smallest timestamp tuples val mints si si sn remove tuples window si having timestamps smaller ti group tuples value val timestamp mints join order si si sn mints exp val loop si si mints exp val si mints exp val loop si sn sn mints exp val exp ts 
exp ts exp ts 
exp ts return 

loops si sn loops si multi join processing sliding windows lazy evaluation enforcing restore semantics expensive timestamp comparisons join processing 
issues explored depth section 
evaluating join restore semantics expensive choose accept restore semantics proportion lost results small 
suppose distribution lifetime lengths join results uniform 
new tuple equal probability joining new old tuples windows 
case proportion lost results may approximated ratio re evaluation interval window length weighted stream arrival rates stream bounded window different length 
example join second windows evaluated lazily seconds percent results missing 
hand consider join windows input streams lags sense newly arrived tuples window join old tuples window 
lag approximately equal window size join results short lived lazy re evaluation may return small fraction result set 
recall input join operator strict non monotonic choice join algorithms somewhat limited 
particular algorithm eager evaluation lazy expiration apply algorithm perform eager expiration predict tuples expire re evaluation remove early algorithm attach exp timestamps tuple invalidated corresponding negative tuple 
underscores need update pattern simplification recall section strict nonmonotonic operators pulled operators weakest weak nonmonotonic inputs 
course query count windows input join strict non monotonic 
join ordering prior experimentally evaluating join algorithms section deals choosing efficient join order 
pipelined possibilities having examine possibilities 
examples section context nested loops join eager evaluation expiration time windows general solution applicable scenarios 
join orders evaluated unit time model relative join processing cost specifically number attribute comparisons unit time 
tuple insertion expiration costs omitted vary different join orderings algorithm 
estimating join sizes standard assumptions regarding containment value sets uniform distribution attribute values 
containment value sets states common join attribute takes values av window choose values prefix list 
stream parameters arrival rates number distinct values inside current window expected fluctuate lifetime persistent queries join order may need adjusted periodically algorithm deciding change join order orthogonal issue pursued 
sliding window query processing data streams cost formulae suppose windows joined global join order 
expected intermediate result size join windows si sj ij iti jtj max vi vj number distinct values intermediate result min vi vj follow assumption containment value sets 
formula may extended multi joins obvious way example size join si sj sk follows 
iti tj max vi vj ijk max min vi vj vk ktk ij jtj max min vi vj vk size join si sj multiplied size window sk result divided maximum number distinct values join si sj min vi vj window sk 
join processing cost computed follows 
processing new tuples join evaluated times unit time 
time scanned cost tuple accesses 
tuple joins new tuple expected number tuples max tuple joined tuples scanned cost tuple accesses 
tuple joins composite tuple max max min tuples tuple joined tuples followed joining result tuples scanned cost tuple accesses 
total cost unit time processing tuples call follows 
max max max min processing new tuples cost calculated get max max max min cost unit time processing new tuples max max max min cost unit time processing new tuples max max max min total cost unit time sum 
multi join processing sliding windows table stream parameters initial heuristic example stream stream stream stream join ordering heuristic table sizes intermediate join results max max max max max max max min max min motivate cost differences various join orders suppose window number distinct values 
sensible globally order joins ascending order window sizes tuples iti average hash bucket sizes ti sliding windows bi stored hash tables 
placing small window outer loop strategy minimizes number tuples passed inner loops processing 
generally sensible heuristic assemble joins descending order binary join selectivities leaving little possible inner loops join predicate selective produces smaller result set 
consider streams parameters shown table suppose hash tables available 
intermediate result sizes shown table 
descending order binary join selectivities join produces fewest intermediate results ordered heuristic chooses ordering 
equations developed earlier may calculate cost follows 
sliding window query processing data streams table stream parameters augmented heuristic example stream stream stream stream table stream parameters example fast streams slow streams stream stream stream stream total cost unit time 
comparison worst plan cost nearly 
example turns cheapest plans ordered global order suggests possible augmentation heuristic 
heuristic computes cost join order selectivities calculates cost join orders fast streams ordered near top plan say top third plan 
cheapest join order selected 
test augmented heuristic consider streams parameters table 
absence hash tables best global order costs 
initial heuristic chooses cost approximately 
note stream faster improved heuristic moves get optimal global ordering 
interestingly moving fast stream way get worse costs 
comparison worst plan costs 
stream significantly faster parameters shown table augmented heuristic works 
ordered ascending join selectivity initial plan cost 
fast streams ordered heuristic moves 
moving gives cost optimal ordering scenario moving gives cost 
combination considered heuristic costs average cost unit time orderings case 
moving fast streams way top get recommended plans cost respectively 
summary reasonable heuristic eager re evaluation multi way join initially order joins descending order selectivities 
streams faster beneficial consider orderings fast streams moved join order way top 
number orderings considered order number fast streams 
multi join processing sliding windows experimental results experimental setting experiments performed validate join ordering heuristic compare performance proposed join algorithms 
algorithms built update pattern aware query processor chapter tested experimental environment 
real packet header stream synthetic packet stream order control distribution join attribute values 
stream produced follows 
continuous loop connected query processor generates tuple iteration random stream probability equal tuple timestamp equal current loop index join attribute value chosen uniformly random set vi fields experiments assigned random values 
procedure simulates relative stream rates guarantees containment value sets 
note uniform distribution join attribute values leads uniform distribution lifetime lengths results proportion lost tuples fairly small recall discussion section 
stream pushed query plan consisting multi way join operator time windows 
join state implemented fifo queue hash table buckets fifo queues 
hash functions simple modular divisions number hash buckets 
experiment repeated times average processing time input tuples reported 
validation cost model join ordering heuristic recall join ordering example stream parameters table 
ordering joins selectivity gives order 
stream faster improved heuristic additionally considers optimal global ordering 
illustrates processing time join orderings stream parameters normalized respect optimal ordering 
addition predicted cost ordering algorithms tested eager execution eager execution lazy expiration time units lazy execution time units lazy execution restore semantics abbreviated algorithms hash tables buckets stream 
relative costs join orders tested similar predicted costs algorithm differences orderings quite high predicted 
cost model considers join processing ignores costs insertion new tuples expiration old tuples 
performing eager evaluation lazy expiration third set bars left matches predicted costs closely 
hand lazy evaluation hash joins show reduced differences join orderings join processing costs smaller fraction query processing cost 
sliding window query processing data streams validation join ordering heuristic relative performance join algorithms set experiments highlights cost differences proposed join algorithms 
stream parameters previous experiment join ordering fixed optimal ordering 
nested loop algorithms eager evaluation lazy evaluation lazy evaluation restore semantics summarized 
costs units milliseconds graphed function understood expiration interval context eager evaluation re evaluation interval context lazy evaluation 
note eager evaluation includes data point denoting eager expiration new tuple arrives processing 
expected lazy join evaluation efficient eager evaluation noticeable penalty enforcing restore semantics 
increases cost eager evaluation increases 
means savings expiration costs outweighed added complexity algorithm compared algorithm padding join predicates timestamp comparisons order ensure expired tuples produce new join results 
hand lazy algorithms efficient increases absolute terms relative eager evaluation 
new tuples having values join attribute processed duplicates expected buffer large 
particular enhancement speeds lazy join restore semantics goes despite fact results lost recovered 
cost hash algorithms shown lines top corresponding hash tables buckets stream lines bottom denoting hash tables buckets stream 
expected query faster execute 
performance results buckets hash table similar noticeable difference small values lazy join restore semantics performs worse increases 
overhead restore semantics higher savings gained lazy evaluation 
small tuples buffer values join attribute opportunities multi join processing sliding windows cost nested loops algorithms cost hash algorithms batching new tuples probing windows batch 
moving results buckets hash table query processing costs lower performance differences join algorithms noticeable straightforward technique improvement join processing cost allocate hash buckets windows expected store tuples 
interestingly eager evaluation improves grows zero begins perform worse 
frequent expiration expensive hash buckets probed separately order determine tuples expired 
large expiration costs severe algorithm execute timestamp comparisons probing state 
performance eager evaluation eventually declines observed previous experiments 
algorithms lazy evaluation restore restore semantics slightly efficient grows difference far smaller buckets hash table cuts join processing costs significantly additional improvement lazy evaluation relatively small 
lessons learned experiments shown best way reduce cost query containing sliding window joins store join inputs hash buckets 
cases lazy evaluation additional improvement increasing re evaluation interval beneficial batch newly arrived tuples expected contain duplicate values join attribute 
furthermore shown overhead enforcing restore semantics noticeable impact join performance lazy evaluation restore semantics efficient eager evaluation especially re evaluation interval large 
chapter sliding window aggregation finding frequent items second chapters sliding window query operators focusing periodically refreshed top queries sliding windows internet traffic streams 
internet traffic web page popularity patterns observed highly skewed obeying zipf distribution 
implies outgoing incoming bandwidth consumed directed small set heavy users popular destinations 
queries return list frequently occurring items important context traffic engineering routing system analysis customer billing detection anomalies denial service attacks 
instance internet service provider isp may interested monitoring streams ip packets originating clients identifying users consume bandwidth time interval see additional motivating examples 
types queries objective return list frequent items called top queries hot list queries items occur frequency called threshold queries generally known frequent item queries 
analysis meaningful bandwidth usage statistics kept limited amount time example sliding window arrived data replaced new measurements 
failure remove stale data leads statistics aggregated entire lifetime stream unsuitable identifying usage trends 
entire window fits main memory answering threshold queries sliding windows simple suffices maintain frequency counts distinct item window update counters new items arrive old items expire 
periodically refreshed answers acceptable assumed chapter basic interval synopsis may recall discussion section storing frequency counters interval 
speed query terms item item type value category interchangeably chapter 
sliding window query processing data streams basic window synopsis storing popular url sub window evaluation set global counters may additionally stored updated new interval added synopsis oldest interval dropped 
internet traffic high speed link arrives fast useful sliding windows may large fit memory system may sufficient resources keep stream 
discussed section way reduce memory requirements basic window synopsis store sketches sub window complete sets frequency counters 
chapter evaluates alternate solution approximating complete frequency distribution sketches space efficient store exact frequency counts frequent packet types observed sub window 
effect storing constant amount information sub window top aggregate holistic treated distributive recall section 
consequently technical problem approach obvious rule merging constant size partial information stored sub windows final answer 
illustrate technical challenges proposed approach consider simple example illustrated showing basic window synopsis length minutes stores popular destination url individual minute 
bay popular url minutes cnn google 
information clear popular url entire minute window 
general subwindow stores counts top categories say item appearing top lists frequent types sliding window bursty packet type dominates sub window may appear sub windows 
necessarily true frequent item appeared top sub window list small say possible ignore frequent item type consistently ranks fourth sub window appears top lists 
fortunately shown empirically problems far serious sliding window conforms power law distribution case frequent categories expected popular source ip addresses protocol types repeatedly included nearly top list 
answering top queries sliding windows objective refreshing answer new item arrives old item expires window 
algorithms store tuples inside window compatible goals chapter periodic query evaluation limited storage 
furthermore computing top queries multiple sub window top lists similar sliding window aggregation finding frequent items rank aggregation conventional possibly distributed dbmss 
main idea combine multiple ranked lists assumed available entirety single list 
difference dsms context top query access complete sets frequency counters sub window calculate top list entire sliding window limited information 
presents framework distributed top monitoring goal minimize amount data transferred distributed sources central processing system 
furthermore consider sliding window model 
remainder chapter algorithm finding frequent items line data streams section experimentally evaluated section 
proposed algorithm identifies frequently occurring items sliding windows extent estimates true frequencies 
deterministic uses limited memory sub window stores constant amount data requires constant processing time packet amortized pass data shown tested tcp traffic logs 
proposed solution algorithm description section proposes algorithm stores top list sub window 
assume single sub window fits main memory item frequencies may counted exactly 
frequency kth frequent item ith sub window 
upper limit frequency item type appear top lists 
reported frequencies item top list summed exists category reported frequency exceeds category guaranteed true frequency 
pseudocode algorithm assuming count window size number elements sub window total number sub windows 
updated answer generated window slides forward packets 

distinct item types 
provides example single execution algorithm sliding window consisting sub windows 
note shown algorithm assumes sub windows number items case count windows 
assumption necessary ensure algorithm correctness line may replaced condition emptying queue say time units 
algorithm may time windows modifications 
algorithm compatible inputs resulting weak strict non monotonic query plans satisfy fifo property 
remainder section maintains assumption equal item counts sub windows order simplify analysis 
sliding window query processing data streams algorithm frequent input number tuples window number elements sub window local variables integer local counters global counters queue summary loop tuple tuples local counter exists type tuple increment local counter create new local counter type set equal add summary containing identities counts frequent items back queue delete local counters type named global counter exists type add count recorded create new global counter type set equal count recorded add count kth largest type sizeof remove summary front subtract count kth largest type types named subtract global counters counts recorded counter decremented zero delete output identity value global counter loop sliding window aggregation finding frequent items analysis example single execution algorithm algorithm accepts parameters choice governed latency requirements application choosing small value increases frequency new results generated 
amount available memory dictates maximum number sub windows value space requirement algorithm consists parts working space needed create summary current sub window storage space needed top lists 
number distinct item types sub window value may different sub window point ignored order simplify analysis number distinct values sliding window 
worst case working space requires local counters size log storage sub window summaries requiring counters size log kn global counters size log gives total worst case space bound log kn log log 
time complexity algorithm min pass outer loop 
pass consumes arriving elements gives amortized time element 
algorithm may return false negatives 
consider item appears top lists summing frequency top lists exceed 
item may sufficiently frequent sub windows frequent register top lists windows true frequency count exceeds 
obvious solution reducing number false negatives increase increases space usage 
alternatively decreasing increases number sub windows may help eliminate false negatives 
possible downside algorithm small may large algorithm report frequent flows 
hand large synopsis contains items different type repeated top winners note specified units time time windows 
conceptually similar idea context incremental maintenance top view conventional dbms maintain top view sliding window query processing data streams algorithm may require great deal storage space size sliding window 
notably slightly larger may fewer distinct items sub window 
case algorithm track exact frequencies distinct packet types 
experimental results experimental setup algorithm tested experimental environment tcp traffic trace chapter 
trace contains distinct source ip addresses treated distinct item types 
value set values considered sub windows total sub windows total sub windows total 
value varies 
experiment starting points trace chosen random packets starting points form input stream 
brute force algorithm executed input order calculate true item type frequencies 
quantities measured average threshold average number threshold flows reported accuracy space usage trials shown 
accuracy recall algorithm identifies category threshold category frequency count recorded top synopses exceeds 
increases frequency kth frequent item decreases threshold decreases seen 
furthermore increasing number sub windows decreasing increases smaller subwindows capture burstiness finer scale 
consequently increases number packet types exceed threshold increases seen 
plots number threshold ip addresses shows number ip addresses identified algorithm threshold 
example threshold frequency roughly percent source ip addresses frequencies exceed threshold 
seen algorithm identify packet types exceed threshold may false negatives recall false positives 
shows percentage threshold ip addresses identified algorithm 
general trend percent threshold ip addresses identified 
increasing number sub windows decreasing sub window size improves chances identifying threshold packet types 
instance false negatives occur rarely frequently occurring item types appear top lists individual sub windows 
sliding window aggregation finding frequent items space usage shows space usage algorithm terms number attribute value frequency count pairs need stored 
recall sliding window size experiments may considered rough estimate space usage naive technique stores entire window 
space usage algorithm significantly smaller especially large small 
top list stored subwindow number sub windows greatest effect space requirements 
precision recall algorithm may report false negatives 
frequent types typically frequencies slightly exceed threshold meaning frequent types reported 
furthermore reported frequency estimates cases close actual frequencies meaning reported frequent ip addresses arranged correct order item types similar frequencies ordered incorrectly 
quantify statement plots average relative error difference measured frequency actual frequency divided actual frequency frequency estimation threshold ip addresses values values relative error decreases increases decreases 
example average relative error percent 
reported ip addresses nearly ordered correctly ip addresses frequencies percent ip addresses exceed threshold percent may remain 
lessons learned algorithm works identifier frequent items extent approximate frequencies internet traffic streams 
expected increasing size top synopses increases number frequent flows reported decreases number false negatives improves accuracy frequency estimates 
increasing number sub windows reduces refresh delay decreases proportion false negatives increases accuracy frequency estimates 
space usage grows increases decreases 
sliding window query processing data streams analysis algorithm 
part shows average value threshold part shows number packet types frequencies exceed threshold part graphs number packet types reported exceeding threshold part shows percentage threshold packets identified part plots space usage part shows relative error frequency estimates threshold items function 
chapter concurrency control periodic queries sliding windows far notion update pattern awareness introduced significance context sliding window maintenance query processing explained 
chapter examines concurrency issues arising simultaneous execution periodic queries periodic window slides presents update pattern aware transaction scheduler 
recall periodically sliding window implemented circular array sub windows periodic window updates replacing oldest sub window batch newly arrived data 
windows slide forward dsms executes dynamic workload persistent time queries 
assume query execution involves scanning window exactly sub window time assumption justified section 
combined periodic window movements dsms data access modeled terms atomic operations sub window scan read replacement oldest sub window new data write 
window update single write operation query sequence sub window read operations sub window read exactly 
window may slide accessed query leading read write conflict 
consider sequence operations illustrated processing times window updates queries shown time axis 
represents ideal scenario possible execute queries pair window updates avoiding read write conflicts 
system environment query workload stream arrival rates availability system resources change greatly lifetime remainder chapter terms window update window movement window slide interchangeably 
precisely window update single logical write operation logically performs series delete operations order clear oldest sub window series insert operations write newly arrived tuples buffer empty sub window 
sliding window query processing data streams examples query window update sequences dsms persistent query 
realistic sequence shown takes longer execute expected 
running second update ready applied causing delay performing update turn causing read write conflict re executed third update take place 
may appear read write conflicts prevented increasing time interval window updates sub window size 
sub windows size terms time number tuples depending type sliding window window size fixed times 
system taken line re partition entire window sets sub windows maintained transition period window rolls sub windows new size 
case inappropriate line dsms second solution immediately eliminate read write conflicts transition period 
existing data stream solutions avoid read write conflicts serially executing queries window movements 
words query locks window scanning order prevent concurrent window movements 
approach eliminates need performance overhead sophisticated concurrency control solutions 
interleaved execution updates window scanned query allows date answers generated provided issue resolved drop throughput due overhead concurrency control minimal 
consider suspending processing order perform window update 
recall query assumed perform sequence atomic sub window reads may interrupted read subwindows 
ensured resumed correctly read updated window state 
answer slightly delayed time taken perform update date reflects second update 
result worse answer delayed date 
example illustrated suspended concurrency control periodic queries sliding windows perform window update run immediately 
desirable important query requires immediate date answer 
chapter studies concurrency control issues dsms periodic window movements periodic executions persistent queries demand snapshot querying 
motivated goal provide query scheduling flexibility guarantee date results minimal loss throughput due overhead concurrency 
particular contributions chapter follows 
modeling window movements queries transactions consisting atomic subwindow reads writes chapter extends concurrency theory cover queries periodically advancing windows 
shown conflict serializability sufficient presence interleaved queries window movements serialization orders produce incorrect answers 
new isolation level proposed stronger snapshot isolation conflict serializability restricts permissible serialization orders 
update pattern aware transaction scheduler designed efficiently enforces desired isolation level 
insight scheduler predict sub window overwritten ensure new copy read concurrent queries 
scheduler proven optimal sense aborts smallest possible number transactions allowing immediate optimistic scheduling window updates 
experimental evaluation transaction scheduler shows improved query freshness response times minimal drop throughput 
remainder chapter organized follows 
section explains system model assumptions motivates concurrency control issue dsms 
section defines new isolation levels dsms transactions section presents update transaction scheduler enforcing 
section presents experimental results section compares contributions chapter previous 
motivation assumptions data query model stream assumed bounded time window length nt stored circular array sub windows spanning time length time units oldest subwindow replaced buffer containing incoming tuples arrived time units 
value assumed significantly larger time taken perform window update system spend time advancing windows executing queries 
persistent query specifies desired re execution frequency multiple scheduled re execution window updates specifies window size jt queries windows shorter nt allowed provided window lengths multiples sliding window query processing data streams techniques computing sliding window sums sub window length 
assumed plan weakest weak non monotonic strict non monotonic update patterns considered chapter 
dsms attempts execute queries desired frequencies guarantee case times due unpredictable system conditions scheduling re executions persistent queries covered detail chapter 
periodic query execution strategies may classified general types window scan ws incremental scan synopsis scan ss incremental synopsis scan iss 
illustrate suppose sums attribute stream computed sum window size sub windows sum window size sub windows 
ws default access path scans entire window windows sub window time computes query scratch 
shown sub windows read youngest oldest sum shorter window may re computing sum longer window 
way speed execution types periodic queries store permanent state allows answers refreshed incrementally 
shown stores previously calculated answer query pair pointers denoting window answer computed indicated dotted arrows 
re evaluation query scans tuples sub windows added expired sub window may deleted interested queries advanced pointers forward 
compute new sums sum tuples new sub window lightly shaded added sum expired tuples shaded subtracted 
strategy applies queries recall section contribution expired tuples may subtracted stored answer 
furthermore discussed section incremental computation holistic aggregates requires query store list distinct values occurring window multiplicities sufficient store previous answer 
observe concurrency control periodic queries sliding windows expired tuples different sub windows depending window size query 
instance expired tuples respect window size needed sum left oldest sub window expired tuples respect shorter window size needed sum sub windows right 
workload includes sum queries windows different sizes entire window may need scanned order re compute answers ws 
storing separate state query ss maintains sliding window synopses discussed section 
example shown illustrating shared processing sums different window sizes basic interval synopsis running synopses considered chapter apply aggregates 
note shared query evaluation involves merging pre aggregated sub windows youngest oldest 
iss combination ss 
illustrated stores synopses individual query state 
refresh answer sum queries suffices look pre aggregated sums new expired tuples 
summaries new expired sub windows accessed 
similarly iss suitable queries 
motivation study concurrency control remainder chapter ws ss query evaluation 
ws default access plan time queries known ahead time may find applicable synopses 
ws may option initial evaluation new persistent query 
case window may scanned produce initial answer optionally build synopsis query re executions 
observe ss comparable space usage provided workload includes similar queries various window sizes 
see note requires query store permanent state queries identical window sizes 
example sum help compute sum 
hand ss stores piece data sub window pre aggregated value list frequency counters size large state individual query 
addition retain expired sub windows query subtracted contribution expired tuples stored answer 
contrast ss simply overwrites oldest sub window interval new value new counters 
ss yields faster processing times read sub windows containing new expired tuples may non queries 
note space usage iss window summaries query state may prohibitive 
number synopses stored dsms may large 
time queries may need suspend persistent queries currently running 
case system set aside state space suspended queries resume reserve state space potential time queries 
recall 
window allowed slide accessed query query read new window state correctly 
terms concurrency control query read old tuples expire query terminates 
problem sliding window query processing data streams assumed system architecture exist iss window update replace expired data 
expired sub windows retained query subtracted contribution expired tuples stored answer 
ws ss scan window synopsis sub window time 
queries may see old copy window read old sub window overwritten 
expired sub windows retained requires space processing time old sub windows may need re scanned queries order remove contribution expired tuples answer currently computed 
desirable prevent double scanning 
system model assumed system architecture illustrated 
expanded view shaded part architecture local storage component omitted 
denote replacement ith sub window newly arrived data 
data stream generates periodic write transactions tj subscript order defined tj wj mod cj cj signifies commit tj 
processed transaction manager propagates updates synopses window join window 
stream transaction manager initially executes tn fill windows 
tj effect moving window forward sub window 
order ensure queries access latest data transaction scheduler executes immediately commits tj soon buffer full 
time queries executed accessing suitable synopsis available scanning underlying window 
persistent queries re executed periodically lifetimes existing synopses building new synopses discussed detail chapter context multi query optimization 
interface query manager transaction scheduler consists read transactions corresponding re execution similar queries 
scan read ith sub window summary loss generality remainder chapter referred concurrency control periodic queries sliding windows sub window 
time query particular re execution persistent queries read transaction tqk defined tqk cqk tqk commits successfully tqk include abort operation contain commit operation cqk 
tqk performs scan window sub result summary reading sub window exactly 
queries windows shorter nt may defined similarly transactions reading appropriate number sub windows starting youngest sub window circular array 
example zero th sub window currently youngest committed query window length corresponds tqk cqk 
oldest sub window currently st sub window read 
fifth sub window currently youngest query corresponds tqk cqk 
fourth sub window oldest read query 
conflict serializability sliding window queries serializability serialization orders isolation level requirements queries periodically sliding windows analyzed 
assume queries access single window correspond plans produce weakest non monotonic update patterns queries accessing synopses joins multiple windows weak non monotonic update patterns discussed section 
consider possible types conflicts arising concurrent execution transactions 
conflict occurs interleaved transactions operate sub window operations write 
clearly read write conflict occurs tj interrupts tqk 
tqk reads sub window including sub window overwritten tj 
window movements assumed executed committed immediately write write conflicts occur 
traditional method dealing conflicts requires execution history serializable 
conflict serializability insufficient context sliding windows demonstrated example 
assume sliding window partitioned sub windows numbered zero sub window zero oldest current time 
consider histories ha hb hc hd initial transactions fill window omitted brevity 
ha rq rq rq rq rq cq hb rq rq rq rq rq cq hc rq rq rq rq rq cq hd rq rq rq rq rq cq history represents interleaved execution read transaction tq window movements 
difference histories window movements take place different times 
associated serialization graphs drawn 
di sliding window query processing data streams serialization graphs ha hb hc hd differences results returned tq ha hb hc hd edges corresponds order conflicting operations serialized 
particular pairs conflicting operations schedule rq rq 
note graphs acyclic histories serializable serialization orders different 
consider state sliding window read tq histories 
illustrated sub windows left correspond initial state window executed 
advances window forward sub window may thought overwriting old copy sub window far left new copy appended 
state window commits represented contiguous sequence sub windows 
advances window appending new copy far right implicitly deleting old copy left 
state window commits equivalent contiguous sequence sub windows 
shaded sub windows represent read tq histories explained 
consider sg ha note ha serializes tq meaning window movement caused creation new version sub window reflected query 
ha serializes earlier window update tq prior window movement caused creation new version hidden query 
ha causes tq read old copy new copy illustrated correspond window state point time 
shaded rectangles form contiguous sequence sub windows 
recall hb serializes window movements tq query reads old versions illustrated 
corresponds state window commits 
similar reasoning hc allows tq read state window commits hd ensures tq reads date state window reflects 
sg hd serializes window movements concurrency control periodic queries sliding windows tqk meaning tqk sees updates 
isolation levels sliding window queries having shown serialization order affects semantics read transactions section proposes stronger isolation levels restrict allowed serialization orders 
definition history said window serializable ws committed tqk transactions read true state sliding window point time respective commit times contiguous sequence sub windows read query 
definition window serializable history said latest window serializable lws committed tqk transactions read state window respective commit times 
note lws guarantees queries read date state window central requirement dsms concurrency control explained section 
furthermore note ws corresponds dbms snapshot isolation related notion strong snapshot isolation read transactions see snapshots data start times stronger ws weaker lws 
motivated theorems hold respect transaction workload assumed chapter 
theorem history window serializable iff sg property tqk ti serialized tqk tj serialized tqk proof 
suppose ws 
transactions tqk contained incur concurrent window movement clearly sg satisfies desired property 
note tqk read sliding window state point past case tqk isolated concurrent window updates reads update reads oldest updates 
cases sg contains updates serialized query updates serialized query wanted 
suppose sg satisfies property tj serialized tqk higher subscripts serialized tqk 
maximum subscript transaction ti serialized tqk 
follows tqk reads sliding window state resulted applying updates tm ws 
theorem history latest window serializable iff sg property tqk concurrent ti transactions serialized tqk 
sliding window query processing data streams proof 
suppose lws tqk query incurs concurrent window movement 
follows tqk reads state window results applying concurrent updates 
concurrent window updates serialized queries wanted 
suppose sg contain links pointing tqk ti 
means queries interrupted window updates queries see 
lws 
transaction scheduler design producing lws histories section presents design dsms transaction scheduler produces lws histories 
recall section write transactions tj executed highest priority queries access date version window 
requirement proposed scheduler executes window movements immediately aborts read transactions participate read write conflicts 
scheduler summarized algorithm 
query tqk length window tqk reads nk youngest sub windows 
note nk lines serially execute window movements immediately technically line wait write operation performed 
lines initialize bit array newly arrived tqk bit set tqk read sub window lines execute read transactions sub window scan time set corresponding bit true committing tql line algorithm wait performing read operation line 
note algorithm allows multiple read transactions executed time order line conflict 
lines resolve lws conflicts proven 
theorem algorithm produces lws histories 
proof 
definition committed read transactions tqk property window movements tj executed time tqk serialized tqk 
note time new lws violation may possibly appear window update tj commits done immediately performing write operation tqk transactions running 
furthermore lws conflict appears recall query window shorter nt say reads nk youngest sub windows 
concurrent window movement changes set sub windows read queries windows shorter nt recall discussion section 
assume algorithm explicitly changes contents affected query transactions immediately window movement line access correct set sub window reads performed query time 
simpler solution shortly 
concurrency control periodic queries sliding windows algorithm dsms transaction scheduler input list currently running tqk transactions local variables bit array loop new transaction tj arrives scheduling execute wj mod cj tqk nk mod true execute abort tqk elseif new transaction tqk arrives scheduling add tqk set false empty choose tql execute operation tql call rql set true read operations left tql execute cql remove tql loop tj updated sub window older copy read currently running tqk transactions case tj serialized tqk 
occurs nk mod set currently running tqk 
easy see nk mod th bit set true query read mod th sub window aborted 
nk recall note observation query window length update jth sub window implies nk mod th sub window contains expired tuples respect window length 
query explicitly read updated sub window aborted seen data expired shorter window length 
case algorithm aborts tqk line ensuring tqk transactions committed line satisfy definition 
algorithm supports read transactions different priorities time queries important persistent queries 
assume query sliding window query processing data streams manager embeds priority tqk change line algorithm read tql transaction highest value 
consequently low priority tqk currently executed higher priority transaction effect suspending tqk 
extension impact correctness algorithm introduce new lws conflicts 
optimal ordering read operations algorithm may abort read transactions order guarantee lws desirable minimize required number aborts 
idea shuffle read operations tqk transactions insight 
aborts occur sub window updated older version read concurrent tqk transaction tqk executed reading sub window scheduled updated farthest 
precisely define time update ttu sub window number window movement transactions tj applied sub window updated 
scheduler chooses read transaction tqk process executes remaining read operation tqk sub window highest ttu value time 
note time sub window highest ttu value updated window movement transaction 
revised scheduler shown algorithm adding support multiple priority levels done changing line process highest priority transaction 
main changes 
lines update ttu values sub window window movement 
newly updated sub window receives value take write transaction sub window updated ttu values remaining sub windows decremented 
furthermore line selects index sub window highest ttu value read tql 
recall section algorithm assumed change contents readonly transactions corresponding queries windows shorter nt concurrent window update took place 
technique applies algorithm simpler solution possible 
line reads sub windows ttu order query window length simply defined reading nk sub windows highest ttu values youngest sub windows 
concurrent window movement takes place ttu values sub windows updated lines explicit modification contents query transactions necessary 
lines may replaced instructions maintain counter number sub windows read query tqk nk schedule read youngest window counter query non zero counter drops zero condition line true query transaction may committed 
sub window read modified line assumed order data read affect final answer query case traditional relational query optimization different access paths data possible 
concurrency control periodic queries sliding windows correctly identifies transactions need aborted correspond queries scan windows shorter nt recall theorem 
idea algorithm similar longest forward distance cache replacement algorithm evicts page access latest 
optimal line case terms number page faults system knows entire page request sequence page faults cost 
algorithm dsms transaction scheduler ttu input list currently running tqk transactions local variables bit array array sub window ttu values loop new transaction tj arrives scheduling execute wj mod cj set set mod tqk nk mod true execute abort tqk elseif new transaction tqk arrives scheduling add tqk set false empty choose tql execute rql set true read operations left tql execute cql remove tql loop theorem algorithm optimal ensuring lws sense performs fewest possible aborts history proof 
scheduler algorithm transaction scheduler sliding window query processing data streams serializes transactions way differs ordering read operations inside read transactions 
corresponds algorithm arbitrary implementation meaning operation line 
objective prove performs fewer aborts history hi prefix containing read operations interleaved zero write operations zero commit abort operations 
proof proceeds inductively transforming sequence read operations produced produced read operation time 
accomplish define transaction scheduler si si properties 

si si order read operations hi way 
si orders read operations hi way performs aborts si hi 
rk st read operation executed si rk st read operation executed si 
due assumption differ ordering read operations inside read transactions st read operations done si si belong transaction call tqk 
sub window mod highest ttu value time 
si si property holds proof completed 
si si differ st read operation 
suppose tqk interrupted write transactions read operation 
tqk aborted si si hi proof completed property holds 
suppose tqk interrupted write transaction read operation 
remainder proof broken cases collectively prove property 
case suppose set interrupting transactions contains ty tz 
sub window mod highest ttu value time write transactions generated serially executed increasing order subscripts write transaction subscript higher 
si aborts tqk hi 
tqk read old version sub window mod ty serialized tqk 
si abort tqk hi 
see observe tqk possibly read sub windows just updated 
due fact sub windows lower ttu values sub window mod necessarily scheduled sub window mod si 
second case suppose set interrupting transactions contain ty tz 
reasoning write transaction subscript higher 
si abort tqk hi tqk possibly read sub windows updated ty lower ttu values sub window mod 
terms satisfying property matter si case 
third case suppose set interrupting transactions contains ty tz 
si si abort tqk hi schedulers allow tqk read sub window updated 
concurrency control periodic queries sliding windows algorithm takes advantage weakest non monotonic update patterns sliding windows order anticipate possible lws violations prevent greatest possible extent 
example need reordering read operations read transactions consider interleaved schedule query tq window movements parameters histories ha hd defined section 
rq rq rq rq rq cq sub window zero oldest ttu updated write transaction 
sub window ttu sub window ttu 
read operation scheduled reads sub window highest ttu value sub window 
sub window zero updated ttu changes ttu values subwindows decremented 
sub window zero read tq ttu value highest 
sub windows ttu values respectively 
point sub window remains read done updated 
contrast schedule sequentially executed read operations tq shown schedule hf latest window serializability violated immediately committed 
hf rq rq rq rq rq cq far assumed newly arrived data overwrite oldest sub window meaning query read old copy freshly updated sub window aborted order guarantee lws 
recall discussion section mentioning possibility temporarily keeping expired sub windows allowing queries re read order undo contribution expired tuples query state 
algorithm applies case 
difference lws conflict discovered transaction re scans old copy newly updated sub window followed reading new copy 
aborts necessary 
context algorithm optimal sense minimizing number required sub window re scans 
note queries accessing materialized sub result assumed window synopsis scanned query takes input weakest non monotonic query plan 
query reads weak non monotonic result longer case oldest sub window may dropped newest sub window inserted place 
solution chapter employed calendar queue store state corresponding intermediate result weak non monotonic query plan 
suppose calendar queue partitioned expiration time window joined contains sub windows 
illustrated windows slide oldest sub window expires 
sub window may incur insertions new tuples may various expiration sliding window query processing data streams update materialized sub result having weak non monotonic update patterns times deal issue modification scheduling algorithms 
materialized sub result having weak non monotonic update patterns updated query scanning summary tuples inserted sub windows read copied passed query prior inserted sub windows synopses 
way query guaranteed see updates lws preserved query update logic complex 
note query need read new tuples inserted sub windows read read query scans sub windows 
experiments implementation details experimental procedure simple dsms query manager implemented java transaction schedulers algorithm abbreviated ttu algorithm re order read operations transactions abbreviated lws scheduler similar algorithm enforces window serializability abbreviated ws scheduler executes transactions serially current dsmss abbreviated serial 
experiments performed pentium iv pc ghz cpu gb ram running linux 
input stream sequence simulated ip header packets randomly generated attribute values 
example source destination ip addresses random values data size random integer 
steady state stream arrival rate packet millisecond specific arrival rate particular sub window allowed deviate steady state rate factor 
query workload simulates network traffic analysis :10.1.1.113.2257
levels transaction priorities corresponding re executions periodic queries low priority corresponding time queries high priority 
total periodic queries executed arranged groups shared processing queries computing aggregate different window lengths require scan window basic interval synopsis 
periodic queries chosen randomly set top queries source destination ip addresses percentile queries th th th th th synopsis result weak non monotonic query plan may maintained similar fashion discussed section 
concurrency control periodic queries sliding windows staleness response time inter execution time th percentiles total bandwidth consumed directed distinct ip addresses 
window sizes referenced queries generated randomly total number sub windows 
simplicity implementation periodic queries executed scanning window building hash table required attribute 
time queries chosen set simple aggregates random subset source destination ip addresses 
query time window stored main memory 
initializing sliding window randomly generated input stream transaction schedulers tested identical query workload 
tests proceed time equal window length repeated times different input streams 
results averaged trials 
parameters varied experiments query workload window size controlled number sub windows length sub window controls frequency window movements 
performance metrics evaluate transaction schedulers illustrated corresponding execution time line 
query staleness difference time query reports answer time window update reflected answer 
response time difference query execution start time time 
metric important time queries usually time sensitive may posed order investigate suspicious change result persistent query 
inter execution time long running query length interval dsms expected tolerate slightly longer inter execution times returned answers date 
motivation older answer returned earlier system re execute query soon order produce answer reflects new state window 
percentage aborted transactions experiment illustrates theorem comparing percentage aborted read transactions algorithms 
sub window sizes tested sec 
explained detail chapter inter execution interval typically supplied query 
simplicity experiments chapter assume query desired inter execution interval queries continually re executed round robin fashion 
sliding window query processing data streams percentage read transactions aborted algorithm comparison query staleness serial ws lws ttu sec number sub windows varied 
number periodic queries set sec 
sec 
percentage transactions aborted algorithm shown 
contrast algorithm abort transactions experiment 
normal execution periodic query incur concurrent window update suspended long time order run heavy workload time queries 
algorithm ensures read transactions postpone reading sub window updated aborts easily avoided number concurrent window updates small 
note proportion read transactions aborted algorithm higher sec 
smaller sub window size implies window movements executed increasing chances read write conflicts 
aborts frequent number sub windows increases length sliding window grows causes longer query evaluation times number read transactions window updates decreases 
turn increases proportion read transactions execute time window movements raises chances read write conflicts 
worst case frequent window movement long window size sec 
sub windows algorithm aborts half read transactions nearly transaction incurs concurrent window movement ends causing lws conflict 
similar results obtained time queries added workload issued random times 
particular algorithm abort transactions 
experiments workload periodic queries section presents results executing serial ws lws ttu workload consisting periodic queries interleaved window movements 
sub window sizes number subwindows number periodic queries previous experiment assume time queries posed 
variables measured average staleness concurrency control periodic queries sliding windows comparison query times serial ws lws ttu comparison throughput read transactions lws inter execution time throughput 
average query staleness units seconds shown lower value better 
ttu lws clearly outperform ws serial guarantee serializable schedules queries access date state window 
expected staleness increases schedulers sub window size grows sec 
window movements frequent 
increasing number sub windows equivalently increasing window length generally adverse effect staleness query execution times increase 
note serial performs slightly better ws ws adds query execution time performing concurrent window movements answer reflect updates 
ttu provides lowest query staleness tested scenarios 
average query inter execution times units seconds graphed 
cluster bars corresponds order serial ws lws ttu sec followed serial ws lws ttu sec 
serial best lowest inter execution times incur overhead serialization graph testing total query execution time slightly lower 
notably lws corresponding third seventh bars cluster performs worst 
instance aborting second re execution periodic query means inter execution time doubles 
general increasing sub window size sec 
increasing total window size leads longer inter execution times schedulers queries take longer process 
similarly increasing number subwindows increases query evaluation times negatively affects inter execution times 
serial yields best query inter execution times ws ttu sliding window query processing data streams comparison time query response times serial ws lws ttu comparison time query staleness serial ws lws ttu closely lws performs badly due aborted transactions 
illustrates throughput units number read transactions second lws versus schedulers serial ws ttu labeled yield similar results 
particular throughput penalty ttu versus serial small typically percent percent 
serialization graph testing done ttu consists simple bit operations window movement causes negligible overhead 
note poor performance lws throughput lower cases due aborted transactions 
expected throughput schedulers decreases transactions take longer execute occurs sliding window large number sub windows increases sub window size increases 
experiments mixed workload periodic time queries section reports results experiments mixed workload periodic time queries concurrent window movements 
sub window size fixed seconds number periodic queries number time queries sub window length 
time queries scheduled random times average time requests set second 
average time query response times units seconds shown 
ttu ws perform best yield nearly identical response times 
response times lws noticeably longer forced abort restart time queries 
serial exhibits worst results experiment unable suspend periodic query execute time query immediately general serial inappropriate situation involving prioritized scheduling 
number sub windows increases response time achieved schedulers worsens costly execute query 
concurrency control periodic queries sliding windows comparison periodic query staleness serial ws lws ttu plots average time query staleness units seconds 
expected ttu outperforms schedulers guarantees latest window serializability abort transactions 
performance lws somewhat worse transactions corresponding time queries aborted restarted time 
ws serial guarantee latest window serializability exhibit worst performance 
ttu yields best results terms time query staleness tied best terms response time 
average staleness periodic queries examined separately order verify performance edge ttu context time query staleness come cost poor periodic query staleness 
results shown 
seen ttu maintains superiority producing date results periodic queries 
lessons learned experiments shown advantages executing latest window serializable histories particularly enforced proposed update pattern aware transaction scheduler 
staleness response time shown improve expense minimal loss throughput 
comparison related concurrency control mechanisms chapter compatible dsms employs periodic updates sliding windows query results 
techniques applicable system psoup mobile users connect dsms intermittently retrieve latest results sliding window queries :10.1.1.1.4609
context asynchronous requests may modeled time queries issued various times 
mobile users may low connectivity system wireless channel sliding window query processing data streams particularly important guarantee low response times date query answers 
transaction scheduler proposed chapter fulfills requirements 
transaction model chapter resembles multi level concurrency control multi granularity locking considers sub window entire window atomic data object 
novelty order sub window read operations performed maintained way minimize number aborted transactions 
furthermore note order read operations changes window slides sub window ttu values change 
contrast fixed resource ordering employed prevent deadlocks 
system model studied chapter encounter deadlocks due relative simplicity transactional workload 
algorithm able change ttu ordering window slides minimizing number aborted read transactions causing deadlocks 
ttu scheduler employed conflict concurrency control 
scheduling techniques include phase locking timestamping 
phase locking may appropriate context clear force particular serialization order locks 
possible problem timestamping dsms concurrency control difficulty ensuring latest window serializability 
suppose transaction receives timestamp passed transaction scheduler serialization order determined timestamps 
case concurrent window update transaction assigned higher timestamp read transaction serialized read transaction 
algorithm forced abort read transaction interrupted window movement 
latest window serializability similar commit order preserving serializability cps conflicting operations ordered way commits 
venn diagram illustrates relationship isolation levels general case 
histories hd section cps ws lws 
contrast history call hg cps ws lws 
hg rq rq rq rq rq cq see observe hg similar ha section commitment delayed tq commits order correspond serialization order 
clearly ws cps commit order matches serialization order 
hand history call hh ws lws cps 
query transaction tq fact see concurrent update reads latest state sliding window 
update transaction happens commit query commits serialized query 
hh rq rq rq rq rq cq worth noting lws cps shown 
theorem specific transaction workload assumed chapter assumption window movements commit immediately lws cps 
concurrency control periodic queries sliding windows relationship commit order preserving serializability cps window serializability ws latest window serializability lws proof 
suppose history lws 
means read transaction tqk operations interleaved write transaction true concurrent write transactions serialized tqk 
write transactions assumed commit immediately serialization order equivalent commit order 
cps 
suppose cps 
means tqk concurrent write transactions serialized tqk 
write transactions commit immediately commit query transaction 
write transactions serialized tqk 
means lws query transactions guaranteed see concurrent window movements 
chapter multi query optimization sliding window aggregates preceding chapters dealt time evolving nature data streams proposed exploited notion update pattern awareness sliding window query processing 
focus chapter multi query optimization context periodically re executed monitoring queries 
example query monitors median packet length stream ip packet headers call computed minutes minute window 
syntax similar cql query may specified follows 
select median length window min slide min current workload may include queries similar having additional predicates different window sizes different periods expressions slide interval period interchangeably 
instance workload may include query 
select median length window min slide min queries may posed different users network engineers user wishes summarize network traffic different time scales may simultaneously ask similar aggregate queries different window lengths 
examples applications issue aggregate queries parallel different window lengths include detecting bursts unusual activity identified abnormally high low values aggregate sum count 
burst suspicious activity may denial service attack network stock unusually high trading volume 
length burst typically unknown short lived burst produce unusual values span seconds sliding window query processing data streams possible ways schedule queries longer term burst generate suspicious packets minute series aggregates range window lengths needs monitored 
compute aggregate window lengths periods different 
obvious share memory computation 
furthermore determine queries share resources novel problem context similar queries having different slide intervals may scheduled re execution different times 
example illustrates time axis possible execution sequence defined 
assuming re answer computed shorter window computation sharing exploited minutes common multiple slide intervals 
possibility schedule due refresh 
case computation shared savings processing time may defeated expended updating necessary 
motivated issues chapter presents multi query optimization framework periodically refreshed aggregates sliding windows 
framework consists components identifying queries share state computation synchronizing execution times similar queries 
component starts existing techniques sharing state aggregates different window sizes 
techniques extended directions allowing state sharing queries containing aggregation selection joins discovering opportunities shared computation intermediate result previously executed query query 
second part novel definition slide clause proposed gives rise novel specification semantics periodic queries 
monitoring queries modeled periodic tasks query scheduler developed basis earliest deadline edf algorithm 
scheduler improves basic approaches discussed ways 

cost heuristic proposed deciding query re executed necessary execution times synchronized similar query 

additional sharing opportunities shown arise periods overload experienced dsms due changes time persistent query workload fluctuations stream arrival rates 
suppose due refresh time time system unable run time choices time clear backlog executing late queries moving recognize similar execute multi query optimization sliding window aggregates assumed query processing architecture moving late queries case cheaper evaluate re answer computed 
shown looking similar queries late query set currently scheduled query set increases throughput 
remainder chapter organized follows 
section introduces system model assumptions 
component multi query optimization framework section second section 
solution evaluated experimentally section compared related section 
preliminaries assumed query processing architecture illustrated corresponds described section transaction manager abstracted 
global query plan constructed selections shared joins final aggregates time windows :10.1.1.1.9425
joins maintain state corresponding hash tables windows inputs aggregates connected synopses 
allowed aggregates sum count avg max min count distinct quantile top may exact approximate 
types synopses running interval basic interval discussed section illustrated 
window join windows may associated synopses may different aggregates aggregates different attributes 
furthermore synopsis may shared queries discussed section 
part shared plan lies upstream left buffers executed continuously background note part shared plan weakest weak nonmonotonic 
new results continually deposited buffers pre aggregated counted sketched fly recall synopsis stores pre aggregated values frequency counters sketches various intervals current sliding window 
described section synopses updated periodically retrieving new data buffers inserting new interval removing intervals corresponding expired tuples 
queries scheduled re execution appropriate synopses probed obtain answer query scheduling discussed section 
sliding window query processing data streams lifetime query expires query may removed global plan shared components plan retained 
conversely new query merged global plan dropped outright case system overloaded 
appropriate synopses exist underlying windows stored ws approach section new query may execution immediately 
interesting case occurs matching synopsis window length short new query 
time span matching synopsis may extended deleting oldest intervals updates 
note causes delay query begins generating output 
fails new synopsis may built new query scratch take window length synopsis fills data 
identifying processing similar queries part solution identifies queries share state computation 
slide intervals queries ignored 
focus determining queries benefit shared evaluation re execution times happen coincide 
state sharing abbreviated ss computation sharing abbreviated cs rules simple aggregates working complex multi operator queries 
rule set means exhaustive new rules easily added proposed framework 
sliding window aggregates type queries considered consisting single aggregate operator single window 
straightforward rule motivated section ss synopsis parameters may queries computing aggregate different aggregates require data interval different window lengths size ns extent computation sharing depends type synopsis 
recall section observe shared probing running interval synopsis queries different window lengths faster separate probing 
different running intervals subtracted different window sizes 
generally different set non overlapping intervals probed 
cs multiple queries share running interval synopsis state may executed window length 
example count distinct top queries may computed interval synopsis frequency counts subtracting counts appropriate intervals performing appropriate post processing 
note part computation shared queries 
hand issues related admission control orthogonal discussed 
multi query optimization sliding window aggregates cs queries accessing basic interval synopsis may computed 
cs holds answers different window sizes may returned way synopsis probed youngest interval oldest 
regardless number queries intervals accessed 
interval synopses access log intervals query cs cs suggest basic interval synopsis log queries executed 
case basic interval synopsis exceeds query efficiency interval synopsis half space 
determine queries scheduled executed slide intervals need examined 
treatment issue deferred section 
rules hold avg ss exists running synopsis parameters storing sums running synopsis parameters storing counts may avg window size ns update times aligned 
cs ss holds exist queries computing sum count avg window length may executed 
ss requires synopses aligned updated times sum count computed exactly window 
significance cs avg simply divide answers computed sum count 
aggregates joins synopsis design weakest non monotonic update patterns exploited synopses updates oldest interval summarizes expired tuples dropped 
recall chapter sliding window join weak non monotonic operator 
result existing synopses suitable 
instance aggregate value computed join results generated time units different join results windows length 
existing synopses may extended handle join results defining intervals terms tuple expiration times basic interval join bij synopsis join windows length illustrated update time data stored interval shown may consist pre aggregated values frequency counters sketches 
interval labeled expiration time ranges join results summarized 
behaviour buffer preceding bij synopsis modified pre compute 
dropped summarizes tuples due expire times refers new join results expire times appended 
recall similar concept calendar queue chapter context storing intermediate results weak non monotonic queries 
sliding window query processing data streams examples rj bij synopses remaining intervals updated merging values corresponding precomputed intervals 
interval join ij synopsis may constructed interval synopsis case intervals updated time units 
running join rj synopsis shown update time requires buffer pre compute aggregates 
update removes adds updates intervals illustrated 
space usage new synopses respective existing synopsis update complexity grows intervals modified 
sharing state computation denote join windows sizes respectively join 
suppose group queries contains join 
case rules defined far apply 
instance probing intervals bij synopsis right left yields result join 
see consider join results part join observe results belong oldest interval join synopsis 
true join results contain tuple oldest part corresponding window part arrived time units ago 
means expiration times join results time time similar reasoning applies rj synopsis 
suppose consider count query join 
intuitively count higher join lower join 
necessary subtract appropriate tuples oldest interval join synopsis 
example suggests solution modifies join operator flag results involving tuples multi query optimization sliding window aggregates example generalized bij synopsis oldest part window part join 
illustrates generalized version bij synopsis associated additional parameter stores pieces data oldest intervals 
ij rj synopses may generalized similarly 
values middle interval correspond bij synopsis 
additional sets values stored oldest intervals corresponding aggregates exclude flagged join results second window respectively 
terms buffer design separately pre aggregate values needed oldest intervals 
sharing rules generalized join synopses follows 
ss generalized bij ij rj synopsis parameters may shared aggregates joins windows length ns joins cs queries accessing generalized ij rj synopsis may computed window lengths join 
cs queries accessing generalized bij synopsis may computed 
aggregates selection simple solution queries various selection predicates execute separately separate synopses 
synopses may shared queries overlapping predicates 
assume query predicates disjunctive normal form duplicate predicates removed 
furthermore assume term disjunction atom form attribute op constant op simple operation equality inequality greater 
define query predicate 
pi covered set synopses synopsis computes aggregate contains data counters sketches input terms pk correspond exactly concatenation predicates associated synopses additionally subset superset terms pk appear concatenation predicates 
definitions illustrated queries stream ip packets headers window slide clauses omitted clarity 
sliding window query processing data streams select sum length protocol tcp select sum length protocol udp select sum length protocol tcp protocol udp select max length protocol tcp select max length user select max length protocol tcp user suppose synopses 
synopses cover compute aggregate stream include terms predicate 
synopsis 
similarly synopses cover 
additionally synopsis 
predicate disjoint terms pk disjoint term equality predicate attribute 
set synopses disjoint cover covers synopsis disjoint predicate concatenation predicates appearing disjoint 
example synopses belonging disjoint cover belonging disjoint cover terms protocol tcp user necessarily disjoint 
final definition needed predicate matching deals duplicates 
distributive aggregate recall section duplicate insensitive overlapping multi sets 
duplicate sensitive 
aggregates considered sum count duplicate sensitive complex aggregates require synopses store counters sketches 
min max duplicate insensitive 
examples suggest new queries may re synopses cover 
example obtain answer synopsis answer synopsis add 
leads decrease space usage synopsis maintenance costs third synopses needed 
motivated observation step framework may predicate overlap identification 
set relevant synopses may answer new query 
update times relevant synopsis aligned recall rule ss 
duplicate sensitive aggregates relevant synopses form disjoint cover incorrect answers produced due overlap predicates 
aggregates suffices set cover aggregates relevant set may disjoint provided exists disjoint cover terms appear synopses may answer subtraction 
second step provides rule answering combining results obtained relevant synopsis 
operation may maximum minimum takes maximum answer answer addition sums counts counters sketches subtraction addition 
third step returns set candidate queries shared computation example candidates 
procedure yields rules 
multi query optimization sliding window aggregates ss non empty set relevant synopses may new query provided window lengths matching synopses long new query cs relevant synopses type running interval generalized rj generalized ij candidate queries followed new query may executed window lengths 
cs relevant synopses type basic interval generalized bij candidate queries followed new query may executed 
note soundness framework follows distributive property sliding window synopses employed chapter merging partial answers multiple synopses equivalent merging aggregated information frequency counts intervals individual synopsis 
details regarding finding set relevant synopses incoming query maintaining sets relevant synopses queries come go orthogonal discussed 
note exception ss cs cs rules section universally applicable 
ss ss applied building separate synopses similar queries shorter window sizes 
similarly cs cs lead situations computation amortized multiple queries 
ss cs cs represent space versus time tradeoff saving space sharing synopses may lead higher query processing times fewer synopses maintained multiple synopses probed answer queries 
multi query scheduling having defined set rules state computation sharing section presents second component proposed solution scheduling similar queries order exploit sharing opportunities 
section begins novel definition semantics slide clause 
definition earliest deadline scheduler designed queries section 
scheduler extended schedule multiple queries section 
improvements synchronizing schedules similar queries sections 
semantics periodic query re execution consider query accessing synopses 
recall synopsis updated buffer completes pre aggregating current interval say interval updates 
means time buffers computing aggregates interval ready send pre aggregated values synopses 
updates recall section possible extend time span existing synopses new query tolerate delay arrival time begins produce answers 
sliding window query processing data streams semantics periodic query re execution taken place time synopses reflect state window time assume ample time updates execute queries 
slide interval synopses update times time line illustrated showing re execution time answer reflects state synopses time slide interval ns means number times synopses updated consecutive re executions re evaluation reflect state synopses time done time illustrated 
note period query multiple inter update interval synopses 
practical remarks regarding definition worth making 
defining upper bound number synopsis updates query re executions assumed queries may refreshed specified 
assumption consequences 
system lightly loaded may fact possible re execute queries definition assumed rigid re execution interval system experience periods idle time 
second allowing query refreshed sooner required enables synchronization re execution times similar query illustrated 
definition required fixed re execution interval resource sharing significantly limited illustrated 
second involves words definition periodic re execution 
accommodates periods overload occur due fluctuations query workload stream arrival rates 
precisely assumed periodic query dsms follow definition possible permitted break necessary 
consequently definition allows solutions handling overload 
dsms may drop fraction queries overload detected block users re registering dropped queries overload 
second dsms may continue re execute queries overload temporarily increase periods 
second solution assumed remainder chapter ensures fairness query workload 
may argued users interested tracking events expected occur regularly say minutes insist queries refreshed exactly minutes 
situations different queries discussed chapter ways 
tracking specific event periodic query continuous query keeps listening new input immediately reacts observing specified event raising alarm 
second event tracking corresponds multi query optimization sliding window aggregates selection queries possibly complex predicates aggregation sliding windows 
earliest deadline scheduling suggests execution sequence time system updates synopses waiting aggregates finds queries due refresh attempts execute synopses updated 
shared sets synopses need synchronized 
sequence started time running sequence corresponding different group synopses queries may 
remainder section deals local scheduling task sequence containing queries access group synopses 
scheduling solutions compatible underlying global scheduler allocating weighted time slice local scheduler 
reflect slide semantics defined persistent query modeled task ti period 
denote rth re execution ti assign time deadline task denoted ti follows 
done set ti ni 
update synopses set ti ti 
said execute time ti done 
example ti query executed ti time interval ti time re execution query query executed time ti re execution 
due fluctuating stream arrival rates changes query workload may possible estimate long take execute possible schedule tasks line 
consequently line earliest deadline edf algorithm chosen starting point local query scheduler algorithm 
query scheduled separately 
algorithm maintains task queue containing current query workload 
new queries translated new tasks added queries lifetimes expired removed 
assumed update notification sent interval currently pre aggregated buffers fills synopses due update 
clarity algorithm remaining scheduling algorithms follow assume queries window updates executed isolation 
concurrency control techniques chapter compatible scheduling algorithms described 
observations regarding algorithm worth noting ti re executed late ti set ni done 
reasoning lateness may imply system overload attempting late re execution scheduling re execution early overload worse 
ties line may broken arbitrarily 
alternatively query may assigned userdefined priority case highest priority task tasks deadline zero executed 
algorithm adaptively adjusts query periods response system load 
tasks may executed ti values reach zero 
overload algorithm attempts clear backlog executing queries largest negative value ti 
tasks may executed ti values negative sliding window query processing data streams algorithm local scheduler input task periods ni task queue local variables array ti initially ti ni loop update notification arrives update synopses decrement ti tasks ti empty execute task ti lowest value ti reset ti ni loop periods lengthened implicitly 
behaviour may thought form automatic load shedding recall section 
scheduling multiple queries recall computation sharing rules cs cs section 
identify queries may executed scheduled time 
suppose application rules returns set query groups gq 
group contains queries may different slide intervals queries basic interval generalized join synopses may different window lengths cs cs cs 
remainder section suppose group contains queries computing max window single basic interval synopsis minute cs queries group may different window sizes 
window slide parameters queries follows 

window min slide min 
window min slide min 
window min slide min 
window min slide min 
window min slide min 
window min slide min 
window min slide min incorporate multi query scheduling algorithm group gi defined single task ti period ni equal shortest period queries 
technique referred aggressive scheduling 
illustrated aggressive scheduling executes queries minutes 
simple technique jointly executes similar queries due refresh time 
achieved splitting group gi sub groups gi gi gi qi containing queries slide interval 
multi query optimization sliding window aggregates algorithm conservative scheduler input sub group periods ni task queue local variables array ti initially ti ni loop update notification arrives update synopses decrement ti tasks ti empty lowest ti value task ti ti ti choose task ti jointly execute ti task ti reset values tasks just executed loop furthermore task ti corresponds queries gi executed 
technique name conservative scheduling 
example partitioned containing minutes containing minutes containing minutes 
resulting schedule shown 
algorithm summarizes conservative scheduling 
line ensures queries subgroups gi group gi executed slide intervals different sub groups coincide 
instance minutes may executed 
meaning joint execution line depends computation sharing rule create group 
case cs cs synopsis scanned result saved sketch corresponding shared window length query separately post processes appropriate 
case cs cs synopsis scanned youngest interval oldest queries shorter windows computed 
case cs sum count executed probing respective synopses answers divided obtain average 
case cs predecessor queries executed answers saved new query 
case cs predecessor queries executed answers shorter windows may need saved new query 
example window length window length processed maximum window length saved 
rule applies algorithm improvements discussed section 
cs query registered system query arrives identical including window size period longer share output stream sliding window query processing data streams execution schedules queries group various scheduling techniques words system computing query may shorten period re results generated note lifetime expires period may reset original value may need relocated different sub group gi hybrid scheduling improved scheduling technique called hybrid scheduling 
relative cost model determines sub groups re executed order synchronize schedules sub groups 
relative cost schedule may computed adding synopsis access costs intervals accessed needed combine pre aggregated values intervals post processing costs sorting frequency counts find top largest ones combining answers multiple synopses 
synopsis maintenance costs may ignored vary schedules 
hybrid scheduling introduced queries section recall partitioned conservative scheduling sub groups 
step calculate relative cost single re execution sub group 
basic interval synopsis queries computed scanning youngest intervals synopsis answers shorter windows needed computed way 
cost comparisons determine maximum maximum values stored interval 
similarly cost cost multi query optimization sliding window aggregates 
execution cost needed incurred conservative scheduling recall 
minutes common multiple subgroups executed cost scanning synopsis compute maximum minute window needed answers queries computed way 
interim executed separately twice cost cost 
total cost minutes minute 
suppose executed due refresh 
case sub groups executed minutes 
cost minute 
best way execute sub groups schedule period minutes 
total possibilities sub groups change periods corresponds conservative scheduling costs minute shortens period minutes minute shorten periods minutes minute changes period minutes minute shortens period minutes minute 
hybrid scheduling chooses efficient possibilities reducing period executing queries sub groups illustrated 
algorithm may hybrid scheduling modifications difference periods sub groups shorter 
hybrid scheduling expected outperform aggressive conservative scheduling performs right amount sharing appropriate shortens periods queries order synchronize similar queries 
hybrid scheduling expensive maintain 
query workload changes cost separate merged execution various sub groups recomputed 
expected major source overhead cost model simple efficient schedule may computed dynamic programming memorizing execution cost overlapping subsets sub groups order prevent duplicate calculations 
point worthwhile revisit observation section regarding choice basic interval synopsis versus interval synopsis 
recall uses half space slower query processing times 
basic interval synopsis accessed log queries time outperforms interval synopsis space usage query processing time 
hybrid scheduling align schedules queries achieved 
similar queries breakpoint value log additional sharing overload additional computation sharing possible overload tasks negative ti values 
define late set contain tasks ti ti pending set contain tasks ti ti 
suppose particular execution queries sub group late 
suppose particular execution queries sub group late 
sub groups may scheduled belong group algorithm conservative scheduling schedules tasks ti values moving 
missed sliding window query processing data streams algorithm conservative hybrid scheduler late pending sharing input sub group periods ni task queue local variables array ti initially ti ni loop update notification arrives update synopses decrement ti tasks ti empty lowest ti value task ti ti ti ti ti choose task ti jointly execute ti task ti reset values tasks just executed loop sharing opportunity exploited help clear overload faster 
possible extension conservative hybrid scheduling call late sharing schedules matching sub groups entire late set lowest ti value 
possibilities sharing 
suppose addition late value current time 
possible schedule sub groups 
shifts system resources away clearing backlog late tasks beneficial long run late window slides 
system throughput improve 
technique referred late pending sharing summarized algorithm 
differs algorithm defines union late set pending set overload lines 
note late sharing implemented replacing line ti ti 
possible schedule produced hybrid scheduling late pending sharing context example section illustrated 
indicated arrows suppose late time pending 
queries sub groups executed 
multi query optimization sliding window aggregates experimental evaluation setting optimization rules query scheduling techniques chapter implemented dsms query manager chapter tested environment 
previous chapter input consists simulated ip packet headers randomly generated attribute values 
initially number distinct source destination ip addresses set number distinct protocols ports 
tested workload consists groups periodic queries group computing top lists quantiles bandwidth usage source ip address destination ip address pairs protocol port protocol port pairs 
workload sizes considered queries group giving total number periodic queries respectively 
query randomly generated window length randomly generated slide interval half window length 
additionally time queries requesting bandwidth usage statistics random source ip address executed average second 
rule cs group periodic queries shares basic interval synopsis storing appropriate counters 
simplicity synopses updated time queries priority 
time queries served separate running synopsis 
queue recall algorithms implemented heap sorted task deadlines 
storing time deadline values decrementing synopses updated stores actual deadline times need revised re inserted heap task executed 
variables measured experiments throughput queries re executed second average latency query defined additional number times synopsis updated re executions 
example query requests slide seconds synopsis updates re executions synopsis slides times re execution average latency 
query re executed early latency remains zero 
experiment repeated average data rates tuples second 
higher data rate number distinct values packet fields doubled order force queries generating answers cause overload 
results varying window size omitted effects data rates change cases queries access data re execution 
table lists scheduling techniques abbreviations 
baseline sharing technique implemented equivalent algorithm tasks corresponding subgroups gi sharing similar conservative scheduling execute matching sub groups due refresh time 
late sharing late pending sharing added conservative scheduling performed worse hybrid scheduling discussed 
sliding window query processing data streams throughput measurements data rate tuples second results low data rate table abbreviations scheduling techniques sharing aggressive scheduling cs conservative scheduling hs hybrid scheduling ls hybrid scheduling late sharing lp hybrid scheduling late pending sharing average latency measurements data rate tuples second results experiments data rate tuples second 
throughput shown average latency queries 
expected cs lowest throughput gap growing number queries increases similar queries different periods due refresh time 
similarly cs high latency particularly bad small number queries meaning cause system overload easily overload occurs average latency zero 
note hs easily doubles throughput cs reduces latency order magnitude 
particular hs routinely shorten periods half sub groups order enable shared computation recall section 
sub groups conservative scheduling case hybrid scheduling requires separately scheduled sub groups tasks 
additional improvements throughput latency gained ls lp especially number queries grows system falls overload 
note achieves throughput poor latency 
queries needlessly refreshed deadlines 
multi query optimization sliding window aggregates throughput measurements data rate tuples second results high data rate average latency measurements data rate tuples second figures respectively graph throughput latency achieved data rate tuples second 
general latencies higher throughput lower techniques due heavier overload 
cs continue yield poor throughput high latency extremely high latency case sharing 
relative improvement hs modest continues shorten periods half sub groups queries re executed 
hand lp doubles throughput hs 
lp clear winner throughput latency 
overload severe exploiting additional sharing opportunities queries different deadlines crucial 
curiously throughput drops significantly experiment costly re execute queries especially long window sizes normally refreshed sporadically done frequently 
lessons learned experimental results hs significantly improves throughput system underloaded lightly overloaded 
overload lp superior technique clear winner second set experiments 
comparison related terms multi query optimization dsmss previous concentrates shared execution filters joins 
works assume incoming tuples processed immediately typically updating materialized joins affected new tuple matching new tuple query predicate index 
body sliding window query processing data streams largely orthogonal framework introduced chapter may speed processing continuous part shared query plan illustrated 
existing dsms solutions consider periodic query execution deals sharing state simple aggregates proposes running interval synopses 
chapter extends enlarging set supported queries proposing computation sharing rules addition state sharing 
solution supports shared computation similar distributive aggregates different group columns may incorporated rule set section 
furthermore periodic re evaluation selections unbounded streams joins streams tables discussed :10.1.1.136.4253
system model similar illustrated shared query plans employed 
query buffer due re execution activates shared plan computes new results similar queries buffers 
sliding windows new results computed re execution different query expire original query issued 
aggregation schedule synchronization supported 
fourth solution deals multi query optimization aggregates sliding windows different lengths different selection predicates 
contains steps relevant orthogonal ideas outlined chapter 
particular workload shown optimally reduce number intervals need stored basic interval synopsis 
modification fully compatible approach 
second different selection predicates accommodated storing query lineage tuple 
particular tuple contains bitmap specifies queries satisfies aggregate values pre computed distinct bitmap vector 
effectively creates separate basic interval synopsis bit vector storing separate synopsis query 
technique possible implementation relevant synopsis creation matching process outlined section 
note schedule synchronization considered 
join synopses section calendar queue section appropriate extensions multi query processing 
computing approximate aggregates data stream joins discussed works consider periodic updates join synopses sharing queries referencing joins different window lengths 
semantics sliding windows defined periodically sliding window represented sequence overlapping extents 
new aggregate value returned extent closes tuples mapped 
definition corresponds way synopses updated new interval computed buffer fills inserted synopsis 
semantics slide clause section separate underlying synopsis updates query execution times possible execute queries instantaneously window slide 
research scheduling dsmss considers scheduling level individual tuples operators choosing tuple process time 
goals bound sizes inter operator queues control output latency 
scheduling level multi query optimization sliding window aggregates queries considered 
related scheduling approach described chapter deadline load shedding framework described window slide pending query re executions dropped system predict insufficient time window update deadline perform scheduled tasks 
approach taken chapter different reasons 
require mechanism predicting cost advancing windows re executing queries 
second query re executions dropped periods queries increased overload 
avoids situations query long period re executions dropped wait long time refresh 
earliest deadline algorithm edf adapted scheduling sliding window queries 
dynamic nature query workload lack reliable estimates task completion times desire prioritize late tasks dropping eliminate real time job shop scheduling algorithms rate monotonic shortest time completion slack highest value 
edf known perform poorly overload may wonder chosen basis dsms query scheduler 
answer edf performs badly terms goals real time systems completing tasks possible deadlines 
edf poor choice case gives priority transactions finish time deadlines close 
edf plausible technique context dsms goal re execute queries desired periods 
consequently better prioritize queries earliest re execution deadlines unnecessarily executing query due refresh 
known edf optimal terms minimizing maximum task lateness 
assumptions proof tasks executed separately 
interesting area involves finding optimal scheduling algorithm scenario chapter shared execution periodic tasks possibility overload 
terms minimizing maximum task lateness maximizing system throughput 
rules section related extensive body traditional multi query optimization answering queries views particularly context queries aggregation group 
applicable dsms scenario may added framework section 
additionally chapter novel rules proposed detecting similar queries properties aggregate functions duplicate sensitivity 
difference traditional multi query optimization dsms multi query optimization framework proposed chapter includes additional step synchronizing schedules similar queries 
chapter summary contributions focus research sliding window query processing unbounded data streams emphasis persistent query semantics query processing optimization concurrency control 
central notion update pattern awareness introduced defines way inputs outputs persistent queries change time new data arrive stream windows slide forward chapter 
insight update pattern awareness dsms predict order data expire underlying windows intermediate operator state traditional dbms deals updates far frequently allows users modify piece data time subject integrity constraints defined database 
consequence data item sliding window intermediate operator state may associated lifetime predictable length lifetime row relational table typically unknown advance 
update pattern awareness define semantics persistent queries build framework sliding window query processing optimization 
order magnitude performance gains observed various conditions identifying update pattern aware query processing key issues efficient support dsms applications occupying middle requirements spectrum illustrated 
terms sliding window maintenance solutions efficient main memory storage time evolving data having equal variable lifetimes chapter 
need store time evolving data disk motivated context applications perform line stream mining analysis 
shown existing indexing sliding windows disk applies data having fixed lifetimes 
index proposed data items having variable lifetimes chapter 
insight solution simultaneously partition data insertion expiration times order ensure fast bulk updates 
particular proposed index employs update pattern information order avoid bringing entire data set memory update 
significant improvements index update times observed especially large data sets 
sliding window query processing data streams implementation optimization sliding window join discussed chapter 
impact eager versus lazy evaluation eager versus lazy expiration shown significance update patterns join inputs terms implementation 
furthermore join ordering heuristic proposed showing classical ordering heuristic join selectivities produce efficient orders context sliding windows 
improved heuristic takes account stream arrival rates window sizes examines small fraction possible join space 
update pattern aware algorithm detecting frequently occurring item types sliding windows chapter 
objective avoid storing maintaining histogram entire window 
summarizing underlying distribution item types sub linear space insight solution maintain exact frequencies frequently occurring items non overlapping partitions sliding window 
proposed algorithm shown perform bursty tcp ip streams containing small set popular item types 
dsms concurrency control mechanism motivated developed chapter 
shown window may slide forward associated synopsis data structure scanned query 
explained worthwhile temporarily interrupt processing query order update state window query read changes resumed 
proposed solution model views dsms data access mix concurrent read write transactions 
conflict serializability shown insufficient order guarantee suspended queries read date state sliding window restarted 
observation prompted need stronger isolation levels dsmss running periodic queries sliding windows 
update transaction scheduler developed enforcing new isolation levels 
idea reorder read operations queries tuples expected expire read transaction 
scheduler provably optimal reducing number aborted transactions experimentally shown improve query freshness response times maintaining high transaction throughput 
multi query optimization identified second key issues dsms query processing sliding windows chapter 
novel problem similar queries potentially executed may different periods slide intervals 
result queries scheduled different times missing opportunity share resources 
components multi query optimization framework 
extensible set rules identifying queries may share state computation 
rule set covered queries individual windows joins queries containing disjunctive selection conditions 
second query scheduling algorithm attempts synchronize re execution times similar queries possible including periods system overload 
experimental results showed advantages proposed techniques terms system throughput 
directions research research may extended lines 
update pattern aware query algebra chapter introduced update pattern awareness terms sliding window maintenance operator implementation query optimization 
adding update pattern awareness data stream algebra possibility research 
example problem domain finding set algebraic operators express possible weakest weak non monotonic queries 
optimization strict non monotonic queries discussed chapter strict nonmonotonic queries count windows containing negation processed negative tuple approach 
way speed types queries reduce number negative tuples flowing plan 
may done temporarily buffering result tuples 
example producing results negation right away query wait see matching tuple arrive input near cause negative tuple produced original result appended output stream immediately 
adaptive query processing persistent query plan may need adjusted time 
possible question update pattern awareness improve adaptivity sliding window query plans changing stream conditions 
instance plans obtained pulling operators having complex update patterns may resilient changes stream arrival rates plan shielded sudden increase number negative tuples processed 
issue involves increasing robustness join ordering heuristic chapter 
possibility overestimate arrival rates streams expected bursty chosen join order significantly sub optimal estimated stream parameters deviate actual stream conditions 
sliding window join processing materialized sub results possible extension chapter involves join ordering presence materialized sub results stored update pattern aware data structures order minimize view maintenance costs generally selection sub results materialize spare memory available 
multi query optimization chapter dealt multi query optimization context periodic queries aggregation recall 
possibility research investigate shared processing continuous queries chapter 
instance similar strict non monotonic queries executed plan queries smaller window sets negative tuples may need propagated announce expirations larger window smaller window 
furthermore rule set chapter extended cover wider range queries 
particularly interesting type queries containing user defined aggregates 
may possible identify similar parts different userdefined aggregates partially share state computation 
sliding window query processing data streams concurrency control complex queries chapter may extended investigate concurrency control issues complex query plans containing number pipelined window operators 
problem appears sub query occurs query case query may need read data execution sub query flattened 
dsms recovery treatment dsms concurrency control chapter may extended include semantics data loss crash recovery loss data particular time interval impossible queries read full window 
update pattern aware dsms security access control important problem data streams transmitted wireless sensors generated internet users easily accessible information stored private database 
simple example novel issue context consider application stores sliding windows confidential privileged information 
old data expire completely removed system archived remain confidential available access larger group users 
bibliography abadi ahmad balazinska cetintemel cherniack 
hwang lindner tatbul xing zdonik 
design stream processing engine 
proc 
biennial conf 
innovative data sys 
res 
cidr pages 
abadi carney cetintemel cherniack convey lee stonebraker tatbul zdonik 
aurora new model architecture data stream management 
vldb journal aug 
abbott garcia molina 
scheduling real time transactions performance evaluation 
proc 
int 
conf 
large data bases vldb pages 
adamic huberman 
nature markets world wide web 
quarterly journal electronic commerce 
aggarwal han wang yu 
framework projected clustering high dimensional data streams 
proc 
int 
conf 
large data bases vldb pages 
ahmad cetintemel 
network aware query processing stream applications 
proc 
int 
conf 
large data bases vldb pages 
albert jeong 
barabasi 
diameter world wide web 
nature 
ali aref bose elmagarmid helal kamel 
nile pdt phenomenon detection tracking framework data stream management systems 
proc 
int 
conf 
large data bases vldb pages 
alon matias szegedy 
space complexity approximating frequency moments 
proc 
acm symp 
theory computing stoc pages 
franklin tomasic urhan 
scrambling query plans cope unexpected delays 
proc 
int 
conf 
parallel distr 
inf 
sys 
pdis pages 
arasu babcock babu widom :10.1.1.10.3265
characterizing memory requirements queries continuous data streams 
acm trans 
database sys march 
arasu babu widom 
cql continuous query language semantic foundations query execution 
vldb journal appear 
arasu cherniack maier stonebraker 
linear road stream data management benchmark 
proc 
int 
conf 
large data bases vldb pages 
sliding window query processing data streams arasu manku 
approximate counts quantiles sliding windows 
proc 
acm sigmod sigact sigart symp 
princ 
database sys 
pods pages 
arasu widom 
denotational semantics continuous queries streams relations 
acm sigmod record 
arasu widom 
resource sharing continuous sliding window aggregates 
proc 
int 
conf 
large data bases vldb pages 
avnur hellerstein 
eddies continuously adaptive query processing 
proc 
acm sigmod int 
conf 
management data pages 
naughton 
static optimization conjunctive queries sliding windows unbounded streaming information sources 
proc 
acm sigmod int 
conf 
management data pages 
naughton wright srivastava 
approximate streaming window joins cpu limitations 
proc 
int 
conf 
data eng 
icde page 
babcock babu datar motwani thomas :10.1.1.58.1029
operator scheduling data stream systems 
vldb journal 
babcock babu datar motwani widom 
models issues data streams 
proc 
acm sigmod sigact sigart symp 
princ 
database sys 
pods pages 
babcock datar motwani 
load shedding aggregation queries data streams 
proc 
int 
conf 
data eng 
icde pages 
babcock datar motwani callaghan 
maintaining variance medians data stream windows 
proc 
acm sigmod sigact sigart symp 
princ 
database sys 
pods pages 
babcock olston 
distributed top monitoring 
proc 
acm sigmod int 
conf 
management data pages 
babu 
adaptive query processing looking glass 
proc 
biennial conf 
innovative data sys 
res 
cidr pages 
babu motwani widom 
adaptive ordering pipelined stream filters 
proc 
acm sigmod int 
conf 
management data pages 
babu widom motwani 
adaptive caching continuous queries 
proc 
int 
conf 
data eng 
icde pages 
babu srivastava widom 
exploiting constraints reduce memory overhead continuous queries data streams 
acm trans 
database sys sep 
babu widom 
adaptive engine stream query processing 
proc 
acm sigmod int 
conf 
management data pages 
balakrishnan balazinska carney cetintemel cherniack convey stonebraker tatbul zdonik 
retrospective aurora 
vldb journal 
bibliography balazinska balakrishnan madden stonebraker 
fault tolerance distributed stream processing system 
proc 
acm sigmod int 
conf 
management data pages 
balazinska balakrishnan stonebraker 
load management high availability medusa distributed stream processing engine 
proc 
acm sigmod int 
conf 
management data pages 
belady 
study replacement algorithms virtual storage computers 
ibm syst 

ben david gehrke kifer 
detecting change data streams 
proc 
int 
conf 
large data bases vldb pages 
bernstein hadzilacos goodman 
concurrency control recovery database systems 
addison wesley 
berthold schmidt lehner 
hamann 
integrated resource management data stream systems 
proc 
acm symp 
applied comp 
sac pages 
babu dewitt widom 
content routing different plans different data 
proc 
int 
conf 
large data bases vldb pages 
larson tompa 
efficiently updating materialized views 
proc 
acm sigmod int 
conf 
management data pages 
bonnet gehrke seshadri 
sensor database systems 
proc 
int 
conf 
mobile data management mdm pages 
brown 
calendar queues fast priority queue implementation simulation event set problem 
communications acm oct 
singh 
swat hierarchical stream summarization 
proc 
int 
conf 
data eng 
icde pages 
singh 
unified framework monitoring data streams real time 
proc 
int 
conf 
data eng 
icde pages 
cai clutter pape han 
mining alarming incidents data streams 
proc 
acm sigmod int 
conf 
management data pages 
kr mer seeger 
stream processing production business software 
proc 
int 
conf 
data eng 
icde page 
kr mer seeger 
approach adaptive memory management data stream systems 
proc 
int 
conf 
data eng 
icde page 
carney cetintemel zdonik cherniack stonebraker 
operator scheduling data stream manager 
proc 
int 
conf 
large data bases vldb pages 
chai wang yu 
load shedding data stream mining 
proc 
int 
conf 
large data bases vldb pages 
sliding window query processing data streams chandrasekaran cooper deshpande franklin hellerstein hong krishnamurthy madden raman reiss shah :10.1.1.11.8839
telegraphcq continuous dataflow processing uncertain world 
proc 
biennial conf 
innovative data sys 
res 
cidr pages 
chandrasekaran franklin :10.1.1.1.4609
psoup system streaming queries streaming data 
vldb journal aug 
chandrasekaran franklin 
remembrance streams past overload sensitive management archived streams 
proc 
int 
conf 
large data bases vldb pages 
chen dewitt naughton 
design evaluation alternative selection placement strategies optimizing continuous queries 
proc 
int 
conf 
data eng 
icde pages 
chen dewitt tian wang :10.1.1.136.4253
niagaracq scalable continuous query system internet databases 
proc 
acm sigmod int 
conf 
management data pages 
cheng kao prabhakar kwan tu 
adaptive stream filters entity queries non value tolerance 
proc 
int 
conf 
large data bases vldb pages 
cherniack balakrishnan balazinska carney cetintemel xing zdonik 
scalable distributed stream processing 
proc 
biennial conf 
innovative data sys 
res 
cidr pages 
chomicki 
efficient checking temporal integrity constraints bounded history encoding 
acm trans 
database sys 
chomicki toman 
implementing temporal integrity constraints active dbms 
ieee trans 
knowledge data eng 
cohen kaplan 
spatially decaying aggregation network model algorithms 
proc 
acm sigmod int 
conf 
management data pages 
cohen strauss 
maintaining time decaying stream aggregates 
proc 
acm sigmod sigact sigart symp 
princ 
database sys 
pods pages 
cohen 
user defined aggregate functions bridging theory practice 
proc 
acm sigmod int 
conf 
management data pages 
cormode garofalakis 
sketching streams net distributed approximate query tracking 
proc 
int 
conf 
large data bases vldb pages 
cormode garofalakis muthukrishnan rastogi 
holistic aggregates networked world distributed tracking approximate quantiles 
proc 
acm sigmod int 
conf 
management data pages 
cormode johnson korn muthukrishnan spatscheck srivastava 
holistic udafs streaming speeds 
proc 
acm sigmod int 
conf 
management data pages 
bibliography cormode muthukrishnan 
improved data stream summary count min sketch applications 
proc 
latin american theoretical informatics latin pages 
cormode muthukrishnan zhuang 
different distributed continuous monitoring duplicate resilient aggregates data streams 
proc 
int 
conf 
data eng 
icde page 
cortes fisher pregibon rogers smith 
hancock language extracting signatures data streams 
proc 
acm sigkdd int 
conf 
knowledge disc 
data mining pages 
cranor johnson spatscheck shkapenyuk 
gigascope high performance network monitoring sql interface 
proc 
acm sigmod int 
conf 
management data pages 
das ganguly garofalakis rastogi 
distributed set expression cardinality estimation 
proc 
int 
conf 
large data bases vldb pages 
das gehrke 
semantic approximation data stream joins 
ieee trans 
knowledge data eng 
krishnan venkatasubramanian yi 
information theoretic approach detecting changes multi dimensional data streams 
proc 
symp 
interface statistics computing science applications 
datar gionis indyk motwani :10.1.1.24.7941
maintaining stream statistics sliding windows 
proc 
acm siam symp 
discrete alg 
soda pages 
salem 
lazy database replication snapshot isolation 
proc 
int 
conf 
large data bases vldb 
demaine lopez ortiz munro 
frequency estimation internet packet streams limited space 
proc 
european symp 
algorithms esa pages 
demers gehrke hong white 
expressive publish subscribe systems 
proc 
int 
conf 
extending database technology edbt pages 
deng jia yang 
supporting efficient distributed top monitoring 
proc 
int 
conf 
advances web age inf 
management pages 
denny franklin 
predicate result range caching continuous queries 
proc 
acm sigmod int 
conf 
management data pages 
denny franklin 
operators expensive functions continuous queries 
proc 
int 
conf 
data eng 
icde page 
deshpande 
initial study overheads eddies 
acm sigmod record 
deshpande guestrin madden 
probabilistic models data management environments 
proc 
biennial conf 
innovative data sys 
res 
cidr pages 
deshpande hellerstein 
lifting burden history adaptive query processing 
proc 
int 
conf 
large data bases vldb pages 
sliding window query processing data streams ding mehta rundensteiner 
joining punctuated streams 
proc 
int 
conf 
extending database technology edbt pages 
ding 
evaluating window joins punctuated streams 
proc 
int 
conf 
information knowledge management cikm pages 

dittrich seeger taylor widmayer 
progressive merge join generic non blocking sort join algorithm 
proc 
int 
conf 
large data bases vldb pages 
dobra garofalakis gehrke rastogi 
processing complex aggregate queries data streams 
proc 
acm sigmod int 
conf 
management data pages 
dobra garofalakis gehrke rastogi 
sketch multi query processing data streams 
proc 
int 
conf 
extending database technology edbt pages 
douglis palmer richards tao tracey lin 
position short object lifetimes require delete optimized storage system 
proc 
acm sigops european workshop 
estan varghese 
new directions traffic measurement accounting 
proc 
int 
conf 
app tech arch prot 
comp 
communications sigcomm pages 
fabret 
jacobsen llirbat pereira ross shasha 
filtering algorithms implementation fast publish subscribe systems 
proc 
acm sigmod int 
conf 
management data pages 
faloutsos 
sensor data mining similarity search pattern analysis 
proc 
int 
conf 
large data bases vldb 
faloutsos jagadish 
tree indices skewed distributions 
proc 
int 
conf 
large data bases vldb pages 
flajolet martin 
probabilistic counting 
proc 
symp 
foundations comp 
sci 
focs pages 
gupta subramanian shankar sheng 
optimizing refresh set materialized views 
proc 
int 
conf 
large data bases vldb pages 
franklin jeffery krishnamurthy reiss rizvi wu cooper hong 
design considerations high fan systems approach 
proc 
biennial conf 
innovative data sys 
res 
cidr pages 
zaslavsky krishnaswamy 
mining data streams review 
acm sigmod record 
ganguly garofalakis rastogi 
processing data stream join aggregates skimmed sketches 
proc 
int 
conf 
extending database technology edbt pages 
ganti gehrke ramakrishnan 
demon mining monitoring evolving data 
ieee trans 
knowledge data eng 
garcia molina ullman widom 
database system implementation 
prentice hall 
bibliography garofalakis gehrke rastogi 
querying mining data streams get look 
proc 
acm sigmod int 
conf 
management data page 
liu 
quality aware distributed data delivery continuous query services 
proc 
acm sigmod int 
conf 
management data pages 

wu yu liu 
adaptive load shedding windowed stream joins 
proc 
int 
conf 
information knowledge management cikm pages 
aref elmagarmid 
exploiting predicate window semantics data streams 
acm sigmod record 
gibbons 
distinct sampling highly accurate answers distinct values queries event reports 
proc 
int 
conf 
large data bases vldb pages 
gibbons matias 
new sampling summary statistics improving approximate query answers 
proc 
acm sigmod int 
conf 
management data pages 
gibbons 
estimating simple functions union data streams 
proc 
acm symp 
parallel alg 
arch 
spaa pages 
gibbons 
distributed streams algorithms sliding windows 
proc 
acm symp 
parallel alg 
arch 
spaa pages 
gilbert kotidis muthukrishnan strauss 
surfing wavelets streams summaries approximate aggregate queries 
proc 
int 
conf 
large data bases vldb pages 
gilbert kotidis muthukrishnan strauss 
summarize universe dynamic maintenance quantiles 
proc 
int 
conf 
large data bases vldb pages 
zsu 
concurrency control sliding window queries data streams 
proc 
int 
conf 
extending database technology edbt pages 
demaine lopez ortiz munro 
identifying frequent items sliding windows line packet streams 
proc 
acm sigcomm internet measurement conf 
imc pages 
garg zsu 
indexing sliding windows line data streams 
proc 
int 
conf 
extending database technology edbt pages 
zsu 
issues data stream management 
acm sigmod record 
zsu 
processing sliding window multi joins continuous queries data streams 
proc 
int 
conf 
large data bases vldb pages 
zsu 
update pattern aware modeling processing continuous queries 
proc 
acm sigmod int 
conf 
management data pages 
zsu 
indexing time evolving data variable lifetimes 
proc 
int 
conf 
scientific statistical database management ssdbm pages 
sliding window query processing data streams gonzalez han li 
warehousing analyzing massive rfid data sets 
proc 
int 
conf 
data eng 
icde page 
paton 
adaptive query processing survey 
proc 
british nat 
conf 
databases pages 
gray bosworth layman pirahesh 
data cube relational aggregation operator generalizing group cross tab sub total 
proc 
int 
conf 
data eng 
icde pages 
greenwald khanna 
space efficient line computation quantile summaries 
proc 
acm sigmod int 
conf 
management data pages 
greenwald khanna 
power conserving computation order statistics sensor networks 
proc 
acm sigmod sigact sigart symp 
princ 
database sys 
pods pages 
guha mcgregor 
approximate quantiles order stream 
proc 
acm sigmod sigact sigart symp 
princ 
database sys 
pods pages 
guha shim 
offline data stream algorithms efficient computation synopsis structures 
proc 
int 
conf 
large data bases vldb page 
haas hellerstein 
ripple joins online aggregation 
proc 
acm sigmod int 
conf 
management data pages 
halevy 
answering queries views survey 
vldb journal 
aref elmagarmid 
stream window join tracking moving objects databases 
proc 
int 
conf 
scientific statistical database management ssdbm pages 
aref elmagarmid 
optimizing order execution continuous queries streamed sensor data 
proc 
int 
conf 
scientific statistical database management ssdbm pages 
aref franklin elmagarmid 
efficient execution sliding window queries data streams 
technical report csd tr purdue university 
franklin aref elmagarmid 
scheduling shared window joins data streams 
proc 
int 
conf 
large data bases vldb pages 
ali aref elmagarmid xiong 
nile query processing engine data streams 
proc 
int 
conf 
data eng 
icde page 
han xiao zhou wang huo hui 
load shedding window joins streams 
proc 
int 
conf 
advances web age inf 
management pages 
hanson huang 
scalable trigger processing 
proc 
int 
conf 
data eng 
icde pages 
harinarayan rajaraman ullman 
implementing data cubes efficiently 
proc 
acm sigmod int 
conf 
management data pages 
bibliography carey livny 
earliest deadline scheduling real time database systems 
proc 
ieee real time systems symp 
hellerstein haas wang 
online aggregation 
proc 
acm sigmod int 
conf 
management data pages 
hellerstein hong madden 
sensor spectrum technology trends requirements 
acm sigmod record dec 
hwang balazinska cetintemel stonebraker zdonik 
high availability algorithms distributed stream processing 
proc 
int 
conf 
data eng 
icde pages 

rank aware query processing optimization 
phd thesis purdue university 
jagadish mumick silberschatz 
view maintenance issues chronicle data model 
proc 
acm sigmod sigact sigart symp 
princ 
database sys 
pods pages 
jain chang 
wang 
adaptive stream resource management kalman filters 
proc 
acm sigmod int 
conf 
management data pages 
jain amini andrade king park selo 
design implementation evaluation linear road benchmark stream processing core 
proc 
acm sigmod int 
conf 
management data pages 
jeffery alonso franklin hong widom 
pipelined framework line cleaning sensor data streams 
proc 
int 
conf 
data eng 
icde page 
jensen locke tokuda 
time driven scheduling model real time operating systems 
proc 
ieee real time sytems symp pages 
jiang chakravarthy 
queueing analysis relational operators continuous data streams 
proc 
int 
conf 
information knowledge management cikm pages 
jiang chakravarthy 
scheduling strategies processing continuous queries streams 
proc 
british nat 
conf 
databases pages 
johnson muthukrishnan 
sampling algorithms stream operator 
proc 
acm sigmod int 
conf 
management data pages 
johnson muthukrishnan shkapenyuk spatscheck 
heartbeat mechanism application gigascope 
proc 
int 
conf 
large data bases vldb pages 
johnson muthukrishnan spatscheck srivastava 
streams security scalability 
proc 
th annual ifip conf 
data applications security lncs pages 
kabra dewitt 
efficient mid query re optimization sub optimal query execution plans 
proc 
acm sigmod int 
conf 
management data pages 
kang naughton 
evaluating window joins unbounded streams 
proc 
int 
conf 
data eng 
icde pages 
sliding window query processing data streams cormode 
communication efficient distributed monitoring threshold counts 
proc 
acm sigmod int 
conf 
management data pages 
kleinberg 
bursty hierarchical structure streams 
proc 
acm sigkdd int 
conf 
knowledge disc 
data mining pages 
kleinberg tardos 
algorithm design 
addison wesley 
korn muthukrishnan wu 
modeling skew data streams 
proc 
acm sigmod int 
conf 
management data pages 
koudas srivastava 
data stream query processing tutorial 
proc 
int 
conf 
large data bases vldb page 
kr mer seeger 
pipes public infrastructure processing exploring streams 
proc 
acm sigmod int 
conf 
management data pages 
kr mer seeger 
temporal foundation continuous queries data streams 
proc 
th int 
conf 
management data pages 
krishnamurthy franklin hellerstein jacobson 
case precision sharing 
proc 
int 
conf 
large data bases vldb pages 
krishnamurthy wu franklin 
fly sharing streamed aggregation 
proc 
acm sigmod int 
conf 
management data pages 

law wang zaniolo 
query languages data models database sequences data streams 
proc 
int 
conf 
large data bases vldb pages 
mehrotra 
capturing sensor generated time series quality guarantees 
proc 
int 
conf 
data eng 
icde pages 
lee leong si 
data stream processing system chunking 
proc 
int 
database eng 
app 
symp 
ideas pages 
lee ting 
simpler efficient deterministic scheme finding frequent items sliding windows 
proc 
acm sigmod sigact sigart symp 
princ 
database sys 
pods pages 
leland taqqu willinger wilson 
self similar nature ethernet traffic 
ieee acm trans 
networking 
lerner shasha 
query language ordered data optimization techniques experiments 
proc 
int 
conf 
large data bases vldb pages 
lerner shasha 
virtues challenges ad hoc streams querying finance 
ieee quarterly bulletin data engineering 
li chang bestavros 
characterizing exploiting locality data stream applications 
proc 
int 
conf 
data eng 
icde page 

li chen agrawal candan 

safety guarantee continuous join queries punctuated data streams 
proc 
int 
conf 
large data bases vldb 
bibliography li maier tufte tucker 
pane gain efficient evaluation sliding window aggregates data streams 
acm sigmod record 
li maier tufte tucker 
semantics evaluation techniques window aggregates data streams 
proc 
acm sigmod int 
conf 
management data pages 

lim 
lee 
lee 
whang 
song 
continuous query processing data streams duality data queries 
proc 
acm sigmod int 
conf 
management data pages 
lin keogh lonardi lankford nystrom 
visually mining monitoring massive time series 
proc 
acm sigkdd int 
conf 
knowledge disc 
data mining pages 
lin lu xu xu yu :10.1.1.89.6970
continuously maintaining quantile summaries elements data stream 
proc 
int 
conf 
data eng 
icde pages 
lin yuan wang lu 
stabbing sky efficient skyline computation sliding windows 
proc 
int 
conf 
data eng 
icde pages 
liu zhu rundensteiner 
dynamically adaptive distributed system processing complex continuous queries 
proc 
int 
conf 
large data bases vldb pages 
liu zhu rundensteiner 
run time operator state spilling memory intensive long running queries 
proc 
acm sigmod int 
conf 
management data pages 
liu lu han 
error adaptive time aware maintenance frequency counts data streams 
proc 
int 
conf 
advances web age inf 
management pages 
liu pu tang 
continual queries internet scale event driven information delivery 
ieee trans 
knowledge data eng 
muntz 
aspen stream processing environment 
proc 
parallel architectures languages europe volume ii parallel language pages 
luo wang zaniolo 
native extension sql mining data streams 
proc 
acm sigmod int 
conf 
management data pages 
luo naughton 
non blocking parallel spatial join algorithm 
proc 
int 
conf 
data eng 
icde pages 
ma li li 
stream operators querying data streams 
proc 
int 
conf 
advances web age inf 
management pages 
madden franklin 
stream architecture queries streaming sensor data 
proc 
int 
conf 
data eng 
icde pages 
madden franklin hellerstein hong 
tag tiny aggregation service ad hoc sensor networks 
proc 
symp 
operating systems design implementation osdi 
sliding window query processing data streams madden franklin hellerstein hong 
design query processor sensor networks 
proc 
acm sigmod int 
conf 
management data pages 
madden shah hellerstein raman :10.1.1.12.4794
continuously adaptive continuous queries streams 
proc 
acm sigmod int 
conf 
management data pages 
nath gibbons 
deltas efficient robust aggregation sensor network streams 
proc 
acm sigmod int 
conf 
management data pages 
shkapenyuk dhamdhere olston 
finding frequent items distributed data streams 
proc 
int 
conf 
data eng 
icde pages 
manku rajagopalan lindsay 
random sampling techniques space efficient online computation order statistics large datasets 
proc 
acm sigmod int 
conf 
management data pages 
manku motwani 
approximate frequency counts data streams 
proc 
int 
conf 
large data bases vldb pages 
agrawal el abbadi 
efficient computation frequent top elements data streams 
proc 
int 
conf 
database theory icdt pages 
lu aref 
hash merge join non blocking join algorithm producing fast early join results 
proc 
int 
conf 
data eng 
icde pages 
motwani widom arasu babcock babu datar manku olston rosenstein varma 
query processing approximation resource management data stream management system 
proc 
biennial conf 
innovative data sys 
res 
cidr pages 
papadias 
continuous monitoring top queries sliding windows 
proc 
acm sigmod int 
conf 
management data pages 
muthukrishnan 
data streams algorithms applications 
manuscript 
nath gibbons seshan anderson 
synopsis diffusion robust aggregation sensor networks 
proc 
acm conf 
embedded networked sensor sys 
sensys pages 
olston jiang widom 
adaptive filters continuous queries distributed data streams 
proc 
acm sigmod int 
conf 
management data pages 
ou yu yu wu yang deng 
tick scheduling deadline optimal task scheduling approach real time data stream systems 
proc 
int 
conf 
advances web age inf 
management pages 
keogh gunopulos 
online amnesic approximation streaming time series 
proc 
int 
conf 
data eng 
icde pages 
parker 
stream data analysis prolog 
mit press 
paton diaz 
active database systems 
acm computing surveys 

range efficient computation massive data streams 
proc 
int 
conf 
data eng 
icde pages 
bibliography paxson floyd :10.1.1.144.7995
wide area traffic failure poisson modeling 
ieee acm trans 
networking jun 
qiao agrawal el abbadi 
supporting sliding window queries continuous data streams 
proc 
int 
conf 
scientific statistical database management ssdbm pages 
ramakrishnan ranganathan beyer 
sorted relational query language 
proc 
int 
conf 
scientific statistical database management ssdbm pages 
raman deshpande hellerstein 
state modules adaptive query processing 
proc 
int 
conf 
data eng 
icde pages 
reiss hellerstein 
data triage adaptive architecture load shedding telegraphcq 
proc 
int 
conf 
data eng 
icde pages 
rizvi jeffery krishnamurthy franklin burkhart liang 
events edge 
proc 
acm sigmod int 
conf 
management data pages 
rundensteiner ding sutherland zhu mehta 
cape continuous query engine heterogeneous grained adaptivity 
proc 
int 
conf 
large data bases vldb pages 
adams sandler fuchs cherniack zdonik 
revision processing stream processing engine high level design 
proc 
int 
conf 
data eng 
icde page 
sadri zaniolo 
expressing optimizing sequence queries database systems 
acm trans 
database sys june 
salzberg 
comparison access methods time evolving data 
acm computing surveys june 
schmidt jensen 
expiration times data management 
proc 
int 
conf 
data eng 
icde page 
schmidt berthold 
deterministic querying data streams 
proc 
int 
conf 
large data bases vldb pages 
schmidt lehner 
robust real time query processing 
proc 
int 
conf 
large data bases vldb pages 
sellis 
multiple query optimization 
acm trans 
database sys 
seshadri livny ramakrishnan 
sequence query processing 
proc 
acm sigmod int 
conf 
management data pages 
seshadri livny ramakrishnan 
seq model sequence databases 
proc 
int 
conf 
data eng 
icde pages 
seshadri livny ramakrishnan 
design implementation sequence database system 
proc 
int 
conf 
large data bases vldb pages 
sliding window query processing data streams kumar cooper 
optimizing multiple queries distributed data stream systems 
proc 
ieee int 
workshop networking meets databases 
shah hellerstein brewer 
highly available fault tolerant parallel dataflows 
proc 
acm sigmod int 
conf 
management data pages 
shah hellerstein chandrasekaran franklin 
flux adaptive partitioning operator continuous query systems 
proc 
int 
conf 
data eng 
icde pages 
chrysanthis 
freshness aware scheduling continuous queries dynamic web 
proc 
int 
workshop web databases webdb pages 
schuster 
geometric approach monitoring threshold functions distributed data streams 
proc 
acm sigmod int 
conf 
management data pages 
shivakumar garc molina 
wave indices indexing evolving databases 
proc 
acm sigmod int 
conf 
management data pages 
shrivastava agrawal suri 
medians new aggregation techniques sensor networks 
proc 
acm conf 
embedded networked sensor sys 
sensys pages 
yang 
energy efficient monitoring extreme values sensor networks 
proc 
acm sigmod int 
conf 
management data 
srivastava dar jagadish levy 
answering queries aggregation views 
proc 
int 
conf 
large data bases vldb pages 
srivastava widom 
operator placement network stream query processing 
proc 
acm sigmod sigact sigart symp 
princ 
database sys 
pods pages 
srivastava widom 
flexible time management data stream systems 
proc 
acm sigmod sigact sigart symp 
princ 
database sys 
pods pages 
srivastava widom 
memory limited execution windowed stream joins 
proc 
int 
conf 
large data bases vldb pages 
stankovic ramamritham 
deadline scheduling real time systems edf related algorithms 
kluwer academic publishers 
stephens 
survey stream processing 
acta informatica 
stonebraker cetintemel zdonik 
requirements real time stream processing 
acm sigmod record 
subramanian leung zdonik 
aqua approach querying lists trees object oriented databases 
proc 
int 
conf 
data eng 
icde pages 
sullivan 
tribeca system managing large databases network traffic 
proc 
usenix annual technical conf 
bibliography tao papadias 
maintaining sliding window data streams 
ieee trans 
knowledge data eng 
tao papadias 
producing fast join results streams rate optimization 
proc 
acm sigmod int 
conf 
management data pages 
tatbul cetintemel zdonik cherniack stonebraker 
load shedding data stream manager 
proc 
int 
conf 
large data bases vldb pages 
tatbul zdonik 
dealing overload distributed stream processing systems 
proc 
ieee int 
workshop networking meets databases 
tatbul zdonik 
subset load shedding approach aggregation queries data streams 
proc 
int 
conf 
large data bases vldb 
terry goldberg nichols oki 
continuous queries append databases 
proc 
acm sigmod int 
conf 
management data pages 
tian dewitt 
tuple routing strategies distributed eddies 
proc 
int 
conf 
large data bases vldb pages 
tok 
efficient adaptive processing multiple continuous queries 
proc 
int 
conf 
extending database technology edbt pages 
scheuermann hinze 
evolving triggers dynamic environments 
proc 
int 
conf 
extending database technology edbt pages 
yao demers gehrke rajaraman 
multi query optimization sensor networks 
proc 
int 
conf 
distr 
comp 
sensor sys 
pages 

tu liu prabhakar yao 
load shedding stream databases control approach 
proc 
int 
conf 
large data bases vldb 
tucker maier sheard 
exploiting punctuation semantics continuous data streams 
ieee trans 
knowledge data eng 
urhan franklin 
xjoin reactively scheduled pipelined join operator 
ieee quarterly bulletin data engineering june 
urhan franklin 
dynamic pipeline scheduling improving interactive query performance 
proc 
int 
conf 
large data bases vldb pages 
urhan franklin 
cost query scrambling initial delays 
proc 
acm sigmod int 
conf 
management data pages 
naughton 
rate query optimization streaming information sources 
proc 
acm sigmod int 
conf 
management data pages 
naughton burger 
maximizing output rate multi join queries streaming information sources 
proc 
int 
conf 
large data bases vldb pages 

processing continuous queries unlimited data streams 
proc 
int 
conf 
database expert sys 
app 
dexa pages 
sliding window query processing data streams wang zaniolo luo 
atlas small complete sql extension data mining data streams 
proc 
int 
conf 
large data bases vldb pages 
wang rundensteiner ganguly 
state slice new paradigm optimization window stream queries 
proc 
int 
conf 
large data bases vldb 
wang li zhang guo 
processing sliding window join aggregate continuous queries data streams 
proc 
east european conf 
advances databases inf 
sys 
adbis pages 
weikum vossen 
transactional information systems 
theory algorithms practice concurrency control recovery 
morgan kauffman 

whang krishnamurthy 
query optimization memory resident domain relational calculus database system 
acm trans 
database sys 
widom ceri 
active database systems triggers rules advanced database processing 
morgan kaufmann 
wilschut apers 
dataflow query execution parallel main memory environment 
proc 
int 
conf 
parallel distr 
inf 
sys 
pdis pages 
wu rizvi 
high performance complex event processing streams 
proc 
acm sigmod int 
conf 
management data pages 

wu 
chen yu 
interval query indexing efficient stream processing 
proc 
int 
conf 
information knowledge management cikm pages 
wu yu yu ou yang gu 
deadline sensitive approach real time processing sliding windows 
proc 
int 
conf 
advances web age inf 
management pages 
xie yang chen 
joining caching stochastic streams 
proc 
acm sigmod int 
conf 
management data pages 
xing 
hwang cetintemel zdonik 
providing resiliency load variations distributed stream processing 
proc 
int 
conf 
large data bases vldb 
xing zdonik 
hwang 
dynamic load distribution stream processor 
proc 
int 
conf 
data eng 
icde pages 
xu lin zhou 
space efficient quantile summary constrained sliding windows data stream 
proc 
int 
conf 
advances web age inf 
management pages 
yao gehrke :10.1.1.12.1378
query processing sensor networks 
proc 
biennial conf 
innovative data sys 
res 
cidr pages 
yi yu yang xia chen 
efficient maintenance materialized top views 
proc 
int 
conf 
data eng 
icde pages 
zaniolo ceri faloutsos snodgrass subrahmanian zicari 
advanced database systems 
morgan kaufmann 
bibliography zhang li wang 
sliding window multi join algorithms distributed data streams 
proc 
int 
conf 
data eng 
icde page 
zhang li zhang wang guo 
dynamic adjustment sliding window data streams 
proc 
int 
conf 
advances web age inf 
management pages 
zhang koudas ooi srivastava 
multiple aggregations data streams 
proc 
acm sigmod int 
conf 
management data pages 
zhang shasha 
better burst detection 
proc 
int 
conf 
data eng 
icde page 
zhou yan yu zhou 
optimizing distributed multi way stream joins stream partitioning 
proc 
int 
conf 
database syst 
advanced app 
dasfaa 
zhu ravishankar 
scalable approach approximating aggregate queries intermittent streams 
proc 
int 
conf 
scientific statistical database management ssdbm pages 
zhu rundensteiner 
dynamic plan migration continuous queries data streams 
proc 
acm sigmod int 
conf 
management data pages 
zhu shasha 
statstream statistical monitoring thousands data streams real time 
proc 
int 
conf 
large data bases vldb pages 
zhu shasha 
efficient elastic burst detection data streams 
proc 
acm sigkdd int 
conf 
knowledge disc 
data mining pages 
zipf 
human behaviour principle effort 
addison wesley 
appendix proof theorem appendix presents proof theorem section asserts roundrobin partitioning produces sub indices sizes uniform created chronological partitioning 
recall notation chapter total number sub indices upper bound lifetimes data items interval consecutive index updates define number times index updated data items initially index expired 
enumerate insertion timestamp ts expiration timestamp exp ranges simplicity set exp exp ranges 
loss generality suppose range oldest range youngest 
furthermore assume sub index required span refresh intervals sub index store tuples particular ts range particular exp range difference chronological partitioning round robin partitioning 
consequently smallest value take case sub index spans time refresh intervals insertion expiration times 
notation assumptions chronologically partitioned index repeated may characterized follows 
stores tuples ts ranges stores tuples ts ranges stores tuples ts ranges stores tuples ts ranges exp ranges exp ranges exp ranges exp ranges similarly round robin partitioned index repeated may summarized follows 
stores tuples ts ranges exp ranges 
assume upper level lower level partitions proven optimal section 
assume distribution lifetime lengths uniform 
assume rate insertion index constant 
sliding window query processing data streams example doubly partitioned index showing update time bottom stores tuples ts ranges exp ranges stores tuples ts ranges exp ranges 
stores tuples ts ranges exp ranges define size sub index expected number tuples stores 
assume unit size corresponds number tuples ts range exp range due assumption uniform result generation rate uniform distribution tuple lifetimes range pairs contain number tuples 
instance number tuples ts exp assumed number tuples ts exp 
note expected number tuples entire index possible exp range ts possible exp ranges ts lemmas prove theorem 
lemma average variance sub index sizes chronological partition ing 
proof 
generalizing discussion chronologically partitioned index may summarized follows 
stores tuples ts exp ranges tuples ts exp unit 
tuples ts exp exp units results ts 
continuing units tuples ts total size appendix example round robin doubly partitioned index showing update time bottom stores tuples ts ranges exp ranges exp time ranges greater ts time ranges tuple lifetime larger maximum lifetime order reside sub index empty 
similarly empty 
sub index second insertion time partition stores tuples exp ranges tuples ts ts ranges exp exp units 
situation similar tuples ts values size stores tuples ts exp ranges ts exp ranges size calculation analogous size empty exp time ranges greater ts time ranges similar 
terms third insertion time partition similar analysis show size size empty 
continuing insertion time partition size size sliding window query processing data streams summarizing analysis initial sub index sizes chronologically partitioned index follows 
sub indices sizes remaining sub indices half size zero half size consider index updates 
update incur insertions 
incur deletions remaining sub indices change size 
procedure shown updates size ts range equivalent exp range size indices inserted grows zero ts ranges younger exp ranges size indices deleted shrinks zero exp ranges larger ts ranges 
updates process repeats exception incur insertions 
incur deletions remaining unchanged 
sub indices incur insertions size drop zero 
furthermore sub indices incur insertions empty grow size sub index begins size deleted change size 
continuing analysis repeating sequence inserted steps emerges sub indices evolve size way set indices inserted deleted changes 
particular sub indices sizes remaining sub indices half size zero half size update grow decrease obtain suffices add variance sub indices size change average possible sizes remaining sub indices 
recall entire gives index expected size mean sub index size ip lemma average variance sub index sizes round robin partitioning 

appendix proof 
generalizing discussion round robin index may summarized follows 
stores tuples ts exp ranges 
tuples ts exp unit 
tuples ts exp exp units 
continuing possible exp values units tuples ts 
total size 
stores tuples ts ranges exp ranges 
tuples ts exp meaning fact stored 
tuples ts exp unit 
tuples ts exp exp units 
continuing ts possible ts values units tuples ts 
total size 
analysis similar size terms second insertion time partition size sub indices size terms third insertion time partition size sub indices size continuing insertion time partition sub indices size summary round robin index begins sub indices having size remaining sub indices having size update accesses different set sub indices shown sub indices inserted grow size sub indices incur deletions shrink size size single index incurs insertions deletions change size 
round robin index goes repeating sequence states initial size distribution true size sub indices size remaining sub indices consequently average variance sub index sizes follows recall mean sub index size 
sliding window query processing data streams theorem theorem section average variance sub index sizes round robin partitioning lower average variance sub index sizes chronological partitioning 
proof 

lemma lemma partial derivatives respect setting zero shown positive values considered level index sub indices explained earlier 
difference average sub index variance chronological partitioning versus round robin partitioning positive 

