discov framework discovering objects video david liu chen carnegie mellon university electrical computer engineering department forbes ave pittsburgh pa usa cmu edu cmu edu presents probabilistic framework discovering objects video 
video switch different shots unknown objects leave enter scene multiple times background cluttered 
framework consists appearance model motion model 
appearance model exploits consistency object parts appearance frames 
maximally stable extremal regions observations model provide robustness object variations scale lighting viewpoint 
appearance model provides location scale estimates unknown objects compact probabilistic representation 
compact representation contains knowledge scene object level allowing augment motion information motion model 
framework applied wide range different videos object types provides basis higher level video content analysis tasks 
applications video object discovery video content analysis problems video segmentation threading demonstrate superior performance methods exploit global image statistics frequent itemset data mining techniques 
video object discovery task extracting unknown objects video 
video want ask object interest sequence providing system examples 
different object detection computer vision literature see example characteristics object interest learned labeled data 
object detection involves lot human labor labeling images putting bounding boxes object interest difficulty scaling multiple objects 
object interest sequence type object difficult train comprehensive object detector covers types objects 
state art multi class object detector recognition rate recognizing pre defined object categories requires human labeled images 
approach object discovery unsupervised nature 
labeled images needed training system examples specifying object interest 
high level intuition achieved follows video car appearing multiple frames able wheels windows smaller parts larger entity repeats different images 
scenario concept larger entity composed smaller parts emerges 
smaller parts constitute larger entity generic need semantic meanings wheels windows example 
approach works small objects low resolution video 
object interest single feature point background feature points 
system designed videos single object interest extracted 
consider limitation advantage 
videos multiple objects object main interest 
proposed method intended discover major object interest 
discovering objects video discov involves processes image level extracting salient patches robust pose scale lighting variations generic dealing different types objects 
salient patches serve candidate parts constitute larger entities 
video level constructing appearance motion models larger entities exploiting consistency multiple frames 
ii 
related approach video object discovery observe scene long time build color distribution model pixel 
unusual objects identified pixels observe substantial deviation long term color distribution models 
kind background modeling approaches suitable video surveillance static camera image sequence obtained moving camera pixel correspond fixed scene position accurately register image sequence build color distribution pixel 
methods exploit optical flow discover objects 
optical flow apparent motion pair images 
problem difficult lack constraints aperture problem insufficient sampling near occlusion boundaries 
optical flow computes local image gradients best suited successive pairs frames low frame rates large motions 
short duration flow field optical flow frame clustered providing initial estimates object positions frame 
frame frame optical flow fields concatenated obtain longer range correspondences providing information determine motion consistent direction time 
consistency useful rejecting distracting motions specularities water oscillation vegetation wind 
long range optical flow field refine field step avoid drifting mentioned 
optical flow provides dense short range motion field feature tracking distinctive textured patches provides long range sparse motion field 
correspondence distinctive feature patches successive frames grouped occurrences 
approach uses distinctive textured patches explicitly compute correspondences frames computationally expensive 
differs layer extraction methods frames video partitioned number regions pixels share apparent motion model 
contrast approach allows low frame rate case methods relying image registration register background frames 
approach compute affine transformation patches problem low frame rates 
multiple object detectors airplanes buildings people provide input data mining algorithm feature vector describing presence absence objects 
mentioned section state art class object detectors recognition rate requires huge amount training data type object recognition approaches inherent difficulties 
systems build specialized video object detectors labeled data train object detector track trajectory exploit prior knowledge color distribution target human skin color distribution 
require track initialization initial position target target appearance initialization 
approaches intended object discovery require prior knowledge appearance position objects 
mentioned earlier approach works small objects low resolution video object interest single feature point background feature points 
contrast methods exploit rich set textures foreground object 
spatial scan statistic applied detect clusters epidemiological brain imaging data 
challenge find sets points conform underlying model dense noisy set observations 
spatial data mining methods methods focus point patterns density points conveys information 
data different appearance features extracted different image patches density identity atomic unit plays role object discovery 
topic models applied object discovery images videos 
follow approach applications including video segmentation threading 
image domain appearance model spatial model patches 
temporal domain motion data association model tightly coupled appearance spatial model 
framework yields principled efficient object discovery method appearance learnt simultaneously motion completely unsupervised manner 
appearance model accounts appearance variations background clutter motion data association model accounts randomness presence absence features due appearance measurement noise 
features simple spatial features demonstrating generality system sophisticated spatial temporal features certainly 
section iii introduce discov framework 
start image representation uses generic region detectors descriptors 
introduce appearance motion models provide unsupervised method discovering object interest video sequences 
section iv experimental results applications video object discovery video segmentation threading 
iii 
discov framework appearance spatial modeling denote image frames dn define hidden variables zi indicating th mser frame dk originates object interest 
refer msers belong object interest background bg clutter 
zi hidden variables goal infer values 
define conditional probabilities mser follows di indicates frame di mser originates object interest di defined likewise 
wj indicates mser originated object interest appearance corresponding visual word wj wj defined likewise 
denote position th mser frame dk ri hidden variable zi mk 
index dropped avoid cluttering equations 
define image word position occurrence table di wj ri denoting number occurrences word wj position ri frame di di denotes number words frame di 
words di wj ri frame di word wj position ri di wj ri 
introduce spatial distributions 
describe object interest background clutter spatially distributed image 
dependence position frame allows object different locations scales frame 
allowing different locations scales different frames desirable provides basis translation scale invariance 
concept semantic shift algorithm 
section constrain object position follow motion model 
important distinction foreground topic identification step required correctly identify hidden variable corresponds object interest step unnecessary 
foreground object interest automatically identified due un symmetric nature distributions 
assume object interest located image coordinate horizontal vertical scale estimates related motion model detailed section 
spatial distribution object interest defined diagonal matrix elements related scale object 
values unknown estimated 
detail parameter estimation procedure section iii worth mentioning parameters appearance spatial motion model section iii estimated iterative manner matter models initialized 
regularization constant avoids numerical issues approaches zero 
spatial distribution probability mass function constant ensure mass adds 
achieved summing msers ri frame spatial distribution background clutter simply defined uniform distribution 
empirically distributions perform better reason background spatial distribution requires parameter tuning difficult data dependent 
probabilistic model combines appearance location scale motion information expressed joint probability distribution postulates conditional independence provides compact representation joint probability 
provides basis efficiently finding maximum likelihood estimates unknown appearance models detail section iii 
motion modeling motion modeling provides location scale estimates spatial distribution 
define state unknown position velocity object discovered video frame index 
assume constant velocity motion model plane state evolves fs state matrix process noise sequence white gaussian mean zero constant covariance matrix 
suppose time number mk observations 
observation ri position mser 
observation ri originates foreground object expressed ri hs wi output matrix observation noise sequence wi assumed white gaussian mean zero constant covariance matrix 
build motion model background clutter 
want establish relationship observations states 
know observation originated object interest background clutter data association problem 
probabilistic data association pda filter solves data association problem assigning observation association probability specifies observation deviates model prediction 
original pda filter association probabilities calculated deviation observations predicted states states consists position velocity appearance utilized 
posterior probability association probability 
posterior probability calculated follows naturally includes location information appearance information 
state estimate written mk si zi dk ri si updated state estimate conditioned event ri originated foreground object 
kalman filter follows si ri innovation observation prediction kalman gain 
state estimation equations pda filter 
estimate interquartile range msers weighted posterior probability 
implementation duplicate points image space posterior probability compute interquartile range points 
interquartile range provides robust scale estimate weighted standard deviation 
maximum likelihood parameter estimation distributions appearance model estimated expectation maximization em algorithm maximizes log likelihood dk wj ri log dk wj ri em algorithm consists steps step computes posterior probabilities hidden variables step maximizes expected complete data likelihood step zi dk wj ri zi dk wj zi ri zi dk step wj zi zi dk wj ri zi dk zi dk wj ri dk ri zi dk updated section iii dk wj ri normalization constants values functions valid probability mass functions 
see spatial distribution ri zi dk updated em iteration means temporal information enters em iteration influences appearance estimation 
initialization handle case object may disappear scene re enter scene re initialize motion model position object estimated go scene color histogram scene changes certain threshold 
implementation particularly important video sequences post edited camera view changes object interest objects 
distributions wj dk dk initialized randomly 
spatial distribution parameters initialized center frame scale equal half size frame 
state estimate initialized center frame zero velocity 
representation images visual words textons atomic units image representation 
various applications photometric stereo object recognition image retrieval discuss detail generate visual words 
find number patches generate visual words 
patches determined running maximally stable extremal regions mser operator 
examples shown 
msers parts image local contrast high 
operator general wide range different scenes objects commonly stereo matching object recognition image retrieval mentioned earlier 
operators see collection 
features extracted msers scale invariant feature transform sift yielding dimensional fig 

maximally stable extremal regions msers 
left position msers 
middle coverage msers 
right output discov showing discovered object regions 
local feature descriptor mser 
color information largely application dependent 
data mining task discover instances specific object category cars video color information color different different instances category 
hand data mining task discover single object instance color information provides discrimination objects video 
color information useful shape grayscale texture discriminative 
extract msers sift descriptors grayscale images patches features extracted color images easily 
dimensional sift descriptors collected images vector quantized means clustering 
resulting cluster centers form dictionary visual words wj 
mser represented closest visual word 
msers represented discrete visual words continuous sift descriptors 
note acquisition visual words require labeled data shows unsupervised nature system 
iv 
empirical study experiments conducted real world data sets validate framework 
video sequences downloaded youtube com resolution sampled frame second 
videos available author homepage amp ece cmu edu people david 
practical internet video analysis systems expected handle low frame rate videos order keep speed vast amount available online videos nowadays 
tried downsampling original videos various frame rates frame second retain content providing computational efficiency 
low frame rate poses higher difficulty system object motion large appearance changes significant 
duration videos range seconds shown table video segmentation experiment sec 
iv fraction frames containing object interest ranges videos represent variety different shooting styles 
average duration shot ranges frames videos bike 
videos contain large number shot transitions posing difficulty methods motion 
localization experiments sec 
iv included extra videos contain shot transitions demonstrate method works equally situation 
summary video sequences pose challenges object interest wild changes appearances including scale pose lighting variations background highly cluttered non stationary object leave re enter scene multiple times may occur due large camera motion post editing video sequence 
baseline methods briefly describe baseline methods 
baseline nm semantic shift algorithm 
object discovery method developed image collections 
apply video sequences treat video collection images 
motion information call baseline motion 
baseline nl probabilistic latent semantic analysis algorithm 
similar baseline nm object discovery method images 
appearance information location image patches call baseline location 
baseline freq frequent closed itemset mining data mining literature itemset refers set items application refers candidate set regions represent object interest 
frequent itemset itemset occurs certain number times corresponds object interest 
data mining algorithm closet discovers frequent closed itemset discovered frequent itemset exists superset equal frequency 
helps reducing final number itemsets considered 
closet algorithm requires minimum itemset frequency input parameter 
setting minimum frequency small result frequent closed itemsets correspond object interest 
start largest possible minimum frequency equal number frames gradually decrease frequent closed itemsets 
give best results 
baseline km means clustering image word cooccurrence matrix approach assigns feature vector frame feature vector histogram visual words 
reported perform worse baseline nl 
euclidean distance computing distance feature vectors 
baseline km means clustering color histogram approach assigns feature vector frame feature vector rgb color histogram pixels frame 
regular bins color channel concatenate histograms 
chi square distance 
give best results 
object oriented video segmentation consider video camera switching number scenes 
example test drive scene fig camera switches driver frontal view car side view 
cluster frames semantically meaningful groups 
classical temporal segmentation methods similarity frames assessed global image characteristics 
example pixels build color histogram frame distance measure chi square distance measure similarity histograms 
means clustering spectral clustering methods employed 
method suitable shot boundary detection camera switches shots color information provides indicator scene transition 
color information provide object level segmentation 
object interest occupies small part scene global color statistics dominated background clutter 
color provide knowledge frames separated different groups 
discov framework provides natural way objectoriented clustering able point exactly factor separates frames 
table compare discov baseline methods 
video sequence natural object interest pepsi peugeot sequences commercial advertisements object interests pepsi logo peugeot vehicle respectively benz peugeot sequences test drive videos featuring car object interests video naturally defined 
bike horse sequences localization experiment contain transitions object 
frame rate frame second motion object interest background fast making non trivial apply optical flow layer extraction methods discovering objects 
addition sequences frequently transition different shots 
average duration shot ranges frames relatively short compared video length 
demonstrates difficulty optical flow methods 
ground truth data labels presence absence object interest frame 
evaluate object discovery performance detection problem 
classification rates shown table discov ranks images di frames di baseline nm 
interpretation ranking images contains object interest 
ranking obtained report classification rate point false alarm rate equals false reject rate 
baseline nl baseline km baseline km clustering methods knowledge cluster corresponds background clutter cluster corresponds object interest 
compute classification rate clusters turn report result higher classification rate 
baseline freq assigns different number frequent closed itemsets frame rank frames frequent closed itemsets contains inside 
baseline km performs slightly worse baseline nl 
consistent report 
baseline nm similar performance baseline nl 
see global color information provides little discriminative ability baseline km performs worst 
due large color variations background clutter dominates object interest 
baseline freq lowest classification rate 
shows number frequent closed itemsets frame indicator presence object interest 
discov outperforms experiments 
peugeot sequence result discov worse baseline nm baseline nl shooting style object interest appears random locations fast shot transitions baseline methods model motion perform better 
discov leading performance weighted average classification rate weighting comes number frames 
km baseline sequence table video segmentation performance 
numbers parenthesis indicate number frames containing object interest 
detailed section iv 
bike benz pepsi peugeot km weighted average peugeot object oriented threading capability object oriented video segmentation suggests application called threading occurrences object linked 
threading different keyframe extraction 
aim keyframe extraction obtain set frames covers aspects video sequence frames need contain object interest 
aim object oriented threading obtain set frames includes object interest different keyframe extraction 
threading keyframe extraction useful application dependent better understand different video sequence trivial solution discov baseline nm baseline nl bike horse bike peugeot peugeot benz pepsi table ii localization performance 
detailed section iv 
tion techniques 
methods attempt cover temporal domain threading focuses object interest 
approach threading object oriented 
rank images contain object interest di section iv 
put top frames highest values candidate set 
frames visually similar redundant apply means clustering rgb color histograms features pick cluster highest value di resulting frames shown fig 

pepsi logo appears frames candidate keyframes contains pepsi logo 
likewise mercedes benz appears frames 
candidate keyframes correspond th th th th th frame benz video th nd th th th frame pepsi video showing little temporal redundancy frames sampled frame second 
object interest localization order see discovered objects truly correspond object interest evaluate localization performance 
ground truth data provides bounding box object interest frame frames contain object interest evaluated 
object discovery algorithm assigns mser object background label 
mser center position 
average position covariance object msers provides rough estimate object position scale shape 
hit estimated position scale matches ground truth bounding box certain threshold 
reported numbers shown percentage hit rates averaged video sequence 
noted occasionally background clutter assigned object label outliers move average position object msers outside bounding box showing lower hit rates 
results shown table ii 
trivial solution naive algorithm return center frame position estimate object interest 
larger objects covering center position trivial solution provides sense difficulty video sequence 
numbers percentages ratios hit rate algorithm trivial solution 
larger better 
seen discov clearly outperforms baseline nm baseline nl 
computation speed computation time discov frame video sequence seconds mser extraction seconds running em algorithm 
em algorithm written matlab intentionally optimized speed 
video data mining object oriented nature approach provides promising new directions video content analysis 
discov provides rough position estimate object interest 
keyframe extraction video segmentation suffice areas high quality editing interest obtain clearer contour segmentation image pixels 
require sophisticated feature detectors addition msers 
investigating applications spatial data mining tasks traditionally density feature points considered discov able handle atomic units different appearances different identities 
vi 
supported taiwan merit scholarship tms arda program 
schneiderman kanade object detection statistics parts international journal computer vision vol 
pp 

darrell pyramid match kernel discriminative classification sets image features ieee intl 
conf 
computer vision pp 

stauffer grimson learning patterns activity real time tracking ieee trans 
pattern anal 
mach 
intell vol 
pp 

elgammal harwood davis background foreground modeling non parametric kernel density estimation visual surveillance proceedings ieee vol 
pp 

mittal paragios motion background subtraction adaptive kernel density estimation proc 
ieee conf 
computer vision pattern recognition pp 

sand teller particle video long range motion estimation point trajectories proc 
ieee conf 
computer vision pattern recognition pp 

pan 
ngo moving object detection association selection home videos ieee trans 
multimedia vol 
pp 

wixson detecting salient motion accumulating flow ieee trans 
pattern anal 
mach 
intell vol 
pp 

collins unsupervised learning object features video sequences proc 
ieee conf 
computer vision pattern recognition pp 

irani anandan unified approach moving object detection scenes ieee trans 
pattern analysis machine intelligence vol 
pp 

ke kanade robust subspace clustering combined metric svd algorithm proc 
ieee conf 
computer vision pattern recognition pp 

xie 
chang pattern mining visual concept streams proc 
ieee intl 
conf 
multimedia expo pp 

xie 
chang smith visual event detection multi dimensional concept dynamics proc 
ieee intl 
conf 
multimedia expo pp 

tekalp temporal video segmentation unsupervised clustering semantic object tracking journal electronic imaging vol 
pp 

efficient fully unsupervised video object segmentation scheme adaptive neural network classifier architecture ieee trans 
neural networks vol 
pp 

comaniciu ramesh meer real time tracking nonrigid objects mean shift proc 
ieee conf 
computer vision pattern recognition pp 

zisserman video google text retrieval approach object matching videos proc 
ieee intl 
conf 
computer vision pp 

jojic locus learning object classes unsupervised segmentation proc 
ieee intl 
conf 
computer vision pp 

zisserman video data mining configurations viewpoint invariant regions proc 
ieee conf 
computer vision pattern recognition pp 

forsyth barnard building models animals video ieee trans 
pattern analysis machine intelligence vol 
pp 

neill moore detecting significant multidimensional spatial clusters proc 
advances neural information processing systems pp 

moore connolly variable kd tree algorithms spatial pattern search discovery proc 
advances neural information processing systems pp 

cressie statistics spatial data wiley 
hofmann unsupervised learning probabilistic latent semantic analysis machine learning vol 
pp 

russell efros zisserman freeman discovering objects location images proc 
ieee intl 
conf 
computer vision pp 


perez tuytelaars van gool modeling scenes local descriptors latent aspects proc 
ieee intl 
conf 
computer vision pp 

fergus fei fei perona zisserman learning object categories google image search proc 
ieee intl 
conf 
computer vision pp 

liu chen semantic shift unsupervised object detection proc 
ieee cvpr workshop patches pp 

liu chen topic motion model unsupervised video object discovery proc 
ieee conf 
computer vision pattern recognition pp 

wang fei fei unsupervised learning human action categories spatial temporal words proc 
british machine vision conference pp 

dollar cottrell belongie behavior recognition sparse spatio temporal features proc 
iccv workshop visual surveillance performance evaluation tracking surveillance pp 

lindeberg space time interest points proc 
ieee intl 
conf 
computer vision pp 

bar shalom fortmann tracking data association academic press 
peter 
huber robust statistics wiley 
dempster laird rubin maximum likelihood incomplete data em algorithm journal royal statistical society vol 
pp 

tan lin quan resolution enhanced photometric stereo proc 
european conf 
computer vision pp 

leung texton correlation recognition proc 
european conf 
computer vision pp 

matas urban robust wide baseline stereo maximally stable extremal regions proc 
british machine vision conference pp 

www robots ox ac uk research affine 
lowe distinctive image features scale invariant keypoints intl 
journal computer vision vol 
pp 

hebert extracting scale illuminant invariant regions color proc 
british machine vision conference pp 

fig 

samples video sequences youtube com 
top rows samples benz sequence 
bottom rows samples pepsi sequence 
images displayed left right 
fig 

results object oriented threading section iv 
frame top row contains black mercedes vehicle bottom row frame contains pepsi logo 
provides object oriented overview video sequence different way traditional keyframe extraction 
duda hart stork pattern classification nd ed wiley 
wang han pei closet searching best strategies mining frequent closed itemsets proc 
int 
conf 
knowledge discovery data mining pp 

zhao wang bhat improving color video shot detection proc 
ieee intl 
conf 
multimedia computing systems pp 

ma zhang video snapshot bird view video sequence proc 
intl 
multimedia modelling conf pp 

