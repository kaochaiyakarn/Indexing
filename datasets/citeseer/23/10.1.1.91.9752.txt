robot tool behavior developmental approach autonomous tool dissertation academic faculty alexander partial fulfillment requirements degree doctor philosophy computer science college computing georgia institute technology august copyright alexander robot tool behavior developmental approach autonomous tool approved ronald arkin advisor college computing georgia institute technology aaron bobick college computing georgia institute technology tucker balch college computing georgia institute technology charles isbell college computing georgia institute technology harvey mechanical engineering georgia institute technology date approved june late grandfather carpenter taught tools workshop child 
wanted architect 
hope distant second list 
iii preface fortunate stumble topic autonomous tool robots tion 
joined robotics lab georgia tech began look dissertation topic 
years reading robotics literature goal mind 
enjoyed reading read felt dissertation topics taken 
started reading books fields science hope finding inspiration 
years reading paid thomas power book entitled play exploration children animals angry borrowing book library children playing toys picture front cover showed 
decided browse pages 
pages contained tables compared known object exploration strategies animals humans 
book contained reprint benjamin beck taxonomy tool modes animals see table 
immediately struck problem autonomous tool addressed robotics 
minutes decided abandon research ideas start working new direction 
read new topic liked 
read harder address enormous topic 
interested developmental aspect tool 
biggest challenges focus ideas creating defined developmental trajectory robot take order learn tools autonomously topic dissertation 
iv main reasons picked robotics area specialization inherently multi disciplinary 
expected research take journey different disciplines ethology anthropology neu psychophysics developmental psychology computer graphics computer vision dynamics course robotics 
ultimately satisfying experience admit feel way 
people acknowledge support years graduate student 
members dissertation committee ron arkin aaron bobick tucker balch charles isbell harvey 
advisor ron arkin deserves special seemingly infinite patience tested occasions 
understood importance problem picked dissertation gave unlimited academic freedom pursue 
time kept toes asking new experimental results conference papers forthcoming 
appreciated ron dependability impressed time management skills 
knew find office am day came back sabbatical 
aaron bobick mentor supporter 
discussions step ahead challenged tried push research directions compelling demonstration potential 
enjoyed classes learned lot takes teacher 
tucker balch partially responsible coming atlanta 
got know came people took time reply long mail questions ph program robotics georgia tech 
tucker mobile robotics lab tech advice lab related issues invaluable charles isbell volunteered dissertation committee liked topic 
really enjoyed discussions machine learning applications robotics 
harvey professor long career student tried messy handwriting 
handed back midterm exam pencil eraser attached 
nice gesture come late improve handwriting surely learned lot robot control dynamics class 
knowledge came handy programming dynamics robot simulator 
chris atkeson sven koenig served qualifying exam committee 
sven served dissertation proposal committee 
georgia tech moved carnegie mellon usc respectively conversations 
funding agencies sponsors paid graduate student salary 
yamaha motor sponsored project graduate student research project belief robotics field want 
humanoids research group honda tokyo japan sponsored second research project 
april fortunate people world see live demo humanoid robot 
hand experience believer day world inhabited robots walking working 
contribution bring closer vision 
worked darpa funded projects tactical mobile robotics tmr mobile autonomous robot software mars mobile autonomous robot software vision mars 
am confident experiences life match excitement large scale darpa demo 
fortunate take part demos rockville maryland fort georgia 
fellow graduate students mobile robotics lab endo kira alan wagner patrick ulam eric matt pow eres michael ranganathan 
long hours lab cold mornings darpa demo days enjoyable 
fall opportunity pleasure teaching graduate class developmental robotics 
dissertation finished vi class lot coherent readable think class 
say know explain classroom 
students graduate class adam adrian allen bradley dae ki jacob jesse jie john kevin lou matthew matthew michael ryan tyler stimulating class discussions insightful answers open questions developmental robotics homework assignments 
chair computer science department iowa state university carl chang giving opportunity teach class 
isu colleague honavar encouraged teach new experimental class robotics class 
due colleagues virtual reality applications center iowa state university jim oliver derrick eliot 
provided perfect working conditions start career gave breathing room finish dissertation 
gvu center georgia tech national science dation nsf american association artificial intelligence aaai awarding travel allowed attend academic conferences area 
bulgarian branch open society foundation paid airplane ticket united states years undergraduate education american university bulgaria deeply appreciated 
bulgarian friends tech ivan technical help encouragement years 
mother sisters believing abilities encouraging pursue dreams 
certainly happy going graduate school miles away home knew best thing try late father live see america 
proud daniela 
knows go get point 
love support kept going years 
vii table contents dedication 
iii preface 
iv 
list tables 
xii list figures 
xiv summary 

tool animals robots 
research questions 
contributions dissertation 
overview 
ii related 
tool 
object exploration 
modes tool 
animal tool 
origins tool behaviors 
ethological viewpoint 
anthropological viewpoint 
psychological influences 
piaget 
gibson 
ai robotics 
tool modeling 
tool recognition 
tool application 
viii iii developmental approach autonomous tool robots 
verification principle 
principle embodiment 
principle subjectivity 
sensorimotor limitations 
experiential limitations 
principle grounding 
principle gradual exploration 
developmental sequence autonomous tool 
summary 
iv evaluation platforms 
dynamics robot simulator 
mobile robot manipulator 
self detection robots 

related 
self detection humans 
self detection animals 
self detection robots 
problem statement 
methodology 
detecting visual features 
motor babbling 
visual movement detection 
learning efferent afferent delay 
experiments single robot 
experiments single robot static background features experiments robots uncorrelated movements 
experiments robots mimicking movements 
ix self versus discrimination 
experiments single robot 
experiments single robot static background features experiments robots uncorrelated movements 
experiments robots mimicking movements 
self detection tv monitor 
chapter summary 
vi extendable robot body schema 

related 
related neuroscience 
related robotics 
self organizing body schema bos model 
properties representation 
achieving goal directed movements 
identifying body frames 
problem statement 
methodology 
experimental results 
nested rbs representation 
behavioral specification nested rbs 
extending robot body schema 
example extension triggered tool 
example extension triggered video image 
achieving video guided behaviors 
similar experiments animals 
experimental setup 
calculating similarity transformation 
experimental results 
chapter summary 
vii learning affordances tools 

affordances exploratory behaviors 
behavior grounded tool representation 
robots tools tasks 
theoretical formulation 
experimental setup 
exploratory behaviors 
grasping behavior 
observation vector 
learning trials 
learned 
querying affordance table 
testing trials 
extension reach 
adaptation tool breaks 
discussion behavioral outcomes geometric shapes tools chapter summary 
viii 
self detection robots 
extendable body schema model robots 
learning tool affordances 

bibliography 
xi list tables types object manipulation behaviors identified primates multi species studies 
power 
postulated links knowledge objects exploratory procedures may gain knowledge 
power 
modes tool animals 
indicates mode observed members specific group 
beck 
categories technology identified campbell 
experimental conditions described subsections 
mean efferent afferent delay dataset dataset estimated different methods 
estimates mean standard deviation delay dataset background markers 
estimates mean standard deviation delay dataset robots 
estimates mean standard deviation delay mimicking dataset robots 
experimental conditions described subsections 
values necessity sufficiency indexes trial 
classification marker shown column 
values necessity sufficiency indexes trial 
markers classified correctly self 
values necessity sufficiency indexes trial 
markers classified correctly self case 
body icons table 
row table represents body icon consists fixed estimates kinematic sensory vectors associated specific body pose 
sample body icons table robot shown row table represents kinematic visual vectors specific robot pose 
visual vectors expressed coordinate system centered rotational joint robot 
sample movement coincidence matrix 
entry ci represents counter indicating times feature fi feature fj observed start moving time interval 
matrix symmetric 
xii matrix derived matrix shown table dividing entry value stored diagonal entry row 
values described text 
matrix longer symmetric 
highlights show pairs markers grouped start movement coincidences 
correspond rigid bodies robot shoulder arm wrist 
highlights show pairs markers grouped movement coincidences 
correspond rigid bodies robot shoulder arm wrist 
pairs markers identified start movement coincidences robots uncorrelated movements see section 
pairs markers correspond rigid bodies robots 
pairs markers identified movement coincidences robots uncorrelated movements see section 
pairs markers correspond rigid bodies robots 
body icons table wrist 
row table represents observed joint sensory vectors specific wrist pose observed positions wrist markers calculated arm frame coordinates 
start movement coincidence results short sequence robot waves stick tool see 
entries highlighted green show stick markers start move time wrist markers 
shoulder robot move short sequence markers grouped 
arm markers grouped movements 
movement coincidence results short sequence robot waves stick tool see 
results similar ones shown table 
mapping body frames tv frames start movement coincidence results tv sequence 
highlighted areas show body markers tv markers grouped 
yellow tv marker matched real markers position detection noise 
results corrected marker visibility 
similar results obtained tv sequences 
transformation parameters normal test case 
transformation parameters rotation test case 
transformation parameters zoomed test case 
xiii list figures experiments performed hler 
tools boxes sticks cases randomly placed environment 
chimpanzees learn arrange get bananas 
experiment designed test chimpanzees appreciate hook affordance tool 
task bring platforms reach tools get banana 
see text details 
povinelli 

tube problem described 
peanut placed inside transparent plastic tube 
get lure monkey stick push tube 
test tools monkeys training straight stick 
see text details 
trap tube problem described stick inserted affects final outcome 
inverted trap tube problem stick inserted affect final outcome 
progression stone tool technology 
sophistication design number operations needed manufacture tool increase technology improves 
left right hand axes homo scraping tool times stone knife people modern type 
campbell 
computational aspects tool published robotics ai literature divided main categories 
tool models representations capture shape functionality tool 
additional representations data structures necessary perform mapping shape functionality 
tool recognition approaches classified type recognition algorithms type sensing modality perceive tool 
robotic tool application classified criteria shown 
semantic network representation hammer 
connell brady 
object functionality representation rivlin 

screen snapshots simulated robots different stages research 
joint robot gripper nomad robot simulation version crs mobile manipulator described section 
joint configuration crs arm 

xiv joint limits crs manipulator 

mobile manipulator tools experiments 
efferent afferent delay defined time interval start motor command efferent signal detection visual movement afferent signal 
goal robot learn characteristic delay called perfect contingency self observation data 
self versus discrimination 
robot learned delay value classify visual features detect self feature blue classified self starts move expected efferent afferent delay plus minus tolerance shown brown region 
features classified start move late feature soon feature motor command issued 
experimental setup experiments described chapter 
shows positions colors body markers 
marker assigned number refer marker text figures follow 
left right markers colors dark orange dark red dark green dark blue yellow light green 
color segmentation results frame shown 
robot poses selected motor babbling procedure 
color segmentation results robot poses shown 
average marker movement consecutive frames robot moving 
results pixels frame body markers 
average marker movement consecutive frames robot moving 
words shows position detection noise body markers static 
results pixels frame 
frames test sequence robot moving object 
histogram measured efferent afferent delays dataset 
histogram measured efferent afferent delays dataset 
histogram measured efferent afferent delays dataset 
histogram shown bins histogram updated motor command 
earliest detected movement motor command 
histogram measured efferent afferent delays dataset 
histogram shown bins histogram updated motor command 
earliest detected movement motor command 
xv average efferent afferent delay corresponding standard deviation body markers calculated dataset 
average efferent afferent delay corresponding standard deviation body markers calculated dataset 
frames form test sequence static background markers 
histogram measured efferent afferent delays robot static background markers see 
bin corresponds th second 
due false positive movements detected background markers bins histogram values 
see text details 
frames test sequence robots movements robots uncorrelated 
robot controlled separate motor babbling routine 
robot left trying estimate efferent afferent delay 
histogram measured delays motor commands observed visual movements test sequence robots movements uncorrelated see 
contributions bins histogram shown movements second robot 
histogram shows movements second robot occur possible times motor command robot 
drop seconds due fact robot performs motor command approximately seconds 
subsequent movements second robot second interval matched motor command robot 
frames test sequence robots robot right mimics robot left 
mimicking delay frames seconds histogram measured delays motor commands observed visual movements mimicking test sequence robots see 
left peak produced movements body markers robot 
right peak produced movements body markers second mimicking robot 
shows calculated values necessity ni sufficiency si indexes visual features 
motor commands feature observed move twice movements contingent robot motor commands 
feature necessity sufficiency index 
movements feature contingent motor commands movements temporally contingent 
feature equal movements contingent robot motor commands 
shows value sufficiency index calculated time body markers 
index value markers threshold 
values calculated dataset 
xvi shows value sufficiency index calculated time body markers 
index value markers threshold 
values calculated dataset 
value necessity index calculated time body markers dataset 
calculation differentiate type motor command performed 
markers classified self index values threshold 
solution problem shown see text details 
value necessity index calculated time body markers dataset 
calculation differentiate type motor command performed 
markers classified self index values threshold 
solution problem shown see text details 
figures shows values necessity index body markers dataset 
shows lines correspond possible types motor commands 

considered classification self marker necessity index motor command trial 
markers classified self dataset 
shows values necessity index body markers dataset 
shows lines correspond possible types motor commands 

considered classification self marker necessity index motor command trial 
markers classified self dataset 
sufficiency index body markers 
markers index value threshold 
true necessity indexes shown 
body markers classified self 
sufficiency index static background markers 
markers index value threshold 
true necessity indexes shown 
background markers classified 
necessity index body markers 
shows lines correspond possible types motor commands 

considered classification self marker necessity index motor command trial 
true body markers shown 
correctly classified self 
xvii necessity index background markers 
shows lines correspond possible motor commands 

considered classification self marker necessity index motor command trial 
true background markers shown 
correctly classified 
shows sufficiency indexes body markers robot left robot 
expected values close threshold 
true necessity indexes shown 
markers robot classified self 
shows sufficiency indexes body markers second robot right robot 
expected values close threshold 
true necessity indexes shown 
markers second robot classified 
body markers robot 
shows lines correspond possible types motor commands 

considered classification self marker necessity index motor command trial 
true body markers shown 
correctly classified self case 
necessity index necessity index body markers second robot 
shows lines correspond possible types motor commands 

considered classification self marker necessity index motor command trial 
true body markers second robot shown 
correctly classified case 
shows sufficiency indexes calculated time body markers robot mimicking dataset 
expected values close threshold 
true necessity indexes shown 
markers robot classified self 
shows sufficiency indexes calculated time body markers second robot mimicking dataset 
expected values close threshold 
true necessity indexes shown 
markers robot classified 
xviii necessity index body markers 
shows lines correspond possible types motor commands 

considered classification self marker necessity index motor command trial 
true body markers shown 
correctly classified self 
necessity index body markers 
shows lines correspond possible types motor commands 

considered classification self marker necessity index motor command trial 
true body markers second robot shown 
correctly classified case 
frames tv sequence 
tv image shows real time movements robot captured camera different robot camera 
frames tv sequence body markers visible tv image due limited size tv screen 
sufficiency indexes calculated time tv markers 
results calculated visibility markers account 
sufficiency indexes calculated time tv markers 
results calculated visibility markers account 
necessity indexes calculated time tv markers 
results calculated visibility markers account 
necessity indexes calculated time tv markers 
results calculated visibility markers account 
tv markers 
shows lines correspond possible types motor commands 

considered classification self marker trial necessity index motor command graphs calculated visibility tv markers account 
values necessity index joint robot example 
robot body markers joint angles 
coordinates body body markers visual space vectors 
motor vector robot configuration shown 
body poses robot shown 
observed positions red body marker observed positions green body marker 
sensory vectors vi xix shows joint vectors correspond sensory vectors shown 
point represents qi joint vectors 
robot poses selected motor babbling procedure 
plots show sensory components body icons learned single run motor babbling procedure 
plot shows observed positions single body marker 
coordinates point plots represent observed centroid largest blob color 
size camera image 
flow chart diagram approximating sensory vector vk joint vector formula 
notation variables represent stored kinematic sensory components body icons ng normalized gaussian function formula compute activation value ui th body icon stand summation multiplication respectively 
shows magnitude direction approximation errors sensor vectors obtained formula 
gray points represent sensory components body icons 
errors represented arrows 
base arrow indicates true position sensory vector query joint vector calculated forward kinematics 
tip arrow represents approximated position calculated formula 
joint robot example 
goal move tip second limb body marker goal region 
calculation potential field 
body icons calculate distance 
body icon assign scalar value inversely proportional squared distance space point indexed final potential field shown resulting potential field goal configuration shown surface shows log plot approximated field dots show true positions discrete samples 
corresponding gradient vector field approximated formula vector magnitudes scale arrows rescaled uniform length order show direction entire vector field 
methodology identifying body frames detecting temporal coincidences movements different features 
shows example observed movement patterns visual features 
feature red feature green start move short interval time indicated shaded region 
start movement third feature blue correlated start movement features 
xx shows different body frames shoulder frame xs ys formed markers arm frame xa ya formed markers wrist frame xw yw formed markers 
frames constructed robot body markers markers clustered movement patterns 
table table show clustering results form frames 
shows observed positions green body marker coordinates expressed arm body frame xa ya camera centric frame shown circular pattern clearly shows possible positions wrist relative arm 
finite state automaton fsa describing grasping behavior 
states fsa linked perceptual triggers determine robot switch state 
example pre reach behavior progress 
purple spheres represent sensory components yellow marker body icons 
highly activated components colored cyan clustered target grasp point stick 
example orient wrist behavior progress 
arm positioned grasp point wrist robot moved relative arm frame 
green spheres show possible positions light green marker relative arm frame 
red spheres correspond wrist positions highly activated body icons 
example lower arm behavior progress 
behavior controls positions yellow marker light green marker 
result arm lowered grasp point wrist rotated remains perpendicular table 
positions body markers controlled simultaneously different body frames separate sets body icons 
frames short sequence minutes robot waves stick tool 
stick object color markers detected robot 
color segmentation results robot poses shown 
visual representation matching markers start movement coincidence results table 
shows experimental setup iriki 

setup consists tv monitor displays real time images captured camera 
opaque panel prevents monkey observing movements hands directly 
tv image guide reaching behaviors order grasp food item 
initial training phase transparent window located close eye level monkey left open observe movements hands directly tv monitor 
iriki 

xxi experimental setup menzel 

experimental setup robot experiments described section 
field view robot camera sony evi setup shown robot sees testing experiments described 
shows visual components vi corresponding blue body marker see body icons 
shows views robot camera experimental conditions 
image robot tv approximately size real robot rotated negative scaled zoomed factor 
actual experiments robot see body show 
shows robot sees experiments test conditions 
left half frame see digitally erased zeroed processed 
images show incentive object pink square robot required grasp observing position directly 
robot tv image guide grasping behaviors 
shows extended positions body icons visual components blue wrist marker extension rbs test conditions 
comparing obvious visual components body icons translated rotated translated scaled rotated translated relative original configuration 
furthermore new positions coincide positions blue marker observed tv 
extended positions longer tied camera coordinates may fall outside camera image 
robot tools experiments 
experimental setup 
color tracking raw camera image 
color tracking segmentation results 
pattern camera calibration 
results color segmentation applied calibration pattern 
flowchart diagram exploration procedure robot learn affordances specific tool tool applied attractor object contents sample row affordance table hook tool 
visualizing affordance table hook tool 
graphs show observed movements attractor object specific exploratory behavior performed multiple times 
start arrow corresponds position attractor wrist centered coordinates relative tool grasp point just prior start exploratory behavior 
arrow represents total distance direction movement attractor camera coordinates exploratory behavior 
flowchart diagram procedure robot solve tool tasks help behavior grounded affordance representation 
shows positions goal regions initial attractor positions extension reach experiments 
dashed lines indicate boundaries robot sphere reach holding tool 
hook missing right hook equivalent hook 
broken tool part adaptation initially robot tries move attractor goal missing right hook 
puck fails move expected robot reduces replication probability affordances associated part tool 
broken tool part ii solving task adapting modified affordances tool robot completes task intact left hook 
alternative way visualize affordance table hook tool 
graphs show information 
case shape tool detected robot shown 
black square shows position robot wrist position grasp point square green body marker 
view affordance table human readable shows better representation tool point view robot 
tool represented terms exploratory behaviors extracting shape tool 
robot holding stick tool 
robot holding stick tool 
color segmentation results stick tool 
color segmentation results stick tool 
learned affordance representation stick tool 
learned affordance representation stick tool 
frames sequence robot uses stick push puck away goal 
robot performs pushing movements stick alternating right left contact surface tool puck 
result puck takes zig zag path goal 
xxiii summary ability tools intelligence 
tool fundamental human life years 
tools extend reach amplify physical strength achieve tasks 
large number animals observed tools 
despite widespread tools animal world studies autonomous robotic tool rare 
dissertation examines problem autonomous tool robots point view developmental robotics 
main focus optimizing robotic solutions specific tool tasks designing algorithms representations robot develop tool abilities 
dissertation describes developmental sequence trajectory robot take order learn tools autonomously 
developmental sequence begins learning model robot body body consistent predictable part environment 
specifically robot learns perceptual features sociated body environment 
robot identify certain patterns exhibited body learn robot body schema model encode goal oriented behaviors 
robot body defined frame properties environmental objects explored relating body 
robot relate environmental objects learn certain actions object affect second object object tool 
main contributions dissertation broadly summarized follows demonstrates method autonomous self detection robots demonstrates model extendable robot body schema achieve goal oriented behaviors including video guided behaviors demonstrates behavior grounded method learning affordances tools solve tool tasks 
chapter tool animals robots ability tools intelligence 
tools tool fundamental human life years reed 
tools extend reach amplify physical strength transfer objects liquids achieve everyday tasks 
hand tools axe knife needle indispensable human society campbell 
hard imagine lives tools 
years believed humans tool species earth 
fact tool considered key features distinguished animals 
starting darwin belief challenged vigorously 
century substantial evidence collected clearly demon large number animals different groups tools wild beck 
birds example cactus pines probe bark trees reach lack 
egyptian stones break hard shells eggs goodall van 
chimpanzees stones crack nuts open sticks reach food hler dig holes attack predators van goodall 
fish ter grass blades ellis parker sticks open boxes ellis darwin 
sea stones open hard hall 
horses elephants sticks scratch bodies chevalier 
examples see beck van goodall detailed overview suggest ability tools adaptation mechanism organisms overcome limitations imposed anatomy 
despite widespread tools animal world studies autonomous robotic tool rare 
industrial robots tools tasks welding cutting painting operations carefully scripted human programmer 
robot hardware capabilities continue increase remarkable rate 
humanoid robots honda nasa sony feature motor capabilities similar humans hirai fujita 
near similar robots working side side humans homes offices hospitals outer space 
difficult imagine robots look act live physical environment useful capable innate human culture ability tools 
humanoid anatomy robots undoubtedly external objects variety tasks instance improve reach increase physical strength 
important problems addressed robotics community date 
dissertation investigates robots added list tool species 
specifically dissertation investigates computational representations algorithms facilitate development tool abilities autonomous robots 
experiments described dissertation inspired influenced long history tool experiments animals summarized section 
meth ods experiments described influenced psychological ethological neuroscience research 
claim dissertation attempts model human animal tool abilities encoded developed 
related fields science serves inspiration robotics research 
research questions research question autonomous robots effective tool agents 
problem autonomous tool robots may addressed multiple ways 
dissertation examines problem point view developmental robotics newest branches robotics weng 
focus dissertation optimizing robotic solutions specific tool tasks designing algorithms representations robot develop tool abilities 
order answer main research question investigates subsidiary questions 
subsidiary question robot identify sensory stimuli produced body produced external world 
major developmental theories proposed development requires ini tial investment task differentiating self external world watson 
words normal development requires self detection abilities self emerges actual experience predetermined watson 
evidence primate studies proficient tool species clear distinction tool bodies povinelli 
research question explores method autonomous self detection robots 
question evaluates results self detection method robot classify visual stimuli self subsidiary question robot learn sensorimotor model body morph model facilitate goal oriented tasks 
neuroscience literature tells brain keeps constantly updates model body called body schema 
model static extended external objects tools matter seconds 
example iriki 
shown body representation monkey extended monkey holding tool extension may important tool behaviors 
similar extension body occurs monkey observes hand tv monitor iriki 
extension body allows monkey perform video guided behaviors observe hand movements tv monitor 
research question investigates robot learn sensorimotor model body self observation data 
question investigates representation help robot achieve tool tasks video guided behaviors 
subsidiary question robot exploratory behaviors learn represent functional properties affordances tools 
related animal object exploration indicates animals stereotyped exploratory behaviors faced new object see section 
species animals tests include entire behavioral repertoire lorenz 
studies human subjects suggest internal model brain uses represent new tool encoded terms specific past experiences mah mussa ivaldi 
research question evaluates robot exploratory behaviors au learn functional properties affordances gibson tools 
question investigates robot behavior grounded affordance representa tion solve tool tasks 
contributions dissertation dissertation contributions field robotics demonstrates method autonomous self detection robots chapter 
demonstrates model extendable robot body schema chapter 
demonstrates method learning affordances tools robot chapter 
researchers robotics addressed issues manipulation grasp ing objects generally treated objects tools 
addressed problem holding object purposes transporting 
applications robot arms specialized instruments usually firmly attached effector qualify tools see definitions section 
furthermore control laws instruments usually provided human programmer cases learned human demonstration 
existing date robotics literature knowledge attempted investigate prin manner general problem handling external objects tools learning affordances 
dissertation step goal building intelligent robots adapt environment extending capabilities tools 
robots capable doing far useful robots today 
abilities autonomous tool especially useful humanoid robots operating human inhabited environments 
humanoid anatomy robots faced challenges humans face daily lives 
overcoming challenges undoubtedly require external objects tools variety tasks 
planetary exploration missions may benefit research autonomous robot tool 
example nasa plans space exploration missions call collecting soil rock samples distant planets bringing back earth 
task requires li 
cases hammer expose internal geological makeup rock samples li 
scenarios may possible engineer acceptable solutions providing robot preprogrammed behaviors tool 
available tools may break deformed 
autonomous adaptation critical success mission situations 
near research autonomous robotic tool may play major role answering fundamental questions tool abilities animals humans 
years tool experiments animals see section comprehensive theory attempting explain origins development learning tool behaviors living organisms 
overview rest document organized follows 
chapter surveys existing literature tool fields science ethology psychology anthropology neuroscience robotics artificial intelligence 
chapter formulates basic principles formulate developmental approach autonomous tool robots 
chapter de evaluation platforms perform experiments 
chapter describes algorithm autonomous self detection robots experimental conditions tested 
chapter describes computational model extendable robot body schema shows facilitate tool tasks video guided behaviors 
chapter describes behavior grounded approach autonomous learning tool affordances shows learned affordances solve tool tasks 
chapter draws suggests directions 
chapter ii related interdisciplinary nature dissertation mandates extensive overview existing body literature ethology psychology anthropology robotics artificial intelligence 
goal chapter establish solid theoretical foundation chapters differentiate research previous 
tool related necessary give working definition tool 
definitions tool literature 
definition adopted beck tool external employment environmental object alter efficiently form position condition object organism user user holds carries tool just prior responsible proper effective orientation tool beck 
definition object considered tool part user body 
user physical contact tool hold carry right 
tool act object organism user 
user orient tool position effective current task 
alternative definitions tool van goodall parker gibson 
similar beck definition listed completeness 
tool manipulation inanimate object internally manufactured effect improving animal efficiency altering form position separate object tool external object functional extension mouth beak hand claw attainment immediate goal van goodall 
goal directed manipulation detached object relative cases force field involving subsequent change state objects hitting object directly throwing object opening object lever parker gibson 
object exploration definition tool broad allow environ mental object tool manipulable user 
happen physical functional properties object need explored understood user form object manipulation 
psychological liter distinguishes main forms object manipulation exploration object play tool power 
exploration reduce uncertainty object information gathering 
exploration typically occurs encounter object new environment 
purpose answer intrinsic question object behaviorally consists long stereotyped sequence behaviors rely synchrony visual tactile sensors 
object play occurs initial exploration object 
tries answer implicit query object involves series short behavioral sequences highly variable idiosyncratic nature 
object play typical observe little coordination different sensory modalities 
tool goal directed behavior clear objective object means 
object achieve easily specific behavioral goals 
common objects modes object manipulation occur animals humans years life power 
adult table types object manipulation behaviors identified primates multi species studies 
power 
investigating relating sniffing poking touching rolling picking biting wrapping holding scratching hitting striking carrying rotating dropping transferring bringing eyes lining transforming large motor behaviors tearing breaking waving shaking twisting pushing pulling forming throwing animals humans exploratory behaviors faced new object 
table lists commonly object manipulation routines instrumental gathering information object properties mass durability stiffness ease handling 
long recognized opportunity explore serve powerful motivator montgomery segall 
numerous psychological theorists written intense interest infants young children everyday objects piaget white hunt 
theories postulated animals explore order satisfy stimulus hunger barnett seek stimuli sake 
mentioned exploration typically occurs organism exposure object change environment observed montgomery 
respect exploration similar typical responses fear avoidance power 
responses chosen depends degree fear new things induced object power 
case exploration chosen interesting thing occurs object subjected battery tests form exploratory behaviors 
species animals tests include entire behavioral repertoire animal 
quote conrad lorenz founding fathers ethology summarizes point young bird confronted object seen runs practically behavioral patterns social sexual ones 
treats object predator dangerous prey killed dead prey pulled pieces food hidden indifferent material hide food 
new situations usually call curiosity supplies motivation strong behavior situation ultimately established familiarity new object words new knowledge 
fact difference man organisms founded new possibilities cognition opened exploratory behavior lorenz table lists exploratory procedures links object properties learned applying procedures object 
table postulated links knowledge objects exploratory procedures may gain knowledge 
power 
knowledge object exploratory procedure substance related properties texture lateral motion hardness pressure temperature static contact weight unsupported holding structure related properties weight unsupported holding volume enclosure contour global shape enclosure exact shape contour functional properties part motion part motion test specific motion function test power lorenz observations object exploration achieved active experimentation stereotyped behaviors motivates similar approach robotic tool exploration 
specifically waving pushing pulling behaviors learn tools affordances 
modes tool mode object manipulation listed previous section tool 
beck taxonomy widely adopted today animals tools different functions extend reach amplify mechanical force exert environment enhance effectiveness antagonistic display behaviors control flow liquids 
table lists modes tool fit categories fit 
limited number additional uses shows tool defined evolutionary advantages readily adopted species beck 
function tool extension reach applicable situations animal prevented getting close incentive 
tool bring incentive sphere reach animal 
incentive located animal tool supporting structure order climb incentive objects stacked top achieve objective 
incentive living animal catch away 
inserting probing incentive located narrow holes may sphere reach inaccessible animal structures thick beck 
second function tool amplify mechanical force animal exert environment 
modes listed function table increasing mass decreasing elasticity increasing speed animal structures 
example hitting increases speed force swing beck 
uses leverage amplify applied force 
deliver force effectively concentrating small area 
common tools animal world amplify aggressive antagonistic behaviors 
modes fall category drop throw throw wave drag kick roll see table 
example observed throw stones sticks human observers 
try scare away snakes kicking sand faces cross 
fourth function tool control liquids effectively 
mode includes containment transportation liquids 
example chimpanzees clumps leaves wipe mud sticky foods blood bodies van goodall 
leaves absorb water van goodall 
laboratory crow university chicago observed carry water plastic cup order dry food beck 
robot tool tasks described chapters fall extension reach category beck taxonomy 
tasks category years test formulate theories tool animals 
section reviews prominent studies 
table modes tool animals 
indicates mode observed members specific group 
beck 
mode tool fish birds new old apes mammals world world monkeys monkeys extend reach reach prop climb balance climb stack insert probe amplify mechanical force pound hammer aimed throw club hit dig prod augment antagonistic display drop throw throw wave drag kick roll control flow liquids wipe contain absorb fitting affix hang swing animal tool numerous accounts animal tool listed chapter 
table see previous section lists observed modes tool members groups animals 
animal species mammals observed tools phenomenon apparently require highly evolved central nervous system campbell 
cognitively complex man chimpanzees truly proficient tool users tomasello call 
animals capable tool considered intelligent tool users tools limited narrowly specialized feeding adaptations parker gibson 
majority tool experiments performed primates 
wolfgang hler systematically study tool behavior chimpanzees 
goals research establish chimpanzees behave intelligence insight conditions require behavior hler 
hler views apes experimental subjects mistakes expose limited cognitive abilities serve basis building theoretical model nature intelligent acts notes humans subjects rarely encounter simple tasks time unfamiliar situations perform task mentally act behaviors easily observed 
hler performed large number experiments chimpanzees stranded island world war 
experimental designs quite elaborate required variety tools straight sticks sticks sticks ladders boxes rocks ribbons ropes coils wire 
incentive animal banana piece apple reached available tools 
experimental methodology animals freely experiment available tools limited time period 
problem solved time experiment terminated repeated time 
noted experiments children performed time writing valuable hler 
experiments performed hler 
tools boxes sticks cases randomly placed environment 
chimpanzees learn arrange get bananas 
order explain abilities apes achieve complex tasks hler formulated theory called theory chance 
states tasks solved lucky accident may occur performing action possibly unrelated current objective 
solving task animals try different actions attempt solve half understood problem 
solution may arise chance outcome actions hler 
hler observed impatience anger complicated cases take hler 
observed kl ver 
beck witnessed phenomena hypothesized observing outcomes misplaced aggression anger lead accidental discovery tool 
hler divides errors subjects main categories point view observer errors favorable impression observer animal gets task done errors caused complete lack comprehension conditions task animal innocent limitation prevents grasping task crude arising habits seemingly simple situations animal able achieve task 
pioneering studies performed bingham kl ver 
reached agreement hler finding 
kl ver example concluded monkeys achieved success performing series attempts displayed variety behaviors experiment designed test chimpanzees appreciate hook affordance tool 
task bring platforms reach tools get banana 
see text details 
povinelli 

external objects 
behaviors eventually produced desired result 
complicated problems requiring fine manipulation precise ordering actions remained unsolved 
experimental povinelli 
replicated exper iments performed hler statistical techniques analyze results 
experiment shown required chimpanzees choose appropriate tool bringing platform bananas reach 
tools hook positioned hook ape straight stick 
task may trivial chimpanzees chose straight stick trial 
subsequent trials show clear preference hook better tool task 
interestingly chimpanzees picked hook tool 
apparent lack progress tool tried 
ones picked straight stick provides advantage 
chimpanzees show understand advantage hook offers task povinelli 
main reached researchers chimpanzees understand functionalities tools 
solutions tool tasks may due simple rules extracted experience contact objects necessary sufficient tube problem described 
peanut placed inside transparent plastic tube 
get lure monkey stick push tube 
test tools monkeys training straight stick 
see text details 
establish covariation movement povinelli reorient tool progress try povinelli 
chimpanzees may tried establish contact tool platform regardless shape tool 
tool cause desired movement platform switched tools current tool povinelli 
furthermore concluded chimpanzees reason actions tool tasks terms unobservable phenomena force gravity 
notion contact visual contact physical contact support povinelli 
study tested monkeys tube task peanut placed middle transparent tube length diameter animal grab peanut directly 
training straight stick variety tools provided monkeys push lure tube short long sticks thick sticks bundled sticks sticks blocked ends 
test subjects eventually succeeded trap tube problem described stick inserted affects final outcome 
inverted trap tube problem stick inserted affect final outcome 
performing task number errors example inserting short stick tube inserting short stick opposite side tube freeing stick inserting tube 
led researchers conclude monkeys representational level characteristics tool required task face 
concluded acquire general set rules concerning properties stick 
subsequent study tube modified small trap hole right middle food pushed inside hole taken 
initially animals learned task 
learn better tube inserting stick inserted side tube 
corrections movement food location relative trap 
interestingly monkeys continued avoid trap tube rotated degrees trap upside longer capture food 
performance task guided entirely position food relative hole 
observed food moving hole stick inserted direction 
results experiments described section indicate situations non human primates clear idea functional properties tool capable solving tool tasks 
base solutions heuristics extracted observable phenomena actions 
cases movement attractor object important thing pay attention 
movement serves indicator progress task 
experiments new tools tasks solved purely accident series seemingly random exploratory behaviors 
observations taken account chapter formulates theoretical model autonomous robotic tool 
robot experiments described chapters inspired primate experiments described section 
origins tool behaviors identified factors important contributing origins animal human tool 
subsections describe currently adopted theories fields science 
ethological viewpoint beck explanation discovery tool trial error learning 
argues process animal variety responses produces reinforcement beck 
similar operant conditioning training methods skinner case trainer uses variety techniques elicit response 
case tool discovery teacher provide reinforcement 
cases origins tool behavior may involve small change stimulus substitution existing behavioral sequence beck 
way achieve result transfer existing behavioral pattern slightly novel stimulus situation beck 
debatable triggers substitution transfer 
beck suggests observing results frustration displaced aggression may lead accidental discovery tool beck 
animal world tool behaviors learned active tuition parent imitation kawamura de waal 
active tuition rare authors questioned exists povinelli 
finch example learn cactus spines push tree holes social learning 
fact behavior acquired parents tools get prey 
motivation provided environmental conditions greater impact dry environments food stimulate development behavior wet suppress 
ecological conditions may contributed evolution tool 
condition scientists agree involves extractive foraging embedded foods parker gibson beck 
examples embedded foods include nuts insects dwell underground nests foods edible portions protected hard shell hard reach 
evolutionary significance tools tool species seen compensation animal lack biological equipment substitute adaptation morphology parker gibson wilson 
species resort functionally equivalent behavior tool compensate lack anatomical specializations 
tool behavior give significant competitive advantage species behavior 
suggests tool species able invade ecological niches characteristic phylogenetic groups 
tools may provide key advantage competition resources species living ecological niche 
tool species may obtain monopoly near monopoly specific resource eliminate competitors campbell 
tool behaviors increase diversify food supplies indirectly improve animal reproductive chances survival species 
important factor evolution tool behaviors presence powerful motivator 
mentioned food extraction probably powerful motivator animal world 
food resources plentiful food obtained little effort bare hands tool behaviors evolve 
may case group wild african chimpanzees tools live area food supplies abundant mckee 
findings insightful time quite relevant robotics 
robots today capable spread environments inhabited species humans menzel 
humans tool species robots adapt demands new ecological niches tool species order compete successfully 
order achieve vision mass adoption robots everyday lives discussed chapter fundamental questions autonomously learn represent functional properties tools need addressed 
finding answers questions main motivation dissertation 
anthropological viewpoint archaeological record left ancestors clearly indicates tools essential part humanity years 
oldest stone tools date years ago 
simple chips pebbles river 
shaped identified tools shaped stones caves occur naturally 
ages design tools methods manufacture increased steady pace 
shows tools different stages human evolution 
sophistication design number operations needed manufacture tool increase left right 
common manufacturing techniques evolved simple striking stone stone hard soft materials better control grinding polishing 
producing tool shown rightmost image required major manufacturing steps approximately individual operations campbell 
archaeological evidence suggest stone tools earlier years ago 
tools preserved 
tools bio materials bone horn teeth wood bark leaves stems plants campbell 
similar tools modern day hunter gatherer communities living africa australia 
common tool modern digging stick preserved composition mckee 
fact stone tools hardness may invented order cut softer raw progression stone tool technology 
sophistication design number operations needed manufacture tool increase technology improves 
left right hand axes homo scraping tool times stone knife people modern type 
campbell 
materials wood bone campbell 
ability tools may evolved gradually advantages offered quite substantial 
quality life possible tools changed pressures natural selection changed structure man 
darwin suggest tool required free hands may selective evolutionary advantage adoption legged locomotion 
stone tools may played important role adoption diet early 
initially ancestors vegetarian diet gradually began scavenging remains dead animals killed 
cut bare hands teeth sufficient job collins 
fact shown early stone tools cut meat analyzing patterns edges 
benefits tool may lead gradual increase localization abilities memory capacity purpose remembering location raw tool materials 
especially important harsh environments materials sparse 
theories propose certain stone tools large numbers fact early tool repositories potts 
remembering location stone caches crucial survival tribe especially hunter gatherer tribe may traverse tens kilometers day 
calvin proposed interesting theory stone throwing specific mode tool may played important role brain development language 
throwing stone requires precise coordination sequential handed motor skills may required increased cognitive abilities concentrated brain hemispheres 
language sequential skill may benefited cognitive abilities developed stone throwing 
fact brain centers throwing language located close left hemisphere brain may evolved simultaneously kimura lieberman 
language may evolved reason connected tools 
increasing importance tools survival species may put evolutionary pressure development communication system 
communication hard refer specific tools daily activities harder pass ability manufacture tools generation mckee 
combined effect increased hand manipulation required tool diet increasing requirements mental communication abilities undoubtedly contributed increase brain size mckee 
provided computational resources invent new tools tasks 
increasing sophistication tools tool making technology years resulted today technological society 
aspect lives today affected abilities manufacture tools 
table divides human technology main categories 
categorization invention stone tools marks human technology 
ancestors may tools long technology start realized tools manufacture new tools 
fact primate animals living today capable tool tool modification man known manufacture new tools existing tools mckee 
similar distinction fire fire making 
early may fire created natural table categories technology identified campbell 

tool tool modification 
technology tool manufacture stone technology secondary tools 
fire fire control fire making metal industries casting forging 
facilities containers cords energy control 
machines 
instruments 
computers means lightning forest fires years pass capable starting fire mckee 
ability fire emerged production complicated robust tools possible 
human technology advanced rapidly extent modern lives impossible automobiles computers electricity telephones 
evolution tools different purposes table 
tools extend amplify motor physical abilities 
cutting digging scraping provided definite advantage tools actions high demand 
trend changed producing tools amplify sensing abilities 
instruments telescope microscope allowed people see objects great distances magnify hard see objects campbell 
trend begun invention computer promises revolutionize computational planning abilities 
similar history evolution human tool behavior robot experiments de scribed chapters involve simple tools sticks extend physical capabilities robot 
reason choosing stick primary tool experi ments comes psychological discussed section 
psychological theories intelligent behaviors children stick bring distant objects grasping range 
psychological influences psychologists long interested abilities humans animals tools manipulate external objects 
psychological theories interactions external objects important directly influence development human intelligence piaget 
theories focused capacity tools trans form organisms capable ones gibson 
focused differences animal human tool behaviors search origins hu man intelligence power 
section provides brief summary psychological theories tool influenced dissertation 
piaget jean piaget formulated probably influential theories child development 
theory external objects play important role development human sensorimotor abilities 
piaget theory suggests intelligent behaviors developed process interaction objects 
manifestation intelligence piaget observed child successfully manages bring distant objects closer pulling support placed stick bring field piaget 
desire strike swing objects reveals child power stick chance extends action hand 
child aims reach object situated outside field natural desire arouse schemata question 
strike object stick order draw oneself necessary discover give object appropriate movement 
child soon sees object displaced little influence stick blows understands possibility utilizing displacements view drawing object question 
comprehension due initial schemata root subject searching schema grasping striking 
due auxiliary schemata join piaget 
piaget mathematical abilities humans origins object interaction children learn concept number counting external objects 
piaget theory divides years human life distinct stages piaget 
perceptual motor skills child developed years 
additional stage behaviors child progress simple intelligent ones 
role external objects play development child increases additional stage 
brief summary major developments stage provided 
stage reflex structures month piaget suggests birth children cognitive structures 
reflex structures grasping crying 
example newborn children close hands touched 
similarly children start object comes contact lips piaget 
stage ii primary circular reactions months infant reflex structures gradually transformed sensorimotor action schemas piaget calls primary circular reactions 
happens repeated reflex structures baby apply object 
example babies grasp fingers stage ii infants concerned objects pay attention effects actions external world 
execute action applied object 
un common open close hands mid air 
repeated action forms primary circular reaction 
stage iii secondary circular reactions months stage ii infants capable exploring world 
form associations actions results produced external environment 
child actively tries reproduce prolong results 
repetition child discovers generalizes behavioral patterns produce interesting sights piaget 
piaget calls behavioral patterns secondary circular reactions 
external objects play important role stage iii differences objects noticed infant handles way 
stage iv coordination secondary schemes months stage iv marks problem solving 
babies capable ing secondary schemas means ends fashion 
merely reproducing results actions children schema achieve specific goal 
goal simply schema 
example order play toy covered cloth child remove cloth pick toy 
overcoming obstacles intermediate means unforeseen difficulties requires adaptation familiar schemas realities new situations piaget 
coordination secondary schemas gradually leads generalization ap growing number objects piaget 
children capable applying new situations accelerates exploration capabilities 
limitation stage iv infants capable employing familiar schemes 
task requires new way interaction world baby simply solve 
stage tertiary circular reactions months stage babies real explorers 
systematically vary behaviors pay close attention observed results 
discover new means active experimentation 
piaget calls experiments tertiary circular reactions piaget 
experiments guided search novelty goal piaget calls experiments order see piaget 
time child truly adapt unfamiliar situations existing schemas actively seeking finding new methods piaget 
stage marks intelligent tool 
piaget manifestation child ability bring distant objects reach 
achieved pulling support objects standing stick push field 
complex action formed coordination different schemas grasping striking bringing oneself 
schemas serve means achieving final goal directed schema 
stage vi invention new means mental combinations months exploration problem solving stage vi continues way stage important difference actual experimentation occurs mentally 
child pauses think solving problem 
theoretical approach robotic tool chapter inspired piaget ideas 
computational method learning affordances tools chapter resembles tertiary circular reactions described piaget 
piaget suggestion intelligent acts children stick bring reach objects grasping range inspired choice tools tool tasks robot experiments 
gibson james gibson proponent ecological approach perception ad perception direct process cognitive process 
time gibson writing predominant view psychology objects properties qualities associated order perceive object organism properties 
properties color texture composition size shape features shape mass elasticity rigidity mobility 
gibson proposed alternative theory objects perceived terms affordances qualities 
affordance defined invariant combina tion variables presumably easier perceive invariant perceive variables separately 
gibson words necessary distinguish features object fact impossible perception economical gibson 
important property chair example affords sitting exact shape color material secondary importance 
gibson theory suggest capable distinguishing object properties 
states perceiving objects observe affordances properties 
gibson process occurs child development infants notice affordances objects recognize properties gibson 
gibson specific way object affordances learned suggest affordances learned infancy child experiments objects 
example object affords throwing grasped moved away body swift action hand letting go 
perceptual invariant case shrinking visual angle object flying air 
highly interesting zoom effect draw attention child gibson 
gibson divides environmental objects main categories attached detached 
attached objects defined substances partially wholly surrounded medium displaced detached gibson 
detached objects hand objects displaced portable afford carrying 
detached objects comparable size animal consideration order afford behavior 
example object graspable approximately hand size gibson surfaces distance span hand gibson 
object affords different things people different body sizes object graspable adult may graspable child 
gibson suggests child learns scale sizes commensurate body measuring stick gibson 
definitions gibson defines tools detached objects graspable portable manipulable usually rigid gibson 
hammer example elongated object graspable weighted affords hitting 
knife hand graspable object sharp blade affords cutting 
writing tool pencil leaves traces applied surfaces affords trace making gibson 
gibson views tool rule governed activity 
rules extensions rules control hands bodies perform similar task tool 
example rule analogous gibson 
line reasoning extended suggest tools viewed extensions hands bodies blur boundary environment tool sort extension hand attachment part user body longer part environment user 
tool simply detached object environment graspable portable sure external observer 
capacity attach body suggests boundary animal environment fixed surface skin shift gibson note extension qualifies everyday objects clothes tools 
clothes rarely qualified tools extension perfect sense think clothes tools afford maintain body temperature 
worn clothes part wearer body longer part environment 
worn clothes just detached objects fabric gibson 
gibson postulated tools act extensions human body 
suggested body schema representation body brain modified external objects tools see section 
chapter describes computational model robot body schema extensibility properties similar biological analog 
ai robotics mentioned chapter studies autonomous tool robotics ai rare 
multiple researchers addressed different aspects broader problem robot tool 
computational aspects tool published literature divided main categories tool modeling tool recognition tool application 
section reviews related areas 
tool tool tool tool modeling recognition application computational aspects tool published robotics ai literature divided main categories 
aspect tool literature tool modeling 
tool models computational representations data structures capture shape function ality tool 
instances tool shape tool functionality treated separate entities additional data structures required perform mapping 
depending assumptions different approaches mapping 
shape representation methods divided types depending detail model bound ary volume tool exact boundary exact volume approximation 
function representation methods library functional primitives described terms geometric relationships object parts represent object 
shows classification graphically 
second component tool described literature tool recognition 
goal recognition process identify type tool extract functional tool modeling geometric shape tool functionality shape function mapping exact boundary exact volume approximate tool models representations capture shape functionality tool 
additional representations data structures necessary perform mapping shape functionality 
properties tool successfully applied task 
problem subset general problem object recognition 
techniques category come field computer vision 
algorithms recognition process fall main categories shape function 
approaches object recognition shape 
function approaches gaining popularity 
especially true recog objects clearly defined functionality hand tools 
sensing modality perceive tool recognition purposes visual haptic combination 
classification shown 
third component robotic tool tool application 
tool application act tool achieve task 
approaches described literature classified tool recognition algorithm sensing modality shape function visual haptic tool recognition approaches classified type recognition algorithms type sensing modality perceive tool 
tool application control mode grasp type tool extends number robots autonomous teleoperated non rigid flexible articulated physical capabilities sensing capabilities cooperative team robotic tool application classified criteria shown 
criteria control mode grasp type tool type robot capabilities tool extends number robots tool 
control mode autonomous teleoperated 
main types grasps control tool non 
tools rigid objects flexible objects ropes articulated objects scissors moving parts 
tool usually extends physical capabilities robot ability reach tool extend sensing capabilities robot stick hit object discover acoustic properties 
instances tool performed single robot manipulation large objects requires cooperative team robots 
subsections summarize related areas 
tool modeling variety shape representation techniques objects developed years ballard brown haralick shapiro 
invented computer graphics computer vision applications origins early ai 
shape representation methods divided main categories described 
category includes methods describe objects terms boundaries 
examples include polylines chain codes splines wire frames surface edge vertex representations 
methods second category focus representing area volume case objects 
example methods category spatial occupancy arrays quad trees oct trees 
methods category represent boundary volume object approximation techniques economical give better results object recognition tasks 
examples skeleton stick representations sticks plates blobs shapiro generalized cylinders brooks barr gardiner 
finding mapping object shape object functionality difficult prob lem 
nature mapping clear object usually functionality 
furthermore functionality depends intended task 
assumptions possible reasoning infer functionality object shape 
prominent approaches ai addressed problem context tool reviewed 
section describes additional approaches problem context tool recognition 
early conceptual lowry describes framework reasoning structural functional relationships objects 
framework structure described hierarchy generalized cylinders motion sequences spines gen cylinders 
function hand expressed hierarchy kinematic primitives functional primitives causal networks 
analogical reasoning represen tation constraints link functional topological hierarchies describing object 
qualitative quantitative reasoning extract relationships hierarchies 
example structural symmetry usually predictor functional symmetry 
brady 
outline system intended assist people con struction assembly 
project named mechanic mate main semantic network representation hammer 
connell brady 
objectives understand interplay planning reasoning domain hand tools explore different geometric tool representations explore qualitative quantitative representations capture dynamics tools objects 
smoothed local symmetries suggested shape representa tion primitives system brady asada 
case planning suggested way specializing existing tool plans new situations 
connell brady describe system performs analogical reasoning shapes domain hand tools 
semantic nets describe structural relations object subparts 
hammer example head handle ends sides 
descriptions learned positive negative examples objects 
representations complex see small errors due poor learning object recognition may lead completely different object functionality 
minimize errors algorithm gray coding small changes errors symbolic representation cause small changes semantic representation 
describe different approach bridging gap shape functionality descriptions 
fuzzy set representations compute compatibility object shape required function 
edison system hodges uses naive mechanical knowledge reason function devices moving parts opener 
functional ontology naive mechanics defined includes physical behavioral functional properties objects devices 
semantic networks describe shapes devices 
discussed representation disadvantage creating mapping form function 
hodges sees advantage claims diversity help finding innovative uses device 
reasoning find functional equivalences devices parts 
equivalences exploited problem solving 
overview different approaches reasoning functionality tools st 
authors conclude relying shape object determine functionality limited 
suggest agent interested learning tool 
needs look changes achieve physical world tool st 
tool representation described chapter consistent observation 
tool recognition studies computer vision ai focused object recognition 
specific area research relevant current discussion function object recog nition 
systems subscribe methodology information shape object reason purposes object serve helping recogni tion process stark bowyer stark sutton green 
approaches proven useful recognition objects clearly defined functionality hand tools 
subsection reviews approaches explicitly dealt domain tools 
detailed complete function recognition systems date generic recognition form function stark bowyer 
project began evolved different generations including object categories generation stark bowyer sutton 
uses function definitions chairs includes objects furniture category incorporates dishes cups plates pans includes objects hand tools category 
takes input cad description object outputs list possible shape interpretations object 
set knowledge primitives describing basic physical properties reason input shape 
primitives take input portions object descriptions output value 
global evaluation measure obtained combining primitive measurements 
knowledge primitives currently relative orientation dimensions proximity clearance stability sure 
primitive take parameters modify output 
example relative orientation primitive takes normals surfaces compares angle normals falls specified range 
primitive measure transformation required align surfaces normals parallel 
project object categories described definition trees 
root tree represents general category chair 
nodes tree represent different sub categories lounge chair balance chair high chair 
leaves tree represent invocations knowledge primitives describe specific functional property provides arm support provides back support 
evaluating object functionality tries evaluate object function instance category looking intended purpose recognize turned upside serve chair 
fine tuning object membership functions rely knowledge primitive functions proved increasingly difficult objects added cad database 
difficulty learning variant called developed stark 
learns membership functions correctly classified examples objects 
rivlin 
describe computer vision system recognizes simple hand tools 
trying reason global object object functionality representation rivlin 

characteristics stability height existence large horizontal surfaces 
reason object parts defined qualitatively extended version sticks plates blobs paradigm shapiro 
spatial relations primitives expressed quantitatively 
angle joining example oblique perpendicular tangential position joint surface qualitatively described near middle near side near corner near surface 
functional primitives defined linked functional relations 
mapping shape primitives relations functional primitives achieved function see 
general mapping falls category authors assumption hand tools functionality 
assumption research hand tools clearly defined effectors parts deliver action handles parts provide interface agent effector 

describe system recognizes objects hand tools cate gory bottle 
introduce concept defined recipients direct effects functional primitives 
functional model tool consists variety functional primitives 
chair example provides back support functional primitive 
recipient primitive case back human body 
similarly wrench defined lever working nut hand 
main goal approach verify hypothesized functionality object 
approach computationally complex requires testing possible combinations functional primitives 
case chair example requires estimating degree support offered object possible human body postures 
bajcsy describe system evaluates applicability differently shaped tools cutting piercing operations bajcsy 
robot manipulator move tool contact various materials wood computer vision system tracks outline tool measures penetration material 
outlines tools modeled clustering algorithms identify interesting properties successful tools see section details 
methods discussed far visual information derived camera shape information obtained form cad model 
studies haptic information primary sensing modality allen stansfield 
allen uses robotic arm library haptic exploratory procedures derive models objects recognition purposes 
example contour hand movements generate generalized cylinders model object grasping containment generate model object allen 
hybrid visual haptic approach object recognition described stansfield 
systems may perform object recognition tasks bajcsy tested real robot platform perform tool task 
functional models tools systems suitable object recognition robotic tasks incorporate properties robot tool tool object interaction 
tool application st wood provide overview literature physical tool argue creating artificial agents tool agents important challenge robotics ai 
st wood introduce concept tooling test variant turing test involves physical interaction world 
robot pass test independent human observer distinguish tool robot acting remotely controlled human 
bajcsy example knowledge attempted study object functionality intention object tool robot 
ph dissertation uses robot arm manipulate variety pointed objects order determine applicability cutting piercing operations 
tools consist clearly detectable parts handle endpoint 
physical tools dimensional objects shape extracted camera image approximated pair dimensional handle endpoint 
defined parameters control tapering width length shape 
robot tool interaction scripted discrete event system graph robot actions perceptual events 
sensory routines look specific events defined output touch sensor determine tool touched surface object 
robot experiments evaluate applicability differently shaped tools cutting piercing tasks 
tools applied different types materials pine wood 
outcome experiment success failure 
clustering algorithms identify interesting properties successful tools 
specifically interesting properties identified parameters difference class means success largest relative class standard deviation parameter 
experimental data build force shape maps tool 
maps provide way classifying tool respect shape force exerted depth penetration material 
maps represented interpolated dimensional surfaces constructed fitting second order curves empirical data 
axis force shape map represent force depth penetration tool sharpness 
shortcoming approach shape functionality tool represented mapping tool shape tool functionality 
chopping piercing tasks problem critical functionality tool sharpness extracted directly shape 
shortcoming limitations capabilities robot taken consideration robot manipulator serves lower tool vertical direction 
way point contact tool object predetermined edge chopper tip 
general tool tasks tool object come contact point boundaries outcome task may depend point contact 
asada describe method learning manipulator tool tasks hu man demonstration 
displacement tool force exerted human stored approximate robot controller 
force moment applied tool human position tion tool goal come robot control law approximates performance human expert 
function approximate human data easy compute allow real time robot control 
method applied grinding task tool moved vertically depending surface 
donald rus conducted series robot experiments constrained manipulation ropes 
example collaborative tool team robots achieve task moving large objects tied rope 
tool case flexible object task robots complex 
complexity reduced carefully coordinating actions robots defining basic manipulation skills 
skills rope object translating bound object pulling rotating bound object movements rope 
mackenzie arkin behavior approach control mobile ma drum sampling task 
sampling instrument attached effector robot manipulator allows robot inspect contents drums po hazardous materials 
motor schemas control direction movement sampling instrument 
schemas controlled perceptual features drums open holes extracted camera images 
pseudo forces calculated motor schemas applied tip sampling instrument 
jacobian manipulator convert forces corresponding joint torques cameron 
way instrument arm base move cohesive unit 
notes relatively little robotics research geared dis covering external objects properties shape position 
particular research concerned robotic identification material properties objects 
exploration methods employed robot tools coupled sensory routines discover object properties 
example watch method uses wooden pendulum strike object estimate mass coefficient sliding friction displacement acceleration object impact 
hit listen method uses blind person cane determine acoustic properties objects 
cane dropped fixed heights variety objects sound frequency patterns detected impact classify types materials objects 
fitzpatrick 
similar approach program robot poke objects arm tool learn rolling properties objects resulting displacements 
single poking behavior parameterized possible starting positions robot arm 
robot learns model object slides toy cars tend slide direction elongated axis balls slide direction 
tool tasks generally require grasping tool 
robotics literature offers numerous examples robotic grasping objects 
particular interest current discussion studies addressed problem grasping objects intended functionality 
cutkosky formulated grasp taxonomy observations tool grasps human mechanics 
taxonomy type tool task relates grip power object size dexterity manipulation 
taxonomy find suitable grasp choices depending task requirements 
force mobility sensitivity tool object attributes geometry texture fragility 
stansfield describes knowledge system uses simple heuristics choose grasps initially unknown objects 
system uses structured light extract fixed set view dependent object features stansfield 
line similar general function recognition problem 
kang ikeuchi human input gathered data glove teach robot different grasping strategies demonstration kang ikeuchi kang 
approaches object manipulation grasping 
examples non manipulation include pushing throwing rolling tumbling pivot ing sliding slipping mason lynch mason lynch erdmann 
examples include impulse manipulation robot applies instantaneous force specific location object causing object move slightly direction huang palm ma entire surface robot manipulator opposed fingertips erdmann manipulation robot indirectly manipulates objects confined container tray sliding objects walls walls corners reduce number possible orientations objects erdmann mason 
manipulations useful practical situations fact grasping necessary simplifies robot hardware 
hardware simplification comes expense increased complexity control planning algorithms 
similar tool area address problem objects tools 
focuses direct manipulation objects grasping 
numerous examples robot systems performing tasks qualified tool authors fall category definition section 
tasks include juggling tennis ball juggling devil stick schaal atkeson stick schaal playing air hockey atkeson 
general solutions tasks tuned particular domain providing detailed kinematic dynamic models robot 
cases models learned human demonstration serves way reducing complexity learning task 
despite advances robotics described number domains require intelligent tool robots 
problems domains solvable existing robot technology 
nasa example demonstrated need tool robots high risk high cost missions planetary exploration 
domain requires collecting soil rock samples 
cases hammer expose internal geological makeup rock samples li 
twin nasa rovers spirit opportunity landed mars carried rock tools board 
operation tools controlled remotely earth 
may feasible distant planets 
domain tool robots space station satellite maintenance 
construction international space station requires thousands hours exhausting dangerous space walks 
nasa developing humanoid robot help task 
space station components initially designed assembled humans capable handling tools required assembly tasks li 
initial goal nasa robot teleoperated mode 
chapter iii developmental approach autonomous tool robots chapter formulates basic principles developmental robotics gives example principles applied problem autonomous tool robots 
principles formulated recurring themes developmental learning literature author research 
principles follow logically verification principle see section assumed self evident 
developmental robotics newest branches robotics weng 
basic research assumption field true intelligence natural possibly artificial systems presupposes crucial properties embodiment system situatedness physical social environment prolonged epigenetic developmental process increasingly complex cognitive structures emerge system result interactions physical social environment 
study autonomous tool abilities robots task ideally suited methods developmental robotics 
main reasons 
tool abilities develop relatively early life cycles animals humans years birth piaget tomasello call power 
time order magnitude shorter time required full maturation humans takes approximately years 
robots learn developmentally translates shorter learning times 
second ability tools precedes development cognitive abilities potentially difficult model existing ai techniques development tool abilities human infants precedes development language 
developmental sequence leading autonomous tool surprisingly uniform different primate species tomasello call power 
follows developmental sequence outlined piaget see section 
observed variations species deal duration individual stages order tomasello call power 
lack variation suggests evolution developmental solution problem autonomous tool works different organisms 
increases probability sequence may robots 
fields science organized small set fundamental laws physics newton laws thermodynamics fundamental laws 
progress field fundamental laws tends slow incoherent 
fundamental laws formulated field thrive building 
progress continues laws insufficient explain latest experimental evidence 
point old laws rejected new laws formulated scientific progress continue 
fields science possible formulate fundamental laws impossible prove empirically 
possible get obstacle formulating set basic principles stated form postulates axioms statements proof considered self evident 
famous example approach course euclid formulation fundamental axioms geometry 
developmental robotics infancy premature try come fundamental laws axioms field 
recurring themes developmental learning literature author research formulate basic principles 
principles laws proved point axioms hard argue point self evident form consistent set 
basic principles guide research inadequate time modify reject 
basic principles described 
verification principle developmental robotics emerged field partly reaction inability traditional robot architectures scale tasks require close human levels intelligence 
primary reasons scalability problems amount programming knowledge engineering robot designers perform grows rapidly complexity robot tasks 
mounting evidence pre programming solution scalability problem 
environments robots expected operate simply complex unpredictable 
naive think complexity captured code robot allowed experience world sensors effectors 
consider task programming household robot example ability handle possible objects encounter inside home 
simply possible robot designer predict number objects robot may encounter contexts robot projected service time 
fundamental problem pre programming ad dress worse 
problem programmers introduce hidden assumptions robot code 
assumptions fail robot begins act strangely programmers sent back drawing board try fix wrong 
robot way testing verifying hidden assumptions explicit 
robot capable autonomously adapting situations violate assumptions 
way overcome problem put robot charge testing verifying learns 
basic principle stated 
called cation principle postulated richard sutton series line essays sutton 
principle stated follows verification principle ai system create maintain knowledge extent verify knowledge 
sutton sutton key successful ai tell working correctly sutton 
reasonable way achieve goal put ai system charge learning verification principle 
verification possible concept ai system attempt learn concept 
words ai systems ai learning algorithms follow verification learning 
sutton points verification principle eventually adopted ai practitioners offers fundamental practical advantages alternative methods comes scalability 
way saying thing program bigger head sutton 
verification principle stands autonomous testing verification performed robot robot 
explained unrealistic expect robot programmers fix robots time robots encounter problem due hidden assumption 
fact robots telling programmers wrong way 
point mentioned dennett dennett points sufficiently complicated system default considered intelligent 
furthermore goes wrong sufficiently complex system people charge operating choice accept system explanation wrong 
sutton researcher ai state verification principle explicitly 
origins verification principle go back ideas logical philosophers prominent rudolf carnap alfred ayer 
argued statements proved disproved experience metaphysical statements meaningless 
ayer defined types verifiability strong weak formulated follows proposition said verifiable strong sense term truth conclusively established experience 
verifiable weak sense possible experience render probable ayer order verify strong sense physically perform verification sequence 
hand verify weak sense perform verification sequence directly prerequisite sensors effectors abilities perform verification sequence necessary 
example blind person may able verify strong sense statement object soft physically touching object testing softness 
verify statement weak sense physically capable performing verification procedure necessary 
ayer view blind person able verify strong weak sense statement object red ability see perceive colors 
ayer words remain number significant propositions concerning matters fact verify chose simply lack practical means placing situation relevant observations ayer verification principle easy state 
commitment follow principle implications far reaching 
fact principle different practices traditional autonomous robotics changes 
particular forces programmer rethink ways learnable quantities encoded robot architecture potentially learnable autonomously verifiable 
verification principle profound remaining principles con sidered corollaries 
connection may intuitively obvious stated separate principles 
principle embodiment important implication verification principle robot ability verify learns 
verification performed absence actions robot means affecting world body 
principle embodiment defended times literature varela brooks stein brooks clark pfeifer scheier gibbs 
robotics consensus principle followed 
aren robots bodies 
arguments favor embodiment principle put forward justifying principle opponents brooks stein brooks 

reasons historical 
early ai systems brooks calls old fashioned ai gofai disembodied consisted learning algorithms manipulated data computer memory need interact external world 
result historic debate arguments favor embodiment main point 
debate embrace principle embodiment 
debate different ways program truly embodied robots 
gibbs similar observation current state art ai robotics despite embracing embodiment situatedness designing robots systems fail capture way bodily mechanisms truly embedded environments gibbs 
arguments justify embodiment principle easily explained point view verification principle 
connection explicit far 
rehashing debate favor embodiment argued varela gibbs am going focus slightly different interpretation embodiment light verification principle 
opinion arguments favor embodiment principle distinction body world treat body special 
words body world boundary explicit 
distinction artificial 
reason body may special body consistent predictable verifiable part environment 
difference body external world 
brain body may special just brain body captive audience 
words body run away 
new interpretation embodiment principle described body required sake verification 
verification principle applicable properties body 
say properties body autonomously verifiable 
learning exploration principles robot uses explore external world ones uses explore properties body 
interpretation reduces special status body 
treating body special new interpretation treats body simply consistent predictable verifiable part environment 
body easily distinguished environment 
furthermore developmental trajectory body explored 
fact distinguishing body external world relatively easy certain events owner body experience 
calls events self specifying lists events efferent afferent loops moving ones hand seeing move double touch touching index fingers behaviors followed hearing results crying hearing oneself cry 
events characterized fact multimodal involve sensory motor modality 
events autonomously verifiable repeat action observe result 
body constructed actual verifiable experience theory possible change body representation 
fact turns surprisingly easy 
experiments shown body world boundary altered matter seconds ramachandran iriki 
example comes total surprise people realize normally think body just phantom created brains 
simple experiment performed special equipment exposes phantom body ramachandran 
experiment goes subject places arm table 
person conducting experiment sits right subject uses hands deliver simultaneous taps strokes subject arm table surface table 
taps strokes delivered synchronously minutes subject bizarre sensation table part body part skin stretched lie surface table 
similar extensions re mappings body reported cohen iriki 
studies may strange typically assume embodiment implies solid representation body brain 
possible reason phantom body body constant changes time 
bodies change age 
change gain lose weight 
change suffer results injuries accidents 
short bodies constantly changing 
impossible brain keep fixed representation body 
representation flexible sooner obsolete useless 
possible reason phantom body may impossible brain predict complicated events occur body 
composition body constructed continuously latest available information 
stated brain predict commands neural chemical especially play body play resulting states depend local biochemical contexts numerous variables body fully represented neurally 
played body constructed anew moment moment exact replica happened 
suspect body states algorithmically predictable brain brain waits body report chapter uses insights section formulate algorithm autonomous self detection robot 
algorithm uses proprioceptive visual efferent afferent loops self specifying events identify visual features belong robot body 
chapter describes computational representation robot body schema rbs 
representation learned robot self observation data 
rbs representation meets requirements verification principle embodiment principle robot builds model body self observation data observable 
principle subjectivity principle subjectivity follows quite naturally verification principle 
robot allowed learn maintain knowledge autonomously verify follows robot learns function robot experienced sensors effectors learning function experience 
consequence robots control architectures different histories interactions totally different representations object 
words representations subjective 
ayer probably recognize verification principle implies sub 
observed knowledge verifiable experience follows knowledge subjective formed individual experi ences ayer 
learned depends entirely capabilities learner history interactions learner environment learner body 
furthermore learner ca perform specific verification procedure learner able learn depends procedure blind person example 
subjectivity may developmental learning relativity physics fundamental limitation avoided circumvented 
subjectivity principle captures subjective nature object affordances 
similar notion suggested gibson stated child learns scale sizes commensurate body measuring stick gibson 
object affords different things people different body sizes object graspable adult may graspable child 
modern interpretation gibson ideas stressed affordances skill relative affordances animal relative depending example size shape animal 
worth noting skill relative 
give example hitter baseball thrown pitch affords certain possibilities movement 
excellence hitter consist primarily having excellent vision 
may consist mastery sensorimotor skills possession enables situation afford opportunity action available said far infer essence principle sub imposes limitations potentially learnable specific agent 
particular types limitations sensorimotor experiential 
discussed adaptation mechanisms adopted animals humans reduce impact limitations 
sensorimotor limitations limitation imposed robot subjectivity principle potentially learnable determined sensorimotor capabilities robot body 
words subjectivity principle implies learning pre conditioned body capable doing 
example blind robot learn meaning color red ability perceive colors 
may impossible learn sensorimotor tions body certainly possible push limits farther building tools instruments 
common theme history human technological progress constant augmentation extension existing capabilities bodies 
example campbell outlines technological milestones essentially pushed body limit campbell 
technological progression described campbell starts tools augment physical abilities sticks stone axes spears moves tools instruments augment perceptual abilities telescopes currently stage tools augment cognitive abilities computers pdas 
regardless complicated tools instruments ties learned conceptualized understood relative sensorimotor capabilities 
words tools instruments devices tied pre existing capabilities bodies 
furthermore tool body connection established verification principle 
way understand new tool works expressing functionality terms sensorimotor repertoire 
true tools instruments substitute sensing modality 
example humans natural means reading magnetic fields invented com pass allows 
compass convert direction magnetic field modality interpret infrared light 
converts human readable form help needle 
exploration process involved learning functional properties affordances new tool straight forward 
typically process involves active trial error 
probably interesting aspect exploration functional properties new tool learned relation existing behavioral repertoire learner 
related animal object exploration indicates animals stereotyped exploratory behaviors faced new object power lorenz 
set behaviors species specific may genetically predetermined 
species animals tests include entire behavioral repertoire young bird confronted object seen runs practically behavioral patterns social sexual ones lorenz adult humans rarely explore new object subjecting possible behaviors behavioral repertoire 
human object exploration tends fo case human infants power 
extensive exploration process similar displayed observed adult humans 
process easily observed members tech primitive societies exposed time object technologically advanced society diamond 
chapter describes method autonomous learning object affordances robot 
robot learns affordances different tools terms expected outcomes specific exploratory behaviors 
affordance representation inherently subjective expressed terms behavioral repertoire robot skill relative 
affordance representation subjective affordances expressed relative capabilities robot body 
example object thick grasped robot robot learns object graspable graspable different robot larger gripper 
experiential limitations addition sensorimotor limitations subjectivity principle imposes experiential limitations robot 
experiential limitations restrict potentially learnable simply learning depends history interactions robot environment depends experience 
things experience function time limitation essentially due finite amount time available type learning 
interesting corollary intelligent life form longer spend developmental stage 
time key factor developmental learning 
default developmental learning requires interaction external world 
limit fast interaction occur ultimately restricts speed learning 
limitation time avoided possible speed learning relying experience 
reason violate subjectivity principle verification performed weak sense strong sense humans example exploit shortcut 
writing invented able experience places events words pictures 
vicarious experiences essential 
vicarious experiences require sort basic overlap standing world 
question arises learned subjective different people common understanding 
obviously big issue humans able function normally 
fundamental questions philosophers 
answer question violating basic principles stated far allow fact representations agents may functionally different qualitatively 
furthermore verification principle establish qualitative equivalence representations different agents 
understood ayer stated define qualitative identity difference people terms similarity dissimilarity reactions empirical tests 
determine instance people colour sense observe classify colour confronted way say man color blind asserting classifies certain colour different way classified majority people ayer reason humans understand totally different life experiences similar physical bodies 
human bodies exactly similar structure 
furthermore bodies limits determine explore world move hands fast 
hand world structured imposes restrictions explore actions object wide may graspable 
similar bodies live physical world significant overlap allows shared understanding 
similar ideas proposed psychology gaining popularity years glenberg regan gibbs 
consequently experience constantly shape change internal representations agent time 
representations flexible able change adapt new experience available 
amount experimental evidence suggest adaptation takes place biological systems 
example representation fingers somatosensory cortex monkey depends pattern wang 
fingers fingers number neurons somatosensory cortex encode fingers increase wang 
affordance representation described chapter influenced actual history interactions robot tools 
affordance representation accommodate latest empirical evidence properties tool 
example representation accommodate tools break drastic change significantly alters affordances 
principle grounding verification principle states things robot learns verifiable grounding principle describes constitutes valid verification 
grounding important verification principle left unchecked easily go infinite recursion 
point needs indivisible entity brought scrutiny entity require additional verification 
speaking grounding puts brakes verification 
grounding familiar problem ai 
fact oldest open problems ai called symbol grounding problem harnad 
grounding loaded term 
unfortunately difficult come term replace 
purposes document term grounding refer process outcome process determines constitutes successful verification 
despite challenges defining constitutes grounding follow principles outlined far arrive basic components grounding 
motivation stating embodiment principle verification impossible ability affect world 
implies component necessary successful verification grounding action behavior 
action useful purposes successful tion grounding provide sort feedback 
order verify robot needs able observe outcomes actions 
second component verification procedure outcome outcomes associated action performed 
leads main insights section grounding consists act outcome behavior observation pairs 
words grounding achieved coupling actions observable outcomes 
piaget expressed idea said children real explorers perform experiments order see similar ideas proposed defended gibson varela regan gibbs 
grounding information single act outcome pair sufficient outcome may due lucky coincidence 
grounding occur outcome replicated times context 
act outcome pair replicated robot build probabilistic confidence observed just due pure coincidence real relationship reliably reproduced 
grounding requires action outcome pairs coupled sort probabilistic estimates repeatability 
confidence built time multiple executions action lead outcome similar conditions 
situations robot able repeat action sequence actions executed just prior detection outcome 
outcome replicated act outcome pair worth remembering autonomously verifiable 
way achieve goal remember long sequences possibly different act outcome pairs occur context due length sequence 
method closer gibson ideas representing affordances 
stating grounding performed terms act outcome pairs coupled prob estimate start leaves formulation grounding somewhat vague 
action behavior possibly complicated process involves multiple levels detail 
true outcomes observations 
remains addressed identify persistent features verification sequence constant different contexts 
words needs identify sensorimotor invariants 
invariants remain unchanged worth remembering grounding 
potentially infinite number ways ground information section focus 
arguably easiest pick sensorimotor flux probably discovered developmentally 
mechanism grounding detection temporal contingency 
temporal contingency appealing method grounding abstracts away nature complexity stimuli involved reduces relative time occurrence 
signals come different parts body origins different sensors actuators 
temporal contingency easy calculate 
requirement mechanism reliable detection interval events 
events represented binary detection performed times signals change 
furthermore delay signals estimated predict events 
timing contingency detection chapter detect perceptual features belong body robot 
order robot learns characteristic delay motor actions efferent stimuli movements perceptual features environment afferent stimuli 
delay classify perceptual stimuli robot detect self 
detection temporal contingency important normal development social skills 
fact suggested contingency powerful social signal plays important role learning imitate jones language acquisition goldstein 
watson watson proposed contingency relation behavior subsequent stimulus may serve social signal possibly independent signal value stimulus exploring suggestion fruitful direction social robotics 
principle gradual exploration principle gradual exploration recognizes fact impossible learn thing time 
learn walk learn crawl 
learn read learn recognize individual letters 
way 
similarly certain milestones stages achieved developmental learning development continue stage 
major developmental theory assumes explicitly states development proceeds stages piaget freud 
theories disagree causes stages triggers transitions 
variations timing stages observed members species 
age limits set piaget developmental milestone happen treated rough guidelines fixed rules 
stages correspond roughly age levels children studied piaget significance offer behavior norms specific ages sequence stages transition stage invariant wolff gibson gibson wife expressed doubts useful ness formulating stages developmental learning want look trends devel opment am dubious stages 
repeat trends imply stages radically new process emerges imply maturation new direction exclusive learning created gibson fruitful area research days compare contrast developmental sequences different organisms 
comparative studies primates humans useful precisely expose major developmental differences different species follow piaget sequence development tomasello call power 
regardless causes stages important lessons draw studies final outcome depends just stages relative order duration 
example time autonomous locomotion emerges birth primates varies significantly different species tomasello call power 
chimpanzees achieved fairly rapidly move environment 
humans hand independent locomotion emerge year birth 
important consequence human infants longer developmental period manually explore manipulate objects 
tend play objects rotate chew throw relate bring eyes take closer look 
contrast chimpanzees interested sitting manually exploring objects learn walk younger age 
extent object exploration occurs chimpanzees usually performed objects ground tomasello call power 
chimpanzees rarely pick object order bring eyes explore power 
interesting result comparative studies object exploration exploration general self guided require external reinforcement 
clear process initiates exploration process terminates 
principle gradual exploration states exploration self regulated proceeds verifiable verifiable parts environment 
words exploration guided attention mechanism continually attracted parts environment exhibit medium levels verifiability 
exploration process chart developmental trajectory external reinforcement worth exploring depends explored 
previous section described temporal contingency successful verifiability grounding 
section builds example takes account level contingency detected 
point time parts environment interesting worth exploring exhibit medium levels contingency 
see case consider insights reached watson 
experiments watson studied attentional mechanisms infants change time 
watson terminology delay motor commands efferent signals observed movements visual stimuli afferent signals called perfect contingency 
furthermore watson defines levels contingency delay deviates delay associated perfect contingency 
watson observed level contingency detected infants important 
example observed month old infants paid attention stimuli exhibit perfect contingency watson week old infants paid attention stimuli exhibit imperfect contingencies watson 
experiments infants watched tv monitor showed woman face 
tv image manipulated woman face animated second intervals infant kicked legs watson 
level contingency varied adjusting timing delay infants kicking movements animation 
somewhat surprisingly week old infants study paid attention faces show perfect contingency faces move immediately infants kicking movements 
result led watson conclude infant attentional mechanisms may modulated inverted shaped function contingency stimulus watson 
attention function properties ideal autonomous robot 
stimulus exhibits perfect contingency interesting robot predict stimulus 
hand stimulus exhibits low levels contingency robot learn predictive model stimulus stimulus uninteresting 
really interesting stimuli exhibit medium levels contingency 
gibson reached similar watson 
argued percep tual systems self organized way try reduce uncertainty 
furthermore search self regulated require external reinforcement search directed task intrinsic cognitive motives 
need get information environment strong get food obviously useful survival 
search terminated externally provided rewards punishments internal reduction uncertainty 
products search property reducing information processed 
perception active adaptive self regulated gibson main message section try identify attention functions intrinsic motivation functions autonomous robots properties similar ones described 
functions guide robot gradual exploration environment verifiable verifiable parts 
promising area research 
developmental sequence autonomous tool section provides example uses principles described devel sequence 
sequence autonomous robots acquire tool abilities 
sequence robot explore progressively larger chunks initially unknown environment surrounds 
gradual exploration achieved de regularities explained replicated sensorimotor repertoire robot 
exploration proceeds predictable predictable parts environment 
developmental sequence begins learning model robot body body consistent predictable part environment 
internal models reliably identify sensorimotor contingencies associated robot body learned self observation data 
example robot learn characteristic delay motor actions efferent stimuli movements perceptual features environment afferent stimuli 
selecting consistently observed delay robot learn efferent afferent delay 
furthermore delay classify perceptual stimuli robot detect self see chapter 
perceptual features associated robot body identified robot learn certain patterns exhibited body 
example features belong body clustered groups movement contingencies 
groups form frames body frames turn control movements robot predict locations certain stimuli see chapter 
stage robot uses body defined frame movements positions environmental objects observed 
particular robot learn certain behaviors grasping reliably cause environ mental object move way part robot body wrist subsequent robot behaviors 
robot learn grasping behavior necessary order control position object reliably 
knowledge subsequent tool behaviors 
method learning order binding affordances described 
robot previously explored properties objects relate objects 
way robot learn certain actions objects affect objects tools 
principles verification grounding robot learn affordances tools 
robot autonomously verify correct affordances tool changes breaks see chapter 
summary chapter proposed basic principles developmental robotics 
principles formulated recurring themes developmental learning literature author research 
principles follow logically verification principle postulated richard sutton assumed self evident 
chapter described example principles applied au tool robots 
chapters follow describes individual components sequence details 
chapter iv evaluation platforms chapter describes evaluation platforms chosen performing exper iments described chapters 
platforms dynamics robot simulator mobile robot manipulator described detail 
dynamics robot simulator experimental platform physics dynamics robot simulator 
simulator implemented fast prototyping environment verification testing approach autonomous robotic tool 
simulator provides rich set routines modeling simulating controlling drawing simulated worlds robots environmental objects 
shows screen snapshots robots different stages research 
simulated robots modeled collection rigid bodies 
shape rigid body described primitive geometric shapes 
primitive geometric shapes supported simulator sphere capped cylinder cylinder hemispheres 
rigid bodies connected joint imposes constraints relative movements bodies 
joints currently supported hinge prismatic ball socket universal 
configuration robots specified plain text configuration files 
feature allows rapid prototyping new robots making changes existing robots 
process build objects tools simulated worlds 
geometric shapes rigid bodies calculate collision points turn calculate corresponding collision forces 
collision forces forces gravity friction robot motor torques included dynamics calculations produce physically accurate movements simulated objects 
achieve simulator computes positions rotations accelerations torques rigid bodies regular time intervals 
timestep calculations specified parameter allows accurate simulations expense computational time 
dynamics calculations performed open dynamics engine ode library smith 
ode provides basic capabilities dynamically simulating rigid objects calculating collisions 
provide functionality building controlling robots 
ode includes opengl visualization library extended purposes simulator 
robot simulators ode 
multiple robots simulator dynamics developed usc code available sourceforge net html 
geared mobile non articulated robots limited robot modeling capabilities 
michael offers robot building capabilities commercial product users limited modify access source code 
go open source simulator geared robot soccer applications 
developed carnegie mellon similar simulators 
feature simulator research afore mentioned simulators computer vision routines integrated simulator 
opengl rendered simulator window treated camera image computer vision processing performed 
simulator supports multiple cameras static attached robot 
open source color segmentation library bruce track movements robots tools objects simu lated 
objects locations interest color coded accommodate tracking process 
combination physically realistic dynamics simulation computer vision routines simulated images provides level realism achieved previous generation autonomous robot simulators mackenzie balch stage 
despite advances simulation technology robot simulator simulator 
common problem simulators fail capture complexities real world try simulate 
simulation environment may provide false sense success 
necessary validate simulation results repeating experiments real robot 
section describes robot purpose 
screen snapshots simulated robots different stages research 
joint robot gripper nomad robot simulation version crs mobile manipulator described section 
mobile robot manipulator second experimental platform crs manipulator arm 
robot degrees freedom waist roll shoulder pitch elbow pitch wrist pitch wrist roll plus gripper 
joint limits manipulator shown 
addition arm mounted nomad robot allows manipulator move sideways 
nomad wheeled holonomic vehicle separately steerable turret base 
experiments movements restricted simple translations parallel table tools attractors placed 
words nomad linear track manipulator 
joint configuration crs arm 

joint limits crs manipulator 

mobile manipulator tools experiments 
computer camera track positions tools objects robot 
color tracking library integrated simulator track object real world 
different positions camera depending task 
setups described chapters 
manipulator nomad robots controlled serial line 
robot control code color tracker run pentium iv machine ghz gb ram running redhat linux 
chapter self detection robots important problem organisms solve early developmental cycles distinguish surrounding environment 
words learn identify sensory stimuli produced bodies produced external world 
solving problem critically important normal development 
example human infants fail develop self detection abilities suffer disorders autism syndrome watson 
chapter addresses problem autonomous self detection robot 
chap ter describes methodology autonomous learning characteristic delay motor commands efferent signals observed movements visual stimuli afferent sig 
robot estimates efferent afferent delay called perfect contin self observation data gathered robot performing motor babbling 
say robot gathers data executing random rhythmic movements sim ilar primary circular reactions described piaget 
efferent afferent delay estimated robot delay classify visual stimuli self 
results robot experiments performed environments increasing degrees difficulty reported 
related chapter inspired john watson entitled detection self perfect algorithm read wanted implement ideas robot 
time distant dissertation topic kept putting 
ironically ideas autonomous tool kept evolving came realize self detection early developmental milestone achieved fall place 
section reviews main findings theories self detection described literature 
self detection humans fundamental questions self detection abilities humans mechanism developed self detection mechanism developed 
section summarizes answers questions prior research 
major developmental theory recognizes fact normal develop ment requires initial investment task differentiating self external world watson 
certainly case influential theories th century freud piaget theories disagree ways self detection process achieved 
freud followers believed achieved early life gradual differentiation self mother see lewis brooks gunn 
piaget hand appears ignore question altogether 
explicitly assumes self detection subsequent self versus discrimination occur necessary com ponent secondary circular reactions exploratory behaviors directed external objects 
freud piaget agree self emerges actual experience predetermined watson 
modern theories human development agree self derived actual experience 
furthermore identify types experience required efferent afferent loops coupled sort probabilistic estimate repeatability 
gist theories summarized help examples lewis brooks gunn watson 
suggests certain events self specifying 
events experienced owner body 
self specifying events multimodal involve sensory motor modality 
events unique owner body easy identify replicate 
explicitly lists self specifying events infants experience crying touch experience perfect contingency seen felt bodily movements arm crossing field view perceive perceive 
transport ir hand face frequent birth pregnancy unique tactile experience tactile experience entails double touch hand touches face simultaneously face touching hand 
auditory experience ir crying visual proprioceptive experience accompanying self produced movement 
basic perceptual multimodal experiences self specifying perception experienced infant birth prior birth confines maternal decades earlier lewis brooks gunn proposed similar process infant detect self 
self defined action outcome pairings efferent afferent loops coupled probabilistic estimate regularity consistency 
describe emergence call existential self self subject distinct world existential self developed consistency regularity contingency infant action outcome world 
mechanism feedback provides contingency information child kinesthetic feedback produced infant actions basis development self 
example time certain set muscles operates eyes close black see 
kinesthetic systems provide immediate regular action outcome pairings lewis brooks gunn example illustrate self detection abilities humans comes watson 
watson proposes process self detection achieved detecting temporal contingency efferent afferent stimuli 
level contingency detected serves filter determines stimuli generated body ones generated external world 
words level contingency measure 
watson words option imperfect contingency efferent afferent activity implies body sources stimulation perfect contingency implies body sources non contingent stimuli ambiguous 
order specify mechanism necessary specify mean temporal contingency 
mean temporal pattern events potentially reflects causal dependency watson examples suggest self discovered quite naturally predictable consistent part environment 
furthermore confirm self constructed self specifying events essentially efferent afferent loops action outcome pairs 
studies reached similar 
numerous summarized 
extensive overview reader referred lewis brooks gunn parker 

study tried identify minimum set perceptual features required self detection 
showed month old infants perceive proprioceptive visual relation basis motion information infants legs eliminated 
experiments fitted infants socks contained dots 
camera image preprocessed positions markers projected tv monitor 
way infants observe point light display feet tv monitor placed front 
experimental results showed month olds able differentiate self produced contingent leg motion pre recorded non contingent motion produced legs infant 
results illustrate movement information sufficient self detection features edges texture eliminated experiments 
robot experiments described similar experimental design robot visual system perceptual filters allow robot see positions movements specific color markers placed robot body 
similar infants dotted socks experiments robot see point light display movements 
second fundamental question self detection abilities humans abilities developed 
developmental literature suggests human infants task takes approximately months lewis brooks gunn watson 
estimate derived experiments infants various ages tested looking preferences preferences stimuli 
experiments test infants discriminate perfectly contingent movements legs non contingent movements baby legs 
experimental setup typically consist tv monitors infant observe time 
monitor shows leg movements infant captured camera 
second monitor shows leg movements infant recorded previous trial watson 
results experiments show distribution looking preferences month old infants bimodal half infants preferred see movements half preferred see movement child watson 
age months children showed significant preferential fixation image contingent self 
results experiments watson proposed infants go developmental phase months old switch self seeking self avoiding 
months child trying estimate perfect contingency motor commands efferent signals resulting sensory perceptions afferent signals 
perfect contingency estimated infant focuses attention parts environment show perfect contingency 
third month attention mechanisms infant modified seek interact parts environment objects people exhibit imperfect contingency 
evidence existence self seeking period followed self avoidance period comes studies children genetic diseases syndrome watson 
children affected disorder appear develop normally period months rapidly form severe mental retardation watson 
transition sudden accompanied increasingly repetitive hand hand hand mouth movements watson 
watson calls movement patterns deviant self seeking genetic disorder flips switch reverses developmental cycle result infants transition back self seeking patterns performing months lives 
evidence suggest onset schizophrenia adult humans accompanied loss capacity self recognition 
notion self manifestations 
related social aspects self lewis brooks gunn call categorical self example identified levels self awareness unfold moment birth approximately years age 
levels self world differentiation sense body situated relation entities environment development concept children order distinguish people development temporally extended concept children recognize photographs development theories mind representational abilities relation self 
exception level scope dissertation 
self detection animals studies focused self detection abilities animals 
influential study performed reported time abilities chimpanzees self recognize mirror 
chimpanzees placed color markers faces asleep 
chimpanzees allowed move cages 
brief adaptation period mirror introduced environment 
measured sharp increase number self directed movements spot marker placed mirror introduced 
furthermore directed exploratory actions image mirror faces 
shows understood difference 
treatment mirror test see 
discovery followed large number studies attempted test species animals pass mirror test 
somewhat surprisingly number turned small chimpanzees great apes called forgotten ape see de waal 
study documented similar capabilities dolphins reiss marino 
dolphins study results directly comparable mirror experiments 
study reported asian elephant tested conclusively passed mirror test 
attempts replicate mirror test primate non primates species failed 
unfortunately scientific community divided mirror test test povinelli cant barth de waal 
process natural selection favored ability self recognition mirror carries immediate advantages mention mirrors pre historic africa 
explanations needed 
studies shown great apes don pass mirror test rhesus monkeys show intense interest exploring markers placed wrists abdomen places bodies normally see 
pay attention markers faces markers seen mirror 
hand things chimpanzees exposed mirror study parts bodies normally see faces nostrils barth 
studies reported learn control image mirror exploiting contingencies movements movements mirror image parker 
similarly juvenile chimpanzees observed display contingent behaviors mirror image showing self exploratory behaviors eddy 
plausible developmental perspective process self recognition goes stage self detection detecting temporal contingencies 
self recognition abilities probably require detailed representation body 
argued differences probably due different degrees self awareness 
reason differences may due absence sufficiently integrated self concept 
reason species pass mirror test direct attention outward external world inwards bodies subject attention humans course developed self exploration abilities create branches science medicine biology genetics 
hypothesis ability detect oneself mirror small manifestation sophisticated system represent body positions space povinelli cant barth 
primary function system control plan body movements 
barth 
claim explain don pass mirror test 
evolutionarily advanced expect opposite true 
answer barth 
ability represent body movements fine level detail developed common ancestor species lived years ago 
lost ability required terrestrial 
hand inherited ability actively support 
large body weight plan movements precisely branch branch avoid falling trees povinelli cant 
furthermore animals elaborate representation bodies elaborate body schemas proficient tool users povinelli 
fact discovered factor best predicts degree tool abilities different primate species ability recognize mirror ability pass mirror test 
habitat food supplies factors predictive 
concluded psychological capacities underlie tools associated underlie mirror inspection 
species animals observed tools see species primates pass mirror test detailed representation body strictly required tool 
barth 
point hypothesis simply explicitly distinction self object represented rapidly tool emerge barth 
similar reached predictions experiments monkeys predict level ability tools positively correlated mirror interest relationship occurs independently capacity self recognition 
predict level ability tools necessary sufficient condition emergence self recognition 
believe mirror aided self recognition reflects cognitive process enables animals fully comprehend properties specific type tool 
self detection robots self detection experiments robots rare 
published studies subject conducted michel gold scassellati 
implemented approach autonomous self detection similar temporal contingency strategy described watson 
robot successful identifying movements generated body 
robot able identify movements hand reflected mirror self generated motion reflection obeyed temporal contingency robot body 
limitation study self detection performed pixel level results carried high level visual features robot body 
permanent trace visual features constitute robot body 
detection performed robot moving 
study chapter goes step keeps probabilistic estimate visual features robot detect belong robot body 
way stimuli classified self robot moving 
limitation michel 
study training procedure estimate efferent afferent delay performed robot moving object environment 
algorithm described section suffer limitation 
team attempted perform self detection experiments robots different self specifying event called double touch yoshikawa 
double touch self specifying event experienced robot touches body 
event experienced robot touches object somebody touches robot cases correspond single touch event 
papers published team far clear results self detection purpose bootstrap robot learning properties objects 
self may identified robustly inputs double touch events motor visual efferent afferent loops combined 
fruitful area research 
problem statement related shows processes self detection self recognition devel oped different developmental schedules influenced number factors 
humans developmental process quite complicated requires years social interactions aspects self fully developed 
robotics implementation described chapter focuses problem autonomous self detection 
words robot learns visual features belong body 
problems self recognition relating self social agents environment addressed 
sake clarity problem autonomous self detection robot stated explicitly notation 
robot set joints 
jn corresponding joint angles 
qn 
joints connect set rigid bodies 
bn impose restrictions bodies move respect 
example joint ji lower upper joint limits qu available robot controller inferred 
joint ji controlled motor command move ji qi takes target joint angle qi start time moves joint target joint angle 
move command active time 
set visual features 
fk robot detect track time 
features belong robot body located outer surfaces set rigid bodies features belong external environment objects 
robot detect positions visual features detect moving point time 
words robot set perceptual functions 
pk pi fi 
say function pi returns feature fi moving time 
goal robot classify set features self 
words robot split set features subsets 
methodology problem self detection robot divided separate problems follows sub problem robot estimate efferent afferent delay delay robot motor actions perceived effects 
sub problem robot efferent afferent delay classify visual features detect self 
methodology solving sub problems illustrated figures 
fig ure shows robot estimate efferent afferent delay sub problem measuring elapsed time start motor command start visual move ment 
approach relies detecting temporal contingency motor commands observed movements visual features 
get reliable estimate delay robot gathers statistical information executing multiple motor commands extended pe time 
section shows approach reliable moving visual features environment movements typically correlated robot motor commands 
delay estimated robot value remembers irreversibly uses solve sub problem 
visual movement movement movement motor command issued efferent afferent delay start visual movement detected visual movement detected perceived visual movement efferent afferent delay defined time interval start motor command efferent signal detection visual movement afferent signal 
goal robot learn characteristic delay called perfect contingency self observation data 
time shows estimated efferent afferent delay classify visual features self sub problem 
shows visual features detected movements time represented red green blue lines 
features feature blue classified self conforms perfect contingency 
feature red begins move late motor command issued feature green begins move soon movement command issued 
visual movement feature visual movement feature visual movement feature average expected efferent afferent delay motor command issued classified moves late time classified moves soon time classified self moves expected self versus discrimination 
robot learned delay value classify visual features detect self feature blue classified self starts move expected efferent afferent delay plus minus tolerance shown brown region 
features classified start move late feature soon feature motor command issued 
time far methodology described similar described michel 

mentioned section approach performs detection pixel level generalize detection results high level perceptual features 
methodology overcomes problem described 
classification single observation unreliable due sensory noise lucky coincidence movements features relative robot motor command 
robot maintains probabilistic estimate feature part robot body 
probabilistic estimate sufficiency necessity indices proposed watson 
sufficiency index measures probability stimulus visual movement occur specified period time action motor command 
necessity index hand measures probability action motor command performed specified period time stimulus visual movement observed 
robot continuously updates indexes feature new evidence available 
features indexes certain threshold classified self classified section provides details procedure 
remaining sections chapter describe individual components necessary solve sub problems self detection 
section summarizes method detecting visual features 
section describes motor babbling procedure robot gather self observation data 
section explains procedure detecting movements visual features 
section describes method learning efferent afferent delay robot experiments test method 
section presents results robot experiments self versus discrimination 
detecting visual features experiments chapter performed robot arm described section 
movements robot restricted vertical plane 
words joints shoulder pitch elbow pitch wrist pitch allowed move see 
joints waist roll wrist roll disabled joint angles set 
mobile base robot disabled linear translations 
experimental setup shown 
color markers called body markers placed body robot shown 
robot body markers located tracked color segmentation see 
position marker determined centroid largest blob matched specific color 
color segmentation performed computer vision code performs histogram matching hsv color space help opencv library open source computer vision package 
digital video camera sony evi mounted tripod field view adjusted see body markers possible joint configurations robot 
image resolution set 
experiments described chapter frames captured frames second 
color tracking notoriously difficult problem computer vision 
course research disproportionately large amount time spent fine tuning color tracker selecting distinct colors experiments 
established empirically colors tracked reliably extended periods time 
colors selected dark orange dark red dark green dark blue yellow light green pink tan orange violet light blue red 
color tracker fine tuned look areas image specific colors 
areas filtered 
important note possible colors ones listed turned impossible track colors time light conditions lab 
tracking results depend ambient light amount time camera turned related operating temperature 
color limit slightly higher colors simulator suffer transient lighting effects color limit higher simulator supports textures shading significantly change appearance uniform colored surfaces 
comparison robots robocup legged league limited colors yellow cyan pink green orange white red blue carefully selected maximize detectability 
color tracking computationally fast convenient method easy place color markers robot objects robot uses 
alternative computationally expensive approach paint body robot different textures track locations unique local features 
experimental setup experiments described chapter 
shows positions colors body markers 
marker assigned number refer marker text figures follow 
left right markers colors dark orange dark red dark green dark blue yellow light green 
color segmentation results frame shown 
motor babbling experiments described chapter rely common motor babbling procedure allows robot gather self observation data visual proprioceptive performing random joint movements 
procedure consists random joint movements similar primary circular reactions described piaget see section directed object environment 
algorithm shows pseudocode motor babbling procedure 
motor babbling robot controller randomly generates target joint vector tries move robot achieve vector 
movements performed adjusting joint angle direction target joint angle 
target joint vector achieved tolerance degrees joint timeout period seconds attempt aborted random joint vector chosen iteration 
procedure repeated specified number iterations random motor commands 
number iterations set experiments described 
algorithm uses functions defined standard pro gramming environments 
min max returns integer number interval min max 
example returns probability 
similarly min max returns random floating point number interval min max 
function abs number returns absolute value pa rameter 
function returns system time function sleep time waits amount time 
addition robot interface represented robot object functions perform operations implied names 
worth noting function asynchronous returns immediately move command issued hardware waiting move finish 
necessary due fact randomly generated joint vectors correspond invalid joint configurations result self collisions 
motor babbling algorithm affected self collisions collision prevents robot reaching randomly generated target joint vector 
timeout period algorithm abandons goal selects target joint vector iteration 
self collisions damage robot avoided possible 
crs arm side effect self collisions power breaker joints triggered 
renders robot unusable power restored 
motor babbling routine modified generate body poses result self collisions change shown algorithm specific robot mounting configuration 
restricted poses represent small fraction possible body poses acceptable solution ensures safety robot compromise validity experimental results 
shows joint configurations randomly selected mo tor babbling procedure 
corresponding color segmentation results track positions robot body markers shown 
algorithm motor babbling robot robot robot robot jv keep current joint angle joint 
jv robot return jv robot robot dist abs robot dist tolerance return false return true robot timeout tolerance ime motor robot motor timestamp repeat robot motor sleep ime motor timestamp timeout reach joint vector 
try iteration 
break done robot motor tolerance done true return motor robot poses selected motor babbling procedure 
color segmentation results robot poses shown 
visual movement detection methods detecting movements visual features color markers tried 
method compared centroid position marker frame 
distance positions empirically established threshold pixels marker declared moving 
course research clear method reliable 
reason body markers move different speeds depending positions robot body 
markers placed robot wrist example move faster markers placed robot shoulder see 
markers located wrist appear start moving sooner markers located shoulder 
opposite result observed movement markers placed shoulder robot appear moving sooner markers placed wrist 
effect observed robot movements executed actively controlled joints start moving time 
problem resolved movement threshold reduced pixels frame pixels frame results total tion quality tracking results 
reason smaller movement threshold approximately magnitude position detection noise marker robot moving markers static see 
movement threshold reduced pixels frame marker movements detected robot moving 
position detection results shown quite decent marker po sitions detected sub pixel accuracy approximately pixels frame 
shows movement detection approach feasible 
movement threshold reduced position detection noise large movement threshold 
impossible distinguish marker movement resulting corresponding robot movement marker move ment resulting detection noise 
method movement detection abandoned experiments 
alternative method described 
second movement detection method overcomes noise problems mentioned performing movement detection fixed interval time longer interval consecutive frames 
method compensate frame frame tracking noise looks movements longer time window 
way movement threshold larger tracking noise 
advantage method sensitive small variations frame rate due system load 
final implementation image frame color marker declared mov ing position changed pixels second interval immediately preceding current frame 
timing intervals calculated timestamps frames stored standard unix format 
result tracking technique binary signal currently visible markers similar graphs shown 
signals slightly noisy filtered box filter called averaging filter width corresponds smoothing tracking signal consecutive frames 
filter changes values movement detection signal average local neighborhood 
example movement detection signal filter output 
hand sequence filter output 
algorithm shows pseudocode movement detector box filter 
marker movement pixels frame average marker movement consecutive frames robot moving direction color markers average marker movement consecutive frames robot moving 
results pixels frame body markers 
marker movement pixels frame average marker movement consecutive frames robot moving color markers average marker movement consecutive frames robot moving 
words shows position detection noise body markers static 
results pixels frame 
algorithm movement detection dist dist threshold return return sequence index sum index index sum sum sequence sum return return nf buffer frames advance ok frame image frame timestamp nf frame image frame timestamp find index frame captured seconds ago frame timestamp index frame timestamp detect marker movements filter data mov frame image frame image mov mov return mov learning efferent afferent delay section describes procedure robot estimate efferent afferent delay self observation data procedure solves sub problem de scribed section 
methodology solving problem described section mathematical formulation section 
different experi mental conditions test delay estimation procedure obtained experimental results described sections 
section describes results section solve problem self versus discrimination sub problem described section 
pseudocode procedure estimating efferent afferent delay robot shown algorithm 
algorithm uses results motor babbling procedure described section uses array motor commands timestamps 
uses results movement detection method described section uses number captured frames move array holds information feature moving frame 
algorithm batch form straightforward rewrite incremental form 
algorithm maintains histogram measured delays interval seconds 
delays longer seconds ignored 
bin histogram corresponds th second equal time interval consecutive frames 
frame algorithm checks markers starting move frame 
information stored move array returned function algorithm 
start movement detected algorithm finds motor command executed prior current frame 
timestamp motor command subtracted timestamp current frame resulting delay update histogram 
histogram update frame allowed bin count bin incremented 
restriction ensures large object moving parts robot field view object movements bias histogram confuse detection process 
code histogram routines shown algorithm algorithm 
algorithm learning efferent afferent delay nf frame mov motor skip frames captured prior motor command 
start frame start timestamp motor timestamp start start create histogram bin size th second time interval seconds 
hist idx index array motor commands start nf check new motor command issued 
frame timestamp motor idx timestamp idx idx transition start movement 
mov mov delay frame timestamp motor idx timestamp hist delay break histogram update frame allowed threshold histogram peak value 
hist threshold hist threshold threshold efferent afferent delay hist return efferent afferent delay algorithm histogram code min max nbins simplify code additional bins reserved bin bin nbins 
bins hold values min greater max 
bin new int nbins indexes 
nbins nbins limit new double nbins indexes 
nbins nbins initialize bin boundaries step max min nbins limit min nbins limit limit step limit nbins max limit nbins nbins bin value nbins value limit bin bin break min maxint nbins bin min min bin return min max nbins bin max max bin return max algorithm histogram code continued threshold threshold nbins bin threshold bin bin bin threshold count sum nbins count count bin sum sum bin limit limit return sum count function algorithm 
count sum sum nbins count count bin middle limit limit sum sum bin middle sum sum bin middle middle count return return sum sum sum count count function algorithm 
variance return variance delays measured algorithm finds bin largest count corresponds peak histogram 
reduce effect noisy histogram updates histogram thresholded empirically derived threshold equal peak value 
example largest bin count threshold set 
histogram thresholded mean delay estimated multiplying bin count bin corresponding delay adding products dividing sum total bin count see pseudocode algorithm 
reasons histogram approach selected 
reason keeping histogram algorithm uses fixed amount memory 
alter native store measured delays calculate mean entire data sample 
alternative approach estimate mean delay accurately calculations biased values outliers created noisy readings 
order eliminate outliers sort thresholding required way equivalent histogram method 
second reason histogram method related findings bio logical brains large number neuron delay detectors specifically dedicated measuring timing delays gallistel gibbon 
supposedly detectors fine tuned detect specific timing delays 
way think bins histogram bank detectors responsible detecting specific timing delay 
value mean delay useful measured delays exact value 
mentioned section order classify visual features self measured delay feature tolerance interval mean 
interval shown brown region 
way determine tolerance interval calculate standard deviation measured delays classify feature self movement delay lies standard deviation mean 
words feature classified self 
standard deviation calculated histogram shows algo rithm 
histogram thresholded estimate reliable delays outliers eliminated 
case standard deviation small useful 
hand histogram thresh estimate standard deviation large useful calculated entire data sample includes outliers 
correct estimation standard deviation trivial task 
especially true robot moving object environment see 
fortunately psychophysics literature provides elegant solution problem 
turns discrimination abilities timing delays animals humans obey called weber law gibbon 
law named german physician ernst heinrich weber experimental psychologists 
weber observed sensory discrimination abilities humans depend magnitude stimulus trying discriminate 
example hypothetical numbers explain weber law 
suppose friend asks lift weight remember effort involved 
lift weight notice force pulls hand 
trial friend adds additional knowledge asks lift weight tell feel difference 
lift weight feel difference 
third trial friend adds additional asks try 
feel difference confidently say new weight heavier 
takes weight difference feel difference 
experiment performed starting weight find additional weight equal tell difference 
words magnitude just noticeable difference different case versus 
cases value equal original weight 
similar example www cis rit edu people faculty pages chap ch html mathematical notation weber law stated represents magnitude stimulus value just noticeable difference constant depend value fraction known weber fraction 
law implies difference signals detected difference weber fraction 
weber law predict difference stimuli detected 
stimuli indistinguishable inequality holds constant depend values robot experiments described similar discrimination rule mean efferent afferent delay currently measured delay motor command perceived visual movement constant depend 
neural mechanisms weber law unknown numerous experiments shown animals humans obey law 
fact law applies virtually sensory discrimination tasks distinction colors bright ness aguilar stiles distances sounds weights time gibbon 
furthermore timing discrimination tasks just noticeable difference approximately equal standard deviation underlying timing delay 
distributions property know scalar distributions standard ation scalar multiple mean gibbon 
result prominent theories timing interval learning gibbon gibbon church gallistel gibbon 
problem reliably estimate standard deviation measured efferent afferent delay trivial 
standard deviation simply equal constant multiplied mean efferent afferent delay 
value parameter determined empirically 
timing discrimination tasks pigeons value estimated catania 
estimates different animals range 
robot experiments described value set 
worth mentioning robotic implementation self detection rely weber law 
robot controlled computer internal clock precision 
problem reliably estimating standard deviation timing delays remains 
decided implications weber law order solve eliminate problem 
solution proposed biologically plausible computationally efficient 
subsections follow describe different experimental conditions test procedure estimating efferent afferent delay robot self observation data algorithm 
test conditions summarized table 
table experimental conditions described subsections 
test condition description section single robot ideal test conditions 
robot moving object environment object perceptual features 
section single robot static robot moving object section background features environment static environmental features robot detect 
robots robot longer moving object 
section lated movements movements second robot independent movements robot 
robots moving robots section ing movements environment 
second robot mimics movements robot 
experiments single robot frames test sequence robot moving object 
set experiments tested algorithm ideal conditions robot moving object environment see 
furthermore robot object environment detectable visual features color markers 
experimental data consists datasets collected running mo tor babbling procedure iterations 
dataset entire sequence frames captured camera converted jpg files saved disk 
frames recorded frames second resolution pixels 
dataset corre sponds roughly minutes wall clock time 
time limit selected data dataset fit single dvd storage capacity gb 
frame timestamp denoting time frame captured precisely timestamp indicates time frame stored computer memory transfered capture card 
motor commands timestamps saved part dataset 
results reported section datasets 
results useful take look raw data gathered datasets 
shows histogram measured efferent afferent delays dataset 
shows representation dataset 
bin histograms corresponds th second equal time consecutive frames 
seen histograms average measured delay approximately second 
delay may relatively large unavoidable due slowness robot controller 
robot faster controller may shorter delay 
comparison average efferent afferent delay reported advanced robot michel 
seconds 
figures sum bin values greater histograms greater number motor commands dataset 
possible motor command algorithm may increment bin count bin 
algorithm allow multiple bin updates frame possible body markers may start move consecutive frames result histogram updates 
addition false positive movements detected due sensory noise contribute effect 
histograms preserve shape histogram update motor command allowed see figures 
measured delays consistent different body markers 
figures show average measured delays body markers corresponding standard deviations 
expected markers similar delays small variations statistically significant 
algorithm estimated efferent afferent delays datasets seconds dataset seconds dataset 
estimates close 
difference th second equivalent half frame see column table 
comparison table shows average efferent afferent delays calculated raw delay data 
seen table second method slightly overestimates peak histogram calculations affected noisy readings 
algorithm offers reliable estimate efferent afferent delay see figures 
table mean efferent afferent delay dataset dataset estimated different methods 
algorithm raw data mean delay dataset mean delay dataset number times start movement detected number times start movement detected measured efferent afferent delay dataset seconds histogram measured efferent afferent delays dataset 
measured efferent afferent delay dataset seconds histogram measured efferent afferent delays dataset 
number times start movement detected measured efferent afferent delay dataset seconds histogram measured efferent afferent delays dataset 
histogram shown bins histogram updated motor command 
earliest detected movement motor command 
number times start movement detected measured efferent afferent delay dataset seconds histogram measured efferent afferent delays dataset 
histogram shown bins histogram updated motor command 
earliest detected movement motor command 
average efferent afferent delay seconds color markers average efferent afferent delay corresponding standard deviation body markers calculated dataset 
average efferent afferent delay seconds color markers average efferent afferent delay corresponding standard deviation body markers calculated dataset 
experiments single robot static background features frames form test sequence static background markers 
second experimental setup tested algorithm presence static visual fea tures placed environment 
addition robot body markers markers placed background wall see 
background markers remained static experiment possible occluded temporarily robot arm 
robot controlled motor babbling procedure 
new dataset motor commands collected procedure described section 
shows delay histogram dataset 
histogram similar histograms shown previous subsection 
noticeable difference bins case values 
due detection false positive movements background markers filtered box filter 
main reasons necessary threshold histogram 
similar pronounced effect observed section background markers allowed move 
shows false positive movements exhibit uniform dis tribution interval seconds 
expected correlated motor commands robot 
drop seconds due fact robot executes new motor command approximately seconds 
false positive movements background markers detected second interval associated motor command 
table shows mean efferent afferent delay standard deviation mea different ways 
shown table algorithm performs better method uses raw data overestimates value delay seconds 
second method overestimates value standard deviation estimating seconds 
explained section algorithm underestimates value standard deviation 
problem decision curve self versus discrimination constructed weber law requires mean estimated correctly 
discrimination threshold set mean 
table estimates mean standard deviation efferent afferent delay dataset background markers 
number times start movement detected algorithm raw data mean stdev measured efferent afferent delay seconds histogram measured efferent afferent delays robot static background markers see 
bin corresponds th second 
due false positive movements detected background markers bins histogram values 
see text details 
experiments robots uncorrelated movements frames test sequence robots movements robots uncorrelated 
robot controlled separate motor babbling routine 
robot left trying estimate efferent afferent delay 
sets experiments designed test robot learn efferent afferent delay situations robot moving object envi ronment 
case moving object introduced robot arm placed field view robot 
test conditions vary de gree correlation movements robots follows uncorrelated movements mimicking movements 
test conditions new dataset motor commands generated 
shows frames dataset corresponding test condition 
second test condition described subsection 
experiments described small technical clarification 
robot available perform sets experiments second robot generated digital video special effect 
frame robots composite frames robot frames taken datasets described section 
robot left position previous datasets 
order get robot right left part second frame cropped flipped horizontally translated pasted top right part frame 
similar experimental designs quite common self detection experiments infants watson watson 
studies infants placed front tv screens 
screen infants see leg movements number times start movement detected measured efferent afferent delay seconds histogram measured delays motor commands observed visual movements test sequence robots movements uncorrelated see 
captured camera 
second screen see movements infant recorded previous experiment 
shows experimental setup robots 
test condition movements robots uncorrelated 
frames test sequence generated combining frames dataset dataset described section 
motor commands robot left come dataset robot right comes dataset 
motor babbling sequences different random seed values movements robots uncorrelated 
frames robot left trying estimate efferent afferent delay 
shows histogram measured delays sequence 
seen histogram values bins 
clearly defined peak shape position previous test cases taken ideal conditions 
algorithm estimated efferent afferent delay number times start movement detected measured efferent afferent delay seconds contributions bins histogram shown movements second robot 
histogram shows movements second robot occur possible times motor command robot 
drop seconds due fact robot performs motor command approximately seconds 
subsequent movements second robot second interval matched motor command robot 
histogram thresholded threshold equal peak value 
comparison table shows mean delay estimated raw data significantly overestimated see 
table shows value standard deviation calculated methods 
algorithm underestimates value method overestimates 
movements second robot uncorrelated motor commands robot detected movements body markers second robot scattered bins histogram 
movements second robot confuse algorithm picking wrong value mean efferent afferent delay 
presents closer look measured delays motor commands robot movements body markers second robot 
histogram table estimates mean standard deviation efferent afferent delay dataset robots 
algorithm raw data mean stdev shows movements exhibit uniform distribution interval seconds 
drop seconds due fact robot performs new movement approximately seconds 
movements performed second robot second interval associated motor command robot 
results show moving objects environment possible robot learn efferent afferent delay 
instances body markers second robot detected move perfect contingency significantly instances start move early late 
timing difference movements background object represented noise histogram 
minimize chance wrong efferent afferent delay developmental period characteristic delay learned increased 
fact watson period lasts approximately months humans 
current set robot experiments shown motor commands minutes real time data sufficient estimate delay reliably test conditions described section 
subsection explores happens independence condition robots violated second robot mimics 
experiments robots mimicking movements frames test sequence robots robot right mimics robot left 
mimicking delay frames seconds 
test condition second robot right mimicking robot left 
mimicking robot starts move frames seconds robot 
dataset motor commands constructed frames dataset described section offsetting left right parts image frames 
mimicking delay resulting histogram see fig ure bimodal 
left peak centered second produced body markers robot 
right peak centered seconds produced body markers second robot 
algorithm deal situations selects delay peaks see table 
calculating mean delay raw data produces mean estimate peak values 
table estimates mean standard deviation efferent afferent delay mimicking dataset robots 
algorithm raw data mean stdev possible modify algorithm avoid problem choosing peak corresponds shorter delay example 
evidence animal studies shows multiple time delays associated food rewards reinforced animals learn mean reinforced distribution lower limit gibbon reinforced delays generated different underlying distributions animals learn mean associated mixture model distributions 
algorithm left unmodified 
reason leave algorithm intact exists mimicking test condition degenerate case highly occur real situation robots independent 
negative result undermine usefulness algorithm learning efferent afferent delay 
probability independent robots perform sequence movements extended period time effectively zero 
continuous mimicking extended periods time certainly situation humans animals encounter real world 
results mimicking robot experiments suggest interesting study conducted monkeys provided brain detecting interpreting signals motor neurons infant monkey available 
decoded signals send movement commands robot arm move shortly monkey arm 
period watson suggests efferent afferent delay learned monkey able function properly occurs implant removed 
number times start movement detected measured efferent afferent delay seconds histogram measured delays motor commands observed visual movements mimicking test sequence robots see 
left peak produced movements body markers robot 
right peak produced movements body markers second mimicking robot 
self versus discrimination previous section examined possible robot learn efferent afferent delay self observation data sub problem described section 
section examines robot delay label visual features detects self belonging robot body belonging external world 
words section formulates tests approach sub problem described section 
methodology solving problem described section mathematical formulation section 
different experimental conditions test approach obtained experimental results described sections 
basic methodology performing discrimination shown fig ure 
concrete implementation visual field view robot seg mented features movements detected method described section 
feature robot maintains independent probabilistic estimates jointly determine feature belong robot body 
probabilistic estimates necessity index sufficiency index described watson 
necessity index measures feature moves consistently motor command 
sufficiency index measures movement feature corresponding motor command precedes 
formulas probabilities 
necessity index sufficiency index number temporally contingent movements number motor commands number temporally contingent movements number observed movements feature shows example visual features calculated necessity sufficiency indexes 
motor commands feature red necessity index contingent movement motor commands sufficiency index contingent movement observed movements 
feature green necessity index con movements motor commands sufficiency index contingent visual movement feature visual movement feature visual movement feature motor command issued delay delay motor command issued time time shows calculated values necessity ni sufficiency si indexes visual features 
motor commands feature observed move twice movements contingent robot motor commands 
feature necessity sufficiency index 
movements feature contingent motor commands movements temporally contingent 
feature equal movements contingent robot motor commands 
movements observed movements half movements contingent 
feature blue necessity index contingent movements motor commands sufficiency index contingent movements observed movements 
results robot classify feature self necessity sufficiency indexes equal 
features classified feature fi robot maintains necessity index ni sufficiency index si 
values indexes time ni si 
values indexes calculated maintaining counters ci mi ti 
definitions follows ci represents number motor commands executed robot start time current time mi number observed movements feature fi time time ti number temporally contingent movements observed feature fi time counters trivial calculate 
third counter ti incremented time feature fi detected move mi mi time movement delay relative motor command approximately equal mean efferent afferent delay plus minus tolerance interval 
words di ti mi mi ti ti estimate mean efferent afferent delay di delay currently detected movement feature fi motor command constant 
value independent di equal weber fraction see section 
inequality formula essentially defines width decision region see brown regions 
notation values necessity sufficiency indexes time calculated follows ni ti ci si ti mi indexes updated time new evidence available new motor command issued feature observed move 
belief robot fi part body time jointly ni si 
robot classify feature fi threshold values greater threshold value feature fi classified self 
words ni si fi ideally ni si 
practice rarely case sensory noise filtered 
robot experiments threshold value set empirically derived value 
subsections follow test approach self versus discrimination number experimental situations 
set experiments assumed robot estimated efferent afferent delay required classify features self delay 
test situations ones described previous section 
experiments follow value mean efferent afferent delay set 
value equal average means calculated datasets described sections rounded deci mal points 
value set 
visual movement classified temporally contingent motor command measured delay seconds 
subsections follow describe different experimental conditions test procedure self discrimination described 
test conditions summarized table 
test conditions described section 
case goal robot learn efferent afferent delay 
goal classify different visual features self table experimental conditions described subsections 
test condition description section single robot ideal test conditions 
robot moving object environment object perceptual features 
section single robot static robot moving object section background features environment static environmental features robot detect 
robots robot longer moving object 
section lated movements movements second robot independent movements robot 
robots moving robots section ing movements environment 
second robot mimics movements robot 
experiments single robot test condition described section uses datasets derived motor babbling commands 
case robot estimate efferent afferent delay seconds required classify markers self 
datasets don contain background markers robot classify markers self experiments show case 
shows value sufficiency index calculated time body markers dataset 
shows thing dataset 
mentioned values equal long period time due sensory noise 
figures demonstrate sufficiency indexes markers datasets greater value threshold 
interesting observation plots initial adaptation period approximately minutes values indexes stabilize don change see 
suggests indexes calculated running window entire dataset similar results 
oscillations minutes trial shown due fact counters index values initially start zero 
values counters relatively small single noisy update counter results large changes value fraction calculate specific index difference large difference 
shows value necessity index calculated time markers dataset 
shows thing dataset 
figures show necessity indexes consistently threshold body markers yellow green 
may surprising markers part robot body similar values necessity indexes 
reason result robot different joints affected motor babbling routine see algorithm 
motor command moves joints independently joints 
furthermore motor commands executed simultaneously 
robot total different types motor commands 
binary notation commands labeled 
notation corresponds motor command moves wrist joint moves elbow joint moves joints time 
note valid command move joints 
markers located wrist move motor command 
markers located shoulder observed move motor commands 
markers observed move motor commands necessity index close approximately see 
example shows probability necessity may computed cor rectly may competing causes 
fact observation supported fact statistical inference literature pearl 
necessity causation concept tailored specific event consideration singular causation suf ficient causation general tendency certain event types produce event types pearl 
distinction watson concerned discrete motor actions kicking kicking tacitly assumed infants kick legs simultaneously 
probability necessity may identifiable general case possible calculate possible motor commands 
accommodate fact necessity indexes ni conditioned motor commands notation augmented superscript stands possible types motor commands 
necessity index associated feature fi calculated th motor command time values necessity index feature fi calculated possible motor commands total number motor commands type performed time number movements feature fi temporally contingent motor commands type calculation sufficiency indexes remains 
change notation marker classified self time sufficiency index si greater exists type motor command 
words fi si shows values necessity index body markers calculated time dataset new notation 
graph shows lines correspond possible motor commands 
seen marker motor command necessity index greater threshold 
markers correctly classified self displays similar results dataset 
worth noting approach described relies identifying joints participate motor command markers observed start moving shortly motor command 
type robot movement fast slow fixed speed variable speed long marker moving result affect results produced approach 
subsections test approach different experimental conditions 
sufficiency index time minutes shows value sufficiency index calculated time body markers 
index value markers threshold 
values calculated dataset 
sufficiency index time minutes shows value sufficiency index calculated time body markers 
index value markers threshold 
values calculated dataset 
necessity index time minutes value necessity index calculated time body markers dataset 
calculation differentiate type motor command performed 
markers classified self index values threshold 
solution problem shown see text details 
necessity index time minutes value necessity index calculated time body markers dataset 
calculation differentiate type motor command performed 
markers classified self index values threshold 
solution problem shown see text details 
necessity index necessity index necessity index time minutes marker time minutes marker time minutes marker necessity index necessity index necessity index time minutes marker time minutes marker time minutes marker figures shows values necessity index body markers dataset 
shows lines correspond possible types motor commands 

considered classification self marker necessity index motor command trial 
markers classified self dataset 
necessity index necessity index necessity index time minutes marker time minutes marker time minutes marker necessity index necessity index necessity index time minutes marker time minutes marker time minutes marker shows values necessity index body markers dataset 
shows lines correspond possible types motor commands 

considered classification self marker necessity index motor command trial 
markers classified self dataset 
experiments single robot static background features test condition described section 
addition robot body markers additional markers placed background wall see fig ure 
robot performed motor babbling motor commands 
dataset recorded purposes section 
table shows classification results test 
results demonstrate clear distinction sets markers markers classified correctly self background markers classified correctly background markers labeled clockwise starting upper left marker red 
colors red violet pink tan orange light blue 
table values necessity sufficiency indexes trial 
classification marker shown column 
marker max si threshold classification actual self self self self self self self self self self self self values sufficiency indexes calculated time shown body markers background markers 
necessity indexes motor commands shown 
background markers marker temporarily occluded robot arm increases position tracking noise 
results detection occasional false positive movements markers 
necessity indexes equal zero case marker 
trial maximum necessity index background markers correctly classified sufficiency index time minutes sufficiency index body markers 
markers index value threshold 
true necessity indexes shown 
body markers classified self sufficiency index time minutes sufficiency index static background markers 
markers index value threshold 
true necessity indexes shown 
background markers classified necessity index necessity index necessity index time minutes marker time minutes marker time minutes marker necessity index necessity index necessity index time minutes marker time minutes marker time minutes marker necessity index body markers 
shows lines correspond possible types motor commands 

considered classification self marker necessity index motor command trial 
true body markers shown 
correctly classified self necessity index necessity index necessity index time minutes marker time minutes marker time minutes marker necessity index necessity index necessity index time minutes marker time minutes marker time minutes marker necessity index background markers 
shows lines correspond possible motor commands 

considered classification self marker necessity index motor command trial 
true background markers shown 
correctly classified experiments robots uncorrelated movements experimental condition described section 
dataset recorded purposes section 
self detection algorithm works expected markers classified self markers 
markers classified table shows algorithm performs satisfactorily 
shows sufficiency indexes body markers robot trying perform self versus discrimination left robot 
expected index values close 
shows sufficiency indexes body markers second robot 
movements second robot correlated motor commands robot values close zero 
shows necessity indexes body markers robot motor commands 
expected indexes greater motor command 
shows markers second robot 
case necessity indexes close zero 
markers correctly classified table values necessity sufficiency indexes trial 
markers classified correctly self marker max si threshold classification actual self self self self self self self self self self self self sufficiency index time minutes shows sufficiency indexes body markers robot left robot 
expected values close threshold 
true necessity indexes shown 
markers robot classified self sufficiency index time minutes shows sufficiency indexes body markers second robot right robot 
expected values close threshold 
true necessity indexes shown 
markers second robot classified necessity index necessity index necessity index time minutes marker time minutes marker time minutes marker necessity index necessity index necessity index time minutes marker time minutes marker time minutes marker necessity index body markers robot 
shows lines correspond possible types motor commands 

considered classification self marker necessity index motor command trial 
true body markers shown 
correctly classified self case 
necessity index necessity index necessity index time minutes marker time minutes marker time minutes marker necessity index necessity index necessity index time minutes marker time minutes marker time minutes marker necessity index body markers second robot 
shows lines correspond possible types motor commands 

considered classification self marker necessity index motor command trial 
true body markers second robot shown 
correctly classified case 
experiments robots mimicking movements test condition described section 
mean efferent afferent delay experiment set seconds 
note value different wrong value seconds estimated degenerate case section 
table shows values necessity sufficiency indexes minute interval 
expected sufficiency indexes body markers robot close see 
similarly necessity indexes close motor command see 
body markers second robot situation just opposite 
shows sufficiency indexes calculated time 
shows sufficiency indexes calculated possible motor commands 
somewhat surprisingly mimicking test condition turned easiest classify 
second robot start move fixed interval time robot temporally contingent movements detected body markers 
necessity sufficiency indexes markers second robot equal zero 
marker exception counterpart marker position detection see 
table values necessity sufficiency indexes trial 
markers classified correctly self case 
marker max si threshold classification actual self self self self self self self self self self self self sufficiency index time minutes shows sufficiency indexes calculated time body markers robot mimicking dataset 
expected values close threshold 
true necessity indexes shown 
markers robot classified self sufficiency index time minutes shows sufficiency indexes calculated time body markers second robot mimicking dataset 
expected values close threshold 
true necessity indexes shown 
markers robot classified necessity index necessity index necessity index time minutes marker time minutes marker time minutes marker necessity index necessity index necessity index time minutes marker time minutes marker time minutes marker necessity index body markers 
shows lines correspond possible types motor commands 

considered classification self marker necessity index motor command trial 
true body markers shown 
correctly classified self necessity index necessity index necessity index time minutes marker time minutes marker time minutes marker necessity index necessity index necessity index time minutes marker time minutes marker time minutes marker necessity index body markers 
shows lines correspond possible types motor commands 

considered classification self marker necessity index motor command trial 
true body markers second robot shown 
correctly classified case 
self detection tv monitor frames tv sequence 
tv image shows real time movements robot captured camera different robot camera 
section describes experiment tests robot estimated efferent afferent delay methodology described section detect image shown tv monitor image body 
experiment inspired similar setups watson self detection experiments infants 
experiment described section adds tv monitor existing setup shown 
tv image displays movements robot real time captured camera different robot camera 
detailed description experimental setup section uses self detection results described achieve video guided robot behaviors 
new data set movement commands gathered experiment 
similarly previous experiments robot control motor babbling procedure 
dataset analyzed way described previous sections 
difference position detection tv markers slightly noisy previous datasets 
raw marker position data averaged consecutive frames smallest number required proper averaging 
marker movements shorter frames duration ignored 
results sufficiency necessity indexes robot body markers similar described previous sections discussed 
section describe results images body markers tv monitor refereed tv markers tv tv 
tv 
frames tv sequence body markers visible tv image due limited size tv screen 
shows sufficiency indices calculated tv markers 
somewhat surprisingly sufficiency indexes half markers exceed threshold value markers belong robot body projected real time tv monitor 
reason simple size tv image 
real body markers seen robot camera body poses projections body markers tv image seen robot specific body poses 
body poses robot arm high low markers observed tv monitor 
shows frames tv sequence demonstrate clearly 
actual visibility values tv markers follows tv tv tv tv tv tv 
contrast robot markers visible time 
result prompted modification formulas calculating necessity sufficiency indexes 
addition account specific motor command self detection algorithm take account visibility markers 
previous test cases body markers visible body configurations subject occasional transient sensory noise 
visibility considered implicitly included detection marker movements 
complicated robots humanoids visibility markers taken account 
robots body poses may able see body parts hand back 
address visibility issue changes way necessity sufficiency indexes calculated 
marker new variable vi introduced value th marker visible time 
robot checks visibility marker time interval immediately motor command 
th motor command issued time tk st command issued time tk 
tk tk tk time th motor command longer considered contingent visual movements 
words tk tk average efferent afferent delay estimate standard deviation calculated weber law see section 
th marker visible time interval tk tk tk vi tk tk movements marker ignored time interval tk tk motor commands 
words counters ti ci mi associated marker calculate necessity sufficiency indexes updated motor command 
visibility correction sufficiency indexes images tv markers threshold shown 
exception yellow marker tv sufficiency index correcting visibility 
reason marker color appears similar background wall tk tv image 
result position tracking noisier 
shows values necessity indexes tv markers visibility correction 
values visibility correction shown 
previous sections necessity values exceed threshold robot correct type motor command issued 
necessary markers shoulder affected motor commands remain static 
move specific motor commands move shoulder joint 
shows necessity indexes calculated type motor command tv marker visibility markers account 
seen tv markers correctly classified self trial sufficiency index greater necessity index greater motor command 
marker classified self yellow marker reasons explained 
results section offer insight studies self detection animals humans visibility features taken account calculating probabilities necessity sufficiency 
previous studies infants watson watson tacitly assumed required features visible times 
results section demonstrate best knowledge experiment self detection robot tv monitor 
section builds results section shows achieve video guided robot behaviors 
sufficiency index time minutes sufficiency indexes calculated time tv markers 
results calculated visibility markers account 
sufficiency index tv tv tv tv tv tv time minutes sufficiency indexes calculated time tv markers 
results calculated visibility markers account 
tv tv tv tv tv tv necessity index time minutes necessity indexes calculated time tv markers 
results calculated visibility markers account 
necessity index tv tv tv tv tv tv time minutes necessity indexes calculated time tv markers 
results calculated visibility markers account 
tv tv tv tv tv tv necessity index necessity index necessity index time minutes marker tv time minutes marker tv time minutes marker tv necessity index necessity index necessity index time minutes marker tv time minutes marker tv time minutes marker tv values necessity index tv markers 
shows lines correspond possible types motor commands 

considered classification self marker trial necessity index motor command graphs calculated visibility tv markers account 
chapter summary chapter described methodology autonomous self detection robot 
methodology detection temporal contingency motor com mands efferent signals visual movements afferent signals estimate efferent afferent delay robot 
shown robot estimate efferent afferent delay self observation data gathered robot performs motor bab random joint movements similar primary circular reactions described piaget 
shown self detection algorithm performs experimental conditions described chapter 
chapter introduced method feature level self detection ideas described watson 
method maintains probabilistic estimate fea tures belong robot body 
probabilities estimated probabilistic estimates necessity sufficiency 
method successfully robot detect self image tv monitor 
results section show watson ideas suitable application robots 
implementation details watson foresee applicable experimental setups infants 
example size tv image imposes restriction body markers seen body poses 
correcting visibility values necessity sufficiency indexes exhibit medium levels contingency 
factor mentioned watson self detection algorithm take account types motor commands issued body markers moved motor command 
correction necessity indexes reach near perfect values greater robot experiments required successful self detection 
modifications implemented tested successfully robot 
experimental results described chapter show robot successfully distinguish body external environment 
results directly support research question stated section 
robot able correctly classify different visual stimuli self chapter builds self detection uses self detection results construct sensorimotor model robot body 
model includes sensations color markers classified self chapter vi extendable robot body schema sense body probably important senses studied 
complex sense combines information coming somatosensory visual sensors build model body called body schema 
shown brain keeps constantly updates model order register location sensations body control body movements head holmes berthoz 
studies neuroscience shown model body static extended objects attached body clothes tools iriki 
may case far brain concerned boundary body coincide anatomical boundaries iriki ramachandran 
chapter describes computational model robot body schema prop erties similar biological analog 
robot learns body schema representation combining visual proprioceptive information 
resulting representation scaled rotated translated 
morphing properties body schema accommodate attached tools 
achieve video guided behaviors described chapter 
related related neuroscience notion body schema suggested head holmes studied perceptual mechanisms humans perceive bodies 
define body schema postural model body model surface body 
perceptual model body formed combining information somatosensory visual sensors 
suggested brain uses model order register location sensations body control body movements 
indirect evidence supporting existence body schema comes numerous clinical patients experience disorders perceiving parts bodies lacking sensations feeling sensations wrong place head holmes 
phenomenon called phantom limb reported feel sensations pain coming limb ramachandran rogers ramachandran 
direct evidence existence body schema provided studies brain imaging techniques identify specialized regions primate human brain responsible encoding iriki 
studies shown body movements encoded terms body schema berthoz 
case reflex behaviors berthoz 
interesting property body schema static modified extended dynamically short periods time 
extensions triggered non objects clothes tools 
example head holmes suggest feather woman hat affects ability move localize environment 
body schema tied anatomical boundaries 
actual boundaries depend intended body parts external objects attached body 
inclusion inanimate objects body schema temporary phenomenon contingent actual objects 
example people drive car get feeling boundary car part body schultz 
get car body schema goes exact term postural scheme 
term body schema pick popular published monograph german entitled das 
back normal 
cases possible permanent modification body schema established objects wedding rings worn extended periods time 
suggested body schema plays role acquisition tool behaviors head holmes 
studies conducted primates support hypothesis iriki 
iriki 
trained macaque monkey retrieve distant objects rake recorded brain activity monkey tool 
discovered large number bimodal neurons sensitive visual somatosensory stimuli appear code schema hand iriki 
tool receptive fields rf neurons centered hand 
tool somatosensory rf stayed visual rf altered include entire length rake cover expanded accessible space iriki 
modification visual receptive field limited time tool usage conditional intention tool 
monkey stopped tool continued hold tool visual rf contracted back normal iriki 
follow study monkey prevented directly observing actions feedback camera image projected video monitor 
case visual rf bimodal neurons projected video screen iriki 
studies suggest encoding body schema brain extremely tools easily incorporated 
studies conducted humans reached similar 
addition tools body schema modified limbs patients 
patients incorporate limb body schema way perform similar tasks real limb 
unfortunately little known neural organization body schema pri mate brains 
study quite striking unexpected discoveries reject previous theories organization map body control body movements 

primary motor premotor cortex monkeys behaviorally relevant time scales ms 
previous studies established stimulation areas produces muscle stimulation times quite short 
longer stimulation times allowed true purpose areas revealed stimulation behaviorally relevant time scale evoked coordinated complex postures involved joints 
example stimulation site caused mouth open caused hand shape grip posture move mouth 
stimulation site drove joints final posture regardless direction movement required reach posture 
stimulation cortical sites evoked different postures similar results obtained facial expressions stimulation particular site produced final facial expression regardless initial facial expres sion 
similar results obtained monkeys accuracy final postures case precise 
interesting observation obstacles completely ignored arm movements induced 
obstacle trajectory starting posture final posture hand try go straight obstacle exist 
results led 
conclude sites primate brain form coherent map workspace body 
important realization map plays active part formation execution kinds movements 
achieving complex postures involving multiple joints may highly complex task consequence encoding map 
interpolation different building blocks map final postures produce highly coordinated movements multiple joints 
section describes computational model self organizing body schema bos developed morasso adopted extended chapter 
model displays similar properties observations 
equivalent final postures called body icons model morasso 
body icon stimulated acts attractor causing joint configuration robot converge described body icon 
extension bos model motivated findings iriki introduced section model extensibility robot body schema 
related robotics robotics body schemas infancy papers attempted tackle subject 
yoshikawa 
formulated fully connected neural network model identified common firing patterns tactile visual tive sensors 
model capable making right associations sensory modalities lacked extensibility properties 
kuniyoshi describe method changing prop erties robot controller inverse kinematics accommodate attached tools 
extension triggered coincidence firing tactile sensors hand grasping tool diminishing visual distance free tool visual landmark 
extension method requires direct physical contact object 
chapter builds previous introduced com putational model extendable robot body schema rbs 
model uses visual proprioceptive information build representation robot body 
visual com ponents representation allowed extend boundaries robot body 
proprioceptive representation remains fixed times robot perform visually guided tool movements extended body 
previous study extension rbs triggered tactile sensations generated objects attached robot body tools 
novel extension mechanism described triggered temporal contingency actions robot observed movements attached object self movements video image see section direct physical contact longer required 
self organizing body schema bos model computational model chosen implementation robot body schema self organizing body schema bos model introduced morasso san 
section provides brief summary bos model interprets terms existing robotics research 
sections follow modify extend bos model extensibility properties 
bos model introduced help notation 
robot joints controlled kinematic configuration vector 
qm qi represents target joint angle 
furthermore set distinct visual features fn surface robot body uniquely identified robot vision system 
position feature fi camera centric ordinates denoted vi set vectors body markers denoted 
vn 
angles configuration space robot subset cartesian product joint 
qm sensor space sensory stimuli coming robot body subset cartesian product perceptual vectors 
vn main idea rbs representation link configuration space sensor space robot cs space cs space 
space identify current robot configuration plan robot movements 
previous approaches described robotics literature noted usefulness space planning specifying robot movements herv sharma sharma 
algebraic techniques express space dimensional manifold hard simple robots sharma 
current approach uses non parametric statistical techniques approximate cs space described 
robot body schema model built concept body icon 
body icon tuple vi representing kinematic sensory components specific joint configuration pose robot variables represent fixed estimates 
large number empirically learned body icons vi 
represent robot body schema table 
believed brain uses similar representation encoded cortical map morasso 
table body icons table 
row table represents body icon consists fixed estimates kinematic sensory vectors associated specific body pose 
kinematic sensory components components 




qi 
qi vi vi 
vi example consider planar robot rigid limbs rotational joints shown limbs lengths 
joints rotate degrees 
robot body markers 
marker red marker placed elbow robot 
marker green marker placed free second limb 
positions body markers vectors 
lie dimensional space defined camera image 
sensory vector see 
kinematic joint angle vector see 
table shows sensory kinematic components body icons associated sample body poses joint robot 
robot performs different movements positions markers camera coordinates keep changing 
time robot learn marker positions corre joint angles learn new body icons 
number body icons increased body icons table begins approximate working envelope robot 
shows elements observed sensory vectors vi body icons camera robot joint robot example 
robot body markers joint angles 
coordinates body body markers visual space vectors 
motor vector robot configuration shown 
table sample body icons table robot shown row table represents kinematic visual vectors specific robot pose 
visual vectors expressed coordinate system centered rotational joint robot 
body kinematic sensory pose components components vi vi 

points represent subset possible positions red elbow marker 
similarly shows positions elements visual vectors vi 
points represent subset possible positions green wrist marker 
joint angle vectors points lying inside square 
sensory vectors vi body poses robot shown 
observed positions red body marker observed positions green body marker 
shows joint vectors correspond sensory vectors shown 
point represents qi joint vectors 
second example demonstrate body schema representation uses crs robot manipulator described section 
learn body representation robot performs motor babbling procedure described section 
shows body poses picked motor babbling procedure 
previous experiments robot color markers placed body 
positions markers tracked computer vision code color histogram matching see section 
shows observed positions body markers body poses 
seen plots quite bit variation positions markers 
example markers attached shoulder robot observed positions form arc camera coordinates 
hand light green marker located wrist observed large area camera image see 
number body icons increases density sensory components cover working envelope robot increases 
body representation approximation different body poses density high 
empirically established body icons sufficient crs robot 
number body icons required smooth robot movements grows exponentially number degrees freedom 
overcome limitation section considers problem learning nested representations 
robot poses selected motor babbling procedure 
marker marker marker marker marker marker plots show sensory components body icons learned single run motor babbling procedure 
plot shows observed positions single body marker 
coordinates point plots represent observed centroid largest blob color 
size camera image 
properties representation representation robot body schema terms body icons properties described 
main building blocks bos model processing elements pes activation function ui preferred body icon vi 
activation function pe determined normalized gaussian softmax function described morasso ui gaussian variance zero mean current joint vector stored joint vector th body icon 
variance small body icon activated joint vector close current joint vector 
large body icons activated specific query vector 
learning algorithm described morasso guarantees processing element neighborhood processing elements body icons similar 
similarity terms vectors activation levels fixed joint vector morasso 
locality property exploited implement gradient ascent strategy moving robot configuration described sub section 
mapping joint vectors sensory vectors forward kinematics explicit joint vectors prototypes learned body icons equal vi assuming zero sensory noise 
arbitrary joint vector 
unknown 
possible approximate sensory vector formula morasso approx ui activation value th body icon due proprioceptive information 
activation value determined normalized gaussian function 
formula interpreted step approximation algorithm look interpolation similar memory learning approach atkeson schaal atkeson 
step looks body icons joint vectors similar query joint vector 
second step sums sensory vectors vi body icons scaled activation value ui approximate 
individual components vk sensory vector formula rewritten approx flow chart diagram formula shown 
ui approximation errors formula estimated comparing approxi mated sensory vectors real values 
shows magnitude direction errors arrows 
base arrow represents true value sensory vector calculated forward kinematics 
tip arrow represents approxi mated value formula 
gray points represent sensory components body icons 
shows approximation errors small reachability space 
due fact number body icons cover area twice smaller locations body icons cover unreachable space 
approx vk ng ng ng body icons mk body marker joint vector approximation result flow chart diagram approximating sensory vector vk joint vector formula 
notation variables represent stored kinematic sensory components body icons ng normalized gaussian function formula compute activation value ui th body icon stand summation multiplication respectively 
shows magnitude direction approximation errors sensor vectors obtained formula 
gray points represent sensory components body icons 
errors represented arrows 
base arrow indicates true position sensory vector query joint vector calculated forward kinematics 
tip arrow represents approximated position calculated formula 
achieving goal directed movements representation robot body schema terms body icons control goal directed movements 
robot movements specified cartesian space carried joint space need inverse kinematics mapping spaces implicit way body icons constructed 
possible control strategy moving robot configuration gradient ascent gradient descent potential field morasso 
gradient ascent carried potential field location target maximum value points assigned values proportion distance target 
potential field imposed components body icons computed vi components distance goal sensor space 
calculation potential field similar motor schema approach robot control arkin cameron 
case potential field discretized body icons 
body icon assigned value sample magnitude potential field 
global potential field approximated equation iui desired direction movement point potential field corresponding gradient vector field defined gradient operator 
gradient ascent strategy potential field performed integrating equation determines step size 
advantage body icons representation form softmax activation function gradient ascent strategy achieved formula derived morasso iui constraint potential field represented com bination individual fields scaled appropriate coefficients 
words 
ki scalars determine relative weights field 
example consider task moving joint robot shown tip second limb positioned goal region 
example potential field goal specified inverse function squared euclidean distance body icons goal magnitude point potential field computed space body icon representation field imposed space 
shows process 
final potential field configuration shown corresponding gradient vector field computed formula shown camera robot goal joint robot example 
goal move tip second limb body marker goal region 
calculation potential field 
body icons calculate distance 
body icon assign scalar value inversely proportional squared distance space point indexed final potential field shown log resulting potential field goal configuration shown surface shows log plot approximated field dots show true positions discrete samples 
corresponding gradient vector field approximated formula vector magnitudes scale arrows rescaled uniform length order show direction entire vector field 
identifying body frames certain tasks expressed naturally relative frames 
example grasping task easier perform expressed coordinate frame relative wrist relative shoulder 
furthermore tasks handwriting performed easily joints arm constrained putting arm surface desk 
evidence biological brains maintain multiple body frames order coordinate body movements newcombe huttenlocher gallistel 
gallistel example suggests intelligent behavior learning coordinate frames 
mystery behaviors expressed coordinated multiple body frames 
section builds self detection results described chapter shows coordinate frames attached different body parts robot identified constructed automatically 
visual features classified self clustered groups movement patterns 
clusters body markers correspond rigid bodies form body robot 
cluster construct coordinate frame called body frame 
body frames help simplify specification robot behaviors expressing positions body markers body frames natural task 
problem statement sake clarity problem autonomously identifying body frames robot stated explicitly notation 
set visual features 
fm robot detect track time 
features autonomously identified robot features belonging robot body method described chapter means 
body robot consists set rigid bodies 
bn connected set joints 
jn 
robot detect positions visual features detect moving point time 
words robot set perceptual functions 
pm pi fi 
say function pi returns feature fi moving time 
goal robot cluster set features subsets fk 
fk 
furthermore clustering features belong subset fj lie rigid body 
words features clustered rigid bodies lie 
methodology methodology identifying body frames similar methodology self detection 
case goal detect temporal coincidences events oc cur time movements different visual features temporal contingency motor commands visual movements 
gives example visual features red green blue movement patterns 
feature red feature green start moving small interval time 
movement coincidence shown shaded region 
feature blue observed move start movement correlated start movement features 
visual movement feature visual movement feature visual movement feature movement coincidence detected methodology identifying body frames detecting temporal coincidences movements different features 
shows example observed movement patterns visual features 
feature red feature green start move short interval time indicated shaded region 
start movement third feature blue correlated start movement features 
time time time similar movement coincidences observed multiple times reasonable conclude feature feature lie rigid body start move 
furthermore features frequently observed moving case evidence favor lying rigid body stronger 
pair features fi fj possible keep temporal coincidence movement coincidence counter ci indicates times features observed start moving short time interval 
special case counter ci measures times feature fi observed move 
movement coincidence counters organized matrix shown table 
matrix symmetric main diagonal ci cj table sample movement coincidence matrix 
entry ci represents counter indicating times feature fi feature fj observed start moving time interval 
matrix symmetric 

fm 



fm 
cm values counters possible calculate probabilities pi qi similar necessity sufficiency indexes previous chapter 
probabilities formulas pi ci ci qi ci cj probabilities calculated movement coincidence matrix elements row divided main diagonal entry row 
operation performed place resulting matrix main diagonal main diagonal main diagonal shown table 
features fi fj clustered lying rigid body table matrix derived matrix shown table dividing entry value stored diagonal entry row 
values described text 
matrix longer symmetric 

fm 


fm 
pi qi threshold value 
threshold value arbitrary set automatically number independent motor commands crs robot 
calculations performed focusing movement coincidences visual movements 
case matrix similar shown table calculated 
results different types coincidences combined improve final results 
subsection shows experimental results methodology tested robot 
experimental results form table 
experimental results methodology described tested datasets described section 
datasets color processed way described previous chapter 
timing coincidence calculations sensitive sensory noise positions color markers averaged consecutive frames marker movements shorter frames th second ignored 
body frames identified shown 
clustering results form frames shown table table described 
table shows results dataset robot moving object environment see section 
results form shown table 
results pairs markers emerge shown shows different body frames shoulder frame xs ys formed markers arm frame xa ya formed markers wrist frame xw yw formed markers 
frames constructed robot body markers markers clustered movement patterns 
table table show clustering results form frames 
highlights 
pairs markers pi qi greater threshold set number different motor commands 
time interval set seconds 
similarly table displays results dataset movement dences visual movements considered 
pairs markers emerge case 
similar results obtained datasets described section 
datasets algorithm clustered correctly body markers groups 
results body frames formed pairs body markers shown 
coordinate frame specified just different points 
point serves origin frame 
axis frame determined vector point second point 
axis table highlights show pairs markers grouped start movement coincidences 
correspond rigid bodies robot shoulder arm wrist 
table highlights show pairs markers grouped movement coincidences 
correspond rigid bodies robot shoulder arm wrist 
vector perpendicular vector oriented positive counterclockwise direction 
subsections show body frames learn nested rbs representations encode robot behaviors 
interesting point method described capable segmenting structure rigid articulated objects don belong robot body 
example table provides results dataset robots uncorrelated movements described section 
case pairs markers identified 
correspond rigid bodies second robot 
similar results obtained movement coincidences considered see table 
results suggest way segment visual scene individual objects 
com puter vision difficult identify visual features constitute object 
object defined set visual features start moving method described may object segmentation especially robot allowed push move objects 
test hypothesis 
table pairs markers identified start movement coincidences robots uncorrelated movements see section 
pairs markers correspond rigid bodies robots 
table pairs markers identified movement coincidences robots uncorrelated movements see section 
pairs markers correspond rigid bodies robots 
nested rbs representation body frames identified positions body markers expressed different body frames camera centric frame 
example shows observed positions light green marker relative arm frame xa ya 
data points data points shown coordinates expressed arm frame camera centric frame 
new view data clearly shows possible positions wrist marker relative arm 
locations dark green dark blue markers determine coordinate frame shown large circles 
shows observed positions green body marker coordinates expressed arm body frame xa ya camera centric frame shown circular pattern clearly shows possible positions wrist relative arm 
possible take approach step define nested rbs repre sentation 
example separate body icons table learned wrist markers 
joint vectors body icons contain joint angles wrist joint 
sensory vectors hand contain positions wrist markers 
important detail case visual coordinates wrist markers expressed arm frame coordinates camera centric coordinates 
words body icons table format table body icons table wrist 
row table represents observed joint sensory vectors specific wrist pose observed positions wrist markers calculated arm frame coordinates 
kinematic sensory components components 
vi vi nested rbs representation advantages 
reduces dimensions sensory joint vectors requires memory store body icons 
second reduced dimensionality smaller number body icons learned certain level approximation accuracy reached 
nested representation specify different control laws behaviors different joint groups robot 
subsection shows example wrist arm controlled independently 
behavioral specification nested rbs body markers body frames provide convenient way specification moni execution robot behaviors 
section demonstrates robot behaviors encoded nested rbs 
rbs model provides blueprint possible configurations robot body 
blueprint localize individual body parts space 
control planning body movements 
movements specified desired final positions specific body markers relative visual features 
robot access sensorimotor stimuli produced body behaviors expressed terms desired final positions stimuli 
approach consistent ideas berthoz argues reflex behaviors living organisms encoded terms body schemas 
complex behaviors constructed combining multiple primitive behaviors 
typ ically primitive behaviors sequenced fused 
example consider grasping behavior composed steps shown 
behavior specified finite state automaton fsa 
states fsa linked perceptual triggers arkin determine robot switch state 
start immediate pre grasp orient touch sensations reach close gripper point grasp point wrist lower arm orientation complete finite state automaton fsa describing grasping behavior 
states fsa linked perceptual triggers determine robot switch state 
figures show sequence movements simulated robot attempts grasp stick object 
pre reach phase position yellow body marker controlled way position marker target grasp point 
orient wrist phase wrist moved relative arm frame 
green spheres show sensory components body icons light green wrist marker relative arm frame 
red spheres show highly activated body icons closest grasp point 
arm lowered controlling position yellow marker light green marker wrist remains perpendicular table 
words positions different body markers controlled different body frames simultaneously 
gripper closed simulated tactile sensors triggered 
completes grasping behavior 
similarly encoded grasping behavior section real robot 
behavior hand coded learned 
learning behaviors rbs representation topic 
example pre reach behavior progress 
purple spheres represent sensory components yellow marker body icons 
highly activated components colored cyan clustered target grasp point stick 
example orient wrist behavior progress 
arm positioned grasp point wrist robot moved relative arm frame 
green spheres show possible positions light green marker relative arm frame 
red spheres correspond wrist positions highly activated body icons 
example lower arm behavior progress 
behavior controls positions yellow marker light green marker 
result arm lowered grasp point wrist rotated remains perpendicular table 
positions body markers controlled simultaneously different body frames separate sets body icons 
extending robot body schema body schema model described far extended order assimilate external object robot body representation 
section modifies model extensibility properties similar biological body schema 
iriki 
trained monkeys rake shaped tools extend reach 
reported tool bimodal neurons encode monkey body schema change visual receptive fields fire expanded area reach able tool 
main criteria met extension body representation take place 
movements tool tempo rally correlated movements monkey arm 
small variation unpredictable time delay disrupt process iriki 
second intention object tool just holding object sufficient trigger extension body iriki 
model described inspired iriki 

experiments monkeys serve inspiration robotics 
robot capable replicating experiments robotics attempt model monkey brain works 
goal test functional level building blocks form complex system representing body robot body representation extended remapped depending task demands 
basic idea extension method morph body representation robot better suited task requires external object 
example robot control position tip stick object convenient perform operation stick treated extension robot wrist 
alternative approach treat stick different body reconcile different control strategies 
extension morphing mechanism triggered near perfect temporal coincidence self movements external object movements 
robot needs detect movements stick coincide movements robot wrist 
answer markers stick move efferent afferent delay robot 
stick assimilated robot body schema duration usage 
unpredictable variable time delays external object assimilated robot body representation 
tools solid ropes rubber trigger extension body 
limitation current approach applies rigid bodies 
japanese monkeys similar limitations reported iriki 
extension mechanism triggered necessary calculate parameters body transformation 
transformation may involve rotation translation scaling 
parameters calculated observed spatial relation external object corresponding body part 
observation data available prior experience gathered motor babbling commands robot experiments reported 
observations produce sets points corresponding mapping 
words observed body poses corresponding pose object targeted assimilation 
information robot calculates parameters transformation 
transformation parameters calculated transformation applied body icons affected body schema body schema involved nested 
rbs model represents positions robot body markers various body poses point cloud formed visual components body icons 
main idea extension method morph positions visual components body icons keep kinematic components 
visual components represented point cloud applying transformation equivalent transforming points individually 
transformation completed transformed point cloud control robot movements way 
subsections show examples body extensions triggered tool tv image 
section explains extended body representation achieve video guided behaviors 
example extension triggered tool example demonstrates robot establish temporary equivalence body markers frames markers external object 
equiva movement coincidences sets markers 
mapping temporary long robot grasping tool 
tool dropped movement coincidence violate condition extension identified iriki 

movement incidence mapping morph body representation include attached tool 
experimental procedure described 
shows frames short sequence frames minutes robot waves stick 
frame shows intermediary body pose robot stops short period time performing movement 
robot performed movements shown times 
resulted total wrist movements arm movements 
stick object color markers referred 
colors red orange 
markers placed tip stick mid point respectively 
previous chapter robot see point light display movements different color markers 
color segmentation results frames shown 
table shows start movement coincidence results robot body markers markers stick 
cells highlighted green indicate stick markers move way wrist markers 
cells highlighted cyan correspond arm frame 
shoulder robot move short sequence shoulder markers grouped case longer sequences described previous section 
similarly table shows results movement coincidences 
markers stick movement patterns markers wrist 
results indicate body movements possible identify external object reliably controlled robot 
furthermore possible identify body frame object attached case wrist frame 
mapping established step perform actual extension position robot body markers temporarily transformed coincide positions new stick markers 
section describes trans formation parameters calculated 
table start movement coincidence results short sequence robot waves stick tool see 
entries highlighted green show stick markers start move time wrist markers 
shoulder robot move short sequence markers grouped 
arm markers grouped movements 
table movement coincidence results short sequence robot waves stick tool see 
results similar ones shown table 
frames short sequence minutes robot waves stick tool 
stick object color markers detected robot 
color segmentation results robot poses shown 
example extension triggered video image section shows movement coincidences sets markers successfully establish marker correspondence 
correspondence established remap positions robot body icons tv monitor 
tv sequence described section example 
chapter showed robot detect tv markers associated body 
methodology described chapter address problem mapping tv markers robot markers 
words address issue wrist marker tv image really corresponds robot wrist marker 
solving problem important colors markers tv may slightly different real world counterparts case tv experiments 
previous example section robot direct physical contact external object body extension triggered 
second example described physical contact possible required see 
obstacle extension body triggered movement coincidence detector physical contact detector 
table shows start movement coincidence results tv sequence 
fig ure shows alternative way visualize results 
results indicate body frames robot tv image mapped correctly body frames real robot 
exception yellow marker position detection noisy color similar color background wall tv image 
omission critical rest tv experiments yellow marker encode robot behaviors grasping 
matching ambiguities remain timing coincidences method establishes correspondences body frames individual body markers see 
resolved matching nearest marker feature space case hsv color space 
similar results obtained tv sequences 
section builds results describes remaining details extension process 
table mapping body frames tv frames start movement coincidence results tv sequence 
highlighted areas show body markers tv markers grouped 
yellow tv marker matched real markers position detection noise 
results corrected marker visibility 
similar results obtained tv sequences 
tv tv tv tv tv tv tv tv tv tv tv tv visual representation matching markers start movement coincidence results table 
achieving video guided behaviors humans capable performing behaviors receive visual feedback actions indirect means mirror reflection real time video image 
examples include getting dressed front mirror driving car reverse rear view mirrors playing video game joystick control virtual character mouse position mouse pointer computer monitor 
behaviors common perform daily basis thinking complexity 
primates capable performing similar behaviors 
example consider task shown described iriki 

hands monkey incentive object piece apple placed opaque panel observed directly monkey 
order reach grasp incentive object monkey real time video feedback movements captured camera projected tv monitor 
shows experimental setup iriki 

setup consists tv monitor displays real time images captured camera 
opaque panel prevents monkey observing movements hands directly 
tv image guide reaching behaviors order grasp food item 
initial training phase transparent window located close eye level monkey left open observe movements hands directly tv monitor 
iriki 

solve problem monkey solve sub problems 
realize tv monitor displays real time video hands say recording movements monkey 
second monkey similarity transformation translation rotation scaling position real arm estimated proprioceptive informations seen directly image arm tv monitor 
monkey video image guide hand incentive object 
section describes computational framework successfully robot solve task described 
robot solves sub problem detecting temporal contingency motor commands observed self movements video image 
video image projected real time visual self movements detected occur expected proprioceptive visual efferent afferent delay robot see chapter 
second sub problem solved estimating similarity transformation translation rotation scaling sets points 
set consists positions specific body locations estimated proprioceptive information observed directly 
second set consists observed positions body locations video 
similarity transformation calculated robot extend body schema perform grasping move ment direct visual feedback body 
setup robot experiments described section related animals 
similar experiments animals menzel 
reported time abilities chimpanzees perform video guided reaching behaviors 
experimental setup shown 
chimpanzees study capable detecting tv monitors shows self image shows recording previous trial 
succeeded tv image rotated experiments visual feedback comes mirror video image performed 
itakura reported japanese monkeys reach experimental setup menzel 

targets observed mirror image 
epstein 
able train pigeons peak spot body seen mirror 
discovery chimpanzees self recognize mirror flood studies mirrors primate experiments 
studies far numerous summarized 
see barth comprehensive summary 
iriki 
performed reaching experiments japanese monkeys see simultaneously recording firing patterns neurons located believed encode body schema monkeys 
results show neurons fire monkey observes hand directly trained fire hand observed tv image 
furthermore showed visual receptive fields neurons shift expand contract depending position magnification tv image 
order learn skills monkey hand movement displayed video monitor time delay 
coincidence movement real hand video image hand essential iriki 
section inspired iriki 
describes experiments japanese monkeys learned solve task shown 
study serves inspiration robotics 
robot capable replicating experiments reported iriki section attempt model brain works 
goal section study functional level building blocks form complex system representing body robot body representation extended remapped depending current task 
experimental setup experimental setup robot experiments described shown 
experiments performed crs manipulator arm described chapter 
robot degrees freedom waist roll shoulder pitch elbow pitch wrist pitch wrist roll plus gripper 
purposes current experiments roll joints allowed move away positions 
words movements robot restricted vertical plane 
mobile base robot disabled remained fixed experiments 
experimental setup uses cameras 
camera sony evi camera robot receives visual input 
image resolution set 
second camera sony dcr hc placed robot camera capture approximately working envelope robot 
frames captured second camera displayed real time tv monitor samsung ltn inch lcd flat panel tv 
previous experiments color markers placed robot body 
positions markers tracked computer vision code performs histogram matching hsv color space opencv library open source computer vision package 
position marker determined centroid largest blob matched specific color 
procedure applied track positions color markers tv 
robot control code color tracker run experimental setup robot experiments described section 
pentium iv machine ghz gb ram running linux core 
colors body markers real robot arm colors body markers tv image looked slightly different viewed sony evi camera right camera 
color calibration contrast settings tv adjusted difference small possible 
despite efforts appearance sets colors 
overcome problem color tracking primary sensing modality sets color histograms real body markers image tv monitor 
configuration robot observe real arm image arm tv monitor see 
original experimental design called opaque panel similar shown 
large object frame changed auto color calibration camera field view robot camera sony evi setup shown robot sees testing experiments described 
turned 
negatively impacted quality color tracking results decided digital version opaque panel 
words left half frame captured camera erased zeroed processed see 
shows observed positions blue wrist marker 
positions recorded real robot data robot performing motor babbling 
sub section shows positions extended map tv image 
shows visual components vi corresponding blue body marker see body icons 
calculating similarity transformation sub section describes method calculating similarity transformation trans lation rotation scaling position real robot arm image arm tv monitor 
parameters transformation extend visual components body icons rbs model 
extension tv image video guided behaviors 
method calculates similarity transformation sets points 
set consists different positions specific body marker blue wrist marker 
positions estimated proprioceptive information formula body marker observed directly see 
second set consists corresponding positions body marker observed video image 
robot gathers sets performing motor babbling 
wrist marker detected joint configuration tv frame sensory noise reduces visible size marker detection threshold pixels robot picks new random joint vector continues motor babbling 
sets data points gathered similarity transformation parameters calculated method described 
method calculates translation rotation scaling set points common problem computer vision 
sake completeness results summarized proofs 
problem solution stated follows 
sets points xi yi 
dimensional space typically find similarity transformation parameters rotation translation scaling minimizes mean squared error sets points 
error yi showed optimum transformation parameters deter mined uniquely follows usv cr tr ds xy xi yi xi yi yi xi formulas mean vectors variances mean vectors xy covariance matrix matrix diag di dm determined singular value decomposition xy uv matrix rank xy rank xy 
det xy diag det xy det det diag det det experiments described section singular value decompositions performed code numerical recipes press pp 

experimental results experimental conditions shown test applicability rbs extension method video guided behaviors 
similar test conditions iriki 
experiments japanese monkeys 
test conditions differ rotation zoom second camera affects orientation size tv image 
test condition tv image approximately equal image real robot see 
second test condition camera rotated tv image rotated see 
rotation angle camera tv image 
third test condition camera horizontal image zoomed see 
zoom factor 
value calculated image averaging horizontal vertical zoom ratios sony provide user tv introduces image scaling 
shows views robot camera experimental conditions 
image robot tv approximately size real robot rotated negative scaled zoomed factor 
actual experiments robot see body show 
shows robot sees experiments test conditions 
left half frame see digitally erased zeroed processed 
images show incentive object pink square robot required grasp observing position directly 
robot tv image guide grasping behaviors 
shows extended positions body icons visual components blue wrist marker extension rbs test conditions 
comparing obvious visual components body icons translated rotated translated scaled rotated translated relative original configuration 
furthermore new positions coincide positions blue marker observed tv 
extended positions longer tied camera coordinates may fall outside camera image 
tables show estimated transformation parameters test conditions separate trials 
stereo vision meaningful translation parameters tx ty rotation parameter 
scale factor estimated method 
real robot data results slightly noisy 
transformation parameters estimated correctly trials indicated small standard deviations 
table transformation parameters normal test case 
trial tx ty scale trial trial trial trial trial trial trial trial trial trial mean stdev condition robot tested task grasping incentive object pink object 
experiments object seen tv image see 
test conditions grasping experiment performed times 
robot successfully grasped incentive object trials condition trials condition trials condition 
possible reason robot failed completely zoom condition due poor quality color tracking results high level magnification 
result counter intuitive expect just opposite true 
image robot arm really large auto color calibration sony turned affected smallest movements robot 
shadows transient light effects magnified 
proved difficult table transformation parameters rotation test case 
trial tx ty scale trial trial trial trial trial trial trial trial trial trial mean stdev table transformation parameters zoomed test case 
trial tx ty scale trial trial trial trial trial trial trial trial trial trial mean stdev track body markers zoomed test condition current tracking method 
transformation parameters test case estimated correctly see table data points needed calculation collected wrist marker observed tv possible body configurations 
failure rotation test case due poor color tracking results 
chapter summary chapter introduced notion extended robot body schema described compu tational model implements notion 
rbs model learned self observation data visual proprioceptive ered motor babbling phase 
rbs provides robot sensorimotor model body control robot movements 
process extension rbs accommodate changes configuration robot triggered attached objects 
extension triggered near perfect correlation self movements movements external object 
chapter described extension robot body schema triggered temporal contingency actions robot observed self movements video image 
reported experiment robot able detect self image tv monitor real time video image guide actions order reach object observable tv image 
extension rbs allows robot tv image guide arm movements observing directly 
constitutes reported instance video guided behavior robot 
build principles described chapter extend domains robots video guided behaviors 
example mouse position cursor computer monitor rear view camera mirror back car just possible applications 
results described chapter demonstrate robot learn sensorimotor model body self observation data answer second research question stated section 
results show body model facilitate goal oriented tasks video guided behaviors 
chapter vii learning affordances tools simple object stick numerous tasks quite different 
example stick strike poke prop scratch dig mystery animals humans learn affordances gibson cognitive structures represent 
chapter introduces novel approach representing learning tool affordances robot 
tool representation described uses behavior approach ground tool affordances behavioral repertoire robot 
representation learned behavioral babbling stage robot randomly chooses different exploratory behaviors applies tool observes effects environmental objects 
chapter shows autonomously learned affordance representation solve tool tasks dynamically sequencing exploratory behaviors expected outcomes 
quality learned representation tested extension reach tool tasks 
affordances exploratory behaviors james gibson defined affordances perceptual invariants directly perceived organism enable perform tasks gibson see section 
gibson specific way affordances learned suggests affordances learned infancy child experiments external objects 
related animal object exploration section indicates animals stereotyped exploratory behaviors faced new object power lorenz 
set behaviors species specific may genetically predetermined 
fact glickman observed exploratory behaviors frequently overlap behaviors species 
species animals tests include entire behavioral repertoire young bird confronted object seen runs practically behavioral patterns social sexual ones lorenz 
studies human subjects suggest internal representation new tool brain encoded terms specific past experiences mah mussa ivaldi 
furthermore past experiences consist brief feedforward movement segments initial exploration tool mah mussa ivaldi 
tool task learned dynamically combining sequences 
properties tool animal learn directly related behavioral perceptual repertoire animal 
furthermore learning properties relatively easy requirement perform small set exploratory behaviors observe effects 
results experiments animal builds internal representation tool actions affords 
solving tool tasks dynamically combining exploratory behaviors expected results 
section formulates behavior grounded computational model tool principles 
behavior grounded tool representation robots tools tasks notion robotic tool brings mind things robot environmental object labeled tool environmental object tool applied labeled attractor tool task 
tool occur components need 
fact meaningless talk account 
tool robot may tool differences robots capabilities 
alternatively tool suitable task object completely useless 
tasks may range capabilities robot robot capable tools 
components tool taken consideration 
compatible gibson claim objects afford different things people different body sizes 
example object graspable adult may graspable child 
gibson suggests child learns scale sizes commensurate body measuring stick gibson 
section gives additional examples relates subjectivity principle 
arguments tool representation take account robot tool 
words representation grounded behav perceptual repertoire robot 
main advantage approach tool affordances expressed concrete terms behaviors available robot controller 
note sharp contrast theories intelligent systems reasoning objects physical world hayes stark bowyer 
assumption object properties expressed form human account specific robot 
advantage behavior grounded approach handle changes tool properties time 
example familiar tool deformed piece breaks longer tool 
robot directly test accuracy representation executing set exploratory behaviors past 
inconsistencies detected resulting observations update tool representation 
accuracy representation directly tested robot mandated verification principle see section 
theoretical formulation previous section justification exploratory behaviors learn affordances tools 
section describes theoretical formulation ideas 
tool representation introduced uses behavior approach arkin ground tool affordances existing behavioral repertoire robot 
behavior grounded approach formulated notation 

ek set exploratory behaviors available robot 
behavior parameters modify outcome 
parameters behavior ei parameter vector ei ei ei 
ei number parameters behavior 
behaviors parameters learned imitation programmed manually learned autonomously robot 
purposes chapter issue behaviors selected learned ignored 
similar fashion 
bm set binding behaviors available robot 
behaviors allow robot attach tools body 
common binding behavior grasping 
examples tool controlled grasped holding teeth 
term binding 
parameters binding behavior bi parameter vector bi bi 
bi 
furthermore robot perceptual routines provide stream observations form observation vector 

assumed set observations rich capture essential features tasks tool applied 
change detection function takes observation vec tors parameters defined 
function determines interesting observation detected time interval 
current set experiments attractor moving execution exploratory behavior 
function defined binary movement detected 
furthermore movement detection falls general category events grab attention 
regan refer collectively events property environment 
notation mind functionality tool represented affordance table form binding binding exploratory exploratory start times times behavior params behavior params succ row table entries represent binding behavior 
second entries represent exploratory behavior parameters 
entries store observation vector start exploratory behavior 
entries integer counters estimate probability success sequence behaviors 
meanings entries best explained example 
consider sample row binding binding exploratory exploratory start times times behavior params behavior params succ binding behavior parameter performed grasp tool 
specific value parameter behavior represent specific fixed value 
exploratory behavior specific values sign performed parameters 
value observation vector prior start value completed 
sequence behaviors performed times 
trials observed movement direction attractor similar stored movement direction table row 
attractor movements considered similar angular movement directions see section 
replication probability affordance 
section provide information organization affordance table 
initially affordance table blank 
robot tool performs behavioral babbling routine picks binding exploratory behaviors random applies tools objects observes effects updates table 
new rows added table exploratory behavior performed 
integer counters updated learning trials 
prior testing trials counters rows initialized updated actual experience 
robot tools experiments 
experimental setup experiments performed mobile manipulator described section 
tools experiments stick stick hook stick hook fig ure 
tools built pine wood painted spray paint 
choice tools motivated similar tools hler experiments chimpanzees hler 
orange hockey puck attractor object 
sony evi camera mounted tripod overlooking robot working area 
robot wrist tools attractor color coded positions uniquely identified tracked computer vision see figures 
computer vision code run hz resolution mode 
ensure consistent tracking results multiple robot experiments camera calibrated time powered 
calibration performed roger tsai method tsai code 
calibration pattern 
pattern consists small color markers placed cardboard inches apart form square pattern 
pixel coordinates uniformly colored markers identified automatically color segmentation 
pixel coordinates markers world coordinates measured coordinate system attached table passed camera calibration procedure calculates intrinsic extrinsic parameters camera 
parameters mapping function assigns camera coordinates location world coordinates parameter supplied user height table 
experimental setup 
color tracking raw camera image 
color tracking segmentation results 
pattern camera calibration 
results color segmentation applied calibration pattern 
exploratory behaviors behaviors encoded manually library motor schemas ceptual schemas arkin developed specific robot 
behaviors result different arm movement patterns described 
exploratory behaviors parameters extend arm offset distance contract arm offset distance slide arm left offset distance slide arm right offset distance position wrist behaviors move arm indicated direction keeping wrist perpendicular table tool slides 
behaviors single parameter determines far arm travel relative current position 
different values parameter inches 
position wrist behavior moves manipulator centroid attractor offset relative wrist 
grasping behavior multiple ways tool grasped 
represent set affordances call binding affordances different ways robot attach tool body 
affordances different output affordances tool different ways tool act objects 
chapter focuses output affordances binding affordances specified grasping behavior 
behavior takes parameter location single grasp point located lower part tool handle 
observation vector observation vector real value components 
groups represent position attractor object camera centric coordinates position object relative wrist robot color object color tool 
observation meaning positions object camera centric positions object wrist centric color components object color components tool change detection function defined components 
determine attractor moving calculates euclidean distance thresholds empirically determined value inches 
times successful counter incre mented observed attractor movement degrees expected movement stored affordance table 
learning trials third research question stated section asked robot exploratory behaviors learn represent functional properties affordances tools 
section describes procedure meets criteria successfully crs robot learn affordances tools shown 
flowchart diagram procedure learning trails shown 
procedure testing trials described section 
learning trials robot allowed freely explore properties stick tools shown 
exploration tool consists trying different exploratory behaviors observing results filling affordance table tool 
new entry added affordance table attractor object observed move exploratory behavior performed 
object affected exploratory behavior affordance table remains unchanged 
object movement acts attention grabbing mechanism triggers update affordance representation indicator effect tool object see section 
initial positions attractor object tool random 
attractor pushed tool reach robot learning trial temporarily suspended attractor manually placed new random position 
learning trials limited hour run time tool 
flowchart diagram exploration procedure robot learn affordances specific tool tool applied attractor object 
learned illustrates robot learn properties hook tool single exploratory behavior 
example exploratory behavior contract arm parameter inches observation vectors stylized purposes example 
information robot retains images tool puck coordinates positions explained 
different exploratory behavior selected robot possible movement puck detected 
case robot store information row affordance table 
contents sample row affordance table hook tool 
robot performs multiple exploratory behaviors compact way rep resent information required 
way visualize robot learns graphs ones shown 
figures show observed outcomes exploratory behaviors hook tool applied hockey puck robot performing behavioral babbling 
graphs shows observed movements attractor object specific exploratory behavior performed 
movements attractor object shown arrows 
start arrow corresponds initial position attractor relative wrist robot relative grasp point just prior start exploratory behavior 
arrow represents observed distance direction movement attractor camera coordinates exploratory behavior 
words arrows shown represents observed movement puck similar detected movement arrow show 
arrows superimposed initial configuration tool final configuration 
affordance representation interpreted predictive model results exploratory behaviors 
words affordances represented expected outcomes specific behaviors 
interpretation affordances consistent idea biological brains organized predictive machines anticipate consequences actions berthoz 
consistent findings internal representation functional properties novel objects tools humans 
mah mussa ivaldi note brain predict effect pushing pulling object effectively internal model object manipulation 
result theoretical ai literature shows state dynamic system represented outcomes set tests singh littman 
tests consist action observation sequences 
shown state system fully specified outcomes basis set test called core tests known advance littman 
extend arm inches slide right inches extend arm inches slide right inches slide left inches contract arm inches slide left inches contract arm inches visualizing affordance table hook tool 
graphs show observed movements attractor object specific exploratory behavior performed multiple times 
start arrow corresponds position attractor wrist centered coordinates relative tool grasp point just prior start exploratory behavior 
arrow represents total distance direction movement attractor camera coordinates exploratory behavior 
querying affordance table affordance table populated values queried dynamically create behavioral sequences solve specific tool task 
behaviors sequences behaviors fill table 
section describe test procedure employed robot tool tasks 
subsection describes search heuristic select best affordance current task configuration required procedure shown 
testing trials best affordance specific step tool task selected greedy heuristic search 
query method adopted uses empirically de rived heuristics perform multiple nested linear searches affordance table described 
successive search performed rows elim previous searches 
level search best tool affordance applicable current situation focused affordances ready met previous search criteria 
nested searches performed order shown select rows observation vectors consistent colors current tool object 
remaining rows select probability success greater select rows replication probability times successful times greater reasons choosing threshold value described 
sort remaining rows increasing order expected distance attractor object goal region behavior associated row performed 
top sorted rows choose row minimizes re positioning tool relative current location repositioning rule described section 
mentioned greedy step lookahead heuristic derived em 
performance heuristic fine tuned speed adaptation presence uncertainty important multiple robot trials performed 
example threshold value step chosen order speed elimination outdated affordances geometry tool suddenly changes see experiment described section 
threshold value takes unsuccessful behavioral execution order eliminate affordance con 
attempt formulate principled approach affordance space planning problem preferably performance data derived tool experiments animals humans mah mussa ivaldi 
testing trials section shows affordance representation described previous section solve tool tasks 
words section answers affirmatively second part research question stated section 
shows flowchart diagram procedure robot testing trials 
experiments described subsections require robot move attractor object color coded goal region 
testing procedure starts identifying position goal region 
current tool attractor object identified unique colors 
testing trial ends attractor object placed goal region timeout interval expired 
procedure shown uses affordance representation currently available tool represented help affordance table see 
step robot selects best tool affordance applicable current situation greedy heuristic described section 
observation vector start associated selected affordance robot decides needs reposition tool 
tool repositioned current position attractor object relative tool relative green wrist marker shown inches away attractor position stored start best affordance 
robot performs exploratory behavior associated best affordance compares outcome outcome stored affordance table 
observed object movement matches movement stored affordance table counters times times successful affordance incremented see 
behavior effect attractor object object observed move replication probability affordance reduced times counter incremented effectively reduces value fraction times successful times 
similarly effect behavior object different expected effect previous experience direction movement attractor degrees expected movement direction see section replication probability affordance reduced 
flowchart diagram procedure robot solve tool tasks help behavior grounded affordance representation 
subsections describe types experiments performed 
measured quality learned representation adaptation abilities tool deformed respectively 
extension reach experiment robot required pull attractor color coded goal region 
different goal positions defined 
goal shown dark square front robot 
second goal located farther away robot see 
achieve robot push attractor away body 
goals placed mid line table shown 
shows positions goal regions initial attractor positions extension reach experiments 
dashed lines indicate boundaries robot sphere reach holding tool 
addition initial attractor positions goal 
initial positions located mid line table inches apart 
tool placed center table 
total trials performed goals attractor positions tools 
table summarizes results goal tool 
table entry represents number successful trials tool goal configuration 
trial considered success puck placed goal region possible maximum value initial position puck goal configuration 
tool goal goal goal goal stick stick hook stick hook seen table robot able solve task majority test cases 
common failure condition due pushing attractor tool reach 
failure caused greedy step lookahead heuristic selecting tool movement 
robot plans possible movements puck moves ahead failures eliminated 
notable exception stick tool pull object back near goal 
robot lacks required exploratory behavior turn wrist angle pull required detect affordance stick 
adding capability learning new exploratory behaviors resolve problem 
results experiment show behavior grounded tool representation solve tool tasks second part research question 
adaptation tool breaks second experiment designed test flexibility representation presence uncertainties 
case tool break 
example shows tool transformation occurs hook tool loses hooks 
result hook tool 
section describes results experiment robot exposed tool transformation learned affordances hook tool 
simulate broken tool robot tool color hook missing right hook equivalent hook 
id tool different shape 
specifically learning performed hook replaced hook 
color feature recognize tools robot believes old tool 
tools differ upper right sections 
robot tried affordances associated missing parts tool produce expected attractor movements 
shows frames sequence robot tried vain upper right part tool move attractor goal 
trials replication probability affordances associated part tool reduced excluded consideration 
shows rest sequence robot able complete task intact left hook tool 
total trials similar shown performed goal regions initial attractor positions 
experiments robot started testing trial original representation hook tool modified actual experience 
robot successful experiments robot able place attractor target goal region broken tool experiments 
results experiment show behavior grounded tool representation autonomously tested verified corrected robot mandated verification principle 
important contribution dissertation 
broken tool part adaptation initially robot tries move attractor goal missing right hook 
puck fails move expected robot reduces replication probability affordances associated part tool 
broken tool part ii solving task adapting modified affordances tool robot completes task intact left hook 
discussion behavioral outcomes geometric shapes tools important emphasize behavior grounded approach taken repre sentation tool encoded entirely terms exploratory behaviors 
important note robot lacks information geometric shape tool 
shape tool extracted robot 
perceptual feature robot detects tool color serves unique id tool 
affordance table tool contains information possible movements attractor object certain exploratory behavior contains arrows 
shape tool shown visualization purposes order results human readable 
accurate visualization affordance table shown 
previous boundary tool help human observer 
extend arm inches slide right inches extend arm inches slide right inches slide left inches contract arm inches slide left inches contract arm inches alternative way visualize affordance table hook tool 
graphs show information 
case shape tool detected robot shown 
black square shows position robot wrist position grasp point square green body marker 
view affordance table human readable shows better representation tool point view robot 
tool represented terms exploratory behaviors extracting shape tool 
point obvious tools designed stick stick shown 
new tools pine wood tools 
top parts thin metal 
shapes distinct human observer robot indistinguishable 
reason metal parts tools thin detected robot color tracking algorithm 
metal parts tools indistinguishable background tracking noise 
color tracking results tools shown 
robot learned affordances tools way tools 
words allowed play tool hour 
attractor object pushed tool reach period learning trial suspended short time attractor placed back table new random location 
learned affordance representations tools shown 
seen figures robot observe top parts tools learned act different ways indicated movements attractor object 
furthermore robot able successfully invisible parts tools 
example shows behavior grounded approach relies coupling robot behaviors observable outcomes 
example shows frames sequence robot able stick successfully push attractor distant goal goal 
task solvable straight stick explained 
affordances stick task solvable 
robot performs pushing movements stick alternating right left contact surface tool puck 
result puck takes zig zag path goal 
robot holding stick tool 
robot holding stick tool 
color segmentation results stick tool 
color segmentation results stick tool 
extend arm inches slide right inches extend arm inches slide right inches slide left inches contract arm inches slide left inches contract arm inches learned affordance representation stick tool 
extend arm inches slide right inches extend arm inches slide right inches slide left inches contract arm inches slide left inches contract arm inches learned affordance representation stick tool 
frames sequence robot uses stick push puck away goal 
robot performs pushing movements stick alternating right left contact surface tool puck 
result puck takes zig zag path goal 
chapter summary chapter introduced novel approach representing learning tool affordances robot 
affordance representation grounded behavioral perceptual repertoire robot 
specifically affordances different tools represented terms set exploratory behaviors resulting effects 
shown representation solve tool tasks dynamically sequencing exploratory behaviors expected outcomes 
results described chapter answer affirmatively third research question stated section asked robot exploratory behaviors learn represent functional properties affordances tools 
behavior grounded approach represents tools affordances concrete terms behaviors available robot controller 
robot directly test accuracy tool representation executing set exploratory behaviors past 
inconsistencies detected resulting observations update tool representation 
accuracy repre sentation directly tested verified robot mandated verification principle see section 
demonstrated robot approach adapt changes tool properties time tools break 
shortcoming behavior grounded approach tool affordances discovered required exploratory behavior available robot 
problem observed animals macaque monkeys significant difficulties learning push object tool away bodies movement performed normal daily routines 

problem resolved ability learn new exploratory behaviors added 
obvious extensions left 
current implementation starts exploration new tool scratch may similar explored tool 
adding ability rapidly infer affordances new tool shape similarity previous tools nice extension 
second current implementation uses purely random behavioral babbling ration procedure 
different strategies random focused infor mation structured robot exploration speed learning process 
third behavior grounded approach compared experimentally plan pushing objects mason 
expected behavior grounded method approach asymptotically accuracy planners number diversity exploratory behaviors increased 
expected behavior grounded approach excel situations predicted planners tools break objects center mass shift trials 
chapter viii dissertation important contributions field robotics 
main contributions dissertation broadly summarized follows demonstrates method autonomous self detection robots chapter 
demonstrates model extendable robot body schema achieve video guided behaviors chapter 
demonstrates behavior grounded method learning affordances tools solve tool tasks chapter 
contributions described analyzed detail 
self detection robots chapter described method autonomous self detection robot 
method detects temporal contingency motor commands efferent signals visual movements afferent signals estimate efferent afferent delay robot 
compliance verification principle subjectivity principle chapter showed robot estimate efferent afferent delay self observation data 
shown robot estimate delay performing random joint movements similar primary circular reactions described piaget 
value delay robot learn features belong body environment important contribution research 
shown self detection algorithm robust variety test conditions 
example algorithm affected presence moving objects environment algorithm performed second independently moving robot environment 
approach robot able detect self image tv monitor important contribution research 
experimental results described chapter show robot successfully distinguish body external environment 
results directly support research question stated section 
robot able correctly classify different visual stimuli self contribution dissertation applying concept temporal contin psychology literature watson robotics field implementing computational model uses concept real robot 
results described chapter demonstrate watson general framework appropri ate application robots 
results showed model shortcomings reported time resolved successfully 
studies modification self detection experiments robots infants 
limitation current implementation assumption visually distinct features color markers exist surface robot body reliably identified tracked 
color markers chosen order solve tracking correspondence problems computationally efficient way 
retrospect decision probably optimal 
reliable color tracking extended periods time remains challenging problem 
number distinct colors tracked reliably long periods time turned quite small constrained experimental designs 
focus eliminating need distinct perceptual features adding ability learn features actual experience 
extendable body schema model robots chapter described extendable body schema model robots 
basic model self organizing body schema model described morasso 
chapter modified model body schema model extensibility properties similar biological analog 
chapter extension mechanism triggered movement coincidence perceptual features associated robot body perceptual features asso ciated external object 
external object image robot tv monitor 
physical contact required trigger extension mechanism 
chapter described experiment involving reaching task 
robot allowed observe movements directly 
able observe movements real time tv image 
robot able detect temporal contingency motor actions movements visual features tv monitor 
information robot able extend body schema video image feedback order execute reaching behavior 
robot able reach object tv image rotated de 
experiment constitutes demonstration video guided behavior robot 
experiment showed usefulness body schema control robot behaviors robot receive feedback actions indirect means tv monitor 
shortcoming current implementation relies existence unique visual features placed robot body 
color tracking unreliable large tv image 
focus modifying body schema model features color necessarily unique 
shortcoming current implementation take account dynamics robot attached tool 
example long stick may potential extend reach robot stick heavy extension may achievable joint configurations robot 
results described chapter demonstrate robot learn sensorimotor model body self observation data answers affirmatively second research question stated section 
results described chapter show body representation facilitate execution goal oriented tasks video guided behaviors important contribution dissertation 
build principles described chapter achieve video guided robot behaviors tasks 
example task potential practical applications mouse position mouse cursor computer monitor 
task numerous practical applications rear view camera mirror back car truck 
learning tool affordances chapter described novel method learning tool affordances robot 
tool affordances represented terms expected outcomes exploratory behaviors 
words affordances tools grounded behavioral repertoire robot 
robot learns tool representation verification principle robot independently test verify representation 
furthermore robot autonomously correct representation tools don behave expected 
example robot able affordances tool tool broken 
verification principle gives robot ability autonomously detect errors representation 
consequently robot ability perform error driven learning 
robot programmed specific tool specific way able recover failure 
chapter represents computational models tool affordances 
started working area term affordance familiar 
couple years interest area growing steadily soon affordance research may mainstream robotics 
example dagstuhl germany workshop entitled affordance robot control 
results chapter demonstrate robot exploratory behaviors learn represent functional properties affordances tools 
answers affirmatively third research question stated section 
shortcoming behavior grounded approach tool affordances see www dagstuhl de de programm discovered robot lacks required exploratory behavior 
example robot pushing behavior behavioral repertoire able discover pushing affordance new tool 
problem solved ability learn new exploratory behaviors added 
best way achieve social interaction humans experienced tool users 
address problem social learning exploratory behaviors human robot interaction 
shortcoming current implementation robot uses purely random behavioral babbling exploration procedure learn affordances tools 
better option human feedback learning process narrow exploration space 
example human suggest behaviors robot explore tool 
human focus attention robot specific part tool critical solving specific task 
shortcoming current implementation robot explores new tools way 
start exploration empty affordance table adds new affordances discovered behavioral babbling 
new tool similar explored tool robot able explore similarity speed exploration process 
currently possible method ignores shape tools completely 
shape detected way 
tool representation entirely observable outcomes movements tool produce attractor object 
natural extension learn associate affordances specific local shapes tools 
infer affordances novel tool performing exploratory behaviors 
dissertation began vision day intelligent robots overcome limitations bodies tools useful robots today 
dissertation small step direction 
significant challenges overcome truly autonomous tool robots 
section describes broad areas bring closer vision modes tool experiments described dissertation focused tool mode extension reach 
designing robot algorithms representations address amplification force control liquids tool modes fruitful area 
modes challenging implement robot 
example learning hammer crush objects non trivial task crushed object totally transformed action hammer 
sensing challenges liquids difficult 
robots learn control liquids autonomously useful especially household robots assist everyday chores nurse robots take care elderly people homes hospitals 
tool modification experiments described dissertations rigid non deformable tools 
humans animals capable de tools 
example lab conditions new crow observed consistently bend piece wire hook order extract food rewards impossible get weir 
single robot today autonomously solve task 
tool manufacture challenging area tool manufacture 
tool modification focuses modifying single tool tool manufacture focuses combining tools build new tool 
tool manufacture animals reported hler observed chimpanzees able combine hollow sticks longer stick inserting 
tools extend sensory abilities fruitful area deals tools extend sensory abilities robot magnifying glasses night vision goggles 
example magnifying glass study shapes forms small objects 
robots achieve need design models organization robot senses 
challenges perceptual perspective significant 
tasks mentioned real challenge solving individual task concretely specified task engineered solution designed 
real challenge design robot algorithms solve tasks au 
words algorithms internal representations robot uses independent task 
believe research autonomous tool robots going increase importance robots spread human inhabited environments 
began happen 
really exciting applications autonomous tool robots ahead 
bibliography drucker task level robot learning juggling tennis ball accurately 
ieee international conference robotics automation pages scottsdale az 
left hand objects related patient right brain damage 

aguilar stiles saturation rod mechanism retina high levels stimulation 
acta 
inaba inoue pivoting new method manipulation object robot fingers 
ieee rsj international conference intelligent robots systems pages yokohama japan 
origin tool egyptian 
ibis 
evolution tools feeding animals 
evolution 
animal behavior evolutionary approach 
assoc 
sunderland ma 
allen mapping haptic exploratory procedures multiple shape representations 
ieee international conference robotics automation pages 
nasa space humanoid 
ieee intelligent systems applications 
arkin behavior robotics 
mit press 
asada direct teaching tool manipulation skills impedance identification human motions 
ieee international conference robotics automation pages 
atkeson moore schaal locally weighted learning 
artificial intelligence review 
atkeson schaal memory neural networks robot learning 
neurocomputing 
ayer language truth logic 
dover publications new york 
watson detection proprioceptive visual contingency basis self perception infancy 
developmental psychology 
balch behavioral diversity learning robot teams 
phd thesis georgia institute technology 
ballard brown computer vision 
prentice hall 
barnett exploratory behavior 
british journal psychology 
barr angle preserving transformations 
ieee computer graphics applications 
barth povinelli cant bodily origins self 
lampinen editors self memory pages 
psychology press new york 
beck animal tool behavior manufacture tools animals 
garland stmp press new york 
atkeson learning observation primitives 
ieee international conference robotics automation volume pages 
body brain neural bases awareness 
trends neuroscience 
novelty curiosity determinants exploratory behavior 
british journal psychology 
curiosity exploration 
science pages 
berthoz brains sense movement 
harvard university press cambridge ma 
translated weiss 
far near remapping space tool 
journal cognitive neuroscience 
st reasoning functionality tools physical artifacts 
review available www csc ncsu edu faculty papers index html date accessed march 
bingham selective transportation chimpanzee 
comparative psychology monographs 
optimization nut cracking natural wild chimpanzees 
behavior 
tool tool making wild chimpanzees 

identification functional features observations interactions 
phd thesis university pennsylvania 
bajcsy interactive recognition representation functionality 
computer vision image understanding 
cohen rubber hands feel touch eyes see 
nature 
attachment volume 
basic book new york 
brady agre connell mechanics mate 
shea editor advances artificial intelligence pages 
elsevier science publishers new york 
brady asada smoothed local symmetries implementation 
international journal robotics research 
brooks breazeal marjanovic scassellati williamson cog project building humanoid robot 
nehaniv editor computation metaphors analogy agents lecture notes artificial intelligence pages 
springer new york 
brooks stein building brains bodies 
autonomous robots november 
brooks symbolic reasoning models images 
artificial intelligence 
bruce balch veloso fast inexpensive color image segmentation interactive robots 
proceedings ieee rsj international conference intelligent robots systems iros japan october 
calvin stone throw launch window timing precision implications language brains 
journal theoretical biology 
cameron mackenzie ward arkin book reactive control mobile robot manipulation 
ieee international conference robotics automation volume pages atlanta ga may 
campbell 
human ecology 
new york 
campbell human evolution man adaptations 
new york third edition 
catania reinforcement schedules psychophysical judgments study temporal properties behavior 
editor theory reinforcement schedules pages 
appleton century crofts new york 
chevalier tool wild captive elephants 
animal behavior 
clark putting brain body world 
mit press cambridge ma 
collins human revolution ape artist 
press oxford 
connell brady generating generalizing models visual objects 
artificial intelligence 

technical manual series small industrial robot system 
crs plus burlington ontario canada 
cutkosky grasp choice grasp models design hands manufacturing tasks 
ieee transactions robotics automation 
darwin descent man selection relation sex volume murray london 
de waal forgotten ape 
university california press berkeley 
de waal ape master cultural reflections 
basic books new york 
de waal freeman hall monkey mirror hardly stranger 
proceedings national academy sciences pnas 
descartes error emotion reason human brain 
putnam pres new york 
dennett intentional stance 
mit press 
diamond guns steel fates human societies 
trucco giunchiglia ricci fur understanding functional reasoning 
international journal intelligent systems 
donald rus distributed manipulation objects ropes 
international symposium experimental robotics 
donald rus distributed manipulation multiple objects ropes 
ieee international conference robotics automation volume pages 
object classification acoustic analysis impact 
technical report cmu ri tr robotics institute carnegie mellon university june 
eddy povinelli age differences ability chimpanzees distinguish mirror images self video images 
journal comparative psychology march 
ellis tool oklahoma city zoo 
keeper 
epstein lanza skinner self awareness pigeon 
science 
erdmann exploration palm manipulation zebras 
laumond 
overmars editors algorithms robotic motion manipulation workshop algorithmic foundations robotics pages wellesley ma 
peters 
erdmann mason exploration manipulation 
ieee journal robotics automation august 
dynamic size change hand space tool 
june 
fitzpatrick metta rao sandini learning objects action initial steps artificial cognition 
ieee icra taipei taiwan may 
featural information necessary month olds perception motion specifying self 
society research child development minneapolis mn april 
disorders body schema 
editors handbook clinical neurology disorders speech perception symbolic behavior volume pages 
north holland 
freud new introductory lectures 
norton new york 
fujita ishida doi autonomous behavior control architecture entertainment humanoid robot sdr 
proceedings ieee rsj international conference intelligent robots systems iros pages oct 
gallistel time come 
neuron 
gallistel coordinate transformations genesis directed action 
bly editors cognitive science pages 
academic new york 
gallistel gibbon time rate conditioning 
psychological review 
anderson mirror test 
allen editors cognitive animal empirical theoretical perspectives animal cognition 
mit press cambridge ma 
self recognition primates comparative approach bidirectional properties consciousness 
american psychologist 
failure find self recognition mother infant rhesus monkey pairs 

chimpanzees self recognition 
science jan 
gardiner curve ellipse rectangle 
scientific american 
vaughan howard player stage project tools multi robot distributed sensor systems 
proceedings th international conference advanced robotics pages coimbra portugal june 
gibbon scalar expectancy theory weber law animal timing 
psychological review 
gibbon origins scalar timing 
learning motivation february may 
gibbon church sources variance information processing theory timing 
roitblat terrace editors animal cognition pages 
erlbaum associates hillsdale nj 
gibbon dale gallistel neurobiology temporal cognition advances challenges 
current opin neurobiology 
gibbs jr embodiment cognitive science 
cambridge university press 
gibson principles perceptual learning development 
appleton century crofts new york 
gibson ecological approach visual perception 
houghton mifflin boston 
experimental analysis behavioral effects perceptual consequence unrelated organic drive states 
american psychologist 
glenberg memory 
behavioral brain sciences 
glickman curiosity zoo animals 
behaviour 
go browning veloso accurate flexible simulation dynamic vision centric robot 
technical report cmu cs computer science department carnegie mellon university pittsburgh pa november 
goldstein king west social interaction shapes babbling testing parallels speech 
proceedings national academy sciences pnas june 
tool aimed throwing community free living chimpanzees 
nature 
goodall van tools egyptian 
nature 
taylor moore complex movements evoked cortex 
neuron may 
cooke taylor coding location arm sight 
science december 
green eggert stark bowyer generic recognition articulated objects reasoning potential function 
computer vision image understanding september 
hall tool behavior california sea otter 
journal 
haralick shapiro computer robot vision chapter object models matching 
addison wesley 
harnad symbol grounding problem 
physica 

garden city 
hayes second naive physics manifesto 
formal theories commonsense world 
ablex 
head holmes sensory disturbances cerebral lesions 
brain 
herv sharma geometry visual coordination 
proceedings ninth national conference artificial intelligence aaai pages 
hirai hirose development honda humanoid robot 
proceedings international conference robotics automation leuven belgium may 
hodges naive mechanics computational model device function design improvisation 
ieee expert pages february 
hodges naive mechanics taxonomy representation primitives representing reasoning problem solving simple mechanical device 
aaai workshop reasoning function page washington july 
hodges functional physical object characteristics object recognition improvisation 
computer vision image understanding 
huang mason impulsive manipulation 
ieee international conference robotics automation pages 
hunt intrinsic motivation role psychological development 
levine editor nebraska symposium motivation pages lincoln 
university nebraska press 
cognitive theory exploratory behavior 
archer editors exploration animals humans pages 
van nostrand reinhold england 
iriki personal communication 
mail november 
iriki tanaka coding modified body schema tool macaque neurons 

iriki tanaka self images video monitor coded monkey neurons 
neuroscience research 
iriki acquisition development monkey tool behavioral kinematic analyses 
canadian journal physiology pharmacology 
itakura mirror guided behavior japanese monkeys 
primates 
exploratory behavior development perceiving acting acquiring knowledge 
annual review psychology 
jones infants learn imitate imitated 
proceedings fifth international conference development learning bloomington may june 
kang robot instruction human demonstration 
phd thesis robotics institute carnegie mellon university 
kang ikeuchi automatic robot instruction perception temporal segmentation tasks human hand motion 
ieee transactions robotics automation october 
kawamura process sub culture propagation japanese 
primates 
functions flint tools 
isaac editors human ancestors readings scientific american pages 
freeman 
originally published nov 
kimura evolution human communication 
raleigh editors neurobiology social communication primates evolutionary perspective pages 
academic press new york 
dan function model simple tools application recognition shapes 
technical report tech 
gr 
sig fai 
dan consideration functional models 
information modeling knowledge bases pages 
ios amsterdam 
kl ver behavior mechanisms monkeys 
behavior research fund monographs 
university chicago press chicago il 
hler mentality apes 
harcourt brace new york 
translated winter 
schaal synchronized robot neural oscillator 
journal robotics society japan 
perception material properties robotic probing preliminary investigations 
international joint conference artificial intelligence pages montreal august 
lack darwin 
scientific america 
lewis brooks gunn social cognition acquisition self 
plenum press new york 
li cox shelton barry 
development telepresence controlled robot space application 
proceedings ieee international conference robotics automation pages 
lieberman uniquely human evolution speech thought behavior 
harvard university press cambridge ma 
littman sutton singh predictive state 
advances neural information processing systems volume 
lorenz innate bases learning 
king editors learning self organization 
lawrence erlbaum associates publishers mahwah new jersey 
lowry reasoning structure function 
proceedings image understanding workshop pages 
science applications 
lynch issues manipulation 
agarwal kavraki mason editors robotics algorithmic perspective third workshop algorithmic foundations robotics pages 
peters natick ma 
lynch mason dynamic manipulation controllability planning experiments 
international journal robotics research 
mackenzie arkin behavior mobile manipulation drum sampling 
ieee international conference robotics automation pages minneapolis mn april 
mackenzie cameron arkin multiagent mission specification execution 
autonomous robots january 
mah mussa ivaldi evidence specific internal representation motion force relationships object manipulation 
biological cybernetics 
mason manipulator grasping pushing operations 
phd thesis artificial intelligence laboratory massachusetts institute technology 
mason mechanics planning manipulator pushing operations 
international journal robotics research 
mason mechanics robotic manipulation 
mit press 
chimpanzees material culture implications human evolution 
cambridge university press cambridge 
socialization object manipulation wild chimpanzees 
chevalier editors primate bio social development biological social ecological determinants number 
garland new york 
evolutionary implications sex differences chimpanzee predation tool 
hamburg editors great apes 
benjamin cummings menlo park ca 
phantom limbs 
scientific american april 
menzel jr lawson chimpanzee pan spatial problem solving mirrors equivalents mirrors 
journal comparative psychology 
menzel evolution new species 
material world mit press cambridge ma 
michael professional mobile robot simulation 
international journal advanced robotic systems 
see www com 
michel gold scassellati motion robotic self recognition 
ieee rsj international conference intelligent robots systems iros sendai japan 
montgomery exploratory behavior function similarity stimulus situations 
journal comparative physiological psychology 
montgomery segall discriminative learning exploratory drive 
journal comparative psychology 
morasso self organizing body schema motor planning 
journal motor behavior 
shapiro haralick matching sticks plates blobs objects geometric relational constraints 
image vision computing 
kuniyoshi timing model body schema adaptation role perception tool robot case study 
proc 
th intl 
conference development learning pages july 
newcombe huttenlocher making space development spatial representation reasoning 
mit press cambridge ma 
action perception 
mit press cambridge ma 
regan sensorimotor account vision visual consciousness 
behavioral brain sciences 
virginia behavior california ground 
animal behavior 
cross snake california ground adaptive variation ontogeny 
behaviour 
hand tool functional architecture human technical skills 
editors tools human non human primates pages 
oxford university press new york 
parker tools apes 

parker gibson object manipulation tool sensorimotor intelligence feeding adaptations monkeys great apes 
hum 
evol 
parker mitchell editors 
self awareness animals humans developmental perspectives 
cambridge university press cambridge 
parker developmental approach origins self recognition great apes 
human evolution 
pearl causality models reasoning inference 
cambridge university press 
pfeifer scheier understanding intelligence 
mit press 
piaget origins intelligence children 
international universities press new york 
pick st rung der eigen 
psychol 

de waal reiss self recognition asian elephant 
proceedings national academy sciences united states pnas november 
mckee understanding human evolution 
prentice hall upper saddle river new jersey fourth edition 
potts home bases early 
american scientific 
povinelli cant evolution 
quarterly review biology issue dec 
povinelli folk physics apes chimpanzee theory world works 
oxford university press oxford 
power play exploration children animals 
lawrence erlbaum associates publishers mahwah new jersey 
press teukolsky vetterling flannery numerical recipes art scientific computing 
cambridge university press cambridge new york second edition edition 
ramachandran brain probing mysteries human mind 
william morrow new york 
ramachandran rogers ramachandran phantom limbs induced mirrors 
proc 
royal society london series apr 
reed applying theory action systems study motor skills 
roth editors complex movement behavior motor action controversy pages 
elsevier sciences publishers north holland 
reiss marino mirror self recognition dolphin case cognitive convergence 
proceedings national academy sciences pnas may 
sea 
monterey bay monterey california 
rivlin dickinson rosenfeld recognition functional parts 
computer vision image understanding 
levels self awareness unfold early life 
consciousness cognition 
schaal atkeson robot juggling implementation memory learning 
control systems magazine 
das 
springer verlag berlin 
schultz 
princeton weekly bulletin april 
shapiro 
matching dimensional objects relational paradigm 
pattern recognition 
sharma herv dynamic robot manipulation visual tracking 
proceedings ieee international conference robotics automation pages 
sharma integrating configuration space sensor space robot motion planning 
laumond 
overmars editors workshop algorithmic foundations robotics algorithms robotic motion manipulation pages wellesley massachusetts 
peters 
beck factors affecting mirror western gorilla gorilla 
animal behaviour 
singh littman sutton stone learning predictive state representations 
draft unpublished 
skinner behavior organisms experimental analysis 
appleton century new york 
smith open dynamics engine ode user guide 
ode org date accessed may 
st wood tool autonomous agents 
proceedings national conference artificial intelligence aaai pages 
stansfield visually guided haptic object recognition 
phd thesis university pennsylvania dept computer information science 
technical report ms cis 
stansfield representing generic objects exploration identification 
proceedings ieee international conference robotics automation pages 
stansfield robotic grasping unknown objects knowledge approach 
international journal robotics research august 
stark bowyer generic object recognition form function volume series machine perception artificial intelligence 
world scientific singapore 
stark bowyer woods hall cook application machine learning function recognition 
ikeuchi veloso editors symbolic visual learning pages 
oxford university press new york 
stark bowyer achieving generalized object recognition reasoning association function structure 
ieee transactions pattern analysis machine intelligence october 
computational model extendable robot body schema 
technical report git cc georgia institute technology college computing october 
learning binding affordances objects behavior grounded approach 
proceedings aaai symposium developmental robotics pages stanford university mar 
evidence tool chimpanzees ivory coast 
primates 
sutton stark bowyer generalizing domain recognition system 
pattern recognition december 
sutton stark bowyer dishes don windows function modeling recognition rigid objects 
spie intelligent robots computer vision xi algorithms techniques active vision pages boston ma november 
sutton stark bowyer function generic recognition multiple object categories 
jain flynn editors dimensional object recognition systems pages 
elsevier science publishers 
sutton verification 
line essay www cs ualberta ca sutton verification html date accessed september 
sutton verification key ai 
line essay www cs ualberta ca sutton html date accessed september 
editors 
encyclopedia human evolution 
garland publishing new york 
acquire tool social learning 
proceedings royal society london series biological sciences november 
body schema body image interdisciplinary philosophical study 
swets zeitlinger amsterdam 
tomasello call primate cognition 
oxford university press new york 
temporal discrimination indifference interval implications model internal clock 
psychological monographs 
noise weber law discrimination brightness dimensions 
psychological review 
tsai efficient accurate camera calibration technique machine vision 
proceedings ieee conference computer vision pattern recognition pages miami beach fl 
tsai versatile camera calibration technique high accuracy machine vision metrology shelf tv cameras lenses 
ieee journal robotics automation ra august 
pinpointing upper limb prosthesis 
journal 
squares estimation transformation parameters point patterns 
ieee transactions pattern analysis machine intelligence pami 
van goodall tool primates vertebrates 
shaw editors advances study behavior volume pages 
academic press new york 
varela thompson rosch embodies mind cognitive science human experience 
mit press cambridge ma 
phylogenetic approach object manipulation human ape infants 
human development 
object structure action requirements compatibility model functional recognition 
international journal intelligent systems 
tool south american monkey species overview characteristics limits tool 
editors tools human non human primates pages 
clarendon press oxford 
lack comprehension cause effect relations tool monkeys 
journal comparative psychology 
tool monkeys distinguishing performing understanding 
primates 
wang jenkins hand representation adult cortex determined timing tactile stimulation 
nature nov 
tools human evolution 
isaac editors human ancestors readings scientific american 
freeman 
originally published sep 
watson contingency perception early social development 
field fox editors social perception infants pages 
ablex pub 
norwood 
watson detection self perfect algorithm 
parker mitchell editors self awareness animals humans developmental perspectives pages 
cambridge university press cambridge 
weir chappell shaping hooks new 
science august 
executive competence prospective observational study 
genetic psychology monographs 
weng mcclelland pentland sporns sur thelen autonomous mental development robots animals 
science jan 
mirror inspection varies age tool ability monkeys 
human evolution 
white motivation reconsidered concept competence 
psychological review 
tsai camera calibration software 
document source code downloaded www cs cmu edu html date accessed january 
wilson sociobiology new synthesis 
cambridge ma 
wolff developmental jean piaget 
psychological issues 
monograph 
chimpanzees laboratory colony 
yale university press new haven 
great apes study life 
yale university press new haven 
yoshikawa hosoda asada cross anchoring binding tactile visual sensations unique association self perception 
proceedings third international conference development learning 
yoshikawa asada hosoda body scheme acquisition cross map learning tactile image proprioceptive spaces 
proceedings second international workshop epigenetic robotics 
epigenetic robotics 
proceedings international workshop epigenetic robotics september 
erdmann palm manipulation nonequilibrium transitions stable states 
ieee international conference robotics automation pages 

