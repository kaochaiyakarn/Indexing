multiple instance learning disjunctive programming boosting stuart andrews department computer science brown university providence ri stu cs brown edu thomas hofmann department computer science brown university providence ri th cs brown edu learning ambiguous training data highly relevant applications 
new learning algorithm classification problems labels associated sets pattern individual patterns 
encompasses multiple instance learning special case 
approach generalization linear programming boosting uses results disjunctive programming generate successively stronger linear relaxations discrete non convex problem 
applications machine learning inherently difficult prohibitively expensive generate large amounts labeled training data 
considerably challenging provide weakly labeled data labels annotations associated sets patterns bags individual patterns bags reflect fundamental ambiguity correspondence patterns associated label expressed logically disjunction form example class 
plain english labeled bag contains pattern possibly belonging class identities patterns unknown 
special case particular relevance known multiple instance learning mil 
mil labels binary ambiguity asymmetric sense bags negative labels size 
label uncertainty restricted members positive bags 
interesting problems training data kind arises quite naturally including drug activity prediction content image indexing text categorization :10.1.1.31.4110:10.1.1.86.8281
ambiguity typically arises polymorphisms allowing multiple representations molecule different conformations part am annotations may associated images documents attached objects image passages document 
notice intertwined objectives goal may learn pattern level classifier ambiguous training examples may primarily interested classifying new bags necessarily resolving ambiguity individual patterns 
number algorithms developed mil including special purpose algorithms axis parallel rectangular hypotheses diverse density neural networks kernel methods 
versions learning architecture solving multiple instance learning problem :10.1.1.86.8281
combinatorial nature problem simple optimization heuristic learn discriminant functions :10.1.1.86.8281
take principled approach carefully analyzing nature resulting optimization problem deriving sequence successively stronger relaxations compute lower upper bounds objective 
turns exploiting sparseness crucial aspect focused linear programming formulation generalizing algorithm call resulting method disjunctive programming boosting 
linear programming boosting linear programming approach boosting aims learning ensemble classifiers form sgn khk hk called base classifiers weak hypotheses features combination weights 
ensemble margin labeled example defined yf 
set labeled training examples xm ym formulates supervised learning problem norm soft margin objective yif xi 
min controls tradeoff hinge loss regularization term 
notice formulation remains meaningful training examples just negative just positive 
dual program eq 
written max ui xi ui 
useful take closer look kkt complementary conditions ui yif xi xi 
optimal values slack variables implicitly determined yif xi set conditions states ui yif xi 
ui interpreted misclassification cost implies instances tight margin constraints may non vanishing associated costs 
second set conditions ensures xi states weak hypothesis hk included ensemble weighted score xi strictly maximum score 
typical solution may sparse ways small number weak hypothesis may contribute ensemble ii solution may depend subset training data instances ui 
exploits sparseness ensemble incrementally selecting columns simplex tableau optimizing smaller tableau 
amounts finding round hypothesis hk constraint eq 
violated adding ensemble re optimizing tableau selected columns 
column selection heuristic authors propose magnitude violation pick weak hypothesis hk maximal score xi 
disjunctive programming boosting order deal pattern ambiguity employ disjunctive programming framework 
spirit transductive large margin methods propose estimate parameters discriminant function way achieves large margin patterns bag :10.1.1.33.4031
applying principle compile training data set disjunctive constraints 
extend define polyhedra hi yi khk 
formulate disjunctive program min 
hi 
xi notice xi constraint imposed xi highly non convex defined union halfspaces 
trivial bags xi resulting constraints eq 

handle cases quite differently sequel introduce index sets xi xj 
suitable way define relaxation non convex optimization problem replace disjunctive set eq 
convex hull 
shown hierarchy relaxations built fundamental fact cl conv cl conv cl conv cl conv denotes closure convex hull limiting points means tighter convex relaxation obtained intersect sets possible convex hull 
repeated intersections disjunctive sets element leads combinatorial blow number constraints propose intersect ambiguous disjunctive constraint non ambiguous constraint called parallel reduction step 
results convex relaxation constraints eq 
cl conv hi hj xj xi abused notation slightly identified xj xj bags pattern 
rationale relaxation resulting convex optimization problem tractable may provide reasonably accurate approximation original disjunctive program strengthened combination branch bound search 
lift project representation convex hulls eq 
characterize feasible set projection higher dimensional polyhedron explicitly characterized 
proposition 
assume set non empty linear constraints hi 
cl conv hi exist proof 
pause briefly recapitulate achieved far 
derived lp relaxation original disjunctive program boosting ambiguity 
relaxation obtained linearization original non convex constraints 
furthermore demonstrated relaxation improved parallel reduction steps 
applying linearization convex hull eq 
individually notice needs introduce duplicates parameters slack variables xi 
addition constraints xi relevant constraint set ambiguous bag xi resulting lp written xi yi khk xi yj khk xj xi xi 
margin constraint eq 
associated specific pattern second set margin constraints eq 
stems parallel reduction performed unambiguous bags 
calculate dual lp relaxation derivation appendix 
resulting program complicated bound structure variables crucial constraints involving data xi hk hk xj ik ik 
size resulting problem significant 
result linearization parallel reductions number parameters primal lp denote number patterns ambiguous unambiguous bags compared standard 
number constraints variables dual inflated significantly number ambiguous bags 
order maintain spirit dealing efficiently large scale linear program propose maintain column selection scheme selecting round 
notice column selection proceed independently equality constraints xi xi particular implies xi xi propose simultaneously add columns xi involving weak hypothesis prune back boosting round order exploit expected sparseness solution 
order select feature hk compute score hk hk xj 
ik ik max notice due block structure tableau working reduced set columns eliminates large number inequalities rows 
large set inequalities parallel reductions prohibitive 
order address problem propose perform incremental row selection outer loop 
converged column basis current relaxed lp add subset rows corresponding useful parallel reductions 
magnitude margin violation heuristic perform row selection 
propose score khk xj xi yj means current values duplicated ensemble weights selects parallel reduction margin constraint associated ambiguous pattern unambiguous pattern violated strongly 
margin constraints imposed unambiguous training instances xj yj redundant performed parallel reduction step eq 
add problem give better starting point respect row selection process may lead sparser solution 
add constraints primal khk xj yj introduce additional dual variables uj notice worst case inequalities imposed ambiguous training instances xi vacuous sure recovers standard formulation unambiguous examples 
think row generation process way deriving useful information ambiguous examples 
information takes form linear inequalities high dimensional representation convex hull sequentially reduce version space set feasible pairs 
algorithm algorithm initialize ux xi uj uj repeat repeat column selection select hk maximal hk xi solve lp max row selection select set pairs maximal ux solve lp max left normalized intensity plot generate synthetic data sets 
right performance relative degree label ambiguity 
mean standard deviation pattern level classification accuracy plotted versus solid perfect selector dotted dashed naive algorithms 
plots correspond data sets size 
experiments generated set synthetic weakly labeled data sets evaluate small scale 
multiple instance data sets label uncertainty asymmetric ambiguous bags xi positive 
specifically generated instances sampled uniformly random white yi black yi regions leaving intermediate gray area separating margin :10.1.1.86.8281
degree ambiguity controlled generating ambiguous bags size poisson having positive negative patterns 
control data set size generated pre specified number ambiguous bags number singleton unambiguous bags 
proof concept benchmark compared classification perfomance variants perfect knowledge perfect selector naive algorithms 
variants base algorithm slightly different preprocessing steps accomodate mil data sets 
corresponds supervised algorithm true pattern level labels 
algorithm deal ambiguity perform better 
second uses true pattern level labels prune negative examples ambiguous bags solves smaller supervised problem 
algorithm provides interesting benchmark performance best hope 
extreme third variant assumes ambiguous pattern labels equal respective bag labels 
algorithms thresholded rbf features 
shows discriminant boundary black line learned algorithms data set generated having ambiguous bags 


total 
ambiguous patterns marked unambiguous ones background shaded indicate value ensemble clamped 
clear shading ensemble small number active features perfect selector perfect knowledge algorithms 
classifier report pattern level classification accuracy uniform grid points 
sparsity dual variables verified percent dual variables reductions active 
ran fold cross validation synthetic data sets data sets having 
right side shows mean pattern level classification accuracy error bars showing standard deviation function discriminant boundaries learned naive accuracy perfect selector perfect knowledge algorithms 
parameter 
new learning algorithm classification problems labels associated sets pattern individual patterns 
synthetic data expected behaviour algorithm demonstrated 
current implementation handle large data sets improvements followed large scale validation comparison algorithms benchmark mil data sets follow 
acknowledgments david making cplex mex interface available online 
ioannis tsochantaridis keith hall useful discussion advice 
sponsored nsf itr award number iis 
stuart andrews ioannis tsochantaridis thomas hofmann :10.1.1.86.8281
support vector machines multiple instance learning 
advances neural information processing systems volume 
mit press 
egon balas 
disjunctive programming hierarchy relaxations discrete optimization problems 
siam journal algebraic discrete methods july 
bennett 
optimization approaches semisupervised learning 
ferris mangasarian pang editors applications algorithms complementarity 
kluwer academic publishers boston 
demiriz kristin bennett john shawe taylor 
linear programming boosting column generation 
machine learning 
dietterich lathrop lozano perez 
solving multiple instance problem axis parallel rectangles 
artificial intelligence 
rtner flach kowalczyk smola 
multi instance kernels 
proc 
th international conf 
machine learning 
morgan kaufmann san francisco ca 
grove schuurmans 
boosting limit maximizing margin learned ensembles 
proceedings fifteenth national conference artifical intelligence 
joachims 
transductive inference text classification support vector machines 
proceedings th international conference machine learning pages 
morgan kaufmann san francisco ca 
lee grossmann 
new algorithms nonlinear generalized disjunctive programming 
computers chemical engineering journal october 
maron :10.1.1.31.4110
multiple instance learning natural scene classification 
proc 
th international conf 
machine learning pages 
morgan kaufmann san francisco ca 
ramon de raedt 
multi instance neural networks 
proceedings icml workshop attribute value relational learning 
tsch onoda 
ller 
soft margins adaboost 
technical report nc tr department computer science royal holloway university london egham uk 
gunnar tsch sebastian mika bernhard sch lkopf klaus robert ller 
constructing boosting algorithms svms application class classification 
ieee transactions pattern analysis machine intelligence 
qi zhang sally goldman 
em dd improved multiple instance learning technique 
advances neural information processing systems volume 
mit press 
appendix primal variables dual variables ux margin constraints ik equality constraints respectively 
lagrangian xi ik yj xi xi yi khk xj xi xi xi xi khk ij derivatives primal variables leads dual max ij hk hk xj ik ik xi xi ij xi 
