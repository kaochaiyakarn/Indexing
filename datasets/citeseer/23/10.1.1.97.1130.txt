advances clustering brief survey department mathematics university patras educational software development laboratory math gr unsupervised learning clustering deals instances pre classified way class attribute associated 
scope applying clustering algorithms discover useful unknown classes items 
unsupervised learning approach learning instances automatically placed meaningful groups similarity 
introduces fundamental concepts unsupervised learning surveys clustering algorithms 
advances unsupervised learning ensembles clustering algorithms distributed clustering described 
key words pattern analysis machine intelligence intelligent systems cluster analysis unsupervised learning method constitutes cornerstone intelligent data analysis process 
exploration inter relationships collection patterns organizing homogeneous clusters 
called unsupervised learning classification known supervised learning priori labeling patterns available categorizing inferring cluster structure data 
intra connectivity measure density connections instances single cluster 
high intra connectivity indicates clustering arrangement instances grouped cluster highly dependent 
inter connectivity measure connectivity distinct clusters 
low degree interconnectivity desirable indicates individual clusters largely independent 
instance data set represented set attributes 
attributes continuous categorical binary 
induce hypothesis data set learning system needs assumptions hypothesis learned 
assumptions called biases 
learning algorithm uses biases behaves domains biases appropriate performs poorly domains 
problem clustering methods interpretation clusters may difficult 
addition algorithms assign data clusters clusters data 
goal inferences cluster structure essential analyze data set exhibits clustering tendency 
real world application may errors called noise collected data set due inaccurate measurement due missing values pre processing needed choose strategy handling missing attribute values 
choice specific learning algorithm critical step 
issue relating learning algorithms type data nature problem solved remains open fundamental problem 
evaluation criterion clustering quality unknown attribute prediction accuracy 
step unseen instance removing value attributes trying classify 
missing attribute unseen instance predicted value attribute closest matching instance 
value compared actual value removed attribute judged correct 
process repeated attribute 
number attributes correctly predicted divided number attributes order give average prediction accuracy 
cluster analysis difficult problem factors effective similarity measures criterion functions algorithms initial conditions come play devising tuned clustering technique clustering problem 
known clustering method adequately handle sorts cluster structures shape size density 
quality clusters improved pre processing data 
uncommon try find noisy values eliminate preprocessing step 
common technique post processing steps try fix clusters 
example small clusters eliminated frequently represent groups outliers instances noise 
alternatively small clusters close merged 
large clusters split smaller clusters 
outlier detection major technologies data mining task find small groups data objects exceptional compared rest large amount data 
outlier mining strong application background telecommunication financial fraud detection data cleaning patterns lying outliers usually interesting helping decision makers profit improve service quality 
years outliers draw attention outlier detection studied intensively data mining community 
missing value problem occur due occasional sensor failures 
simple wasteful method cope problem throw away incomplete attribute vectors 
logical method missing attribute values numeric attributes instantiate median value attribute training instances 
missing attribute values categorical attributes replaced mode value attribute training instances 
comparisons various methods dealing missing data 
usually statistical point view instances irrelevant input attributes provide little information 
practical applications wise carefully choose attributes provide learning algorithm 
different algorithms developed purpose 
example accomplished discarding attributes show little variation highly correlated attributes 
generally clustering algorithms categorized partitioning methods hierarchical methods density methods grid methods model methods 
excellent survey clustering techniques jain 
apart brief description clustering techniques refer works jain article articles referred jain 
reader cautioned single article couldn comprehensive review learning algorithms 
goal provide representative sample research learning technique 
areas papers describe relevant 
typical applications clustering fields han kamber 
partitioning algorithms construct various partitions evaluate criterion described section 
hierarchical algorithms create hierarchical decomposition instances criterion covered section 
section explains density algorithms connectivity density functions 
section describes grid methods multiple level granularity structure 
model algorithms covered section advances clustering techniques ensembles clustering algorithms described section 
final section concludes 
partitioning methods partitioning methods divided major subcategories centroid medoids algorithms 
centroid algorithms represent cluster gravity centre instances 
medoid algorithms represent cluster means instances closest gravity centre 
known centroid algorithm means 
means method partitions data set subsets points subset closest centre 
detail randomly selects instances represent clusters 
selected attributes remaining instances assigned closer centre 
means computes new centers mean data points belonging cluster 
operation iterated change gravity centres 
known ahead time various values evaluated suitable 
effectiveness method relies heavily objective function measuring distance instances 
difficulty finding distance measure works types data 
approaches define distance instances 
generally means algorithm important properties 
efficient processing large data sets 
terminates local optimum 
clusters spherical shapes 
sensitive noise 
algorithm described classified batch method requires data available advance 
variants means clustering process gets limitation 
choosing proper initial centroids key step basic means procedure 
modes algorithm partitioning algorithm uses simple matching coefficient measure deal categorical attributes 
prototypes algorithm definition combined dissimilarity measure integrates means modes algorithms allow clustering instances described mixed attributes 
generalization conventional means clustering algorithm 
new applicable ellipse shaped data clusters ball shaped ones dead unit problem performs correct clustering pre determining exact cluster number 
traditional clustering approaches generate partitions partition pattern belongs cluster 
clusters hard clustering disjoint 
fuzzy clustering extends notion associate pattern cluster membership function 
larger membership values indicate higher confidence assignment pattern cluster 
widely algorithm fuzzy means fcm algorithm means 
fcm attempts find characteristic point cluster considered center cluster grade membership instance clusters 
soft clustering algorithms developed expectation maximization em algorithm 
assume underlying probability model parameters describe probability instance belongs certain cluster 
strategy algorithm start initial guesses mixture model parameters 
values calculate cluster probabilities instance 
probabilities turn re estimate parameters process repeated 
drawback algorithms tend computationally expensive 
problem previous approach called overfitting 
problem caused reasons 
hand large number clusters may specified 
distributions probabilities parameters 
context possible solution adopt fully bayesian approach parameter prior probability distribution 
hierarchical algorithms create hierarchical decomposition instances covered section 
hierarchical clustering hierarchical methods group data instances tree clusters 
major methods category 
agglomerative method forms clusters bottom fashion data instances belong cluster 
divisive method splits data set smaller cluster top fashion cluster contains instance 
divisive algorithms agglomerative algorithms represented dendrograms 
agglomerative divisive methods known quick termination 
methods suffer inability perform adjustments splitting merging decision 
advantages require number clusters known advance computes complete hierarchy clusters result visualizations integrated methods flat partition derived cut dendrogram 
hierarchical clustering techniques various criteria decide locally step clusters joined split divisive approaches 
agglomerative hierarchical techniques criterion typically merge closest pair clusters close defined specified measure cluster proximity 
definitions closeness clusters single link complete link average link 
single link similarity clusters similarity similar instances appears cluster 
single link handling non elliptical shapes sensitive noise outliers 
complete link similarity similarity dissimilar instances cluster 
complete link susceptible noise outliers break large clusters trouble convex shapes 
average link similarity compromise 
hierarchical clustering algorithms balanced iterative reducing clustering hierarchies birch clustering representatives cure chameleon 
birch uses hierarchical data structure called cf tree partitioning incoming data points incremental dynamic way 
cf tree height balanced tree stores clustering features parameters branching factor threshold refer diameter cluster diameter radius cluster 
cf tree built data scanned 
data point encountered cf tree traversed starting root choosing closest node level 
closest leaf cluster current data point identified test performed see adding data item candidate cluster result new cluster diameter greater threshold birch typically find clustering single scan data improve quality additional scans 
handle noise effectively 
birch reasonably fast intelligent alternative data sampling order improve scalability clustering algorithms 
birch drawback may clusters spherical uses concept radius diameter control boundary cluster 
addition order sensitive may generate different clusters different orders input data 
bubble bubble fm clustering algorithms extensions birch general metric spaces categorical values attributes 
cure single centroid represent cluster constant number representative points chosen represent cluster 
number points chosen parameter value worked 
similarity clusters measured similarity closest pair representative points belonging different clusters 
centroid medoid methods cure capable finding clusters arbitrary shapes ellipsoidal spiral cylindrical non convex sizes represents cluster multiple representative points 
shrinking representative points centroid helps cure avoiding problem noise single link method 
applied directly large data sets 
reason cure takes random sample performs hierarchical clustering sampled data points 
rock clustering algorithm categorical data jaccard coefficient measure similarity 
accepts input set sampled points clustered drawn randomly original data set number desired clusters rock samples data set manner cure 
chameleon finds clusters data set phase algorithm 
step generates nearest neighbor graph contains links point nearest neighbors 
chameleon uses graph partitioning algorithm cluster data items large number relatively small sub clusters 
second phase uses agglomerative hierarchical clustering algorithm find genuine clusters repeatedly combining sub clusters 
cluster contain user specific number instances 
novel incremental hierarchical clustering algorithm grin numerical data sets gravity theory physics 
main factor grin algorithm able deliver favorite clustering quality optimal parameters settings grin algorithm sensitive distribution data set 
density clustering density clustering algorithms try find clusters density data points region 
key idea density clustering instance cluster neighborhood radius eps contain minimum number instances minpts 
known density clustering algorithms dbscan 
dbscan separate data points classes fig 
core points 
points interior cluster 
point interior point points neighborhood 
border points 
border point point core point points neighborhood falls neighborhood core point 
noise points 
noise point point core point border point 
find cluster dbscan starts arbitrary instance data set retrieves instances respect eps minpts 
algorithm spatial data structure tree locate points eps distance core points clusters 
incremental version dbscan incremental dbscan 
proven incremental algorithm yields result dbscan 
addition clustering algorithm generalizing density algorithm dbscan 
cluster point instances numerical categorical attributes 
parallel version dbscan 
furthermore distribution clustering large spatial data sets eliminates need minpts eps parameters 
incrementally augments initial cluster neighboring points long nearest neighbor distance set resulting cluster fits expected distance distribution 
distance set cluster fit expected distance distribution necessarily hold subsets cluster 
order testing candidates crucial 
new algorithm optics introduced creates ordering data set representing density clustering structure 
versatile basis interactive cluster analysis 
density algorithm 
basic idea model point density analytically sum influence functions data points 
influence function seen function describes impact data point neighbourhood 
determining maximum density function identify clusters 
algorithm allows compact mathematical description arbitrarily shaped clusters high dimensional data sets significantly faster density clustering algorithms 
produces clustering results large amount noise 
approaches quality resulting clustering depends adequate choice parameters 
approach important parameters 
parameter determines influence point neighborhood describes density attractor significant 
density attractors local maxima density function 
fdc algorithm fast density clustering density clustering defined density linked relationship 
clustering algorithm defined equivalence relationship objects database 
complexity fdc linear size database faster algorithm dbscan 
algorithm snn shared nearest neighbors blends density approach idea rock 
snn similarity matrix keeping nearest neighbors derives total strength links grid clustering grid clustering algorithms quantize clustering space finite number cells hyper rectangles perform required operations quantized space 
cells contain certain number points treated dense dense cells connected form clusters 
grid clustering algorithms statistical information grid method sting clustering quest clique 
sting divides spatial area levels rectangular cells order form hierarchical structure 
cells high level composed cells lower level 
generates hierarchical structure grid cells represent clustering information different levels 
sting generates clustering results short running time major problems algorithm 
firstly performance sting relies granularity lowest level grid structure 
secondly resulting clusters bounded horizontally vertically diagonally 
shortcoming greatly affect cluster quality 
clique grid clustering algorithm 
clique starts finding dense areas dimensional spaces corresponding attribute 
clique generates set dimensional cells possibly dense looking dense dimensional cells dimensional cell associated pair dense dimensional cells 
generally clique generates possible set dimensional cells possibly dense looking dense dimensional cells 
clique produces identical results irrespective order input records 
addition generates cluster descriptions form dnf expressions ease comprehension 
empirical evaluation shows clique scales linearly number instances scalability number attributes increased 
clustering methods require users give number clusters 
uses wavelet transformation transform original feature space 
wavelet transform convolution appropriate function results transformed space natural clusters data distinguishable 
powerful method efficient high dimensional space 
model methods autoclass uses bayesian approach starting random initialization parameters incrementally adjusts attempt find maximum likelihood estimates 
assumed addition observed predictive attributes hidden variable 
unobserved variable reflects cluster membership case data set 
data clustering problem example supervised learning incomplete data due existence hidden variable 
approach learning called recursive bayesian multinets 
model method som net 
som net thought layers neural network 
neuron represented dimensional weight vector mn equal dimension input vectors 
neurons som cluster centers accommodate interpretation map units combined form bigger clusters 
som trained iteratively 
training step sample vector input data set chosen randomly distance weight vectors som calculated distance measure euclidean distance 
finding best matching unit neuron weight vector closest input vector weight vectors som updated best matching unit moved closer input vector input space 
topological neighbors treated similar way 
important property som robust 
outlier easily detected map distance input space units large 
som deal missing data values 
applications require clustering large amounts high dimensional data 
automated clustering techniques effectively efficiently high dimensional data clusters certain unexpected characteristics 
various reasons 
difficult find necessary parameters tuning clustering algorithms specific applications characteristics 
second hard verify interpret resulting high dimensional clusters third concept clusters inspired low dimensional cases extended high dimensional cases 
solution integrating requirements single algorithm try build combination clustering algorithms ensembles clustering algorithms 
ensembles clustering algorithms theoretical foundation combining multiple clustering algorithms early stages 
fact combining multiple clustering algorithms challenging problem combining multiple classifiers 
reason impede study clustering combination identified various clustering algorithms produce largely different results due different clustering criteria combining clustering results directly integration rules sum product median majority vote generate meaningful result 
cluster ensembles formed number different ways number different clustering techniques deliberately arbitrarily selected 
single technique times different initial conditions 
different partial subsets features patterns 
split merge strategy followed 
step decompose complex data small compact clusters 
means algorithm serves purpose ensemble clustering algorithms produced random initializations cluster centroids 
data partitions clusterings mapped new similarity matrix patterns voting mechanism 
matrix independent data sparseness extract natural clusters single link algorithm 
idea combining multiple different clustering algorithms set data patterns weighted shared nearest neighbors graph introduced 
due increasing size current databases constructing efficient distributed clustering algorithms attracted considerable attention 
distributed clustering assumes objects clustered reside different sites 
transmitting objects central site denoted server apply standard clustering algorithms analyze data data clustered independently different local sites denoted clients 
subsequent step central site tries establish global clustering local models representatives 
generally far distributed clustering concerned different scenarios feature distributed clustering fdc consists combining set clusterings obtained clustering algorithm having partial view data features 
object distributed clustering odc consists combining clusterings obtained clustering algorithm access set data features limited number objects 
feature object distributed clustering consists combining clusterings obtained clustering algorithm having access limited number objects features data 
list comprehensive list papers discussing unsupervised methods aim produce critical review key ideas simple list publications discussed ideas 
despite hope cited cover major theoretical issues provide routes main branches literature dealing methods 
generally say partitioning algorithms typically represent clusters prototype 
iterative control strategy optimize clustering average squared distances instances prototypes minimized 
consequently clustering algorithms effective determining clustering clusters convex shape similar size density number clusters reasonably estimated 
general disability identify appropriate number clusters fundamental shortcomings non hierarchical techniques 
hierarchical clustering algorithms decompose data set levels partitioning usually represented dendrogram tree splits data set recursively smaller subsets 
hierarchical clustering algorithms effective knowledge discovery cost creating dendrograms prohibitively expensive large data sets 
density approaches apply local cluster criterion popular purpose data set mining 
clusters regarded regions data space instances dense separated regions low instance density noise 
regions may arbitrary shape points inside region may arbitrarily distributed 
performance comparison shows dbscan slightly faster dbscan faster hierarchical clustering algorithms partitioning algorithms 
generally grid clustering algorithms separate clustering space finite number cells hyper rectangles perform required operations quantized space 
cells contain certain number points treated dense dense cells connected form clusters 
solution better results integrating requirements single algorithm try build combination clustering algorithms 
theoretical foundation combining multiple clustering algorithms early stages needed direction 
addition study impact coordinated sub sampling strategies performance quality object distributed clustering 
question determine types overlap object ownership structures lend particularly knowledge reuse 
agrawal gehrke gunopulos raghavan 

automatic subspace clustering high dimensional data data mining applications 
proc 
acm sigmod conf 
management data 
ankerst breunig kriegel sander optics ordering points identify clustering structure proc 
acm sigmod int 
conf 
management data 
kamel 
finding natural clusters multi clusterer combiner shared nearest neighbors 
multiple classifier systems fourth international workshop mcs guildford surrey united kingdom june 
breunig 
kriegel ng sander 
lof identifying density local outliers 
proc 
sigmod pages 
cheeseman stutz bayesian classification autoclass theory results fayyad piatetsky shapiro smith uthurusamy editors advances knowledge discovery data mining pages aaai mit press 
ming cheung means new generalized means clustering algorithm pattern recognition letters 
chien yu chen ching hwang yen jen incremental hierarchical data clustering algorithm gravity theory gravity theory advances knowledge discovery data mining th pacific asia conference pakdd taiwan may springer verlag lncs 
ert steinbach kumar 
finding clusters different sizes shapes densities noisy high dimensional data 
proceedings second siam international conference data mining san francisco ca usa may 
ester kriegel sander xu 
density algorithm discovering clusters large spatial data sets noise 
proc 
nd int 
conf 
knowledge discovery data mining 
portland pp 

ester kriegel sander xu 
incremental clustering mining data warehousing environment proceedings th vldb conference new york usa 
fred jain 
data clustering evidence accumulation 
proceedings th international conference pattern recognition 
icpr volume pages quebec city quebec canada august 
gaede gunther 
multidimensional access methods acm computing surveys vol 

ganti ramakrishnan gehrke powell french clustering large datasets arbitrary metric spaces icde pp 

goebel gruenwald 
survey data mining knowledge discovery software tools sigkdd explorations vol 
june 
gordon 
clusters 
investigation procedures detecting nested cluster structure 
data science classification related methods edited hayashi tanaka bock baba 
tokyo springer verlag 
jerzy busse ming hu comparison approaches missing attribute values data mining rough sets current trends computing second international conference banff canada 
guha rastogi shim 
rock robust clustering algorithm categorical attributes proceedings ieee conference data engineering 
guha rastogi shim 
cure efficient clustering algorithm large data sets published proceedings acm sigmod conference 
hinneburg keim 
efficient approach clustering large multimedia data sets noise proceedings th international conference knowledge discovery data mining pages 
huang 
extensions means algorithm clustering large data sets categorical values data mining knowledge discovery 
jain murty 
data clustering review acm computing surveys vol 
jensen 
bayesian networks 
springer 
karypis han kumar 
chameleon hierarchical clustering algorithm dynamic modeling computer 
katayama satoh 
sr tree index structure high dimensional nearest neighbor queries proceedings acm sigmod international conference management data tucson arizona 
kohonen 
self organizing maps second extended edition springer series information sciences vol 
springer berlin heidelberg new york 
mclachlan krishnan 
em algorithm extensions sons 
ng han 
efficient effective clustering methods spatial data mining 
proc 
th int 
conf 
large data bases 
santiago chile pp 

pena lozano 
learning recursive bayesian multinets data clustering means constructive induction machine learning 
qian suen 
clustering combination method 
international conference pattern recognition 
icpr volume pages barcelona spain september 
ramaswamy rastogi shim 
efficient algorithms mining outliers large data sets 
proc 
sigmod pages 
sander martin ester hans peter kriegel xu density clustering spatial data sets algorithm applications data mining knowledge discovery kluwer academic publishers 
sato sato jain 
fuzzy clustering models applications studies fuzziness soft computing vol 
isbn chatterjee zhang 
multiresolution clustering approach large spatial data set 
proc 
th vldb conference 
strehl ghosh 
cluster ensembles knowledge reuse framework combining partitionings 
conference artificial intelligence aaai pages edmonton july 
aaai mit press 

dependency dimensionality reduction clustering symbolic data 
proceedings workshop pre post processing machine learning data mining advanced course artificial intelligence 
wang yang muntz 
sting statistical information grid approach spatial data mining proceedings rd vldb conference athens greece 
xu jager hans peter kriegel fast parallel clustering algorithm large spatial data sets data mining knowledge discovery 
xu ester kriegel sander 
nonparametric clustering algorithm knowledge discovery large spatial data sets proc 
ieee int 
conf 
data engineering ieee computer society press 
zhang ramakrishnan 
birch efficient data clustering method large data sets 
data mining knowledge discovery 
bo zhou david cheung ben kao fast algorithm density clustering large database pakdd lnai pp 

