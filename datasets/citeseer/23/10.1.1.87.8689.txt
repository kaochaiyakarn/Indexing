online filtering smoothing probabilistic modeling streaming data deshpande cs umd edu cs umd edu university maryland university maryland address problem extending relational database system facilitate efficient real time application dynamic probabilistic models streaming data 
proposed abstraction model views purpose allowing users declaratively specify model applied presenting output models user probabilistic database view 
support declarative querying views extended version sql allows querying probabilistic data 
underneath particle filters class sequential monte carlo algorithms commonly implement dynamic probabilistic models represent historical states model sets weighted samples particles kept date new readings arrive 
develop novel techniques convert queries model view directly queries particle tables enabling highly efficient query processing 
experimental evaluation prototype implementation sensor data intel lab dataset demonstrates feasibility online modeling streaming data system establishes advantages tight integration dynamic probabilistic models database systems 
enormous amounts streaming data generated everyday measurement infrastructures continuously monitor variety things environmental properties sensor networks behavior large computational clusters 
fully harvest benefits extensive monitoring able process analyze data streams real time 
years data stream management systems process high rate data streams real time continuously evaluate sql queries 
large class commonly stream processing tasks expressed sql queries benefit advances stream data processing 
examples tasks include inferring hidden variables real world data streams attributes interest may directly observable working status remotely located wireless sensor may expensive measure light berkeley mote 
common processing task data streams continuously infer value hidden variables observed data 
hidden markov models variations thereof purpose 
types models allow combine prior domain knowledge system behavior actual observations compute values hidden variables section 
eliminating measurement noise data streams generated distributed measurement infrastructures sensor networks gps devices invariably noisy calibration effects temperature sensors typically report voltages converted celsius errors due poor coupling analog digital conversion inaccuracies due non robust measurement techniques fail harsh environments multi path propagation errors occur gps urban settings inherent flaws mass produced sensing devices 
removing measurement noise important step analyzing data streams processing user queries 
analytical filtering techniques kalman filters section extensions extended kalman filters unscented kalman filters commonly purpose wide variety domains 
probabilistically modeling high level events low level sensor readings automatically recognizing higher level events user activities unobtrusive sensing technologies considered key field ubiquitous computing :10.1.1.1.5074
instance patterson demonstrate transportation mode user learned gps readings design guiding device cognitively impaired people :10.1.1.1.5074
increasing deployments large scale sensing infrastructures enable applications near 
ideally perform type modeling real time data generated streamed system application developers provided access inferred events subject privacy policies directly streaming fashion provide user services 
common stream processing tasks predictive modeling extrapolation fill missing values identifying temporal spatial trends patterns data novelty anomaly detection expressed sql queries 
applications majority analysis querying typically done outside database system leading repetition functionality highly inefficient execution 
start presenting motivating application detail subsection 
motivating application consider stream processing task inferring transportation mode velocity urban traveler gps data :10.1.1.1.5074
gps vital global utility indispensable modern navigation 
patterson show inferring transportation modes help building rich predictive models human behavior central theme ubiquitous computing :10.1.1.1.5074
shows simulated gps trace person going home plots trace road map 
note gps data contains inherent measurement noise due loss signal triangulation error multi path propogation prominent urban settings 
instance locate user parking lot gps readings indicate user 
query executed table bound errors readings represent raw measurement values underlying location person interest 
table gps readings directly querying purposes 
patterson show dynamic probabilistic model clean data infer velocity transportation mode gps data :10.1.1.1.5074
discuss specific form model take section essence model state system time variables obtain probability distribution possible states dpm 
iii shows possible output model user probabilistic view 
view provides consistent picture underlying model user variables interest 
system user free ask rich sql queries output models 
noted time position 

input gps data plot gps trace time position velocity mode vx vy 
walking walking driving driving driving driving driving driving walking walking 
output probabilistic view system gps trace urban traveler traveling home 
output dynamic probabilistic model clean gps data infer velocity transportation mode user deterministic database table 
queries posed velocity mode hidden attributes inferred dbn 
extensible system exploits commonalities tasks natively support inside relational database system 
aforementioned tasks seen applications specific instances dynamic probabilistic models streaming data proposed abstraction model views push application wide range streaming data inside relational dbms enabling easy application tasks 
contributions salient contributions follows extend abstraction model views output dpm users probabilistic tables leading intuitive user interaction system 
exploit structure particle filters widely applicable sequential monte carlo inference technique efficiently store probabilistic output dpm set weighted samples called particles 
internal representation naturally captures attributes correlations data 
design novel techniques convert queries posed single dpm view including aggregate queries queries internal particle representation allowing exploit existing query processing machinery 
experimental results show achieve sufficient accuracy particles time taken process large number particles quite reasonable 
system feasible online modeling streaming data 
rest organized follows 
overview dynamic probabilistic models section 
describe abstraction dpm views section detailed description system algorithms sections 
conclude experimental evaluation prototype implementation section 
dynamic probabilistic models dynamic probabilistic models widely practice model complex real world stochastic processes reason 
form active area research machine learning community playing increasingly important role design machine learning algorithms :10.1.1.56.7874:10.1.1.129.4770
simplest widely examples dynamic probabilistic models hidden markov models hmms linear dynamical systems better known kalman filter models 
illustrate dynamic probabilistic models describing simple applications hmms describe generalized graphical representation 
hidden markov models hidden markov models hmms variety applications speech recognition bioinformatics fault detection 
short hmms infer values unobservable hidden state variables imprecise observations related variables 
illustrate hmms simple fault detection application 
fault detection mass produced low cost sensor nodes important research problem widely studied literature 
consider example single sensor possibly faulty measuring temperatures room transmitting central database server 
want know sensor working correctly assume equivalent class dynamic bayesian networks 
literature considered general class models ones consider 
tt tt tt st min max st st st st vt vt vt xt xt vt xt vt zt xt xt ar hmm ii kfm graphical representations 
hmm fault detection ii kfm velocity location estimation 
ignore erroneous readings produced faulty sensors 
information sensor temperature readings transmits 
hmm infer sensor status readings 
example hidden variable measure status sensor states 
observed readings temperatures measured device 
shows graphical representation hmm model state system 
shaded node denotes observed temperature time denoted tt unshaded node denotes hidden status variable captures sensor working denoted st 
prior knowledge behavior system determine sensor failed captured conditional probability distributions tt tt st distribution captures expected behavior sensor sensor functioning correctly 
instance prior knowledge process expect time sensor return values tt plus small gaussian noise 
distribution learned historical data 
tt tt st distribution captures expected behavior sensor faulty 
simple way model assume sensor return value uniformly independently actual temperature 
clearly faulty behavior depends nature sensor 
st st shows possible table captures prior knowledge sensor small probability failing 
table indicates sensor working time probability fail time instant sensor failed probability time instant 
actual probabilities depend nature ar hmms auto regressive hmms specific class hmms 
sensor possibly manufacturing process devices type information typically available 
conditional distributions form parameters hmm 
combining observed temperatures data stream hmms provide mechanisms infer best possible estimate hidden variables case status sensor various times observed measurements 
common analytical algorithms purpose forward backward algorithms 
algorithms seen special cases general inference algorithms designed dynamic probabilistic models describe inference technique section :10.1.1.150.82
note model appropriate predicting temperature values current temperature appropriate fault detection 
model predict temperatures shown 
linear dynamical systems linear dynamical system commonly known kalman filter model kfm widely dynamic probabilistic model 
illustrate application 
interested computing position velocity car continuous observations position car inaccurate gps device 
velocity hidden variable measured directly 
furthermore actual position known inherent measurement noise gps data 
case state car time denoted xt vt xt denotes true location car assuming dimensional motion vt denotes velocity 
zt denote observed location car 
ii shows pictorial representation kfm application 
model described murphy 
similar earlier example summarize prior knowledge process equations equations easily recast conditional probability distributions shown ii 
zt xt xt xt vt vt vt equation specifies measurement noise assumed zero mean gaussian covariance affects observed locations equations encode movement object random perturbations location velocity subject 
kalman filter refers specific analytical inference algorithm lds model 
observed variables conditional distributions algorithm obtain distribution hidden variables velocity true location case seen special case general inference algorithms :10.1.1.25.968
continue call model kalman filter model kfm 
graphical representation generally speaking dynamic probabilistic model dpm compactly represent stochastic evolution set random variables time :10.1.1.129.4770
typically represented directed graphical structure shown graph structure captures complex interdependencies variables process 
illustrate graphical representation model shown graphical representation dpm modeling intel lab data section ii generic dpm mode estimation application discussed section 
call dpm 
model infer hidden temperature values observed humidity values sensor network remove noise observed humidity values section 
ii generic dpm transportation mode estimation example discussed section 
details graphical representation illustrated 
nodes nodes graph represent attributes system modeled modeled random variables 
attributes system modeled temperature tt humidity ht 
measured humidity mt hour day observed quantities 
convention observed nodes shaded hidden nodes clear 
edges directed edges represent causality 
temperature time influences temperature time 
similarly temperature time influences humidity time degree causality indicated conditional probability distribution function cpd 
cpd node indicated denotes parents node time time represented dpm vertical slices 
vertical slice graphical model corresponds state system time instant 
time advances unroll model repeating structure parameters model shown figures ii 
cpd key parameters dpm conditional probability distributions encode knowledge system monitored evolution time 
need sets probability distributions fully specify dpm prior unconditional probability distributions variables slice may parents 
conditional probability distributions encode knowledge state time depends state time conditional probability distributions encode knowledge observation time depends state time abstraction model views typically assumed variables time depend directly variables time markov assumption slice representation shown figures ii usually sufficient 
cpd node tt depends tt hour day ht 
hourly change temperature depends hour day 
temperature increases day decreases night magnitude depends hour 
cpd humidity node ht similar 
inference ultimate goal modeling stochastic process dpm obtain posterior distribution hidden variables graphical model observed measurements 
task called inference 
inference algorithms developed efficient inference special cases kalman filters general purpose inference techniques junction tree algorithm known 
general purpose algorithm monte carlo techniques section 
output inference algorithm typically probability distribution hidden variables inference algorithms may provide expected values hidden variables 
learning cpd parameters dpm typically known user need learned training data 
maximum likelihood estimation mle popular statistical methods learning parameters cpds 
learning data mle estimates values parameter values maximizes likelihood observing learning data 
words determine parameter learning data 
details mle described section 
section proposal presenting output dpm users 
database views abstraction model views proposed prior output dpm users 
abstraction analogous known abstraction database views allows creating virtual tables sql query database tables 
model views time temp tt humidity ht 
sid time temp humidity weight 

dpm view associated particle table dpm views contain probabilistic attributes particle representation view particles corresponding second tuple time shown clarity abstraction allow creating virtual tables statistical model 
examples model views non parametric statistical models linear regression interpolation described 
extend abstraction allowing views defined 
shows schema view user dpm model section infers temperature observed humidity values 
see schema contains state variables dpm attributes time attribute 
traditional database views virtual table may may materialized 
note nature forces probabilistic views attributes virtual table may probabilistic 
instance temperature attribute known certainty dpm provides probability distribution 
dpm view shows continuous variables dpm views discrete variables 
status attribute hmm view user fault detection example section 
issue querying representing probabilistic data received attention years challenges face form active research focuses area :10.1.1.108.6943
plan utilize techniques developed large extent building system especially language extensions querying tables 
currently allow querying single table dpm views extended version sql features allow users specify operations expected values probabilistic attributes extensions 
predicate temp indicates condition mean value temperature attribute 
confidence construct allows users specify minimum confidence result tuples returned users 
allow queries aggregates avg min max nn nearest neighbor 
query processing cognizant probability distributions correlations attributes final result probabilistic user expected values values case discrete attributes 
significant way dpm views differ prior area dpm views exhibit complex strong attribute correlations ignored query processing 
probabilistic databases assumes independence severely restrict correlations represented 
differentiate types correlations intra tuple correlations exist attributes single tuple 
example humidity temperature attributes correlated 
inter tuple correlations exist attributes different tuples 
example temperatures times highly correlated 
internal representation discuss currently captures intra tuple correlations query results affected 
inter tuple correlations hand harder capture currently ignore query processing plan develop intuitive ways representing querying correlations 
particle representation representation weighted samples called particles store dpm views internally 
allows handle complex continuous correlated probability distributions may generated probabilistic modeling forms basis inference technique 
definition particle weighted sample drawn probability distribution 
weight associated sample represents likelihood occurence distribution 
represent dpm view relational table deterministic attributes essentially maintain set particles tuple view 
particles drawn joint distribution attributes view 
shows example set particles corresponding tuples view 
clearly accuracy representation depends number particles system parameter 
shown theoretically accuracy representation proportional 
schema table called particle table consists attributes view attribute sid weight attribute 
particle table expected values attributes computed weighted averages particles 
example expected value temperature attribute time similarly compute expected value humidity attribute 
particles drawn joint distribution intra tuple correlations naturally captured representation 
populating particle tables start process time particle table initially populated sampling prior distributions attributes 
particles directly generated cases updated inference algorithm section 
system design schematic diagram depicting architecture system shown 
suppose user interested modeling data stream suitable probabilistic model 
sequence steps occur look operations detail 
architecture system 
user issues request view manager create dpm view providing create view definition statement section 
specifies dpm data stream modeled training data learn dpm 

parameters learned training data learning module invoked training data section 

particle table created populated prior distributions specified view definition section 

user interacts dpm view issuing sql style queries extended deal probabilistic data 
query transformer intercepts queries converts sql queries particle table executed traditional query processor section 

particle table continuously updated update manager order keep consistent incoming data stream section specifying dpm views create dpm view stream user required specify details schema view 
data stream modeled 
dynamic probabilistic model dpm model data 
generic view definition statement create dpm view follows 
create view name view schema dpm dpm config file training data sql query training data streaming data sql query streaming data node properties hidden discrete node wo fa node wo fa graph adjacency matrix graph cpds nodes cpd cpd val cpd val cpd val val node properties hidden discrete graph adjacency matrix graph cpds nodes cpd cpd cpd val cpd val cpd val val cpd val configuration file hmm model ii file kfm model ii sample configuration files dpm views shown figures ii syntax definition val variable modeled node cpd cpd node normally distributed cpd mean variance uniformly distributed cpd range discrete distribution probability state second state third state 
val discrete cpd possible states takes state val state state val second state conventions specify dpm views see format specifying views kept close view definition statement traditional database views 
line statement specifies schema view including name attributes 
fourth line specifies data stream modeled sql query stream portion data stream interest 
structure parameters dpm specified configuration file provided view definition 
shows examples configuration files models section 
configuration file contains details model properties attributes dpm including nodes hidden observed continuous discrete set values take discrete 
attributes corresponding slices dpm times typically specified 
adjacency matrix graphical representation dpm 
edges assumed directed node corresponding row node corresponding column 
note graphical representation dpm required acyclic 
cpds prior conditional probability distributions section nodes graph 
complex part dpm specification 
allow users specify cpds ways 
set pre defined probability distributions shows distributions currently support 
example represents normal distribution mean standard deviation 
represents discrete distribution random variable states pi represent probabilities variable states 
similarly val represents discrete cpd depends val 
val state follows distribution val second state follows distribution 
example cpd ii specifies cpd node prior distribution velocity variable normally distributed mean variance 
similarly cpd node ii val indicates node normally distributed mean value value node variance 
node hmm discrete distribution specified transition probability matrix section 
represent distribution way 
node time state distribution node discrete binary distribution 
distribution node 
providing java module file supports appropriate api probability distribution specified ones supported allow user provide distribution form java class file 
class implemented support pre defined api 
discuss details api section 
specifying parameters explicitly configuration file user may specify training dataset learn parameters line view creation syntax 
learning algorithms described section 
query processing query processing dpm views simplified result internal particle representation system uses 
probabilistic query executed dpm views converting query corresponding particle tables existing query processor query optimizer execute new query 
approach minimizes number changes underlying database system results highly efficient query execution 
describe detail query transformation process case simple select project queries single dpm view 
look issues involved transforming complex aggregate queries section 
transformation process aggregate queries especially aggregates min max quite complex look examples transformed queries 
simplicity discussion assume section attributes view key attributes continuous 
extensions handling discrete attributes quite straightforward 
algorithm converting single table select project queries require user sql query model view 
attribute select clause key attribute add select clause add sum weight select clause replace occurrences dpm view particle table clause 
add key dpm view group clause predicate clause involves key attributes add clause having clause consider dpm view infers temperature measured set sensors observed humidity values section 
schema view time id temp humidity id denotes sensor identifier temp temperature sensor 
unique key view time id schema corresponding particle table particle table time id temp humidity weight illustrate query transformation process example dpm view 
select project sql queries shows examples query transformation view 
query simply asks temperatures measured sensors 
discussed section final result attributes query probabilistic expected values returned 
shown corresponding query particle table simply groups particles key attributes returns weighted average temperature attribute 
algorithm constructing confidence query require user sql query model view 
construct query select clause sum weight clause particle table clause clause add key key predicates clause second query specifies predicate probabilistic attribute confidence value specifies minimum confidence required result tuples default confidence value assumed user doesn specify 
case query transformer constructs queries result query ii select id time temp select id time sum temp weight particle table group id time select id temp temp time confidence select id sum temp weight particle table time group id having select sum weight particle table id id temp time examples query transformation 
denotes original query model view denotes queries particle table 
confidence query merged single query shown 
result query generates output desired fashion similar query confidence query sure tuples sufficient confidence returned back user 
algorithms show pseudo code general procedure converting select project query single dpm view query particle table 
sql query dpm view algorithm computes result query algorithm computes confidence query intuitively occurrence non key attribute select clause replaced weighted average attribute 
predicates clause non key attributes moved confidence query affect confidence result 
correlated sub query ensure tuples sufficient confidence returned user 
construct section treated key attribute purpose query conversion 
instance query contains predicate temp replace sum temp weight keep predicate result query 
view contains discrete non key attributes final result returned user value attribute value highest probability 
algorithms extended fairly straightforward manner handle case omit details due space constraints 
aggregate queries show transform probabilistic aggregate queries 
prabhakar propose classification aggregate queries posed uncertain database :10.1.1.108.6943
broadly classified value queries return single number aggregate entity queries return set objects satisfy query 
classified aggregate value queries probabilistic sum avg query probabilistic min max query vminq aggregate entity queries probabilistic range query erq probabilistic min max query eminq probabilistic nearest neighbor query illustrate conversion routines type query mentioned 
probabilistic avg query sum query consider sql query asks compute average temperature sensors time equal 
transform query query particle table create temporary table tbl contains temperature measured sensor individually 
compute average temperatures order compute average sensors 
essence exploiting linearity expectation compute average 
transformed query shown 
transformation process probabilistic sum query similar 
aggregates min max nearest neighbor nn properties general need complicated sql queries order compute aggregates 
consider min aggregate 
probabilistic min query vminq eminq example entity version min query eminq query asks sensor recording minimum temperature time equal value version asks minimum temperature 
temperature uncertain attribute sensor potentially infinite set temperature values take 
general ranges values sensors overlap sensor candidate values potentially minimum temperature 
equivalently sensor certain probability recording minimum temperature 
answer query weighted samples essence numerical integration complex multi variate integral :10.1.1.108.6943
samples sensor compute probability minimum value 
done constructing temporary tables tbl tbl shown ii 
intuitively compute probability particular value ti sensor candidate minimum compute probability sensors measure temperature greater ti multiply quantities 
involves performing self join particle table computing sum weights tuples sensors temperature values greater ti multiply sums 
operators multiply row values group clause compute sums evaluate necessary product turning sum logarithms 
information stored tbl 
table tbl constructed pruning sensors probability minimum 
check performed having clause create table tbl statement 
computing tables tbl tbl compute results entity query value query shown 
probabilistic max query transformation probabilistic max queries similar min query vminq eminq respectively 
difference comparison operator create temporary table tbl operator 
rest query 
select id sum weight temp tbl particles time group id select avg temp tbl transforming avg query original query shown tbl select id pid temp temp weight weight id qid log sum weight particles particles pid qid temp temp time time group id temp weight id tbl select pid temp weight exp sum probability tbl group pid temp having count select count distinct id particles select sum probability weight temp tbl vminq select pid sum probability weight tbl group pid eminq ii transformation min query original query shown examples aggregate query transformation 
probabilistic range query erq consider sql query determines sensors measure temperatures range tl tu 
temperature uncertain attribute sensor non zero probability measuring temperature range 
execute query need integrate temperature probability distribution sensor range tl tu compute necessary probability values 
sample representation temperature probability distribution integration easily performed just computing sum weights 
transformed query particle table shown 
probabilistic nearest neighbor query select id sum weight particles time temp tl temp tu group id time transformation probabilistic range query original query shown tbl select id pid temp temp weight weight id qid log sum weight particles particles pid qid abs temp temp time time group id temp weight id tbl select pid temp weight exp sum probability tbl group pid temp having count select count distinct id particles select sum probability weight temp tbl vminq select pid sum probability weight tbl group pid eminq ii transformation nearest neighbor query original query shown examples aggregate query conversion example nearest neighbor query 
report sensor measures temperature closest value time essence need determine sensor ti tj 
effectively determining sensor minimum value 
execute nearest neighbour query just min query different expression minimize 
transformed query shown ii 
update manager update manager charge keeping particle table updated consistent incoming data stream 
sequential monte carlo technique called particle filtering purpose 
brief overview inference technique 
particle filters particle filtering known sequential monte carlo algorithm performing state estimation shown effective wide variety scenarios 
short algorithm computes constantly maintains sets particles describe historical states model 
discussed section essentially internal representation system uses maintain dpm views 
components particle filtering technique initialization prediction filtering resampling smoothing 
algorithms show pseudo code routines 
illustrate routines dpm 
initialization process initial set particles created randomly sampling prior distributions attributes 
prediction prediction step invoked advance time 
step state time estimated state time done conditional probability distributions associated model 
specifically existing particle time new particle time created sampling appropriate cpd 
hi denote ith particle time model 
corresponding particle time hi created sampling distributions tt tt ht ht hour time section filtering filtering procedure involves updates arrive time update state estimate time 
new particle assigned weight values observed variables time 
particles closer observed values receive higher weights compared particles observed values 
weights computed cpds observed nodes 
running example weights assigned predicted particles cpd observed node mt mt ht 
step typically integrated prediction step algorithm 
step weights normalized sum 
re sampling critical problems particle filtering technique may degenerate case single particle weight 
handled re sampling step set particles created filtering step re sampled generate new set particles 
re sampling step creates new set particles weight care degeneracy 
note particle may repeated multiple times resulting set particles 
problem prediction step generate different new particles identical particles 
smoothing routine uses current state distribution correct state previous times 
illustrate example 
consider scenario temperature modeled changes suddenly 
reading contains change may affect inferred temperature noise process 
time new readings arrive confirming change inference process sure change temperature 
intuitively speaking earlier change attributed noise re attributed actual change temperature 
done smoothing procedure recomputes weights particles earlier times 
theory change propagated way back time 
effect typically diminishes steps update distribution steps atmost time units away called smoothing lag 
pseudo code smoothing shown algorithm 
smoothing step order reduce variance filtering output 
expensive operation number particles performed time step 
offers trade accuracy performance control smoothing oper algorithm prediction filtering require particles time observations obs time 
particle pi time create partial particle pi time hidden node time slice topological order denote parents xj denote values xj pi pi constructed far sample value xj xj 
add new sampled value pi set weight new particle wi 
observed node wi wi yt algorithm smoothing require smoothing lag particles time time particle time wj algorithm update manager xi pn wk xj xk initialize particle table sampling prior distributions hidden nodes slice dpm 
time instant predict new set particles time old particle set time new data data stream time filter particles 
resample new particles 
smooth particles previous times 
ation lag order obtain necessary bounds 
models smoothing significantly improve results reduce variance filtering step cases filtering guarantees sufficient modeling accuracy performance 
update manager repeatedly invokes routines described keep particle table updated new data tuples arrive 
pseudo code update manager shown algorithm 
learning maximum likelihood estimation maximum likelihood estimation mle popular statistical method learn parameters underlying probability distribution data set 
suppose sample data 
xn want infer distribution came 
common assumption data independent identically distributed iid parametric distribution unknown parameters 
mle technique estimate unknown parameters 
probability distribution determined parametric form parametrized try maximize likelihood function 

xn data iid simplify expression follows 
xi log log xi determine value maximizes log likelihood function 
simple illustration method determining parameters gaussian distribution shown 
xi log xi log xi optimizing expression respect independently gives values 
learning cpds xi xi applications system learn conditional probability distributions form 
order learn cpds initially learn joint distribution mle obtain expression conditional distribution theorem 
continue illustrate gaussian example 
suppose want compute 
denote random variable 
vector distributed ct conditional distribution computed rule implementation details cb cb section briefly discuss implementation details system 
built prototype system java open source apache java embedded database system store select oid second oid time second time second time second second ii select oid queries experiments intersection query ii trajectory query kfm view moving objects particle tables 
prototype implementation currently application level software lies abstraction layer 
application accesses particle tables jdbc calls 
addition cache particles belong time steps smoothing lag section memory efficient access particles written database background 
currently working moving entire implementation inside 
experiments section conducted linux machine ghz intel pentium iv processor mb memory 
single important challenge faced implementation handling different possible types node variables associated cpds 
nodes dpm continuous discrete variety domains 
node may number discrete continuous parent attributes cpd may known parametric function may non parametric 
implementation needs generic order support various forms 
need provide flexibility user easily augment system instance adding new cpd currently supported suitable application 
extensible cpd api details specific cpds inside cpd object export generic functions necessary higher level learning inference procedures 
add new probability distribution cpd implementor provide functions public object arraylist function produces new sample value node value parents supplied arraylist 
double double val arraylist function returns probability node variable takes value val parents values specified 
public void double val arraylist function adds new data sample repository samples learn particular cpd 
public void function invoked training samples added learn parameters cpd 
system evaluation section results experimental evaluation prototype implementation 
salient points study summarized follows 
necessity dynamic probabilistic models deal erroneous incomplete realworld data streams 

accuracy error mse obtained inference process follows theoretically expected behavior number particles 
particles error percentage obtained real dataset 

efficiency inference times required system large number particles quite small ms feasible online inference high rate data streams 
experimental setup datasets evaluation 
dataset moving objects increasing amount location data gps data available today interest providing location services data moving objects databases received attention years :10.1.1.108.6943
consider moving objects scenario number point objects moving dimensional space 
assume object fitted gps device constantly transmits position central server 
gps data may contain noise location updates may lost process 
interested modeling data stream infer true locations velocities objects 
lacking real world dataset gps traces multiple objects generate simulated data properties described 
simulate gps readings random trajectories objects 
add white gaussian noise standard deviation units insert noise data 
addition drop readings randomly model incomplete data communication failures 
kfm model process data infer true locations velocities section 
perform smoothing operation lag 
moving object modeled separately different kfm model store information objects single table 
view creation command shown configuration file shown create views 
schema view time oid vx vy dataset ii sensor data managing noisy incomplete sensor data inferring useful information 
attempt system perform similar tasks 
publicly available intel lab dataset consists traces node sensor network deployment intel lab berkeley 
dataset consists light humidity temperature readings collected lab 
readings collected extremely noisy cases incomplete 
sensors failed midway deployment continued transmit erroneous values leading errors 
observed dataset intra tuple correlations temperature humidity correlations time 
order decrease acquisition costs query processing power aware sensor networks efficient strategy observe subset attributes easy acquire infer rest attributes probabilistic model 
experiment attempt accurately infer values temperature observed humidity readings dynamic probabilistic model shown 
ran series processings tasks overs data 
step remove incorrect data remove incorrect values dataset 
involves detection missed intersections raw gps data kalman filter view delta temperature temperature acquired sensor working faulty dpm view status working status faulty time temperature temperature recorded sensor working faulty dpm view status working status faulty missed intersections function raw data kfm view ii observed temperatures sensor status inferred hmm 
iii ii simulated faults inserted 
failure times sensor nodes 
perform hmm view hmm model shown 
step learn dpm incorrect sensor readings removed split data training testing datasets 
training dataset data collected days learn conditional probability distributions nodes 
step inferring temperature values humidity readings test dataset data collected days infer temperatures dpm shown generating 
step true temperature values order evaluate accuracy inferred temperatures remove noise observed temperatures dpm view 
dpm similar kfm shown 
resulting correct temperatures compared temperatures inferred step evaluate accuracy inferred temperatures 
experimental results applying data critical dataset show importance modeling data streams pose intersection query moving objects database 
query measures number intersections objects times particles closer specified distance 
execute query raw gps data compare number correct intersections measured cases 
shows plot comparing percentage missed intersections raw data kfm view 
see large number intersections missed executing query raw data especially smaller values 
missing data noise data 
kfm view hand able capture real intersections data 
dataset ii figures ii iii show temperature values measured sensors readings marked incorrect hmm view 
see ii incorrect values hours days approx need removed learning 
added simulated faults order verify hmm view correctly identifies faulty readings 
inference particle filtering accurate time mean squared error gps kf view raw gps data temperature dpm view number particles log scale time inference step sec time time ms filtering number particles ii iii time inference step millisecond particle filtering system analytical filtering number particles log scale plot mean squared error vs number particles dataset dataset ii 
mean squared error falls ii graph shows time taken inference step various smoothing lags 
iii update times particle filtering comparable analytical technique 
set experiments show particle filtering algorithm accurately determines hidden state system modeled 
dataset execute trajectory query shown ii returns path traced object raw data kfm view 
accuracy result measured computing deviation path actual path sum squared error function 
plot estimate error function number particles 
dataset ii compare value temperatures inferred just filtering smoothing true temperature values generated step 
compute mean square error estimate plot mean squared error function number particles 
obtain graph shown 
plots see error kfm views gps datasets raw data 
error raw data indicated straight line 
verify error decreases number particles increases 
low values error reduces drastically higher values particles remains fairly constant 
error graphs follow theoretically estimated graph validates experiments 
temperature data dataset ii mean square error obtained test data just filtering units error just particles 
inference particle filtering efficient provide details regarding performance system 
learning data modeled dpm time initially spent learning cpds 
learning cpds temperature humidity nodes dpm records dimension took seconds 
inference cpds learnt receive data continuously time spent performing inference procedure 
inference procedure performed time instant results addition new rows modification existing rows smoothing 
measure time taken inference step function number particles 
carry experiment different values smoothing lag parameter 
results obtained shown ii 
find execution time increases linearly increase number particles axis log scale explicitly seen 
perform filtering inference time small process particles just ms 
continuously perform smoothing time taken inference increases drastically shown graph 
smoothing lag time steps process particles ms reasonable common streams 
accuracy graph shows may achieve sufficient accuracy 
considering lazy smoothing strategies perform smoothing time step essential 
comparison analytical filtering systems perform tasks similar system implemented analytical solution kalman filters called 
compare performance particle filtering inference algorithm 
particles directly sampled mathematical equations kalman filter inserted database order obtain common ground comparison 
note generate samples order execute queries output model 
compare time taken system kfm view dataset 
systems perform smoothing procedure 
iii shows execution times single inference step function number particles 
expected kalman filter implementation analytical formulas takes time particle filtering algorithm 
difference significant number particles large 
note prototype implementation fine tuned performance expect careful implementation reduce time taken implementation 
related bayesian networks dynamic probabilistic models bayesian networks long rich history wide variety research disciplines numerous books written addressing aspects models 
dynamic probabilistic models called dynamic bayesian networks dynamic probabilistic networks relatively newer established concept allow reasoning temporal dimension extensively modeling complex stochastic processes 
years seen tool unify similar concepts seemingly disparate domains probabilistic expert systems statistical physics image analysis genetics 
instance hmms kalman filters common examples models developed independently engineering speech recognition communities similarities graphical models observed fairly 
years general purpose toolkits developed support bayesian networks cases dynamic bayesian networks 
best knowledge proposes directly implement arbitrary dynamic probabilistic models inside databases making easier increasing functionality appeal relational database systems 
probabilistic relational models generalization bayesian networks learning probabilistic models data relational tables 
dynamic probabilistic relational probabilistic models considered machine learning community 
complementary approach 
probabilistic databases years seen renewed interest area probabilistic databases fueled primarily large increase amount real world data inherently noisy incomplete uncertain 
research efforts underway build systems manage uncertain data trio orion conquer :10.1.1.108.6943
discussed section views dynamic probabilistic models naturally probabilistic plan techniques developed probabilistic databases research especially query languages semantics 
data streams sensor networks data stream management systems proposed realtime processing continuously generated data sensor networks 
main focus efficient evaluation large number continuous queries high rate streaming data 
complementary focuses efficiently modeling streaming data query results meaningful useful user 
sensor networks active area research years see survey large body data collection sensor networks applies higher level techniques sensor network data processing 
tinydb cougar provide declarative interfaces acquiring data sensor networks 
systems propose probabilistic modeling techniques answer queries sensor networks typically specific models generalized implementation existing relational database 
discussed section system generalizes significantly enriches abstraction model views originally proposed system 
advances miniaturization technology networking resulted rapid increase number large scale deployments measurement infrastructures continuously generate tremendous volumes data 
approach build extensible database system enables users apply general purpose dynamic probabilistic models data real time significantly enriching functionality appeal databases managing data 
provide intuitive interfaces declaratively specify models applied query output application models data streams 
particle filtering perform inference tasks show enables efficient query execution dpm views 
techniques develop representing querying probabilistic tables particles independent interest probabilistic database community 
experimental evaluation prototype implementation illustrates advantages enabling real time application dynamic probabilistic models streaming data 
akyildiz su 
wireless sensor networks survey 
computer networks 
ariel miller 
clean answers dirty databases 
icde 
apache project 
web site 
db apache org 
barbara garcia molina porter 
management probabilistic data 
ieee tkde 
carney 
monitoring streams new class data management applications 
vldb 
chandrasekaran 
telegraphcq continuous dataflow processing uncertain world 
cidr 
chen david dewitt feng tian yuan wang 
niagaracq scalable continuous query system internet databases 
sigmod 
cheng prabhakar :10.1.1.108.6943
evaluating probabilistic queries imprecise data 
sigmod 
choudhury philipose danny wyatt jonathan lester 
activity databases sensors statistical models summarize people lives 
ieee data eng 
bull 
chu zhao 
scalable information driven sensor querying routing ad hoc heterogeneous sensor networks 
intl journal high performance computing applications 
dan suciu 
efficient query evaluation probabilistic databases 
vldb 
deshpande carlos guestrin sam madden joe hellerstein wei hong 
model driven data acquisition sensor networks 
vldb 
deshpande samuel madden 
supporting model user views database systems 
sigmod conference pages 
arnaud doucet de freitas neil gordon 
sequential monte carlo methods practice 
springer 
durbin eddy krogh mitchison 
biological sequence analysis probabilistic models proteins nucleic acids 
cambridge univ press 
friedman murphy russell :10.1.1.129.4770
learning structure dynamic probabilistic networks 
uai 
lise getoor 
learning statistical models relat data 
phd thesis stanford university 
zoubin ghahramani 
learning dynamic bayesian networks 
lecture notes computer science 
sun faloutsos 
intelligent system monitoring large clusters 
vldb 

package graphical modelling technical report aalborg university 
jain change wang 
adaptive stream resource management kalman filters 
sigmod 
michael jordan 
learning graphical models ed 
mit press 
potkonjak sangiovanni vincentelli 
line fault detection sensor measurements 
ieee sensors 
lakshmanan leone ross subrahmanian 
flexible probabilistic database system 
acm tods 
levy benveniste :10.1.1.25.968
high level primitives recursive maximum likelihood estimation 
ieee trans 
automatic control ac 
aloimonos 
sensory grammar inferring behaviors sensor networks 
ipsn 
sam madden 
intel lab data 
berkeley intel research net 
samuel madden wei hong joseph hellerstein michael franklin 
tinydb web page 
telegraph cs berkeley edu tinydb 
mainwaring culler polastre szewczyk anderson 
wireless sensor networks habitat monitoring 
wsna 
petkovic 
dynamic bayesian networks state art 
university twente document repository 
rajeev motwani 
query processing resource management approximation data stream management system 
cidr 
kevin murphy 
bayes net toolbox matlab 
computing science statistics 
kevin murphy 
dynamic bayesian networks representation inference 
phd thesis uc berkeley 
patterson liao fox kautz :10.1.1.1.5074
inferring high level behavior low level sensors 
ubicomp 
judea pearl 
probabilistic reasoning intelligent systems networks plausible inference 
morgan kaufmann 
rabiner 
tutorial hidden markov models selected applications speech recognition 

manolopoulos 
quadtree moving objects databases 
lecture notes computer science volume jan 
domingos weld 
dynamic probabilistic relational models 
ijcai 
sen deshpande 
representing querying correlated tuples probabilistic databases 
icde 
smyth heckerman jordan :10.1.1.150.82
probabilistic independence networks hidden markov models 
neural computation 
padhraic smyth 
belief networks hidden markov models markov random fields unifying view 
pattern recognition letters 
ouri wolfson klaus hinrichs sam chamberlain 
managing uncertainty moving objects databases 
acm trans 
database syst 
greg welch gary bishop 
kalman filter 
www cs unc edu welch kalman html 
widom 
trio system integrated management data accuracy lineage 
cidr 
yao gehrke 
query processing sensor networks 
cidr 
jie ying 
hidden markov model algorithm fault diagnosis partial imperfect tests 
ieee trans 
systems man cybernetics part 

