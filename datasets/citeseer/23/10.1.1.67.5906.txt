operant conditioning david touretzky computer science department center neural basis cognition carnegie mellon university pittsburgh pa dst cs cmu edu lisa robotics institute center neural basis cognition carnegie mellon university pittsburgh pa ri cmu edu appear adaptive behavior 
copyright mit press 
instrumental operant conditioning form animal learning similar reinforcement learning watkins allows agent adapt actions gain maximally environment rewarded correct performance 
animals learn complicated behaviors instrumental conditioning robots presently acquire reinforcement learning 
describe new computational model conditioning process attempts capture aspects missing simple reinforcement learning conditioned reinforcers shifting reinforcement contingencies explicit action sequencing state space re nement 
apply model task commonly study working memory rats monkeys delayed match sample task 
animals learn task stages 
simulation model acquires task stages similar manner 
model train rwi robot 
keywords operant conditioning instrumental learning shaping chaining learning robots running head operant conditioning 
service dog trained assist handicapped person tasks daily living respond verbal commands turn lights open refrigerator door retrieve dropped objects 
cci 
animals including rodents pigeons dolphins shown capable learning complicated behavioral routines 
see pryor striking accounts behaviors taught species 
animals learn new behaviors quickly trained instrumental operant conditioning techniques principles cognitive psychology 
mobile robots trained methods learning watkins come close matching sophistication versatility animal learners 
disparity doubt partly due superior perceptual motor capabilities animals techniques animal training studied considerably longer investigators robot training 
suggest closer attention paid animal training literature serious attempt model ects described may yield bene ts immediate value robot learning researchers provide new perspective animal learning 
due pioneering skinner operant conditioning catania harnad coined term describe autonomous learning robots employ strategies exhibit behavioral ects characteristic instrumental learning touretzky 
describes investigation particular conditioning technique called chaining behavioral routines built smaller action segments applied mobile robot learning 
developed learning algorithm incorporates aspects chaining reinforcement learning techniques address shifting reinforcement contingencies learning conditioned reinforcers 
classic cognitive assessment task involves behavioral sequences delayed match sample task rst test case learning model 
implemented model rwi mobile robot 

operant conditioning operant conditioning acquisition performance action depends consequences experienced completion 
type learning called operant behavior operates ect environment instrumental behavior instrumental producing reward 
type learning ords animal degree control environment ability produce changes situation performing appropriate action 
example may learn food produced pressing lever 
follows instrumental learning enables animals cope dynamic environment consequences actions may vary 
contrasts classical conditioning pavlov learning limited associating possibly arbitrary conditioned stimulus reinforcing unconditioned stimulus elicits type innate behavioral response 
example food unconditioned stimulus naturally produces responses electric shocks produce fear avoidance responses stimulus pu air delivered eyeball produces defensive responses 
classical conditioning procedure initially neutral stimulus tone light repeatedly followed unconditioned stimulus 
learning conditioned stimulus comes elicit similar behavioral response absence unconditioned stimulus 
bell rings dog food delivered 
responses occur classical conditioning innate animal learn contingencies wholly dependent processes construct responses appropriate stimuli received 
phenomena classical operant conditioning easily distinguished description suggests shares properties suggesting involve underlying mechanism 
responses known occur part conditioned behaviors rat learned press bar get food bar pressed holland 
conversely process known classical contingencies produce sort voluntary behavior normally associated instrumental conditioning purely autonomic re exive responses brown jenkins 
original experiments done pigeons standard operant chamber response key food hopper 
key illuminated xed brief period time food set illumination 
pigeon learned peck key reinforcement contingent action 
classical conditioning developed computational theory wagner theory descendants wagner sutton barto klopf barto sutton predicts strength stimulus reward association factors stimulus saliency background stimulus rate training history 
addition simple models classical conditioning implemented robots 
classical conditioning value robots useful robot able learn predictive values stimuli possibly follow innate anticipatory responses 
instrumental learning involves associations actions outcomes allows modi cation responses unstable environment confers ability probably critical robustness practicality mobile robot 
theories instrumental conditioning comparable scope explicitness wagner model classical conditioning uni ed theory phenomena 
goal provide theory instantiated computational model 
describes initial step direction 

chaining complex behaviors broken components analyzed sequence 
example chick trained play piano sequence keys obtain food reinforcement tune 
pig taught grocery shop pushes cart selects speci items place 
behavioral chain analyzed sequence stimuli responses 
core unit chain called link consists discriminative stimulus response reinforcer 
chain begins presentation rst discriminative stimulus 
animal appropriate response presence stimulus conditioned reinforcer reward response 
reinforcer functions discriminative stimulus link chain setting occasion desired response 
process continues number links reaching nal stimulus chain primary innate reinforcer food 
links overlapped discriminative stimulus production response reinforcer previous response holds chain 
concept chaining di ers examples response sequences xed action patterns chains behavior modi ed reinforcement 
fixed action patterns animals hardwired sequence initiated goes completion independent consequences behavior 
example type behavior occurs goose 
egg rolls nest stand put bill egg pull back chin roll egg nest 
engaged xed action pattern goose performs behaviors order 
continue pattern loses grip egg pattern triggered round stimulus outside nest including beach balls 
type behavior exible animal learning literature de nes classes behavioral responses schwartz respondents originate stimuli elicit re ex ii determined ects environment require eliciting stimuli 
types reinforcers distinguished reynolds primary reinforcers reinforce behavior animal having prior experience food water 
ii conditioned reinforcers acquire power reinforce behavior lifetime animal mechanism stimulus conditioned reinforcer repeatedly paired primary reinforcer 
involved instrumental chaining 
see barnett additional examples xed action patterns 
idea patterns responding reduced succession stimulus response units controversial skinner skinner claimed behavior including language represented way chomsky chomsky held sequential behavior adequately accounted terms 
considerable evidence probably types behavior sequences held way 
concept constructing behavioral sequences mobile robots small elements appealing programmer limited construction just behavioral primitives plus learning algorithm putting 
di erent behaviors assembled awell designed set primitives learning potentially faster knowledge shared tasks similar sub tasks 

previous models previous computational models operant conditioning phenomena described 
models conditioning baxter raymond focused learned suppression motor action 
mixed classical operant models known process models escape avoidance behavior vertebrates grossberg schmajuk address simple responses conditioned stimuli 
models approach full richness vertebrate learning involving example acquisition secondary reinforcers construction behavior chains 
graham graham describe virtual rat designed undergraduates try hand operant conditioning 
program hard wired acquire particular conditioned reinforcer sound food dispenser respond speci shaping strategy teach simulated rat bar press food 
primitive actions grooming encouraged linking food rewards program exible permit shaping complex bar pressing possible teach rat respond external signals tone light 
presently provisions chaining behaviors modifying qualities particular motor response re ning simulated animal perceptual abilities 
model learning match sample task delay backpropagation network 
animals task requires learning complex sequence actions see section 
network takes sample stimulus potential match stimuli input learns compute exclusive functions output 
produces overt behavior just match left match right signal 
model emulate operant conditioning er suggestions learned internal representations stimuli result conditioning 
reinforcement learning bears similarity operant conditioning reinforcement learners need shown correct responses training stimuli required supervised learners backpropagation 
operant conditioning reinforcement learning appealing theoretically allows agent autonomously adapt actions get environment gains information time 
reinforcement learning capture aspects animal behavior adaptive foraging bees montague 
furthermore neural representation kind reward signal required reinforcement learning bees neuron hammer primates dopamine neurons pars ventral area schultz 
argue section operant conditioning mammals richer phenomenon addressed current reinforcement learning theories 
done reinforcement learning sequential tasks 
singh singh describes sequential task learner separate modules learn di erent elemental composite tasks mahadevan connell mahadevan connell learning acquire multiple behaviors controlled hardwired switching scheme designate active time 
asada constructed robot soccer player learned push ball goal avoiding opponent asada 
examine techniques combining ball shooting collision avoidance behaviors acquired separately learning policy function accomplishes tasks 
papers look sequential task learning approaches demonstrated simple environments subject usual combinatorial limitations learning 
composing behaviors primitives general problem chaining investigated mobile robots 
mataric showed foraging behavior constructed routines wandering homing aggregation dispersion plus innate re grasping object encountered mataric :10.1.1.42.323
reinforcement learning implement complex behavior deriving policy selecting appropriate primitive behavior robot current state mataric 
examples reinforcement robot learning include dorigo colombetti 
authors rely immediate reinforcement strategies robot action time step positively negatively reinforced automated trainer 
human trainer unable keep 
realistic model animal learning 

issues critical success instrumental conditioning 
model instrumental conditioning close examination steps involved chaining animal behavior reveals important issues critical success procedure considered previous computational models conditioning 
conditioned reinforcers bridging stimuli 
contiguity action outcome critical instrumental learning action closely followed reinforcer order animal learn association 
training situation di cult reward animal food immediately occurrence desired response 
conditioned reinforcers stimuli associated food water innate reward exercise serve signal reward coming eliminating gap desired action reinforcement signal 
example skinner box time animal receive food pellet hear click food dispenser operating 
sound quickly conditioned reinforcer animal learns click means food available soon 
close temporal contiguity action sound imminent reward su cient produce increased likelihood performing action 
important consideration sound dispenser heard skinner box 
possible reward animal food hopper 
typical rl techniques credit assignment major problem 
completing sequence actions leading agent goal order learn actions credited contributing nal success agent needs evaluate goodness action performed 
reward obtained occurs sequence knowledge cumulative ect actions derived 
model deals issue learning conditioned reinforcers sort described 
discovers primitive subgoals hearing sound dispenser activating seeks ways achieve 

shifting reinforcement contingencies 
operant conditioning nonstationary reward function 
constructing complex behavioral chain new reward contingency introduced time new phase training begun 
dramatic example response change reward phenomenon known extinction 
reinforcement discontinued animal eventually producing behavior 
short term activity level rises response discontinued reinforcement furthermore variability responses increases 
way animal broadens exploration action space may learned action produce expected reward 
animal trainers exploit phenomenon shape complex behaviors 
see related idea increasing variability actions robot learner response failure improve performance 
reinforcement learning algorithms learning watkins track nonstationary environments explicitly detect changes reinforcement contingencies respond animals 
model detects nonstationarity uses information trigger changes representation environment 
example early stages learning delayed match sample task described switch press produces water reward 
task acquired switch press outcomes water pump runs light comes depending context 
initial predictor water pump quite successful suddenly wrong half time 
model responds resetting reward tables hear pump goal success counts predictors 
causes model temporarily plastic readily entertaining new predictors exhibit greater accuracy willingly dropping old ones replaced better versions 

action sequencing 
di culty sequential task decomposition mechanism place directing construction behavior chain highly agent able achieve complicated goal state simply composing action sequences randomly 
model uses explicit temporal predicate representation allows distinguish order events occur order learn behavioral sequences 
primitive subgoals mentioned function discriminative stimuli set occasion action take place 

perceptual state space re nement 
problem rl techniques usually restricted small state space avoid combinatorial explosion 
approaches explicit symbolic representations including classical ai accomodate large state space factoring set predicates 
construct logical expressions refer collections states economical ways 
advantage approach permits incremental re nement state space adding new predicates 
example classical operant conditioning animal learn distinguish tones di erent frequencies associated di erent rates reward 
predicate hear tone eventually hear high tone hear low tone 
wehave included shaping stimulus discriminations current learning algorithm intend address 

action re nement 
combinatorial considerations limit number actions available reinforcement learning simulations 
animals capable nite variety actions 
taught produce arbitrary gesture shaping process initially innate behavior close desired gesture rewarded increase repetition rate criterion reward smoothly altered shift animal performance desired direction 
example dog shaped turn circle initially rewarding slight movement left raising requirements eventually full degree turn achieved 
address shaping article note actions represented parameterized templates simple version shaping hill climbing 
reward signal increases likelihood action repeated shifts description action 

memory representation table 
introduce model consider simple case rat pushing bar get water 
working memory module holds collection time labeled predicates describing rat current perceptions actions past 
instant rat receives water reward having previously heard pump run contents working memory appear table 
notation time time previous instant time instant 
table 
algorithm inferring reinforcement contingencies operates collection slightly items called temporal predicates 
derived working memory elements replacing numeric time tags symbolic labels shown table 
conciseness tag usually left implicit rest 
fut tag refer predicates true retrospective analysis results action time working memory elements persist small number time steps depending predicate involved 
simulation goto predicates time steps see hear press 
animal location nearly moving location related items accumulate quickly 
conditioned stimuli actions bar pressing occur frequently memorable 
level representation program form conjunctions predicates 
temporal tagging items allows infer cause ect relationships actions stimuli construct temporal sequences 
example crucial match relationship task described conjunction press switch past press switch plus similar conjunction second switch 

learning reinforcement contingencies conjunctions program constructs describe sequences stimuli actions occur world 
occur frequently encountered 
furthermore sequences followed reinforcement signal 
order extract information experience world program maintains tables reinforcer 
counts number times conjunction satis ed reinforcer acquired table counts number times conjunction occurrence followed time step reinforcer 
reward rate conjunction second quantity divided rst 
program attempts nd conjunctions maximum reward rates 
conjunction predicts rewards false alarms reward rate 
complex domains ord test possible conjunctions predicates heuristic search 
conjunctions constructed incrementally combining pool currently best conjunctions starting null conjunction pool best predicates 
best conjunction reward rate standard deviation mean rate reward count standard deviation mean count 
tests necessary 
items high reward counts constitute important features environment need incorporated conjunctions reward rates isolation low 
example going water dispenser pump run goto dispenser low reward rate water available high reward count 
items high reward rates accurate predictors retained exploration reward counts relatively low meaning account limited rewards received 
drescher similar observation learning model distinguishes relevance reliability measures drescher 
learning conjunctions su ciently correlated rewards generate predictors rules predicting reward 
may displace earlier predictors performed 
allow ects noise predictors replaced reasonably high application count success rate accurately estimated replacement signi cantly higher success rate 
initial magazine training learning go food water dispenser mechanism heard activate typical sequence learned predictors reward rates shown 
receive water goto dispenser receive water hear pump receive water hear pump goto dispenser predictor says time simulated rat heard pump immediately went water dispenser received water reward 
conjunction predicts water perfect accuracy 
generate behavior look predictors satis ed rat action currently available 
predictor suggests going water dispenser initially rat spends lot time 
causes reward rate goto dispenser drop occasions water available 
reward count predictor remains high relative predicates dispenser place water obtained 
predictor gives false expectations reward soon dropped 
predictor somewhat successful satis ed rat actions point training rat way cause pump sound occur 
predictor accurately describes current reward contingencies environment rat generate behavior pump heard run 
predictors model divided classes contain action term 
satis ed executing action instrumental rules 
predictor may viewed rules represent association stimuli 
response generated association innate hardwired 

acquiring conditioned reinforcers second type learning model acquisition new conditioned reinforcers 
nd way hear pump true predictor suggests get water wanted 
hear pump secondary reinforcer begins trying theories causes pump run 
point training process trainer stops randomly triggering pump magazine training rewards bar presses 
exploration eventually discovers pressing bar pump run 
predictor acquired hear pump press bar suppose water dispenser north wall skinner box switch northeast corner 
predictor apply press bar operator available dispenser 
impasse generates new secondary reinforcer press bar seeks control leading discover predictor bar ne corner fut fut tag indicates northeast corner time able press switch att 
predicate true action south wall need refrain going 
hierarchy reinforcers 
primary innate reinforcer water 
important secondary reinforcer pump sound 
remote secondary reinforcer ability press switch 

action selection time step seeks predictor satisfy 
predictors prioritized nature reinforcement promise act secure basic reward water ability press bar 
nds predictor predicates currently true matches item working memory true action presently available select action high probability 
randomness action selection mechanism facilitate exploration 
goals handled specially 
looked program subgoal satis ed goal action available 
example predictor bar pressing antecedent conjunction see light press bar needs able press bar sees light rest time doesn matter press bar predictor satis ed light 
see light true predictor satis ed press bar available action 
press bar goal worth satisfying point turn allows predictor goal lure location bar 
previously discussed predictors bar pressing task ordering imposed reinforcer priorities shuttle back forth northeast corner center north wall alternately pressing bar collecting water reward 

shows ow information learning program 

predictor creation deletion variety heuristics constrain search space possible predictors 
new predictors reinforcer created reinforcer just received reward counts updated 
point program check candidate predictors working memory constructs predictors predicted reward just got 
furthermore order new predictors created reward unexpected meaning current set predictors incomplete false prediction reward encountered meaning erroneous predictor speci accurately express reward contingencies 
new predictors created best scoring conjunctions currently maintained reinforcer 
conjunctions tied top score ones fewest number terms selected 
candidates chosen random new predictors 
turn best choices experience increase scores conjunctions chosen instance reward counts updated working memory time step 
addition occasional selection random actions may give rise unexpected rewards cause new conjunctions created 
best performing conjunctions see scores increase predictors subsequent trial eventually replace predictors outperform 
numerical measures assign scores conjunctions predictors merit 
estimate lower upper bounds respectively true reward rate number examples seen far 
number times conjunction observed true number times reinforcer received subsequent time step 
merit de ned max min merit de ned 
di erence merit values taken uncertainty measure estimate reward rate gallistel chap 

see 
approaches merit converge true reward rate 
constants equations merit chosen empirically give appropriate balance reward estimates con dence values small 
example conjunction true times followed reward times estimated reward rate merit 
conjunction true twice followed reward time estimated reward rate merit due low con dence 
constants merit equation chosen 

creating new predictors candidate conjunctions sorted merit raw reward rate give greater weight conjunctions sampled heavily 
deleting predictors program conservative judgements delete quickly 
predictors deleted circumstances 
predictor just false alarm may deleted certain minimum value 
necessary poor predictors trap program unsuccessful behaviors hindering discovery better options 
second reinforcer just correctly predicted predictor may deleted highest merit successful predictor reinforcer 
words program con dent better performing predictor exists poorer displaced 
predictors predicted reinforcer just received 
predictor deleted predictor antecedent uses strict subset terms predictor conjunction merit nearly number trials su ciently high reasonable con dence predictors equivalent 
helps program nd minimal predictors domain replacing extraneous terms 
adequate set predictors learned unexpected occurences reinforcer false alarms current version program stops creating new predictors reinforcer strictly minimal set predictors attained 

task delayed match sample task widely cognitive neuroscience measure properties working memory 
basic idea subject stimulus sample impose delay pair stimuli matches sample 
subject select matching stimulus order receive reward 
delay period varied control length time sample maintained working memory 
spatial nonspatial versions task 
spatial version stimuli identical distinguished basis location appear 
nonspatial version sample appears location probe stimuli appear locations visual characteristics stimuli matter 
debate spatial version task involves working memory animals type mediating strategy aligning body site stimulus bridge delay 
learning algorithm applied spatial non spatial version task 

describe spatial version rats uses stimuli switches mounted wall skinner box shown 
dispenser located switches light port mounted opposite wall 
port hole infrared led sensor positioned time rat nose hole breaks beam allowing event detected 
start trial switches extends rat go press switch 
causes switch retract time light port 
rat opposite wall repeated variable delay period averaging minute 
requirement prevent rat parking front switch just pressed switches extend 
sort mediating strategy eliminate need working memory 
delay period causes light go switches extend 
rat return switch pressed previously press 
chooses correct switch receives water reward 
rats taught task stages 
report training time months 

shifting reinforcement contingencies task rats model require multiple training stages learn task 
simulation stages 
rst stage pump triggered random times task learn water available dispenser pump sound heard 
second stage switch start trial 
switch immediately retracts pressed pump runs 
leads predictor switch similar rule learned switch hear pump press switch switches pressed extended position visible predictor learned press switch see switch goto sw loc notice predictor uses goto sw loc sw loc fut 
rat location predicate su ce bring switch 
reason goto preferred rat goes switch press switch time time switch retracted 
predictor antecedent satis ed generate false expectation press switch true 
preferred predictor avoids error satis ed action time press goto 
note rat switch executes goto sw loc anyway action ect case antecedent satis ed true prediction switch 
third training stage trial starts light going port 
rat learns poking port light causes switches extend see switch see light poke poke port similar rule switch 
fourth nal stage single switch appears start trial pressing causes light go 
stage switch pressing ran pump 
produce pump light depending context 
previously learned predictors hear pump see light longer accurate 
program observes changed contingencies responds resetting reward tables govern behavior reinforcers ect making model plastic eager acquire new predictors willing replace old ones 
predictors earlier adequate job characterizing environment reinforcement contingencies replaced selective versions see light reinforced past press switch hear pump switch past press switch reinforced predicate true time model received reinforcers record working memory 
way marking start trial 
seeing switch reinforcing comes time nose poke model begun new trial predictor checks reinforced past 
time switch reappears near trial item faded working memory 
marker second half trial model uses see light past 
second half switch press produces pump sound light 

behavior model trying formulate explanations reinforcers construct explanation possible 
example start training pump triggered random times 
model generate predictors hear pump act whichever ones highest apparent reward rate 
occasions happened moving southeast corner northeast corner pump ran decide action causing pump run repeating deliberately 
water dispensed randomly su ciently frequent intervals predictor successful retained strengthened 
sort behavior observed real animals skinner underlying mechanisms point unclear staddon 
second training stage pump sound reliably predicted switch pressing model replaces predictors accurate ones 
begins forming predictors appearance switch occurs start trial 

results 
simulation minimum predictors required task shown 
program learns set predictors equivalent optimal set extraneous terms redundant predictors remaining 
example formulation equivalent predictors receiving water pump runs learned nearly time receive water hear pump goto dispenser receive water hear pump dispenser fut examples correct predictors program learned harmless extra terms hear pump press switch past see switch press switch see switch sw loc prev see light prev poke poke port see switch reinforced past see light past poke poke port points learning process animal may develop bias favor switches presses switch 
program 
animal develops bias trainer introduces correction trials animal forced choose correct switch 
approach 
training mechanism alternates switches samples correct responses keeps track times chosen match phase trial 
ratio switches exceeds correction trial correct switch match phase program forced pay attention switch 
leads propose new predictors involving switch compete earlier ones correct set predictors 
typical run program experienced trials stage stage stage stage 
created total predictors nearly see switch see switch goals occur start trial predictable preceding stimuli 
long predictions goal perfect program keeps trying new predictors 

program performance trial shown actual predictors produced behavior shown 
time steps program nose poke port location switch waiting new trial 
caused created predictor number soon deleted 
time switch appears program presses 
note predictor get switch 
happened predictor predicts see light press switch 
predictor successful predictor predictors cause switch pressed program arrived location 
time step light turns response switch press program nose 
causes switches extend predictor generates goal predictor satis es program switch 
program presses matching switch causing pump run 
trial concludes receipt water reward 

robot implementation 
amelia shown rwi mobile robot color camera pan tilt head degree freedom arm gripper 
computing power provided board pentium processors 
mbps radio modem links amelia network sparc stations contribute additional processing cycles 
experiments ran learning program common lisp sparc tca task control architecture simmons communicate robot 

provide reinforcement stimuli robot added logitech button radio trackball 
human trainer stand vicinity robot press button send reward signal desired response occurs 
button press picked board receiver plugged serial port laptop relayed learning program sparc 
robot acknowledges button presses brief audio response 
preliminary experiment robot training amelia taught sort objects bins color 
pink green plastic dog toys blue recycling bins 
rst training stage provided single recycling bin left platform dog toys robot 
amelia pink toys time rewarded dropping bin 
second stage placed recycling bin right platform provided green toys rewarding amelia dropping bin 
point amelia learned dropping objects bins produced rewards learned discriminations color location 
third stage placed bins side central platform alternately pink green toys rewarding robot dropping pink toy left bin green toy right bin 
correct behavior quickly obtained constructing predictors sense reward holding pink toy drop loc sense reward holding green toy drop loc training robot realtime raises number issues addressed computer simulation proper delivery reward signals 
current learning program works discrete time steps important action performed time rewarded 
solution clock tick instant action begun 
robot decides time lower gripper drop pink toy bin left drop loc action time clock advanced 
soon trainer sees robot moving drop toy press reward button reward recorded occurring 
trainer waits long action complete takes essentially time robot decide action clock reward arrives 
expect switch time model avoid sort brittleness 

discussion described model operant conditioning successfully learns task requiring complex behavioral chain task 
highlights aspects operant conditioning addressed earlier models 
reinforcement contingencies change time 
incorporation model allows trainer add new elements animal robot behavior losing previously learned information 

conditioned reinforcers hold behavioral chain 
learned reinforcers asthe sound pump appearance light help animal deal credit assignment problem learning complex task 

discriminative stimuli set occasion performing particular behavior 
words signal animal execution action produce reward 
model represents stimuli terms conjunction 
chained behaviors discriminative stimuli help animal keep track order actions 
example light task presence indicates time nose poke 
discriminative stimuli time 
animal trainers technique called stimulus fading signal perform action gradually subtle replaced altogether salient stimulus 
model stimulus fading 

animals large continuous state action spaces 
model factor state space conjunctions predicates refer collections states economical way 
way limitations table driven reinforcement learning algorithms require small state space avoid combinatorial explosion 
ai programs approach 
novel development heuristics reward rate total reward guide construction new conjunctions predictors program experience 
remains done complete computational level model operant conditioning 
order expand model chaining incorporate results animal learning literature idea explore operator shaping 
equip robot initial set innate behaviors operators may necessarily able fully satisfy requirements trainer environment 
needed means re ning operators experience similar animal training technique called shaping 
evidence existence innate behavioral elements combined success shaping animal learning paradigms suggests powerful mechanism improving performance learning algorithm 
need add facilities re ning perceptual predicates experience model acquire ner grain discriminations reinforcement contingencies require 
animals learn ne distinctions pitch intensity color generalize properties depending demands task 
state space dynamically re nable experience 
coined term refer class agents designed operant conditioning skinner eschew representations theory 
laid groundwork model able move model addresses presently unsettled psychological issues instrumental learning dickinson 
acknowledgments supported national science foundation iri 
joseph sullivan scott raymond technical assistance robot randy gallistel rob bruce blumberg helpful discussions 
captions flow information learning program 
merit curves converge true reward rate number samples increases 
skinner box con gured task 
optimal predictors task 
performance trial task 
number embedded arrow predictor applied indicates predictor satis ed situation clueless 
actual predictors responsible program behavior trial shown order applied 
amelia performing toy sorting task 
human trainer issues rewards radio trackball left hand 
table captions table state working memory moment water received 
table tags construct temporal predicates 
asada noda hosoda 

coordination multiple behaviors acquired vision reinforcement learning 
international conference intelligent robots systems 
ieee 
barnett 

modern ethology 
oxford university press 
barto sutton 

time derivative models conditioning 
gabriel moore editors learning computational neuroscience foundations adaptive networks pages 
mit press ma 
baxter raymond cook byrne 

empirically derived adaptive elements networks simulate associative learning 
commons grossberg staddon editors neural network models conditioning action pages 
lawrence erlbaum associates hillsdale nj 
parr 

natural syntax rules control action sequence rats 
behavioural brain research 


delayed matching pigeon 
journal experimental analysis behavior 


misbehavior organisms 
american psychologist 
brown jenkins 

auto shaping pigeon 
journal experimental analysis behavior 
muir robbins 

automated touchscreen procedure assessing learning rat computer graphic stimuli 
neuroscience research communications 
catania harnad editors 
selection behavior 
cambridge university press 
cci 
cci program 
canine companions independence santa rosa ca 
informational page available berkeley edu cci cci html 
chomsky 

review skinner verbal behavior 
language 
colombetti dorigo 

behavior analysis training methodology behavior engineering 
ieee transactions systems man cybernetics part 
dickinson 

instrumental conditioning 
editor handbook perception cognition 
volume 
academic press orlando fl 
dorigo 

robot shaping developing autonomous agents learning 
arti cial intelligence 
drescher 

minds 
mit press cambridge ma 
gallistel 

organization learning 
mit press cambridge ma 


conditioned reinforcement schedule ects 
staddon editors handbook operant behavior 
prentice hall 
graham 

sni virtual rat simulated operant conditioning 
research methods instruments computers 
grossberg 

neural theory punishment avoidance ii quantitative theory 
mathematical biosciences 
barnes rawlins 

working memory tasks choice operant chambers relative absolute spatial memories 
behavioral neuroscience 
hammer 

identi ed neuron mediates unconditioned stimulus associative olfactory learning 
nature 


hippocampal cell ring correlates sample performance rat 
behavioral neuroscience 
holland 

cognitive aspects classical conditioning 
current opinion neurobiology 
klopf 

neuronal model conditioning 

graham 

sni virtual rat 
brooks cole paci grove ca 
includes software diskette 


problem serial order behavior 
je ries editor cerebral mechanisms behavior 
john wiley sons 
mahadevan connell 

automatic programing behavior robots reinforcement learning 
arti cial intelligence 


connectionist approach conditional discriminations learning short term memory attention 
commons grossberg staddon editors neural network models conditioning action pages 
lawrence erlbaum associates hillsdale nj 
mataric 

designing understanding adaptive group behavior 
adaptive behavior 
mataric 

reinforcement learning multi robot domains 
autonomous robots 


learning cient reactive behavioral sequences basic re goal directed autonomous robot 
animals animats proceedings third international conference simulation adaptive behavior pages cambridge ma 
mit press 


rapid safe incremental learning navigation strategies 
ieee transactions systems man cybernetics part 
montague dayan person sejnowski 

bee foraging uncertain environments predictive hebbian learning 
nature 
pavlov 

conditioned re 
oxford university press 
pryor 

wind 
harper row new york 
raymond baxter byrne 

learning rule empirically derived activity dependent supports operant small network 
neural networks 
wagner 

theory conditioning variations ectiveness reinforcement 
black editors classical conditioning ii theory research 
appleton century crofts new york 
reynolds 

primer operant conditioning 
scott 
schmajuk 

complexity adaptive neural network 
models action 
lawrence erlbaum associates hillsdale nj 
schultz ljungberg dickinson 

signals carried dopamine neurons 
davis editors models information processing basal ganglia chapter pages 
mit press 
schwartz 

psychology learning behavior 
norton 
simmons 

structured control autonomous robots 
ieee transactions robotics automation 
singh 

transfer learning sequential tasks 
machine learning 
skinner 

behavior organisms 
appleton century crofts 
skinner 

pigeon 
journal experimental psychology 
staddon 

experiment reexamination implications principle adaptive behavior 
psychological review 
sutton barto 

modern theory adaptive networks expectation prediction 
psychological review 
touretzky 


maes mataric meyer pollack wilson editors animals animats proceedings fourth international conference simulation adaptive behavior pages 
mit press 
wray sporns edelman 

multilevel analysis classical conditioning real world artifact 
robotics autonomous systems 
watkins 

learning delayed rewards 
phd thesis cambridge university cambridge england 
flow information learning program 
counts time working memory time match predictors generate new predictors select action working memory time execute action time action taken rewards counts time working memory time perceive match world predictors time new percepts merit uncertainty estimate reward rate number trials merit curves converge true reward rate number samples increases 
port cue light left switch extended water dispenser right switch retracted skinner box con gured task 
receive water hear pump goto dispenser hear pump press switch past press switch hear pump press switch past press switch see light reinforced past press switch see light reinforced past press switch see switch see light poke poke port see switch see light poke poke port press switch see switch goto sw loc press switch see switch goto sw loc poke poke port port loc fut optimal predictors task 
reinforced sw loc goto port loc poke poke port reinforced port loc goto sw loc see switch sw loc goto sw loc switch extended press switch see switch sw loc press switch switch extended see light sw loc goto port loc light poke poke port see light port loc poke poke port light poke poke port see switch see switch port loc goto sw loc req switch extended switch extended press switch see switch see switch sw loc press switch switch extended switch extended hear pump sw loc goto dispenser pump running dispenser receive water goto sw loc performance trial task 
number embedded arrow predictor applied indicates predictor satis ed situation clueless 
see switch port loc past reinforced prev goto sw loc prev see light reinforced past see switch prev goto sw loc prev see light reinforced past press switch see switch sw loc past see light prev goto port loc prev see switch see light prev poke poke port press switch see switch goto sw loc hear pump press switch past see switch press switch receive water hear pump fut actual predictors responsible program behavior trial shown order applied 
black white photograph supplied separately amelia performing toy sorting task 
human trainer issues rewards radio trackball left hand 
age sensory predicates action predicate ne corner goto se corner se corner hear pump goto dispenser dispenser receive water table state working memory moment water received 
tag meaning fut true true prev true past true table tags construct temporal predicates 

