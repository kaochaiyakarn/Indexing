information theoretic tools mining database structure large data sets university toronto cs toronto edu data design characterized process arriving design maximizes information content piece data equivalently minimizes redundancy 
information content redundancy measured respect prescribed model data model expressed set constraints 
consider problem doing data redesign environment prescribed model unknown incomplete 
specifically consider problem finding structural clues instance data instance may contain errors missing values duplicate records 
propose set information theoretic tools finding structural summaries useful characterizing information content data ultimately useful data design 
provide algorithms creating summaries large categorical data sets 
study summaries specific physical design task ranking functional dependencies data redundancy 
show ranking physical data design tool find vertical decompositions relation decompositions improve information content design 
evaluation approach real data sets 

growth networked databases led larger complex databases structure semantics gets difficult understand 
heterogeneous applications data may exchanged integrated 
integration may introduce anomalies duplicate records missing values erroneous values 
addition lack documentation unavailability original designers task understanding structure semantics databases difficult 
matter carefully database designed past guarantee data semantics preserved evolves time 
usually assumed schema constraints trustworthy means provide accurate model time invariant properties data 
legacy databases integrated data may valid assumption 
may need redesign database find model schema constraints better fit current data 
consider problem mining data instance permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
sigmod june paris france 
copyright acm 

ren miller university toronto miller cs toronto edu univ rome la sapienza dis uniroma structural clues help identifying better data design 
spirit approaches propose tools help analyst process understanding cleaning database 
approaches focus providing summaries help process integration querying focus summaries reveal information data design information content 
approach problem important understand data design 
data design characterized process arriving design maximizes information content piece data equivalently minimizes redundancy 
information content redundancy measured respect prescribed model data model expressed set constraints dependencies 
arenas libkin information theoretic measures comparing data designs :10.1.1.10.1809
schema set constraints information content design precisely characterized 
approach benefit permits designs database compared directly 
characterize information content necessary prescribed model 
consider example 
ename city zip pat boston pat boston sal boston examples duplication redundancy clearly duplication values instance 
consider redundant depend constraints expressed schema 
functional dependency ename city holds value boston tuple redundant presence tuple 
remove value inferred information tuple 
third tuple redundant 
lose value know city 
value boston duplicated redundant 
change constraints ename city dependency zip city situation reversed 
redundant 
understanding redundancy heart database design 
redundancy occurs naturally reflects intuitive thinking process humans 
humans naturally associative naturally tend aggregate bring information minds facilitates processing information 
way store information computer 
normalization systematic process database design separate information different entities objects interest different tables 
allows avoid data redundancy occur naturally associating different types information 
obvious apply normalization define information content database environment schema constraints may incorrect incomplete 
consider problem 
core techniques find duplicate values 
techniques counting example frequent item set mining information theoretic clustering techniques identify summarize information content duplicate values 
approach viewing data inconsistent incomplete respect schema consider schema potentially inconsistent incomplete respect data instance 
contributions 
propose set information theoretic tools clustering discover duplicate records sets correlated attribute values groups attributes share values 
provide set efficient algorithms identify duplication large categorical data sets 
algorithms generate compact summaries analyst identify errors understand information content data set 
applications summaries data quality problems duplicate elimination identification anomalous values 
applications data design problems horizontally partitioning integrated overloaded relation ranking functional dependencies information content 
application show techniques combination dependency miner help understand discovered dependencies 
rest organized follows 
section related section introduce basic concepts information theory 
section draw relationship existence duplicate information clustering 
section describe limbo scalable informationtheoretic clustering algorithm section tools algorithm derive structural clues 
section introduce novel algorithm ranks functional dependencies hold instance 
section presents experimental evaluation methods section concludes discusses additional applications 

related finds inspiration independent lines 
data quality browsers potter wheel bellman 
second information theoretic foundation data design 
data browsers aim help analyst understand query transform data 
addition sophisticated visualization techniques adaptive query transformation processing techniques employ host statistical summaries permit real time browsing 
consider generation summaries data browser data re design 
summaries complement summaries bellman focus identifying occurrence values different relations identify join paths correspondences attributes different relations 
robust set techniques identifying summarizing various forms duplication relation 
arenas libkin provide information theoretic measures comparing data designs :10.1.1.10.1809
schema set constraints information content design precisely characterized 
measures computational infeasible rely having clean instance conforms fixed set constraints 
techniques efficient informationtheoretic clustering approach 
unsupervised learning able create informative summaries accurate model set constraints data 
show techniques identify accurately better designs 
constraint dependency mining related field study goal find dependencies hold instance data dependencies invalidated instance 
approaches include discovery functional multi valued dependencies 
complements providing means characterizing redundancy captured dependency 
constraint miners reveal hundreds thousands potential approximate dependencies run large real data sets 
helps data analyst understand quickly identify interesting dependencies large sets 
importance automated data design redesign tools recognized reports state database research 
advances area largely limited physical design tools help tailor design best meet performance characteristics workload 
cluster analysis vertical partitioning techniques partition attributes relation usage workload queries data 
hand mirrors store different versions database combined query optimization 
technique usage attributes queries 
complements duplicate elimination 
propose technique identify duplicates information content tuples 
approach consider identify distance functions measuring error values main focus related area 
interesting area combine techniques 

information theory basics follows introduce basic concepts information theory 
find definitions textbook information theory 
denote discrete random variable set takes values 
denotes probability mass function entropy defined log 
intuitively entropy measure uncertainty variable value high certainty predict values random variable low 
variable takes states maximum value entropy hmax log realized states equiprobable discrete random variables takes values sets respectively conditional entropy defined follows 
log conditional entropy measure uncertainty predict values random variable values 
remainder italic capital letters denote random variables boldface capital letters denote set random variable takes values 
having defined entropy conditional entropy may introduce mutual information 
measure captures amount information variables convey 
symmetric non negative relation entropy equation 
relative entropy kullback leibler kl divergence information theoretic measure quantify distance probability distributions 
distributions set relative entropy defined follows 
dkl log intuitively relative entropy dkl measures error encoding assumes distribution true distribution 

clustering duplication section consider information tuples values tuples build structural information independent constraints hold relation 
techniques designed find duplication large data sets 
considering real data sets may contain errors missing values looking groups containing exact duplicates groups containing near duplicates similar values 
techniques clustering 
clustering identify groups data objects similar objects different groups dissimilar 
schemas structured query languages treat data values largely uninterpreted objects 
property called genericity closely tied data independence concept schemas provide abstraction data set independent internal representation data 
choice specific data value pat patricia inherent semantics influence schema structure values 
semantics captured schema independent choices 
query languages genericity usually formalized saying query commute possible permutations data values permutations may restricted preserve distinguished set constants 
property important considers clustering algorithms 
clustering assumes defined notion similarity data objects 
clustering methodologies employ similarity functions depend semantics data values 
example values numbers euclidean distance may define similarity 
want impose application specific semantics data values database 
seeking identify duplication set tuples need measure similarity reflects duplication tuples 
measure obvious define quality results 
hand humans intuitive notion quality clustering 
clustering clusters informative objects contain 
cluster able predict attribute values tuples cluster maximum possible 
assume model set tuples defined attributes 
am 
domain attribute ai set vi vi vi 
vi 
tuple takes exactly value set vi th attribute 
functional dependency attribute sets denoted holds tuples agree values agree corresponding values 
apply information theoretic techniques treat relations distributions 
tuple containing value set probability appears tuple go back example consider representation tuples 
row corresponds tuple 
non zero value row attribute value tuple values row sum 
sal boston example tuple representation representation consider values data set 
row table charac sal boston example value representation occurrence values tuples value non zero entry tuples appears 
similar tuple row sums 
formal definitions representations section 
representations consider number novel clustering approaches identifying duplication tuples values attributes 
techniques founded ib method introduce 

clustering methodology section describe information bottleneck ib method scalable clustering algorithm ib 
information bottleneck intuitive idea producing clusters informative objects contain formalized tishby pereira bialek 
recast clustering compression random variable compact representation preserves information possible random variable 
approach named information bottleneck ib method applied variety different areas 
formally set objects set expressed set seek clustering mutual information remains large possible loss information described minimum 
ib method generic imposing semantics specific data values 
finding optimal clustering np complete problem 
slonim tishby propose greedy agglomerative approach agglomerative information bottleneck aib algorithm finding informative clustering 
set contains objects algorithm starts clustering cq object assigned cluster 
due mapping cq cq 
algorithm proceeds iteratively steps number desired clusters reducing number clusters current clustering iteration 
step clusters ci cj clustering clustering clusters merged cluster produce new clustering 
algorithm forms clusters smaller size information clustering contains decreases means 
clusters ci cj merged chosen loss information ci cj moving clustering minimum 
merging clusters ci cj new cluster ci cj ci cj ci tishby show cj ci cj ci cj ci cj djs ci cj djs jensen shannon js divergence defined follows 
pi ci pj cj ci cj pi pj djs distance defined follows 
djs pi pj ci cj dkl pi dkl pj djs distance defines metric bounded 
note information loss merging clusters ci cj depends clusters ci cj parts clustering 
scalable clustering aib algorithm suffers high computational complexity quadratic number objects clustered appropriate large sets 
scalable version aib called limbo scalable information bottleneck 
limbo uses distributional summaries order deal large data sets 
algorithm similar spirit birch clustering algorithm idea need keep clusters main memory just sufficient statistics describe 
sufficient statistics called distributional cluster features dcf compute distance clusters cluster tuple 
set objects clustered expressed set corresponding random variables 
denote clustering corresponding random variable 
cluster dcf defined pair dcf probability cluster conditional probability distribution values cluster consists single object computed described section 
denote cluster obtain merging clusters 
dcf cluster equal dcf computed equations respectively 
clusters define distance dcf dcf information loss incurred merging corresponding clusters 
computed equation 
importance dcf lies fact stored updated incrementally 
probability vectors stored sparse vectors reducing amount space considerably 
dcf provides summary corresponding cluster sufficient computing distance clusters 
tree data structure termed dcf tree 
scalable algorithm proceeds phases 
phase dcf tree constructed summarize data 
second phase dcf tree leaves merged produce chosen number clusters 
third phase associate object tuple attribute value attribute dcf closest 
phase insertion dcf tree 
objects clustered read disk time point construction tree dcf leaves define clustering tuples seen far 
non leaf node stores dcf produced merging dcf children 
objects inserted tree dcf tree embodies compact representation data set summarized information dcf leaves 
summarization parameter controls accuracy model represented tree 
precisely quantity threshold merge dcf leaf level tree exceed 
smaller values result compact summarizations 
instance merge identical objects limbo equivalent aib 
phase clustering 
creation tree apply aib smaller number objects represented dcf leaves 
phase associating object clusters 
chosen value phase produces dcf serve representatives clusters 
final phase perform scan data set assign object cluster minimized 
approach shall scalable clustering algorithm find duplicate groups tuples attribute values groups attributes considered similar contain groups 

duplication summaries section suite structure discovery tasks performed information theoretic clustering 
see information tuples build structural information attribute values information attributes relation 
input problem set tuples set vm denotes set possible values 
denote size set shall denote random variables range sets respectively 
tuple clustering tuple clustering find clusters tuples preserve information values contain possible 
represent data matrix tuple contains attribute value zero 
note vector tuple contains tuple defined exactly attribute values define appears intuitively consider tuple equi probable normalize matrix th row holds conditional probability distribution 
define mutual infor terms attribute values values interchangeably 
mation cluster tuples clusters ct information loss ct minimum 
duplicate tuples duplicate tuples introduced data integration 
different sources may store information entity 
values stored may differ slightly integration performed entries may created entity 
example imagine situation employee information integrated different sources employee numbers represented differently sources 
integration natural expect tuples referring employee may differ employee number attributes database date 
identify duplicate duplicate tuples proceed follows 

set value 

apply phase construct tuple summaries 

leaf dcf apply phase associate tuples initial data set closest summary proximity measured information loss 
step procedure defines accuracy representation groups tuples summaries leaf level dcf tree 
merge identical tuples representation exact 
increase summaries permit errors duplicate values 
step applies phase produce summaries step associates tuples summaries represent groups tuples tuple 
natural explore sets tuples associated summaries find candidate duplicate ones 
horizontal partitioning second application tuple clustering horizontal partitioning table 
horizontal partitioning useful tables overloaded different types data 
example order table originally designed store product orders may reused store new service orders 
horizontal partitioning seeking separate different types tuples similarities attribute values 
specifically try identify natural clustering separates tuples having different characteristics 
horizontal partitioning full clustering 
apply phase obtain small set summary 
need set priori threshold information loss pick number leaves sufficiently large example leaves apply phase obtain summaries 
apply aib leaves obtain clusterings values 
heuristic identify values may correspond natural horizontal partitions 
producing statistics directly compare clusterings 
statistics include rate change mutual information clusterings ck rate change conditional entropy clusterings ck varies number leaf entries 
conditional entropy ck captures dissimilarity clusters clustering ck 
examining derivatives able identify clusterings different values 
clustering may inspect clustering determine clustering corresponds natural semantic distinction objects 
attribute value clustering tuple clustering build clusters attribute values maintain information tuples appear possible 
parameter case denoted small values allow identification perfectly occurring groups attribute values 
useful connection tuple attribute value clustering drawn number tuples large 
value cluster tuples attribute values expressed smaller set tuple clusters individual tuples 
attribute value clustering performed described 
technique referred double clustering 
contrary tuple clustering goal cluster values represented random variable retain information tuples appear 
represent data matrix attribute value appears tuple zero 
note vector value contains dv di di value define dv appears intuitively consider value equi probable normalize matrix th row holds conditional probability distribution 
consider example relation depicted 
left shows normalized matrix relation 
define sec duplication perfect correlation matrix left right ond matrix keeps track frequency attribute values corresponding attributes 
defined matrix dv value appears dv times attribute intuitively entry matrix stores support value attribute relation 
example matrix right hand side 
note value aj dv attribute vl matrix define mutual information cluster attribute values clusters cv loss information cv minimum 
intuitively seek groups attribute values cv retain information tuples appear 
groups values may contain duplicate values 
show characterize sets attribute values clusters cv subsection 
set may entail large number values aib algorithm infeasible 
perform clustering limbo dcf extended order include information matrix define attribute distributional cluster features cluster values triplet defined section sum corresponding rows sub clusters represents 
similar fashion tuple clustering limbo identify duplicate duplicate values data set 

set value 

apply phase construct summaries attribute values 

leaf apply phase associate attribute values initial data set closest summary proximity measured information loss 
augmenting dcf way able perform value clustering value matrix time 
able find sets attribute values arbitrary size counts number tuples appear application clustering algorithm 
specifically require passes dataset 
pass construct matrices pass perform phase final pass perform phase 
example performing clustering allow loss information merges attribute values clustered values 
values perfect occurrence tuples original relation 
clustering values depicted left hand side 
resulting matrix example depicted clustered matrix left right right hand side 
cluster values corresponding row means values cluster appear times attribute times attribute general stores cumulative counts values inside attributes relation 
contain important information sub section describes finding duplicate non duplicate groups values 
moving sub section critical emphasize role parameter explained control accuracy model represented leaves tree 
plays significant role identifying perfect occurrences values 
illustrate consider relation 
relation value second tuple 
constructing matrices done explained 
trying cluster method place exhibit perfect occurrence 
may result erroneous placement second tuple difference representation data sources integrated table 
functional dependency holds relation approximate hold tuples 
capture anomalies perform clustering allows small loss information merging leaves tree 
matrices depicted 
notion approximation value 
matrix left right contrast methods characterize approximation number tuples values tuples 
data method determines value second tuple affects perfect duplication pair value 
tuple attribute value clustering combined size input large 
specifically define mutual information cluster tuples clusters represented ct define ct ct define ct scale clustering attribute values 
grouping attributes information loss define notion proximity values 
define proximity attributes values contain 
cluster attributes limbo 
application limbo control information loss value denoted typically number attributes number tuples small values rows compressed matrix represent groups values conditional probability distributions tuples appear exactly approximately 
rows corresponding rows compressed matrix infer groups attribute values appear duplicates set attributes 
looking clusters values appearance tuple attribute 
precisely define 
denotes set duplicate groups attribute values 
set values belongs tuples ti tj ti tj time attributes ax ay ax ay 
nd denotes set non duplicate groups attribute values 
set comprised values cv sets appear just tuples data set 
example easy see nd groups contains interesting information may lead grouping attributes attributes group contain duplicate values attributes different groups 
set attributes random variable takes values set express members information kept matrix denote members random variable takes values set group attributes clustering information remains maximum 
intuitively cluster attributes information duplicate groups attribute values exist remains high possible 
set cv focus set attributes potentially offer higher duplication time reduce size input task 
set usually includes manageable number attributes limbo produce full clustering attributes produce clusterings 
performing agglomerative clustering phase attributes step cluster pair creates group maximum possible duplication 
example depicts table attributes expressed set explained information matrix rows correspond members 
note matrix example name matrix normalizing rows sum proceed algorithm cluster attributes 
merges performed depicted dendrogram 
dendrogram tree structure depicts sequence merges clustering corresponding values distance similarity 
horizontal axis example shows information loss incurred merging point 
initially attributes form singleton clusters 
merge amount information loss occurs attributes attribute merged previous cluster 
matrix attr 
cluster dendrogram looking back example see attributes contain tuples duplicate group values respect group values 
section show attribute clustering rank set functional dependencies holding instance 
ranking reveals dependencies best decomposition algorithm improve information content schema 

ranking dependencies desirable goal structure discovery derive clues respect potential decomposition integrated data set 
tools finding exact approximate relationships tuples attribute values attributes data set 
pointed duplication redundancy 
understand relationship turn mining constraints dependencies 
approaches discovery functional multivalued dependencies 
approaches presents resulting dependencies 
section novel procedure performs ranking functional dependencies hold instance redundancy represent initial relation 
motivate fd rank input set merge sequence threshold output set 
fd single attribute rank fd max max inf 
loss rank fd il inf 
loss merge attributes participate il max 
fd fd rank fd rank fd set fd 
order set ascending order rank produce fd rank algorithm decompositions dependencies high rank produce better designs decompositions 
indication amount duplication values cluster attributes ca entropy ca 
entropy captures skewed distribution ca skewed distributions expected higher duplication 
lower entropy skewed distribution 
proposition shows step clustering attributes minimizes entropy 
proposition 
sets attributes ca ca ca information loss merging ca ca smaller information loss merging ca ca duplication larger duplication 
proof 
clustering merge ca ca ca ca inequality states duplicate groups values appear times implies duplication higher 
result justifies observation scan dendrogram full clustering attributes sub clusters get merged ones higher duplication 
creation dendrogram set functional dependencies rank duplication initial relation removed decomposition 
functional dependency contains attributes high duplication may say duplicate values attributes redundant 
redundancy functional dependency removes initial relation interesting purposes 
knowing values information loss merges sequence attribute sub clusters proceed algorithm fd rank rank functional dependencies intuitively sequence merges attributes matrix set corresponding information losses initialize rank dependency maximum information loss realized full clustering procedure step 
set values participate functional dependency step update rank highest information loss merge attributes merged information loss percentage specified maximum information loss step 
point break ties functional dependencies acquire ranking number participating attributes rank ones attributes higher 
step collapses functional dependencies antecedent ranks single functional dependency step orders set ascending order corresponding ranks 
example maximum information loss realized attribute clustering approximately 
initial rank dependencies acquire 
update rank functional dependency information loss merge attributes merge lower 
point highest ranked functional dependency contains attributes highest redundancy 
looking back initial relation dependency decompose relation relations reduction tuples redundancy reduction higher decompose relations 
number functional dependencies finding greatest common merge smaller times maximum information loss realized done time attributes participating dependency traverse merges find desired common merge 
final step ordering dependencies ranks worst case complexity log 
total complexity log 
case practice previous complexity dominated number dependencies term 

experimental evaluation ran set experiments determine effectiveness tools discussed structure discovery process 
report results data set provide evidence usefulness approach 
data sets 
experiments data sets 
db sample database data set constructed small database pre installed ibm db 
built single relation joining tables database tables employee department project 
schema tables key attributes separated line top box foreign key arrows constraints depicted 
relational algebra expression produce single relation initials relation depno depno depno relation contains tuples attributes attribute values 
instance illustrate types errors able discover information theoretic methods dblp database data set created xml document dblp uni trier de xml 
document stores information different types computer science publications 
order integrate information single relation chose ibm schema mapping tool permits creation queries transform information stored xml format relations 
specified target schema www ibm com software data db udb employee empno firstname lastname job sex department depno project db sample dblp author publisher year editor pages booktitle month volume number school series isbn dblp schema tuples relation defined containing attributes depicted 
specified correspondences source xml schema attributes 
queries mapping tool create relation contained tuples attribute values 
tuple contains information single author particular publication involved author mapping created additional tuples 
highly heterogeneous information source xml document information regarding conference journal publications introduced large number null values tuples relation 
highly heterogeneous relation demonstrate strength approaches suggesting better structure target relation initially specified 
parameters 
observed experimentally branching factor dcf tree significantly affect quality clustering 
set phase insertion time manageable smaller values lead higher insertion cost due increased height dcf tree 
explored large number values 
generally speaking larger values delay leaf node splits create smaller tree coarse representation data set 
hand smaller values incur splits preserve detailed summary initial data set 
value method equivalent aib identical objects merged 
functional dependency discovery 
goal rediscover functional dependencies provide ranking existing set 
purposes study method discover functional dependencies 
methods 
computes maximal invalid dependencies pairwise comparison tuples set computes minimal valid dependencies 
algorithm proposed flach performs second step depthfirst search approach set maximal invalid dependencies test functional dependency holds prune search space 
computing functional dependencies computed minimum cover maier algorithm 
duplication measures 
order evaluate amount redundancy removed initial data set measures quantify results approach 
measures relative attribute duplication rad relative tuple reduction rt defined 
relative attribute duplication set tuples set ca 
aj attributes tion tc tuples attributes ca assume bag semantics define rad ca tc ca log intuitively rad captures number bits save representation ca due repetition values 
definition clearly distinguish duplication differently sized relations 
example assume relations single attribute having value tuples second value tuples 
definition suggest relations rad equal missing fact relation contains duplication second contains tuples 
overcome introduce measure 
relative tuple reduction set tuples set ca 
aj attributes tc set tuples projected set ca assume set semantics define rt ca intuitively rt quantifies relative reduction number tuples get project tuples relation ca 
rad rt offer different measures extent values repeated relation 
closer look rad reveals measure width sensitive 
definition conditional entropy nominator fraction rad considered weighted entropy tuples particular set attributes weights taken probability set attributes 
hand rt size sensitive quantify duplication different set tuples taken set attributes 
small scale experiments phase experiments performed collection structure discovery tasks db sample data set see effective tools finding exact duplicate tuples values data 
data set clean errors introduced illustrate potential methods 
application tuple clustering exact tuple duplicates 
method identify exact duplicates introduced data set order 
duplicates 
typographic notational schema discrepancies 
errors may introduced information recorded differently data sources integrated single source 
example case employee numbers stored different schemes typographical notational errors 
hand case unknown values integration filled values order satisfy common integrated schema schema discrepancies 
identify type errors introduced tuples data set values attributes differ values corresponding attributes matching tuples data set 
fixed value performed study various numbers erroneous tuples attribute values 
fixed number erroneous tuples inserted performed study number erroneous attribute values varied 
changed number attribute values inserted tuples time 
results experiments table 
table strength method determining groups tuples differ lot evident 
small number dirty tuples inserted table left indicates method fails discover approximate duplicates number attribute values differ half number attributes schema 
table shows number duplicates increases performance method deteriorates gracefully 
table right number inserted tuples shows accuracy chosen model summaries decreases larger values identification approximate duplicates difficult cases tuples associated constructed summaries 
general duplicates tuple clustering user inspection suggested tuples reveals interesting ones duplicates corresponding physical entities represented tuples 
note effectiveness phase fail identify correct correspondences tuples summaries leaf entries tree 
application attribute value clustering section experiments attribute value clustering 
perfect correlations increasing approximate ones attribute values data set 
value correlations 
clustering tuples performed looked perfect correlations values groups attributes values appear exclusively tuples 
clustering method successfully discovered groups values set note expect get perfectly correlated sets values believe information critical aligns method frequent itemset counting 
higher values able discover potential entry errors 
value errors 
part experiments introduced errors similar ones tuple clustering goal locate values responsible errors tuple proximity 
better results may combine results tuple attribute value clustering 
performed experiments set tuples artificially inserted performed tuple clustering counted number correct placements dirty values clusters attribute values appear exclusively tuples 
wanted see dirty value correctly clustered values replaced 
results experiments table 
similar tuple clustering method performs number inserted tuples quite large relative size initial data set 
correct placement attribute value clusters takes place number altered values covers half attributes data set 
attribute grouping having information duplicate values built matrix dendrogram produced depicted 
remind reader horizontal axis represents information loss 
data set maximum information loss realized 
indicated boxes attribute grouping separated attributes initial schemas large extent exception attributes 
dendrogram identify pairs empno name lastname empno firstname lastname err 
tuples err 
tuples value errors value errors value errors value errors table db sample results erroneous tuples left err 
tuples right err 
tuples err 
tuples value errors value errors value errors value errors table db sample results erroneous values left err 
tuples right max information loss db sample attribute clusters exhibit highest redundancy data set result agrees data instance intuition 
addition previous experiment increased value respectively 
set attributes remained attribute included 
large information loss attribute merged attributes 
experiments relative sequence merges remained indicating attribute grouping stable presence errors higher values 
ranking functional dependencies having sequence merged attributes fd rank identify functional dependencies decomposition help removal high amounts redundancy initial data set 
initially discovered functional dependencies minimum cover consisted dependencies 
highest ranked dependencies order increasing rank list 


empno firstname lastname 
fd rad rt 



table rad rt values db sample table shows rad rt values previous functional dependencies attributes project tuples initial relation 
table shows decompositions initial relation ordered list dependencies favor removal considerable amounts redundancy 
ranking identifies dependencies high redundancy high rad rt values 
attributed fact correlations corresponding attributes high attribute value clusters lower support initial data set 
fact visible dendrogram attributes lower information loss project proposition going remove redundancy 
large scale experiments experiments larger dblp data set 
performed different series experiments large integrated relations part structure discovery task 
dblp data set contains integrated information 
relation contains tuples computer science publications appeared part conference proceedings journals theses argued type information added anomalies due discrepancies source target 
specifically conference publications attributes filled values 
conference publications appear part publication sigmod publications sigmod record journal direct projection attributes known conference journal publications lead errors 
better approach horizontally partition data set small number groups similar characteristics 
performing horizontal partitioning performed attribute grouping order identify attributes useful partitioning 
reduced number tuples performed attribute grouping 
result grouping depicted 
dendrogram observe number attributes demonstrate perfect correlation 
author pages booktitle publisher isbn editor series school month year volume journal number dblp attribute clusters attributes dashed box zero zero information loss indicating correspondence values 
true value prevails set attributes null value 
manual inspection data set revealed set attributes publisher isbn editor series school month contains values anomaly introduced transformation xml data integrated schema 
having set attributes limited non missing information horizontal partitioning produced unexpected results 
precisely performed phases algorithm cluster tuples groups 
result contained huge cluster tuples clusters tuple 
result informative 
tuples relation duplicates attributes null values forced summaries 
observation attributes values set aside considerable loss information tuples 
time goal definition possible schema relation existence huge percentage null values suggests attributes contain large amounts duplication stored separately horizontal partitioning 
previous observation projected initial relation attribute set author pages booktitle year volume journal number 
performed horizontal partitioning tuples 
heuristic choosing described section determined natural grouping data 
loss initial information phase indicating clusters highly informative 
characteristics clusters table 
consider cluster separately due lack space report results attribute grouping dependency ranking 
cluster table horizontal partitions cluster horizontal partition contains conference publications booktitle attribute non null value tuple 
number attribute values performed grouping attributes result 
dendrogram attributes reveals zero distance volume journal number attributes 
attributes exclusively contained null values cluster 
addition zero distance attributes author happens due mapping values author tuples unique pages values cluster 
booktitle closer previous attributes conference titles correlated authors 
having sequence attribute merges find functional dependencies hold fd rank rank 
dependencies minimum cover contained 
noted functional dependency author pages booktitle 
top dependencies rad rt values attributes table 
numbers indicate significant redundancy reduction achieve dependencies decomposition 
dependencies ranked higher contain conference attributes highly informative values attributes cover indicate removal redundancy 
hand author pages booktitle large domains significant redundancy reduction 
rad rt volume journal number journal table ranked dependencies 
cluster second horizontal partition contains journal publications journal volume number attributes non null values 
size attribute values dendrogram produced depicted 
observation attributes generally characteristics journal publications 
see correlations appear journal volume number natural assume publications 
example sigmod record journal appears quarter values number attribute 
sequence merges attributes ranked functional dependencies holding partition 
discovered set functional dependencies minimum cover contained dependencies 
fd rank top ranked dependencies table rad rt values attributes contain 
note dependencies rank 
dependency attributes ranked top 
rad rt author volume journal number year author year volume journal table ranked dependencies 
cluster horizontal partition small size compared previous contained miscellaneous publications technical reports theses contained small number conference journal publications written single author 
dendrogram produced set 
nature size cluster attribute associations random find functional dependencies partition fact suggesting relation internal structure 
point initial horizontal partitioning adds additional benefit approach initial relation defined attributes contained hundreds author pages booktitle year volume journal number cluster author pages year number volume journal functional dependencies mainly due attributes containing null values clusters produced small number dependencies defined attributes 
understanding schema easier task 

novel approach discover structure 
approach defines schema discovery problem schema relation inconsistent respect data opposite 
set information theoretic tools clustering discover duplicate duplicate tuples attribute values relational instance 
information collected values approach groups attributes duplication values 
groups attributes large duplication provide important clues redefinition schema relation 
clues introduced novel approach rank set functional dependencies valid instance 
case studies demonstrated effectiveness methods discovering integration anomalies alternative structural properties 

abiteboul hull vianu 
foundations databases 
addison wesley 
agrawal imielinski swami 
mining association rules sets items large databases 
sigmod pages washington usa 
agrawal chaudhuri narasayya 
materialized view index selection tool microsoft sql server 
sigmod page 
chaudhuri ganti 
eliminating fuzzy duplicates data warehouses 
vldb pages hong kong china 
miller sevcik 
limbo scalable clustering categorical data 
edbt pages heraklion greece 
arenas libkin :10.1.1.10.1809
information theoretic approach normal forms relational xml data 
pods pages san diego ca usa 
cover thomas 
elements information theory 
wiley sons new york ny usa 
robertson 
information dependencies 
pods pages dallas tx usa 
johnson 
exploratory data mining data cleaning 
john wiley sons 
johnson muthukrishnan shkapenyuk 
mining database structure build data quality browser 
sigmod pages madison wi usa 
el yaniv 
iterative double clustering unsupervised semi supervised learning 
ecml pages freiburg germany 
garey johnson 
computers intractability guide theory np completeness 
freeman 
cluster author journal year booktitle cluster hern ndez stolfo 
merge purge problem large databases 
sigmod pages san jose california 

cluster analysis physical data base design 
vldb pages framingham ma usa 
rkk inen toivonen 
efficient algorithm discovering functional approximate dependencies 
computer journal 
maier 
minimum covers relational database model 
journal acm oct 
navathe ceri wiederhold dou 
vertical partitioning algorithms database design 
tods 
navathe ra 
vertical partitioning database design graphical algorithm 
sigmod pages portland usa 
popa hernandez miller fagin 
translating web data 
vldb pages hong kong china aug 
dewitt 
case mirrors 
vldb pages hong kong china aug 
raman hellerstein 
potter wheel interactive data cleaning system 
vldb pages roma italy 
sarawagi 
interactive deduplication active learning 
kdd pages edmonton canada 
sarawagi editor 
special issue data cleaning 
bulletin technical committee data engineering volume december 
flach 
bottom induction functional dependencies relations 
aaai workshop knowledge discovery databases pages washington dc usa 
flach 
dependencies relations 
intelligent data analysis journal 
slonim tishby 
agglomerative information bottleneck 
nips pages breckenridge 
tishby pereira bialek 
information bottleneck method 
th annual allerton conference communication control computing urban champaign il 
robertson 
heuristic driven depth algorithm mining functional dependencies relation instances 
pages munich germany 
zhang ramakrishnan livny 
birch efficient data clustering method large databases 
sigmod pages montreal qb 
