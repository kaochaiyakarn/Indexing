mitsubishi electric research laboratories www merl com human detection classification riemannian manifolds peter meer tr july new algorithm detect humans images utilizing covariance matrices object descriptors 
descriptors lie vector space known machine learning techniques adequate learn classifiers 
space dimensional nonsingular covariance matrices represented connected riemannian manifold 
novel approach classifying points lying riemannian manifold incorporating priori information geometry space 
algorithm tested inria human database superior detection rates observed previous approaches 
ieee cvpr may copied reproduced part commercial purpose 
permission copy part payment fee granted nonprofit educational research purposes provided partial copies include notice copying permission mitsubishi electric research laboratories acknowledgment authors individual contributions applicable portions copyright notice 
copying reproduction republishing purpose shall require license payment fee mitsubishi electric research laboratories rights reserved 
copyright mitsubishi electric research laboratories broadway cambridge massachusetts human detection classification riemannian manifolds rutgers university cs piscataway nj caip rutgers edu new algorithm detect humans images utilizing covariance matrices object descriptors 
descriptors lie vector space known machine learning techniques adequate learn classifiers 
space dimensional nonsingular covariance matrices represented connected riemannian manifold 
novel approach classifying points lying riemannian manifold incorporating priori information geometry space 
algorithm tested inria human database superior detection rates observed previous approaches 

human detection images considered hardest examples object detection problems 
articulated structure variable appearance human body combined illumination pose variations contribute complexity problem 
leading approaches human detection separated groups search method 
group methods sequentially applying classifier possible subwindows image 
polynomial support vector machine svm learned haar wavelets human descriptors 
extended multiple classifiers trained detect human parts responses inside detection window combined give final decision 
similar images real time moving human detection algorithm described haar wavelet descriptors extracted space time differences video 
adaboost discriminative features selected multiple classifiers combined form rejection cascade classifier rejects hypothesis considered negative example 
excellent human detector described training svm classifier densely sampled histogram oriented gradients mitsubishi electric research labs cambridge ma merl com peter meer rutgers university ece piscataway nj meer caip rutgers edu similar sift descriptors inside detection window 
performance proposed descriptors shown inria human database previous methods false positive rates orders magnitude higher detection rates 
similar approach near real time detection performances achieved training cascade model histogram oriented gradients hog features 
second group methods detecting human parts common shapes assembling local features geometric constraints form final human model 
parts represented occurrences local orientation features separate detectors trained part adaboost 
human location determined maximizing joint likelihood part occurrences combined geometric relations 
human detection system crowded scenes described 
approach combined local appearance features geometric relations global cues top segmentation pixel likelihoods 
approaches include silhouette information matching classification framework 
approach belongs group similar haar wavelets hog features covariance features human descriptors 
covariance features introduced matching texture classification problems extended tracking 
region represented covariance matrix image features spatial location intensity higher order derivatives similarly represent human covariance matrices overlapping regions 
adequate classical machine learning techniques train classifiers covariance matrices lie vector space 
symmetric positive definite matrices nonsingular covariance matrices formulated connected riemannian manifold 
main contribution novel approach classifying points lying riemannian manifold incorporating priori information geometry space 
relevant papers clustering data points lying differentiable manifolds 
organized follows 
section briefly describe covariance descriptors 
section riemannian geometry focussing space symmetric positive definite matrices 
sections describe algorithm classification riemannian manifolds application human detection 
experiments section 
covariance descriptors brief overview covariance descriptors specialization human detection 
dimensional intensity dimensional color image dimensional feature image extracted function mapping intensity color gradients filter responses rectangular region zi dimensional feature points inside region represented covariance matrix feature points cr zi zi mean points 
human detection problem define mapping ix iy arctan ix iy pixel location ix 
intensity derivatives term edge orientation 
defined mapping input image mapped dimensional feature image 
covariance descriptor region matrix due symmetry upper triangular part stored different values 
descriptor encodes information variances defined features inside region correlations spatial layout 
efficient way compute covariance descriptors integral images 
constructing integral images covariance descriptor rectangular region computed time independent region size 
refer readers details descriptors computational method 
arbitrary sized detection window large number covariance descriptors 
covariance descriptor 
dimensional feature image constructed input image mapping 
detection window possible descriptor subwindows 
computed subwindows shown 
perform sampling consider subwindows starting minimum size width height detection window possible locations 
size incremented steps horizontal vertical approach considered redundant due overlaps significant evidence overlapping regions important factor detection performances 
boosting mechanism described allows search best regions 
covariance descriptors robust illumination changes 
enhance property include local illumination variations image 
possible feature subwindow inside detection window compute covariance detection window cr subwindow cr integral representation 
normalized covariance matrix computed dividing columns rows cr respective diagonal entries cr 
method described equivalent normalizing feature vectors inside region zero mean unit standard deviation computing covariance descriptor subwindow process requires extra division operations 

riemannian geometry brief riemannian geometry focussing space symmetric positive definite matrices 
see detailed description 
refer points lying vector space small bold letters points lying manifold capital bold letters 
riemannian manifolds manifold topological space locally similar euclidean space 
point manifold neighborhood exists homeomorphism continuous mapping directions mapping neighborhood rm differentiable manifolds possible define derivatives curves manifold 
derivatives point manifold lies vector space tx tangent space point 
riemannian manifold differentiable manifold tangent space inner product varies smoothly point point 
inner product induces norm tangent vectors tangent space minimum length curve connecting points manifold called geodesic distance points length curve 
tx exists unique geodesic starting tangent vector exponential map exp tx maps vector point reached geodesic distance geodesic exp general exponential map exp neighborhood inverse mapping log tx uniquely defined neighborhood point exists tx exp log tangent vector smallest norm 
notice operators point dependent dependence explicit subscript 

space symmetric positive definite matrices dimensional symmetric positive definite matrices nonsingular covariance matrices sym formulated connected riemannian manifold ant riemannian metric tangent space sym tr yx zx 
exponential map associated riemannian metric exp yx global diffeomorphism continuously differentiable mapping directions 
logarithm uniquely defined points manifold log yx 
exp log ordinary matrix exponential logarithm operators 
confused exp log manifold specific operators point dependent sym tangent space sym space symmetric matrices manifold tangent spaces dimensional 
symmetric matrices ordinary matrix exponential logarithm operators computed easily 
eigenvalue decomposition symmetric matrix 
exponential series exp ut 
exp diagonal matrix eigenvalue exponentials 
similarly logarithm log 
exponential operator defined logarithms exist symmetric matrices positive eigenvalues sym definition geodesic previ ous section distance points sym measured substituting tr log yx 
note equivalent form affine invariant distance metric terms joint eigenvalues define orthogonal coordinate system tangent space vector operation 
orthogonal coordinates vector tangent space point upper yx upper refers vector form upper triangular part matrix 
mapping relates riemannian metric tangent space canonical metric defined 
mean points riemannian manifolds xi set points riemannian manifold similar euclidean spaces mean points riemannian manifold point minimizes sum squared distances arg min xi case distance metric 
differentiating error function respect setting equal zero gives gradient descent procedure exp log xi finds local minimum error function 
method iterates computing order approximations mean tangent space 
weighted mean computation similar 
replace inside expo mean tangent vectors weighted mean xi 
wi 
classification riemannian manifolds xi yi training set respect class labels xi yi riemannian manifold 
want find function divides manifold training set labeled items 
function divides manifold complicated notion compared euclidean space 
example consider simplest form linear classifier point direction vector defines line separates 
equivalently dimensional differentiable manifold consider point manifold tangent vector tangent space point defines curve manifold exponential map 
example consider image lines torus curves divide manifold 
straightforward approach classification map manifold higher dimensional euclidean space considered flattening manifold 
general case mapping globally preserves distances points manifold 
classifier trained flattened space reflect global structure points 

local maps boosting propose incremental approach training weak classifiers tangent space combining boosting 
start defining mappings neighborhoods manifold euclidean space similar coordinate charts 
maps logarithm maps log map neighborhood points tangent spaces tx 
mapping homeomorphism neighborhood point structure manifold preserved locally 
tangent space vector space learn classifiers space 
classifiers trained tangent space point manifold 
mean points minimizes sum squared distances manifold approximation order 
iteration compute weighted mean points weights adjusted boosting 
map points tangent space mean learn weak classifier vector space 
weights samples misclassified earlier stages boosting increase weighted mean moves points producing accurate classifiers points 
approach minimizes approximation error averaging weak classifiers 
input training set xi yi xi yi start weights wi xi repeat compute response values weights zi wi xi xi 
compute weighted mean points arg miny wid xi 
map data points tangent space xi vec log xi 
fit function gl weighted square regression zi xi weights wi 
update fl fl de fined ef output classifier sign sign fl 
logitboost riemannian manifolds 

logitboost riemannian manifolds start brief description logitboost algorithm vector spaces 
consider binary classification problem yi 
probability class represented ef fl 
logitboost algorithm learns set regression functions fl weak learners minimizing negative binomial log likelihood data xi yi log xi newton iterations 
core algorithm logitboost fits weighted square regression fl training points xi response values zi weights wi 
logitboost algorithm riemannian manifolds similar original logitboost differences level weak learners 
case domain weak learners fl discussion previous section learn regression functions tangent space weighted mean points manifold 
define weak learners fl gl vec log learn functions gl weighted mean points notice mapping vec gives orthogonal coordinates tangent vectors 
algorithm 
steps marked differences original logitboost algorithm 
functions gl possible form weighted squares regression linear functions regression stumps domain functions 
human detection human detection combine logitboost classifiers sym rejection cascade shown 
weak classifiers gl linear regression tan functions learned tangent space sym gent space dimensional vector space 
npi number positive negative images training set 
detection window sampled negative image negative sample possible generate negative examples number negative images 
assume training kth cascade level 
classify possible detection windows negative training images cascade previous logitboost classifiers 
samples misclassified form possible negative set samples classified positive 
cardinality possible negative set large sample nn examples set negative examples cascade level cascade level consider positive training images positive training set 
single human positive images np npi 
large number covariance descriptors computed single detection window computationally intractable test 
boosting iteration kth logitboost level sample subwindows possible subwindows construct normalized covariance descriptors described section 
learn weak classifiers representing subwindow add best classifier minimizes negative binomial log likelihood cascade level level cascade detector optimized correctly detect positive examples rejecting negative examples 
addition enforce margin constraint positive samples decision boundary 
pk probability sample positive cascade level evaluated 
xp positive example np th largest probability positive examples 
xn negative example nn th smallest probability negative examples 
continue add weak classifiers cascade level pk xp pk xn set 

cascade logitboost classifiers 
kth logitboost classifier selects normalized covariance descriptors subwindows rk constraint satisfied new sample classified positive cascade level pk pk xp pk xn equivalently fk fk xn 
proposed method positive training samples top percentile probability decision boundary 
process continues training th cascade level method slight modification logitboost classifier riemannian manifolds described section 
compute weighted means positive examples negative set characterized detection tasks 
rarely happens features totally correlated singularities covariance descriptor 
ignore cases adding small identity matrix covariance 

experiments perform experiments inria human database 
database contains human annotations reflections person free images 
detection inria human database challenging includes subjects wide range variations pose clothing illumination background partial occlusions 
perform separation training testing sets directly compare results methods dalal triggs zhu 
knowledge methods produce best results published database detailed comparison previous methods 
experiment compare results 
noted kernel svm computationally expensive consider linear kernel svm method 
method trains boosted classifier hog features different results reported normalization 
consider best performing result norm 
plot detection error tradeoff curves log log scale 
axis corresponds rate os xaxis corresponds false positives window 
comparison methods dalal triggs zhu 
curves approaches generated respective papers 
see text details 
os os 
curve method generated adding cascade level time 
example case rightmost marker corresponds detection levels cascade marker positioned corresponds cascade levels 
markers extremes correspond cascade levels 
generate result leftmost marker shifted decision boundaries cascade levels produce false positives cost higher rates 
place decision boundary pk pk xn pk xp margin reduced half 
see section details 
see false positive rates rates significantly lower approaches 
closest result method kernel svm classifier requires kernel evaluation dimensional space classify single detection window 
consider acceptable false positive rate window rate second best result 
method removes samples rejected previous levels cascade training levels small amount negative samples order remained 
levels training error generalize detection rates achieved test set 
seen dense markers believe better detection rates achieved low false positive rates negative images 
note method false positives come single textured image training set include similar image 
second experiment consider empirical val 
detection rates different approaches method 
see text details 
classification algorithm riemannian manifolds 
detection error tradeoff curves different approaches 
original method maps points tangent spaces weighted means 
mean computation step removed original algorithm points mapped tangent space identity matrix 
ignore geometry sym stack upper triangular part covariance matrix vector learning performed vector space 
replace covariance descriptors hog descriptors perform original logitboost classification 
original method outperforms approaches significantly 
second best result achieved mapping points tangent space identity matrix followed vector space approaches 
plot number weak classifiers cascade level accumulated rejection rate cascade levels 
classifiers early levels cascade level reject negative examples 
average method requires evaluation covariance descriptors negative detection window average hog evaluations required 
detection examples shown crowded scenes humans having variable illumination appearance pose partial occlusion 
search images different scales white regions show detection results 
filter detection results adaptive bandwidth mean shift filtering bandwidth window width height 
black dots show modes ellipses generated averaging detection window sizes converging mode 

number weak classifiers cascade level accumulated rejection rate cascade levels 
see text details 
training classifiers took days current state art pc reasonable time train cascade model 
novel image average method search detection windows second 
computationally expensive operation method eigenvalue decomposition compute logarithm matrix requires arithmetic operations 
compared previous approaches search time faster slower produces significantly lower detection rates 

new approach human detection problem utilizing covariance matrices object descriptors novel learning algorithm riemannian manifolds 
proposed learning algorithm specific sym train classifiers points lying connected riemannian manifold 
superior performance proposed approach shown inria human database previous methods significantly higher rates false positive rates window 
werman 
affine invariance revisited 
proc 
ieee conf 
computer vision pattern recognition new york ny volume pages 

differentiable manifolds riemannian geometry 
academic press 
comaniciu meer 
mean shift robust approach feature space analysis 
ieee trans 
pattern anal 
machine intell 
dalal triggs 
histograms oriented gradients human detection 
proc 
ieee conf 
computer vision pattern recognition san diego ca volume pages 
felzenszwalb huttenlocher 
pictorial structures object recognition 
intl 
computer vision 
moonen 
metric covariance matrices 
technical report dept geodesy stuttgart university 
friedman hastie tibshirani 
additive logistic regression statistical view boosting 
ann 
statist 
gavrila 
real time object detection smart vehicles 
proc 
ieee conf 
computer vision pattern recognition fort collins pages 
ioffe forsyth 
probabilistic methods finding people 
intl 
computer vision 

riemannian center mass smoothing 
commun 
pure appl 
math 
schiele 
pedestrian detection crowded scenes 
proc 
ieee conf 
computer vision pattern recognition san diego ca volume pages 
mikolajczyk schiele 
multiple object class detection generative model 
proc 
ieee conf 
computer vision pattern recognition new york ny volume pages 
mikolajczyk schmid zisserman 
human detection probabilistic assembly robust part detectors 
proc 
european conf 
computer vision prague czech republic volume pages 
mohan papageorgiou poggio 
example object detection images components 
ieee trans 
pattern anal 
machine intell 
pinz zisserman 
incremental learning object detectors visual shape alphabet 
proc 
ieee conf 
computer vision pattern recognition new york ny volume pages 
papageorgiou poggio 
trainable system object detection 
intl 
computer vision 
pennec ayache 
riemannian framework tensor computing 
intl 
computer vision 
meer 
covariance tracking model update lie algebra 
proc 
ieee conf 
computer vision pattern recognition new york ny volume pages 

detection examples 
white dots show detection results 
black dots modes generated mean shift smoothing ellipses average detection window sizes 
extremely false positives negatives 
ronfard schmid triggs 
learning parse pictures people 
proc 
european conf 
computer vision denmark volume pages 
meer 
nonlinear mean shift clustering analytic manifolds 
proc 
ieee conf 
computer vision pattern recognition new york ny volume pages 
meer 
region covariance fast descriptor detection classification 
proc 
european conf 
computer vision graz austria volume pages 
meer 
simultaneous multiple motion estimation mode finding lie groups 
proc 
th intl 
conf 
computer vision beijing china volume pages 
viola jones snow 
detecting pedestrians patterns motion appearance 
proc 
ieee conf 
computer vision pattern recognition new york ny volume pages 
zhu avidan yeh cheng 
fast human detection cascade histograms oriented gradients 
proc 
ieee conf 
computer vision pattern recognition new york ny volume pages 
