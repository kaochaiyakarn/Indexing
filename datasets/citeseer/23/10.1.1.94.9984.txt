clustering large data sets mixed numeric categorical values huang csiro mathematical information sciences gpo box canberra act australia huang csiro au efficient partitioning large data sets homogenous clusters fundamental problem data mining 
standard hierarchical clustering methods provide solution problem due computational inefficiency 
means methods promising efficiency processing large data sets 
limited numeric data 
prototypes algorithm means paradigm removes numeric data limitation whilst preserving efficiency 
algorithm objects clustered prototypes 
method developed dynamically update prototypes order maximise intra cluster similarity objects 
applied numeric data algorithm identical kmeans 
assist interpretation clusters decision tree induction algorithms create rules clusters 
rules statistics clusters assist data miners understand identify interesting clusters 
data mining applications require partitioning data homogeneous clusters interesting groups may discovered group motor insurance policy holders high average claim cost group clients banking database showing heavy investment real estate 
perform analyses problems solved efficient partitioning large data set homogeneous groups clusters effective interpretation clusters 
proposes solution problem suggests solution second 
number data partitioning methods employed problem 
little known distribution data clustering methods 
data mining distinct traditional applications cluster analysis deals large high dimensional data thousands millions records tens hundreds attributes 
characteristic prohibits existing clustering algorithms data mining applications 
characteristic data data mining contains numeric categorical values 
traditional way treat categorical attributes numeric produce meaningful results categorical domains ordered 
standard hierarchical clustering methods handle data numeric categorical values quadratic computational cost supported cooperative research centre advanced computational systems established australian government cooperative research centres program 
unacceptable clustering large data sets 
means methods efficient processing large data sets attractive data mining 
major handicap limited numeric data 
reason algorithms optimise cost function defined euclidean distance measure data points means clusters minimising cost function calculating means limits numeric data 
conceptual clustering algorithms developed machine learning cluster data categorical values produce conceptual descriptions clusters 
feature important data mining conceptual descriptions provide assistance interpreting clustering results 
statistical clustering methods algorithms search objects carry similar concepts 
efficiency relies search strategies 
problems data mining involve concepts large object spaces concepts search methods potential handicap algorithms deal extremely large data sets 
clustering algorithm solve data partition problems data mining 
algorithm means paradigm removes numeric data limitation whilst preserving efficiency 
algorithm clusters objects numeric categorical attributes way similar means 
objects clustered prototypes means clusters call prototypes algorithm 
developed method dynamically update prototypes order maximise intra cluster similarity objects 
object similarity measure derived numeric categorical attributes 
applied numeric data algorithm identical means 
testing real data algorithm demonstrated capability partitioning data sets range records described numeric categorical attributes clusters couple hours sun sparc workstation 
consider conceptual descriptions clusters 
dealing large data sets take different approach 
clustering carried fit classified data decision tree induction algorithm create rules cluster descriptions 
rules statistics clusters assist data miners understand identify interesting clusters 
rest organised follows 
section gives mathematical preliminaries algorithm 
section discuss algorithm 
section simulation results show numeric categorical attributes interact process clustering algorithm 
initial performance test results large real world data set 
section summarise discussions point directions 
mathematical preliminaries xn denote set objects xi xi xi xim object represented attribute values 
positive integer 
objective clustering find partition divides objects disjoint clusters 
number possible partitions definite extremely large impractical investigate partition order find better classification problem 
common solution choose clustering criterion guide search partition 
clustering criterion called cost function 
cost function widely cost function trace cluster dispersion matrix way define cost function il ql ql ql representative vector prototype cluster element partition matrix similarity measure defined square euclidean distance 
properties 
called hard partition fuzzy partition hard partition indicates object assigned cluster consider hard partitions 
inner term el eq 
total cost assigning il cluster total dispersion objects cluster prototype minimised lj il ij nl number objects cluster categorical attributes introduce similarity measure mc ij lj ij xij values numeric attributes xij values categorical attributes object prototype cluster mc numbers numeric categorical attributes 
weight categorical attributes cluster rewrite el il ij lj il ij lj lj total cost numeric attributes objects cluster el minimised calculated eq 

set containing unique values categorical attribute pc cj probability value occurring cluster el eq 
rewritten mc lj nl number objects cluster solution minimise el lemma 
lemma specific cluster el minimised pq lj cj pc cj categorical attributes 
rewrite eq 
cost function clustering data set numeric categorical values 
non negative minimisation achieved minimising total costs numeric categorical attributes clusters 
minimised calculating numeric elements cluster prototypes eq 
minimised selecting categorical elements cluster prototypes lemma 
eq 
lemma define way choose cluster prototypes minimise cost function eq 

basis prototypes algorithm discussed section 
similarity measure cost function eq 
defined eq 
combined similarity measure numeric categorical attributes objects cluster prototypes 
similarity measure numeric attributes square euclidean distance similarity measure categorical attributes number mismatches objects cluster prototypes 
weight introduced avoid favouring type attribute 
influence weight clustering illustrated 
assume triangles diamonds represent set objects described categorical numeric attributes 
triangle diamond represent values categorical attribute numeric attribute values reflected locations objects 
objects partitioned clusters 

influence clustering 
clustering depends numeric attributes locations objects 
result clusters separated vertical dashed line 
object may change right cluster close cluster categorical value majority objects cluster 
similarly object may change left cluster 
object may stay left cluster far right categorical value majority objects cluster 
similarly object may right cluster 
object uncertain depending biased numeric categorical attributes 
biased categorical attribute object may change right cluster 
stay left 
choice dependent distributions numeric attributes 
generally speaking related average standard deviation numeric attributes cluster practice guidance determine unknown clustering average standard deviation numeric attributes iterative algorithm calculated preceding clustering result 
section simulations prototypes algorithm prototypes algorithm described follows 
select initial prototypes data set cluster 
allocate object cluster prototype nearest eq 

update prototype cluster allocation 
objects allocated cluster retest similarity objects current prototypes 
object nearest prototype belongs cluster current reallocate object cluster update prototypes clusters 
repeat object changed clusters full cycle test algorithm built processes initial prototypes selection initial allocation re allocation 
process simply randomly selects objects initial prototypes clusters 
second process 
starting set initial cluster prototypes process assigns object cluster updates cluster prototype accordingly assignment 
represents object value attribute object prototypes prototypes store numeric categorical attribute parts cluster prototypes respectively 
prototypes prototypes corresponding numeric categorical elements prototype cluster distance square euclidean distance function sigma implementation function eq 

record cluster membership objects numbers objects clusters 
sums numeric values objects clusters update numeric attributes cluster prototypes 
records frequencies different values categorical attributes clusters 
function implementation lemma update categorical attributes prototypes 
reallocation process similar initial allocation process reallocation object prototypes previous current clusters object updated 
variable moves records number objects changed clusters process 
distance prototypes gamma sigma prototypes distance distance prototypes gamma sigma prototypes distance distance cluster endif endfor cluster cluster cluster prototypes cluster cluster cluster endfor cluster prototypes cluster cluster endfor endfor 
initial allocation process 
moves find cluster prototype nearest object cluster moves cluster cluster prototypes cluster cluster cluster prototypes endfor cluster prototypes cluster cluster prototypes endfor endif endfor 
reallocation process 
algorithm iterates reallocation process moves indicates algorithm stabilised local optimum eq 
shows typical convergence curve algorithm obtained data set records attributes 
number clusters 
number objects changing clusters iteration iterations 
convergence behaviour prototype algorithm 
see number objects changing clusters drops rapidly 
dropping speed gradually slows nearly unchanged stage 
goes little number changes zero 
indicates iteration reallocation process terminated point dropping speed small 
compromise reduce running time significantly large data sets 
computational cost algorithm kn number objects number clusters number iterations reallocation process 
usually exceed experiments large real world data set 
algorithm efficient clustering large data sets 
means algorithm algorithm produces local optimal solutions affected initial cluster prototypes 
avoid trapped local optimum introduce perturbations process 
guarantee global optimal solution 
number techniques solving global optimisation problem simulated annealing genetic algorithms experiments section simulation results clustering data mixed numeric categorical values prototypes algorithm 
briefly describe exercise clustering real world data set 
data set construction order simplify illustration data records having attributes numeric categorical 
records generated follows 
created sets dimensional points methods set contains points normal distribution second normal distributions contains points 
expanded points dimensions adding categorical value point see figures 
data set deliberately divided parts assigned majority points part identical categorical value rest categorical values 
instance majority points left high part assigned categorical value rest part assigned assignments randomly done 
similar assignments second point set 
note categorical value point indicate class membership 
fact points classification 
categorical values simply represent objects third dimension continuous order 
view dimension set planes overlaid distance planes 
plane identified unique categorical value 
points projected corresponding planes categorical values 
simulations main purpose simulations demonstrate numeric categorical attributes interact process clustering algorithm 
set cluster prototypes data set described section rule assigning object cluster third dimension point assigned cluster prototype cluster nearest point 
third dimension involved situations happen 

point assigned cluster prototype cluster nearest point dimensional numeric space prototype categorical value cluster point 

point may assigned cluster prototype nearest dimensional continuous subspace categorical value majority points cluster point 



point may assigned cluster categorical value prototype different distance point cluster prototype small 
second situation indicates categorical attribute strong impact clustering third situation shows strong impact numeric attributes 
implemented prototypes algorithm global clusters 
tested different values clustering data sets shown 
small indicates clustering process favours numeric attributes large means result biased categorical attribute 
shows results clustering data set different values 
data clustered completely numeric attributes equivalent clustering data 
known dimensional points normal distribution represents natural cluster 
clustering process divides inherent sense classification point view 
cluster cluster ii cluster iii cluster vi cluster cluster ii cluster iii cluster vi cluster cluster ii cluster iii cluster vi cluster cluster ii cluster iii cluster vi cluster cluster ii cluster iii cluster vi 

cluster cluster ii cluster iii cluster vi third categorical dimension involved inherent distribution longer valid dimensional space see 
contribution categorical dimension new clusters produced different 
comparison find new clusters represent regions dominated categorical value 
clustering points dependent numeric categorical values 
points spatially close categorical values clustered 
point categorical value close majority points having categorical value far away majority points having categorical value point clustered points categorical value majority 
case numeric values determine cluster point categorical value 
point having categorical value surrounded points having categorical value far away points categorical value clustered points categorical value case cluster membership determined categorical value spatial location 
numeric categorical attributes play equivalent role determining cluster memberships points 
result biased categorical attribute 
compared numeric attributes played little role clustering points 
shows results clustering data 
know data set spatially normal distributions 
produced small clearly recovers distributions clustering biased numeric attributes 
shows medium result 
clustering categorical attribute played significant role 
see number points spatially located cluster vi clustered cluster ii 
points cluster homogenous clustered numeric attributes 
evident produced large 
selection value guided average standard deviation numeric attributes 
average standard deviation data 
suitable balance similarity measure 
average standard deviation data 
suitable lies 
suitable lies data sets 
needs done understand behaviour 
clustering real data set algorithm tested real world data set consisting records numeric categorical attributes 
record represents motor insurance policy 
prototypes algorithm partition data set homogenous clusters order identify groups policy holders claims groups 
ran algorithm sun sparc workstation 
table gives time performance partitioning different numbers policies clusters 
table shows time performance partitioning policies different numbers clusters 
termination condition experiments policy changed clusters reallocation process 
iteration reallocation process terminated point number policies changing clusters reallocation process drops slowly see running time reduced significantly 
table records time sec 
table clusters time sec 
interpret clusters decision tree induction algorithm derive descriptions clusters 
example description cluster partition may look age policy holders sex male insured amount kinds descriptions statistics clusters number policies average claim cost assist data miners understand identify interesting policy groups 
summary prototypes algorithm cluster large real world data sets 
algorithm preserves efficiency means algorithm removes numeric data limitation 
demonstrated efficient clustering large data sets mixed numeric categorical values 
data sets occur data mining applications 
suggested decision tree induction algorithms obtain descriptions clusters 
descriptions assist interpretation clusters aid data miners understand identify interesting object groups represented clusters 
believe integration clustering decision tree induction algorithms useful tool knowledge discovery databases 
motivated problem dealing large mixed data sets common data mining applications 
size data set exceeds certain limit existing algorithms longer practical 
extremely large data sets data mining challenge existing algorithms effective small data sets 
plan test algorithm larger data sets pursue parallel implementation necessary 
initial opened research topics pursue global optimisation effective cluster interpretation tree structured clustering mixed data 
acknowledgments author wants peter milne drs glenn stone graham williams phil kirby valuable comments 

anderberg cluster analysis applications 
academic press new york 

bezdek means clustering norms 
ieee transactions systems man cybernetics pp 

olshen stone classification regression trees 
wadsworth 


buhmann hnel vector quantisation complexity costs 
ieee transactions information theory pp 


everitt cluster analysis 
heinemann educational books 


fisher knowledge acquisition incremental conceptual clustering 
machine learning pp 
goldberg genetic algorithms search optimisation machine learning 
addison wesley 

gower general coefficient similarity properties 
biometrics pp 

hand discrimination classification 
john wiley sons 

kirkpatrick gelatt vecchi optimisation simulated annealing 
science pp 

lebowitz experiments incremental concept formation 
machine learning pp 

macqueen methods classification analysis multivariate observations 
proceedings th berkeley symposium mathematical statistics probability pp 

michalski stepp automated construction classifications clustering versus numerical taxonomy 
ieee transactions pattern analysis machine intelligence pp 

miller rose non greedy approach tree structured clustering 
pattern recognition letters pp 


quinlan programs machine learning 
morgan kaufmann publishers 

rose gurewitz fox deterministic annealing approach clustering 
pattern recognition letters pp 

