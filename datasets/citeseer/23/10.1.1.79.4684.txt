inducing morphological lexicon natural language unannotated text mathias creutz krista lagus neural networks research centre helsinki university technology box fin espoo finland mathias creutz krista lagus hut fi presents algorithm unsupervised learning induction simple morphology natural language 
probabilistic maximum posteriori model utilized builds hierarchical representations set morphs morpheme units discovered unannotated text corpora 
induced morph lexicon stores parameters related meaning form morphs contains 
parameters affect role morphs words 
model implemented task unsupervised morpheme segmentation finnish english words 
results obtained finnish results obtained english task 

emergence large amounts textual data languages prospects designing algorithms capable acquiring language unsupervised manner data promising 
due large amounts data available increasing need minimally supervised natural language processing systems 
writing systems word boundaries explicitly marked word segmentation necessary step natural language processing task dealing written text 
languages employing writing systems comprise chinese japanese 
existing algorithms automatic word segmentation usually rely man lexicons sproat trained pre segmented text teahan 
number data driven algorithms supervision induce raw text plausible segmentation text words de marcken kit wilks brent yu ando lee peng schuurmans 
word boundaries marked writing system language words may consist lengthy sequences morphemes 
morphemes defined linguistic theory smallest meaning bearing units smallest elements syntax matthews 
morphemes conceivably useful artificial language production understanding applications speech recognition machine translation information retrieval 
automatic segmentation words morphemes morpheme units take place unsupervised data driven morphology inducing algorithms jean goldsmith creutz lagus creutz creutz lagus resemble algorithms word segmentation 
word morpheme segmentation algorithms drawn inspiration works harris word morpheme boundary suggested locations predictability letter letter sequence low jean ando lee 
investigate methods aimed accurate segmentation possible additionally learn representation language data 
typically representation induced data consists lexicon words morpheme units 
word morpheme segmentation text obtained choosing sequence words morphemes contained lexicon 
new model algorithm simple morphology induction previous creutz lagus creutz creutz lagus 
latest method previous versions referred family 
motivations new model discussed section mathematical formulation follows section 
section reports experiments carried unsupervised morpheme segmentation finnish english words section concludes 

representation lexical information models addressed formulated minimum description length mdl rissanen maximum posteriori map framework 
approaches essentially equivalent demonstrated chen 
aim find optimal balance accuracy representation model complexity generally improves generalization capacity inhibiting overlearning 
central question regarding morpheme segmentation compositionality meaning form 
meaning word transparent sense sum meaning parts word split parts morphemes english foot print joy ful ness play er 
uncommon form consist morphemes smallest elements syntax meaning entirely compositional english foot man male servant wearing uniform joy stick control device sky scrap er tall building 

composition perturbation de marcken proposes model unsupervised language acquisition involves central concepts composition perturbation 
composition means entry lexicon composed entries joystick composed joy stick 
perturbation means changes introduced give unique identity meaning joystick exactly result composition parts 
framework similar class hierarchy programming languages classes modify default behaviors inherited superclasses 
things de marcken applies model task unsupervised word segmentation text blanks removed 
result hierarchical segmentations obtained phrase purpose ur po 
problem practical point view way determining level segmentation corresponds best conventional word segmentation 
coarsest level phrase works independent word 
detailed level phrase shattered individual letters 

baseline morph segmentation called recursive mdl method creutz lagus follow creutz words corpus split segments called morphs 
call methods baseline algorithm 
baseline model described technical report creutz lagus software implementing publicly available baseline similar unsupervised word segmentation algorithms brent kit wilks yu 
baseline lexicon morphs constructed possible form word corpus concatenation morphs 
word corpus rewritten sequence morph pointers point entries lexicon 
aim find optimal lexicon segmentation set morphs concise gives concise representation corpus 
consequence kind approach frequent word forms remain unsplit rare word forms excessively split 
follows fact concise representation obtained frequent word stored lexicon english www cis hut fi projects morpho arvo lis sta value addition tax 
morpheme segmentation finnish word exclusive value added tax 
having soldiers states rarely occurring words better coded parts han ed ious vol 
proper notion compositionality model frequent strings usually kept rare strings split 
contrast model proposed de marcken lexicon flat hierarchical means possible inner structure morphs lost 

learning inflectional paradigms goldsmith assumes restrictive word structure algorithm linguistica splits words stem followed possibly empty suffix 
prefixes allowed 
sets stems suffixes grouped called signatures inflectional paradigms discovered training corpus 
linguistica principle handles stem suffix compositional structure better baseline method advantage modeling simple morphotactics word internal syntax 
instance linguistica suggest typical suffixes words mistake occasionally baseline ed ward urge 
unfortunately goldsmith model poorly suits highly compounding languages words consist possibly lengthy sequences morphemes alternation stems suffixes 
shows example finnish word 

morphotactics highly languages called categories model called categories ml model creutz lagus remedies shortcomings baseline goldsmith linguistica 
model maximum likelihood ml model functions segmentation produced baseline algorithm 
categories ml algorithm operates data consisting word types single occurrence picked distinct word form occurring corpus 
words represented hidden markov models hmm latent morph categories prefixes stems suffixes additional temporary noise category 
categories emit morphs word segments particular probabilities 
context sensitivity corresponding simple morphotactics due transition probabilities morph categories 
stems alternate prefixes suffixes impossible category sequences suffixes allowed prefixes words 
furthermore impossible move directly prefix suffix passing stem 
stm stm op non stm stm stm stm stm suf ja suf stm straightforward stm ness suf straight stm forward stm non ward stm 
hierarchical segmentations finnish word mp opposition english word obtained categories map model see section details 
additionally morph tagged category category morph context 
compositionality handled approximative manner morph lexicon consists morphs lexicon ed split forced restrictions redundant morph removed lexicon 
hand word shattered short fragments conditions considered noise 
noise morphs removed joining neighboring morphs hopefully creates proper morph han orphan 
categories ml algorithm performs formulation model somewhat ad hoc 
data fed algorithm consist corpus vocabulary word type collection duplicate word forms removed 
means information word frequency corpus lost 
wish draw parallels language processing humans undesirable property word frequency play important role human language processing 
baayen refer numerous psycholinguistic studies report high frequency words responded quickly accurately low frequency words various experimental tasks 
effect obtained regardless words compositional structure 

functionality elegance new model proposed called categories map draws inspiration de marcken 
hierarchical lexicon induced morph consist string letters recursively consist 
categories ml model words represented hmm morph categories prefix pre stem stm suffix suf non morpheme non 
morph function categories determined meaning corresponds features collected usage morph words 
model expressed maximum posteriori map framework likelihood category membership follows usage parameters prior probability distributions 
shows hierarchical representations obtained finnish word member parliament opposition english word 
categories map model information word frequency english word frequent corpus included lexicon entry 
finnish word frequent split opposition member parliament separate entries lexicon induced finnish corpus 
frequent words word segments accessed directly economical fast 
time inner structure words retained lexicon morphs represented concatenation sub morphs lexicon finnish word bracketed op ja english word straight ward ness 
morphs lexicon need sense represent meaning 
morphs correspond closely syllables short fragments words 
existence possible represent longer morphs economically finnish consists op position op tagged non morpheme stem 
helps oversegmentation rare words 
instance new name memorized constructed shorter familiar fragments breaking individual letters 
example english experiments name occurred twice corpus added morph lexicon stm ski non 
task morpheme segmentation described data structure useful 
de marcken means knowing level segmentation desired expand hierarchical representation finest resolution contain non morphemes 
level indicated bold face font 
finnish word expanded ja literally opposition people represent ative 
english word expanded straight forward ness 
morph forward expanded ward tagged non morpheme current context 

mathematical formulation model search algorithm aim finding optimal lexicon segmentation set morphs concise gives concise representation corpus 
maximum posteriori map estimate maximized arg max lexicon corpus lexicon arg max corpus lexicon lexicon 
lexicon search configuration yields highest probability involves steps explained briefly section 
calculation lexicon corpus lexicon described 

probability morph lexicon lexicon consists distinct morphs morph types 
probability coming particular set morphs making lexicon written lexicon 
meaning form probability morph divided separate parts meaning form 
terms discussed sections form meaning 
factor 
explained fact 
possible orderings set items lexicon regardless order morphs emerged 

probability segmented corpus order hidden markov model utilized order model simple morphotactics word internal syntax 
probability corpus particular lexicon morph segmentation takes form corpus lexicon nj cj cj jk cjk cj cjk product taken words corpus token count split nj morphs 
th morph th word jk assigned category cjk probability morph probability morph emitted category written jk cjk 
additionally transition probabilities cjk categories cjk denotes category assigned th morph word denotes category assigned th morph 
transition probabilities comprise transitions special word boundary category morph word cj cj transition morph word boundary nj 

form morph probability form morph depends morph represented string letters concatenation form length cij 
ci ci ci ci ci 
probability morph substructure morph consists 
estimated lexicon dividing number morphs having substructure total number morphs 
cij probability th letter th morph lexicon 
letter morph morph character terminates morph 
probability distribution letters alphabet estimated corpus lexicon 
equation resembles equation probability corpus 
ci probability morph substructure assigned category ci 
ci ci transition probability categories second 
ci ci probabilities conditioned categories ci ci 
transition morph probabilities probability corpus eq 


features related meaning morph common view meaning words morphs reflected directly 
parameters related usage morphs words collected 
parameters properties morph properties context typically appears 
typical usage morph stored lexicon form symbolic realization morph see equation 
set features defining meaning limited 
properties morph count frequency morph segmented corpus length letters morph 
distilled properties context morph occurs consider intra word right left perplexity 
consequence probability meaning morph meaning product prior probabilities frequency length right left perplexity 
note set possible features large typical set morphs occur context target morph stored 
typical syntactic relations morph morphs included 
size context vary small big revealing different aspects meaning morph fine grained syntactic categories broader semantic topical distinctions 

frequency frequent infrequent morphs generally different semantics 
frequent morphs function words affixes common concepts 
meaning frequent morphs ambiguous opposed rare morphs predominantly names persons locations phenomena 
morph emission probabilities jk cjk eq 
depend frequency morph training data 
probability lexicon affected prior frequency distribution morphs 

total number morph tokens corpus equals sum frequencies morph types lexicon 
equation derived combinatorics ways choosing positive integers sum probability particular frequency distribution frequencies summing note probability frequency morph lexicon equation computing separate probabilities morph frequency 

length length morph affects probability morph stem belong morph category 
stems carry semantic opposed syntactic information 
set stems large language stems short morphs need distinguishable 
creutz defines prior distribution morph length 
explicit prior length morph deduced representation form morph lexicon section 

left right perplexity left right perplexity give condensed image immediate context morph typically occurs 
perplexity serves measure predictability preceding morph 
grammatical affixes mainly carry syntactic information 
common general purpose morphs connection large number morphs 
assume morph prefix difficult predict morph going 
possible right contexts morph right perplexity high 
correspondingly morph suffix difficult predict preceding morph left perplexity high 
right perplexity target morph calculated right ppl right 
occurrences target morph corpus 
morph tokens occur right immediately occurrences 
probability distribution calculated left perplexity computed analogously 
reasonable probability distribution possible values right left perplexity rissanen universal prior positive numbers rissanen log log log log log log log 
sum includes positive iterates constant 

morph emission probabilities section describes properties related meaning morph translated emission probabilities jk cjk needed eq 

bayes formula applied jk cjk cjk jk jk cjk cjk jk jk cjk 
category independent probabilities jk maximum likelihood estimates computed frequency morph jk corpus divided total number morph tokens 
tendency morph assigned particular category cjk jk probability english morph ness functions suffix derived parameters related morph words 
graded threshold prefix likeness obtained applying sigmoid function right perplexity morph prefix jk exp right ppl jk 
parameter perplexity threshold indicates point morph jk prefix non prefix 
parameter governs steepness sigmoid 
equation suffix likeness identical left perplexity applied right perplexity 
stems assume stem likeness morph correlates positively length letters morph 
sigmoid function employed yields stem jk exp length jk 
length threshold governs steepness curve 
prefix suffix stem likeness assume values zero probabilities usually sum 
proper probability distribution obtained introducing category corresponds cases proper morph classes 
non morphemes typically short affixes right rissanen defines universal prior non negative numbers write left side equation 
lowest possible perplexity include zero possible value formula 
left perplexities low indicates occur sufficient number different contexts order qualify pre suffix 
probability segment non morpheme non non jk prefix jk suffix jk stem jk 
remaining probability mass distributed prefix stem suffix proportionally square prefix stem suffix likeness values 
morph consists category membership probabilities affected category tagging 
prevents conflicts syntactic role morph substructure 
tagged non morpheme dependencies apply considered mere sound patterns syntactic semantic function 
dependencies stems need consist sub stem pre stm stm stm stm suf 
suffixes consist suffixes 
morph consisting suffixes fair chance tagged suffix left perplexity high 
prefixes treated analogously suffixes 

search algorithm search probable categories map segmentation takes place greedy search algorithm 
attempt avoid local maxima probability function steps morphs alternated 
steps briefly described sections follow 

initialization segmentation 

splitting morphs 

joining morphs bottom strategy 

splitting morphs 

corpus viterbi algorithm re estimation probabilities convergence 

repetition steps 

expansion morph substructures finest resolution contain non morphemes 

initialization baseline algorithm producing initial segmentation words morphs 
morph categories point 
termination search segments obtained tagged category labels equations section 
point full categories map model formulated mathematically 
producing reasonably initial segmentation observed important apparently due greedy nature categories map search algorithm 
bad initial segmentation preliminary experiments result clearly poorer 

splitting morphs morphs sorted order increasing length 
possible substructure morph tested possible split morph 
probable split split chosen 
additionally different category morphs tested 
transition probabilities changes affect context morph occurs 
morph evaluated separately different contexts result different representations chosen different contexts 
morph categories plus additional word boundary category 
implies different combinations preceding category tags 
chosen cluster cases different contexts order increase expected number observations particular morph particular context 
clustering increases probability mass tested modifications increases probability search get stuck suboptimal local maxima 
contexts word initial word final word initial final word internal 
preceding word boundary prefix context word initial scheme succeeding word boundary suffix context word final 
morphs processed round morph splitting 
times splitting morphs interrupted 
corpus viterbi algorithm probabilities re estimated splitting continues 

joining morphs bottom morphs joined form longer morphs starting frequent morph bigrams proceeding order decreasing frequency 
probable alternative chosen keep morphs separate ii concatenate morphs new morph having substructure iii add higher level morph substructure consists 
additionally different category morphs tested 
morph bigram evaluated separately different contexts just splitting morphs 
times joining morphs interrupted 
corpus viterbi algorithm probabilities re estimated morph joining continues 

experiments categories map algorithm evaluated morpheme segmentation task finnish english data 
gold standard segmentations words obtained creutz lind contains linguistic morpheme segmentations finnish english word forms finnish data consist prose news texts finnish centre science csc finnish national news agency 
english data composed www cis hut fi projects morpho measure finnish linguistica categories ml categories map baseline corpus size words measure baseline english categories ml categories map linguistica corpus size words 
morpheme segmentation performance categories map algorithms finnish english test data 
data point average runs separate test sets exception words finnish words english test set 
cases lack test data constrained number runs 
standard deviations averages shown intervals data points 
data point linguistica largest finnish test set program unsuited large amounts data due considerable memory consumption 
prose news scientific texts gutenberg project brown corpus sample corpus 
evaluations carried data sets containing words finnish 
data set sizes english largest data set contained words 
parameter values equations set held development sets part final test sets 
evaluation metric measure harmonic mean precision recall combines values measure precision 
recall precision proportion correct boundaries morph boundaries suggested algorithm 
recall proportion correct boundaries discovered algorithm relation morpheme boundaries gold standard 
evaluation performed corpus vocabulary word types word form frequent rare equal weight evaluation 

results measure segmentations obtained finnish english test sets shown 
performance new categories map algorithm compared performance baseline categories ml algorithms goldsmith linguistica see section 
detailed com humanities uchicago edu faculty goldsmith linguistica december version parison older algorithms creutz lagus 
shows categories map performs morpheme segmentation finnish words rivals categories ml best performing algorithm 
data sizes words difference statistically significant test level 
english difference algorithms smaller finnish 
categories map places best performing categories ml baseline algorithm largest data set categories map falls slightly baseline 
english data difference statistically significant categories ml lowest scoring algorithm linguistica words baseline words 
english achieved measure level finnish advantage categories map compared simpler baseline method evident 
decrease measure observed algorithms largest english data set 
set contains foreign words may explain degradation performance careful examination finding needed 

computational requirements categories map algorithm implemented number perl scripts makefiles 
largest finnish data set took hours largest english set hours run amd opteron mhz processor 
memory consumption exceeded gb 
algorithms considerably faster linguistica memory consuming 
compare number distinct morph types segmentation data reflecting size morph lexicon induced 
algorithms compared baseline tends produce lexicon smallest number entries linguistica produces largest lexicons 
sizes morph inventories discovered category models differ morphs discovered largest finnish data set morphs largest english set 

demonstrated meaning form morpheme units modeled morphology induction task model morpheme segmentation word forms 
important feature new categories map model frequent complex entities representation inner structure entities represented examined desired level detail 
attempt model non concatenative phenomena sound changes occurring word stems 
far modeling meaning touched extended semantically richer contextual information obtained longer textual contexts multimodal data 
current model family assumes existence distinct albeit probabilistic categories 
order develop model family continuous latent representations draw inspiration conceptual spaces framework proposed rdenfors 

acknowledgments grateful graduate school language technology finland providing funding 
thankful persons sharing stimulating ideas especially lind anonymous reviewers helpful comments manuscript 
ando lee 

unsupervised statistical segmentation japanese applications 
proc 
th applied natural language processing conference st meeting north american chapter association computational linguistics anlp naacl pages 
baayen 

psycholinguistic computational model morphological parsing 
philosophical transactions royal society series mathematical physical engineering sciences pages 
brent 

efficient probabilistically sound algorithm segmentation word discovery 
machine learning 
chen 

building probabilistic models natural language 
phd thesis harvard university 
creutz 

unsupervised segmentation words prior distributions morph length frequency 
proc 
acl pages sapporo japan 
creutz lagus 

unsupervised discovery morphemes 
proc 
workshop morphological phonological learning acl pages philadelphia pennsylvania usa 
creutz lagus 

induction simple morphology highly languages 
proc 
th meeting acl special interest group computational phonology pages barcelona 
creutz lagus 

unsupervised morpheme segmentation morphology induction text corpora 
technical report publications computer information science helsinki university technology 
creutz lind 

morpheme segmentation gold standards finnish english 
technical report publications computer information science helsinki university technology 
de marcken 

unsupervised language acquisition 
phd thesis mit 
jean 

morphemes necessary concept structures discovery untagged corpora 
workshop paradigms grounding natural language learning pages adelaide 
rdenfors 

conceptual spaces 
mit press 
goldsmith 

unsupervised learning morphology natural language 
computational linguistics 
creutz 

lexicon creation turkish lvcsr 
proc 
eurospeech pages geneva switzerland 
kit wilks 

unsupervised learning word boundary description length gain 
proc 
conll acl workshop bergen 
matthews 

morphology 
cambridge textbooks linguistics nd edition 
peng schuurmans 

self supervised chinese word segmentation 
proc 
fourth international conference intelligent data analysis ida pages 
springer 
rissanen 

stochastic complexity statistical inquiry volume 
world scientific series computer science singapore 
ki creutz 

unlimited vocabulary speech recognition morphs discovered unsupervised manner 
proc 
eurospeech pages geneva switzerland 
sproat shih gale chang 

stochastic finite state word segmentation algorithm chinese 
computational linguistics 
teahan wen mcnab witten 

compression algorithm chinese word segmentation 
computational linguistics 
yu 

unsupervised word induction mdl criterion 
proc 
beijing 
