fair service mice presence elephants seth lee andreas show randomized caches resource poor partial state routers provide fair share bandwidth short lived flows known mice long lived flows known elephants 
keywords algorithms randomized algorithms caching probabilistic queues 
offering internet access apartments hotels commonplace 
networks users watching streaming video broadcasts consume available bandwidth time users browsing web experience unreasonably long delays 
case congestion router may forced drop packets 
observe experimental data long lived flows elephants receive larger share bandwidth short lived flows mice common queuing policies drop tail fair queuing random early detection stochastic fair queuing class queuing 
elephant flow phenomenon gained interest networking community see example 
inexpensive scalable solution monitor elephant flows router keeping information flows proposed kim reddy 
basic idea scheme sample packets insert certain probability flow identifiers cache keep count number packets flow flows cache purge packets elephant flows cache queue necessary 
propose variation scheme step achieves goal 
give thorough analysis prove randomized caching scheme able identify elephant flows high probability 
department computer science university denver st denver department computer science texas university college station tx contact author mail cs tamu edu version june algorithm propose queuing mechanism router uses randomized cache eviction strategy congestion control 
incoming packet enqueued queue pending packets flow identifier id calculated header information packet 
flow identifier id inserted probability cache queue router exceeds allowable number packets due network congestion packets packet identifier id deleted queue pseudocode queuing algorithm shown algorithm 
algorithm probabilistic queuing 
allowable cache insertion probability allowable specifies maximum length queue initialization pending empty list empty queue request item arrives pending pending pending allowable congestion need dequeue requests empty choose differing ids requests put ids forall id dequeue id pending pending number dequeued requests enqueue id operation enqueue inserts packet tail operation dequeue id removes packet flow identifier id statement calls randomized version lru cache corresponding pseudocode shown algorithm 
algorithm randomized cache 
id random put true id inserted probability id exists move id top id exist contains elements full evict bottom element delete create new element id put top insert id flow identifier id id incoming packet placed cache probability random put realizes coin flip returns true probability 
cache contain identifier id operation insert id inserts id top cache moves id top contains elements full new item going inserted item bottom th element evicted operation delete 
randomized cache determines items deleted queue case congestion 
flow flow identifier id contains packets probability id cache point time processes sending requests inserted cache 
show cache small compared length queue pending packets allowable flow packets elephant reside cache mouse flow packets 
queuing scheme router fewer users get penalized case congestion ones bandwidth 

obvious variation scheme store flow identifier counter 
initially inserts id flow identifier id inserted flow identifier moved top cache counter increased 
way deletes packets flows high counters packets purged queue alleviate congestion 
practice scheme differ significantly scheme theorem fact cache small 
analysis list realizes randomized cache update strategy 
purpose cache discriminate elephant mice flows 
assume flows submitting packets finite set containing elements 
assume requests flows independent identically distributed probability pr pr 
assumption matter convenience turns scheme shows behavior probability distributions focus uniformly distributed case easier analyze view space constraints 
cache fairly small actual system typically smaller length pending queue allowable 
long term behavior cache particular interest 
assume cache size flow identifiers inserted cache probability 
interested long term behavior may assume cache contains identifiers 
state cache described string letters alphabet contains repetitions 
set possible states cache denoted markov chain model behavior cache states set states cache 
selections flow identifiers cache 
possible orderings gives total 

different states markov chain 
admissible transitions markov chain reflect move front rule cache 
components contribute transition probabilities markov chain insertion probability probability pr flow issues request 
state 
ut cache remains unchanged message included cache request selected inclusion transition probability pr 
message selected included cache contained markov model transition current state 
ut ut state 
ut probability pr 
message flow selected top cache markov model transition current state 

ut state 

ut probability pr 
markov chain nonzero probability go state state steps irreducible 
nonzero probability stay state aperiodic 
follows exists limiting probability measure satisfies transition matrix markov chain matter state markov chain initially sequence states approach probability distribution 
theorem stationary distribution state space markov chain insertion probability state 
ut 
pr pr uk pr proof 
verify direct calculation probability measure satisfies sta condition 
transition rules markov chain find 
ut satisfies equation 
ut 
ut pr 
ut ut 
um um 
ut term right hand side models fact state remains unchanged arriving item flow included terms model possible states lead inclusion subtracting sides dividing yields 
ut pr 
ut 
um um 
ut 
ut clearly suffices check satisfies 
convenient denote di term substituting 
ut yields ut 
ut note sum depend follows similarly pr ut di pr 
pr uk dk pr ut pr uk pr dk pr ut pr 
product term right hand side ut pr uk 
ut dk pr 
um um 
ut pr uk di di pr substituting equations equation find pr uk di pr di di pr di dk pr di pr simplify expression pr uk di pr di di pr di di pr fact dt pr 
turns term brackets equal consequence polynomial identity xi xi xk easily proved expanding right hand side simplifying expression 
suppose pr pr pr un 
preceding theorem shows state limiting probability measure state 
ut 
notice markov chains reach limiting probability measure regardless insertion probability 
main difference process converge slowly limiting distribution small values 
denote pr ui probability find identifier flow ui position cache stationary distribution 
theorem gives precise analytic result probability theorem requests flows independent identically distributed probability pr ui find identifier flow ui position cache stationary state pr ui pr ui qz ui inclusion probability 
inner sum taken subsets set flows qz pr 
proof 
suppose cache stationary state 
history past requests selected inclusion cache uj uj uj 
request flow ui request jk ui position cache set xk 
uj cardinality 
simple observation determine probability flow ui position cache 
follows assumptions requests included cache independent identically distributed 
request occurs probability pr 
previous observation flow ui position cache ui random subset xk past requests contain ui xk 
allows express probability pr ui form pr ui pr ui ui xk xk events brackets disjoint different values state right hand side explicitly terms subsets cardinality universe flows pr ui pr ui ui pr xk pr ui ui pr xk 
inclusion exclusion principle yields pr xk pr xk 
words pr xk pr 
uj uj qz pr 
combining expression pr xk previous formula pr ui yields exchanging sums pr ui pr ui ui straightforward reformulation expression gives simplified concludes proof 
pr ui pr ui pr ui pr ui pr ui 
qz qz qz ui equation shows instance flow ui top cache probability pr ui pr ui 
flow packets highest chance top cache 
application particularly interested probability elephant flow ahead mouse flow cache 
theorem stationary distribution probability find flow ui ahead flow uj cache pr ui ahead uj regardless cache inclusion probability 
pr ui pr ui pr uj proof 
assume flows initially total order 
move front rule applied flow included cache introducing new order 
way flows represent state randomized lru cache new order ensures flow evicted cache ahead flows outside cache 
probability find flow ui ahead flow uj requests pr ui ahead uj requests pr ui pr uj pr ui pr uj pr ui term right hand side describes case ui initially ahead uj included cache requests second term represents case ui included cache time uj included time straightforward proof induction shows limit get pr ui ahead uj requests pr ui pr ui pr uj pr ui pr uj pr uj pr ui pr ui pr uj pr ui ahead uj pr ui pr ui pr uj proves claim assumed ui uj cache 
elephant flow ue sends times requests mouse flow um probability pr ue ahead um pr um ahead ue 
shows elephant flows near top cache mouse flows evicted cache outside cache 

exists extensive literature move front rule sorting corresponds case general deterministic lru caches studied 
goal papers usually estimate expected computational cost expected cache ratio learn valuable lessons classical works 
analyzed randomized caching algorithm markov chain model derived closed form stationary distribution 
computed closed form probability flow resides certain position cache 
furthermore calculated probability flow ahead flow cache 
results show elephant flows reside cache 
contrast compare incoming packet flow identifiers cache achieve result 
acknowledgments 
reddy introducing concept partial state router 
research supported university denver prof 
research supported part nsf ccr nsf career award ccf select young faculty award 

heuristics dynamically organize data structures 
siam comput 

model storage search 
appl 
prob 
coffman jr denning 
operating systems theory 
prentice hall englewood cliffs nj 
estan varghese 
new directions traffic measurement accounting focusing elephants ignoring mice 
acm trans 
comput 
syst 
hendricks 
stationary distribution interesting markov chain 
appl 
prob 
king iii 
analysis demand paging algorithms 
information processing ifip congress ljubljana yugoslavia pages 
north holland 
lawler coyle 
lectures contemporary probability 
student mathematical library ias park city mathematical subseries 
ams 
mccabe 
serial files relocatable records 
operations research 
rivest 
self organizing sequential search heuristics 
comm 
acm 
kim reddy 
identifying long term high bandwidth flows router 
proceedings th international conference high performance computing pages london uk 
springer verlag 

