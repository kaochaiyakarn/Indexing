combining association measures collocation extraction pavel pavel schlesinger institute formal applied linguistics charles university prague czech republic schlesinger mff cz introduce possibility combining lexical association measures empirical results methods employed automatic collocation extraction 
comprehensive summary overview association measures performance manually annotated data evaluated precision recall graphs mean average precision 
second describe classification methods combining association measures followed evaluation comparison individual measures 
propose feature selection algorithm significantly reducing number combined measures small performance degradation 
lexical association measures mathematical formulas determining strength association words occurrences cooccurrences text corpus 
wide spectrum applications field natural language processing computational linguistics automatic collocation extraction manning sch tze bilingual word alignment mihalcea pedersen dependency parsing 
number various association measures introduced decades 
overview widely techniques manning sch tze pearce 
researchers attempted compare existing methods suggest different evaluation schemes kita 
comprehensive study statistical aspects word cooccurrences 
novel approach automatic collocation extraction combining multiple lexical association measures 
address issue evaluation association measures precision recall graphs mean av erage precision scores 
propose stepwise feature selection algorithm reduces number combined measures needed respect performance held data 
term collocation linguistic lexicographic character 
various definitions widely accepted 
adopt definition choueka defines collocational expression syntactic semantic unit exact unambiguous meaning connotation derived directly meaning connotation components 
notion collocation relatively wide covers broad range lexical phenomena idioms phrasal verbs light verb compounds technological expressions proper names stock phrases 
motivation originates machine translation want capture phenomena may require special treatment translation 
experiments performed czech data attention restricted word bigram collocations primarily limited scalability methods higher order grams reason experiments longer word expressions require processing larger corpus obtain evidence observed events 
data step create data set 
suggests collocation extraction methods evaluated set collocations manually extracted full candidate data corpus 
avoid experiments biased underlying data preprocessing part speech tagging lemmatization parsing extracted data morphologically syntactically annotated prague dependency treebank containing words annotated analytical layer pdt 
corpus size certainly sufficient real world applications adequate evaluation purposes larger corpus manual collocation extraction task infeasible 
proceedings coling acl main conference poster sessions pages sydney july 
association computational linguistics dependency trees corpus broken dependency bigrams consisting lemmas head word modifier part speech pattern dependency type 
sentences containing words obtained total different dependency bigrams types 
occur data times 
frequent bigrams meet requirement sufficient evidence observations needed methods assume normal distribution observations unreliable dealing rare events included evaluation 
agree moore arguing cases comprise majority data zipfian phenomenon excluded real world applications 
filtered bigrams having part speech patterns form collocation conjunction preposition preposition pronoun obtained list consisting dependency bigrams called collocation candidates 
manual annotation list collocation candidates manually processed trained linguists parallel independently aim identifying collocations defined choueka 
simplify clarify instructed select bigrams assigned categories idiomatic expressions cold war vis question mark hanging open question technical terms vl dy prime minister sv dek eye witness support verb constructions right init decision names persons locations entities pra sk prague castle red cross stock phrases probl major problem year expected observation agreement categories poor cohen annotators ranged demonstrates notion collocation subjective domain specific somewhat vague 
reason annotators get precise objective idea considered collocation combining outcomes multiple annotators 
bigrams annotators independently recognized collocations type considered true collocations 
data set contains bigrams 
categories 
data split stratified samples 
folds fold cross validation average performance estimation 
remaining fold put aside held data experiments described section 
association measures context collocation extraction lexical association measures formulas determining degree association collocation components 
compute association score collocation candidate extracted corpus 
scores indicate potential candidate collocation 
ranking candidates high scores top classification setting threshold discarding bigrams threshold 
words occur chance may evidence special function simply explained result combination manning sch tze 
property known linguistics non compositionality 
think corpus randomly generated sequence words viewed sequence word pairs dependency bigrams case 
occurrence frequencies marginal frequencies association measures reflect word cooccurrence accidental 
measures include estimation joint conditional bigram probabilities table mutual information derived measures statistical tests independence likelihood measures various heuristic association measures coefficients originating different research fields 
determining entropy immediate context word sequence words immediately preceding bigram association measures rank collocations assumption occur syntactic units information theoretically noisy environment 
comparing empirical contexts word sequence components open class words occurring name formula 
joint probability xy 
conditional probability 
reverse conditional prob 

pointwise mutual inform 

mutual dependency md 
log frequency biased md xy log xy log xy log log xy 
normalized expectation xy 
mutual expectation 
salience xy xy xy log 
pearson xy test fij fij ij 
fisher exact test 
test 
xy xy 
xy xy xy xy 
score xy xy xy xy 
poison significance measure xy xy log xy xy 
logn 
log likelihood ratio fij log fij ij 
squared log likelihood ratio ij ij association coefficients 
russel rao 
sokal 
rogers tanimoto 
hamann 
third sokal 
jaccard 

second sokal 
second 
fourth sokal 
odds ratio 


driver ad bc ad bc ad bc ad bc ad bc 
fifth sokal ad 
pearson 
ad bc ad ad 
braun max 
simpson min 
michael ad bc 
bc ab ac 

unigram max log ad bc 
cost log min max 
cost log min 
cost log log 
combined cost 
phi xy 
kappa xy 
measure max xy log log xy log xy log xy xy name formula 
gini index max 
confidence max 
laplace np xy np xy max np np 
conviction max xy 
shapiro xy 
factor max 
added value av max 
collective strength 
context measures xy xy xy av 
context entropy cxy logp cxy 
left context entropy cl xy logp cl xy 
right context entropy cr xy logp cr xy 
left context divergence logp cl xy logp cl xy 
right context divergence logp wp cr xy logp cr xy 
cross entropy wp cx log cy 
reverse cross entropy wp cy log cx 
intersection measure 
euclidean norm cx cy cx cy cx cy 
cosine norm cx cy cx cy 
norm cx cy 
confusion probability 
reverse confusion prob 
cw cw cw cw 
jensen shannon 
cx cx cy cy cx cy 
cosine pointwise mi mi mi mi mi 
kl divergence cx cx log cy 
reverse kl divergence cy log cy cx 
skew divergence cx cy cx 
reverse skew divergence cy cx cy 
phrase word cxy xy cxy xy 
word association cosine context similarity 
boolean vector space zi cz 
tf vector space cz cy xy xy cx xy xy cos cx cxy cos cy cxy xi cz zi cos cx cy xi yi 
tf idf vector space cz df df cx dice context similarity dice cx cxy dice cy cxy 
boolean vector space cz 
tf vector space cz contingency table contains observed frequencies marginal frequencies bigram xy stands word stands word total number bigrams 
table cells referred fij 
statistical tests independence contingency tables expected frequencies xy cz dice cx cy xi yi 
tf idf vector space cz df df cx table lexical association measures bigram collocation extraction 
denotes selected model reduction algorithm discussed section 
cw empirical context cxy empirical context xy xy left immediate context xy xy right immediate context xy precision precision curve averaged curve recall vertical averaging precision recall curves 
thin curves represent individual non averaged curves obtained pointwise mutual information data folds 
specified context window association measures rank collocations assumption semantically non compositional expressions typically occur semantic units different contexts components zhai 
measures information theory background measures adopted field information retrieval 
evaluation collocation extraction viewed classification categories 
setting threshold association measure binary classifier bigrams higher association scores fall class collocations rest class non collocations 
performance classifiers measured example accuracy fraction correct predictions 
proportion classes case far equal want distinguish classifier performance 
case authors suggest precision fraction positive predictions correct recall fraction positives correctly predicted 
higher scores better classification precision recall curves choosing classification threshold depends primarily intended application principled way finding inkpen hirst measure performance association measures precision recall scores entire interval possible threshold values 
manner individual association measures thoroughly compared dimensional precision recall curves visualizing quality ranking committing classification threshold 
closer curve stays top right better ranking procedure average precision pointwise mutual information pearson test score cosine context similarity boolean vector space unigram measure recall averaged precision recall curves selected association measures numbers brackets refer table 
precision recall curves sensitive data see 
order obtain estimate shapes cross validation averaging necessary cross validation folds scores instance combined single curve drawn 
averaging done ways vertical fixing recall averaging precision horizontal fixing precision averaging recall combined fixing threshold averaging precision recall fawcett 
vertical averaging illustrated worked reasonably case experiments 
mean average precision visual comparison precision recall curves evaluation tool research fields information retrieval 
serious weakness 
easily compare curves cross 
curve entire interval recall obviously better 
case judgment obvious 
significance tests curves problematic 
defined dimensional quality measures rank evaluated methods performance 
adopt measure information retrieval hull 
cross validation data fold define average precision ap expected value precision possible values recall assuming uniform distribution mean average precision map mean measure computed data fold 
significance testing case realized paired test appropriate nonparametric paired wilcoxon test 
due unreliable precision scores low recall fast changes high recall estimation ap limited narrower recall interval mean average precision mean average precision association measures descending order 
methods referred numbers table 
solid points correspond measures selected model reduction algorithm section 
visualization values significance tests difference method pair order graphs 
darker points correspond values greater indicate methods statistically indistinguishable performance measured paired wilcoxon test values average precision obtained independent data folds 
experiments results initial experiments implemented association measures table processed morphologically syntactically annotated sentences pdt computed scores association measures dependency bigram data 
association measure evaluation data folds computed precision recall scores drew averaged precision recall curve 
curves performing methods depicted 
association measure data fold estimated scores average precision narrower recall interval computed mean average precision ranked association measures map descending order result depicted 
applied paired wilcoxon test detected measures statistically indistinguishable performance visualized information 
baseline system ranking bigrams randomly operates average precision 
best performing method collocation extraction measured mean average precision cosine context similarity boolean vector space map followed association measures nearly identical performance 
include popular methods known perform reliably task pointwise mutual information pearson test score odds ratio squared log likelihood ratio 
interesting point note terms map context similarity measures 
slightly outperform measures simple oc frequencies 

thorough comparison recall curves observe significantly half recall interval vice versa second half 
case map sufficient metric comparison association measure performance 
worth pointing methods precision recall curves actual bigram rank order different 
existence non correlated terms ranking measures essential sections 
combining association measures collocation candidate described feature vector 
xi consisting association scores table assigned label indicates bigram considered collocation 
look ranker function determines strength lexical association components bigram character association measure 
allows compare association measures means precision recall curves mean average precision 
classification methods demonstrate employed ranking function ranker 
see ripley 
linear logistic regression additive model binary response represented generalized linear model glm form logistic regression logit 
method ap map nnet units nnet units nnet units svm linear lda svm quadratic nnet unit glm cosine similarity unigram table performance methods combining association measures average precision ap fixed recall values mean average precision map narrower recall interval relative improvement column values 
logit log canonical link function odds ratio conditional probability positive response vector estimation done maximum likelihood method solved iteratively reweighted squares algorithm 
ranker function case defined predicted value equivalently due monotonicity logit link function linear combination linear discriminant analysis basic idea fisher linear discriminant analysis lda find dimensional projection defined vector projected combination ratio variance variance maximized max bc projection directly ranker 
support vector machines technical reason change labels yi 
goal support vector machines svm estimate function find classifier sign solved convex optimization min regularization parameter 
hinge loss function yf active positive values bad predictions suitable ranking models ranker function 
setting regularization parameter crucial estimators classification ranking 
alternative inappropriate grid average precision neural network units support vector machine linear linear discriminant analysis neural network unit linear logistic regression cosine context similarity boolean vector space unigram measure recall precision recall curves selected methods combining association measures compared curves best measures employed individually data sets 
search hastie proposed effective algorithm fits entire svm regularization path gave option choose optimal value 
objective function total amount loss training data 
neural networks assuming common model neural networks nnet hidden layer aim find inner weights wjh outer weights whi whi ranges units hidden layer 
activation functions function fixed 
typically taken logistic function exp exp indicator function classification threshold 
ranking simply set parameters neural networks estimated backpropagation algorithm 
loss function squares maximum 
avoid problems convergence algorithm 
tuning parameter classifier number units hidden layer 
experiments results avoid association measures experiments common preprocessing technique multivariate standardization centered values association measure zero scaled unit variance 
precision recall curves methods obtained vertical averaging fold cross validation data earlier experiments 
mean average precision computed average precision values estimated recall interval cross validation step folds training fold testing 
methods performed comparison individual measures 
best result achieved neural network units hidden layer map relative improvement compared best individual measure 
complex models neural networks units hidden layer support vector machines higher order polynomial kernels highly overfitted training data folds better results achieved simpler models 
detailed results experiment table precision recall curves selected methods depicted 
model reduction combining association measures methods reasonable helps collocation extraction task 
combination models complex number predictors 
association measures similar analytically empirically predictors redundant 
measures models training harder excluded 
principal component analysis applied evaluation data showed total variance explained principal components explained 
gives idea able significantly reduce number variables models small degradation performance 
algorithm straightforward case hardly feasible approach exhaustive search space possible subsets association measures 
option heuristic step wise algorithm iteratively removing variable time stopping criterion met 
algorithms robust sensitive data generally recommended 
tried avoid problems initializing step wise algorithm clustering similar variables choosing predictor cluster representative variables contribution model 
remove highly predictors continue step wise procedure 
average precision nnet units predictors nnet units predictors nnet units predictors nnet units predictors cosine context similarity boolean vector space unigram measure recall precision recall curves nnet models model reduction process different number predictors compared curves best individual methods 
algorithm starts hierarchical clustering variables order group similar contribution model measured absolute value pearson correlation coefficient 
iterations variables grouped non empty clusters representative cluster selected predictor initial model 
selection individual predictor performance held data 
algorithm continues predictors initial model iteration removes predictor causing minimal degradation performance measured map held data 
algorithm stops difference significant statistically paired wilcoxon test practically set human 
experiments results performed model reduction experiment neural network units hidden layer best performing combination method 
similarity matrix hierarchical clustering computed held data parameter number initial predictors experimentally set 
iteration algorithm data folds previous experiments fitting models held fold measure performance models select variable removed 
new model cross validated data folds previous experiments 
precision recall curves intermediate models shown 
conclude able reduce nnet model predictors statistically significant difference performance 
corresponding association measures marked table highlighted 
include measures entire range individual mean average precision values 
discussion created manually annotated data set consisting czech dependency bigrams 
agreed collocation annotators 
implemented association measures employed collocation extraction evaluated data set averaged precision recall curves mean average precision fold cross validation 
best result achieved method measuring cosine context similarity boolean vector space mean average precision 
exploit fact different subgroups collocations different sensitivity certain association measures showed combining measures aids collocation extraction 
investigated methods significantly outperformed individual association measures 
best results achieved simple neural network units hidden layer 
mean average precision relative improvement respect best individual measure 
complex neural networks quadratic separator support vector machines led overtraining improve test data 
proposed stepwise feature selection algorithm reducing number predictors combination models tested neural network 
able reduce number variables significant degradation performance 
attempt select best universal method combining association measures elicit best association measures collocation extraction 
tasks depend heavily data language notion collocation 
demonstrated combining association measures meaningful improves recall extraction procedure full performance improvement achieved relatively small number measures combined 
preliminary results research published 
current new version prague treebank pdt data improved additional manual linguists 
acknowledgments supported ministry education czech republic projects msm lc 
advisor jan haji colleagues anonymous reviewers valuable comments 
choueka 

looking needles haystack locating interesting collocational expressions large textual databases 
proceedings riao 


methods qualitative evaluation lexical association measures 
proceedings th annual meeting acl toulouse france 


statistics word cooccurrences word pairs collocations 
ph thesis univ stuttgart 
fawcett 

roc graphs notes practical considerations data mining researchers 
technical report hpl 
hp laboratories palo alto ca 
hastie rosset tibshirani zhu 

entire regularization path support vector machine 
journal machine learning research 
hull 

statistical testing evaluation retrieval experiments 
proceedings th annual international acm sigir conference research development information retrieval new york ny 
inkpen hirst 

acquiring collocations lexical choice near synonyms 
siglex workshop unsupervised lexical acquisition th meeting acl philadelphia 
kita kato 

comparative study automatic extraction collocations corpora mutual information vs cost criteria 
journal natural language processing 


usual suspects data oriented models identification representation lexical collocations 
ph thesis saarland university 
manning sch tze 

foundations statistical natural language processing 
mit press cambridge massachusetts 
mihalcea pedersen 

evaluation exercise word alignment 
proceedings hlt naacl workshop building parallel texts data driven machine translation edmonton alberta 
moore 

log likelihood ratios significance rare events 
proceedings conference emnlp barcelona spain 
pearce 

comparative evaluation collocation extraction techniques 
third international conference language resources evaluation las palmas spain 


extensive empirical study collocation extraction methods 
proceedings acl student research workshop ann arbor usa 
nagata 

retrieving collocations occurrences word order constraints 
proc 
th meeting acl eacl madrid spain 
ripley 

modern applied statistics th ed 
springer verlag new york 
zhai 

exploiting context identify lexical atoms statistical view linguistic context 
international interdisciplinary conf 
modeling context 
pdt 

mff cz pdt 
