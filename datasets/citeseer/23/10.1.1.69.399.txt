active shape models gradient descent optimization description length tobias wolf williams hans peter div 
medical biological informatics german cancer research center heidelberg germany de div 
imaging science building oxford road university manchester pt uk 
active shape models popular method segmenting dimensional medical images 
obtain required landmark correspondences various automatic approaches proposed 
improved version minimizing description length mdl model 
initialize algorithm describe method distribute landmarks training shapes conformal parameterization function 
introduce novel procedure modify landmark positions locally disturbing established correspondences 
employ gradient descent optimization minimize mdl cost function speeding automatic model building orders magnitude compared original mdl approach 
necessary gradient information estimated singular value decomposition accurate technique calculate pca commonly eigendecomposition covariance matrix 
results synthetic real world datasets demonstrating procedure generates models significantly better quality fraction time needed previous approaches 
cootes active shape models asms popular tools automatic segmentation medical images 
main challenge approach point correspondence problem model construction phase training sample asm landmarks placed consistent manner 
manual labeling time consuming feasible solution models limited number landmarks highly impractical domain required number landmarks higher case increasingly difficult identify pinpoint corresponding points experts 
springer verlag berlin heidelberg 
published christensen sonka eds ipmi lncs pp 
www com content ql ge available electronic reprint personal 
automated methods find correspondences proposed 
brett taylor pairwise corresponder symmetric version icp algorithm 
training shapes decimated generate sparse polyhedral approximations merged binary tree propagate landmark positions 
shelton measures correspondence surfaces arbitrary dimensions cost function composed parts representing euclidean distance surface deformation prior information 
function minimized multi resolution approach matches highly decimated versions meshes iteratively refines results 
match decimated template mesh training shapes thin plate spline warping controlled small set manually placed anatomic landmarks 
resulting meshes relaxed fit training shapes markov random field regularization 
approach matching templates zhao employ adaptive focus deformable model match training shape need manually placed landmarks 
shape yielding best results process subsequently determine point correspondences enhanced bridge procedure outliers 
common characteristic methods base notion correspondence general geometric properties minimum euclidean distance low distortion surfaces 
different approach davies propose minimize cost function minimum description length resulting statistical shape model 
comparison approach shown superior correspondence methods 
optimization mdl criterion shapes complex implement computationally expensive 
optimized procedure minimizing description length easier implement efficient current method 
fundamentals active shape models popular kind asms uses point distribution models pdms represent dimensional training sample set landmarks 
sample landmark positions defined single vector storing coordinates landmark xi xi xi 
vectors training samples form columns landmark configuration matrix applying principal component analysis pca matrix delivers principal modes variation pm training data 
restricting model modes valid shapes approximated mean shape linear combination displacement vectors cootes eigenvector decomposition covariance matrix calculate pca method commonly employed purpose 
results achieved singular value decomposition svd numerically stable accurate covariance matrix ill conditioned 
theorem real matrix written product column orthogonal matrices size respectively diagonal matrix 
holds eigenvectors matrix aa corresponding eigenvalues 
calculating covariance matrix pca obtained svd matrix number samples matrix columns set addition increased accuracy matrices allow calculating gradient information eigenvalues optimization stage model building process 
correspondence minimizing description length prerequisite statistical shape models set landmark points located corresponding positions training shapes 
quantify correspondence mdl approach introduced davies defines cost function minimum description length generated model 
simplified version mdl proposed defined log cut cut lm lm cut cut formulation features free parameter cut represents expected noise training data 
shapes rescaled produce mean shape rms radius pca optimal value cut depends original average radius training shapes cut standard deviation noise training data 
coherence voxel quantization error uses experiments 
adopt value modify depending resolution images training shapes extracted 
mesh parameterization define initial set correspondences means manipulating efficiently need convenient parameter domain training shapes 
closed objects natural choice parameter domain arc length position contour choosing arbitrary starting point normalizing total arc length positions contour potential landmark positions described single parameter 
order minimize complexity parameterization shapes restrict discussion closed manifolds genus surfaces holes self intersections 
objects class topologically equivalent sphere comprise shapes encountered medical imaging liver kidneys lungs 
task find mapping assigns point surface mesh unique position unit sphere described parameters longitude latitude 
mapping arbitrary shape sphere inevitably introduces distortion 
number different approaches attempt minimize distortion typically preserving local angles facet areas trying minimize distortions 
overview topic 
initial parameterization davies uses diffusion mapping simplified version method described hler angle area preserving 
due optimization strategy sect 
focus lies preserving angles moving neighboring points parameterization sphere specific direction expect corresponding landmarks training shape move coherent direction 
behavior guaranteed conformal mapping functions transformations preserve local angles 
creating conformal mapping definition training sample asm represented triangulated mesh vertices edges vertex positions specified embedding function defined vertices second function specifies coordinates mapped unit sphere 
gu variational method create conformal parameterization 
initial gauss map represents normal vector gradient descent optimization minimize string energy mesh defined ku minimizing string energy edge weights ku set yields barycentric mapping vertex positioned center neighbors 
subsequently conformal mapping obtained edge weights depending opposing angles faces adjacent ku cot cot optimization process vertices constantly projected back sphere 
formal correctness approach proved 
mapping landmarks preceding sections parameterization defined spherical mesh topology training sample 
order obtain position arbitrary landmark spherical coordinates generally vertex find intersection ray origin parameterization mesh 
mapping landmarks computationally expensive part model building process intelligent search strategy ordering triangles likelihood ray intersection speeds algorithm considerably 
intersected triangle indices landmark cached case cache neighboring triangles priority searching ray intersection 
test triangle intersection method described conveniently produces barycentric coordinates intersection point 
coordinates respective triangle training mesh yield final landmark position 
optimizing landmark correspondences initial conformal parameterization training sample acquire necessary landmarks mapping set spherical coordinates shape 
optimize point correspondences mdl criterion possibilities available change individual maintain fixed set global landmarks modify individual landmark sets opted alternative advantage correspondence valid set points placed unit sphere 
possible alter number placement landmarks unit sphere stage optimization better adapt triangulation training shapes 
need worry correct ordering landmarks valid set unit sphere fixed ensuring mapping training shapes sufficient 
re parameterization modify individual parameterizations iterative optimization process need transformation function type 
davies symmetric theta transformations purpose employing wrapped cauchy kernel certain width amplitude landmarks near kernel position spread sphere landmarks regions surface compressed 
accumulating effects thousands kernels different positions arbitrary parameterizations created 
re parameterization method produces required effect inefficient means modifying surface parameterizations 
main disadvantage global modification adding new kernel modifies landmark positions object 
intuitively desirable keep established landmark correspondences stable 
suggest new method modifying parameterization functions kernels strictly local effects 
assume know principal direction vertices local neighborhood parameterization mesh move improve landmark correspondences 
define gaussian envelope function change spherical coordinate variable denotes euclidean distance center kernel specific vertex parameterization mesh specifies size kernel 
movements cut limit range keep modification local 
course optimization decreased optimize larger regions details 
examples possible kernel configurations different values shown fig 

fig 

kernel configurations values 
red colors mark regions large vertex movements blue ones modification 
proposed method modification kernel includes poles spherical parameterization mesh vertices move away point depending 
positions different kernels change course optimization order guarantee equal treatment vertices parameterization mesh 
limitation overcome defining specific kernel configurations shown fig 
cover pole sections sphere 
keeping configurations fixed rotating parameterizations global landmark collection random rotation matrix relative kernel positions changed touching pole 
random rotation matrices operations acquired method described 
calculating mdl gradients kernel certain position need direction movement minimizes cost function 
modifications parameterization change landmark positions training sample step quantify effect landmark movements mdl value 
shown estimating jacobian svd purpose calculating gradients mdl objective function respect individual landmarks 
calculation singular value derivatives add significant computational overhead 
centered un biased landmark configuration matrix sect 
derivative th singular value dm calculated dm uim aij scalars uim elements matrices 
mdl cost function uses derive mdl gradients lm lm dm cut aij aij aij cut cut derivation yields gradient landmark revealing influence movements cost function 
examples resulting gradient fields visualized fig 

putting final step transform calculated gradient fields optimal kernel movements parameterization mesh 
chain rule get aij aij finite differences estimate surface gradients aij davies describe cases mdl optimization lead landmarks certain regions collapsing point 
davies keeps shape master example fixed landmarks prevent effect suggests adding stabilizing term cost fig 

gradients mdl cost function visualized sample shapes 
value directional derivative color coded ranging blue weak gradients red strongest gradients 
function 
observed problematic behavior new re parameterization employ methods 
addition modifying mapping functions re parameterization variables influence landmark positions included optimization 
rotation mapping determines position landmark training shape relative orientation 
calculating gradients rotating parameterization mesh euclidean axes surface gradients aij efficient method optimize variable 
possibilities optimization include scale rotation individual training shapes normally determined generalized procrustes matching 
optimize scale procedure notice significant improvements resulting mdl values due step 
results datasets tested method synthetic real life datasets 
synthetic data advantage global minimum mdl function known calculated correspondences inherent generated data 
tabular description employed datasets tab 

performance measures davies describes measures quantify quality created shape model generalization ability specificity compactness 
mea table 
collection datasets evaluation 
cuboids ellipsoids lungs origin synthetic synthetic clinical clinical mean size radius voxels number samples perceived sample variance low medium medium high sample complexity vertices model complexity landmarks sures comparison different correspondence methods 
generalization ability quantifies capability model represent new shapes 
estimated performing series leave tests training set measuring distance omitted training shape closest match reduced model 
specificity describes validity shapes model produces 
value estimated generating random parameter values normal distribution zero mean respective standard deviation pca 
distance generated shape closest match training set averaged number runs 
compactness simply measures accumulative variance model 
measures defined functions number modes parameters model displayed piecewise linear graphs 
smaller values indicate better models 
generalization ability specificity established qualities inherent model compactness implementation specific measure mdl approach assumes low variances result asm imminent truth 
restrict evaluation measures 
comparison current standard datasets described sect 
active shape models generated gradient descent technique gd proposed current standard approach std davies 
gd algorithm implemented run ghz intel pentium windows xp mb memory 
code hyper threading architecture optimize samples concurrently 
std experiments performed original matlab code ghz intel xenon linux gb memory 
optimization global landmark sets gd optimized models adjusted match landmark distributions std models 
evaluation models rescaled dimensions average training sample 
results experiments summarized tab 

gd optimization list additional intermediate values point mdl values surpasses results std method 
gd optimization reaches mdl values converged times faster produces distinctly better final results 
gen ability specificity values datasets displayed fig 

accordance mdl values models optimized gd method exhibit significantly better generalization ability specificity values 
table 
resulting mdl values different stages optimization gradient descent gd standard std method datasets 
times hours minutes 
cuboids ellipsoids lungs optimization time mdl time mdl time mdl time mdl initial values std converged gd intermediate gd converged demonstrated preceding section gradient descent optimization produces significantly better models current standard approach time orders magnitude faster 
highly detailed models containing landmarks successfully optimized hours normal desktop pc 
significant performance gain opens new possibilities building larger detailed asms 
excluding platform difference major part improvements attributed novel method local parameter modification controlled estimated gradients mdl cost function 
lower mdl values optimization indicate method sensitive convergence local minima original approach 
offers efficient robust versatile approach automatic model building propagate asms clinical practice 
represent complex shapes brain ventricles mesh surface cut parameterized multiple domains single sphere 
research investigate far established correspondences reorganize landmarks optimization order represent geometry model optimally minimum number points 
additionally stability re parameterization method landmark collapse verified larger number test datasets 
reported partially funded german research foundation sfb information technology medicine 
special davies inspiring discussions mdl optimization 
original lung data kindly provided christian meshes created max sch 
ct liver data segmentations supplied matthias thorn jan oliver neumann 
mean error mean error mean error mean error cuboid generalization ability initial values standard optimization gradient descent optimization modes ellipsoid generalization ability initial values standard optimization gradient descent optimization modes modes lung generalization ability initial values standard optimization gradient descent optimization liver generalization ability initial values standard optimization gradient descent optimization modes mean error mean error mean error mean error cuboid specificity initial values standard optimization gradient descent optimization modes ellipsoid specificity initial values standard optimization gradient descent optimization modes lung specificity initial values standard optimization gradient descent optimization modes liver specificity initial values standard optimization gradient descent optimization modes fig 

graphs generalization ability specificity different numbers modes datasets 
addition results standard optimization gradient descent method initial values optimization displayed orientation 

cootes taylor cooper graham active shape models training application 
computer vision image understanding 
brett taylor method automated landmark generation automated pdm construction 
image vision computing 
shelton morphable surface models 
int 
journal computer vision 
shape modelling markov random field restoration point correspondences 
proc 
ipmi 

zhao novel framework automated pdm construction deformable models 
proc 
spie medical imaging 
volume 

davies cootes taylor statistical shape models direct optimisation description length 
proc 
european conference computer vision part iii springer 
rajamani sz taylor davies evaluation correspondence methods model building 
proc 
ipmi 

kalman valuable decomposition svd matrix 
college math journal 
davies cootes taylor minimum description length approach statistical shape modelling 
ieee trans 
medical imaging 
minimum description length shape appearance models 
proc 
ipmi 

floater hormann surface parameterization tutorial survey 
floater sabin eds advances multiresolution geometric modelling 
mathematics visualization 
springer berlin heidelberg 
hler gerig parametrization closed surfaces shape description 
computer vision image understanding 
gu wang chan thompson yau genus zero surface conformal mapping application brain surface mapping 
proc 
ipmi 

gotsman gu sheffer fundamentals spherical parameterization meshes 
acm trans 
graph 

ller fast minimum storage ray triangle intersection 
journal graphics tools 
arvo fast random rotation matrices 
kirk ed graphics gems iii 
academic press 
ericsson astr minimizing description length steepest descent 
proc 
british machine vision conference 

estimating jacobian singular value decomposition theory applications 
proc 
european conference computer vision springer 
davies learning shape optimal models analysing shape variability 
phd thesis university manchester manchester uk 
