machine learning journal fl kluwer academic publishers boston 
manufactured netherlands 
unsupervised learning multiple motifs biopolymers expectation maximization timothy bailey cs ucsd edu charles elkan elkan cs ucsd edu department computer science engineering university california san diego la jolla california editor lawrence hunter 
meme algorithm extends expectation maximization em algorithm identifying motifs sequences 
aim meme discover new motifs set biopolymer sequences little known advance motifs may 
meme innovations expand range problems solved em increase chance finding solutions 
subsequences occur biopolymer sequences starting points em algorithm increase probability finding globally optimal motifs 
second assumption sequence contains exactly occurrence shared motif removed 
allows multiple appearances motif occur sequence permits algorithm ignore sequences appearance shared motif increasing resistance noisy data 
third method probabilistically erasing shared motifs incorporated distinct motifs set sequences different motifs appear different sequences single sequence may contain multiple motifs 
experiments show meme discover crp lexa binding sites set sequences contain sites meme discover gamma gamma promoter regions set coli sequences 
keywords unsupervised learning expectation maximization consensus sequence motif biopolymer promoter binding site dna protein sequence analysis 
problem addressed identifying characterizing shared motifs set unaligned genetic protein sequences 
motif defined pattern common set nucleic amino acid subsequences share biological property interest dna binding sites regulatory protein 
computer science terminology problem set strings find set non overlapping approximately matching substrings 
report concerned contiguous motifs 
biological terms means appearances motif may differ point mutations insertions deletions allowed 
computer science terms means approximately matching substrings length 
simpler version problem dataset biopolymer sequences believed contain single shared motif locate starting position sequence appearance shared motif describe shared motif 
report addresses general problem finding describing multiple distinct shared motifs set biopolymer timothy bailey charles elkan sequences 
assumed known advance width position letter frequencies motifs common motifs may exist set sequences 
methods literature problems related discovering multiple distinct shared motifs set biological sequences 
purpose research extend range problems attacked 
hertz greedy algorithm discovering single shared motif set sequences 
lawrence reilly extended developing expectation maximization em algorithm solving problem 
lawrence solve related problem discovering multiple distinct motifs number occurrences motif sequence known gibbs sampling strategy 
report describes meme new tool intended help discover motifs number motifs number occurrences motif sequence known 
meme incorporates novel ideas discovering motifs 
ffl subsequences occur input dna protein sequences starting points em converges iteratively locally optimal motifs 
increases likelihood finding globally optimal motifs 
ffl second heuristic modification em algorithm allows assumption sequence contains exactly occurrence shared motif removed 
allows multiple appearances motif occur sequence permits algorithm ignore sequences appearance shared motif increases resistance noisy data 
ffl third motifs probabilistically erased 
allows distinct motifs set sequences different motifs appear different sequences single sequence may contain multiple motifs 

searching tools versus learning tools section explains place meme spectrum sequence analysis tools 
experts biological sequence analysis may wish skip directly section 
searching tools 
sequence analysis tools may divided broad categories searching tools learning tools 
grail fasta searching tools meme learning tool 
searching tool called patternmatching tool takes input sequences pattern decides pattern matches input sequence 
pattern may sequence fasta ii consensus subsequence regular expression defining motif iii high level combination features grail 
unsupervised learning multiple motifs biopolymers em learning tools 
supervised learning tool called supervised tool takes input set sequences discovers pattern sequences share 
supervised learning done humans software open ended problem harder searching 
example prosite profiles created amos bairoch personally examining families proteins 
unsupervised learning tool takes input set sequences discovers pattern sequences share 
unsupervised learning harder supervised learning space possible patterns larger 
pattern discovered required input sequence unsupervised learning algorithm simultaneously look cluster input sequences pattern members cluster common 
meme performs unsupervised learning 
output learning tool pattern search tool order find new sequences exhibit pattern 
members family sequences known applying learning tool family useful examining patterns subsets family common give insight structure function evolution 

expectation maximization em algorithm lawrence reilly introduced expectation maximization method means solving supervised motif learning problem 
algorithm takes input set unaligned sequences motif length returns probabilistic model shared motif 
idea method sequence dataset contains single example motif 
shall refer model data occurrence sequence model just model 
assumed motif appears starting offset example unknown 
known subsequences length sequence starting known offset aligned insertions deletions allowed observed frequencies letters column alignment model motif 
fact example motif assumed generated sequence independent discrete random variables observed frequencies letters columns maximum likelihood estimates distributions random variables 
course original sequences dataset unaligned offsets known estimated 
em algorithm estimates probability shared motif starts position sequence dataset data initial guess description motif 
probability estimates ij reestimate probability letter column motif ae lc letter alphabet done described appendix 
em algorithm alternately ae ae changes little timothy bailey charles elkan iteration iteration 
notation refer matrix offset probabilities ij likewise ae refers matrix letter probabilities ae ij pseudo code description basic em algorithm 
em starts estimate model parameters ae provided user generated random 

em dataset 
choose starting point ae 

reestimate ae 
reestimate ae 
change ae ffl 
return 
em algorithm simultaneously discovers model motif sequence independent discrete random variables parameters ae estimates probability possible starting point examples motif sequences dataset 
definition likelihood model training data probability data model 
em algorithm finds values model parameters maximize expected likelihood data model ae missing data occurrence sequence model data lawrence reilly logarithm likelihood log likelihood lj log ae lj gamma log ae log gamma number sequences dataset length sequences length shared motif alphabet sequences ae lj unknown probability letter position motif ae unknown probability letter non motif positions lj observed frequency letter position motif observed non motif positions sequences 
shown expectation maximization algorithms find values model parameters likelihood function assumes local maximum 
reasonable assume correct solution problem characterizing shared motif occurs global maximum likelihood function 
reason equal parameter values model give higher values likelihood function considered better solutions problem 
unsupervised learning multiple motifs biopolymers em 
limitations em occurrence sequence model 
em model suffer limitations 
clear choose starting point initial value ae quit trying different starting points 
difficult satisfied correct shared motif 
second model assumes sequence dataset contains exactly appearance shared motif 
means sequences multiple appearances contribute sequences appearances contribute characterization motif 
having sequences appearances motif dataset may impossible em model find shared motif 
em model assumes shared motif sequences keep looking motifs characterizing 
em model incapable finding motifs insertions variable length incapable discovering multiple motifs may occur different sequences dataset 
eliminating reducing limitations em model method susceptible noise dataset able find complex patterns data useful exploring datasets may contain instances different motifs 
algorithm described report meme extends em algorithm overcome limitations described 
meme chooses starting points systematically subsequences sequences training dataset 
allows model different model eliminates assumption sequence occurrence allows sequence contain zero appearances shared motif 
call new model dataset model just model 
assumes dataset contains exactly occurrences motif specified user 
meme probabilistically erases appearances motif continues searching shared motifs dataset 
meme algorithm model tested datasets 
dataset combining coli sequences containing crp binding sites sequences containing lexa binding sites 
meme discovered lexa binding site pass crp binding site second pass 
second dataset contained coli promoter sequences 
meme discovered consensus sequences second passes respectively 
demonstrates ability meme avoid local optima tolerate large number sequences contain motif find multiple motifs single dataset 

meme algorithm meme algorithm core modified version em algorithm 
pseudo code algorithm 
inner loop algorithm timothy bailey charles elkan em algorithm run repeatedly different starting points chosen model model model 
shall refer particular application em algorithm simply em follows 
starting points derived actual subsequences occur input dataset 
em run iteration convergence starting point save time 
run em produces probabilistic model possible shared motif 
starting point yields model highest likelihood chosen em run convergence starting point 
model shared motif discovered printed 
appearances shared motif dataset erased 
outer loop repeats process discover shared motifs 
sections describe steps algorithm detail 

meme dataset nsites passes 
passes 
subsequence dataset 
run em iteration starting point 
derived subsequence 
choose model shared motif highest likelihood 
run em convergence starting point 
generated model 
print converged model shared motif 
erase appearances shared motif dataset 


output meme includes specificity log odds matrix spec 
logodds matrix rows columns calculated spec ij log ae ij ae information content score subsequence calculated summing entries matrix corresponding letters subsequence 
score gives measure likelihood subsequence instance motif versus instance background 
suitable threshold information content score classify subsequences new sequences part training set 

subsequences starting points em different starting points initial letter probability matrices ae em algorithm may converge different final models 
models local maxima likelihood function described earlier 
correct model shared motif expected model globally maximizes likelihood function em guaranteed find global maximum local maximum 
previous unsupervised learning multiple motifs biopolymers em authors recommended starting points em choosing model highest likelihood choose starting points discussed detail 
try randomly chosen letter frequency matrices starting points sequences dataset provide way choose intelligent ones 
models motifs allow insertions deletions optimal model agree contiguous subsequences sequences dataset instances motif sequences 
way search space possible starting points em convert subsequence length letter probability matrix matrix starting point 
approach meme 
starting point letter frequency matrices obtained subsequences corresponding actual occurrences shared motif close correct letter probability matrix model em tend converge global optimum run starting points 
example suppose unknown optimal value ae shared motif trying discover meme letter position motif consensus sequence 
presumably sequence close mutations occurs sequences dataset 
reasonable postulate choose starting point em letter probability matrix derived simple manner consensus sequence subsequence similar em tend converge optimal model 
try subsequences length example sequences dataset reasonable assume close cause em converge optimal model 
note meme possible subsequences length just ones occur dataset 
question remains convert subsequence letter probability matrix 
simply convert matrix probability letter subsequence convert letter position motif timothy bailey charles elkan em algorithm move starting point 
starting point offset probabilities estimated subsequences match starting point subsequence exactly 
cause reestimation letter frequencies yield starting point 
effective somewhat arbitrary solution fix frequency letter subsequence value fix frequencies letters gamma gamma length alphabet 
ensures frequencies column sum close starting point close subsequence 
results reported 
values worked approximately equally experimental data shown 
value starting point em generated subsequence letter position motif highly expensive computationally run em convergence possible starting point corresponding subsequence length input dataset 
turns necessary 
em converges quickly subsequences similar shared motif best starting point detected running iteration em 
described meme able find shared motifs run iteration possible subsequence starting point run convergence starting point highest likelihood 
words meme runs em specified number iterations iteration results reported subsequence starting point chooses starting point yields highest likelihood runs em convergence starting point 
iteration em algorithm takes computation time roughly linear size dataset number subsequences linear size dataset meme takes time size dataset characters 

dealing multiple appearances shared motif meme allows user specify model model 
model meme uses em algorithm lawrence reilly fit model dataset 
fit model heuristic modification em algorithm 
model assumes sequence dataset contains exactly appearance shared motif characterized 
assumption determines way offset probabilities reestimated 
reestimation procedure ensures offset probabilities sequence sum 
means unsupervised learning multiple motifs biopolymers em sequence appearance shared motif contribute reestimation letter frequencies sequence appearance 
additionally sequence appearances shared motif common event exploring new shared motifs contributes erroneously reestimation letter frequencies 
meme modifies em algorithm fitting model dataset 
normalizing reestimated offset probabilities sum sequence offset probabilities normalized sum user supplied value nsites subject constraint single offset probability may exceed 
normalization done sequences simultaneously sequence sequence 
intent nsites expected number appearances shared motif dataset 
nsites set equal number sequences dataset possible model get approximately results model dataset appearance shared motif sequence 
datasets appearances motif distributed sequence meme model able choose models assign offset probabilities fashion satisfies constraints mentioned 
relaxation motif appearance sequence constraint model allows meme benefit sequences multiple appearances shared motif 
help alleviate problem sequences contain motif blurring characterization 
nsites lower number sequences dataset meme assign low offset probabilities positions sequence contain motif 
contrast model assign offset probabilities summing sequence dataset 
effect various settings nsites discussed section 
summary exact value chosen nsites critical necessary know advance exactly times motif dataset 
side effect allowing single sequence offset probabilities sum long repeated sequences seen meme model multiple appearances shorter sequence 
example sequence aaaaaaaa treated model roughly appearances sequence 
model allow offsets sequence maximum probability 
model allow total offset probability single sequence sum problematic far surprising find non overlapping occurrences sequence find occurrence sequence aaaaaaaa 
meme search nsites non overlapping occurrences motif 
overcome difficulty meme enforces additional constraint calculating offset probabilities model 
offset probabilities adjacent offsets probabilities sum greater 
essentially model treat sequences aaaaaaaa way timothy bailey charles elkan model assigning probability offsets identical subsequences start 

finding shared motifs single dataset sequences contains distinct shared motif em model directly find 
motifs similarity em may converge conserved motif 
possibility em may converge model describes part conserved motif left right side instance 
meme algorithm solves problem probabilistically erasing shared motif em repeating em find shared motif 
effectively removing motif meme able find motif interference conserved motifs 
manner meme erases motif designed continuous possible 
new variables ij defined associate weight position sequence weights represent probability position sequence part motif previously discovered meme 
weights set initially 
meme discovers shared motif offset probability ij gives probability appearance motif starts position sequence assuming independence probability position sequence part newly discovered motif product gamma ij gamma old value ij updated multiplying probability potential motif overlaps example newly discovered shared motif 
ij letter frequencies 
summing offset probabilities ij weighted offset probabilities ij delta ij summed 
understand weighting scheme effectively erases previously discovered motifs suppose meme discovered motif looking second 
suppose position sequence start appearance motif 
new weights ij gamma gamma ij contribute reestimation ae effectively erased 
notice position matches discovered motif poorly ij low weight position remain fairly high 
degree position erased proportional certainty ij part previously discovered motif 
meme sensitive chance similarities match threshold set positions ij value threshold completely erased 

experimental results section describes experiments meme conducted datasets 
cases model meme model 
dataset unsupervised learning multiple motifs biopolymers em referred crp lexa dataset comprises dna fragments contain binding sites crp lexa regulatory proteins 
crp lexa dataset consists samples crp dataset plus samples lexa dataset described 
second dataset referred promoter dataset contains samples promoter regions 
described detail 
overview contents datasets table 
crp dataset taken stormo turn derived berg von hippel de 
contains dna fragments coli believed contain crp binding sites 
dataset contains crp binding sites verified protection experiments dataset compiled 
fragments contain putative crp binding sites determined sequence similarity known binding sites 
fragment dataset contains bases fragments aligned particular way 
lexa dataset taken table 
contains dna fragments believed contain lexa binding sites 
dataset contains lexa binding sites verified protection experiments dataset compiled 
additional putative lexa binding sites determined sequence similarity known binding sites dataset 
fragments contain bases preceding bases transcription start position gene 
fragments shorter bases flanking start position gene available 
samples lexa dataset overlaps sample crp dataset 
overlap includes known crp site 
promoter dataset taken stormo 
contains coli dna fragments believed contain promoter regions 
dataset originally compiled harley reynolds contained fragments stormo omitted number fragments highly redundant sequences known mutant promoters 
fragments roughly comprise positions gamma respect start transcription 
previous harley reynolds shown promoter motif consist highly conserved sub motifs width separated variable length spacer 
spacer usually bases long 
meme directly model variable length motif indirectly discovering highly conserved ends motifs 

meme discover different binding site motifs meme run passes crp lexa dataset nsites 
value chosen prior knowledge literature approximate size crp lexa binding sites dna base pairs 
value nsites chosen arbitrarily half number sequences dataset roughly sites type timothy bailey charles elkan table 
overview contents datasets 
dataset samples average length samples proven crp sites proven lexa sites crp lexa crp lexa promoter na na dataset 
mentioned previously exact value nsites critical meme discover motifs 
pass meme yielded excellent model lexa binding site 
second pass produced model crp binding site 
subsequent passes produced models unknown significance 
results meme crp lexa summarized table 
table 
models pass meme crp lexa dataset visually summarized consensus sequence derived ae matrix choosing letter highest probability 
values information content log likelihood give qualitative idea statistical significance model 
higher values imply model significant 
models lexa crp passes meme considerably higher log likelihood information content models passes 
note nsites 
pass starting subsequence final consensus log likelihood model produced pass meme crp lexa identified characterized lexa binding site extremely 
quality model judged partly degree correctly identifies known lexa binding sites dataset 
way model produced meme examine values ij see positions samples dataset high probabilities start motif 
meme prints highest values ij sample dataset pass 
table shows values ij pass meme known lexa binding sites 
easily seen model pass characterizes lexa binding site 
furthermore values ij model appears specific lexa binding site 
consensus sequence model discovered pass meme crp lexa dataset agrees exceedingly lexa binding site 
meme prints consensus probable letter position motif determined ae pass 
consensus pass unsupervised learning multiple motifs biopolymers em matches consensus reported perfect dna palindrome 
table 
values ij model meme pass crp lexa dataset positions known lexa sites 
virtually known sites high values ij compared rest positions samples 
table shows positions known sites site site site values ij model positions 
positions values ij 
site position sequence ij value highest ij values sequence 
proven sites known ij positions samples low 
sample site ij site ij site ij df ia ib lexa indicates site known sequence similarity known sites 
way seeing model learned pass meme characterizes lexa binding sites plot information content score subsequence input data 
shows information content scores crp lexa samples pass model 
scores zero set zero easier interpret 
easily seen model gives known binding sites high scores subsequences receive low scores 
pass meme discovers crp motif 
consensus sequence reports pass agrees consensus model reported 
significantly model characterizes crp motif judging values ij various positions samples dataset 
table shows values ij pass crp lexa dataset 
crp dataset contains known crp binding sites verified protection experiments 
value ij model eleven ij values 
turns samples lexa dataset contain timothy bailey charles elkan base number information content scores input subsequences known lexa sites 
information content score subsequence crp lexa dataset specificity matrix pass meme 
crp samples short curves top lexa samples long curves bottom 
vertical scale highest peak bits 
values zero set zero 
unsupervised learning multiple motifs biopolymers em crp binding sites 
sample labeled lexa dataset sequence overlaps sample labeled cole crp dataset 
overlap contains crp motif 
lexa samples ia ib appear contain crp sites virtually identical cole crp site 
sites ij extremely high 
particular version crp binding site model learned pass biased representing version crp binding site genes 
may explain model fit crp sites equally 
table 
values ij model meme pass crp lexa dataset positions known crp sites 
known crp sites high values ij twelve stated bound values ij top ij values sequence 
sites labeled lexa dataset crp dataset 
sequence named gene cole overlaps crp site region 
site ia may reported previously ib site previously reported lexa site 
sample site ij site ij cole pbr trn cat tdc ia ib indicates site known sequence similarity known sites 
lexa dataset sample overlaps crp sample cole 
site may reported previously 
apparent crp site may confused lexa site hertz 
shows information content scores crp lexa dataset computed specificity matrix learned pass meme 
timothy bailey charles elkan base number information content scores input subsequences known crp sites 
information content score subsequence crp lexa dataset specificity matrix pass meme 
crp samples short curves top 
strong match model samples lexa dataset seen second third fourth long curves 
vertical scale highest peak bits 
values zero set zero 
model defined pass clearly matches known crp sites large degree 

meme discover parts single binding site meme run passes promoter dataset nsites 
value chosen prior knowledge derived literature approximate size gamma gamma regions coli promoters 
value nsites chosen assumption sample dataset contains promoter 
pass meme yielded model consensus known gamma region consensus 
second pass produced model consensus unsupervised learning multiple motifs biopolymers em close conventional gamma region consensus 
passes produced models unknown significance 
results meme promoter dataset summarized table 
table 
models pass meme promoter dataset summarized consensus sequences 
gamma gamma region models passes meme higher log likelihood information content models 
pass starting subsequence final consensus model log likelihood models learned passes meme promoter dataset applied samples dataset information content score subsequence dataset plotted figures 
base corresponding start transcription sample position horizontal axis plot 
column peaks position shows model identifies gamma consensus region promoters 
column peaks position confirms second model identifies gamma region promoters consensus sequence slightly different generally accepted 

robustness meme algorithm crp lexa dataset promoter dataset test usefulness various separate ideas entering design meme algorithm evaluate sensitivity algorithm particular values chosen parameters 
algorithm appears robust 
noted meme run model 

subsequence derived starting points em idea running em iteration starting points derived possible subsequence input dataset tested 
experiments demonstrate method appears predicting starting points run em convergence 
experiments consisted running em iteration possible subsequence derived starting point datasets 
likelihood models obtained plotted starting position subsequence starting point derived 
point plotted position sample dataset 
timothy bailey charles elkan base number information content scores input sequences 
information content score subsequence sequences promoter dataset specificity matrix pass meme 
concept learned pass meme promoter dataset locates gamma region promoters 
vertical scale highest peak bits 
values zero set zero 
unsupervised learning multiple motifs biopolymers em base number information content scores input sequences 
information content score subsequence sequences promoter dataset specificity matrix pass meme 
concept learned pass meme promoter dataset locates gamma region promoters 
vertical scale highest peak bits 
values zero set zero 
timothy bailey charles elkan residue number log likelihood models em iteration known crp lexa sites 
log likelihood iteration em starting points derived possible subsequence crp lexa dataset 
em appears converge quickly starting points derived subsequences near lexa binding sites 
short curves top crp samples longer curves lexa samples 
vertical axis curve scaled highest peaks lowest valleys 
hoped starting points yield models significantly higher likelihood just iteration 
em run convergence starting points model obtained selected output meme 
experiment combined crp lexa dataset 
meme algorithm run iteration em possible starting point 
log likelihood values derived models plotted position sequence starting point derived seen large peaks likelihood function occurring lexa samples 
information content scores plotted graph similar appearance 
em maximizes likelihood model information content log likelihood chosen criterion choosing starting points 
information content similar results 
unsupervised learning multiple motifs biopolymers em base number performance starting points sample pass known lexa sites 
em finds models high likelihood run iteration crp lexa dataset starting points derived subsequences sample 
starting points correspond known lexa binding sites left ends indicated horizontal axis 
investigation showed peaks tended occur positions known lexa binding sites 
shows expanded view curve sample 
sample contains lexa binding sites left ends marked horizontal axis 
peaks curve occur near positions 
phenomenon observed lexa samples previous researchers noted match lexa consensus 
erasing motif necessary find closer inspection plots peaks seen curves crp samples positions corresponding known crp binding sites 
shows expanded view crp sample 
seen difficult distinguish peaks generated starting points derived timothy bailey charles elkan base number performance starting points sample pass known crp sites 
log likelihood model iteration em meme varies strongly starting point 
plot shows log likelihood model iteration em dataset crp lexa run starting points generated subsequences sample labeled 
subsequences crp binding sites peaks correspond known sites 
appears peaks due em starting converge model related lexa motif 
bad model highly conserved lexa motifs may log likelihood similar best model crp binding sites due fact lexa binding sites highly conserved crp binding sites 
highest peaks produced subsequences crp samples lower highest peaks produced lexa samples 
crp sample produced peak position corresponding crp binding site clearly higher peaks produced subsequences crp samples 
shows necessity eliminating lexa binding sites data order able discover best starting points run em learn model crp binding sites 
unsupervised learning multiple motifs biopolymers em 
expected number motif appearances critical choice nsites critical ability meme model find distinct motifs parts motifs dataset necessary know advance appearances motif dataset 
restrict usefulness meme discovering completely new motifs sequence data 
fortunately meme discovers models motifs nsites set wide range values 
running meme just values nsites probably suffice find motifs represented dataset 
meme run crp lexa dataset various values nsites parameters fixed 
models meme pass examined see fit known consensus sequences lexa crp 
table shows passes meme models lexa crp motifs discovered information content log likelihood models 
meme finds model lexa motif pass 
low nsites finds lexa due presumably fact lexa binding sites get completely erased 
meme effectively erases nsites occurrences motif pass nsites fifteen lexa binding sites left pass find model lexa motif 
meme model crp motif passes values nsites tried nsites 
usually crp second model 
values information content log likelihood lexa models higher models meme true crp models 
nsites close actual number known crp binding sites dataset information content log likelihood crp model higher models unknown biological significance meme 

model sensitive noise model removal motif appearance sequence assumption intended things model sensitive noise model 
example suspected sequences dataset noise contain appearance motif nsites set value number sequences dataset 
meme correctly locates just appearances motif model higher log likelihood model forced choose appearance sequence dataset 
test assumption meme run model model datasets contained varying numbers randomly generated sequences nsites set fixed value time 
random sequences letter frequencies dataset length 
datasets crp lexa various numbers random sequences timothy bailey charles elkan table 
meme finds models lexa crp binding sites nsites values 
nsites lexa crp usually passes 
nsites meme fail find crp passes 
nsites pass consensus log likelihood motif lexa lexa lexa lexa crp lexa crp lexa crp lexa crp lexa crp lexa crp crp added 
cases meme model learned correct concept unsupervised learning multiple motifs biopolymers em pass datasets random sequences meme model tolerate 
meme model learned model crp binding site random sequences added sequences crp dataset 
learned model random sequences learned second pass 
meme model able learn lexa binding site model random samples added dataset learned center model random samples dataset 
meme model learned correct lexa model random samples added dataset 
shows information content crp lexa models learned meme model model pass datasets various numbers random sequences added 
crp models learned model consistently higher information content learned model 
true model learned random sequences added dataset 
presumably indicative fact model advantage sequences multiple appearances crp site 
models learned model lexa extremely robust number random samples added dataset 
decrease information content matter random samples 
model hand models lower information content random samples dataset 
clear meme model find set highly conserved binding sites datasets vast majority sequences contain 
model suffers fact average supposed motif appearance sample 
meme model able deal particular type noise samples containing motif appearances estimate true number motif appearances nsites available 

discussion meme algorithm demonstrates power new ideas 
starting points shown powerful way selecting starting points em may useful methods 
em tends converge quickly starting points meme saves great deal time running em iteration starting point greedily selecting best starting point likelihood learned model 
modifications em algorithm allow meme drop assumption sequence contains exactly appearance motif fit model dataset shown give meme ability discover motifs datasets contain sequences contain motif 
probabilistic weighting scheme meme erase appearances motif pass demonstrated finding multiple different motifs motifs multiple parts 
timothy bailey charles elkan number random sequences added dataset sensitivity models irrelevant sequences crp model model crp model model lexa model model lexa model model 
information content lexa crp models pass meme model model run separately crp lexa datasets different numbers random examples added 
comparative advantage model clear 
especially motifs occurrences highly conserved model finds models sequences containing motif 
meme run 
nsites set model 
unsupervised learning multiple motifs biopolymers em meme algorithm prove useful analyzing biological sequence data 
robust tool discovering new motifs sequence data little prior knowledge available 
meme discover motifs sequence data performing unsupervised learning 
effectively meme finds clusters similar subsequences set sequences 
measure cluster information content model example decide methods experimentation applied verify sites match model biologically related 
plots information content scores various positions sequences dataset helpful biologist discovering clusters significant may statistical artifacts 
meme dataset sequences known contain motif promoter dataset performing supervised learning 
models meme learns allow motif variable length insertions deletions allowed meme limited learning restricted class motifs 
may possible multiple models learned meme passes dataset features learning algorithm 
example decision tree learner id cart models learned meme promoter dataset features learn classification rule coli promoters 
passes meme models gamma gamma regions promoter approach high chance success 
promising idea short motifs learned meme construct starting points hidden markov models 
innovations added em algorithm meme hidden markov models hmms 
idea subsequence derived starting points may adaptable hmms 
method meme probabilistically erasing sites pass certainly easy add standard forward backward hmm learning algorithm 
possible design hmm model eliminates assumption motif sequence 
may possible adapt meme innovations learning stochastic context free grammars biopolymer concepts 
meme discovered crp sites ia ib samples 
site ib mentioned lexa site possibly crp site 
appear classified lexa site 
results reported indicate site probably crp binding site lexa binding site information content score site crp model lexa model 
mention crp site ia literature 
acknowledgments supported part national science foundation award 
iri timothy bailey supported nih genome analysis pre doctoral training 
hg 
authors grateful michael timothy bailey charles elkan gribskov useful conversations course reported douglas smith extensive suggestions writing article colleagues advice encouragement 
appendix ae models 
iteration em values letter probabilities motif model ae offset probabilities reestimated 
model values reestimated bayes rule current estimate ae 
models values ae estimated expected values letter frequencies 
done described 
describe em algorithm model types formally definitions useful 
number sequences length motif length sequence assume length 
define ij estimate iterations em probability site begins position sequence model data 
ae lk estimate iterations em probability letter appearing position motif 
ith sequence dataset ij letter appearing position sequence 
define indicator variable ij equals site starts position sequence 
ignore probability letters outside motif consider probability letters motif 
model types em calculate probability sequence motif start model 
written jy ij ae ae sequence letter position gamma gamma forms basis calculating model bayes rule estimate jy ij ae 
bayes rule states ajb bja ij ij ae jy ij ae ij gammaw jy ik ae ik ij prior probability motif begins position sequence estimated assumed uniform ij gamma gamma unsupervised learning multiple motifs biopolymers em simplifies ij jy ij ae gammaw jy ik ae probability estimated sites completely sequence assumed range gamma calculations notice formula ensures sums sequence 
enforces implicit assumption model sequence contains exactly appearance shared motif 
model modified em algorithm normalizes sum positions sequences nsites written formally ij nsites jy ij ae gammaw sn jy ik ae calculated model undergoes normalizations enforce constraints ij equal sum ij window length equal 
constraints written formally ij gamma ij gamma different ways constraints enforced 
particular manner chosen reduces computational effort 
claim best choice 
constraints enforced separately applying algorithms order 
presents algorithm passes offset probabilities normalizing sum nsites squashing setting exceed normalization 
pass offset probabilities get squashed pass raise value offset probabilities squashed nsites total enforced 
practice usually passes needed 
second algorithm run enforce constraint window positions offset probabilities sum 
achieved dividing sequence adjacent windows length normalizing window separately 
windows shifted right process repeated 
done possible shifts windows guarantees window width offset probabilities summing greater may reduce total sum nsites squashing algorithm repeated correct done interest saving computation time 
timothy bailey charles elkan 
squash unnormalized ij jy ij ae 
total total sequences positions 
nsites number appearances motif expected 
length sequences 
number sequences 
renormalize true 
renormalize 
renormalize false 
normalize total nsites 
total 

gamma 
ij 

normalize 


nsites nsites gamma 
renormalize true 


ij 
total total 



return 

squash normalize ij sum nsites constraining 
unsupervised learning multiple motifs biopolymers em 
smooth normalized offset probabilities 
length sequences 
number sequences 

offset 
offset gamma 












return 

smooth constrain sum offset probabilities window width sum 
timothy bailey charles elkan notes 
name meme explanations 
acronym multiple em motif elicitation 
second english word meme means theme motif propagation cultural evolution similar propagation gene biological evolution 
third meme greedy algorithm algorithm 

related measure occasionally model information content model 
sum information content position motif positions motif 
information content position motif defined ae lj log ae lj frequency letter dataset 
information content model defined model relationship model log likelihood discussed stormo bailey 

promoter sequences dna sequences precede genes necessary transcription dna messenger rna 

consensus sequence motif sequence consisting commonly occurring letter position appearances motif 
ties resolved arbitrarily 

see discussion matrix scoring sequences 

possible subsequences dataset sequence suggested 
meme approach subsequences sequences preferable order sequences unimportant 
just sample eliminates problem sample happening contain motif occurrence 

idea conserved motif comes biological idea occurrences motifs related evolution 
conserved motif appearances identical little mutation occurred separated common ancestor 

biologists number bases letters dna sequence base base transcription dna messenger rna begins 
bases preceding start transcription negative numbers starting 

best value known advance meme run repeatedly different values 
addresses question choosing best value run meme uses single value motifs 

timothy bailey 
likelihood vs information aligning biopolymer sequences 
technical report cs university california san diego february 

amos bairoch 
prosite dictionary sites patterns proteins current status 
nucleic acids research july 

otto berg peter von hippel 
selection dna binding sites regulatory proteins 
journal molecular biology 

breiman friedman olshen stone 
classification regression trees 
wadsworth belmont california 
unsupervised learning multiple motifs biopolymers em 
lon gary stormo 
expectation maximization algorithm identifying protein binding sites variable lengths unaligned dna fragments 
journal molecular biology 

benoit de stephen henri buc 
cyclic amp receptor protein role transcription activation 
science may 

dempster laird rubin 
maximum likelihood incomplete data em algorithm 
journal royal statistical society 

richard duda peter hart 
pattern classification scene analysis 
john wiley sons 

harley reynolds 
analysis coli promoter sequences 
nucleic acids research 

haussler krogh mian 
protein modeling hidden markov models analysis globins 
proceedings hawaii international conference system sciences volume pages los alamitos ca 
ieee computer society press 

gerald hertz george iii gary stormo 
identification consensus patterns unaligned dna sequences known functionally related 
computer applications biosciences 

smith 
fast searching protein sequences regular expression patterns related protein structure function 
december 

charles lawrence stephen altschul mark boguski jun liu andrew neuwald john 
detecting subtle sequence signals gibbs sampling strategy multiple alignment 
science 

charles lawrence andrew reilly 
expectation maximization em algorithm identification characterization common sites unaligned biopolymer sequences 
proteins structure function genetics 

john quinlan 
induction decision trees 
machine learning 

sakakibara michael brown rebecca underwood mian david haussler 
stochastic context free grammars modeling rna 
technical report ucsc crl june 

gary stormo 
computer methods analyzing sequence recognition nucleic acids 
annual review biophysics biophysical chemistry 

gary stormo 
consensus patterns dna 
methods 

gary stormo george iii 
tool multiple sequence alignment 
proc 
natl 
acad 
sci 
usa 

edward richard mural 
locating protein coding regions human dna sequences multiple sensor neural network approach 
proc 
natl 
acad 
sci 
usa 

jennifer graham 
analysis cloned ib gene complete nucleotide sequence implications regulation expression 
nucleic acids research 
