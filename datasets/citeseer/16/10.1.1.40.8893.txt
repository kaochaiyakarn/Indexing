packet pair flow control srinivasan keshav bell laboratories mountain avenue murray hill nj usa keshav research att com presents packet pair rate feedback flow control scheme 
scheme designed networks individual connections reserve bandwidth available bitrate best effort component integrated networks 
assume round robin queue service discipline output queues network switches propose linear stochastic model single conversation network switches 
model motivates packet pair rate probing technique forms basis provably stable discrete continuous time rate flow control schemes 
novel state estimation scheme fuzzy logic 
address practical concerns dealing system startup retransmission timeout strategy dynamic setpoint probing 
finite state machine source code model implementation 
dynamics single source interactions multiple sources behavior packet pair sources variety benchmark scenarios evaluated means detailed simulations 
close remarks possible extensions packet pair limitations outline related 

emerging paradigm data communication concept integrated network traffic constant bitrate variable bitrate bursty sources intelligently multiplexed provide quality service guarantees individual connections 
integrated networks expected provide classes service 
class users regulate traffic fit behavior envelope exchange network gives guarantees performance 
example traffic source may agree obey leaky bucket descriptor exchange bound expected loss rate 
second class sources specify bound traffic return performance guarantees 
sources adapt changing network conditions order achieve data transfer goals 
service useful sources incapable describing expected behavior behavior may bursty unpredictable 
second class service call available bitrate abr service compatible existing computer networks internet various lan technologies important component networks 
scheme congestion control abr component integrated networks equally applicable existing datagram oriented networks 
congestion control abr traffic involves packet cell schedulers queuing points flow control protocol traffic sources 
consider role packet schedulers congestion control 
shown strong motivation round robin packet schedulers bursty data traffic provides advantages traditional come discipline 
round robin service automatically enforces min max fair allocation resources 
automatically polices sources source sending faster fair share subjected packet cell loss 
ensures behaved users protected ill behaved users desirable public data networks 
due advantages round robin schedulers widely implemented 
packet pair flow control way exploit properties schedulers intelligent flow control 
packet pair strictly refers technique probing bottleneck bandwidth availability extend meaning packet pair flow control include additional components 
technique probing network state estimators smooth state information control law uses smoothed network state technique flow control startup current network state information available strategy compute timeout intervals retransmission strategy buffer management strategy taken schemes strategies intended provide complete solution problem flow control best effort sources high speed networks round robin servers 
roughly stages theory implementation simulations 
section justify analytic model networks round robin servers 
model serves basis control law choice estimators packet pair probing technique discussed section 
section presents strategy state information control framework followed discrete continuous time control scheme stability analysis design fuzzy logic state estimators 
sections schemes startup timeout retransmission strategy buffer management strategy 
section discusses implementation considerations section detailed simulation study scheme 
section discusses possible extensions packet pair section presents review related 

network model section justify analytical model network round robin servers 
describe variants round robin service generic model 
assume packets source destination traverse unicast route 
true virtual circuit networks atm networks datagram networks typical transport higher layer connect times shorter routing table update time 

round robin rate allocating servers packet servers cell servers atm networks associated queueing point packet switched network typically output queues packet switches 
round robin server active connection associated logical physical connection data queue server serves non empty data queues turn 
time duration spanned visit server non empty data queues called round 
single packet served round service scheduler strict round robin 
packet served round scheduler called weighted round robin 
packet size small fixed simple round robin service provides equal bandwidth share connection 
packet sizes variable potentially large packet receive service inverse proportion length order achieve fair bandwidth allocation 
done tagging packets completion time service head line processor sharing serving packets increasing order tags fair queueing 
shown fair queueing emulates head line processor sharing asymptotically conversation length 
connections may allocated unequal bandwidth shares varying weights done weighted fair queueing discipline 
round spans constant time duration output trunk kept idle necessary non conserving discipline called framed round robin service 
multilevel framed round robin server called hierarchical round robin server 
network model flow control scheme described adequate describe variants round robin service packet size connection fixed atm networks service weighted reflect packet size fair queueing weighted fair queueing packetized generalized processor sharing virtual clock 
call kind round robin server rate allocating server ras round connection allocated service rate depending number active connections weights relatively independent traffic arrival patterns connections 
say relatively independent connection sporadically active increase decrease number active connections way influence service rate allocated connections 
note variations service rate ras provides conversation consistent service rate come served fcfs server 
fcfs server service rate conversation linked detail arrival pattern conversation server perceived service rate varies rapidly 
example consider situation number conversations sending data server fixed conversation data send scheduled service 
fcfs server conversation sends large burst data service rate conversations effectively drops burst served 
ras conversations unaffected 
server allocates rate service conversation approximation independent arrival patterns conversations 

stochastic model conversation stochastic model conversation network 
extension deterministic model 
model conversation ras network sequence regularly spaced packets source destination series servers connected links 
servers path conversation numbered source numbered 
destination assumed acknowledge packet 
assume ease analysis sources data send 
simplification allows ignore start transients analysis 
fact start costs significant analyzed 
time taken service ith server time denoted instantaneous service rate defined 
includes time taken serve packets conversations round robin order round time 
service rate inverse time consecutive packet services conversation 
source sending rate denoted source assumed send packets spaced exactly time units apart 
define max bottleneck service time conversation index bottleneck server 
bottleneck service rate defined 
changes due changes number active conversations 
model changes discrete time intervals changes discrete time steps 

choice step duration discussed section 
number active conversations ac large expect change ac time interval small compared ac change interval small close 
model random walk 
represents fact cross traffic bottleneck point uncontrollable suffers random variations 
model simple represents dynamics order sufficient effective control practice 
define max random variable 
assumptions distribution depending choice estimator 
discussed sections 
modelling effect cross traffic random noise variable essentially linearized system max operator 
control task relatively straightforward 
linearization possible ras service isolates conversation service details arrival pattern cross traffic 
fcfs service isolation associated non linear control complex 

packet pair probing source server bottleneck sink rtt rate estimate bottleneck rate packet pair probing packet pair mechanism send data form back back pairs estimate bottleneck service rate spacing 
presents time diagram time increasing vertical axis 
axis represents source sink queueing point communication network 
parallelograms represent transmission packet correspond kinds delays vertical sides long transmission delay packet size divided line capacity 
slope longer sides proportional propagation delay 
network store forward packet sent till completely received 
packet arrives may queued receives service 
represented space dotted lines de 
packet pair scheme source sends back back packets time 
size second packet packets served bottleneck definition interpacket service time instantaneous service rate source bottleneck acks preserve spacing known source measure inter ack spacing estimate consider possible sources error estimate 
server marked server spaces back back packets affect measurement moment reflection reveals long second packet pair arrives bottleneck bottleneck ends service packet problem 
packet arrive time definition server bottleneck 
spacing packets servers bottleneck server consequence introduce errors scheme 
factor introduce error packet may arrive server serving packets may delayed example de 
delay common packets pair affect estimation service capacity 
introduce error fact acks may spread due different queueing delays ack return path 
note ack net queueing delay ij lm second zero queueing delay 
effect increasing estimate note source error persist inter ack spacing noted sink sent source state exchange scheme 
measuring sink reduce effect noise eliminate server bottleneck potentially introduces noise measurement 
model error measurement observation noise 
observed value increased decreased noise equal probability direction expect noise distribution symmetric 
flow control design flow control algorithm uses probed values philosophy design necessary simplifications assumptions enable analytical design simulations refine design test validity assumptions 
section theoretical framework design section validation extensive simulation 

design strategy design strategy flow control mechanism separation theorem 
informally theorem states linear stochastic system observer estimates system state uses estimate control eigenvalues state estimator controller separable 
theorem allows technique state estimation implement control estimated state actual state derive control law assuming required estimators available estimators derived section 
preliminary considerations 

choice setpoint aim control maintain number packets bottleneck queue desired setpoint 
system delay components possible control stay setpoint times 
system oscillate setpoint value 
assume moment queueing point allocates buffers conversation static quantity known source 
assumption relaxed section 
choice setpoint reflects tradeoff mean packet delay buffer usage packet loss bandwidth loss bandwidth conversation loses data send eligible service 
consider distribution controlled system pr 
bounded left right contains information things pr loss bandwidth pr ras server schedules conversation service 
assuming events independent reasonable assumption find pr loss bandwidth proportional 
similarly pr loss packet pr packet arrival density denoted proportional probability packet loss 
mean queuing delay xn dx packet takes average units time get service bottleneck 
setpoint small distribution driven left probability bandwidth loss increases mean packet delay decreased probability packet loss decreased 
trade bandwidth loss lower mean delay packet loss 
similarly choose large setpoint trade packet loss larger mean delay lower probability bandwidth loss 
sequel assume setpoint 
justification system noise symmetric control tracks system noise expect symmetric setpoint 
case setpoint balances tradeoffs 
choice setpoint chosen loss generality section show modifying setpoint deal case unknown 
mitra shown asymptotic analysis product form queueing networks derive optimal value setpoint 
ideas directly applicable assumptions fcfs scheduling poisson cross traffic exponentially distributed packet service time distribution approximation results may determine choice optimal setpoint control system 

assumptions regarding round trip time delay assume propagation delay constant conversation 
usually true propagation delay due speed light fiber hardware switching delays 
fixed rare rerouting 
assume round trip time large compared spacing acknowledgments 
analysis treat arrival packet pair single event measures round trip time bottleneck service rate 
assume measured round trip time epoch denoted rtt estimate round trip time epoch 
justification system equilibrium queue lengths expected approximately successive epochs 
case wide area networks propagation delay larger additional delay caused change queueing delay 
approximation change ignored 

controller design discrete time control initially restrict control actions round trip time rtt restriction removed 
purpose exposition divide time epochs length rtt propagation delay queueing delays 
done simply transmitting specially marked packet pair returns control action sending marked pair 
control action taken epoch 
consider situation kth epoch 
time know rtt round trip time kth epoch number packets outstanding time 
predict estimator average service rate th epoch 
service rate bursty time average may lead problems 
example average value large part control cycle actual value low bottleneck buffers overflow 
cases take control action arrival probe discussed section shows time diagram control 
vertical axis left source axis right bottleneck 
line axes represents packet pair 
control epochs marked source bottleneck 
note epochs bottleneck time delayed respect source 
convention kth epoch called time refers number packets bottleneck kth epoch 
estimators marked hat 
observations regarding 
distance ab rtt measured source time packet pair sent time ack received 
earlier assumption propagation delay th special pair kth pair 
ab cd length epoch source bottleneck equal rtt 
time marked kth epoch packets sent epoch acknowledged 
unacknowledged packets sent kth epoch number outstanding packets 
approximated sending rate multiplied sending interval rtt 
rtt number packets bottleneck th epoch simply number epoch epoch epoch epoch nb nb source bottleneck line represents packet pair rtt rtt nb time scale control packets kth epoch added number came minus served kth epoch subject condition lies 
rtt packets sent rtt packets serviced interval rtt rtt rtt rtt rtt rtt max min terms state equation system nonlinear boundaries 
note setpoint chosen lie interior range system linear setpoint 
small deviations setpoint rtt equations fundamental equations analysis 
combined give rtt determined sent kth epoch way control 
control 
rtt rtt rtt control set 
set obtain 
rtt rtt gives rtt rtt rtt replacing values estimators derived rtt rtt rtt earlier assumption set rtt rtt 
gives rtt rtt control law 
control tries get buffer epoch 
note control law requires maintain estimators 
effectiveness control depends choice estimators 
considered sections 

stability analysis discrete time control stability analysis controlled system substituted state equation control law 
assume estimators perfect replace estimators true values 
know state equation step ahead time 
gives rtt substitute find state evolution controlled system 
rtt rtt rtt rtt assumption rtt close rtt 
moving back steps time rtt rtt transform sizes get rtt rtt considering state variable characteristic equation system asymptotically stable roots characteristic equation eigenvalues system lie inside unit circle complex plane 
solving get eigenvalues lie unit circle controlled system asymptotically stable 
place pole characteristic equation system asymptotically stable 
consider control law rtt rtt leads characteristic equation az roots poles symmetric real axis need ensure means system asymptotically stable 
separation theorem system observer eigenvalues distinct stability result holds independent choice estimators 
physical interpretation simple reach epoch source send exactly rate computed 
system may unstable 
sends slightly lower rate ensures system asymptotically stable 
note constant independent system dynamics chosen advance desired value smaller 
exact value chosen controls rise time system adequate responsiveness small 
simulations indicate value compromise responsiveness instability 
similar studies mentioned 

controller design continuous time control section describes frequency control increased information propagation delay 
note estimate number packets bottleneck queue plays critical role control system 
controller tracks changes necessary estimator accurate additional information network available 
piece information value propagation delay 
round trip time packet delays due causes propagation delay speed light processing switches interfaces queueing delay switch previous packets conversation serviced phase delay introduced packet previously inactive conversation waits server finish service packets conversations propagation delay depends geographical spread network wans order tens milliseconds 
phase delay roughly magnitude time takes send packet conversations sharing server round time 
queueing delay order round times packet queue takes round time get service 
high speed networks expect propagation queueing delays roughly magnitude phase delay order magnitude smaller 
queueing delays avoided measured round trip time approximately propagation delay conversation 
easy way avoid queueing delays measure round trip time packet packet pair 
packet queueing delays estimate propagation delay conversation packet measured round trip time 
call propagation delay value useful number packets bottleneck queue epoch estimated number packets transmitted pipeline subtracted number unacknowledged packets epoch 
known gives way determining 
update alternative equation 
advantage approach equation susceptible parameter drift 
successive errors add differ substantially new scheme risk considerably reduced systematic error advantage approach enables control actions taken arrival packet pair rtt 
controller react earliest possible moment changes system 
system described far limited rtt control enables simple relationship equation 
control actions taken faster rtt epoch size smaller relationship longer true 
new relationship complicated easily shown state input vectors expand include time delayed values faster control actions required larger state vector complicates analysis control 
contrast information propagation delay control done quickly packet pair change length state vector 
control done probe easier continuous time 
fluid approximation packet boundaries ignored data flow fluid hydraulic system 
approximation commonly analysis simulations show approximation close particularly bandwidth delay product large 
assume input rate held fixed duration average service rate time interval assumed lie linear region space 
note amount information bottleneck buffer estimated difference amount unacknowledged data amount data flight control goal setpoint value 
control law 
stability system easily determined 
note limit equation define state system equilibrium point state equation clearly eigenvalue system positive system lyapunov stable asymptotically stable 
system pole placement parameter plays exactly role discrete time system 
close eigenvalue system close system reach equilibrium point rapidly 
larger values cause system move equilibrium point slowly 
intuitively satisfying choice round trip time easily estimated 
practice values known estimated 
fuzzy prediction having derived control law proved stability need determine stable estimators system state 
earlier studied kalman estimator 
estimator requires priori knowledge variances system observation noise 
values hard determine turn novel technique state estimation fuzzy prediction 
basis fuzzy prediction exponential averaging predictor aq predictor controlled parameter weight past history 
larger weight past history relation observation 
method called exponential averaging predictor discrete convolution observed sequence exponential curve time constant exponential averaging technique robust number applications 
major problem exponential averaging predictor choice principle determined knowledge system observation noise variances practice variances unknown 
useful automatically determine value able change value line system behavior changes 
approach uses fuzzy control effect tuning 
fuzzy exponential averaging uses assumption system thought belonging spectrum behavior ranges steady noisy 
steady system sequence approximately constant affected mainly observation noise 
large past history weight transient changes ignored 
contrast system noisy vary considerably reflects changes observation noise 
choosing lower value observer quickly tracks changes ignoring past history provides old information 
choice extremal cases simple choice intermediate values spectrum hard 
fuzzy controller determine value gracefully responds changes system behavior 
system moves noise spectrum adapts change allowing obtain estimate times 
observer know priori predictor automatically determines appropriate value 
linked noise system amount noise system determined assume moment variance order magnitude larger variance assumption removed section 
assumption system steady exponential averaging predictor usually accurate prediction errors small 
situation large 
contrast system noisy exponential averaging predictor large estimation error 
system noise large past history predict 
matter value usually large error 
case best give little weight past history choosing small value observer track changes system 
summarize observation predictor error large small vice versa 
treating small large fuzzy linguistic variables basis fuzzy controller estimation controller implements fuzzy laws proportional error low high proportional error medium medium proportional error high low linguistic variables low medium high proportional error defined usual way 
input fuzzy controller value proportional error outputs steps 
proportional error value mapped membership fuzzy sets low medium high definition 
control rules determine applicability outcome resultant control 
fuzzy set expressing control centroid 
error processed steps input fuzzy system 
converted proportional value error second idea absolute error value directly spikes cause error large drops past history lost 
linguistic variables describe alpha low medium high low medium high linguistic variables describe error definition linguistic variables absolute error smoothed exponential 
constant obtained fuzzy controller links change error value idea change error large large spikes ignored 
small 
change error defined linguistic variables low high defined exactly corresponding variables changes assumption variance observation noise small removed 
resulting system shown 
details prediction system performance analysis 
exponential exponential fuzzy system fuzzy system observation proportional error smoothed proportional error estimate fuzzy prediction system 
startup far discussed situation rate control mechanism time collect past history steady stream user data continuous rate probing 
unfortunately situations situation hold 
transfer length may short source accumulate history get estimator second source may intermittent long idle periods stored state information aged useless 
startup phase conversation information network 
cases share common problem source state network informed decision 
control law described earlier sections directly applicable 
call startup problem describe solutions problem section 
note having startup algorithm essential part flow control 
startup aggressive startup conversation overflow buffers undesirable 
hand conservative startup lead poor performance short transfers 
large class applications remote procedure calls consist short transfers compared round trip bandwidth delay product having startup scheme crucial 
startup schemes described literature 
decbit scheme open window linearly till operating point reached 
poor choice bandwidth delay product large 
example operating window packets scheme take round trip times reach size 
faster way reach operating point exponential linear scheme proposed jacobson karels 
choice change phase exponential linear increase ad hoc 
kanakia mishra proposed linear increase sending rate till operating point reached constant acceleration sending rate 
scheme performs better decbit scheme choice acceleration crucial addressed 
proposal adaptive exponential rise nominal operating point 
current nominal operating point rate control exponentially increase sending rate point 
new information operating point arrives asymptote exponential rise adjusted fly 
time sending rate target target target target adaptive exponential startup starting time sending rate exponentially rises target operating point 
soon reaching asymptote fresh information target arrives sending rate moves exponentially new target 
sending quickly adjust information arrives 
idea information obtained startup accurate want rise immediately 
want overly conservative 
choosing exponential rise room maneuver giving poor performance short transfers 
target operating point chosen applying control law current estimator startup source sends packet pair probe waiting pair acks arrive 
gives information control law choose target operating point 
second round trip time packet pairs sent estimators get better target operating points change 
source adaptive exponential rise targets change 
note round trip time delay startup 
avoided network administrator guarantee new connection guaranteed nominal bandwidth 
round trip time connection send bandwidth revising estimate actual available bandwidth round trip time 
important determine startup phase 
words need know operating point reached 
information available looking estimator bottleneck buffer size sending rate operating point close zero service rate exceed sending rate 
approach operating point buffer setpoint reached rise zero reach chosen setpoint 
simple way know operating point reached check 
practice allow measurement errors check 
having adaptive exponential rise scheme discuss solutions problems raised section 
short transfers startup long transfers adaptive exponential rise scheme 
short transfers transfer may complete condition reached 
problem intermittent transfers note burst causes value drop zero 
new burst starts flow control automatically goes slow start 
network state information automatically updated startup 
adaptive exponential rise technique useful state estimators suspected inaccurate 
situation arises number active sources bottleneck suddenly decreases 
consider scenario sources share line 
note source sends pair packets output perfectly interleaved 
source correctly estimates capacity line capacity 
terminates round trip time send data slower available capacity draining bottleneck queue 
leads zero length queue possible pairs arriving conversation served back back arrival pairs conversation 
example pairs source served back back server idle 
occurs source 
conversations incorrectly estimate share line round trip time send high rate 
time arrivals departures capacity estimate time arrivals departures capacity estimate source stops transmission get wrong rate estimates real problem sources receive poor estimates bottleneck capacity bottleneck buffers empty 
buffers non empty conversation terminated packets available interfere packets correctly inform share capacity 
endpoints notice small act cautiously estimators received situation holds problem avoided 
source check condition times just startup adaptive exponential rise condition holds 
simulations show solution works practice 

timeout retransmission strategy timeout retransmission strategy usually considered part error control flow control 
timers small numerous retransmissions lead network congestion 
poor choice direction lead long pauses wasting available bandwidth 
choice timers packets retransmit intimately related flow congestion control 
considerations guided design timeout retransmission strategy packet pair 
believe timers mechanism resort 
normal case losses detected timers 
timers needed choice timeout value chosen intelligently current network state 
second sender try continuously keep sending data order keep probing network state 
desirable keep pipeline full possible 
loss detection correction orthogonal flow control 
attain objective transport layer connection maintains transmission queue buffers incoming user data data retransmitted 
transmission queue partitioned high priority zone head low priority zone tail queue 
data application layer placed tail low priority zone packets awaiting retransmission added tail high priority zone queue 
rate control process removes data queue rate specified control law startup procedure 
idea retransmissions data share queue possible violate sending rate due retransmissions 
transmission queue effective decouples rate error control processes 
data application retransmissions transmission queue rate control transmission queue detect losses timers monitor sequence numbers carried acknowledgments 
assume tcp sequence number sequence packet seen far packet acknowledged 
addition carries offset sequence packet seen sequence number packet generated acknowledgment 
example receiver receives sequence numbers tuple sequence number acknowledgment corresponding offset 
non zero offset indicates packet sequence number larger sequence number lost received order 
assuming packets delivered order true virtual circuit oriented networks atm sender retransmit packet sequence number 
example sender presumes packet lost retransmit 
idea retransmitting packets time called fast retransmit due jacobson 
fast retransmits indication receiver state acknowledgments lost information repeated duplicate acknowledgment sequence number inform sender loss data packet 
contrast jacobson approach duplicate acks automatically trigger retransmission flow control window offset information intelligent retransmission 
ack non zero offset received sender notes packet sequence number ack sequence number offset reached safely 
retransmits packet range sequence number ack sequence number offset retransmitted received correctly detected earlier 
continuing example sender receives retransmit note correctly received 
received retransmitted received retransmissions occur 
single loss single retransmission occur 
large chunk outstanding packets lost retransmitted 
scheme guarantees packet correctly received acknowledged retransmitted 
sense optimal 
retransmitted packet lost scheme described fail 
handled schemes called soft timeout timeout respectively 
soft timeout scheme round trip times source checks progress consecutive received round trip times measured timers described discussion buffer setpoint probing section 
progress packet sequence number ack retransmitted 
usual case hole transmission window corrected having timer 
course packet lost window timeout needed 
order minimize os requirements implementation timeouts done single shared timer packet timer 
timer re initialized start packet transmission 
timeout entire flow control window put retransmission queue packets received correctly 
multiple losses round trip time automatically retransmitted 
scheme sender keeps pipeline full extent possible 
note retransmission scheme combines robustness low overhead go back protocol transmission efficiency selective retransmission scheme 
note actions duplicate ack timeout identical duplicate ack scheme retransmit packet retransmitted timeout scheme 
timeout value chosen deal case window acknowledgments lost example mobile host moved cell fast retransmission lost 
expect round trip time 
set timer expectation ack heard time wrong 
estimators enables set timeouts fairly accurately 
necessary multiplier tuned achieve best results particular network 
control law assumes correct count number outstanding packets available 
important know accurately estimate number packets bottleneck directly depends value 
packet losses simply incremented packet transmission decremented ack 
packet lost increment transmission corresponding decrement 
corrected deal lost packets slowly increase time causing systematic error rate control 
deal sender decrements packet retransmitted fast retransmission timeout 
correctly accounts lost packet prevents drift 

buffer management strategy section assumed intermediate point reserve buffers conversation 
feasible preceding treatment sufficient 
expect networks intermediate queueing points reserve buffers conversation 
case endpoint strategies 
minimize losses choosing small setpoint 
discussed section lead lower effective throughput loss rate lower 
suitable risk averse applications remote procedure calls 
strategy choose largest setpoint supported network causing excessive packet losses conversation 
done choosing small setpoint increasing setpoint additively round trip times till loss occurs trigger fast retransmit multiplicative decrease setpoint 
dynamic probing setpoint risk client choose setpoint largest supported time 
maximizes available bandwidth risk incurring packet losses additional queueing delay 
increasing setpoint round trip times multiplicative decrease factor effective circumstances 
note additive increase algorithm modeled decbit scheme different aim 
decbit scheme window size increased decreased modify operating rate 
choose sending rate packet pair information 
buffer setpoint modified risk applications maximize usage buffers bottleneck 

implementation section presents details implementation packet pair flow control 
feedback flow control algorithms typically implemented transport layer protocol stack 
data source trusted incapable flow control functionality implemented network interface unit interposed traffic source public isdn network 
case assume system able support connection state give access real time clock provide timer 
state diagram protocol describing actions state 
describe sending side packet pair protocol 
packet acknowledged receiver sequence number acknowledgment sequence packet seen receiver far 
connection assumed transmission queue buffers packets awaiting transmission 
flow chart describing implementation protocol 
state diagram system usually blocked state waiting input 
ack tick int timeout user input 
packet containing ack arrives non zero sequence number offset know packet current send window lost 
sender notes sequence number ack offset correctly received scans current send window places packets range ack ack offset retransmitted high priority portion transmission queue retransmitted eventually 
ack signals round trip times progress packet sequence number ack retransmitted soft timeout 
blocked 
ack note time note rtt note seq check seq compute inter ack compute alpha compute estimator mu compute new sending rate timeout send packet pair possible mark line free mark pair eligible set timer int tick enqueue packets retransmission queue append user data transmission queue user data retransmit packets non zero offset 

ack progress modify buffer setpoint finite state machine description protocol ack pair field transport layer header current time noted 
comparing transmission time packet current time round trip time computed stored state variable 
sequence number packet current time stored 
arrival ack reduces count outstanding packets 
ack header claims second pair validate sequence number testing larger sequence number ack seen 
valid ack pair time current measurement bottleneck service time 
compared current estimate service time proportional error fed fuzzy controller get new value exponential section 
new observation new value computed 
plugged continuous time control law equation obtain new sending rate 
rate stored state variable connection timer time loaded 
note multiple updates sending rate occur current rate timer expires latest value sending rate automatically 
dynamically modify setpoint source maintains state variables rtt count counts round trip times rtt seq stores sequence number 
rtt seq initially 
ack arrives sequence number greater rtt seq rtt seq set sequence number packet sent rtt count incremented 
ack packet arrive approximately round trip time method gives cheap approximate round trip time counter 
rtt count reaches chosen value setpoint increased counter reset zero 
packet loss setpoint multiplicatively decreased 
dynamic setpoint probing quite simple implement 
testing see ack sequence number greater equal rtt seq scheme tolerant packet loss 
errors introduced fact packet sent immediately small tolerable purpose 
adaptive exponential rise uses state variable called mean send rate exponentially averaged value actual sending rate 
control variable exponential averaging supplied system quite insensitive choice 
value 
adaptive rise implemented exponential increase current mean send rate target operating point specified control law 
specifically current target current mean send rate sending rate chosen factor updated exponential 
factor 
deal startup current value sending rate chosen value computed value computed control law target operating point 
startup mean send rate set holds system automatically adaptive rise 
section mentioned pole placement parameter control speed system reacts changes 
large value lead slow reaction small leads quick reaction possible oscillations 
value rtt chosen arbitrarily 
values implementation 
setpoint buffer react quickly order prevent packet loss 
setpoint aggressive reaction rate 
achieved choosing constants attack attack attack rtt attack rtt attack attack works variety simulated situations 
timeout event occurs currently unacknowledged packets placed transmission queue 
similar go back policy packets removed queue received queue emptied 
int event occurs indicates output line free state variable set note 
user input event occurs users data appended tail transmission queue 
transmission queue full user process optionally put sleep 
tick event occurs indicates rate timer expired state variable modified indicate valid send packet pair 
tick timer reloaded value computed control law latest ack pair 
event processing source checks see possible send packet pair 
true rate timer credits output trunk free receiver flow control window full timeout duplicate retransmission event 
conditions true packets removed head transmission queue packet pair sent 
packet sent timeout timer reloaded value computed current estimate propagation queueing delays number outstanding packets increased 
conditions fail source falls test blocked state 
dealing singletons discussion implicitly assumed user write data integral number packet pairs 
test state packet worth data send user sends data packet transmitted error 
user calls transport layer say byte data telnet application transport layer deal singleton packet 
clearly user may hand transport layer byte transport layer assume fragment user data send data pair 
alternate solution accompany small packets dummy packet purpose provide pair probe bottleneck state 
inefficient 
alternate solution adopted allow packets singletons 
packets contribute state probing 
transport layer receives packet starts timer goes packet led timer set transmission queue transmitted singleton 
saves transmission efficiency cost extra timer user delay singleton packets 
unacceptable applications timer set zero singletons sent right away 
implementation chose singleton timer anticipated application sensitivity delay ms implementation details table shows state variables implementation meanings initial values 
table shows control parameters meanings suggested values 
concludes description packet pair scheme 
evaluate effectiveness means simulations 

simulation results section simulation results measure performance packet pair variety situations 
start simple scenarios explore dynamics system move complicated scenarios test limits packet pair control 
simulation scenarios network elements common 
study behavior source sending data sink source sink separated wan link 
loss generality assume resource contention occurs destination lan 
data packet size bytes transport layer ack packet assumed bytes long 
correspond mean packet sizes observed internet 
source lan speed assumed wan link speed destination lan speed assumed tenth wan link speed 
line speeds propagation delays chosen bandwidth delay product packets round trip time time units tus 
bottleneck router buffer capacity packets 
congestion queueing happens router abstracted network shown 
pipeline depth packets round trip time delay tus model variety bandwidth delay products 
table shows sample lans mans wans results directly applicable 
table bandwidth refers sustained wan bandwidth available network interface unit single system 
note high speed lans medium speed wans fall bandwidth delay regime modeled similar parameters 
show sample parameters atm networks flow control done atm cell aal frame basis 
current economics lan interconnection mbps connections cost dollars mile month feel simulation parameters fairly representative 
variable initial value meaning seq sequence number counter sent highest sequence number sent far num outstanding number packets outstanding time ack time ack timeout timeout value alpha exp av 
const rate estimate estimate number packets bottleneck se bottleneck rate estimator re estimator rtt clean estimate propagation delay send rate computed sending rate mean send rate smoothed sending tate inter ack current inter ack time value ack ack seen far pair seq number ack pair num dup acks number duplicate acks seen far packets sent packets sent far total dup acks number packets retransmitted far dupacks initial current buffer setpoint rtt count rtts gone rtt seq ack sequence number indicates rtt num window size number retransmissions sequence 
ok window size packet seq 
correctly 
table state variables meaning variable suggested value meaning attack attack rate bottleneck attack attack rate bottleneck timeout multiplier times rtt estimate timeout value factor factor controlling send rate increase ms alpha exponential averaging constant mean send rate dec factor multiplicative decrease factor setpoint add factor additive increase constant setpoint initial initial value setpoint min smallest value setpoint count rtts wait changing setpoint table control parameters network type packet size bandwidth delay buffer size lan bytes mbps ms kbytes man bytes mbps ms kbytes wan bytes mbps ms kbytes atm lan bytes mbps ms kbytes atm man bytes mbps ms kbytes atm wan bytes kbps ms kbytes table simulation bandwidth delay regime 
base case dynamics simplest possible dynamics single source sends packets single bottleneck adequate buffers 
best possible case flow control algorithm 
case study dynamics free running flow control 
lan wan lan sink source router router simulation scenario source router sink bits time unit bits time unit delay delay time units buffer pkts round trip time time units bandwidth delay product packets pkt size bytes ack size bytes abstracted scenario test study behavior risk averse source turning setpoint probing observing behavior flow control algorithm isolation 
shows setpoint queue length bottleneck buffer estimated value number outstanding packets versus simulation time measured round trip times rtts 
startup bottleneck queue length close zero 
sending rate matches service rate queue length rises exponentially setpoint packets stays till simulation 
clear estimator queue length 
number outstanding packets pipeline depth added buffer setpoint 
detailed view queueing shown 
note packets arrive pairs depart spacing time unit service rate bottleneck 
arriving pairs exactly synchronize departing pairs oscillation bottleneck exactly packets amplitude mean buffer setpoint packets 
buffer size estimate rtt queue size estimate setpoint pkts queue length setpoint number outstanding packets oscillates point 
rtt queue size estimate setpoint closer look queue size estimator setpoint flow control immediately reach buffer setpoint adaptive exponential rise startup 
time reach setpoint seen switch utilization curve 
utilization measured intervals time units 
note utilization mark reached round trip times 
utilization stays bottleneck queue empty 
sequence numbers numbers rise smoothly slope equal service rate bottleneck 
experiment enable buffer setpoint probing 
setpoint probing great advantage rtt switch utilization sequence number rtt sequence number ack number sequence number number space single source 
fact need probing single source source variation buffer share 
probing useful number sources fair buffer share changes time 
shows dynamic setpoint probing sources share bottleneck 
note sources increase setpoint till sum setpoints reaches packet losses occur sources immediately reduce setpoint 
setpoints oscillate fair share buffers 
shown queue lengths exactly follow setpoints 
retransmission strategy described section losses affect sources minimally 
illustrated sequence number trace 
note loss corrected single retransmission losses affect sending rate reflecting decoupling flow control retransmission strategy 
rtt setpoint setpoint setpoint setpoint dynamic setpoint probing sources sharing buffers packets rtt seq seq seq seq sequence numbers sources probing setpoint increased linearly round trip times loss occurs setpoint multiplicatively decreased factor 
setpoint increase factor increased increase interval decreased decrease factor closer frequency setpoint probing increase 
induce losses 
view loss event giving information highest achievable setpoint 
better information achieved increased losses 
goal loss free transfer setpoint probing mutually contradictory 
prefer somewhat conservative inducing losses evidenced choice probing parameters 
possible trade losses better probing 
example scenario sources lost packets course simulation 
additive increase setpoint round trip times loss source conservative tradeoff 
problem dynamic probing instantaneous setpoints achieved different sources necessarily fair 
buffer size sources setpoints converge fair buffer share instantaneous bandwidth shares guaranteed fair round robin scheduling discipline loss events cause drastic changes setpoint short intervals time buffer share unfairly distributed 
fair queueing follows policy dropping packet longest queue long periods buffer share fairly distributed 
problems severe form bsd implementation tcp induced losses probe window size 
case probing flow control window uneven losses lead unfair bandwidth allocation 
case unfairness setpoints lead unfair allocations bandwidth 

dynamics interaction sources set scenarios study behavior source additional sources start share bottleneck bandwidth 
cases interest 
study effect adding source existing set sources 
second study effect adding additional sources simultaneously varies range 
case source study starts time new sources start round trip times sources active 
source starts see incremental effect source sources active ranges 
behavior system depends choice source study time react change change occurs 
source chance adjust sending rate seeing change 
study sub cases 
shows sending rates versus time sources source study 
source sends packets sources send packets 
start times staggered time units apart starting time 
source initially sending rate completely uses bottleneck 
setpoint increases queue occupancy rises 
time source starts time units new source starts 
source adaptive exponential rise takes round trip times complete effect additional sources source drastic 
source starts time time source brought rate fair share queues drain fair buffer share 
time onwards system quite stable sources sharing bandwidth equally 
sources terminate share distributed remaining sources appears rise sending rates simulation time 
shows sending rates versus time case 
source stabilizes time slightly bottleneck rate queue size increases increasing setpoint 
source starts source sending rate decreases drops incrementally sources active 
time source starts time source nearly fair share rate affected new source 
clear previous experiment 
degree source affected new source depends number sources active 
second variation sending rate new source decreases number active sources increases 
easy explain sources active addition new source changes bottleneck service rate change 
increases fraction decreases factor system behaves stable fashion 
sense packet pair scales desirable 
turn attention behavior source sources simultaneously added system 
increases source study suffers bandwidth loss ratio new service rate old decreases linearly study cases buffer size buffers rtt sending rate sending rate sending rate sending rate sending rates new sources added rtt rtt sending rate sending rate sending rate sending rate sending rates new sources added rtt look number losses suffered source buffer size infinite study peak buffer size attained source 
consider behavior source case sources start time 
behavior source goes distinct phases explained 
shows sending rate packets second inter ack spacing seen packet pair probe sent source shows queue bottleneck 
recall service rate approximately packet second 
sources active inter ack spacing sending rate ought 
phase time source sees inter ack spacing sends packet second slow start period discussed earlier 
time phase begins sources send probe source service rate drops 
period seen sending rate stays building queue 
time packet losses possible 
phase begins round trip time phase new service rate known estimate bottleneck queue suddenly increases 
allow bottleneck queue drain sending rate rapidly drops nearly zero 
third phase source sends new probe 
probe encounters sources slow start phases source imagines network inter ack spacing seen 
begins transmitting full rate phase 
sources soon attain final sending rates source queue starts building second queue buildup packet losses possible 
source sees inter ack spacing sources simultaneously active source sends correct rate phase bottleneck queue correct value packets 
packets lost phase retransmitted phase lost round trip time source attempts soft timeouts downward spikes 
competing sources complete service rate suddenly increases source queue rapidly drains 
phase 
seventh phase source detects service rate increased queue increases setpoint 
source able send full rate till transmission soft timeouts unable fill lost packets transmission window 
case source able send receive window fills point wait timeout packet retransmitted second time receive window opens 
eighth phase source idle waiting timeout ninth phase begins new slow start 
phases occur example observed larger values shows loss behavior source 
note entire window lost time retransmitted phase packets lost 
source recovers loss phase soft timeouts 
rtt sending rate inter ack time sending rate inter ack probes source scenario illustrates difficulty designing retransmission strategy rate flow control algorithm 
needs design just rate probing algorithm choice timeout slow start strategy information sent back source receiver problems incorrect probes 
believe achieved reasonably mix packet pair flow control 
consider quantitative metrics packet pair performance increases 
table shows rtt queue length queue length bottleneck source rtt sequence number ack number sequence space source number loss rate retransmission rate completion time peak buffer occupancy function note completion time increases monotonically 
expected total number packets served increases increases 
loss rate retransmission rate match exactly shows retransmission strategy optimal claimed 
loss rate expressed mean number packets lost time units length simulation generally increases buffer share decreases peak buffer occupancy shows interesting trend decreasing increasing turns 
explanation peaks achieved different phases phase peak achieved different increases peak phase increases maximum 
peak phase depends slow start behavior sources peaks occupancy 
peak occupancy achieved loss service rate small queue achieved phase larger target setpoint 
phase sending rate slows drain queue occur 
phase buildup adds phase buildup leading large queue 
losses phase longer phase buildup smaller rate probes interfere competing sources 
peak phase buildup achieved 
summarize losses peak interference 
packet losses phase queue draining phase subsequent phase buildup peaks 
phase buildup peaks 
loss retransmission completion peak buffer rate rate time occupancy pkts tus pkts tus tu pkts table system limited buffers consider peak buffer occupancy buffer large packets table 
phase missing phase add peak queue occupancy reached time 
phase buildup larger phase buildup cases peaks 
achieves largest phase buildup smaller phase buildup 
peak occupancy table system unlimited buffers draw study packet pair dynamics 
dynamics influenced number factors important achieve synergy retransmission flow control strategies 
second scheme behaves nearly optimally drastic changes bottleneck capacity 
estimator bottleneck queue length tracks real queue length quite closely due fuzzy prediction algorithm 
setpoint probes allow sources share bottleneck buffers fairly 
third peak buffer occupancy achieved phases queue buildup 
phase buildup expected reflects lack information rate change round trip time 
amount buildup exactly minimum predicted multiplying change service rate round trip time 
phase buildup improper rate probing sources startup phase somewhat unexpected 
turns effect dominates peak buffer occupancy 
fourth simulations show packet pair robust large changes service rate large numbers packet losses improper rate information small number available buffers situations bandwidth delay product large packets 
robustness necessary practical rate flow control mechanism 

goodput public data network study scenario models public data network 
sources regulated packet pair flow control compete single bottleneck server 
source modeled pair processes 
producer process places number packets transmission queue exponentially distributed time idle exponentially distributed time 
consumer process packet pair flow regulator empties transmission queue network 
producer process nominal rate mean rate places data transmission queue 
actual source rate determined flow control algorithm 
metric interest study throughput loss behavior system sum nominal source rate increases goes bottleneck capacity 
sources stochastic nature sources active time leading possible congestion 
large public network choose simulate active sources scenarios 
change loading increasing sum nominal rates bottleneck capacity capacity 
types sources studied open closed sources 
open source puts data transmission queue independent state queue 
sum duration independent network loading 
models file transfer type application 
closed source enters time transmission queue empty 
actual sum times varies load system 
open system models file transfer type application closed system models transaction processing environment 
measure performance packet pair scenario goodput retransmission rate subtracted transmission rate function sum nominal loads sources 
losses retransmissions fairly shared sources due fair buffer loss property fair bandwidth allocation property fair queueing 
simply add retransmissions incurred sources subtract throughput determine goodput 
sources sends packets course simulation rtx total retransmissions corresponds mean goodput rtx 
table shows mean goodput source nominal rate increases open closed systems 
cases bottleneck buffers bandwidth delay product network packets 
nominal load open system closed system retransmissions goodput retransmissions goodput table goodput public data network note cases goodput excellent considering sources share single round trip time worth buffers delay substantial 
shown cases sources maintains approximately packets buffer times achieving fair setpoint 
mind simulations indicate packet pair suitable best effort traffic isdn networks 

file transfer benchmark tests section study behavior packet pair set benchmarks designed stress flow control algorithm number ways 
compare behavior packet pair optimal flow control defined 
sources finite amounts data file send file transfer time primary metric compare performance various schemes 
file transfer time defined interval instant byte data available transport level sender instant sender receives destination received byte file 
carefully designing topology network experimental environment measure subsumes traditional performance measures link utilization fairness throughput 
considerations design benchmark 
simply benchmarks results obtained packet pair 
compare packet pair schemes reasons 
schemes designed networks come served servers optimized case 
behavior fcfs servers nice round robin servers packet pair unfair advantage 
pragmatic reason number flow control schemes proposed literature large impractical study 
schemes parametrized large number parameters published literature 
reasons benchmark results packet pair 
optimal file transfer time obtained analytically assuming bottleneck infinite buffers 
optimal scheme send entire file bottleneck stored served fair share capacity 
round robin network transfer time lowest achievable 

benchmark slow changes cross traffic configuration experiment shown 
scenario cross traffic load seen primary connection changes gradually 
connection shown starts time zero megabytes data send 
bottleneck round trip time worth buffers 
cross traffic stream connection starts ms cross traffic streams come intervals ms round trip propagation delay connections 
fundamental time constant reacting changes network state round trip time rtt flow control mechanisms highly stressed new traffic sources come spaced apart rtt 
cross traffic stream kbytes data send 
transmission speeds links size files chosen cross traffic load gradually increases decreases back zero interval connection transmitting data 
table shows packet pair achieves throughput optimal case 
connection connections mb ms delay mb ms delay configuration benchmark optimal packet pair slowdown table benchmark completion times milliseconds 
benchmark sudden jumps cross traffic configuration experiment previous experiment shown 
scenario cross traffic load seen primary connection changes rapidly 
scenario evaluates packet pair terms buffers required bottleneck face large perturbation 
connection starts time zero megabytes data send 
crosstraffic stream connection starts ms cross traffic streams come intervals ms smaller rtt connection experiences large drop available bandwidth rtt 
time interval ms large throw schemes simply count number new connection requests accurately allocate bandwidth existing new connections 
cross traffic stream kbytes data send 
optimal packet pair slowdown table benchmark completion times milliseconds benchmark shows large changes available bit rate packet pair stable shows small degradation performance slower optimal compared slower benchmark 
confirms results section 

benchmark transfer time short files transfer time critical performance measure small file transfers 
main factor increases transfer time short amounts data transfers slow start mechanism flow control schemes section 
experiment isolate slow start mechanism effect lost packets lost bandwidth due cross traffic 
cross traffic 
configuration experiment shown 
file sizes packets configuration 
file transfer times sending files packets shown table 
results indicate number packets sent increases packet pair increasing decreasing slowdown factor 
easy explain factor decreases note round trip propagation delay optimal scheme completes time 
packet pair roughly time 
completion time roughly 
slowdown ratio written 
function slowdown factor approaches increases 
increase small harder explain depends detail behavior packet pair 
acknowledgment number trace scenario transfer length packets compute slowdown factor value shown 
note peak slowdown achieved transfer packets 
feel order slowdown inevitable real life algorithm deal imperfect knowledge network state time start 
fact proposals slowstart show similar worse behavior recall decbit algorithm achieve window size take round trip times packet pair performs roughly times better 
mb ms delay mb ms delay connection configuration benchmark packets optimal packet pair slowdown table benchmark completion times milliseconds packets transferred percentage slowdown function number packets transferred 
benchmark fairness previous studies window flow control performance observed connections longer delay path get smaller share bandwidth bottleneck example see 
unfairness increases file transfer times traffic streams going longer paths 
experiment fairness bandwidth allocations measured 
configuration experiment shown 
primary connections started time megabytes data send 
connection goes path approximately twice propagation delay connection 
connections see cross traffic load bottleneck link shared connections 
starting times file sizes cross traffic streams experiment 
file transfer times sending files different delay paths shown table 
different reaction times change flow control scheme discriminate connection longer delay paths degree 
optimal file transfer time connection slightly longer connection longer round trip delay 
packet pair performs optimal long short connection 
discrimination longer delay paths mitigated extent choosing larger buffer setpoint longer paths 

benchmark migrating bottlenecks bottleneck time path connection 
site bottleneck may migrate changes network traffic 
experiment explore performance flow control schemes presence migrating bottlenecks 
simplicity considered generic case bottleneck develops link shifts link shifts back original link 
shifts site bottleneck induced introducing cross traffic streams different file transfer sizes separate links 
primary connection comes time zero connection mb ms delay mb ms delay connection mb ms delay connections configuration benchmark optimal packet pair slowdown short long short long short long table benchmark completion times milliseconds megabytes data send 
connection switches ms megabyte data send 
connection switches link bottleneck connection 
time ms connections switch kilobytes data send 
causes bottleneck connection shift link 
connections terminate link bottleneck connection 
configuration experiment shown 
file transfer times sending files shown table 
surprisingly migrating bottleneck traffic scenario results presents little difficulties packet pair scheme get explicit feedback bottleneck 
result suggest filters predict adapt rates packet pair scheme functioning reasonably 
connection mb ms delay mb ms delay connection connections mb ms delay configuration benchmark optimal packet pair slowdown table benchmark completion times milliseconds 
benchmark way traffic traffic scenario traffic flowing directions switch important examine role played packets flow control schemes 
tcp scheme uses acks clocking mechanism inject packets network roughly bottleneck rate 
packet pair scheme uses gap acknowledgment packets estimate service rate bottleneck node 
unfortunately congestion burstiness traffic reverse path chance successive acks may get bunched adversely affect schemes frequency ack arrivals inter ack gaps control policies 
experiment designed detect conditions measure impact performance 
configuration experiment shown 
configuration similar experiment connections duplicated reversed create exactly symmetrical flow directions 
primary reverse connection started host sink primary forward connection 
primary forward reverse connections start time zero 
cross traffic streams mirrored similar fashion 
file transfer times sending files forward backward directions shown table 
times compared file transfer time observed experiment order determine impact having congested reverse path 
note optimal file transfer time longer data packets share bandwidth ack packets 
packet pair performs better expected better benchmark 
fuzzy filtering spacing acks ignores noise generated bi directional traffic 
connection mb ms delay mb ms delay connections connections connection configuration benchmark optimal packet pair slowdown conn conn conn conn conn conn table benchmark completion times milliseconds 
benchmark non compliant cross traffic network expect traffic streams subject single flow control discipline 
example real time traffic source packet video camera follow flow control scheme followed bursty data source file transfer 
furthermore short data transfer applications distributed computation subject flow control 
important measure performance packet pair non compliant traffic streams 
configuration experiment shown 
configuration identical experiment cross traffic streams uncontrolled packet arrival process cross traffic source poisson aggregate arrival rate cross connections bottleneck link bandwidth 
primary connection comes time zero cross traffic streams switch ms intervals starting ms file transfer times shown table 
slowdown percentage decreases increase cross traffic intensity 
reflects time lost due slow start independent simulation length 
factor plays smaller role optimal transfer time increases slowdown optimal correspondingly decreases 
performance results show packet pair worse non compliant cross traffic 
believe packet pair robust behaved presence non compliant cross traffic streams 
cross traffic optimal packet pair slowdown intensity mean variance table benchmark completion times milliseconds 
benchmark fewer data buffers switch experiment study effect having fewer buffers switch 
believe having round trip time worth buffering shared conversations minimum may case amount buffering available 
scenario experiment switch tenth round trip time worth buffers 
table shows despite having buffers packet pair able perform quite 
rtt worth buffering completion time ms tenth completion time deteriorated ms ms 
robust efficient retransmission strategies developed section 
optimal packet pair slowdown table benchmark completion times milliseconds 
benchmark test rate schemes scenario designed test rate schemes stresses believed weakest aspects rate flow control 
configuration experiment shown 
scenario connection round trip time ms connection rtt ms sharing bottleneck link 
cross traffic provided sources start times ms ms respectively 
source sends total bottleneck link capacity ms goes idle ms number backlogged sources changes changes times round trip time source ms rtt gets chance adjust immediately 
file transfer times connections shown table 
clear large discrepancies round trip times sources difference completion times small 
due efficient filtering rate information continuous time control system implemented packet pair 
connection connection connections sources mb ms delay mb ms delay mb ms delay configuration benchmark conn conn table benchmark completion times milliseconds 
summary set benchmarks shows packet pair robust wide variety scenarios 
tested scheme scenarios regulated cross traffic unregulated cross traffic small number buffers rapidly changing cross traffic migrating bottlenecks 
cases scheme stable performs worse optimal small transfers slow start scheme causes bandwidth lost 
considerations space allow detailed results sequence number trace scenario behavior cases extreme stress similar section dynamics packet pair 
results feel scheme suitable public data networks 

packet video packet pair final test packet pair carry mpeg compressed video simulated network 
experimental method software coded mpeg carried simulated network active sources limited buffering sudden changes available bandwidth 
feedback signals flow control algorithm modify quality compression algorithm 
onset congestion coder informed subsequent data rate decreased 
course results loss quality quality degradation worse packet losses occur subsequent decrease sending rate happen open loop flow control leaky bucket 
results experiment showed perceptual quality video stream carried packet pair congested network hop hop congestion control scheme uses explicit virtual circuit rate feedback 
packet pair explicit rate information advantage obvious 

extensions packet pair section discuss extensions packet pair approach deal different environments 
subsection discusses packet pair fit atm environment section outlines packet pair multicast interact 
section considers interaction window flow control packet pair rate flow control 
section outlines implementation packet pair runs receiver sender 

packet pair atm packet pair scheme designed atm environments 
propose place packet pair transport layer native mode atm protocol stack 
user data handed session layer transport layer transmission queue described section 
transport layer packet pair send pairs aal frames 
peer transport layer send rate control transmission queue 
note packet pair works fair queueing environment 
fair queueing tries emulate bit bit round robin scheduling closely approximated cell cell round robin high transmission speeds 
rate probing technique works despite segmentation reassembly done aal 
rate probing effective queueing points round robin multiplexing data streams network 
high speed atm networks existence implement round robin service 
proposed native mode atm stack multiplexing preserve virtual circuit quality service constraints 
feel restrictions easily satisfied atm networks making feasible implement packet pair isdn environments 

packet pair multicast environment discussion far context point point data transfer packet pair multicast environment long acknowledgments endpoint identifier aal mid field 
trivial determine slowest link send data rate 
timeout retransmission strategy information contained acknowledgments maintaining destination retransmission queue believe flow control scheme multicast networks developed 

interaction window flow control note control system give guarantees shape buffer size distribution 
non zero probability packet loss 
applications packet loss undesirable 
requires endpoints retransmit messages frequent retransmissions lead congestion 
may desirable guarantee zero packet arranged having window flow control algorithm operating simultaneously rate flow control algorithm described 
scheme rate flow control provides operating point setpoint user selects 
addition source limit number packets outstanding window size server path reserves window worth buffers conversation 
assures system deviates setpoint system lose packets possible congestive losses completely avoided 
note reserving buffers conversation introduced reservations network earlier claimed 
argument strict bandwidth reservation leads loss statistical multiplexing 
long conversation refused admission due lack buffers statistical multiplexing bandwidth affected buffer reservation multiplexing gain identical received network buffer reservations 
large cheap memories claim possible reserve buffers loss statistical multiplexing 
repeat rate flow control select operating point window flow control conservative cut point 
respect agree jain forms flow control diametrically opposed fact 
choice window size critical 
fixed sized windows usually possible high speed networks bandwidth delay product required window large order hundreds kilobytes conversation 
view adaptive window allocation scheme proposed attractive 
scheme conversation allocated flow control window larger product allocated bandwidth bottleneck round trip propagation delay 
conversation constrained size flow control window 
signaling scheme dynamically adjusts window size response changes network state 
believe window flow control scheme complementary rate flow control scheme proposed 

receiver control discussion far places rate control sender 
reasonable data transfer type applications dispense way transfers video streams 
case implement packet pair receiver 
done making extensions packet pair 
sender places header containing current state 
receiver receives continuous updates sender state 
second receiver measures inter packet spacing computes appropriate sending rate 
third receiver sends periodic messages sender optimal sending rate 
frequency messages determines effectiveness control 
state exchange feel fairly parsimonious state exchange protocol give reasonably performance 
area interesting 

limitations main limitation approach restricts scheduling discipline round 
unfortunately vast majority current networks implement come served discipline 
rate probing technique fcfs networks parts scheme optimal retransmission carry fcfs networks 
restriction believe quite general treatment feedback congestion control abr traffic 
benefits round robin service data service feel gain importance 

related related threads research congestion control 
broadly speaking congestion control classified open loop closed loop 
closed loop feedback schemes packet pair generally subdivided dynamic window rate schemes 

dynamic window schemes dynamic window schemes attract wide attention proposed tcp jacobson karels dec network architecture jain ramakrishnan chiu 
schemes seminal contributions area best suited fcfs networks small bandwidth delay products 
scheme exploits linearization property round robin service take control actions round trip times unsuitable networks large bandwidth delay product 
product increases startup algorithms embodied algorithms packet losses small data transfers expensive 
jacobson karels approach uses packet losses indication congestion 
consequence congestion indicator seen congestion taken toll 
reduces achievable goodput 
schemes assume sources cooperative respond correctly congestion signals 
noncooperative source benchmark cause compliant source reduce load zero 
clearly undesirable public networks 
dynamic window scheme uses band signalling achieve zero packet loss minimizing buffer usage proposed morgan 
scheme efficient bandwidth buffers uses fairly complicated signaling protocol 
contrast packet pair achieves performance passive probes 
mitra proposed adaptive window scheme networks large products 
results depend cross traffic poisson may hold true current networks predictive control propagation delays lead control oscillate stable conditions 
dynamic window schemes mathematically analyzed bolot rodrigues weiss mukherjee 
analyses give insight performance generic dynamic window schemes 

rate flow control rate flow control schemes proposed literature 
earliest scheme netblt heuristics thoroughly studied 
netblt transmitter sends data rate round trip times receiver clocks data see received rate 
sender increases rate cuts back suffers problem increase available capacity known inducing congestion 
avoid packet pair probes 
early approach hop hop predictive control proposed ko mishra tripathi 
shares objectives packet pair independently developed time 
differences approach congestion indicator explicitly communicated source smoothing estimates uses exponential chosen priori fuzzy predictor 
appeal primarily intuitive heuristics formal control theoretic model develop control 
williamson proposed loss load scheme uses throughput versus loss curve compute optimal sending rate 
approach numerous 
ignores system considerations fact monitoring connection switch poses considerable burden switch controller 
source may lose packets sending fair share 
sender computes rate solving equation kth degree loss rate 
loss rate solving equation real time impossible current technology 
feel packet pair better attuned current networking realities 
kanakia mishra proposed hop hop congestion control scheme predictive control 
similar approach 
scheme requires switch monitor conversations overhead switch switch transfer rate information 
hop hop scheme perform better packet pair 
packet pair uses passive probing feel loss performance may worth 
low studied scheme bits explicit feedback information switch 
estimate network state bits state prediction kumar varaiya step ahead predictor assuming system state density function gaussian 
simulations confirm design 
scheme may viable alternative simulations detailed diverse verify correctness assumptions 
shown scheme stable taken implementation considerations account 
browning proposed scheme concept disturbance accomodation control 
scheme derives control law similar derive section validating 
done detailed simulations confirm control law 
park proposed warp congestion control scheme 
scheme receiver detects network state observing arrival times data packets sender uses determine appropriate sending rate 
suffers error mathematical model equation equation bottleneck queue size may negative clearly impossible 
entire control equation doubt correctness approach 
theoretical analyses rate flow control generic schemes done rodrigues 

studies ensembles controlled systems body considered dynamics system users update sending rate synchronously asynchronously response measured round trip delays explicit congestion signals example 
approaches typically assume poisson sources availability global information simple flow update rule exponential servers 
assumptions 
deal dynamics entire system sending rate users explicitly taken account 
contrast consider system single user effects users considered system noise 
approach user uses complex flow update rule part fuzzy prediction analysis amenable simplistic approach authors 

optimal flow control control theoretic approach individual optimal flow control described originally extended 
approach conversation modeled order differential equation fluid approximation 
modeling parameters tuned steady state solution differential equation solution corresponding queueing model agree 
model service rate bottleneck random walk assume service rate non linear function queue length 
nonlinear function 
true ras service rate independent queue length 
apply techniques problem 
hsiao lazar control theoretic approach optimal flow control double bus tdma local area integrated voice data networks 
assume exponential fcfs servers network geographically dispersed propagation delays ignored 
modeling service rate random variable opposed random walk propose recursive minimum mean squared error filters estimate system state bulk results assume complete information network state 
lazar considered design optimal traffic filters state fully observable filters specialized voice traffic 
lazar hsiao lazar shown variety conditions optimal flow control network poisson traffic bang bang approximated window scheme 
clear result holds strong assumptions regarding service removed 

summary summary feel approach substantially different described literature 
scheme concentrated problem feedback flow control networks round robin servers uses complex signaling protocol 
schemes assumed particular scheduling discipline assumed fcfs exploit linearization property round robin service 
packet pair estimate system state unique estimation critical enabling control scheme 
described provably stable rate flow control schemes novel estimation scheme fuzzy logic 
numerous practical concerns implementing scheme addressed 
proposed novel schemes startup optimal retransmission buffer setpoint probing 
performed exhaustive simulation study scheme shown useful wide variety scenarios 
shown packet pair responds quickly cleanly changes network state 
current flow control algorithms decbit jacobson modifications bsd system behaves situations bandwidth delay product large cross traffic misbehaved bursty 
implementation tuning algorithm straightforward complex ad hoc controls current flow control algorithms 
complicated scenarios dynamics simple understand manage 
packet pair behaves stress importantly simple implement tune 
fortuitous reflect theoretical underpinnings approach 

scott shenker introducing area congestion control guiding earlier attempts build rate flow control schemes 
domenico ferrari support constant encouragement keen questioning 
subsequently numerous valuable discussions chuck kanakia sam morgan mishra motivated explore limits scheme 
packet pairs probe bottleneck service rate independently suggested ashok agrawala samar singh 
noise variable model bottleneck service rate suggested srinivasan 
collaborated design fuzzy controller 
benchmarks section jointly designed kanakia mishra 
public data network scenario section suggested sam morgan 
amy reibman supplied codec data packet video experiment section converted results videotape 
helpful advice criticism sally floyd mitra singh pravin varaiya anonymous acm sigcomm acm transactions computer systems aspects appreciated 


dynamic modeling control congestion prone systems operations research 

anderson moore linear quadratic methods prentice hall 

anick mitra sondhi stochastic theory data handling system multiple sources bell system technical journal 

feedback control congestion store forward networks case single congested node acm ieee trans 
networking appear 

kumar jaffe new approach performance oriented flow control ieee trans 
communication com april 

bolot shankar analysis fluid approximation flow control dynamics proc 
ieee infocom 

lazar decentralized algorithms optimal flow control proc 
th allerton conference communications control computing october 
university illinois urbana champaign 

lazar asynchronous algorithms optimal flow control networks tech 
rpt 
wucs washington university st louis mo february 

browning flow control high speed communication networks ieee trans 
comm 
appear 

caceres danzig jamin mitzel characteristics application conversations tcp ip wide area internetworks proc 
acm sigcomm september 

clark lambert zhang netblt bulk data transfer protocol rfc network working group march 

demers keshav shenker analysis simulation fair queueing algorithm journal internetworking research experience september 
proc 
acm sigcomm sept pp 

majumdar user optimal flow control integrated environment proc 
indo workshop systems signals january 
bangalore india 

bandwidth management congestion control strategy broadband packet networks characterizing throughput burstiness filter proc 
itc specialist seminar adelaide 

rodrigues weiss analysis rate control strategy delayed feedback proc 
acm sigcomm 

rodrigues adaptive framework dynamic access bandwidth high speeds proc 
acm sigcomm 

modelling control dynamic flows communication networks springer verlag 

fraser designing public data network ieee communications magazine october 

fraser kaplan marshall nationwide testbed high speed networking proc 
ieee infocom may 

gafni bertsekas dynamic control session input rates communication networks ieee trans 
automatic control 

greenberg madras comparison fair queueing discipline processor sharing performance proceedings th ifip wg international symposium computer performance modelling measurement evaluation north holland edinburgh scotland september 

greenberg madras fair fair queueing journal acm 

morgan fairness congestion control large atm data network dynamically adjustable windows th international teletraffic congress copenhagen june 

round robin scheduling fair flow control data communication networks lids th laboratory information decision systems massachusetts institute technology cambridge ma 

hsiao lazar optimal flow control multi class queueing networks partial information ieee transactions automatic control july 

jacobson congestion avoidance control proc 
acm sigcomm august 

jain myths congestion management high speed networks technical report digital equipment october 

kanakia keshav rate controlled servers high speed networks proc 
globecom december 

kanakia mishra hop hop rate congestion control scheme proc 
acm sigcomm 

kanakia mishra reibman adaptive congestion control scheme real time packet video transport proc 
acm sigcomm 

kanakia keshav mishra comparision congestion control schemes proc 
fourth annual workshop high speed networks baltimore maryland march 

keshav control theoretic approach flow control proc 
acm sigcomm september 

keshav agrawala singh design analysis flow control algorithm network rate allocating servers protocols high speed networks ii elsevier science publishers north holland april 

keshav congestion control computer networks phd thesis comp 
sci 
dept tech 
rpt 
university california berkeley august 

keshav flow control high speed networks long propagation delays proc 
inet june 

keshav semantics implementation native mode atm protocol stack submitted infocom august 

keshav fuzzy prediction timeseries proc 
ieee conference fuzzy systems march 

ko mishra tripathi predictive congestion control high speed wide area networks protocols high speed networks ii johnson editor elsevier science publishers north holland april 

leland taqqu willinger wilson self similar nature ethernet traffic proc 
acm sigcomm 

low varaiya simple theory traffic resource allocation atm conference record globecom december 

low plotkin wong yee usefulness explicit congestion notification high speed networks nd international conference telecommunication systems modeling analysis march 

mitra dynamic adaptive windows high speed data networks theory simulations proc 
acm sigcomm september 

mitra asymptotically optimal design congestion control high speed data networks ieee trans 
communications feb 

morgan queueing disciplines passive congestion control byte stream networks proc 
ieee infocom 

mukherjee analysis dynamic congestion control protocols approximation proc 
acm sigcomm september 

parekh generalized processor sharing approach flow control integrated services networks phd thesis massachusetts institute technology february 

park warp control dynamically stable congestion protocol analysis proc 
acm sigcomm 

ramakrishnan jain binary feedback scheme congestion avoidance computer networks acm trans 
comp 
sys 
may 

lazar modeling optimal flow control network performance evaluation 

netravali high speed transport protocol datagram virtual circuit networks proc 
acm sigcomm september 

keshav scheduling discipline admission control policy ii multimedia systems journal september 

shenker theoretical analysis feedback flow control proc 
acm sigcomm september 

singh agrawala keshav deterministic analysis flow congestion control policies virtual circuits tech 
rpt university maryland june 

tanenbaum computer networks prentice hall englewood cliffs nj 

numerical methods modeling computer networks nonstationary conditions jsac december 

hsiao lazar flow control integrated local area networks performance evaluation 

lazar flow control protocols integrated networks partially observed traffic ieee transactions automatic control 

agrawala dynamic behavior data flow virtual circuits comp 
sci tech 
rpt university maryland may 

window dynamics phd thesis university maryland college park may 

williamson cheriton loss load curves support rate congestion control high speed datagram networks proc 
acm sigcomm september 

williamson optimizing file transfer response time loss load congestion control mechanism proc 
acm sigcomm 

zadeh fuzzy sets journal information control 

zadeh outline new approach analysis complex systems decision processes ieee trans 
systems man cybernetics 

zhang tcp timers don proc 
sigcomm 

zhang new architecture packet switching network protocols phd thesis massachusetts institute technology july 

zhang shenker clark observations dynamics congestion control algorithm effects way traffic proc 
acm sigcomm september 

zimmerman fuzzy set theory applications kluwer academic publishers 
