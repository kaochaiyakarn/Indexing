prior research embodied interface agents users find engaging 
argue embodiment serve stronger function system designers actual human conversational protocols design interface 
communicative behaviors conversational turn interruptions referring objects pointing gestures examples protocols native speakers language know perform leveraged intelligent interface 
discuss protocols integrated rea embodied multi modal conversational interface agent acts real estate salesperson show embodiment required successful implementation 
qualitative difference face face conversation forms human human communication 
academics routinely travel long distances conduct certain face toface interactions electronic forms communication seemingly just 
people really important say say person 
qualitative difference situations just enjoy looking humans computer screens human body enables certain communication protocols face face conversation provide rich robust channel communication afforded medium available today 
gaze gesture intonation body posture play essential role proper execution just pretty face affordances embodiment cassell bickmore yan gesture narrative language group mit media laboratory ames st cambridge massachusetts justine bickmore hannes media mit edu conversational functions conversation initiation termination turn interruption handling feedback error correction kinds behaviors enable exchange multiple levels information real time 
people extremely adept extracting meaning subtle variations performance behaviors example slight variations pause length feedback nod timing gaze behavior significantly alter interpretation utterance consider great job vs 
great job 
particular interest interface designers communication protocols come free users need trained native speakers language skills daily 
embodied interface agent exploits protocols potential provide higher bandwidth communication possible 
course depictions human bodies decorative menus screen new interface design currently quite attractive users 
unfortunately embodied interface agents developed date don go novelty value 
aside pointing gestures facial expressions animated interface agents provide little amusing look old system handles mechanics interaction 
little wonder systems engaging provide improvement task performance text speech interfaces 
review embodied interface agents developed date summarize results evaluations performed 
discuss human communication protocols interface utility requirements embodiment 
rea embodied interface agent implements protocols describe ongoing research program develop embodied interface agents leverage knowledge human communication skills 
related researchers built embodied interface agents varying degrees conversational ability 
closest research area rickel johnson andre rist lester agents verbal nonverbal conversational behaviors move objects interface pointing gestures combination speech text output 
systems association verbal nonverbal behaviors additive affordances body exploited kinds tasks performs better speech 
animated conversation system automatically generated context appropriate gestures facial movements intonational patterns 
case domain conversation artificial agents emphasis production non verbal propositional behaviors emphasized reinforced content speech 
system designed interact user run real time 
provides example embodied interface agent inspired studies human psychosocial competencies developed 
agent gandalf recognized displayed interactional information gaze simple gesture canned speech events 
way able perceive generate turn back channel behaviors lead natural conversational interaction 
gandalf limited ability recognize generate propositional information limited ability provide correct intonation speech emphasis speech output occurring gestures speech 
conversational character system developed prevost uses architecture developed research groups application domain implementation details different 
system conversational character assists user complex system controlling equipment answering questions giving tutorials 
date conversational behaviors agent limited greeting rituals gaze pointing gestures body positioning 
user studies embodied interface agents maes takeuchi studied user responses interfaces static animated faces users rated engaging entertaining functionally equivalent interfaces face 
kiesler sproull users cooperative interface agent human face vs dog image cartoon 
andre rist muller users rated animated presentation agent ppp persona entertaining helpful equivalent interface agent 
difference actual performance comprehension recall material interfaces agent vs interfaces 
user study gandalf system mentioned users rated smoothness interaction agent language skills significantly higher test conditions gandalf utilized limited conversational behavior gaze turn limited gesture behaviors disabled 
evaluations tried address embodiment system useful usually keeping interaction including including animated 
studies testing particular uses embodiment may improve task learning performance 
previous studies inspire showing mere presence character wins points need focus contribution embodiment fully functional conversational interfaces order need start better understanding embodiment contributes human human interaction 
human communication protocols requiring embodiment embodiment provides wide range behaviors executed tight synchronization language carry communicative function 
important understand particular behaviors raising eyebrows employed variety circumstances produce different communicative effects communicative function may realized different sets behaviors 
clear system dealing conversational modeling handle function separately run risk inflexible insensitive natural phases conversation 
briefly describe fundamental communication protocols functional elements examples nonverbal behavior contribute successful implementation 
table shows examples mappings communicative function particular behaviors previous research typical north american nonverbal displays mainly 
mapping form function relies fundamental division conversational goals contributions conversation propositional interactional 
propositional information corresponds content conversation 
includes meaningful speech hand gestures complement elaborate speech content gestures indicate size sentence big 
interactional information consists cues regulate conversational process includes range nonverbal behaviors quick head nods indicate regulatory speech huh 
theoretical stance allows examine role embodiment just task behaviors 
standpoint note previous embodied interface agents deal interactional propositional information integrated manner prevents fully exploiting affordances body 
conversation initiation termination humans elaborate ritual engaging conversation 
example people show readiness engage conversation turning potential interlocutor gazing person exchanging signs mutual recognition typically involving smile eyebrow movement tossing head waving arm 
initial synchronization stage distance salutation communicative functions communicative behavior initiation termination reacting short glance inviting contact sustained glance smile distance salutation looking head toss nod raise eyebrows wave smile close salutation looking head nod embrace handshake smile break away glance looking head nod wave turn give turn looking raise eyebrows followed silence wanting turn raise hands gesture space take turn glance away start talking feedback request feedback looking raise eyebrows give feedback looking head nod table 
examples conversational functions behavior realization content elaboration emphasis gestures convey information content conversation ways hands uniquely suited fulfill 
example hands better indicate simultaneity spatial relationships voice channels 
probably commonly thought body conversation pointing deictic gesture possibly accounting fact commonly implemented bodies animated interface agents 
fact conversations don involve deictic gestures interlocutors discussing shared task currently people approach sealing commitment conversation close salutation handshake accompanied verbal exchange 
greeting phase ends participants reorient bodies moving away face orientation stand angle 
terminating conversation similarly moves stages starting non verbal cues orientation shifts glances away verbal exchange breaking mutual gaze 
conversational turn interruption interlocutors normally talk time imposing turn sequence conversation 
protocols involved floor management determining turn turn listener involve factors including gaze intonation 
addition listeners interrupt speaker voice gesturing indicate want turn 
conversational gestures convey semantic pragmatic information 
beat gestures small baton movements hands change form content accompanying speech 
serve pragmatic function conveying information new speaker discourse 
iconic metaphoric gestures convey features action event described 
redundant complementary relative speech channel convey additional information provide robustness emphasis respect said 
convey information spatial relationships concepts represent concepts physical form sweeping gesture accompanying property title free clear 
feedback error correction conversation speakers non verbally request feedback listeners gaze raised eyebrows listeners provide feedback head nods uh huh mmm speaker understood confused facial expression lack positive feedback 
listener ask clarifying questions hear understand speaker said 
rea embodied conversational agent rea project mit media lab goal construction embodied multi modal real time conversational interface agent :10.1.1.31.711
rea implements conversational protocols described order interactions natural face face conversation person 
current task domain rea acts real estate salesperson answering user questions properties database showing users virtual houses 

user interacting rea rea fully articulated graphical body sense user passively cameras audio input capable speech intonation facial display gestural output 
system currently consists large projection screen rea displayed user stands front 
cameras mounted top projection screen track user head hand positions space 
users wear microphone capturing speech input 
single sgi octane computer runs graphics conversation engine rea computers manage speech recognition generation image processing rea able conduct conversation describing features task domain responding users verbal non verbal input 
user cues typically associated turn behavior gesturing rea allows interrupted takes turn able 
able initiate conversational error correction user says generate combined voice facial expression gestural output 
rea responses generated incremental natural language generation engine extended synthesize redundant complementary gestures synchronized speech output 
simple discourse model determining speech acts users engaging resolving generating anaphoric 
architecture shows modules rea architecture designed meet requirements real time face face conversation 
design input accepted modalities input devices 
different modalities integrated single semantic representation passed module module 
representation kqml frame slots interactional propositional information regulatory content oriented contribution conversational act maintained system 
categorization behaviors terms conversational functions mirrored organization architecture decisions terms functions deliberative module moves periphery decisions terms behaviors input manager action scheduler 
addition input manager action scheduler communicate hardwired reaction connection respond immediately msec 
user input system commands 
tracking user gaze shifts move example reactive behavior 
modules deliberative nature perform non trivial inferencing actions take multiple realtime cycles complete 
rea implemented clips rule expert system language 
input devices speech body pos 
gaze gesture input manager im hardwired reaction understanding module um 
rea software architecture deliberative module overview implemented communication protocols rea implements human communication protocols previously described follows 
conversation initiation termination rea acknowledges user presence posture turning face user detected vision system 
exchanges greetings user verbal non verbal gestural output response user verbal greeting 
rea recognizes user turns away conversation vision input suspends speech input processing user turns face 
conversational turn interruption rea tracks speaking turn conversational state model speaks holds turn 
currently rea allows verbal interruption audio threshold detection yields turn soon user begins speak 
user gestures detected vision system interpret expression desire speak halt remarks nearest sentence boundary 
exhibits look away behavior planning response serves hold turn ready speak speaking turn turns face user indicate turn transition point 
decision module dm interactional processing propositional processing response planner knowledge base discourse model generation module gm speech gesture gen action scheduler output devices speech body pos 
gaze gesture content elaboration emphasis rea currently uses pointing gestures refer pictures houses environment 
research generation pointing gestures disambiguate objects virtual house walk throughs recognition user pointing gestures currently pursued 
rea generates natural language responses accompanying conversational gestures unified text generation module 
module distributes information conveyed user voice gesture channels semantic pragmatic criteria resulting redundant complementary gestures 
gestures composed function hand starting positions trajectory hand shape envelope size 
beat gestures generated mark new information semantic information conveyed gesture channel 
example describing new property rea says lovely garden demonstrates hands garden surrounds sides house 
development module classify user conversational gestures input vision system statistical models currently underway 
feedback error correction rea provides non verbal feedback user turn nodding head user utterances detected audio threshold device user keeps turn 
rea fully understand user input typically due errors reported speech recognition system attempts repair asking clarifying question 
sample interaction detail order understand better rea processes user input propositional interactional produces appropriate output behavior helpful look segment interaction user describe messages sent rea internal modules 
paragraph records actual interaction user rea tim approaches rea rea notices looks smiles tim says hello rea responds hello help hand wave tim says looking buy place near mit rea glances away keep turn thinking rea says house beat gesture emphasis new information house tim interrupts gesture rea finishes current utterance saying cambridge gives turn 
tim asks details 
focus different modules rea architecture contribute carrying interaction 
messages packaged kqml tell performative sender recipient fields contain names modules communicating 
messages describing interaction user rea including messages example content field contains frame type 
sender recipient fields denote communicative action originated intended recipient value rea user depending interpreted generated rea decision module dm 
general processing sequence follows input manager im new information user actions creates new sender user rea 
input field places description behaviors detected 
understanding module um receives interprets behaviors fills prop intr fields accordingly sending dm 
reaction incoming dm may construct new time sender rea recipient user 
filling prop intr fields dm passes frame generation module gm job translate propositional interactional descriptions series low level behaviors placed output field 
lastly action scheduler receives new output field coordinates verbal non verbal realization 
tell sender um recipient dm content sender user recipient rea input speaking state true prop gesturing state true intr 
sample performative user comes feet rea stereoscopic vision system starts track user head hand movements 
receiving information im um sends dm interactional message saying user 
system transition state sending gm interactional request generating invitation start conversation 
gm maps request sequence behaviors includes look user smile sent execution 
user responds invitation saying hello im reports onset voice um sends dm interactional message saying user taken turn 
system transitions state stays im delivers parsed speech content um dm received um interactional message saying user turn propositional message form speech act case type sa ritual greet 
inside dm speech act generates obligation respond greeting 
similar sa ritual greet speech act return fulfil obligation dm sends act gm execution 
gm breaks speech act hand wave behavior spoken utterance hello help realized 
system momentarily state speech act performed returns back state done 

rea conversational states user starts speaking gm produces interactional message indicating user taken turn shifting system state 
user finishes asking looking buy place near mit gm gives dm interactional message user turn propositional message user performed sa request place 
gm adds attribute place order considered dm determines house meets user preferences sa request place speech act generates obligation offer house 
time house user obligation describe house generated 
looking obligations time dm sends gm sa offer house fulfil 
propositional message interactional message stating rea needs take turn sent gm 
gm consults text gesture generator generating appropriate verbal gestural expression proposition instructing glance away effort take keep turn 
user notices rea planning speak grab floor allowing rea stay state 
rea delivering utterance generated spud house user realizes near mit weak constraint wants add detail spontaneously raises hands anticipation elaborating query 
vision notices sudden hand movement um sends message dm saying user turn 
gesture treated low priority interrupt rea finish current utterance giving user turn dm removes obligation describe house allows gm continue executing current utterance 
user interrupted speech overlapping rea dm halted gm execution causing rea give user turn immediately 
rea finishes utterance cambridge looks user state user continues 
user testing gandalf capable conversational functions described showed users relied interactional competency system negotiate turn preferred system embodied character capable emotional expression 
fact users comfortable gandalf began overlap speech limited speech recognition spud system developed matthew stone augmented synthesize conversational gestures addition speech real time 
capabilities 
step test rea see implementation larger set conversational functions including error correction gesture synthesis allows users engage efficient fluent interaction system 
argued embodied interface agents provide qualitative advantage interfaces bodies ways leverage knowledge human communicative behavior 
demonstrated approach rea system 
increasingly capable making intelligent propositional contribution conversation rea sensitive regulatory interactional function verbal non verbal conversational behaviors capable producing regulatory behaviors improve interaction helping user remain aware state conversation 
members rea team lee campbell david nina yu jennifer smith contribution comments 
candy sidner anonymous reviewers helpful comments improved 

andre rist mueller integrating reactive scripted behaviors life presentation agent 
proceedings agents minneapolis st paul may acm press 

azarbayejani wren pentland real time tracking human body 
proceedings image com bordeaux france may 

ball ling miller pugh thiel van dantzich wax 
lifelike computer characters persona project microsoft research 
software agents bradshaw ed mit press cambridge ma 

boyle anderson effects visibility cooperative problem solving task 
language speech 


cassell embodied conversation integrating face gesture automatic spoken dialogue systems 
ed spoken dialogue systems 
appear cambridge ma mit press 

cassell bickmore campbell chang yan embodiment conversational interfaces rea acm chi conference proceedings pittsburgh pa 

cassell bickmore campbell yan human conversation system framework designing embodied conversational agents cassell editor embodied conversational agents mit press cambridge ma 
cassell pelachaud badler steedman beckett douville prevost stone animated conversation rule generation facial display gesture spoken intonation multiple conversational agents 
computer graphics siggraph proceedings 

cassell th risson power nod glance envelope vs emotional feedback animated conversational agents 
journal applied artificial intelligence press 

cassell torres prevost turn vs discourse structure best model multimodal conversation 
wilks ed 
machine conversations 
kluwer hague 

discourse oriented facial displays conversation 
research language social interaction 

clips manual version 
technical report number software technology branch lyndon johnson space center houston tx 

finin fritzson kqml agent communication language 
proceedings third international conference information knowledge management cikm november acm press 

keisler sproull social human computer interaction 
friedman ed human values design computer technology 
csli publications new york 


kendon conducting interaction patterns behavior focused encounters 
cambridge university press 
new york 


maes agents faces effect personification 
proceedings fifth ieee international workshop robot human communication ro man 


lester converse barlow stone persona effect affective impact animated pedagogical agents 
pemberton ed human factors computing systems chi conference proceedings 

new york acm press 

mcneill hand mind gestures reveal thought 
university chicago press 


prevost hodgson cook churchill face face interfaces 
williams eds human factors computing systems chi extended abstracts 

new york acm press 

rickel johnson task oriented dialogs animated agents virtual reality 
proceedings workshop embodied conversational characters tahoe city california october 


stone modality dialogue planning pragmatics computation 
phd thesis university pennsylvania 

th risson communicative humanoids computational model psychosocial dialogue skills 
phd thesis mit media laboratory 

takeuchi situated facial displays social interaction 
katz mack marks rosson nielsen eds human factors computing systems chi conference proceedings 

new york acm press 
