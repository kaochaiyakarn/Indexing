modelling financial time series switching state space models mehdi ian neural computing research group aston university birmingham uk aston ac uk aston ac uk deficiencies stationary models applied financial time series documented 
special form non stationarity underlying generator switches approximately stationary regimes particularly appropriate financial markets 
dynamic switching modelled hidden markov model combined linear dynamical system hybrid switching state space model discuss practical details training models variational em algorithm due ghahramani hinton 
performance evaluated financial data sets shown improve number existing benchmark methods 
traditional time series models assumption stationarity underlying generator data assumed globally time invariant 
known financial time series assumption breaks 
instance obstacles effective forecasting exchange rates non constant conditional variance known heteroscedasticity 
garch models developed estimate time dependent variance bollerslev 
local assumption stationarity acceptable system switches different regimes regime approximately locally stationary 
fields econometrics control engineering hybrid approaches developed order model behaviour 
example mixture experts jacobs weigend decomposes global model linear non linear local models known experts specialises modelling small region input space 
limitation models gating network combines local models dynamics 
controlled current value time series 
way address limitation hidden markov model dynamics switch local models 
autoregressive hidden markov models switch autoregressive models predictions linear combination past values 
applied financial engineering order model high frequency foreign exchange data shown promising results shi weigend 
switching state space models consist multiple linear state space models controlled dynamic switch 
models assume behaviour system characterised finite number linear dynamical systems hidden states tracks dynamics different regime 
long standing limitation models complexity exact training algorithm grows exponentially order number models length time sequence 
various completely satisfactory approximations proposed decade bar shalom li 
ghahramani hinton reintroduced proposed efficient principled approximate algorithm training models maximum likelihood approach 
propose switching state space models modelling financial data 
approach motivated fact market behaviour different time periods explained different underlying regimes 
allows create predictive model discover times transitions occur regimes segment time series purely price data 
structured follows 
section introduce switching state space models show parameters learned variational methods 
review problems learning inference show models time series segmentation probabilistic density prediction risk estimation 
section apply currency exchange rate data compare results standard techniques 
model due flexibility simplicity efficiency parameter estimation algorithm hidden markov models hmms linear dynamical systems lds widely tools learning probabilistic models time series data 
models represent information past random variable hidden state 
conditioned state past observation independent 
case hmms state variable discrete viewed switching variable different process regimes 
lds hidden state continuous specified linear dynamical equation equation 
hmms trained efficiently maximum likelihood framework em algorithm 
variant step hmm known forward backward algorithm lds kalman smoother 
switching state space models generalisation hmm lds dynamics transition discrete manner linear regime 
regarded generalisation mixture experts autoregressive hmms autoregressive model rewritten state space model form 
different linear dynamical systems kalman filters compete order describe observation state vector evolves time steps system equation gamma gamma gamma qm delta fm state transition matrix qm process covariance matrix associated state vector assume initial state vector gaussian distribution sigma equation ensures gaussian time step discrete variable mg plays role gate 
system enters specific mode observation gaussian rm rm output noise covariance matrix associated model state discrete state variable evolves markov dynamics represented discrete transition matrix fa ij ij gamma essentially mixture model information past conveyed types random variable continuous discrete 
markov dependence relations joint probability sequence states observations written js gamma jx gamma jx learning algorithm sequence observations learning problem consists estimating parameters theta ffm qm gm rm sigma mm kalman filter transition matrix discrete state markov process order maximise likelihood 
efficient procedure solve maximum likelihood estimation derived expectation maximisation algorithm dempster 
step called inference step consists computing posterior probabilities jy theta hidden states step uses expected values reestimate parameters model 
unfortunately shown exact inference computationally tractable scales jy gaussian jy general mixture gaussians exponential number terms 
approximations proposed circumvent inference problem bar shalom li shumway stoffer 
ghahramani hinton proposed generalised em algorithm 
posterior distribution hidden states approximated tractable distribution method maximises lower bound likelihood approximating posterior probabilities parameterised distribution called variational approximation parisi 
shown judicious choice render inference step tractable saul jordan notation denote sequence random variables time time 
authors show step approximated decoupling forward backward recursions hmm baum kalman smoothing recursion rauch state space model relevant versions step hidden markov models linear dynamical systems posterior probabilities approximated easy derive re estimations parameters theta 
parameters hmm reestimated baum welch equations parameters kalman filter re estimated separately weighting observation responsibility assigned shumway stoffer 
initialisation mixture models trained em algorithm guaranteed reach local maximum likelihood solution 
local maxima models sensitive initialised 
choice initial conditions crucial prefer initialise model carefully simple random initialisation 
switching state space models initialisation important part learning algorithm hmm linear dynamical systems initialised 
key point start segmentation data set segmentation mean partition data modelled lds 
ghahramani hinton mentioned importance methods initialisation modified training algorithm approximation distribution broadened parameter annealed time 
large portion training runs converge poor local maxima 
initialisation algorithm propose train autoregressive hidden markov model discrete states data set run viterbi algorithm order obtain path sequence hidden states best explains observation sequence rabiner 
data point assigned probable hidden state gives segmentation data 
simple linear dynamical system initialised segment 
parameters ij discrete transition matrix initialised counting number transitions state state dividing number transitions state state 
financial data noticed problems method underestimates number samples hmm remains state proper learning phase lead model linear dynamical systems update parameters responsible data points 
prefer ad hoc adjustment diagonal entries initialised values closed 
synthetic data sleep data set ghahramani hinton shown approach significant improvement technical report preparation 
recommend rabiner anderson moore overview models 
making predictions step ahead predictions new data noting model contributes prediction observation rewritten switch variable vector 
line estimations model decouple naturally modification likelihood observation weighted responsibility kalman filter recursive equations hold model output covariance matrix rm weighted equation responsibility unfortunately known advance expected value obtained bayes theorem gamma gamma gamma term numerator equation 
second term represents predicted probability model time discrete state markov process probability gamma gamma gamma denominator normalising term gamma gamma gamma hard soft competition implemented 
hard competition kalman filter highest predicted probability running 
case models 
soft competition model allowed adapt parameters 
possible estimate time responsibility model detect mode transitions 
recursion equations control system community known multiple model algorithm 
simulations propose model financial time series probabilistic framework 
capability kalman filter track quasi stationary data power hmms uncovering hidden switching regimes believe models appropriate financial time series 
advantage viewing model probabilistic framework attach confidence intervals predictions covariance matrix random variable estimated time step immediate important application financial engineering concerns risk estimation 
addition value gate variable viewed indicating regime market time gives segmentation data value right 
trained model data sets foreign exchange rates 
results simulations dem usd foreign exchange rate daily returns 
training set contains points 
test set contains points 
application model uncover underlying regimes example plots segmentation obtained test set simple state space model 
kalman filter learns dynamics specific regime model capable detecting abrupt changes time series 
instance see kalman filter activated certain range volatility 
soft competition clearly see segments linear dynamical systems explain observation 
absolute return time top plots dem usd absolute returns test set 
bottom shows responsibility linear dynamical system time step 
mentioned model allows line estimate covariance prediction 
plots predictive distribution small window time mode transition occurred time 
shows confidence intervals change respect mode 
time window selected order show prediction affected change volatility model moves high volatility region low volatility region predictions course affected change clearly see confidence intervals sensitive transition 
evaluated performance objective measures compared models 
trained autoregressive models ar garch models mlp neural networks nn autoregressive hidden markov models data sets dem usd gbp usd yen usd 
training gbp usd yen usd data sets contain points test sets contain points 
shows profit loss curve models time window points dem usd test data set 
illustrative purposes assume transaction cost 
highest profit comparison neural networks 
models give better results predictive distribution time time contour plot predictive distribution jx gamma 
model switches state corresponding change volatility 
retain clarity report corresponding curves 
table gives nn time profit loss profit loss switching state space models solid line compared autoregressive hidden markov models dashed line neural networks dash dotted line 
profits different models time window compared simple short hold buy hold strategies 
ar garch nn short buy gamma gamma table profits different models compared short hold buy hold strategies selected time window 
table compares average performance model test data set 
purpose computed likelihood normal mean squared error nmse percentage accuracy correct target sign prediction 
model models initialised different seeds trained 
compared models clearly see behave unseen data 
exact computation likelihood tractable bound dem usd model likelihood nmse hits mean std mean std mean std ar gamma garch gamma nn gamma gamma gamma gbp usd model likelihood nmse hits mean std mean std mean std ar gamma garch gamma nn gamma gamma gamma yen usd model likelihood nmse hits mean std mean std mean std ar gamma garch gamma nn gamma gamma gamma table average log likelihood normalised mean squared errors hits test set runs 
ar nn models input dimension simply taken 
neural network contains hidden non linear nodes hidden states 
give lower bound likelihood 
comparable best value obtained 
comparing nmse percentage accuracy give best results 
switching state space models powerful probabilistic models modelling time series application finance new 
showed train initialise models prediction 
model mean variance conditional distribution interesting application models financial engineering risk estimation building trading models 
promising extension models model interaction different currencies inputs dynamical system multivariate output time series 
intend remove restriction kalman filters linear state space models 
acknowledgments funded epsrc contract 
cheng matlab implementation garch models 
anderson moore 

optimal filtering 
prentice hall englewood cliffs nj 
bar shalom li 

estimation tracking 
artech house boston ma 
baum petrie soules weiss 

maximization technique occurring statistical analysis probabilistic functions markov chains 
annals mathematical statistics 
bollerslev 

generalized autoregressive conditional 
journal econometrics 
dempster laird rubin 

maximum likelihood incomplete data em algorithm 
roy 
stat 
soc 
ghahramani hinton 

switching state space models 
technical report departement computer science university toronto 
ftp ftp cs toronto edu pub zoubin switch ftp ps gz 
jacobs jordan nowlan hinton 

adaptive mixture experts 
neural computation 
bar shalom dayan 

interacting multiple model methods target tracking survey 
ieee transactions aerospace electronic systems 
parisi 

statistical field theory 
addison wesley redwood city ca 


hidden markov models guided tour 
ieee international conference acoustic speech signal proceedings volume 
rabiner 

tutorial hidden markov models selected application speech recognition 
proceedings ieee volume pages 
rauch 

solutions linear smoothing problem 
ieee transactions automatic control 
saul jordan 

exploiting tractable substructures intractable networks 
mozer hasselmo editors advances neural information processing systems volume pages cambridge ma 
mit press 
shi weigend 

time seriously hidden markov experts applied financial engineering 
conference computational financial engineering 
ieee 
shumway stoffer 

approach time series smoothing forecasting em algorithm 
journal time series analysis 
shumway stoffer 

dynamic linear models switching 
amer 
stat 
assoc 
weigend srivastava 

nonlinear gated experts time series 
international journal neural systems 

