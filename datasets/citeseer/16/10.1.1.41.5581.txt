comparison study static mapping heuristics class meta tasks heterogeneous computing systems tracy braun howard jay siegel noah beck maheswaran albert james robertson mitchell bin yao debra hensgen pi richard freund school electrical computer engineering department computer science department computer sciences university manitoba purdue university mb canada west lafayette usa cs ca hj noah ecn purdue edu cs purdue edu motorola pi department computer science parkway naval postgraduate school russ blvd ste 
bldg 
md oe monterey ca usa san diego ca usa austin tx usa hensgen cs nps navy mil com com heterogeneous computing hc environments suited meet computational demands large diverse groups tasks meta task 
problem mapping defined matching scheduling tasks machines hc environment shown general np complete requiring development heuristic techniques 
selecting best heuristic environment remains difficult problem comparisons different underlying assumptions original studies heuristic 
collection eleven heuristics literature selected implemented analyzed set common assumptions 
eleven heuristics examined opportunistic load balancing user directed assignment fast greedy min min max min greedy genetic algorithm simulated annealing genetic simulated annealing tabu 
study provides basis comparison insights circumstances technique perform 
evaluation procedure specified heuristics defined selected comparison results shown 
research supported part darpa ito quorum program nps subcontract numbers 
equipment donated intel 

mixed machine heterogeneous computing hc environments utilize distributed suite different highperformance machines interconnected high speed links perform different computationally intensive applications diverse computational requirements 
general problem mapping matching scheduling tasks machines shown np complete 
heuristics developed perform mapping function difficult compare different underlying assumptions original studies heuristic 
collection eleven heuristics literature selected implemented compared simulation studies set common assumptions 
facilitate comparisons certain simplifying assumptions 
meta task defined collection independent tasks data dependencies task may subtasks dependencies subtasks 
case study assumed static line predictive mapping meta tasks performed 
systems tasks subtasks meta task defined referred just tasks 
assumed machine executes single task time order tasks ar rived 
dependencies tasks scheduling simplified resulting solutions mapping heuristics focus finding efficient matching tasks machines 
assumed size meta task number tasks execute number machines hc environment static known priori 
section defines computational environment parameters varied simulations 
descriptions eleven mapping heuristics section 
section examines selected results simulation study 
list implementation parameters procedures varied heuristic section 
research supported part darpa ito quorum program project called mshn management system heterogeneous networks 
mshn collaborative research effort naval postgraduate school purdue university university southern california 
technical objective mshn project design prototype refine distributed resource management system leverages heterogeneity resources tasks deliver requested qualities service 
heuristics developed derivatives may included scheduling advisor component mshn prototype 

simulation model eleven static mapping heuristics evaluated simulated execution times hc environment 
static heuristics assumed accurate estimate expected execution time task machine known prior execution contained expected time compute matrix 
row matrix contains estimated execution times task machine 
similarly column matrix consists estimated execution times machine task meta task 
estimated execution time task machine 
times assumed include time move executables data associated task particular machine 
assumption estimated expected execution times known studying mapping heuristics hc systems 
approaches doing estimation task profiling analytical benchmarking discussed 
simulation studies characteristics matrices varied attempt represent variety possible hc environments 
matrices generated method 
initially theta baseline column vector floating point values created 
oe upper bound range possible values baseline vector 
baseline column vector generated repeatedly selecting uniform random number oe letting rows matrix constructed 
element row matrix created baseline value multiplying uniform random number upper bound oe new random number oe called row multiplier 
row requires different row multipliers row matrix described theta 
baseline column appear final matrix 
process repeated row theta matrix full 
value matrix range oe theta oe 
evaluate heuristics different mapping scenarios characteristics matrix varied different methods 
amount variance execution times tasks meta task machine defined task heterogeneity 
task heterogeneity varied changing upper bound random numbers baseline column vector 
high task heterogeneity represented oe low task heterogeneity oe 
machine heterogeneity represents variation possible execution times task machines 
machine heterogeneity varied changing upper bound random numbers multiply baseline values 
high machine heterogeneity values generated oe low machine heterogeneity values oe 
vary matrix attempt capture aspects realistic mapping situations different matrix 
matrix said consistent machine executes task faster machine machine executes tasks faster machine 
consistent matrices generated sorting row matrix independently 
contrast inconsistent matrices characterize situation machine faster machine tasks slower 
matrices left unordered random state generated 
extremes semi consistent matrices represent partial ordering machine task execution times 
semi consistent matrices row elements column positions row extracted sorted replaced order row elements column positions remain unordered columns consistent odd columns inconsistent 
sample matrices twelve possible permutations characteristics listed shown figures 
probability distributions values including exponential distribution truncated gaussian distribution investigated included results discussed 
results study matrices size tasks machines 
necessary select specific parameter values allow implementation simulation characteristics techniques completely general 
parameter values apply specific situation interest researchers may substitute ranges distributions matrix sizes evaluation software study apply 

heuristic descriptions definitions eleven static meta task mapping heuristics provided 
preliminary terms defined 
machine availability time mat earliest time machine complete execution tasks previously assigned 
completion time ct machine availability time plus execution time task machine ct mat 
performance criterion compare results heuristics maximum value ct mapping known makespan 
heuristic attempting minimize makespan finish execution meta task soon possible 
descriptions implicitly assume machine availability times updated task mapped 
cases tasks considered arbitrary order order tasks appeared matrix 
heuristics listed modified original implementation better handle scenarios consideration 
heuristics control parameters values control function specifications selected implementation 
studies values specifications selected experimentation information literature 
parameters functions mentioned section 
olb opportunistic load balancing olb assigns task arbitrary order available machine regardless task expected execution time machine 
contrast olb user directed assignment assigns task arbitrary order machine best expected execution time task regardless machine availability 
referred limited best assignment lba 
fast greedy fast greedy assigns task arbitrary order machine minimum completion time task 
min min min min heuristic begins set unmapped tasks 
set minimum completion times fm min ct ug 
task minimum completion time selected assigned corresponding machine name min min 
lastly newly mapped task removed process repeats tasks mapped 
intuitively min min attempts map tasks possible choice machine basis completion time assumption result shorter makespan 
tasks shorter execution times mapped expected percentage tasks receive choice machine generally higher min min max min defined verified data recorded simulations 
max min max min heuristic similar min min 
max min heuristic begins set unmapped tasks 
set minimum completion times fm min ct ug 
task maximum completion time selected assigned corresponding machine name max min 
lastly newly mapped task removed process repeats tasks mapped 
motivation max min attempt minimize penalties incurred performing tasks longer execution times 
assume mapped tasks short execution times small quantity tasks long execution times 
mapping tasks longer execution times best machines allows tasks executed concurrently remaining tasks shorter execution times 
concurrent execution long short tasks beneficial min min mapping shorter tasks execute longer run ning tasks execute machines sit idle 
assumption max min tasks shorter execution times mixed longer tasks evenly distributed machines resulting better machine utilization better meta task makespan 
greedy greedy heuristic literally combination min min max min heuristics 
greedy heuristic performs min min max min heuristics uses better solution 
ga genetic algorithms gas popular technique searching large solution spaces 
version heuristic study adapted particular solution space 
shows steps general genetic algorithm 
genetic algorithm implemented operates population chromosomes possible mappings meta task 
chromosome theta vector position represents task entry position machine task mapped 
initial population generated methods randomly generated chromosomes uniform distribution chromosome min min solution random solutions mappings 
method called seeding population min min chromosome 
ga executes times times initial populations method best mappings final solution 
generation initial population chromosomes population evaluated ranked fitness value makespan smaller fitness value better mapping 
main loop entered roulette wheel scheme selection 
scheme probabilistically generates new populations better mappings higher probability surviving generation 
elitism property guaranteeing best solution remains population implemented 
crossover operation selects pair chromosomes chooses random point chromosome 
sections chromosomes point chromosome crossover exchanges machine assignments corresponding tasks 
chromosome considered crossover probability 
crossover mutation operation performed 
mutation randomly selects task chromosome randomly new machine 
random operations select values uniform distribution 
chromosome considered mutation probability 
chromosomes modified population evaluated 
completes iteration ga ga stops conditions met total iterations change elite chromosome iterations chromosomes converge 
stopping criteria met loop repeats selection new population 
stopping criteria usually occurred testing change elite chromosome iterations 
sa simulated annealing sa iterative technique considers possible solution mapping meta task time 
solution uses representation solution chromosome ga sa uses procedure probabilistically allows poorer solutions accepted attempt obtain better search solution space 
probability system temperature decreases iteration 
system temperature difficult poorer solutions accepted 
initial system temperature makespan initial mapping 
specific sa procedure implemented follows 
initial mapping generated uniform random distribution 
mapping mutated manner ga new makespan evaluated 
decision algorithm accepting rejecting new mapping 
new makespan better new mapping replaces old 
new makespan worse larger uniform random number selected 
compared old makespan makespan temperature new poorer mapping accepted rejected old mapping kept 
notice solutions similar makespans system temperature large poorer solutions easily accepted 
contrast solutions different makespans system temperature small poorer solutions usually rejected 
mutation system temperature decreased 
defines iteration sa 
heuristic stops change makespan iterations system temperature reaches zero 
tests ended change makespan iterations 
gsa genetic simulated annealing gsa heuristic combination ga sa techniques 
general gsa follows procedures similar ga outlined 
selection process gsa uses sa cooling schedule system temperature simplified sa decision process accepting rejecting new chromosomes 
specifically initial system temperature set average makespan initial population decreased iteration 
new post crossover chromosome compared corresponding original chromosome new makespan original makespan plus system temperature new chromosome accepted 
original chromosome survives iteration 
system temperature decreases difficult poorer solutions accepted 
stopping criteria change elite chromosome iterations total iterations 
common stopping criteria change elite chromosome iterations 
tabu tabu search solution space search keeps track regions solution space searched repeat search near areas 
solution mapping uses representation chromosome ga approach 
implementation tabu search begins random mapping generated uniform distribution 
starting task mapping task possible pair tasks formed gamma pair tasks formed exchange machine assignments 
constitutes short hop 
intuitive purpose short hop find nearest local minimum solution solution space 
exchange new makespan evaluated 
new makespan improvement new mapping accepted successful short hop pair generation exchange sequence starts new mapping 
pair generation exchange sequence continues previous state 
new short hops generated successful short hops combinations task pairs exhausted improvement 
point final mapping local solution space search added tabu list 
tabu list method keeping track regions solution space searched 
new random mapping generated differ mapping tabu list half machine assignments successful long hop 
intuitive purpose long hop move new region solution space searched 
final stopping criterion heuristic total successful hops short long combined best mapping tabu list final answer 
final heuristic comparison study known heuristic 
applied task allocation problems 
technique similar 
tree search root node usually null solution 
tree grows intermediate nodes represent partial solutions subset tasks assigned machines leaf nodes represent final solutions tasks assigned machines 
partial solution child node task mapped parent node 
call additional task parent node generates children possible mapping parent node done parent node removed replaced tree children 
keep execution time heuristic tractable maximum number nodes tree time limited study nmax 
node cost function associated 
cost function estimated lower bound makespan best solution includes partial solution represented node represent makespan task machine assignments partial solution node maximum machine availability times mat set tasks mapped machines node partial solution 
lower bound estimate difference makespan node partial solution makespan best complete solution includes node partial solution 
cost function node computed represents makespan partial solution node plus lower bound estimate time execute rest unmapped tasks meta task 
function defined terms functions different approaches deriving lower bound estimate 
recall fm min ct ug 
node maximum element maximum minimum completion time 
intuitively represents best possible meta task makespan making typically unrealistic assumption task assigned machine indicated conflict 
defined max gamma sum differences machine availability time machines executing tasks partial solution represented node gamma gamma mat intuitively represents amount machine availability time remaining scheduled increasing final makespan 
defined sum minimum expected execution times values tasks min gives estimate amount remaining increase final makespan 
function defined max gamma gamma represents estimate minimum increase meta task makespan tasks ideally general unrealistically distributed machines 
definitions max representing lower bound estimate time execute tasks root node replaced children nmax nodes created 
point time node added tree pruned deleting node largest 
process continues leaf node representing complete mapping reached 
note tree pruned method equivalent exhaustive search 

experimental results interactive software application developed allows simulation testing demonstration heuristics examined section applied meta tasks defined matrices described section 
software allows user specify select matrices choose heuristics execute 
generates specified matrices executes desired heuristics displays results similar figures 
results discussed section generated portions software 
comparing mapping heuristics execution time heuristics important consideration 
heuristics listed execution times varied greatly 
experimental results discussed obtained pentium ii mhz processor gb ram 
simpler heuristics olb fast greedy greedy executed seconds matrix 
sized matrix sa tabu manipulate single solution point time averaged seconds 
ga gsa required approximately seconds matrix manipulate entire populations required minutes matrix 
resulting meta task execution times makespans simulations case consistency task heterogeneity machine heterogeneity shown figures 
experimental results represent execution time meta task defined particular matrix mapping heuristic specified averaged different matrices type mappings 
heuristic range bars show minimum maximum meta task execution times mappings matrices compute average meta task execution time 
tables show sample subsections types inconsistent matrices considered 
semi consistent consistent matrices types generated matrices described section 
results described entirely new matrices generated case 
consistent cases figures algorithm worst execution times order magnitude 
easy explain 
consistent cases tasks lowest execution time machine tasks mapped particular machine 
corresponds results 
poor performance results included figures 
olb max min sa poorest results 
ga performed best consistent cases 
due part performance minmin heuristic 
best ga solution came populations seeded min min solution 
apparent figures minmin performed giving second best results 
mutation crossover selection operations ga able improve solution 
gsa minmin seed improve min min solution 
probabilistic procedure selection gsa accept poorer intermediate solutions 
poorer intermediate solutions led better final solutions gsa gave third best results 
performance hindered estimates accurate consistent cases inconsistent semi consistent cases 
consistent cases estimates competition machines estimates workload distributed machine 
results suggest best solution desired ga employed 
improvement ga solution min min solution 
minmin may appropriate certain situations difference execution times heuristics 
inconsistent test cases figures performs better performance olb degrades 
pattern consistency olb assign tasks poor worst case machines resulting poorer schedules 
contrast improves best machines distributed set machines task assignments evenly distributed set machines avoiding load imbalance 
similarly fast greedy min min performed slightly outperformed machines providing best task completion times evenly distributed set machines 
min min better max min inconsistent cases 
advantages min min gains mapping best case tasks outweighs savings penalties max min mapping worst case tasks 
tabu gave second poorest results inconsistent cases poorer heuristics 
inconsistent matrices generated successful short hops associated consistent matrices 
fewer long hops generated solution space searched resulting poorer solutions 
increased number successful short hops inconsistent matrices explained follows 
pairwise comparison procedure short hop procedure assign machines better performance early search procedure 
consistent cases machines set machines 
inconsistent cases machines machine 
consistent cases search somewhat ordered successful short hops get exhausted faster 
inconsistent cases lack order means successful short hops resulting fewer long hops 
ga best average execution times usually small constant factor 
random approach employed methods useful helped overcome difficulty locating mappings inconsistent matrices 
ga benefited having min min initial mapping 
tasks get evenly distributed machines closely matches lower bound estimates 
consider semi consistent cases figures 
semi consistent cases high machine heterogeneity heuristic gave worst results 
intuitively suffering problem consistent cases half tasks getting assigned machine 
olb poorly high machine heterogeneity cases worst case matchings higher execution times high machine heterogeneity 
low machine heterogeneity worst case matchings lower penalty 
best heuristics cases min min ga surprising best heuristics consistent inconsistent tests matrices combination consistent inconsistent matrices 
min min able searched entire row task assigned high percentage tasks choice 
ga robust handle consistent components matrices reasons mentioned inconsistent matrices 
tabu search performed nearly low machine heterogeneity cases slightly worse high machine heterogeneity cases similar olb 
semi consistent low machine heterogeneity cases closer consistent tabu performs semi consistent high machine heterogeneity cases similar inconsistent matrices tabu performance poor 

alternative implementations experimental results section show performance heuristic assumptions 
heuristics specific control parameter values control functions selected 
cases control parameter values control functions cited experi ments conducted 
heuristics different valid implementations possible different control parameters control functions 
ga sa gsa parameter values varied techniques including appropriate population size crossover probability mutation probability stopping criteria number runs different initial populations result system temperature 
specific procedures actions modified appropriate including initial population seed generation mutation crossover selection elitism accept reject new mapping procedure 
tabu short hop method implemented descent take improvement possible method 
steepest descent methods short hops considered simultaneously improvement selected practice 
techniques varied long hop method order short hop pair generation exchange sequence stopping condition 
possible alternative stopping criteria tabu list reaches specified number entries change best solution specified number hops 
variations method employed implemented 
different functions estimate lower bound 
maximum size search tree varied techniques exist tree pruning 
summary ga sa gsa tabu heuristics great number possible valid implementations 
attempt reasonable implementation heuristic study 
examine implementations 

goal study provide basis comparison insights circumstances technique perform eleven different heuristics 
characteristics matrices input heuristics methods generate specified 
implementation collection eleven heuristics literature described 
results mapping heuristics discussed revealing best heuristics certain scenarios 
situations implementations parameter values ga best heuristic cases followed closely min min doing inconsistent matrices 
software tool developed allows compare heuristics different types matrices 
heuristics basis mapping toolkit 
toolkit matrix representing actual meta task actual hc environment toolkit analyze matrix utilize best mapping heuristic scenario 
depending situation execution time mapping heuristic may impact decision 
example best mapping available minute desired characteristics matrix closely matched consistent matrix min min time available finding best mapping ga considered 
comparisons eleven heuristics twelve situations provided study researchers starting point choosing heuristics apply different scenarios 
researchers selecting heuristics compare new developing techniques 
acknowledgments authors ali comments 
armstrong hensgen kidd relative performance various mapping algorithms independent sizable variances run time predictions th ieee heterogeneous computing workshop hcw mar pp 

armstrong investigation effect different run time distributions smartnet performance thesis department computer science naval postgraduate school monterey ca sept hensgen advisor 
braun siegel beck maheswaran robertson yao taxonomy describing matching scheduling heuristics heterogeneous computing systems ieee workshop advances parallel distributed systems appear oct 
chen flann watson parallel genetic simulated annealing massively parallel simd approach ieee transactions parallel distributed computing vol 
feb pp 

chow liu mapping signal processing algorithms heterogeneous multiprocessor system international conference acoustics speech signal processing icassp vol 
may pp 

coli real time pipelined system design simulated annealing journal systems architecture vol 
dec pp 

de del vaccaro improving search incorporating evolution principles parallel tabu search ieee conference evolutionary computation vol 
pp 

fernandez allocating modules processors distributed system ieee transactions software engineering vol 
se nov pp 

freund campbell hensgen keith kidd lima moore rust siegel scheduling resources multi user heterogeneous computing environments smartnet th ieee heterogeneous computing workshop hcw mar pp 

freund siegel heterogeneous processing ieee computer vol 
june pp 

yang distributed heterogeneous supercomputing management system ieee computer vol 
june pp 

glover laguna tabu search kluwer academic publishers boston ma june 
prasanna wang heterogeneous computing challenges opportunities ieee computer vol 
june pp 

ibarra kim heuristic algorithms scheduling independent tasks processors journal acm vol 
apr pp 

ahmad optimal task assignment heterogeneous distributed computing systems ieee concurrency vol 
july sept pp 

kirkpatrick gelatt jr vecchi optimization simulated annealing science vol 
may pp 

maheswaran braun siegel heterogeneous distributed computing encyclopedia electrical electronics engineering webster ed john wiley sons new york ny appear 
scheduling theory algorithms systems prentice hall englewood cliffs nj 
rudolph convergence analysis canonical genetic algorithms ieee transactions neural networks vol 
jan pp 

russell norvig artificial intelligence modern approach prentice hall englewood cliffs nj 

shen 
tsai graph matching approach optimal task assignment distributed computing system minimax criterion ieee transactions computers vol 
mar pp 

watson flann freund genetic simulated annealing scheduling tasks heterogeneous environments th ieee heterogeneous computing workshop hcw april pp 

siegel dietz antonio software support heterogeneous computing computer science engineering handbook tucker jr ed crc press boca raton fl pp 

singh youssef mapping scheduling heterogeneous task graphs genetic algorithms th ieee heterogeneous computing workshop hcw apr pp 

srinivas genetic algorithms survey ieee computer vol 
june pp 

wang siegel roychowdhury task matching scheduling heterogeneous computing environments genetic algorithm approach journal parallel distributed computing vol 
nov pp 

biographies tracy braun phd student research assistant school electrical computer engineering purdue university 
received bachelor science electrical engineering honors high distinction university iowa 
received school electrical computer engineering purdue university 
received benjamin fellowship purdue university academic year 
member ieee ieee computer society eta kappa nu society 
active member beta chapter eta kappa nu purdue university held offices studies purdue including chapter president 
employed data systems silicon graphics cray research 
research interests include parallel algorithms heterogeneous computing computer security software design 
siegel professor school electrical computer engineering purdue university 
fellow ieee fellow acm 
received bs degrees electrical engineering management mit ma mse phd degrees department electrical engineering computer science princeton university 
prof siegel coauthored technical papers volumes wrote book interconnection networks large scale parallel processing 
chief journal parallel distributed computing editorial boards ieee transactions parallel distributed systems ieee transactions computers 
program chair chair conferences general chair chair conferences chair chair workshops 
international keynote speaker tutorial lecturer consultant government industry 
noah beck research assistant student purdue university school electrical computer engineering 
received bachelor science computer engineering purdue university active member beta chapter eta kappa nu society 
employed intel research interests include microprocessor architecture parallel computing heterogeneous computing 
phd student research assistant computer sciences department purdue university 
received diploma engineer degree computer engineering honors technical university romania 
received fellowship hungarian academy sciences academic year 
member acm upsilon pi epsilon society 
research interests include distributed object systems autonomous agents parallel computing 
maheswaran assistant professor department computer science university manitoba canada 
received bsc degree electrical electronic engineering university sri 
received degree phd degree school electrical computer engineering purdue university 
held fulbright scholarship tenure student purdue university 
research interests include computer architecture distributed computing heterogeneous computing internet world wide web systems metacomputing mobile programs network computing parallel computing resource management systems metacomputing scientific computing 
authored coauthored technical papers related areas 
member eta kappa nu society 
albert james robertson currently works motorola powerpc system performance modeling group 
received bachelor science computer engineering honors school electrical computer engineering purdue university 
undergraduate student received nsf undergraduate research scholarship 
received purdue university 
member ieee ieee computer society eta kappa nu society 
attending purdue university active member beta chapter eta kappa nu having held offices including chapter 
mitchell phd student research assistant school electrical computer engineering purdue university 
received bachelor science computer electrical engineering highest distinction master science electrical engineering purdue 
received support benjamin fellowship purdue university intel graduate fellowship graduate fellowship 
member eta kappa nu society ieee ieee computer society 
elected president beta chapter eta kappa nu purdue university held various offices stay purdue 
held positions compaq computer lawrence livermore national laboratory 
research interests include design single chip parallel machines heterogeneous computing parallel processing software hardware design 
bin yao phd student research assistant school electrical computer engineering purdue university 
received bachelor science electrical engineering beijing university 
received andrews fellowship purdue university academic years 
student member ieee 
research interests include distributed algorithms fault tolerant computing heterogeneous computing 
debra hensgen associate professor computer science department naval postgraduate school 
received phd area distributed operating systems university kentucky 
currently principal investigator darpa sponsored management system heterogeneous networks quorum project mshn investigator darpa sponsored server active agent management saam generation internet project 
areas interest include active modeling resource management systems network re routing preserve quality service guarantees visualization tools performance debugging parallel distributed systems methods aggregating sensor information 
published numerous papers concerning contributions toolkit automatically generating safe efficient concurrent code graze parallel processing performance debugger saam path information base smartnet mshn resource management systems 
richard freund tracy braun phd student research assistant school electrical computer engineering purdue university 
received bachelor science electrical engineering honors high distinction university iowa 
received school electrical computer engineering purdue university 
received benjamin fellowship purdue university academic year 
member ieee ieee computer society eta kappa nu society 
active member beta chapter eta kappa nu purdue university held offices studies purdue including chapter president 
employed data systems silicon graphics cray research 
research interests include parallel algorithms heterogeneous computing computer security software design 
tracy braun phd student research assistant school electrical computer engineering purdue university 
received bachelor science electrical engineering honors high distinction university iowa 
received school electrical computer engineering purdue university 
received benjamin fellowship purdue university academic year 
member ieee ieee computer society eta kappa nu society 
active member beta chapter eta kappa nu purdue university held offices studies purdue including chapter president 
employed data systems silicon graphics cray research 
research interests include parallel algorithms heterogeneous computing computer security software design 
initial population generation evaluation stopping criteria met selection crossover mutation evaluation 
general procedure genetic algorithm 
consistent high task high machine heterogeneity olb fast greedy min min max min greedy ga sa gsa tabu trials tasks machines 
consistent high task high machine heterogeneity 
consistent high task low machine heterogeneity olb fast greedy min min max min greedy ga sa gsa tabu trials tasks machines 
consistent high task low machine heterogeneity 
consistent low task high machine heterogeneity olb fast greedy min min max min greedy ga sa gsa tabu trials tasks machines 
consistent low task high machine heterogeneity 
consistent low task low machine heterogeneity olb fast greedy min min max min greedy ga sa gsa tabu trials tasks machines 
consistent low task low machine heterogeneity 
inconsistent high task high machine heterogeneity olb fast greedy min min max min greedy ga sa gsa tabu trials tasks machines 
inconsistent high task high machine heterogeneity 
inconsistent high task low machine heterogeneity olb fast greedy min min max min greedy ga sa gsa tabu trials tasks machines 
inconsistent high task low machine heterogeneity 
inconsistent low task high machine heterogeneity olb fast greedy min min max min greedy ga sa gsa tabu trials tasks machines 
inconsistent low task high machine heterogeneity 
inconsistent low task low machine heterogeneity olb fast greedy min min max min greedy ga sa gsa tabu trials tasks machines 
inconsistent low task low machine heterogeneity 
semi consistent high task high machine heterogeneity olb fast greedy min min max min greedy ga sa gsa tabu trials tasks machines 
semi consistent high task high machine heterogeneity 
semi consistent high task low machine heterogeneity olb fast greedy min min max min greedy ga sa gsa tabu trials tasks machines 
semi consistent high task low machine heterogeneity 
semi consistent low task high machine heterogeneity olb fast greedy min min max min greedy ga sa gsa tabu trials tasks machines 
semi consistent low task high machine heterogeneity 
semi consistent low task low machine heterogeneity olb fast greedy min min max min greedy ga sa gsa tabu trials tasks machines 
semi consistent low task low machine heterogeneity 
machines table 
sample theta excerpt inconsistent high task high machine heterogeneity 
machines table 
sample theta excerpt inconsistent high task low machine heterogeneity 
machines table 
sample theta excerpt inconsistent low task high machine heterogeneity 
machines table 
sample theta excerpt inconsistent low task low machine heterogeneity 

