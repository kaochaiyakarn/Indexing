communication reduce locality distributed multi agent learning maja matari computer science department university southern california west th place sal mc los angeles ca mataric cs usc edu attempts bridge fields machine learning robotics distributed ai 
discusses communication reducing undesirable effects locality fully distributed multi agent systems multiple agents robots learning parallel interacting 
key problems hidden state credit assignment addressed applying local undirected broadcast communication dual role sensing reinforcement 
methodology demonstrated multi robot learning experiments 
describes learning tightly coupled coordination task robots second loosely coupled task robots learning social rules 
communication share sensory data overcome hidden state share reinforcement overcome credit assignment problem agents bridge gap local individual global group payoff 
attempts bridge fields machine learning robotics distributed ai 
describes simple communication methods ap plied enable speed learning complex noisy situated multi agent systems 
domains question permit reliance complex communication protocols significantly manageable minimalist communication schemes require additional alteration learning framework 
describe schemes apply reduce undesirable effects locality fully distributed multi agent systems multiple concurrent learning agents 
focuses simple communication methods deal key problems hidden state credit assignment 
hidden state problem arises situated agents typically sense relevant information necessary completing task learning perform efficiently 
credit assignment problem arises reinforcement distributed system provided global level divided multiple agents impact differs varies time 
problems addressed simple strategies apply communication dual role sensing reinforcement case local undirected broadcast 
cases communication treated manner consistent sensory inputs requires additional overhead 
demonstrate methodology multi robot learning experiments 
describes robots learning tightly coupled coordination task box pushing communication sharing sensory data overcome hidden state reinforcement data overcome credit assignment problem agents 
second experiment describes loosely coupled task robots learning social rules yielding sharing information communication share social reinforcement order bridge gap global group local individual payoff 
cases role communication locally space time increase scope impact single agent 
communication serves effectively cluster agents period time tightly interacting 
effect making system temporarily locally distributed consequently alleviates hidden state credit assignment problems inherent distributed multi agent learning 
organized follows 
section defines key terms concerning communication cooperation 
section addresses simple communication means sensing enlarging agent perceptual space capabilities cooperation learning 
section focuses communication reinforcement addressing credit assignment problem reducing locality agents actions 
section describes robot experiments demonstrates communication enable robots learn tightly coupled cooperation task 
section describes second robot experiment roots learn social rules yielding sharing information 
section discussed results section overviews related section concludes 
communication cooperation definitions communication common means interaction intelligent agents 
observable behavior consequences interpreted form communication 
purposes clarity introduce definitions scope 
direct communication purely communicative act sole purpose transmitting information speech act transmission radio message 
specifically directed communication direct communication aimed particular receiver 
directed communication cases receivers identified 
contrast indirect communication observed behavior communication agents effects environment 
type communication referred stigmergic biological literature refers communication modifications environment direct message passing 
direct indirect communication practiced species nature 
example bees signals dance sole purpose transmitting information recruiting 
contrast cues direction flight transmit hive information product behaviors 
cooperation form interaction usually communication 
certain types cooperative behavior depend directed communication 
specifically cooperative behaviors require negotiation agents depend directed communication order assign particular tasks participants 
analogously communication explicit cooperation defined set interactions involve exchanging information performing actions order benefit agent 
contrast implicit cooperation consists actions part agent goal achieving behavior repertoire effects world help agents achieve goals 
order study role communication controlled fashion explore communication needed group behaviors studying adopted minimalist approach 
directed communication agents experiments 
indirect communication sensing external state neighboring agents sensing density effects actions 
direct communication undirected limited local broadcast agents transmit messages received near 
agents ability choose receivers messages engage directed communication 
show simple form communication powerful mechanism aiding various aspects learning distributed multi agent system 
communication sensing lack accurate reliable sensors arguably common complaint researchers situated agent control learning 
robotics particular sensors targeted limiting factors way progress complex autonomous behavior 
commonly sensors provide noisy data difficult accurately characterize model presenting major challenge real time robot learning matari 
multi agent perspective ability sense correctly distinguish members group obstacles various features environment crucial tasks 
inability distinctions preclude symbiotic relationships axelrod lack sophisticated perceptual discrimination critical limitation multi robot 
non visual sensors infra red contact sensors sonars limited social recognition task 
vision typically offers best discrimination capabilities traditional image analysis involves computational overhead prohibitive collection moving dynamically interacting robots 
effective low overhead approaches robot vision imple mented single robots horswill scaled groups 
inability obtain sufficient sensory information properly discriminate results perceptual aliasing hidden state problem whitehead ballard 
due sensory limitations multiple world states perceived input state inducing serious problems learning domain 
problems particularly acute multi agent robot domains behavior system result interactions agents limitations amplified 
viewed form sensing communication multi agent systems effectively deal hidden state problem 
sensors radio receivers microphones perceive signals messages communicated pass processing 
specific properties sensors vary greatly differences usefully exploited information difficult directly sense visually discriminate easily communicated tradeoff frequently biological systems wehner 
demonstrate agents locally broadcast elements state may difficult impossible access significant advantage learning scenario 
important keep mind communication suffers similar noise inaccuracy properties sensors messages may corrupted dropped received order 
features may play key role disembodied multi agent impact multi robot learning strongly discussed 
communication reinforcement key challenge distributed multi agent systems achieve group level coherence 
coherence best guaranteed top control requires prohibitive computational overhead scales poorly increased group size 
central controller maintain updated information entire group perform optimizations global state space send commands group necessary information typically available computation completed real time communication imposes significant bottleneck matari 
completely distributed alternatives agents learn independently concurrently scale better turn introduce difficulties non stationary environments credit assignment problem 
group agents learning parallel creates non stationary world agents learn behavior changes resulting inconsistencies 
furthermore multi agent systems face credit assignment problem level individual level group 
individual level interaction agents delays agent payoff temporal credit assignment problem 
group level local individual behavior appropriately associated global outcomes 
describe communication reinforcement strategy enables agents locally share reward order overcome credit assignment problem levels 
effect locally sharing reinforcement agents decreases locality learning system 
summary argued communication effectively treated part input state 
complementary direct sensing similarly abstracted similar noise properties effectively augmenting agent sensory space 
furthermore communication powerful source reinforcement appropriately bias shape agent reward function 
rest illustrates communication examples multi robot learning 
addresses communication extend local sensing robots impacting hidden state credit assignment problem 
second addresses communication share reinforcement impacting credit assignment individual group levels 
cases communication extends individual sensing action reinforcement binding agents locally short amount time behavior immediately related 
simple idea powerful effect distributed learning 
communication shared sensing section describes communication handle hidden state credit assignment experiment pairing mobile robots concurrently learning perform box pushing task 
achievement task requires tightly coupled coordination box chosen large agents push goal 
ii legged robots learn cooperative equipped whiskers detecting contact box sensors detecting light goal radios communication 
agents legged mobile robots equipped radio communication mechanism whiskers detect contact box array sensors detect direction goal marked bright light 
sensors provide information robots absolute location relative location box 
furthermore available sensory information noisy detailed sensory characteristics provided 
goal learning experiment robots automatically discover strategy allows coordinate efforts coherent policy capable delivering box goal regardless initial positions robots box robots inability directly sense movement box 
experiment set reinforcement learning rl framework robots learning reactive mapping sensory perceptions repertoire pre programmed fixed duration behaviors reinforcement received time kaelbling 
sensory data inputs whiskers light sensors 
whiskers returned bit contact contact value probed 
light sensors consisted curved array units centered front robot position maximum brightness max pyro returned sensor probed 
behavior repertoire consisted ffl find box move forward whiskers detects contact turn direction whiskers detect contact ffl push forward move forward maintaining contact whiskers ffl push left turn left pushing accomplished smaller steps left legs ffl push right turn right pushing accomplished smaller steps right legs ffl send msg broadcast max pyro value radio ffl 
reinforcement learning algorithm summed reward punishment values time 
values computed changes direction goal 
moving sensors facing light turning intense light generated internal reward turning away light generated internal punishment 
reinforcement identical magnitude opposite sign reward punishment signals 
reinforcement computed completion behavior reinforce perception behavior pair 
system maintained updated table perception behavior values dynamically compute policy 
algorithm employed discounting system learning purely reactive pushing policy 
completion behavior computation reinforcement behavior activated 
behavior selection algorithm chose best behavior table time random behavior time 
merely servoing light box simple 
communication key making task learnable robots having large box incomplete sensing distinguish direction relative light orientation box agent 
communication robots combine sensory data get information points box 
result hidden state problem case solved having agents pool sensory resources 
general pooling sensory resources agents task equivalent centralized control approach 
fortunately task require level communication decomposable concurrent subtasks 
robot experiment demonstrates tightly coupled sub tasks require communication overcome sensory deficiencies 
alternative solutions employ robots powerful sensors donald jennings rus larger group robots looser communication information sharing requirements demonstrated second robot experiment section 
challenge task finding joint robot actions result appropriate coordinated state action mapping task 
multi agent credit assignment problem arises box getting closer goal actions responsible progress 
agents rewarded 
agent undoing 
way solving problem communication agent tells action perform take coordinated actions observe outcomes share subsequent reward punishment 
side effect communication synchronizes actions ensuring coordinated movement 
note guarantee agents move synchrony behaviors exactly time accuracy capabilities robots noisy communication control mechanisms 
synchronization provided communication mechanism coarse signal provides sufficient information initiate terminate behaviors 
coarseness signaling implies exact duration behavior execution may vary effect system performance 
points important illustrate sparse minimal communication effectively employed augmentation basic sensing behavior system 
described far robots learning policy perceptual inputs motor outputs 
learning system complex 
experiments robots learned behaviors execute communicate 
pre programmed send msg behavior enabled communicate sensory information learning language order overcome hidden state problem 
addition built capability robots learned choose pooled sensory data action take described action communicate robot 
robot learned functional mapping combined perceptual states best behaviors action agent action 
resulting policy table consisted combined amy theta case js combined theta 
desired policy learned robots trials average learned minutes contiguous turns 
details experimental trials described matari 
order learning converge robots took turns controlling box 
alternative solution establish master slave system robots learning commanding actions 
intrinsic differences sensor effector characteristics robots opted scheme favor 
coarse turn easily accomplished communication channel effectively alleviated credit assignment problem robots 
behaviors executed robot compute reinforcement directly updated combined sensory data 
robots shared identical internal reinforcement functions received identical reinforcement modulo sensory communication noise 
strategies learned robots identical depended side box robot happened 
learned handed strategy left right 
specialization generalized single variable representing box side 
learning task communication effective extending individual agent local incomplete view world part comes near agent sensors actions involved solving shared task 
experiment involving larger group robots demonstrates idea communication tie spatially local agents important uses learning larger loosely coupled groups frequent completely asynchronous communication behavior 
communication shared reward section describes communication handle hidden state credit assignment experiment featuring mobile robots concurrently learning non greedy social rules dealing yielding shar ing information location pucks collecting 
robots equipped infra red sensors obstacle puck detection bump sensors position sensors radios communication 
sensors noisy error prone provide information robots external state behavior 
previous experiment robots pre programmed simple behaviors enabled collect pucks pickup drop go home wander follow avoid send messages send msg 
experiment form messages broadcast small amounts information case communication done asynchronously content messages quite different described 
goal experiment robots improve individual puck collecting behavior learning yield proceed send message sharing information location pucks follow received message location communicated 
experiment set reinforcement learning rl framework robots learning functional mapping sensory perceptions behavior repertoire 
table situation behavior pairs maintained robot behavior selection algorithm chose best behavior time random behavior time follow msg behavior time 
behavior induced robot follow received message 
sensors group robots included infra red bump position communication inputs clustered set predicates puck home near pucks near near indicating robot puck gripper home region area pucks deposited near source pucks reasonable proximity near robot 
behaviors learning subset enabling social rules part learning system send msg proceed 
perceptual conditions rest behaviors fixed previous learning experiments matari 
consequently robots need learn collect pucks need learn social efficient fashion 
learning social rules scenario difficult due delayed reinforcement credit assignment problem agents 
reinforce robotics robots learn yield top robots communicate location pucks bottom robots equipped infra red sensors obstacle puck detection bump sensors position sensors radios communication 
ment learning paradigm agent tries maximize payoff time 
social behaviors communicating puck location increase agent payoff behaviors yielding may decrease delaying preventing reward 
difficult individual agents learn social rules having centrally imposed pre programmed advocated game theoretic axelrod 
experiments demonstrated simple communication spatially local agents described social rules learned 
communication channel provide payoff generate reinforcement observing behavior near agent mimicking 
way relating near agents behavior effective means learning social rules 
observing agents behavior difficult perceptual task easily solved communication robots broadcast limited area perceptual range behavior performing reinforcement receiving 
note potentially sensed richer sensory apparatus camera clever processing typically 
message communication replaces augment sensors information cases sensed trivially communicated 
communicating external state behavior internal state reinforcement locally interacting agents dual effect 
information allows robot select observed behavior imitate vicarious reinforcement decreasing need experimentation 
key assumption positive reinforcement consistent agents assumption holds spatial temporal locality shared information 
robots nearly place time receive reinforcement actions 
second addition encouraging social behaviors communicating sharing reinforcement provides payoff social actions yielding benefit agent directly 
implementation robot yields reaches goal receives reinforcement directly shares reinforcing social behavior 
sharing performed communicating reward 
near robots observed yielding behavior received payoff impetus imitate learn 
learning send messages works identical fashion 
robot finds pucks communicates location near agents perceive information move location find pucks receive share reward 
mapping finding pucks sending message reinforced mapping receiving message 
locally sharing information sufficient enable group learn social behaviors close robots yielded food broadcast information received message location executing behavior followed message location proceeded yielded 
desired social policy yielding sharing information learned robots trials average learned minutes 
mutual yielding symmetries broken noise inherent robots sensing actuation 
obeying social rules resulted better performance group compared non social individually greedy system 
result comparisons measured total collection time fixed number pucks group multiple trials 
experiment learning task communication extend agent local incomplete view world 
experiment sensory information shared reinforcement individual case sensory information individual reinforcement shared 
described method demonstration addressing multi agent credit assignment problem communication 
communication method local independent group size scales 
broadcasting behavior reinforcement simple implement proved robust presence noise minimal amount radio filtering 
corrupted messages largely detected ignored 
lost messages rare broadcast fixed number times 
lost omission effect slowing learning sensor noise 
confined area robots encountered high frequency exposed social conditions facilitated learning 
discussion noisy asynchronous dynamic worlds multi robot multi agent systems simple forms communication help address important stumbling blocks way system adaptability 
described utilizes simple built communication strategies compensate sensory limitations exploit message passing broader form sensing reinforcement 
robot learning known difficult problem mahadevan kaelbling multi robot learning challenging instance combines issues learning robots multi agent systems 
applied simplifying strategies learning problem manageable largely individual robot level 
include behaviors higher level descriptions action experiments combinations sensory values higher level predicates second experiment 
combination effectively collapses potentially prohibitively large exponential search space learning system 
pros cons approach described length matari relevant key message focuses effective communication 
experiment communicated pre programmed resulting control policy learned 
sensory effector noise inherent physical systems particular experimental robots strategy allows learning system initially helped communication capability discover adapt control policy time 
controller coordinated box pushing robots may impossible program demonstrated learning time presents viable certainly adaptive alternative 
second experiment communicated control policy learned 
better argument scaling properties local broadcast communication 
argued earlier learning social rules prohibitively time consuming may unintuitive programming task distributed system 
approach biases learning system smaller state space allows learn rules autonomously 
system sufficient sensing control complexity mobile robots built bias crucial order enable system learn higher level including group behavior social rules 
multi robot learning demonstrations performed date tended direction discussed section 
related described applies concepts machine learning ml distributed ai dai robotics 
problems hidden state credit assignment dealt extensively ml literature mccallum sutton 
whitehead analyzed cooperative rl mechanisms littman markov games framework simulated rl soccer playing agents 
tan applied rl simulated hunter prey scenario agents communication exchange instantaneous information experiments episodic learned knowledge 
communication multi agent cooperation addressed applied multi agent yanco stein dudek jenkin milios wilkes 
dai learning related contributions area studying multiple simulated reinforcement learners see collection weiss sen applied robotics multi robot learning identified area addressed mahadevan kaelbling 
robot learning mahadevan connell focused state generalization controller modularity applied sonar robot learning push box experiment complementary addresses problem similar approach introduces communication extend multi robot domain 
cooperative robot pushing addressed control donald 
demonstrated non learning robot sofa moving system powerful sensors eliminate need communication 
contrast uses communication compensate robots sensory limitations facilitate learning 
previous matari treated learning multi robot system introduced behaviors associated conditions means state space reduction applied described 
previous focused internal progress estimators address temporal credit assignment problem agent individually communication 
contrast parker addressed issue coordinating loosely coupled group foraging robots described communication combine abilities heterogeneous agents order complete cooperative task efficiently 
asada hosoda asada hosoda related papers address case interacting competing agents apply related behavior reinforcement learning ideas learning aspects soccer multi robot environment 
del address homogeneous foraging problem simulation learning activate behaviors limited communication agents reinforcement time complete task entire group 
approach similar requires collective reinforcement signal possible distributed multi agent domains aggravates temporal spatial credit assignment problem 
goal draw ideas machine learning robotics dai order deal problems learning distributed multiagent systems hidden state agents sense relevant information credit assignment difficult distribute reinforcement multiple concurrently acting agents 
described simple communication local broadcast address problems illustrated ideas multi robot demonstrations 
robots learn cooperatively push box communicating sen readings second robots learn social rules yielding sending information communication share reinforcement 
cases communication treated sensory inputs requiring additional processing overhead departure reinforcement learning framework 
principle effect described limited broadcast communication schemes temporarily bind spatially local agents 
idea utilizes simple communication temporarily decrease system just robots near point time 
demonstrated different domains tightly coupled task pooled sensory information coarsely bound agents coarse common action synchronizer loosely coupled task local exchange internal state information enabled distributed group robots learn social rules spite temporal spatial credit assignment problem 
simple idea local broadcast scales particularly suitable noisy dynamic domains agents interact incomplete sensory information 
environments abound robotics communication may compensate limitations direct sensory modalities enabling learning multi robot systems 
acknowledgments described supported office naval research nsf infrastructure cda 
box pushing learning performed swedish institute computer science collaboration kristian martin nilsson 
author francois suggestion write detailed insightful discussions preparation anonymous reviewers constructive comments 

initial results inter robot communication multiple mobile robotic system proceedings ijcai workshop dynamically interacting robots chambery france pp 

asada hosoda 
agents learn competitive agents proceedings machine learning conference workshop agents learn agents 
axelrod 
evolution cooperation basic books ny 
donald jennings rus 
information invariants cooperating autonomous mobile robots proc 
international symposium robotics research hidden valley pa dudek jenkin milios wilkes 
utility multiagent autonomous robot systems proceedings ijcai workshop dynamically interacting robots chambery france pp 

horswill 
specialization perceptual processes phd thesis mit 
kaelbling 
learning embedded systems phd thesis stanford university 
littman 
markov games framework multi agent reinforcement learning cohen hirsh eds proceedings eleventh international conference machine learning ml morgan kauffman publishers new brunswick nj pp 

mahadevan connell 
automatic programming robots reinforcement learning proceedings aaai pittsburgh pa pp 

mahadevan kaelbling 
national science foundation workshop reinforcement learning ai magazine 
matari 
reward functions accelerated learning cohen hirsh eds proceedings eleventh international conference machine learning ml morgan kauffman publishers new brunswick nj pp 

matari 
issues approaches design collective autonomous agents robotics autonomous systems 
matari 
reinforcement learning multi robot domain autonomous robots 
mccallum 
learning selective attention short term memory sequential tasks maes matari 
meyer pollack wilson eds animals animats proceedings fourth international conference simulation adaptive behavior mit press pp 

del 
learning signaling behaviors specialization cooperative agents adaptive behavior 
parker 
learning cooperative robot teams proceedings ijcai workshop dynamically interacting robots chambery france pp 


honey bee colony superorganism american scientist 
matari 
learning cooperate legged mobile robots proceedings third european workshop learning robots heraklion crete greece 
sutton 
machine learning special issue reinforcement learning kluwer academic publishers boston 
tan 
multi agent reinforcement learning independent vs cooperative agents proceedings tenth international conference machine learning amherst ma pp 

asada hosoda 
strategy classification multi agent applying reinforcement soccer agents proceedings workshop robocup soccer problem agent systems 
wehner 
matched filters neural models external world journal computational physiology 
weiss sen 
adaptation learning multi agent systems lecture notes artificial intelligence vol 
springer verlag 
whitehead 
complexity analysis cooperative mechanisms reinforcement learning proceedings aaai pittsburgh pa whitehead ballard 
active perception reinforcement learning proceedings seventh international conference machine learning austin texas 
yanco stein 
adaptive communication protocol cooperating mobile robots 
meyer roitblat wilson eds animals animats international conference simulation adaptive behavior mit press pp 


