incremental clustering dynamic information retrieval moses charikar chandra chekuri tom feder rajeev motwani motivated applications document image classification information retrieval consider problem clustering dynamic point sets metric space 
propose model called incremental clustering careful analysis requirements information retrieval application useful applications 
goal efficiently maintain clusters small diameter new points inserted 
analyze natural greedy algorithms demonstrate perform poorly 
propose new deterministic randomized incremental clustering algorithms provably performance 
complement positive results lower bounds performance incremental algorithms 
consider dual clustering problem clusters fixed diameter goal minimize number clusters 
consider problem sequence points metric space efficiently maintain clustering points minimize maximum cluster diameter 
problems arise variety applications particular document image classification department computer science stanford university stanford ca 
mail moses cs stanford edu 
supported nsf award ccr matching funds ibm mitsubishi schlumberger foundation shell foundation xerox 
department computer science stanford university stanford ca 
mail chekuri cs stanford edu 
supported nsf award ccr matching funds ibm mitsubishi schlumberger foundation shell foundation xerox 
mail tomas theory stanford edu department computer science stanford university stanford ca 
mail rajeev cs stanford edu 
supported alfred sloan research fellowship ibm faculty partnership award aro muri daah nsf young investigator award ccr matching funds ibm mitsubishi schlumberger foundation shell foundation xerox 
information retrieval 
propose model called incremental clustering primarily requirements information retrieval application model relevant applications 
analyzing natural greedy algorithms discover perform poorly setting 
identify new deterministic randomized algorithms provably performance 
complement positive results lower bounds performance incremental algorithms 
consider dual clustering problem clusters fixed diameter goal minimize number clusters 
describing results greater detail motivate formalize new model 
clustering data analysis classification wide variety application 
proved particularly important tool information retrieval constructing taxonomy corpus documents forming groups closely related documents 
purpose distance metric imposed documents enabling view points metric space 
central role clustering application captured called cluster hypothesis documents relevant query tend similar irrelevant documents clustered 
typically clustering accelerate query processing considering small number representatives clusters entire corpus 
addition classification suggested method facilitating browsing :10.1.1.34.6746
current information explosion fueled availability hypermedia world wide web led generation increasing volume data posing growing challenge information retrieval systems efficiently store retrieve information 
major issue document databases facing extremely high rate update 
practitioners complained existing clustering algorithms suitable maintaining clusters dynamic environment problem updating clusters frequently performing complete reclustering 
theoretical perspective different formulations possible dynamic clustering problem clear priori best addresses concerns practitioners 
careful study requirements propose model described 
hierarchical agglomerative clustering 
clustering strategy employed universally information retrieval hierarchical agglomerative clustering hac 
popular applications biology medicine image processing geographical information systems 
basic idea initially assign input points distinct clusters repeatedly merge pairs clusters number sufficiently small 
instantiations proposed implemented differing mainly rule deciding clusters merge step 
note hac computes hierarchy trees clusters called leaves individual points internal nodes correspond clusters formed merging clusters children 
key advantage trees permit refinement responses queries moving hierarchy 
typically internal nodes labeled indexing information called conceptual information processing queries associating semantics clusters browsing 
experience shows hac performs extremely terms efficiency cluster quality 
dynamic setting desirable retain hierarchical structure ensuring efficient update high quality clustering 
important goal avoid major modifications clustering processing updates extensive recomputation index information swamp cost clustering 
input size typical applications super quadratic time impractical fact desirable obtain close linear time 
model incremental clustering 
various measures distance documents proposed literature concern details thereof purposes suffices note distance measures induce metric space 
documents usually represented high dimensional vectors stronger assumption arbitrary metric space see results improve geometric spaces 
formally clustering problem points metric space partition points clusters minimize maximum cluster diameter 
diameter cluster defined maximum inter point distance 
objective function chosen maximum cluster radius 
euclidean spaces radius denotes radius minimum ball enclosing points cluster 
extend notion radius arbitrary metric spaces select center point cluster radius defined maximum distance center point cluster 
assume diameter measure default 
define incremental clustering problem follows update sequence points maintain collection clusters input point assigned current clusters starts new cluster existing clusters merged 
define performance ratio incremental clustering algorithm maximum update sequences ratio maximum cluster diameter radius optimal clustering input points 
model enforces requirement times incremental algorithm maintain hac points time 
algorithm free rule choosing clusters merge step 
model preserves desirable properties hac providing clean extension dynamic case 
addition observed incremental algorithms exhibit paging performance clusters stored secondary storage cluster representatives preserved main memory 
avoided labeling model online clustering problem referring performance ratio competitive ratio reasons 
recall online setting compare performance algorithm adversary knows update sequence advance process points order arrival 
model stronger requirement incremental algorithms compared adversaries need respect input ordering compare algorithms optimal clusterings final point set intermediate clusterings need maintained 
online algorithms permitted superpolynomial running times 
contrast model essentially requires polynomial time approximation algorithms constrained incrementally maintain hac 
may interesting explore different online clustering example newly inserted point starts new cluster allow points old cluster redistributed remaining requiring clusters merged 
problem formulations lead entail recomputation index structures clusters renders algorithms useless point view applications consideration 
previous static clustering 
closely related problems clustering minimize diameter radius called pairwise clustering center problem respectively 
np hard fact hard approximate factor arbitrary metric spaces 
euclidean spaces clustering line easy higher dimensions np hard approximate factors close regardless metric 
furthest point heuristic due gonzalez see hochbaum shmoys gives approximation metric spaces 
algorithm requires kn distance computations metric space induced shortest path distances weighted graphs running time 
feder greene gave implementation euclidean spaces running time log 
overview results 
results incremental clustering show possible obtain algorithms comparable best possible static setting terms efficiency performance ratio 
section considering natural greedy algorithms choose clusters merge measure resulting cluster 
establish greedy algorithms behave poorly proving center greedy algorithm tight performance ratio gamma diameter greedy algorithm lower bound omega gamma 
greedy algorithms behave better geometric spaces discover evidence case line 
show diameter greedy performance ratio line 
analysis suggests variant diameter greedy shown achieve ratio line 
section doubling algorithm show performance ratio randomized version ratio 
obvious implementation algorithms expensive show implemented achieve amortized time log update 
results doubling algorithm carry radius measure 
section clique algorithm show performance ratio randomized version ratio 
clique algorithm may appear dominate doubling algorithm case requires computing clique partitions np hard problem said defense clique partitions need computed graphs vertices 
performance ratio clique algorithm radius measure improved bounds possible dimensional euclidean spaces specifically show radius performance ratio clique algorithm improves asymptotic large section provide lower bounds incremental clustering algorithms 
show line deterministic randomized algorithm achieve ratio better 
improve lower bound deterministic algorithms general metric spaces 
section consider dual clustering problem minimizing number clusters fixed radius 
impossible achieve bounded ratios general metric spaces focus dimensional euclidean spaces 
incremental algorithm performance ratio log provide lower bound omega gamma log log log 
interesting directions research suggested 
obvious questions improving upper lower bounds particularly dual clustering problem 
important theoretical question geometric setting permits better ratios metric spaces 
model generalized different ways 
depending exact application may wish consider measures clustering quality minimum variance cluster diameter sum squares inter point distances cluster 
issue handling deletions important motivating application information retrieval may relevant applications 
question formulating model adaptive clustering clustering may modified result queries user feedback updates 
greedy algorithms examining natural greedy algorithms 
greedy incremental clustering algorithm merges clusters minimize fixed measure 
results indicate algorithms perform poorly 
definition center greedy algorithm associates center cluster merges clusters centers closest 
center old cluster larger radius new center 
possible define variants center greedy centers clusters picked restrict definition reasons simplicity intuitiveness 
definition diameter greedy algorithm merges clusters minimize diameter resulting merged cluster 
establish lower bounds performance ratio greedy algorithms 
omit proofs extended 
theorem center greedy algorithm performance ratio gamma 
theorem diameter greedy algorithm performance ratio omega line 
give tight upper bound center greedy algorithm 
note ratio larger performance worse algorithms 
theorem center greedy algorithm performance ratio gamma metric space 
proof suppose set points inserted 
optimal clustering partition fc optimal diameter 
show diameter cluster produced center greedy gamma define graph set optimal clusters clusters connected edge minimum distance distance clusters minimum distances points 
consider connected components note clusters different connected components minimum distance strictly greater say cluster intersects connected component consisting optimal clusters intersects claim times cluster produced intersects exactly connected component prove claim induction suppose claim true new point arrives 
initially cluster center greedy clusters intersect exactly connected component cluster centers optimal cluster 
implies distance closest centers clusters center greedy merges stage centers apart 
clusters centers lie connected component say inductive hypothesis points points new cluster lie establishing inductive hypothesis 
cluster produced center greedy lies exactly connected component diameter bounded maximum diameter connected component gamma diameter greedy general metric spaces weak upper bound proof deferred final version 
theorem diameter greedy algorithm performance ratio metric space 
spite lower bounds greedy algorithms may entirely useless variant may perform geometric spaces 
obtain positive evidence regard analysis line 
upper bounds contrasted lower bound line shown section 
definitions underlie analysis 
definition set points line partition subdivides interval points subintervals endpoints diameter minimum partitions maximum interval length partition diameter diameter diameter radius center constrained point define family algorithms notion diameter 
definition diameter greedy algorithm merges clusters minimize diameter merged cluster 
note diameter greedy diameter greedy 
diameter greedy ratio ratio show lower bound omega gamma performance ratio line 
theorem diameter greedy algorithm line performance ratio performance ratio 
diameter greedy show diameter greedy bounded performance ratio line 
theorem diameter greedy algorithm performance ratio line 
proof fact show produces clustering diameter optimal diameter factor follows 
assume holds clusters merged 
intervals optimal clustering maximum diameter current clusters diameter merged 
starts ends gamma notice delta delta delta gamma 
assume ends starts replace argument intervals argument intervals clusters region gamma intervals gamma current clusters region 
bounds imply 
merging contained single interval diameter say gap consecutive intervals involved diameter merger diameter partition completes proof 
comment briefly running time algorithm 
proof diameter interval may replaced easily computed upper bound time creation interval gap containing upper bound max gamma gamma gamma 
maintaining points sorted balanced tree running time logn points inserted 
doubling algorithm describe doubling algorithm performance ratio incremental clustering general metric spaces 
phases uses parameters ff fi specified ff ff gamma fi 
start phase collection clusters lower bound optimal clustering diameter denoted opt 
cluster center points cluster 
invariants assumed start phase cluster radius defined max ffd pair clusters inter center distance opt 
phase consists stages merging stage algorithm reduces number clusters merging certain pairs second update stage algorithm accepts new updates tries maintain clusters increasing radius clusters violating invariants clearly making new points separate clusters 
phase ends number clusters exceeds definition threshold graph set points fp png graph merging stage works follows 
define fid threshold graph cluster centers graph merge clusters repeatedly performing steps graph non empty pick arbitrary cluster merge neighbors new cluster center remove neighbors new clusters merging stage 
note possible graph edges case algorithm forced declare phase going update stage 
lemma pairwise distance cluster centers merging stage phase lemma radius clusters merging stage phase ffd ffd proof prior merging distance clusters adjacent threshold graph radius ffd radius merged clusters ffd ff fi ffd inequality follows choice ff ff gamma fi 
update stage continues number clusters new point arrives algorithm attempts place current clusters exceeding radius bound ffd new cluster formed update cluster center 
number clusters reaches phase ends current set clusters input st phase 
remains specified algorithm initialization 
algorithm waits points arrived enters phase point center cluster containing just set distance closest pair points 
easily verified invariants hold start phase 
lemma shows clusters ith phase satisfy invariants st phase 
lemma clusters ith phase satisfy conditions 
radius clusters ffd 
pairwise distance cluster centers 
opt opt diameter optimal clustering current set points 
proof clusters phase terminating condition 
lemma radius clusters merging stage ffd description update stage bound violated insertion new points 
distance clusters centers merging stage new cluster created request point away current cluster centers 
cluster centers pairwise distance phase cluster centers apart optimal clustering forced put cluster 
follows opt lemmas observations 
algorithm ensures invariant opt start phase radius clusters phase ffd performance ratio time phase ffd opt opt fffi 
choose ff fi note choice satisfies condition ff ff gamma fi 
leads performance bound shown tight 
theorem doubling algorithm performance ratio metric space tight 
examination proof preceding theorem shows radius clusters factor diameter optimal clustering leading result 
corollary performance ratio radius measure 
simple modification doubling algorithm pick new cluster centers simple left right scan improves ratio case line 
obvious implementation algorithm appears inefficient establish time bound close best possible 
theorem doubling algorithm implemented run log amortized time update 
proof assume black box computing distance points metric space unit time 
reasonable assumption applications case static algorithms analysis requires assumption 
information retrieval application documents represented vectors black box implementation depend vector length exact definition distance 
show doubling algorithm may implemented amortized time required processing new update bounded log 
maintain edge lengths complete graph induced current cluster centers heap 
clusters space requirement 
new point arrives compute distance point current cluster centers requires time 
point added current clusters done 
hand new point initiates new cluster insert heap edges labeled distances new center existing cluster centers takes log time 
accounting purposes amortized analysis associate log credits inserted edge 
show possible charge cost implementing merging stage algorithm credits associated edges 
implies desired time bound 
assume loss generality merging stage merges clusters 
threshold phase 
algorithm extracts edges heap length number edges deleted heap 
deletion heap costs log time 
threshhold graph cluster centers exactly graph induced edges 
easy see procedure described find new cluster centers threshold graph takes time linear number edges graph assuming edges form adjacency list 
forming adjacency list edges takes linear time 
total cost merging phase bounded log log time 
credit log placed edge inserted heap accounts cost completing proof 
describe randomized doubling algorithm significantly better performance ratio 
algorithm essentially main change value lower bound phase 
deterministic case chose minimum pairwise distance points say choose random value probability density function set rx redefine fi ff gamma 
similar randomization earlier scheduling applications 
theorem randomized doubling algorithm expected performance ratio metric space 
bound achieved radius measure 
proof oe sequence updates optimal cluster diameter oe flx minimum pairwise distance points 
optimal value fl 
suppose choose rx 
ae maximum radius clusters created oe value arguments similar proof theorem show ae ffd gamma largest integer gamma gamma rx opt flx 
integer gamma fl ffi fl ae gamma ffi ffi ae re xfl gamma ffi ffi gamma indicator variables events ffi ffi respectively 
claim expected value ae bounded ae ex gamma ffi gamma dr ffi gamma ex gamma dr ffi gamma ffi gamma expected diameter 
clique partition algorithm describe clique algorithm performance ratio 
totally improve doubling algorithm new algorithm involves solving np hard clique partition problem graph vertices 
finding minimum clique partition np hard graphs induced points euclidean plane polynomial time points line 
algorithm needs solve clique partition problem graphs vertices may inefficient small definition undirected unweighted graph clique partition partition induced graphs cliques 
minimum clique partition clique partition minimum possible value clique algorithm similar doubling algorithm operates phases merging stage followed update stage 
invariants maintained algorithm different 
start ith phase clusters value radius cluster diameter cluster opt 
merging works follows 
form minimum clique partition threshold graph cluster centers 
new clusters formed merging clusters clique clique partition 
arbitrarily choose cluster clique center cluster center new merged cluster 
resulting clusters 
rest phase need know old clusters merged form new clusters 
lemma radius clusters merging stage diameter proof jn clusters union new cluster loss generality assume center chosen center centers jn induce clique threshold graph distance new center old cluster centers radius jn follows new radius diameter update phase new point handled follows 
current number clusters recall clusters formed merging stage 
exists js js cluster merged form add cluster exists new cluster center 
phase ends number clusters exceeds clusters merging phase 
intuition new algorithm 
phase clusters lower bound optimal 
lower bound increase radius existing clusters merge 
maintain invariant lower bound phase need ensure merging number clusters merging optimal algorithm achieve lower bound phase 
doubling algorithm achieved picking independent set new cluster centers distance threshold graph 
weakness approach bound diameter function radius new cluster 
get improvement observing better bound number clusters achievable optimal diameter bounded size minimum clique partition distance threshold graph 
need condition radius order doubling cliques bound diameter new clusters better twice radius 
lemmas show clusters phase satisfy invariants phase 
lemma radius clusters phase diameter clusters lemma phase opt 
proof suppose opt 
fc cluster centers phase 
note centers belong fc set cluster centers clusters formed phase merging stage 
centers started new cluster optimal center cluster contains center implies centers contained gamma clusters diameter contradiction size minimum clique partition threshold graph diameter clusters phase maintain invariant opt start phase 
performance ratio algorithm 
theorem clique algorithm performance ratio metric space tight 
radius clusters optimal diameter obtain corollary 
corollary clique algorithm performance ratio metric space radius measure 
case doubling algorithm randomization improve bound 
minimum distance points 
randomized algorithm sets rx phase deterministic algorithm chosen probability density function ln analysis similar theorem omit details 
theorem randomized clique algorithm performance ratio ln metric space 
corollary randomized clique algorithm performance ratio ln radius measure metric space 
special structure clusters clique algorithm show performance ratio radius measure better geometric case 
result geometry defer proofs proposition consequence 
proposition convex set diameter circumscribed sphere radius satisfies recurrence base case gamma gamma solution recurrence 
theorem clique algorithm performance ratio radius measure implies performance ratio asymptotically large lower bounds lower bounds performance incremental clustering 
lower bounds apply diameter radius measures proofs diameter case 
theorem shows simplest geometric space expect ratio better proof omitted 
theorem lower bound gamma performance ratio deterministic randomized algorithms respectively incremental clustering line 
case general metric spaces establish stronger lower bound 
theorem lower bound performance ratio deterministic incremental clustering algorithm arbitrary metric spaces 
proof consider metric space consisting points ij distances points shortest path distances graph distances specified ij ji ij ij 
fp ij jg 
note sets partition metric space clusters diameter 
deterministic algorithm incremental clustering problem 

consider clusters produced points ij described 
case suppose maximum diameter clusters 
clusters sets fp ij ji adversary gives point ij large number 
optimal clustering fqg sets optimal diameter 
claim maximum diameter 
cluster contains contains point claim clearly true 
hand cluster contains contain point merged existing clusters 
maximum diameter resulting clusters 
performance ratio 
case suppose maximum diameter clusters greater 
cluster contains points distance apart 
points yz 
adversary gives points ij ij ij ij ji 
optimal clustering consists sets fr ij ij ji optimal diameter 
claim maximum diameter clusters 
note 

puts ij cluster claim clearly true 
ij separate clusters clusters contain 
clusters say contain wx yz diameter ij distance yz performance ratio 
improve randomized lower bound slightly case arbitrary metric spaces 
theorem ffl lower bound gamma ffl performance ratio randomized incremental algorithm 
proof yao technique show lower bound deterministic algorithms appropriately chosen distribution 
deterministic algorithm incremental clustering 
distribution inputs follows 
initially adversary provides points pn distance 
adversary partitions points disjoint sets random partitions equally 
adversary provides points 
diameter optimal solution input distribution obtained constructing clusters fq incremental algorithm produce clustering diameter clusters produces sees points pn precisely sets selected random adversary 
number ways partition points sets 
probability incremental algorithm produces clustering diameter 
probability gamma incremental algorithm produces clustering diameter 
expected value diameter clustering produced gamma expected value performance ratio gamma chosing suitably large arbitrarily large arbitrarily small particular smaller ffl fixed ffl 
dual clustering consider dual clustering problem sequence pn cover point unit ball arrives minimize total number balls 
static case problem np complete ptas fixed dimension 
note general metric spaces possible achieve bounded ratio 
algorithm analysis theorem combinatorial geometry called roger theorem see theorem says covered convex shape covering density log 
volume radius ball times volume ball number balls needed cover ball radius balls unit radius log 
describe incremental algorithm performance ratio 
establish asymptotic lower bound omega gamma log log log log proof yields lower bounds respectively 
theorem dual clustering problem incremental algorithm performance ratio log 
proof algorithm maintains set centers subset points arrived far initially 
define range center sphere radius centers ensure 
associated center set points gamma called neighbors convenience assume gamma 
ensure neighbors lie 
new point received center add gamma breaking ties arbitrarily 
center exists distance greater existing centers 
case new center set gamma fxg 
roger theorem packing density sphere radius covered log spheres radius 
new center created fix set spheres cover 
point added gamma covered previously placed sphere add sphere value 
note sphere exist spheres cover completely 
centers covered sphere unit radius solution separate sphere cover center 
number centers lower bound number spheres optimal offline algorithm 
center incremental algorithm uses spheres cover points gamma 
performance ratio incremental algorithm bounded log 
theorem gives lower bound dual clustering problem 
theorem dual clustering problem incremental algorithm performance ratio omega gamma log log log log 
proof idea follows 
time points adversary case points covered ball radius 
adversary find point lying outside unit balls laid algorithm minimize radius ball required cover points request 
game terminates time time 
clearly lower bound performance ratio points covered ball radius algorithm balls point 
remains analyze worst case growth rate function note 
ff denote volume unit ball time ball radius covers points ffi specified define ball ball center radius ffi choose ffi volume implying current unit balls placed algorithm cover entire volume imply choice point inside covered current balls 
clear new set points covered ball radius ffi 
implying ffi determine value ffi easy inequality ff ffi requirement ball volume equal unit balls 
gamma ffl substituting equations obtain ffi ffl gamma ffl ffi ffl gamma ffl ff ffl gamma ffl ln ffl gamma ffl ln note ffl gamma ffl 
fact ln see choosing ffl ffl gamma ffl ln satisfy requirements 
unfolding recurrence ffl gamma ffl ln gammai ln gammai ln gammai ln noting ffl obtain ffl gammat gamma gamma ln lower bound smallest value ffl negative 
max largest value gamma ln ln max omega log log log log gives desired lower bound 
pankaj agarwal leonidas guibas helpful discussions suggesting consider dual clustering problem 

cluster analysis 
sage beverly hills 
bern eppstein 
approximation algorithms geometric problems 
hochbaum editor approximation algorithms np hard problems 
pws publishing 
brucker 
complexity clustering problems 
korte editors optimization operations research heidelberg new york ny pp 


incremental clustering dynamic information processing 
acm transactions information processing systems pp 


dynamic cluster maintenance system information retrieval 
proceedingsof tenth annual international acm sigir conference pp 

ii 
incremental clustering dynamic document databases 
proceedingsof symposium applied computing pp 

chakrabarti phillips schulz shmoys stein wein 
improved scheduling algorithms criteria 
proceedingsof rd international colloquium automata languages programming springer 
chaudhri 
dynamic clustering time incremental data 
pattern recognition letters pp 

cutting karger pederson tukey 
scatter gather cluster approach browsing large document collections 
proceedingsof th annual international acm sigir conference pp 

cutting karger pederson 
constant interaction time scatter gather browsing large document collections 
proceedings th annual international acm sigir conference pp 

duda hart 
pattern classification scene analysis 
john wiley sons ny 
everitt 
cluster analysis 
heinemann educational london 
faloutsos oard 
survey information retrieval filtering methods 
technical report cs tr department computer science university maryland college park 
feder greene 
optimal algorithms approximate clustering 
proceedings twentieth annual symposium theory computing pp 

fowler paterson tanimoto 
optimal packing covering plane np complete 
information processing letters pp 


baeza yates editors 
information retrieval data structures algorithms 
prentice hall 
garey johnson computers intractability guide theory np completeness freeman 
goemans kleinberg 
improved approximation ratio minimum latency problem 
proceedings seventh acm siam symposium discrete algorithms pp 

gonzalez 
clustering minimize maximum intercluster distance 
theoretical computer science pp 

hartigan 
clustering algorithms 
wiley new york ny 
hochbaum 
various notions approximations better best 
hochbaum editor approximation algorithms np hard problems 
pws publishing 
hochbaum 
approximation schemes covering packing problems image processing vlsi 
journal acm pp 

hochbaum shmoys 
best possible heuristic center problem 
mathematics operations research pp 

hochbaum shmoys 
unified approach approximation algorithms bottleneck problems 
journal acm pp 

irani karlin 
online computation 
hochbaum editor approximation algorithms np hard problems 
pws publishing 
jardine van rijsbergen 
hierarchical clustering information retrieval 
information storage retrieval pp 

jain dubes 
algorithms clustering data 
prentice hall nj 

algorithmic approach network location problems part centers problem 
siam journal applied mathematics pp 

megiddo 
complexity common geometric problems 
siam journal computing pp 


lower bounds metric center problems 
manuscript 
motwani phillips 
non scheduling proceedings fourth acm siam symposium discrete algorithms pp 

see theoretical computer science pp 

omiecinski scheuermann 
global approach record clustering file organization 
proceedings third bcs acm symposium research development information retrieval pp 

pach agarwal 
combinatorial geometry 
john wiley sons new york ny 
rasmussen 
clustering algorithms 
chapter frakes andr 
baeza yates editors information retrieval data structures algorithms prentice hall englewood cliffs nj 
van rijsbergen 
information retrieval 
butterworths london 
rogers 
note coverings 
pp 

salton 
automatic text processing 
addison wesley reading ma 
salton mcgill 
modern information retrieval 
mcgraw hill newyork ny 
willett 
trends hierarchical document clustering critical review 
information processing management pp 

witten moffat bell 
managing gigabytes indexing documents images 
van nostrand reinhold new york ny 
