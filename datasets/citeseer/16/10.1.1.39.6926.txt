free lunch theorems optimization david wolpert ibm almaden research center na harry road san jose ca william macready santa fe institute hyde park road santa fe nm december framework developed explore connection effective optimization algorithms problems solving 
number free lunch nfl theorems establish algorithm elevated performance class problems exactly paid performance class 
theorems result geometric interpretation means algorithm suited optimization problem 
applications nfl theorems information theoretic aspects optimization benchmark measures performance 
issues addressed time varying optimization problems priori head head minimax distinctions optimization algorithms distinctions obtain despite nfl theorems enforcing type uniformity algorithms 
past decades seen increased interest general purpose black box optimization algorithms exploit little knowledge concerning optimization problem run 
large part algorithms drawn inspiration optimization processes occur nature 
particular popular black box optimization strategies evolutionary algorithms fow hol simulated annealing kgv mimic processes natural selection statistical mechanics respectively 
light interest general purpose optimization algorithms important understand relationship algorithm performs optimization problem run 
formal analysis contributes understanding addressing questions plethora black box optimization algorithms optimization problems best match algorithms problems best relax black box nature algorithms exploit knowledge concerning optimization problem 
particular serious optimization practitioners perform matching usually ad hoc basis matching formally analyzed 
generally underlying mathematical skeleton optimization theory flesh probability distributions particular context set optimization problems imposed information theory bayesian analysis contribute understanding issues 
priori generalizable performance results certain algorithm certain class problems performance classes problems 
measure generalization assess performance algorithms problems may programmatically compare algorithms 
broadly speaking take approaches questions 
investigate priori restrictions pattern performance algorithms runs set optimization problems 
second approach focus particular problem consider effects running algorithms 
current results types analyses concentrate largely approach 
reader referred companion mw kinds analysis involving second approach 
section introducing necessary notation 
discussed section model computation adopt limitations reasons chose 
expect pairs search algorithms performs better average outperforms example expect hill climbing usually outperforms hill descending goal find maximum cost function 
expect outperform random search context 
main results expectations incorrect 
prove nfl theorems section demonstrate generally illuminate connection algorithms problems 
roughly speaking show static time dependent optimization problems average performance pair algorithms possible problems exactly identical 
means particular algorithm performance superior algorithm set optimization problems reverse true set optimization problems 
reader urged read section carefully precise statement theorems 
true algorithms random algorithm performs worse randomly just readily set optimization problems performs better randomly 
possible objections results addressed sections 
section geometric interpretation nfl theorems 
particular show algorithm average performance determined aligned underlying probability distribution optimization problems run 
section critical wishing understand nfl results consistent accepted fact search algorithms take account knowledge concerning cost function quite practice section demonstrates nfl theorems allow answer number intractable questions 
implications answers measures algorithm performance best compare optimization algorithms explored section 
section discuss ways despite nfl theorems algorithms priori distinctions hold specified concerning optimization problems 
particular show head head minimax distinctions pair algorithms show considered time pair algorithms may distinguishable looks 
section alternative approach formal analysis optimization problems held fixed looks properties space algorithms 
results hold general hold optimization problems independent kinds problems encounter real world 
particular results state priori justification search algorithm behavior far particular cost function predict behavior function 
fact choosing algorithms observed performance suffice assumption cost function currently poorly understood assumptions algorithms question related cost function 
addition presenting results mw section serves perspective adopted mw 
conclude section brief discussion summary results short list open problems 
confined proofs appendices possible facilitate flow 
detailed substantially longer version version analyzes issues addressed wm 
emphasize claims whatsoever concerning various search algorithms practice 
focus said priori assumptions mathematical principles concerning utility search algorithm 
preliminaries restrict attention combinatorial optimization search space quite large finite 
assume space possible cost values finite 
restrictions automatically met optimization algorithms run digital computers 
example typically bit representation real numbers case 
size spaces indicated jx jyj respectively 
optimization problems called cost functions objective functions energy functions represented mappings 
space possible problems 
size jyj jx large finite number 
addition static shall interested optimization problems depend explicitly time 
extra notation needed time dependent problems introduced needed 
common optimization community adopt oracle view computation 
view assessing performance algorithms results stated terms number function evaluations required find certain solution 
unfortunately optimization algorithms wasteful function evaluations 
particular algorithms remember searched revisit points 
algorithm wasteful fashion efficient simply remembering tabu search glo glo real world algorithms elect employ stratagem 
accordingly point view oracle performance measures artefacts distorting apparent relationship real world algorithms 
difficulty exacerbated fact amount revisiting occurs complicated function algorithm optimization problem simply filtered mathematical analysis 
accordingly elected circumvent problem entirely comparing algorithms number distinct function evaluations performed 
note mean compare algorithms wasteful evaluations simply means compare algorithms counting number distinct calls oracle 
call time ordered set distinct visited points sample size samples denoted dm delta delta delta points sample ordered time generated 
indicates value ith successive element sample size associated cost value 
fd delta delta delta indicate ordered set cost values 
space samples size dm theta dm dm set possible samples arbitrary size dm important clarification definition consider hill descending algorithm 
algorithm examines set neighboring points moves having lowest cost 
process iterated newly chosen point 
implementations hill descending reach local minimum easily extended run longer randomly jumping new unvisited point neighborhood local minimum exhausted 
point note sample contains previous points oracles consulted includes values neighbors current point lowest cost algorithm moves 
taken account counting value optimization algorithms represented mappings previously visited sets points single new previously unvisited point formally 
dx decision measure distinct function evaluations algorithm revisits previously searched points definition algorithm includes common black box optimization techniques simulated annealing evolutionary algorithms 
techniques branch bound lw included rely explicitly cost structure partial solutions interested primarily black box algorithms 
defined search algorithm deterministic sample maps unique new point 
course essentially algorithms implemented computers deterministic definition restrictive 
worth noting results extensible non deterministic algorithms new point chosen stochastically set unvisited points 
point returned 
oracle model computation measure performance algorithm iterations function sample performance measures indicated phi 
example trying find minimum reasonable measure performance value lowest value phi min fd mg 
note measures performance factors wall clock time outside scope results 
shall cast results terms probability theory 
reasons 
allows simple generalization results stochastic algorithms 
second setting deterministic probability theory provides simple consistent framework carry proofs 
third reason probability theory interesting 
crucial factor probabilistic framework distribution delta delta delta 
distribution defined gives probability actual optimization problem hand 
approach distribution immediate advantage knowledge problem statistical nature information may easily encodable 
example markov gibbs random field descriptions ks families optimization problems express exactly 
exploiting advantages single uniquely specified cost function 
advantage fact may fully specified aspects cost function effectively unknown certainly know extrema function 
ways appropriate effective ignorance reflected analysis probability distribution 
generally usually act cost function partially unknown 
example search algorithm cost functions class traveling salesman problems having certain characteristics 
doing implicitly acknowledging consider distinctions cost functions class irrelevant 
sense single particular problem class act probability distribution cost functions distribution non zero members class cost functions 
prior specification class optimization problem hand different classes problems corresponding different choices algorithms particular note random number generators deterministic seed 
giving rise different distributions 
choice probability theory performance algorithm iterated times cost function measured jf 
conditional probability obtaining particular sample dm stated conditions 
jf performance measures phi easily 
section analyze jf particular vary algorithm proceeding analysis worth briefly noting formal approaches issues investigated 
prominent field computational complexity 
approach taken computational complexity ignores statistical nature search concentrates computational issues 
means computational complexity concerned physically unrealizable computational devices turing machines worst case amount resources require find optimal solutions 
contrast analysis concern computational engine search algorithm concentrates exclusively underlying statistical nature search problem 
current probabilistic approach complimentary computational complexity 
involves combining analysis statistical nature search practical concerns computational resources 
nfl theorems section analyze connection algorithms cost functions 
dubbed associated results free lunch nfl theorems demonstrate algorithm performs certain class problems necessarily pays degraded performance set remaining problems 
additionally name emphasizes parallel similar results supervised learning wol wol 
precise question addressed section set problems ae algorithm performs better algorithm compare set ae reverse true 
address question compare sum jf sum jf 
comparison constitutes major result jf independent average cost functions theorem pair algorithms jf jf proof result appendix immediate corollary result performance measure phi average phi jf independent precise way sample mapped performance measure unimportant 
theorem explicitly demonstrates algorithm gains performance class problems necessarily pays remaining problems way algorithms averaged performance 
result analogous theorem holds class time dependent cost functions 
time dependent functions consider initial cost function sampling value 
subsequent iteration optimization algorithm cost function deformed new function specified mapping theta indicate mapping notation function ith iteration 
assumed potentially dependent bijection impose hold evolution cost functions narrow region algorithms may perform better 
constitute priori bias favor algorithms bias analysis wish defer 
best assess quality algorithm performance time dependent cost functions clear 
consider schemes manipulations definition sample 
scheme particular value corresponding particular value cost function sampled 
contrast scheme imagine sample values cost function values formally fd delta delta delta scheme ff delta delta delta tm gamma gamma scheme ffm delta delta delta fm fm tm gamma gamma final cost function 
situations may members sample live long time time scale evolution cost function 
situations may appropriate judge quality search algorithm previous elements sample alive time current cost interest 
hand members sample live short time time scale evolution cost function may concerned things living member sample track changing cost function 
situations may sense judge quality algorithm sample 
results similar theorem derived schemes 
analogy theorem average possible ways cost function may time dependent average 
consider jf initial cost function 
takes effect fixed priori distinctions algorithms far member population concerned 
redefining samples contain elements added iteration algorithm arrive result proven appendix theorem algorithms initial cost functions jf jf jf jf obvious restriction require doesn vary time mapping simply analysis limited way scope 
particular algorithm outperforms certain kinds evolution operators reverse true set evolution operators 
particular result similar nfl result static case general time dependent situation subtle 
particular time dependence situations priori distinctions algorithms members population arising 
example general distinctions algorithms considering quantity jf 
see consider case set contiguous integers iterations shift operator replacing gamma min gamma max 
case construct algorithms behave differently priori 
example take algorithm samples regardless values population 
identical values 
accordingly jf non zero values identical 
search algorithms shift restriction values 
constitutes priori distinction algorithms 
implications nfl theorems emphasized nfl theorems mean algorithm particularly class problems poorly remaining problems 
particular algorithm performs better random search class problems perform worse random search remaining problems 
comparisons reporting performance particular algorithm particular parameter setting sample problems limited utility 
results indicate behavior narrow range problems considered wary trying generalize results problems 
note nfl theorem need viewed way way comparing function classes classes evolution operators case 
viewed statement concerning algorithm performance fixed uniform prior cost functions jf wish analyze performance fixed alternative nfl theorem contrast nfl case chosen non uniform prior analyze explicitly sum jm jf certainly true class problems faced practitioner flat prior practical implications nfl theorems viewed statement concerning algorithm performance non fixed 
question taken greater detail section comments 
practitioner knowledge problem characteristics incorporate optimization algorithm effectively uniform 
recall viewed statement concerning practitioner choice optimization algorithms 
case nfl theorems establish formal assurances algorithm chosen effective 
secondly classes problems certainly structure known exploitable simple existence structure justify choice particular algorithm structure known reflected directly choice algorithm serve justification 
words simple existence structure se absent specification structure provide basis preferring algorithm 
formally established existence nfl type theorems average specific cost functions averages specific kinds structure theorems averages distributions 
theorems hold averages means indistinguishability algorithms associated uniform pathological outlier case 
uniform typical distribution far indistinguishability algorithms concerned 
simple fact hand non uniform serve determine choice optimization algorithm 
important emphasize considering case fixed performing associated average uniform essential nfl hold 
nfl demonstrated range non uniform priors 
example prior form distribution values give nfl 
average enforce correlations costs different values nfl obtain 
example costs rank ordered ties broken arbitrary way sum cost functions permutations orders nfl holds 
choice uniform motivated theoretical concerns way analyzing theoretical structure optimization 
cautionary observations clear analysis uniform case number ramifications practitioners 
stochastic optimization algorithms far considered case algorithms deterministic 
situation stochastic algorithms 
turns nfl results hold algorithms 
proof straightforward 
oe stochastic non potentially revisiting algorithm 
formally means oe mapping dependent distribution equals zero 
sense oe statistics community known hyper parameter specifying function dm oe 
reproduce derivation nfl result deterministic algorithms replaced oe 
doing steps proof remain valid 
establishes nfl results apply stochastic algorithms deterministic ones 
geometric perspective nfl theorems intuitively nfl theorem illustrates knowledge specified incorporated formal assurances effective 
effective optimization relies fortuitous matching point formally established viewing nfl theorem geometric perspective 
consider space possible cost functions 
previously discussed regard equation probability obtaining jm jm prior probability optimization problem hand cost function sum functions viewed inner product precisely defining space vectors components jm respectively jm delta equation provides geometric interpretation optimization process 
viewed fixed sample desired usually low cost value measure computational resources afforded 
knowledge properties cost function goes prior cost functions equation says performance algorithm determined magnitude projection aligned problems alternatively averaging easy see jm inner product jm 
expectation performance measure phi written similarly 
cases match aligned get desired behavior 
need matching provides new perspective certain algorithms perform practice specific kinds problems 
example means years research traveling salesman problem tsp resulted algorithms aligned implicit describing traveling salesman problems interest tsp researchers 
geometric view nfl result jf independent interpretation particular algorithms projection uniform represented diagonal vector 
formally delta cst 
deterministic algorithms components probabilities algorithm gives sample cost function distinct cost evaluations nfl implies cst 
geometrically indicates length independent different algorithms generate different vectors having length lying cone constant projection 
schematic situation shown case dimensional 
components binary equivalently view lying subset vertices boolean hypercube having hamming distance 
schematic view situation function space dimensional 
uniform prior space lies diagonal 
different algorithms give different vectors lying cone surrounding diagonal 
particular problem represented prior lying simplex 
algorithm perform best algorithm cone having largest inner product restrict attention algorithms having probability particular algorithms set lie intersection cones diagonal set nfl theorem set having probability general jf gamma dimensional manifold 
continuing impose restrictions set algorithms continue reduce dimensionality manifold focusing intersections cones 
geometric view optimization suggests alternative measures determining similar optimization algorithms 
consider equation 
algorithm directly gives straight forward way compare algorithms measuring similar vectors 
evaluating dot product vectors 
vectors occur right hand side equation performance algorithms ultimate concern occur left hand side 
suggests measuring similarity algorithms directly terms vectors terms dot products vectors example may case algorithms behave similarly certain quite different 
respects knowing algorithms interest knowing vectors compare 
example similarity measure suggested geometric perspective measure similarity algorithms similarities 
example different algorithms imagine solving optimizes algorithms non trivial sense 
measure distance distributions gauge similar associated algorithms 
unfortunately exploiting inner product formula practice going algorithm optimal appears quite difficult 
determining plausible situation hand difficult 
consider example tsp problems cities 
degree practitioner attacks city tsp cost functions algorithm practitioner implicitly ignores distinctions cost functions 
practitioner implicitly agreed problem fixed algorithm set city tsp cost functions 
detailed nature uniform class problems appears difficult elucidate 
hand growing body rely explicitly enumeration 
example applications markov random fields gri ks cost landscapes yield directly gibbs distribution 
calculational applications nfl theorems section explore applications nfl theorems performing calculations concerning optimization 
consider calculations practical theoretical interest calculations theoretical interest informationtheoretic quantities arise naturally 
information theoretic aspects optimization expository purposes simplify discussion slightly considering histogram number instances possible cost value produced run algorithm temporal order cost values generated 
essentially realworld performance measures independent temporal information 
indicate histogram symbol components delta delta delta jyj number times cost value occurs sample consider question fraction cost functions give particular histogram cost values distinct cost evaluations produced particular instantiation evolutionary algorithm fow hol 
glance intractable question 
turn nfl theorem provides way answer 
nfl theorem answer independent algorithm generate consequently chose algorithm calculation tractable 
particular may want impose restrictions 
instance may wish consider invariant partial relabelling elements preclude algorithm luck land min query 
theorem algorithm fraction cost functions result particular histogram ff ae ff delta delta delta jyj jyj jx gammam jyj jx delta delta delta jyj jyj large approximated ae ff jyj exp ms ff jy ff ff entropy distribution ff jyj constant depend ff 
theorem derived appendix ff approximation holds redefined exclude corresponding zero valued ff defined normalization constant equation summing ff lying unit simplex 
question related addressed theorem cost function fraction ae alg algorithms give rise particular turns feature relevant question histogram cost values formed looking specify fractional form histogram fi fi jx points th value 
appendix shown leading order ae alg ff fi depends information theoretic quantity kullback liebler distance ct ff fi theorem histogram jx fi fraction algorithms give rise histogram ff ae alg ff fi jy jx large written ae alg ff fi jx jyj gammam dkl ff fi jyj ff dkl ff fi kullback liebler distributions ff fi 
calculated summing ff unit simplex 
measures performance show apply nfl framework calculate certain benchmark performance measures 
allow programmatic ad hoc assessment efficacy individual optimization algorithm principled comparisons algorithms 
loss generality assume goal search process finding minimum 
interested ffl dependence min ffl mean probability minimum cost algorithm finds problem distinct evaluations larger ffl 
quantities related conditional probability gauge algorithm performance particular optimization run uniform average min ffl cost functions 
ii form min ffl takes random algorithm uses information sample dm iii fraction algorithms particular result minimum exceeds ffl 
measures give benchmarks algorithm run particular cost function surpass algorithm considered having worked cost function 
loss generality assume th cost value equals cost values run minimum maximum jyj integer increments 
results derived appendix theorem min ffl ffl ffl gamma ffl jyj fraction cost lying ffl 
limit jyj distribution obeys relationship min jyj algorithm best cost far drop faster drop associated results hard pressed claim algorithm suited cost function hand 
performance algorithm doing better expect randomly chosen cost function 
preceding measure measures analyzed take account actual cost function hand 
manifested values measures vector cost function histogram jx fi theorem random algorithm min ffl gamma omega gamma ffl gamma jx gamma jx omega gamma ffl jyj ffl jx fraction points ffl 
order jx min ffl omega ffl gamma gamma gamma omega gamma ffl omega gamma ffl jx delta delta delta result allows calculation quantities interest measuring performance example quantity min jf jy ffl ffl min ffl gamma min ffl note cost functions practical theoretical interest cost values distributed 
cases gaussian nature distribution facilitate calculations 
particular mean variance gaussian oe respectively omega gamma ffl erfc ffl gamma oe erfc complimentary error function 
calculate third performance measure note fixed deterministic algorithm ffl 
fraction algorithms result minimum exceeds ffl min ffl expanding terms rewrite numerator ratio min fflj 
ratio quantity exactly calculated evaluated measure ii see argument deriving equation 
establishes theorem fixed fraction algorithms result minimum exceeds ffl quantity right hand sides equations 
particular example applying result consider measuring value min produced particular run algorithm 
imagine evaluated ffl equal value quantity equation 
situation algorithm question worse half search algorithms hand hardly endorsement 
discussion explicitly concerns dynamics algorithm performance increases 
aspects dynamics may interest 
example consider grows change algorithm performance compares random algorithm 
sample generated algorithm steps dm define min 
number additional steps takes algorithm find estimate number steps taken random search algorithm search gamma dx find point expected value number steps gamma fraction gamma gamma worse random algorithm average 
imagine letting run steps fitness function plotting comparison random algorithm run increased 
consider step finds th new value min 
step associated number steps min 
accordingly indicate step plot point gamma 
put points plot successive values min run run better match random search algorithm points plot ordinate values lie 
random algorithm won comparisons mean point lying 
general points lie side expect search progresses corresponding systematic variation far away points lie 
variation tells algorithm entering harder easier parts search 
note fixed different starting points algorithm generate plots superimpose 
allows plot mean value gamma function associated error bar 
similarly replace single number characterizing random algorithm full distribution number required steps find new minimum 
similar ways generate nuanced picture algorithm performance provided single numbers performance measure discussed 
minimax distinctions algorithms nfl theorems address minimax properties search 
example say re considering deterministic algorithms may exist cost functions histogram better appropriate performance measure cost functions reverse true 
nfl theorem obeyed scenario true histogram better vice versa slightly better scenario certain sense better head head minimax behavior beats badly substantially worse formally say exists head head minimax distinctions algorithms iff exists cost function difference gamma gamma 
similar definition interested phi appears analyzing head head minimax properties algorithms substantially difficult analyzing average behavior nfl theorem 
presently little known minimax behavior involving stochastic algorithms 
particular known senses stochastic version deterministic algorithm better worse minimax behavior deterministic algorithm 
fact stick completely deterministic algorithms extremely preliminary understanding minimax issues reached 
know 
consider quantity deterministic algorithms 
pa meant distribution random variable evaluated 
deterministic algorithms quantity just number true produces population components produces population components appendix proven example quantity need symmetric interchange theorem general means certain circumstances knowing components populations produced algorithms run unknown infer concerning algorithm produced population 
consider quantity pc deterministic algorithms quantity just number true produces histogram produces histogram need symmetric interchange see appendix 
stronger statement asymmetry statement particular histogram corresponds multiple populations 
results directly implies algorithms histogram better reverse true 
investigate problem involves looking pairs histograms pair relationship performances algorithms reflected histograms 
simply having inequality sums directly imply relative performances associated pair histograms asymmetric 
formally establish involve creating scenarios inequality sums head head minimax distinctions 
analysis scope 
hand having sums equal carry obvious implications head head minimax distinctions 
example algorithms deterministic particular equals pair 
case just number result pair 
implies head head minimax distinctions converse appear hold 
preliminary analysis head head minimax distinctions exploit result appendix concerns case jx jyj 
define performance measures element populations 
ii 
iii argument 
appendix show scenario exist pairs algorithms generates histogram fy generates histogram fy reverse occurs generates histogram fy generates fy 
scenario defined performance measure minimax distinctions performance measures algorithms respectively 
difference values algorithms difference 
algorithm minimax superior algorithm currently known restrictions needed minimax distinctions algorithms 
example may min fd minimax distinctions algorithms 
generally known big problem kinds asymmetries 
examples asymmetry considered arise set consider grid pairs 
assign grid point number result grid point pair 
constraints hypothesis head head minimax distinctions grid point assigned non zero number ii theorem sum numbers row equals sum numbers column constraints appear imply distribution numbers symmetric interchange rows columns 
formally establish point involve explicitly creating search scenarios holds 
values visited overlaps visited 
overlap certain properties algorithms generated overlap asymmetry arises 
precise specification certain properties hand 
known generic percentage pairs algorithms arise 
issues easy state see appendix clear best answer 
consider case assured steps populations particular algorithms overlapped 
assurances hold example comparing hill climbing algorithms start far apart scale turns assurances asymmetries algorithms element populations 
see formally go argument prove nfl theorem apply argument quantity 
doing establishes theorem overlap immediate consequence theorem overlap conditions quantity pc symmetric interchange distributions determined distribution difference extrema 
note stochastic algorithms give non zero probability overlap consider 
possibility asymmetry algorithms stochastic 
independent results point largely considered behavior various algorithms wide range problems 
section introduce kinds results obtained reverse roles consider properties algorithms single problem 
results type mw 
results section sweeping nfl results hold matter real world distribution cost functions search algorithms 
define choosing procedure rule examines samples dm produced respectively populations decides subsequent part search 
example rational choosing procedure subsequent part search generated lower cost value sample conversely consider irrational choosing procedure went algorithm generated sample lowest cost solution 
point choosing procedure takes effect cost function sampled dm accordingly refers samples cost function come choosing algorithm user interested remaining sample loss generality assumed search algorithm chosen choosing procedure return points theorem proven appendix establishes priori justification particular choosing procedure 
loosely speaking matter cost function special consideration algorithm hand simply observing algorithm done far tells priori continue cost function 
simplicity stating result consider deterministic algorithms 
theorem dm fixed samples size generated algorithms respectively run arbitrary cost function hand 
different choosing procedures 
number elements implicit result assumption sum excludes algorithms result respectively run precise form result may appear misleading treats populations equally populations 
weights populations probability occurrence true average choosing procedure uses effect established result proven appendix theorem conditions preceding theorem results show assumption justifies choosing procedure far subsequent search concerned 
intelligent choosing procedure take account search algorithms choosing 
may surprising 
particular note means intrinsic advantage rational choosing procedure continues better irrational choosing procedure opposite 
results interesting implications degenerate choosing procedures algorithm ag algorithm applied case know avoid elements seen 
priori way avoid elements hasn seen vice versa 
definition depend elements gamma similarly deal problem defining set elements lie outside 
similar convention exploited deal potentially retracing algorithms 
formally means random variable function means may fewer elements histogram population mean fixed better average algorithms set better average algorithms set algorithms 
particular favorite algorithms certain behaved results better performance random behaved gives worse random behavior set remaining algorithms 
sense just universally search algorithms universally benign assured resulting better random performance regardless algorithm 
fact things may worse 
supervised learning related result wol 
translated current context result suggests restricts sums algorithms match case stupid choosing procedures irrational procedure choosing algorithm desirable outperform intelligent ones 
set algorithms summed rational choosing procedure superior irrational currently known 
framework compare general purpose optimization algorithms 
number nfl theorems derived demonstrate danger comparing algorithms performance small sample problems 
results indicate importance incorporating problem specific knowledge behavior algorithm 
geometric interpretation showing means algorithm suited solving certain class problems 
geometric perspective suggests number measures compare similarity various optimization algorithms 
direct calculational applications nfl theorem demonstrated investigating certain information theoretic aspects search developing number benchmark measures algorithm performance 
benchmark measures prove useful practice 
provided analysis ways algorithms differ priori despite nfl theorems 
provided variant framework focuses behavior range algorithms specific problems specific algorithms range problems 
variant leads directly reconsideration issues addressed computational complexity detailed mw 
clearly remains reader directed wm list 
important development practical applications ideas 
geometric viewpoint construct new optimization techniques practice 
believe answer 
minimum markov random field models landscapes wide spread approach embodied find wider applicability 
acknowledgments raja das david fogel tal grossman paul helman bennett una may reviewers helpful comments suggestions 
santa fe institute funding santa fe institute txn support 
ct cover thomas 
elements information theory 
john wiley sons new york 
fow fogel owens walsh 
artificial intelligence simulated evolution 
wiley new york 
glo glover 
orsa comput 
glo glover 
orsa comput 
gri 
random fields 
springer verlag new york 
hol holland 
adaptation natural artificial systems 
mit press cambridge ma 
kgv kirkpatrick gelatt vecchi 
optimization simulated annealing 
science 
ks snell 
markov random fields applications 
american mathematical society providence 
lw lawler wood 
operations research 
mw macready wolpert 
optimization problem 
complexity 
wm wolpert macready 
free lunch theorems search 
technical report sfi tr ftp ftp santafe edu pub tp nf search ps santa fe institute 
wol wolpert 
lack prior distinctions learning algorithms existence priori distinctions learning algorithms 
neural computation 
wol wolpert 
bias plus variance 
neural computation press 
nfl proof static cost functions show dependence conceptually proof quite simple necessary book keeping complicates things lengthening proof considerably 
intuition proof quite simple summing ensure past performance algorithm bearing performance 
accordingly sum algorithms perform equally 
proof induction 
induction inductive step breaking independent parts evaluated separately giving desired result 
write sample fd set possible value ffi ffi kronecker delta function 
summing possible cost functions ffi functions cost point sum equals jyj jx gamma independent jyj jx gamma independent bases induction 
inductive step requires jf independent jf 
establishing step completes proof 
writing jf fd jf jf jd jf jf jd jf new value depend new value 
expand possible values obtaining jf jf xjd jf ffi xjd jf note depend directly consequently expand remove dependence xjd jf ffi xjd jd theta jf ffi dm theta jf fact xjd ffi dm fact jf jf 
sum cost functions done 
cost function defined points restricted points outside jf depend values defined points inside ffi dm depends values defined points outside 
recall jf jf ffi dm sum contributes constant jyj jx gammam gamma equal number functions defined points passing dm 
jf jyj jx gammam gamma jf jyj jf jyj jf hypothesis right hand side equation independent left hand side 
completes proof 
nfl proof time dependent cost functions analogy proof static nfl theorem proof time dependent case proceeds establishing independence sum cj replace sum set cost functions iteration algorithm 
start delta delta deltaf cj delta delta delta fm delta delta deltaf delta delta delta fm sequence cost functions indicated vector delta delta delta fm 
step sum possible decomposed series sums 
sum series values take particular iteration algorithm 
formally write delta delta deltaf theta ffi delta delta delta tm gamma ffi tm gamma tm gamma delta delta delta note independent values gamma values absorbed independent proportionality constant 
consider innermost sum tm gamma fixed values outer sum indices tm gamma fixed values outer indices tm gamma tm gamma delta delta delta just particular fixed cost function 
accordingly innermost sum tm gamma simply number bijections map fixed cost function fm constant jf gamma 
consequently evaluating tm gamma sum yields cj delta delta deltaf cj theta ffi delta delta delta tm gamma ffi gamma tm gamma tm gamma delta delta delta sum tm gamma accomplished manner tm gamma summed 
fact sums done leaving delta delta deltaf delta delta deltaf cj delta delta delta fm gamma step statistical independence fm 
progress depends represents analysis case 
case cj jf reflects cost values cost function fm result gives delta delta deltaf gamma jf delta delta delta fm gamma fm jf final sum fm constant equal number ways generating sample cost values drawn fm important point independent particular sum evaluated eliminating dependence 
jf delta delta deltaf gamma delta delta delta fm gamma completes proof theorem case proof theorem completed turning case 
considerably difficult simplified sums decoupled 
nfl result holds 
proven expanding equation possible values 
jf delta delta deltaf jd delta delta delta fm gamma jd delta delta deltaf delta delta delta fm gamma ffi innermost sum fm effect ffi term contributes fm ffi fm 
constant equal jyj jx gamma leaves jd delta delta deltaf gamma delta delta delta fm gamma gamma ffi sum simple jf jd delta delta delta gamma delta delta deltaf gamma gamma delta delta delta fm gamma theta gamma ffi equation form equation remaining population size gamma consequently analogous manner scheme evaluate sums fm existed equation sums fm gamma gamma evaluated 
doing simply generates independent proportionality constants 
continuing manner sums evaluated find ffi algorithm dependence result trivial dependence discussed previously 
arises algorithm selects point population 
restricting interest points sample generated subsequent result shows distinctions algorithms 
alternatively summing initial cost function points sample considered retaining nfl result 
proof ae result noted discussion leading theorem fraction functions giving specified histogram ff independent algorithm 
consequently simple algorithm prove theorem 
algorithm visits points canonical order say xm recall histogram specified giving frequencies occurrence xm jyj possible cost values 
number giving desired histogram algorithm just multinomial giving number ways distributing cost values remaining jx gamma points cost assume jyj values giving result theorem 
expression ae ff terms entropy ff follows application stirling approximation order valid large 
case multinomial written ln delta delta delta jyj ln gamma jyj ln ln gamma jyj ln ms ff gamma jyj ln gamma jyj ln ff theorem follows exponentiating result 
proof ae alg result section proportion algorithms give particular particular calculated 
calculation proceeds steps finite finite number different samples 
deterministic huge finite list indexed possible 
entry list question outputs index 
consider particular unordered set pairs pairs share value 
set called unordered path loss generality implicitly restrict discussion unordered paths length particular particular unordered set pairs identical numerator right hand side equation number unordered paths give desired number unordered paths give desired numerator right hand side equation proportional number give desired proof claim constitutes proof equation 
furthermore proportionality constant independent proof proof established constructing mapping oe 
gives desired producing gives desired showing number algorithms oe constant independent oe single valued complete proof 
recalling value unordered path distinct unordered path gives set 
different ordered paths 
ordered path ord turn provides set successive empty included indicate ord set provided ord ordered path ord partial algorithm constructed 
consists list ord entries list filled remaining entries blank 

distinct partial ordered path corresponding 
partially filled lists partial algorithm may may consistent particular full algorithm 
allows definition inverse oe gives oe gamma set consistent partial algorithm generated give run 
complete part proof shown give oe gamma contains number elements regardless generate ordered paths induced associate ordered path distinct element partial algorithm 
full algorithms lists consistent partial algorithm partial lists 
question answered core appendix 
answer question reorder entries partial algorithm lists permuting indices lists 
obviously reordering won change answer question 
reordering accomplished interchanging pairs indices 
interchange index form entry filled partial algorithm lists arbitrary constant value refers th element create arbitrary fixed ordering jx 
interchange index form entry filled new partial algorithm lists xm 
recall distinct 
construction resultant partial algorithm lists independent number lists 
number algorithms consistent partial algorithm list oe gamma independent completes part proof 
second part choose unordered paths differ ordered path ord constructed equals ordered path ord constructed choose ord ord disagree null know deterministic agrees 
agree null sampled single element disagree agrees 
agree double element continue manner gamma element ordered paths differ disagreed point agrees 
true ord ord see oe gamma oe gamma 
completes proof 
show relation kullback liebler distance product expanded aid approximation large ln jyj jy gamma ln ln gamma ln gamma gamma ln gamma ln gamma ln gamma gamma ln assumed reasonable jx expanding ln gamma gammaz gamma gamma delta delta delta second order gives ln jyj jyj ln gamma ln gamma ln gamma gamma delta delta delta jx terms ff fi finds ln jyj kl ff fi gamma ln jx gamma jyj ln gamma jyj ln ff jx ff fi gamma ff delta delta delta dkl ff fi ff ln fi ff kullback liebler distance distributions ff fi 
exponentiating expression yields second result theorem 
benchmark measures performance result benchmark measure established turn 
measure min jf 
consider min jf summand equals deterministic ii iii dm 
restrictions fix value points remains free points 
jyj jx gammam result equation find min ffl jyj min ffl jyj min ffl jyj jyj gamma ffl result quoted theorem 
limit jyj gets large write min jf jy ffl ffl 
ffl gamma gamma ffl substitute ffl gamma ffl jyj 
replacing ffl turns sum jy gamma gamma yj gamma gamma jy 
write jyj delta multiply divide summand delta 
jyj delta 
take limit delta apply rule ratio summand 
fact delta going cancel terms summand 
carrying algebra dividing delta get riemann sum form dx gamma gamma evaluating integral gives second result theorem 
second benchmark concerns behavior random algorithm 
marginalizing values different histograms performance min ffl min ffl probability obtaining histogram random draws histogram function viewed definition probability calculated previously jy jx min ffl jx delta delta delta jyj ffi jyj min fflj jyj jx ffl delta delta delta jyj ffi jy ffl jyj ffl ip jyj ffl jx omega gamma ffl jx jx equation theorem 
proof related minimax distinctions algorithms proof example 
consider points points point visits point visits point sees jumps jumps point sees jumps sees jumps consider cost function values values fy respectively 
produce population function produce 
proof completed show cost function produces population containing produces population containing possible pairs populations consider ii iii iv 
point jumps starts point second point equal point 
rules possibilities ii 
possibilities iii iv population know form fy variable case iii need equal due point population 
case second point sees value contrary hypothesis 
case iv know equal due point population 
mean jumps second point see contrary hypothesis 
accordingly cases possible 
case symmetry exchange symmetry exchange histograms 
qed 
fixed cost functions choosing procedures deterministic search algorithm mapping ae ae search algorithm vector space components vector indexed possible populations value component algorithm produces associated population 
consider particular population size say population size greater ordered elements ordered elements 
set populations start way defines set components algorithm vector components indicated remaining components types 
populations equivalent elements values components vector algorithm indicated aed second type consists components corresponding remaining populations 
intuitively populations compatible examples populations populations contain elements element populations re order elements values components second type indicated proc interested proc aed aed jf proc summand independent values 
addition number values constant 
product populations consistent number possible population mapped 
constant independent proc sum equals aed aed aed aed proc definition implicitly restricting sum summand defined 
means allow value component aed value gives element similarly aed sum reduces proc note component lies true sum components sum fixed proc choice fixed 
accordingly loss generality sum rewritten implicit assumption set sum independent proc 
proof theorem proc refer choosing procedure 
interested proc proc theta proc sum moved outside sum consider term sum particular pair values 
term proc just result respectively run 
recall assumption deterministic 
means proc factor simply restricts sum considered theorem 
accordingly theorem tell summand sum choosing procedures full sum procedures 

