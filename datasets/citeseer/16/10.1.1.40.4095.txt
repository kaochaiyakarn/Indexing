automatic labeling self organizing maps information retrieval dieter merkl andreas rauber institut technische universit wien www ifs tuwien ac ifs research ir self organizing map popular unsupervised neural network model analysis highdimensional input data information retrieval applications 
interpretation map requires manual effort especially far analysis learned features characteristics identified clusters concerned 
novel labelsom method features learned map automatically selects descriptive features input patterns mapped particular unit map making characteristics various clusters map explicit 
demonstrate benefits approach example text classification real world document archive 
particular case features correspond keywords describing contents document 
benefit approach various document clusters characterized terms shared keywords making easy user explore contents unknown document archive 
today information age may characterized constant massive production dissemination written information 
powerful tools exploring searching organizing mass information needed 
particularly aspect exploration limited attention research community compared aspects information retrieval systems 
current information retrieval technology relies systems retrieve documents similarity keyword document query representations 
attractive way assist user document archive exploration unsupervised artificial neural networks especially selforganizing maps document space representation 
number research publications show idea appreciation community :10.1.1.52.5514
maps visualize similarity documents terms distances dimensional map display 
similar documents may neighboring regions map display 
mentioned papers focus visualization cluster structure 
remains tedious task interpret mapping self organizing map analyze attributes relevant particular mapping 
look applications self organizing map usually find labeled manually way inspection trained map set keywords assigned unit cluster provide user hints contents map 
apart fact manually assigning labels highly labour intensive requiring manual inspection data items mapped units difficult impossible high dimensional data sets 
needed way automatically label units clusters self organizing map structures learned map explicit give justification particular mapping 
novel method automatically assign keywords units trained self organizing map 
brevity refer method labelsom method 
demonstrate benefits method application scenario information retrieval 
particular describe results labeling self organizing map trained collection time magazine articles 
labelsom method allows automatically describe subject matter documents features learned selforganizing map assists user understanding data collection map 
self organizing maps self organizing map general unsupervised tool ordering highdimensional data way similar input items grouped spatially close 
model consists number neural processing elements units 
units assigned dimensional weight vector important note weight vectors dimensionality input patterns 
training process self organizing maps may described terms input pattern presentation weight vector adaptation 
training iteration starts random selection input pattern 
input pattern self organizing map unit determines activation 
usually euclidean distance weight vector input pattern calculate unit activation 
particular case unit lowest activation referred winner training iteration expression 
min weight vector winner weight vectors selected units vicinity winner adapted 
adaptation implemented gradual reduction difference corresponding components input pattern weight vector shown expression 
ci geometrically speaking weight vectors adapted units moved bit input pattern 
amount weight vector movement guided called learning rate decreasing time 
number units affected adaptation determined socalled neighborhood function ci number units decreases time training process winner adapted 
typically neighborhood function unimodal function symmetric location winner monotonically decreasing increasing distance winner 
gaussian may model neighborhood function expression representing dimensional vector pointing location unit grid denoting distance units winner training iteration terms output space 
common practice training wide area output space subject adaptation 
spatial width units affected adaptation reduced gradually training process 
allows formation large clusters finegrained input discrimination training process 
spatial width adaptation guided means time varying parameter 
ci exp movement weight vectors consequence euclidean distance input weight vectors decreases weight vectors similar input pattern 
respective unit win presentations input pattern 
consequence adapting winner number units neighborhood winner leads spatial clustering similar input patters neighboring parts self organizing map 
similarities input patterns dimensional input space mirrored dimensional output space selforganizing map 
training process self organizing map describes topology preserving mapping high dimensional input space dimensional output space similar patterns mapped geographically close locations output space 
experimental document archive experiments classic time magazine document collection 
collection comprises time magazine articles early step documents mapped representation language order enable analyses 
process termed indexing information retrieval literature 
number different strategies suggested years information retrieval research 
common representation techniques single term full text indexing text documents accessed various words forming document extracted 
words may mapped just approximate word stem yielding called terms represent documents 
resulting set terms usually cleared called words words appear rarely document collection little influence discriminating different documents just unnecessarily increase computational load classification 
vector space model information retrieval documents contained collection represented means feature vectors form representation correspond index terms extracted documents described 
specific value corresponds importance index term describing particular document hand 
find lot strategies prescribe importance index term particular document 
loss generality may assume importance represented scalar range zero means particular index term absolutely unimportant describe document :10.1.1.57.3859
deviation zero proportional increased importance index term hand 
vector space model similarity documents corresponds distance vector representations 
indexing process time magazine collection identified content terms terms document representation omitting words appear documents 
terms roughly stemmed weighted tf idf weighting scheme term frequency times inverse document frequency 
weighting scheme favors terms appear frequently document rarely document collection 
various vectors representing documents neural network training 
experimental results document description outlined trained self organizing map represent contents document archive 
gives graphical representation training result 
unit marked document numbers documents unit won training 
quite obvious needs profound knowledge document archive order determine quality training result 
situation change dramatically say document titles document numbers 
just give examples title document reads allies horse cold war spirit moscow south nam coping 
leave reader guess subject matter documents 
self organizing map time magazine document collection order improve document space representation provide user semantically labeled units self organizing map derived labelsom method 
basically interested index terms best characterize documents mapped particular unit 
terms may regarded sort summary documents represented unit 
labeling analyze occurrence patterns index terms document representations 
particular deviation weight vector components respective components input vectors 
denoting set documents mapped unit may write deviation ik particular vector component index term expression 
index terms deviation certain threshold candidates labeling 
ik xj di ik jk application area information retrieval take care second criterion 
keyword document representation characterized fact term document matrix populated sparsely 
quite huge number index terms simply represent particular document term weight zero yield small deviation expression 
deviation zero possible index terms represent documents mapped particular unit 
usually interested terms describe set documents terms index terms labels corresponding weight vector value second threshold parameter rationale criterion weight vector entry particular index term tends represent average term weight documents represented unit 
high weight vector entries correspond roughly index terms important documents 
labels selected units 
labeled document space representation obviously easier explore contents unknown document collection 
consider example unit labeled soviet moscow nuclear negotiation treaty berlin west russia agreement pact undergo test 
documents see concerned negotiations led nuclear test ban treaty 
right hand side map find units representing documents respectively 
units labeled quite similarly 
look documents recognize unit contains documents discuss suggestion staff nato ships equipped polaris nuclear missiles multilateral crew members 
unit contains documents similar topic british french efforts building nuclear forces 
suggested transfer submarine polaris missiles european command 
british government accepted suggestion caused dispute french president general de 
upper right unit contains documents deals problems related birth malaysia independent state 
countries affected issue clearly visible labels name malaysia prime minister abdul rahman 
turning lower left part map find units 
labeled quite similar terms 
corresponding documents report religious problems south vietnam buddhist monks roman catholic government ngo 
neighboring units right 
concerned vietnam war mapped perfect region map 
example consider units 
labels obvious corresponding documents deal british keeler scandal 
script scandal british minister defense john affair christine keeler connections soviet secret service 
today point view kind funny history repeats document quoted keeler 
article reports speech wife left commons races park night cheek cheek tory party ball 
leave reader guess subject matter documents represented remaining units shown detail 
show labels units space considerations 
complete map available interactive exploration www ifs tuwien ac ifs research ir time notation refer unit located row column labels self organizing map time magazine document collection related text classification self organizing maps produced impressive record publications 
marks attempt self organizing map information retrieval setting 
authors report results classifying number technical documents keywords extracted various titles 
total document representation manually selected index terms really realistic 
line research continued time full text indexed documents realistic high dimensional document representation 
stream research direction followed project independent self organizing maps represent distributed document collection 
number papers published utilization self organizing maps interactive exploration document collections websom project :10.1.1.57.3859
interesting aspects radically different document representation seminal 
pragmatically speaking occurrence words document analyzed means selforganizing map leading word category map represent various documents contained archive 
apart self organizing map number artificial neural network architectures document classification 
comparison adaptive resonance theory self organizing maps provided results document classification 
severe shortcoming adaptive resonance theory lack intercluster similarity representation 
information concerning similarity documents assigned different classes training process deduced training result 
growing cell structures neural network adaptive architecture grows splits training process requirements input space document classification 
principle model feasible document classification intracluster similarities represented map display 
intercluster similarity represented 
additionally neural network model requires training parameters related network structure adaptation adjusted prior training process training results susceptible minor variations parameters 
series experiments hierarchical feature maps document archive organization described 
neural network model allows hierarchical document clustering relying predefined hierarchical neural network architecture 
hierarchical feature maps independent self organizing maps 
benefits related dramatically increased training speed second intuitive representation document similarity 
major shortcoming need defining hierarchical network architecture prior training requires knowledge particular characteristics document archive 
labelsom method provides straightforward way assigning labels units self organizing map 
attributes shared input signals mapped particular unit describe unit 
facilitates interpretation understanding contents selforganizing map features learned hardly possible additional information provided automatically created labels 
utilization labelsom method largely improves applicability self organizing map field information retrieval data mining general 
clusters identified map intuitively visible enhanced cluster visualization methods developed far characterized terms shared keywords 
benefits applicability labelsom method producing labeled self organizing map news magazine article collection read understood way expect manually indexed document archives 

honkela kaski lagus kohonen websom self organizing maps document collections proc workshop self organizing maps 

merkl visualizing similarities high dimensional input spaces growing splitting neural network proc int conf artificial neural networks 

kohonen self organized formation topologically correct feature maps biological cybernetics 

kohonen self organizing maps springer verlag berlin 

kohonen self organization large document collections state art proc int conf artificial neural networks 

lagus honkela kaski kohonen self organizing maps document collections new approach interactive exploration proc int conf knowledge discovery data mining 

lin soergel marchionini selforganizing semantic map information retrieval proc acm sigir int conf information retrieval 

merkl connectionist view document classification proc australasian database conf 

merkl content software classification self organization proc ieee int conf neural networks 
merkl exploration text collections hierarchical feature maps proc int acm si gir conf information retrieval 
merkl text classification selforganizing maps lessons learned neurocomputing 
miikkulainen script recognition hierarchical feature maps connection science 
rauber merkl creating order distributed digital libraries integrating independent self organizing maps proc int conf artificial neural networks 
rauber merkl digital library system neural networks 
proc acm int conf digital libraries 

ritter kohonen self organizing semantic maps biological cybernetics 
ramsey information forage adaptive visualization proc acm int conf digital libraries 
salton automatic text processing transformation analysis retrieval information computer addison wesley reading ma 
