optimizations dynamic inverted index maintenance doug cutting jan pedersen xerox palo alto research center coyote hill road palo alto california free text search rapidly evolving corpora dynamic update inverted indices basic requirement 
trees effective tool implementing indices 
zipfian distribution postings suggests space time optimizations unique task 
particular novel optimizations merge update performs better straight forward block update significantly reduces space requirements sacrificing performance 
inverted indices standard free text search methods information retrieval ir implemented efficiently inverted index 
include standard boolean extended boolean proximity relevance search algorithms 
inverted index data structure maps word atomic search item set documents set indexed units contain word postings 
individual posting may binary indication presence word document may contain additional information frequency document offset occurrence required various non boolean search algorithms 
simplify situation assuming word occurrence indexed corresponding posting 
approximation advantage amenable analysis 
access inverted index single key word interest efficient access typically implies index sorted organized hash table 
assume keys sorted 
hashing schemes interested reader directed 
part operational ir system properties formal description important 
concerned performance criteria ffl block update speed time required index documents 
presumed practical ir system manipulating indices large conveniently fit main memory inverted index represented data structure secondary storage 
insertion sorted structure best log operation number previously indexed postings measure performance number secondary storage 
justified noting sorts computations typically completely dominated disk access time 
ffl access speed time required access postings word 
search performance extremely user visible 
access time inherently log may require fewer log disk accesses 
ffl index size amount storage required inverted index 
record posting inverted index proportional number postings 
proportionality constant referred indexing overhead size index expressed percentage size entire corpus 
ffl dynamics ease inverted index incrementally updated 
particularly important rapidly evolving corpora 
insertion typically common deletion 
indexing schemes presume static corpus 
may updated reconstructing entire index 
discuss incrementally updatable indices 
ffl scalability relation corpus size 
indexing algorithms scale gracefully increasing corpus size 
particular main memory usage independent corpus size 
assume important seek methods perform axes 
trees file data structure particularly appropriate implementation dynamically modifiable inverted indices 
analyze trees task suggest novel time space optimizations 
trees conceptually tree maintains ordered sequence ary branching balanced tree tree resides secondary storage main memory 
nodes tree represented disk pages rebalancing algorithms insure insertion examination deletion entries log disk accesses branching factor tree number entries contained tree 
quantity log referred depth tree 
entries may enumerated sorted order time proportional requiring roughly disk accesses 
branching factor related page size average size entries typically fairly large say 
means entry tree containing entries may accessed disk accesses 
may improved retaining tree nodes pages main store 
page contains entries average holding page memory requires storage proportional root page kept core reduce number disk accesses required operation cost storing just entries 
similar gain cache immediate children root 
general cost access log gamma log disk accesses number entries stored core cache size 
note describing upper nodes caching strategy 
strategies lru cache similar performance characteristics 
entire tree represented core disk accesses required 
non terminal nodes cached core access operation may performed just disk access 
example tree size depth cache size guarantees random access just disk operation 
typical inverted index operation random access postings word sorted enumeration property tree may exploited prefix wild 
suppose words sorted lexicographic order words common prefix adjacent tree 
log storage allocated hold path pages root current point enumeration disk operation need occur adjacent entries 
naive tree indexing tree inverted index clearly addresses issues access speed dynamic update scalability 
access entry requires log disk accesses trees intrinsically updatable access times may reduced relatively small page caches 
discuss time required block update space occupied tree index 
analyze block update time terms number disk reads required 
actual update course requires disk writes read require write total cost update operation worse proportional number disk reads 
simple approach constructing tree inverted index consider entry pair form ordered word second location 
entry just posting ordered postings word adjacent 
random access postings word simply tree enumeration requiring disk access postings 
index update representation requires tree insert word instance new text 
indexing words new text requires log gamma log disk reads 
removal document accomplished expense insertion providing document available 
tokens comprising document longer available exhaustive enumeration index required find remove 
speed optimization shown number disk accesses required perform update reduced caching upper nodes tree core 
core memory buffer postings merged tree full disk accesses eliminated 
equation gives expected number disk reads insert new postings page cache containing room entries 
postings buffered sorted word core having instances words associated list postings 
time required sort core requires disk accesses event time required sort postings tree inserts 
merge time insert entries tree 
postings entry typically fit single tree page approximately equivalent disk access time inserts sort order 
assume entries uniformly distributed set keys ordered insert require average advance entries tree 
suppose log pages held core hold path root leaf 
cost advance estimated follows 
consider sub tree defined span advanced 
tree contains definition entries leftmost path core 
access entry span bring rightmost path core 
requires log disk transactions 
log log gamma log disk accesses required average index postings technique 
large frequency distribution unique words approximately follow zipf law words constant frequency word set instances rank frequencies words set postings 
note approximation vocabulary size frequency frequent word 
follows rdr ln words vocabulary size grows rapidly number word occurrences fact estimated demonstrate memory better utilized buffer page cache show constant cost disk accesses denoted greater denoted may expressed equating number postings memory may allocated page cache store postings buffer 
considerations ln log gamma log ln log gamma log clearly ln log ln suppose substitution ln log ln rearrangement ln ln gamma log ln substituting rearranging terms reduces ln gamma log gamma log ln log ln log log log ln ln ln gamma exponentiating sides leads ln ln ln gamma words iff inequality holds 
ln valid ln substantial exponent ln ln gamma close unity 
update case expect example consideration ln 

expect ln gamma log ln substantially fewer disk accesses required memory buffer sorting subsequently merging postings existing tree inverted index allocated tree page cache updates occurrence order 
table merge experiment predicted observed case reads reads writes cache merge cache merge cache merge cache merge experimental results table contains results experiments demonstrate effectiveness merge optimization 
initially tree created containing postings corpus word instances 
branching factor averaged depth 
ran cached merged updates new postings 
tree cache size merge buffer size trial set equal number new postings 
predictions equations 
observed results merge case higher expected due inaccuracies zipf law predicting vocabulary size observed results cases slightly higher expected equations account page reads due tree rebalancing 
writes exceed reads case due creation new pages 
space optimizations obvious redundancy naive indexing scheme word instance requires word 
set postings word decomposed word sequence locations redundancy eliminated 
small overhead performing grouping representation sequence locations requires record length termination 
prefix length indication preferred serve record marginal corpus frequency 
words addition requiring cell word location word additional cell required note total number locations 
example naive case words frequency occupy cells revised representation requires cells words frequency require cells representations 
general naive representations requires cells postings grouping requires ln cells vocabulary size postings 
ln smaller true ln 
ratio cells required strategies ln ln ln slightly 
grouping postings reduces space requirements 
words represented integers case lexicon built provide word number mapping locations integers cells may presumed roughly equivalent size 
case space analysis refers real sizes respective indices 
heap update grouped index may implemented considering variable length tree entries form marginal frequency word location refers corpus position single posting 
entry exists unique word tree ordering function need examine word 
difficulty immediately arises words large number postings 
recall definition maximum size tree entry tree page locations sequence overflows limit recourse available 
number locations fit btree page expect corpus size ln postings overflow limit highest frequency word 
situation may ameliorated indexing tuples form posi pos indicates position auxiliary data structure known heap file sequence locations 
suggested name heap file simply binary file manipulated main memory 
continuous chunks memory allocated necessary storage arbitrary data case location sequences 
update accomplished place sizes change sufficiently allocating new chunk hold updated sequence freeing old chunk 
implies chunks comprising heap file maintained dynamic storage allocation algorithm 
algorithm buddy system allocates chunks sizes powers 
arrangement insures chunks average full comparable storage utilization trees 
access individual postings list representation requires log disk reads log read tree entry followed access heap pos 
block update proceeds new instance encountered appending new location chunk pos computed adding pos incrementing additional cost incurred chunk filled contents copied freshly allocated twice larger chunk old chunk deallocated 
chunks allocated powers location sequence length copied log times 
amortized instance cost log additional accesses sufficiently small 
block update time proportional log gamma log postings 
merge optimization mentioned may applied case reduce expense tree page cache 
space requirements representation similar additional cell hold heap file pointer 
postings occupy ln cells 
ratio respect naive indexing strategy ln slightly greater 
heap file solves tree page overflow problem cost slightly increased access time slightly larger index size 
tree overflows occur relatively high frequency words 
observations leads consider buffering postings directly tree overflowing heap file necessary technique known 
essentially threshold chosen determines maximum number locations stored immediately 
updates directly tree new instances word seen locations pulsed heap 
words newest posting word appear directly tree additional postings heap file 
representation tree entries form posi word pos length locations convention pos need provided space saving measure 
words frequency postings directly accessible 
cost access log effective number postings tree estimate computing number occurrences words frequencies equal iff follows fw tg dr ln cost access log 
ln postings reside directly tree avoid heap file access probability ln ln expected access time worse log gamma log log gamma words comparison access accelerated hit rate potentially penalized larger tree size particular ratio access times log log gamma log log log ln gamma ratio greater iff log ln buffer postings tree page size directly tree 
page cache block update expected cost proportional log gamma log gamma representation occupies space heap file indirection avoided probability entry cells 
entry indirection uses cells 
space occupied postings fw tg fw tg dr dr ln gamma threshold may selected generate desired hit probability example 
achieve hit rate require 
words threshold reduces frequency access heap file 
delta encoding typical inverted index operation randomly accesses postings word 
postings typically processed linearly 
words inverted index need provide easy random access individual postings 
suggests sequence postings may compressed fashion requires worse linear time decode 
strategy arranges locations stored order indexed 
location represented integer integers allocated increasing manner particularly simple compression scheme term delta encoding possible 
storing actual location difference previous location delta stored 
yields sequence smaller integers original sequence locations 
uninteresting integers encoded way small integers occupy space large integers 
typical scheme performing encoding employs high order bit byte indicate byte need read 
bit bytes numbers may represented byte bytes 
word occurs average locations location average occupy byte 
order easily incrementally append new locations existing chunk locations having decode entire chunk size block location maintained 
maintained tree block 
preferred minimizes amount block touched 
information chunk position heap need stored words marginal frequency threshold application random access individual postings desirable deletion 
compression strategy delta encoding require read entire postings list word delete single entry require rewrite sequence postings changed 
words space access time optimized expense relatively rare operation 
free text search rapidly evolving corpora dynamic update inverted indices basic requirement 
trees effective tool implementing indices may optimized reduce access update time minimize size 
speed optimization merge update performs better straight forward block update space optimizations delta encoding significantly reduce space requirements sacrificing performance 
bayer mccreight 
organization maintenance large ordered indices 
acta informatica 
harman 
candela 
fast prototype retrieval system statistical ranking 
sigir forum summer 
heaps 
storage analysis compression coding document database 
infor february 
knuth 
art computer programming volume fundamental algorithms 
addison wesley 
knuth 
art computer programming volume sorting searching 
addison wesley 
salton 
automatic text processing 
addisonwesley 
salton mcgill 
modern information retrieval 
mcgraw hill 
zipf 
human behavior principle effort 
addison wesley 

