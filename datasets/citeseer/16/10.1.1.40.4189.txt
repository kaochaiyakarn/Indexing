lars niklasson department computer science university sweden lars ida se question connectionism offers new way looking cognitive architecture main contribution implementational account classical symbol view extensively debated decade 
special interest debate achieve tasks easily explained symbolic framework tasks seemingly require possession systematicity representation process novel way connectionist systems 
argue connectionism offer new framework aspects cognition 
specifically argue connectionism offer new notions compositionality content context dependence connectionist primitives architectures learning weights internal activations open new variations systematicity 
fodor pylyshyn published seminal defined relation systematicity systematic structure mental representations structure sensitivity mental processes compositionality method composing decomposing structured mental representations cognitive architecture debate intense 
main research agendas exhibit explain systematicity connectionist systems smolensky van gelder pollack chalmers niklasson sharkey niklasson van gelder phillips ii question relevance systematicity compositionality phenomenon altogether van gelder niklasson matthews 
success early connectionist counter examples questioned hadley 
noted examples success due constitution training set 
re formulated systematicity learning fashion defining different levels systematicity depending content training set 
identified levels systematicity weak systematicity concerned generalization novel sentences tokens appear syntactic positions appeared training quasi systematicity requires weak systematicity embedded structures strong systematicity requires quasi systematicity generalization syntactic positioning tokens 
hadley argued counter example achieved strongest form systematicity possible exception niklasson van gelder 
hadley concerned approach adopted niklasson van gelder generating representations 
separate network encoded syntactic information order generate similar distributed representations close representational space tokens similar types caused hadley classify result border line case 
phillips pointed connectionist architectures representations account strong systematicity 
restriction preclude separate mechanisms generating similarity representations subsequent systematicity tasks 
outlined research directions develop architectures support systematicity input output representations justify similarity distributed representations sufficient allowing systematicity 
directions exemplified hadley hayward showed network achieve stronger form systematicity semantic systematicity defined system possesses semantic systematicity strongly systematic assigns appropriate meanings words occurring novel test sentences demonstrate strong systematicity network hadley 
intention take research direction pointed phillips justify similarity representations sufficient systematicity 
forms justifications identified empirical justification exact boundaries systematicity phenomenon analytic approach ii technical justification related representational primitives connectionist architectures synthetic approach 
take define meaning content relation connectionist content context connectionist networks mikael department cs ee university queensland australia department computer science university sweden mikael ida se architectures learning weights internal activations show implications approach different compared notions 
argue view allows systematic processes sensitive syntax representation cornerstone traditional definition context content representations defined 
context naturally include processing expressions syntactic structure 
substantiate arguments examples performance results assign appropriate meaning admittedly somewhat different defined hadley novel test cases 
examples indicate approach empirically validated refuted 
approach accepted allow connectionists go traditional symbol processing account context dependent semantic systematicity 
content connectionist representations classical system appropriate meaning assigned words depending structural positioning representational tokens 
due definition classical system hinges possession combinatorial syntax semantics mental expressions 
definition states content complex representation function meaning constituents constituent structure representation 
kind connectionist system mind possess syntactically structured representations 
relies possession spatially structured representations formed result individual learning situation 
main difference approaches assumed trying extract content representations 
connectionist system spatial structure result specific learning situation 
generally contrary classical approach possible assume surrounding context constructing representations 
order objectively compare approaches argue allowed assumptions context constructing systematicity examples 
natural language examples difficult define complete contextual framework different domain including reasoning defaults exceptions 
propose understanding content context connectionist framework context supplied network defined terms training set 
content representations depends context 
organization representations arbitrary depends context expressed training set 
weights operating representations extract content expressed 
weights internal dynamics receiving units define content entails explanation systematic processes working representations possible 
possible objection view definition content argue line palmer definition information cognitive representation information contained representation operations defined obtain palmer exemplifies points 
input units connected logistic output unit weights respectively 
addition bias weight connected output unit 
shows particular weight configuration partitions input space allowing extraction content sample input representations network 
context relations expressed training set example representations belong category different 
seen network particular case learned classification 
clear weights trained network extract content input representations novel ones identify spatial regions different classes 
result particular learning situation 
lines represent different values simple example show organization representations locations points dimensional representational space sensitive particular context expressed training set 
need extend architecture features allowing learnable representations tokens 
input input bias architecture niklasson see 
architecture intended incorporate different kinds context 
simple hierarchical taxonomy birds ernie sparrow objects encoder oe generate compositional representations context 
addition representations needed train test inference network need generated bird fly bird fly 
done assertions encoder ae 
particular inferences valid particular context birds fact fly trained 
encoders standard raam networks pollack inference network related chalmers transformation network 
main difference chalmers network error feedback extension chrisman confluent representations 
network error feedback see allows representation object ernie affected relation objects domain assertions appears valid inferences part 
referred contextual feedback 
illustrative example oe trained encode node denoted oe bird nil bird oe sparrow bird sparrow oe ernie sparrow ernie oe penguin bird penguin oe tweety penguin tweety ae trained encode assertions ae bird fly ae bird fly ae sparrow fly ae sparrow fly ae penguin fly ae penguin fly ae ernie fly ae ernie fly ae ernie fly ae tweety fly ae tweety fly ae tweety fly ernie tweety possible inferences generated test purposes 
trained inferences ae bird fly ae bird fly ae penguin fly ae penguin fly ae sparrow fly ae sparrow fly relations encoded oe valid inferences visualized see graphical representation domain 
main purpose simplified example show architecture handle defaults exceptions relate points context content specific example 
shows particular network generalize novel situations ae ernie fly ae tweety fly visualization purposes dimensionality hidden layer encoders reduced units 
oe sequential raam left input slot size units right hidden layer 
representations atomic objects bird sparrow assigned element non overlapping representation 
ae sequential raam feedforward network 
hidden space encoded objects shown 
diagram hyperplanes weights connected output units units represented respectively representing classes bird sparrow penguin bird sparrow ernie tweety penguin isa fly bird nil bird bird nil sparrow bird sparrow sparrow bird ernie sparrow ernie ernie sparrow objects encoder oe bird fly bf bird fly bf bf assertions encoder ae bf inference network error feedback activation complete architecture 
oe ae standard raam networks 
noted show network different stages encoding process 
numbers indicate different error feedback feedback network feedback ae feedback ae oe 
feedback possible separate dictionary store representations bird relation constituents bird nil 
vectors classified bird penguin tweety sparrow ernie vectors classified vectors classified vectors classified included 
thing note representation bird top left corner close 
means members class bird penguin sparrow negative side hyperplane enforced class unit unit positive side unit 
representational region oe members bird class region positive side second hyperplane axis 
similarly region members sparrow class represented region hyperplanes penguin class top right region diagram 
reason bird ends sparrow class region representation chosen nil developed sparrow class 
essential current purposes 
assertion space representational regions fly easy identify 
regions defined output units ae 
fly located positive side negative side vice versa 
findings objects space useful assertion space turn space 
possible identify region assertion space instance new members penguin class 
note units oe axis receive activation members penguin class 
means new members class positive side hidden space oe ae 
please note locations space bird generated representation training bird 
units ae combined fly region appears 
combining hyperplanes possible define region correct inferences concerning penguin 
location positive side hyperplanes means inference network transform location assertion space classified fly zone hyperplanes 
note members penguin class guaranteed positive side hyperplanes 
receive activation ae transformed position close axis definitely axis novel member penguin class classified flying 
simulation see examples 
context dependent processing turn remaining issue resolved impact context solving practical problems 
refer simulations reported cf 
niklasson 
series simulations examined performance architecture problems involving defaults exceptions 
contexts test objects see evaluate performance architecture 
special interest evaluate effect contextual feedback different sub networks allowing fully context dependent representations 
sample contexts 
architecture trained contexts 
training tested content assigned test objects 
content assigned compared representations formed ae closest euclidean distance chosen 
reasons explained earlier somewhat misleading approach favor outcome means average runs give objective result 
run inference output 
size raams oe ae 
size 
experiment runs conducted contextual feedback enabled disabled 
training conducted epochs learning rate momentum 
results listed table 
interesting observations 
generally architecture supports shortest path reasoning 
contextual feedback preference obvious path long 
results show architecture feedback assigns positive negative content equal probability feedback vs feedback vs 
compare feedback increased bias shorter paths 
obvious reflection effect dramatic 
feedback outcomes occur equal probability 
feedback preference 
example compared extension famous nixon diamond nixon quaker republican colonel 

way reasoning majority categories nixon member non 
argued connectionism offer alternatives classical explanations cognitive phenomena provided content context defined terms natural connectionist architectures learning weights internal activations 
definitions provided connected example 
approach suggest accepted possible explain context independent reasoning see niklasson van gelder related architecture syntactic transformations contextdependent reasoning referring performance exhibited data sets 
phillips noted networks niklasson van gelder support systematicity table results data sets context object contextual feedback compositional level component level 
approach shows connectionist architectures support systematicity levels incorporating contextual feedback 
shown compositionality context dependence exist framework 
explanation supply weight regions expressing spatial structure mirror contextual similarities representations 
argued connectionist systems allowed assumption example domain 
small data sets give complete story serve useful indicators look 
quite easy define empirical investigation humans perform 
performances humans differ significantly performance architecture quite damaging argument 
view justified technical empirical grounds 
acknowledgment possible foundation knowledge competence development sweden author australian research council second author authors university sweden 
niklasson semantic systematicity context connectionist networks submitted connection science publishers 
chalmers syntactic transformation distributed representations connection science vol 
nos pp 
chrisman learning recursive distributed representation holistic computation connection science vol 
pp 

fodor pylyshyn connectionism cognitive architecture critical analysis connections symbols pinker mehler eds mit press pp 

concept representation representation concepts connectionist models ramsey rumelhart eds philosophy connectionist theory lea pp 

hadley compositionality systematicity connectionist language learning proceedings fourteenth annual conference cognitive science society pp 

hadley systematicity connectionist language learning mind language vol 

hadley systematicity revisited mind language vol 
blackwell publ pp 

hadley hayward strong semantic systematicity hebbian connectionist learning mind machines pp 

matthews concept monte explanation implementation systematicity synthese kluwer academic publishers pp 

niklasson sharkey connectionism issues compositionality systematicity cybernetics systems research trappl ed world scientific pp 

niklasson van gelder connectionist models exhibit explain non classical structure sensitivity proceedings sixteenth annual conference cognitive science society lea pp 

palmer fundamental aspects cognitive representation cognition categorization rosch lloyd eds lea hillsdale nj pp 

phillips strong systematicity connectionism tensor recurrent network proceedings sixteenth annual conference cognitive science society lea pp 

phillips feedforward recurrent networks systematic 
analysis implications connectionist cognitive architecture connection science publishing vol pp 

pollack recursive distributed representations artificial intelligence pp 
smolensky tensor product variable binding representation symbolic structures connectionist systems artificial intelligence pp 
van gelder compositionality connectionist variation classical theme cognitive science vol 
pp 

van gelder niklasson cognitive architecture proceedings sixteenth annual conference cognitive science society lea pp 

