language independent automated learning text categorization models apte damerau weiss acm sigir july ibm research report rc 
proceedings acm sigir language independent automated learning text categorization models apte fred damerau weiss ibm research division ibm research division rutgers university watson research center watson research center dept computer science yorktown heights ny yorktown heights ny new brunswick nj apte watson ibm com damerau watson ibm com weiss cs rutgers edu describe results extensive machine learning experiments large collections reuters english german newswires 
goal experiments automatically discover classi cation patterns assignment topics individual newswires 
results english newswire collection show avery large gain performance compared published benchmarks initial results german newswires appear promising 
methodology insensitive language document collections discuss issues related di erences results obtained collections 
carefully organized text storage retrieval systems texts classi ed codes chosen classi cation system 
examples include ntis national technical information service documents government news services reuters publications acm computing reviews 
assigning subject classi cation codes manually documents time consuming expensive 
shown certain environments knowledge systems code assignment quickly accurately hayes weinstein hayes 
human engineered rule models assigning subject codes relatively ective expensive time ort development continued support 
machine learning methods provide interesting alternative automating rule construction process 
report presents results experiments derive assignment rules automatically samples text classi ed 
awell known example knowledge system classi cation task construe system hayes reuters news service 
rule expert system manually constructed rules assign subject categories news stories reported recall precision test cases hayes weinstein 
exceptionally results test set relatively sparse compared number possible topics 
example machine learning system task system memory reasoning masand nearest neighbor style classi cation reported accuracy range dow jones news stories 
considering problem categorizing documents rule approach considerable appeal 
weighted solutions linear probabilistic methods lewis nearestneighbor methods may prove reasonable models employ explicitly interpretable 
human engineered systems successfully constructed rule solutions useful continue model compatible human expressed knowledge 
parsimonious interpretable nature decision rules readily augment knowledge verify rules examining related categorized documents 
report results obtained rule machine learning approach large collections reuters newswires english german 
collections essentially streams stories numbering tens thousands 
story associated headline date topics assigned reuters sta various fragments information mainly book keeping purposes 
goal computer system induce pattern directed rules automatically assigning topics 
interesting observations fact methodology perform equally english german collection suggesting approach may insensitive language issues making versatile portable technique document classi cation 
automated learning topic assignment models machine learning systems solve problems examining samples described terms measurements features 
machine learning methods applicable samples documents transformed type representation 
text categorization adaptation machine learning method implement main processes preprocessing step determining values features attributes representing individual documents collection 
essentially dictionary creation process 
representation step mapping individual document training sample dictionary associating label identi es category 
induction step nding patterns distinguish categories 
evaluation step choosing best solution minimizing classi cation error cost 
initial task produce list attributes samples text labeled documents dictionary 
attributes single words word phrases 
attribute list sample cases described terms words phrases documents 
case consists values attributes single article values boolean indicating attribute appears text numerical frequency occurrence text processed 
addition case labeled indicate classi cation topic article represents 
rule induction objective nd sets decision rules distinguish category text 
best rule set selected best rule set accurate excessively complex 
accuracy rule sets ectively measured large numbers independent test cases 
complexity measured terms numbers rules rule components smaller rule sets reasonably close best accuracy preferred complex rules sets slightly greater accuracy 
illustrates strategy 
dictionary created classi cation topic 
single words documents topic entered local dictionary 
local dictionary frequently occurring words features 
addition boolean features frequency counts occurrence words story complicated frequency related measures 
research machine learning text suggests simpler dictionaries single words give best performance 
mean best solution ignores phrases combinations words 
clearly combinations important understanding text 
burden shifted preprocessing program composes dictionary learning program nds solution 
research results suggest di cult nd right combinations words independent ultimate decision model 
implication analysis performance increased improved learning methods 
methods potentially nd higher order relationships feature space dictionary words 
main distinguishing characteristics approach rule induction model representation 
example rules illustrated table 
problem posed class problem 
rules satis ed story classi ed football 
decision reverts default class non football article 
applications text classi cation involve classes exclusive categories occur simultaneously 
problems handled multiple class problems 
rule tree induction methods extensively described published works breiman weiss kulikowski quinlan 
document indexing system rule induction technique called swap weiss indurkhya 
rule induction methods attempt documents document classification rules dictionary creation local model induction text representation frequency boolean machine learning architecture document classi cation rule class running back football article kicker football article reserve football article award player football article table example induced rule set nd compact covering rule set completely partitions examples correct classes 
covering set heuristically searching single best rule covers cases class 
having best conjunctive rule class rule added rule set cases satisfying removed consideration 
process repeated cases remain covered 
decision tree induction programs rule induction methods swap advantage uses optimization techniques revise improve decisions 
covering set separates classes induced set rules re ned pruning statistical techniques 
train test evaluation methods initial covering rule set scaled back statistically accurate subset rules 
document classi cation application swap induces rules represent patterns combinations attributes determine class article 
result applying swap training set cases set rules table associated error rates training test samples 
results applying rule set table illustrated table 
detailed discussion swap document classi cation experiments appears apte 
results english reuters newswires provide objective basis comparison results particularly lewis lewis extensive number runs english reuters data 
news stories 
stories april th independent test cases remaining obtained anonymous ftp pub doc reuters ftp cs umass edu 
free distribution research purposes granted reuters carnegie group 
arrangements access david lewis 
training cases football football football football test cases football football football football table example estimated performance rule set data training cases 
data consists training cases test cases 
topics interest topics occurring training data 
newswires stories empty topic assignments 
chose ignore stories learn test 
result raw data worked training cases test cases 
derived dictionaries attributes raw document training data applied rule induction machine learning methods swap 
experiment topic random subset corresponding training data reserved error estimation 
recursively pruned rule sets evaluated randomly selected cases help select best rule set 
estimates cases generally performance selected rule sets independent test cases april th 
wheat farm 
wheat wheat commodity 
wheat export 
wheat wheat agriculture 
wheat wheat 
wheat wheat winter soft 
wheat test cases wheat wheat wheat wheat table induced rule set performance test data reuters english wheat category dictionaries created di erent ways 
approach local dictionary procedure frequent words topic generated 
brief universal list stopwords maintained words removed frequent words 
second approach create universal dictionary counting words documents training set words 
depending topic variable number features derived entropy feature selection method 
universal dictionary approximately features number features selected category ranged 
text representation experimented frequency boolean features 
performance measured recall precision 
recall percentage total documents topic correctly classi ed 
precision percentage predicted documents topic correctly classi ed 
document topics mutually exclusive document classi cation problems usually analyzed series dichotomous classi cation problems topic vs topic 
example table illustrates rule set induced wheat category local dictionary boolean representation text 
included gure performance table rule set reuters post april test data 
rule evaluation table table measure performance wide variety metrics error rates costs 
purpose study wehave chosen measure lewis ringuette 
toevaluate performance entire set topics results microaveraged performance tables topics added recall precision computed 
point recall equals precision breakeven point single summarizing measure comparison results 
breakeven point combinations dictionaries features illustrated table 
addition previously reported breakeven points decision trees lewis ringuette probabilistic method lewis listed 
text treated learning method dictionary text representation performance breakeven optimized rule induction local frequency headlines frequency boolean universal frequency boolean decision tree probabilistic bayes table breakeven points reuters english data uniformly breakeven point local dictionary frequency features 
newswire stories contain line headline provide additional clues topic 
words occurring headline additional emphasis counting twice uniform count words headline body article performance local dictionary frequency features increased breakeven point 
breakeven point summary measure text categorization recall precision may 
illustrates performance rule induction variations 
determine breakeven point learning experiments performed parameter varied elicit tradeo recall precision 
appropriate technique may vary learning method 
rule induction traditional goal minimize number errors 
may occur breakeven point 
standard approach substituting costs errors vary recall precision 
cost false negative counted error cost false negative counted errors 
ect increasing cost false negatives increase recall expense precision 
experiments reuters data breakeven point achieved near cost setting 
precision recall headline local frequency local frequency local boolean universal frequency universal boolean recall precision tradeo reuters english data results german reuters newswires best results obtained english reuters data observed salient features automated learning methodology cost equivalent usual minimum error criterion 
usage local dictionaries individual topic 
language independent match mechanism determining entries local dictionary 
usage frequency occurrence local dictionary entries feature vector representing news stories 
weighting terms encountered headlines stories 
methodology rely language speci technique hypothesized perform similarly document collections languages 
provide objective veri cation hypothesis conducted detailed experiments german reuters data 
news stories 
stories july st independent test cases remaining data training cases 
data consist training cases test cases 
topics interest 
security council 
military 
rockets 
bosnia 
nato 
soldiers 
test cases table induced rule set performance test data reuters german defence category simple list topics english reuters collection topics german reuters formed taxonomy 
major topics levels hierarchies major level 
leaf level hierarchy encountered stories topic 
german reuters topics broader ones saw english reuters 
preliminary analysis suggested variability assigning topics stories 
assigning topics taxonomy story complete assignment include topic level taxonomy story 
analysis collection indicated humans assigned fewer topics story deemed appropriate 
poses problem classi cation learning apparatus 
assuming system attempting learn topic assignment model topic training cases sets examples set corresponds newswires topics set corresponds newswires topics 
disparity assignment observed raw data possibly inthe set stories topics direct indirect parents children classi cation taxonomy 
cause weakening classi cation tests strong discriminators 
modify machine learning apparatus learn topic assignment presence uncertainty 
training set prepare may modi ed simple extended fashion simple remove direct parents children competition direct descendants topic remove stories set topics direct parents children extended remove ancestors descendants competition topic remove stories set topics direct indirect parents descendants assumption extended option result categorization models accurate ran experiments extended modi cation option exactly apparatus obtaining best results english reuters 
pre stopword top word local dictionary topic averaged words post stopword dictionary 
collection obtained ibm research reuters exclusive ongoing research 
table illustrates example induced rule set performance topic defense 
rules example topics intuitively appropriate part 
table illustrates breakeven performance obtained variations tried far 
note lower levels tested topics newswires newswires 
top level chose topics su cient newswires available 
observe performance declines include topics fewer newswires 
topics selected number topics performance breakeven breakeven cost top level lower levels newswires lower levels newswires levels newswires levels newswires table breakeven points reuters german data current hypothesis slightly lower performance compared english reuters twofold 
sample size working german collection far smaller english collection 
secondly uncertainties introduced due incomplete topic assignments reuters sta taxonomic viewpoint fully resolved existing methodology need continued investigation 
discussion methodology automatic generation text categorization models perform consistently document collections languages 
hypothesis match mechanism creating dictionary tokens representing text ability rule induction process learn category distinguishing pattern sets tokens principle components provide pattern directed language independent classi cation power 
compared previous results english reuters data new results appear signi cantly better 
suggests local dictionaries frequency information ective improved results rule induction methods 
far greatest improvement came learning method swap 
previous experience shown optimization techniques rule induction method substantially improve results competitive methods decision trees text classi cation optimized rule induction particularly suitable 
optimization techniques employed quite strong nding feature dependencies 
terms text classi cation means single word dictionaries nd key word combination occurrences distinguish topics 
source uncertainty german newswires caused hierarchic classi cation system 
top level classes problem 
uniform pattern human code assignment top level 
stories top level code assigned 
compared story leaf node code assigned lies hierarchy 
assignment top level code considered equivalent leaf node code 
stories computing classi cation results test data set 
issues require continued investigation 
german language salient major di erences english language family 
rst german heavily ected language suppose important normalize word forms stems 
results bear 
appears frequent non common words features tend occur ection topic part 
second major di erence german tends word formations involving stems form single word english noun phrase 
suppose need decomposed 
results support 
relatively long compounds occur features considered specialized idioms decomposed 
example experiment top non common word stems features category politics compounds exterior minister human rights minister president partner states arguably idioms context 
experiments appears optimized rule induction competitive machine learning techniques masand lewis ringuette lewis document classi cation close human engineered systems hayes weinstein 
supported rigorous comparisons 
english reuters stories widely circulated prove objective comparisons 
german reuters collection hopefully provide additional benchmark continue extend results 
apte apte damerau weiss 
automated learning rules text categorization 
technical report rc ibm watson research center 
appear acm transactions ce information systems 
breiman breiman friedman olshen stone 
classi cation regression trees 
wadsworth ca 
hayes weinstein weinstein 
adding value financial news computer 
proceedings international conference onarti cial intelligence applications wall street pages 
hayes hayes andersen nirenburg schmandt 
tcs shell content text categorization 
proceedings sixth ieee pages 
lewis ringuette lewis ringuette 
comparison learning algorithms text categorization 
symposium document analysis information retrieval nv april 
univ nevada las vegas 
appear 
lewis lewis 
evaluation phrasal clustered representations text categorization task 
proceedings fifteenth annual international acm sigir conference development information retrieval pages june 
edited nicholas belkin peter ingwersen mark pejtersen 
lewis lewis 
feature selection feature extraction text categorization 
speech natural language workshop pages february 
sponsored defense advanced research projects agency 
masand masand waltz 
classifying news stories memory reasoning 
proceedings fifteenth annual international acm sigir conference development information retrieval pages june 
edited nicholas belkin peter ingwersen mark pejtersen 
quinlan quinlan 
programs machine learning 
morgan kaufmann 
weiss indurkhya weiss indurkhya 
optimized rule induction 
ieee expert december 
weiss kulikowski weiss kulikowski 
computer systems learn 
morgan kaufmann 
