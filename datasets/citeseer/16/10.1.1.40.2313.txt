td gammon 
jordan pollack alan blair computer science department brandeis university waltham ma pollack blair cs brandeis edu td gammon major successes machine learning led similar impressive breakthroughs temporal difference learning applications games 
able replicate success td gammon developing competitive evaluation function parameter feed forward neural network back propagation reinforcement temporal difference learning methods 
apply simple hill climbing relative fitness environment 
results analysis suggest surprising success tesauro program evolutionary structure learning task dynamics backgammon game 
took great gerald tesauro start wasting computer cycles temporal difference learning game backgammon tesauro 
letting machine learning program play hopes expert 
dream computers mastering domain self play introspection early days ai forming part samuel checker player samuel donald michie tic tac toe learner michie 
self conditioning systems weak non existent internal representations generally fraught problems scale abandoned field ai 
self playing learners usually develop brittle strategies allow draw play poorly humans programs 
tesauro result showed self play approach powerful refinement millions iterations self play td gammon program best backgammon players world tesauro 
derived weights viewed significant intellectual property keep trade secret leverage sales minority operating system international business machines 
replicated td result research purposes boyan commercial purposes 
respect goal self organizing learning machine starts minimal specification rises great sophistication td gammon stands 
success understood explained replicated domains 
td gammon news reinforcement learning method 
hypothesis success td gammon due back propagation reinforcement temporal difference technologies inherent bias dynamics game backgammon evolutionary setup training task dynamically changes learning progresses 
test hypothesis simpler evolutionary learning method backgammon hill climbing 
setup standard feedforward neural network layers sigmoid function set fashion tesauro units represent number player pieces points plus units indicate bar board 
addition added unit reports game reached endgame race situation making total input units 
fully connected hidden units connected output unit judges position 
including bias hidden units total weights 
game played generating legal moves converting proper network input picking position judged best network 
started weights set zero 
initial algorithm hillclimbing 
add gaussian noise weights 
play network mutant number games 
mutant wins half games select generation 
noise set step rms distance euclidean distance divided 
surprisingly worked reasonably 
networks evolved improved rapidly 
problem perceived comparing close backgammon players tossing biased coin repeatedly may take dozens hundreds games find sure better 
replacing tested champion dangerous information prove challenger really better player just lucky novice 
burden system computation introduced modifications algorithm avoid douglas effect firstly games played pairs order play reversed random seed generate dice rolls games 
unfairness due dice rolls networks close particular identical result win 
secondly challenger wins contest just replacing champion challenger small adjustment direction champion champion challenger idea similar inertia term back propagation introduced assumption small changes weights lead small changes decision making evaluation function 
preserving current champion decisions catastrophic replacement champion lucky novice challenger 
initial stages evolution pairs parallel games played challenger required win games 
shows players rated pubeval strong public domain player trained tesauro human expert preferences 
things note percentage losses pubeval falls generations frequency successful increases time player improves epochs starting performance pubeval begins 
fact shows simple self playing hill climber capable learning 
second fact quite counter intuitive expected player improved harder challenge 
true respect uniform sampling dimensional weight space true sampling neighborhood player player part weight space small changes weights lead similar strategies ones moves situations 
games determine relative fitness increased frequency change allows system drift may account subsequent degrading performance 
counteract drift decided change rules engagement evolution proceeds annealing schedule generations number games challenger required win increased generations increased 
numbers chosen ad hoc basis observing frequency successful challenges 
games developed surprisingly strong player capable winning games pubeval 
networks sampled generations order test performance 
networks generation extracted benchmarks 
shows percentage losses sampled players benchmark networks 
note curves cross line respectively show general improvement time 
game backgammon called bear yardstick progress learning 
bear occurs player pieces player home points dice rolls remove pieces set racing board pieces player point piece point played player games averaging number rolls 
monotonic improvement rolls generations 
pubeval scored task 

percentage losses generation players pubeval 
match consisted games 
generation loss discussion machine learning evolution believe evidence success learning backgammon simple hillclimbing indicates reinforcement temporal difference methodology tesauro td gammon non essential success 
success came setup evolutionary self play biased dynamics backgammon 
result similar bias mitchell crutchfield packard evolution cellular automata edge chaos packard mitchell 
td gammon major milestone kind evolutionary machine learning initial specification model far simpler expected learning environment specified implicitly emerges result evolution learning system training environment learner embedded environment responds improvements spiral 
effect seen population models completely unexpected hillclimbing evolution 
evolution explored hillis hillis sorting problem angeline pollack angeline pollack genetically programmed tic tac toe players predator prey games 
cliff miller reynolds pollack intertwined spirals problem pollack 
rosin belew applied competitive fitness games rosin belew :10.1.1.30.1584
tesauro td gammon date viewed instance evolutionary learning sims artificial robot game sims domain complex backgammon substantial success 
learnability learnability formally defined time constraint search space 
hard randomly pick floating point weights backgammon evaluator 
simply impossible 
hard find weights better current set 
initially weights random quite easy 
playing improves expect get harder harder similar probability tornado constructing 
search neighborhood current weights find players moves capitalize slightly different choices exposed weaknesses tournament 

percentage losses benchmark networks generation lower middle upper 
loss generation setting parameters initial runs involved guesswork large set players examine try understand phenomenon 
th th th champions run sampled random players neighborhoods different rms distances find find winning challenger 
took random neighbors different rms distances played games corresponding champion 
plots average number games won champions range neighborhoods 
graph demonstrates players improve time probability finding neighborhood increases 
accounts frequency successful challenges goes 
successive challenger required take small step changing moves champion order beat 
evolution apparently learnable convert single question continuous stream questions dependent previous answer 
avoiding mediocre stable states general problem learning self play player keep playing kinds games exploring narrow region strategy space missing critical areas game vulnerable programs human experts 
learning system declare success reality simply converged mediocre stable state continual draws long term cooperation merely mimics competition 
state arise human education systems student gets answers right rewards teacher positive feedback asking harder questions 
problem particularly prevalent self play deterministic games chess tic tac toe 
worked population get angeline pollack 
schraudolph added non determinism game go choosing moves boltzmann distribution statistical mechanics 
fogel expanded exploration forcing initial moves 
epstein studied mix training self play random testing playing expert order better understand phenomenon 
suggesting hillclimbing advanced machine learning technique bring tasks 
internal cognition opponent behavior evolution usually requires population 
dynamics backgammon helpful permitted td 
distance versus probability random challenger winning champions generation 
rms distance fr om champion wins challenger learning hill climbing succeed clearly fail tasks games scale 
understand backgammon domain led successful acquisition expert strategies random initial conditions able re cast domains image 
tesauro pointed features backgammon suitable approaches involving self play random initial conditions 
chess draw impossible game played untrained network making random moves eventually terminate may take longer game competent players randomness dice rolls leads self play larger part search space explore deterministic game 
believe simply dice rolls overcome problems self learning 
tried add randomness deterministic games generally met success 
critical dynamics backgammon sets apart games random elements monopoly 
outcome game continues uncertain contact broken side clear advantage 
observers find exciting backgammon helps novice overcome expert number situations dice roll improbable sequence dramatically reverse player expected win 
learning system viewed meta game teacher student identical self play situation 
teacher goal expose student mistakes student goal teacher avoid exposure 
mediocre stable state self learning system seen equilibrium situation 
player learns repeatedly draw meta game equilibrium learning 
draws allowed may possible self playing learner collude simulate competition cooperating angeline 
example slightly suboptimal moves allow player throw game player self play find meta game equilibrium alternately throwing games 
hypothesis dynamics backgammon discussed actively prevent sort collusion forming meta game self learning 
tesauro result beat sun achieved parity trained expert knowledge 
available 
td learning incorporated number hand crafted expert knowledge features eventually producing network achieved world master level play tesauro 
features included concepts existence prime probability hit probability escape opponent barrier 
best players win pubeval trained comparison training tesauro 
believe players achieve approximately power tesauro results advanced learning algorithms 
claim generation player td gammon ready challenge best humans just surprisingly considering humble origins hill climbing relative fitness measure 
tuning parameters adding input features powerful players point study 
td gammon remains tremendous success machine learning causes success understood 
replicating td gammon success simpler learning paradigm find primary cause success dynamics backgammon combined power evolutionary learning 
isolate features backgammon domain enable evolutionary learning may lead better understanding conditions necessary general complex self organization 
acknowledgments supported onr foundation postdoctoral fellowship 
gerry tesauro providing pubeval subsequent means calibrate jack laurence pablo funes development www front evolved player 
interested players challenge evolved network web browser home page www demo cs brandeis edu angeline 

alternate interpretation iterated prisoner dilemma evolution non mutual cooperation 
brooks maes editors proceedings th artificial life conference pages 
mit press 
angeline pollack 

competitive environments evolve better solutions complex tasks 
forrest editor genetic algorithms proceedings fifth inter national conference 
boyan 

modular neural networks learning context dependent game strategies 
master thesis computer speech language processing cambridge university 
cliff miller 

tracking red queen measurements adaptive progress evolutionary simulations 
third european conference artificial life pages 
hillis 

evolving parasites improves simulated evolution optimization procedure 
langton taylor rasmussen editors artificial life ii 
addison wesley reading ma 
international business machines sept 
ibm family os warp hits retail shelves 
pollack 

massively parallel genetic programming 
angeline kinnear editors advances genetic programming ii 
mit press cambridge 
michie 

trial error 
science survey part pages 
penguin 
mitchell crutchfield 

revisiting edge chaos evolving cellular automata perform computations 
complex systems 
packard 

adaptation edge chaos 
kelso editors dynamic patterns complex systems pages 
world scientific 
reynolds 

competition coevolution game tag 
proceedings th artificial life conference 
mit press 
rosin belew 

methods competitive evolution finding opponents worth beating 
proceedings th international conference genetic algorithms pages 
morgan kaufman 
samuel 

studies machine learning game checkers 
ibm research development 
sims 

evolving morphology behavior competition 
brooks maes editors proceedings th artificial life conference 
mit press 
tesauro 

connectionist learning expert preferences comparison training 
touretzky editor advances neural information processing systems volume pages denver 
morgan kaufmann san mateo 
tesauro 

practical issues temporal difference learning 
machine learning 
tesauro 

temporal difference learning td gammon 
communications acm 
