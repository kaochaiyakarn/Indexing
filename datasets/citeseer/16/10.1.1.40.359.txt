coding analysis interpretation recognition facial expressions describe computer vision system observing facial motion optimal estimation optical flow method coupled geometric physical motion dynamic models describing facial structure 
method produces reliable parametric representation face independent muscle action groups accurate estimate facial motion 
previous efforts analysis facial expression facial action coding system facs representation developed order allow human psychologists code expression static pictures 
avoid heuristic coding scheme computer vision system probabilistically characterize facial motion muscle activation experimental population deriving new accurate representation human facial expressions call facs 
show method coding analysis interpretation recognition facial expressions 
keywords facial expression analysis expression recognition face processing emotion recognition facial analysis motion analysis perception action vision hci 

faces keys individual identity play major role communication interaction machine understanding perception modeling human expression important problem computer vision 
significant amount research facial expressions computer vision computer graphics see review 
fundamental problem area categorize active spontaneous facial expressions extract information underlying emotional states 

large body dealing human perception facial motions exists attempt develop objective methods quantifying facial movements 
irfan essa college computing gvu center georgia institute technology atlanta ga usa 
irfan cc gatech edu 
important area ekman friesen produced widely system describing visually distinguishable facial movements 
system called facial action coding system facs enumeration action units face cause facial movements 
recognized limitation method lack temporal detailed spatial information local global scales 
additionally heuristic dictionary facial actions originally developed coding emotion initial experimentation proven quite difficult adapt machine recognition facial expression 
improve situation objectively quantify facial movements computer vision techniques 
consequently goal provide method extracting extended facs model facs coupling optical flow techniques dynamic model motion may physics model skin muscle geometric representation face motion specific model 
show method capable detailed repeatable facial motion estimation time space sufficient accuracy measure previously unquantified muscle relates facial motions facial expressions 
demonstrate parameters extracted method provide improved accuracy analysis interpretation coding recognition facial expression 
background representations facial motion ekman friesen produced system describing visually distinguishable facial movements called facial action coding system facs 
enumeration action units aus face cause facial movements 
aus facs account changes facial expression 
combination action units result large set possible facial expressions 
example smile expression considered combination pulling lip corners au mouth opening au upper lip raiser au bit furrow deepening au type smile variations motions having different intensity actuation 
despite limitations method widely method measuring human facial motion human machine perception 
tracking facial motion attempts track facial expressions time 
mase pentland track action units optical flow 
method simple physical model formulated statically dynamic optimal estimation framework results sufficiently show usefulness optical flow observing facial motion 
terzopoulos waters developed sophisticated method tracked linear facial features estimate corresponding parameters dimensional wireframe face model allowing reproduce facial expressions 
significant system requires facial features highlighted successful tracking 
li robert describe approach control feedback loop visualized analyzed facial image coding system 
similar goals implementation different 
main limitation lack detail motion estimation large predefined areas observed affine motion computed area 
limits may acceptable loss quality image coding applications 
purposes limitation severe means observe true patterns dynamic model changes muscle method assumes facs model underlying representation 
interested developing representation dependent facs suitable just tracking recognition analysis 
recognition facial motion recognition facial expressions achieved categorizing set predetermined facial motions facs determining motion facial point independently 
approach taken researchers recognition systems :10.1.1.27.7641
yacoob davis extend mase detect motion directions predefined hand initialized rectangular regions face simplifications facs rules universal expressions recognition 
motion rectangular regions frames correlated facs rules recognition 
black yacoob extend method local parameterized models image motion deal large scale head motions 
methods show accuracy recognizing expressions database expressions :10.1.1.27.7641
mase smaller set data test cases obtained accuracy 
ways impressive results considering complexity facs model difficulty measuring facial motion small windowed regions face 
view principle difficulty researchers encountered sheer complexity describing human facial movement facs 
facs representation large number aus combine extremely complex ways give rise expressions 
growing body psychological research argues dynamics expression detailed spatial deformations important expression recognition 
researchers claimed timing expressions completely missing facs critical parameter recognizing emotions 
issue addressed nsf workshops reports facial expressions 
strongly suggests moving away static dissect change analysis expression facs model developed face analysis facial dynamics motion sequences 

visual coding facial motion vision sensing visual motion optical flow processing basis perception measurement facial motion 
simoncelli method optical flow computation uses multi scale coarse fine kalman algorithm provides motion estimates information 
method compute estimated mean velocity vector vi estimated flow time 
store flow covariances different frames determining confidence measures error corrections observations dynamic model see section observation loop 
facial modeling facial structure required framework 
face model elaboration facial mesh developed platt badler 
extend topologically invariant physics model adding anatomically muscles 
order conduct analysis facial expressions define new suitable set control parameters facs vision observations require model time dependent states state evolution relationships 
facs related au descriptions purely static passive association facs descriptor dynamic muscle inherently inconsistent 
modeling elastic nature facial skin anatomical nature facial muscles develop dynamic element centroid thickness hi ai aj ak total area hi hj hk ai assemble mesh 
geometric mesh determine continuum mechanics parameters skin finite element methods 
muscle model face including facs control parameters see implementation details 
physically dynamic model face may constructed finite element methods 
methods give facial model anatomically facial structure modeling facial tissue skin muscle actuators geometric model describe force deformations control parameters 
defining triangles polygonal mesh triangular shell element calculate mass stiffness damping matrices element dv tel thickness material properties skin acquired 
assemblage process direct stiffness method required matrices mesh determined 
integration compute matrices done prior assemblage matrices element may different thickness tel large differences thickness neighboring elements suitable convergence 
step formulating dynamic model face combination skin model dynamic muscle model 
requires information attachment points muscles face geometric case attachment vertices geometric surface mesh 
pieper waters provides required detailed information muscles muscle attachments 
dynamic modeling estimation initialization model image developing representation facial motion compare new data need locate face facial features image followed registration features faces database 
initially started estimation process manually translating rotating deforming facial model fit face image 
automate process original image eyes lips face model nose extracted mask warped canonical model masked points extracted 
initialization face image modular eigenfeatures method canonical model face 
view modular eigenspace methods pentland moghaddam :10.1.1.50.71
method automatically extract positions eyes nose lips image shown 
feature positions warp face image match canonical face mesh 
allows extract additional canonical feature points image correspond fixed non rigid nodes mesh 
initial registering model image coarse fine flow computation methods simoncelli wang compute flow :10.1.1.30.656
model face image tracks motion head face correctly long excessive amount rigid motion face expression 
limitation addressed methods attempt track stabilize head movements 
images face model simoncelli coarse fine algorithm optical flow computations provides estimated flow vector vi 
mapping function compute velocities vertices face model vg 
physically modeling techniques relevant geometric physical models described earlier calculate forces caused motion 
mapping global information image image geometric model concern translations vector rotations matrix 
galerkin polynomial interpolation function strain displacement function mass stiffness damping matrices basis finite element method applied describe deformable behavior model 
frontal view determine fa physics control parameters muscle activation control input facial expressions motion field observations observation errors feedback dynamics geometry shape parameters state estimates 
block diagram control theoretic approach 
showing estimation correction loop dynamics loop feedback loop 
cial motion model expressions possible prepared estimate velocities motions third axis going image axis 
accomplish define function spherical mapping spherical coordinates 
spherical function computed prototype model face spherical parameterization canonical face model wrap image shape 
manner determine mapping equation vg vi hsr vi rest specified talk velocities assume mapping applied 
estimation control driving physical system inputs noisy motion estimates result divergence chaotic physical response 
estimation control framework needs incorporated obtain stable results 
similar considerations motivated control framework 
shows framework estimation control active facial expression modeling system 
sections discuss formulations 
continuous time kalman filter allows estimate uncorrupted state vector produces optimal squares estimate quite general conditions 
kalman filter particularly suited application recursive estimation technique introduce delays system keeping system active 
system bu ect linear squares estimate error covariance matrix 
kalman gain matrix obtained solving riccati equation obtain optimal error covariance matrix dt ea pg ec solve equation assuming steady state sys tem dt 
kalman filter equation mimics noise free dynamics corrects estimate term proportional difference innovations process 
correction observation best prediction previous data 
shows estimation loop bottom loop correct dynamics error predictions 
optical flow computation method established probability distribution respect observations 
simply distribution dynamic observations relationships 
obtain vi control measurement correction dynamic motion control theory approach obtain muscle 
derived observed image velocities 
control input vector provided control feedback law gx control feedback gain matrix 
assume instance control study falls category optimal regulator need optimality criteria optimal solution 
optimal control law optimal state trajectory pc solving matrix riccati equation 
real symmetric positive semi definite state weighting matrix real symmetric positive definite control weighting matrix 
comparing control feedback law obtain pc 
control loop shown block diagram upper loop 
motion templates facial model far discussed extract muscle observed expression 
methods relied detailed geometric physics description facial structure 
control theoretic approach extract corrected motion field associated facial expression 
words dynamics motion implicit analysis explicitly require geometric physical model structure 
detailed models back project facial surprise smile model motion energy 
determining expressions video sequences 
show expressions smile surprise show model surprise smile expressions show spatiotemporal motion energy representation facial motion expressions 
motion models models extract representation state space models 
just motion velocity measurements analysis interpretation recognition geometric physical models 
possible motion energy templates encode just motion 
encoded motion representation facial action 
system shown employs optimal estimation optimal control feedback framework 
maps motion observations images dynamic model estimates corrected motions optimal dynamic model correct observations model 
show corrected flow expressions raise eyebrow smile show corrected flow applied dynamic face model 
corrections possible deformations facial skin model constraints state space measures image motion 
methodology detailed geometric physical models back projecting facial motion estimates image remove complexity physics modeling representation fa expression magnitude control point deformation au raising eyebrow defs time shape pe control points defs time shape pe control points 
facs candide deformation vs observed deformation raising eyebrow expression 
surface plots top show deformation time facs actions au bottom actual video sequence raising eyebrows 
cial motion 
learning ideal motion views motion energy expression characterize spatio temporal templates expressions 
shows examples representation facial motion energy 
representation facial motion generating spatio temporal templates coding interpretation recognition facial expressions 

analysis representations goal develop new representation facial action accurately captures characteristics facial motion employ recognition coding interpretation facial motion 
current state art facial descriptions facs muscle control versions facs major weaknesses action units purely local spatial patterns 
real facial motion completely localized ekman described action units unnatural type facial movement 
detecting unique set action units specific facial expression guaranteed 
time component description heuristic 
emg studies known expression magnitude control point deformation au smile defs time shape pe control points defs time shape pe control points 
facs candide deformation vs observed deformation happiness expression 
surface plots top show deformation time facs action au bottom actual video sequence happiness 
facial actions occur distinct phases application release relaxation 
contrast current systems typically simple linear ramps approximate actuation profile 
coarticulation effects accounted facial movement 
limitations facs include inability describe fine eye lip motions inability describe coarticulation effects commonly speech 
muscle models computer graphics alleviated problems simple accurately describe real facial motion 
method lets characterize functional form actuation profile lets determine basis set action units better describes spatial properties real facial motion 
evaluation important part need experiment extensively real data measure validity new representation 
purpose developed video database people making expressions results video sequences users making different expressions 
expressions acquired frames second full ntsc video resolution 
currently subjects video taped making expression demand 
demand expressions limitation subjects emotion generally relate expression 
moment interested measuring facial motion human emotion 
paragraphs illustrate resolution representation smile eyebrow raising expressions 
questions repeatability accuracy briefly addressed 
spatial patterning illustrate new parameters facial expressions spatially detailed facs comparisons expressions raising eyebrow smile produced standard facs muscle activations visually extracted muscle activations shown 
top row shows au raising eyebrow facs model linear actuation profile corresponding geometric control points 
type spatio temporal patterning commonly computer graphics animation 
bottom row shows observed motion control points expression raising eyebrow paul ekman 
plot achieved mapping motion facs model control points measured 
seen observed pattern deformation different assumed standard implementation facs 
wide distribution motion control points just largest activation points 
similar plots smile expression shown 
observed distributed patterns motion provide detailed representation facial motion show sufficient accurate characterization facial expressions 
temporal patterning important observation facial motion apparent facial motion far linear time 
observation important facial motion studied muscles fact effector facial motion underlying parameter differentiating facial movements facs 
top rows show development facs expressions represented muscle actuation step function profile 
show plots facial muscle observed smile eyebrow raising expressions 
purpose illustration face muscles combined local groups basis proximity regions effected 
seen simplest expressions require multiple muscle 
particular interest temporal patterning muscle 
fit exponential curves activation release portions muscle actuation profile suggest type rise decay seen emg studies muscles 
data suggest relaxation phase muscle actuation due passive stretching muscles residual stress skin 
note smile expression shows second delayed actuation muscle group frames muscle actuation application release relax bx bx time frames group group group group group group group expected 
time main muscle groups expressions raising brow 
plots shows time muscle groups expected profile application release relax phases muscle activation 
muscle application release relax bx bx second peak time frames group group group group group group group expected 
time main muscle groups expressions smiling lip motion 
plots shows time muscle groups expected profile application release relax phases muscle activation 
peak muscle group 
muscle group includes muscles eyes seen primary muscle group raising eye brow expression 
example illustrates coarticulation effects observed system occur quite simple expressions 
observed temporal patterns muscle activation simple linear ramps heuristic approaches representing temporal changes accurately characterize facial expressions 
characterization facial expressions main advantages methods ability real imagery define representations different expressions 
discussed section want rely pre existing models facial expression generally suited interests needs 
observe subjects making expressions measured motion muscle motion energy accurately characterize expression 
initial experimentation automatic characterization facial expression image sequences people making expressions smile surprise anger disgust raise brow 
subjects problems making expression sad decided exclude expression study 
complete detail expression recognition representations discussed appears 
different methods detailed physical model spatio temporal motion energy templates showed recognition accuracy rates 

discussion developed mathematical formulation implemented computer vision system capable detailed analysis facial expressions active dynamic framework 
purpose system analyze real facial motion order derive improved model facs spatial temporal patterns exhibited human face 
system analyzes facial expressions observing expressive articulations subject face video sequences 
visual observation sensing achieved optimal optical flow method 
motion coupled physical model describing skin muscle structure muscle control variables estimated 
observing control parameters wide range facial motions extract minimal parametric representation facial control 
extract minimal parametric representation facial patterning representation useful static analysis facial expression 
representation real time tracking synthesis facial expressions experimented expression recognition 
currently expression recognition accuracy database sequences 
muscle models motion energy models classification 
working expanding database cover expressions expressions speech 
categorization human emotion basis facial expression important topic research psychology believe methods useful area 
collaborating psychologists problem funding undertake controlled experiments area emphasis evaluation validity 
acknowledgments eero simoncelli john wang trevor darrell paul ekman steve pieper keith waters steve platt norm badler nancy help various parts project 

left shows motion field expression raise eye brow expression optical flow computation right figures shows motion field mapped dynamic face model control theoretic approach 

left shows motion field expression smile expression optical flow computation right figures shows motion field mapped dynamic face model control theoretic approach 

facial motion perception faces emotional expression 
journal experimental 

emotion recognition role facial motion relative importance upper lower areas face 
journal personality social psychology 
klaus rgen 
finite element procedures engineering analysis 
prentice hall 
black yacoob 
tracking recognizing rigid nonrigid facial motions local parametric model image motion 
proceedings international conference computer vision pages 
ieee computer society cambridge ma 
brown 
random signal analysis kalman filtering 
john wiley sons 
bruce 
recognising faces 
lawrence erlbaum associates 
bruner 
perception people 
handbook social 
addison wesley 
ekman 
argument evidence universals facial expressions emotion 
wagner editors handbook social psychophysiology 
lawrence erlbaum 
ekman friesen 
facial action coding system 
consulting psychologists press college avenue palo alto california 
ekman huang sejnowski hager editors 
final report nsf planning workshop facial expression understanding 
technical report national science foundation human interaction lab ca 
essa 
analysis interpretation synthesis facial expressions 
phd thesis massachusetts institute technology mit media laboratory cambridge ma usa 
essa basu darrell pentland 
modeling tracking interactive animation faces heads input video 
proceedings computer animation conference pages 
ieee computer society press june 
essa darrell pentland 
tracking facial motion 
proceedings workshop motion nonrigid articulated objects pages 
ieee computer society 
essa pentland 
facial expression recognition dynamic model motion energy 
proceedings international conference computer vision pages 
ieee computer society cambridge ma 
essa sclaroff pentland 
unified approach physical geometric modeling graphics animation 
computer graphics forum international journal eurographics association 

control system design state space methods 
mcgraw hill 
izard 
facial regulation emotions 
journal personality psychology 
li 
motion estimation model facial image coding 
ieee trans 
pattern analysis machine intelligence june 
mase 
recognition facial expressions optical flow 
ieice transactions special issue computer vision applications 
mase pentland 
lipreading optical flow 
systems computers 
metaxas terzopoulos 
shape nonrigid motion estimation physics synthesis 
ieee trans 
pattern analysis machine intelligence 
moghaddam pentland 
face recognition view modular eigenspaces 
automatic systems identification inspection humans volume 
spie 
pelachaud badler 
final report nsf standards facial animation workshop 
technical report national science foundation university pennsylvania philadelphia pa 
pentland moghaddam starner 
view modular eigenspaces face recognition 
computer vision pattern recognition conference pages 
ieee computer society 
pentland sclaroff 
closed form solutions physically shape modeling recovery 
ieee trans 
pattern analysis machine intelligence july 
pieper rosen zeltzer 
interactive graphics plastic surgery task level analysis implementation 
computer graphics special issue acm siggraph symposium interactive graphics pages 
platt badler 
animating facial expression 
acm sig graph conference proceedings 
simoncelli 
distributed representation analysis visual motion 
phd thesis massachusetts institute technology 
waters 
analysis synthesis facial image sequences physical anatomical models 
ieee trans 
pattern analysis machine intelligence june 
wainwright biggs curry 
mechanical design organisms 
princeton university press 
wang adelson :10.1.1.30.656
layered representation motion analysis 
proceedings computer vision pattern recognition conference 
waters terzopoulos 
modeling animating faces scanned data 
journal visualization computer animation 
yacoob davis 
computing spatio temporal representations human faces 
proceedings computer vision pattern recognition conference pages 
ieee computer society 

