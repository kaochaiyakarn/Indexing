resource constrained software pipelining alexander aiken computer science division university california berkeley berkeley ca email aiken cs berkeley edu alexandru nicolau department information computer science university california irvine irvine ca email nicolau ics uci edu steven department information computer science university california irvine irvine ca email ics uci edu presents software pipelining algorithm automatic extraction fine grain parallelism general loops 
algorithm accounts machine resource constraints way smoothly integrates management resource constraints software pipelining 
furthermore generality software pipelining algorithm sacrificed handle resource constraints scheduling choices truly global information 
proofs correctness results experiments implementation 
considerable interest class compiler parallelization techniques known collectively software pipelining 
software pipelining algorithms compute static parallel schedule overlapping operations loop body way hardware pipeline overlaps operations dynamic instruction stream 
schedule computed software pipelining algorithm suitable execution synchronous tightly coupled parallel machine super scalar vliw long instruction word machine 
software pipelining algorithms interesting reasons 
reason super scalar vliw machines built 
ibm system execute operations parallel intel chips execute operations parallel 
largest tightly coupled synchronous machine built date multiflow trace functional units 
computer manufacturers hp phillips siemens developing vliw super scalar architectures 
second reason tightly coupled machines programmed low supported part onr supported part onr level 
writing program tightly coupled machine develop parallel schedule means person know account details hardware design instruction timings resource conflicts functional units 
task extremely time consuming error prone compilation techniques needed translate programs written reasonably high level parallel schedules 
final reason software pipelining techniques hold promise producing better code faster compilation time scheduling techniques 
potential illustrated example 
shows simple sequential loop figures show different parallel schedules loop 
convenience label operations original loop refer labels parallel loops 
example parallelism loop body operations executed simultaneously iterations iteration overlap iteration 
classical approach scheduling loop unroll loop body number times apply scheduling heuristics unrolled loop body fis illustrated 
approach allows parallelism exploited iterations original loop sequentiality imposed iterations unrolled loop body 
general loop fully unrolled parallelism inside iterations exploited approach 
full unrolling usually impossible impractical obtain 
software pipelining provides direct way exploiting parallelism inside iterations loop software pipelining achieves effect scheduling full unrolling 
software pipelined version original loop 
previous body software pipelining focussed establishing formalism required adequately address software pipelining algorithms achieve 
results line development include software pipelining algorithm generates optimal code loops conditional tests proof optimal software pipelining impossible general sge 
largely ignored resource constraints 
existing software pipelining algorithms handle resource constraints variety ways 
algorithms deal weak forms resource constraints number operations executed parallel 
assume resource constraints handled separate fix phase software pipelining npa 
software pipelining algorithms account resource constraints directly part software pipelining algorithm rg lam 
algorithms treatment resource constraints intimately connected software pipelining software pipelining separable handling resource constraints 
interests separate really intrinsic software pipelining orthogonal concerns 
extensive discussion previous related included section 
example loop 
unrolled twice scheduled 
pipelined loop 
loop unrolling software pipelining approach algorithm smoothly integrates software pipelining treatment resource constraints time maintaining structured design separates orthogonal concerns 
algorithm serves purposes 
believe algorithm represents practical direction form basis implementations software pipelining discuss implementation algorithm section 
second algorithm represents summary interesting aspects investigation software pipelining years nic aik aik 
algorithm novel features ffl handling resource constraints orthogonal software pipelining 
ffl step algorithm global information operations scheduled 
ffl technical sense defined precisely section sufficient resources algorithm produce code arbitrarily close theoretical optimum 
advantage point treatment resources modified say different machine changes required algorithm 
second third points imply quality final pipelined loop limited ability resource allocation decisions see section design software pipelining algorithm 
software pipelining algorithm built components scheduler dependence analyzer 
machine dependent scheduler incrementally build parallelized loop sequential loop 
parallel instruction scheduler selects operations schedule set operations available scheduling instruction available resources 
set available operations maintained global dependence analyzer scheduler decisions place operations set available operations updated incrementally 
scheduler dependence analyzer encapsulate machine dependent information 
parallelized loop constructed software pipelining algorithm checks repeating states pipelined 
software pipelining algorithm simple difficulty lies establishing minimal restrictions scheduler dependence analyzer guarantee correctness termination software pipelining algorithm 
rest divided sections 
section defines model parallel computation develop algorithm 
section works small example give intuitive idea software pipelining algorithm works 
section describes algorithm presents proof correctness 
section gives algorithm incrementally maintaining set available operations 
section describes integration resource constraints algorithm 
handling resources critical realistic applications software pipelining 
section briefly describes implementation algorithm additional optimizations experimental results 
experimental results bear strengths approach point weaknesses discussed length 
section presents result suggests algorithm achieve best schedules possible presence resource constraints 
discussion related section 
final section summarizes presents 
basic terminology section develops simple model tightly coupled synchronous parallel machine 
formalism explain software pipelining algorithm provide basis proof correctness 
program automaton hx ffi set operations fx gamma operations divided assignments read write global store tests boolean valued functions affect flow control distinguished operation 
body program set states nm gamma state start state program 
associated state ops operations elements states represent parallel instructions intuitively control reaches state operations ops executed simultaneously 
simplify presentation assume operations execute unit time 
extensions multi cycle operations pipelined functional units discussed section 
configuration pair hn si state store contents memory locations registers 
transition function ffi maps configurations configurations 
execution sequence configurations hn ffi hn hn transition function describes tightly coupled synchronous machine executes parallel instruction 
deliberately avoid defining transition function detail 
transition functions super scalar vliw machines complex vary considerably machine machine 
greatest source complexity defining means execute test parallel multi way jumps 
example possible model tests state organized binary decision tree unique root 
branch test decision tree labeled true labeled false 
leaf decision tree pointer state 
state executed tests evaluated parallel store 
state executed leaf terminates unique path root branch labeled value test store 
possible implementations multi way jumps mechanisms proposed implemented fis kn 
software pipelining algorithm applies control flow mechanisms 
abstraction control flow 
assume control flow determined entirely tests result evaluating tests state determines state 
branch state truth assignment hx true false tests set branches branch tests branch singleton set consisting empty truth assignment 
function succ branch maps state branch branch successor node name succ branch stands successor branch 
note cases node tests distinct successors 
generality treat branches separately algorithm implementation particular control flow mechanism branches assume succ branch state ffi hn si hn evaluation tests configuration hn si satisfies truth assignment set successors succ state fn succ branch executed control transferred succ 
state contains operation contain operations successors 
define meaning function programs proof software pipelining algorithm correct preserves meaning original program 
definition program hx ffi execution hhn si hn ii ops execution exists 
programs equivalent 
software pipelining loop parallelization technique describe loops interested parallelizing 
convenience definition 
sequential loop program operations gamma states gamma fx backedges go start state succ 
state assumed reachable start state 
example sequential loop software pipelining algorithm incrementally builds parallelized loop initially parallelized loop empty states algorithm chooses set operations sequential loop legally scheduled start state parallel loop 
scheduling subset available operations start state algorithm recursively schedules successors start state considering operations scheduled successor states 
main difficulty guaranteeing procedure terminates 
show eventually scheduled states fall detectable repeating pattern point loop constructed pattern repeating states 
important data structure algorithm incrementally maintained set available operations 
step contains set operations available scheduling current state constructed 
set built maintained discussed section 
important understand set contains operations scheduled legally current state violating program semantics 
initially new program graph empty contains operations available scheduling state 
consider program 
display programs control flow graphs convention true branches tests left false branches right 
operations scheduled state example scheduled value writes 
standard compiler terminology data dependence 
example assume machine model reads take place writes execution state write conflicts permitted 
model operations treated 
gamma gamma gamma gamma psi gammaa gamma gamma gamma psi example loop 
available scheduling state 
algorithm may overlap operations different iterations superscript operations scheduled iteration came 
addition subscript available operation sets keep track different values different states 
initially fa component pipelining algorithm scheduler 
scheduler selects set operations schedule current state 
procedure maintain set available operations scheduler encapsulate machine dependent information 
software pipelining algorithm built top components 
pipelined version loop 
state labeled integer rest section describes software pipelining algorithm computes parallel schedule sequential loop 
state assuming machine sufficient resources scheduler choose schedule available operations 
test successors state case evaluates true case evaluates false 
sets available operations different successors 
consider successor case evaluates false 
case easy program terminates branch 
new set available operations fc reflecting fact scheduled branch loop exit 
write conflicts permitted scheduled state available hj gamma gamma gamma psi au delta delta deltaff loop software pipelining 
point dependences statements satisfied 
assume scheduler selects operations state operation test successors state 
successor evaluates false set available operations fe assume scheduler places single successor set available operations just fg operation 
contains backing set available operations branch evaluates true fg successor path completes terminating path path evaluates true new set available operations fc note operation second iteration available scheduling parallel statements iteration 
subtle point operation available scheduling reads take place writes operations iteration read variable available operation available scheduled state 
operations read scheduled fact prevents statements write available 
assume scheduler selects operations state operation test successors state 
successor evaluates true set fb assuming scheduler places operations set available operations successor path true fc note superscripts set exactly superscripts just way keeping track iteration operation sets operations 
continue scheduling point pipelining algorithm simply successor similarly set available operations successor evaluates false fc superscripts exactly pipelining algorithm successor gamma div gamma gamma example loop 
incorrect schedule 
example loop 
backing pipelining algorithm considers successor evaluates false 
set available operations fe assuming scheduler places operations sets available operations successors scheduling proceeds just algorithm terminates schedule 
technically difficult aspects software pipelining algorithm 
problem justifying step previously scheduled states reused pipelining algorithm decided successor simply implied correct example happens correct general step correct 
intuitively problem just sets available operations happen different states guarantee subsequent sets available operations successors states 
illustrate problem loop 
example simple possible conditional statements exits loop 
assuming variable zero entering loop note statements independent iterations data dependent iterations 
dependence analysis recognizes independent iterations parallelized loop built scheduler place iterations 
pipelining strategy previous example repeating states detected second iteration leading parallelized program clearly incorrect 
example irregular dependencies difficult detect repeating behavior 
section formalizes software pipelining algorithm provides constraints scheduler available operation information guarantee correctness termination software pipelining algorithm 
second problem computing sets available operations 
algorithm maintaining sets incrementally en programs loops acyclic control flow graphs 
section detailed description computation maintenance available operations software pipelining loops 
presentation simpler easier understand implement algorithm en 
third significant problem managing finite resources 
resource allocation bear directly correctness software pipelining algorithm resource usage obviously important algorithm useful practice 
section show finite resources integrated software pipelining system 
software pipelining algorithm example section illustrates key step algorithm discovering states reused form software pipeline 
recognizing patterns scheduled operations trivial fact valid scheduler available operation analysis constrained way 
example scheduler merely selects operations schedule random repeating behavior inferred 
similarly scheduler behaved example shows available operation analysis exhibit detectable pattern software pipelining possible 
section constraints scheduler available operation analysis software pipelining possible 
constraints quite weak easily satisfied practice 
presenting constraints software pipelining algorithm prove correctness 
discuss termination software pipelining algorithm 
constraints recall denotes instance operation iteration loop 
definition discussion constraints 
definition set operations 
set set discussed section component software pipelining algorithm scheduler specific machine 
constraint requires scheduler function scheduler schedule operation state operation chosen depend set operations available relative distance iterations operations available actual iterations operations available 
constraint set operations 
scheduler function mapping set scheduled operations set available operations single operation value 
addition schedule 
require schedule schedule algorithm set operations scheduled state currently consideration 
operation returned scheduler additional instruction scheduled state 
primary restriction imposed constraint scheduler function operations available state scheduled 
constraint weak set available operations provides global information program scheduler choose statement legally scheduled current state 
particular constraint significant design benefit cleanly separates scheduler rest algorithm isolating machine dependent portion code 
scheduler satisfying constraint software pipelining algorithm 
section show generalize constraint include resource constraints 
scheduler software pipelining algorithm repeatedly select operations scheduling state 
scheduler returns state finished successors state scheduled 
section simplified example scheduler chooses subset available operations scheduling 
iterative method described necessary general operations available scheduling state depend set operations scheduled example consider simple program fragment 
assuming parallel machine performs reads writes clear scheduled state scheduled scheduled available scheduling scheduled set available operations simply fa bg scheduler choose schedule successor incorrect 
second constraint placed available operations 
moment set operations available scheduling associated state ways updated 
procedure call update returns pair consisting updated state operations ops fx new set available operations scheduled 
second complete wish compute set available operations successors procedure call maps set pairs fhn ig branch branch new empty node succ branch set operations available implementations procedures update section 
imagine powerful schedulers example scheduler having global information just state time states times 
scheduling inherently hard problem clear extra theoretical power translates practical advantage scheme see section 
simple program 
constraint consider arbitrary set available operations state operation exists set operations update hm ops ops ops ops fx furthermore exist sets operations states fhn ig ops ops constraint says operations available may depend operations scheduled relative distance iterations operations scheduled depend actual values iterations operations scheduled 
implementation update result node simply updated include operation see section 
constraint satisfied depends form data dependence analysis maintain operation availability information 
standard data dependence graphs satisfy constraint extensions dependence graphs labeling edges constant distance vectors 
fact far know proposed representation dependence information satisfies constraint 
constraint needed rule pathological cases irregular dependence analysis leads incorrect schedules 
algorithm software pipelining algorithm 
initial set available operations procedure pipeline invokes procedure schedule state build single state build states branches state 
point algorithm encounters set available operations modulo iteration numbers second time uses previously scheduled state 
algorithm backtracks explore alternative schedules 
backtracking version designed easily feel backtracking algorithm slow practical 
order pipeline processes successors scheduled state unspecified difference final parallel program 
order states scheduled difference procedure schedule state schedule ops schedule ops hn ai update return hn ai procedure pipeline scheduled empty node todo aig hn ai todo scheduled scheduled todo todo gamma fhn aig hn schedule state hn scheduled todo todo hn gamma fhn aig software pipelining algorithm 
efficiency available operations computation section slightly modified version algorithm processes states efficient order 
constraints prove correctness software pipelining algorithm 
sequential loop result software pipelining 
show step proof assume available operation analysis correct 
intuitively available operation analysis correct schedule consistent analysis preserves program semantics 
program formalize intuition 
program identical reuse previously scheduled states 
infinite parallel program defined algorithm loop available operation analysis correct choice scheduler essential step proving correctness procedure pipeline show execution execution lemma pipeline pipeline 
execution hhn hn ii execution hhn hn ii proof proof induction length execution 
base case hhn ii execution consider initial states built 
initial set available operations 
procedure pipeline scheduled initially states scheduled 
schedule state hn bi 
clearly hhn ii execution procedure pipeline empty node todo aig condition true hn ai todo hn schedule state hn todo todo hn gamma fhn aig algorithm defines infinite parallel program 
induction step assume hhn hn ii execution hhn hn ii execution furthermore assume exists states scheduled sets available operations procedure pipeline procedure pipeline respectively 
assume ops ops easy check assumptions hold base case 
final states done 
transition ffi hn hn ffi hn hn stores transitions hypothesis operations 
branch taken state hn note taken state hn operations evaluated store 
finish proof need show operations possibly differing iteration numbers pipelining algorithm 
show ops ops consider state software pipelining algorithms scheduled 
constraint induction hypothesis hm bi hm fresh empty states branch respectively 
cases 
case assume scheduled hm removed todo list pipeline 
schedule state hn ci 
constraints schedule state hn ops ops second case assume hm removed todo list pipeline scheduled scheduled available operations rest argument symmetric case place fact constraints needed prove lemma 
constraints ensure having operations available states implies possible branches states 
combining correctness condition available operation analysis lemma gives proof correctness 
theorem procedure pipeline produces loop initial loop proof prove show 
assumption available operations analysis correct 
lemma execution execution 
termination theorem proves software pipelining algorithm produces correct results show terminates 
show termination prove todo set procedure pipeline eventually empty 
todo set decreases size pair hn ai scheduled previously 
equivalence relation sets operations assume procedure schedule state terminates prove termination sufficient show finitely equivalence classes unfortunately may infinitely equivalence classes fact procedure pipeline necessarily terminating constraints far 
consider example happens sets simply increase size recursive call 
necessary condition jaj jbj sets unbounded cardinality infinitely equivalence classes 
additional constraint placed availability information limit size set operations available scheduling 
constraint constant possible availability sets constraint states operations available consecutive iterations time 
scheduler sliding window operations operations iteration scheduled window shifted include new iteration 
lemma constraint ensures finitely equivalence classes sets operations proof operations loop body consecutive iterations appear available operation set subset value constraint parameter software pipelining algorithm 
need loop scheduled computed dynamically maximum value particular loop 
necessary window integral number iterations 
partial iterations just details implementation bit complex 
constraint motivated need guarantee termination leads implementation procedure pipeline 
expensive part pipeline checking current set available operations scheduled window size iterations operation availability information iterations gamma represented bit vector length kn number operations sequential loop 
bit hn operation available scheduling 
iteration completely scheduled occurs bits bit vector shifted left bits discarding information iteration bits set reflect availability operations iteration representation checking availability information seen requires checking bit vector seen implemented efficiently hashing 
available operations available operations analysis plays role algorithm similar role global data flow analysis plays traditional optimizing compilers 
algorithm computing available operations en historical reasons available operations termed unifiable ops en 
section give new presentation available operations 
functionally equivalent algorithms en presentation simpler direct final algorithms easier implement 
development divided parts 
show compute initial set available operations 
second show incrementally update information response decisions scheduler 
section prove correctness analysis discuss efficiency considerations 
computing available operations recall constraint forces available operations span iterations loop 
compute operations available scheduling sufficient examine iterations loop 
number unrolled iterations form acyclic program restrict problem computing available operations analysis programs 
computing available operations requires dependence analysis operations 
variations dependence analysis literature satisfy requirements constraint scope include fow 
algorithms section mechanism dependence 
particular dependence analysis representation algorithms efficient 
definitions model dependence analysis 
definition location memory address register 
operations sets operations define gamma gamma gamma psi operation kill live root 
write set locations may write write write kill set locations write kill kill read set locations may read read read depends write read write depends depends set write resp 
read include location write resp 
read 
set kill include locations writes 
different sets write kill defined dependence analysis conservative general possible know compiletime exactly locations operation may read write 
predicate depends true may dependence defining correct available operation analysis requires identifying operations available potential data dependence violations 
assume precedes path depends true 
clearly available path scheduled scheduled resulting dependence violation 
dataflow equation specifies operations reachable state data dependent intervening operation ops succ gamma ops program fragment analyzed computed single bottom traversal control flow graph program illustrates situation operation available 
case operation available scheduling state definition change value read operation standard compiler terminology location live state kill clearly operation kill live available 
second component available operations analysis computation live 
location live state state reachable potentially read intervening write conventional live analysis sufficient purposes wish compute live discounting effect particular operation precisely wish know set live assuming moved root state program 
case say moved root means occurrences potentially move root counted live variable computation 
intuitive justification computation moving operation schedule necessary check kill live new position 
deciding kill live new position count current position 
dataflow equation defines set locations live state modulo operation live read succ gamma kill live live ops gamma fxg cases definition distinguish cases occurrences blocked data dependencies 
occurrence path blocked data dependencies occurrence discounted live computation live 
occurrence potentially move live counted live counts effect store 
computation live computed states operations single bottom traversal control flow graph improvements efficiency procedure discussed section 
initial state root operation available scheduling satisfies conditions kill live operations sliding window operations 
recall constraint requires operations consecutive iterations available state 
set available operations min minimum iteration number operation available fx jx gamma min kg gamma live note concerned live root operations potentially kill live internal state included 
program illustrates situation 
operation live root reads value written important observation operation kill live root kill dependent preceding operation depends 
live root preceded operation writes operation prevents operations write available root 
expensive part computing available computing live operation efficiency naive procedure described improved ways 
necessary compute live sufficient compute operations superset operations available scheduling 
second operations kill gamma gamma gamma psi operation kill live root 
live detected earlier computation checking root alternative simplify presentation 
maintaining available operations describe high level available operations maintained give implementations procedures update 
sequential program 
add empty state state operations root initial state procedure pipeline see 
empty state filled operations chosen scheduler 
step compute dataflow analysis section 
point set operations available scheduling state available 
initial global analysis completed ready scheduling states 
state scheduled filled operations schedule state hn ai removed todo set successors added todo set 
state todo set frontier state 
point incremental development parallelized loop frontier state parallel loop property known predecessors scheduled successors scheduled 
unknown predecessors added backedges inserted complete software pipelined loop 
available operations needed frontier states predecessors frontier states modified 
procedure pipeline terminates frontier states modified program parallel loop 
gives generic snapshot algorithm data structures scheduling 
states line labeled parallel states scheduled algorithm 
states arranged tree backedges added pipelining 
states lines frontier states 
empty states filled operations 
states line states original sequential loop 
conceptually states part parallel loop compute available operations information frontier states 
todo set available ig 
initially frontier state 
procedure pipeline selects pair hr available todo fills operations calling schedule state available 
procedure schedule state turn calls update times choose scheduled oper snapshot software pipelining scheduling 
ations see 
procedure call update available performs tasks 
deleted interior states added frontier state transformation moves original place sequential schedule 
copies may remain interior states move paths frontier state see discussion 
test moved control flow modified preserve semantics 
second sets live updated necessary 
important fact deletion updating live sets restricted relatively small subset states property incremental cost maintaining available operations reasonable 
new set available operations updated available 
scheduling complete ig set empty successors corresponding sets available operations implement inserting new empty state succ branch branch 
set available exactly set operations available scheduling branch note new frontier states implementation allows available operation analysis shared elements todo set 
scheduling proceeds multiple frontier states element todo 
implementation 
lemma modifications performed 
proof procedure inserts empty nodes complete description available operations give implementation procedure update 
trivially terms local transformations percolation scheduling procedure branch fresh empty state succ branch succ branch succ branch hi live live operations return available ijr defined implementation 
nic completeness describe direct implementation closer way done practice 
frontier state schedule ops available assume 
describe deleted added assignment easier case 
moving operation preserving semantics little subtle may available frontier state blocked data dependencies paths 
program illustrates situation 
example available root kill live root path root case passing false branch dependent operation path 
may paths root case passing true branch dependent operation path clearly deleted path 
addition may paths frontier states represented incoming edge 
moved root preserved paths frontier states 
illustrated problem resolved duplicating states instance operation moved shared paths move paths move 
example single state containing needs duplicated general multiple states may duplicated 
state deleted operation moved root 
easy verify program equivalent program 
formalize states duplicated states deleted need additional definitions notation 
path sequence states hn succ state covered state operation path hn operation path covered fn exists path hn say path covered state path covered 
operation moved frontier state deleted paths covered paths left unchanged 
simplest case path covered 
say program delete consistent covered fxg path frontier state covered 
delete consistent blocked data root gamma gamma gamma psi gamma gamma gamma psi moved 
root gamma gamma gamma psi gamma gamma gamma psi delete consistent 
root moved 
moving assignment 
dependencies path frontier state delete states fxg covered update predecessors point successor add lemma assignment available fxg covered assume delete consistent 
changes 
recall hi empty branch see section 
ffl modify succ branch succ branch succ hi ffl delete ffl fxg proof brevity sketch proof 
transformation implemented sequence semantics preserving percolation scheduling transformations adjacent nodes nic 
individual percolation scheduling transformation preserves program semantics entire sequence preserves program semantics 
course lemma applies delete consistent 
show arbitrary program delete consistent 
set predecessors state pred fn jn succ lemma gives easy test determining delete consistent 
lemma delete consistent iff covered pred covered 
root gamma gamma gamma psi moved 
root gamma gamma gamma psi moved 
moving test 
proof predecessor member covered covered clearly path covered covered 
direction assume covered pred covered 
path frontier state form hr ni 
path covered 
algorithm delete consistent 
covered 
iterate steps chosen choose pred 
duplicate pred succ branch modify succ branch note algorithm copies minimum number states needed delete consistent 
delete consistent steps lemma applied move frontier state 
remains update live sets 
states duplicated making delete consistent retain live information original state 
set states analysis change covered 
live computed bottom analysis updated single bottom pass paths covered 
show update available operations case instruction chosen update test 
frontier state schedule ops available 
update move test preserving semantics necessary modify control flow intuitively duplicate covered paths original set paths leads successor true branch duplicate set paths leads successor false branch 
transformation illustrated figures 
program delete consistent root 
moved root state duplicated true false branches preserve control flow 
recall branch truth assignment tests hx true false 
lemma shows move test frontier state 
lemma program frontier state available test 
assume delete consistent covered program modifications performed order state ops ops branch succ branch covered covered ops fxg succ branch hx false covered ops fxg succ branch 
succ branch ops fxg modify succ branch succ branch hx true branch hx succ branch succ branch hx true succ branch hx false ops ops fxg proof brevity sketch proof 
easy verify preserves control flow proof lemma transformation expressed sequence local transformations adjacent nodes 
part lemma duplicates covered paths creating copy state covered assigning successors paths formed lead false branch part modifies original states covered lead true branch part modifies branches point original nodes true copied nodes false 
description procedure update 
implementation described somewhat naive inefficiencies eliminated cost greater complexity algorithm 
potential problems related space explosion size final code size intermediate data structures algorithm 
states initially different may identical result scheduling operations 
observation applies states parallel schedule states scheduled 
implementation merge states identical identical paths 
performed states parallel schedule optimization reduces size final code 
note construction original states containing removed unreachable control flow redirected 
procedure update delete consistent lemma covered assignment perform steps lemma perform steps lemma update live states added lemma return hr available implementation procedure update 
separate potential problem lies definition delete consistency 
making sequential program delete consistent prior moving operation may result duplicating states sequential program 
duplicates subsequently merged occurs set paths original position paths blocked data dependence set paths moved 
partial solution move far possible paths blocked data dependence allowing sharing common paths 
scheduling systems property nic 
optimization may marginal value algorithm duplicated states sequential program soon eliminated subsequent scheduling anyway 
approach improving efficiency techniques representation control flow graph computing available operations 
obvious alternative form program dependence graph admits efficient algorithms purposes see la uses program dependence graphs context software pipelining 
techniques control flow graph representation simplicity barrier potentially faster representations implementation 
correctness analysis section assumed available operations analysis correct prove correctness software pipelining algorithm 
recall available operations analysis correct sequential loop infinite parallel program computed pipeline 
section prove implementation available operations sections correct 
lemma program defined pipeline loop scheduler proof infinite acyclic program formed full unrolling apply pipeline available operations analysis final program 
transformation update preserves semantics lemmas 
managing window performance reasons obviously desirable minimize number iterations available operations analysis 
possible iterations constraint forces available operations analysis state span iterations loop section show number iterations needed available operations analysis limited problem limiting number iterations analysis different frontier nodes may require available operations different iteration windows 
example frontier state operations may available iterations gamma frontier state operations may available iterations gamma 
naive implementation contain operations iterations gamma cover frontier states 
fortunately necessary 
schedule iterations gamma states operations available iteration states operations available iteration scheduled new iteration added window shifted modified version pipeline 
implementation frontier states operations available iteration scheduled frontier states operations available iteration 
new iteration added state operations available iteration scheduled 
contains minimal number iterations iterations added infrequently possible 
detail omitted 
ith iteration added live sets leaf states states iteration initialized set locations live iteration resources resource allocation critical issue software pipelining algorithms 
section show allocation functional units smoothly integrated software pipelining algorithm 
approach incorporating functional resources similar reservation table methods dynamic scheduling algorithms bae 
describe modifications algorithm accommodate functional resources require additional definitions 
ff set functional units machine 
drop assumption operation executes single cycle assume greatest number cycles required operation 
reservation table theta array boolean values entry true iff resource busy cycle operation reservation table resources describes resources required cycle execution 
difficulty extending model multi cycle operations 
operation requires procedure pipeline scheduled iterations empty root todo aig todo hn ai todo min scheduled scheduled todo todo gamma fhn aig hn schedule state hn todo todo hn gamma fhn aig scheduled add iteration update analysis modified software pipelining algorithm 
multiple cycles complete result available multiple cycles 
data dependencies resource constraints prevent operations depend result scheduled cycle initiated 
resolve problem treating cycle operation cycle operations operations depend result dependent operation chain 
guarantee legal schedules necessary constrain unit cycle operations scheduled successive cycles interruption 
constraint encapsulated entirely policy selecting operations schedule affect structure software pipelining algorithm 
allocate functional units software pipelining algorithm modified state scheduled reservation table associated describing resource usage point schedule 
scheduler modified chooses operation available resources allocated 
reservation tables compatible require functional unit cycle point true 
reservation table associated state scheduler choose operation schedule compatible resources 
constraint modifies constraint include reservation tables 
constraint sets operations reservation table 
scheduler function takes set scheduled operations available operations reservation table returns operation 
addition exists compatible resources schedule ops scheduler choose operation state possible 
require schedule compatible resources schedule procedures update modified update reservation tables reflect changes available resources operations scheduled 
procedure call advance reservation table cycle reflect fact successors resources cycle longer reserved 
procedure call update update update adding resources required constraint modifies constraint include reservation tables 
logical reservations tables table 
reservation table advance table false 
constraint consider arbitrary set available operations state operation reservation table exists set operations update hm resources ops ops ops ops fx procedure schedule state schedule ops schedule ops hn ri update return hn ri procedure pipeline scheduled empty node empty reservation table todo rig hn ri todo scheduled scheduled todo todo gamma fhn aig hn schedule state fhn ig todo todo fhn ig gamma fhn rig scheduled software pipelining algorithm 
furthermore exist sets operations states fhn advance ig ops ops gives modified version software pipelining algorithm includes reservation tables 
simplicity modifications original algorithm efficient version 
note detection repeating states involves set available operations reservation table 
constraints straightforward adapt original proof correctness software pipelining prove correctness algorithm 
termination guaranteed finite number reservation tables repeating states guaranteed occur 
register allocation registers critical resource utilized effectively achieve results practice 
traditional register allocation interact badly software pipelining 
register assignment performed scheduling usual practice software pipelining may produce poor results register allocator may unnecessarily reuse registers adding data dependences program 
approach modify initial register allocation fly software pipelining 
basic technique easy describe similar technique ebcioglu 
consider op op instruction unavailable 
op op renaming registers 
dynamically improving register allocation 
program fragment 
example operation available scheduling root target register operand registers operation spare register dependence broken renaming destination register 
operation available scheduling 
necessary insert register move program restore machine state operation transformation heuristic assumes advantage gained eliminating dependence outweighs cost extra copy 
usually true copy operation removed global pass generalized copy propagation pnw 
additional problem register allocation scheme described 
including register allocation software pipelining algorithm requires registers taken account determining states 
sufficient condition states considered register holds value generated operation state value generated operation state condition guarantees correctness termination analogous similar requirements available operations functional units 
practice appears condition permits impractical number states generated loops repeating pattern fails emerge reasonable number steps 
problem small register files number possible assignments values registers astronomical 
accelerate convergence pipelining algorithm necessary limit space possible register assignments way 
solution follows 
register file renaming register file mapped set register register transfers 
software pipelining algorithm states considered equivalent register files states renamings conditions operations functional units satisfied 
design identifies register files accelerating convergence algorithm 
cost register register transfers issued backedges pipelined loops move values correct registers 
copy operations eliminated separate copy elimination optimization pass software pipelining 
leaving copy operations code reasonable incur minor performance penalty see section 
implementation experiments software pipelining algorithm described implemented part compiler project university california irvine 
compiler version gnu compiler gcc modified accommodate methods 
gcc front translate level source intermediate representation 
translation includes initial register allocation number common optimizations constant folding jump optimization removing jumps jumps common subexpression elimination strength reduction 
gcc instruction scheduling loop unrolling inlining disabled replaced software pipelining scheduling algorithm 
number incremental optimizations incremental tree height reduction beneficial conjunction software pipelining pipelining 
results dynamic renaming see section load store elimination performed pipelining 
store elimination identifies loads depend unique store loads eliminated favor uses value stored 
cases store removed known eliminated load read location written store 
load store elimination useful removes register spill code dead result dynamic renaming 
dynamic renaming load store elimination inherent part fly register allocation scheme 
strength software pipelining framework flexibility exploit fine grain parallelism available loop 
restrictions placed code motions designed weak possible guaranteeing correctness termination 
discussed flexibility fact translate speedups variety architectural models 
downside weak restrictions system huge number potential states small loops machines modest resources 
huge state space cause slow convergence pipelining pattern large final loops 
clean solution problem scheduler designed minimize code explosion restricting code motions increase code size 
purposes focussed experiments reveal information software pipelining algorithm information particular smart scheduling heuristics 
simple greedy list scheduling heuristics effort take account impact code motions code size 
shall see shortly majority cases size state space problem software pipelining converges quickly pattern naive scheduling 
cases iteration window large maximally exploit available parallelism results slow convergence 
identify cases experiment find name latency description alu cycle integer add sub logical shift cycle arithmetic logical shifts cycles floating point add sub logical mul cycles integer floating point multiply div cycles integer floating point divide mem cycles cache read cache stalls processor cycle cache write branch cycles conditional branch table functional unit kind latency useful introduce notion cut convergence constrains maximum number iterations scheduled fixed amount remainder paths converged cut number iterations simply scheduled sequentially 
stress cut convergence creature experiment purpose identify code explosion problem 
practice prefer scheduling heuristics designed prevent code explosion topic discussed section 
architectural models pipelined vliw architecture models experiments homogeneous functional units heterogeneous functional units 
models assume single bit wide register file shared functional units 
exception unlimited resource experiments measure threshold performance results register file assumed registers 
operation latencies models table similar motorola superscalar 
instance heterogeneous model unlimited number functional units defined table 
instance homogeneous model unlimited number homogeneous functional units homogeneous functional unit perform functions defined table 
vliw instruction specifies possibly nop operation functional unit 
operation optional side effect advancing pipeline 
models hardware interlocks detecting data control hazards compiler entirely responsible ensuring hazards avoided run time 
experimental results tables show dynamic speedup measured target architecture models livermore loops 
speedups respect running unscheduled code sequentially target architecture 
speedups reflect exploitation multiple functional units pipelining kernel fu fu fu infx ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll avg table homogeneous multi cycle functional units speed kernel infx ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll avg table heterogeneous multi cycle functional units speed functional unit 
columns table show speedups homogeneous model assuming registers homogeneous functional units respectively 
table shows information heterogeneous model configured units type assuming registers 
columns table show threshold performance levels discussed 
results columns table loops pipelined progressively larger iteration windows noticeable increase average speedup benchmarks 
numbers parentheses top column show smallest iteration window sizes highest average performance attained speedups shown tables generated 
notice window sizes fairly small exceeds iterations 
results shown columns iterations scheduled cut 
cases fraction number needed convergence pattern 
conv type column tables algorithm terminated indicates convergence pattern indicates cut convergence path 
columns tables identical tables show speedups obtained assuming unlimited number functional units registers column infx unlimited number registers column 
columns want show maximum speedup obtained specific architecture configuration fixed code motion capabilities scheduling heuristics front optimizations system 
infx columns iteration window size cut limits set number iterations executed loop run time loops iterations 
loops exhibit natural convergence guaranteed optimal sense defined theorem loops converge optimal sense fully unrolled scheduled 
note homogeneous functional units heterogeneous functional units speedups optimal respect infx numbers obtained iteration window size just iterations 
loops fu speedups optimal respect numbers shows optimal register allocation loops increase performance 
wide range speedups exist tables ranging way 
tried show fixed set code motion capabilities scheduling heuristics frontend optimizations produced gcc software pipelining algorithm able achieve performance fully unrolling scheduling loop 
furthermore despite generality approach algorithm manages achieve utilization resources naive scheduling heuristics 
performance benchmarks pipelining complete unrolling improved number ways orthogonal software pipelining approach improving memory disambiguation 
due cyclic dependencies involving long latency operations floating point division procedure calls performance loops ll improve significantly perfect fu fu fu conv reg min max total conv reg min max total conv reg min max total kernel type loop loop size type loop loop size type loop loop size ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll avg infx conv reg min max total conv reg min max total kernel type loop loop size type loop loop size ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll avg table homogeneous multi cycle functional units misc 
performance measures conv reg min max total conv reg min max total conv reg min max total kernel type loop loop size type loop loop size type loop loop size ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll avg infx conv reg min max total conv reg min max total kernel type loop loop size type loop loop size ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll ll avg table heterogeneous multi cycle functional units misc 
performance measures rest section discuss interpret performance results detail 
aid interpreting results shown tables performance measures tables conv type convergence type means pipelining converged pattern means converged cut 
reg maximum number registers instruction state 
min loop number instructions shortest path pipelined loop 
max loop number instructions longest path pipelined loop 
total size total number instructions benchmark including inner loop instructions code preceding succeeding loop 
discussed section software pipelining inserts register register transfers order speed convergence algorithm 
transfers eliminated copy propagation albeit cost increase code size counted speedup figures tables 
copies eliminated figures tables table show performance penalty low 
example ll homogeneous functional units worst case registers live copied backedge costs cycles length pipelined loop body 
large loops penalty small loops overhead reduced unrolling pipelined loop body 
interesting anomalies speedup tables 
benchmarks ll ll ll tables speedup decreases slightly increases number resources 
cause pipelined loops may exhibit asymptotic speedup overhead pre loop post loop code differ speedup goes going infx ll 
cause small decreases performance resources increase overly simplistic scheduling heuristics 
instance list scheduling heuristics currently compiler allow operations scheduled earlier potentially saturating register file subsequent states preventing removal false dependencies renaming allow operations critical path scheduled earlier 
kernels ll ll provide examples effect 
fewer resources fewer unimportant critical path operations scheduled head uses register file saturated unimportant values 
problem alleviated different scheduling heuristics 
case issue orthogonal software pipelining 
disambiguation 
note single path loops min loop max loop usually equivalent case represent total number instruction pipelined loop 
anomaly occurs loops ll ll ll table ll ll ll table 
factoring considerations scheduling anomaly heuristic aspects speculative scheduling expect speedup increase linearly number functional units threshold speedup reached 
doubling number functional units expect speedup lesser twice old speedup maximum unlimited speedup second class anomaly going functional units table functional units table see speedup slightly expected value 
reason iteration window size chosen maximize average speedup shown tables performance loops table improved larger window size significant effect average speedup loops 
interesting consider circumstances algorithm fails converge pattern cutoff reached 
analysis kernels type convergence see tables shows problem arises vectorizable loops generally loops flow dependencies 
case constraints resource constraints operations free move schedule 
situation lack dependence structure program combined greedy scheduling heuristics tends lead explosion set states slowing convergence 
variations device ebcioglu may show modify scheduler avoid problem 
basic idea introduce artificial dependencies don harm parallelism extraction dramatically reduce number potential states scheduler may explore 
example rule thumb vectorizable loops operation scheduled time loop vectorizable reason prefer scheduling eliminating orderings reduces number potential states 
notice cases total size final loop order magnitude larger shortest longest paths loops 
loop control conditionals succeeding iterations scheduled parallel operations preceding iterations new loop exit path usually created iteration scheduled 
cases simply cost side cost vs performance trade inherent scheduling conditional jumps benefits allow strictly control dependent operations operations stores renamed scheduled earlier commit alternative control paths early possible minimize amount speculative scheduling 
fortunately cases loop exit code cost significantly reduced merging multiple identical control paths single shared path 
context available operations scheduling accomplished merging states identical available operations sets optimization implemented 
guarantee preservation correct semantics scheduling conditional operations precede necessary duplicate operations branch conditional scheduled 
optimal software pipelining section briefly review research limitations software pipelining especially result showing optimal software pipelining unachievable sge 
result show algorithm possible sense produce arbitrarily schedules 
research software pipelining naturally focused discovering algorithms computing pipelined schedules general specific machines 
concurrently researchers investigated theoretical limitations software pipelining 
central theoretical questions software pipelining algorithm produces optimal pipelined schedules arbitrary loop 
scheduling algorithms preserving data dependences natural meaning optimality respect length dependence chains 
definition program time optimal execution hhx ii length longest dependence chain execution 
obvious form optimality question stated follows algorithm takes input machine description resource constraints instruction timings loop produces time optimal schedule machine 
problem statement useful scheduling problems finite resources computationally intractable software pipelining 
gain insight software pipelining researchers usually abstracted problem sufficient resources loop algorithm computes time optimal schedule 
answer question trivially programs 
recall instructions scheduled instruction write store location 
branch test optimized expense branch exist parallel version time optimal 
conflict usually classified type dependence output dependence 
avoid problem rephrase question unbounded resources loop output dependences algorithm computes time optimal schedule 
question resolved negatively sge 
problem loops optimal closed form parallel version exist 
definition natural appears qualifications required apply analysis general software pipelining algorithms ceases useful 
purposes adopt different definition means software pipelining algorithm possible 
recall section loop infinite parallel program results scheduling complete information available operations 
may optimal represents best done global knowledge program ability fully unroll loops 
theorem shows window size software pipelining algorithm increases quality code approaches theorem loop result applying pipeline scheduling window iterations 
store 
define length execution store lim proof largest index iteration execution store programs identical executions store theorem theoretical result practice scheduling window cover iterations 
show framework algorithm possible generate arbitrarily code subject ability scheduler scheduling decisions finite resources 
related software pipelining relatively old idea 
programmers microcode community software pipelined code hand decades 
semi automatic technique software pipelining proposed cha 
overview history instruction level parallelism see rf 
today variety algorithms frameworks software pipelining 
describe discuss relationship 
large amount area discussion proposal necessarily brief 
modulo scheduling modulo scheduling important software pipelining technique introduced rau rg subsequently basis numerous algorithms lam jon rts 
modulo scheduling compilers fps series tou machine rg 
basic modulo scheduling algorithm works follows 
consider loop requires resource times iteration loop body 
target machine resource upper bound throughput iteration cycles 
initiation interval max 
modulo scheduling loop body heuristically scheduled statement time 
statement scheduled time instance iteration scheduled time point statement added schedule due resource dependency constraints schedule abandoned algorithm backtracks tries larger initiation interval 
modulo scheduling smoothly integrates simultaneous treatment resource constraints software pipelining 
primary disadvantage modulo scheduling apply directly loops conditional tests loop body 
extensions proposed overcome limitation 
lam introduced hierarchical reduction combine modulo scheduling complex control flow lam hierarchical reduction branches conditional test scheduled independently 
shorter branch padded length longer branch scheduler encapsulates entire construct single statement 
hierarchical reduction suffers drawbacks 
paths padded may slow execution second treating single statement necessarily overestimates resource requirements third preserving control structure program restricts possible code motions 
second proposal integrating modulo scheduling conditional tests conversion modulo scheduling reverse conversion modulo scheduling 
loop converted expression control flow changed explicit jumps guarded operations operation original loop guarded predicates conditionals control execution 
way non trivial control flow loop replaced data dependences 
modulo scheduling conversion appears improve modulo scheduling hierarchical reduction 
conversion retains undesirable features hierarchical reduction considerable degree 
control flow expressed data dependence speculative execution operations moving operations conditionals possible possible reorder conditionals reason 
possible code motions restricted 
addition performing conversion greatly hinders management limited resources scheduling 
conversion schedules operations original loop body single basic block 
operations compete resources scheduling including operations execute simultaneously appear different control paths original loop 
straightforward modulo scheduling converted loops overestimates resource requirements 
case loops control flow unlimited resources considerable commonality algorithm modulo scheduling 
example shown simplified version algorithm produces optimal code loops conditionals body machines sufficient resources 
despite differences conception algorithms result shown hold small modification modulo scheduling jon 
short algorithm combines software pipelining resource constraints handling control flow flexibility matched current modulo scheduling techniques 
opinion significant practical advantage modulo scheduling time cases techniques produce equally fast schedules schedules produced modulo scheduling generally concise jon 
pipeline scheduling closely related ebcioglu ebcioglu nakatani ne en ne moon ebcioglu 
pipeline scheduling differs approach loop body constructed scheduling testing repeating states 
original loop incrementally transformed create parallel schedule 
software pipelining achieved moving operations backedge loop effect moving operation loop iterations 
handling control flow principles approach limitation noted indication overcome 
equally general 
scheduling window operations ne purpose reduce code explosion guarantee termination 
advantage pipeline scheduling loop equivalent original loop legal apply semantics preserving transformation loop time transformations little directly scheduling 
ebcioglu nakatani exploit property aggressively renaming registers performing strength reduction optimizations substantially alter dependence structure loop 
apply optimizations see section apply generally pipeline scheduling need guarantee regular dependences correctness 
aside best knowledge modulo scheduling implementations perform transformations modify dependence graph 
advantage algorithm current pipeline scheduling algorithm handling resource constraints 
pipeline scheduling uses local transformations move operations state 
points resource constraints may need violated schedule operation moves state way state 
deal property pipeline scheduling moderately elaborate phase structure resources constraints alternately enforced relaxed specific portions loop body 
algorithm treats resource constraints direct uniform way 
global unrolling pipelining software pipelining technique proposed su ding xia 
technique algorithm pipelining loops tests 
loop step apply path original loop body 
separate pipelined paths put form pipelined loop compensation code added points execution jump path 
approach similar philosophy trace scheduling paths optimized basic blocks ignoring jumps path fix code added ensure correctness 
subject criticism trace scheduling 
reason execution program repeatedly follow path loop body 
approach approach ebcioglu nakatani uniform overlapping iterations paths subset paths 
petri net techniques interest petri nets formalize software pipelining problem ra 
natural mapping operations dependences resource constraints petri nets combining features single understood formalism 
approach shown competitive modulo scheduling hierarchical reduction ra appears promising 
weakness current algorithms petri net techniques control flow handled way similar conversion 
net effect mapping petri net model control flow enforced just data dependences speculative execution operations possible 
furthermore rate execution iterations determined length longest path loop body shorter paths loop taken execution 
simple fairly detailed description compaction software pipelining algorithm handles resource constraints 
novel aspect algorithm cleanly fact completely separates issues specific software pipelining detecting repeating pipeline states termination orthogonal issues computation available operations scheduling decisions 
hope contributions state art 
algorithm explains fairly simple way software pipelining unique characteristics 
second modular simple design algorithm facilitate development general retargetable implementations software pipelining 
gross kung lam webb 
warp architecture implementation 
proceedings th annual symposium computer architecture pages june 
aik aiken 
compaction parallelization 
phd thesis cornell 
department computer science technical report 
aik aiken 
theory compaction parallelization 
theoretical computer science 
allan lee srinivas 
enhanced region scheduling program dependence graph 
proceedings th international symposium workshop microarchitecture micro december 
allen kennedy porterfield warren 
conversion control dependence data dependence 
proceedings symposium principles programming languages pages january 
aiken nicolau 
optimal loop parallelization 
proceedings acm sigplan conference programming language design implementation pages june 
aiken nicolau 
perfect pipelining new loop parallelization technique 
proceedings european symposium programming pages 
springer verlag lecture notes computer science march 
aiken nicolau 
realistic resource constrained software pipelining algorithm 
advances languages compilers parallel processing pages 
mit press 
bae baer 
computer systems architecture 
computer press 
cha 
approach scientific array processing architectural design ap fps family 
ieee computer 
palo alto ca 
technical summary 
ebcioglu 
compilation technique software pipelining loops conditional jumps 
proceedings th annual workshop microprogramming pages december 
en ebcioglu nicolau 
global resource constrained parallelization technique 
proceedings acm sigarch international conference supercomputing june 
en ebcioglu nakatani 
new compilation technique parallelizing loops unpredictable branches vliw architecture 
languages compilers parallel computing pages 
mit press 
fis fisher 
way jump hardware effective instruction binding method 
proceedings th annual workshop microprogramming pages december 
fis fisher 
trace scheduling technique global microcode compaction 
ieee transactions computers july 
fow ferrante ottenstein warren 
program dependence graph optimization 
acm transactions programming languages systems june 
gao wong ning 
timed petri net model fine grain loop scheduling 
proceedings acm sigplan conference programming language design implementation pages june 
huff 
lifetime sensitive modulo scheduling 
proceedings acm sigplan conference programming language design implementation pages june 
jon jones 
constrained software pipelining 
master thesis department computer science utah state university logan ut september 
kuck kuhn padua wolfe 
dependence graphs compiler optimizations 
proceedings sigact sigplan symposium principles programming languages pages january 
kn karplus nicolau 
efficient hardware multi way jumps pre fetches 
proceedings th annual workshop microprogramming pages december 

microprogramming pipelined processors 
proceedings th annual international symposium computer architecture 
la lee allan 
advanced software pipelining program dependence graph 
fourth ieee symposium parallel distributed processing december 
lam lam 
systolic array optimizing compiler 
phd thesis carnegie mellon university 
moon ebcioglu 
efficient resource constrained global scheduling technique superscalar vliw processors 
proceedings th international symposium workshop microarchitecture micro pages december 
ne nakatani ebcioglu 
combining compilation technique vliw architectures 
proceedings nd annual workshop microprogramming pages 
ne nakatani ebcioglu 
lookahead window compaction parallelizing compiler 
proceedings rd annual workshop microprogramming 
nic nicolau 
uniform parallelism exploitation ordinary programs 
proceedings international conference parallel processing pages august 
npa nicolau pingali aiken 
fine grain compilation pipelined machines 
journal supercomputing august 
pingali beck johnson 
dependence flow graphs algebraic approach program dependences 
proceedings symposium principles programming languages pages january 
pnw nicolau wang 
register allocation renaming impact fine grain parallelism 
proceedings workshop languages compilers parallel computing pages 
springer verlag lecture notes computer science april 
ra rajagopalan allan 
efficient scheduling fine grain parallelism loops 
proceedings th annual international symposium microarchitecture pages december 
rf rau fisher 
instruction level parallel processing history overview perspective 
journal supercomputing january 
rg rau 
scheduling techniques easily schedulable horizontal architecture high performance scientific computing 
proceedings th annual workshop microprogramming pages october 
rts rau schlansker 
register allocation software pipelined loops 
proceedings acm sigplan conference programming language design implementation pages june 
su ding xia 
extension software pipelining 
proceedings th annual workshop microprogramming pages october 
su ding xia 
method global software pipelining 
proceedings th annual workshop microprogramming pages december 
sge ebcioglu 
optimal parallelization arbitrary loops 
journal parallel distributed computing 
tou 
fortran compiler fps scientific computer 
proceedings acm sigplan symposium compiler construction pages june 
warter 
enhanced modulo scheduling loops conditional branches 
proceedings th international symposium workshop microarchitecture micro december 
warter mahlke hwu rau 
reverse conversion 
proceedings acm sigplan conference programming language design implementation pages june 

