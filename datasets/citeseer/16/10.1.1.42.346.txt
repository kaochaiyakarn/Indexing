vision gesture recognition review ying wu thomas huang beckman institute mathews university illinois urbana champaign urbana il huang ifp uiuc edu 
gesture natural interface serves motivating force research modeling analyzing recognition gestures 
particular human computer intelligent interaction needs vision gesture recognition involves interdisciplinary studies 
survey vision gesture recognition approaches 
shall review methods static hand posture temporal gesture recognition 
application systems gesture recognition described 
conclude thoughts research directions 
evolution user interface ui witnessed development text ui keyboard gui mice 
counterpart mouse trying explore virtual environments ves human computer intelligent interaction perceptual user interface pui 
current applications keyboards mice joysticks popular dominant devices 
inconvenient unnatural 
human movements especially hand gestures important part years serves motivating force research modeling analyzing recognition hand gestures 
techniques developed extended areas surveillance robot control teleconferencing 
recognizing gestures complex task involves aspects motion modeling motion analysis pattern recognition machine learning psycholinguistic studies 
survey papers human motion analysis interpretation 
gesture recognition receiving attention research comprehensive review various gesture recognition techniques developed years needed 
surveys studies vision gesture recognition techniques 
section discusses human gesture representation paradigms psycholinguistic cognitive studies high level temporal gesture recognition tasks represented paradigms serve cognitive model complicated temporal hand gestures 
promising application systems section 
recognition method ying wu thomas huang needs feature extraction data collection section discusses gesture features current studies section provides brief overview tracking techniques serves data collection process vision gesture recognition 
meaningful hand gestures classified static hand postures temporal gestures section section discuss various techniques hand posture recognition temporal gesture recognition respectively 
especially recognition modeling dynamics section recognition modeling semantics section recognition hmm framework section techniques section section 
sign language recognition important task section discusses studies related 
thoughts section section respectively 
human gesture representation studies human gestures psycholinguistic research 
represents gestures aspects hand shape position orientation movement 
kendon describes gesture consists language gestures sign language 
sign languages characterized specific set vocabulary grammar 
informal gestural expressions meaning depend convention culture lexicon 
di erent application scenarios hand gestures classified categories conversational gestures controlling gestures manipulative gestures communicative gestures 
sign language important case communicative gestures 
sign languages highly structural suitable acting test bed vision algorithms 
time way help disabled interact computers 
controlling gestures focus current research vision interface 
virtual objects located analyzing pointing gestures 
display control applications demonstrate potential pointing gestures hci 
controlling gesture navigating gesture 
orientation hands captured directional input navigate ves 
manipulative gesture serve natural way interact virtual objects 
tele operation virtual assembly examples applications 
communicative gestures subtle human interaction involves psychological studies vision motion capturing techniques help studies 
communicative gestures decomposed motion phases preparation stroke retraction 
psycholinguistic studies show stroke may distinguished gesture phases stroke contains information 
model taken quek 
distinction presentation gestures repetitive gestures 
lecture notes computer science gesture workshop bobick emphasizes dynamical part gestures 
represents gestures movement activity action 
movements typically atomic primitive form motion interpreted semantically 
activity sequence movements static configurations 
dynamic models may recognize activities 
actions high level entities people typically describe happening 
time context fundamental reason context unclear 
application systems implemented application systems domains virtual environments smart surveillance teleconferencing sign language translation 
zeller visual environment large scale biomolecular modeling application 
system permits interactive modeling biopolymers linking molecular graphics molecular dynamics simulation program 
hand gestures serve input controlling device virtual environment 
pavlovic berry integrate controlling gesture virtual environment battlefield hand gestures navigating interactive device select move virtual objects battlefield 
ju develop automatic system analyzing annotating video sequences technical talks 
speaker gestures pointing writing automatically tracked recognized provide rich annotation sequence access condensed version talk 
davis bobick implement prototype system virtual personal trainer pat 
system allows user create personalize session meet user needs desires 
stretching movements recognized system 
quek presents fingermouse application recognize finger movements input desktop 
crowley coutaz develop application finger input device augmented reality 
triesch develop person independent gesture interface real robot allows user give simple commands grasp object put 
implement bi directional translation system japanese sign language jsl japanese order help hearing impaired communicate normal speaking people sign language 
features gesture recognition selecting features crucial gesture recognition hand gestures rich shape variation motion textures 
static hand posture recognition possible recognize hand posture extracting geometric features fingertips finger directions hand contours features available reliable due self occlusion lighting conditions 
non geometric features color ying wu thomas huang silhouette textures inadequate recognition 
easy specify features explicitly image transformed image taken input features selected implicitly automatically recognizer cui weng investigate di erence discriminating features mdf expressive features 
extracted projection 
may best classification features describe major variations class typically irrelevant subclasses divided 
selected multi class multivariate discriminate analysis significantly higher capability catch major di erences classes 
experiments showed superior automatic feature selection classification 
recognizing temporal gestures needs spatial features require temporal features 
possible recognize gestures locations hands general view dependent 
fundamental feature location interested blob 
wren multi class statistical model color shape obtain representation head hand wide range viewing conditions tracking system pfinder 
order achieve spatial invariant recognition features necessary 
campbell investigated invariant features comparing recognition performance di erent feature vectors derived single set ai chi gestures staying alive application developed becker pentland 
hidden markov model hmm taken recognizer 
reported dr dz best recognition rates 
time experiments highlight fact choosing right set features crucial performance 
features temporally invariant gesture recognition hard specify depends temporal representation gestures 
handled implicitly recognition approaches finite state machine hmm discussed section 
data collection recognition collect data temporal gesture recognition trivial task 
hand localized image sequences segmented background 
tracking supplies localized information hand bounding boxes centroid hand blobs 
simple motion trajectories extracted image sequences 
cases features su cient gesture recognition 
tracking algorithms color tracking motion tracking template matching blob tracking multiple cues integrating 
tracking gives position information hand recognition applications need features hand orientation hand shape 
tracking approaches try locate hand space position orientation hand 
hand treated lecture notes computer science gesture workshop rigid object hard estimate hand orientation 
position hand achieved stereo camera model approaches 
hand highly articulated shape depends viewpoint hand shape hard describe 
studies try recover state hand represented set joint angles full dof tracking 
hand configuration estimated recognizing finger spelling may easier 
estimate configuration articulated objects needs study 
static hand posture recognition hand postures express concepts act special transition states temporal gestures recognizing estimate hand postures human postures main topics gestures recognition 
cui weng discriminating features classify hand signs partitioning mdf space 
manifold interpolation scheme introduced generalize variations limited number learned samples 
algorithm handle complex background 
triesch malsburg employ elastic graph matching technique classify hand postures complex backgrounds 
hand postures represented labeled graphs underlying dimensional topology 
attached nodes jets sort local image description gabor filters 
recognition rate complex background 
approach achieve scale invariant user independent recognition need hand segmentation 
graph hand posture insu cient approach view independent 
quek zhao introduced inductive learning system able derive rules disjunctive normal form formulate 
dnf describes hand pose conjunct dnf constitutes single rule 
features area bounding box compactness hand normalized moments served input feature vector learning algorithm 
obtained recognition rate 
ritter detected location fingertips local linear mapping lln neural network locations mapped position parametric self organizing map neural network ability perform associative completion fragmentary input 
means approach recognize hand pose di erent views 
temporal gesture modeling recognition similarities temporal gestures speech techniques speech hmm applied gesture 
temporal gesture complicated speech 
low level movements ying wu thomas huang recognized dynamic models 
gesture semantics exploited recognize high level activities 
example learning methods 
techniques developed years 
recognition modeling dynamics modeling low level dynamics human motion important human tracking human motion recognition 
serves quantitative representation simple movements simple movements recognized reduced space trajectories motion parameters 
low level dynamics models su cient represent complicated human motions 
low level motions represented simple dynamic processes kalman filter employed estimate interpolate predict motion parameters 
simple dynamic model sufficient model cases human motion gaussian assumption kalman filtering usually invalid 
black jepson extended condensation algorithm recognize temporal trajectories 
sampling technique represent probability density condensation algorithm approach avoids di culties kalman filtering 
gesture recognition achieved matching input motion trajectories model trajectories dynamic time warping dtw 
pentland liu try represent human behavior complex model 
alternative models represent human dynamics class response 
model switching observation state dynamics 
approach produces generalized maximum likelihood estimate current values state variables 
recognition achieved determining model best fits observation 
blake push technique combining idea model switching condensation 
mixed discrete continuous states couple perception classification continuous variable describes motion parameters discrete variable labels class motion 
arma model represent dynamics 
approach achieve automatic temporal sequence segmentation 
dealing specific gestures 
cohen dynamic model represent circle line gesture generate recognize basic oscillatory gestures crane control gestures 
recognition modeling semantics applications need recognize complex gestures include semantic meaning movements 
modeling dynamics su cient tasks 
finite state machine usually employed technique handle situation 
davis shah technique recognize simple hand gestures 
jo kuno shirai take approach recognize manipulative lecture notes computer science gesture workshop hand gestures grasping holding extending 
task knowledge represented state transition diagram state indicates possible gesture states moment 
rest state unintentional actions ignored 
pavlovic berry take approach 
approach rule modeling 
quek uses extended logic rule induction algorithm build inductive learning system recognize gestures 
cutler turk build set simple rules recognize gestures waving jumping marching pinhanez bobick develop new representation temporal gestures valued domain past fut pnf network 
occurrence action computed minimizing domain pnf network constraints imposed current state sensors previous states network 
promising approach modeling semantics temporal gestures bayesian network dynamic bayesian network 
pavlovic push idea forward 
gesture recognition hmm framework hmm type statistical model 
hmm consists states transition matrix 
state assigned output probability distribution function gives probability state generating observation condition system basic problems hmms 
problem evaluation solved forwardbackward algorithm 
second problem find state sequence observation hmm model maxp 
viterbi algorithm solve 
third problem train hmm 
algorithm solve 
pentland liu hmm model state transitions set dynamic models 
bregler takes approach 
hmm capacity modeling low level dynamics semantics gestures 
stoll ohya employ hmm model semantically meaningful human movements hmm learned motion class 
data modeling human motions approximate pose derived image sequence 
nam hmm method recognize controlling gestures 
approach takes account hand movement hand postures palm orientations 
variations hmm 
yang model gesture employing multi dimensional hmm contains observation symbol time 
approach able model multi path gestures provides means integrate multiple modality increase recognition rate 
output probability feature vectors state hmm unique hmm handle piecewise stationary processes adequate gesture modeling 
kobayashi introduce markov model temporal matching 
darrell pentland ying wu thomas huang introduce hidden state reinforcement learning paradigm partially observable markov decision process gesture recognition active camera guided 
markov condition violated conventional hmms fails 
hmms ill suited system compositional states 
brand algorithm coupling training hmms model interactions processes may di erent state structures degrees influence 
problems occur vision speech coupled hmms suited applications requiring sensor fusion modalities 
wilson bobick extended standard hmm method include global parametric variation output probabilities hmm handle parameterized movements musical conducting driving em algorithm 
results di erent movements size gesture point gesture show robustness respect noise input features 
techniques statistical learning techniques applied gesture recognition 
describe cui weng multiclass multidimensional discriminant analysis automatically select discriminating features gesture recognition 
polana nelson attempt recognize motion low level statistical features image motion information 
simple nearest centroid algorithm serves classifier 
experiments show approach suitable repetitive gesture recognition 
watanabe yachida introduce eigenspace constructed multi input image sequences recognize gestures 
eigenspace represents approximate information gestures approach handle self occlusion 
bobick ivanov model low level temporal behaviors hmm techniques 
outputs hmm serve input stream stochastic contextfree grammar parsing system 
grammar parser provide longer range temporal constraints 
uncertainty low level movement detection disambiguated high level parser include priori knowledge structure temporal actions 
yang ahuja time delay neural networks tdnn classify motion patterns 
tdnn trained database asl signs 
input tdnn motion trajectories extracted multi scale motion segmentation 
sign language recognition general gestures sign languages highly structured provides appealing test bed understanding general principles 
clear boundaries individual signs recognition sign languages di cult 
speech recognition sign language recognition parallels 
time varying processes show statistical variations making lecture notes computer science gesture workshop hmms plausible choice modeling processes 
devise ways cope context articulation ects 
hmms provide framework capturing statistical variations position duration movement 
addition segment gesture stream implicitly 
kinds gestures recognized isolated gesture continuous gesture 
presence silence boundaries isolated gestures easy spot 
sign extracted trained hmms individually 
continuous sign recognition hand harder silence signs 
hmms er compelling advantage able segment streams signs automatically viterbi algorithm 
articulation di cult handle continuous recognition results insertion extra movement signs 
starner employ hmm recognize american sign language asl 
assume detailed information hand shape necessary humans interpret sign language coarse tracking system studies 
possible approaches deal articulation problem 
context dependent hmms modeling articulation 
idea context dependent hmms train bi sign tri sign context dependent hmms 
method 
vogler metaxas study articulation sign language recognition 
propose unsupervised clustering scheme obtain necessary classes phonemes modeling movements signs 
phonemes signs basic units asl signs broken phonemes movements holds hmms trained recognize phonemes 
number phonemes limited possible hmms recognize large scale vocabularies 
liang take hmm approach recognition continuous sign language vocabulary signs 
temporal segmentation performed explicitly discontinuity movements gesture parameters posture position orientation motion 
directions current static hand posture recognition techniques seldom try achieve view independent recognition 
approach extract features estimate hand configuration 
approach learning 
approaches need investigation hand gestures 
representation temporal gesture crucial recognition 
lowlevel movement recognition tracking automatic switching di erent motion models considered studies 
current gesture applications look symbolic gesture commands 
automatic segmentation temporal gestures plays important role extracting segmenting ying wu thomas huang gesture commands continuous movements 
open problem receive attention 
hmm handle segmentation cases may fail presence articulation 
handed gestures tracking di cult interpretation gesture harder 
problems investigated research 
speech gestures coupled natural consider combing gesture speech multi modality system 
report development research hand gesture recognition focus various recognition techniques 
feature selection specified explicitly implicitly recognizer crucial recognition algorithms 
data collection visual gesture learning trivial task 
various algorithms static hand posture recognition temporal gesture recognition surveyed 
hmm variants sign language recognition 
due complexity gesture machine leaning techniques promising task 
gesture recognition infancy 
involves cooperation disciplines 
order understand hand gestures machines humans substantial research orts computer vision machine learning psycholinguistics needed 
supported part national science foundation cda iri 

becker real time recognition feedback training system tai chi gestures mit media lab ms thesis 
berry small wall multimodal human computer intelligent interaction test bed applications dept ece university illinois urbana champaign ms thesis 
black jepson recognition temporal trajectories condensation algorithm int conf 
automatic face gesture recognition japan pp 
bobick ivanov action recognition probabilistic parsing ieee int conf 
computer vision pattern recognition 
bobick wilson state approach representation recognition gesture ieee trans 
pami vol dec pp 
yeo yeung gesture speech video content navigation proc 
workshop perceptual user interfaces 
brand oliver pentland coupled hidden markov models complex action recognition proc 
ieee int conf 
computer vision pattern recognition 
bregler learning recognizing human dynamics video sequences proc 
ieee int conf 
computer vision pattern recognition 
campbell invariant features gesture recognition int conf 
automatic face gesture recognition killington pp 

cohen conway koditschek dynamical system representation generation recognition basic oscillatory motion gestures int conf 
automatic face gesture recognition killington lecture notes computer science gesture workshop 
crowley coutaz finger tracking input device augmented reality int workshop automatic face gesture recognition zurich pp 

cui weng hand sign recognition intensity image sequences complex background proc 
ieee conference computer vision pattern recognition pp 

cui weng hand segmentation learning prediction verification hand sign recognition int conf 
automatic face gesture recognition killington 
cui swets weng learning hand sign recognition int 
workshop automatic face gesture recognition zurich pp 

cutler turk view interpretation real time optical flow gesture recognition ieee int 
conf 
automatic face gesture recognition japan 

darrell pentland active gesture recognition partially observable markov decision processes ieee int conf 
pattern recognition 
davis bobick virtual pat virtual personal trainer proc 
workshop perceptual user interfaces pp 

davis bobick representation recognition action temporal templates ieee cvpr pp 

davis shah visual gesture recognition vision image signal processing pp 

fernandez stochastic modeling physiological signals hidden markov models step frustration detection human computer interfaces mit media lab ms thesis 

gavrila visual analysis human movement survey computer vision image understanding vol jan pp 

goncalves bernardo perona reach touch space ieee int 
conf 
automatic face gesture recognition japan 
lu igi color hand tracking system sign language recognition ieee int 
conf 
automatic face gesture recognition japan 

jo kuno shirai manipulative hand gestures recognition task knowledge human computer interaction ieee int 
conf 
automatic face gesture recognition japan 

ju black minneman analysis gesture action technical talks video indexing ieee conf 
computer vision pattern recognition cvpr 

kendon issues study gesture biological foundation gestures motor semiotic aspects pp lawrence erlbaum associate hillsdale nj 
kjeldsen interaction screen objects visual gesture recognition proc 
ieee cvpr 
kobayashi partly hidden markov model application gesture recognition ieee proceedings icassp vol 
vi pp 

gesture recognition features images hmm recognizer ieee int 
conf 
automatic face gesture recognition japan 

liang real time continuous gesture recognition system sign language ieee int 
conf 
automatic face gesture recognition japan 

mcneil hand mind university chicago press chicago 

nam recognition space time hand gestures hidden markov acm symposium virtual reality software technology hongkong pp 


ritter illumination independent recognition deictic arm postures proc 
th annual conf 
ieee industrial electronics society germany pp 


pavlovic dynamic bayesian networks information fusion applications human computer interfaces dept ece university illinois urbana champaign ph dissertation 
pavlovic sharma huang visual interpretation hand gestures humancomputer interaction review ieee trans 
pami vol july pp 
pentland liu modeling prediction human behavior ieee intelligent vehicles 
pinhanez bobick human action detection pnf propagation temporal constraints ieee iccv 
polana nelson low level recognition human motion ieee workshop motion non rigid articulated objects austin pp 

quek unencumbered gestural interaction ieee multimedia vol pp 
quek zhao inductive learning hand pose recognition ieee automatic face gesture recognition 
rohr model recognition human movements image sequences cvgip image understanding vol jan pp ying wu thomas huang 
blake classification human body motion ieee int conf 
computer vision 
starner weaver pentland real time american sign language recognition desk wearable computer video ieee trans 
pami 
sign language structure university bu alo press 
stoll ohya applications hmm modeling recognizing human gestures image sequences man machine interface ieee intl workshop robot human communication 
triesch malsburg robust classification hand postures complex background intl conf 
automatic face gesture recognition 
triesch malsburg gesture interface human robot interaction intl conf 
automatic face gesture recognition 
kishino hand gesture recognition system multiple cameras ieee icpr 
vogler metaxas asl recognition coupling hmms motion analysis ieee iccv 
vogler metaxas scalability asl recognition breaking signs phonemes ieee gesture workshop 
watanabe yachida real time gesture recognition eigenspace multi input image sequences intl conf 
automatic face gesture recognition japan 
wilson bobick recognition interpretation parametric gesture ieee intl conf 
computer vision 
wren pentland dynamic modeling human motion ieee intl conf 
automatic face gesture recognition 
wu huang human hand modeling analysis animation context hci ieee intl conf 
image processing 
yang xu chen gesture interface modeling learning proc 
ieee int 
conf 
robotics automation vol 
pp 

yang ahuja extraction classification visual motion patterns hand gesture recognition ieee int conf 
computer vision pattern recognition 
zeller visual computing environment large scale biomolecular modeling proc 
ieee int 
conf 
application specific systems architectures processors asap zurich pp 


