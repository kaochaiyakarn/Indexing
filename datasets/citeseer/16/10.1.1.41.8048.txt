comprehensive database facial expression analysis takeo kanade robotics institute carnegie mellon university pittsburgh pa usa tk cs cmu edu www cs cmu edu face past decade significant effort occurred developing methods facial expression analysis 
investigators relatively limited data sets generalizability various methods remains unknown 
describe problem space facial expression analysis includes level description transitions expression eliciting conditions reliability validity training test data individual differences subjects head orientation scene complexity image characteristics relation non verbal behavior 
cmu pittsburgh au coded face expression image database currently includes digitized image sequences adult subjects varying ethnicity performing multiple tokens primary facs action units 
database comprehensive test bed date comparative studies facial expression analysis 

past decade significant effort occurred developing methods facial feature tracking analysis 
analysis includes measurement facial motion recognition expression 
investigators relatively limited data sets generalizability different approaches facial expression analysis remains unknown 
exceptions relatively global facial expressions joy anger considered subjects number homogeneous respect age ethnic background recording conditions optimized 
approaches facial expression analysis developed way jeffrey cohn department psychology university pittsburgh robotics institute carnegie mellon university hara street pittsburgh pa usa pitt edu tian robotics institute carnegie mellon university pittsburgh pa usa cs cmu edu may transfer poorly applications expressions subjects contexts image properties variable 
addition common data exist multiple laboratories may conduct comparative tests methods 
absence comparative tests common data relative strengths weaknesses different approaches difficult determine 
areas face speech recognition comparative tests proven valuable similar benefits accrue study facial expression analysis 
large representative test bed needed evaluate different approaches 
describe problem space facial expression analysis 
space includes multiple dimensions level description temporal organization eliciting conditions reliability manually coded expression individual differences subjects head orientation scene complexity image acquisition relation non facial behavior 
note date confined relatively restricted region space 
describe characteristics databases map problem space evaluate phase cmu pittsburgh au coded facial expression database criteria 
database provides large representative test bed comparative studies different approaches facial expression analysis 
problem space face expression analysis level description current facial expression analysis attempts recognize small set expressions 
prototypes occur relatively infrequently provide incomplete description facial expression 
capture subtlety human facial expression fine grained description facial expression needed 
facial action coding system facs human system designed detect subtle changes facial features 
viewing videotaped facial behavior slow motion trained observers manually facs code possible facial displays referred action units au may occur individually combinations 
facs consists action units 
anatomically related contraction specific set facial muscles table 
anatomic basis remaining unspecified table 
table 
facs action units 
referred facs miscellaneous actions 
action units may coded symmetrical asymmetrical 
action units vary intensity point ordinal scale measure degree muscle contraction 
ekman friesen proposed specific combinations facs action units represent expressions emotion emotion specified expressions part facs coded separate systems 
facs purely descriptive includes inferential labels 
converting facs codes similar systems face images may coded emotion specified expressions joy anger categories positive negative emotion 
au facial muscle description muscle movement pars inner corner eyebrow raised pars outer corner eyebrow raised eyebrows drawn eyes widened pars cheeks raised eyes narrowed pars lower eyelid raised drawn upper lip raised inverted superior part furrow deepened dilated medial slip muscle upper lip raised furrow deepened producing square furrows nostrils lower medial part furrow deepened major lip corners pulled laterally minor angle mouth elevated muscle deep layer muscles opens lips lip corners tightened 
cheeks compressed teeth corner mouth pulled downward inward lower lip pulled laterally skin chin elevated lips lip corners pulled laterally lips lips tightened lips pressed relaxation lips relaxed temporal internal jaw dropped mouth stretched open lips relaxation upper eyelid eyelid slit relaxation pars eyes closed pars eyes relaxation pars blink relaxation pars table 
miscellaneous actions 
au description movement lips tongue show neck tighten jaw thrust jaw sideways jaw bite lip blow cheek tongue bulge lip wipe compress transitions expressions simplifying assumption previous research expressions singular neutral position 
reality facial expression complex especially level action units 
action units may occur combinations show serial dependence 
transitions action units combination actions may involve intervening neutral state 
parsing stream behavior essential requirement robust facial analysis system training data needed include dynamic combinations action units may additive non additive 
example additive combination smiling au mouth opening coded au au au depending degree lip far lowered 
case au instance facial analysis system need detect transitions levels mouth opening continuing recognize au may simultaneously changing intensity 
non additive combinations represent complexity 
usage speech science refer interactions articulation effects 
example combination au occurs embarrassment 
au raises cheeks action lip corners modified downward action au 
resulting appearance change highly dependent timing 
downward action lip corners may occur simultaneously sequentially 
comprehensive database include individual action units additive non additive combinations especially involve coarticulation effects 
classifier trained single action units may perform poorly combinations articulation effects occur 
deliberate versus spontaneous expression face expression data collected asking subjects perform series expressions 
directed facial action tasks may differ appearance timing spontaneously occurring behavior 
deliberate spontaneous facial behavior mediated separate motor pathways pyramidal extra pyramidal motor tracks respectively 
consequence fine motor control deliberate facial actions inferior symmetric occurs spontaneously 
people instance able raise outer brows spontaneously leaving inner brows rest perform action voluntarily 
spontaneous depression lip corners au raising narrowing inner corners brow au common signs sadness 
training people perform actions deliberately incidentally aid lie detection 
differences temporal organization spontaneous deliberate facial actions particularly important pattern recognition approaches hidden markov modeling highly dependent timing appearance change 
database includes deliberate spontaneous facial actions prove inadequate developing face expression methods robust differences 
reliability expression data training system recognize facial expression investigator assumes training test data accurately labeled 
assumption may may accurate 
asking subjects perform action guarantee 
ensure internal validity expression data manually coded reliability coding verified 
inter observer reliability improved providing rigorous training observers monitoring performance 
facs coders pass standardized test ensures initially uniform coding international laboratories 
monitoring best achieved having observers independently code portion data 
general rule data comparison coded 
guard drift coding criteria re standardization important 
assessing reliability coefficient kappa preferable raw percentage agreement may inflated marginal frequencies codes 
kappa quantifies inter observer agreement correcting level agreement expected chance 
individual differences subjects face shape texture color facial scalp hair vary sex ethnic background age 
infants instance smoother textured skin lack facial hair brows scalp 
eye opening contrast iris differ markedly northern may affect robustness eye tracking facial feature analysis generally 
jewelry may obscure facial features 
individual differences appearance may important consequence face analysis 
attempts study influence exist 
exception study 
algorithms optical flow component detection optimized young adults performed infants 
reduced texture infants skin increased fatty tissue juvenile facial conformation lack transient furrows may contributed differences observed face analysis infants adults 
addition individual differences appearance individual differences expressiveness refers degree facial plasticity morphology frequency intense expression rate expression 
individual differences characteristics established important aspect individual identity 
incidentally individual differences augment accuracy face recognition algorithms 
extreme example variability expressiveness occurs individuals incurred damage facial nerve central nervous system 
develop algorithms robust individual differences facial features behavior essential include large sample varying ethnic background age sex includes people facial hair wear jewelry includes normal clinically impaired individuals 
head orientation scene complexity face orientation relative camera presence actions people background conditions may influence face analysis 
face recognition literature face orientation received deliberate attention 
feret data base instance includes frontal oblique views specialized data bases collected try develop methods face recognition invariant moderate change face orientation 
face expression literature multiple perspectives rare relatively attention focused problem pose invariance 
researchers assume face orientation limited plane variation plane variation small 
reality large variation head position common accompanies change expression 
kraut smiling typically occurs turning person 
showed infant surprise expressions occur infant pitches head back 
develop pose invariant methods face expression analysis image data needed facial expression changes combination significant non planar change pose 
scene complexity background presence people potentially influences accuracy face detection feature tracking expression recognition 
databases image data background neutral consistent pattern single person scene 
natural environments multiple people interacting effects need understood 
variation represented training data difficult develop test algorithms robust variation 
image acquisition resolution image acquisition includes properties number video cameras digitizer size face image relative total image dimensions ambient lighting 
factors may influence facial expression analysis 
images acquired low light coarse resolution provide information facial features 
similarly face image size small relative total image size information available 
ntsc cameras record images frames second implications sampling rate unknown 
algorithms optical flow assume pixel displacement adjacent frames small 
tested range sampling rates robustness sampling rate resolution assessed 
image sequence change head position relative light source variation ambient lighting potentially significant effects face expression analysis 
light source subject head cause shadows fall brows obscure eyes especially subject pronounced bone structure hair 
methods studio lighting may perform poorly naturalistic lighting exterior window angle lighting changes image sequence 
investigators single camera set ups problematic frontal orientation required 
image data single camera outof plane variation may difficult standardize 
small plane rotation multiple cameras may required 
multiple camera setups support modeling cases ground truth assess accuracy image alignment 
image resolution concern 
professional grade pal cameras instance provide high resolution images 
contrast security cameras provide ones seriously degraded 
post processing may improve image resolution degree potential improvement limited 
effects post processing expression recognition known 
algorithms optimal resolutions full face frontal images studio lighting expected perform poorly recording conditions degraded images compressed 
knowing boundary conditions face expression algorithms comparative performance difficult assess 
algorithms appear superior set boundary conditions may perform poorly range potential applications 
appropriate data factors tested needed 
relation non facial behavior facial expression channels nonverbal communication may occur 
contraction major au instance associated positive happy vocalizations smiling tends increase vocal fundamental frequency 
research groups attempted integrate gesture recognition broadly defined multiple channels communication 
important question advantages early late integration 
databases containing multi modal expressive behavior afford opportunity integrated approaches analysis facial expression prosody gesture kinetic expression 
summary problem statement problem space facial expression includes multiple dimensions 
develop robust methods facial expression analysis dimensions adequately sampled 
addition allow comparative tests alternative approaches facial expression analysis appropriate data available face analysis community 
meet needs developed cmu pittsburgh au coded facial expression database serve test bed algorithm development testing 
cmu pittsburgh au coded face expression image database interdisciplinary research group psychologists computer scientists developing large representative facial expression database training testing algorithms facial expression analysis 
section describe cmu pittsburgh au coded face expression database 
evaluate database criteria discuss current 
description database facial behavior recorded adults ages years 
female male euro american american groups table 
observed observation room equipped chair sit panasonic wv cameras connected panasonic ag video recorder synchronized time code generator 
cameras located directly front subject positioned degrees subject right 
example image data cmu pittsburgh au coded facial expression database seen 
approximately third subjects ambient room lighting augmented high intensity lamp 
thirds lamps reflective provide uniform lighting 
table 
cmu pittsburgh au coded facial expression database 
subjects number subjects age years women men euro american american digitized sequences number subjects resolution grayscale bit color frontal view degree view videotape sequence duration frames sequence action units table au table au subjects instructed experimenter perform series facial displays included single action units combinations action units 
display began ended neutral face combinations timing action units examined 
subjects performed head rotation degrees facial expression recorded cameras 
image sequences frontal views digitized pixel arrays bit gray scale bit color values 
date image sequences subjects facs coded target action units entire sequence 
degree views available videotape 
approximately fifteen percent sequences comparison coded second certified facs coder 
inter observer agreement quantified coefficient kappa proportion agreement expected occur chance 
mean inter observer agreement action units coded apex frame frame coding 
action units coded apex performing additional coding 
increasing number action units coded intensity 

frontal degree side views available cmu pittsburgh au coded facial expression database 
cmu pittsburgh au coded face expression image database includes action units listed table combination aus exception au people find difficult perform voluntarily occurs infrequently spontaneous behavior 
miscellaneous actions listed table represented 
database studies 
information database please contact second author 
database evaluation sequences male female subjects varying ethnic background database provides sufficiently large representative test bed assessing facial behavior factors 
level facial expression description supports analyses single action units additive non additive combinations 
applying emotion specified expressions joy anger may analyzed 
action unit combinations representing joy surprise sadness disgust anger fear included adequate numbers 
expressions may combined form aggregates positive negative expression 
database includes subjects varying skin color facial conformation influence factors may examined 
lighting conditions context relatively uniform 
plane head motion small mild 
images acquired video cameras approximately lines frame digitized frame rate omitting odd fields 
image data may transformed sampled examine effects reduced resolution sampling rate image compression luminance 
database limitations form 
intensity scoring action units incomplete sequences target frames entire sequence coded 
noted continued coding underway order improve data 
limitation lack spontaneous expressions 
deliberate spontaneous expressions may different appearance timing important adequate numbers 
solution pursuing examine videotapes instances spontaneously occurring action units occurred experimental session 
large sample spontaneous smiles au related action units au added database 

automated face detection facial feature eye tracking image sequence obtained synchronized cameras split screen generator 
database extension 
emotion analysis 
making arrangements include data studies emotion processes 
studies elicited emotion responses infants children adults recorded facial vocal behavior 
shows example automated face detection feature tracking image sequence face face interaction mother infant 
image acquired synchronized cameras split screen generator commonly psychologists study social interaction 
image suggests challenges dimensions face analysis problem space 
face images facial features especially infant small relative image size infant face low texture shadows occur likelihood sudden large motion occasional occlusion moderate plane motion high 
challenging problems appropriate training testing data critical 
surgical application 
data source facial behavior patients experienced damage facial nerve higher brain centers control facial behavior 
example seen 
notice mild asymmetry due muscle weakness marked asymmetry occurs second frame 
inclusion clinical data challenges assumptions symmetry common working directed facial action task images subjects normal facial function 

automated facial feature tracking image sequence subject facial nerve impairment 
omni view facial analysis 
plan expand ability analyze facial expression multiple perspectives 
research team method referred virtualized reality integrate input dense arrays cameras 
example face image multiple camera views seen 
subject shown perspective cameras 
virtualized reality intermediate views may generated possible perspectives 
approach affords accurate modeling facial expression necessary ground truth test image alignment algorithms single camera data 


problem space facial expression analysis includes multiple dimensions 
include level description transitions expressions distinctions deliberate spontaneous expressions reliability validity training test data individual differences subjects facial features related characteristics head orientation scene complexity image characteristics relation non verbal behavior 
development robust methods facial expression analysis requires access databases adequately sample problem space 
cmu pittsburgh au coded facial expression image database provides valuable test bed multiple approaches facial expression analysis may tested 
current new increase generalizability database 

face images obtained camera 
images shown available 

research supported number mh national institute mental health 

bartlett hager ekman sejnowski measuring facial expressions computer image analysis 
psychophysiology 
lambrecht michel 
infant surprise expressions coordinative motor structures 
journal nonverbal behavior 
cohn katz bimodal expression emotion face voice 
acm atr workshop face gesture recognition applications 
ekman friesen facial action coding system consulting psychologist press palo alto ca 
ekman rosenberg eds face reveals 
ny oxford university 
farkas munro anthropometric facial proportions medicine springfield illinois charles thomas 
statistical methods rates proportions ny wiley 
friesen ekman emotional facial action coding system unpublished manuscript university california san francisco 
kraut johnson social emotional messages smiling ethological approach 
journal personality social psychology 
lien kanade cohn li detection tracking classification subtle changes facial expression 
journal robotics autonomous systems press 
lien kanade cohn li 
automated facial expression recognition 
proceedings third ieee international conference automatic face gesture recognition fg 
martin measuring behavior introductory guide 
cambridge cambridge university 
matias cohn ross comparison systems code infants affective expression 
developmental psychology 
expressiveness individual difference 
feldman rime eds fundamentals nonverbal behavior 
ny cambridge university 
narayanan kanade constructing virtual worlds dense flow 
proceedings international conference computer vision 
neuropsychology facial expression review neurological psychological mechanisms producing facial expressions 
psychological bulletin 
rizvi phillips moon feret verification testing protocol face recognition algorithms 
proceedings third international conference automatic face gesture recognition 
tian kanade cohn robust lip tracking combining shape color motion 
asian conference computer vision 
cohn bajaj specific impairment smiling increases severity symptoms patients facial disorders 
journal aesthetic plastic surgery press 
vetter learning novels views single face image 
proceedings ieee international conference automatic face gesture recognition 
cohn pixel wise tracking facial movement computer image processing 
robert ivy society plastic reconstructive surgeons pittsburgh 
deciphering emotion face evaluation facs emg computer vision approaches facial expression analysis 
unpublished manuscript university pittsburgh 
cohn lien kanade computer vision method facial expression analysis parent infant interaction international conference infant studies atlanta georgia april 
