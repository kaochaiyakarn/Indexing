technical report 
submitted cog 
sci 
conf 
semi distributed representations overcome catastrophic forgetting connectionist networks robert french center research concepts cognition indiana university north bloomington indiana mail french cogsci indiana edu connectionist networks newly learned information destroys previously learned information network continually retrained old information 
behavior known catastrophic forgetting unacceptable practical purposes model mind 
advances claim catastrophic forgetting direct consequence overlap system distributed representations reduced reducing overlap 
simple algorithm allows standard feedforward backpropagation network develop semi distributed representations significantly reducing problem catastrophic forgetting 
catastrophic forgetting inability neural network retain old information presence new 
new information destroys old old information continually net 
mccloskey cohen ratcliff demonstrated serious problem connectionist networks 
related problem connectionist networks sensitive overtraining 
network trained times associate pattern pattern forget fact just quickly network trained association cycles 
clearly behavior unacceptable model mind purely practical standpoint 
network thoroughly learned set patterns able learn completely new set able recall set relative ease 
suggest catastrophic forgetting arises overlap distributed representations algorithm allow standard feedforward backpropagation network overcome significant extent problems catastrophic forgetting insensitivity overtraining 
catastrophic forgetting overlap representations suggest relation catastrophic forgetting representations distributed system catastrophic forgetting direct consequence overlap distributed representations reduced reducing overlap 
local representations exhibit catastrophic forgetting little interaction representations 
consider extreme example look table overlap representations 
catastrophic forgetting new information added interfering old information 
completely local representations look table lacks important ability generalize 
extreme fully distributed networks considerable interaction representations 
interaction responsible networks generalization ability 
hand networks severely affected catastrophic forgetting 
extreme fully distributed networks considerable interaction representations 
interaction responsible networks generalization ability 
hand networks severely affected catastrophic forgetting 
moral story ways 
system develops highly distributed representations able generalize suffer forgetting conversely system develops local representations suffer catastrophic forgetting lose ability generalize 
challenge develop systems capable producing semi distributed representations local overcome catastrophic forgetting sufficiently distributed allow generalization 
follows examine distributed systems suffer catastrophic forgetting 
systems representations fully distributed entire memory semi distributed exhibit limited representation overlap prior memory saturation 
simple method allows standard layered feedforward backpropagation networks develop semi distributed representations hidden layer 
method appear dramatically reduce catastrophic forgetting allows system representations partially reflect degree particular pattern learned 
particular pattern learned overlearning continues modify connection weights way pattern difficult 
examples semi distributed representations briefly examine systems produce semi distributed representations 
systems assuming saturated little overlap representations produced 
reason exhibit little catastrophic forgetting 
sparse distributed memory sparse distributed memory sdm kanerva auto associative content addressable memory typically consisting bit memory locations 
memory called sparse uses locations possible approximately possible locations 
locations vector integers called counters 
new data represented system follows wish write particular bit string memory select memory locations hamming distance bits write address 
gives approximately locations entire address space 
bit string written memory increment corresponding counter vectors memory locations decrement corresponding counter 
clearly semi distributed representation input data storage bit string distributed different memory locations memory locations account mere total available memory 
system easily store new information interfering previously stored information long representations overlap 
soon memory starts saturated somewhat words written memory interference representations learning new information begins interfere old 
case forgetting old information new information stored 
kruschke computer memory model nosofsky exemplar memory model nosofsky 
model suffer phenomenon catastrophic forgetting noted ratcliff mccloskey cohen 
see sdm uses semi distributed representations 
kruschke computer memory model nosofsky exemplar memory model nosofsky 
model suffer phenomenon catastrophic forgetting noted ratcliff mccloskey cohen 
see sdm uses semi distributed representations 
layer feed forward network activation node hidden layer inversely exponentially proportional distance hidden node position input stimulus position 
hidden layer regarded covering input layer 
inverse exponential activation function effect producing localized receptive field hidden node causing respond limited part input field 
kind localization exist standard networks 
system represents inputs semi distributed manner hidden nodes part representation input 
architecture representation new inputs especially new inputs close learned patterns overlap significantly old representations 
means set weights produced old representations remain largely unaffected new input 
sdm representations somewhat distributed conferring system ability generalize 
width receptive fields node increased making representation distributed causing greater overlap representations amount interference representations increases 
semi distributed representations networks catastrophic forgetting reduced order inputs network important 
training done sequentially concurrently 
words artificial constraint requiring training data network interleaved fashion relaxed 
addition representations reflected amount training required produce possible produce system better model overlearning standard networks 
initial attempt reduce catastrophic forgetting semi distributed representations differentially modifying learning rates connections network described french jones 
technique gave promising results small networks failed scale larger networks 
algorithm different technique allows semi distributed representations evolve significantly reduce catastrophic forgetting 
activation overlap representational interference networks catastrophic forgetting closely related studied phenomenon crosstalk 
discussion crosstalk traditionally involved capacity network store information willshaw certain capacity distributed networks longer store new information destroying old 
standard backpropagation models serious problem 
things currently stand networks artificially interleaved training sets 
network near theoretical storage capacity learning single new input completely disrupt previously learned information 
catastrophic forgetting crosstalk 
feedforward backpropagation network represents inputs activation patterns units hidden layer 
amount interaction representations measured degree activation overlap 
activation overlap number representations hidden layer defined average shared activation units hidden layer 
example hidden units representation input second calculate activation overlap summing smaller activations shared activation unit averaging units 
activation overlap 
feedforward backpropagation network represents inputs activation patterns units hidden layer 
amount interaction representations measured degree activation overlap 
activation overlap number representations hidden layer defined average shared activation units hidden layer 
example hidden units representation input second calculate activation overlap summing smaller activations shared activation unit averaging units 
activation overlap 
suggest amount representations interfere directly proportional amount activation overlap 
example consider activation patterns 
activation overlap 
regardless weights connections hidden layer output layer interference production separate output patterns 
activation overlap increases level interference 
find way network produce representations little activation overlap possible able significantly reduce catastrophic forgetting 
sharpening activation hidden units technique call activation sharpening allow system gradually develop semi distributed representations hidden layer 
activation sharpening consists increasing activation number active hidden units small amount slightly decreasing activation units similar fashion changing input hidden layer weights accommodate changes 
new activation nodes hidden layer calculated follows new old old nodes sharpened new old aa old nodes sharpening factor 
idea 
nodes activation values close far significant effect output average nodes activations close 
system evolve representations highly activated nodes nodes average activation levels reduce average amount activation overlap representations 
result decrease catastrophic forgetting 
addition sharpening occurs gradually course learning continues particular association learned representations developed reflect amount training took produce 
consider node sharpening 
pass find active node increase activation slightly decrease activations nodes 
preserve changes difference pre sharpened activation sharpened activation weights input layer hidden layer 
details algorithm node sharpening perform forward activation pass input layer hidden layer 
record activations hidden layer sharpen activations nodes difference old activation sharpened activation node error error input layer modifying weights input layer hidden layer appropriately full forward pass input layer output layer 
usual output layer input layer repeat 
experimental results experiments consisted training overtraining feedforward backpropagation network set eleven associations 
learning rate momentum 
network new association 
new association learned associations set chosen tested see system remembered 
presentation previously learned association network invariably badly 
maximum error output nodes greater average error greater 
amount memory refresh required standard backpropagation network association recorded compared network node node node sharpening 
case sharpening factor 
results 
note node sharpening standard backpropagation 
seen node node node sharpening perform dramatically better standard network 
experiments consisted training overtraining feedforward backpropagation network set eleven associations 
learning rate momentum 
network new association 
new association learned associations set chosen tested see system remembered 
presentation previously learned association network invariably badly 
maximum error output nodes greater average error greater 
amount memory refresh required standard backpropagation network association recorded compared network node node node sharpening 
case sharpening factor 
results 
note node sharpening standard backpropagation 
seen node node node sharpening perform dramatically better standard network 
separate runs standard network required average cycles previously learned association 
dropped cycles node sharpening cycles node sharpening 
note runs terminated cycles 
activations nodes sharpened amount relearning began rise 
node sharpening cycles required 
node cycles node cycles sharpening modified system better standard backpropagation 
significantly worse 
graphs figures suggest amount memory refresh required varies directly amount activation overlap representations 
shows amount activation overlap eleven originally learned inputs various degrees activation sharpening 
nodes sharpened indicates standard backpropagation 
general activation overlap catastrophic forgetting measured number cycles required previously learned pattern 
see effect sharpening algorithm representations association 
runs activation patterns hidden nodes initial training period recorded 
nodes runs sorted activation levels figures averaged 
expected standard backpropagation distribution activations nodes approximately uniform 
gives activation profile active nodes active nodes approximately constant slope 
result node sharpening quite dramatic nodes active 
phenomenon observed experiments nodes sharpened 

activation sharpening 
examine activation sharpening reduces catastrophic forgetting 
consider node sharpening 
system learns set associations develops set sharpened representations hidden layer 
new association network 
activation sharpening immediately starts new representation sharpened form hidden nodes highly active 
early newly developing representation chance activation overlap formed representations standard backpropagation activation spread nodes 
sharpened activation patterns interfere weights network ones 
reason way backpropagation algorithm changes weights 
activation node near zero weight changes links associated small 
significant number nodes new representation low activation weights 
nodes sharpened effect sharpening amount memory refresh 
nodes sharpened effect sharpening activation overlap sharpened activation patterns interfere weights network ones 
reason way backpropagation algorithm changes weights 
activation node near zero weight changes links associated small 
significant number nodes new representation low activation weights 
nodes sharpened effect sharpening amount memory refresh 
nodes sharpened effect sharpening activation overlap connections node modified average weights associated highly active node 
representations significantly affected new representation highly active nodes overlap 
consequently reduce probability overlap activation sharpening decrease amount disruption old weights catastrophic interference reduced 
idea sharpen new activation patterns quickly possible decreasing potential interfere learned patterns 
keeping learning rate low relatively high sharpening factor allows new activation patterns sharpened chance damage previously learned weights 
preliminary experiments fact indicate learning rate decreased sharpening factor held constant catastrophic forgetting decreases 
semi distributed representations cost network ability generalize 
optimal generalization depends information possible part mapping input space output space 
mechanism tending reduce amount information brought bear new association reduce quality mapping 
sense activation sharpening forces input data representational bottleneck results information lost 
extent severity loss effect generalization subject ongoing study 
nodes sharpened 
open question 
nodes hidden layer answer smallest integer greater number inputs 
words sufficient number nodes sharpened allow existence distinct sharpened representations cover input space 
minimize activation overlap sufficient number sharpened nodes chosen 
number input patterns learned known advance activation standard backpropagation activation node sharpening activation node sharpening activation node sharpening activation node sharpening effect sharpening hidden layer activation profiles open question 
nodes hidden layer answer smallest integer greater number inputs 
words sufficient number nodes sharpened allow existence distinct sharpened representations cover input space 
minimize activation overlap sufficient number sharpened nodes chosen 
number input patterns learned known advance activation standard backpropagation activation node sharpening activation node sharpening activation node sharpening activation node sharpening effect sharpening hidden layer activation profiles activation profiles various node reasonable sharpen approximately log nodes 
estimate crosstalk willshaw 
indicates distributed memory crosstalk avoided number active units input pattern proportional logarithm total number units 
reasonable apply result sharpening hidden unit activations 
argued catastrophic forgetting distributed systems direct consequence amount overlap representations system 
suggested trade catastrophic forgetting generalization inevitable 
claimed way maintain generalization capabilities reducing catastrophic forgetting semi distributed representations 
simple method allow feedforward backpropagation network dynamically evolve semi distributed representations 
acknowledgments acknowledgments mark weaver invaluable assistance ideas emphasis 
david chalmers terry jones members sesame helpful comments 
bibliography feldman connectionist representation concepts connectionist models implications waltz feldman 
eds 
french jones differential hardening link weights simple method decreasing catastrophic forgetting neural networks technical report 
seidenberg catastrophic interference connectionist networks proceedings th annual conference cognitive science society hillsdale nj erlbaum 
kanerva sparse distributed memory cambridge ma mit press 
chris 
episodic memory connectionist networks proceedings th annual conference cognitive science society hillsdale nj erlbaum 
kruschke exemplar connectionist model category learning indiana university cognitive science research report february 
mccloskey cohen catastrophic interference connectionist networks sequential learning problem psychology learning motivation vol 

nosofsky choice similarity context theory classification exp psych 
learning memory cognition vol 

ratcliff connections models recognition memory constraints imposed learning forgetting function psychological review vol 

sloman rumelhart reducing interference distributed memories episodic gating healy kosslyn shiffrin eds essays honor estes press 
weaver active symbol connectionist model concept learning unpublished manuscript 
willshaw associative memory inductive generalization hinton anderson eds parallel models associative memory 
hillsdale nj erlbaum 

