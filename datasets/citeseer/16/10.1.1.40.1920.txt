survey optimization building probabilistic models martin pelikan david goldberg fernando lobo illigal report september illinois genetic algorithms laboratory university illinois urbana champaign transportation building mathews avenue urbana il office fax survey optimization building probabilistic models martin pelikan david goldberg fernando lobo illinois genetic algorithms laboratory department general engineering university illinois urbana champaign deg illigal ge uiuc edu summarizes research population probabilistic search algorithms modeling promising solutions estimating probability distribution constructed model guide exploration search space 
settles algorithms field genetic evolutionary computation originated 
methods classified classes complexity class models 
algorithms classes briefly described strengths weaknesses discussed 
number evolutionary algorithms guide exploration search space building probabilistic models promising solutions far proposed 
algorithms shown perform wide variety problems 
spite attempts field lacks global overview done research area heading 
purpose review describe basic principles proposed population search algorithms probabilistic modeling promising solutions guide search 
settles algorithms context genetic evolutionary computation classifies algorithms complexity class models discusses advantages disadvantages classes 
section briefly introduces basic principles genetic algorithms starting point 
continues sequentially describing classes approaches classified complexity class models general 
section approaches string representation solutions described 
summarized concluded section 
genetic algorithms problem decomposition building blocks simple genetic algorithms gas holland goldberg population search algorithms guide exploration search space application selection genetic operators recombination crossover mutation 
usually applied problems solutions represented mapped fixed length strings finite alphabet 
user defines problem ga attempt solve choosing length base alphabet strings representing solutions defining function discriminates string solutions quality 
function usually called fitness 
string fitness function returns real number quantifying quality respect solved problem 
higher fitness better solution 
gas start randomly generated population solutions 
current population solutions better solutions selected selection operator 
selected solutions processed applying recombination mutation operators 
recombination combines multiple usually solutions selected exchanging parts 
various strategies point uniform crossover 
mutation performs slight perturbation resulting solutions 
created solutions replace old ones process repeated termination criteria user met 
selection search biased high quality solutions 
new regions search space explored combining mutating repeatedly selected promising solutions 
mutation close neighborhood original solutions explored local hill climbing 
recombination brings innovation combining pieces multiple promising solutions 
gas problems decomposed subproblems bounded difficulty solving combining solutions global solution constructed 
average solutions sub problems called building blocks ga literature 
reproducing building blocks applying selection preserving disruption combination mixing powerful principle solve decomposable problems harik cant paz goldberg miller muhlenbein mahnig rodriguez 
fixed problem independent recombination operators break building blocks frequently mix effectively 
gas problems building blocks located tightly strings representing solutions thierens 
problems building blocks spread solutions simple gas experience poor performance thierens 
growing interest methods learn structure problem fly information ensure proper mixing growth building blocks 
approaches probabilistic modeling promising solutions guide exploration search space crossover mutation simple gas 
evolutionary algorithms probabilistic modeling algorithms probabilistic model promising solutions guide exploration search space called estimation distribution algorithms edas muhlenbein paa 
edas better solutions selected initially randomly generated population solutions simple ga true probability distribution selected set solutions estimated 
new solutions generated estimate 
new solutions added original population replacing old ones 
process repeated termination criteria met 
edas simple gas replace genetic recombination mutation operators steps model estimate true distribution selected promising solutions constructed 
new solutions generated constructed model 
edas process solutions different way simple gas theoretically empirically proven results similar 
instance simple ga uniform crossover randomly picks value position parents works asymptotically called univariate marginal distribution algorithm muhlenbein paa assumes variables independent muhlenbein harik pelikan muhlenbein 
distribution estimate capture building block structure problem accurately ensure effective mixing reproduction building blocks 
results linear subquadratic performance edas problems muhlenbein mahnig pelikan 
fact accurate distribution estimate captures structure solved problem edas simple gas perform ga theory assumptions claims 
estimation true distribution far trivial task 
trade accuracy efficiency estimate 
sections describe classes edas applied problems solutions represented fixed length strings finite alphabet 
algorithms classified complexity class models 
starting methods assume variables problem string positions independent ones take account pairwise interactions methods accurately model complex problem structure highly overlapping multivariate building blocks 
example model class models shown 
models displayed bayesian networks directed acyclic graphs nodes corresponding variables problem string positions edges corresponding probabilistic relationships covered model 
edge nodes bayesian network relates nodes value variable corresponding node edge depends value variable corresponding starting node 
interactions simplest way estimate distribution promising solutions assume variables problem independent look values variable regardless remaining solutions see 
model selected promising solutions generate new ones contains set frequencies values string positions selected set 
frequencies guide search generating new string solutions position position frequency values 
fashion building blocks order reproduced mixed efficiently 
algorithms principle linear problems variables mutually interacting muhlenbein harik 
population incremental learning pbil algorithm baluja solutions represented binary strings fixed length 
population solutions replaced called probability vector initially set assign value position probability 
generating number solutions best solutions selected probability vector shifted selected solutions hebbian learning rule hertz krogh palmer 
pbil referred hill climbing learning pelikan incremental univariate marginal distribution algorithm muhlenbein 
analysis pbil algorithm 

univariate marginal distribution algorithm umda muhlenbein paa population solutions processed 
iteration frequencies values position selected set promising solutions computed generate new solutions graphical model interactions covered 
replace old ones 
new solutions replace old ones process repeated termination criteria met 
theory umda muhlenbein 
compact genetic algorithm cga harik lobo goldberg replaces population single probability vector pbil 
pbil modifies probability vector direct correspondence population represented probability vector probability vector 
shifting vector components proportionally distance component vector updated shifting value contribution single individual total frequency assuming particular population size 
update rule theory simple genetic algorithms directly order estimate parameters behavior cga 
algorithms described section perform similarly 
linear problems achieve linear sub quadratic performance depending type problem fail problems strong interactions variables 
information described algorithm theoretical empirical results see cited papers 
algorithms take account interdependencies various bits variables fail problems strong interactions variables account algorithms mislead 
lot effort put extending methods simple model cover interactions methods solve general class problems efficiently simple pbil umda cga solve linear problems 
pairwise interactions algorithms assume variables problem independent cover pairwise interactions 
mutual information maximizing input clustering mimic algorithm de bonet isbell viola uses simple chain distribution see maximizes called mutual information neighboring variables string positions 
fashion kullback liebler divergence kullback leibler chain complete joint distribution minimized 
construct chain equivalent ordering variables mimic uses greedy search algorithm due efficiency global optimality distribution guaranteed 
baluja davies dependency trees see model promising solutions 
major advantages trees chains 
trees general chains chain tree 
relaxing constraints model order find best model measure decomposable terms order polynomial maximal branching algorithm edmonds guarantees global optimality solution 
hand mimic uses greedy search order learn chain distributions np complete algorithm needed 
similarly pbil population replaced probability vector contains pairwise probabilities 
bivariate marginal distribution algorithm pelikan muhlenbein forest set mutually independent dependency trees see 
class models general class dependency trees single tree fact set tree 
measure determine variables connected pearson chi square test 
measure discriminate remaining dependencies order construct final model 
mimic baluja davies graphical models pairwise interactions covered 
pairwise models allow covering interactions problem easy learn 
algorithms section reproduce mix building blocks order efficiently linear quadratic problems de bonet baluja davies muhlenbein pelikan muhlenbein thierens 
approaches solve spin glass problems efficiently pelikan muhlenbein 
multivariate interactions covering pairwise interactions shown insufficient solve problems multivariate highly overlapping building blocks pelikan muhlenbein thierens 
research area continued complex models 
hand general models brought powerful algorithms capable solving decomposable problems quickly accurately reliably 
hand general models resulted necessity complex learning algorithms require significant computational time guarantee global optimality resulting models 
spite increased computational time spent learning models number evaluations optimized function reduced significantly 
fashion time complexity reduced 
problems algorithms simply 
learning structure problem algorithms information expert simply incapable biasing search order solve complex decomposable problems reasonable computational cost 
algorithms section models cover multivariate interactions 
extended compact genetic algorithm ecga harik variables divided number intact clusters manipulated independent variables umda see 
cluster building block taken different clusters considered mutually independent 
discriminate models ecga uses minimum description length mdl metric mitchell prefers models allow higher compression data selected set promising solutions 
advantage mdl metric penalizes complex models needed resulting models overly complex 
find model simple greedy algorithm 
starting variables separated iteration current groups variables merged metric increases 
improvement possible current model 
theory umda problems separable decomposable non overlapping subproblems bounded order ecga model perform sub quadratic time 
question ecga finds model effort takes 
problems contain highly overlapping building blocks spin glass systems accurately modeled simply dividing variables distinct classes 
results poor performance ecga problems 
factorized distribution algorithm fda muhlenbein mahnig rodriguez uses factorized distribution fixed model computation 
fda capable learning structure problem fly 
distribution factorization expert 
distributions allowed contain marginal conditional probabilities updated currently selected set solutions 
theoretically proven model correct fda solves decomposable problems quickly reliably accurately muhlenbein mahnig rodriguez 
fda requires prior information problem form decomposition factorization 
unfortunately usually available solving real world problems fda limited problems accurately approximate structure problem 
bayesian optimization algorithm boa pelikan goldberg cant paz uses general class distributions ecga 
incorporates methods learning bayesian networks see uses model promising solutions generate new ones 
boa selecting promising solutions bayesian network models constructed 
constructed network generate new solutions 
measure quality networks metric bayesian dirichlet bd metric heckerman geiger chickering mdl metric published experiments bd scoring metric 
bd metric prefer simpler models complex ones 
uses accuracy encoded distribution criterion 
space possible models reduced specifying maximal order interactions problem taken account 
construct network respect metric algorithm searches domain possible bayesian networks 
experiments greedy algorithm due efficiency 
boa uses equivalent class models fda require information problem input 
able discover information 
prior information incorporated ratio prior information information contained set high quality solutions far controlled user 
boa fill gap fda uninformed search methods offers method efficient prior information pelikan schwarz pelikan prohibit improvement 
algorithm uses bayesian networks model promising solutions called estimation bayesian network ecga boa graphical models multivariate interactions covered 
algorithm proposed larra 
algorithms models capable covering multivariate interactions achieve performance wide range decomposable problems spin glass systems pelikan muhlenbein mahnig graph partitioning schwarz communication network optimization problems decomposable terms bounded order difficult solve 
overlapping subproblems mislead algorithm right solution particular subproblem sequentially distributed solutions see muhlenbein mahnig 
generating initial population problem specific information building blocks size proportional size problem results exponential performance algorithms 
brings question problems aim solve algorithms reproduction mixing building blocks shortly discussed earlier section 
attempt solve problems decomposed terms bounded order 
problems approach solve decomposable sense solved approaching problem level solutions lower order combining best construct optimal close optimal solution 
bias search total space explored algorithm substantially reduces couple orders magnitude computationally hard problems solved quickly accurately reliably 
string representation solutions algorithms described problems defined fixed length strings finite alphabet 
attempts go simple representation directly tackle problems solutions represented vectors real number computer programs mapping solutions strings 
approaches simple models cover interactions problem 
stochastic hill climbing learning vectors normal distributions solutions represented real valued vectors 
population solutions replaced modeled vector mean values gaussian normal distribution optimized variable see 
standard deviation oe stored globally variables 
generating number new solutions mean values shifted best generated solutions standard deviation oe reduced variable variable variable variable variable variable variable variable variable probabilistic models real vectors independent variables 
exploration search space narrower 
various ways modifying oe parameter exploited sebag 
implementation real coded pbil stern variable interval number stored see 
stands probability solution right half interval 
initialized 
time new solutions generated corresponding intervals best solutions selected numbers shifted 
variable gets close interval reduced corresponding half 
mapped corresponding interval 
probabilistic incremental program evolution pipe algorithm schmidhuber computer programs mathematical functions evolved genetic programming koza 
pair wise crossover mutation replaced probabilistic modeling promising programs 
programs represented trees internal node represents function instruction leaves represent input variable constant 
pipe algorithm probabilistic representation program trees 
probabilities instruction node maximal possible tree model promising generate new programs see 
unused portions tree simply cut evaluation program fitness function 
initially model set trees generated random 
current population programs ones perform best selected 
update probabilistic model 
process repeated termination criteria met 
summary probabilistic modeling genetic evolutionary computation popular 
combining various achievements machine learning genetic evolutionary computation efficient algorithms solving broad class problems constructed 
algorithms continuously proving efficiency offer promising approach solving problems resolved combining high quality pieces information bounded order 
reviewed algorithms probabilistic models promising cos cos cos cos cos cos cos sin cos graphical model program interactions covered pipe 
solutions far guide exploration search space 
algorithms classified classes complexity class models 
basic properties classes algorithms shortly discussed thorough list published papers 
acknowledgments authors cant paz martin butz dimitri jiri valuable discussions useful comments helped shape 
sponsored air force office scientific research air force materiel command usaf number 
research funding project provided army research laboratory federated laboratory program cooperative agreement daal 
government authorized reproduce distribute reprints governmental purposes notwithstanding copyright notation thereon 
views contained authors interpreted necessarily representing official policies endorsements expressed implied air force scientific research government 
baluja 

population incremental learning method integrating genetic search function optimization competitive learning tech 
rep 
cmu cs 
pittsburgh pa carnegie mellon university 
baluja davies 

optimal dependency trees combinatorial optimization learning structure search space 
proceedings th international conference machine learning pp 

morgan kaufmann 
thierens 

linkage information processing distribution estimation algorithms 
banzhaf daida eiben garzon honavar smith 
eds proceedings genetic evolutionary computation conference gecco volume pp 

orlando fl morgan kaufmann publishers san fransisco ca 
de bonet isbell viola 

mimic finding optima estimating probability densities 
mozer jordan petsche 
eds advances neural information processing systems volume pp 

mit press cambridge 
edmonds 

optimum branching 
res 
nbs 
larra 
march 
global optimization bayesian networks 
second symposium artificial intelligence pp 

cuba 
goldberg 

genetic algorithms search optimization machine learning 
reading ma addison wesley 
harik 

linkage learning probabilistic modeling ecga illigal report 
urbana il university illinois urbana champaign illinois genetic algorithms laboratory 
harik cant paz goldberg miller 

gambler ruin problem genetic algorithms sizing populations 
proceedings international conference evolutionary computation icec pp 

piscataway nj ieee press 
harik lobo goldberg 

compact genetic algorithm 
proceedings international conference evolutionary computation icec pp 

piscataway nj ieee service center 
heckerman geiger chickering 

learning bayesian networks combination knowledge statistical data technical report msr tr 
redmond wa microsoft research 
hertz krogh palmer 

theory neural computation 
reading ma addison wesley 
holland 

adaptation natural artificial systems 
ann arbor mi university michigan press 
koza 

genetic programming programming computers means natural selection 
cambridge ma mit press 
kullback leibler 

information sufficiency 
annals math 
stats 
pelikan 

hill climbing learning abstraction genetic algorithm 
neural network world 


nonparametric distribution free methods social sciences 
ca brooks cole publishing 
mitchell 

machine learning 
mcgraw hill 
muhlenbein 

equation response selection prediction 
evolutionary computation 
muhlenbein mahnig 

convergence theory applications factorized distribution algorithm 
published 
muhlenbein mahnig rodriguez 

schemata distributions graphical models evolutionary optimization 
submitted publication 
muhlenbein paa 

recombination genes estimation distributions binary parameters 
pp 

pelikan goldberg cant paz 

linkage problem distribution estimation bayesian networks illigal report 
urbana il university illinois urbana champaign illinois genetic algorithms laboratory 
pelikan goldberg cant paz 

boa bayesian optimization algorithm 
banzhaf daida eiben garzon honavar smith 
eds proceedings genetic evolutionary computation conference gecco volume pp 

orlando fl morgan kaufmann publishers san fransisco ca 
pelikan muhlenbein 

bivariate marginal distribution algorithm 
roy 
eds advances soft computing engineering design manufacturing pp 

london springer verlag 


communication network optimization 
personal communication 


stochastic hill climbing learning vectors normal distributions 
nagoya japan 
schmidhuber 

probabilistic incremental program evolution stochastic search program space 
van someren widmer 
eds machine learning ecml volume lecture notes artificial intelligence pp 

springer verlag 
schwarz 
june 
experimental study hypergraph partitioning simple advanced algorithms boa 
brno czech republic 
printing 
sebag 

extending population incremental learning continuous search spaces 
parallel problem solving nature ppsn pp 

berlin springer verlag 
stern 

telephone network traffic overloading diagnosis evolutionary computation techniques 
proceedings third european conference artificial evolution ae pp 

thierens 

analysis design genetic algorithms 
doctoral dissertation leuven belgium 

