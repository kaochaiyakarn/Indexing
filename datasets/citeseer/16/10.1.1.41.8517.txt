learning rules classify mail william cohen laboratories mountain avenue murray hill nj research att com methods learning text classifiers compared classification problems arise filtering filing personal mail messages traditional ir method tf idf weighting new method learning sets keyword spotting rules ripper rule learning algorithm 
demonstrated methods obtain significant generalizations small number examples methods comparable generalization performance problems type methods reasonably efficient fairly large training sets 
greater comprehensibility rules may advantageous system allows users extend modify learned classifier 
discussed technical phenomenon years rapid growth internet generally rapid growth number line documents 
led increased interest intelligent methods filtering categorizing documents 
example great deal interest systems allow technically naive user easily construct personalized system filtering classifying documents mail netnews articles web pages 
compare methods learning text classifiers focusing kinds classification problems arise filtering filing personal mail messages 
particular focus learning plausible message categories relatively small sets labeled messages 
goal performing study determine traditional ir learning methods compare systems learn concise easily interpreted classifiers specifically compare traditional ir methods systems learn sets keyword spotting rules 
keyword spotting rule primitive conditions test see word appears appear certain field mail message 
example set keyword spotting rules 
cfp cfp subject subject 
cfp cfp subject subject 
cfp call body papers body 
rule set states mail message classified instance class cfp call papers contains tokens cfp subject field tokens cfp subject field contains tokens call papers body message 
motivation learning keyword spotting rules belief rules relatively easy users understand modify second suspicion learning methods adequate solution categorization problems type 
mix automatically manually constructed classifiers necessary account fact user interests distribution messages change quite rapidly time 
instance time writing ruleset may accurate messages received months point certainly appropriate modify replacing 
keyword spotting rulesets advantage comprehensibility knowledge extensively evaluated text categorization problems 
noted rulesets quite different classifiers constructed common text categorization learning methods naive bayes term frequency inverse document frequency weighting tf idf salton 
making decisions weighted combination words document rules decisions small number keywords 
keyword spotting rules base classification decisions word frequency presence absence word 
goal evaluation determine learning algorithm considered assume keywords cfp drawn small set 
token appearing training example possible keyword 
accuracy lost keyword spotting rules relative classifiers 
second goal determine cpu time needed learn accurate rulesets moderate sized sets examples particular reasonable rule learning component interactive message filtering system 
final goal gain understanding number examples necessary learn accurate classifiers 
learning algorithms text categorization algorithms compared 
uses tf idf weighting salton 
implementation follows ittner 
adapt rocchio relevance feedback algorithm rocchio classification 
briefly document represented vector components correspond words appear training corpus 
document value component word depends frequency inverse frequency corpus length learning done adding vectors corresponding positive examples class subtracting vectors corresponding negative examples yielding prototypical vector class document vectors ranked distance prototype 
novel document classified positive distance threshold chosen balance recall precision set manner 
experiments chosen minimize error training set 
second algorithm extension rule learning algorithm ripper described detail cohen 
briefly ripper builds ruleset repeatedly adding rules empty ruleset positive examples covered 
rules formed greedily adding conditions antecedent rule starting empty antecedent negative examples covered 
ruleset constructed optimization postpass ruleset reduce size improve fit training data 
combination cross validation minimum description length techniques prevent overfitting 
previous experiments ripper shown comparable rules quinlan terms generalization accuracy faster large noisy datasets 
running experiments ripper modified efficient text categorization problems 
initial implementation ripper examples represented feature vectors 
implementation learn rules necessary construct boolean feature possible condition form field represent document vector boolean features 
inefficient moderately large corpus contain hundreds words 
common way avoiding problem restrict vocabulary example considering frequent words highly informative words 
chose extend ripper allow value attribute set symbols single symbolic value number 
means structured document easily naturally represented 
example mail message represented attributes subject body 
value attribute set words appear corresponding section mail message 
primitive tests set valued attribute tests allowed rules form field 
constructing rule ripper finds test maximizes information gain set examples efficiently making pass attribute 
words appear elements attribute training example considered ripper 
set valued attributes allows represent set documents easily naturally 
arguably elegant potentially robust say entropy feature selection lewis ringuette apt derive small features 
representation simplifies preprocessing examples worthwhile aim eventual goal integration learner interactive system 
set valued attributes discussed detail cohen 
second extension ripper motivated text categorization problems allows user specify loss ratio lewis catlett 
loss ratio indicates ratio cost false negative cost false positive goal learning minimize misclassification cost unseen data 
loss ratios ripper implemented changing weights false positive errors false negative errors pruning optimization stages learning algorithm 
recall tf idf learning algorithm trade recall precision making appropriate choice similarity threshold appropriate loss ratio ripper trade 
experimental comparisons discussed focus classifier error stated loss ratio 
experiments described messages parsed header body 
words subject fields extracted header words extracted body 
word maximal length sequence alphanumeric characters normalized converting uppercase lower case characters 
ripper examples represented set valued attributes 
tf idf examples represented set tokens form word field appeared instance word call appearing recall foil rel foil prop ripper prob 
ap problems uncertainty samples subject field encoded subject call 
header fields subject discarded 
random sample contained positive examples concept learned discarded 
decision limit size example words message body driven efficiency considerations absent restriction occasional long message postscript source journal learning expensive 
words body document sort feature selection usually sentences mail message indicate message general content 
experiments preliminary experiments text text version ripper tested number categorization problems 
gives flavor comparisons 
graph summarizes ripper performance measured recall precision corpus ap newswire headlines lewis gale 
statistics averaged categories equally weighted 
various points precision recall curve generated varying ripper loss ratio 
training done example samples selected procedure called uncertainty sampling lewis gale 
ripper average performance comparable superior systems previously applied problem quinlan probabilistic bayesian classifier lewis gale foil quinlan 
obtained similarly encouraging results reuters corpus lewis set news story classification problems cohen 
encodings foil propositional encoding supports rules similar rules constructed ripper relational encoding supports rules containing types phrases 
details see cohen 
problems particularly representative categorization problems arise processing mail 
obvious difference amount training data examples ap titles instance selected total set far expected available construction personalized mail filter 
subtler issues 
ap titles instance documents generally shorter typical mail message little words length average 
ap titles reuters documents documents classified written professionals goal making subject immediately apparent newspaper reader 
topics generally relatively broad semantic categories ratings wheat atypical categories interest processing mail 
noted reuters data considerable variation topics relative performance different classifiers wiener important evaluate learning methods problems representative problems encountered practise 
researchers lang armstrong noted learning methods tfidf perform quite relative complex learning learning methods experiments ripper ap titles dataset reuters tended confirm observation 
comparisons focus tf idf ripper 
recognizing talk announcements category talk announcements chosen representative test case 
corpus assembled messages posted center wide electronic bulletin year period 
messages manually labeled talk announcements 
partitioned corpus chronologically training set messages test set messages 
tf idf ripper compared different sized subsets training data 
results averaged trials summarized upper lefthand graph 
generally speaking ripper better tf idf particularly small numbers examples 
difference frequently statistically significant 
training subsample paired test performed comparing ripper tf idf hypotheses test data 
paired tests ripper hypothesis statistically significantly superior trials tf idf hypothesis statistically significantly superior 
remaining trials difference statistically significant 
message test set posted latest message training set 
training examples talk announcements ripper tf idf training examples sydney uni folders ripper tf idf training examples jair folders ripper tf idf training examples ml folders ripper tf idf error rates various problems mail folders looked number categories reflect file mail 
filing system mail messages currently completely manual somewhat haphazard am reluctant categories form messages filed folder foo exemplary useful natural classes 
filing subtasks reasonable categories experiment 
decided corpora categories 
sydney university folders corpus messages saved folders received september october visit basser department computer science sydney university 
folders explicitly correspond messages single sender highly correlated sender 
class generated folder messages filed folder positive examples messages filed folders negative examples 
results averaged trials class classes summarized upper right hand graph 
ripper performs slightly better tf idf average comparison nearly sided talk announcement problem probably accurate say problems performance ripper tf idf 
paired tests instance ripper statistically significantly better tf idf times statistically significantly worse times statistically indistinguishable remainder trials 
jair folders corpus messages saved folders pertaining duties editor journal ai research jair 
class generated folder 
contrast sydney university folders folders semantically defined 
contain correspondence connected single jair submission 
results averaged trials class classes summarized lower left hand graph 
algorithms roughly comparable 
average ripper gets slightly lower error rate training examples tf idf gets slightly lower error rate fewer training examples 
paired tests ripper statistically significantly superior times statistically significantly worse times indistinguishable remaining times 
ml folders corpus messages saved folders pertaining duties machine learning conference 
class generated folder contained messages total total classes 
folders mixed lot 
semantically defined budget associated particular person 
classes completely disjoint number messages filed multiple folders 
dataset appear noisy learning algorithms assume classes disjoint 
results averaged trials class classes summarized lower right hand graph 
problems systems comparable performance tf idf slight edge sample sizes 
paired tests ripper statistically significantly superior times statistically significantly worse times indistinguishable remaining times 
regardless statistical significance absolute differences algorithms small average hypotheses agree nearly test cases 
mail filters section consider type message category categories useful filtering prioritizing unread mail 
categories considered obtained follows 
colleagues implemented customizable mail reader called isbell 
mail reader allows user define ordered list mailboxes associated classification rule 
convention mailbox list called misc associated classification rule succeeds 
read incoming mail messages placed mailbox rule accepts message classifies message positive 
classification rules boolean combinations substring regular expression matches language includes keyword spotting rulesets considered current implementation explicitly programmed user 
allows number properties associated mailbox 
instance user request user problem positive negative name examples examples user software conferences talks user association task subject user subject personal association todo table summary mail filtering problems messages placed mailbox automatically archived set intervals weekly 
user ask alerted mailbox unread messages oldest unread message days old prioritize unread mail 
typical put common types electronic junk mail special mailboxes appropriate alerting archiving policies 
messages notably messages specific mailing lists detected reliably looking sender 
interviewed number users users employing system intriguing way 
users defined mailboxes corresponding particular message categories interest gave mailboxes vacuous classification rules highly approximate rules 
messages manually moved misc mailbox wound semantically appropriate mailbox 
reason doing usually take advantage automatic archiving features message categories difficult write accurate classification rules 
realized manually correcting missing erroneous classification rules automatically archiving results actions users providing training data learning system 
case messages manually placed mailbox positive examples associated classification rule messages placed mailboxes negative examples 
noted users computer scientists researcher area computational linguistics written classification rules hand 
categories relatively difficult explicitly program categories particularly interesting targets learning 
assembled eleven datasets sort different users 
characteristics problems summarized table 
interests privacy replaced actual user names mail box names generic terms 
datasets represent months worth mail users complete archiving strategies datasets large 
case simplified problem slightly default misc mailbox source negative examples 
eleven categories sets talk announcements providing nice confirmation typicality problem selected study 
shows average error rates problems 
followed methodology similar training learning algorithms different sized subsets total data measuring error rates remaining data sizes datasets different range percentages dataset range absolute sizes training set 
ripper performs better problems 
paired tests ripper statistically significantly superior times statistically significantly worse times indistinguishable remaining times 
additional easily interpreted point comparison measured error rates systems problems fold cross validation 
results summarized table statistically significant differences marked asterisk 
ripper error rate slightly higher eleven problems lower remaining 
problems ripper error rate dramatically lower half tf idf error rate ripper statistically significantly worse 
conclude general comments 
problems ripper somewhat better tf idf sufficiently large number training examples 
compared ripper tfidf perform best little training data particularly positive examples 
second performance learners small number training examples roughly performance default classifier performance improve quite rapidly 
talk announcement problem folder problems example noticeable significant reduction error training examples 
run time performance tf idf run time performance relatively wellunderstood efficient implementation requires small number passes corpus leading linear run time low constant 
ripper run time performance hand evaluated large noisy datasets efficiency extension set valued attributes previously investigated 
brief ripper reasonably efficient problems sort quite fast interactive system current hardware 
learning complete set talk announcement examples corpus containing distinct words total words ripper requires seconds sun 
seconds time spent reading dataset 
comparison tf idf takes seconds talk announcement problem time reading data 
ripper performance example samples ml folder concepts comparable ripper takes average seconds construct ruleset 
related previous related study rule learning system swap compared learned classifiers reuters dataset lewis corpus containing documents classified different categories apt 
documents reuters collection news stories averaging words length training sets large order labeled examples 
focus comparison text categorization problems representative arise handling mail correspondence 
noted substantial variation different reuters categories little reason suppose typical mail categorization problems 
technical difference studies text categorization rules learned apte contained primitive tests compare word frequency fixed threshold simply checking presence absence word 
representation presumably accurate comprehensible keyword spotting rules 
currently conducting studies reuters collection 
goal studies compare performance ripper swap 
motivated interest learning classifiers text easy users understand modify compared extension ripper rule learning method tf idf number text categorization problems 
benchmark problems problems plausibly arise filing filtering personal mail 
encouraging result study methods fairly steep learning curves significant amounts generalization obtained relatively small number examples 
graphs instance significant reduction error rate occurs examples learning takes place examples users days worth mail 
rapid learning rate somewhat surprising categories relatively data training average filtering problems ripper tf idf error rate averaged filtering problems user problem error ripper se tf idf se user software conferences talks user association task subject user subject personal association todo table performance mail filtering problems cv infrequent expect see handful positive examples training set size 
clearly needs done experiments shed light relative performance rule learning methods traditional ir methods 
priori expect rule induction methods concise description category poorly cases 
filtering mail course number arguably natural types categories simple rulesets 
example categories associated single unique sender instance messages particular mailing list 
example categories distinguished salient keywords talk announcements category instance sort category 
talk announcements include number salient keywords talk speaker 
experiments suggest induction keyword spotting rulesets competitive traditional ir learning methods relatively broad class text categorization problems 
particular rule methods competitive situations categories semantically defined 
suggests system combines learned keyword spotting rules may viable architecture personalized email filtering system 
apt fred damerau weiss 
automated learning decision rules text categorization 
acm transactions information systems 
armstrong joachims mitchell 
webwatcher learning apprentice world wide web 
proceedings aaai spring symposium information gathering heterogeneous distributed environments stanford ca 
aaai press 
william cohen 
fast effective rule induction 
machine learning proceedings twelfth international conference lake california 
morgan kaufmann 

cohen 
text categorization relational learning 
machine learning proceedings twelfth international conference lake california 
morgan kaufmann 

cohen 
learning set valued features 
submitted aaai 
william cohen 
experiments text categorization rules 
preparation 
jonathan isaac charles lee isbell 
immediate identification important information 
submitted chi 
david ittner david lewis david ahn 
text categorization low quality images 
symposium document analysis information retrieval pages las vegas nv 
univ nevada las vegas 
ken lang 
newsweeder learning filter netnews 
machine learning proceedings twelfth international conference lake california 
morgan kaufmann 
david lewis jason catlett 
heterogeneous uncertainty sampling supervised learning 
machine learning proceedings eleventh annual conference new brunswick new jersey 
morgan kaufmann 
david lewis william gale 
training text classifiers uncertainty sampling 
seventeenth annual international acm sigir conference research development information retrieval 
david lewis mark ringuette 
comparison learning algorithms text categorization 
symposium document analysis information retrieval las vegas nevada 
david lewis 
representation learning information retrieval 
technical report computer science dept university massachusetts amherst 
phd thesis 
ross quinlan 
learning logical definitions relations 
machine learning 
ross quinlan 
programs machine learning 
morgan kaufmann 
rocchio 
relevance feedback information retrieval 
gerard salton editor smart retrieval system experiments automatic document processing pages 
prentice hall englewood cliffs nj 
gerard salton 
developments automatic text retrieval 
science 
wiener pederson 
neural network approach topic spotting 
symposium document analysis information retrieval pages las vegas nevada 
