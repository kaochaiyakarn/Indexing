learning hierarchical performance knowledge observation michael van lent john laird artificial intelligence lab university michigan beal ave ann arbor mi developing automated agents intelligently perform complex real world tasks time consuming expensive 
expensive part developing intelligent task performance agents involves extracting knowledge human experts encoding form useable automated agents 
machine learning sufficiently rich focused knowledge source significantly reduce cost developing intelligent performance agents automating knowledge acquisition encoding process 
potential knowledge sources include instructions human experts experiments performed task environment observation expert performing task 
observation particularly suited learning hierarchical performance knowledge tasks require realistic human behavior 
learning observation system called knomic knowledge mimic extracts knowledge observations expert performing task generalizes knowledge rules agent perform task 
learning performance knowledge observation efficient hand coding knowledge number ways 
knowledge encoded directly expert need knowledge engineer act intermediary 
expert needs demonstrate task organize communicate relevant information 
describe knowledge required task performance describe knowledge learned knomic report efforts learn performance knowledge tactical air combat domain computer game quake ii 
keywords supervised learning observation induction performance tasks email address contact author umich edu phone number contact author electronic version postscript frequently time consuming costly part developing intelligent agents acquisition hand coding task performance knowledge appropriate knowledge format production rules 
knowledge acquisition approach involves lengthy interviews human experts thousands hours debugging performance knowledge frequent demonstrations allow experts verify final agent behavior 
experts required organize communicate knowledge programmers programmers required learn details task effectively experts 
approach improving efficiency knowledge acquisition develop tools expert encode knowledge 
reduces need knowledge engineer act intermediary expert encoded performance knowledge 
expert required organize describe necessary knowledge additionally learn knowledge acquisition tool 
second approach develop unsupervised learning system learns perform task relying expert experimentation 
unfortunately learning perform task solely unsupervised experiments task environment generally costly original knowledge acquisition 
furthermore resulting performance agents successful may perform tasks humans limits usefulness training tasks 
third approach develop supervised learning system uses expert provide focused source knowledge instruction observation 
supervised learning differs knowledge acquisition tool approach described expert interacts system knowledge level implementation level 
supervised learning doesn require expert learn new tool programming language doesn require programmer expert task 
furthermore resulting performance knowledge expert knowledge allows different experts generate different styles performance 
chosen form expert input minimize need expert organize communicate knowledge 
supervised learning system takes observations expert performing task generates generalized task performance knowledge directly observations fulfills requirements discussed 
learning observation requires experts perform task expert 
addition programmer isn involved encoding knowledge doesn need taught task knowledge 
agent performance encoded knowledge closely correspond expert behavior multiple experts available learning observation capture variations knowledge provide multiple styles performance 
knomic knowledge mimic system learns knowledge necessary intelligent agent perform task observations expert performing task expert annotations indicating goals achieved 
design tasks analysis tasks performance tasks represents class problems machine learning 
performance task intelligent agent performs actions constantly changing environment achieve maintain collection goals 
agent constantly receives sensor inputs updating state environment uses performance knowledge select current goals actions achieve goals 
research performance knowledge represented production rules implement operators generate maintain internal state features test goal achievement 
observations knomic consist sequence time steps sensor inputs environment actions taken expert annotations indicating goal achievement recorded time step 
system learn online observations generated observations stored learn line 
sensor inputs actions described description language domain 
programmer develops domain description language attempt mimic concepts expert closely possible 
knomic designed complex domains real time behavior requirements external actions non determinism complications 
time steps potentially short lots activity time steps activity 
section supervised learning systems observation primary knowledge source described behavioral cloning observer system 
section describes format performance knowledge generated 
knomic system described fourth section combines strengths systems described section overcoming weaknesses 
fifth section provides examples evaluation knowledge generated knomic 
related research knomic system described preceded significant research efforts area learning observation 
behavioral cloning uses pure induction observation traces build decision trees decide actions take sensor input 
behavioral cloning successfully applied complex real world domain representation performance knowledge learned behavioral cloning limited 
observer system uses version spaces type approach learn strips style operators 
observer learns aspects performance knowledge including knowledge effects operators required planning 
observer assumptions domain limits effectiveness complex dynamic domains 
knomic viewed attempt combine powerful knowledge representation observer techniques behavioral cloning learn complex domain 
behavioral cloning sammut hurst michie behavioral cloning learn knowledge necessary fly specific flight plan silicon graphics flight simulator 
human expert behavior cloned flies strictly defined flight plan times 
recording sensor inputs value control approximately times second creates observation log flight 
observation logs form large set training examples sensor inputs attributes controls class values 
behavioral cloning uses set training examples induce decision trees classify appropriate control values actions current sensor inputs 
decision trees mimic expert behavior fly plane setting control value specified applying current sensor inputs decision tree 
learn single decision tree control flight plan divided stages separate decision tree learned stage 
stage different goal takeoff fly altitude feet expert responses sensor inputs differ goal current stage separate decision tree needed stage 
splitting observation logs stages adds goal directed aspect behavioral cloning 
similarly single set decision trees couldn learned observations multiple experts different experts react inputs different ways achieve goals 
behavioral cloning system able learn decision trees effectively control controls stages flight plan 
decision trees performance knowledge intelligent agent take follow defined flight plan land manner similar expert cloned 
impressive aspects behavioral cloning effectiveness complex domain 
flight simulator domain non deterministic includes large set complex sensors exhibits standard homeostatic goals observations contain noise nature domain requires rapid reactions input 
number small decision trees behavior cloning splits knowledge rapidly processed rules applied sufficiently quickly 
major weakness behavioral cloning limited usefulness decision trees form generalized performance knowledge 
decision trees learned effective single flight plan need flight plan aircraft dynamics change 
decision trees easily handle symbolic inputs flight plans impossible learn generally useful decision trees apply multiple flight paths 
weakness decision trees encode reactive knowledge useful execution 
planning task knowledge predictive allowing outcome potential plans evaluated 
decision trees contain information effects actions appropriate planning 
observer observer system learns strips style operators learning method similar version spaces 
wang developed observer applied process planning domain task generate plan produce machine parts meeting set specifications 
operator observer creates refines specific set operator preconditions op general set operator preconditions op set operator effects op 
observer initially learns op op learning observation phase 
second unsupervised learning phase improve op op learn op 
op op match operator preconditions assumed correct 
advantage observer system behavioral cloning performance knowledge learned observer uses limited form representation 
strips style operators learned observer include complexities negated preconditions conditional actions 
operators somewhat difficult learn represent aspects performance knowledge effectively deal symbolic inputs 
additionally operator effects learned part operator predict applying operator change current state 
effects provide predictive knowledge necessary evaluate outcome proposed plans 
observer system described context design task isn complex performance tasks demonstrated behavioral cloning 
weakness strips style operators represent large complex actions easily highly reactive fine grained actions needed flight simulation task 
design task contains noise non determinism observer generate knowledge single observation 
complex domains result incorrect specific operators 
observer doesn goal knowledge learning process 
goal knowledge useful learning operator effects goal provides set features operators trying achieve 
performance knowledge representation knomic system uses soar architecture execute learned performance knowledge 
accordingly knowledge representation learned knomic specialized form soar production rule format 
rules implement hierarchy operators higher level operators having multiple sub operators representing steps completion high level operator 
operator set pre conditions set goal conditions achieves 
operator selected pre conditions matched 
selected series conditional operator application rules perform actions achieve operator goal conditions 
goal conditions met operator specific goal achieved feature added system internal state 
operator goal feature appears state operator unselected allowing operator selected level hierarchy 
non persistent goal features removed state goal conditions longer matched 
persistent goal features remain state independent status goal conditions removed action operator 
operators classified maintain operators time operators repeatable operators depending persistence goal features 
operators goal features called maintain operators goal conditions untrue goal feature removed operator goal conditions maintaining goal conditions 
flying specific waypoint maintain operator set plane heading point waypoint direction 
plane flying waypoint operator goal achieved operator unselected 
plane heading deviates direction goal achieved feature retracted operator re achieve goal 
operator maintains heading pointing waypoint 
time operators persistent goal features removed 
operators achieve goal goal achieved feature remains state indefinitely operator 
initialization operators fire task examples time operators 
repeatable operators persistent goal features time operators persistent features removed operator repeated 
examples repeatable operators context air combat domain 
types rules implement operators 
operator selection rules test state features internal external select operator executed 
operator application rules generate actions current operator state feature tests performed external environment 
goal feature generation rules create internal goal features representing operator goal achieved 
knomic learns types production rules 
strips operators knomic operators contain operator preconditions operator effects 
operator selection rules define operator pre conditions 
common classes pre conditions include relevance conditions goal achieved features previous current operators 
relevance conditions traditional state feature tests assure operator selected actions relevant 
operator goal features test goal achieved feature operators 
conditions assure operators series operators aren selected earlier operators finished 
current operator goal feature condition negated test current operator goal achieved feature 
operator achieved goal goal feature generated conditions operator longer match due negated goal feature test operator automatically unselected 
strips knomic operators may applied series time steps making possible higher level operator remain place sub operators selected 
operator remains selected long conditions selection rule matched 
operator selection rules generated ensured mutually exclusive avoid operator conflicts 
operator application rules test internal external state features issues single action value command environment 
example action value pair heading cause plane controlled turn heading degrees due north 
application rule tests name current operator associates rule operator selected application rule fire 
multiple operators issue action command separate application rule required operator 
similar behavioral cloning multiple decision trees allows different operators select values actions differently specific goal 
cases action value taken features tested rule conditions 
type application rule said pass value sensor input action command 
goal feature generation rules test current operator goal conditions create persistent non persistent goal features 
non persistent rules add goal achieved feature state goal conditions satisfied remove feature inputs change goal conditions longer satisfied 
persistent rules add goal achieved feature state remains place goal conditions longer matched 
persistent goal features removed action operator 
goal achieved features frequently represent relationships sensor inputs important domain 
example takeoff operator goal conditions test plane current altitude equal flight plan cruising altitude 
goal achieved feature operator tested rules relearning relationship altitude cruising altitude time 
goal features represent concepts familiar expert making learned rules easier understand 
knomic combines form knowledge representation similar observer reactive ability learn effectively complex performance tasks behavioral cloning 
specialized form soar operators knomic uses somewhat similar strips style operators observer 
operators combine performance knowledge necessary intelligent agent perform task complex dynamic environment predictive knowledge plan new approaches task performance 
major advantage soar operators potential knomic conjunction learning systems generate soar operators including soar learns expert instruction improv learns unsupervised experimentation 
knomic knomic system techniques behavioral cloning learn effectively complex flight simulator environment 
operators expressed separate selection application rules matching expert annotations goal conditions condition learning classify goals efficiently calculated quick reactivity 
knomic learns multiple observations allowing incorrect rules corrected replaced necessary 
additionally knomic extensive goal knowledge focus learning process 
behavioral cloning fixed goals knomic learns goals subgoals dynamically annotations provided expert part observation log 
knomic system consists components observe interactions expert environment simulator communicate generate performance knowledge see 
soar architecture acts brains intelligent agent learned knowledge perform task 
condition learning component compares expert system behavior current performance knowledge generalizes operator goal conditions situations performance knowledge doesn match expert behavior 
goal classification component uses learned goal conditions expert behavior classify goal feature persistent non persistent build necessary goal removal operators 
conditions goal classifications passed knowledge generation component simply formats conditions soar production rules 
intelligent agent soar architecture perform task new performance knowledge 
section knomic described context flight simulation domain similar domains behavioral cloning tacair soar rule hand coded intelligent agent air combat training exercises 
expert environment loop sensor inputs actions behavior trace expert interaction environment performing task viewed communication loop 
environment sends information expert form environment sensor inputs actions relevance conditions goal conditions goal removal soar knowledge generation knomic system including expert environment loop condition learning goal classification knowledge generation components soar architecture 
instruments altitude dial air speed indication displayed computer screen view cockpit window sounds radio 
expert reacts information sending actions environment form changes aircraft controls flight stick throttle mouse movements represent aircraft controls simulation 
environment reacts actions modifying information sent expert reflect changes actions current situation plane environment 
knomic information passed expert environment translated symbolic form 
expert perceives needle pointing airspeed indicator knomic perceives vehicle speed sensor feature value 
relevant sensor displayed expert knomic receives corresponding sensor input feature 
similarly action expert take knomic provided symbolic action value command air speed 
creating symbolic sensor inputs actions requires programmer programmer needs limited amount task knowledge create interface 
expert performs task recording changes sensor inputs action commands issued expert creates trace expert behavior 
rapidly changing environment flight simulator inputs actions need recorded multiple times second 
mentioned previously expert annotates observation log comments describing operators sub operators currently active operator hierarchy 
example expert report top level operator execute mission sub operator execute mission fly racetrack pattern fly racetrack pattern fly waypoint 
generally annotating observation trace done task performed easier expert developed operator hierarchy ahead time 
expert needs provide annotations markers denoting selection operators 
knomic needs information operators hierarchy selected 
condition learning operator condition learning component select sensor input value tests true operator appropriate current situation applicable current goals 
successfully perform realistic complex tasks operators able test absence input value pairs negated tests inputs ranges values pairs inputs equal values 
condition learning component find correct selection goal conditions operator excluding irrelevant conditions 
simple specific general learning algorithm learn selection goal conditions initially creates specific set conditions generalizes removing irrelevant conditions observation traces 
expert annotations allow knomic compare conditions expert selects operator performance knowledge operator proposal conditions 
performance knowledge doesn conditions operator initial set maximally specific conditions current sensor input values assigned operator 
expert selects operator situation performance knowledge operator proposal conditions aren matched proposal conditions generalized match current situation 
performance knowledge selects operator expert didn select operator proposal conditions 
cases cause overgeneralization operator disjunctive proposal conditions 
knomic currently learn disjunctive operator proposal conditions plan correcting overgeneralization splitting proposal conditions sets disjunctive conditions implemented 
sensor inputs represent static domain constants flight plan parameters cruising altitude feet 
knomic detect relationships dynamic sensor inputs static sensor inputs called parameters units create operator proposal conditions representing relationship values 
proposal conditions fly destination operator plane altitude feet parameter input cruising altitude value feet knomic specify altitude cruising altitude selection condition fly destination remove altitude condition 
relearning performance knowledge change flight plan cruising altitude simply changing cruising altitude parameter allow existing performance knowledge fly new altitude 
operator goal conditions represent input value conditions operator actions sub operators achieve operator selected 
goal conditions learned similar fashion operator proposal conditions 
time expert annotations indicate operator unselected knomic collects sensor inputs changed initializes operator goal conditions changes 
subsequent observations operator unselected goal conditions generalized include sensor input changes immediately proceed operator unselected 
plane altitude reaches feet immediately takeoff operator unselected observation goal conditions takeoff altitude feet 
cruising altitude parameter mentioned condition test current altitude equals cruising altitude 
goal conditions test parameters just greater sensor inputs 
observation coincidence wind speed sensor changes knots just takeoff unselected 
case wind speed goal condition takeoff observation 
wind speed change just right time twice extra condition removed goal takeoff generalized second observation expert 
sensor inputs change rapidly changed operator unselected 
knomic detects frequently changing inputs doesn include goal conditions part condition tests sensor relationship parameter 
goal classification goal classification component needs learn conditions operator goal feature removed internal memory 
simple cases goal features removed removed soon goal conditions longer true 
complex cases new operator new selection conditions needs learned remove goal feature 
goal features classified examining expert reacts operator goal conditions true change true false 
expert immediately operator time operator goal conditions longer true expert applying operator maintain truth goal conditions 
case operator classified maintain operator goal feature marked non persistent 
expert achieved operator goal sensor inputs change goal conditions untrue operator isn operator needs executed time operator certain conditions repeatable operator 
case goal feature operator marked non persistent 
operator time operator classified repeatable situations operator learn proposal conditions goal feature removal operator 
soar architecture soar architecture uses sensor inputs performance knowledge generate actions perform task 
simple level soar architecture compares performance knowledge rules current symbolic sensor inputs 
top level hierarchy operator matching selection conditions selected 
operator selected application rules sub operators selected applied goal conditions achieved 
goal achieved goal feature generated operator unselected new operator selected applied 
full description soar architecture necessary understand performance knowledge learned knomic 
performance knowledge correctly learned intelligent agent soar replace human expert perform task style human 
experimental results knomic system described fully implemented connected modsaf simulator tacair soar project computer game quake ii 
modsaf simulator values converted fly outbound leg fly inbound leg correct symbolic sensor inputs including plane position velocity radar information mission parameters waypoints waypoint computer 
output actions available including flight controls radar controls weapon controls various miscellaneous controls 
interface quake ii somewhat complex implementing symbolic sensor inputs output actions 
sensor inputs output actions knomic originally developed part tacair soar project incorporated unchanged 
human interface panel implemented connected system knomic learn task knowledge observations human expert controlling plane modsaf 
knomic learn observing hand coded intelligent agents control plane play quake ii 
results section experiments knomic learning hand coded tacair soar agents 
particularly interesting rules learned knomic compared hand coded rules 
performance knowledge successfully learned quake ii experiments 
human experts precise performance task cause variations observations 
cases additional noise may help system generalize irrelevant conditions general learning observations human experts difficult 
variations human behavior delays receiving input actions performance errors introduce large amount noise observation traces 
early experiments racetrack portion air combat task shown knomic learn correct functional rules observations humans 
air combat task incorrect waypoint agent flies outbound leg waypoint turns fly inbound leg searching inbound enemies waypoint range meters 
knowledge learned experiments modsaf simulator attempts perform air combat task observations micro tacair soar agent 
micro tacair soar agent reduced version full tacair soar agent conditions conditions learned observation results knomic learning series observations tacair soar agent performing racetrack task 
fourth data set represents handcoded research teaching situations 
perform air combat task tacair soar takes flies specified waypoint 
waypoint reached plane flies patrol pattern called racetrack enemy plane detected radar 
enemy plane detected agent engages enemy plane selects fires missiles threat eliminated returns flying racetrack pattern 
hand coded micro tacair soar agent uses approximately production rules perform air combat task 
racetrack pattern involves flying specific heading racetrack heading parameter specific distance racetrack distance parameter away specified waypoint reached flying back waypoint 
racetrack waypoint heading distance specified mission parameters static sensor inputs 
operator annotations hand coded operator hierarchy divide task top level operators init agent create agent wait start vehicle execute mission 
execute mission operator sub operators racetrack intercept 
racetrack operator sub operators fly racetrack fly inbound leg fly outbound leg intercept operators level hierarchy 
aspect racetrack pattern demonstrates persistent features necessary 
consider case knomic agent flying waypoint change heading racetrack direction parameter plane close waypoint see 
happen situation leg operator achieves goal waypoint range waypoint achieved range parameter generates goal feature terminates 
fly outbound leg goal feature pre condition fly inbound leg fly inbound leg selected observation observation observation hand coded racetrack proposal intercept proposal racetrack goal intercept goal application rule fires immediately turn plane racetrack direction parameter 
fly outbound leg goal feature non persistent waypoint range greater achieved parameter goal feature removed leg unselected pre conditions longer satisfied 
agent effectively forgets flying inbound leg completes turn fly racetrack direction 
goal feature persistent removed waypoint range greater achieved parameter turn completed correctly 
note fly outbound leg persistent goal feature removed goal feature removal operator fly outbound leg 
performance knowledge learned racetrack displays results knomic learning observations racetrack portion air combat task 
generally observations knomic generated correct rules flying racetrack pattern quarters intercept part task correct 
knomic learning algorithm specific rules learned initially specific conditions subsequent observations rules generalized removing irrelevant conditions 
observation conditions learned rules implement operators required air combat task 
altogether rules operator selection conditions goal conditions 
second observation selection conditions goal conditions removed generalization 
starting conditions third observation slightly different allowing greater generalization selection conditions goal conditions removed 
observations knowledge performing racetrack portion task functional knowledge intercept portion working 
performance knowledge functional 
contain number extraneous conditions hand coded productions 
productions unnecessary incorrect cause learned agent behave differently hand coded agent 
rules learned knomic bear striking similarity hand coded rules tacair soar system 
approximately percent rules learned knomic recognizable hand coded counterparts 
similarity performance knowledge knomic hand coded knowledge suggests programmers experts easily understand knowledge generated knomic needs examined 
efficiency learning observation vs hand coding performance knowledge learned racetrack portion intercept portion task correct functional knomic useful generates knowledge efficiently programmer 
test minutes compared time required knomic generate performance knowledge racetrack portion task time taken programmers 
modsaf simulator run times faster real time decreases time knomic spends observing doesn affecting knowledge generated 
shown run times real time knomic requires minutes start simulator minutes observation minutes generate task knowledge minutes demonstrate final behavior total time minutes 
run real time increases approximately minutes 
comparison fastest human programmer required minutes learn racetrack task minutes program performance knowledge 
slowest human programmed half required performance knowledge minutes 
experiment demonstrates knomic generate performance knowledge efficiently generated human programmers 
research task knowledge generation expert expert expert current focus research knomic system correct expand learning algorithm entire air combat task correctly learned 
number operators intercept portion task set internal timers unselected timers expire 
adding timer sensors actions observation trace allows knomic learn operators unclear knomic detect equivalent delays human expert 
knomic correctly learn conjunctive selection expert knowledge generation learn racetrack time knomic experts spent generating performance knowledge necessary racetrack task 
knomic learned observations run times conditions conjunctive goal conditions currently learned 
due bias changed inputs goal conditions knomic learns condition conjunction true 
possible solutions include relaxing bias including small amount domain knowledge suggests combinations inputs tested 
date knomic applied observational traces taken human experts opposed hand coded intelligent agents experts 
variations human behavior delays receiving input actions performance errors probably introduce large amount noise observation traces 
experiments performed promising knomic need noise tolerant learn human experts 
possibility integrate systems different supervised knowledge sources instruction unsupervised learning experimentation 
research supported contract defense advanced research projects agency arpa 
bain sammut 
framework behavioral cloning 
muggleton michie eds machine intelligence 
oxford university press 
fikes nilsson 

strips new approach application theorem proving problem solving 
artificial intelligence 
huffman autonomous agents 
phd thesis university michigan dept electrical engineering computer science 
laird newell rosenbloom 

soar architecture general intelligence 
artificial intelligence 
pearson learning procedural planning knowledge complex environments 
phd thesis university michigan dept electrical engineering computer science 
sammut hurst michie 

learning fly 
sleeman ed 
proceedings ninth international conference machine learning aberdeen morgan kaufmann 
tambe johnson jones laird rosenbloom 

intelligent agents interactive simulation environments 
ai magazine 
wang 

learning planning operators observation practice 
phd thesis carnegie mellon university computer science dept 
wang 

learning observation practice incremental approach planning operator acquisition 
proceedings th international conference machine learning 

