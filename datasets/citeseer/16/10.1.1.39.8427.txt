recognizing action units facial expression analysis ying li tian takeo kanade jeffrey cohn cmu ri tr robotics institute carnegie mellon university pittsburgh pa december copyright tian research sponsored nimh contract mh facial expression analysis computer image processing 
keywords facial expression analysis action units neural network automatic expression analysis systems attempt recognize small set expressions happiness anger 
expressions occur infrequently 
human emotions intentions communicated changes discrete facial features 
develop automatic system analyze subtle changes facial expressions permanent facial features brows eyes mouth transient facial features deepening facial furrows nearly frontal image sequence 
existing systems system attempts recognize fine grained changes facial expression facial action coding system facs action units aus basic expressions happiness anger 
multi state face facial component models proposed tracking modeling different facial features including lips eyes brows cheeks related wrinkles facial furrows 
convert results tracking detailed parametric descriptions facial features 
features inputs lower face action units aus upper face aus recognized neural network algorithm 
recognition rate lower face aus upper face aus obtained respectively 
recognition results indicate system identify action units regardless occurred singly combinations 

facial expression analysis attracted attention computer vision literature :10.1.1.40.359
automatic expression analysis systems attempt recognize small set expressions joy surprise anger sadness fear disgust 
everyday life expressions occur relatively infrequently 
emotion communicated changes discrete facial features tightening lips anger lowering lip corners sadness 
change isolated features especially area brows eyelids typical displays instance raising brows signals greeting 
capture subtlety human emotion communication automated recognition fine grained changes facial expression needed 
ekman friesen developed facial action coding system facs describing facial expressions 
facs human observer system designed describe subtle changes facial features 
facs consists action units including head eye positions 
aus anatomically related contraction specific facial muscles 
occur singly combinations 
au combinations may additive case combination change appearance constituents nonadditive case appearance constituents changes analogous articulation effects speech 
action units vary intensity point ordinal scale measure degree muscle contraction 
number atomic action units small combinations action units observed 
facs provides necessary detail describe facial expression 
automatic recognition action units difficult problem 
aus quantitative definitions noted appear complex combinations 
researchers tried recognize aus 
system lien dense flow feature point tracking edge extraction recognize upper face aus au combinations au au au au au au lower face aus au combinations au au au au au au au au au 
bartlett recognized individual upper face aus au au au au au au occurred combinations 
performance feature classifier novel faces new images faces training rate 
combining holistic spatial analysis optical flow local features hybrid system bartlett increased accuracy correct 
donato compared techniques recognizing action units including optical flow principal component analysis independent component analysis local feature analysis gabor wavelet representation 
best performances obtained gabor wavelet representation independent component analysis achieved average recognition rate upper face aus lower face aus 
report developed feature au recognition system 
system explicitly analyzes appearance changes localized facial features 
au associated specific set facial muscles believe accurate geometrical modeling facial features lead better recognition results 
furthermore knowledge exact facial feature positions benefit area holistic analysis optical flow classifiers 
depicts overview analysis system 
head orientation face position detected 
subtle changes facial components measured 
motivated facs action units changes represented collection mid level feature parameters 
action units classified feeding parameters neural network 
appearance facial features dependent head orientation develop multi state model system tracking facial features 
different head orientations corresponding variation appearance face components defined separate states 
state corresponding description feature extraction methods developed 
separately represent facial features parameter groups upper face lower face facial actions upper lower face relatively independent 
fifteen parameters describe eye shape motion state brow cheek motion upper face furrows upper face 
parameters describe lip shape lip motion lip state lower face furrows lower face 
facial features correctly extracted suitably represented employ neural network recognize upper face aus neutral au au au au au au lower face aus neutral au au au au au au au au au au respectively 
basic upper face aus eleven basic lower face aus identified regardless occurred singly combinations 
upper face au recognition compared bartlett results database system achieves recognition accuracy average recognition rate fewer parameters difficult case aus may occur individually additive nonadditive combinations 
lower face au recognition previous attempt similar task recognized lower face aus combinations au au au au au au average recognition rate separate hidden markov models action unit action unit combination 
compared previous results system achieves recognition accuracy average recognition rate 
difficult cases aus occur individually additive nonadditive combinations handled 

feature action unit recognition system 

multi state models face facial components 
multi state face model head orientation significant factor affects appearance face 
head orientation head states defined 
develop robust facial expression recognition system head state considered 
different head states facial components lips appear differently requiring specific facial component models 
example facial component models front face include left right left right 
right face includes component models 
current system assume face images nearly front view possible plane head rotations 

multi state face component models different face component models different states 
example lip model front face doesn profile face 
give detailed facial component models nearly front view face 
permanent components lips eyes brows cheeks transient components furrows considered 
different appearances different components different geometric models model component location shape appearance 
head state 
different facial components head state 

multiple state face model 
head state left left front front right front right 
different facial component models different head states 
component employs multi state model corresponding different component states 
example state lip model defined describe lip states open closed tightly closed 
state eye model model open closed eye 
state brow cheek 
absent model states transient facial features 
multi state component models different components described table 
table 
multi state facial component models front face component state description feature opened lip closed xc yc tightly closed lip corner lip corner eye open xc yc closed corner corner brow cheek furrow eye inner corner line furrows absent 
facial feature extraction contraction facial muscles produces changes direction magnitude motion skin surface appearance permanent transient facial features 
examples permanent features lips eyes furrows permanent age 
transient features include facial lines furrows rest 
assume frame neutral expression 
initializing templates permanent features frame permanent transient features tracked detected image sequence regardless states facial components 
tracking results show method robust tracking facial features large plane head rotation 

permanent features lip features state lip model tracking modeling lip features 
shown table classify mouth states open closed tightly closed 
different lip templates obtain lip contours 
currently template open closed mouth 
parabolic arcs model position orientation shape lips 
template open closed lips parameters lip center xc yc lip shape lip orientation 
tightly closed mouth dark mouth line connecting lip corners detected image model position orientation shape tightly closed lips 
lip template manually located neutral expression frame lip color obtained modeling gaussian mixture 
shape location lip template image sequence automatically tracked feature point tracking 
lip shape color information determine lip state state transitions 
detailed lip tracking method 
eye features eye trackers developed far open eyes simply track eye locations 
recognizing facial action units need recognize state eyes open closed parameters eye model location radius iris corners height open eye 
shown table eye model consists open closed 
iris provides important information eye state 
eye open part iris normally visible 
eye closed 
different states specific eye templates different algorithms obtain eye features 
open eye assume outer contour eye symmetrical perpendicular bisector line connecting eye corners 
template illustrated table composed circle parameters parabolic arcs parameters 
eye template yuille points located center 
closed eye template reduced parameters eye corners 
default eye state open 
locating open eye template frame eye inner corner tracked accurately feature point tracking 
outer corners hard track stable inner corners assume outer corners line connects inner corners 
outer corners obtained eye width calculated frame 
intensity edge information detect iris iris provides important information eye state 
half circle iris mask obtain correct iris edges 
iris detected eye open iris center iris mask center 
image sequence eyelid contours tracked open eyes feature point tracking 
closed eye need track eyelid contours 
line connects inner outer corners eye eye boundary 
detailed eye feature tracking techniques 
brow cheek features features brow cheek areas important facial expression analysis 
brow cheek state respectively triangular template parameters model position brow cheek 
brow cheek tracked feature point tracking 
modified version gradient tracking algorithm track points image sequence 
permanent facial feature tracking results different expressions shown 
facial feature tracking results www cs cmu edu face 

transient features facial motion produces transient features 
wrinkles furrows appear perpendicular motion direction activated muscle 
transient features provide crucial information recognition action units 
contraction muscle instance produces vertical furrows brows coded facs au contraction medial portion muscle au causes horizontal center forehead 
lines furrows may permanent age 
permanent feet wrinkles outside corners eyes characteristic au transient common adults infants 
lines furrows permanent facial features contraction corresponding muscles produces changes appearance deepening lengthening 
presence absence furrows face image determined geometric feature analysis eigen analysis 
kwon lobo detect furrows snake classify pictures people different age groups 
lien detected face horizontal vertical diagonal edges face expression recognition 
system currently detect furrows nose wrinkles feet wrinkles 
define states absent 
compared neutral frame state wrinkles appear deepen lengthen 
absent 
obtaining permanent facial features areas furrows related different aus decided permanent facial feature locations 
define furrow area area eye inner corners line lip corners line 
nose area square eye inner corners 
feet areas eye outer corners 
canny edge detector detect edge information areas 
nose wrinkles feet wrinkles compare edge pixel numbers current frame edge pixel numbers frame areas 
large threshold furrows 
furrows absent 
furrows detect continued diagonal edges 
furrow detection results shown fig 

facial feature representation action unit facs anatomically related contraction specific facial muscle 
instance au oblique raising lip corners results contraction major muscle au lip stretch contraction muscle au oblique lowering lip corners contraction muscle 
muscle contractions produce motion skin deform shape location facial components 
order recognize 
permanent feature tracking results different expressions 
narrowing eyes opened mouth 
large open eye blinking large opened mouth 
tight closed eye eye blinking 
tightly closed mouth blinking 

furrow detection results 
subject furrow angle furrow line connected eye inner corners different different expressions 
subtle changes face expression represent upper face features lower face features group suitable parameters respectively facial actions upper face little influence facial motion lower face vice versa 
defining parameters define basic coordinate system 
eye inner corners stable features face relatively insensitive deformation facial expressions define axis line connecting inner corners eyes axis perpendicular axis 
order remove effects different size face images different image sequences parameters wrinkles states calculated ratio scores comparison neutral frame 

upper face feature representation represent upper face features parameters 
parameters describe motion shape eyes brows cheeks 
parameters describe state feet wrinkles parameter describes distance brows 
shows coordinate system parameter meanings 
definitions upper face parameters listed table 
table 
upper face feature representation au recognition permanent features left right inner brow outer brow eye height motion motion bi bi bo bo gamma inner brow outer brow eye height move 
move 
increases 
eye top lid eye bottom lid cheek motion motion top motion cheek top cheek gammah gamma gammah gamma gammac top cheek eye top lid eye bottom lid cheek move 
move 
move 
features distance left right brows feet wrinkles feet wrinkles brow lef right brow lef right gammad left feet right feet 


upper face features 
hl hl hl hr hr hr height left eye right eye distance brows cl cr motion left cheek right cheek 
bli bri motion inner part left brow right brow 
blo bro motion outer part left brow right brow 
fr left right feet areas 

lower face feature representation define parameters represent lower face features tracked facial features 
parameters describe permanent features lip shape lip state lip motion parameters describe transient features furrows nose wrinkles 
notice furrow different angles furrow axis different action units 
example furrow angle au au larger au 
angle represent orientation 
nose wrinkles located upper face classify parameter lower face feature related lower face aus 
definitions lower face parameters listed table 
feature data affine aligned calculating line connected inner corners eyes normalized individual differences facial conformation converting ratio scores 
parameter meanings shown 

lower face features 
top bottom lip heights lip width lef distance left lip corner eye inner corners line right distance right lip corner eye inner corners line nose area 

facial action unit definitions ekman friesen developed facial action coding system facs describing facial expressions action units aus au combinations 
facs aus anatomically related table 
representation lower face features aus recognition permanent features lip height lip width left lip corner height width motion lef height width lef gamma gammaw gamma left gammad left left height width lef lip height lip width left lip corner increases 
increases 
move 
right lip corner top lip motion bottom lip right top motion right top gamma right gammad right right gamma dtop gammad top top gamma gammad right top right lip corner top lip bottom lip move 
move 
move 
transient features left right state nose furrow angle furrow angle wrinkles ang lef ang right left left furrow furrow nose wrinkles angle ang lef angle 
ang right contraction specific set facial muscles 
upper face lower face 
action units occur singly combinations 
action unit combinations may additive au case combination change appearance constituents nonadditive case appearance constituents change au 
number atomic action units small combinations action units observed 
facs provides necessary detail describe facial expression 
table 
basic upper face action units au combinations au au au inner portion outer portion brows lowered brows brows drawn raised 
raised 
au au au upper eyelids cheeks lower eyelids raised 
raised 
raised 
au au au medial portion brows lowered inner outer brows drawn portions raised pulled brows raised 

upper eyelids raised 
au au au neutral brows pulled brow eyelids eyes brow cheek raised 
cheek upward 
relaxed 

upper face action units table shows definitions individual upper face aus non additive combinations involving action units 
example non additive effect au appears differently depending occurs combination au au 
au occurs brows drawn lowered 
au brows drawn raised action au 
example difficult notice difference static images au au action au pulls inner brow results similar appearance au 
contrast action au little effect outer brow 

lower face action units table shows definitions lower face aus au combinations 

image database 
image database upper face au recognition database bartlett upper face aus recognition 
image database obtained subjects consisting males females 
image sequence consists frames neutral low magnitude facial actions high magnitude facial actions 
sequence action units coded certified facs coder 
investigation image sequences subjects processed 
image sequences contain individual upper face aus image sequences contain upper face au combinations 
training testing performed initial final frames image sequence 
image sequences lighting normalizations performed 
test algorithm individual aus randomly generate training testing sets image sequences shown table 
rains tests ensure subjects appear training testing sets 
test algorithm aus au combinations generate training set testing set shown table 
table 
basic lower face action units au combination au au au lips triangle triangle lower portion center pushed upwards 
upper lip upper lip furrow pulled pulled upwards 
raised 
nose pulled back nose absent 
laterally 

mouth elongated 
au au au corner chin boss lip corners lips pushed pulled 
pulled 
upwards 
au au au lips relaxed lips relaxed mouth stretched 
open pulled lowered 
downwards 
au neutral lips tightened lips relaxed narrowed closed 
pressed 
table 
data distribution data set upper face au recognition 
single au data sets aus au au au au au au au total trains tests trains tests trains tests au combination data sets 
image database lower face au recognition data pitt cmu au coded face expression image database lower face au recognition 
database currently includes image sequences adult subjects varying ethnicity performing multiple tokens primary facs action units 
subjects sat directly front camera performed series facial expressions included single action units au smile combinations action units au 
expression sequence began neutral face 
sequence action units coded certified facs coder 
total image sequences adults female male european american african american asian ages years processed lower face action unit recognition 
image sequences action unit combinations au au au au au au 
image sequence neutral frame peak frames 
image sequences training data different image sequences test data 
training testing data sets shown table 
table 
training data set lower face au recognition neutral au au au au au au au au au au total train set test set 
face action units recognition 
upper face action units recognition layer neural networks hidden layer 
inputs neural networks parameters shown table 
separate neural networks evaluated 
comparison bartlett results nn recognizing individual aus 
second nn recognizing au combinations modeling individual upper face aus 
third nn recognizing au combinations separately modeling nonadditive au combinations 
desired number hidden units achieve recognition investigated 
upper face individual au recognition nn outputs individual upper face aus 
output unit gives estimate probability input image consisting associated action units 
experiments hidden units sufficient 
order recognize individual action units training testing data include individual aus 
table shows results nn rains tests training testing sets 
recognition rate obtained 
increase training data rains test tests recognition rate obtained 
detecting system robustness new faces tested algorithm rains tests training testing sets 
recognition results shown table 
average recognition rate zero false alarms 
aus probability output units labeled au close highest probability treated incorrect result 
table 
au recognition single aus rains tests 
rows correspond nn outputs columns correspond human labels 
au au au au au au au au au au au au au au average recognition rate example obtain probability au au au au labeled au means au misidentified au 
tested nn trained single au image sequences data set containing au combinations recognition rate decreases 
table 
au recognition single aus test data come new subjects training 
au au au au au au au au au au au au au au average recognition rate upper face au combination recognition modeling individual aus nn similar previous section output units fire 
restrict output individual aus 
additive nonadditive au combinations value corresponding individual aus training data set 
example au outputs au au au 
experiments need increase number hidden units 
table shows results nn training testing set 
average recognition rate achieved false alarm rate 
higher false alarm rate comes au combination 
example obtained recognition results au au labeled au treated au au 
means au recognized au false alarm 
table 
au recognition au combinations modeling single aus 
au 
correct false missed confused recognition rate total false alarm upper face au combination recognition modeling nonadditive combinations nn separately model nonadditive au combinations 
outputs consist individual upper face aus non additive au combinations au au au au 
non additive au combinations corresponding individual aus strongly depend 
table shows correlations au au au au au au au au training set 
set values appearances aus combinations 
table shows results nn training testing set 
average recognition rate achieved slightly lower false alarm rate 
case modeling separately nonadditive combinations improve recognition rate due fact table 
correlation au au au au au au au au 
au au au au au au au au au au au au au au au au aus combinations strongly depend 
table 
au recognition au combinations modeling non additive au combinations separate aus 
au 
correct false missed confused recognition rate total false alarm 
lower face action units recognition layer neural network hidden layer recognize lower face action units 
inputs neural network lower face feature parameters shown table 
parameters parameters furrows 
don angles furrows varied different subjects 
generally analyze different expressions subject 
separate neural networks trained lower face au recognition 
outputs nn ignore nonadditive combinations models basic single action units shown table 
au au au occur 
outputs second separately models nonadditive combinations au au basic single action units 
recognition results modeling basic lower face aus shown table recognition rate 
recognition results modeling non additive au combinations shown table average recognition rate 
separately model nonadditive combinations slightly increase lower action unit recognition accuracy 
come au au au 
mistakes au confused au 
reasonable au au lips 
au lowered 
jaw motion information current system 
mistakes au au caused image sequences au combination au 
combinations au classified au 
combination au classified au missing au 
combination au modified single au appearance 
neural network needs learn modification training data au 
examples au training data current system 
data au collecting training 
system able identify action units regardless occurred singly combinations 
system trained large number subjects included african americans addition european americans providing sufficient test initial training analyses generalized new image sequences 
evaluating necessity including nonadditive combinations train neural network basic lower face action units outputs 
test data set average recognition rate 

discussion developed feature facial expression recognition system recognize individual aus au combinations 
localize subtle changes appearance facial features developed multi state method tracking facial features uses convergent methods feature analysis 
table 
lower face action unit recognition results modeling basic lower face aus 
au 
correct false missed confused recognition rate au au total table 
lower face action unit recognition results modeling non additive au combinations 
au 
correct false missed confused recognition rate au au total high sensitivity specificity subtle differences facial expressions 
facial features represented group feature parameters 
network able learn correlations facial feature parameter patterns specific action units 
correlated effects muscle contraction potentially provide unique information facial expression 
action units facs instance closely related expressions disgust produced variant regions muscle 
shape furrow state nose wrinkles 
changes appearance facial features affect reliability measurements pixel motion face image 
closing lips blinking eyes produces occlusion confound optical flow estimation 
information motion feature appearance considered accuracy facial expression analysis particular sensitivity subtle differences expression may impaired 
recognition rate achieved basic upper face aus 
eleven basic lower face action units recognized action units correctly classified 
previous methods build separate model au au combination build single model recognizes aus occur singly combinations 
important capability number possible au combinations large combination modeled separately 
database bartlett recognized single upper face action units combinations 
performance feature classifier novel faces new images face training rate 
combined holistic spatial analysis feature measures optical flow obtained best performance correct 
compared system feature classifier obtained higher performance rate novel faces new images face training individual au recognition 
system works difficult case aus occur individually additive nonadditive au combinations 
upper face aus au combinations correctly classified regardless action units occur singly combination 
disagreements occur nonadditive au combinations au au au au au 
result analysis nonadditive au combinations done 
experimental results observations 
recognition performance facial feature measurements comparable holistic analysis gabor wavelet representation au recognition 

hidden units sufficient code individual upper face aus 
hidden units needed aus may occur singly complex combinations 

upper face au recognition separately modeling nonadditive au combinations affords increase recognition accuracy 
contrast separately modeling nonadditive au combinations affords slightly increase recognition accuracy lower face au recognition 

sufficient data train nn recognition accuracy stable recognizing aus new faces 
summary face image analysis system demonstrated concurrent validity manual facs coding 
multi state model convergent measures approach proved capture subtle changes facial features 
test set included subjects mixed ethnicity average recognition accuracy basic action units lower face basic action units upper face regardless action units occur singly combinations 
comparable level inter observer agreement achieved manual facs coding represents advancement existing computer vision systems recognize small set expressions vary facial regions 
authors paul ekman human interaction laboratory university california san francisco providing database 
authors peters michelle processing images 
supported nimh mh 
bartlett hager ekman sejnowski 
measuring facial expressions computer image analysis 
psychophysiology 
carroll russell 
facial expression hollywood portrayal emotion 
journal personality social psychology 
donato bartlett hager ekman sejnowski 
classifying facial actions 
international journal pattern analysis machine intelligence october 
ekman friesen 
facial action coding system technique measurement facial movement 
consulting psychologists press san francisco ca 
essa pentland 
coding analysis interpretation recognition facial expressions 
ieee 
pattern analysis machine intelligence july 
yamaguchi 
facial feature point extraction method combination shape extraction pattern matching 
systems computers japan 
kirby sirovich 
application procedure characterization human faces 
ieee 
pattern analysis machine intelligence jan 
kwon lobo 
age classification facial images 
proc 
ieee conf 
computer vision pattern recognition pages 

lien kanade li 
detection tracking classification action units facial expression 
journal robotics autonomous system press 
lucas kanade 
image registration technique application stereo vision 
th international joint conference artificial intelligence pages 
mase 
recognition facial expression optical flow 
ieice 
scherer ekman 
handbook methods nonverbal behavior research 
cambridge university press cambridge uk 
terzopoulos waters 
analysis facial images physical anatomical models 
ieee international conference computer vision pages 
tian kanade cohn 
dual state parametric eye tracking 
submit international conference face gesture recognition 
tian kanade cohn 
robust lip tracking combining shape color motion 
proc 

turk pentland 
face recognition eigenfaces 
proc 
ieee conf 
computer vision pattern recognition pages 
yacoob davis 
recognizing human facial expression long image sequences optical flow 
ieee trans 
pattern analysis machine intelligence june 
yuille cohen 
feature extraction faces deformable templates 
international journal computer vision 
zhang 
feature facial expression recognition sensitivity analysis experiments multilayer perceptron 
international journal pattern recognition artificial intelligence 

