purdue university department computer sciences technical report lightweight write detection checkpointing ne grained persistence antony hosking purdue university eliot moss university massachusetts amherst systems dynamically track writes cached data purpose reconciling updates respect permanent global state data 
example distributed systems employ coherency protocols ensure consistent view shared data 
similarly database systems log updates concurrency control ensure resilience updates face system failures 
measure compare absolute performance alternative mechanisms lightweight detection writes cached data persistent system relative overhead log writes stable storage form checkpoint 
de nes consistent state system restored event ofany subsequent failure 
cient detection logging updates critical performance persistent systems embody ne grained data model object overheads typically low 
results reveal wide range performance alternatives indicating right choice mechanism important 
demonstrate software write detection mechanisms signi cantly outperform approaches rely solely hardware operating system 
categories subject descriptors general terms additional key words phrases 
persistent system atkinson atkinson atkinson atkinson buneman maintains data independently transitory programs create manipulate data data may outlive creators manipulated programs 
achieve persistent systems provide abstraction persistent storage programmers view stable supported national science foundation ccr ccr dcr companies corporations sun microsystems digital equipment apple computer gte laboratories eastman kodak general electric parcplace systems xerox tektronix 
name antony hosking liation purdue university address department computer sciences purdue university west lafayette hosking cs purdue edu name eliot moss liation university massachusetts amherst address department computer science university massachusetts amherst ma moss cs umass edu disk resident extension memory dynamically allocate new data persists program invocation 
persistent programming language allows traversal manipulation persistent data programmed transparently explicit calls transfer data volatile main memory stable persistent storage 
language implementation run time system persistent data available memory demand non resident pages automatically resident paged virtual memory system 
persistent program modify persistent data commit modi cations updates permanently recorded persistent storage 
traditional database systems persistent systems typically treat memory relatively scarce resource respect size database maintaining cache frequently accessed persistent data volatile memory cient manipulation 
updates cheaply place memory ultimately propagate back stable storage permanent 
operation modi es persistent data requires immediate subsequent action commit update disk 
system write modi cations straight disk update approach unnecessarily expensive updates frequent incur little overhead 
applications exhibiting locality update may bene approach groups related updates cient batch transfer disk deferring writes absolutely necessary program issues explicit checkpoint operation 
approach reduces update overhead checkpoint latencies minimized smallest possible impact 
example interactive environments checkpoints noticeably delay response times 
overheads manage updates persistent data constitute write barrier signi cantly impact performance persistent systems 
adding persistence conventional programming languages algol family including pascal modula object oriented cousins modula smalltalk complicated ne grained view data provide fundamental data types operations correspond closely ubiquitous primitive types operations supported machines von neumann model computation 
close correspondence means operations supported language implemented directly little instruction target machine 
integrating persistence languages poses new problems performance arising ne granularity types operations supported language 
principle orthogonality mandates data values ne grained single byte smallest value typically addressable current machines ought persist independently 
clearly situation signi cantly di erent traditional database systems date date unit persistence record usually consisting tens hundreds bytes 
relational database system spend hundreds thousands instructions implementing relational operators algol persistent programming language take approach persistence swamp low overhead frequently executed operations 
implementations write barrier languages su ciently lightweight represent marginal overhead frequently executed operations ne grained persistent data 
performance write barrier persistence broken components run time overhead track updates occur checkpoint overhead required ush updates disk 
explore relative performance comprehensive set overhead write barrier implementations prototype persistent system 
precisely measure run time checkpoint overheads alternative characterize tradeo results show alternatives exhibit wide range performance implying right choice mechanism important 
results somewhat counterintuitive reveal write barrier mechanisms implemented software signi cantly outperform alternative approaches rely support hardware operating system track updates 
results general implications choice write barrier mechanism domains persistence garbage collection distributed systems 
addition direct performance results er experimental methodology representing unique blend performance measurement simulation characterizing low level behavior complex software system 
remainder organized follows 
section covers background material persistent systems 
section presents methodology performance evaluation including description prototype implementation write detection mechanisms compared benchmarks experimental con guration performance metrics 
section presents performance results analysis simulations 
section discusses related 
section suggests directions section ers nal 

background persistent systems born fundamental convergence programming language database technology integrating data manipulation features programming languages storage management features databases 
sections review important architectural features persistent programming languages systems describe particular architecture persistence rationale 
persistent programming languages persistent programming languages place full type system language programmer disposal de ning persistent data 
early atkinson characterized persistence orthogonal property data independent data type way data manipulated 
particular characterization encourages view language extended support persistence minimal disturbance existing syntax 
persistent programming languages represent extend address space programs addressed directly available hardware just virtual memory represents extension memory address space program physical memory virtual address translation allows transparent access data regardless physical memory location operating system hardware cooperate trap pages resident memory 
provide abstraction persistent storage terms persistent dynamic allocation heap data heap referred language supported pointers 
entire heap virtual memory mapped directly pointers represented direct virtual memory addresses 
limits size heap virtual address space 
extended requires pointers necessarily virtual memory addresses mechanism perform translation pointers virtual addresses allow program manipulate data 
way persistent program may refer resident non resident persistent objects 
ideally memory resident persistent object referred virtual address accessing object fast accessing non persistent object 
program traverses non resident object available program memory call object fault 
persistent objects faulted memory demand non resident pages automatically resident virtual memory system 
implementations object faulting possible driven software checks pointer dereferences supported language implementation userlevel virtual memory primitives supported operating system hardware appel li hosking moss 
storage management architectures persistence typically component common storage manager responsible maintaining data inexpensive stable storage medium magnetic disk requests retrieve save speci ed data 
object oriented storage managers allow retrieval data object identi er id systems called persistent object stores 
object oriented database systems support style access distinguished persistent object stores additionally providing full database functionality including concurrency control recovery transactions distribution data access associative queries languages data de nition manipulation 
implementation uses mneme persistent object store moss manage storage retrieval objects grouped segments cient transfer disk 
mneme intended tight integration persistent programming languages procedural interface 
primary abstraction persistent store persistent heap objects persist long reachable designated root objects 
architecture persistence object caching architecture persistence unusual 
example bears close resemblance object caching architectures white dewitt kemper napier brown brown 
architecture realization unique allows language implementation maximum control objects manipulated program having pass restrictive interface underlying storage manager 
exibility comes result mneme allows direct access objects bu ers virtual memory pointers 
server possibly remote disk segments memory mneme client buffer pool segment segment swizzle fig 

system architecture application memory space old objects new objects log records log local disk architecture illustrated 
mneme client maintains bu er segments containing persistent objects main memory necessary 
object faults trigger copying objects client bu er pool virtual memory address space application program 
copying includes translation needed convert objects form acceptable program 
particular mneme uses object identi ers refer objects program uses virtual memory pointers object may direct memory pointers manipulation program process known swizzling 
architecture permits standard programming language techniques memory management including garbage collection manage objects resident program virtual address space 
object resident pointer elds swizzled mechanism employed triggering object faults 
elds referring resident objects converted point directly objects mneme supports mapping ciently hash table 
converted form trigger object fault traversed 
checkpoints notion recovery dictated speci assumptions behavior persistent programs 
assume program invoke operation certain points execution permanent modi cations persistent objects 
event system crash recovery mechanism restore state persistent store checkpoint 
assume checkpoint latencies minimized smallest possible impact running time program 
point important interactive environments checkpoints may noticeably delay response times 
operation consists copying modi ed objects modi ed subranges objects back client bu er pool generating log records describing range values modi ed regions objects 
log records generated di erences object original client bu er pool 
persistence system reachability operation may encounter pointers objects newly created checkpoint 
object assigned persistent identi er unswizzled turn dragging newly created objects persistent store log record describing new object generated 
precise format log records relevant study interested mechanisms detect log updates 
note log record tagged persistent identi er modi ed object encodes range modi ed bytes 
recovery involves applying log records objects pertain order occur log 
alternative log record formats yield compact log allow cient recovery log minimal sense records just information reconstruct modi ed object 
di logging minimizes disk tra cost computing di erences 
preliminary performance studies determined tradeo worthwhile 
result con rmed settings white dewitt 
extensions basic architecture described far architecture supports single user access recovery 
argue architecture extended provided additional functionality bu er management concurrency control 
bu er management 
integrate bu er management recovery model guarantee modi ed segment ushed disk log records associated modi cations written 
outside constraint bu er manager free appropriate bu er replacement policy 
management swizzled objects application virtual memory rely techniques similar garbage collection determine objects subject replacement hosking compatible recovery model modi ed objects selected replacement unswizzled logged disk inclusion checkpoint 
concurrency control 
recovery model indi erent concurrency introduced architecture ways 
separate applications share persistent store arbitrated server 
locking managed server application view recovery unchanged modulo additional information required log entry identify owner 
second single application may multi threaded 
additional locks managed application data shared threads 
recovery model remains essentially unchanged modulo additional log entry information identify owner entry 
recovery model support concurrency provide foundation transaction model 
incorporation transaction models persistent programming languages remains open topic research 
directly concerned issue merely recovery model extended transactions similarly database cache bayer transaction models exist 
system database cache designed fast transaction commit rapid recovery crash 

methodology evaluate performance alternative write barrier implementations single prototype persistent system 
di erent instantiations prototype di erent implementations low level write barrier mechanism 
aspects implementation kept constant instantiation prototype 
allows head head comparison alternative implementations particular mechanism study varies instances prototype 
respect experimental test bed exploration persistent systems implementation allowing direct comparison alternatives 
experiments encompass measurements elapsed time cache simulation instruction pro ling obtain counts cache misses execution frequency instruction address 
combined measurements allow precise determination absolute run time overheads terms cycles update relative checkpoint overheads alternative write barrier implementation 
implementation persistent smalltalk prototype persistent system study implementation smalltalk programming language environment goldberg robson extended persistence 
implementation components virtual machine virtual image 
virtual machine implements bytecode instruction set smalltalk source code compiled certain primitives functionality built directly virtual machine 
typically provide low level access underlying hardware operating system virtual machine implemented 
example low level oating point integer arithmetic indexed access elds objects object allocation supported primitives 
notable features implementation smalltalk virtual machine direct bit object pointers improved scheme managing smalltalk stack frames activation records moss generation scavenging garbage collection ungar ungar dynamic translation compiled methods bytecodes threaded code bell 
threaded code signi cantly improves performance virtual machine replacing expensive decode bytecode instruction cycle straightforward indirect branch 
result interpreted smalltalk system exhibits performance times faster sparcstation equivalent implementation bytecode instructions xerox dorado mccall 
virtual image derived xerox parc smalltalk image version april minor modi cations 
implements smalltalk functionality smalltalk development environment including editors browsers debugger bytecode compiler class libraries rst class objects smalltalk sense 
bootstrapping non persistent smalltalk environment entails loading entire virtual image memory execution virtual machine 
persistent implementation smalltalk places virtual image tent store environment bootstrapped loading just subset objects image su cient resumption execution virtual machine 
retain original bytecode instruction set minor modi cations virtual image 
orts focus virtual machine carefully augmented fault objects memory needed executing image 
precise mechanism object faulting relevant study say software approach kept constant variations write barrier mechanism 
object faulting overheads low restricted solely method invocation sequence bytecode dispatch execution entirely free object faulting overheads 
comparisons alternative schemes object faulting prototype appear hosking moss hosking moss hosking 
implementing write barrier detecting logging updates lightweight mechanisms inspired similar solutions write barrier problem garbage collection act storing pointer object noted order minimize number pointer locations examined collector hosking 
similarly cient logging requires keeping track updates objects minimize number locations unswizzled generating log recall log record generated di erences new version object original client bu er pool 
study examines implementations write barrier including approaches previously garbage collection applied rst time problem detecting logging updates persistent data 
note log consists di erence information obtained comparing old new versions objects schemes generating exactly log information 
schemes vary granularity update information record amount comparison required generate log 
object schemes 
rst schemes record updates logical level objects 
approach mark updated objects setting bit header object modi ed 
checkpoint operation scan cached objects discover marked updated 
marked object unswizzled compared original bu er pool determine di erences logged 
drawback approach additional checkpoint overhead required scan cached objects nd marked 
avoid scanning second scheme uses data structure called remembered set ungar record modi ed persistent objects 
need process entries remembered set locate objects unswizzled possibly logged 
remembered set implemented dynamic hash table 
remembered set large inline lter applied record updates persistent objects opposed newly created transient objects smalltalk allocator vast majority updates transient objects 
requires check see updated object located separately managed persistent area volatile heap determined high bits address index table contains information 
updated object persistent subroutine invoked hash object pointer remembered set 
remembered sets advantage concise accurate cost ltering hashing keep sets small repeated updates object result just entry remembered set incur repeated overhead lter hash 
card schemes 
object schemes concisely represent just objects modi ed need unswizzled checkpoint 
updates larger objects may su er poor locality respect object size resulting unnecessary comparison checkpoint bounded solely size object 
alternative record updates xed size units virtual memory space dividing memory aligned logical regions size bytes address rst byte region low bits zero 
regions called cards sobalvarro 
card corresponding entry card table indicating card contains updated locations 
mapping address entry table simple shift address right bits result index table 
object modi ed corresponding card 
attractive features card marking simplicity write barrier 
ignoring cache ects update overhead constant 
keeping overhead minimum highly desirable 
implementing card table byte array bitmap interpreting zero bytes dirty entries non zero bytes clean store recorded just sparc instructions shift index byte store zero wilson moher wilson moher 
checkpoint operation scans dirty cards containing persistent objects perform obtain di erences logging 
requires locating pointers card 
log records generated respect modi ed objects card recording object identi er contiguous ranges modi ed bytes 
formats objects card encoded object headers header rst object card located start scan 
purpose table card sets parallel dirty card table records location highest address object header card 
card scanning header rst object card object previous card 
dirty cards marked clean scanning 
reduce overhead scanning contiguous dirty cards scanned batch running rst scan 
implementation takes great pains avoid unnecessary memory accesses scanning card table locate run dirty cards loading entire memory word table time 
size cards important factor uencing checkpoint costs modern risc architectures provide byte store instruction implement reading full word modifying appropriate byte writing back modi ed word 
machines may code read modify write explicitly sequence instructions revert bitmap implementation dirty card table 
large cards mean fewer cards smaller tables 
larger cards imply unnecessary checkpoint overhead perform comparison objects unmodi ed just happen lie dirty card 
interesting question arises exists optimal card size minimizes sum competing overheads 
performance evaluation answers question program behaviors consider 
page protection schemes 
card approach uses hardware supported page protection primitives operating system detect stores clean cards 
card scheme corresponds page virtual memory 
clean pages protected writes 
write occurs protected page trap handler corresponding entry card table page 
subsequent writes dirty page incur extra overhead 
dirty page table updated line trap handler probably important entry page table incur minimal overhead dirty page table kept small possible 
prefer reimplement dirty page table bitmap byte map reducing table size factor 
continue byte table direct comparison page sized card scheme 
benchmarks performance evaluation draws oo object operations benchmarks cattell skeen compare alternative implementation approaches 
benchmarks retrieval oriented operate substantial data structures benchmarks simple easily understood 
execution patterns include phases intensive computation memory residence important 
oo benchmarks relatively low level su cient exhaustive exploration behavior minimal write barrier mechanisms 
benchmark database 
oo benchmark database consists collection part objects indexed part numbers range exactly connections part parts 
connections randomly selected produce locality connections closest parts remainder randomly chosen part 
closeness de ned parts numerically closest part numbers 
implement part database benchmarks entirely smalltalk including tree index parts 
database including base smalltalk virtual image parts data mb 
newly created objects clustered mneme segments encountered essentially breadth rst traversal similar copying garbage collectors cheney 
part objects bytes size including object header 
outgoing connections stored directly part objects 
string elds associated operating system ciently supply information needed page protection scheme ering appropriate calls obtain page dirty bits maintained memory management hardware shaw 
part connection represented separate smalltalk objects bytes 
similarly part incoming connections represented separate smalltalk array object containing parts source incoming connection 
tree index parts consumes kb 
benchmark operations 
oo benchmarks comprise separate operations measure response time execution operation 
rst operations read leaving permanent database untouched 
retrieval oriented involve modi cation database relevant study write barrier mechanisms 
describe merely completeness lookup fetches randomly chosen parts database 
procedure invoked part arguments type elds part 
traversal fetches parts connected randomly chosen part part connected hops total parts possible duplicates 
similar lookup benchmark procedure invoked part arguments type elds part 
third operation requires updating permanent database appropriate comparing write barrier mechanisms insert allocates new parts database connections randomly selected parts described section applying rules locality 
index structure updated entire set changes committed disk 
operation reasonable measure update overhead hampered lack control number distribution locations modi ed mixing updates parts index 
controlled benchmark update white dewitt operates way traversal measure calling null procedure performs simple update part object encountered xed probability 
update consists incrementing scalar integer elds part 
changes committed disk 
probability update vary run change frequency density updates 
benchmarks intended representative data operations engineering applications 
lookup benchmark emphasizes selective re oo speci es reverse traversal operation swapping directions 
reverse traversal operation minimal practical random nature connections means number connections varies parts part outgoing connections number incoming connections varies randomly 
di erent iterations reverse traversal vary randomly number objects traverse amount ofwork perform 
trieval objects attributes traversal benchmark illuminates cost raw pointer traversal 
update variant measures costs modifying objects making changes permanent 
additionally insert benchmark measures update overhead cost creating new persistent objects 
oo calls benchmark measure iterated times rst system cold database cached apart schema system information necessary initialize system 
run iterations execute chill program client read mb le server scanning rst forward backward operating system kernel bu er cache client server rst iteration truly cold 
successive iteration accesses di erent set random parts 
may overlap parts accessed di erent iterations case implementations cache data iteration exhibit warming trend improved performance warm iterations access data cached earlier iterations 
addition cold warm iterations useful measure performance hot iterations benchmarks hot iteration initial part warm iterations 
hot runs guaranteed access resident objects free overheads due handling object faults 
experimental con guration ran experiments sparcstation semiconductor cy integer unit clocked mhz running sunos 
sparcstation kb uni ed cache instruction data line size bytes 
read misses cost cycles 
hit writes update cache memory byte write bu er reduces overhead bu er full processor stall cycles completion slow memory cycle 
write misses invalidate allocate corresponding cache line 
system mb main memory dram su cient entire benchmark database cached memory 
bu er management policies ignored interpreting experimental results 
log le written locally internal sun scsi disk kb unformatted capacity mb peak data rate mb sustained data rate ms average seek time 
log records bu ered written batch calls write followed immediately call fsync force log data local disk checkpoint completes 
checkpoints break phases writing measured separately 
database stored locally client server simple sparcstation trademark sparc international licensed exclusively sun microsystems 
sunos trademark sun microsystems 
data rate varies disk constant linear density tracks outer tracks yielding faster bit rate inner tracks 
peak data rate data rate possible single sector 
sustained data rate calculated number byte sectors track multiplied angular velocity number sectors track decreases outer inner tracks calculation approximate 
reason experimental apparatus easier obtain control results remote database di er network latency retrieval objects remote server disk 
local disk latencies high demonstrate caching ects inherent implementation 
database resides external sun scsi disk kb unformatted capacity mb peak data rate mb sustained data rate ms average seek time 
metrics measure elapsed time execution benchmark operations version smalltalk virtual machine instrumented calls sunos system call gettimeofday 
directly accesses system hardware clock resolution sparcstation 
ne grained accuracy permits phase execution running swizzling disk retrieval logging measured separately minimal disturbance results due measurement overheads 
benchmarks run client single user mode disconnected network minimize interference network tra virtual memory paging operating system activity 
times reported seconds stated exclude time initialize smalltalk system prior benchmark 
benchmark run consists cold warm iterations plus single hot iteration 
guarantee repeatability permanent database kept entirely static updates written log propagated permanent database di erent runs physical database 
run begins random number seed nth iteration benchmark run accesses parts nth iteration benchmark run 
words di erent set random parts accessed cold warm iteration run corresponding iterations di erent runs access set parts directly comparable 
may uncontrollable variations system behavior run 
example variations disk state track block position disk read write arm may ect read performance 
get idea signi cance variation comparison di erent implementations repeat runs implementation calculate results con dence intervals mean elapsed time 
measuring elapsed time shade instruction set simulator cmelik keppel obtain precise execution pro les run 
modi ed versions shade tools cache simulation instruction pro ling obtain precise counts instruction address execution frequency cache misses sparcstation cache con guration described 

results analysis experiments insert update benchmarks update probabilities measure performance object marking objects remembered sets remsets access protected virtual memory pages pages card marking cards bytes card size table schemes compared scheme update checkpoint scan scan objects objects set bit header changed object scan changed objects remsets enter object update set iterate update set cards dirty card table entry scan dirty table dirty cards bytes process objects fragments cards pages dirty page scan dirty table dirty pages bytes process objects fragments pages schemes write di erences minimal log volume 

worst case scenario include scheme scan track individual updates simply scans entire set resident persistent objects checkpoint compares object unmodi ed copy bu er cache 
virtual memory page size sparcstation bytes 
schemes summarized table addition cold warm hot iterations perform update traversal checkpoint measure performance longer transactions varying number hot update traversals performed single transaction 
allows derivation precise estimate run time overheads excluding swizzling disk accesses retrieval di erent write barrier mechanisms 
measure total elapsed time iterations checkpoint 
insert results insert plotted summarized table ii 
baseline non persistent implementation treats checkpoint operation 
cold transactions results pages scheme reveal high cost calls operating system manage page protections 
system performance pages fall worst case scan approach pays consistently high overhead scan entire set resident objects checkpoint 
hot transaction insertions set objects warm transactions 
hot transaction includes object faults swizzling page protection scheme longer penalized having manipulate page protections swizzling achieves performance closer schemes incurs page traps clean pages modi ed manipulate page protections checkpoint 
schemes little distinguish cold warm transactions 
di erences better discerned considering raw elapsed times table ii 
cold insert pages scheme signi cantly expensive scan overhead manage page protections objects resident 
best remsets closely followed objects schemes incur overhead resident set objects grows elapsed time cold iteration warm hot fig 

insert table ii 
insert scan pages objects remsets cards cards cards cards cards non persistent scheme cold warm hot non persistent scan objects remsets cards cards cards cards cards pages running old new write elapsed time scan objects remsets cards cards cards cards cards pages fig 

insert hot breakdown card schemes grow tables cover expanding set resident objects 
warmer iterations checkpoint cost important smaller granularity schemes require scanning preferred focus ort 
notice factors uence results card schemes moderately large cards cards better system cold resident set objects grows frequently growing card tables cheaper smaller cards better warm cards hot cards iterations checkpoint overheads dominate 
better understanding behavior hot results shows breakdown elapsed time phase execution benchmark running time spent interpreter executing program opposed old new objects generate di erences writing di erences log note running includes cost noting modi cations occur old time old modi ed objects generate log entries new time new objects generate log entries write time ush log entries disk time remaining bookkeeping activities modifying page protections scavenging free transient memory space 
interesting feature old component re ects amount scanning required determine di erences cached object original client bu er pool 
card schemes evident tradeo size card table card size small cards require overhead scan card table overhead scanning cards larger cards smaller table overhead scan larger cards 
variation schemes components due intrinsic costs schemes subtle underlying hardware cache ects component exhibits variation result scavenging transient space having markedly di erent cache performance schemes 
refrain discussion results insert move update benchmark ords precise control benchmark parameters 
update comparison results implementation alternatives easier consider key cold warm hot results separately 
cold update 
presents elapsed time rst cold iteration update probabilities repeats plot expanded scale omitting results pages scan 
little variation update probability cold times dominated swizzling costs 
pages signi cantly expensive worse scan due overheads page protection management trap updates protected pages manipulate page protections swizzling 
best objects closely followed remsets schemes incurs additional overhead elapsed time elapsed time actual fraction parts modified schemes actual fraction parts modified expanded scale fig 

cold update pages scan cards cards cards cards cards remsets objects cards cards cards cards cards remsets objects resident set objects grows contrast card schemes grow tables cover expanding cache resident objects 
warm update 
tenth iteration checkpoint cost important 
worst scan resident objects generate log 
worst pages overhead manage page protections 
card schemes ranked size smaller cards providing precise information objects modi ed 
remsets scheme performance close smaller card schemes concisely records just objects modi ed 
hot update 
hot transaction traverses exactly parts tenth warm iteration part 
hot transaction incurs object faults swizzling 
hot results similar warm transaction objects needed traversal having cached fetching swizzling objects occurs 
page protection scheme longer penalized having manipulate page protections swizzling achieves performance closer page sized card scheme 
remaining di erence schemes elapsed time elapsed time actual fraction parts modified schemes actual fraction parts modified expanded scale fig 

warm update scan pages objects cards cards cards cards cards remsets objects cards cards cards cards cards remsets explained need manipulate protection dirty pages checkpoint 
breakdowns elapsed time hot update update probability plotted figures note scale changes update probability increases omitting results scan non persistent 
saw insert checkpoint latency dominates old component decisive di erence schemes particularly larger update probabilities 
tradeo card table size card size evident 
lower update probabilities cost scanning card table exerts uence schemes small cards larger card table fare worse larger cards 
higher update probabilities dirty cards process overheads dominate scanning card table larger cards requiring generate di erences smaller cards 
tradeo pronounced byte cards substantially smaller average object size costs outweigh card table scanning costs higher update probabilities 
remembered sets er concise record updates allowing modi ed objects unswizzled scanning 
scanning overhead clearly evident object marking scheme especially low update probabilities objects worst performance 
elapsed time elapsed time actual fraction parts modified schemes actual fraction parts modified expanded scale fig 

hot update scan pages objects cards cards cards cards cards remsets objects cards cards cards cards cards remsets apart pages scheme variation schemes running component signi cant indicating checkpoint overheads dominating uence short transaction benchmark 
pages scheme incur signi cant run time overhead high cost traps note updates 
note part objects modi ed updates occur objects system cause page traps 
elapsed time pages cards cards cards cards cards remsets objects pages cards cards cards cards cards remsets objects pages cards cards cards cards cards remsets objects pages cards cards cards cards cards remsets objects write new old running elapsed time pages cards cards cards cards cards remsets objects pages cards cards cards cards cards remsets objects pages cards cards cards cards cards remsets objects fig 

update hot breakdown long transactions 
run time overheads come play transactions long computation dominate checkpoint overhead 
nal set results concerns experiments multiple hot update traversals performed single transaction 
generalize results obtaining linear regression ts scheme model bx total elapsed time number update traversals transaction 
expected hot traversal constant cost matter times performed ts excellent 
axis intercept approximates checkpoint latency familiar form seen short running transactions see 
slope measure traversal run time costs scheme plotted 
remsets scheme highest overhead note updates 
card schemes clustered mid range overhead objects measured overhead apart scan 
curiously pages second worst measured overhead update incurs additional cost subsequent updates modi ed pages 
overhead eld page protection traps constant value regression trap overhead extracted component coe cient 
turns pages scheme victim anomalous hardware cache behavior 
traversal instruction measure plotted pages overhead equivalent scan 
anomaly revealed figures see contention data instructions cache lines uni ed instruction data cache sparcstation 
subsequent inspection cache simulation results indicates contention restricted single instruction data location accessed part modi ed update traversal slopes lines pages figures approximately modi ed part 
similar anomaly remsets update probabilities remembered set data structure grows dynamically contention code data varies dynamically 
linear regressions traversal elapsed time instruction versus actual number parts modi ed slopes lines figures obtain measure run time overhead scheme part modi ed table iii 
non persistent scan results base level overhead required perform update calculate net update overhead attributed schemes overhead part scan overhead part net overhead update division re ects fact modifying part consists updates increment attribute increment attribute 
net overhead update table iii 
adjusted pages result obtained subtracting cycles correct anomalous read misses modi ed part incurred pages scheme cycles 
validation results observed instruction overheads di erent schemes correspond actual instruction overheads revealed inspection code generated compiler 
cards scheme requires instructions card sizes shares traversal elapsed time ms traversal instruction misses thousands remsets pages cards cards cards cards cards objects scan checkpoint latency actual fraction parts modified objects pages cards cards cards cards cards remsets fig 

long running update checkpoint latency actual fraction parts modified pages remsets scan objects cards cards cards cards cards elapsed time actual fraction parts modified instruction misses traversal instruction millions traversal data read misses thousands remsets cards objects cards pages scan actual fraction parts modified pages remsets objects cards cards cards cards cards scan fig 

run time overheads instruction actual fraction parts modified data read misses table iii 
long running update run time overheads part modi ed net update scheme time cycles instructions time cycles instructions non persistent scan objects remsets cards cards cards cards cards pages raw pages adjusted net overhead update overhead part scan overhead part code write barrier generation scavenging garbage collector uses byte cards 
results precisely measure run time overheads schemes 
page protection scheme pages ers overhead update schemes record updates apart scan non persistent transaction entails repeated updates locations rst update location causes page trap 
remaining updates proceed additional overhead 
note remaining cycles overhead pages probably anomalous indicates cache disturbance due page protection traps 
software mediated card schemes show marginally higher overhead remsets scheme incurs high cost call hash updated location remembered set update 
lastly determine break point pages cards hot update benchmark number update traversals required front cost pages incurred managing page protections checkpoints transaction run time cost page traps equal update runtime costs cards 
calculated di erence checkpoint latency plotted say dividing cards net cost cycles update table iii times number updates traversal mhz number parts modi ed traversal calculations summarized table iv 
note frequency density update ects tradeo high transaction cost pages versus run time costs cards amortization front transaction overheads occurs fewer update traversals higher update probabilities 
high breakeven points show pages preferable extreme cases transactions particularly long updates extremely frequent dense 
maintaining card table base register shift breakeven points table iv 
long running update break points cards versus pages update checkpoint latency seconds parts modi ed break point probability pages cards traversal traversals favor cards eliminating instructions load base leaving just instructions index store appropriate table location 
eliminating load removes possibility read data cache reasonable expect ratio cycles instructions update improve 
summary results show clear ranking alternative schemes approaches record updates smaller granularities having signi cant advantage transactions short update locality poor greatly reduce checkpoint overheads generation di erences log 
short transactions remembered set scheme best update probabilities provides concise summary just objects modi ed 
small granularity cards er robust performance range update probabilities advantage lower precisely bounded run time overhead 
longer transactions run time costs update detection come play 
remembered set scheme loses appeal due relatively high expense managing remembered set 
page protection scheme advantage detection overhead paid front page protection violation trap rst write clean page subsequent updates proceed cost 
overheads card object marking schemes change little update probability varies di erence due hardware cache ects 
di erences run time overheads schemes slight compared checkpoint overheads 
transaction length important factor tension run time checkpoint overheads various schemes 
long transactions produce correspondingly updates increasing checkpoint latency 
volume modi ed data small respect length transaction run time costs schemes permitted guide choice update detection mechanism 
overwhelming uence generation log records indicates general bias accurate smaller granularities schemes low run time overheads 
respect hardware approach embodied page protection scheme seen involve substantial extra overhead typical operations represented benchmarks 
hardware approach attractive 
current realizations expensive calls operating system limited ectiveness 
large page size remains serious de ciency scheme improved operating system support succeed lowering costs managing update information access page dirty bits hosking moss explore rami cations support detail 
er guidelines generation recovery information persistent systems avoid large granules update detection minimize checkpoint latency 
choose checkpoint frequency corresponding rate generation new update information checkpoint delays tolerable 
long running applications perform updates need infrequent checkpoints 
page protection mechanisms update locality infrequent 

related white dewitt compare performance various object faulting pointer swizzling schemes supported di erent persistent object stores 
basic architecture similar object caching scheme white dewitt thrust study signi cantly di erent 
comparing di erent architectures persistence keep architecture xed varying mechanisms generate log information 
representations non resident objects lightweight white dewitt mechanisms support generation log 
white dewitt results suggest method generate recovery information signi cant impact performance system ne grained update information bene cial transactions short poor update locality 
explored issue directly addressing speci question mechanisms best factors determine method ectiveness xed framework single persistent programming language implementation 
subsequent study white dewitt speculate advantages gained augmenting language implementation generate log information relying memory mapping mechanisms generate page di erence records 
precisely done studies di erent mechanisms noting updates logging 
white dewitt consider approaches generating recovery information client server environment full blown database concurrency control mechanisms 
system places log server increased availability case client crashes server continue process log requests clients 
log placed database server network transmission times tend dominate swamping di erences mechanisms track updates generate log information 
white dewitt focus actual log information generated ect performance produce simple di erence log write detection mechanisms consideration 
prevent similar techniques white dewitt reduce amount information written log 
explore performance software approaches detection writes ne grained data maintenance cache coherency distributed shared memory system 
results show software write detection support sharing lower overhead corresponding trap scheme 
con rm experience page sized granularities incur unnecessary overhead processing writes dominant factor ecting performance system 
case ne grained update information minimizes amount data transferred synchronization points maintain consistency distributed shared memory 
thekkath levy describe approach performing cient handling synchronous exceptions user level code 
implementation reduces overhead exception handling order magnitude may su cient hardware trap approach update detection acceptable 
issue page sized granularity concern critical factor ecting checkpoint latencies 
thekkath levy discuss possibility sub page protection mechanisms driven paging hardware 
proposed implementation accessing unprotected sub page lies page protected sub page causes exception kernel emulate instruction returning 
unclear additional overhead degrade performance unacceptable levels 

avenues research deserve exploration expanding range processors operating systems measured see shifts behavior comparing tradeo byte map card marking page trap approaches compact bit map implementation keeping pointer base bit byte map register reduce indexing overhead obtaining similar measurements compiled language setting 
fact results obtained interpreted language taken lightly run time overheads interpretation times higher compiled programs 
see reason results carry compiled setting 
acknowledge compilation shrink running time portion total execution overheads write detection pronounced relative total execution time 
various mechanisms retain rankings respect absolute costs remain modulo shifting possibly spurious hardware cache ects 
compile time derivation control ow information may reveal opportunities merging elimination explicit write barrier code example updates object occur basic block just operation note update necessary 
optimizations reduce importance run time overheads software schemes checkpoint overheads dominant factor uencing choice write detection scheme 
exploring ects compile time optimization implementation persistent modula hosking moss hosking moss moss hosking 

explored lightweight implementations write barrier persistence 
experiments established benchmarks compare performance alternative realizations mechanisms prototype persistent programming language 
importantly demonstrated software mediated techniques competitive alternative hardware assisted techniques 
results implications realm persistence 
general level results performance operating system virtual memory primitives 
overhead eld page protection violations user level signal handlers high cost calls operating system modify page protections mean applications relying primitives pay unnecessarily high overheads 
problem lies large granularity relative ne grained objects virtual memory pages modern operating systems architectures signi cantly ects performance 
processor speeds improve physical memories grow page sizes larger degrading performance virtual memory solutions applications naturally smaller granularity 
worthwhile noting similar results obtained domains cient implementation data breakpoints debuggers wahbe generational garbage collection hosking hosking moss 
concede sub page protection dirty bits appropriate operating system interfaces somewhat overcome performance disadvantages observed thekkath levy 
clear user level virtual memory primitives er transparent solutions various memory management problems requiring modi cation programming language implementation run time handle protection violations necessarily er best performance 
particular setting overhead required software write detection precision information obtained 
additionally card marking approaches advantages bounded overhead write elimination conditional code update site 
advantages sure important current trend architectural advances continues 
appel li 
virtual memory primitives user programs 
proceedings acm international conference support programming languages operating systems santa clara california pp 

atkinson cockshott 
ps algol algol persistent heap 
acm sigplan notices july 
atkinson bailey chisholm cockshott morrison 
approach persistent programming 
computer journal nov 
atkinson buneman 
types persistence database programming languages 
acm computing surveys june 
atkinson chisholm cockshott marshall 
algorithms persistent heap 
software practice experience march 
bell 
threaded code 
commun 
acm june 
brown dearle morrison munro rosenberg 
layered persistent architecture napier 
technical report may university st andrews bremen germany 
brown matthes mueller 
open system architecture persistent object store 
research report cs university st andrews 
cattell skeen 
object operations benchmark 
acm transactions database systems march 
cheney 
nonrecursive list compacting algorithm 
commun 
acm nov 
cmelik keppel 
shade fast instruction set simulator execution pro ling 
proceedings acm conference measurement modeling computer systems pp 

date 
database systems volume ii 
addison wesley 
date 
database systems fourth ed volume addison wesley 
corrected 
bayer 
database cache high performance fast restart database systems 
acm transactions database systems dec 
goldberg robson 
smalltalk language implementation 
addison wesley 
hosking 
main memory management persistence 
position oopsla workshop garbage collection 
hosking 
lightweight support fine grained persistence stock hardware 
ph thesis university massachusetts amherst 
available department computer science technical report 
hosking brown moss 
update logging persistent programming languages comparative performance evaluation 
proceedings international conference onvery large data bases dublin ireland pp 

morgan kaufmann 
hosking moss 
compile time optimisations persistence 
dearle shaw zdonik eds proceedings international workshop persistent object systems martha vineyard massachusetts pp 

implementing persistent object bases principles practice morgan kaufmann 
hosking moss 
compiler support persistent programming 
technical report march department computer science university massachusetts amherst 
hosking moss 
object fault handling persistent programming languages performance evaluation 
proceedings acm conference object oriented programming systems languages applications washington dc pp 

hosking moss 
protection traps alternatives memory management object oriented language 
proceedings acm symposium operating systems principles asheville north carolina pp 

hosking moss 
comparative performance evaluation write barrier implementations 
proceedings acm conference object oriented programming systems languages applications vancouver canada pp 

kemper 
dual bu ering strategies object bases 
proceedings international conference onvery large data bases santiago chile 
morgan kaufmann 
mccall 
smalltalk benchmarks 
krasner ed smalltalk bits history words advice chapter pp 

addison wesley 
moss 
managing stack frames smalltalk 
proceedings acm symposium interpreters interpretive techniques st paul minnesota pp 

moss 
design mneme persistent object store 
acm transactions information systems april 
moss hosking 
expressing object residency optimizations pointer type annotations 
atkinson maier benzaken eds proceedings international workshop persistent object systems workshops computing france pp 

springer verlag 
shaw 
improving garbage collector performance virtual memory 
technical report csl tr march stanford university 
sobalvarro 
lifetime garbage collector lisp systems generalpurpose computers 
thesis dept eecs massachusetts institute technology cambridge 
thekkath levy 
hardware software support cient exception handling 
proceedings acm international conference architectural support programming languages operating systems san jose california pp 

ungar 
generation scavenging non disruptive high performance storage reclamation algorithm 
proceedings acm symposium practical software development environments pittsburgh pennsylvania pp 

ungar 
design evaluation high performance smalltalk system 
acm distinguished dissertations 
mit press cambridge massachusetts 
wahbe 
cient data breakpoints 
proceedings acm international conference support programming languages operating systems boston massachusetts pp 

white dewitt 
performance study alternative object faulting pointer swizzling strategies 
proceedings international conference onvery large data bases vancouver canada pp 

morgan kaufmann 
white dewitt 
high performance mapped object store 
proceedings acm international conference management data minneapolis minnesota pp 

white dewitt 
implementing crash recovery performance study 
inproceedings acm international conference management data san jose california pp 

wilson moher 
card marking scheme controlling intergenerational generation garbage collection stock hardware 
acm sigplan notices may 
wilson moher 
design opportunistic garbage collector 
proceedings acm conference object oriented programming systems languages applications new orleans louisiana pp 

bershad 
software write detection distributed shared memory 
proceedings usenix symposium operating systems design implementation monterey california pp 


