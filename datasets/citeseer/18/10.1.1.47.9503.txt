media laboratory perceptual computing section technical report published ieee transactions pattern analysis machine intelligence july vol pp 
pfinder real time tracking human body christopher wren ali azarbayejani trevor darrell alex pentland mit media laboratory computing section ames street cambridge ma usa trevor media mit edu pfinder www media mit edu projects pfinder pfinder real time system tracking people interpreting behavior 
runs hz standard sgi indy computer performed reliably thousands people different physical locations 
system uses multi class statistical model color shape obtain representation head hands wide range viewing conditions 
pfinder successfully wide range applications including wireless interfaces video databases low bandwidth coding 
applications video databases wireless virtual reality interfaces smart rooms low bandwidth video compression security monitoring common need track interpret human behavior 
ability find follow people head hands body important visual problem 
address need developed real time system called pfinder person finder substantially solves problem arbitrarily complex fixed camera situations 
image image registration techniques preprocessing step allow pfinder function presence camera rotation zoom real time performance achieved special purpose hardware 
system provides interactive performance general purpose hardware tested thousands people installations world performed quite reliably 
pfinder real time interface device information performance spaces video games distributed virtual reality populated artificial life 
pre processor gesture recognition systems including recognize word subset american sign language near perfect accuracy 
pfinder adopts maximum posteriori probability map approach detection tracking human body simple models 
incorporates priori knowledge people primarily bootstrap recover errors 
central tracking description algorithms equally applied tracking vehicles animals fact done informal experiments areas 
pfinder descendant vision routines originally developed alive system performed person tracking explicit model person required controlled background 
pfinder general accurate method person segmentation tracking interpretation 
background notion grouping atomic parts scene form blob entities proximity visual appearance natural interest visual scientists gestalt psychologists studied grouping criteria early century 
modern computer vision processing seek group image pixels segment images visual coherence features obtained efforts usually taken boundaries contours regions regions 
complex scenes containing people natural objects contour features proven unreliable difficult find 
blob representation developed pentland way extracting extremely compact structurally meaningful description multi spectral satellite mss imagery 
method feature vectors pixel formed adding spatial coordinates spectral textural components imagery 
clustered image properties color spatial similarity combine form coherent connected regions blobs pixels similar image properties 
blob description method fact special case minimum description length mdl algorithms 
pfinder system related body tracking research rehg kanade rohr gavrila davis kinematic models pentland horowitz metaxas left video input color image shown greyscale center segmentation right representation blob statistics dynamic models 
contrast pfinder systems require accurate initialization local image features 
consequently difficulty occlusion require massive computational resources 
functionally systems closely related bichsel baumberg hogg 
systems segment person background real time standard workstation 
limitation analyze person shape internal features silhouette person 
consequently track head hands determine body pose recognize simplest gestures 
steady state tracking describe pfinder representations operation steady state case built representations person scene 
sections describe error recovery processes 
modeling person represent regions low order statistics 
clusters points spatial means covariance matrices shall denote blob spatial statistics described terms second order properties computational convenience interpret gaussian model pr exp gamma gamma gamma gamma jkj gaussian interpretation terribly significant keep pixel pixel support map showing actual occupancy 
define support map blob ae aggregate support map blob models represents segmentation image classes 
representations computer vision signal analysis including superquadrics modal analysis eigenvector representations blobs represent global aspects shape augmented higherorder statistics attain detail data supports 
reduction degrees freedom individual pixels blob parameters form regularization allows ill conditioned problem solved principled stable way 
blob spatial color component 
color expressed yuv color space 
additionally motion texture measurements part blob descriptions current hardware restricted position color 
different semantics spatial color distributions assumed independent 
block diagonal uncoupled spatial spectral components 
blob detailed representation shape appearance modeled differences underlying blob statistics 
ability efficiently compute compact representations people appearance useful low bandwidth applications 
statistics blob recursively updated combine information contained image knowledge contained current class statistics priors 
modeling scene assume majority time pfinder processing scene consists relatively static situation office single moving person 
consequently appropriate different types model scene person 
model scene surrounding human texture surface point texture surface associated mean color value distribution mean 
color distribution pixel modeled gaussian described full covariance matrix 
instance white curtain front black wall color covariance elongated luminance direction narrow chrominance directions 
define mean point texture surface covariance point distribution 
spatial position point treated implicitly particular image pixel location need consider color mean covariance corresponding texture location 
scene texture map considered class zero 
key outputs pfinder indication scene pixels occluded human visible 
information critical low bandwidth coding video graphics compositing required augmented reality applications 
frame visible pixels statistics recursively updated simple adaptive filter 
gamma ff gamma allows compensate changes lighting object movement 
instance person moves book causes texture map change locations book tracking person know areas changed part texture model update statistics new value 
updating process done recursively large changes illumination substantially compensated seconds 
analysis loop person model scene model acquire new image interpret update scene person models 
accomplish steps predict appearance user new image current state model image pixel blob model calculate likelihood pixel member blob resolve pixel pixel likelihoods support map update statistical models blob models 
steps described detail 
step update spatial model associated blob blob dynamic model yield blob predicted spatial distribution current image njn gamma phi gamma gamma jn gamma estimated state vector includes blob position velocity observations mean spatial coordinates blob current image filter kalman gain matrix assuming simple newtonian dynamics 
image pixel measure likelihood member blob models scene model 
pixel new image define vector 
class blob corresponding point scene texture model measure log likelihood gamma gamma gamma gamma gamma ln jk gamma ln self shadowing cast shadows particular difficulty measuring membership likelihoods approach sufficient compensate shadowing 
observe pixel significantly brighter larger component predicted class statistics need consider possibility shadowing 
case pixel darker potential shadow 
pixel darker class statistics indicate normalize chrominance information brightness normalization removes effect changes amount illumination 
common office environment step produce stable chrominance measure despite shadowing 
log likelihood computation gamma gamma gamma gamma gamma ln jk gamma ln image pixel location mean class corresponding covariance 
step resolve class membership likelihoods pixel support maps indicating pixel part blobs scene 
spatial priors connectivity constraints accomplish resolution 
individual pixels assigned particular classes scene texture class foreground blob 
classification decision pixel comparing computed class membership likelihoods choosing best map sense argmax connectivity constraints enforced iterative morphological growing single central point produce single region guaranteed connected see 
step morphologically grow foreground region mixture density comprised blob classes 
defines single connected region corresponding parts user 
individual blobs morphologically grown constraint remain confined foreground region 
morphological grow operation results set connected blobs fill foreground region 
boundaries blobs quite due misclassification individual pixels interior 
simple markov priors smooth scene class likelihoods 
resolved support map update statistical models blob scene texture model 
comparing new model parameters previous model parameters update dynamic models blobs 
class pixels marked members class estimate new model mean second order statistics estimate model covariance matrix gamma gamma process simplified re writing form conducive iterative calculation 
term built examples mean subtracted known gamma gamma yy gamma computational efficiency color models built different color spaces standard space brightness normalized color space 
errors classification feature tracking lead instability model 
way ensure model remains valid reconcile individual blob models domain specific prior knowledge 
instance parameters color person hand expected stable stay fairly close prior distribution expected stable weak priors shirt color expected change quickly weak priors hand position 
intelligently chosen prior knowledge turn class solid feature tracker 
instance classes intended follow flesh candidates assertive prior knowledge people normalized skin color surprisingly constant different skin levels radiation damage 
initialization pfinder initialization process consists primarily building representations person surrounding scene 
builds scene model observing scene people human enters scene begins build model person 
person model built detecting large change scene building multi blob model user time 
model building process driven distribution color person body blobs added account differently colored region 
typically separate blobs required person hands head feet shirt pants 
process building blob model guided contour shape analysis recognizes silhouettes body parts reliably labeled 
instance user faces camera extends arms refer star fish configuration reliably determine image location head hands feet 
user points reliably determine location head hand feet 
locations integrated blob model building process prior probabilities blob creation tracking 
instance face hand image positions identified set strong prior probability skin colored blobs 
subsections describe blob model building process greater detail 
learning scene system attempts locate people scene learn scene 
accomplish pfinder begins acquiring sequence video frames contain person 
typically sequence relatively long second order obtain estimate color covariance associated image pixel 
computational efficiency color models built standard brightness normalized color spaces 
detect person scene modeled pfinder watches large deviations model 
new pixel values compared known scene measuring mahalanobis distance color space class appropriate location scene model equation 
changed region image sufficient size rule unusual camera noise pfinder proceeds analyze region detail begins build blob model person 
building person model initialize blob models pfinder uses contour shape analysis attempts identify head hands feet locations 
contour analysis identify locations new blob created placed location 
hand face locations blobs strong flesh colored color priors 
blobs initialized cover clothing regions 
blobs introduced contour analysis compete blobs describe data 
blob find data describe hand foot occluded deleted person model 
hand foot reappears new blob created contour process normal case color splitting process 
deletion addition process pfinder robust occlusions dark shadows 
hand reappears occluded shadowed normally frames video go person model accurate complete 
blob models contour analyzer produce features head hands feet different failure modes 
contour analysis find features single frame exist results tend noisy 
class analysis produces accurate results track features contour depends stability underlying models continuity underlying features occlusion 
stage model building involves reconciliation modes 
feature pfinder heuristically rates validity signal mode 
signals blended prior probabilities derived ratings 
allows color trackers track hands front body hands produce evidence contour 
class models lost due occlusion rapid motion contour tracker dominate set feature positions re acquired contour 
limitations pfinder explicitly employs domain specific assumptions vision task tractable 
assumptions break system degrades specific ways 
due nature pfinder structure model user fairly weak system degrades gracefully recovers frames assumption holds 
pfinder expects scene significantly dynamic user 
pfinder ability compensate small gradual changes scene lighting compensate large sudden changes scene 
changes occur mistakenly considered part foreground region test hand arm translation pixels pixels rel rel rotation theta degrees degrees rel rel table pfinder estimation performance attempt explain user model 
limitation related dynamic scene problem system expects user space 
multiple users don cause problems low level segmentation blob tracking algorithms cause significant difficulties gesture recognition system attempts explain blob model single human 
performance find rms errors pfinder tracking order pixels shown table 
term hand refers region approximately wrist fingers 
arm extends elbow fingers 
translation tests user moves environment holding straight guide 
relative error ratio rms error total path length 
rotation error test user moves cycles approximately degree rotation 
guide test path rotation absolute extent directly measure error 
settle measuring noise data 
rms distance low pass filtered version data provides measure 
applications interesting full implications realtime human tracking concrete information create interactive application 
pfinder explore different human interface applications 
modular interface pfinder provides modular interface allows client applications request subsets information pfinder provides 
wide range data exported pfinder interface blob model statistics polygon representation support map video texture bounding box alpha map semantically labeled features head right hand static gestures standing sitting pointing 
gesture control alive survive applications desirable interface controlled gesture keyboard mouse 
application artificial life ive alive system 
alive utilizes pfinder support map polygon define alpha values video compositing placing user scene artificial life forms real time 
pfinder gesture tags feature positions artificial life forms decisions interact user illustrated fig 

pfinder output simpler direct manner 
position user configuration user mapped control space sounds user change operating mode 
allows user control application body directly 
interface navigate virtual game environment survive simulated urban recreational violence ive illustrated fig 

recognition american sign language interesting application attends spatial statistics blobs associated users hands 
starner pentland blob representation hidden markov modeling interpret word subset american sign language asl 
approach able produce real time asl interpreter sign recognition accuracy 
thad starner shown system fig 

avatars telepresence pfinder estimates user head hands feet position possible create convincing shared virtual spaces 
alive system instance places user particular place virtual room populated virtual occupants compositing real time computer graphics live video 
convincing world video placed correctly environment video person able occlude occluded graphics 
high level description user suitable low bandwidth telepresence applications 
remote information user head hand feet position drive video avatar represents user scene 
avatar illustrated fig 

important note avatars need accurate representation user human 
hardware pfinder implemented sgi architecture vl video library interface 
typical frame rate sixteenth resolution pixel frames hz mhz processor indy vino video 
input single ccd color camera 
provides video signal sgi 
pfinder demonstrates utility stochastic regionbased features real time image understanding 
approach allows meaningful interactive rate interpretation human form custom hardware 
technique stable support real applications higher order vision techniques 
azarbayejani pentland 
recursive estimation motion structure focal length 
ieee trans 
pattern analysis machine intelligence june 
baumberg hogg 
efficient method contour tracking active shape models 
proceeding workshop motion nonrigid articulated objects 
ieee computer society 
martin bichsel 
segmenting simply connected moving objects static scene 
pattern analysis machine intelligence nov 
darrell pentland 
cooperative robust estimation layers support 
ieee trans 
pattern analysis machine intelligence may 
trevor darrell bruce blumberg sharon daniel brad rhodes pattie maes alex pentland 
alive dreams illusions 
acm siggraph computer graphics visual proceedings july 
willis davis ellis 
source book gestalt psychology 
harcourt brace new york 
gavrila davis 
modelbased tracking recognition human movement multi view approach 
international workshop automatic face gesture recognition 
ieee computer society 
zurich 
pentland thomas 
blob unsupervised clustering approach spatial preprocessing mss imagery 
th int symposium remote sensing environment ann arbor mi april 
pattie maes bruce blumberg trevor darrell alex pentland 
alive system full body interaction animated autonomous agents 
acm multimedia systems 
chris wren playing bruce blumberg virtual dog alive space playing survive 
real time reading american sign language thad starner doing signing trevor darrell demonstrating vision driven avatars 
mann picard 
video orbits characterizing coordinate transformation images projective group 
ieee image proc 
appear 
metaxas terzopoulos 
shape non rigid motion estimation physics synthesis 
ieee trans 
pattern analysis machine intelligence 
pentland horowitz 
recovery nonrigid motion structure 
ieee trans 
pattern analysis machine intelligence july 
alex pentland 
classification clustering 
proceedings symposium machine processing remotely sensed data 
ieee ieee computer society press june 
rehg kanade 
visual tracking high dof articulated structures application human hand tracking 
european conference computer vision pages 
rohr 
model recognition human movements image sequences 
cvgip image understanding jan 
sawhney ayer 
compact representations videos dominant multiple motion estimation 
ieee transactions pattern analysis machine intelligence 
thad starner alex pentland 
real time american sign language recognition video hidden markov models 
proceedings international symposium computer vision coral fl usa 
ieee computer society press 
wren sparacino azarbayejani darrell starner chao russell pentland perceptive spaces entertainment untethered interaction computer vision audition 
applied artificial intelligence june 
