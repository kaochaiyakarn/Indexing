compression sparse matrices achieving minimal table size proceedings algorithms experiments alex trento italy feb battiti bertossi eds 
pp 
compression sparse matrices achieving minimal table size nicola institute theoretical computer science eth zentrum zurich switzerland mail inf ethz ch bernhard institute theoretical computer science eth zentrum zurich switzerland mail inf ethz ch klaus simon institute theoretical computer science eth zentrum zurich switzerland mail simon inf ethz ch consider simple method compress sparse theta random matrix table size works expected linear time 
worst case time access entries compressed table 
compression scheme random greedy algorithm places row matrix nonzero entries table size minimal table size achieved high probability 
case failure table extended 
experimental results show algorithm efficient small inputs 
compression sparse matrix related fundamental problems computer science storing efficiently data structures tries computing perfect hash functions 
problem theta matrix nonzero entries want store nonzero entries table size 
entry accessible compressed data structure constant worst case time 
tarjan yao proposed method matrix compressed table size worst case 
steps needed 
matrix mapped table size log log 
storage reduced exploiting bit representation data 
construction deterministic requires quadratic worst case running time 
method difficult implement 
ziegler proposed simpler method improved chang 
experimental results show compression efficient general 
method hard analyze theoretically 
consider similar random compression scheme efficient analyzed theoretically 
study asymptotic behavior show experimentally works part supported project 
compression sparse matrices achieving minimal table size rd example compression 
rows input matrix left shifted circularly row displacement rd column contains nonzero entry rows overlapping 
entry column stored 
small input sizes 
assume matrix contains exactly nonzero entries distributed random 
case compress matrix circular table size high probability 
algorithm works linear expected time requires additional array size compression table minimal size fails add new block size expected size remains delta 
method extended compress matrix nonzero entries table linear expected size 
rest organized follows 
section algorithmic idea compression scheme 
analyze average behavior section 
section give experimental results compare performance compression schemes 
algorithm section consider problem compressing theta random matrix nonzero entries table size worst case access time item compressed data structure constant 
divide rows classes say set contains rows nonzero entry ones 
initially table empty 
map nonzero entries try place row delta position words look displacement gamma mod cf 
example 
rows critical valid value treated rows displacement row determined greedy strategy 
random values chosen condition satisfied possibilities tried 
valid displacement nonzero entries delta stored gamma mod stored array rd valid displacement exists compression fails 
compression successful rd mod compression sparse matrices achieving minimal table size note entry corresponding row number stored recover entries 
minimal compression fails continue adding new blocks table needed 
case rd div block delta rd mod offset section see matrix compressed table minimal size consists block elements high probability 
algorithm extended random matrices nonzero entries 
number blocks correspondingly increased 
analysis analysis assume nonzero entries matrix uniformly distributed possible positions 
time row placed assume nonzero entries uniformly distributed table 
construction nonzero entries uniformly distributed 
algorithm tends avoid repetitions periodicities substructures table 
consider bit string string shifted displacement 
average number bits common lower compared uniformly distributed string 
advantage rows placed price arbitrary row placed fewer positions 
informal argument justifies assumption 
consider variant algorithm 
choosing displacement row random possible values choose displacements independent previous ones 
displacements row delta independent gamma mod mod row shifted shifted overlapping nonzero entries 
furthermore row contains nonzero entries trials note row independent displacements 
way probability row placed uniformly distributed table depends number nonzero entries row table position corresponding nonzero entries 
proposition random matrix containing nonzero entries stored table size high probability 
worst case access time additional array size entry needed 
proof 
probability compression successful depends essentially parameters ffl density table step ffl density row placed 
consider moment try place row critical case compression 
number zeros greater number rows having exactly nonzero entry delta delta gamma gamma gamma delta gamma delta delta high probability 
compression sparse matrices achieving minimal table size expected number rows containing nonzero entries delta gamma delta delta gamma gamma gammai delta gamma delta delta 



approaches ff delta log log log ff 
follows maximal number nonzero entries row bounded logn log log high probability 
probability row placed bn positions denotes number nonzero entries 
gamma delta delta gamma gammak gammaj delta gamma delta delta gamma gammak gammaj consider arbitrary position 
row placed entries row collide nonzero entries kg 
happens probability gamma delta delta gamma gammak gammaj delta gamma delta positions independent trial corresponds experiment table size gamma gamma nonzero entries 
shows equation holds 
gamma gammak gammaj gamma gammak gamma difficult place row dense table higher 
equation infer gamma delta delta gamma gammak gammaj delta gamma delta gamma gammak gamma gammak gamma gamma gamma gammaj deltak gammaj delta gamma gamma gamma deltak gammaj delta due gamma gamma gamma gammak delta gamma delta gamma gamma gamma delta gamma gammak gamma delta gamma gamma gamma delta gamma gamma gamma delta delta delta delta obtain gamma gamma gamma log log log log def gamma delta gamma def high probability sufficiently large 
conditions probability row placed bounded gamma delta logn gamma delta delta log gamma gamma probability compression fails delta gamma gamma compression sparse matrices achieving minimal table size proposition derive algorithm compress matrix linear expected space 
proposition random theta matrix nonzero entries compressed table expected size delta 
proof 
proposition observations 
firstly probability equals gamma log log log secondly chebychev inequality implies gamma delta probability gamma 
size table bounded worst case 
consider rows nonzero entries 
number bounded require table size delta rows placed table size delta 
assume row contains entries 
try place rows 
table contains gamma nonzero entries 
row placed position nonzero entries collide maximal number positions excluded gamma delta position row placed 
size table worst case cf 

implies expected size table delta gamma gamma delta gamma delta proposition compression done linear expected time 
proof 
recall execute independent trials place row determine row displacement 
independent trials associated dependent experiments 
follows independent trial successful probability gammao large 
corresponding expected number trials delta trial test entries 
probability row contains nonzero entries obtain comparisons delta delta delta 
assuming rows stored list fm expected running time place rows 
large omega gamma compare entries 
happens probability gamma 
place non critical rows time simply filling remaining gaps compression scheme works linear expected time 
experimental results previous section analyzed algorithm asymptotically 
seen theta random matrix nonzero entries compressed table size high probability 
analysis pessimistic holds sufficiently large values compression sparse matrices achieving minimal table size probability success experimental results upper curve compared gamma gamma 
number comparisons needed compression lower curve compared delta 
section show compression works realistic values 
probability compression fail compared gamma gamma curve result simulation point random matrices generated compressed 
expected running time number tested entries compared curve delta point average compressions 
shows algorithm works practice 
improvements possible 
instance sorting rows significantly increases success rate 
effective sorting strategy place rows maximal number nonzero entries cf 

note compression optimal experiments executed point 
similar compression scheme fit method consists trying place rows non circular table choosing displacement deterministically gammas gamma gamma position nonzero entry row 
experimental results show nonzero entries placed entries table 
remaining nonzero entries increase table size 
average size tables generated fit method compared circular blocks 
rows sorted decreasing order number nonzero entries 
seen sparse random matrix compressed simple algorithm table small size 
general considered method helps understand compression schemes sparse matrices extremely practice 
compression matrix nonzero entries improved randomizing input minimal compression fails mapped new matrix permuting nonzero entries 
done linear expected time technique proposed 
worst case access time remains constant additional storage needed 
points analysis remain open 
particular theoretical study distribution table step missing 
compression sparse matrices achieving minimal table size probability success sorted upper curve compared corresponding probability unsorted 
average table size firstfit method upper curve circular blocks lower curve 
rows maximal density placed 
alon spencer erdos probabilistic method john wiley sons 

chang improvement ziegler sparse matrix compression algorithm journal systems software 

chang 
wu letter oriented perfect hashing scheme sparse table compression software practice experience 
dietzfelbinger dynamic perfect hashing upper lower bounds siam jour 
comp 
fredman storing sparse table worst case access time journal acm 
mehlhorn data structures algorithms sorting searching springer 
tarjan yao storing sparse table communications acm 
ziegler small fast table driven parser madison academic computing center univ wisconsin madison wisconsin 
