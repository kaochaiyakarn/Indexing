scheduling parallel applications distributed networks jon weissman xin zhao division computer science university texas san antonio san antonio tx jon cs edu prophet run time scheduling system designed support efficient execution parallel applications written mentat programming language 
prior results demonstrated spmd applications scheduled automatically ethernet local area workstation network performance 
describes efforts extend prophet dimensions improved overhead control greater resource sharing greater resource heterogeneity wide area scheduling new application types 
show spmd task parallel applications scheduled effectively shared heterogeneous lan environment containing ethernet atm networks exploiting application structure dynamic run time information 
scheduling parallel applications distributed networks complex problem requires coordinated effort scheduling system applications programmer 
complexity arises distinguishing features network environment distribution resources multiple networks heterogeneity network resources sharing network resources 

partially funded nsf asc 
dynamic nature network environment suggests compiler solution scheduling problem adequate 
similarly run time system schedulers operating system schedulers assumptions inappropriate parallel applications 
example adaptive load sharing common system level scheduling technique assumes tasks uniform independent 
approaches typically exploit structure parallel applications heterogeneity system resources 
example individual application tasks scheduled regard communication relationships lead high communication overhead 
third option leave scheduling hands programmer providing access low level scheduling api 
believe option restrict network parallel processing expert parallel programmer 
middle ground solution provide automated run time scheduling programmer provided application information 
system called prophet developed objectives 
prophet supports execution spmd applications heterogeneous workstation networks 
selects best cpu network resources allocate application decomposes application selected resources exploits structure spmd applications produce high quality scheduling decisions 
unique features prophet run time granularity information select best number processors apply application 
prophet scheduling cost driven cost models constructed programmer provided application information 
prophet integrated mentat object oriented parallel processing system developed university virginia significantly improved scheduling quality spmd mentat programs native mentat scheduler ethernet network environment 
previously prophet limited spmd applications local area ethernet networks supports atm wide area networks application types including task parallel pipelines pp 
prophet overhead manageable applications way guarantee acceptable overhead 
system overhead aware provides better control run time scheduling overhead 
prophet assumed limited sharing cpus networks supports highly shared networks 
experimental results indicate spmd pp applications scheduled effectively prophet produce reduced completion time small overhead 
results obtained highly shared heterogeneous lan environment containing ethernet atm subnetworks 
prophet utilizes dynamic system information level cpu network sharing produce high quality scheduling decisions 
results encouraging provide evidence run time scheduling support effectively provided large useful class parallel applications heterogeneous network environment 
research projects investigating problem scheduling parallel applications shared heterogeneous networks 
dataparallel system provides scheduling dynamic load balancing data parallel applications 
advantage approach programmer need insert scheduling directives provide application information 
dataparallel system limited scheduling regular spmd applications written dataparallel broadly applicable 
interesting approach apples application level scheduling system 
apples approach recognizes applications require special purpose tuned schedulers achieve best possible performance 
apples scheduling agent responsible scheduling tightly coupled application 
apples approach general requires programmer write scheduling agent may complex task 
prophet provides scheduling capability decoupled application automated user dataparallel limited partic ular application type 
prophet application aware achieve best performance application 
organized follows 
section reviews prophet architecture key features 
section describes extensions prophet 
section presents performance results obtained scheduling applications heterogeneous lan environment prophet 
section presents summary 
prophet overview prophet utilizes cost driven method scheduling spmd applications heterogeneous workstation networks 
scheduling spmd applications consists parts partitioning placement 
partitioning application decomposed set heterogeneous processors 
number processors selected depends computation granularity application large computation granularity may benefit large number processors relative smaller 
processor selection depends granularity supported network resources 
faster network atm vs ethernet may allow greater parallelism exploited 
placement task placed selected processor assigned piece data domain 
tasks assigned specific processors reduce communication overhead spmd scheduling 
application decomposed set data regions shaded rectangles assigned task circle placed processor square 
example tasks arranged communication topology 
induced routing contention 
spmd model tasks identical parameterized compute data region 
data domain decomposed give load balance tasks heterogeneous processors portion data domain proportional power processor 
prophet exploits information spmd application network resources order scheduling decisions 
network resources organized processor clusters 
processor clusters contain computers separate subnetworks communication bandwidth shared cluster clusters 
prophet uses cluster information help guide scheduling decisions cluster latency bandwidth topology specific communication cost functions number type processors aggregate processing power 
parameters reflect peak cluster performance 
information spmd application provided application callbacks 
functions provide important information computation communication structure application 
callbacks point stencil application depicted arch cost callback omitted cycles undefined 
computation callbacks pdu primitive data unit smallest piece data domain application 
example pdu row grid stencil prophet application information resource information scheduling decision kernel prophet system architecture scheduling application 
full discussion callbacks 
scheduling process assign pdus task proportional power processor assigned 
prophet explores set candidate processor configurations apply application order minimize completion time 
details process 
idealized view relationship processor selection completion time ct depicted 
picture indicates scheduling regions 
region additional parallelism may exploited adding processors point diminishing returns reached 
point adding processors increase communication costs greater decrease computation costs 
practice function multimodal regions corresponding especially processors interconnection network network organization 
environment containing processor clusters connected ethernet atm 
topology comm complexity comp complexity arch cost sparc ultrasparc sparc callbacks 
lists callback functions 
shows callbacks point stencil shown 
topology tree ring broadcast comm complexity avg message size bytes num data elements problem comp complexity executed instructions pdu arch cost arch specific execution cost instruction pdu usec instruction cycles number iterations known heterogeneous 
objective prophet find scheduling point close minimum expending significant run time overhead 
guarantee locate minimum require prophet explore exponential number processor configurations practical 
prophet uses heuristic simulation practice yielded excellent results 
basis heuristic construction set cost functions predict application completion time ct candidate schedule different processor configurations different ct values algorithm searches configuration predicted give minimum ct average computation time spent processor task cycle iteration execution 
average cost executing pdu selected processors average communication time spent processor task iteration execution 
communication function shown spmd applications ethernet linear number processors message size comm complexity 
multiple processor clusters 
algorithm tries minimize sum comm comp number cycles required 
ct processors finding optimal scheduling point 
comp comp ct spmd comm comp comm spmd complexity comp arch cost comm eq eq eq communication cost functions combined appropriately 
form eq typical spmd applications simultaneous communication tasks processors contend network concurrently 
constants depend application communication topology determined line latency dependent constant bandwidth dependent constant 
addition scheduling process determines assignment pdus selected processors number pdus assigned task processor relative processor weight application eq 
property faster processors receive greater share data domain processors cluster receive equal share 
equations constructed callback information 
step scheduling process placement tasks processors 
comm dependent task placement placement algorithm run evaluating configuration explored prophet 
placement algorithm exploits information application topology network topology assign tasks processors communication efficient manner 
reducing communication costs achieved maintaining communication locality avoiding router crossings effectively exploiting communication bandwidth clusters 
achieved inter cluster placement objective minimize communi arch arch eq eq cation costs clusters 
achieved intra cluster placement objective minimize communication costs clusters 
intra cluster placement known mapping embedding widely studied 
algorithms forms placement topology specific 
inter cluster placement depends communication topology 
inter cluster placement strategies ring tree topologies clusters black boxes routers 
notice number router crossings communication hops minimized 
prophet extensions overhead control scheduling run time process crucial run time overhead small possible 
prophet overhead controlled exploiting knowledge application 
prophet spend time scheduling long running application better mask additional scheduling overhead 
prophet overhead exploring single processor configuration benchmarked line architecture type average prophet available scheduling algorithms 
measure include cost acquire dynamic state information cluster discussed section 
amount prophet overhead experienced ring tree inter cluster placement application constrained proportional expected sequential run time application averaged processor types seq currently prophet overhead fall estimated sequential run time application 
prophet overhead controlled limiting number processor configurations num explored scheduling seq num easily computed callbacks 
applications run longer finding high quality schedule important prophet spend greater overhead explore processor configurations 
example user prefer schedule takes minute vs minutes demand schedule takes day vs days 
desirable adjust overhead percentage function seq allow user control parameter 
option explored 
wide area scheduling prophet extended run wide area environment exploit opportunities better performance 
projects similar objectives 
heterogeneity ubiquity availability internet resources exploited locate best intra site resources user applications 
running applications multiple sites known metacomputing requires high speed networks running oc ds speeds 
small scale oc ds speed widearea networks emerging support metacomputing internet wide metacomputing practical applications current internet technology 
opportunity explored near 
num seq prophet seq comp eq eq executing application remotely prophet requires cost parameters callbacks application binaries files available remote sites 
information encapsulated mentat class called job class 
programmer writes simple front program creates job class object submits system execution 
details process 
wide area network contains set sites site organized internally 
site runs scheduling manager sm local scheduler ls process 
sm run wide area scheduling algorithm 
sm interfaces site ls sm 
ls responsible managing local site resources manner transparent sm 
ls decides resources site available wide area scheduling point time providing site autonomy 
ls contains components 
component interface sm interface site specific scheduling system prophet 
system called allows local schedulers condor developed 
job class specification persistent mentat class job class public execution parameters arg list args includes binaries files main prog class main prog main program arg list get arg list callbacks domain job domain domain get job domain wide area scheduling process contains global local phase 
global phase initiated arrival scheduling request local site sm 
sm passed job class object initiate scheduling application 
wide area scheduling algorithm distributed algorithm parts local site sm component remote site sm component 
application request arrives local site sm set candidate sites selected including local site job class object sent remote site sm bidding 
selecting candidate sites done manner 
sites closest local site terms communication performance greatest priority files binaries results scheduling control messages may transmitted local selected remote site 
communication closeness determined probing network regular intervals 
applications expensive consider available sites 
estimate scheduling overhead constrain number sites consideration 
overhead terms protocol overhead file transfer overhead event remote site selected 
overhead estimate computed measured network bandwidth latency site wide area scheduling protocol file transfer local scheduling overhead prophet 
prophet site site sm sm wide area system organization ls prophet ls internet local scheduling overhead paid sites run algorithm parallel 
communication overhead wide area scheduling protocol file transfer dominates 
number sites selected bidding constrained estimated scheduling overhead falls best execution time achieved locally 
best local execution time obtained having ls prophet generate best schedule local site 
small applications remote sites considered larger applications run longer larger number remote sites selected 
candidate set sites determined local sm contacts selected site sm start scheduling process 
sm contacts ls get list machines available 
remote sm runs local scheduling algorithm search set machines evaluate possible schedules 
current implementation sm invokes prophet evaluate schedules 
best schedule projected completion time returned local site sm 
sm locks schedule scheduling transaction complete 
best schedule smallest predicted completion time 
local sm receives bids selects best site initiates scheduling application site informs remote sites decision 
chosen site sm passes application job class object local ls execution 
point remote sm release lock best candidate schedule 
details algorithm may 
interactions various system components depicted site sm selected run application 
highly shared networks dynamic resource monitoring previously prophet scheduling process limited dynamic resource information dynamic processor load information mark processors available lightly loaded unavailable highly loaded dynamic network information available bandwidth 
reasonable lightly loaded network may lead poor scheduling decisions highly shared network 
prophet extended utilize dynamic resource information provided dynamic resource monitor 
information improve processor selection partitioning application types 
network resource monitoring system designed implemented unix network environment 
runs stand program prophet scheduling tools may utilize improve scheduling decisions 
consists daemon process drm runs computer monitor collect system state information directory process dm runs computer processor cluster 
drm runs continually writes state information database disk 
dm keeps updated table resources reside domain processor cluster cpu status virtual real memory status user logins network latency bandwidth 
resource attributes reliability determined certain resources cpus network 
unix system calls uptime finger ping provide information 
sm local site sm sm remote sites wa sched get best get best go sm go sm front wide area scheduling execution ls ls job class launch main prog class type resource modeled object encapsulates information type resource 
instance memory object contains available virtual memory space available real memory space network resource object contains latency bandwidth network type 
processor clusters multiple network interfaces atm ethernet treated distinct network resource objects 
prophet queries dm processor cluster get date information state cluster resources 
supports wide array query options including information individual resources cpu load particular machine collective information average cpu load machines processor cluster 
query specify temporal range information including past prediction example query request average load processor cluster right time yesterday past hours hours 
prediction support provided network weather service nws implemented 
supports form event notification 
mechanism client may indicate informed average load processor cluster goes threshold network bandwidth increases decreases threshold type notification useful dynamic resource monitor configuration drm drm dm drm prophet performing adaptive scheduling 
dm supports resource location services locate idle ultrasparc find user id weissman logged built directory tree dynamically scaled system scaled 
maintains knowledge system resources monitoring domain domain defined terms directory file system protection domain 
simplest domain set resources share common file system 
prophet uses information provided provide accurate scheduling adjusted reflect processor load adjusted reflect reduced bandwidth term average cpu availability percentage idle available selected processors 
reflects peak execution time scaled give true cost eq 
number pdus assigned processor change function individual cpu avail values 
term amount bandwidth available cluster percentage idle network available 
communication parameters reflect peak communication rates scale bandwidth dependent portion eq 
probable cpu load impacts comm reported model accurate average gives acceptable scheduling results 
new calculations improve processor selection data domain decom comp comm comp comp avail comm spmd complexity bw avail cpu avail arch cost cpu avail bw avail bw avail comm comp comm eq eq position 
equations sequential time estimate application seq processor weight change function cpu load parallel pipelines pipelining important source parallelism applications 
archetype example image processing pipeline 
problem number input images pumped pipeline stages overlapped execution 
speedup limited pipeline depth maximum computation time pipeline stages 
overcome performance limitation pipeline replicated run parallel 
parallel pipeline model pp model computation stage task assigned processor 
pipeline depth pipelines kn processors needed 
initial version pp support stage sequential computation 
requirement relaxed 
prophet determine appropriate number pipelines processors apply pp application placement computation tasks processors 
scheduling spmd applications need partition data domain 
inputs served ini cpu arch cpu arch seq comp cpu avail image filter image convolution edge detection images image understanding 
image processing pipeline eq eq tial stage pipelines idle 
pp applications pdu input image callback information provided 
computation stage comp complexity comm complexity callback defined 
number processors depends number inputs provided callback computation granularity stages amount communication contention parallel pipelines 
communication cost difficult determine assume simultaneous access spmd case 
pp applications stages may differ amount computation communication pipelines running asynchronously 
consequently contention harder predict 
observed contention linear number pipelines np short pipelines depends ratio computation communication pipeline 
greater ratio communications interfere 
binomial distribution model probability contention great accuracy 

larger speculate inter pipeline communication contention occur 
real applications relatively short pipeline depth 
inputs 
parallel pipelines prophet explores series processor configurations identify best schedule 
prophet constructs cost function pp application completion time candidate schedule average comp complexity comm complexity stages respectively 
average computation communication time stages respectively 
communication cost linear nc expected value number simultaneous communications 
value range number pipelines np 
probability communication pipeline issued simultaneously communication pipeline 
probability estimated percentage communication relative computation stage average 
easily computed callbacks 
binomial distribution compute expected value number simultaneous communications example stages performed communication expected value number simultaneous communications np 
binomial distribution constant probability simultaneity success failure ct pp num comm comp comp pp comp cost avail comm pp nc complexity bw avail comp complexity comm complexity comp comm nc ig np np np comm pp comm pp comp pp knnc eq eq eq eq eq pipelines issue messages asynchronously approximate independence 
communication model validated experimentally 
functions full pipelines number inputs sufficiently large fill pipelines 
pp communications rings task placement straightforward see 
tasks pipeline placed cluster 
results prophet applied prototype spmd pp applications heterogeneous lan environment 
results application class 
spmd application point stencil compute equation grid different sizes 
mentat implementation application illustrated callbacks shown 
pp application synthetic stage image processing application different filter computations specified stages 
mxm convolution mask applied input image moves pipeline pixel bytes 
mask may applied iteratively perform thinning pruning operations 
callbacks specified image dimension mask dimension stage iters number times applied num inputs number input images 
parameters specified command line arguments 
particular pp application stage communicates entire comp comm topology ring comm complexity num inputs comp complexity iters iters iters callbacks pp application input image subsequent stage pipeline 
pp applications may communicate reduced compressed input 
execution environment consists heterogeneous processor clusters separate subnetworks containing processors 
ethernet cluster containing sparc ethernet cluster containing sparc atm network containing 
processor clusters shared users 
communication mentat reliable udp communication library 
range problem instances scheduled prophet see table 
experimental results spmd pp problems shown table 
prophet schedule contains selected cluster number processors chosen cluster 
pp problem instances number multiple application uses stage pipelines 
example processors pipelines 
schedule completion time application shown prophet disables enables dynamic resource information 
predicted completion time time prophet estimates application require selected schedule shown case information enabled 
overhead time prophet takes compute schedule 
problem instances prophet opted processors single processor cluster 
larger problems low degrees sharing prophet multiple processor clusters necessary 
prophet overhead small fraction completion time problem instances 
overhead higher pp pp uses complex cost evaluation procedure 
problem granularity larger higher numbered problem instances prophet selects larger number processors problems 
smaller problems prophet explores fewer processor configurations overhead range millisecond 
prophet accurately predicts application completion time information run time state system resources 
addition prophet better scheduling decisions run time information info column speedups modest applications deal communication especially pp prophet data collected system loaded sequential time reflects execution time fastest single computer idle 
included point 
true speedup loaded machine sequential run higher 
problem instance problem parameters description pp iters images stage performs convolution applied times stage pp iters images stage performs convolution applied times stage pp iters images stage performs convolution applied times stage sten iters input grid run iterations sten iters input grid run iterations sten iters input grid run iterations table experimental problem instances table experimental results 
times shown milliseconds 
sequential time prophet overhead shown fastest machine type ultrasparc 
machine application submitted 
prophet runs submitted machine default 
sequential time estimated arch cost comp complexity callbacks idle machine 
problem instance sequential time prophet schedule completion time predicted completion time prophet overhead info info info info info pp pp pp sten sten sten experiments run variety load conditions explore benefit cpu network load information 
typically applications consume bandwidth cpu cycles run background create resource sharing 
problem instance prophet run information enabled info disabled info compare 
information enabled prophet chooses best schedule static information reflecting peak cpu network information 
information enabled prophet respond cpu network sharing produce better schedules 
pp best schedule atm connected forming pipeline unloaded 
background application run pp scheduled prophet information 
information enabled prophet opted avoid due observed reduced bandwidth computation power available chose sparc information disabled prophet chose pp granularity higher best schedule exploit additional parallelism available unloaded processors available background application run caused prophet correctly bypass favor scheduling pp 
prophet choose cpu power sparc low 
pp high granularity suggests chosen unloaded 
background application run case prophet avoided selected 
sten best schedule atm connected unloaded 
background application run case information affect prophet processor selection selected probably 
background applications instances test applications 
problem granularity fairly low impact data domain decomposition selected processors 
data distribution reflecting different processor loads prevented load imbalance 
sten best schedule background application run prophet opted sparc 
sten granularity high best schedule sparc background application run prophet opted stay contract schedule sparc 
case prophet load information provide load balanced decomposition data domain 
clearly single parallel applications prophet produced better completion times dynamic resource information processor load available network bandwidth 
benefit ranged problem instances 
related benefit prophet produce higher system throughput sets jobs 
cases prophet avoid clusters running cpu network intensive applications 
prevents newly scheduled job interfering currently running jobs providing performance benefit 
preliminary results wide area scheduling parallel applications looks promising 
prophet represents point spectrum scheduling approaches fully automated system schedulers hand tuned programmer generated schedules 
prophet demonstrates possible effectively schedule parallel applications run time shared heterogeneous lans wans limited programmer effort 
prophet exploits structure application information system resources produce reduced completion time spmd pp application types 
performance prophet superior system schedulers mentat scheduler direct comparison hand tuned programmer scheduled applications needed 
ultimate goal show performance better system schedulers applications percent highly tuned programmer scheduled applications 
prophet compared apples 
investigating applications types discover range applications scheduled automatically 
parallel application types include bag task bot combinations bot pp spmd applications 
example stages pipeline spmd computations 
suitability prophet loosely coupled distributed applications metacomputing problems open question hope answer 
lastly planning support application adaptivity re scheduling prophet 
example system resources allocated application change dramatically positively negatively application may need respond changes 
investigating provide run time support adaptivity user applications 
mechanisms performing rescheduling dynamic load balancing known 
effective policies making re scheduling decisions received little attention 
cost models predict overhead benefit re scheduling developed support process 
berman wolski scheduling perspective application proceedings fifth international symposium high performance distributed computing august 
taxonomy scheduling general purpose distributed computing systems ieee transactions software engineering vol 
february 
chandy schooler designing directories distributed systems systematic framework fifth international symposium high performance distributed computing august 
eager lazowska zahorjan adaptive load sharing homogeneous distributed systems ieee transactions software engineering vol 
may 
berman modeling effects contention performance heterogeneous applications proceedings fifth ieee international symposium high performance distributed computing august 
foster kesselman globus metacomputing infrastructure toolkit international journal supercomputing applications appear 
grimshaw easy object oriented parallel programming mentat ieee computer may 
grimshaw wulf legion vision worldwide virtual computer communications acm vol 

jain fundamentals digital image processing prentice hall publisher 
quinn data parallel programming network heterogeneous workstations proceedings ieee international symposium highperformance distributed computing sept 
software architecture virtual distributed computing environment proceedings sixth ieee international symposium high performance distributed computing august 

weissman grimshaw federated model scheduling wide area systems proceedings fifth ieee international symposium high performance distributed computing august 
weissman interference paradigm network job scheduling heterogeneous computing workshop th international parallel processing symposium ipps april 
weissman grimshaw framework partitioning parallel computations heterogeneous environments concurrency practice experience vol 
august 
weissman scheduling parallel computations heterogeneous environment ph dissertation university virginia august 
weissman grimshaw network partitioning data parallel computations proceedings third ieee international symposium high performance distributed computing august 
weissman benefits wide area computing parallel processing technical report cs september 
wolski forecasting network performance support dynamic scheduling proceedings sixth ieee international symposium high performance distributed computing 
