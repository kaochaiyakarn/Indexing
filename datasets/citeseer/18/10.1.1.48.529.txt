appears international joint conference artificial intelligence ijcai study cross validation bootstrap accuracy estimation model selection ron kohavi computer science department stanford university stanford ca 
ronnyk cs stanford edu robotics stanford edu ronnyk review accuracy estimation methods compare common methods crossvalidation bootstrap 
experimental results artificial data theoretical results restricted settings shown selecting classifier set classifiers model selection fold cross validation may better expensive cross validation 
report largescale experiment half runs naive bayes algorithm estimate effects different parameters algorithms real world datasets 
crossvalidation vary number folds folds stratified bootstrap vary number bootstrap samples 
results indicate real word datasets similar best method model selection fold stratified cross validation computation power allows folds 
emphasized claim whatsoever algorithms equivalent practice real world 
particular claim cross validation real world 
wolpert estimating accuracy classifier induced supervised learning algorithms important predict prediction accuracy choosing classifier set model selection combining classifiers wolpert 
estimating final accuracy classifier estimation method low bias low variance 
choose classifier combine classifiers absolute accuracies important willing trade bias longer version retrieved anonymous ftp stanford edu pub ronnyk long ps low variance assuming bias affects classifiers similarly estimates pessimistic 
explain assumptions different estimation methods concrete examples method fails 
known accuracy estimation correct time wolpert schaffer interested identifying method suited biases trends typical real world datasets 
results theoretical experimental shown case increasing computational cost beneficial especially relative accuracies important exact values 
example leave unbiased high variance leading unreliable estimates efron 
linear models leave cross validation model selection asymptotically inconsistent sense probability selecting model best predictive power converge total number observations approaches infinity zhang shao 
organized follows 
section describes common accuracy estimation methods ways computing confidence bounds hold assumptions 
section discusses related comparing cross validation variants bootstrap variants 
section discusses methodology underlying experiment 
results experiments section discussion important observations 
conclude summary section 
methods accuracy estimation classifier function maps unlabelled instance label internal data structures 
inducer induction algorithm builds classifier dataset 
cart breiman friedman olshen stone quinlan decision tree inducers build decision tree classifiers 
interested specific method inducing classifiers assume access dataset inducer interest 
space unlabelled instances set possible labels 
theta space labelled instances fx xng dataset possibly multiset consisting labelled instances hv yi 
classifier maps unlabelled instance label inducer maps dataset classifier notation denote label assigned unlabelled instance classifier built inducer dataset 
assume exists distribution set labelled instances dataset consists 
independently identically distributed instances 
consider equal misclassification costs loss function accuracy estimation methods easily extended loss functions 
accuracy classifier probability correctly classifying randomly selected instance acc pr randomly selected instance hv yi probability distribution instance space distribution select instances inducer training set 
finite dataset estimate performance classifier induced inducer dataset 
single accuracy estimate usually meaningless confidence interval consider approximate interval possible 
order identify weaknesses attempt identify cases estimates fail 
holdout holdout method called test sample estimation partitions data mutually exclusive subsets called training set test set holdout set 
common designate data training set remaining test set 
training set inducer induced classifier tested test set 
formally holdout set subset size holdout estimated accuracy defined acc hv dh ffi ffi 
assuming inducer accuracy increases instances seen holdout method pessimistic estimator portion data inducer training 
instances leave test set higher bias estimate fewer test set instances means confidence interval accuracy wider shown 
test instance viewed bernoulli trial correct incorrect prediction 
number correct classifications test set distributed binomially sum bernoulli trials 
reasonably large holdout sets distribution approximately normal mean acc true accuracy classifier variance acc gamma acc de laplace limit theorem pr gammaz acc gamma acc acc gamma acc fl fl th quantile point standard normal distribution 
get fl percent confidence interval determines inverts inequalities 
inversion inequalities leads quadratic equation acc roots low high confidence points delta acc sigma delta delta acc gamma delta acc equation conditioned dataset information available probability dataset taken account 
holdout estimate random number depends division training set test set 
random subsampling holdout method repeated times estimated accuracy derived averaging runs 
standard deviation estimated standard deviation accuracy estimations holdout run 
main assumption violated random subsampling independence instances test set training set 
training test set formed split original dataset represented class subset underrepresented 
demonstrate issue simulated split fisher famous iris dataset majority inducer builds classifier predicting prevalent class training set 
iris dataset describes iris plants continuous features task classify instance iris iris setosa iris iris virginica 
class label exactly third instances label instances class total instances expect prediction accuracy 
test set contain instances class prevalent training set accuracy predicted holdout method standard deviation estimated averaging 
practice dataset size finite usually smaller 
holdout method inefficient data third dataset training inducer 
cross validation leave stratification fold cross validation called rotation estimation dataset randomly split mutually exclusive subsets folds approximately equal size 
inducer trained tested times time kg trained tested cross validation estimate accuracy number correct classifications divided number instances dataset 
formally test set includes instance hv cross validation estimate accuracy hv ffi cross validation estimate random number depends division folds 
complete cross validation average gamma delta possibilities choosing instances usually expensive 
leave fold cross validation complete fold crossvalidation estimating complete fold cross validation single split data folds 
repeating cross validation multiple times different splits folds provides better monte carlo estimate complete cross validation added cost 
stratified cross validation folds stratified contain approximately proportions labels original dataset 
inducer stable dataset set perturbations induces classifiers predictions perturbed datasets 
proposition variance fold cv dataset inducer 
inducer stable perturbations caused deleting instances folds fold cross validation cross validation estimate unbiased variance estimated accuracy approximately acc cv delta gamma acc cv number instances dataset 
proof assume classifiers produced predictions estimated accuracy binomial distribution trials probability success equal accuracy classifier 
large confidence interval may computed equation equal number instances 
reality complex inducer stable large perturbations reached maximal learning capacity 
expect perturbations induced leave small classifier stable 
increase size perturbations stability hold expect stability hold fold cross validation fold cross validation stable holdout 
proposition apply resubstitution estimate requires inducer stable instances dataset 
proposition helps understand possible assumption cross validation inducer unstable particular dataset set perturbations introduced cross validation accuracy estimate unreliable 
inducer stable dataset expect reliable estimate 
corollary takes idea slightly shows result observed empirically change variance cross validation estimate number folds varied 
corollary variance cross validation dataset inducer 
inducer stable perturbations caused deleting test instances folds fold cross validation various values variance estimates 
proof variance fold cross validation proposition depend inducers inherently stable example shows take account dataset actual perturbations 
example failure leave fisher iris dataset contains instances class leading expect majority inducer accuracy 
combination dataset majority inducer unstable small perturbations performed leave 
instance deleted dataset label minority training set majority inducer predicts classes errs classifying test instance 
leave estimated accuracy majority inducer iris dataset 
folds estimated accuracy standard deviation folds giving unjustified assurance estimate stable 
example shows inherent problem crossvalidation applies just majority inducer 
information dataset label values completely random best induction algorithm predict majority 
leave dataset labels class majority inducer best possible inducer predict accuracy 
bootstrap bootstrap family introduced efron fully described efron tibshirani 
dataset size bootstrap sample created sampling instances uniformly data replacement dataset sampled replacement probability instance chosen samples gamma gamma expected number distinct instances original dataset appearing test set 
ffl accuracy estimate derived bootstrap sample training rest instances testing 
number number bootstrap samples ffl accuracy estimate bootstrap sample bootstrap estimate defined acc boot delta ffl delta acc acc resubstitution accuracy estimate full dataset accuracy training set 
variance estimate determined computing variance estimates samples 
assumptions bootstrap basically cross validation stability algorithm dataset bootstrap world closely approximate real world 
bootstrap fails give expected result classifier perfect unpruned decision tree nearest neighbor classifier dataset completely random say classes 
resubstitution accuracy ffl accuracy 
plugging bootstrap formula gets estimated accuracy far real accuracy 
bootstrap shown fail add module inducer adjust predictions 
remembers training set predictions test instance training instances adjusting predictions resubstitution accuracy change bias estimated accuracy direction want 
related experimental studies comparing different accuracy estimation methods previously done artificial small datasets 
describe efforts 
efron conducted sampling experiments compared leave cross validation variants bootstrap methods 
purpose experiments investigate related estimators offer considerably improved estimation small samples 
results indicate leave cross validation gives nearly unbiased estimates accuracy unacceptably high variability particularly small samples bootstrap performed best 
breiman 
conducted experiments cross validation decision tree pruning 
chose fold cross validation cart program claimed satisfactory choosing correct tree 
claimed difference cross validation estimates risks rules tends accurate estimates 
jain dubes chen compared performance ffl bootstrap leave cross validation nearest neighbor classifiers artificial data claimed confidence interval bootstrap estimator smaller leave 
weiss followed similar lines compared stratified cross validation bootstrap methods nearest neighbor classifiers 
results stratified fold cross validation relatively low variance superior leave 
breiman spector conducted feature subset selection experiments regression compared leave cross validation fold cross validation various stratified fold cross validation bootstrap partial cross validation discussed 
tests done artificial datasets instances 
behavior observed leave low bias rms root mean square error fold fold crossvalidation larger bias rms error models features pessimistic bias fold cross validation small samples significantly reduced samples size model selection fold cross validation better leave 
bailey elkan compared leave crossvalidation bootstrap foil inducer synthetic datasets involving boolean concepts 
observed high variability little bias leave estimates low variability large bias estimates 
weiss weiss indurkhya conducted experiments real world data determine applicability cross validation decision tree pruning 
results samples size stratified fold cross validation choose amount pruning yields unbiased trees respect optimal size 
methodology order conduct large scale experiment decided naive bayesian classifier 
algorithm quinlan descendent id builds decision trees top 
naive bayesian classifier langley iba thompson implemented mlc kohavi john long manley pfleger uses observed ratios nominal features assumes gaussian distribution continuous features 
exact details crucial interested behavior accuracy estimation methods internals induction algorithms 
underlying hypothesis spaces decision trees summary statistics naive bayes different hope induction algorithms apply induction algorithms 
target concept unknown real world concepts holdout method estimate quality cross validation bootstrap estimates 
choose set datasets looked learning curves naive bayes supervised classification datasets uc irvine repository murphy aha contained instances datasets 
felt minimum instances required testing 
true accuracies real dataset computed know target concept estimate true accuracies holdout method 
true accuracy estimates table computed random sample size computing accuracy rest dataset test set repeating times 
chose datasets wide variety domains learning curve algorithms flatten early instances 
added information dataset rand boolean features boolean random label 
dataset vehicle generalization accuracy naive bayes algorithm deteriorated instances 
similar phenomenon observed shuttle dataset 
phenomenon predicted schaffer wolpert schaffer wolpert surprised observed real world datasets 
see accuracy estimation method performs sampled instances dataset uniformly replacement created training set desired size 
ran induction algorithm training set tested classifier rest instances dataset 
repeated times points learning curve sloping 
folds cross validation samples bootstrap algorithms compared 
results discussion show experimental results discuss significance 
discussion bias estimation methods follow discussion variance 
due lack space omit graphs naive bayes algorithm behavior approximately 
bias bias method estimate parameter defined expected value minus estimated value 
unbiased estimation method method zero bias 
shows bias variance fold cross validation datasets breast cancer dataset shown 
diagrams clearly show fold cross validation pessimistically biased especially folds 
learning curves large derivative measurement point pessimism fold cross folds acc soybean vehicle rand folds acc chess hypo mushroom bias cross validation varying folds 
negative folds stands leave 
error bars confidence intervals mean 
gray regions indicate confidence intervals true accuracies 
note different ranges accuracy axis 
validation small apparent 
estimates reasonably folds folds unbiased 
stratified cross validation shown similar behavior lower pessimism 
estimated accuracy soybean fold higher fold higher vehicle fold accuracy higher fold higher 
stratification biased estimation method 
shows bias variance bootstrap accuracy estimation method 
bootstrap unbiased chess hypothyroid mushroom inducers highly biased soybean vehicle inducers rand inducers 
bias vehicle 
variance method may low bias performance accuracy estimation case may poor due high variance 
experiments formed confidence intervals standard deviation mean accuracy 
switch standard deviation population expected standard deviation single accuracy estimation run 
practice single cross validation run expected accuracy mean reported standard deviation higher factor number runs averaged experiments 
dataset 
sample size 
duplicate naive bayes attr 
total size categories instances breast cancer sigma sigma chess sigma sigma hypothyroid sigma sigma mushroom sigma sigma soybean large sigma sigma vehicle sigma sigma rand sigma sigma table true accuracy estimates datasets naive bayes classifiers chosen sample sizes 
samples acc soybean vehicle rand estimated soybean vehicle rand samples acc chess hypo mushroom bias bootstrap varying samples 
estimates mushroom hypothyroid chess extremely biased optimistically vehicle rand somewhat biased soybean 
follows figures standard deviation drawn range standard deviation 
shows standard deviations naive bayes varying number folds cross validation 
results stratified cross validation similar slightly lower variance 
shows information bootstrap 
cross validation high variance folds naive bayes 
high variance high ends leave leave files datasets 
stratification reduces variance slightly uniformly better cross validation bias variance 
folds std dev mushroom chess hypo breast vehicle soybean rand folds naive bayes std dev mushroom chess hypo breast vehicle soybean rand cross validation standard deviation accuracy population 
different line styles help differentiate curves 
summary reviewed common accuracy estimation methods including holdout cross validation bootstrap showed examples fails produce estimate 
compared approaches variety real world datasets differing characteristics 
proposition shows induction algorithm stable dataset variance crossvalidation estimates approximately independent number folds 
induction algorithms stable approximately stable 
fold cross validation moderate values reduces variance increasing bias 
decreases sample sizes get smaller variance due instability training samples std dev mushroom chess hypo breast vehicle soybean rand bootstrap standard deviation accuracy population 
sets leading increase variance 
apparent datasets categories soybean 
situations stratification help repeated runs may better approach 
results indicate stratification generally better scheme terms bias variance compared regular cross validation 
bootstrap low variance extremely large bias problems 
recommend stratified fold cross validation model selection 
acknowledgments david wolpert thorough reading interesting discussions 
wray buntine tom bylander brad efron jerry friedman rob holte george john pat langley rob tibshirani weiss helpful comments suggestions 
dan sommerfield implemented bootstrap method mlc experiments conducted mlc partly partly funded onr nsf iri iri 
bailey elkan 
estimating accuracy learned concepts proceedings international joint conference artificial intelligence morgan kaufmann publishers pp 

breiman spector 
submodel selection evaluation regression 
random case international statistical review 
breiman friedman olshen stone 
classification regression trees wadsworth international group 
efron 
estimating error rate prediction rule improvement cross validation journal american statistical association 
efron tibshirani 
bootstrap chapman hall 
jain dubes chen 
bootstrap techniques error estimation ieee transactions pattern analysis machine intelligence pami 
kohavi john long manley pfleger 
mlc machine learning library tools artificial intelligence ieee computer society press pp 

available anonymous ftp stanford edu pub ronnyk mlc ps 
langley iba thompson 
analysis bayesian classifiers proceedings tenth national conference artificial intelligence aaai press mit press pp 

murphy aha 
uci repository machine learning databases www ics uci edu mlearn mlrepository html 
quinlan 
programs machine learning morgan kaufmann los altos california 
schaffer 
conservation law generalization performance machine learning proceedings eleventh international conference morgan kaufmann pp 

shao 
linear model selection crossvalidation journal american statistical association 
weiss 
small sample error rate estimation nearest neighbor classifiers ieee transactions pattern analysis machine intelligence 
weiss indurkhya 
decision tree pruning biased optimal proceedings twelfth national conference artificial intelligence aaai press mit press pp 

wolpert 
stacked generalization neural networks 
wolpert 
training set error priori distinctions learning algorithms technical report sfi tr fe institute 
wolpert 
relationship pac statistical physics framework bayesian framework vc framework technical report santa fe institute santa fe nm 
zhang 
distributional properties model selection criteria journal american statistical association 
