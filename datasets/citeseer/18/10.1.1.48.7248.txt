stochastic simulation algorithms dynamic probabilistic networks kanazawa daphne koller stuart russell computer science division university california berkeley ca usa stochastic simulation algorithms likelihood weighting give fast accurate approximations posterior probabilities probabilistic networks methods choice large networks 
unfortunately special characteristics dynamic probabilistic networks dpns represent stochastic temporal processes mean standard simulation algorithms perform poorly 
essence simulation trials diverge reality process observed time 
simulation algorithms evidence observed time step push set trials back reality 
algorithm evidence reversal er restructures time slice dpn evidence nodes slice ancestors state variables 
second algorithm called survival fittest sampling sof set trials time step stochastic reproduction rate weighted likelihood evidence trial 
compare performance algorithm likelihood weighting original network investigate benefits combining er sof methods 
er sof combination appears maintain bounded error independent number time steps simulation 
dynamic probabilistic networks dpns dean kanazawa nicholson brady kjaerulff species belief network designed model stochastic temporal processes 
section network called time slice repre alternative terms include dynamic belief networks temporal belief networks 
sent snapshot evolving temporal process 
dpn consists sequence time slices nodes time slice connected nodes time slice nodes slice shows coarse structure generic dpn 
conditional probability tables cpts dpn include state evolution model describes transition probabilities states sensor model describes observations result state 
typically assumes cpts slice vary time 
parameters duplicated time slice network 
state evolution model sensor model percept percept percept percept percept state state state state state generic structure dynamic probabilistic network 
actual network may state sensor variables time slice 
dpns serve number purposes 
monitoring partially observable system example nicholson brady dpn track moving robots light beam sensors 
project possible evolutions observed system adding slices 
decision nodes added enable approximately rational decision making limited horizon shachter 
freeway surveillance huang controlling autonomous vehicle forbes 
concentrate dpns monitoring maintaining probability distribution possible current states world 
correct decision partially observable environment depends distribution astrom monitoring essential component embedded 
exact clustering algorithms dpns described kjaerulff 
applications clustering approach expensive exact probabilities needed 
furthermore continuous variables included dpns seldom conform structural requirements cg distributions lauritzen wermuth 
exact algorithms available 
investigated stochastic simulation algorithms provide fast approximations required probabilities arbitrary combinations discrete continuous distributions 
context dpns stochastic simulation methods attempt approximate joint distribution current state collection simulated realities describing possible evolution environment 
simplest simulation algorithm logic sampling henrion 
logic sampling stochastically instantiates network root nodes appropriate conditional distributions extend instantiation network 
logic sampling discards trials variable instantiation conflicts observed evidence ineffective dpn monitoring evidence observed temporal sequence 
likelihood weighting lw fung chang shachter peot attempts overcome general problem logic sampling 
discarding trials conflict evidence trial weighted probability assigns observed evidence 
probabilities variables interest calculated weighted average values generated population trials 
shown likelihood weighting produces unbiased estimate required probabilities 
lw algorithm adapted purposes maintaining beliefs dpn evidence arrives time shown 
notation denote evidence variables time slice denote state variables time slice number samples generated ith sample weight number time steps simulation run 
likelihood ejs denotes product individual conditional probabilities evidence sampled values parents time slice current belief calculated normalized score sample set 
likelihood weighting dpns reveals problems require special treatment 
difficulty straightforward application generates simulations simply ignore observed evidence increasingly irrelevant 
consider simple example tracking moving dot sur hand logic sampling extremely effective projection evidence observed slices 
procedure likelihood weighting loop ws loop instantiate loop add sample ws ws theta likelihood add ws score sampled values likelihood weighting algorithm 
face 
suppose state evolution model fairly weak example models motion random walk sensor fairly accurate small gaussian error 
illustrates difficulty 
samples evolved state evolution model spreading randomly surface object moves particular trajectory unrelated sample distribution 
weighting process assign extremely low weights samples disagree sensor observations 
estimated distribution dominated small number samples closest true state effective number samples diminishes rapidly time 
results large estimation errors 
occurs despite fact sensors track object error 
case traffic surveillance discovered naive application likelihood weighting results large number imaginary traffic scenes bear relation happening road 
simple monitoring problem 
object starts centre disc follows path shown solid line 
sensor observations shown crosses 
small circles show snapshot population samples generated naive application likelihood weighting 
snapshots shown 
clearly need algorithms current sensor values reposition sample population closer reality allowing evolve sensor values available 
section describes simple method evidence reversal restructuring dpn likelihood weighting desired effect 
section describes related method survival fittest uses likelihood weights prefer propagate samples shows combined evidence reversal 
section describes experimental comparison techniques naive lw 
evidence reversal long known stochastic simulation algorithms quite effective network contains evidence dagum luby 
argument show evidence network root nodes approximating probabilities rest network computationally tractable 
explains appeal logic sampling projection directly applicable monitoring problem evidence obtained time slice 
force evidence root nodes network simply reversing arcs shachter transformations doing slice dpn results exponential blowup 
compromise judiciously selected arc reversals suggested fung chang 
specific case dpns take advantage fact sample instantiates variables time slice gamma separates preceding time slices state time simply reverse arcs slice evidence state gamma parents state time shown schematic form 
percept state state percept state state schematic diagram evidence reversal transformation dbns 
process follows 
time slice number fully specified states weights 

reverse arcs evidence state time state variables time gamma parents evidence time 
evidence time adjust weights samples time gamma standard likelihood weighting 

propagate sample time gamma modified state evolution model uses evidence time obtained arc reversed time slice 
er current evidence parent current state influence process extending samples state variables particular tracking example shown samples stay closely clustered observed position object accurate sensor readings dominate weak state evolution model conditional distribution generating new samples 
survival fittest problem naive application sampling algorithms viewed resource allocation 
samples constrained resource allocated state space try fit actual joint distribution possible 
samples totally imaginary scenarios propagated contribute estimation desired probabilities 
idea survival fittest sof sampling preferentially propagate forward time samples high likelihood observed evidence 
sof process keeps fixed number samples generates sample population time slice weighted random selection samples time gamma weight likelihood evidence observed time idea closely related fitness related propagation genetic algorithms sample repositioning method randomized go winners algorithms aldous vazirani 
sof approach understood slice likelihood weighting process 
samples provide approximation joint probability distribution entire network propagate belief state joint probability distribution state time slice 
precisely weighted samples time gamma approximation belief state time gamma 
approximate belief state starting point sampling time slice 
sample state weight defined current likelihood weighted samples 
samples turn weighted evidence time provide approximation belief state time note probability sampling state time just likelihood evidence time accumulated likelihood evidence including time case standard likelihood weighting 
sample population time gamma sof reflects evidence time gamma process preferential propagation 
algorithm shown 
sof clearly provides improvement likelihood weighting general take advantage sensor values quite way er 
context tracking problem sof multiply samples closest actual track entire population consists reasonable samples spread entire surface 
samples spread procedure sof loop instantiate loop add sample ws likelihood add ws score sampled values sample set randomized selection weighted ws survival fittest algorithm 
amount related uncertainty state evolution model regardless accurate sensor model fortunately advantages provided er sof combined er sof hybrid simply applying sof er sampling process 
propagating slice gamma samples step er algorithm sof technique focus ones 
sample distribution obtained step er algorithm propagate modified state evolution model 
empirical results section report simple experiments carried confirm intuitive ideas 
network experiments topology network shown 
aim investigate problem sample population divergence time show er sof mitigate problem 
measure average absolute error marginal probabilities state variables time slice function axis measures time simulated environment 
shows error behaviour lw time steps samples averaged randomly generated sets evidence 
results clearly show lw fails dramatically simple network 
problem sample propagated time sooner sample state value observed evidence impossible state value network observation values possible 
sufficiently steps samples weight point assign error 
steps samples samples extinguished cases 
multiplying number samples delays inevitable small number steps 
shows corresponding error behaviour er 
note scale axis increased 
error remains acceptable currently working generate similar experimental data traffic surveillance networks 
avg absolute error time step samples samples samples samples performance lw graph showing average absolute error marginal probabilities state variables time slice function averaged randomly generated evidence cases 
range 
show slow increase time 
possible error asymptotes run experiments 
avg absolute error time step samples samples samples samples performance er graph showing average absolute error marginal probabilities state variables time slice function averaged randomly generated evidence cases 
figures show performance sof er sof compared er samples respectively 
results show sof effective mechanism maintaining bounded error time 
sof shows somewhat higher error er expect combination er sof shows low error time steps shows sign diverging 
shows performance er sof er sof function number samples range samples 
graph gives average absolute error marginal probabilities state variable 
graphs show sof benefit additional samples er fact curve flat 
currently theoretical analysis algorithm sufficiently advanced explain phenomenon 
avg absolute error time step er sof er sof performance er sof er sof graph showing average absolute error marginal probabilities state variables time slice function averaged randomly generated evidence cases samples 
avg absolute error time step er sof er sof performance er sof er sof graph showing average absolute error marginal probabilities state variables time slice function averaged randomly generated evidence cases samples 
avg absolute error time step er sof er sof performance er sof er sof graph showing average absolute error marginal probabilities state variables time slice function averaged randomly generated evidence cases samples 
avg absolute error time step er sof er sof performance er sof er sof function number fo samples graph showing average absolute error marginal probabilities state variables time slice averaged randomly generated evidence cases 
simple intuitive improvements likelihood weighting technique effective dynamic probabilistic networks 
early experimental results confirm intuitions 
particular error sof er sof independent number time steps simulation 
absolute requirement monitoring applications traffic surveillance inference continues days real time 
needs done establish theoretical properties algorithms 
obvious issue approaches unbiased converge right answer number samples grows infinity 
er clearly unbiased just application likelihood weighting modified network structure 
fairly straightforward show sof er sof converge correct values large sample limit standard probabilistic techniques 
investigate expected error function sample size lw er sof er sof 
fairly simple specific network structures shown 
understanding algorithms behaviour general dpns difficult 
intuitively improvement er sof pronounced cases evidence gives lot information state 
extreme sensor model completely accurate er completely accurate single sample 
behavior sof circumstances depend behavior state evolution model 
fairly behaved appears sof 
extreme sensor model just noise approach provide advantage lw 
hope analyze improvement algorithms quantities distance terms relative entropy belief state distribution time time amount information terms entropy obtained considering sensors 
sof technique applied arbitrary networks just dpns 
interesting see provides consistently better results lw general networks 
lw currently best algorithm known large networks useful development 
david aldous umesh vazirani 
go winners algorithms 
proceedings th annual symposium foundations computer science pages santa fe new mexico november 
ieee computer society press 
astrom 
optimal control markov decision processes incomplete state estimation 
math 
anal 
applic 
dagum luby 
approximating probabilistic inference bayesian belief networks np hard 
artificial intelligence march 
thomas dean kanazawa 
model reasoning persistence causation 
computational intelligence 
jeff forbes tim huang kanazawa stuart russell 
bayesian automated taxi 
submitted ijcai 
fung chang 
weighting integrating evidence stochastic simulation bayesian networks 
proceedings fifth conference uncertainty artificial intelligence uai windsor ontario 
morgan kaufmann 
max henrion 
propagation uncertainty bayesian networks probabilistic logic sampling 
john lemmer kanal editors uncertainty artificial intelligence pages 
elsevier north holland amsterdam london new york 
huang koller malik rao russell weber 
automatic symbolic traffic scene analysis belief networks 
proceedings twelfth national conference artificial intelligence aaai seattle washington 
aaai press 
kjaerulff 
computational scheme reasoning dynamic probabilistic networks 
proceedings eighth conference uncertainty artificial intelligence pages 
lauritzen wermuth 
graphical models associations variables qualitative quantitative 
annals statistics 
nicholson brady 
data association problem monitoring robot vehicles dynamic belief networks 
ecai th european conference artificial intelligence proceedings pages vienna austria august 
wiley 
shachter peot 
simulation approaches general probabilistic inference belief networks 
proceedings fifth conference uncertainty artificial intelligence uai windsor ontario 
morgan kaufmann 
ross shachter 
evaluating influence diagrams 
operations research 
shachter 
dynamic programming influence diagrams 
ieee transactions systems man cybernetics march april 
