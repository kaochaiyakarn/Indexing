survey multiprocessor operating system kernels draft mukherjee bodhi cc gatech edu karsten schwan schwan cc gatech edu gopinath gopinath honeywell com git cc november multiprocessors accepted vehicles improved computing speeds cost performance enhanced reliability availability 
added performance requirements user programs functional capabilities parallel hardware introduce new challenges operating system design implementation 
reviews research commercial developments multiprocessor operating system kernels late early 
discusses common operating system structuring techniques examines advantages disadvantages technique 
identifies major design goals key issues multiprocessor operating systems 
issues solution approaches illustrated review variety research commercial multiprocessor operating system kernels 
college computing georgia institute technology atlanta georgia contents structuring operating system monolithic systems capability systems message passing systems language mechanisms object oriented object supporting operating systems vertical horizontal organizations micro kernel operating systems application specific operating systems design issues processor management scheduling heavyweight processes lightweight threads scheduler structures scheduling policies memory management shared virtual memory numa norma memory management synchronization locks synchronization constructs interprocess communication basic communication primitives remote procedure calls object invocations shared distributed memory machines sample multiprocessor operating system kernels hydra execution environment processes objects protection hydra parallel computing staros task forces synchronization communication scheduling reconfiguration mach memory management interprocess communication scheduling mach micro kernel objects processes synchronization interprocess communication psyche synchronization memory management scheduling presto customization ktk choices tasks threads interprocess communication memory management persistent objects exception handling renaissance process management synchronization process management scheduling synchronization memory management umax process management scheduling synchronization memory management process management scheduling memory management synchronization rp process management scheduling memory management operating systems distributed memory machines ii iii parallel processing premier approach increasing computational power modern supercomputers part driven large scale scientific engineering applications weather prediction materials process modeling require computing speeds terabytes rapidly accessible primary secondary storage 
important hpcc applications named commercial motivations development parallel machines include improved machine cost performance scalability different application requirements enhanced reliability availability 
purpose survey review major concepts operating systems parallel machines roughly reflecting state art early 
importantly identify main research issues addressed operating system multiprocessor machine review resulting solution approaches taken variety commercial research systems constructed decade 
apparent reader finishing solution approaches applied parallel distributed target hardware 
convergence technologies originally developed parallel vs distributed systems partially divergent technical communities discussed different terminologies driven technological developments multiprocessor engines scaled hundreds processors appear distributed sets machines distributed machines linked high performance networks especially local area networks network devices derived current atm supercomputer routing technologies increasingly parallel computing engines 
self imposed limitation survey focus performance reliability parallel systems 
reliable systems surveyed articles including 
second limitation survey treatment operating system kernels operating systems neglecting system functionalities file systems database support network protocols 
focus reflects unfortunate lack attention paid issues previous operating research projects commercial systems 
rapidly correcting deficiencies 
includes industry efforts offer concurrent file system support concurrent databases parallel machines communication protocols high performance parallel machines research efforts addressing efficient file management parallel machines 
motivated intended parallel machines commercial large scale data processing upcoming programs nasa eos satellites generate terabytes data processed re processed earth science applications motivated convergence high performance computing networking technologies resulting large scale physically distributed heterogeneous parallel machines 
brief survey multiprocessor hardware 
current textbooks parallel computing provide overviews parallel machine architectures 
purposes briefly review major types parallel machines eliding architectures simd programs functional programs systolic applications 
depending coupling processors memory multiprocessors may broadly divided major categories ffl shared memory multiprocessors 
shared memory multiprocessor main memory accessible shared processors shown 
shared memory dn connect processor disks processors memory modules pn mn interconnect processor memory multiprocessor architectures multiprocessors classified basis cost accessing shared memory 
uniform memory access uma multiprocessors 
uma architecture access time shared memory processors 
sample uma architecture bus architecture sequent multiprocessor common bus links memory modules computing modules consisting cache shared processor elements devices attached directly bus 

non uniform memory access numa multiprocessors 
numa architecture physical memory system partitioned modules local associated specific processor 
result access time local memory nonlocal memory 
sample numa machines bbn butterfly parallel processor kendall square research supercomputer 
bbn machines interconnection network connect processors memory units ksr machines cache algorithms hierarchical set busses connecting processors memory units 
machines devices attached individual processor modules 
ffl remote memory access norma multiprocessors 
class architectures processor local memory shared processors system 
hypercubes ncube multiprocessors past intel ipsc machines current intel isc mesh machines thinking machines cm workstation clusters examples non shared memory multiprocessors 
workstation clusters differ hypercube mesh machines typically offer specialized hardware low latency inter machine communication implementation selected global operations global synchronization addition broadcast 
uma architectures common parallel machines part machines simply high throughput multiprogrammed multi user timesharing machines execution vehicles single large scale parallel programs 
interestingly memory accessed single shared bus uma machines numa characteristics individual processors access shared memory local caches 
cache misses cache flushing result effectively non uniform memory access times 
furthermore bus contention may aggravate variability memory access times scalability limited shared global bus imposes limits maximum number processors memory modules accommodate 
numa architecture addresses scalability problem attaching local memory processor 
processors directly access local memory communicate remote memory modules interconnection switch 
type switch interconnection network consisting multiple levels internal nodes systems scaled addition internal switch nodes bbn butterfly multiprocessors 
second type switch consists hierarchical set busses access times remote memory depend number internal switch nodes access path processor memory number traversed system busses 
numa architecture allows large number processors single machine experimental large scale multiprocessors numa machines example ibm rp designed contain processors ksr machine offering processors 
norma multiprocessors simplest design build architecture choice current supercomputers intel paragon cray machines 
simplest case collection workstations local area network constitutes norma multiprocessor 
typical norma multiprocessor consists number processors interconnected high speed bus network topology interconnection varies 
major difference numa norma multiprocessors hardware support direct access remote memory modules 
result loosely coupled numa machines 
advances supercomputer technologies leading tradeoffs remote local memory access times norma machines roughly local vs remote memory access times approximate achieved shared memory machines ksr roughly 
suggests numa norma parallel machines require similar operating system programming tool support order achieve high performance parallelism 
main component multiprocessor interconnection network 
connects processors memory modules devices system 
interconnection network may static dynamic facilitates communication processors memory modules 
sample interconnection networks time shared common buses crossbar switches hierarchical switches multistage networks 
design structure performance various interconnection networks reviewed literature scope survey 
variety different kinds multiprocessor architectures coupled diverse application requirements resulted different designs goals features implementations multiprocessor operating systems university research projects commercial domain 
examines projects commercial endeavors 
remainder organized follows 
section briefly reviews common structuring techniques build operating system 
section discusses key design issues 
section examines sample multiprocessor operating system kernels developed research commercial purposes 
structuring operating system multiprocessor operating system typically large complex 
maintainability adaptability portability strongly depend internal structure 
different techniques structuring operating systems described section discussion effects structuring ease operating system adapted multiprocessor computing engines 
various structuring techniques described section mutually exclusive techniques may construction single system 
bulk focusses operating system kernels section occasionally comment organization entire operating system 
context define operating system kernel basic operating system functionality permitting processors main memory interconnection network devices parallel machine 
higher level operating system functionalities user interfaces file systems database support networking unimportant discussion outside scope part performance strongly affected performance attributes basic functionality underlying system kernel 
monolithic systems operating systems unix os vms implemented large monolithic kernels insulated user programs simple hardware boundaries 
protection boundaries exist operating system kernel communication processes implementing higher level operating system functionality file system daemons happens system supplied shared memory explicit message communication constructs 
shown lack strong firewall large operating system kernel combined large kernel sizes complexities monolithic systems difficult modify debug validate 
protection hierarchy underlying hardware directly visible large amount complicated operating system software 
monolithic systems extremely difficult adapt distributed environment systems facilities allow users change specific service provided operating system 
experiences implementation monolithic operating system kernels parallel machines sequent sgi operating systems confined uma machines 
attempts build systems large scale parallel machines rp met mixed success 
result multiprocessor operating systems machines rp bbn butterfly ksr supercomputer mach osf unix smaller kernels offer facilities kernel operating system customization different application domains target machines see section discussion mach operating system configuration support 
capability systems capability system accessible entity exists protection domain entities reside single name space 
capability name set access rights entity managed underlying hardware software kernel 
process allowed entity process current domain capability 
entity shared domain process domain access manipulate entity invoking access method process sufficient rights capability 
invocation system operating applications monolithic systems protection domains happens protected procedure call process domain having appropriate execute capability transfers control second domain executes entirely context second domain 
parameter passing caller callee 
domains capabilities objects capability systems implementation capability addressing carried software hardware techniques 
sample software systems hydra cal tss 
cap intel examples hardware systems 
despite early favorable predictions system builders largely unsuccessful implementing programming capability systems perform machines traditional memory models 
may due fact early research commercial systems focussed capabilities enforcement protection boundaries system security characteristics typically enforcing principle privilege 
principle states program user system operate set privileges necessary complete job 
unfortunately principle implementations implied principle performance means protected expensive access users attempted avoid system protection mechanisms implementors commercial operating systems avoided protection mechanisms maximum extent possible 
appears extremely large address spaces offered modern bit architectures reverse trend part evident program debugging maintainability require fire walls bit addressing range potentially accessible single parallel program 
message passing systems message passing system process remains address space communication processes happens message transfer communication channel 
process address space requests service address space creates message describing requirements sends target address space 
process target address space receives message interprets services request 
demos examples earliest message passing systems 
primary motivation design systems decentralize structure operating system running single computer 
hand motivation message passing systems rig accent various hypercube operating systems build operating system structure distributed computers 
address spaces message message kernel message passing systems contrast fine grained protection capability systems network message passing systems rely coarse grained protection mechanism 
communication facilities messages transparently permit local remote communication 
local communication takes place address spaces machine remote communication takes place address spaces different machines connected communication network 
message passing system enforces modularity suitable distribution 
programs manually structured paradigm foreign control data structuring mechanism traditional algol languages 
specifically message passing data transfers explicitly initiated processes require communication 
gives programmers opportunity application specific knowledge avoid unnecessary data transfers 
message passing requires programmers entirely different mechanisms access memory local memory may accessed normal operations done accessing individual program variables remote memory accessed message operations 
interestingly research address dichotomy providing basic memory abstraction representation local remote memory addressing potential performance penalties arising providing abstraction weakening strong consistency requirements imposed main memory :10.1.1.14.3607
resulting weakened shared memory abstraction programmers may implemented efficiently strong consistency interprocessor communication required memory accesses 
models shared memory exploit programmer directives reduce cost coherence maintenance provide explicit primitives users maintain application specific notions coherence shared state see section information research 
interesting lesson learned current weakly consistent memories message passing shared memory need different mutually exclusive mechanisms 
may result operating systems offer memory abstractions strongly typed abstractions shared queues object specification mechanisms 
operating systems structured collections cooperating objects object invocations may result messages memory sharing objects may internally structured collections cooperating objects fragmented object 
language mechanisms single language systems 
clu eden distributed smalltalk emerald linda examples languages integrate message communication programming environment defining control structures terms messages messages basis building algol entirely new control structures 
advantages language system transparency portability 
local vs remote objects handled transparently automatically language runtime system 
addition type system language encourage optimizations coalesce separate modules address space maintaining logical separation 
optimizations alleviate certain performance problems approach specific language primitives inevitably impose performance penalties programmers aware order write efficient parallel programs 
example ada rendezvous mechanism leads known performance problems global addressing mechanisms fixed language semantics linda lead inefficiencies concerning update access remote information heap maintenance shown difficult languages smalltalk 
inherent problem language protection typing mechanisms mapped protection mechanisms available underlying operating system easily done 
addition language system require cooperating modules written language precludes mixed language environments 
furthermore order guarantee integrity system language level decomposition executable code inspected trusted system entity guarantee type safety runtime es requiring access source code 
language systems require availability lower level runtime system support efficient program execution clearly apparent current efforts develop threads common runtime system layer high performance fortran concurrent 
precisely structuring support concern 
remote procedure calls 
systems supporting remote procedure calls rpc occupy middle ground message single language systems 
rpc allows isolated components transparently integrated single logical system 
rpc system procedure call interface hides underlying communication mechanism passes typed data objects address spaces 
subsystems terms interfaces implemented servers 
absence single uniform address space compensated automatic stub compilers sophisticated runtime libraries transfer complex arguments messages 
rpc systems require data passed cooperating modules strongly typed module programmer free mix languages weakly typed untyped languages violate typing needed execute code source available 
server client kernel kernel messages rpc runtime stubs application remote procedure call rpc local remote communication address space 
rpc address spaces different machines referred cross machine rpc rpc address spaces machine referred space rpc 
principal components rpc system clients servers messages 
server address space contains code data necessary implement set procedures exported address space 
client address space requests service server sending appropriate message 
object oriented object supporting operating systems ongoing projects exploring object oriented paradigm building operating systems 
systems may broadly classified object oriented object supporting operating systems depending internal structures interfaces provide user level 
object oriented operating systems 
object oriented operating system object encapsulates system entity 
object oriented language primarily implement operating system properties language data encapsulation data abstraction inheritance polymorphism structure system 
may may support objects user level 
examples choices renaissance 
object supporting operating systems 
object supporting operating system necessarily structured object oriented fashion 
supports objects user level objects typically language independent 
sample sos cool chaos parallel machines chorus clouds distributed machines 
classified different groups depending kind objects support 
active server model computation objects active entities containing threads execution service requests object 
supporting passive objects offers object thread model single thread execution traverses objects invocation chain 
object orientation operating systems exploit type hierarchies achieve operating system configuration done choices stronger notions structuring available current systems 
technology object encapsulations operating system services order represent operating system services internally different ways invisibly services users 
examples uses internally parallel operating system servers offered eden system chaos presto association protection boundaries certain objects intended psyche internally fragmented objects offered shapiro distributed systems topologies hypercube machines distributed shared abstractions multiprocessor engines 
unresolved issues object oriented operating systems include efficient representation object invocations clear invocations equal ranging rapid unreliable invocations useful real time multiprocessor applications reliable multicast invocations required certain distributed programs 
addition remote procedure calls unclear levels machine language support required efficient implementation object invocations parameter marshaling crossing protection boundaries 
object oriented operating systems increasingly important part wide range parallel architectures sequential machines ranging digital pages workstations supported parallel operating systems increasing importance object oriented languages 
object oriented operating systems constructed micro kernel operating system structuring technique explained section 
vertical horizontal organizations researchers identified broad classes organization operating system kernels referred horizontal vertical organization 
alternatives roughly correspond message procedure organizations respectively 
os servers micro kernel applications 
system program interface application program interface app app app server server portable machine independent machine dependent 
hardware micro kernel operating system vertical organizations 
vertical kernel fundamental distinction process user space process kernel 
user process enters kernel trap required performs kernel operation returns user space 
kernel resource represented data structure shared processes 
vertical organization presents uniform model user kernel level processes closely mimics hardware organization uma multiprocessor 
unix kernels vertically organized 
horizontal organizations 
horizontal kernel major kernel resource represented separate kernel process thread typical kernel operation requires communication set kernel processes represent resources needed operation 
horizontal organization leads kernel synchronization subsumed message passing 
horizontal organization closely mimics hardware organization distributed memory multicomputer 
demos examples horizontal kernels 
micro kernel operating systems micro kernel operating systems structured collection system servers running top minimal kernel see 
micro kernel implements hardware dependent functions operating system 
primitive functions include task thread management interprocess communication synchronization lowlevel memory management minimal device management 
higher level operating system services implemented user level programs 
applications cross address space rpc interact operating system services 
implies performance inter process communication ipc mechanism plays critical role performance operating systems 
primary characteristic micro kernel operating systems modularity hoping improve system extensibility portability reconfigurability improved support distribution 
improvements distribution extensibility reconfigurability result separation system components message passing communication mechanism 
result new services added new servers existing server replaced altering existing components micro kernel 
large monolithic systems architectures localize hardware dependent portions operating system inside kernel potentially improving operating system portability 
furthermore common underlying services provides support coexistence interoperability multiple operating system environments single host user level programs 
mach chorus keykos qnx birlix examples micro kernel operating systems 
application specific operating systems application domains impose specific requirements operating system functionality performance structure 
example requirements comes realtime domain application software operating system support intertwined systems may better described consisting operating software combined application software operating system support functions application software underlying operating system 
contrast parallel distributed application software control software real time systems termed reliable exhibits key attributes computations complete defined timing constraints programs exhibit predictable behavior presence uncertain operating environments 
operating software direct access underlying resources typically controlled operating system complex applications deal uncertainty operating environments permitting programs operating system components adapt change runtime performance functionality system execution 
embedded real time operating systems offering functionality akin multiuser systems impose restrictions resource reservation application programs 
instance chaos chaos arc operating systems operating software implementing application operating system functionality consists number autonomous objects providing number operations entry points invoked objects 
functionality appears different offered object oriented operating systems 
addressing requirements realtime programs chaos arc object invocations range reliable invocations maintain parameters return information communication streams invocations implement unreliable control signals pulses 
furthermore invocation semantics varied attachment real time attributes delays deadlines deadline semantics may vary guaranteed deadlines hard deadlines missed weak deadlines specify partial incomplete results acceptable deadline missed 
resulting direct access resources characteristic real time operating systems share certain single user operating systems parallel machines 
hand system configurability property chaos arc shares current high performance operating systems including synthesis kernel psyche system related research presto 
examples application dependent operating system structures occur database systems operating system facilities networking facilities may determined strongly affected primary application running system large scale database performing transaction processing 
design issues basic functionality multiprocessor operating system include uniprocessor systems 
complexities arise due additional functional capabilities multiprocessor hardware importantly due extreme requirements performance imposed operating system 
main reason parallel hardware improve performance large scale application programs operating system system constructs perform poorly simply acceptable 
specific problems addressed concerning performance include protection large address spaces deadlock prevention exception handling large scale parallel programs efficient representation asynchronous active entities processes threads provision alternative communication schemes synchronization mechanisms resource scheduling process assignment different processors data placement physically distributed memory parallelization operating system order provide scalable performance varying application requirements 
second major reason multiprocessor system provide high reliability graceful degradation event failure 
multiprocessor systems constructed designed improved fault tolerance 
systems discussed survey see survey fault tolerant operating systems 
sections focus design issues concern operating system kernels micro kernels basic functionality offered multiprocessor operating systems including processor management scheduling main memory management interprocess communication synchronization 
processor management scheduling classic functions operating system include creation management active entities processes 
effectiveness parallel computing depends performance primitives offered system express parallelism 
cost creating managing parallelism high coarse grained parallel program exhibits poor performance 
similarly cost creating managing parallelism low fine grained program achieve excellent performance 
heavyweight processes lightweight threads way express parallelism unix processes sharing parts address spaces 
process consists single address space single thread control 
kernels supporting processes distinguish thread address space referred heavyweight threads 
parallelism expressed heavyweight threads coarse grained inefficient general purpose parallel programming reasons ffl kernel treats thread address space single entity threads address space created scheduled destroyed 
result creation deletion heavyweight threads expensive 
ffl processor different address space context switch expensive 
initial scheduling cost decide address space processor reallocated 
cost updating virtual memory mapping registers transferring processor address spaces 
long term cost associated cache tlb performance due address space change 
contemporary operating system kernels address spaces threads decoupled single address space execution threads 
threads referred threads kernel level threads managed operating system kernel posix pthreads 
advantages threads ffl kernel directly schedule application thread available physical processors 
ffl kernel level threads offer general programming interface application 
kernel level threads exhibit problems impractical fine grained parallel programs ffl cost generality kernel level threads acceptable fine grained parallel applications 
example saving restoring floating point context context switch expensive may unnecessary specific application program 
ffl relatively costly protected kernel call required invoke thread management operation including thread synchronization 
example programs direct access hardware synchronization operations 
ffl single model represented style kernel level thread implementation efficient parallel programs 
address problems kernel level threads system researchers turned user level threads known lightweight threads 
user level threads managed runtime library routines linked application 
thread management operation require expensive kernel call 
furthermore lightweight threads enable application program thread management system appropriate problem domain 
mach university washington threads sunos lwp threads popular lightweight thread implementations :10.1.1.13.9310
lightweight thread generally executes context heavyweight thread 
specifically threads library schedules lightweight threads top heavyweight threads turn scheduled kernel available physical processors 
level scheduling policy inherent problems ffl user level threads typically knowledge kernel events processor preemption blocking resuming 
result application library schedule thread just idle processor 
ffl number runnable kernel level threads single address space greater number available processors kernel level threads multiplexed available processors 
implies user level threads built top kernel level threads scheduled kernel thread scheduler little knowledge application scheduling requirements current state :10.1.1.13.9310
problems multi level scheduling arise lack information flow different scheduling levels 
anderson attempt solve problems level scheduling :10.1.1.13.9310
explicit kernel events user level thread scheduler upcalls called scheduler activations scheduler activations defined entities similar kernel level threads 
crucial distinction scheduler activations kernel level threads scheduler activations scheduled kernel 
kernel maintains invariant exactly runnable scheduler activations processors assigned address space 

notifying kernel user level events affecting processor allocation 
tucker gupta propose similar solution controls number processes applications 
scheme discussed details section 
similarly marsh propose set kernel mechanisms incorporated psyche operating system required implement class user level threads addressing problem 
mechanisms include shared kernel user data structures asynchronous communication kernel user software interrupts events require action part user level scheduler scheduler interface convention facilitates interactions user space dissimilar kinds threads see section psyche user level threads 
anderson explores data structure alternatives implementing user level thread packages 
alternate implementations evaluated performance thread run queues idle processor queues spinlock management 
aware general solutions multi level scheduling problem actual exchange configuration operating system threads scheduler application programs done real time systems 
scheduler structures operating system services parallel machines schedulers structured scalable different size target machines different application requirements 
mohan phd thesis addresses problem designing flexible run queue structure scheduler run queues configured number queues may number processors 
similar approach run queue organization taken intel imax operating system 
real time schedulers parallel systems considering effects sharing alternative scheduling information parallel scheduler performance 
scheduler structuring remains largely unexplored receive increased attention operating systems large scale parallel machines intel paragon multiprocessor 
scheduling policies scheduling policy allocates available time processors job process statically dynamically 
processor load balancing considered part scheduling policy 
basic theoretical results static process scheduling parallel machines show scheduling problem np hard static algorithms minimizing average response time include described 
scheduling algorithms appear 
section focus dynamic scheduling scheduling shared memory machines variations distances different processors parallel machine considered 
static dynamic scheduling static scheduler time decision job regarding number processors allocated 
decided job guaranteed exactly number processors active 
static scheduler offers low runtime scheduling overhead assumes stable parallel application 
reasonable assumption large scale scientific applications parallelism derived decomposition regular data domains 
focussing dynamic scheduling reasons complex large scale parallel applications exhibit irregular data domains changes domain decompositions time processor load balancing concerns dynamic distribution processing loads processors parallel machine 
static processor allocation rapidly inefficient large scale parallel machines multi user mode scheduling take account requirements multiple parallel applications sharing single machine 
zahorjan mccann compare performance static dynamic schedulers multi user workloads 
results include ffl independent workload system load dynamic scheduling performs best context switch overheads small 
ffl advantage dynamic scheduling low context switch costs increases larger rapid changes parallelism exhibited workload 
ffl dynamic scheduling performs increasingly relative static counterpart system load increases 
ffl terms average response time dynamic scheduling dominates static scheduling overhead context switch values 
dynamic policy occasionally exhibits performance penalty overhead values large 
reason performance degradation possible high rate processor reallocation 
researchers suggested dampen rate processor allocation release reducing rate useless processors exchange 
modification dynamic policy detrimental performance 
uniprocessors multiprocessor schedulers classified preemptive nonpreemptive schedulers 
scheduler classified scheduling granularity determined executable unit scheduled example schedulers differ may schedule individual groups processes 
accepted multiprocessor scheduling policies reviewed 
single shared ready queue research addressing uma multiprocessors typically assumed single ready queue shared processors 
queue policies come served fcfs shortest job sjf easily implemented evaluated literature 
interesting schedulers scheduling policies directly addressing primary requirement parallel program performance improvements attained parallelism program processes scheduled execute parallel 
goal gang scheduling achieve high degree simultaneous execution processes belonging single job 
particularly useful parallel application cooperating processes communicate frequently 
policy schedules runnable processes job run simultaneously different processors 
job preemption implies simultaneous preemption processes 
effectively system context switches jobs 
ousterhout proposed evaluated different algorithms phd thesis matrix continuous 
matrix algorithm processes arriving jobs arranged matrix columns certain number rows total number processors system 
arrangement jobs processes job reside row 
scheduling algorithm uses round robin mechanism multiplex system different rows matrix processes row 
problem matrix algorithm hole matrix may result processor idle runnable processes 
continuous algorithm addresses problem arranging processes linear sequence activity slots algorithm considers window consecutive positions sequence particular moment 
new job arrives window checked see empty slots satisfy requirements 
window moved positions right leftmost activity slot window empty slot just outside window left full 
process repeated suitable window position contain entire job linear sequence reached 
scheduling consists moving window right time slice leftmost process window leftmost process job previous time slice 
serious problem continuous algorithm analogous external fragmentation segmentation system 
new job may split fragments result unfair scheduling large split jobs vs small contiguous jobs 
ousterhout addresses issue designing algorithm identical continuous algorithm processes new job required contiguous linear activity sequence 
leutenegger vernon slightly modify algorithm eliminate performance problems job arrives processes appended linked list processes 
scheduling done moving window length equal number processors linked list 
process window receives quantum service processor 
quantum window moved linked list slot window process job completely previous quantum 
process window runnable window extended process non runnable process scheduled 
processors switch processes quantum time 
second algorithm modification improves expected performance correlated workloads 
modification movement window 
quanta window moved process job job previous time slice 
round robin rr scheduling versions rr scheduling exist multiprocessors 
version straightforward extension uniprocessor round robin scheduling policy 
arrival job processes appended shared process queue 
round robin scheduling policy invoked process queue 
second version uses jobs processes scheduling unit 
shared process queue replaced shared job queue 
entry job queue contains queue holding processes 
scheduling done round robin jobs 
job front queue receives quanta size number processors system quantum size 
job fewer processes total quanta size equal pq divided equally processes 
number processes job exceeds choices 
choice previous case divide total quanta size pq equally processes 
choice choose processes job round robin fashion process executing quanta 
alternative scheduling overhead second 
authors observe performance application worsens considerably number processes system exceeds total number processors 
attribute decreased performance problems ffl process may preempted inside spinlock controlled critical section processes application busy wait enter critical section 
ousterhout defines activity slot slot activity process may assigned 
scheduling consists selecting activity slot processor assigned activity executed processor 
collection activity slots referred activity space 
algorithms described assume job contains number processors processes 
problem particularly acute fine grain parallel programs 
identical problems arise programs processes engaged producer consumer relationships 
ffl frequent context switches occur number processes greatly exceeds number processors 
ffl processor interleaved multiple address space cache misses major source performance degradation 
careful application design may handle problems associated spinlock controlled critical sections producer consumer processes address performance degradation due cache corruption frequent context switches 
direct solution proposed zahorjan describe thread scheduler avoids preempting processes inside critical sections 
contrast propose approach combining preemption avoidance critical sections 
multiple processes combined form group 
scheduling policy group set processes group scheduled preempted simultaneously individual processes scheduled preempted normally processes group preempted 
individual process may choose override group scheduling policy 
policy flexible leave specific solutions critical section problem user code 
problems cache corruption context switch frequency addressed lazowska evaluate performance multiprocessor scheduling policies notion processor affinity 
process processor affinity contents processor cache 
basic policy schedules process processor executed hoping large percentage working set processor cache 
policy inherently discourages process migration may lead severe load imbalance 
authors address issue proposing variation basic policy successfully reduces cache corruption problem 
similarly affinity local memory plays vital role scheduling processes numa machine context process resides near processor process executed 
zahorjan study effect cache affinity kernel processor scheduling discipline multiprogrammed shared memory multiprocessors conclude cache effects due processor reallocation significant 
experiments demonstrate affinity scheduling negligible effect performance current multiprocessors 
conclude faster machines scheduling policy dynamic reallocation processors jobs outperforms static equipartition policy 
tucker gupta propose different solution reducing frequency context switches reducing cache corruption explained 
dynamic partitioning dynamic partitioning known process control processor partitioning policy proposed tucker gupta goal minimizing context switches time spent rebuilding processor cache 
approach hypothesis application performs best number runnable processes number processors 
result job dynamically allocated equal fraction total number processors job allocated processors runnable processes 
application program periodically polls scheduling server determine number processes ideally run 
ideal number actual number process suspends processes possible 
ideal number greater actual number process wakes previously suspended process 
policy limited generality requires interactions user processes operating system scheduler requires user programs written processes suspended woken program execution 
hand scheduling kernel level scheduler accepts user hints described 
kinds hints exist ffl hints hint discourage scheduler run current thread 
hint may mild strong weak 
david black discusses scheduler accepts hints 
ffl hand hints hand hint suggest scheduler run specific thread 
hand hint current thread hands processor thread intermediate scheduler interference 
schedulers better known handoff schedulers 
experiments scheduling hints described shown scheduling hints improve program performance 
hand scheduling shown perform better program synchronization exploited requester thread hands processor holder lock interprocess communication takes place sender hands processor receiver 
gupta detailed simulation study evaluate performance scheduling strategies 
include regular priority scheduling gang scheduling process control processor partitioning hand scheduling affinity scheduling 
addition tradeoffs busy waiting blocking synchronization primitives explored conjunction interactions different scheduling strategies 
key focus study impact different scheduling strategies caching behavior application 
results demonstrate situations number processes exceeds number processors regular priority scheduling conjunction busy waiting synchronization primitives results extremely poor processor utilization 
cases blocking synchronization primitives improves performance significantly 
process control gang scheduling strategies shown offer highest performance performance relatively independent synchronization methods 
applications sizable working sets fit cache process control performs better gang scheduling 
applications considered performance gains due hand scheduling processor affinity shown small 
authors study effects environmental factors multiprogramming data dependent execution times spinning overhead parallel applications choice scheduling discipline reduce amount spinning case 
specifically conclude decisions allocate processors jobs schedule threads job processors cooperatively 
furthermore range workloads systems considered difference mean performance synchronization spinning vs blocking little 
compare static scheduling policy fixed variable self scheduling policies number independent tasks exceeds number processors available conclude variable self scheduling policy provides performance robust respect overhead costs 
ongoing research addresses development schedulers specific application domains specific target machines 
area real time systems 
real time applications considered particle simulator called mp lu decomposition dense matrices parallel implementation goldberg tarjan maxflow algorithm highly optimized block parallel algorithm multiplying matrices 
system scheduling policy satisfy timing constraints deadlines earliest start times incoming job 
job assigned physical processors scheduler checks system satisfy job timing constraints 
analysis known schedulability analysis 
schedulability analysis scheduling real time systems active areas research scope 
memory management memory management uma multiprocessors conceptually similar multiprogrammed uniprocessors 
mentioned earlier uma architecture memory access times equal processors 
underlying architecture typically supports degree parallelism global memory access 
result uma machines operating system writers exploit available hardware parallelism implementing efficient memory management 
interesting problems arise numa norma machines 
early research memory management parallel machines including implementation physically distributed internally parallel memory managers reader referred innovative designs structures memory object managers cm multiprocessor systems 
research focussed primarily page management memory management context virtual memory systems implemented parallel machines 
shared virtual memory typical virtual memory system manages memory hierarchy consisting cache uniformly accessible primary memory significantly slower secondary memory 
traditional approach level store accent operating system supports single level store primary memory acts cache secondary storage 
filesystem data runtime allocated storage implemented disk data objects 
copies large messages managed shadow paging techniques 
contemporary systems ibm system apollo aegis single level store approach limit application management files 
central feature accent integration virtual memory communication 
large amounts data transmitted processes high performance memory mapping techniques 
result client server processes exchange potentially large data objects files concern traditional data copying cost message passing 
effect accent carries domain message passing systems notion performed virtual memory management 
design mach system memory management largely derived accent system :10.1.1.111.7918
single level store attractive simplify construction application program allowing programmers map file address space process improve program performance permitting file data read directly physical memory pages intermediate buffers managed operating system 
furthermore physical memory cache secondary storage repeated data corresponding disk transfers 
design implementation mach memory management discussed detail section 
memory management services implementations generally dependent operating system underlying machine architecture 
current research example real time executives memory management services simple primitive 
general purpose operating systems unix allow protected address spaces exist machine hardware 
distributed systems support distributed memory schemes 
focussed designing memory management functionalities interfaces independent machine architecture operating system kernel 
example mach operating system implements virtual memory management machine operating system independent :10.1.1.111.7918
machine dependent portion mach virtual memory subsystem implemented separate module 
information important management virtual memory maintained machine independent data structures machine dependent data structures contain mappings necessary run current mix programs see section implementation mach virtual memory management :10.1.1.111.7918
similarly authors design implementation scalable kernel independent generic memory management interface gmi chorus nucleus suitable various architectures paged segmented implementation schemes 
operating systems allow applications specify protection level inaccessible read read write pages allow user programs handle protection violations 
authors survey user level algorithms page protection techniques analyze common characteristics attempt identify primitives operating system provide user processes 
survey benchmarks number systems analyze operating systems support user level page protection techniques 
numa norma memory management early numa multiprocessor systems offer virtual memory support 
numa norma parallel machines thinking machines cm kendall square ksr intel paragon uma operating systems routinely offer virtual memory 
numa multiprocessor organization leads memory management design choices differ markedly common systems designed uniprocessors uma multiprocessors 
specifically numa machines bbn butterfly support cache main memory consistency different processors memory modules 
consistency guaranteed local memory caches non shared memory explicitly enforced shared memory user compiler generated code performing explicit block page moves :10.1.1.111.7918
result numa architectures implementing shared memory programming model typically expose existing memory access hierarchy application program done bbn uniform system 
motivations exposing information include 
giving programmers ability minimize relatively expensive remote vs expensive local memory maximize program locality 
permitting programmers avoid forms potential contention switch memory contention caused large number remote memory 
parallel numa architectures kendall square multiprocessor offer consistent global virtual memory 
performance reasons exposing programmers underlying machine numa properties persist leading system designers include hardware instructions page prefetches 
research memory management parallel machines focussed designing techniques numa multiprocessors relieve programmers responsibility explicit code data placement 
realizing problem memory management similar problem cache management consistency uma multiprocessors mach operating system uma implementation memory management attempts minimize amount data copying replication page copy write similar techniques reduction data movement :10.1.1.111.7918
essence operating system exploiting fact sharing read data multiprocessor require allocation multiple private copies different processes remotely access single copy located writing process 
numa machines extra data movement terms page replication migration may result improved performance due decreased page access times locally stored pages due elimination possible switch memory contention access shared pages demonstrated specific measurements bbn butterfly multiprocessor reported sections including section 
briefly discuss memory management algorithms numa multiprocessors 
various multiprocessor operating systems mach psyche platinum variation mix algorithms 
algorithms described categorized migrate replicate data 
algorithm migrates data site accessed attempt exploit locality data accesses decreases number remote accesses 
algorithms replicate data multiple read accesses happen time local accesses 
migration algorithm migration algorithm data migrated local memory processor accesses 
application exhibits high locality cost data migration amortized multiple accesses 
algorithm may cause thrashing pages local memory 
read replication algorithm disadvantage migration algorithm threads processor access data efficiently 
access second processor may cause migration 
replication reduces average cost read operations allows read simultaneously executed locally multiple processors 
write operations expensive replica may invalidated updated maintain consistency 
ratio reads writes large extra expense write operation may offset 
replication naturally added migration algorithm better performance 
full replication algorithm full replication allows data blocks replicated written 
keeping data copies consistent major concern algorithm 
number algorithms available purpose 
similar algorithm cache consistency 
algorithms discussed specific numa memory management schemes described individual parallel operating systems section 
platinum operating system kernel designed platform research memory management systems numa machines implements evaluates coherent memory abstraction top non uniform access physical memory architectures 
coherent memory uniformly accessible processors system programming numa multiprocessors easier users 
platinum goal explore possibility achieving performance comparable hand tuned programs simple easy shared memory model 
platinum implementation coherent memory replicates migrates data processors creating appearance memory uniformly rapidly accessible 
protocol controlling data movement derived extending directory cache coherency algorithm selective invalidation 
platinum acronym platform investigating non uniform memory page placement kendall square research ksr machines experimental dash multiprocessors numa multiprocessors broadcast invalidate snooping mechanisms maintain consistency multiple copies page writes occur 
programmers operating systems restrict writable pages single copy 
gives rise page placement problem concerns decision local memory contain single page copy 
black refer problem migration problem 
similar problem observed read pages 
specifically replication problem concerned determining set local memories contain copies page 
assumption set local memories contain copies page monotonically non decreasing 
authors implementation page placement mechanism automatically assign pages virtual memory appropriately located physical memory mach operating system ibm ace multiprocessor workstation 
managing locality operating system implementation hides details specific memory architectures making programs portable 
simple strategy page replacement uses local memory cache global managing consistency directory ownership protocol similar li distributed shared virtual memory 
experience indicates simple automatic strategies produce nearly optimal page replacement 
suggests dominant remaining source avoidable performance degradation false sharing reduced improving language processors tuning applications 
kernel developed framework implementing dynamic page replacement policies introduces highly tunable parameterized dynamic page placement policy numa multiprocessors addressing issues related tuning policy suit different architectures applications 
policy supports migration replication uses directory invalidation scheme ensure coherence replicated pages uses freeze defrost strategy control page bouncing 
parameterized numa memory management policy tuned architectural application differences 
authors perform experiments parameterized page replacement policy confirm dynamic placement policies efficient reasonably simple parameterized policy may form basis development machine independent memory management subsystems numa machines 
authors implementation memory management system psyche multiprocessor operating system 
psyche memory management system structured layers abstraction numa uma virtual memory puma psyche memory 
abstractions shown discussed section 
weak memory accent mach operating systems uniprocessor uma multiprocessors demonstrated copy write paging message passing 
li yale showed modified apollo aegis kernel support shared memory mhz token ring similar results demonstrated clouds project georgia tech 
motivated fact parallel programming may simplified underlying system provides basic memory abstraction representation local shared state 
unfortunately performance penalties result fact underlying system implement shared memory abstraction independent applications 
example system keeps copies shared data coherent consistent invalidation writes invalidate existing copies processors having copies access 
current research exploring shared memory may represented parallel dis object shared shared page falsely shared 
excessive page movement controlled freezing page place forcing remote accesses physical memory numa uma puma realm processor processor backing store psyche memory management layers tributed machines performance approximate message passing systems 
example memory models exploit fact synchronization control access shared state properly labeled memory data race free memory 
allows underlying system weaken memory consistency requirements 
resulting weakened shared memory abstraction programmers may implemented efficiently strong consistency interprocessor communication required memory accesses 
models shared memory developed distributed architectures exploit programmer directives reduce cost coherence maintenance provide explicit primitives users maintain application specific notions coherence shared state 
mechanisms memory state sharing significant effects performance parallel distributed applications 
demonstrated designs experimentation alternative memory models large scale multiprocessors exhibit numa memory characteristics due caches reduce communication latencies 
addition distributed memory machines intel ipsc series efficient state sharing necessitated significant differences access times local vs remote information 
leading mach system paging mechanisms page servers implementation intel paragon multiprocessor resulting general research shared state objects distributed shared memory parallel machine 
differences remote local access times pronounced distributed machines sets workstations connected high speed networks notions distributed objects topic research systems quite time evidenced clouds georgia tech chorus fragmented objects france 
synchronization multiple cooperating processes execute simultaneously synchronization primitives needed concurrency control 
multiple processes share address space synchronization required shared memory consistency 
fundamental properties enforced synchronization mutual exclusion protect critical section event ordering 
classical synchronization primitives semaphores monitors widely discussed earlier literature described 
discussed complex synchronization mechanisms path expressions part mechanisms widespread 
section briefly reviews common efficient synchronization constructs supported multiprocessor operating systems 
locks lock shared data structure enforce mutual exclusion 
critical section normally protected lock 
exceptions read write locks lock generally held process time 
process holding lock called lock owner 
enter critical section process atomically gains ownership associated lock called locking 
contender process lock critical section protected lock waits spinning blocking lock released current owner 
process exits critical section atomically releases lock ownership called unlocking 
multiprocessor operating systems typically support multiple types locks reviewed 
spin blocking locks spin locks primitive locks 
lock busy waiting process spins busy waits lock released 
hardware supports spin locks specific instructions instruction sets 
spin waiting consumes processor bus memory cycles early research multiprocessor operating systems clearly demonstrates performance advantages simple locking strategies lock implementations showing spin locks useful situations critical section small compared cost blocking resuming process available processor spin waiting results minimum latency lock release 
blocking lock waiting process called contender process blocks awakened process releasing lock 
locks known mutex locks 
anderson compare performance number software spin waiting algorithms 
propose efficient spin waiting algorithms ethernet style backoff algorithm introducing delay successive spins analogous ethernet backoff aloha software queueing spinning processors 
results demonstrated sequent uma machine apparent results generalize numa multiprocessors 
synchronization numa machines addressed mellor crummey survey spin lock algorithms propose new scalable algorithm list queuing lock known mcs lock generates remote lock acquisition independent number processors attempting acquire lock 
new generation provide powerful atomic operations set compare swap simplify implementations synchronization primitives allow certain concurrent data structures implemented blocking 
instructions fetch add allow certain common operations performed parallel critical sections 
evaluated effects kernel components applications synchronization 
example zahorjan lazowska eager examines extent multiprogramming data dependencies application complicate user decision spin block evaluate overhead spinning affected various scheduling policies 
read write locks read write lock allows multiple readers single writer enter critical section time 
waiting processes may spin block depending lock implemented spinning read write lock blocking read write lock 
configurable locks mukherjee schwan study effects application hardware characteristics multiprocessor locks propose structure configurable locks 
locks allow applications dynamically alter waiting spin block mechanism request handling mechanism lock scheduled 
experiments configurable locks demonstrate combined locks locks spin block waiting improve application performance considerably compared simple spin blocking locks 
furthermore hints lock owners may configure lock improving waiting strategy advisory speculative locks 
addition adaptation policy configure adaptive multiprocessor locks shown improve application performance 
lock detects changes application characteristics adapt suit changes 
authors study strategies including competitive strategies determining long spin blocking waiting lock 
study concludes competitive strategies performance worse optimal line strategy constant factor 
measurements indicate standard blocking strategy performs poorly compared mixed strategies 
mixed strategies studied adaptive algorithms perform better non adaptive ones 
object oriented operating systems choices renaissance take object oriented approach lock configuration customization 
systems define basic classes provide simple crude locks implemented hardware provided instructions 
sophisticated locks implemented top existing classes customizing existing locks see section 
barrier locks barrier lock implements barrier parallel program 
process reaches barrier allowed proceed cooperating processes reach barrier 
waiting process may spin block depending implementation lock 
mellor crummey survey barrier algorithms propose new scalable algorithm tree barrier spins locally accessible flag variables requires space processors performs theoretical minimum number network transactions gamma machines broadcast performs logp network transactions critical path 
barrier lock implementation reminiscent lock implementations distributed memory machines called structured locks 
structured locks distributed memory machines hypercube mesh multiprocessors operating system constructs exception handling multicast communications physically distributed order offer efficient access global operating system functionalities required application programs 
synchronization exception computation performed globally physically distributed processes processors 
result synchronization performed explicit communication structures rings spanning trees touch members group processes synchronized 
essence lock distributed memory machine fragmented distributed abstraction shared independently executable processes importance particular abstractions demonstrated explicit support hardware parallel machines including intel paragon thinking machines cm line machines 
contrast os support uma numa multiprocessors synchronization abstractions distributed memory machines optimized substantially programmable application programmers synchronization combined communications performed application programs 
synchronization constructs condition variables 
condition variables possible thread suspend execution awaiting action thread 
condition variable associated shared variables protected mutex predicate shared variables 
process acquires mutex evaluates predicate 
predicate satisfied process waits condition variable 
wait atomically releases mutex suspends execution process 
process changes shared variables predicate may satisfied may signal waiting thread 
signal allows blocked threads resume action re acquire mutex re evaluate predicate determine proceed wait 
events 
events mainly control thread orderings 
process may wait event blocks event occurs 
event occurrence signal wakes waiting processes 
events come different flavors 
state happened happened may may associated event 
count may associated event enables process wait particular occurrence event 
complicated event structures shown useful application domains target machines prominently including event handling facilities active messages synchronization points designed real time applications 
birrell informal description implementations formal specifications various thread synchronization primitives acquire release condition variables semaphores supported taos operating system 
interprocess communication basic communication primitives cooperating processes threads multiprocessor environment communicate synchronize 
execution process affect communication 
interprocess communication employs schemes shared variables message passing mentioned earlier processes communicate shared memory synchronization required guarantee memory consistency 
section describes popular synchronization primitives 
section focuses inter process communication explicit shared variables 
shared memory multiprocessor message passing primitives disjoint address space may implemented global memory 
exchange messages form communication accessing shared memory locations 
message passing subsumes communication buffering synchronization 
multiprocessor operating systems experimented large variety different communication abstractions including ports mailboxes links implementation point view abstractions kernel handled message buffers 
may unidirectional bidirectional 
process may send may receive messages 
may rights send receive ownership rights associated entities 
different operating systems define different semantics abstractions 
basic communication primitives abstractions send receive come different flavors 
sends receives may blocking process invoking primitive blocks operation complete may nonblocking process wait communication complete may conditional vs unconditional 
communication processes primitives may synchronous asynchronous issues considered designing inter process communication mechanism reviewed numerous surveys distributed operating systems discussed detail 
issues include underlying hardware supports reliable unreliable communication send receives blocking non blocking messages typed untyped variable fixed length message queues kept short handle queue overflows support message priority may necessary messages handled higher priorities transmit names protection issues kernel user programs interact result efficient message transfers 
communication issues specific hypercube mesh machines reviewed 
examples research communication protocols high performance parallel machines addressing association computational activities messages user driven configuration communication protocols improved performance parallelization protocol processing 
interest survey parallel programs typically message mechanisms shared memory available inter process communication 
demonstrated implementations message systems pvm ksr supercomputer implementations message systems bbn butterfly numa machine 
interestingly comparisons message passing direct shared memory result inconclusive results part results strongly depend sizes granularities frequencies communications parallel programs 
remote procedure calls shared memory multiprocessor operating systems support cross address space remote procedure calls rpc means inter process communication 
rpc higher level abstraction message passing 
hides message communication layer beneath procedure call layer 
rpc allows efficient secure communications 
furthermore cross address space rpcs look identical cross machine rpcs messages go network cases operating system kernel involved rpc processing basic paradigm control data transfer 
messages sent way kernel independent threads bound different address space 
performance cross address space rpc discussed extensively 
bershad propose new kernel communication facility called lightweight remote procedure call lrpc designed optimized communication address space machine 
lrpc combines control transfer communication model capability systems programming semantics large grained protection possible kernel numa machine 
model rpc 
bershad propose interprocess communication scheme called user level remote procedure call 
decouples processor allocation data transfer thread management combining fast cross address space communication protocol shared memory lightweight threads managed entirely user level 
decoupling operating system kernel entirely bypassed cross address space communications 
object invocations shared distributed memory machines research object oriented operating systems parallel machines concerned generalized form remote procedure calls inter object communications called object invocations 
specific results include provision mechanisms implementation alternative ways invoke object offered spring operating system subcontract mechanism chaos system policy abstraction 
basic need alternatives derived performance reliability considerations applications ability vary performance semantics object invocation reliable vs unreliable invocations separately target objects invoked precise parameters passed 
ability provided spring attributes policies chaos invocation attributes associated individual accesses fragmented objects built hypercube machines multiprocessors 
sample variations invocation semantics concerned types objects operations invoked include asynchronous vs synchronous invocations ability wait invocation receipt distributed rpc implementations variation invocation considered complete successful transmission invocation receipt invocation invocation completion association additional parameters governing invocations scheduled processed particularly important real time systems relevant parallel applications invocations important 
sample multiprocessor operating system kernels section reviews specific multiprocessor operating system kernels including hydra staros mach developed carnegie mellon university psyche developed university rochester presto developed university washington ktk developed georgia institute technology choices developed university illinois urbana champaign renaissance developed purdue university mach rp developed watson research center ibm successful commercial systems developed sequent multiprocessors developed bbn butterfly machines umax developed encore multimax multiprocessors 
hydra hydra earliest successful multiprocessor kernels developed carnegie mellon university implemented mmp hardware 
extensive descriptions hydra system appear 
major goals hydra 
develop minimal kernel multiprocessor systems arbitrary set operating system facilities policies easily constructed 
allow arbitrary number systems created kernel exist simultaneously 
provide uniform protection mechanism 
hydra rejects strict hierarchical layering structuring operating system originating concept separation mechanism policy 
mechanisms kernel intended support notion resources policies controlling resources 
salient features hydra generalized notion resources definition execution domain capability protection mechanism controlling access resources domain 
capabilities may protect user system level entity 
capabilities objects sets access rights manipulated kernel 
execution environment processes programs hydra consists types objects procedures processes 
procedure object abstraction algol procedures consisting code data accept return parameters 
procedure object contains list capabilities specify rights objects may execution 
capabilities define procedure execution environment 
procedure object contains capability templates partially specified time procedure creation filled execution procedure contain capabilities parameter objects supplied caller 
templates formal parameter specifications actual parameters expected procedure type checking checking access rights 
lns dynamic entity defines execution environment invocation 
consists single list capabilities composed combination caller independent capabilities listed procedure object caller dependent capabilities actual parameters 
unique lns appears invocation disappears procedure terminates 
result execution domain changes time procedure entered exited 
object passed parameter new capability created object new lns consists object right list specified template callee 
callee freedom operate parameter object caller 
process hydra defined unit asynchronous processing 
treated smallest entity independently scheduled external agent 
internally process stack representing state single sequential task 
hydra implements interprocess communication synchronization providing elementary message buffering primitives spin locks dijkstra style semaphore operations 
addition alternative implementations synchronization constructs offered ranging simple spin locks kernel provided semaphores user level policy semaphores 
hydra call mechanism permits process call protected procedure kernel 
kernel checks actual parameter capabilities supplied caller 
meet protection requirements kernel creates new lns defining new environment 
control passed code procedure 
similarly procedure completion returns kernel kernel deletes callee lns restores caller 
kernel entered twice protected procedure call 
objects protection mentioned earlier major goals hydra provide uniform protection mechanism 
hydra provide security levels specific protection policies 
simply provides flexible protection mechanism different types security policies implemented 
object unit protection 
consists unique name type representation 
type object contains unique name distinguished object serves representative object class 
objects referenced multiple capabilities count maintained object deleted count zero 
representation object consists capability part data part 
data part object accessed appropriate access rights capability part manipulated kernel 
capability contains rights list details operations may performed object referenced capability 
right list consists type independent rights kernel rights type dependent rights auxiliary rights 
kernel rights define operations kernel provides controlled manipulation objects capabilities 
hydra parallel computing major contributions hydra address protection issues research results relevant parallel systems including ffl basic results establishing concept program locality effects bus memory contentions parallel program performance importance asynchrony parallel program design implementation ffl demonstrations high performance parallel programs require choices operating system mechanisms provided variety different synchronization mechanisms programs differ granularities parallelism frequencies access shared data ffl experiences specific operating system facilities parallel programs led differences design decisions hydra follow cmu staros system reviewed 
insight parallel programmers seek performance prefer simple fast mechanisms slower mechanisms 
insight affected modern operating system designs parallel machines areas ranging process thread representations communication systems designs implementation synchronization constructs 
staros staros experimental operating system cm multi microprocessor computer developed carnegie mellon university 
design staros influenced protection mechanisms hydra underlying cm architecture principal goals achieving high performance reliability parallel machine users 
cm non uniform memory access numa machine 
consists number computer modules consists processor dec lsi bus lsi bus local memory local switch called attached devices 
switch routes memory module local memory map bus handles local memory originating non local processors 
non local performed map bus connects fourteen computer modules cluster 
computer modules cluster share switch called handles intra inter cluster memory 
clusters connected intercluster buses connecting multiple switches 
comprise hierarchical distributed switch 
cm configuration may arbitrary number connected clusters 
cluster need direct intercluster bus connection cluster configuration 
figuration process computer module process nucleus process loader scheduler manager object input output file systems scheduler manager object nucleus nucleus nucleus nucleus staros executive task force objects capabilities invocations 
hydra staros object oriented system enforcing strong object typing type object determines set functions defined 
furthermore hydra process possess capability object order invoke 
capability names distinct unique object specifies object access rights compared hydra 
object consists disjoint segments data portion containing sequence data words capability list portion containing sequence capabilities 
similarly process name spaces capability name space immediate address space 
data portion object directly mapped window immediate address space process 
machine instructions provided underlying processor may directly manipulate data portion object 
mechanism allows application small objects additional cost compared standard processors 
process may directly invoke objects capabilities 
staros allows users create new objects new object types dynamically 
existing default object types called representation types 
users may create new types representation types 
attributes staros interest parallel systems definition modules functions module invocations blueprint implementation similar functionality intel imax operating system modern object oriented operating systems eden choices chaos 
module defines object exporting set invocable functions 
function invocation process performed asynchronously passing invocation parameters process designated execute function 
invocation parameters passed passing capability small object called carrier contains parameters 
important concept originated staros function object require substantial flexibility synchronization performed conjunction object invocation 
result staros simply offers low level mechanism implementing different synchronization schemes capability mailbox contained carrier 
mailbox contain return parameters invocation waiting invocation completion 
furthermore invocation need routed fixed number processes serving called processes result creation new process called transient process executes invoked function terminates 
processes typically offer lower latency function invocation pre initialized execution specific functions 
pre initialized processes block common invocation mailbox waiting incoming carrier represents function request 
second important innovation parallel operating systems originating staros invocations functions differ functionality entities executing function code case kernel vs user level threads current multiprocessor operating systems 
third concept parallel operating systems originating staros roscoe operating system structuring operating systems operating system kernels micro kernels called nucleus staros 
specifically small subset staros functions called instructions defined execute sequentially synchronously invoking function 
collectively referred nucleus 
nucleus partly implemented firmware partly software 
copy nucleus software runs computer module address space micro kernel 
operating system functionality resides user level transient processes depending frequency 
task forces task force abstraction offered staros representation parallel programs 
task force programmed task language lower level library support simply collection cooperating staros processes collectively accomplish joint task 
compared single process performing task task force programmed take advantage parallelism achieve enhanced reliability selected services performance parallelism implement services 
addition task force programmed adapt changes user requirements underlying hardware growing shrinking dynamically 
staros distinguishes executable task force static task force 
executable task force set processes supporting code data objects performs desired task 
static task force collection modules exporting set functions input data 
task force constructed static form initialized contain number processes comprising executable task force 
realizing parallel programs simply collections unrelated multiple processes threads staros supports kinds relationships processes executable task force 
dependence relationship reflects relationships invoking invoked processes 
process suspension abnormal termination defines forests processes rooted number reconfiguration processes provided default operating system 
second relationship associates mailbox process time process creation report process failures 
simple process provided default operating system 
modern threads parallel operating systems provide staros functionality dependence relationship maintained thread joining forking part process containing threads play role entity threads may bail 
naturally staros operating system represented task force see user level transient processes implement higher level operating system functions processor contains micro kernel nucleus implementing synchronous instructions defined system implementors 
synchronization communication response underlying numa hardware staros message parallel operating system 
process blocks side effect message send receive 
process explicitly suspends execution wishes wait completion actions taken processes 
process interactions messages supported staros mailbox objects 
mailbox created buffer data messages single data words capability messages single capabilities 
basic functions defined mailbox send receive functions imply synchronization actions conjunction message communications 
actions may explicitly programmed event mechanism permits processes block mailbox waiting occurrence specific event 
mailboxes events implement multiple send receive semantics 
specifically receive may invoked conditional registration mode 
mailbox empty conditional receive returns error indication message 
registration mode name invoker event placed queue called registration queue associated mailbox 
event defined process specifying event name capability mailbox location address space message stored 
process may choose block event 
send delivers message directly registered receivers 
message stored location associated event event signalled 
registration queue empty mailbox full send buffers message mailbox 
send fails mailbox full 
communication mechanisms similar staros imax operating system 
scheduling responsibility scheduling staros divided scheduler processes multiplexors 
multiplexor low level mechanism short term decisions process execute processor scheduler implements specific scheduling policy 
multiplexors priority ordered set mailboxes run queues processor may associated single multiple run queue mailboxes 
sets run queues may overlap arbitrarily 
processor multiplexor searches process run priority order selected process assigned processor maximum time quantum 
sum total execution time process exceeds scheduler determined value multiplexor sends process designated scheduler 
may multiple schedulers system staros provide specific support interactions possible conflicts different schedulers done distributed systems bidding methods 
interesting higher level schedulers constructed staros system 
reader referred re engineered version staros built ousterhout called medusa system interesting higher level scheduling strategies implemented evaluated typically referred scheduling gang scheduling literature 
reconfiguration system initialization performed reconfiguration module gathers data physical resources physical memory creates operating system objects initializes initializes nuclei 
system initialization functions include determination number replicated processes created function placement code function physical memory initial assignment operating system processes run queues configuration staros may change time determined system reconfiguration processes periodically examine environment adjust staros configuration accordingly improve system performance maintain desired reliability level 
example particular function invoked frequently processes created execute function 
reconfiguration module dynamically configures system handle hardware software faults 
example physical environment changes addition removal clusters staros expanded reduced accommodate changes 
mach mach multiprocessor operating system kernel developed carnegie mellon university distributed systems tightly coupled uma multiprocessors 
extensions mach address numa norma machines 
mach runs wide variety uniprocessor multiprocessor architectures including dec vax system sun workstations ibm pcs ibm rp multiprocessor encore multimax intel paragon 
mach supported product number hardware vendors 
mach base technology osf operating system open software foundation 
mach separates unix process abstraction tasks threads 
addition mach provides ffl machine independent virtual memory management :10.1.1.111.7918
ffl capability interprocess communication facility 
ffl language support rpc 
ffl support remote file accesses autonomous systems 
mach binary compatible berkley unix bsd release ffl lightweight user level threads known mach 
ffl miscellaneous support debuggers multithreaded applications exception handling structurally mach organized horizontally developed micro kernel technology 
mach kernel minimal extensible kernel provides small set primitive functions 
provides base complete system environments may built 
actual system running particular machine implemented servers top kernel 
mach kernel supports basic abstractions 
task task execution environment threads collection system resources including address space 

thread thread defined basic unit execution 
mach threads belong middle weight process class defined section 

port port communication channel similar object object oriented system 
object messages may represented port 
operation object performed sending message corresponding port 

message message typed collection data objects communication active threads 

memory object memory object repository data mapped address space task 
memory management mach virtual memory management system designed architecture operating system independent 
architecture independence achieved dividing virtual memory implementation machine independent machine dependent portions 
machine independent portion full knowledge virtual memory related information machine dependent portion manages hardware defined physical address maps vax page tables 
machine dependent portion contains mappings essential run current programs 
mapping information page system reconstructed information machine independent portion fault time 
due separation machine dependent independent portions page sizes portions may machine independent page size boot time parameter power machine dependent size 
main data structures mach virtual memory system resident page table keeps track information machine independent pages address map task doubly linked list map entries maps range addresses region memory object memory object unit backing storage maintain machine dependent memory mapping information 
data structures mach supports large sparse virtual address spaces memory mapped files 
mach implements single level store treating primary memory cache virtual memory objects 
mach allows tasks allocate deallocate regions virtual memory set protection inheritance virtual memory regions 
inheritance may specified shared copy page basis 
page specified shared shared reads writes parent child tasks page specified copy effectively copied child address map 
efficiency copy write technique 
page specified passed child 
copy write sharing unrelated tasks employed passing large messages 
virtual memory system exploits lazy evaluation copy write map possible 
important feature mach virtual memory system ability handle page faults page data requests user level 
basic paging services provided inside kernel 
pager may specified implemented outside kernel user level 
particularly important real time implementations mach implementations addressing needs specific parallel architectures 
mach kernel specific support distributed shared memory 
dsm implemented server top kernel 
interprocess communication port kernel protected entity basic transport abstraction mach 
messages sent received port 
task gets access port receiving port capability send receive rights 
mach supports send rights ports useful implementing rpc 
provides dead names dead name notifications allow servers clients detect terminations 
messages variable size collections typed data 
mach supports synchronous asynchronous message transfers 
copy write technique employed large message transfers 
ports messages provide location independence security data type tagging 
mach supports port sets threads serve requests multiple objects 
receive operation port set returns message sent member ports 
sender detection mechanism allows object servers garbage collect receive right represented object 
author discusses design implementation ipc interface mach 
mach kernel implements messages single machine 
transparency mach interprocess communication ipc allows user level server network message servers extend ipc network 
top general message primitives mach implements various flavors communication including server client remote procedure calls distributed object oriented programming streams 
scheduling mach scheduler consists parts responsible processor allocation responsible scheduling threads individual processors 
processor allocation 
user level server performs processor allocation mechanisms provided underlying mach kernel 
processor allocation facility adds new objects mach kernel processor processor set 
imax kernel facilities processor object manipulates physical processors processor set independent entity processors threads assigned 
application creates processor set uses basis communication server 
server performs processor allocation assigning processors processor sets provided clients 
clients power manage processors having direct control 
server satisfies client requests strict order greedy fashion 
thread scheduling 
mach uses priority time sharing scheduling technique processor set 
mach schedules individual threads knowledge relationships threads 
scheduler maintains global run queue shared processors local run queue processor 
run queue priority queue runnable threads 
priority calculation threads discussed detail 
mach self scheduling processor consults run queue needs thread run 
mentioned section mach scheduler accepts kinds user hints hints hand hints 
mach micro kernel mach micro kernel evolved mach eliminating compatibility code bsd unix kernel 
major changes include optimization ipc implementation optimizing ports port rights new algorithms continuations scheduling ipc exception new page fault handling facilities 
application library emulation server unix multi threaded mach kernel unix server mach kernel basic facilities provided mach kernel support implementation operating systems mach applications 
shows organization application unix server relationship mach kernel 
unix server implemented mach task multiple threads control managed mach package 
continuation address routine call thread continues execution plus small data structure contains local state needed routine emulation library functions translator system service requests cache results 
object oriented multiprocessor operating system designed implemented university rochester 
major design goals ffl provide orthogonality mechanisms ffl support significant protection domains ffl support multiple users ffl structure operating system object oriented fashion small kernel 
objects encapsulate abstractions protection domains logical object names lon provide access protection domains processes represent asynchrony semaphores condition variables provide synchronization exceptions report error conditions 
consists series layers implemented bbn butterfly hardware 
software layer program development layer 
layer contains mechanisms support concurrent programming 
subsequent layers constitute kernel implements process threads physical memory allocation objects interprocess communication rpc 
objects object passive entity consisting code data represents instance data type 
object basic unit encapsulation abstraction protection 
object exports set entry procedures manipulate local data 
supports creation long lived processes continue perform object related duties duration object existence 
lon similar capability object 
invoke entry procedure caller appropriate lon 
lon refers unique object user interpreted context value provides mechanism implement various security policies 
map objects 
different object handles different context values enabling object distinguish clients 
object create invalidate lon desired context value 
coarse grain protection access objects implemented kernel fine grain protection access operations object implemented object context values 
lon may passed parameter rpc 
creator lon passes object loses control distribution lon 
object retains control interpretation context values 
object creates lon invalidates 
kernel maintains association lon invoke object corresponding context value 
object may contain active processes deletion time supports distinct object deletion mechanisms 
mechanism deletes object activity object ceases second mechanism allows object deleted immediately referenced canonical lon lon returned object creation time 
processes synchronization primitives process management synchronization implemented object operations implemented kernel 
processes protected address spaces 
process executes code associated object 
orthogonality processes objects allow number processes executing simultaneously inside object done clouds operating system 
necessary synchronization provided object implementation synchronization primitives semaphores condition variables implemented system objects 
supports multiprogramming time slicing multiprocessing transparently 
interprocess communication remote procedure call rpc mechanism communication processes 
processes communicate common object intermediary 
avoid need compiler support requires object programmer provide dispatcher object entries including initialization 
psyche psyche general purpose operating system large scale sharedmemory multiprocessors developed university rochester 
psyche implemented bbn butterfly plus hardware 
major design goals psyche project support multi model parallel computing provide user level flexibility general 
intent allow applications application components machine different ways coexist interact productively 
psyche provides low level kernel interface 
provides minimality functions kernel minimality kernel interface 
extensive shared data structures kernel user minimize kernel calls hardware readily available user level code 
kernel exists primarily implement protection perform operations occur privileged hardware state 
psyche kernel interface abstractions shown 
realm realm unit data sharing 
encapsulates code data 
interprocess communication effected invoking operations realms accessible process 
computation psyche happens invocation realm operations 
invocation may optimized protected depending degree desired protection 

process process psyche thread control implemented user level 

virtual processor virtual processors kernel level abstractions physical processors 
processes run virtual processors 
virtual processor schedules level processes 
single process may run different virtual processors different times 

protection domain protection domains implement mechanism limit access realms 
realm belongs distinguished protection domain protected calls operations execute 
process moves distinguished domain performs protected invocation realm 
protection domains provide boundaries virtual processors processes realms protection domains basic psyche abstractions distinct models parallelism 
implementation wise protection domain separate page table maps realms 
facilitate sharing arbitrary realms run time psyche arranges realm unique system wide virtual address space 
processes different domains may represented differently 
kernel keeps track call chains processes moving protection domains 
keep information regarding representation scheduling processes inside domain 
execute process protection domain user ask kernel create set virtual processors determines maximum level physical parallelism available domain processes 
kernel time slices virtual processors currently located physical node 
psyche kernel symmetric 
cluster node case butterfly contains separate copy kernel code 
original psyche implementation uses shared memory primary kernel kernel communication mechanism 
better performance design modified kernels communicate remote invocations 
synchronization psyche kernel implements types synchronization disabled preemption data structures locked interrupts synchronize device handlers spin locks semaphores 
interesting experimental results primitives reported 
memory management psyche virtual memory system goal integrate numa memory management kernel functions 
design consists distinct abstraction layers 
lowest layer encapsulates physical page frames page tables 
layer provides illusion uniform memory access time page replication migration 
third layer provides default pager backing store mechanism user level pagers final layer implements psyche uniform address space protection domains 
psyche virtual memory implementation evolved time provide user control 
data migration replication layer removed current implementation resulting simpler virtual memory system virtual address space represented hardware page table node executes 
code replicated automatically executing processor 
creator realm owns right specify replication occur realm created opened access particular protection domain page page demand 
scheduling psyche employs level scheduling scheme 
kernel scheduler schedules virtual processors physical processors user level scheduler schedules processes virtual processors 
support user level scheduling kernel provides user virtual processors software interrupts magic pages 
kernel scheduler schedules virtual processors physical processors round robin fashion 
users create processes run virtual processors complete control scheduling processes 
scheduling decision kernel communicates virtual processors software interrupts 
users define handlers type interrupt 
interrupt occurs data structure shared kernel user set contain state running process 
handler information perform context switch long term scheduling decisions 
kernel maintains relevant information load physical processor mapping virtual physical processors states virtual processors magic pages updates periodically 
information facilitate decisions regarding userlevel scheduling 
presto presto developed university washington set tools building parallel programs shared memory multiprocessors 
presto operating system true sense 
implemented top existing operating system 
presto included survey addresses issues concerning operating system configurability important parallel systems research 
presto goal provide framework programmers easily build programming model appropriate application domain 
presto allows degree customization object oriented programming paradigm 
encapsulates system entities processor control scheduling concurrency synchronization inside default structures fixed interfaces 
interfaces insulate users object internal state implementation 
long interface remains change object behavior implementation noticed 
presto supports fundamental objects 
thread thread created destroyed put sleep awakened 

spinlock spinlock guards critical section 

synchronization object synchronization object consists spinlock spinlock implements mutual exclusion queue threads block queue objects required implement semantics 
presto enforce semantics synchronization object 

scheduler scheduler maintains pool threads 

processor encapsulates hardware processor 
idle extracts thread pool maintained scheduler executes 
thread active 
customization lowest levels presto runtime kernel modified extended application required 
presto support idea reconfiguration operating system kernel level 
stated authors infeasible operating system permit easy redefinition concepts processor scheduler lock thread 
basic components operating system allowing users freedom change result chaos 
presto customization performed basic ways 
layered extension layered extension allows programmers build new existing primitives 
major problems layering performance degradation difficulties expressing new abstraction terms existing ones 
layering useful building new abstractions allow existing abstractions changed 

differential extension inherent property hierarchical type system object oriented languages differential extension allows programmer build new class existing ones specifying changes 

lateral extension lateral extension allows programmers change behavior objects dynamically 
presto example possible replace existing scheduler completely different program execution 
presto implemented sequent shared memory multiprocessor 
issues explored implementation include utility alternative internal representations objects object maintain internal parallelism control concurrency imposed objects development synchro object useful efficient representation complex events 
ktk kernel toolkit ktk development georgia institute technology configurable object operating system kernel designed microkernel technology 
major design goal ktk project provide explicit support line program configuration 
ktk layered portable configurable micro kernel 
result ktk run diverse platforms including user level sun kendall square research supercomputer sgi machines native operating system kernel gp bbn butterfly multiprocessor 
policies memory management thread control sync invocations attributes invocation control scheduling configurable threads ktk applications structure kernel toolkit ktk ktk structure 
kernel toolkit consists major components shown configurable micro kernel threads layer kernel toolkit built object types support attributes policies various policies attributes implemented application programs built ktk 
configurable micro kernel partially machine dependent component implements basic abstractions remainder ktk execution threads virtual memory regions synchronization primitives monitoring support capture parallel program ktk state limited number basic attributes configuration threads level abstractions synchronization primitives low level scheduling 
objects 
ktk application program consists number independent objects interact invoking operations methods 
object maintains state state directly accessible objects 
objects range light weight procedure entities multi threaded servers associated concurrency control scheduling policies 
complex objects built having objects components objects starting built object classes chosen due usefulness wide variety parallel applications constructed ktk adt monitor task adt data type defines object execution threads synchronize concurrent calls 
calling adt performed address space caller 
calling threaded data type creates new execution thread execution called operation synchronize concurrent calls 
built object classes ktk quite similar concurrent object constructs offered designs implementations object oriented concurrent languages cc 
monitor object execution threads allows single call active time 
define condition variables calls wait allowing calls proceed condition variable signaled 
task ada tasks single execution thread 
defines number entries called objects 
calls performed context task taken time 
addition primitive objects ktk provides support distributed objects dsa permits programmers define create encapsulated fragmented objects offers low level mechanisms implementing efficient abstraction specific communications object fragments 
typical ktk programs consist complex objects constructed built object classes called layered extension presto 
ktk offers methods extension identified presto additional dynamic configuration permitting definition new policy classes linkage kernel offering distinct views object exist application view system view 
application view objects terms classes characterizing external interfaces methods class abstraction number similar objects 
system view hand defined object policy attributes 
essentially policies define parameterized execution environment objects terms attributes invocation semantics kernel interactions ffl policy interprets attributes defined time creation classes objects states operations 
ffl policy define invocation semantics object intercepting invocation requests defining interpreting invocation time attributes specified part invocation 
ffl policy extend ktk interface special services 
policies executed implicitly result object creation invocation typical application programs see objects classes defined code offered ktk 
synchronization 
addition primitive spin blocking locks ktk supports configurable lock objects configured suit application requirements 
locks contain set implementation dependent attributes dynamically altered result continuous spectrum lock configurations ranging busy waiting blocking useful configurations combined locks advisory locks priority locks handoff locks adaptive locks 
furthermore configurable locks implement customized monitor module sense current state lock 
configuration 
ktk support reconfiguration consists mechanisms attributes policies monitoring mechanism sense current program state 
kernel toolkit offers explicit support line object configuration mechanisms ffl ktk allows specification configuration attributes object classes object instances state variables operations object invocations 
ffl attributes interpreted system programmer defined policies may varied separately abstractions associated 
example policies attributes may vary objects internal implementations changing functionalities vary semantics implementations object invocations affecting methods invoked 
policy associated program components object instance class state variable method object invocation 
association performed program component implementation specification affected 
ffl dynamic configuration may performed policies object level abstraction permitting programmers dynamic changes selected attributes lower level runtime libraries exploit peculiarities underlying multiprocessor hardware 
ktk offers efficient mechanisms line capture program operating system state required dynamic configuration 
mechanisms configuration ktk kernel customization specializing modifying existing kernel abstractions 
addition ktk extensible new abstractions functionality classes policies attributes easily added potentially maintaining uniform kernel interface adding new kernel classes 
choices operating system family called choices class hierarchical open interface custom embedded systems part embedded operating system eos project university illinois urbana champaign 
choices kernel implemented processor encore multimax multiprocessor language 
choices example customizable operating system tailored particular hardware configuration particular application 
choices targeted large multiprocessors interconnected shared memory high speed networks 
uses class hierarchy inheritance represent proper abstractions deriving building new instances choices system 
choices support multitasking task may multiple processors 
choices support application divided parts germ kernel 
set classes called germ encapsulates major hardware dependencies implements mechanisms managing physical resources provides uniform hardware architecture rest classes hierarchy kernel set classes implements resource allocation policies supports applications 
customized system built tailored kernel classes derived germ classes suit particular hardware 
tasks threads choices implement threads kernel 
supports multiple threads single task 
called lightweight threads terminology introduced threads 
task collection address spaces active threads 
interprocess communication communication choices achieved mainly shared memory 
operating system class hierarchy provides common shared memory message passing communication schemes extended customized 
existing communication schemes include path class monitors semaphores simple varieties guarded commands 
communication address spaces tasks performed shared persistent objects support stream communications broadcasts multicasts block memory management provide classes objects memory 
store store encapsulates physical memory 
operations allowed store store instantiation store destruction page allocation page deallocation 

space space encapsulates paged virtual address range mapping physical memory fault handler 
operations provided space creation space destruction virtual page allocation deallocation mapping virtual pages physical pages store installation fault handlers 
universe class represents aggregate spaces virtual memory 
task constructed space region 
threads task created kernel space resident addressable 
persistent objects persistent objects instances classes reside memory longer period execution time particular task 
persistent objects shared tasks implement operating system components protected space outside kernel 
germ kernel objects examples persistent objects choices 
persistent objects may active may act servers 
task accesses persistent object object descriptor method 
object descriptor implements capability addressing scheme 
accessed persistent objects mapped object space 
contents object space may change time requests tasks associated object space 
multiple processors may map persistent object virtual memory simultaneously 
exception handling choices kinds exceptions 
events events asynchronous mechanisms generated hardware handled event mechanism software kernel provided 

traps traps generated executing thread handled kernel provided user provided trap handler objects 
renaissance renaissance successor choices operating system currently development purdue university 
extends ideas choices distributed object environment 
goal renaissance provide transparent access remote objects distributed network machines 
renaissance objectoriented operating system implemented language 
process management process represents single control path program execution 
classes manage functions process management scheduling 
process class represents process defines context process container class represents collection process classes represents process queues processor class represents physical processor stores processor specific information local ready queues 
instances classes manipulate process model 
context process split objects 
process object contains architecture independent context object called contains architecture dependent context 
sending appropriate message processor object returns process ready queue context switch processes initiated sending messages corresponding process objects 
synchronization renaissance supports mutual exclusion synchronization classes 
lock class defines low level mutual exclusion object 
lowest level concrete synchronization class class provides simple crude spin lock implemented hardware provided atomic test set instructions 
spinlock subclass implements sophisticated busy waiting lock 
important synchronizations classes include semaphore class implements dijkstra counting semaphore class classes class augments counting semaphore timeout mechanism event class 
operating system enhanced version unix operating system developed run sequent multiprocessors 
sequent multiprocessor bus uniform access shared memory uma machine 
process management scheduling unix supports heavyweight processes 
processors system share set run queues 
addition processor private run queue 
supports preemptive priority scheduling 
processes grouped queues priorities 
idle processor checks private queue runnable process 
selects process execute highest priority non empty shared queue 
queue processes executed time shared round robin fashion 
priority process may change lifetime 
periodically system defined time period priority process recalculated 
priority cpu intensive process lowered gradually 
user may alter priority process certain extent 
process restrict particular processor process placed private queue processor 
version provides parallel programming library supports expensive processes threads control 
supports multiple threads control process 
semaphore originally introduced 
semaphore causes current process immediately relinquish processor message sent blocked processes 
known processor process affinity 
synchronization kernel provides locks semaphores mutual exclusion synchronization 
interrupt priority processor holding lock set ensure processor interrupted 
semaphore guard large critical section 
memory management virtual memory system enhanced version unix 
unix uses global model uses local model 
process greater role paging activity 
umax umax extension unix runs encore multimax multiprocessors 
encore multimax bus shared memory multiprocessor 
versions umax umax umax umax compatible unix bsd umax compatible unix system process management scheduling umax multi user multi programmed multithreaded operating system 
similar including support heavyweight unix processes 
parallel program constructed multiple unix processes sharing portion process data space 
medium grained parallelism umax provides multitasking library implements notion tasks similar mach threads 
process may multiple tasks sharing address space 
synchronization synchronization primitives provided spin locks semaphores dijkstra style read write locks 
locks semaphores hierarchically prevent deadlock indefinite postponement 
memory management versions umax support demand paged virtual memory provide megabytes virtual address space processor 
operating system provides unix environment butterfly parallel processor 
butterfly non uniform memory access numa shared memory multiprocessor uses interconnection network processor memory switch 
machine node consists processor local memory 
collectively local memories processor nodes form shared global memory machine 
processor access memory machine switch 
remote memory access expensive local memory access 
process management scheduling kernel provides lowest level operating system functions runs processor 
supports processes processor schedulers allow process run node concurrently processes nodes 
memory management butterfly hardware uses segmented virtual memory management system 
memory protection kernel user mode read write execute attributes enforced segment basis 
memory mapping managed kernel controlled directly applications 
kernel provides level abstraction hardware memory management supporting objects associated areas physical memory special system data structures 
objects provide processor independent names areas memory system structures 
object mapped virtual address space process object identifiers called object handles passed processors inter process communication facilities 
synchronization objects associated system data structures provide inter process communication synchronization primitives 
common synchronization primitives events dual queues 
dual queues interlocked data queues locks pass data processes 
process may suspend event 
event posted process scheduled run 
micro coded atomic memory operations provided build simple locks synchronization primitives 
number servers implemented top kernel provide additional functionalities network capabilities remote debugging remote file system application libraries built export operating system interface application program 
libraries includes uniform system develop parallel programs butterfly parallel system buffer management package communicating applications stream oriented interface library performance measurement tools parallel applications 
rp rp numa shared memory multiprocessor developed watson research center ibm 
rp hardware designed scalable way multiprocessing 
way prototype machine built operational 
rp architecture designed give application direct control hardware way enabling application achieve speedups parallel machine application program may choose charge cache coherence 
rp architecture consists number processor memory elements pme connected interconnection network 
pme consists risc processor floating point unit interface mmu cache memory controller memory module network interface switch interface performance measurement chip 
rp operating system commercial systems extension unix 
mach base implementation unix rp mach mach rp master processor reserved unix system call service 
second operating system rp developed nyu deployed actual machine 
process management scheduling mach rp supports version scheduling gang scheduling known family scheduling 
family set cooperating processes possibly exchanging messages sharing part address space synchronizing working single goal 
thread family largest schedulable unit rp corresponds notion family 
port associated family 
thread rights family port request processor allocated deallocated family 
threads family allowed run allocated processors non family threads barred allocated processors 
members family time share processors 
thread family choose bound particular processor 
notable feature rp family scheduling interface flexibility allowing thread issue requests threads 
example thread bind thread thread request processor allocation family 
memory management rp exports non uniform memory model applications deal issues data placement 
mach rp allows task specify virtual memory attributes pages virtual address space inheritance protection attributes mach 
attributes include location attributes thread may specify ranges virtual pages placed local memory replication attributes thread request replicate ranges virtual memory different memory modules attributes thread request ranges virtual pages cacheable 
operating systems distributed memory machines operating systems distributed memory machines part designers hardware backgrounds part due narrow focus attaining high performance application programs operating system considered result better performance machines 
commercial ventures characteristics industry users demanding operating system compatibility existing workstation sequential supercomputer platforms 
current distributed memory machines intel paragon thinking machines cm offer full osf unix operating systems 
unfortunately system implementors plethora past research results 
brief outline operating system research distributed memory machines follows 
caltech hypercube developments resulted broad interest concept active messages 
basic idea active messages associate computing tasks message transfers system minimizes delay message arrival node initiation computations enabled message 
dally mit constructing hardware support active message machines 
livny manber explore similar idea active channels token ring communication protocol extended classes operations performed directly node interfaces arithmetic selection counting 
simulation studies hardware proposals show usefulness applications including dynamic load balancing sorting distribution livny manber research active message construct called topologies hypercubes distributed shared abstractions shared memory multiprocessors previous message operating systems hypercubes assuming presence reliable message delivery processes preconditions postconditions service routine service routine pool invocation blocks service table private vertices user threads input output input edge output edge vertices data object fragments nodes hypercube 
lower level message protocol kernel user level services associated receipt sending individual messages somewhat resembling explicit user level communication calls issued user programs crystalline operating system 
event driven execution model topologies similar execution model supported reactive kernel series multicomputers schedules user processes conditions concern receipt messages processes waiting 
sample object fragment defined appears 
basic idea active messages reflected terms user threads service routines closely associated incoming outgoing message buffers communication topology linking object fragments 
simpler higher performance implementations services threads attached messages implemented systems designed dally mit 
slight generalizations functionality crystalline operating system moose operating system designed caltech early commercial operating systems developed intel ncube hypercube machines 
example moose explicitly addresses process migration load balancing intel operating systems offer simple notions processes process communication constructs amplified support concurrent having reviewed material multiprocessor operating systems tempting try predict developments parallel operating systems 
resist temptation 
conclude system developers mentioned survey stating motivation highlighting specific topics systems 
main motivation writing survey realization current multiprocessor developments assisted tremendously judicious reviews past research 
particularly important case parallel operating systems os community research focus parallel systems late shifted distributed systems addressing parallel machines 
hoping remind researchers past results insights included relatively old operating systems hydra survey thought research protection issues starting point operating system developments parallel machines 
similarly staros system roscoe medusa provides early implementations micro kernels user level operating system services internally parallel reliable system services alternative operating system constructs providing similar functionalities differing costs 
motivation inclusion hydra staros expectation insights protection operating systems may important bit address spaces large scale parallel machines 
second motivation writing aforementioned convergence technologies relevant parallel computing 
convergence high performance computing networking technologies resulting large scale physically distributed heterogeneous parallel machines 
associated technologies originally developed parallel vs distributed systems partially divergent technical communities discussed different terminologies 
technological convergence driven hardware developments multiprocessor engines scaled hundreds processors appear distributed sets machines distributed machines linked high performance networks especially local area networks network devices derived current atm supercomputer routing technologies increasingly parallel computing engines 
increasingly obvious evolution mach operating system addressed single networks workstations running numa norma machines 
prompted include numa operating systems psyche survey operating systems reactive kernel constructs topologies norma machines mentioning developments originally proposed distributed systems weak memory systems 
believe ideas designs implementations fruitfully applied development parallel machine operating systems 
third motivation writing survey current excitement operating systems research general new applications interactive distributed systems new software technologies object oriented software development languages prompting designers seek new dimensions system configurability large scale parallel machines addressed survey sequential machines ranging simple hand held communication computation devices supercomputers 
example industry effort apply object oriented technologies operating system development spring operating system commercialized sun microsystems 
sample research systems included survey kernel toolkit psyche choices renaissance 
insights concerning operating systems parallel machines underly presentation 
modern operating systems built multiple related system structuring techniques inevitably offer different implementations common functionality tailored target architectures intended application domains 
second single set operating system facilities result high performance possible parallel application programs 
result modern systems strive place system functionality user level code offer multiple different user level operating system platforms parallel computing single underlying system kernel 
interesting research questions include userlevel vs kernel functionality 
appropriate interfaces 
suitable mechanisms provision externally driven system configurability 
different statement posing questions admission probably single parallel programming model appropriate parallel application programs 
result systems offer multiple diverse programming model focus single powerful parallel programming paradigm 
jr tevanian 
architecture independent virtual memory management parallel distributed environments 
phd thesis school computer science carnegie mellon university december 
technical report cmu cs 
rozier shapiro 
generic virtual memory management operating system kernels 
proceedings th symposium operating systems principles sigops notices vol pages december 
mike accetta robert baron david golub richard rashid tevanian michael young 
mach new kernel foundation unix development 
proceedings summer usenix conference pages july 
sarita adve mark hill 
weak ordering new definition 
proceedings th annual international symposium computer architecture pages may 
sarita adve mark hill 
unified formalization shared memory models 
technical report department computer science university wisconsin madison september 
gottlieb 
highly parallel computing 
benjamin cummings redwood city calif 
ahamad richard leblanc 
application specific coherence control high performance distributed shared memory 
proceedings rd usenix symposium experience distributed multiprocessor systems iii pages march 
anderson 
perfomance spin lock alternatives shared memory multiprocessors 
ieee transactions parallel distributed systems january 
thomas anderson brian bershad edward lazowska henry levy :10.1.1.13.9310
scheduler activations effective kernel support user level management parallelism 
transactions computer systems acm february 
thomas anderson edward lazowska henry levy 
performance implications thread management alternatives shared memory multiprocessors 
ieee transactions computers december 
thomas anderson henry levy brian bershad edward lazowska 
interaction architecture operating system design 
proceedings fourth international conference architectural support programming languages operating systems sigplan notices vol pages april 
appel li 
virtual memory primitives user programs 
proceedings fourth international conference architectural support programming languages operating systems sigplan notices vol pages april 
archibald 
cache coherence problem shared memory multiprocessors 
phd thesis department computer science university washington february 
atkinson demers hauser jacobi kessler weiser 
experiences creating portable cedar 
proceedings acm sigplan conference programming language design implementation pages portland june 
baron black bolosky chew draves golub rashid tevanian young 
mach kernel interface manual 
school computer science carnegie mellon university august 
forest baskett john howard john montague 
task communication demos 
proceedings sixth acm symposium operating systems principles pages nov 
gerard baudet 
design analysis algorithms asynchronous multiprocessors 
phd thesis computer science department carnegie mellon university april 
bennett 
design implementation distributed smalltalk 
oopsla conference proceedings pages october 
bennett carter zwaenepoel 
munin distributed shared memory type specific memory coherence 
second acm sigplan symposium principles practice parallel programming seattle sigplan notices vol pages 
acm march 
bershad 
increasing irrelevance ipc performance microkernel operating systems 
proceedings usenix workshop micro kernels kernel architectures pages april 
bershad anderson lazowska levy 
lightweight remote procedure call 
acm transactions computer systems february 
appeared proceedings th acm symposium operating systems principles dec 
bershad anderson lazowska levy 
user level interprocess communication shared memory multiprocessors 
acm transactions computer systems may 
bershad lazowska levy 
presto system object oriented parallel programming 
software practice experience august 
bershad lazowska levy wagner 
open environment building parallel programming systems 
proceedings symposium parallel programming experience applications languages systems pages july 
brian bershad 
high performance cross address space communication 
technical report dept computer science eng university washington june 
ph dissertation 
schwan 
comparison adaptation algorithms increasing reliability real time software 
proceedings ninth real time systems symposium huntsville pages 
ieee dec 
schwan 
dynamic adaptation real time software 
acm transactions computer systems may 
kenneth birman implementing fault tolerant distributed objects 
ieee transactions software engineering pages june 
birrell guttag horning levin 
synchronization primitives multiprocessor formal specification 
proceedings th acm symposium operating systems principles pages 
acm december 
birrell nelson 
implementing remote procedure calls 
acm transactions computer systems february 
biswas ramakrishnan towsley krishna 
performance analysis distributed file systems non volatile caches 
proceedings nd international symposium high performance distributed computing pages july 
black golub rashid draves dean forin barrera tokuda malan 
microkernel operating system architectures mach 
proceedings usenix workshop micro kernels kernel architectures pages april 
black golub rashid tevanian young 
mach exception handling facility 
technical report cmu cs school computer science carnegie mellon university april 
david black 
mach cpu server implementation processor allocation 
school computer science carnegie mellon university august 
david 
black 
scheduling resource management techniques multiprocessors 
phd thesis school computer science carnegie mellon university july 
techreport cmu cs 
david 
black 
scheduling support concurrency parallelism mach operating system 
ieee computer may 
ben blake karsten schwan 
experimental evaluation real time scheduler multiprocessor system 
ieee transactions software engineering january 
toby bloom 
dynamic module replacement distributed programming system 
phd thesis laboratory computer science massachusetts institute technology mit lcs tr march 

dual processor scheduling dynamic reassignment 
ieee transactions software engineering se july 
bolosky fitzgerald scott 
simple effective techniques numa memory management 
proceedings twelfth acm symposium operating systems principles pages december 
bolosky scott 
false sharing effect shared memory performance 
proceedings usenix symposium experiences distributed multiprocessor systems iv pages september 
hardy landau shapiro hardy 
keykos architecture 
proceedings usenix workshop microkernels kernel architectures pages april 
ronald isaac 
ada 
ieee computer magazine june 
bryant chang 
experience developing rp operating system 
proceedings nd usenix symposium experience distributed multiprocessor systems pages march 
bryant chang 
operating system support parallel programming rp 
ibm journal november 
campbell islam 
choices frameworks refinement 
computing systems summer 
campbell johnston russo 
choices class hierarchical open interface custom embedded systems 
operating systems review july 
campbell russo johnston 
design multiprocessor operating system 
proceedings usenix conference pages november 
nicholas carriero david gelernter 
net linda kernel 
acm transactions computer systems may 
carter bennett zwaenepoel 
implementation performance munin 
proceedings thirteenth acm symposium operating systems principles pages october 
black 
implementing mach debugger multithreaded applications 
proceedings winter usenix technical conference exhibition pages january 
chase lazowska levy 
amber system parallel programming network multiprocessors 
proceedings th acm symposium operating systems principles pages december 
sheng chang cheng john stankovic ramamritham 
scheduling algorithms hard real time systems brief survey 
tutorial hard real time systems pages 
ieee 
cheriton 
kernel software base distributed systems 
ieee software april 
cheriton 
problem oriented shared memory decentralized approach distributed system design 
proceedings sixth 
international conference distributed computing systems cambridge ma pages may 
cheriton malcolm sager 
portable real time operating system 
comm 
assoc 
comput 
mach feb 
christian mukherjee karsten schwan 
distributed shared abstractions dsa large scale multiprocessors 
proc 
fourth usenix symposium experiences distributed multiprocessor systems pages 
usenix september 
published ieee transactions software engineering 
cohen jefferson 
protection hydra operating system 
proceedings th acm symposium operating systems principles pages 
acm 
jensen 
performance effects architectural complexity intel 
acm transactions computer systems august 
cooper draves 
threads 
technical report cmu cs dept computer science carnegie mellon university june 
cox fowler 
implementation coherent memory abstraction numa multiprocessor experiences platinum 
proceedings twelfth acm symposium operating systems principles pages december 
cox lai pollack 
interprocess communication processor dispatching intel 
acm transactions computer systems february 
george cox william konrad lai fred pollack 
unified model implementation interprocess communication multiprocessor environment 
proceedings th symposium operating system principles asilomar pages 
assoc 
comput 
mach dec 
thomas 
butterfly tm parallel processor 
technical report bbn laboratories incorporated 
curran stumm 
comparison basic cpu scheduling algorithms multiprocessor unix 
computing systems october 
dally chao chein kaplan song wills 
architecture message driven processor 
proceedings th annual international symposium computer architecture jun 
dally seitz 
torus routing chip 
distributed computing 
dasgupta richard leblanc ahamad ramachandran 
clouds distributed operating system 
ieee computer nov 
dasgupta richard leblanc jr william 
clouds distributed operating system functional description implementation details related 
proceedings th international conference distributed computing systems san jose ca pages 
ieee june 
dennis van horn 
programming semantics multiprogrammed computations 
communications acm march 
mok 
multiprocessor line scheduling hard real time tasks 
ieee transactions software engineering dec 
dijkstra 
structure multiprogramming system 
communications acm may 

partitioning multiprocessor systems 
technical report department computer science vanderbilt university july 
draves bershad rashid dean 
continuations implement thread management communication operating systems 
proceedings th acm symposium operating system principles pages october 
draves 
revised ipc interface 
proceedings usenix mach conference pages october 
draves jones thompson 
mig mach interface generator 
department computer science carnegie mellon university july 
eds 
durham fuller jones 
cm review report 
technical report comp 
science dept carnegie mellon univ 
eager zahorjan lazowska 
speedup versus efficiency parallel systems 
ieee transactions computers march 
schonberg 
process management highly parallel unix systems 
proceedings usenix workshop unix supercomputers pages september 
jr das leblanc marsh scott 
kernel kernel communication shared memory multiprocessor 
concurrency practice experience may 
programmer manual version 
bbn laboratories june 
finkel manber 
distributed implementation backtracking 
acm transactions programming languages systems april 
finlayson 
object oriented operating systems 
newsletter 
fitzgerald rashid 
integration virtual memory management interprocess communication accent 
acm transactions computer systems may 
forin barrera young rashid 
design implementation performance evaluation distributed shared memory server mach 
proceedings winter usenix technical conference january 
fox 
implementation high performance operating system intel ipsc hypercube 
technical report caltech concurrent computational program physics dept caltech pasadena ca jan 
geoffrey fox johnson otto salmon walker 
solving problems concurrent processors 
prentice hall 
fuller ousterhout raskin rubinfeld swan 
multiprocessors overview working example 
proceedings ieee feb 
edward daniel siewiorek segall 
parallel processing cm experience 
digital press digital equipment 
kourosh gharachorloo daniel lenoski james laudon phillip gibbons anoop gupta john hennessy 
memory consistency event ordering scalable shared memory multiprocessors 
proceedings th annual international symposium computer architecture pages may 
ahmed mukherjee silva karsten schwan 
ktk kernel support configurable objects invocations 
second international workshop configurable distributed systems 
ieee acm march 
ahmed karsten schwan 
chaos arc kernel support multi weight objects invocations atomicity real time applications 
acm transactions computer systems april 

micro kernel design 
unix review november 
goldberg tarjan 
new approach maximum flow problem 
proceedings th acm symposium theory computing pages 
golub dean forin rashid 
unix application program 
proceedings summer usenix technical conference pages june 
gopinath karsten schwan 
chaos operating system real time applications 
operating systems review july 
gottlieb grishman kruskal mcauliffe rudolph snir 
nyu 
ieee transactions computers february 
shapiro 
fog fragmented object generator 
proceedings usenix conference pages april 
graunke 
synchronization algorithms shared memory multiprocessors 
ieee computer june 
mach networking group 
network server design 
school computer science carnegie mellon university august 
gupta tucker 
impact operating systems scheduling policies synchronization methods performance parallel applications 
proceedings acm sigmetrics conference measurement modeling computer systems pages may 

cool kernel support object oriented environments 
ecoop oopsla conference sigplan notices vol pages 
acm october 
hamilton powell mitchell 
subcontract flexible base distributed programming 
technical report sun microsystems laboratories tr april 
herlihy 
impossibility universality results wait free synchronization 
proceedings seventh annual acm symposium principles distributed computing pages august 
herlihy 
methodology implementing highly concurrent data structures 
proceedings second acm sigplan symposium principles practice parallel programming sigplan notices vol pages march 

architectural overview qnx 
proceedings usenix workshop micro kernels kernel architectures pages april 
hoare 
monitors operating system structuring concept 
communications acm 
horn 
simple scheduling algorithms 
naval res 

quart 
hou patt 
trading disk capacity performance 
proceedings nd international symposium high performance distributed computing pages july 
hutchinson peterson abbott malley 
rpc kernel evaluating new design techniques 
proceedings th acm symposium operating systems principles pages december 
hwang briggs 
computer architecture parallel processing 
computer science series 
mcgraw hill new york 
burkhardt iii frank knobe 
overview ksr computer system 
technical report ksr tr kendall square research boston february 
sun microsystem sun os manual november 
section 
intel oregon 
intel ipsc ipsc user guide 
intel beaverton oregon 
touchstone delta system user guide 
jones jr durham feller 
software management cm distributed multiprocessor 
proceedings national computer conference pages 
jones 
task forces distributed software solving problems substantial size 
proceedings fourth international conference software engineering 
jones durham feiler schwan vegdahl 
programming issues raised multiprocessor 
proceedings ieee feb 
jones durham mohan schwan vegdahl 
staros multiprocessor operating system 
proceedings th symposium operating system principles asilomar ca pages 
assoc 
comput 
mach dec 
anita jones peter schwarz 
experience multiprocessor systems status report 
surveys assoc 
comput 
mach june 
eds 
jones ed 
cm multiprocessor project research review 
technical report school computer science carnegie mellon university cmu cs july 
jones rashid 
mach matchmaker kernel language support object oriented distributed systems 
technical report cmu cs school computer science carnegie mellon university september 
jones rashid thompson 
matchmaker interface specification language 
proceedings acm conference principles programming languages january 
richard jr carla ellis laurence kaplan 
robustness numa memory management 
proceedings th acm symposium operating systems principles pages october 
jul levy hutchinson black 
fine grained mobility emerald system 
acm transactions computer systems february 
karlin li manasse owicki 
empirical studies competitive spinning shared memory multiprocessor 
proceeding thirteenth acm symposium operating systems principles pages october 

lightweight processes unix implementation application 
proceedings proc 
usenix summer conference pages 
khalidi nelson 
implementation unix object oriented operating system 
proceedings winter usenix conference san diego january 
jeff kramer jeff magee 
dynamic configuration distributed systems 
ieee transactions software engineering se april 
bbn laboratories 
butterfly tm parallel processor overview 
bbn computer cambridge ma st edition june 
lampson redell 
experiences processes monitors mesa 
communications acm 
lampson sturgis 
reflections operating system design 
communications acm 
lauer needham 
duality operating system structures 
operating systems review february 
lazowska levy fischer fowler 
architecture eden system 
proceedings th acm symposium operating systems principles pages december 
lazowska 
processor cache affinity shared memory multiprocessor scheduling 
ieee transactions parallel distributed systems february 
leblanc marsh scott 
memory management large scale numa multiprocessors 
technical report tr department computer science university rochester march 
leblanc mellor crummey 
multiprocessor operating system 
software practice experience november 
leblanc 
shared memory versus message passing tightly coupled multiprocessor case study 
proceedings international conference parallel processing pages august 
thomas leblanc friedberg 
hierarchical process composition distributed operating systems 
proceedings th international conference distributed computing systems denver colorado pages may 
leiserson network architecture connection machine cm 
proceedings acm symposium parallel algorithms architectures 
leutenegger vernon 
performance multiprogrammed multiprocessor scheduling policies 
proceedings acm sigmetrics conference measurement modeling computer systems pages may 
levin cohen pollack wulf 
policy mechanism separation hydra 
proceedings th symposium operating system principles austin texas nov 
levy 
computer programming architecture 
digital press 
li 
shared virtual memory loosely coupled multiprocessors 
phd thesis dept computer science yale university 
kai li paul hudak 
memory coherence shared virtual memory systems 
acm transactions computer systems november 
liedtke 
fast thread management communication continuations 
proceedings usenix workshop micro kernels kernel architectures pages april 
bert lindgren bobby mostafa ammar karsten schwan 
architecture toolkit parallel configurable protocols 
proceedings international conference network protocols icnp september 
liskov 
abstraction mechanisms clu 
communications acm march 
barbara liskov robert scheifler 
guardians actions linguistic support robust distributed programs 
acm trans 
prog 
lang 
systems july 
liu james layland 
scheduling algorithms multiprogramming hard real time environment 
journal association computing machinery january 
livny manber 
distributed computation active messages 
ieee transactions computers dec 
livny manber 
active channels applications parallel computing 
proceedings international conference parallel processing pages august 
lo 
comparative analysis multiprocessor scheduling algorithms 
proceedings th international conference distributed computing systems september 
douglas locke 
best effort decision making real time scheduling 
phd thesis carnegie mellon university 
campbell russo cook 
class hierarchy building stream oriented file systems 
proceedings european conference object oriented programming ecoop pages july 
russo campbell 
class hierarchy building unix file systems 
proceedings usenix conference pages october 
majumdar eager bunt 
scheduling multiprogrammed parallel systems 
proceedings acm sigmetrics conference measurement modeling computer systems pages may 
majumdar eager bunt 
characterisation programs scheduling multiprogrammed parallel systems 
performance evaluation october 
shapiro 
library fragmented object types distributed abstractions 
proceedings international workshop object orientation operating systems pages october 
marsh brown leblanc scott becker das karlsson 
rochester checkers player multimodel parallel programming animate vision 
ieee computer february 
marsh scott leblanc markatos 
class user level threads 
proceedings thirteenth acm symposium operating systems principles pages october 
massalin pu 
reimplementing synthesis kernel sony news workstation 
proceedings usenix workshop micro kernels kernel architectures pages april 
henry massalin calton pu 
threads input output synthesis kernel 
proceedings th symposium operating systems principles pages 
sigops assoc 
comput 
mach dec 
mccann zahorjan 
dynamic processor scheduling multiprogrammed shared memory multiprocessors 
technical report department computer science engineering university washington march 
mcjones swart 
evolving unix system interface support multithreaded programs 
proceedings usenix winter conference pages 
mealy witt clark 
functional structure os 
ibm systems journal january 
mellor crummey leblanc 
objectoriented multiprocessor operating system 
technical report bpr department computer science university rochester september 
mellor crummey scott 
algorithms scalable synchronization sharedmemory multiprocessors 
acm transactions computer systems feb 
mogul borg 
effects context switches cache performance 
proceedings fourth international conference architectural support programming languages operating systems sigplan notices vol pages april 
joseph mohan 
performance parallel programs model analyses 
phd thesis computer science department carnegie mellon university pittsburgh pa july 
moore siewiorek neil 
encore multimax tm multiprocessor computing environment 
technical report etr encore computer 
russo 
distributed object interoperability network type system 
proceedings international workshop object orientation operating systems pages october 
mukherjee 
portable reconfigurable threads package 
proceedings sun user group technical conference pages june 
mukherjee greg kaushik ghosh 
machine independent interface lightweight threads 
technical report git cc college computing georgia institute technology august 
published operating system review 
mukherjee karsten schwan 
experimentation reconfigurable micro kernel 
proc 
usenix symposium microkernels kernel architectures pages september 
mukherjee karsten schwan 
experiments configurable lock multiprocessors 
proc 
international conference parallel processing volume pages august 
mukherjee karsten schwan 
improving performance adaptive objects experimentation configurable multiprocessor thread package 
proc 
second international symposium high performance distributed computing pages july 
mukherjee karsten schwan 
survey real time operating systems 
technical report git cc college computing georgia institute technology march 
needham 
cambridge cap computer protection system 
proceedings th acm symposium operating systems principles pages purdue university november 
assoc 
comput 
mach sigops 
nelson 
remote procedure call 
phd thesis department computer science carnegie mellon university may 

implementation evaluation parallel algorithms multiprocessor 
phd thesis carnegie mellon university 
ousterhout 
scheduling techniques concurrent systems 
proceedings distributed computing systems conference pages october 
ousterhout 
partitioning cooperation distributed operating system 
phd thesis department computer science carnegie mellon university april 
john ousterhout donald pradeep 
medusa experiment distributed operating system structure 
comm 
assoc 
comput 
mach feb 
ieee posix 
threads extension portable operating systems 
pallas ungar 
multiprocessor smalltalk case study programming environment 
proceedings sigplan conference programming language design implementation sigplan notices vol pages atlanta ga june 
park 
dynamic partitioning multiprocessor systems 
international journal parallel programming april 
patterson hennessy 
computer architecture quantitative approach 
morgan kaufman publishers san mateo calif 
powell kleiman barton shah stein weeks 
sunos multi thread architecture 
proceedings usenix winter conference pages 
rashid 
threads new system 
unix review 
rashid 
rig accent mach evolution network operating system 
proceedings acm ieee computer society fall joint computer conference pages november 
rashid baron forin golub jones orr 
mach foundation open systems 
proceedings nd workshop workstation operating systems ieee pages september 
rashid robertson 
accent oriented network operating system kernel 
proceedings th acm symposium operating systems principles pages december 
rashid tevanian young golub baron black bolosky chew :10.1.1.111.7918
machine independent virtual memory management paged uniprocessor multiprocessor architectures 
ieee transactions computers august 
kendall square research 
technical summary 
ritchie thompson 
unix time sharing system 
communications assoc 
comput 
mach 
rozier armand kaiser leonard 
overview chorus operating system 
proceedings usenix workshop micro kernels kernel architectures pages april 
russo 
object oriented operating system design 
newsletter 
russo campbell 
virtual memory backing storage management multiprocessor operating systems object oriented design techniques 
oopsla conference proceedings sigplan notices vol pages october 
russo johnston campbell 
process management exception handling multiprocessor operating systems object oriented design techniques 
proceedings rd annual conference object orientated programming systems languages applications oopsla sigplan notices vol pages september 
russo campbell 
operating systems performance case study 
proceedings usenix conference pages april 
russo 
process scheduling synchronization renaissance object oriented multiprocessor operating system 
proceedings nd usenix symposium experiences distributed multiprocessor systems ii pages march 
russo 
object oriented operating system 
phd thesis department computer science university illinois urbana champaign 
sadayappan 
nearest neighbor mapping finite element graphs processors meshes 
ieee transactions computers dec 
salmon callahan 
moose multitasking os hypercubes 
proceedings rd conference hypercube concurrent computers applications pasadena ca pages 
acm jpl jan 
saltzer schroeder 
protection information computer systems 
proceedings ieee september 
schroeder burrows 
performance firefly rpc 
acm transactions computer systems february 

performance birlix operating system 
proceedings usenix workshop micro kernels kernel architectures pages april 
karsten schwan thomas ben blake 
adaptive reliable software distributed parallel real time systems 
proceedings sixth symposium reliability distributed software williamsburg virginia pages 
ieee march 
karsten schwan tom bruce weide gregor 
high performance operating system primitives robotics real time control systems 
acm transactions computer systems aug 
karsten schwan win bo 
topologies distributed objects multicomputers 
acm transactions computer systems may 
karsten schwan harold forbes ahmed mukherjee 
library multiprocessors 
technical report git ics college computing georgia institute technology 
karsten schwan gopinath win bo 
chaos kernel support objects real time domain 
ieee transactions computers july 
karsten schwan anita jones 
specifying resource allocation cm multiprocessor 
ieee software may 
karsten schwan rajiv 
adaptable operating software manufacturing systems robots computer science research agenda 
proceedings th real time systems symposium austin texas pages 
ieee dec 
karsten schwan zhou ahmed 
multiprocessor real time threads 
operating systems review oct 
appears jan issue operating systems review 
scott leblanc marsh 
design rationale psyche general purpose multiprocessor operating system 
proceedings international conference parallel processing ii software pages august 
scott leblanc marsh 
evolution operating system large scale shared memory multiprocessors 
technical report tr department computer science university rochester march 
scott leblanc marsh 
multi model parallel programming psyche 
proceedings second acm sigplan symposium principles practice parallel programming pages march 
scott leblanc marsh becker markatos 
implementation issues psyche multiprocessor operating system 
computing systems winter 
seitz 
reactive kernel 
proceedings rd conf 
hypercube concurrent computers applications pasadena ca pages 
acm jan 
charles seitz william 
multicomputers message passing concurrent computers 
ieee computer august 
sequent computer systems programmer manual 
sequent computer systems symmetry technical summary rev 
sevcik 
characterizations parallelism applications scheduling 
proceedings acm sigmetrics conference measurement modeling computer systems pages may 
shapiro 
structure encapsulation distributed systems proxy principle 
proceedings sixth international conference distributed computing systems boston mass pages 
ieee may 
shapiro 
object support operating systems 
newsletter 
shapiro 
sos object oriented operating system assessment perspectives 
computing systems december 
shapiro 
distributed abstractions lightweight 
proceedings usenix workshop micro kernels kernel architectures pages april 
solomon finkel 
roscoe distributed operating system 
proceedings th symposium operating system principles asilomar ca pages 
assoc 
comput 
mach dec 
spector daniels duchamp pausch 
distributed transactions reliable systems 
proceedings eleventh acm symposium operation systems principles pages 
acm sigops nov 
nelson 
analysis task migration shared memory multiprocessor scheduling 
proceedings acm sigmetrics conference measurement modeling computer systems pages may 
harold stone 
high performance computer architecture 
addison wesley pub 
reading mass 
stumm zhou 
algorithms implementing distributed shared memory 
ieee computer may 
sturgis 
time sharing system 
technical report csl xerox 
sun 
sparc architecture manual 
sun microsystems version january 

resilient distributed computing 
ieee transactions software engineering pages may 
swan fuller siewiorek 
cm modular multi microprocessor 
proceedings national computer conference pages 
assoc 
comput 
mach 
tanenbaum 
operating systems design implementation 
prentice hall englewood cliffs nj 
tanenbaum 
modern operating systems 
prentice hall englewood cliffs nd edition 
tanenbaum van renesse 
distributed operating systems 
computing surveys december 
tevanian rashid 
mach basis unix development 
technical report cmu cs school computer science carnegie mellon university june 
tevanian rashid golub black cooper young 
mach threads unix kernel battle control 
proceedings summer usenix conference pages june 
tevanian rashid young golub thompson bolosky 
unix interface shared memory memory mapped files mach 
proceedings summer usenix conference pages june 
stone 
footprints cache 
acm transactions computer systems november 
thinking machines cambridge massachusetts 
connection machine cm technical summary october 
thomas 
uniform system approach runtime support large scale shared memory parallel processors 
proceedings international conference parallel processing ii software pages august 
torrellas tucker gupta 
benefits cache affinity scheduling sharedmemory multiprocessors 
proceedings acm sigmetrics conference measurement modeling computer systems pages may 
tucker gupta 
process control scheduling issues multiprogrammed shared memory multiprocessors 
proceedings th acm symposium operating systems principles pages december 
zahorjan 
implications cache affinity processor scheduling multiprogrammed shared memory multiprocessors 
proceedings thirteenth acm symposium operating systems principles pages october 
walpole inouye 
modularity interfaces micro kernel design implementation case study chorus hp pa risc 
proceedings usenix workshop micro kernels kernel architectures pages april 
wehner brown 
high performance distributed memory climate model 
proceedings nd international symposium high performance distributed computing pages july 
weide brown meyer 
graphical interconnection language application concurrent real time programming 
proceedings th annual allerton conf 
comm control comp univ ill pages 
ieee oct 
weiser demers hauser 
portable common run time approach interoperability 
proceedings th acm symposium operating systems principles pages december 

operating system application concurrency tightly coupled multiprocessor systems 
phd thesis school computer science carnegie mellon university december 
technical report cmu cs 
wulf 
reliable hardware software architecture 
ieee transactions software engineering se june 
wulf cohen jones levin pierson pollack 
hydra kernel multiprocessor operating system 
communications acm june 
wulf levin harbison 
hydra mmp experimental computer system 
mcgraw hill advanced computer science series 
wulf levin pierson 
overview hydra operating system 
proceedings th symposium operating system principles austin texas pages 
acm nov 
kwong 
survey implementations concurrent parallel distributed smalltalk 
sigplan notices september 
pen chung yew feng duncan lawrie 
distributing hot spot addressing large scale multiprocessors 
ieee transactions computers april 
young tevanian rashid golub chew bolosky black baron 
duality memory communication implementation operating system 
proceedings th acm symposium operating systems principles sigops notices vol pages november 
young 
exporting user interface memory management operating system 
phd thesis school computer science carnegie mellon university november 
technical report cmu cs 
tse yun feng 
survey interconnection networks 
ieee computer pages december 
zahorjan lazowska amd eager 
spinning versus blocking parallel systems uncertainty 
proceedings international performance distributed parallel systems december 
zahorjan lazowska eager 
effect scheduling discipline spin overhead shared memory parallel systems 
ieee transactions parallel distributed systems april 
zahorjan mccann 
processor scheduling shared memory multiprocessors 
proceedings acm sigmetrics conference measurement modeling computer systems pages may 
wei zhao ramamritham stankovic 
preemptive scheduling time resource constraints 
ieee transactions computers august 
zhou karsten schwan 
dynamic scheduling hard real time systems real time threads 
proceedings joint ieee workshop real time operating systems software ifac workshop real time programming atlanta ga ieee may 
zhou karsten schwan ian akyildiz 
performance effects information sharing distributed multiprocessor real time scheduler 
technical report college computing georgia tech git cc sept 
abbreviated version proceedings ieee real time systems symposium phoenix 
zhou stumm li 
heterogeneous distributed shared memory 
ieee transactions parallel distributed systems september 
