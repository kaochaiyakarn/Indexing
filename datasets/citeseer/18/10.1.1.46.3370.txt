baluja baluja cs cmu edu pittsburgh research center carnegie mellon university trying solve combinatorial optimization problem multiple algorithms multiple runs algorithm order find multiple local minima 
information gained previous search runs commonly discarded selecting initialization points runs 
method uses information previous runs determine promising starting points searches 
algorithm termed comit models inter parameter dependencies previously solutions 
comit incrementally learns optimal dependency trees model pairwise dependencies set solutions previous searches 
comit samples probability distributions modeled trees generate new starting points searches 
algorithm successfully applied jobshop scheduling traveling salesman knapsack rectangle packing bin packing problems 
combining multiple optimization runs optimal dependency trees scott davies cs cmu edu school computer science carnegie mellon university trying solve combinatorial optimization problem multiple algorithms multiple runs algorithm order find multiple local minima 
information gained previous search runs commonly discarded selecting initialization points runs 
method uses information previous runs determine promising starting points searches 
algorithm termed comit models inter parameter dependencies previously high evaluation solutions 
comit incrementally learns optimal dependency trees model pairwise dependencies set solutions previous searches 
comit samples probability distributions modeled trees generate new starting points searches 
algorithm successfully applied jobshop scheduling traveling salesman knapsack rectangle packing bin packing problems 
pittsburgh research center henry st pittsburgh pa baluja cs cmu edu school computer science carnegie mellon university pittsburgh pa cs cmu edu combining multiple optimization runs optimal dependency trees baluja scott davies june cmu cs scott davies supported graduate student research fellowship national science foundation 
views contained document authors interpreted representing official policies expressed implied national science foundation 
keywords combinatorial optimization dependency trees probability models bayesian networks heuristic search 
implicitly explicitly black box combinatorial optimization algorithms concentrate generation candidate solutions regions solution space close best previously solutions 
example hillclimbing simulated annealing generate candidate solutions directly neighboring previously discovered solutions 
genetic algorithms crossover operator combine pairs previously solutions new candidate solutions placing random subsets parents bits respective positions child solution 
concentrating generation candidate solutions manner algorithms manage find solutions having explore search space 
inevitable side effect concentration algorithms converge solutions compared closely related solutions far optimal 
consequently algorithms restarted random initialization points rerun hope find better local optima 
performing restarts information gained analyzing various local optima multiple search runs looking features common 
information intelligently select new starting points searches 
example best locally optimal solutions far bit set opposite value bit may sense favor solutions generating new initialization points searches 
selection mechanisms help search procedure ways increasing chance local optima better previously local optima second decreasing number solution evaluations required local optima attained 
approach ascertaining information explored boyan moore predicted eventual fitness achieved hillclimbing runs high level information previously solutions 
describe comit algorithm combining optimizers mutual information trees 
algorithm uses optimal dependency trees probabilistic models dependencies exhibited solutions previous optimization runs 
sampling probabilistic models increase probability selecting starting points basins search space lead solutions 
method significantly improves quality solutions fixed number solution evaluations large set optimization problems 
probabilistic models generate starting points optimization algorithms imagine inserting bit strings generated model directly back data set model immediately updating model 
approach previous de bonet baluja davies 
mimic algorithm heuristic greedy search generate chain variable conditioned previous variable de bonet 
baluja davies extended larger class models trees search technique guaranteed find optimal tree structure 
far approaches optimizing relatively small problems extending models large problems challenging computational expense large sizes data sets needed model search space prematurely converging search 
overcoming problems currently avenue research 
explore alternate models combining runs multiple faster search algorithms 
gain benefits modeling dependencies search space significantly reduced computational cost 
approach advantage able combine strengths different search algorithms allowing algorithm contribute solutions probabilistic model 
ability important algorithm different bias causes search different parts solution space allowing contribute diversity solutions dependencies modeled 
section describe comit algorithm 
section provide empirical results demonstrating effectiveness algorithm 
restrict attention combining results multiple hillclimbing runs extending algorithm underlying combinatorial optimization algorithms straightforward 
section close directions research 
modeling dependencies comit suppose set solutions previous hillclimbing runs 
assume solutions encoded binary bitstrings higher cardinality alphabets easily 
wish discover dependencies exhibited bit strings information generate starting points hillclimbing runs 
try model probability distribution bit strings length variables corresponding values bits 
try learn simplified model empirical probability distribution entailed bitstrings baluja davies restrict model form unknown permutation maps integers integers definition equal words restrict factorizations conditional probability distribution bit depends value bit 
bayesian network terms means models node parent 
method finding optimal model restrictions chow liu 
complete weighted graph created variable represented corresponding vertex weight ij edge vertices set mutual information edges maximum spanning tree determine optimal set conditional probabilities model original probability distribution 
edges undirected decision directionality dependencies construct orderings conforming equation model identical distributions 
trees algorithm produces tree maximizes likelihood data algorithm applied empirical observations drawn unknown distribution 
calculate empirical probabilities form combinations binary assignments 
probabilities calculate mutual information pairs variables maximum spanning tree algorithm identical baluja davies slight variation algorithm originally proposed chou liu select set dependencies maximizes 
log distributions form specified equation distribution minimizes kullback leibler divergence shown chow liu distribution maximizes likelihood dataset optimally models pairwise dependencies exhibited 
tree generation algorithm summarized runs time size number bits solution encoding 
chosen model stochastically generate candidate solutions 
evaluate solutions best solutions starting point new hillclimbing run 
hillclimbing run terminated select subset solutions evaluated run place dataset max influence solutions replaced better solutions generated hillclimbing run size kept constant 
max influence high single hillclimbing cause prematurely converge set similar solutions 
max influence low hillclimbing run large influence history affect search 
shows hillclimbing inner loop finding solutions model dependencies 
log generate optimal dependency tree set root arbitrary bit root bits set root bits added tree bits tree pick bit add maximum mutual information add add estimate relevant probability distributions 
add add tree add parent 
bit tree compare add 
add greater set add procedure generating dependency tree 
initialize dataset bitstrings drawn uniform distribution termination condition met create optimal dependency tree probabilistic model shown 
model stochastically generate bitstrings 
evaluate bitstrings 
execute hillclimbing run starting single best bitstring replace max influence bitstrings best bitstrings hillclimbing run just executed 
user defined constants constant size dataset number samples generate tree hillclimbing max influence max number elements replace single hillclimbing run 
comit algorithm integrating hillclimbing dependency tree 
empirical comparisons algorithm details hillclimbing hc test ideas ascent stochastic hillclimbing 
commonly done heuristic combinatorial optimization solutions encoded binary vectors 
hillclimbing algorithm interesting properties 
allows moves solutions higher equal evaluation extremely important hillclimbing complicated spaces allows hc explore plateaus 
restarting allow patience evaluations worse best evaluation seen far run 
evaluations equal best evaluation seen far counted patience evaluations course counted total evaluations 
parameter large impact effectiveness hillclimbing large search spaces 
problem multiple settings tried parameter 
range values length solution encoding 
results best solution settings reported 
second ascent hillclimber means soon better solution accepted 
contrasts hillclimbing searches possible single bit flips accepts largest improvement 
steepest ascent hillclimbing problems explored 
see hillclimbing algorithm shown detail 
comit experiment versions comit algorithm termed comit samples tree times selecting best point termed comit samples tree times 
note extra evaluations randomly generate binary vector best evaluate iterations worse eval iterations worse eval evaluations evaluations bit random solution encoding length bit flip bit bit new eval evaluate new eval bit flip bit bit iterations worse eval best new eval new eval best iterations worse eval user defined constants solution encoding length length solution vector problem specific 
patience max number evaluations worse best seen far 
max evals max number evaluations allowed run 
detailed description hillclimbing algorithm set maximize returned evaluation 
details reproducibility 
evaluations counted total number evaluations allowed 
parameters need set comit 
study set size max influence 
kept constant experiments 
hillclimbing run initialized bitstrings randomly chosen uniform distribution 
max influence size chosen brief experimentation traveling salesman problem tsp 
results shown 
initially see size increases solution quality increases 
solutions modeling dependencies 
size increased solution quality declines 
run fixed number evaluations 
initialized random bitstrings replaced effectively 
large takes hillclimbing runs replace bitstrings 
way avoid problem start smaller data set grow data available 
approach suffer narrowing search quickly initial stages algorithm 
augmented hillclimbing ahc possible confounding factor determining effective comit comparison hc fact comit examines points choosing hillclimbing 
ensure simply process selecting hillclimbing gives performance gains augment hillclimbing follows 
run ahc examines randomly chosen points 
selects best starting position hillclimber 
difference comit comit samples points generated dependency tree 
versions ahc examined ahc ahc 
problem descriptions 
traveling salesman problems tsp encoding study requires bit string size nlog bits number cities problem 
city assigned substring length log interpreted integer 
city lowest integer value comes tour city second lowest comes second case ties city substring comes bit string comes tour 
encoding taken syswerda 
minimize tour length evaluation tour length 
length tour length tour length function dataset size data set size final solution quality tsp domain function size dataset learn dependency trees 
experiments max influence 
experiments changing max influence underway 

jobshop scheduling problems problem encoded ways 
encoding derived fang 
exact encoding fang baluja 
difference encoding fang study bit strings encode integers standard binary encoding range contrast fang genetic algorithm applied crossover selected portions bitstring 
makespan minimized evaluation potential solution makespan 
standard test problems attempted job machine problem job machine problem 
description problems muth thompson 
second encoding similar encoding traveling salesman problem 
drawback encoding uses bits previous 
empirically revealed improved results 
job assigned entries size log bits 
total length encoding log 
value entry length log determines order jobs scheduled 
job contains smallest valued entry scheduled order machines selected job depends ordering required problem specification 

knapsack problem version knapsack problem single bin limited capacity elements varying sizes values 
problem select elements yield greatest summed value exceeding capacity bin 
evaluation quality solution judged ways solution selects elements summed size elements larger bin size solution judged exceeds capacity bin exceeds capacity better solution 
sum element sizes capacity bin sum values selected elements evaluation 
ensure solutions bin competitive evaluations multiplied small constant 
invalid solutions competitive solutions valid 
evaluations described 
weights values problem randomly generated 

bin packing equal piles version bin packing problem bins varying capacities elements varying sizes 
problem pack bins elements tightly possible exceeding maximum capacity bin 
problems attempted error measured size size value size greater capacity bin size equal capacity bin error cap assigned cap capacity bin assigned total size elements bin solution encoded bit string length log element packed assigned sequential substring length log value indicates bin element placed 
order minimize error evaluation potential solution error 

rectangle packing object problem pack rectangles tight possible page leaving space bottom page possible 
problem encoded log bits 
rectangle assigned unique log bits interpreted integer 
number dictates order rectangles placed page 
rectangle placed placed high left page possible 
changing order rectangles placed page change final configuration rectangles 
evaluation function tries maximize number rectangles page rectangles chosen fit page accomplished maximize amount room left bottom page 

summation cancellation problem parameters solution string large influence quality solution 
goal minimize magnitudes cumulative sums parameters 
small changes parameters cause large changes evaluation 
evaluation problem parameters parameter represented bits encoded standard base values uniformly spaced 
results problems try algorithms mentioned 
algorithm problem try multiple settings patience parameter 
setting patience parameter gives best result report 
done give hc ahc advantage case lowest setting patience parameter worked best comit 
results reported average runs 
algorithm function evaluations problem 
results shown table summary results relative ranks algorithms provided table ii best worst 
additionally significance difference results measured mann whitney test non parametric equivalent test 
problem examined comit significantly improves performance hillclimbing 
comparison ahc hc comit comit performed best problem 
provide intuition comit algorithm progresses shows values evaluation performed hc comit algorithm tsp domain 
features noticed 
spikes evaluations correspond hillclimbing runs 
comit graph spikes represent samples generated sampling tree 
second comit algorithm random initial samples dataset entirely removed evaluation approximately corresponds number evaluations hillclimbing runs run contributed samples table performance hc ahc comit problem problem size bits hc mean std 
dev ahc mean std 
dev ahc mean std 
dev comit mean std 
dev comit mean std 
dev tsp city minimization jobshop problem encoding minimization jobshop problem encoding minimization jobshop problem encoding minimization bin packing elements bins minimization knapsack elements maximization rectangle packing rectangles evaluation minimization sum 

params bits minimization table ii relative ranks hc ahc comit algorithm rank highlighted problem problem size bits hc ahc ahc comit significance 
comit vs comit significance 
comit vs hc ahc ahc hc ahc ahc tsp city jobshop problem encoding jobshop problem encoding jobshop problem encoding bin packing elements bins knapsack elements rectangle packing rectangles sum 

params bits dataset size 
third magnitude spikes comit plot gradually decreases corresponds comit algorithm learning seed hillclimbing runs high quality solutions 
fourth importantly hc runs started noticeably better solutions final solutions hillclimbing run improved standard hillclimbing initial points search 
dependency models generate starting points hillclimbing runs started basins search space lead high evaluation solutions 
shown information gathered previous search runs effectively initializing new searches 
model dependencies previously solutions generated starting points allowed search algorithm concentrate effort promising regions search space 
problems examined led discovery significantly better final solutions 
probabilistic model updated relatively infrequently comit hillclimbing runs may feasible replace dependency trees sophisticated computationally expensive models general bayesian networks 
model arbitrary sets dependencies 
generating network scratch hillclimbing run previous network starting point search network structures model updated dataset modifications previous hillclimbing run searching new bayesian network may relatively inexpensive 
graphs show values evaluation performed hc top comit bottom algorithms tsp domain 
object minimize tour length 
note runs extended evaluations 
tour length evaluation number comit hc purpose advocate comit hillclimbing sophisticated optimization algorithms 
purpose show multiple runs optimizer information obtained run guide searches 
showed incorporate comit hillclimbing 
requires change search algorithms simulated annealing genetic algorithms hillclimbing tabu search glover pbil baluja 
population methods genetic algorithms initialize population 
additionally method multiple search algorithms best solutions search algorithm update pair wise statistics 
trees generated sampled provide initial samples searches 
baluja 
genetic algorithms explicit search statistics advances neural information processing systems 
mozer jordan petsche 
eds 
mit press 
available technical report carnegie mellon university cmu cs www cs cmu edu baluja 
baluja davies 
optimal dependency trees combinatorial optimization learning structure search space proc 
international conference machine learning 
available tech report 
boyan moore 
prediction improve global optimization search submitted 
chou 
liu 
approximating discrete probability distributions dependence trees 
ieee transactions information theory 
de bonet isbell viola 
mimic finding optima estimating probability densities advances neural information processing systems 
mozer jordan petsche 
eds 
fang ross corne promising ga approach job shop scheduling rescheduling open shop scheduling problems 
proc 
int 
conf 
genetic algorithms 
forrest ed 
morgan kaufmann 
glover 
tabu search part orsa journal computing 
muth thompson industrial scheduling prentice hall international 
englewood cliffs nj 
syswerda 
uniform crossover genetic algorithms int 
conf 
genetic algorithms 

