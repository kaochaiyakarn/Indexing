implementation karmarkar algorithm linear programming ilan adler narendra karmarkar mauricio resende veiga 
describes implementation power series dual affine scaling variants karmarkar algorithm linear programming 
continuous version karmarkar algorithm variants resulting second order approximations continuous trajectory implemented tested 
linear programs expressed inequality form allows inexact computation algorithm direction improvement resulting significant computational advantage 
implementation issues particular family algorithms treatment dense columns discussed 
code tested standard linear programming problems compares favorably simplex code minos 
describe family interior point power series affine scaling algorithms linear programming algorithm karmarkar 
algorithms family corresponding second order power series approximations implemented fortran period november march 
tested publicly available linear programming test problems gay 
test algorithms randomly generated multi commodity network flow problems ali timber harvest scheduling problems johnson 
authors see aronson barr loh zaki lustig tomlin tone compared implementations interior point algorithms simplex method codes unable obtain competitive solution times 
implementation projected newton barrier method reported gill murray saunders tomlin wright presents extensive computational evidence indicating interior point algorithm comparable speed simplex method 
computational experiments solution times interior point implementations cases required minos murtagh saunders 
furthermore typically able achieve digit accuracy optimal objective function value experiencing numerical difficulties reported previous implementations 
minos fortran code intended primarily solution constrained nonlinear programming problems includes advanced implementation simplex date march revised may 
key words phrases 
linear programming karmarkar algorithm interior point methods 
article originally appeared mathematical programming 
errata correcting description power series algorithm published mathematical programming 
version incorporates corrections body article 
addition updated articles published final form publication 
request authors refer article original bibliographical 
adler karmarkar resende veiga method 
updated version minos murtagh saunders features scaling option improved set routines computing updating sparse lu factors 
latest version minos available university california berkeley computational tests described carried 
believe purposes study minos constitutes reasonable benchmark simplex implementation 
furthermore evidenced results reported gill 
expect minos perform significantly faster test problems considered 
plan follows 
section describe algorithm basic interior point method commonly referred affine scaling algorithm 
algorithm takes infinitesimal steps iteration resulting continuous trajectory described system differential equations 
section discuss family algorithms constructed truncating taylor expansion representing solution system differential equation 
order approximation taylor expansion results algorithm implement algorithm ii obtained truncating taylor expansion second order polynomial 
show section initial interior solution obtained section algorithms applied general linear 
section describe stopping criterion computational experiments 
section discusses implementation issues including symbolic numerical factorizations approximate scaling matrix reducing fill gaussian elimination conjugate gradient algorithm preconditioning solve problems dense columns 
section report computational results running algorithms sets test problems 
set family publicly available linear programs variety sources 
respectively randomly generated multi commodity network flow problems timber harvest scheduling problems 
compare results simplex code minos case multi commodity network flow problems mcnf specialized simplex code multi flow 
research outlined section 
description algorithm consider linear programming problem maximize subject ax vectors vector full rank matrix 
assumptions relaxed require interior feasible solution expressing standard equality form prefer inequality formulation 
discussed section computational advantages selection search directions formulation 
section show apply approach linear programs standard form 
algorithm described variation karmarkar original projective algorithm karmarkar substituting affine transformation projective transformation objective function potential function 
came attention algorithm proposed independently 
similar algorithms discussed barnes vanderbei freedman 
express linear programming problem standard equality form 
taxonomy referred hooker algorithms implementation karmarkar algorithm classified dual affine scaling algorithms 
algorithms equivalent primal counterparts applied problems inequality form 
starting algorithm generates sequence feasible interior points 

monotonically increasing objective values ax terminating stopping criterion discussed satisfied 
introducing slack variables formulation maximize subject ax vector slack variables 
affine variants karmarkar algorithm consist scaling operation applied followed search procedure determines iterate 
iteration current iterates linear transformation applied solution space diag 

slack variables scaled equidistant hyperplanes generating closed half spaces intersection forms transformed feasible polyhedral set ax 
rewriting equations terms scaled slack variables maximize subject ax set feasible solutions denoted ax set feasible scaled slacks ax 
observed full rank assumption relationship ax 
corresponding relationship linking feasible directions ah adler karmarkar resende veiga 
observe feasible direction lies range space presentations affine variants karmarkar algorithm search direction selected iteration projected objective function gradient respect scaled variables 
slack variables changed affine transformation compute gradient objective function respect 
gradient respect scaled slacks lies range space making projection unnecessary 
consequently search direction corresponding feasible direction computed 
applying inverse affine transformation obtain corresponding feasible direction unscaled slacks 
assumption unboundedness detected 
iterate computed maximum feasible step direction retracting back interior point safety factor ah min 

formulation allows inexact projections loss feasibility 
computed exactly pair feasible search direction obtained computing ah 
interior feasible solution stopping criterion safety factor pseudocode describes algorithm outlined section 
subsequent instances algorithms expressed algol algorithmic notation described tarjan 

family interior point algorithms power series approximations consider continuous trajectory generated algorithm infinitesimal steps taken iteration bayer lagarias 
denote path interior feasible solutions real parameter continuous counterpart iteration counter 
value corresponding search directions computed expressions 
alternatively search directions described equivalent system linear equations implementation karmarkar algorithm 
procedure algorithm stopping criterion 

stopping criterion satisfied 
ax 
diag 


ah 
return fi 
min 

ah 

od 
algorithm pseudo code algorithm ah 
infinitesimal steps resulting continuous trajectory dt dt 
system linear equations replace search directions corresponding derivatives respect trajectory parameter resulting system nonlinear order differential equations dt dt dt boundary conditions initial solution satisfies ax 
trajectory satisfying theoretically obtain optimal solution adler monteiro 
practice build iterative procedure replacing current iterate initial solution boundary condition approximate solution computed truncated taylor power series expansion 
iterate determined search approximate trajectory 
discussed section search procedure requires suitable continuous trajectory monotonically increasing infinitely differentiable real function 
dv dt dr dt adler karmarkar resende veiga dx dt dv dt boundary conditions 
compute exact solution approximate solutions system differential equations backbone family iterative algorithms 
iteration algorithm restarts trajectory initial solution 
new iterate generated moving approximate trajectory violating nonnegativity slack variables 
approximate solutions computed means truncated taylor expansion order karmarkar lagarias wang 
dt 
dt 
compute derivatives orders 
consider functions satisfy 
applying leibniz differentiation theorem product 

dt dt 
derivatives computed recursively dt dt 

dt dt 
derivatives sides rewriting left hand side equation terms dt dt 
combining appropriate derivative system linear equations recursively computes derivatives evaluated dt dt 

dt dt dt dt 
implementation karmarkar algorithm implementable reformulation eliminate binomial terms defining 
dt 
dt 
dt 
dt 
solving az 
approximate trajectory power series order rewritten 
iteration iterate computed sup 

selecting suitable line search computes limited interval 
depend solely derivatives evaluated desired fully characterized constants 
values computed selecting row index forcing dt 

consider search directions ah 

adler karmarkar resende veiga assumptions full rank unboundedness detected 
determine row index performing ratio test search direction argmin 
operation corresponds searching order approximation trajectory 
conditions imposed truncated taylor expansion compute 
iteratively 
compute az 
ah 
satisfy 
pseudo code formalizes algorithm truncated power series order computational experiments reported section include algorithm ii second order version algorithm 
practical implementation additional computational effort compared algorithm dominated solution systems symmetric linear equations compute 
algorithm obtained exactly pair feasible trajectories immediately available 
computing az 
guarantee feasible maximum feasible step 

initial solution algorithm truncated power series algorithms require initial interior solution provided 
solution necessarily exist generic linear program starting solution close faces feasible polyhedral set imply slow convergence megiddo shub propose phase phase ii scheme solve artificial problem single artificial variable having large cost coefficient assigned 
firstly compute tentative solution ac 
computational experiments reported section compute initial value artificial variable min ax 

implementation karmarkar algorithm 
procedure stopping criterion 

stopping criterion satisfied 

ax 
diag 

ah 
return fi 
argmin 






ah 

az 

rof 

sup 



od 
pseudo code power series algorithm occur test problems reported computation 
consequently application generic linear programs recommend alternative computation initial value artificial variable ax 
vector interior solution phase linear programming problem maximize mx subject ax ex 

large artificial cost coefficient computed function problem data large constant 
initially algorithm applied modified stopping criterion 
phase stage algorithm identifies interior dual feasible solution solution adler karmarkar resende veiga exists finds solution satisfies stopping criterion problem defined feasibility tolerance modified stopping criterion phase formulated follows iteration interior feasible solution problem 
ii algorithm satisfies regular stopping criterion declared infeasible 
iii algorithm satisfies regular stopping criterion unboundedness detected optimal solution 
case interior feasible solution 
phase terminates condition algorithm applied problem starting iterate phase regular stopping criterion 

application general linear programming problem common practice formulate linear programming problem 
standard form usually preferred lpp minimize subject matrix vector vectors 
dual linear programming problem desired form lpd maximize subject ax vector 
note lpd identical defined 
iteration current solutions tentative dual solution defined diag 

computation tentative dual solution similar suggested todd performed scaling order search direction iteration algorithm 
iteration 
tentative dual solution minimizes deviation complementary slackness respect current iterate relaxing nonnegativity constraints 
formally consider problem minimize subject 
tentative dual solution solution karush kuhn tucker stationary conditions minimization problem 
implementation karmarkar algorithm sequence feasible primal solutions converging optimal solution corresponding sequence tentative dual estimates converges optimal dual solution 

stopping criterion computational experiments reported study algorithms ii terminated relative improvement objective function small max small positive tolerance 
tentative dual solution computed build alternative stopping criterion 
satisfy 
duality theory linear programming optimal lpp optimal lpd 
automatically satisfied stopping criterion replacing algorithm terminates 

small positive tolerances relations serve verification approximate optimal solutions lpd lpp respectively 
unboundedness lpd theoretically detected algorithm ratio tests involving order search direction fail 
practice additional test required lpd declared unbounded objective function value exceeds supplied bound 

implementation issues section briefly discuss important characteristics implementation 
detailed description data structures programming techniques implementation algorithms ii subject adler karmarkar resende veiga 

computing search directions 
variants karmarkar algorithm main computational requirement algorithms described consists solution sequence sparse symmetric positive definite systems linear equations determining search directions iteration 
algorithm iteration linear trajectory determined feasible direction computed adler karmarkar resende veiga diag 

full rank assumption system linear equations symmetric positive definite 
systems linear equations usually solved means lu factorization lu unit lower triangular matrix matrix exclusively ones main diagonal upper triangular matrix 
case positive definite matrices lu factorization exists unique 
furthermore system symmetric factor trivially obtained diagonal matrix elements drawn diagonal rewriting lu 
direction determined solving triangular systems linear equations performing forward substitution lz followed back substitution uh 
iteration higher order algorithms described section additional directions involve solution linear systems identical different right hand sides 
solving additional systems linear equations involve back forward substitution operations lu factors 
furthermore execution algorithm changes remain unaltered 
nonzero structure static entire solution procedure 
efficient implementation gaussian elimination procedure take advantage property performing algorithm single symbolic factorization step operations depend solely nonzero structure system matrix 
example stage algorithm determine nonzero structure lu factors build list numerical operations performed gaussian elimination procedure 
iteration algorithm actual numerical values computed incorporated symbolic information 
numerical factorization executed traversing list operations yielding lu factors 

approximate scaling matrix 
theoretical approach suggested karmarkar significant reduction computational effort achieved approximate scaling matrix computing numerical values matrix iteration 
matrix system linear equations replaced approximate scaling matrix computed selectively updating scaling matrix preceding iteration 
approximate scaling matrix iteration implementation karmarkar algorithm computed follows 
computing current approximate scaling matrix define 
update expression da 
enables update linear system matrix rescaling reduced set columns 
ordering sparsity 
sparse matrix factored fill usually occurs 
triangular factors contain nonzero elements positions zeros 
fill degrades performance sparse gaussian elimination compute lu factorization affecting back forward substitution operations 
possible reduce fill performing permutation columns rows permutation matrix pb ph pc equivalent systems 
furthermore exists permutation matrix generated triangular factors minimized 
unfortunately finding permutation matrix np complete problem yannakakis 
minimum degree minimum local fill ordering heuristics rose shown perform practice duff reid 
minimum degree heuristic implemented subroutine md yale sparse matrix package schultz sherman minimum local fill implementation 

treating dense columns coefficient matrix 
presence dense columns dense regardless permutation matrix 
consequently face prohibitively high computational effort storage requirements gaussian elimination 
remedy situation hybrid scheme perform incomplete factorization incomplete cholesky factors preconditioners conjugate gradient method solve system linear equations defined 
partition column indices columns density smaller parameter iteration incomplete cholesky factors 
conjugate gradient algorithm solve system linear equations qu 
adler karmarkar resende veiga search direction computed performing back substitution operation solving 
termination tolerance cg conjugate gradient algorithm outlined pseudo code 
procedure cg 

qu 


cg 
qp 


qu 



od 
pseudo code conjugate gradient algorithm 
test problems section report computational results implementations algorithms ii set linear programming test problems gay available netlib dongarra grosse 
netlib system designed provide efficient distribution public domain software scientific community computer networks arpanet unix uucp network 
report results running algorithm linear programs generated models 
set composed randomly generated multi commodity network flow problems generated ali 
collection timber harvest scheduling problems generated johnson linear programming system long range planning forest service 

netlib test problems 
collection linear programs consists problems contributed variety sources 
includes linear programming test problems systems optimization laboratory stanford university staircase linear programs generated ho real world problems 
considered tests available problems bounds section mps representation current version code handle bounded variables implicitly 
table presents statistics test problems obtained netlib ordered increasing number nonzero elements coefficient matrix adding slack variables 
dimensions problems include null fixed variables removed preprocessor applying linear programming algorithm 
number rows include objective function 
column number nonzero elements displayed 
column gives number nonzero elements lower triangular portion permuted pa pa matrix minimum degree ordering heuristic 
implementation karmarkar algorithm table 
netlib test problem statistics problem rows columns pa pa sc share share sctap brandy israel ship ship ship sctap ship sctap fv ship ship minimum degree ordering heuristic 
fv known bp 
column gives nonzero elements cholesky factor 
fill difference columns 
entries columns problem israel algorithm dense columns dropped 
test runs exception algorithm ii carried ibm berkeley vm algorithm ii test runs ibm berkeley vm sp cms fortran programs compiled adler karmarkar resende veiga compiler compiler options opt reported cpu times computed utility routine account preprocessing input matrix cleanup ordering symbolic factorization operations termination 
exclude effort required translate linear programs mps format 
execution times algorithm algorithm ii compared simplex code minos reported cpu times minos subroutine driver excludes time read translate mps input file 
results solving netlib test problems minos displayed table 
running minos default parameters log freq iterations 
problem size parameters rows columns elements set exact number rows columns nonzero elements coefficient matrix 
fashion minos selects value important partial price parameter built default strategy 
default parameters minos achieved digit accuracy problems compared optimal objective values reported gay 
netlib test problems form described algorithms ii solve corresponding dual linear programming problems 
primal optimal solution obtained involving scaling matrix search direction dual slacks 
contrast minos solves test problems original form 
tables summarize computational results algorithm set test problems respectively minimum degree minimum local fill ordering heuristics 
table presents results algorithm ii uses minimum degree ordering heuristic 
algorithms ii tested parameter settings 
safety factor parameter set iterations 
algorithms terminated relative improvement objective function fell phase value artificial variable cost defined determined constant diagonal update tolerance set column density parameter building incomplete cholesky factorization conjugate gradient algorithm set 
table compares execution times algorithms 
cpu times displayed minos algorithm measured ibm algorithm ii ibm sake consistency computing cpu times ratio minos algorithm ii execution times minos ibm figures illustrate graphically performances minos algorithm table focuses subgroups problems subgroup problems having structure generated model 
table ratios minos iterations algorithm iterations minos cpu time iteration algorithm cpu time iteration minos total cpu time algorithm total cpu time 
table presents detailed results related generation primal solutions algorithm number iterates generated algorithm 
normalized duality gap column 
column presents maximum normalized primal infeasibility max 

implementation karmarkar algorithm cpu time seconds number nonzero elements minos algorithm rr rr 
minos algorithm cpu times ibm netlib test problems minimum local fill ordering heuristic algorithm fv included graph 
ratio number nonzero elements 
minos algorithm cpu times ratio ibm netlib test problems minimum local fill ordering heuristic algorithm adler karmarkar resende veiga table 
minos test statistics ibm netlib test problems problem phase total time secs 
objective value sc share share sctap brandy israel ship ship ship sctap ship sctap fv ship ship column gives minimum normalized primal entry min 
column maximum normalized complementarity violation max 

results observations implementation karmarkar algorithm table 
algorithm test statistics ibm netlib test problems minimum degree ordering heuristic algorithm problem phase total time secs 
objective value sc share share sctap brandy israel ship ship ship sctap ship sctap fv ship ship conjugate gradient algorithm triggered running test problem 
iterations algorithm vary see tables growing slowly problem size 
algorithm general faster minos speed see table figures 
total problem set execution time times faster 
minos faster small problems having rows nonzero matrix elements 
adler karmarkar resende veiga table 
algorithm test statistics ibm netlib test problems minimum local fill ordering heuristic problem phase total time secs 
objective value sc share share sctap brandy israel ship ship ship sctap ship sctap fv ship ship conjugate gradient algorithm triggered running test problem 
test problems categorized groups number nonzero elements small ship medium ship large ship algorithm corresponding category average times faster minos 
may infer growth relative speed algorithm respect minos problem sizes increase 
implementation karmarkar algorithm table 
algorithm ii test statistics ibm netlib test problems minimum degree ordering heuristic algorithm ii problem phase total time secs 
objective value sc share share sctap brandy israel ship ship ship sctap ship sctap ship ship problem fv solved algorithm ii current implementation incorporate dense window data structure adler necessary solve problem mbytes memory limit 
table problems similar structure grouped observe minos disadvantage number iterations grows problem size advantage time iteration level larger problems 
minos basis fixed number iterations 
requires order iteration algorithm dominating carried intermediate iterations 
problem adler karmarkar resende veiga table 
comparison run times ibm netlib test problems minimum local fill ordering heuristic problem minos alg alg ii minos alg minos alg ii time time time time ratio time ratio secs 
secs 
secs 
sc share share sctap brandy israel ship ship ship sctap ship sctap fv na na ship ship ibm cpu times minimum degree ordering heuristic algorithm ii 
size increases overhead incurred algorithm preprocessing absorbed expect ratio iteration algorithms worst proportional inverse frequency 
implementation karmarkar algorithm table 
iteration time iteration total time ratios netlib subgroups ibm minimum local fill ordering heuristic problem rows columns minos alg minos alg minos alg iter 
ratio time iter 
ratio time ratio sctap sctap sctap ship ship ship ship ship ship relative simplex codes algorithm increasingly faster problems get larger 
optimal objective values reported table accurate digits compared values reported gay 
primal solution computed termination accurate cases exception problems fv see table 
primal dual relation problem israel implementation direct factorization compute search directions iteration 
considerations algorithm valid algorithm ii 
furthermore algorithm ii requires average iterations converge digit accuracy algorithm translate significant gain solution time extra iteration current implementation offsets savings number iterations 
believe refining extra computation reduction iteration algorithm ii possible leading faster implementation 
conjugate gradient algorithm column density parameter important solving test problem israel 
factorization times problem reduced significantly compared earlier version algorithm conjugate gradient routine implemented 
dropping dense columns significantly affect convergence dual solution generate direction precise computing accurate primal solution termination 
accomplished means exact solution system defining direction 
exact factorization adler karmarkar resende veiga table 
primal dual relations algorithm ibm netlib test problems problem relative max 
normal 
min 
normal 
max 
normal 
duality gap primal 
primal entry 
viol 
sc share share sctap brandy israel ship ship ship sctap ship sctap fv ship ship iteration accuracy primal solution problem israel similar reported problems 
table observe clear advantage minimum local fill ordering heuristic 
ordering algorithm heuristic usually involves longer processing times reduction fill results faster gaussian elimination procedure 
ordering iteration implementation karmarkar algorithm table 
multi commodity network flow test problems statistics problem nodes commodities lp rows lp columns mul mul mul mul mul mul mul mul mul mul mul linear programming algorithm total savings offsets extra processing ordering procedure 
sum solution times including reordering test problems reduced seconds seconds minimal local fill corresponding reduction 
solution times algorithm minimal local fill faster test problems problems having nonzero elements see 

multi commodity network flow problems 
section report multicommodity network flow problems generated ali random multi commodity network flow problem generator 
generates random network structure number arcs nodes supplied user 
additional user specifications include number commodities ranges arc costs capacities 
table displays basic data set test problems 
generated multi commodity network flow problem varying number nodes commodities keeping relative number arcs 
test problems solved algorithm minos mcnf special purpose simplex code multi commodity network flow problems 
algorithm minimum degree ordering heuristic parameter selection described section 
runs carried ibm tables statistics runs 
list observations test results reported section 
multicommodity networks provide important class test problems general purpose simplex method performs poorly see table 
behavior implementation algorithm confirms earlier observation relative speed relation simplex method grows size 
similar leveling time iteration ratios simplex codes algorithm observed see tables 
exception mcnf algorithm ratio commodity problems 
trend data suggests leveling occur larger networks networks nodes 
number iterations grows slowly exceeding 
adler karmarkar resende veiga table 
algorithm test statistics ibm multicommodity networks minimum degree ordering heuristic algorithm problem phase iter 
total iter 
time secs 
mul mul mul mul mul mul mul mul mul mul mul table 
minos test statistics ibm multicommodity networks problem phase total time secs 
mul mul mul mul mul mul mul mul mul mul mul interesting note despite general purpose implementation algorithm performed comparably mcnf 
tailored implementation algorithm integer operations specialized gaussian elimination improve current results 
furthermore trend data table suggests larger problems algorithm outperform mcnf 
objective values solutions obtained implementation algorithm achieved digits accuracy compared values obtained minos 
feasible primal solution recovered algorithm degree accuracy 

timber harvest scheduling problems 
section report timber harvest scheduling problems generated johnson 
data collected united states national forest series timber harvest scheduling models implementation karmarkar algorithm table 
mcnf test statistics ibm multicommodity networks problem total iter 
time sec 
mul mul mul mul mul mul mul mul mul mul mul table 
minos algorithm performance ratios multicommodity networks minimum local fill ordering heuristic problem nodes commodities minos alg minos alg minos alg iter 
ratio time iter ratio time ratio mul mul mul mul mul mul mul mul mul mul mul increasing sizes generated 
framework forest divided management units called analysis areas comprising collection acres forest sharing similar economic characteristics 
test problems created successively increasing number analysis areas resulting models represent subsets original forest 
widely united states national forest system yielding large linear programs pose considerable challenge linear programming codes 
table presents basic statistics family test problems 
table observe test problems significantly variables constraints 
characteristic accentuated problem size 
situation adler karmarkar resende veiga table 
mcnf algorithm performance ratios multicommodity networks minimum local fill ordering heuristic problem nodes commodities mcnf alg mcnf alg mcnf alg iter 
ratio time iter ratio time ratio mul mul mul mul mul mul mul mul mul mul mul cpu time seconds number nonzero elements minos algorithm mcnf 
minos mcnf algorithm cpu times ibm multicommodity flows minimum degree ordering heuristic algorithm implementations provide choice pricing strategies 
particular minos allows partial pricing scheme columns coefficient matrix partitioned equal segments 
pricing operation search incoming basic variable limited segment 
reduces required operation course predictable effect total number iterations 
class implementation karmarkar algorithm table 
timber harvest scheduling test problems statistics problem lp rows lp columns fpk fpk fpk fpk fpk fpk fpk fpk fpk fpk fpk test problems manipulation partial price parameter sets number segments partition impact performance minos enormously 
consequently compare minos algorithm pricing strategies total pricing strategy pricing operation examines total set variables 
default pricing strategy sets partial price parameter half ratio number columns number rows 
improved pricing strategy sets partial price parameter times ratio number columns number rows 
arrived strategy extensive testing test problems 
tables display results running test problems algorithm minos pricing strategies 
illustrates graphically computational performance algorithms 
run carried ibm characteristics tests reported section 
minimum degree ordering heuristic algorithm close section observations results runs timber harvest scheduling problems 
theoretical worst case analysis karmarkar algorithm karmarkar suggests number iterations grow linearly largest dimension coefficient matrix 
behavior confirmed variants algorithm described 
set test problems number columns ranging number iterations convergence grows sublinearly varying consistent earlier observation number iterations grows slowly problem size 
collection test problems unusual behavior solved minos 
decreasing number columns considered pricing operation reduced computation effort simplex operation total number iterations 
number pivots associated solution paths followed different versions simplex method may vary greatly 
sense interior point methods display robust behavior 
recommends caution carrying adler karmarkar resende veiga table 
algorithm test statistics timber harvest scheduling problems minimum degree ordering heuristic problem phase iter 
total iter 
time sec 
fpk fpk fpk fpk fpk fpk fpk fpk fpk fpk fpk table 
minos test statistics total pricing timber harvest scheduling problems problem partial phase total time pricing iter 
iter 
sec 
fpk fpk fpk fpk fpk fpk fpk fpk fpk fpk fpk computational experiments involving simplex method varying single parameter different runs minos execution time largest test problems reduced factor 
implementation algorithm faster straightforward version minos wide margin see table times faster runs default pricing strategy minos runs times faster improved pricing strategy pricing strategy obtained extensive experimentation 
objective values solutions obtained implementation algorithm achieved digits accuracy compared values obtained minos 
implementation karmarkar algorithm table 
minos total pricing algorithm performance ratios timber harvest scheduling problems minimum degree ordering heuristic algorithm problem partial minos alg minos alg minos alg pricing iter 
ratio time iter 
ratio time ratio fpk fpk fpk fpk fpk fpk fpk fpk fpk fpk fpk table 
minos test statistics default pricing timber harvest scheduling problems problem partial phase total time pricing iter 
iter 
sec 
fpk fpk fpk fpk fpk fpk fpk fpk fpk fpk fpk feasible primal solution recovered algorithm degree accuracy 

interpretation computational experiments 
interpretation results computational experiments 
implementation algorithm attained digit accuracy objective function test problems numerical difficulties 
data structures programming techniques led results described adler 
adler karmarkar resende veiga table 
minos default pricing algorithm performance ratios timber harvest scheduling problems minimum degree ordering heuristic algorithm problem partial minos alg minos alg minos alg pricing iter 
ratio time iter 
ratio time ratio fpk fpk fpk fpk fpk fpk fpk fpk fpk fpk fpk table 
minos test statistics improved pricing timber harvest scheduling problems problem partial phase total time pricing iter 
iter 
sec 
fpk fpk fpk fpk fpk fpk fpk fpk fpk fpk fpk selection initial interior solution described section plays significant role fast convergence observed test problems 
procedure attempt start algorithm far faces feasible polyhedral set avoiding difficulties described megiddo shub 
recovering dual solution primal solution format test problems intricate proposition 
convergence dual solution estimates guaranteed examples built converges infeasible solution 
test results display behavior dual solutions 
implementation karmarkar algorithm table 
minos improved pricing algorithm performance ratios timber harvest scheduling problems minimum degree ordering heuristic algorithm problem partial minos alg minos alg minos alg pricing iter 
ratio time iter 
ratio time ratio fpk fpk fpk fpk fpk fpk fpk fpk fpk fpk fpk cpu time seconds number nonzero elements algorithm rr minos total pricing bb minos default pricing minos improved pricing 
minos algorithm cpu times ibm timber harvest problems minimum degree ordering heuristic algorithm stopping criterion described section resulted correct solution desired accuracy 
alternative criterion checks dual complementarity properties loss efficiency 
adler karmarkar resende veiga updating matrix algorithm obtained savings execution times compared full updating degradation method numerical stability 
algorithm sensitive density matrix 
sparse matrix small number dense columns 
maintaining matrix sparse essential algorithm 

extensions computational results illustrate potential interior point methods linear programming 
implementation described developed short period time outperforms minos majority problems tested 
test problems netlib collection solution time speed ups higher observed mid sized problems increase problem size 
digit accuracy objective function value achieved test problems problems sctap fv optimal complementary primal dual pair obtained test problems exception fv numerical difficulties lu algorithm account inaccuracies 
test problems set multi commodity network flow problems 
interior algorithm clearly superior minos competitive specialized simplex algorithm mcnf 
set timber harvest scheduling problems linear programs significantly variables constraints number iterations required algorithm grows slowly number variables 
specialized pricing strategies simplex method better tool solving type linear programming problems 
implementations interior point algorithms described preliminary 
improvements possible approach promising general purpose solver large real world linear programming problems 
extensions planned implementation immediately required implicit treatment upper lower bounds variables 
feasibility adjustment tentative primal solution computed algorithm 
extensions planned preprocessor increasing sparsity input matrices 
higher order approximations solution system differential equation 
optimal basis identification early termination 
bi directional search determining step direction 
develop primal primal dual implementations 
include steps potential function gradient direction 
implementations special lp structures network flows 
implementation parallel computer architectures 
acknowledgment authors acknowledge help volunteered individuals coding numerous modules backbone implementation started joint class project adler fall large scale systems graduate seminar berkeley 
particular chou doucet harrison kaplan monteiro wei involved programming effort 
wish implementation karmarkar algorithm valuable discussions related implementation algorithm ii 
furthermore authors indebted anonymous referees constructive suggestions 
research partially funded brazilian council development science technology cnpq management sciences staff forest service 
adler karmarkar resende veiga 
data structures programming techniques implementation karmarkar algorithm orsa journal computing 
adler monteiro 
limiting behaviour affine scaling continuous trajectories linear programming problems mathematical programming 
ali 
program documentation technical report department industrial engineering operations research southern methodist university dallas tx 
aronson barr loh zaki 
projective transformation algorithm karmarkar computational experiment assignment problems technical report department operations research southern methodist university dallas tx 
barnes 
variation karmarkar algorithm solving linear programming problems mathematical programming 
bayer lagarias 
nonlinear geometry linear programming transactions ams 

class algorithms linear programming research memorandum dept industrial engineering purdue university west lafayette usa 
revised 

needed factor symmetric positive definite matrix technical report orc operations research center university california berkeley ca 

iterative solution problems linear quadratic programming soviet mathematics doklady 
dongarra grosse 
distribution mathematical software electronic mail communications acm 
duff reid 
direct methods sparse matrices press oxford 
schultz sherman 
yale sparse matrix package symmetric codes international journal numerical methods engineering 
gay 
electronic mail distribution linear programming test problems coal newsletter 
gill murray saunders tomlin wright 
projected newton barrier methods linear programming equivalence karmarkar projective method mathematical programming 

interior point algorithms linear programming problems inequality constraints mathematical programming 
ho 
set staircase linear programming test problems mathematical programming 
hooker 
karmarkar linear programming algorithm interfaces 
johnson 
version overview technical report land management planning section forest service fort collins karmarkar 
new polynomial time algorithm linear programming combinatorica 
karmarkar lagarias wang 
power series variants karmarkar type algorithms technical journal 

primal partitioning code solving multicommodity flow problems version technical report department industrial engineering operations research southern methodist university dallas tx 
lustig 
practical approach karmarkar algorithm technical report sol sol systems optimization laboratory stanford university stanford ca 
megiddo shub 
boundary behavior interior point algorithms linear programming mathematics operations research 
murtagh saunders 
minos user guide technical report systems optimization laboratory stanford university stanford ca 
murtagh saunders 
minos user guide technical report systems optimization laboratory stanford university stanford ca 
adler karmarkar resende veiga rose 
graph theoretical study numerical solution sparse positive definite systems linear equations read ed graph theory computing academic press new york ny usa pp 

tarjan 
data structures network algorithms siam philadelphia pa usa 
todd 
extension karmarkar algorithm linear programming dual variables algorithmica 
tomlin 
experimental approach karmarkar projective method linear programming mathematical programming study 
tone 
implementation revised karmarkar method interim report graduate school policy science university japan 
vanderbei freedman 
modification karmarkar linear programming algorithm algorithmica 
yannakakis 
computing minimum fill np complete siam alg disc meth 
adler resende veiga department industrial operations research university california berkeley ca mail address adler ilan berkeley edu karmarkar bell laboratories murray hill nj usa mail address narendra karmarkar att com current address resende bell laboratories murray hill nj usa mail address mauricio resende att com current address veiga bell laboratories holmdel nj usa mail address veiga att com 
