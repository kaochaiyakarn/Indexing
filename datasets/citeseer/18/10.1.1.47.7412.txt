copyright edward scott meadows jr stability continuity nonlinear model predictive control edward scott meadows jr dissertation faculty graduate school university texas austin partial fulfillment requirements degree doctor philosophy university texas austin december stability continuity nonlinear model predictive control approved dissertation committee supervisor acknowledgments express appreciation advisor dr james rawlings 
difficult questions pushed forward stalled insight allowed progress impossible 
vision computing profession provided research group best computer facilities university 
reported dissertation impossible hardware software tools provided 
committee members rafael de la jeff david thomas edgar contributions 
professors edgar rawlings provided superb atmosphere collaboration chemical engineering students faculty 
students students worked deserve special tony listening mathematical speculations john eaton administering computer facilities providing octave ken muske contributions provided foundation parts 
edward scott meadows jr university texas austin december stability continuity nonlinear model predictive control publication 
edward scott meadows jr ph university texas austin supervisor james rawlings provides analysis important properties model predictive control mpc algorithm feedback control dynamic systems 
dissertation contains record related areas stability model predictive control continuity model predictive control feedback laws objective functions resolution implementation issues model predictive control linear models model predictive control stochastic systems 
connections known results linear quadratic optimal control may viewed mpc method dynamic programming 
sufficient conditions stability provided general nonlinear systems 
include non negativity objective continuity origin 
stability obtained lyapunov stability argument mpc objective lyapunov function 
matrix rank condition related constraint set ensures continuity provided 
continuity feedback control law derived model predictive control corresponding objective function important consequences stability performance closed loop system 
unusual example dissertation investigates continuity provides sufficient condition ensure objective function feedback control law continuous respect state 
results reported concerning implementation linear model predictive control previous rawlings muske university texas 
issues discussed technical issues important applications including replacement state stability constraint original proposal better suited numerical implementation replacement infinite series state constraints equivalent finite set 
vii viii demonstrates analysis methods dynamic programming analyze model predictive control algorithm subsume standard results general comprehensive theory 
connection explicitly stated literature date remains rich topic available research 
results concerning stochastic perturbed systems 
provides conditions asymptotically stable control method retain stabilizing ability presence perturbations arising exponentially stable state observer 
second examines performance demonstrates suboptimality model predictive control applied certain stochastic systems 
table contents acknowledgments vii table contents ix list figures xi list tables xiii list symbols xv chapter 
comments concerning nomenclature model predictive control problem definition solution methods existence solutions mpc problems convergence chapter 
stability results asymptotic stability discrete time systems stability results stabilizing formulations mayne dual mode controller keerthi gilbert stability monotonicity dynamic programming linear quadratic optimal control dynamic programming approach chapter 
continuity robustness hermes example problem choice horizon length stability receding horizon control law ix contents numerical results effect horizon length analysis discontinuities chapter 
model predictive control linear processes rawlings muske control formulation final state stability constraint state constraints infinite horizon infeasibilities quadratic program constrained choice horizon length state constraint violations stability continuity controller increasing lipschitz bound limiting continuity control boundary regions stability results perturbed systems stability combined observer controller chapter 
model predictive control stochastic systems dreyfus problem linear system random coefficients dynamic programming solution model predictive control solution control strategies comparison control strategies infinite horizon implementation observations chapter 
appendix berge concept semi continuity appendix constraint reduction algorithm inequality constraints contents xi equality constraints bibliography vita list figures closed loop cost vs initial condition 
system dynamic equation vs 
lyapunov function deltav 
feasible control regions unit circle 
optimal feedback versus state unit circle 
receding horizon objective versus state unit circle closed loop state trajectories 
objective function various horizon lengths 
objective function various horizon lengths close view discontinuities 
control input various 
locus states rank deficient 
control input various 
discontinuity rawlings muske controller 
modified dreyfus optimal path problem 
discrete distribution specified statistics 
normal distribution specified statistics 
feedback gain various control strategies 
expected costs various control strategies 
expected costs various control strategies 
infinite horizon feedback gain dynamic programming xiii list tables tableau constraints 
tableau constraints 
open loop cost state 
feedback control action closed loop cost mpc optimal control 
xv list symbols symbol number parentheses section symbol appears 
cases symbol may differently different context 
symbols referenced different section 
lower case symbols class functions bound lyapunov function class function bounds deltav class function upper bounds deltav constant recursive solution stochastic control problem right hand side linear input constraints perturbation stable dynamic system function dynamic system equation function system equation uncontrolled dynamic system right hand side linear state constraints integer valued time indices bounding index theorem rawlings muske control problem index state constraints active rawlings muske control problem index state constraints longer active dimension control space dimension state space distributional parameter stochastic control problem radius stability definitions radius hermes problem arbitrary element control space control time xvii xviii nomenclature th optimal control solution mpc problem open loop controls control stochastic control problem random variable stochastic control problem arbitrary element state space point stability definitions state estimate state time trajectory perturbed dynamic system states resulting open loop controls upper case symbols system matrices linear control problem linearization matrices dynamic system function operator matrix stable subspace controllability matrix control variable constraint matrix expectation operator composite function final state jacobian matrix respect control state constraint matrix dynamic programming objective function function mapping 
feedback gain matrix lipschitz bound feedback control law stage cost lipschitz constant subset control space theorem horizon length number stages dynamic programming problem cs constrained index subsets state space gilbert tan algorithm nomenclature xix probability pn solutions algebraic riccati riccati difference equations respectively unique stabilizing solution algebraic riccati equation qn weighting matrix fake algebraic riccati equation weighting matrices lqg rawlings muske control problem radius stability definitions matrix dynamic programming operator dynamic programming operator applied times controls dreyfus problem matrix elements real schur decomposition constraint region theorem input variable constraint set stable unstable partitions real schur decomposition matrix lyapunov function ff final state constraint region mayne control problem class function keerthi gilbert control problem state variable constraint set nested sets state space corresponding control problem greek letter symbols ff non decreasing function lyapunov stability theorem delta difference objective functions successive iterations dynamic programming equation fl nonnegative function lower bounding fl non decreasing function lyapunov stability theorem ffl state estimate error xx nomenclature oe optimal mpc objective function oe final state penalty function oe model predictive control objective function stages positive definite function stabilizable linear quadratic system parameter definition theorem distributional parameter stochastic control problem feedback control law considered hermes problem input sequence elements element theorem optimal control sequence mpc problem ae lipschitz constant hager theorem ae constants define bound exponentially stable state observer error xi quadratic weighting matrix infinite horizon suboptimal objective symbols deltav change lyapunov function state follows system equation real numbers non negative real numbers chapter goal research analyze model predictive control mpc algorithms stability performance 
model predictive control mpc refers class control methods process model select control input predictions effect control process output 
model predictive control know receding horizon control moving horizon control control 
specific implementations model predictive control concepts identified distinct control methods right 
examples include gaussian lqg optimal control dynamic matrix control dmc generalized predictive control gpc 
definition mpc broad encompass classical control methods involving frequency domain design linear single variable systems 
distinguish mpc control design techniques features model predictive control methods include ffl model available predict process output currently available information specified control trajectory 
form model differs different researchers practitioners 
model takes form discrete time nonlinear state space model current state assumed available 
ffl mathematical expression control objective defined fixed time period specified initial time 
theoretical practical interest consider limiting case time period called prediction horizon approaches infinity 
case considered 
ffl control determined seeking control minimizes value objective function 
control implemented time problem solved 
ability pose repeatedly solve optimization problem new information available allows model predictive control operate feedback controller 
ffl controller incorporate constraints input state variables 
feature enabled model predictive control gain industrial applications significant distinguishing features 
features incorporated model predictive control problem statement various ways 
discrete time models emphasis mayne achieved significant success analysis design stabilizing robust implementable mpc methods continuous time systems 
earlier continuous time linear systems kwon pearson kailath revealed critical significance final state constraints ensure nominal stability model predictive control formulations topic receives considerable attention research 
similar conducted chen shaw nonlinear continuous time systems 
early model predictive control usually considered continuous time system 
increased interest discrete time case coincided dramatic drop cost computation discrete time formulations amenable computer implementation 
industrial applications developed ahead academic interest late model predictive control successfully applied ad hoc basis industry little theoretical justification analysis 
early industrial applications linear convolution impulse response models 
researchers followed lead early established theoretical foundation mpc practiced time 
review mpc impulse response models provided garc ia 
researchers dealing general nonlinear discrete time case keerthi gilbert provided detailed analysis date 
analyze finite infinite horizon control schemes provide sufficient conditions existence stability mpc controllers 
described detail section 
linear discrete time case analyzed rawlings muske university texas austin 
key contribution find parameterization problem resulting controller nominally stable regardless choice tuning parameters 
significant portion extends results discussed chapter 
remainder dissertation addresses topics ffl chapter contains description model predictive control formulation basis 
mpc problem defined finite infinite horizon cases 
existence solutions model predictive control problem primary purpose research sufficient conditions provided existence finite infinite horizon cases 
ffl chapter provides heart regards nonlinear mpc 
sufficient conditions nominal stability model predictive control provided 
necessary sufficient conditions available stability result clear distinction sufficient conditions existence stability 
results section previously works author 
ffl chapter discusses continuity feedback control laws arising model predictive control 
bulk chapter devoted study unusual example inspired hermes requires discontinuous control stability 
extends stability theorem chapter providing way verify sufficient condition stability 
ffl chapter extends rawlings muske linear discretetime mpc 
primarily directed resolving outstanding computational issues 
include selecting minimal set constraints larger set constraints decision variables improving numerical implementation theory 
ffl chapter addresses issue suboptimality mpc controller applied stochastic systems issue discussed literature largely ignored community mpc practitioners 
comments concerning nomenclature mathematical representation concepts model predictive control difficulties 
solutions mpc control problem consist open loop control sequences corresponding state trajectories response system necessarily follow open loop state trajectory 
common ways express literature double subscripts kjk jk imprecise difficult follow 
dissertation important distinguish open loop states control implemented open loop states controls respectively 
time index indicate time mpc prediction horizon 
symbols represent implemented states controls respectively representing extrinsic time variable 
state variables connected initial condition distinction unnecessary clarity revert notation 
shifts notation indicated clearly occur 
notational difficulty involves representing open loop control sequences number elements unspecified infinite 
generally symbol represent sequence controls fv control sequence know specified number elements represented optimizing sequences superscript superscript generally denote optimal variable 
example stage control objective initial state evaluated arbitrary may oe optimum oe 
potentially confusing distinction distinguishing objective functions model predictive control dynamic programming 
coincide deterministic systems primary focus purposely blurred distinction oe represent 
necessary distinguish chapter dynamic programming oe mpc 
possible source confusion note engineering usage rarely distinguishes functions distinct objects instantiation specific point domain 
tempted enforce distinctions dissertation hope causes confusion discriminating reader 
model predictive control problem definition nonlinear deterministic discrete time dynamic system continuous satisfying wish design stabilizing feedback controller subject general state input constraints dissertation goal controller regulate state system origin 
model predictive control approach construct stage objective function part nonlinear optimization problem solution yields minimizing control sequence satisfies constraints prediction horizon 
move sequence implemented system moves new state new state optimization problem re solved 
method called receding horizon control time objective function computed horizon extends steps mpc controller specified horizon length stage cost system dynamics state constraint input constraint final state penalty oe left general problem statement constraint sets theta typically polyhedral regions theta defined linear inequality constraints 
statement model predictive control problem constraints depend time index closed contain point interior theta oe represent final state penalty function 
conceptually considered zero stage mpc problem 
subsequent sections dynamic programming introduced solution analysis method mpc problems quite natural oe initial condition recursive equation provides mpc control objective function 
common final state penalty oe different formulations linear quadratic optimal control final state penalty function determining factor stability algorithm 
usually oe required satisfy oe oe 
nonlinear examples provided dissertation final state constraint place distinct oe choice oe play role stability mpc 
define control objective function oe gamma oe optimal control program takes form oe min oe subject common include final state constraint provide desirable stability properties closed loop response system 
discuss constraint formulations provide stability 
problem statement infinite horizons allowed limiting case 
problem defined limit finite horizon problems 
sufficient conditions provide existence infinite horizon case discussed subsequent sections 
current state enters external parameter nonlinear program 
solution problem written gamma optimal objective function oe functions usually understood context problem include arguments non optimal objective function oe optimal objective function oe 
model predictive control method entire optimal control sequence applied 
initial control move implemented problem posed new initial state 
open loop controls including functions feedback control law 
solution methods section discuss methods solving nonlinear programs posed model predictive control problem batch optimization dynamic programming 
batch optimization relatively familiar process posing optimization problems multiple variables solved numerically computers 
flexible process applied wide range optimization problems simply model predictive control problems 
obtain numerical solutions usually process commercially available optimization code freely available octave front 
term batch optimization distinguish thought normal numerical optimization method dynamic programming 
dynamic programming method developed control multi stage stochastic processes 
systems proven dynamic programming provides minimizing control sequence true batch method 
deterministic systems primary concern dynamic programming offers advantages batch optimization 
optimization schemes produce result 
model predictive control problems expressed equivalent dynamic programming problems methods results dynamic programming play important role analysis deterministic model predictive control problems 
reason provide brief description algorithm 
bertsekas highly recommended detailed discussion 
consider stage optimization equation 
dynamic programming divides optimization sub problems connected recursive equation oe min oe gamma ng recursion backward index initial condition corresponding final stage cost optimal control problem oe features important subsequent analyses ffl dp objective function oe corresponds exactly mpc horizon horizon length 
special result applies deterministic systems 
chapter shows stochastic systems hold 
subsequent sections tie dynamic programming objective specified stage optimization freely oe represent mpc objective function dp objective function depending context 
ffl optimization indicated equation takes state external parameter solution optimal value depend state 
functional relationship state control values provide feedback control law model predictive control problem horizon length highlights conceptual difference mpc batch optimization dynamic programming 
dynamic programming returns optimal functions better represent equation oe delta min delta oe gamma delta ng form emphasizes problem requires function solution control specific state value notation equation entrenched accept remainder dissertations occasional conceptual differences batch optimization dynamic programming 
ffl minimization indicated equation subject input state constraints original problem 
standard analyses dynamic programming incorporate state constraints additional restrictions set feasible controls 
introduces additional complexity standard formulations determining specific state constraint formulation input constraint equivalent 
questions addressed 
bertsekas adopt shorthand notation dynamic programming equation defining functional follows min fl notation provides convenient way analyze finite horizon model predictive control especially consider limiting case 
example oe objective functions stage mpc problem composition function delta delta delta times function represents final state weighting function stage cost explicit formulation 
dynamic programming algorithm provides control results batch optimization deterministic problems feedback control law stage model predictive control problem represented arg functional dependence control state emphasized expression highlight feedback control law exactly model predictive control 
existence solutions mpc problems dissertation prepared primarily eye applications 
focussed attention obtaining sufficient conditions stability mpc control laws sufficient conditions existence existence problems usually obvious early phases implementation 
helpful aware conditions provide existence guaranteed arbitrary providing sufficient conditions existence result bertsekas required theorem bertsekas conditions hold ffl non negative 
ffl oe 
ffl exists sets fi fi fil oe compact infinite horizon objective function satisfies oe lim oe noted proceeding convergence indicated point wise 
bertsekas explicitly allows extended real valued functions limit points equation information verify oe finite states interest 
question arises dissertation show bounded finding suboptimal control satisfies constraints 
provides upper bound optimal objective 
method theorem example 
arbitrary non negative meeting criteria section able satisfy conditions theorem appropriate choice existence theorem follows directly theorem continuous jjujj closed existence feasible open loop control fv gamma yields bounded objective function oe bounded initial condition implies existence bounded open loop optimal control sequence initial condition 
result holds finite infinite horizon problems 
proof ffl finite horizon recall maximum theorem maximum minimum nonlinear program achieved objective continuous constraint set compact 
continuity oe follows continuity growth condition follows oe jj jj 
consider level set joe oe hypotheses closed bounded compact 
non empty 
consist satisfy constraints final state constraint applicable 
closed set minimizing exists compact set ffl infinite horizon theorem 
nonnegative sets fu jl satisfy growth condition sets compact 
satisfies conditions bertsekas theorem 
boundedness know hypothesis exists control sequence provides upper bound oe 
sufficient existence bounded infinite horizon objective corresponding optimal control sequence 
qed keerthi provided existence theorems difference class finite infinite horizon problems points finite horizon case proven special case infinite horizon problem 
problem statement somewhat different keerthi included infinite finite horizon cases completeness 
demonstrated chapter stability closed loop dynamic system obtained model predictive control closely related properties stage cost minimal properties include 

exists non decreasing fl fl fl jjx jj delta represents norm theta 
lead additional properties 


property follows property 
demonstrate property suffices prove equivalent statement ffi exists ffl ffl implies jj jj ffi 
ffl ffi fl ffi take fl ffi 
exists 
suppose property false jjx ffi 
fl non decreasing fl jjx fl ffi 
combining inequalities yields fl jjx fl ffi fl jjx contradiction 
similar argument yield property 
properties objective function oe model predictive control algorithm final state stability constraint properties exists 
oe 
oe 
fl jjxjj oe 
oe oe conditions purposely left general allow widest possible selection applications 
examples follow chosen quadratic weighted quadratic function convergence sufficient conditions keerthi gilbert show solutions objective functions finite horizon model predictive control converge infinite horizon case 
discussed greater detail section especially section 
convergence mpc costs controls provide basis design finite horizon model predictive control problems approximate behavior infinite horizon case 
unfortunately general nonlinear mpc problem convergence expected 
example illustrates mpc solutions final state stability constraint converge infinite horizon solution 
example open loop states controls represented respectively 
consider scalar dynamic system trajectories follow gamma state control variable constraints initial state gamma 
quadratic stage cost finite horizon model predictive control problem stated follows oe min gamma arbitrary state gamma 
optimization subject final state constraint initial condition take final state constraint demands gamma satisfied 
chosen easy show cost choose control law gamma 
cost associated control law oe jxj corresponding control law sigma gamma jxj gamma initial condition closed loop cost closed loop cost vs initial condition cost optimal solution problem 
somewhat surprisingly solution problem depend horizon length 
cost drive state zero state gamma 
optimal control forces state zero move 
cost advantage delaying enforcement final state stability constraint non zero states occurring stage add cost function decreasing penalty associated final state constraint 
consider problem minimizing objective equation final state stability constraint 
take feedback control law state evolves gamma infinite horizon cost function find cost finite shown solid line 
cost finite horizon controller satisfies final state constraint lower bounded dotted line indicates finite horizon control able approach cost infinite horizon controller 
may conclude general nonlinear model predictive controller defined final state stability constraint converge infinite horizon result 
chapter stability results section reviews basic stability concepts discrete time including significant stability results researchers provides main stability result nonlinear model predictive control 
concluding sections illustrate utility dynamic programming algorithm analysis mpc demonstrate linear systems stability results obtained matrix riccati difference equation may obtained special case dynamic programming analysis 
asymptotic stability discrete time systems section reviews lyapunov stability concept discrete time systems form 
basic definitions standard definition equilibrium point stable exists jjx gamma xjj jjx gamma xjj 
definition equilibrium point asymptotically stable stable addition exists jjx gamma xjj implies jjx gamma xjj 
definitions proceed directly main result theorem satisfies 
exists nonnegative nondecreasing function ff ff ff jjx jj 
exists strictly increasing function fl continuous origin fl gamma fl jjx jj 
continuous 
process defined equation asymptotically stable 
proof address stability choose 
continuous exists ff jjx jj suppose process unstable 
exists jjx jj ff ff hypotheses gamma 
contradiction process stable 
address convergence hypotheses gamma fl jjx jj nonnegativity summing gives gamma fl jjx jj fl jjx jj non negative partial sums fl jjx jj upper bounded function lim fl jjx jj fl continuous implies jjx jj proven 
qed uncommon literature cite result third sufficient condition seminal kalman omits 
follow continuous origin 
counterexample consider dynamic system defined sin graph shown shows trajectories system dynamic equation vs initial conditions pass region reaching zero 
unstable behavior 
take gamma conditions theorem satisfied 
shows deltav clearly satisfy sufficient conditions theorem 
counterexample demonstrates shortcomings literature date gamma deltav gamma deltav lyapunov function deltav area lyapunov stability theory results field concerned continuous time systems 
pre digital computer age discretetime systems concern continuous time 
consequently large body literature developed neglected discrete time case 
discrete time formulations increasingly important computerbased controllers researchers provided discrete time results usually close analogs continuous time counterparts 
unfortunately authors provide detailed proofs discrete time results 
considering importance discrete time formulations computerbased control advisable carefully check discrete time results appearing literature proofs dismissed proceeding continuous time case 
stability results fairly weak conditions receding horizon control provide asymptotic stability 
discussion main stability result follows theorem oe continuous origin satisfies properties origin asymptotically stable equilibrium point dynamic system region attraction consisting points solution nonlinear program equation exists 
result holds limit 
proof consider finite 
ffl convergence infinite horizon infinite horizon objective function oe represented subscript oe optimal value represented oe 
definition receding horizon control oe delta delta delta oe oe fv feasible set indicated minimization includes effects constraint sets optimal objective function control law satisfies oe gamma oe indicates oe non increasing sequence 
positivity oe bounded zero limit 
left hand side equation approaches zero 
property implies sequence converges zero 
finite horizon similar oe delta delta delta gamma gamma gamma delta oe gamma oe gamma case gamma property receding horizon control objective function section inequality implies oe oe inequality established finite horizon objective function proof proceeds infinite horizon case 
ffl stability recognizing inequality property receding horizon objective function holds limit establishes stability finite infinite horizon cases 
choose 
continuity oe origin exists oe fl jjx jj equation oe oe suppose receding horizon control stabilizing 
sufficiently small jjx jj jjx jj fl nondecreasing lower bound oe gives fl fl jjx jj oe 
combining inequalities gives oe oe fl fl jjx jj oe contradiction 
receding horizon control stabilizing 
stability combined convergence implies asymptotic stability 
qed stabilizing formulations results previous section provide sufficient necessary conditions stability 
researcher provided conditions ensure stabilizing model predictive controllers 
mayne reviewed 
stabilizing method keerthi gilbert discussed section 
mayne dual mode controller final state constraint cause numerical problems determining optimal control sequence 
motivated fact mayne investigated possibility relaxing final state constraint retaining stability 
involved continuoustime systems method general applies continuous discrete time systems 
consider processes described equation 
processes linearization origin exists stabilizable mayne propose controller region near origin linearized controller 
outside linearized control region control obtained finite horizon model predictive controller final state constrained lie linearization region 
success method known result theorem linearization origin 
pair stabilizable exists gain matrix closed loop system kx locally asymptotically stable 
difficult find literature discrete time systems proofs continuous time version common 
example proof may sontag 
discrete time proof presents special problems proceeds continuous time case 
statement theorem included word locally parentheses 
asymptotic stability local property word unneeded included emphasize linearized control law kx provides stabilizing feedback neighborhood origin 
mayne identify neighborhood set ff ff adjustable parameter related size ff controller considered dual mode control law changes depending state inside outside ff ff control law control move solution finite horizon optimal control problem min gamma subject ff ff control law simply kx clearly ff contained invariant satisfy kx ff origin contained neighborhood ff arbitrarily small conditions satisfied satisfying theorem 
mayne algorithm provides stabilizing controller region attraction equal set feasible points nonlinear program equation 
detailed proof provided continuous time proof provided argument sketches fundamental concepts theorem linearization provides asymptotically stable controller region attraction ff asymptotic stability shown local argument 
basin attraction enlarged action model predictive controller ability steer feasible set states ff trajectories starting feasible set converge ff sufficient asymptotic stability entire set feasible initial conditions 
keerthi gilbert relevant study receding horizon control discretetime systems keerthi gilbert 
goal find feedback control law general nonlinear system equation minimizes infinite horizon cost function subject constraints 
view finite horizon problems method approximating infinite horizon result 
finite horizon control problems defined include final state stability constraint 
class problems admitted consideration narrowed control horizon exist gamma jj jj class function strictly increasing 
section current state enters problem initial condition providing proof appear condition guarantee finite horizon objective function continuous origin satisfy conditions theorem obtain stable controller keerthi gilbert different arguments proof 
equation represents nonlinear analog familiar linear system controllability criterion kalman 
unfortunately cases severely narrows class systems able considered 
example constrained linear system rawlings muske chapter included nonlinear example provided chapter 
restricted class problems keerthi gilbert able provide conditions convergence finite horizon control problems infinite horizon problem gave existence proof infinite horizon case 
possible reason inclusion strong condition class systems considered keerthi gilbert distinction conditions existence conditions stability 
conditions equivalent provided results distinguish resulting wider class admissible systems 
stability monotonicity dynamic programming stability closed loop feedback law long known infinite horizon linear quadratic lq optimal control solution 
usual derivation involves dynamic programming method rare connection explicitly noted 
stability infinite horizon lq optimal control demonstrated argument involving monotonicity riccati difference equation follows naturally derivation 
subsequent sections review derivation lq optimal control show lq optimal control stability result special case general result available nonlinear systems 
linear quadratic optimal control consider problem maintaining state system ax bu close origin 
closeness origin measured weighted square euclidean length vector jjx jj qx want maintain state close origin excessive control action size control action measured jju jj ru want choose control inputs minimize average value stage cost specified horizon notation developed chapter pose optimal control program find fv gamma oe min fv gamma qz rv subject az bv constraints state control classic linear quadratic problem 
solution problem numerically batch optimization taken external parameter special structure lq problem feedback law obtained closed form 
starting point derivation dynamic programming formulation equation 
summary uses dynamic programming confusion open loop closed loop controls conventional notation 
oe min oe gamma ng qx ru ax bu oe sx dynamic programming equation stage problem oe min qx ru ax bu ax bu unconstrained find solving necessary condition oe rv ax bu obtain sb gamma sax substituting equation equation gives oe sa gamma sb sb gamma sa repeated application recursion equation reveals oe quadratic function argument 
oe pn substituting equation provides classical lqg result riccati difference equation rde pn pn pn gamma pn pn gamma pn initial condition particular horizon length feedback gain kn kn gamma pn gamma pn gamma model predictive control approach stage mpc problem solved batch optimization provide control action applied 
lq problem corresponds constant controller gain kn stability analysis mpc problem stability system particularly readable discussion topic contained remaining material section summarized 
proven section infinite horizon model predictive controller stabilizing 
holds true lq case 
provided iterations equation converge form algebraic riccati equation equation 
result concerning existence solution algebraic riccati equation taken cited theorem consider algebraic riccati equation associated infinite horizon lq control problem pa gamma pb pb gamma pa ffl stabilizable ffl unobservable modes unit circle ffl exists unique non negative definite symmetric solution equation 
furthermore unique stabilizing solution gamma pb gamma pa eigenvalues strictly unit circle 
conditions pn rde equation converge provided cited theorem stabilizable unobservable modes unit circle pn 
taken theorem provide conditions existence finite lq optimal control stabilizing 
tool analyze stability finite horizon model predictive controller fake algebraic riccati equation pn pn gamma pn pn gamma pn qn derived equation making substitution qn gamma gamma pn advantage rewriting equation theorem immediately applicable provide sufficient conditions stability stage controller theorem consider fare equation defines matrix qn qn stabilizable detectable pn stabilizing gamma pn gamma pn eigenvalues strictly unit circle 
theorem indicates satisfy monotonicity condition solutions rde horizon stability follow mpc controllers greater horizon 
substantial body literature developed discusses choose initial condition rde guarantees monotonicity 
reviewed 
way stabilize lq optimal controller set final state horizon zero just nonlinear controller chapter 
shown equivalent converting rde equation related rde involving gamma zero initial condition 
concept discussed thomas context linear observers 
milestone kwon pearson explore zero state constraint detail 
stabilizing formulation provides variant final state constraint case 
deals constrained linear systems muske rawlings provide stabilizing initial condition applied lq optimal controller provide stabilizing feedback gain 
formulation reviewed chapter 
dynamic programming approach section demonstrate analysis dynamic programming incorporates results special case general theory applicable linear nonlinear systems 
helpful review basic results dynamic programming theory 
proofs available works bertsekas 
recall section dynamic programming algorithm expressed operator min operator notation result proven lemma functions 
compare result referring solution riccati difference equation rde equation theorem non negative definite solution pn rde monotonically non increasing time pn pn pn monotonically nonincreasing subsequent times pn pn 
theorem follows immediately lemma recognize iteration rde equivalent dynamic programming iteration 
corresponding dp approach theorem follows theorem suppose 
proof follows immediately applying sides equation invoking lemma 
lemma proven bertsekas linear systems theory 
suggests results literature properties algebraic riccati equations riccati difference equations may nonlinear generalizations 
application analyze model predictive control problem convergence horizon approaches infinity 
example dynamic programming approach applied analyze existence solutions algebraic riccati equation equation theorem 
proof de souza gevers goodwin quite involved resorting theoretical justifications matrix pencils extended nonlinear systems 
exception uniqueness properties solution algebraic riccati equation immediately available dynamic programming analyses 
consider alternative proof ffl existence system stabilizable exists constant feedback gain system bk stable 
unobservable modes unit circle form positive definite function bk bk limit lim xi xi positive definite solution matrix lyapunov equation bk xi pk gamma xi lemma see riccati difference equation expressed min qx ru ax bu bounded converges upper bound sequence converges xix 
demonstrates existence 
ffl stability theorem find lim satisfies min qx ru ax bu take minimizer expression 
ax bu gamma gamma qx ru satisfies xix continuous origin provide stability argument theorem 
ffl non negativity follows immediately lemma 
discussion shows dynamic programming theory provide alternate path known results linear systems theory 
general nonlinear systems dynamic programming equation min gamma initial condition prove stability infinite horizon model predictive control converges function oe continuous origin corresponding control law asymptotically stabilizing argument theorem section 
fake algebraic riccati equation fare method section direct analog nonlinear systems 
dynamic programming equation equation take minimizing control rewrite equation gamma gamma delta gamma gamma delta rearranging gives gamma gammal gamma gamma gammal delta provide sufficient condition stability delta delta provide stability 
analogy lq optimal control result riccati difference equation may possible show sufficiently large righthand side equation non positive arbitrary initial sufficient conditions case currently unknown general nonlinear problem 
possible specify strong conditions provide receding horizon controller stabilizing horizon length theorem theta continuous satisfy 
closed loop controller defined arg stabilizing feedback control law 
proof continuous objective function dynamic programming equation continuous monotonicity dp objective function gamma right hand side equation non positive continuous non negative gamma satisfies conditions theorem asymptotic stability 
qed chapter continuity robustness stability results section require continuity objective function origin 
chapter consider example provides great deal insight condition requires discontinuous controller stability 
mpc provides controller continuous origin 
arising study example provide easily verifiable sufficient condition continuity objective function origin point state space 
hermes example problem discussion contained section requires little distinction open loop closed loop controls revert back familiar notation scalar states open loop controls 
consider dynamic system defined scalar equations example motivated continuous time example hermes hermes example violates condition brockett smooth feedback stabilization 
eaton provides numerical results indicating continuous time version model predictive control asymptotically stabilize system 
far am aware conditions analogous brockett continuous time results available discrete time systems 
hermes continuous time example discrete time system equations continuous feedback law asymptotically stabilizing 
argument demonstrates similar 
note stabilizing control law allow positive negative values 
control strictly positive trajectories originating quadrant move away origin positive control action 
control strictly negative trajectories originating third quadrant move away origin 
zero nonzero 
point fixed point dynamic mapping trajectories containing converge origin 
situation feedback control law assume negative positive values away origin zero away origin 
feedback control law discontinuous 
leads theorem exist discrete time controllable dynamic systems admit asymptotically stabilizing feedback control law continuous state 
outline proof contained discussion 
system equations controllable state driven zero initial state suitable choice controls demonstrated section 
choice horizon length seek controller regulate system origin 
state input constraints stability constraint 
apply model predictive control example choose horizon length 
consider step horizon acceptable 
final state constraint requires equations satisfied constraint feasible curve model predictive control provide stabilizing control nominal plant initial conditions curve 
prefer result wider applicability increase horizon length 
final state constraint requires open loop control profile follows gamma sigma gamma gamma delta gamma upsilon gamma gamma delta choice horizon length feasible model predictive control available points plane allow nonnegative values radical equations 
region bounded axis curve 
succeeded increasing domain allowable initial conditions define feedback law points plane fact neighborhood origin included 
consider longer horizon choose 
choice open loop control moves achieve final state constraint 
cases unknowns equations freeing variable minimize objective 
choice open loop control fu solve final state constraint terms obtain gamma gamma sigma gamma gamma gamma gamma delta gamma gamma upsilon gamma gamma gamma gamma delta open loop controls real values expression inside radicals positive 
inspection exists large positive large negative achieve 
theorem indicates solution problem exists proper choices 
feasible choices real bounded feasible regions bounded surfaces defined gamma gamma gamma feasible control regions unit circle illustrates boundaries feasible region induce discontinuities 
curves indicate boundaries feasible control moves optimal move controller unit circle parameterized cos sin 
solid curve represents solution curve equation broken curve equation 
feasible regions curves signs left hand side equations positive negative 
gain intuitive understanding model predictive control produces discontinuous feedback law consider objective function heavy penalty control 
controller seek small unit circle 
point corresponding expect close boundaries feasible region keep small 
increases suddenly small feasible preferred large penalty stability receding horizon control law having established system equations admit continuous asymptotically stabilizing control show model predictive controller asymptotically stabilize system 
choose quadratic objective function form nonlinear program oe min subject choice satisfy conditions theorem guarantee existence optimum 
show optimal objective function problem oe continuous origin model predictive controller obtained nonlinear program asymptotically stabilizing theorem 
show continuity origin show optimal model predictive objective function bounded continuous functions zero origin 
sufficient continuity optimal objective function origin 
recall equations feasibility nonlinear program equation determined term real valued gamma gamma gamma guarantee feasible point constraints choose argument radical non negative 
achieved choose substituting equations provides feasible open loop control allows evaluate objective function 
defined equation numerator denominator zero 
define value equal limits provide continuous open loop control 
gives fully defines open loop control 
observation non optimal open loop control resulting objective include ffl 
ffl suboptimal open loop control profile continuous 
suboptimal objective function evaluated input sequence composition continuous functions continuous 
ffl objective function zero suboptimal openloop trajectory defined equations 
ffl suboptimal objective function corresponding equations upper bound oe 
ffl optimal objective value oe lower bounded oe upper lower bounded continuous functions values zero origin oe continuous origin 
nonlinear program satisfies sufficient conditions theorem model predictive feedback law defined solution nonlinear program asymptotically stabilizing 
feasible solutions available region attraction numerical results examine discontinuous behavior model predictive feedback law consider initial conditions unit circle examine optimal feedback optimal objective function functions state 
clearly shows feedback control discontinuous state stabilizing feedback 
shows corresponding objective function 
locations discontinuities indicated may change remain regardless distance origin 
shows closed loop behavior system model predictive control points unit circle adjacent discontinuity shown approximately gamma 
control actions produce trajectories initially diverge widely relatively large difference initial control input 
wide divergence expected decrease longer horizon length 
short horizon chosen controller expected aggressive controller longer horizons 
optimal feedback versus state unit circle optimal objective function receding horizon objective versus state unit circle closed loop state trajectories effect horizon length idea longer horizons produce aggressive control action tends borne experimental evidence effects pronounced small greater objective function corresponding optimal control input show little change indicating convergence algorithm system increases 
shows objective value 
experimental data available difference small rendered difficult distinguish 
interestingly enlarging portion shown appears discontinuities observed small positive disappeared view 
discontinuities control clearly visible tested demanded stability 
control move shown 
view results chapter reasonable ask final state penalty replace final state stability constraint 
chapter way ensure stability choose final state penalty function satisfies min fl phi phi phi phi phi phi optimal objective function objective function various horizon lengths optimal objective objective function various horizon lengths close view discontinuities optimal control control input various obvious problem method candidate discontinuous 
continuous chosen theorem berge section indicates control continuous section stabilizing 
may satisfying inequality equation discontinuous system 
research properties inequality indicated better characterize solutions 
analysis discontinuities stability result depends continuity objective function useful provide easily verifiable sufficient conditions determine objective continuous origin 
obviate kind detailed analysis contained section 
highly relevant result berge cited discussion continuity objective functions nonlinear programs 
berge original terminology nomenclature may consistent usage dissertation 
theorem berge topological spaces 
oe continuous numerical function gamma continuous mapping gammax numerical function defined max foe jy gammax continuous mapping phi defined phix fy jy gammax oe upper semi continuous mapping noted berge notion semi continuity point set maps equivalent standard definition single valued functions 
see appendix discussion berge semi continuity concept 
clear consideration gammaoe convert max operation berge theorem equivalent minimization problem retain substance theorem 
identify model predictive control objective function berge oe initial states openloop optimal control sequence result provide sufficient conditions continuity model predictive control objective function respect state 
discussed section continuity non optimal unconstrained mpc objective function follows choose continuous stage cost quadratic objective composition continuous functions berge theorem need continuity constraints respect initial conditions 
constraint regions vary initial conditions continuous respect initial state 
remaining question final state constraint defines constraint region controls continuous 
final state constraint implicitly defines relationship control initial state state equations 
define gamma gamma gamma generality revert back open loop optimal notation final state stability constraint expressed gamma implicitly defines point set mapping state space thetan cartesian product control space control moves 
sufficient conditions existence continuous implicit mapping fv gamma obtained implicit function theorem 
theorem apply case matrix jacobian ff ij fi fi fi gamma fi fi fi fi fi delta delta deltav gamma full rank optimal solution satisfies final state stability constraint 
gain insight hermes example consider points discontinuity observed optimal objective shown 
necessary condition discontinuity lose full rank 
case variables described section jacobian matrix loses rank unit circle discontinuity objective value caused final state stability constraint conditions satisfied gamma gamma separate solutions system equations real valued 
real solutions shown solutions define unique points unit circle plane 
comparison figures points correspond unit circle locus states rank deficient gamma gamma 
shows discontinuity gamma values 
somewhat unexpected illustrates rank condition necessary sufficient discontinuity model predictive control objective 
fortunate hermes case loses rank origin objective continuous 
rank condition sufficient continuity full rank origin model predictive control objective function continuous 
stability closed loop system depends continuity objective function origin 
may interest predict objective function may discontinuous away origin 
replace equation solve system equations numerically obtain locus points 
shown 
happens curves shown correspond equations 
unit circle included provide point comparison results section 
curve discontinuity mpc objective observed reinforcing distinction sufficiency necessity rank condition theorem addresses continuity solutions nonlinear programs applicable question continuity feedback control law generated model predictive control 
discontinuity exhibited controls control input various control law shown gamma appears violate berge theorem 
displayed clearly discontinuous jacobian matrix full rank 
upper semi continuity result berge imply continuous relationship initial state point 
solution apparent paradox lies recognizing berge notion semi continuity applies point set mappings single valued functions 
solution model predictive control program consists controls applicable point set map state space control space shows open loop optimal controls function controls discontinuous state considered individually set continuous gamma jacobian rank deficient berge theorem apply 
discussion leads formal statement concerning continuity model predictive control objective function theorem model predictive control problem section optimal objective function oe continuous jacobian matrix defined equation full rank optimum controls gamma corresponding states 
chapter model predictive control linear processes rawlings muske control formulation analysis coworkers discussed section concerned unconstrained linear systems 
section describes rawlings muske linear systems constraints input state variables 
consider time invariant linear systems ax bu subject state input constraints form fx hg fu dg thetan thetam thetan thetam variables vectors corresponding dimensions 
inequalities taken element wise 
ensure origin included constraint sets assume loss generality elements strictly positive 
motivated part stability infinite horizon lqg optimal controller rawlings muske form optimization problem infinite horizon min fv qz rv solution equation control sequence fv optimization subject linear constraints equations 
theory optimization problem posed limit series finite horizon problems unconstrained lqg problem dynamic programming 
presence constraints prevents derivation state independent matrix riccati equation corresponding control law general problem 
closed form feedback control known necessary resort numerical solutions optimization problem equation 
requires finite parameterization control input 
rawlings muske chose parameterize input fv gamma zero control action th stage 
parameterization mpc objective function divided finite control horizon infinite prediction horizon follows gamma qz rv qz stable eigenvalues magnitude strictly second summation equation evaluated solution matrix lyapunov equation 
recognizing qz qa define qa satisfies gamma sa value infinite horizon objective function equation gamma qz rv immediate question arises formulation evaluate objective unstable approach rawlings muske add state equality constraint mathematical program forces state component unstable subspace final state stability constraint derived analysis stable unstable subspaces schur canonical form described 
final state stability constraint rawlings muske originally formulated final state stability constraint terms jordan canonical form appropriate theoretical purposes direct way identify unstable subspace known numerically unstable 
general cases real schur decomposition provides numerically stable method 
matrix thetan real schur decomposition expressed au orthogonal upper block triangular 
diagonal blocks theta theta corresponding simple complex eigenvalues respectively may arbitrarily ordered 
columns provide basis stable unstable subspaces diagonal blocks ordered smallest magnitude eigenvalues upper left block partitioned columns bases stable unstable subspaces respectively 
unstable modes empty conversely stable modes 
identified final state stability constraint expressed final state penalty matrix equation gamma sa satisfies au matrix derived partition corresponding stable unstable eigenvalues 
stable eigenvalues contained unstable partitions state constraints infinite horizon second complication introduced finite parameterization control input objective function defined finite horizon state constraints satisfied zero control input set constraints takes form ha ha 
ha 
despite having finite parameterization control input mathematical programming problem posed infinite number constraints 
rawlings muske partially addressed concern showing jjz jj active constraints contained finite number stages 
matrices distinct eigenvalues upper bound index active constraint provided min jjz jj ln max max represents largest eigenvalue condition number obtained jordan canonical form gamma 
comparison rawlings muske original definition definition differs theirs 
difference emphasizes idea stages checked tying checks specific index 
bound terms impossible specify priori size mathematical program controller 
implement bound chosen optimization problem solved checked see satisfies equation 
fails optimization problem solved larger value equation satisfied 
state dependent approach undesirable requires iterative procedure convergence properties known requires changing number state constraints depending magnitude initial state 
gilbert tan provided algorithm specify priori largest index equation binding state constraint 
method advantage depend particular problem posed find set fi fi problem solved defining fi fi gilbert tan showed finite result propose numerical procedure determining 
take 
row dimension solve linear programming problem 
deltag ith row matrix argument max ha subject ha 
gamma unbounded take repeat previous step 

optimal satisfies gamma algorithm requires solution series linear programming problems efficient algorithms software implementations available 
current state quadratic program mpc controller min gamma qz rv subject dv hz az bv gamma ha quadratic program summarizes purpose constraint represents state time feedback controller desired represents linear system equations represent specified input state variable constraints represents state constraints infinite horizon portion objective function final state stability constraint stable 
account control horizon quadratic program contains theta decision variables 
quadratic program essentially rawlings muske nominal stability shown provided control formulation 
key extensions ffl characterization unstable subspace schur decomposition ffl application results gilbert tan convert infinite series state constraints finite independent state 
nominal stability result changed extensions directed establishing rawlings muske controller tool applications 
infeasibilities quadratic program analysis guarantee quadratic program equation contain feasible point 
prevailing view infeasibilities literature model predictive control schemes negative 
view taken rawlings muske continued dissertation infeasibilities reveal conflicting demands satisfied stable control scheme require reformulation control objectives 
determine reform necessary examine problem constraints closely 
ffl state equations initial condition constraints measurements physical characteristics system 
short repeating improving model identification process obtaining better process measurements reasonable change obtain feasible point quadratic program 
ffl control variable inequality constraints constraints normally associated hard limits control actuators valve stem positions 
input variables physically limited way conceivable constraints modified provide feasible point quadratic program 
basis analysis algorithm adopt view constraints subject change 
implication position hard constraints control variables carefully considered inclusion quadratic program 
control action desired simply performance objective satisfied increasing weighting matrix objective function 
ffl state variable inequality constraints posed quadratic program equation state variable constraints include initial condition possible initial condition satisfy constraints case seek controller bring state constraint quickly possible 
accomplish simply remove constraint pose modified quadratic program included constraint 
possible relaxing state constraint provide feasible point 
control objective shifts state satisfies constraints soon possible violating input variable constraints 
approach considered rawlings muske shown effect nominal stability 
incorporated algorithm identification time index denoted index state variable constraints satisfied 
constraints hz gamma adjustment algorithm requires solution mixed integer program determine minimum discuss numerical determination subsequent section 
discuss limiting case large allowed exceed show nominal stability basic algorithm retained 
ffl state variable stability constraint constraints absolutely required nominal stability closed loop controller 
may occur combination fixed control variable constraints stability constraint act create empty feasible set 
rawlings muske describe situation lacking constrained increasing may provide feasible point quadratic program 
cases may provide feasible point 
issues discussed 
constrained choice horizon length correct choice control horizon critical stability rawlings muske controller 
concept controllability origin central importance determining definition dynamic system controllable origin exists finite control sequence fu un gamma satisfying 
smallest called controllability index unconstrained time invariant linear systems controllability origin equivalent controllability checked considering rank controllability matrix defined ab delta delta delta gamma controllability index systems satisfies dimension stability rawlings muske controller required unstable modes forced origin equivalently state component unstable subspace 
investigate behavior unstable modes useful derive dynamic system equation unstable modes schur decomposition equation substituting system equation equation multiplying left provides bu unstable modes obtained bottom half partitioned system bu linear systems equivalent controllability unstable modes immediately identify matrix defined delta delta delta nu represents dimension number unstable modes unconstrained linear systems equivalent having full rank 
constrained rank condition necessary controllability unstable modes origin sufficient constrained case input sequence fu un gamma satisfy du input sequence exists achieve stability rawlings muske controller control horizon cs constrained index cs controllability index system equation subject input constraints 
presence input constraints additional complication dependent initial state 
unfortunate consequence states may stabilizable may 
nominal stability represents time problem initial state stabilizable set subsequent states closed loop system stable 
presence disturbances previously stable trajectories may leave set stabilizable states cause quadratic program feasible point 
implications control unstable processes discussed 
am aware closed form priori method verify controllability presence input constraints 
numerical procedure yields index cs provided 
concept algorithm find distance initial condition set stabilizable states fixed test value cs distance non zero initial condition stabilizable test value cs increased 
algorithm terminates distance zero indicating index cs test cs exceeds predetermined maximum value 
take quadratic program checking constrained finding constrained index takes form min fi fi fi fi fi fiu gamma fi fi fi fi fi fi subject dv bv cs gamma ncs optimal objective quadratic algorithm produces controllability index cs exists cs max 
choose max 
set 
solve quadratic program 

max set repeat step 
set cs 

max 
system constrained stabilizable cs max state constraint violations stability mentioned section infeasibilities rawlings muske controller due state constraints may relaxed compromising stability 
strategy calls elimination state constraints initial stages prediction horizon feasible point obtained 
exists system constrained stabilizable cs nominal system controller takes steps subsequent states satisfy state constraints 
looking ahead section interested coupled observer controller rawlings muske controller 
critical importance analysis stability controller observer pair continuity properties feedback control law 
feedback law solution quadratic program turn result hager addresses continuity solutions quadratic programs 
notation terminology hager may correspond usage dissertation 
theorem hager quadratic program min 
rv subject av bv defining data set data subsets ffi delta 
convex set data satisfying 
exists unique solution quadratic program 

exist gamma gamma gamma fi fi fi fi fi fim fi fi fi fi fi fi gamma matrix binding constraints 
exists ff rv satisfying 
exists fi fi fi fi fi fi fim fi fi fi fi fi fi exists constant ae jju gamma jj gamma ffi jj ae jj delta gamma delta jj jj jj constant ae ae ff gamma fi gamma gamma ff gamma ff max gamma fi hager theorem provides foundation analyzing continuity rawlings muske control formulation 
consider case state constraints apply 
table provides illustration constraints apply case 
decision variables fz fv gamma listed top table 
matrix equalities inequalities obtained left multiplying matrices corresponding variable top table 
right hand sides constraints provided far right 
table grouping constraints represent state equations second grouping represents state inequality constraints 
third group final state stability constraint fourth represents state constraints infinite horizon reduced finite number algorithm section 
final block constraints represents input variable inequality constraints 
delta delta delta gamma gamma delta delta delta vn gamma vn gamma vn gamma rhs gammab ax gammaa gammab gammaa gammab gammaa 
gammab gammaa gammab gammaa gammab 
ha 
ha gamma ha 
table tableau constraints visual presentation table easily able verify sufficient conditions hager discussed point point basis ffl convexity data set fixed parameter varies data set initial state corresponds variations hager ax fixed lies feasible region defined remainder constraints table 
strictly positive set linear equality constraints defines convex region satisfies hager convexity condition 
ffl uniqueness solution provided constraints linearly independent optimum point discussed unique weighting matrix hager formulation positive definite 
rawlings muske controller condition satisfied positive definite state control weighting matrices respectively 
ffl existence gamma gamma hager corresponds kronecker products identity matrix vary may take gamma max 
upper bound fi fi fi fi fi fim fi fi fi fi fi fi norm binding constraints needed get gamma bound easily obtained recognizing norm matrix equal largest singular value 
interlacing property singular values sub matrices fact number active constraints equal number decision variables follows gamma equal largest singular value consisting equality constraint matrices augmented subset inequality constraints yields square matrices having maximum norm 
ffl lower bound rv condition equation trivially satisfied positive definite state input weighting matrices ff min foe min oe min oe min oe min represents smallest singular value matrix argument non zero 
bound holds regardless subsidiary condition 
ffl lower bound sufficient condition equation rank condition matrix active constraints solution 
condition may satisfied arbitrary constraints constraints may structured way ensure equation satisfied loss generality constraint reduction algorithm appendix set possible constraints remaining applying reduction algorithm necessarily independent set 
lower bounding constant fi available minimum singular value equality constraints augmented subset inequality constraints provide minimum singular value 
gamma gamma ff fi defined sufficient conditions lipschitz continuity rawlings muske controller fixed satisfied 
determine lipschitz constant equation 
variable consideration initial state equation jju gamma jj gamma jj continuity controller increasing complete formulation rawlings muske controller included possibility removing state constraints time allow wider range initial conditions stabilized 
allow initial state range upper bound need analyze continuity control law varies 
consider sets ae fi fi fi fi feasible point exists quadratic program rawlings muske controller oe sets properties ffl nested ffl defined non strict inequalities equality constraints closed 
ffl may may bounded 
ffl contain neighborhood origin 
originally proposed changes induced absence feasible point constrained stabilizable system 
purpose analysis convenient consider sets having independent existence state controlled system possibly traversing sets time progresses 
issues relevant continuity control law ffl lipschitz bound exists limit ffl control law continuous boundaries regions 
delta delta delta gamma gamma delta delta delta vn gamma vn gamma vn gamma rhs gammab ax gammaa gammab gammaa gammab gammaa 
gammab gammaa gammab gammaa gammab 
ha 
ha gamma ha gamman gammai table tableau constraints lipschitz bound limiting large state constraints longer enforced control horizon convenient introduce new variable quadratic program gamman 
recall controller formulation allows action stable modes state tableau constraints takes slightly different form indicated table 
causes variable enter constraint tableau single matrix equality constraint indicated row table 
finite clear inspection lead linear dependence active constraint set rows com rows multiply variables gamman possible remaining identity matrix linearly dependent combination matrices immediately tableau 
concern alleviated observing righthand side state inequality constraints involving fixed greater zero 
final constraint table requires state inequality constraints binding 
furthermore possible eliminate linearly dependencies binding set constraint reduction algorithm appendix shows lipschitz constant exists finite matrix binding constraints converges 
continuity control boundary regions showed section fixed feedback control law rawlings muske controller lipschitz continuous state 
seek answer question control law continuous function th initial state equivalent continuity boundaries sets control problem possible need enlarged initially allow wider range initial states stabilized model predictive formulation 
rawlings muske showed nominal systems decrease new time step producing quadratic program feasible points 
disturbances monotonically decreasing time 
presence disturbances possible state trajectory move outside feasible set specific value need increased provide feasible point 
increases decreases occur dynamically scheme consider controller continuous numerical experiments indicate controller continuous shows control law versus state variable siso system studied muske rawlings gamma control constraints state constrained hx gamma state control discontinuity rawlings muske controller appear possible discontinuity may impact may suspected 
numerical experiments continue indicate asymptotic stability disturbance 
remains topic current research 
stability results perturbed systems result central discussion coupled observer controller pair stability definitions standard theorem lipschitz continuous origin asymptotically stable fixed point 
exponentially stable sequence origin asymptotically stable fixed point system proof demonstrate asymptotic stability show stability lyapunov stability convergence 
refer results properties lyapunov functions noting include continuous sufficient condition 
sufficient conditions follow continuity assumption 
convergence exist lyapunov function unperturbed system satisfying jjxjj jjxjj deltav gamma gammac jjxjj jjxjj functions class functions continuous strictly increasing 
proves lipschitz continuous shown deltav gamma gammac jj jj jj gammac jj jj kae lipschitz constant 
inequality arises exponential convergence ae jje jj ae summing inequality times gives gamma gamma jj jj kae gamma equivalently jj jj gamma kae gamma kae gamma right hand side inequality function sequence partial sums bounded constant 
means jj jj 
properties implies jj jj convergence proven 
stability identifying ffi ae result follows directly section 
stability combined observer controller section apply result controller rawlings muske unknown initial condition 
linear time invariant model form ax bu cx pair assumed detectable state estimated stable linear observer 
muske rawlings showed asymptotically stabilizing state feedback controller incorporates linear state input constraints constructed solution quadratic program 
controller implemented model predictive controller quadratic program posed solved time step 
control time depends state write equation ax bu represents feedback control law obtained rawlings muske mpc formulation 
absence constraints feedback control law linear function determined linear quadratic gaussian optimal control theory 
constraints nonlinear function longer closed form expression 
previously noted mpc control law delta solution quadratic program lipschitz continuous argument fixed interested effect observer stability system equation 
consider special case unknown initial condition stable linear observer 
control input known exactly nonlinearities bearing stability properties observer reconstruction error ffl exponentially stable 
take true reconstructed state respectively state system evolves accordance ax bu ax bu ffl ax ffl gamma ax bu ffl gamma identifying ax bu see system evolves asymptotically stable system subject additive disturbance ffl gamma time step 
reconstruction error ffl exponentially stable delta satisfies lipschitz condition disturbance satisfies inequality exponentially stable 
jjb ffl gamma jj jj ae inequality see combined observer controller satisfies sufficient conditions theorem resulting system asymptotically stable 
chapter model predictive control stochastic systems model predictive control uses deterministic models predict effect control actions 
implementation mpc stochastic models especially nonlinear constrained systems clearly defined 
bertsekas provides discussion various control strategies involve differences feedback computation expected values controller formulation 
dreyfus law cite example clearly demonstrates suboptimality batch optimization schemes depend current state value mpc compared optimization dynamic programming provides optimal feedback controller 
section modified version specifically highlights differences dynamic programming model predictive control approaches stochastic control problem 
section examine familiar problem linear system containing stochastic coefficients 
general dynamic system state control stochastic input seek controller minimize criterion oe gamma oe fi fi fi fi fi 
expectation conditioned section address issue nonlinear state estimation assume full state measurement available 
see muske rawlings discussion nonlinear state estimation 
assume distributional parameters known stochastic input calculate expectations needed oe 
minimizing control may obtained dynamic programming dp shown provide minimizing controller multistage optimization problems kind 
special cases dynamic programming represent computationally feasible control method curse dimensionality cited bellman 
bertsekas discusses suboptimal control schemes stochastic multistage problems share dimensionality problem dynamic programming 
optimization requires measured initial state treats process measurements stochastic nature differently 
methods follows ffl certainty equivalence control motivated certainty equivalence principle arising lqg control theory 
technique random variables problem replaced expected values 
controller obtained solution resulting deterministic optimal control problem computed resorting dynamic programming 
ffl open loop feedback control incorporates effect stochastic input variables objective function computing expectations arising equation 
effect past random variables incorporated stage adjusting state conform measured value method consider effect measurements optimization criterion 
method identified mpc 
ffl open loop control feedback account effect state observations update current state account current state measurements 
optimal control profile computed changed subsequently new state measurements 
modified dreyfus optimal path problem dreyfus problem section simple stochastic control problem illustrate difference mpc optimal feedback control 
example example dreyfus 
data original example changed order illustrate better points discussed 
consider control problem illustrated 
problem indicated optimal path problem seek path right hand points minimum cost 
cost transition indicated 
control action point 
deterministic problem complete assurance state trajectory proceed exactly control input control decision state moves adjacent vertex similarly control action causes state move 
simple deterministic control problem control sequences result zero cost example 
clearly difference total cost implement feedback scheme initial open loop sequence chosen changes result new state information state perfectly predicted advance 
allow possibility disturbances enter system state sequence det cost stoch 
cost ddd uuu table open loop cost state feedback important 
consider case effect control action random called percent chance implementing percent chance implementing similarly case specify defines stochastic control problem state feedback play role difference dynamic programming model predictive control apparent 
model predictive control implemented problem follows enumerate possible open loop controls point indicated table 
deterministic cost assuming probability making transition accordance control 
stochastic cost obtained expectation costs specified control trajectory 
expectation uses available information problem including transition probabilities current state knowledge transition costs 
example consider control sequence 
non zero costs directly compute expected value control sequence cost costs remaining control sequences indicated table indicate best possible cost control strategy 
implement feedback method inject control series observe state system transition 
state mpc dp input cost input cost non unique solution table feedback control action closed loop cost mpc optimal control 
new initial state compute open loop optimal control input time containing moves result lowest expected cost 
process repeated final desired state right hand side reached 
computed control moves state indicated table cost point problem 
optimal feedback policy determined dynamic programming 
points right hand side optimal policy computed point optimal cost associated point 
algorithm progresses right hand points point optimal feedback laws computed consider fact control moves states optimal 
comparing dynamic programming mpc results table see methods predict control point 
exception point cost dynamic programming half model predictive control 
substantial difference seen examples dreyfus law 
examples difference percent dynamic programming model predictive control 
result argued mpc close dp performance 
example conclusively demonstrates case 
linear system random coefficients dreyfus law example optimal path problem 
claimed example problem chosen unrepresentative real problem practical interest 
section turn somewhat familiar scalar linear dynamic system 
stochastic character arises random coefficient input variable statistics random coefficient known 
seek regulate stochastic dynamic system origin scalar real variables known initial condition description independent random input available gamma gamma 
statistics specify unique distribution possibility discrete takes values gamma probabilities indicated gamma gamma discrete distribution specified statistics illustrated 
possible distribution normally distributed random variable mean gamma variance gamma gamma corresponding normal distribution shown 
figures 
controller designed minimize criterion gamma gamma fi fi fi fi fi indicated expectation taken respect random inputs fw wn gamma conditioned 
indicated usage place case little room confusion chosen retain notation section 
probability density function discrete distribution specified statistics probability density function normal distribution specified statistics dynamic programming solution dp algorithm requires solution recursive series subproblems proceeding backward min gamma fi fi fi ji delta optimal stage objective function state 
dynamic programming objective function equivalent objective function mpc retain notation distinguish 
obtain equations linearity expectation operator 
min gamma ji unconstrained minimization expression gives gamma gamma 
notation section indicate feedback law arising stage dynamic programming problem 
control law equation substituted expression obtain gamma continuing manner reveals proportional dp algorithm represented recursive equation min gamma fi fi fi substituting equations performing indicated minimization gives feedback control law gamma gamma gamma obtain recursive equation substitute equation expression compare result equation obtain gamma gamma gamma gamma gamma complete dynamic programming solution gamma gamma gamma gamma gamma gamma derivation produces recursive solution equivalent bertsekas discusses linear systems stochastic systems matrices 
model predictive control solution contrast dynamic programming mpc approach solve series subproblems 
problem posed complete horizon mathematical programming techniques applied solve complete open loop trajectory prediction horizon 
nonlinearities process model non quadratic penalty functions constraints introduce complexities usually require numerical solutions nonlinear optimization computer codes 
due structure example solution optimization problem available solution dimensional linear algebra problem 
stage mpc controller exactly solution dynamic programming result 
differences appear 
objective min equation performing necessary expansions inserting expectations equations gives oe gamma gamma gamma oe represents stage objective function 
minimization unconstrained optimal values obtained differentiating respect setting result zero solving resulting system equations 
oe gamma gamma oe gamma gamma matrix notation gamma equations gamma solution system equation gamma gamma gamma gamma gamma gamma key distinction results model predictive control dynamic programming illustrated equations way computed control moves depend state 
model predictive control control moves depend initial state dynamic programming control move depends corresponding state depends linear algebra problem equation generalized stages takes form gamma gamma gamma gamma delta delta delta gamma gamma gamma 
delta delta delta 
un gamma un gamma un gamma gamma gamma 
control input desired interested limiting behavior 
convenient derive recursive form recursive solution possible details omitted brevity 
matrix left hand side equation individual equations complete system extracted provide term recursion convenient define gamman rewrite recursion relation terms 
convenience context depart previous stipulation represent open loop optimal control mpc 
additional algebraic manipulations provide gamma gamma gamma delta gamma gamma theta gamma gamma theta gamma gamma gamma gamma vk delta gamma control input provided gamma gamma gamma gamma gamma gamma gamma control strategies model predictive control dynamic programming possible ways design controller system 
comparison consider possibilities open loop optimal control certainty equivalence considered briefly 
open loop optimal control 
method solves open loop optimal controller horizon stages just model predictive control 
mpc state updated new data available 
simply inject open loop optimal control moves calculated initial optimal control problem 
solutions depend fixed value compute open loop control method inherently suited problems fixed final time 
certainty equivalence control 
termed certainty equivalence similarity results linear quadratic gaussian lqg observer controller methods 
solving optimization expectation stochastic objective function equation pose strictly deterministic objective place stochastic model equation insert expected values stochastic variables 
state updated new measurements available 
comparison control strategies compare performance various control strategies final time fixed 
examine feedback control laws initial state expected value objective function entire horizon 
ce mpc dp horizon length feedback gain feedback gain various control strategies feedback control law initial time illustrated function distributional parameter controls linear functions state feedback gains 
shows methods compared yield result 
endpoint cases problem degenerates non stochastic problem 
methods give result strictly deterministic cases 
case method demand control identically zero 
certainty equivalence method corresponds uncontrollable system 
control action add cost affecting state system 
methods corresponds control gain sign equal probability 
best control action case set control zero 
zero control action eliminates effect stochastic variable methods coincide reflected costs shown figures 
open loop optimal control shown control input control mpc 
shows costs associated various control strategies 
clearly certainty equivalence controller performs far worse methods 
show results omitting certainty equivalence method 
figures illustrate dynamic ce mpc dp horizon length cost expected costs various control strategies mpc dp horizon length cost expected costs various control strategies programming yields lowest possible cost stochastic feedback control systems predicted theory 
infinite horizon implementation process control applications batch processes naturally defined finite horizons 
section consider application model predictive control infinite horizon compare mpc performance dynamic programming controller 
infinite number control moves ordinary mathematical programming problem equation 
move optimal sequence implemented possible recursion equations examine behavior infinite horizon model predictive controller compare infinite horizon dynamic programming controller 
refer infinite horizon controller cases am considering controller limit equations model predictive dynamic programming controllers respectively 
model predictive controller 
consider limiting behavior recursion represented equation find different behavior observed open interval 
consider cases 
cases equations gamma gamma analysis equation show gamma ratio converges approximately 
equation provides infinite horizon gain 
converges 
equation gives feedback gain identically limit 
dynamic programming controller 
equations provide convergent sequence sequence equation compute dynamic programming controller converges rapidly produce feedback gain shown 
gain infinite horizon feedback gain dynamic programming costs infinite horizon strategies 
possible compute infinite horizon cost function directly unbounded consider average cost stage resulting candidate control schemes 
costs dynamic programming model predictive control coincide cases 
cost cases quadratic function initial state oe dp mpc observations sections demonstrated linear plants nominal stability properties mpc state feedback sufficient provide asymptotic stability presence disturbances due imperfect state knowledge 
converse lyapunov theorems results stability perturbations theorem provide powerful tools address effects kinds disturbances arise interconnection general nonlinear estimators regulators 
research direction warranted 
sections best possible control performance obtained stochastic process example complete dynamic programming solution available feedback form algebraic equation 
second best provided open loop optimal feedback control identified model predictive control 
ordinary open loop optimal control feedback performed worse previous methods 
ordering consistent previously published results 
certainty equivalence controller showed clear ordering respect methods considered demonstrated performance orders magnitude worse parameter ranges 
feasibility computation relative ordering possible control schemes clear model predictive control stochastic systems competitive approach finite horizon control problems batch processes 
infinite horizon control problems continuous processes picture clear 
hoped extending horizon mpc scheme possible approximate infinite horizon behavior dynamic programming feedback controller 
keerthi gilbert show costs converge class nonlinear deterministic problems considered 
unfortunately case stochastic problem 
examples illustrate obvious best implement model predictive control stochastic systems 
open question remains topic current research 
optimal path problem dreyfus law difference dynamic programming solution called optimal feedback authors dynamic programming percent 
despite small difference characterized model predictive approach going far state little recommend scheme uses information true feedback solution 
protect reader mistakenly believing alternative way computing true optimal feedback solution 
suggests consider today practical approach problems rejected theoretical concerns 
despite rejection model predictive methods embraced industrial practitioners dynamic programming approaches rarely adopted 
possible reasons offered occurred including educational training barriers understanding dynamic programming approach difficulty identifying stochastic models cost function 
model predictive controller hand requires solution open loop optimization problem problem practicable line decrease computing cost development efficient reliable optimization codes 
optimal mpc provide stable feedback controller large class linear nonlinear systems address practical issue constraints inputs 
cost function artificial connected tuning parameters control human operators monitoring line tuning 
fair say mpc may aesthetic appeal optimal control address practical issues reach dynamic programming methods 
chapter focused main areas study model predictive control sufficient conditions nominal stability general nonlinear systems improvements rawlings muske approach linear systems constraints application theory dynamic programming analyze model predictive control application mpc stochastic perturbed systems 
stability nonlinear systems controlled mpc shown depend non negativity continuity mpc objective function 
objective acts lyapunov function state trajectory controlled system 
nominal systems decreasing objective function obtained final state stability constraint prediction horizon infinite prediction horizon 
example demonstrated finite horizon problems necessarily converge infinite horizon problem researchers provided stronger sufficient conditions convergence restrict class systems considered 
continuity mpc objective important stability examined detail behavior system controlled mpc demands discontinuous controller stability 
example provides strong insight final state stability constraint produce discontinuous controller mpc objective function 
provided sufficient condition derived implicit function theorem assures continuity objective function stability 
mpc method rawlings muske maturing implementable method attracted interest industrial ers 
method requires satisfaction linear state constraints infinite number states 
rawlings muske able show constraints certain time index active result state dependent 
reported dissertation incorporates result gilbert tan collapses infinite set constraints equivalent finite set state independent 
resolves important implementation issues raises concern controller may violate sufficient conditions stability presence disturbances 
issue resolved object ongoing research university texas 
showed important results linear quadratic lq optimal control derived special case general theory dynamic programming 
arguments involving monotonicity model predictive control objective extended lq stability result general nonlinear case 
provided sufficient condition stability generalization known result riccati difference equation lq optimal control 
early stages may yield significant results 
considered application model predictive control problems involving stochastic perturbed systems 
key result showed combined observer controller asymptotically stable controller asymptotically stable lipschitz continuous observer exponentially stable 
illustrated pseudo separation principle action nonlinear systems stability properties nominal controller observer derived separately combined yield stable combination 
stochastic systems model predictive control method batch optimization shown inferior designed dynamic programming 
current mpc methods depend batch optimization indicates mpc suboptimal compared dynamic programming shown provide minimizing controller 
result literature little notice researchers practitioners illustrated examples 
despite suboptimality mpc compared full dynamic programming solutions continue advocate controllers designed deterministic models 
stochastic nature physical systems analyzed combination linear nonlinear observers resorting pseudo separation principle 
topics discussed dissertation provide clear avenues study ffl separation principle nonlinear systems section provides sufficient conditions asymptotic stability combined observer controller observer exponentially stable nominal controller asymptotically stable 
unclear similar result hold observer asymptotically stable exponentially stable 
significant practical interest nonlinear observers developed necessarily exponentially stable 
case proven counterexample provided 
ffl recurrent stochastic input observer controller section posed deterministic problem purpose observer reconstruct unknown initial state 
development needed characterize behavior combined observer controller pairs presence recurrent disturbances 
significant contribution regard simply define problem stochastic framework relevant control practice 
kushner provide discussion stability concepts terms bounded disturbances stability probability definitions 
kushner especially emphasize stochastic lyapunov functions 
clear address significant questions control practice addressed 
ffl analysis mpc dynamic programming demonstrated dynamic programming analyze mpc algorithm 
key result inequality solved controller arg stabilizing follows monotonicity property operator investigation solutions inequality equation potentially large impact design nonlinear model predictive controllers 
ffl final state constraint stability monotonicity property important consequences 
may difficult find initial satisfy inequalities 
case satisfy ordering 
sufficient conditions despite having ordering provide sufficient condition stability stage mpc control final state penalty 
linear quadratic case wealth results concerning initial conditions riccati difference equation generalizations nonlinear systems immediate practical benefit 
ffl improvements rawlings muske controller experiments indicate discontinuity controller discussed section may little impact stability combined observer controller despite satisfying sufficient conditions theorem 
analysis needed 
may detailed analysis stochastic systems theory indicate zero measure regions discontinuities exist negates influence stability combined system 
ffl stochastic mpc design emphasis design mpc controllers deterministic models 
results section indicate approach produces suboptimal control 
literature dynamic programming devoted principally solution stochastic optimal control problems 
shown dissertation rich possible mpc applications 
broader overview existing literature area needed fill large gap exists theoreticians control practitioners area 
ffl un decoupled observer controller simplicity analysis briefly discussed analyzed special case observer controller pair provide pseudo separation principle 
cases separation possible 
simultaneous observer controller designed jointly solves observer controller optimization 
idea measurements provided input observer controller algorithm provides controller direct identification state variable 
appendix berge concept semi continuity discussion concerning continuity objective functions solutions sets taken berge 
relevant theorems terms semi continuity point set maps 
berge semi continuity definitions yield familiar definitions discussed elementary calculus classes greatly confounded early efforts understand behavior hermes example section 
refers berge proofs continuity theorems berge book longer print am providing basic discussion berge semi continuity concept 
taken chapter vi berge gamma mapping topological space topological space point say gamma lower semicontinuous open set meeting gammax neighbourhood gammax say gamma upper semi continuous open set containing gammax exists neighbourhood gammax ae say mapping gamma continuous lower upper semi continuous gamma single valued mapping definition lower semi continuity coincides ordinary definition continuity true upper semi continuity 
final quoted paragraph berge clear distinction concepts point set maps single valued functions 
distinction highlighted trap seeking apply results contained book 
appendix constraint reduction algorithm quadratic program form min rv subject av bv seek eliminate constraints redundant meaning rows considered separately implied constraints 
assume constraints consistent meaning exists feasible point satisfy constraints 
inequality constraints dimension vector take fgg ith row algorithm eliminates redundant constraints 
set 
solve linear programming problem min fbg subject av represent corresponding matrices vectors kth row deleted 

fbg reduce constraint set deleting kth row 


take return step 
equality constraints equality constraints simpler problem 
equality constraints consistent merely delete rows individually check rank resulting rank rank kth row deleted constraint set 
bibliography bellman dynamic programming princeton university press princeton new jersey 
berge topological spaces including treatment multi valued functions vector spaces convexity oliver boyd edinburgh london 
bertsekas monotone mappings applications dynamic programming siam cont 
opt pp 

dynamic programming prentice hall englewood cliffs new jersey 
bertsekas shreve stochastic optimal control discrete time case academic press new york 
gevers adaptive optimal control thinking man gpc prentice hall englewood cliffs new jersey 
gevers petersen kaye monotonicity properties solutions riccati difference equation propositions lemmas theorems fallacious conjectures counterexamples sys 
cont 
pp 

brockett asymptotic stability feedback stabilization differential geometric control theory brockett eds birkhauser pp 

chen shaw receding horizon control automatica pp 


necessary condition feedback stabilization sys 
cont 
pp 

de souza gevers goodwin riccati equation optimal filtering systems having singular state transition matrices ieee trans 
auto 
cont pp 

dreyfus dynamic programming calculus variations academic press new york 
dreyfus law art theory dynamic programming academic press new york 
eaton finite horizon predictive control chemical processes phd thesis university texas austin 
eaton octave high level interactive language numerical computations tech 
rep university texas center control systems research austin texas 
edgar optimization chemical processes mcgraw hill new york 
sensitivity analysis nonlinear programming academic press new york 
garc ia morari model predictive control theory practice survey automatica pp 

gilbert tan linear systems state control constraints theory application maximal output admissible sets ieee trans 
auto 
cont pp 

gill murray saunders wright user guide sol version fortran package nonlinear programming technical report sol tech 
rep systems optimization laboratory department operations research stanford university 
golub loan matrix computations johns hopkins baltimore 
hager lipschitz continuity constrained processes siam cont 
opt pp 

quelques questions de la th eorie de la pour les syst emes aux diff erences arch 
rational mech 
anal pp 

hermes asymptotically stabilizing feedback controls nonlinear regulator problem siam cont 
opt pp 

horn johnson matrix analysis cambridge university press 
kalman contributions theory optimal control bull 
soc 
math 
mex pp 

kalman bertram control system analysis design second method lyapunov part ii discrete time systems asme basic engr pp 

keerthi optimal feedback control discrete time systems state control constraints general cost functions phd thesis university michigan 
keerthi gilbert existence theorem discretetime infinite horizon optimal control problems ieee trans 
auto 
cont pp 

moving horizon approximations general class optimal nonlinear infinite horizon discrete time systems proceedings th annual conference information sciences systems princeton nj princeton university pp 

optimal infinite horizon feedback laws general class constrained discrete time systems stability moving horizon approximations optim 
theory appl pp 

easy way stabilize linear constant system ieee trans 
auto 
cont 
stabilizing discrete constant linear system application iterative methods solving riccati equation ieee trans 
auto 
cont pp 

kushner stochastic stability control vol 
mathematics science engineering academic press new york 
kwon bruckstein kailath stabilizing design moving horizon method int 
control pp 

kwon pearson modified quadratic cost problem feedback stabilization linear system ieee trans 
auto 
cont pp 

feedback stabilization time varying discrete linear systems ieee trans 
auto 
cont pp 

stability dynamical systems regional conference series applied mathematics siam 
luenberger optimization vector space methods john wiley sons new york 
mayne implementable receding horizon controller stabilization nonlinear systems proceedings th conference decision control december pp 

receding horizon control nonlinear systems ieee trans 
auto 
cont pp 

model predictive control nonlinear systems proceedings american control conference june pp 

mayne moving horizon observer control proc 
st ieee conference decision control tulsa oklahoma 
moving horizon observer control abstracts washington university nsf workshop nonlinear control systems washington university may 
meadows henson eaton rawlings receding horizon control discontinuous state feedback stabilization 
accepted publication int 
cont 
meadows muske rawlings constrained state estimation discontinuous feedback model predictive control proceedings european control conference european automatic control council june pp 

mayne receding horizon control nonlinear systems differentiability optimal value function sys 
cont 
pp 

mayne moving horizon observers proc 
ifac symposium nonlinear control systems design bordeaux france pp 

moving horizon observers observer control tech 
rep ucd eecs scr college engineering university california davis september 
mayne robust receding horizon control constrained nonlinear systems ieee trans 
auto 
cont pp 

moving horizon observers observer control 
accepted publication ieee trans 
auto 
cont 
muske linear model predictive control chemical processes phd thesis university texas austin 
muske rawlings linear model predictive control unstable processes proc 
cont pp 

model predictive control linear models aiche pp 

nonlinear moving horizon state estimation nato advanced study institute methods model control proceedings ed turkey july kluwer academic publishers 
rawlings meadows muske nonlinear model predictive control tutorial survey proceedings kyoto japan 
rawlings muske stability constrained receding horizon control ieee trans 
auto 
cont pp 

sontag mathematical control theory springer verlag new york 
thomas linear quadratic optimal estimation control receding horizon electron 
lett pp 

nonlinear systems analysis prentice hall englewood cliffs new jersey nd ed 
vita edward scott meadows jr born tulsa oklahoma may son edward meadows maria brown meadows 
decade life spent oklahoma florida south carolina germany air force dependent 
returning oklahoma family settled graduated high school 
entered university oklahoma fall received degree bachelor science chemical engineering 
commissioned naval officer oklahoma city assigned navy division naval reactors washington tour naval reactors left active duty return graduate school university texas austin 
remained affiliated naval reserve commanded different naval reserve units studying austin 
received master science degree university texas permanent address avenue austin tx dissertation typeset author document preparation system 
