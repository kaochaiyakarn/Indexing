robot learning parallel genetic algorithms computers john grefenstette navy center applied research ai naval research laboratory washington dc email aic nrl navy mil keywords parallel genetic algorithms robot learning explores machine learning methods extracting knowledge simulations complex systems 
particular genetic algorithms learn rule strategies autonomous robots 
evaluation strategy may require executions simulation produce meaningful estimate quality strategy 
consequence evaluation single individual genetic algorithm requires fairly substantial amount computation 
system suggests sort large grained parallelism available network workstations 
describe implementation parallel genetic algorithm case studies resulting speedup robot learning tasks 
motivated part growing tion simulations design test complex systems 
view simulations resources knowledge acquisition intelligent autonomous agents 
approach uses genetic algorithms explore space alternative strategies intelligent autonomous agents simulated environment 
learned strategies validated operational system 
developed approach grefenstette ramsey permits learning system modify simulation experience operational environment 
currently testing methods design intelligent autonomous mobile robots grefenstette schultz 
genetic algorithms adaptive search techniques principles derived population genetics selec tive breeding methods 
process shown 
main distinguishing features genetic algorithms evaluate population acceptable solution 
replicate selected members mate mutate evaluate new population output solution genetic algorithm population candidate solutions problem search space candidate solutions process simulated evolution survival fittest reproduce promising solutions idealized forms recombination mutation introduce new variants 
complete discussions see davis grefenstette 
genetic algorithms evaluate population competing solutions iteration natural view parallel algorithms number approaches suggested implementation various parallel processing architectures cohoon hedge martin richards grefenstette born grefenstette tanese whitley starkweather 
focuses running genetic algorithms networks loosely coupled workstations 
section briefly describes specific genetic learning system samuel 
samuel samuel system learns strategies sets decision rules genetic algorithms grefenstette ramsey schultz 
samuel maintains population competing strategies shown 
strategies evaluated running simulation intended task environment learning agent uses strategy perform task 
attempt perform task called episode 
episode automated critic provides assessment scores performance learning agent task 
especially interested complex environments learning agent deal variety conditions including noisy sensors noisy actuators independent agents 
reflect environmental complexity typically average performance strategy learning episodes changing environmental conditions episode 
result substantial amount computation required evaluate fitness strategy 
strategies population evaluated samuel generates new population strategies steps 
strategies selected reproduction observed fitness 
second changes mutations generate new rules slight variations combinations existing rules 
selected strategies recombined exchanging rules parent strategies 
rules active high performance episodes exchanged group order promote spread effective behaviors population 
previous studies samuel shown system capable learning strategies variety interesting tasks including evading predator prey tracking agent distance navigating obstacle field schultz grefenstette grefenstette 
rest section discusses approach speeding learning process exploitation parallel processing 
master process parallel version samuel uses master worker paradigm best suited large grain parallelism finkel 
master process performs functions associated genetic algorithm 
worker processes responsible evaluation individual strategies 
pseudo code master worker process shown figures 
master process initializes population strategies starts evaluation servers worker processes 
pass 
eand individual individual individual population strategies samuel main loop master process corresponds generation 
generation master selects strategies reproduction fitness 
selected parents produce number clones proportional relative fitness 
clones altered crossover mutation described 
altered strategies assigned workers evaluation process described 
master waits workers return assigned strategies generation complete 
termination condition number genera tions completed level performance achieved 
condition satisfied master process terminates workers 
procedure master initialize population startup worker processes assign strategies workers wait workers complete evaluations termination condition satisfied select alter structures assign strategies workers wait workers complete evaluations terminate worker processes 
master process procedure worker forever wait assignment strategies master test strategy episodes augment rules strategy experience test modified strategy episodes assign fitness strategy return modified evaluated strategies master 
process worker processes worker processes evaluate strategies batches assigned master process described 
worker process evaluates strategy phase process shown 
strategy tested executing episodes problem solving simulated environment 
second lamarckian learning operators applied augment strategy rule set experiences grefenstette 
example suppose general rule rule matches situations history mediocre performance happens fire high performance episode 
occurrence may trigger creation specialization possibly rule conditions new rule closely tuned situation original rule led high performance 
form adaptation entirely local individual strategy appropriate parallelize lamarckian learning including worker process 
augmented strategy reevaluated executing set episodes results recorded fitness strategy 
assigned strategies evaluated worker process notifies master process 
assignment tasks workers parallel algorithm definition speedup time required compute problem size processors 
parallel genetic algorithm definition termed rough speedup finkel definition speedup compare parallel algorithm parallel generate test algorithm possible solutions generated iteration lation size 
efficiency parallel generate test algorithm depends ensuring workers finish assigned tasks nearly time 
master waits workers complete time completion worker completion workers wasted 
algorithm maximum speedup processors bn bn time required master process generate candidate solutions time required evaluate single solution 
speedup approaches approaches 
practice speedup due communication overhead 
degradation occurs evenly divided workers tasks perform 
goal having workers complete simultaneously difficult time required complete evaluation strategy fixed 
example task considered simulated robot performs task pre set time limit expired failure event occurred 
result time required execute episodes varies poorest strategies amount time best strategies longest 
tasks variation evaluation time may depend aspects simulation unrelated fitness strategy 
issue samuel designed run network time shared workstations necessarily devoted samuel processes 
consequently load individual processors may vary substantially execution samuel 
considerations master process attempts balance load workers follows master process maintains dynamic estimate time required evaluation worker generation estimate updated follows bt average time evaluation taken worker generation update rate typi cally 
follows 
essentially recency weighted average best known sequential algorithm 
rough definition best sequential robot learning algorithm established 
procedure assign worker expected completion time task select worker minimum value expected completion time add task input queue worker update expected completion time worker 
greedy assignment evaluation tasks workers completion times 
estimate greedy algorithm shown master performs start generation 
procedure assumed time required worker perform task 
intended effect method load processor changes significantly due user processes master adjust number tasks assigned worker generations accordingly 
case studies evaluate effectiveness parallel version samuel ran sets experiments different learning tasks 
task involved robot learning underlying simulations differed complexity 
gives information parallel algorithm scales complexity simulated environment increases 
tracking task task robot game cat mouse 
tracker robot playing role cat learn keep mouse robot target certain distance called tracking distance shown 
target mouse follows random course speed 
learning robot set sensors range target bearing direction target position heading relative direction target motion 
tracker learn control speed direction 
assumed tracker sensors operate master process includes timeout mechanism worker takes long complete master assumes processor unavailable re assigns worker tasks workers 
mechanism invoked experiments described 
tracking range detection range cat mouse task greater distance target sensors 
object keep target range tracker sensors detected target 
usual behavior target robot random walk occasionally changing speed direction 
target detects tracker target immediately area high speed 
target detect tracker tracker detection radius target 
tracker initially information concerning relationship behavior probability detection target 
particular tracker know detection radius range speeds target assume 
details see grefenstette ramsey 
task broken individual tracking episodes 
episode begins random placement robots lasts time steps tracker detected 
episode critic provides payoff time successfully tracks target 
resource gathering task second task involves gathering resources competitive environment 
robots compete energy giving resources appear fixed intervals random locations 
robot reach resource gets energy 
energy consumed robot moves learning task develop strategies balance gathering resources expenditure energy 
robot set sensors time appearance resources energy level position space presence absence goal energy resource goal position relative robot robot position relative robot robot distance goal 
robot learn control speed direction 
second robot uses fixed strategy move goal 
goal resource competition task learning task broken individual episodes appearance energy resource lasting time steps 
episode critic provides payoff net energy change episode 
interested learning long term strategies evaluation strategies performed sequence episodes energy levels robots reset set episodes 
larger number sensors simulated extended number episodes test strategies evaluation time strategy times longer task task 
experimental design series learning experiments conducted test efficiency parallel version samuel simulations described 
task experi ment parameters learning system population size total episodes evaluation generations second task experiment parameters population size total episodes evaluation generations tasks experiments run processors 
worker process executed separate sun sparcstation workstation workstation supported master process 
results parallel algorithm designed give invariant learn ing results regardless number processors fact identical learning results produced parallel processing runs task 
task genetic algorithm learned strategies improved successful tracking start experiment approximately successful tracking generation 
improvement shown second task due speedup processors task task speedup results artificially small number generations experiments 
illustrates speedup observed learning tasks function number processors 
recall relevant difference task task time required evaluation larger task factor 
referring eq 
factor approximately tasks depends primarily population size 
larger task giving nearly linear speedup shown 
realistic tasks involving complex simulations expect ratio smaller 
parallel genetic algorithm scales tasks 
interesting note speedup shown effective rated speed virtual machine comprising networked workstations approximately mflops mips 
speeds available supercomputers years ago 
summary case studies show parallel genetic learning system successfully exploits computing power loosely coupled network time shared workstations 
genetic algorithm lends naturally master worker decomposition 
greedy algorithm assignment tasks worker processes able deal dynamic variations throughput occur time shared processors 
focus scaling approach directions 
analysis suggests larger population sizes may help reduce effect synchronization penalties master worker algorithm 
larger population sizes may improve learning rate genetic algorithm worth exploring 
second explore asynchronous parallel algorithms eliminate waiting time worker processes 
order learn complex tasks examining approach evolving multiple behaviors simultaneously 
parallel processing approaches expected investigations sophisticated robot learning methods feasible 
cohoon hedge martin richards 
punctuated equilibria parallel genetic algorithm 
proc 
second intl 
conf 
genetic algorithms pp grefenstette ed hillsdale nj erlbaum associates 
davis 
ed 

handbook genetic algorithms 
boston van nostrand reinhold 
finkel 

large grain case studies 
characteristics parallel algorithms 
jamieson gannon douglas eds cambridge ma mit press 
grefenstette 

parallel adaptive algorithms function optimization 
technical report cs computer science department vanderbilt university nashville tn 
grefenstette 

genetic algorithms applications 
encyclopedia computer science technology supplement kent williams 
eds new york marcel dekker 
grefenstette 

lamarckian learning multiagent environments 
proceedings fourth international conference genetic algorithms pp 
san diego ca morgan kaufmann 
grefenstette 

evolution strategies multi agent environments 
adaptive behavior 
grefenstette 

special track genetic algorithms 
ieee expert ieee press october 
grefenstette 

evolutionary algorithms robotics robotics manufacturing trends research education applications 
proc 
fifth international symposium robotics manufacturing nguyen 
eds asme press new york 
grefenstette ramsey 
approach anytime learning 
proceedings ninth international conference machine learning pp sleeman edwards eds san mateo ca morgan kaufmann 
grefenstette ramsey schultz 
learning sequential decision rules simulation models competition 
machine learning 
born 
parallel genetic algorithm function optimizer 
parallel computing 
grefenstette 
parallel genetic algorithm 
proc 
second intl 
conf 
genetic algorithms pp grefenstette ed hillsdale nj erlbaum associates 
schultz 

learning robot behaviors genetic algorithms 
intelligent automation soft computing trends research development applications nguyen 
eds tsi press albuquerque 
schultz grefenstette 

genetic algorithm learn behaviors autonomous vehicles 
proc 
american institute aeronautics astronautics guidance navigation control conference hilton head sc aiaa 
tanese 

parallel genetic algorithms hypercube 
proc 
second intl 
conf 
genetic algorithms pp grefenstette ed hillsdale nj erlbaum associates 
whitley starkweather 
genitor ii distributed genetic algorithm 
exp theor 
artif 
intell 
