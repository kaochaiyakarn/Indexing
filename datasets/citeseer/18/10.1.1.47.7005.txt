adaptive call admission control quality service constraints reinforcement learning solution hui tong timothy brown electrical computer engineering university colorado boulder phone fax colorado edu solve adaptive call admission control problem multimedia networks reinforcement learning rl 
problem requires network revenue maximized simultaneously meeting quality service qos constraints forbid entry certain states certain actions 
show rl provides solution constrained semi markov decision problem able earn significantly higher revenues alternative heuristics 
model algorithms rl require explicit state transition models solve decision problems 
feature important considers large integrated service networks supporting number different service types number states large model optimization algorithms infeasible 
packet level qos constraints addressed conservative aggressive approaches qos constraints considered 
corresponding author brown 
tong brown adaptive call admission control number researchers explored application reinforcement learning rl resource allocation admission control problems telecommunications channel allocation wireless systems network routing admission control telecommunication networks 
focuses applications rl method call admission control cac broadband multimedia communication networks atm networks 
broadband networks carry heterogeneous traffic types simultaneously channels 
channels connection oriented packet customers send varying rates time 
calls arrive depart time network choose accept reject connection requests 
network provides quality service qos guarantees packet level packet loss probabilities call level call blocking probabilities 
return network collects revenue payoff customers calls accepts network 
cac policy accepting rejecting call requests 
network wants find cac policy maximizes long term revenue utility meets qos constraints 
maximizing revenue meeting qos constraints suggests constrained semi markov decision process smdp 
rapid growth number states problem complexity led rl approaches problem 
rl applications ignored qos criteria 
draws closely related fundamental problem constrained optimization semi markov decision processes studied researchers control theory operation research artificial intelligence communities see 
admission control divided categories ffl static cac admission controller decide source combinations accepted network meet qos constraints 
steady state behavior sources network 
connection request accepted sufficient resources available establish call required qos maintain agreed qos existing calls 
meeting qos requires decision function decides adding new call violate qos guarantees 
diverse nature voice video data traffic complex underlying statistics finding qos decision functions subject intense research 
results emphasized robust efficient qos decision functions require line adaptive methods 
tong brown adaptive call admission control ffl dynamic cac set calls meet qos requirements new call rejected 
reasons rejecting connection 
example circumstances rejection valuable call acceptable qos constraints room accepting valuable call 
network utility increased 
hand calls may accepted network instantaneous qos violated averaged states service quality met 
described precisely sections 
prior works simultaneously considers problems provides methods scale larger problems combined cac routing networks 
model algorithms linear programming rl algorithm stochastic iterative algorithm require priori knowledge state transition probabilities associated underlying markov chain solve real network problems large state spaces handled model algorithms automatically adapt real traffic conditions 
section describes problem model study 
section formulates cac problem smdp gives rl algorithm solves smdp 
section considers qos constraints details 
packet level call level qos constraints addressed conservative aggressive approaches qos constraints considered 
results demonstrated simple network simulation section 
combined cac network routing studied section 
section concludes 
problem description section describes cac problem model 
emphasize main features problem networking issues queueing essential development simplified eliminated 
emphasized aspects readily incorporated back problem example state augmentation include state information buffer 
substantial literature cac link networks 
single link case significant basic building block larger networks shown network processes decomposed single link processes 
focus single link network 
tong brown adaptive call admission control users attempt access link time network immediately chooses accept reject call 
accepted call generates traffic terms bandwidth function time 
time call terminates departs network 
service calls carried completion preemption 
call accepted network receives immediate revenue payment 
network measures qos metrics transmission delays packet loss ratios call rejection probabilities service class compares guarantees calls 
problem described call arrival traffic departure processes revenue payments qos metrics qos constraints network model 
concrete describe choices examples 
calls divided discrete classes indexed calls generated independent poisson arrival processes arrival rate exponential holding times mean holding time 
model telephone traffic shown telnet ftp session arrivals modeled poisson processes :10.1.1.144.7995
call bandwidth process traffic generating packets rate rate zero mean holding times traffic model easily generate long range dependence self similar traffic fits accurately measured network traffic need pareto distributed periods 
shown long call arrivals departures memoryless markov rl converge optimal control policy 
contrasts considers non markov call arrivals 
class call admitted system collects fixed amount revenue interpreted average reward carrying class call 
network element connects network fixed bandwidth buffer 
total bandwidth accepted calls varies time 
important packet level qos metric fraction time total bandwidth exceeds network bandwidth causes packet losses overload probability general packets violate qos constraints delay delay jitter considered lost 
reason choose packet level qos guarantee upper limit overload probability denote capacity constraint 
previous works call constant bandwidth time effect qos predictable 
variable rate traffic safely approximated assuming transmits maximum peak rate 
peak rate allocation utilizes network cases orders magnitude tong brown adaptive call admission control possible 
stochastic traffic rates real traffic desire high network utilization revenue resulting potential qos violations characterize problem study 
important qos metric call level blocking probability 
offered traffic class cut back meet capacity constraint important fairly denote fairness constraint 
fairness defined number different ways intuitive notion calls class entitled admission probability equivalently rejection probability 
precisely defined section 
ultimately goal find policy system state chooses correct control action maximize revenue subject qos constraints 
formally consider problem finding cac policy maximizes subject number qos constraints real numbers characterize qos constraints characterizes average network revenue policy characterize qos policy 
consider objectives form lim gamma gamma reward functions associated revenue qos average sojourn times state action indexes decision epoch decisions points time referred decision epochs 
semi markov decision processes reinforcement learning sections develop components problem finish justifying particular method suitable cac problem 
tong brown adaptive call admission control states actions section develops state action model reduced state space representation suitable cac problem 
cac problem formulated smdp state transitions control selections take place discrete times time transition continuous random variable 
point time system particular configuration defined number type ongoing calls number calls state type 
random times event occur event occur time instant indicating class call arrival call termination call turned call turned event configuration event determine state system 
class system dimensional vector 
number possible choices general small compare size state space dominated configuration part state 
shown nearly complete decomposability approximation reduce state descriptor form stands call arrival departure event class configuration denote elements equal zero ith element value unity 
states associated class call arrival states associated class call departure gammae reduction ignoring number calls state events call turned gives accuracy cac problem 
reasons simplification 
moment call turns decision point admission controller action needs taken 
second intuitively clear simplification approximation process describing number calls state reaches equilibrium change number calls progress due call arrival departure 
making call admission decision number calls class progress important number calls class state quantities oscillate rapidly relative call arrivals departures 
note affect packet loss rate 
assume equilibrium reached corresponds fixed assume source independence probability configuration tong brown adaptive call admission control binomial distribution gamma gammay fraction time class call spends state gamma gamma gamma 
total packet arrival rate packet loss rate gamma average overload probability class fixed delta delta delta gamma fy deltag indicator function 
related packet level qos average class packet loss probability delta delta delta gamma average overload probability average packet loss probability depend distribution times plays essential role 
require call holding times exponentially distributed 
possible incorporate call holding times smdp formulation require elapsed holding time call progress part state descriptor expand state space dramatically difficult implement 
alternative implement policy depends number calls progress ignores elapsed holding time information 
policy embedded decision chain markov anymore 
easier simulate choose average overload probability capacity constraint average packet loss probability treated similar way 
capacity constraints associated conservative set fx ig set long run average packet level qos constraints satisfied go state period time capacity constraint violated stay forever 
set uniquely determines state space tong brown adaptive call admission control gammae possible consider aggressive approach packet level qos constraints averages allowable configurations ca total system time portion system spends set allowable configurations lim ca lim ca ca equal target obviously unique possible general conservative 
occasions emphasis dependence write 
summary choose state descriptor number class calls progress stands new class call arrival gammae class call departure event occurs learner choose action feasible event 
action set reject new call arrival 
call terminations decision points action needs taken 
symbolically states gamma action due call 
note actions available state general depend example adding new call state violate capacity constraint action set state constrained 
subsequent random time event occurs cycle repeats 
revenue structure cac task learner determine policy accepting calls maximizes long run average revenue infinite horizon meeting qos requirements 
call admission control system constitutes finite state space due capacity constraint finite action space gamma semi markov decision process 
tong brown adaptive call admission control transition probabilities section considers probability model concludes large state spaces classical approaches transition probability model feasible 
theoretically state transition probability probability going state action state derived depends configuration call arrival rates 
exact system models infeasible important reasons 
call arrival rates may depend call class configuration 
routing added problem arrival rates link path depend routing policies 
call arrival rate class may constant general 
second network reasonable size state space extremely large 
example node link network service types states 
possible explicitly list states 
fixing model computing optimal policy means robust actual traffic condition departs assumed model 
reasons clear practical system large state space difficult impossible determine exact transition model markov chain performing model algorithm compute optimal policy 
main motivation study choose model free solutions rl measurements simulations connection flows network automatically adapt real traffic conditions 
learning section develops rl methodology unconstrained maximization revenue 
qos constraints considered section 
learn optimal policy watkins learning algorithm 
optimal values policy defined arg max optimal 
particular implies procedures 
call arrives value accepting call value rejecting call determined 
rejection higher value drop call 
acceptance higher value accept call 
tong brown adaptive call admission control action value exists call departure 
learn update value function follows transition state action time ss gamma fl fl gammaff ss max fl stepsize learning rate integer variable index successive updates ff chosen sufficiently close 
initial values arbitrary 
learning robbins monro stochastic approximation method solves called bellman optimality equation associated decision process 
clear learning require explicit state transition probability models fp proposition suppose fl fl state action pair updated infinite number times 
converges probability proof 
see 
simplified learning process practical issue concerning implementation learning 
discussions learning needs executed state transition including transition caused call departure feasible action set gamma gamma 
action states associated call departures necessary learn optimal values states induce optimal policy states 
possible avoid updates values departure states get optimal policy 
reduce amount computation storage values significantly state space halved drop call departure states 
note interesting states decisions need associated call arrivals fs decision point jumps arrival arrival interarrival period may tong brown adaptive call admission control contain zero departures 
arrival cases departure adjacent arrivals chapman kolmogorov equations transition probability actual decision process gamma gamma number transition steps intermediate state corresponds call departure 
shown optimal policy obtained doing learning states associated call arrivals 
result intuitive call departures random disturbances affect state transitions 
complicates intractable transition model smdp learning depend explicit model asymptotic convergence optimal policy follows 
exploration order learning perform potentially important state action pairs explored 
specifically convergence theorem learning requires state action pairs tried infinitely 
section develops exploration strategy suitable cac problem 
common way try state action pairs rl small probability ffl random action action recommended rl chosen decision point training called ffl exploration 
cac problem considered exploration states visited probabilities orders higher states experiments shown ffl exploration help situation 
training states visited times states visited times resulting value functions far converging optimal policy expected reasonable time 
see call arrival process modeled truncation independent queues system 
truncated system system configurations capacity constraint violated eliminated 
stationary distribution system assuming greedy policy policy accepts new call capacity constraint tong brown adaptive call admission control violated adding new call ae ae delta delta delta ae normalization constant ae ae delta delta delta ae 
ae allowed set configurations truncated system 
state action deterministically define configuration state event part arrival action needs taken occurs independent probability determined due memoryless assumption stationary distribution states depends 
example consider experimental parameters shown table section simplify calculation allowable configuration set truncated system peak rate allocation theta theta 
visited state visited state theta gamma orders difference stationary distribution state action pairs small system 
overcome difficulty huge difference stationary distribution controlled exploration scheme state training feasible actions probability ffl action chosen leads visited configuration 
ffl heuristic effectively reduces difference number visits states significantly speeds convergence value functions 
note terms learning formula action chosen exploration scheme action chosen current value 
termed policy method section 
function approximation vs lookup tables learning deals effectively curse modeling explicit state transition model needed simulator 
major difficulty smdp problems curse dimensionality exponential computational explosion problem dimension 
tong brown adaptive call admission control treatment assumed problem state space kept small lookup table 
lookup table representation means separate variable kept memory state action pair 
clearly number state action pairs large lookup table representation infeasible compact representation represented function smaller set parameters function approximator necessary 
choose approximation architecture correspond state aggregation 
consider partition state space disjoint subsets sm introduce parameter vector oe mth component meant approximate value function states sm action words dealing piecewise constant approximation oe oe sm value small lookup table aggregated problem 
case shown learning converges optimal policy aggregated problem 
function approximators may perform practice convergence result state aggregation case wish avoid 
cac state aggregation interpreted feature architecture assign common value oe states share common feature vector 
feature vectors summarize heuristic sense important characteristics state 
example feature vector may involve call class value indicator specifies load call class high medium low system specifying precisely number ongoing calls class described section 
state space greatly reduced lookup table 
summary section formulates cac problem smdp justify learning approach solving cac problem 
section develops method incorporating constraints framework 
tong brown adaptive call admission control constraints restrict maximization policies violate qos guarantees 
general smdp problems constrained optimal policy randomized stationary policy randomizes states problem 
model linear programming algorithms employed derive policy impractical cac number states large 
needed states usually smaller total number states non randomized stationary policy learned rl approximation constrained optimal policy 
mentioned earlier qos constraints implemented constraining available actions state constrained smdp problem reformulated unconstrained problem previous results apply 
section examine issue detail 
consider important classes qos constraints cac integrated service network 
state dependent constraints past dependent constraints 
conservative capacity constraint example state dependent constraints 
state dependent constraints qos intrinsic state 
overload probability function solely number calls progress current state cf 

past dependent constraints depend statistics past history 
example fairness criterion 
fairness depends statistics rejection ratios past history 
address constraints separately 
capacity constraint simplicity consider total packet overflow probability upper bound conservative approach means set fx cf delta delta delta gamma stated conservative capacity constraint intrinsic property state depends current state 
allows collect qos statistics state treat principled way computing confidence intervals estimates 
current state action uniquely determine configuration projected overload probability state determined forecast impact tong brown adaptive call admission control need evaluate expected overload probability greater constraint action cause action eliminated feasible action set 
cac adding new call violate capacity constraint feasible action reject new call request 
considering aggressive capacity constraint need determine set allowable configurations defined implicitly uniquely lim ca delta total time system spends ca 
note distribution depends control policy 
generalization case different service types different packet level qos requirements easily 
stated serves possible usually conservative 
construct aggressive set gradually decrease find series sets corresponding changing clearly size non increasing decrease contain 
practice value learned policy aggressive overload probability sufficiently close constraint search choose set aggressive capacity constraint 
essence try find corresponding value conservative threshold aggressive threshold construct conservative approach 
way aggressive capacity constraint remains state dependent constraint conservative capacity constraint implement constraint constraining action set state 
determined way may aggressive term revenue maximization loss optimality expected small 
fairness constraint measured rejection ratio class nth call arrival nth decision 
arbitrarily constraints may able find feasible policy 
fairness constraint involves comparisons rejection ratios types calls 
constraints tong brown adaptive call admission control associated fairness formulated max ii gamma min ii maximum allowed rejection ratio discrepancy 
feasible policy exists rejecting call types 
aggressive fairness constraint formulated lim gamma delta gamma inter transition duration state action formulation constrained smdp problem capacity constraint implemented constraining feasible action set state described preceding subsection 
deal fairness constraint lagrange multiplier framework studied 
fairness constraint past dependent constraint vector depends rejection ratios past history fit framework need include history information state descriptor 
new state descriptor form req rej req resp 
rej denotes total number call requests resp 
rejections class current call arrival time interval current call request original state descriptor 
obtain markov chain doing expansion state space enlarged significantly 
specifically due inclusion req rej state space infinite resort form function approximation solve smdp problem 
state aggregation approximation architecture quantizing rejection ratios 
terms lagrange multiplier consider unconstrained optimization parametrized reward gamma original reward function associated revenue tong brown adaptive call admission control cost function associated constraint delta equals numerator 
dependence problem due fact learning model free algorithm 
exists non randomized policy solves bellman optimality equation associated reward function mean time achieves equality shows constrained optimal policy 
case optimal policy exist shown constrained optimality achieved randomization state non randomized policies differ resp 
slightly resp 
overshooting clearly case non randomized constrained optimal policy exist best non randomized policy loss optimality minimal 
reasons avoid complications randomization concentrate non randomized policies 
simulation results experiments model 
total bandwidth normalized unit traffic unit time 
target overflow probability gamma source types considered properties shown table 
fairness constraint average rejection ratio discrepancy service types differ 
noted call holding times exponential arrivals poisson 
periods exponential distributions pareto distributions hyperbolic exponents shown table pr period length gamma concentrate conservative approach capacity constraint 
exploration employed ensure potentially important state action pairs tried naturally enables collect statistics estimate qos state action pairs 
number times state action pair visited increases estimated service quality accurate confidence gradually eliminate state action pairs tong brown adaptive call admission control table experimental parameters source type parameter ii rate mean period mean period hyperbolic exponent call arrival rate call holding time immediate payoff violate qos requirements 
consequence value function updated gradually correct subset state action space sense qos requirements met action subspace 
stated section capacity constraint eliminates state action pairs violate overload probability upper limit 
experiments simple way eliminate state action pairs confidence 
target overflow probability gamma total number visits configuration counted number time steps simulation number overflows gamma gamma gamma conclude acceptable 
thresholds provide close approximations confidence intervals 
sophisticated way estimate proposed artificial neural networks nns trained maximum likelihood principle nn estimates extrapolate gamma simulations discount factor ff chosen gamma learning rate fl exploration probability ffl 
initial values rl artificially set learning started greedy policy 
training completed apply test data set compare policy obtained rl alternative heuristic policies 
final qos measurements obtained rl training learning qos testing different policies 
test rl policies new call arrival algorithm determines accepting call violate qos 
call rejected action chosen arg max accept 
qos constraint cases peak rate allocation statistical multiplexing function learned line denoted qos learned statistical multiplexing function priori denoted qos 
examine different cases rl qos tong brown adaptive call admission control rl qos learned rl peak rate heuristic accepts calls valuable class type qos greedy qos greedy peak rate 
results shown fig 
clear simultaneous learning qos learning converges correctly rl policy obtained giving qos priori doing standard qlearning 
see significant gains due statistical multiplexing vs vs 
gains due rl vs vs 
yield increase revenue conservative peak rate allocation example 
clear rl policies perform better heuristic policies 
fig 
shows rejection ratios different policies 
repeat experiments pareto distributed periods parameters listed table 
results shown figs 

clearly different distributions yield similar gains rl 
consider aggressive approach capacity constraint 
simulation value corresponds aggressive capacity constraint gamma acceptance regions aggressive conservative approaches shown fig 

aggressive acceptance region larger conservative 
number type ii users starts due insufficient measurement data confidence level region 
comparing figs 
figs 
see aggressive approach earns significantly revenue conservative approach greedy policy rl policy note peak rate allocation earns total amount rewards un normalized approaches 
fig 
values initialize rl policy starts greedy policy value set determined rl start learn final policy 
examples performance improvement due rl significant improvement due statistical multiplexing 
fairness constraint imposed case rejection ratios types calls differ significantly 
fairness constraint requires rejection ratios differ average 
test rl fairness constraint set reward parameters type call type ii call keep parameters table unchanged 
stated feature state aggregation cope difficulty large state space caused fairness constraint 
specifically learn feature tong brown adaptive call admission control delta denotes quantization 
experiment experienced rejection ratio discrepancy quantized levels quantized levels corresponding approximate average inter arrival time 
aggregated experiment cases complicated possible aggregate simpler feature 
learned rl policy compared greedy policy fairness constraint accepts calls long fairness constraint met fairness constraint violated accepts calls class experiencing highest rejection ratio 
results shown figs 

fairness strong constraint possible policies gain due rl reduces expected 
figs 
see converge quickly 
fact rl curves figures show oscillations connected learning rates fl 
specifically order learning converge fl satisfy 
simulations small constant learning rate fl condition met 
reason adhered typically prior knowledge fl decreased learning rate small algorithm may making noticeable progress training process long 
small constant learning rate due fact learning stochastic iterative algorithm sample noise involved iteration oscillation performance results 
combining cac network routing general issues cac routing closely related communication network 
combined cac routing formulated smdp 
exact characterization network state require specification number calls progress class possible route network 
detailed specification state intractable computation 
assuming statistical independence links network form decompositions network routing process single link processes usually employed 
preceding results single link admission control link state independence approximation propose decomposition rule allows decentralized training decision making combined cac routing network tries maximize network revenue 
denote predefined routes network action space system tong brown adaptive call admission control gamma action due call departures reject route new call route rg 
link node node keeps separate function ij ij ij link state variable 
new call type routed route contains link immediate reward associated link equal ij satisfying ij example ij jrj jrj number links route learning performed link similarly single link case 
arrival update value link arrival associated link 
new type call originated node destined node decision node way set od set routes carry call violating qos constraints ii define net gain accepting new call routing decision theta ij ij gamma ij ij od admission routing decision arg max od decision making reject call 
route call route approach network state simplified link state ij link action space link simplified reject 
important doing link functions distinguish single link calls multi link calls avoid accepting multi link calls block single link calls may bring amount revenue network resources 
preliminary simulation results node link network supporting call classes show proposed approach earns network revenue heuristic routing policy theta training time steps 
tong brown adaptive call admission control formulates cac problem constrained smdp provides model free simulation measurement rl algorithm computing optimal control policy 
incorporate important classes qos constraints state dependent past dependent constraints rl solution maximize network revenue 
formulation quite general applied capacity fairness constraints 
approach experimented single link problem showed significant improvement simple examples 
extension approach combining cac network routing proposed 
includes study combined cac routing studying function approximators neural networks approximate value functions 
altman shwartz adaptive control constrained markov chains ieee trans 
auto 
control vol 
pp april 
bertsekas gallager data networks nd ed prentice hall 
bertsekas tsitsiklis neural dynamic programming athena scientific 
ross time average optimal constrained semi markov decision processes adv 
appl 
prob vol 
pp 

boyan littman packet routing dynamically changing networks reinforcement learning approach cowan ed 
advances nips morgan kauffman sf pp 

brown adaptive access control applied ethernet data advances nips ed 
mozer mit press pp 

brown adaptive statistical multiplexing broadband communications invited tutorial fifth ifip workshop performance modeling evaluation atm networks july 
appear computer networks isdn systems 
nordstrom control self similar atm call traffic reinforcement learning applications neural networks telecommunications ed 
alspector lea publishers 
mason call admission routing multi service loss networks ieee trans 
commun vol 
pp 
april 
atm network resource management mcgraw hill 
constrained semi markov decision processes average reward zor math 
methods oper 
res vol 
pp 

gabor multi criteria reinforcement learning appear international conference machine learning madison wi july 
atm communications network control neural networks ieee trans 
neural networks vol 
pp 

krishnan markov decision algorithms dynamic routing ieee commun 
mag pp 
oct 
tong brown adaptive call admission control tsitsiklis neuro dynamic approach admission control atm networks single single link case icassp 
schulte tsitsiklis reinforcement learning call admission control routing integrated service networks jordan ed 
advances nips mit press 
mitra wang robust dynamic admission control unified cell call qos statistical multiplexers ieee vol 
pp 

nie haykin learning dynamic channel assignment technique mobile communication systems appear ieee trans 
vehicular technology 
paxson floyd wide area traffic failure poisson modeling proc 
sigcomm london uk pp 

singh bertsekas reinforcement learning dynamic channel allocation cellular telephone systems advances nips ed 
mozer mit press pp 

sutton barto reinforcement learning mit press 
tong brown estimating loss rates integrated services network neural networks accepted ieee global communications conference sydney australia nov 
tong adaptive admission control broadband communications ph thesis university colorado boulder summer 
verma pankaj leon garcia call admission resource reservation guaranteed quality service services internet computer commun vol 
pp 
apr 
watkins dayan learning machine learning vol 
pp 

tong brown adaptive call admission control training time steps comparison different policies exponential rl qos rl qos learned rl peak rate greedy type greedy qos greedy peak rate comparison total rewards rl learning qos capacity constraint rl qos measurements rl peak rate greedy policies peak rate allocation normalized greedy total reward exponential 
greedy peak rate rl peak rate greedy qos rl qos learned exponential comparison rejection ratios policies learned fig 

training time steps comparison different policies pareto rl qos learned greedy qos greedy peak rate comparison total rewards rl learning qos capacity constraint greedy policy peak rate allocation normalized greedy total reward pareto 
rejection rates greedy peak rate greedy qos rl qos learned pareto comparison rejection ratios policies learned fig 

tong brown adaptive call admission control training time steps comparison different policies exponential rl qos learned greedy qos greedy peak rate comparison total rewards rl learning qos capacity constraint greedy policy peak rate allocation normalized greedy total reward exponential aggressive 
greedy peak rate greedy qos rl qos learned exponential comparison rejection ratios policies learned fig 
number users class comparison accept regions aggressive conservative comparison acceptance regions 
tong brown adaptive call admission control training time steps comparison different policies exponential rl qos learned greedy qos comparison total rewards obtained rl policy greedy policy capacity constraint fairness constraint imposed normalized greedy total reward exponential 
greedy qos rl qos learned exponential comparison rejection ratios capacity constraint fairness constraint policies learned fig 
