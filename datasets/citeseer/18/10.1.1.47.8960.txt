ieee control systems magazine pp 
robot hand eye coordination stereo vision gregory hager wen chung chang morse article describes theory implementation system positions robot manipulator visual information cameras 
system simultaneously tracks robot effector visual features define goal positions 
error signal visual distance effector target defined control law moves robot drive error zero derived 
control law integrated system performs tracking stereo control single processor special purpose hardware real time rates 
experiments system shown controller robust calibration error cameras moved centimeters rotated degrees system running adverse effects 
past years sensor feedback robotic systems active area research 
development visual feedback mechanisms continually lagged areas sensor feedback research 
vision systems characteristically viewed computationally expensive error prone difficult calibrate 
largely artifact vision measure absolute position robot frame 
order position estimates accurate vision system extremely calibrated times 
describes approach stereo visual servoing vision measure error 
error defined visual distance robot manipulator pre defined position visual coordinates 
error computed continuously visual tracking 
approach number interesting features ffl longer explicit computation absolute position system dependent calibration robust calibration error 
approach practical free standing cameras cameras rigidly fixed respect robot 
practice necessary perform accurate calibration system 
version article ieee international conference systems man cybernetics 
greg hager department computer science yale university box yale station new haven ct 
change morse department electrical engineering yale university box new haven ct 
chang morse supported part nsf ecs afosr 
hager supported arpa national science foundation iri ddm funds provided yale university 
vision processing feedback control left visual servoing system consisting cameras pan tilt heads connected vision controller robot arm 
middle right diagrams illustrate positioning reducing visual disparity zero 
ffl stereo possible position dimensions minimal information 
furthermore long system stable final positioning accuracy dependent physical positions cameras irrespective system calibration errors 
ffl target positions manipulator defined visual tracking mechanism 
tracking simplifies vision problem task specifications immune changes position attitude target station 
furthermore visual feedback implemented servo loop possible combine visually guided motion position force feedback 
feedback modes extremely useful performing constrained motion tasks 
appears adaptive feedback controllers tune calibration system runs developed 
system quite robust calibration errors adaptive calibration tuning perform real settings 
remainder article structured follows 
section discusses stereo positioning detail reviews previous research visual servoing 
subsequent section formalize visual control problem solutions discuss robustness result 
describe experimental results obtained system implementing visual control algorithms 
close discussion open research problems area 
overview approach depicts generic vision servoing architecture 
major components video cameras free standing pan tilt heads robot arm computers perform low level control operations interface related functions 
classical approach stereo positioning assumes cameras calibrated robot coordinate system 
positions observed features computed stereo triangulation robot estimated position 
system shown mapping robot coordinates images includes camera intrinsic parameters image center image scale factors distortion coefficients focal length extrinsic positional parameters cameras 
includes parameters describing kinematics pan tilt heads kinematics robot arm 
large number parameters modeling errors mechanical careful intensive calibration process produce imprecise estimate hand eye relationship 
cases stereo estimates point positions accurate positioning capabilities robot 
systems fixed cameras eliminating pan tilt inaccuracies cameras mounted arm eliminating kinematics robot arm achieve higher accuracy 
configurations disadvantage limit system working configurations manipulator field view obscured cameras 
main point visual feedback possible achieve extremely accurate positioning servo system relative observed target despite calibration error 
figures illustrate basic principle translational positioning 
cameras observe distances point gripper corner box 
refer angles target goal disparity disparity short 
fundamental invariant exploit zero disparity manipulator goal images means point space shown 
statement true independent locations cameras long coincident goal cameras collinear 
related visual servoing active area research years result large variety experimental systems built see extensive review collection articles 
literature zheng describe visual servoing system window feature tracking monocular image stream 
allen describe stereo motion system grasping toy train stationary cameras 
rizzi koditschek describe stereo vision juggling system anderson describes stereo vision ping pong player 
systems directly observe robot effector observe compute goal position goal configuration system 
moving computed position open loop respect vision system relies calibration 
weiss proposes system utilizing visual feedback controlling manipulator simultaneously adaptive control methods perform online calibration 
authors idea visual feedback 
authors address problem servoing camera maintain constant position relative known object single camera 
describe monocular hand eye system planar positioning image feedback 
authors describe monocular visual servoing systems type adaptivity compensate unknown system parameters refine system calibration 
describe algorithms performing stereo vision positioning 
principle differences approach results cameras mounted robot effector extremely simple binary image processing model camera system assumes cameras aligned perpendicular stereo baseline 
addition configuration system impossible observe note differs classical definition disparity difference location single point images 
robot effector objects held define visual errors observing robot desired goal position 
application system depend knowing exact hand eye calibration 
stereo visual servoing system free standing cameras described cipolla 
approach uses affine approximation inverse perspective transformation compute approximate cartesian positions effector goal position 
compute control signals difference positions 
article error defined image coordinates camera projective mapping approximated 
visual feedback controller noted mapping robot motions visual motions includes robot kinematics hand eye coordinate transformation camera perspective map 
model robot cartesian positioning device negligible dynamics cast problem visual feedback control generating cartesian velocities image observations 
remainder article vectors vector functions denoted lower case letters matrices matrix functions denoted upper case letters 
vectors column vectors 
write transpose denotation indicates unit vector 
consider cameras indices simplify presentation cameras assumed unit focal length 
employ nomenclature robot base coordinate system 
position camera relative coordinate axes camera relative rotation matrix rows cartesian coordinates relative observable point robot 
robot control input 
stereo image coordinates 
mapping cartesian coordinates stereo image coordinates 
camera coordinate directions established follows points right points downward camera imaging plane theta points outward camera optical axis 
camera position defined optical center lens system 
term camera calibration parameters denotes collection baseline camera system line segment field view camera open cone defined camera center rectangle size camera image located unit optical axis 
workspace cameras intersection fields view 
observation point stereo perspective projection gamma delta gamma delta gamma delta gamma delta gamma delta gamma delta gamma delta gamma delta note stereo projection nonlinear mapping generates outputs inputs 
assume point cartesian setpoint observable 
control problem consider develop regulator move stereo camera observations 
denote desired setpoint value define error gamma error integrating subsystem control synthesis task choose function stabilize system jacobian defining gamma delta gamma gammac delta gamma gammac delta gamma gammac delta gamma gammac delta assuming nonsingular position integral pi control law compute gamma gamma positive gain constants 
empirically controller form provide desired tracking provided values chosen appropriately 
square difficult prove asymptotic stability system 
furthermore computationally expensive compute left inverse 
simplify problem introduce projection system outputs 
possible choices mapping depending geometry camera system 
choices discussed article 
oe oe define error oe oe gamma oe error integrating subsystem oe oe control synthesis task choose function oe oe stabilize system oe oe oe jacobian composition assuming nonsingular computed gammaj gamma oe oe see substitution oe gammaj gamma oe oe implies oe gammak oe gamma oe second order system asymptotically stable 
furthermore desired tracking achieved camera calibration parameters approximately correct provided approximation errors destabilize system 
note conceptually straightforward include forward kinematics robot stereo projective map system state joint positions servo system control signal joint velocity 
minor changes controller structure 
possible include rotations robot formulation stereo projection 
point axis rotation provides additional degrees freedom motion 
interested reader may wish consult formulation system stereo cameras mounted robot arm 
estimation far assumed value robot position known 
information directly accessible estimated 
compute estimate rewriting form gamma gamma gamma gamma gamma gamma gamma gamma assuming rank initial estimate computed solving yielding gamma estimate updated combination prediction correction gamma gamma positive gain constant tuned noise characteristics system 
resulting estimated values appropriate 
defining gamma follows expressions gammak components go zero exponentially fast rank 
rank structure discussed 
reducing system dimensionality mapping introduced reduce dimensionality system 
generally accepted choices define gamma respectively 
approach leads commonly referred position control 
name suggests error term computed robot position space 
major advantage approach system calibration correct setpoints correspond positions global coordinate system 
furthermore point topoint trajectories straight lines cartesian space 
error computation requires left inverse computations robot control point setpoint relatively expensive compute 
calibration errors distort geometry inverse projection practice trajectories curves computed coordinates correspond global coordinates 
second approach choosing analysis geometry stereo projection 
particularly simple case arises cameras parallel coordinate systems axis parallel stereo baseline 
easy show identical configuration components deleted projection equations 
result system jacobian matrix estimate square invertible 
approach cameras deviate configuration specified provided deviation extremely large 
stereo camera systems geometry 
possible define function camera calibration parameters computes independent values stereo projection making assumptions geometry system 
cost transformation comparable computing position control 
system stability order vision control stable jacobian projective map rank 
inspection see looses rank globally configuration physically attainable 
looses rank time collinear applications configuration physically attainable field view cameras 
easy show rows identical rows modulo scale factor 
follows looses rank precisely situations visual workspace include optical center camera nonsingular entire workspace 
nonsingular estimated directly 
follows control systems discussed stable motions remain workspace 
particular proportional control trajectory system image straight line initial point setpoint 
motions originate field view move point field view remain entirely field view 
proportional control systems described asymptotically stable visual workspace include center camera 
system stability workspace includes visual singularities remains open problem 
system stability depends accuracy system calibration sampling rate time delay implementation 
issues discussed 
calibration sensitivity designing visual control system described positioning observed target performed accuracy depends physical configuration system accuracy setpoints detected images 
follows directly system stability presence integrator controller 
practice stability insensitive errors camera calibration 
camera intrinsic parameters including focal length image scale image center determined offline high accuracy fixed life system 
introduce substantial calibration error system 
examine effect errors estimates camera position orientation stability consider system camera coordinate frames aligned base coordinate system baseline parallel camera axis 
configuration motion direction independent motion plane 
simplify problem discarding component consider planar version control problem 
follows perspective projection function restricted gamma plane planar versions corresponding quantities defined 
note square matrices case 
control problem independent absolute location base coordinate system 
constraints stated remaining translation parameter affect stability length camera baseline 
denote length remaining degree rotational freedom rotation plane 
denote orientation camera ff convention ff indicates optical axis perpendicular baseline 
gather parameters vector ff ff substituting estimated value jacobian matrix obtain gammaj gamma gamma gammau gamma explicitly included calibration parameters argument quantities 
denote estimated calibration parameters controller 
closed loop system gammau gamma gammam simplification expression symbolic mathematics package shows expressed form lm contain estimated camera separation acts scaling factor affect asymptotic stability continuous time system 
examine effect rotation errors fix ff ff vary orientation physical cameras constraint gammaff ff fi positive values fi correspond raised areas indicate regions stability physical cameras point outward left inward right relative estimated calibration 
cameras located lower border gamma pointing cameras inward negative values correspond pointing cameras outward 
plots region stability pure proportional control rotations ff gamma degrees ff degrees 
rotation outward dramatically reduce region stability rotation inward quickly introduces unstable points camera workspace 
results verified analytically 
analysis symbolic mathematics package leads surprisingly simple result camera rotations inward fi define region stability circle equation gamma cot fi csc fi rotating cameras outward fi defines region bounded lines tan gammafi tan fi gamma results suggest pointing physical cameras inward relative estimated positions tend destabilize system quickly pointing outward 
experimental section contains empirical observations effect 
choosing setpoints controlling trajectory setpoints control algorithm chosen tracking visual targets 
example suppose goal place manipulator located position locating camera images corresponds fixing visual coordinates servoing manipulator control laws described move effector robot visual control system robot system cameras coordinate transformation controller robot estimator block diagram implemented system indicating portions execute robot controller execute workstation performing tracking visual control 
mapping deletes fourth component observation vector 
vector represents robot joint angles 
controlled motions point point defined visual points 
observable points world define define setpoint linear combination observed features gamma parameterizing desired velocity curve define time varying trajectory controlled pointto point motion 
minor modifications control algorithms described track trajectory 
important note trajectory straight line image space 
cartesian trajectory robot curved due nonlinearity perspective mapping 
performing accurate positioning point space relative observed features difficult performing positioning observed features 
perspective projection preserve distances images simple ratios distances 
small motions perspective projection approximated affine projection 
affine projection preserves collinearity ratios distances notation defined controlling system setpoint places point approximately kp gamma units line space containing companion provides detail ways performing relative positioning perspective images 
experiments visual servoing system consists zebra zero robot arm pc controller zebra pan tilt head directed perceptions pan tilt head sony xc cameras mm lenses imaging technologies attached sun sparc ii computer vme adapter 
workstation pc connected ethernet link 
image processing visual control calculations performed sun workstation 
cartesian velocities sent pc converts coordinated joint motions hz 
cameras placed implemented system stages visually guided motion trajectory seen stereo cameras 
left system touching corners floppy disks right system attaining position placing disk directly 
right image shows features tracked 
visual setpoints shown circled 
approximately cm target axis cm apart axis 
oriented point back axis robot 
rely internal robot feedback joint encoders stabilize system robot controller uses integral control necessary integrator visual controller 
experiments described pure proportional control 
shows block diagram combined system 
noted feedback gain set 
cameras nearly parallel remove fourth row obtain square matrices discussed previously 
camera workspace contain visual singularities little noise system robot position estimated directly 
system calibration performed tracking robot series known motions performing optimization determine system calibration parameters relative robot base coordinates 
custom tracking system written provides visual input controller 
system fully described provides fast edge detection memory mapped framebuffer 
addition supports simultaneous tracking multiple edge segments enforce constraints segments 
experiments described tracking corners formed intersection line segments 
segment length pixels search area segment sigma pixels 
entire visual control system including tracking control signal computation runs rate approximately hz 
hz robot tracked velocities covering pixels sec mm lens converts maximum velocities approximately cm sec perpendicular camera optical axis cm 
images experimental setup shown 
left image shows system goal configuration touching corners inch floppy disks 
right image shows robot reaching goal position disk widths inches target disk 
disks convenient testing tool narrow width mm simple track accurately corners provide defined setpoints 
system tested ways 
set tests robot started selected points workspace point 
feature positions joint positions robot measured inspection 
second set tests control robot square trajectory defined sides top target disk 
robot manipulator begins moving left corner disk touch right corner target disk 
moves position left corner disk inches right corner target disk 
robot position gain mm mm robot position gain mm mm left sequence positions robot moves setpoint 
time dot milliseconds 
right expanded view behavior setpoint 
moves right corner disk station inches left corner target disk 
descends touch right corner disk left corner target disk 
complete procedure reversed entire cycle executed repeatedly 
experiment alter position orientation cameras observe effects 
positioning accuracy possible predict ultimate accuracy positioning error edge detection 
camera pixel width approximately mm 
assuming maximal error pixel physical configuration described expected vertical horizontal positioning accuracy sigma mm expected accuracy depth approximately sigma mm 
practice tracking system performs sub pixel localization expect achieve better results 
terms physical setup means expect manipulator position disks overlap 
case 
hundreds trails observed relative positioning error typically millimeter depth fraction millimeter directions 
error measured positioning corners disks described robot stabilizes freezing robot measuring positioning error 
largest source systematic error illumination differences cameras 
large contrast changes cause bright areas dark areas biases edge detector 
problems easily corrected auto aperture lenses 
point manipulator continues perform small corrective motions due noise edge tracker 
shows graph robot positions setpoint 
vertical direction corresponds motion robot axis approximately parallel camera baseline horizontal direction corresponds motion axis approximately parallel camera lines sight 
dots represent position readings taken ms graph see manipulator nearly motionless setpoint 
robot position gain mm mm robot position gain mm mm robot position gain mm mm trajectory robot performing point point motion different feedback gain values 
stability major destabilizing factors system time lag calibration error 
unmodeled dynamics robot appear play role speeds cm sec 
determine effect time delay consider discrete version system unit time delay calibration parameter error gamma gain coefficient sampling time sampling rate 
system characteristic polynomial tk 
system stability guaranteed system tk tk case delays include milliseconds calculate control command approximately milliseconds transmit command robot milliseconds delay robot responds 
theory predicts prevent unwanted oscillation setpoint 
verify analysis performed point point motions varying gain values 
shows performance algorithm point point motion gains expected gain manipulator overshoots target corrects begins slightly setpoint 
calibration sensitivity compelling evidence stability control methods described fact needed calibrate system normal 
qualitatively long cameras approximately correct positions system performs adequately unit gain 
noted analysis section system sensitive relative orientations cameras 
particular inward rotations physical cameras destabilize system 
test empirically performed system calibration described 
rotated cameras approximately degrees inward 
effects quite marked 
shown gain led large oscillations 
reducing gain stabilized system 
stable positioning precision system remained unchanged despite calibration error 
robot position gain mm mm robot position gain mm mm performance point point positioning rotating cameras inward degrees 
believe visual servoing paradigm great potential commercial scientific applications 
simple inexpensive robust portable 
current vision processing control computation system uses special hardware standard run common workstations 
current rate progress frame rate hz servoing easily feasible year 
furthermore entire system including image processing runs software moving newer powerful system largely matter recompiling 
robot camera interfaces extremely generic system easily ported robot imaging hardware 
reported current system easily position effector millimeters relative target 
positioning accuracy easily improved changing camera configuration wider baseline improving image processing accurate 
methods extremely robust 
moderately accurate camera calibration performed quickly robot motions supply input 
cases calibration sufficient provide adequate performance positioning short straight line motions provided cameras moved substantially operation 
constructed adaptive supervisory controller planar version servoing problem 
initial simulation tests indicate stable rapidly system moves 
currently moving full version adaptive controller real system 
successful simple mobile reconfigurable camera systems 
continuing develop interesting useful visual control modes trajectory generation schemes possible proper exploitation image invariants changing focus attention tracking system 
early results area 
investigating methods automatically initializing tracking system prior knowledge scene 
allen 
hand eye coordination robotic tracking grasping 
hashimoto editor visual servoing pages 
world scientific 
anderson 
dynamic sensing ping pong playing robot 
ieee transactions robotics automation 
corke 
visual control robot manipulators review 
hashimoto editor visual servoing pages 
world scientific 
faugeras 
seen dimensions stereo rig 
proc 
european conference computer vision pages 
springer verlag 
lee mitchell 
weighted selection image features resolved rate visual feedback control 
ieee transactions robotics automation february 
franklin powell emami 
feedback control dynamic systems 
addisonwesley nd edition 
hager hutchinson editors 
proc 
workshop visual servoing 
may 
hager 
real time feature tracking projective invariance basis hand eye coordination 
proc 
ieee conference computer vision pattern recognition pages 
ieee computer society press 
hager 
dof visual control relative position 
dcs rr yale university new haven ct june 
hager grunwald 
feature visual servoing application telerobotics 
proc 
ieee international conference intelligent robots systems pages 
ieee computer society press 
hager puri toyama 
framework real time vision tracking shelf hardware 
dcs rr yale university new haven ct september 
hashimoto 
lq optimal nonlinear approaches visual servoing 
hashimoto editor visual servoing pages 
world scientific 
hashimoto editor 
visual servoing 
world scientific 
cipolla 
uncalibrated stereo hand eye coordination 
technical report tr cambridge university dept engineering september 
horn 
robot vision 
mit press 
hutchinson 
exploiting visual constraints robot motion planning 
proc 
ieee international conference robotics automation pages 
ieee computer society press 
lu mjolsness hager 
online computation exterior orientation application hand eye calibration 
dcs rr yale university new haven ct august 
nishikawa miyazaki 
manipulator control visual servoing stereo vision 
proc 
ieee international conference intelligent robots systems pages 
ieee computer society press 
matthies shafer 
error modeling stereo navigation 
ieee transactions robotics automation ra june 
mundy zisserman 
geometric invariance computer vision 
mit press 
nelson khosla 
increasing tracking region eye hand system singularity joint limit avoidance 
proc 
ieee international conference robotics automation pages 
ieee computer society press 
papanikolopoulos khosla kanade 
vision control techniques robotic visual tracking 
proc 
ieee international conference robotics automation pages 
ieee computer society press 
rives chaumette 
positioning robot respect object tracking estimating velocity visual servoing 
proc 
ieee international conference robotics automation pages 
ieee computer society press 
rizzi koditschek 
progress robot juggling spatial juggle 
proc 
ieee international conference robotics automation pages 
ieee computer society press 
tsai 
versatile camera calibration technique high accuracy machine vision metrology shelf tv cameras lenses 
ieee transactions robotics automation ra aug 
weiss sanderson neuman 
dynamic sensor control robots visual feedback 
ieee transactions robotics automation ra oct 
wolfe richards 
eye hand coordination vision guided robot control applications 
international journal robot research 
wilson 
visual servo control robots kalman filter estimates robot pose relative pieces 
hashimoto editor visual servoing pages 
world scientific 
zheng chen tsuji 
active camera guided manipulation 
proc 
ieee international conference robotics automation pages 
ieee computer society press 
