measuring bandwidth kevin lai mary baker cs stanford edu department computer science stanford university accurate network bandwidth measurement important variety network applications 
unfortunately accurate bandwidth measurement difficult 
describe current bandwidth measurement techniques throughput pathchar packet pair 
explain problems techniques including poor accuracy poor scalability lack statistical robustness poor agility adapting bandwidth changes lack flexibility deployment inaccuracy variety traffic types 
solutions problems include packet window adapt quickly bandwidth changes receiver packet pair combine accuracy ease deployment potential bandwidth filtering increase accuracy 
techniques accurate previously filtering algorithms situations techniques accurate 
common complaint internet slow 
slowness due properties points slow servers due properties network propagation delay limited bandwidth 
propagation delay measured widely deployed understood algorithms implemented tools ping traceroute 
unfortunately tools measure bandwidth widely deployed understood 
attempts develop understanding measure bandwidth 
current bandwidth measurement techniques problems poor accuracy poor scalability lack statistical robustness poor agility adapting bandwidth changes lack flexibility deployment inaccuracy variety traffic types 
propose solutions problems demonstrate effectiveness packet window packet window tcp window adapt quickly bandwidth changes 
presence link failure small window accurate infinite window 
receiver packet pair receiver packet pair allow deployment special software host achieving accuracy receiver packet pair 
potential bandwidth filtering potential bandwidth filtering measure bandwidth accurately presence variety packet sizes 
environment accurate previously filtering algorithms :10.1.1.17.2405
research supported gift ntt mobile communications network 
ntt graduate fellowship usenix association sloan foundation faculty fellowship 
goal packet pair algorithms practical robust widely frequently 
approach derive simple algorithms statistically valid network models avoid heuristics 
heuristics especially combination tend difficult debug explain lack robustness apply diverse network environments 
rest organized follows section ii motivation examining bandwidth measurement techniques 
section iii propose ways packet pair algorithms robust practical 
section iv describe bottleneck bandwidth algorithms 
section describe new packet pair filtering algorithm potential bandwidth filtering 
section vi describe simulated different bottleneck bandwidth algorithms variety networks 
section vii results simulations 
section viii describe plans exploration area 
conclude section ix observations algorithms 
ii 
motivation section describe motivation examining bandwidth measurement techniques 
applications applications benefit knowing bottleneck bandwidth route 
developers network protocols applications need know bottleneck bandwidth judge efficiency protocols applications 
example server delivering data close bottleneck bandwidth increasing bandwidth link may increase application performance 
bottleneck link plenty bandwidth spare increasing bandwidth probably improve application performance 
network clients dynamically choose best server operation highest bottleneck bandwidth 
suggested way choose web server proxy 
addition accurate timely bandwidth measurement useful mobile computing 
mobile computers frequently network interface different bandwidths mb ethernet kb wireless 
knowing bandwidth allow mobile host pick highest bandwidth interface default degrade service gracefully detects operating low bandwidth link 
application congestion control 
tcp implicitly measures bandwidth network send packets faster network handle certain disadvantages described section 
bandwidth information build multicast routing trees efficiently dynamically 
ideally multicast routing trees built packets travel tree minimizes duplicate packets latency maximizing bandwidth 
currently multicast routing trees built bandwidth information static information 
metrics distinguish bottleneck bandwidth available bandwidth route 
bottleneck bandwidth route ideal bandwidth lowest bandwidth link bottleneck link route hosts 
networks long route hosts remains bottleneck bandwidth remains 
bottleneck bandwidth affected traffic 
contrast available bandwidth route maximum bandwidth host transmit point time route 
available bandwidth limited traffic route 
question better metric answered application 
applications want know route give minimum delay want estimate taken longer seconds ago 
applications bottleneck bandwidth probably best metric 
applications interested best average throughput 
applications available bandwidth probably best metric 
interested metrics chosen investigate bottleneck bandwidth stable metric useful longer period time bounds available bandwidth accurately compute available bandwidth see section viii 
current techniques importance measuring bandwidth surprising currently techniques doing 
drawbacks applications described 
popular technique throughput approximation bandwidth 
throughput amount data transport protocol tcp transfer unit time 
problem throughput metrics packet drop rate may significant effect tcp throughput affecting bandwidth 
problem measuring throughput application throughput host implies transfers application host 
example web browser sending request web server may experience low throughput request involved running slow cgi script 
browser sending different request experience high throughput request involve running cgi script 
correlating throughput different applications telnet inaccurate 
tcp uses technique estimate bandwidth 
sends packets dropped 
estimates bandwidth sending rate packet dropped half rate 
problems tcp measuring bottleneck router buffer size addition bottleneck bandwidth tcp wastes network resources forcing dropped packet filling router buffers tcp increase sending rate slowly overshoot real bandwidth cause massive packet loss 
problem particularly acute high bandwidth high latency links satellite connections tcp needs log bandwidth delta latency time reach maximum transmission rate 
solution pathchar 
far know pathchar unique ability measure bandwidth link path accurately requiring special software host 
means easily widely deployed 
excellent testing tool problem pathchar slow consume significant amounts network bandwidth 
particular pathchar runs time proportional round trip time network sends relatively fixed amount data regardless actual bandwidth network see section iv 
hosts run pathchar packets significant burden network 
isolated hosts low bandwidth connections pathchar consume bandwidth usable regularly 
iii 
making packet pair robust practical bandwidth measurement technique chosen investigate called packet pair described detail section iv 
advantages techniques mentioned measures true bandwidth network throughput cause packet loss tcp require packet round trips send massive amounts data pathchar 
hand techniques currently robust practical implementation common internet packet pair implementation rarely tools implement version packet pair algorithm including bprobe :10.1.1.134.20:10.1.1.17.2405
key problems current packet pair algorithms propose solve statistically robust previous filtering packet pair samples techniques adding error bars values intersecting clustering values close :10.1.1.17.2405
heuristics understood statistical properties effectiveness may depend particular data set 
kernel density estimator filter data understood statistical properties 
particular assumptions data statistically robust see section iv 
scalable active packet pair implementations generate traffic scalability problems pathchar see section iv :10.1.1.17.2405
packet pair algorithms need 
passive packet pair implementation uses existing network traffic measure bandwidth 
slow hand previous passive implementations designed analyze tcp connection completion occurring 
long duration tcp connections late applications mentioned 
gradual packet pair implementation forms bandwidth estimate packet arrives 
initially gives inaccurate answers gradually converges accurate answer 
way applications obtain estimate soon available see section iv 
results show packet pair give correct estimate packets start connection 
robust traffic passive implementations designed traffic composed large packets 
internet traffic mix packet sizes flow hosts may contain wide variety packet sizes 
existing passive implementations account give inaccurate results diverse traffic mix predominantly small packets large packets see section 
network model implementations account potential bandwidth 
designed new packet pair filtering algorithm called potential bandwidth filtering deliver accurate answer despite variation packet size transmission rate 
mix packet sizes accurate standard filtering algorithm 
flexible bandwidth changes prior implementations detect bandwidth time :10.1.1.17.2405
implementations detect multiple bandwidths differ large amount 
frequent congestion changes bottleneck bandwidth changes happen routing changes mobility 
applications described know soon possible bandwidth changed new bandwidth regardless magnitude 
accomplish propose limited window past packets calculate bandwidth 
increases speed algorithm adapt new bandwidth agility leaves results vulnerable noise 
believe increase agility fundamentally requires vulnerable noise see section iv 
show small window accurate infinite window presence link failure accurate congestion 
difficult deploy current highly accurate packet pair algorithm receiver packet pair rbpp requires packet timings taken sender receiver packets 
means special software deployed sender receiver may possible 
algorithm sender packet pair sbpp requires timings special software sender 
unfortunately sbpp far accurate rbpp 
describe variation rbpp called receiver packet pair ropp accurate sbpp rbpp requiring timings receiver see section iv 
allows applications trade accuracy ease deployment 
results show ropp accurate rbpp 
studied controlled conditions studies packet pair algorithms data internet 
advantage real tcp ip code routers network traffic 
verifiable reproducible results testing variety controlled conditions 
testing controlled conditions internet large difficult impossible 
overcome limitations network simulator fully described section vi compare effectiveness algorithms modifications described previous packet pair implementations 
iv 
bandwidth measurement algorithms section describe models assumptions algorithms measuring bottleneck bandwidth 
consider accuracy timeliness agility active passive require measurements multiple network hosts 
know families bottleneck bandwidth algorithms 
family algorithms call pathchar algorithms tools pathchar 
second family algorithms packet pair algorithm tools bprobe cprobe :10.1.1.134.20:10.1.1.17.2405
variants packet pair algorithm sender packet pair sbpp receiver packet pair rbpp packet bunch mode pbm receiver packet pair ropp 
orthogonal issue packet pair algorithms filter bandwidth samples 
call standard algorithms measured bandwidth filtering mbf propose potential bandwidth filtering 
addition describe refinements packet pair algorithms filtering methods kernel density function increase statistical robustness gradual bandwidth calculation increase timeliness packet window increase agility 
pathchar algorithm section analyze time taken bandwidth consumed pathchar algorithm 
program works sending packets varying sizes measuring round trip time 
correlates round trip times packet sizes calculate bandwidth 
uses results earlier hops calculations father hops 
thorough description pathchar works see 
purposes need know pathchar program uses active algorithm sends packets varying size bytes path mtu stride bytes 
number different packet sizes pathchar sends mtu gamma ethernet mtu bytes 
addition sends packets size hop 
default configuration 
wait packet sends acknowledged sending packet 
total time pathchar run delta delta number hops round trip latency sender hop assume receiver immediately sends ack response packet sender immediately sends packet ack arrives 
hop ethernet network average round trip latency ms pathchar run seconds 
slow host run tcp connection minutes 
configured send fewer packets size cost accuracy 
importantly pathchar consumes considerable amounts network bandwidth 
average bandwidth probing particular hop average packet size round trip latency deltas bytes round trip latency seconds hop 
hop ethernet network latency ms average bandwidth consumed mb considerable imposition mb ethernet 
farther hops consume bandwidth pathchar probe closer hops farther hops 
furthermore total data transferred number hops 
hop ethernet network mentioned pathchar sends mb data 
fact pathchar send mb data hop network regardless bandwidth network depends number hops path mtu path mtu high early hops low bandwidth network link modem pathchar consume bandwidth link extended amount time 
means problems scaling pathchar usage large number hosts 
packet pair basic packet pair algorithm relies fact packets queued bottleneck link exit link seconds apart bnl size second packet bnl bottleneck bandwidth :10.1.1.133.3305
bottleneck separation see 
links lower bandwidth bottleneck link downstream link assuming packets size second packet catch packet 
packets size different size packets different velocities 
second packet smaller transmission delay packet 
consequently pass links faster packet quickly eliminate bottleneck separation 
similarly packet smaller faster second packet continuously grow bottleneck separation 
assuming bottleneck separation constant packets arrive receiver spaced seconds apart 
know calculate bottleneck bandwidth bnl algorithm assumptions may hold practice 
instance impossible guarantee packets queue bottleneck link 
packets queue measurement packets bnl total size packets 
addition packets queue ahead packet downstream bottleneck link extra packets delay sender receiver sender receiver packet send timings packet arrival timings ack arrival timings bottleneck link sender receiver bottleneck separation bottleneck separation ack packet router fig 

shows packet pair algorithm works 
note data packets greater separation bottleneck link separation maintained acks 
arrows pointing sbpp rbpp ropp indicate timing information sent sender receiver algorithms 
packet causing time compression packets 
similarly packets delay second packet causing packets time extended 
time compression cause high estimate bottleneck bandwidth time extension cause low estimate 
packet pair filtering main problem basic packet pair algorithm filter noise caused time compressed extended packets 
solution take mean median bandwidth samples 
unfortunately noise little correlation true bandwidth gives wildly varying estimates 
previous packet pair research proposed finding point greatest density distribution bandwidth estimates 
idea valid samples closely clustered correct value incorrect samples clustered value 
known method doing histogram 
unfortunately problems histograms 
problem bin widths fixed difficult choose appropriate bin width previously knowing distribution 
problem bin boundaries respect distribution 
points lie close side bin boundary bin boundary ignores relationship 
histogram report density points value points bin opposite ends bin 
previous packet pair filtering algorithms overcome problems :10.1.1.134.20:10.1.1.17.2405
kernel density estimator algorithm overcomes problems 
algorithm known statisticians 
define kernel function property gamma dt density point gamma kernel width number points ith point 
kernel function ae gamma oe function desirable properties gives greater weight samples closer point want estimate density simple fast compute 
kernel density estimator algorithm known statistically valid show section vii gives accurate results 
importantly assumptions distribution operates just accurate data sets 
receiver sender packet pair receiver packet pair rbpp sender packet pair sbpp types packet pair algorithms 
differ measured 
shows difference timing measurements taken 
receiver packet pair measured receiver bnl gamma arrival times second packets respectively 
measure arrival times receiver round trip time measured sender sbpp 
equation bnl gamma arrival times acks second packets respectively 
assumes receiver promptly sends back packets 
sbpp packets hosts interfere acks original packets 
receiver sender algorithms apply additional filtering techniques reject incorrect estimates 
detect time compression reordering packets difference transmission times greater difference arrival times rbpp round trip times sbpp 
rbpp sbpp useful different circumstances 
rbpp accurate harder deploy requires measurement collection endpoints 
sbpp easy deploy results highly inaccurate congestion see section vii 
difference sbpp requires packets acknowledged tcp acks constant size relatively small 
acks constant size variation ack size causes variation total round trip time causes noise bandwidth samples 
acks small larger bandwidth path back sender start bottleneck 
bottleneck bandwidth path back sender sender asymmetric network ack size important see effect section vii 
algorithms differ kind traffic paths measure 
sbpp relies data packets flowing away measurement host measure bandwidth path sender receiver 
rbpp traffic available 
usual situation data packets flowing direction acks flowing rbpp determine bandwidth directions 
usually small size acks limit bandwidth measured see section 
applications may need high accuracy rbpp ease deployment sbpp 
applications propose receiver packet pair ropp 
shown ropp takes timing measurements receiver easier deploy rbpp 
timing information sender ropp filter time compressed packets reordered packets sbpp rbpp 
hand sbpp samples rbpp relying round trip latency 
limitation new potential bandwidth filtering algorithm described section limitation needs packets acks flowing paths measurement host determine bandwidth paths 
despite limitations results show ropp achieves accuracy rbpp see vii 
conclude ropp achieves ease deployment sbpp sacrificing little accuracy 
excellent choice applications needing know bandwidth paths host 
timeliness versus accuracy section describe tradeoff accuracy versus timeliness packet pair algorithms implemented algorithms take advantage tradeoffs 
packet pair algorithms described previous sections usually implemented running fixed number packets entire connection providing estimate 
translates long delay providing estimate 
problem applications prefer answer sooner addition accurate answer 
solution calculate bandwidth gradually 
calculating single bandwidth calculate new estimate packet arrival 
section vii show gradual algorithm converge correct bandwidth packets having wait entire life connection 
problem gradual packet pair algorithm slow detect bandwidth change poor agility 
bandwidth change may caused route change link failing host mobility 
gradual algorithm described initially detect bandwidth change noise stick initial estimate 
compensate problem able detect multiple bandwidth changes packet window 
window size packets past calculate bandwidth particular packet 
advantage probably relevant samples calculate bandwidth 
disadvantage window may reduce stability 
smaller windows affected transient conditions congestion may detect temporary bandwidth change shown section vii 
believe fundamental tradeoff 
packet pair algorithm distinguish true changes bandwidth persistent congestion 
fundamental limitation addition windows basic packet pair algorithm enables distinguish bandwidth changes presence light moderate congestion 
potential bandwidth filtering section describe previously unaddressed problem filtering algorithm described section iv 
call algorithm measured bandwidth filtering mbf distinguish solution problem potential bandwidth filtering 
potential bandwidth problem problem packet pair algorithms measure higher bandwidth bandwidth sender sends 
sender sends packets bytes ms separation receiver measure higher bottleneck bandwidth mb true bottleneck bandwidth mb fundamental property packet pair algorithms regardless filtering done 
call bandwidth sender sends packets potential bandwidth measured bandwidth exceed 
problem arises sender sends small packets sends packets slowly 
potential bandwidth lower actual bottleneck bandwidth path measured bandwidth wrong 
fortunately packets large potential bandwidth 
ftp packets large rapidly sent high potential bandwidth 
unfortunately may packets flow high potential bandwidth fact may frequently case high potential bandwidth packets common type packets 
example consider browsing site 
opens tcp connection site uses connection communication 
client receive large packets filled html pages sending acks medium sized packets filled requests 
outbound link dominated small packets medium sized packets 
normal mbf algorithm report measured bandwidth small packets 
discovered problem simulation asymmetric network problem 
asymmetric network high bandwidth inbound link low bandwidth outbound link inbound data transfer fill outbound link acks packet second rate exceed outbound data packets 
potential bandwidth filtering solution general idea potential bandwidth filtering correlate potential bandwidth measured bandwidth sample deciding filter 
samples potential bandwidth measured bandwidth particularly informative actual bandwidth higher 
samples high measured bandwidth low potential bandwidth time compressed filtered 
samples high potential bandwidth low measured bandwidth informative indicate true bandwidth 
measured bandwidth potential bandwidth knee bandwidth samples fig 

graph shows works 
dots represent bandwidth samples plotted potential measured bandwidth 
samples line filtered 
notice knee samples 
implement algorithm plotting samples graph potential bandwidth axis measured bandwidth axis 
example shown 
expect absence congestion samples fall line point samples potential bandwidth approximately equal measured bandwidth 
packets generated samples queue bottleneck link 
samples run line samples higher potential bandwidth measured bandwidth 
packets generated samples queue bottleneck link 
value actual bandwidth 
samples divert line know samples insufficient potential bandwidth 
example case samples left case try active algorithm 
compensate noise fit lines data compute relative error point distance point nearest line divided value point 
ensures errors large dominate calculation 
sum errors points attempt minimize sum choose optimal results show just accurate mbf ethernet network accurate mbf asymmetric network see section vii 
believe essential practical passive packet pair algorithms 
vi 
simulation environment section discuss network simulator simulated network believe results valid 
network simulator want verifiable reproducible results want test algorithms variety conditions believe limitations current simulator technology limited accountable effects experiments 
discuss final point section vi 
simulator goals setup section describe goals simulator configure meet goals 
goal simulation stress algorithms optimal pathological conditions 
want know worst possible conditions affect algorithms 
bottleneck bandwidth algorithms affected conditions 
lack queueing bottleneck link destroys causality packet arrival times bottleneck bandwidth 

queueing bottleneck link destroys causality packet arrival times bottleneck bandwidth 

packet loss causes algorithms take longer converge 

changing bottleneck bandwidth algorithms detect faster 

asymmetric bandwidth cause algorithms assume symmetric bandwidth paths fail 
particular tcp packets arriving high bandwidth downlink cause acks exit low bandwidth uplink 
low potential bandwidth acks may cause mbf algorithms fail see section 
model conditions controlled manner ns network simulator 
generated node network tiers topology generator 
tiers generates network reflects semi hierarchical topology internet 
topology consists wide area network wan nodes metropolitan area network man nodes local area network lan nodes includes redundant links different man nodes lan nodes 
client usually hops server hops away depending links failed 
traffic measured tcp connection client server seconds simulation 
client server different lans mans 
table types client connections 
link type bandwidth latency cable modem uplink kb ms cable modem downlink mb ms ethernet mb ms table ii traffic source parameters table lists traffic source parameters ns simulations 
size size packets 
burst idle give average times sending packets 
shape shape parameter pareto distribution generator 
size burst idle shape bytes ms ms bytes ms ms bytes ms ms simulation runs seconds simulation time 
different link characteristics summarized table iii 
varied simulation parameters client connectivity congestion link failure model 
client connections listed table client connected network client connections 
nodes links described table iii 
created congestion placing traffic sources lan node 
source sends data pareto distribution 
parameters traffic sources summarized table ii 
varied congestion average data rates kb kb mb variety levels congestion allows explore situations packets client queue bottleneck link queue bottleneck link 
varied link failure model failure deterministic failure model selected links path client server fail specific times 
table iii simulator link characteristics type links carry packets fail case type links 
type modeling bw latency wan wan mb ms wan man ethernet mb ms man man ethernet mb ms man lan ethernet mb ms lan lan ethernet mb ms wan man mb ms man lan mb ms link fails seconds seconds 
second link fails seconds seconds 
chose links failure client lan client man wan server man link failures cause packets lost combined redundant links create possibility multiple paths asymmetric bandwidth changing bottleneck bandwidth 
simulator validity believe limitations current simulator technology limited effect results 
internet exhibits effects current simulator reproduce results depend having high fidelity 
goal determine precisely algorithms perform internet average 
goal compare algorithms perform certain conditions known exist internet 
vii 
simulation results section simulation results 
tables show accuracy packet pair algorithms react changes network conditions 
gradual versions algorithms described section iv compute bandwidth estimate packet arrival 
calculate difference estimate real bandwidth point time real bandwidth varies simulations 
express difference ratio error actual bandwidth 
tables show mean ratios 
example mean error indicates algorithm estimate deviated average sigma actual bandwidth 
tables shown alg 
column describes algorithm sender sb receiver rb receiver ro 
filter column describes filtering algorithm 
bw column lists actual bottleneck bandwidth route sender receiver 
fail column lists links fail simulation 
column gives size packet window 
traffic column gives amount extra traffic simulation 
mean oe med max 
columns describe mean standard deviation median maximum respectively ratio estimate error actual bandwidth 
graph plot bandwidth measured elapsed time flow 
collect measurements packet arrival 
packet arrivals evenly distributed time points evenly distributed xaxis 
graph plot actual bandwidth gauge accuracy algorithm 
note graphs section plot bandwidth log scale starting receiver measurements section compare accuracy sender packet pair receiver packet pair new re table iv table compares accuracy various packet pair algorithms depending sender receiver receiver 
alg 
traffic mean oe med 
max 
sb kb rb kb ro kb sb kb ro kb rb kb table table compares accuracy various packet pair algorithms varying window size varying congestion 
alg 
fail traffic mean oe med 
max 
rb kb rb kb rb kb rb kb rb kb rb kb packet pair 
configure simulator ethernet client technology congestion kb congestion 
results summarized table iv 
congestion packet pair algorithms error 
kb congestion error sbpp probably applications error rbpp ropp 
results confirm assertion section iv ropp achieve accuracy close rbpp maintaining ease deployment sbpp 
congestion tolerance detecting bandwidth change section explore rbpp tolerates congestion detects bandwidth changes 
rbpp accurate sbpp ropp wanted isolate effects new algorithms 
enable rbpp detect bandwidth changes setting packet window size 
question assertions section iv accurate larger window size resistant congestion smaller window size adapt quickly bandwidth changes 
results indicate assertion correct 
table summarizes statistics 
lines show accuracy different window sizes experiencing moderate congestion 
expected smaller window values give accurate results 
average error estimate probably tolerable bandwidth log scale elapsed time seconds packet pair varying window size bandwidth change actual bw fig 

graph shows effect varying window size ethernet client simulation varying bandwidth congestion 
notice change actual bandwidth seconds 
applications 
lines show different window sizes affect agility 
test agility smaller window sizes adapting changing bandwidth configure simulator shut primary links periodically route traffic lower bandwidth secondary links see section vi 
packets connection rbpp significant error 
expect error decreases decrease window size 
estimate accurate estimate 
visualize effect different window sizes plotted estimated actual bandwidth 
notice changes actual bandwidth thin solid line seconds 
actual bandwidth begins mb bottleneck bandwidth primary route dips mb bottleneck bandwidth secondary route seconds rises mb seconds switches values seconds 
removed plot graph remains mb obscures plots 
notice estimates jump correct estimate packets start connection 
plot adapts change instantly plot slower adapt 
change plot agile plot 
strangely plot adapts change 
examination trace revealed tcp code ns increasing window 
sending packets potential bandwidth mb table vi table compares accuracy different filtering algorithms 
alg 
filter bw mean oe med 
max 
sb mbf mb sb mb rb mbf mb rb mb sb mbf kb sb kb rb mbf kb rb kb discussed section packet pair algorithms report measured bandwidth higher potential bandwidth 
conclude results decrease window size detect changes bandwidth quickly 
supports section iv tradeoff timeliness accuracy choosing window size 
potential bandwidth filtering section investigate effectiveness new filtering algorithm 
discussed section designed overcome problems standard measured bandwidth filtering mbf algorithm traffic low potential bandwidth packets 
desirable performed worse mbf traffic packets high potential bandwidth 
order test simulated ethernet network high potential bandwidth traffic uplink simulated asymmetric cable modem network low potential bandwidth traffic 
addition varying amount congestion set second tcp connection hosts connection reverse direction 
ensures high potential bandwidth packets outbound direction 
results summarized table vi 
lines show equivalent mbf ethernet network 
lines show accurate average mbf cable modem network 
mbf significantly lower median mbf poor average accuracy blamed outliers 
examination trace verifies analysis section outbound link filled acks overwhelm data packets 
causes mbf incorrectly report bandwidth acks true bandwidth 
able filter samples discern true bandwidth 
viii 
interested simulating networks algorithms calculating different metrics testing ideas internet 
type network simulate wireless network 
ns support wireless networks fully functional time experiments 
wireless networks interesting examine tend high loss rates high variance latency situations challenge packet pair algorithms 
addition simulate pathchar algorithm compare accuracy passive techniques 
apply methods described calculate available bandwidth 
mentioned section ii applications find useful metric 
believe methods described apply minor modifications 
currently bottleneck bandwidth measurement algorithms implement nettimer take live measurements internet 
ix 
examined characteristics current bandwidth measurement techniques problems 
propose statistically robust algorithms overcome problems giving timely estimates agile face bandwidth changes giving flexibility deployment working variety different traffic types 
simulation results show implementation accurate previous techniques 
conclude accurate flexible scalable bandwidth measurement possible desirable order maintain growth reliability internet applications 
acknowledgments acknowledge help people 
stuart cheshire provided code inspiration nettimer 
guido suggested investigating robust methods calculating density 
marcos de alba pointed error pathchar analysis 
vern paxson gave early copy provided valuable feedback potential bandwidth filtering 
craig partridge provided advice motivation 
anonymous reviewers feedback 
mary baker zhao stuart cheshire jonathan stone 
supporting mobility 
proceedings usenix technical conference january 
jean bolot 
packet delay loss behavior internet 
proceedings sigcomm 
kenneth calvert matthew doar ellen zegura 
modeling internet topology 
ieee communications magazine 
robert carter mark crovella 
dynamic server selection bandwidth probing wide area networks 
technical report bucs boston university 
robert carter mark crovella :10.1.1.17.2405
measuring bottleneck link speed packet switched networks 
technical report bu cs boston university 
stuart cheshire mary baker 
experiences wireless network 
proceedings ieee hot interconnects symposium 
william feller 
probability theory applications volume ii 
wiley eastern limited 
van jacobson 
pathchar 
ftp ftp ee lbl gov pathchar 
srinivasan keshav :10.1.1.133.3305
control theoretic approach flow control 
proceedings sigcomm 
steven mccanne sally floyd kevin fall kannan varadhan ns 
www mash cs berkeley edu ns 
vern paxson :10.1.1.134.20
internet packet dynamics 
proceedings sigcomm 
vern paxson 
measurements analysis internet dynamics 
phd thesis university california berkeley april 
vern paxson sally floyd 
don know simulate internet 
proceedings winter simulation conference 
dave scott 
multivariate density estimation theory practice visualization 
addison wesley 
srinivasan seshan mark stemm randy katz 
spand shared passive network performance discovery 
proceedings usenix symposium internet technologies systems 
ronald 
elements statistical computing numerical computation 
chapman hall 
