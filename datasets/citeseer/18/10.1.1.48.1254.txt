bayesian approach filtering junk mail mehran sahami susan dumais david heckerman eric horvitz gates building computer science department microsoft research stanford university redmond wa stanford ca microsoft com sahami cs stanford edu addressing growing problem junk mail internet examine methods automated construction filters eliminate unwanted messages user mail stream 
casting problem decision theoretic framework able probabilistic learning methods conjunction notion differential misclassification cost produce filters especially appropriate nuances task 
may appear straight forward text classification problem show considering domain specific features problem addition raw text mail messages produce accurate filters 
show efficacy filters real world usage scenario arguing technology mature deployment 
number users connected internet continues electronic mail mail quickly fastest economical forms communication available 
mail extremely cheap easy send gained enormous popularity simply means letting friends colleagues exchange messages medium conducting electronic commerce 
unfortunately virtues mail popular casual users direct marketers unsuspecting mailboxes unsolicited messages regarding items sale get rich quick schemes information accessing pornographic web sites 
proliferation direct marketers internet increased availability enormous email address mailing lists volume junk mail referred colloquially spam grown tremendously past years 
result readers mail spend non trivial portion time line unwanted messages 
messages contain offensive material graphic pornography higher cost users viewing mail simply time sort junk 
lastly junk mail wastes user time quickly fill file server storage space especially large sites thousands users may getting duplicate copies junk mail 
result growing problem automated methods filtering junk legitimate mail necessary 
commercial products available allow users set logical rules filter junk mail 
solution problematic best 
systems require users hand build rule set detect junk assume users savvy able construct robust rules 
nature junk mail changes time rule sets constantly tuned refined user 
time consuming tedious process notoriously error prone 
problems manual construction rule sets detect junk point need adaptive methods dealing problem 
junk mail filtering system able automatically adapt changes characteristics junk mail time 
having system learn directly data user mail repository junk filter personalized particular characteristics user legitimate junk mail 
turn lead construction accurate junk filters user 
lines methods suggested automatically learning rules classify email cohen 
approaches shown success general classification tasks text messages employed specifically task filtering junk mail mind 
result systems focused specific features distinguish junk legitimate mail 
domain specific lines focused detecting flame hostile messages spertus 
research looked specifically particular features indicative flames general quite different junk mail filtering 
domain specific features consider full text content messages trying identify flame 
generally find rule approach limited utility junk mail filtering 
due fact logical rule sets usually rigid binary decisions classify message junk 
rules generally provide sense continuous degree confidence classification 
confidence score crucial consider notion differential loss misclassifying mail 
cost misclassifying legitimate message junk usually higher cost classifying piece junk mail legitimate notion utility modeling imperative 
require classification scheme provides probability classification decision second quantification difference cost types errors task 
possible classify junk mail decision theoretic framework 
deal automatically generating probabilistic text classification models naive bayesian classifier lewis ringuette mitchell mccallum expressive bayesian classifiers koller sahami 
continuing vein seek employ bayesian classification techniques problem junk mail filtering 
making extensible framework bayesian modeling employ traditional document classification techniques text messages easily incorporate domain knowledge particular task hand additional features bayesian classifier 
classifier combination loss model optimal decisions standpoint decision theory respect classification message junk 
remainder consider methods learning bayesian classifiers textual data 
turn attention specific features junk mail filtering just text message incorporated probabilistic models learned 
validate provide number comparative experimental results conclude general observations directions 
probabilistic classification order build probabilistic classifiers detect junk mail employ formalism bayesian networks 
bayesian network directed acyclic graph compactly represents probability distribution pearl 
graph random variable denoted node 
directed edge nodes indicates probabilistic influence dependency variable denoted parent node child 
consequently structure network denotes assumption node network conditionally independent parents 
describe probability distribution satisfying assumptions node network associated conditional probability table specifies distribution possible assignment values parents 
bayesian classifier simply bayesian network applied classification task 
contains node representing class variable node features 
specific instance assignment values xn feature variables bayesian network allows compute probability possible class done bayes theorem giving critical quantity equation impractical compute imposing independence assumptions 
oldest restrictive form assumptions embodied naive bayesian classifier assumes feature conditionally independent feature class variable formally yields great deal learning expressive bayesian networks data cooper herskovits heckerman geiger chickering methods learning networks specifically classification tasks friedman geiger goldszmidt sahami 
approaches allow limited form dependence feature variables relax restrictive assumptions naive bayesian classifier 
contrasts structure naive bayesian classifier expressive classifiers 
focus naive bayesian classifier bayesian networks corresponding naive bayesian classifier complex bayesian classifier allowing limited dependencies features 
simply point methods learning richer classification models exist harnessed needed 
context text classification specifically junk mail filtering necessary represent mail messages feature vectors bayesian classification methods directly applicable 
vector space model salton mcgill define dimension space corresponding word entire corpus messages seen 
individual message represented binary vector denoting words absent message 
representation straight forward learn probabilistic classifier detect junk mail pre classified set training messages 
domain specific properties considering specific problem junk mail filtering important note particular features mail just individual words text message provide evidence message junk 
example particular phrases free money emphasized punctuation indicative junk mail 
mail contains non textual features domain type message sender edu com provide great deal information message junk 
straight forward incorporate additional problem specific features junk mail classification bayesian classifiers described simply adding additional variables denoting presence absence features vector message 
way various types evidence messages uniformly incorporated classification models learning algorithms employed need modified 
consider adding different forms problem specific information features classification 
involves examining message text appearance specific phrases free 
approximately hand crafted phrases particularly germane problem included 
omit exhaustive list phrases brevity 
note features manually constructed phrases existing rule set filtering junk readily outperformed probabilistic filtering scheme described 
addition phrasal features considered domain specific non textual features domain type sender mentioned previously 
example junk mail virtually sent edu domains 
programs reading email resolve familiar mail address replace microsoft com susan dumais 
detecting resolutions happen messages sent users familiar recipient provide additional evidence message junk 
non textual indicator distinguishing message junk examining recipient message individual user message sent mailing list 
number simple distinctions message attached documents junk mail message received junk mail sent night powerful junk legitimate mail 
furthermore considered number useful distinctions quite probabilistic classifier problematic rule system 
features included percentage non alphanumeric characters subject mail message junk mail example subject descriptions big money contain high percentage non alphanumeric characters 
shown clear differences distributions non alphanumeric characters subjects legitimate versus junk mes percentage message containing num alphanumeric characters legitimate junk percentages legitimate junk mail subjects comprised varying degrees characters sages 
feature discretized variant checks message subject contains say non alphanumeric characters simple distinction junk reliably 
likewise true domain specific features consider 
features evidence probabilistic classifier increase confidence message classified junk 
total included approximately non phrasal hand crafted domain specific features junk email filter 
features required little create generated short brainstorming meeting particular task 
results validate approach conducted number experiments junk mail detection 
goal measure performance various enhancements simple baseline classification raw text messages looking efficacy learning junk filter operational setting 
feature space text tend large generally order dimensions consequently employ feature selection reasons 
dimensionality reduction helps provide explicit control model variance resulting estimating parameters 
feature selection helps attenuate degree independence assumption violated naive bayesian classifier 
employ zipf law analysis zipf corpus mail messages eliminate words appear fewer times having little resolving power messages 
compute mutual information mi feature class cover thomas mi log select features value greatest feature set build classifier 
conduct rigorous suite experiments arrive optimal number features initial experiments showed value provided reliable results 
note initial feature set select include word hand crafted phrasal domain specific features 
previous feature selection koller sahami yang pedersen indicated information theoretic approaches quite effective text classification problems 
domain specific features set experiments seek determine efficacy features hand crafted specifically problem junk mail detection 
corpus actual mail messages messages pre classified junk messages pre classified legitimate 
note proportion junk legitimate mail corpus legitimate mail classified junk 
error far worse marking piece junk mail legitimate believe class disparity creates challenging classification problem 
data split temporally testing messages arrived training messages training set messages testing set messages 
consider just word tokens subject body mail message feature set 
augment features approximately hand crafted phrasal features constructed task 
enhance feature set non textual domain specific features junk mail detection explicitly described 
training data conjunction feature set perform feature selection build naive bayesian classifier classify testing data junk legitimate 
recalling cost misclassifying legitimate mail junk far outweighs cost marking junk legitimate feature regime precision recall precision recall words words phrases words phrases domain specific table classification results various feature sets 
piece junk legitimate appeal decision theoretic notion cost sensitive classification 
message classified junk probability placed junk class greater 
believe naive bayesian classifier due independence assumption provides accurate probability estimate classification close examination values gives reveal threshold reasonable task 
precision recall junk legitimate mail feature regime table 
specifically junk precision percentage messages test data classified junk truly 
likewise legitimate precision denotes percentage messages test data classified legitimate truly 
junk recall denotes proportion actual junk messages test set categorized junk classifier legitimate recall denotes proportion actual legitimate messages test set categorized legitimate 
clearly junk precision greatest concern users want legitimate mail discarded junk reflected asymmetric notion cost classification 
seen table phrasal information improve performance slightly incorporation little domain knowledge task greatly improves resulting classifications 
gives junk mail precision recall curves various feature sets 
focuses range clearly show greatest variation curves 
clearly find incorporation features especially domain specific information gives consistently superior results just considering words messages 
believe provides evidence targeted text classification problems deal room improvement considering simple salient features domain addition raw text available 
examples features general text categorization problems include information relating document authors author affiliations publishers junk recall words words phrases words phrases domain specific precision recall curves junk mail various feature sets 
sub classes junk mail considering types mail commonly considered junk dominant groupings 
messages related pornographic web sites 
second concerns get rich quick money making opportunities 
groups somewhat disparate consider possibility creating junk mail filter casting junk filtering problem category learning task 
categories mail defined legitimate pornographic junk junk 
distinguishing sub groups junk mail goal better capture characteristics junk allowing degrees freedom learned classifier 
experiment consider collection mail messages junk legitimate 
collection split temporally training set messages testing set messages 
measure efficacy identifying sub groupings junk mail label data different ways 
trial message simply labels legitimate junk 
second trial junk message relabeled pornographic junk junk creating way classification problem 
junk legitimate categories precision recall precision recall legitimate junk legitimate porn junk junk table classification results considering sub groups junk mail 
considering results previous experiments domain specific features include phrasal domain specific features feature sets experiments 
apply feature selection initial feature set produce features learn naive bayesian classifier 
certainty threshold classifying test messages junk reflect asymmetric cost errors task 
note true goal filter junk legitimate mail really identify subgroups junk mail consider test messages classified pornographic junk junk junk mail 
junk messages labels category task considered correctly classified 
realize gives advantage terms evaluation category task category task task misclassifications subcategories junk mail pornographic junk messages classified junk vice versa penalized 
advantage turns help seen 
results experiments sub groups junk mail table 
find surprisingly modeling sub categories junk email improve results worse 
result clearly echoed junk mail precision recall curves experiment shown range 
curve category task dominates category task entire range precision recall values 
believe main reasons results 
features may clearly indicative junk versus legitimate mail category task features may powerful probabilistically skewed category task distinguish sub classes junk 
second compelling reason increase classification variance accompanies model degrees freedom 
classifier category task fit parameters data classifier category task variance estimated junk recall junk porn junk junk precision recall curves considering subgroups junk mail 
parameters leads decrease performance classifier 
especially true parameters sub classes junk estimated data data sub divided category task 
behavior seen contexts decision tree induction known data fragmentation problem pagallo haussler 
real usage scenario test mail collections described far obtained classifying existing mail folders 
users collections gathered viewed deleted legitimate messages time data sampled 
actual deployment junk filter important sure user entire mail stream classified high accuracy 
simply evaluate filter testing set legitimate messages includes messages user read choose store mail repository 
junk mail filter able accurately discern true junk mail user want read discard considered legitimate mail permanently stored 
measure efficacy junk mail filters classified junk classified legitimate total junk precision legitimate precision total table confusion matrix real usage scenario 
real usage scenario consider user real mail repository messages previous year classified junk legitimate training set filter 
testing data messages sent user week period training data collected 
show growing magnitude junk mail problem messages contained messages incoming mail deemed junk user 
experiment consider phrasal domain specific features mail text messages learning junk filter 
employ naive bayesian classifier confidence threshold classifying message junk 
confusion matrix results experiment table 
precision results promising experiment concern messages classified junk filter deemed legitimate user quite important 
case filter considered suitable real world usage 
post mortem analysis misclassifications reveals filter fact working quite 
legitimate messages classified junk filter message junk mail message forwarded user study 
message begins sentence check spam contains full text junk mail message 
misclassified legitimate messages simply news stories mail news service user subscribes 
messages happen talking hype web search engine industry important user 
loss significant information messages classified junk filter 
find filter fact quite successful eliminating incoming junk mail user mail stream 
completeness provide precision recall curve task 
results believe system practical usage commercial mail applications 
junk recall real usage precision recall curve junk mail real usage scenario 
examining growing problem dealing junk mail possible automatically learn effective filters eliminate large portion junk user mail stream 
efficacy filters greatly enhanced considering full text mail messages filtered set hand crafted features specific task hand 
believe improvement seen domain specific features particular problem provides strong evidence incorporation domain knowledge text categorization problems 
extensible classification formalism bayesian networks possible easily uniformly integrate domain knowledge learning task 
experiments show need methods aimed controlling variance parameter estimates text categorization problems 
result corroborated extensive experiments showing efficacy support vector machines svms text domains joachims 
svms known provide explicit controls parameter variance learning vapnik particularly suited text categorization 
believe svms decision theo framework incorporates asymmetric misclassification costs fruitful venue research 
seek consider bayesian classifiers restrictive naive bayes 
way hope obtain better classification probability estimates accurate costs sensitive classifications 
interested extending automatically classify messages user hierarchical mail folder structure machine classifier koller sahami 
way hope provide just junk mail filter entire message organization system users 
cohen 
learning rules classify email 
proceedings aaai spring symposium machine learning information access 
cooper herskovits 
bayesian method induction probabilistic networks data 
machine learning 
cover thomas 
elements information theory 
wiley 
friedman geiger goldszmidt 
bayesian network classifiers 
machine learning 

estimation probabilities essay modern bayesian methods 
press 
heckerman geiger chickering 
learning bayesian networks combination knowledge statistical data 
machine learning 
joachims 
text categorization support vector machines learning relevant features 
technical report ls report universitaet dortmund 
koller sahami 
optimal feature selection 
machine learning proceedings thirteenth international conference 
morgan kaufmann 
koller sahami 
hierarchically classifying documents words 
machine learning proceedings fourteenth international conference 
morgan kaufmann 
lewis ringuette 
comparison learning algorithms text categorization 
proceedings sdair 
mccallum rosenfeld mitchell ng 
improving text classification shrinkage hierarchy classes 
machine learning proceedings fifteenth international conference 
mitchell 
machine learning 
mcgrawhill 
pagallo haussler 
boolean feature discovery empirical learning 
machine learning 
pearl 
probabilistic reasoning intelligent systems networks plausible inference 

sahami 
learning limited dependence bayesian classifiers 
proceedings second international conference knowledge discovery data mining 
salton mcgill 
modern information retrieval 
mcgraw hill book 
spertus 
automatic recognition hostile messages 
proceedings innovative applications artificial intelligence iaai 
vapnik 
nature statistical learning theory 
springer verlag 
yang pedersen 
feature selection statistical learning text categorization 
machine learning proceedings fourteenth international conference 
morgan kaufmann 
zipf 
human behavior principle effort 
addison wesley 
