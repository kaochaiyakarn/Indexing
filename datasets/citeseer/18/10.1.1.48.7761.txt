designing self maintaining storage system satoshi david patterson cs berkeley edu tertiary disk project computer science division university california berkeley california cs berkeley edu td shows suitability self maintaining approach tertiary disk large scale disk array system built commodity components 
incurring cost custom hardware attempt solve various problems design software 
built cluster storage nodes connected switched ethernet 
storage node pc hosting dozen scsi disks running freebsd operating system 
system web image server zoom project cooperation fine arts museums san francisco www thinker org 
designing self maintenance extension os run cluster mitigate system administrator burden 
components required building self maintaining system 
decoupling time failure time hardware replacement 
implies system amount redundancy single point failure 
system fully redundant constructed avoid single point failure 
correctly identifying failures dependencies 
outlines approaches lower human cost system administration system making system autonomous possible 
maintenance big problem large disk storage systems 
instance survey strategic research shows annual cost system administration times annual research funded darpa state california micro program 
ibm intel donating disk drives pcs respectively 
cost hardware 
john wilkes mentioned factor difference storage management depending definition management 
addition cost proper maintenance critical storage systems consequence failure loss valuable data 
packaged solutions hardware raid boxes server systems tandem network appliance successful marketplace reasons 
approach scale past terabyte mark price maintenance complexity having purchase multiple boxes greatly increase complexity administration 
system uses commodity hardware solve problems 
built cluster storage nodes web server 
storage nodes connected switched mbps ethernet internally atm connection outside world 
storage node pc hosting dozen scsi disks running freebsd operating system 
system webbased image server zoom project cooperation fine arts museums san francisco 
designing self maintenance extension os run cluster mitigate system administrator burden 
aspects system consider discussing administrative issues system administrator perspective user perspective 
discussed separately 
system administrator clearly desirable system continue functioning administrator absence 
systems require human intervention point instance hardware replacements system fully automated sense human system administrator time 
self maintaining mean storage system simplify system administrator job ways ffl maintenance required fixed intervals 
ffl maintenance time required tasks clearly defined 
addition reducing cost type maintenance reduce chances operator error allowing person stressful conditions 
having repair system right away system fully functional repair reduces mental stress 
operator working regular working hours mistakes working am 
essential give impression users system times 
users connected system internet hitting reload 
re route accesses seconds failure user able distinguish transient network problem internet failure system 
fact unreliability internet problems caused network 
components required building self maintaining system 
decoupling time failure time hardware replacement 
implies system amount redundancy single point failure 
system fully redundant constructed avoid single point failure 
correctly identifying failures dependencies 
planning add features enclosure monitoring eric anderson card system extensible monitoring system relational databases servers 
major component repairing 
steps necessary mask failures system continue functioning take actions remove vulnerability caused failure reconstruct contents failed disk prepare precise repair instructions human operator 
remainder organized follows 
section described related field 
section clarify concept self maintainability explain approach problem 
section describes application briefly 
section illustrate architecture system experiment 
section illustrates software architecture system section explains validation methodology section describes system scaled bigger size 
related related high availability servers network attached storage maintenance large clusters 
high availability servers tandem manufactures network servers 
nonstop servers fully redundant components necessary take repairs 
architecture called shared single points failure 
component fail system function 
system administration suite called tandem maintenance diagnostic system 
auto diagnostics feature uses ai program compares symptoms system known failure modes tries identify failures 
optionally dial tandem technical support report remote technician consult running diagnostics 
network appliance sells network servers built digital alpha chip 
nfs servers advertised outperform way mhz windows nt system times 
raid parity dedicated parity disk increase performance 
filesystem recover crashes quickly 
network attached storage microsoft tiger video server built commodity pcs called 
goal tolerate failure cub disk degradation service 
mirroring backing data 
tolerate runtime reconstruction overhead parity 
locate primary copies data outer tracks disks better performance backup copies declustered avoid hotspots failures 
tiger distributes files disks maximum striping performance method drawback having reconstruct data entire system new disk added 
reconstruction expensive parity calculation involved 
single controller serves entry point clients 
image data passes controller performance bottlenecks 
take great care ensure sufficient bandwidth available entire course playback delay start playback necessary 
distributed schedule management protocol scalability 
cub partial potentially outdated view schedule pass schedule updating way 
protocol fault detection cub sends periodic ping cub right 
petal example network attached storage system 
collection distributed servers containing multiple disks 
method called chained declustering avoid having load increase machine mirrored counterpart fails 
petal block server 
authors petal designed distributed file system called frangipani run top petal 
cmu nasd network attached secure disks example network attached storage 
xfs combination network striping lfs log structured filesystem 
system avoids complexity distributed filesystems redirects ip masquerading distribute user requests mask failures 
maintenance eric anderson network workstations project studying aspects system administration clusters 
introduces system called card cluster administration relational databases 
proposes relational databases build extensible monitoring system 
uses hybrid push pull protocol collect data individual machines 
emphasis monitoring diagnosis 
planning card building block monitoring diagnosis system 
storage systems program hp working system called self management storage 
focus automatic assignment storage devices humans worry put 
prototype system capable assigning thousands objects devices minutes 
sun jini devices including disks identify part automatic component discovery paradigm 
self maintaining system section define self maintaining means context large disk storage systems outline requirements construct system 
definition aspects self maintainability system depending perspective system administrator user 
system administrator perspective 
system administrator self maintaining system require constant attention 
purpose research define system characteristics 
ffl maintenance required fixed intervals 
ffl maintenance time required tasks clearly defined 
comprises reasonable interval interesting issue 
planning run simulations gathering data failures see system stay varying intervals 
purpose assume interval week 
major benefits approach reduce operator errors help operator performance 
aside required repairs odd hours pressure having fix system right away reduce chances operator errors 
reduce operator cost benefit necessary pay full time wage system administrator system 
hire part time person administer systems just 
second reason similar motivation tandem 
tandem engineers support center hours day systems having problems automatically dial tandem contact support persons 
hours failure support person show customer site necessary repair parts 
companies purchase support contracts hire operators effect sharing operators companies tandem 
system take step 
need middle night fact need central support center 
operators travel customer site week doing week 
user perspective 
classes users web storage system 
users people system internet 
know internals system easily get annoyed doesn may come back unhappy 
usually issue reads system 
content providers relatively people job update contents web server 
part project asked wait system allow writes moment 
knowledge system usually know internal workings 
reduce user frustration important reduce system time seen internet 
note system relies operator keep running available maintains take minutes hours operator able repair damage 
goal system repair interruption service seconds continue function unattended scheduled visit operator 
web server application running illustrated slogan repair reload 
mary baker said ph thesis limit recovery time approaches zero system fast crash recovery indistinguishable system crashes 
research file servers distributed operating system statement qualified appropriate systems tolerate short periods time cluster workstations typical engineering research environment 
believe application web server example system fast crash recovery just system crashes 
observation internet unreliable impossible user distinguish problems servers daily transient problems network 
goal recover single failure seconds 
believe time average user notices network problem 
content providers situation little different 
permissible system state receive input short 
repeated problems affect productivity delay update contents desirable keep short infrequent possible 
order partially shield problems content providers offer portal upload new images 
data portal go 
problem part system disallows writes new images may available web problem fixed 
requirements requirements building system 
requirements listed implementation details sections 
single point failure system allowed single point failures 
possible decouple time repair time failure allowing system run existence failure 
clearly depending failures system tolerate may necessary redundancy having single point failure minimum requirement system designed function continuously event component failure 
constant reliable monitoring system constantly reliably monitored corrective actions taken quickly failures 
simple shell scripts monitoring interval seconds sleeps monitoring 
monitoring scripts autonomous failure machine cause monitoring script machine malfunction 
characteristics application easy build self maintaining system 
hard requirements helped simplify design system 
users issuing reads important aspect system read nature user accesses 
believe unique application applications similar scale share characteristics 
having allow writes degraded mode immediate recovery matter locating backup rerouting user requests lengthy recovery procedures take place 
little internal communication application needs little internal communication handle user re quests see section details user requests handled 
simplifies recovery messages connections lost due failure 
enable system scale nicely 
application main application tertiary disk prototype image database holding pictures objects art 
thinker site www thinker org run fine arts museums san francisco providing access art images internet october 
implemented searchable index user query database keywords artist title description 
user page thumbnails images fit search criteria clicking thumbnails view larger versions images 
largest images provide pixels side 
original files larger theta pixels due disk space constraints lack way adequately users internet decided provide relatively small images 
understandably common complaints users pictures bigger provide disk space larger versions images 
addition providing space wrote viewer called tiled layered jpeg format multiple resolution levels 
images occupying tb storage space fully mirrored 
images stored different formats original mb image human processed average mb image mb image 
shows layer file 
tiles form smallest layer tiles middle layer largest layer consist tiles 
shows interaction client server 
client requests image cgi script cgi returns html page describing page layout 
individual image tiles retrieved separate cgi script cgi 
completely html graphical web browser function client 
thing note server requires little processing power runtime 
images struct width height ratio offsets layer layer layer layer image file struct width height ratio offsets layer layer layer html source jpeg tiles graphical web browser server client cgi cgi interface divided tiles tiff converter numerous calls cgi require accesses file get offset size tile header retrieve tile 
particular jpeg encoding decoding required server side 
files compact accesses requests handled memory disk cache disk surface 
status site open public march images 
currently images available 
reason couldn simply images available photographs quality presentable require manual crop reorient color cor rect provided visitors 
people museum response public favorable 
experienced time despite individual machines crashing rebooted times 
tertiary disk architecture tertiary disk group built prototype disk storage system 
building self maintaining system top 
total capacity terabytes 
highlights ffl pcs mhz pentium pro mb memory disk servers ffl gigabyte ibm rpm scsi disks ffl uw twin channel ultra wide scsi adapters ffl technologies model disk sca enclosures serial interface ffl port mbps fast ethernet switches ffl port serial terminal servers pc consoles disk enclosure interfaces ffl pcs run freebsd operating system minor modifications ffl double feedthrough terminators high availability ffl redundant frontends redirect route user requests ffl power supply ups units ffl remotely controllable power switches pc enclosure power cables ffl pcs mhz pentium frontends ffl pcs mhz pentium pro infrastructure servers nis occupies foot tall inches wide 
different configurations 
pcs configured disk heavy configuration disks pcs 
remaining cpu heavy configuration disks pcs 
computers connected video monitor keyboard serial ports act consoles rest 
frontend machines standard monitor keyboard provide access system machine room 
scsi adapter pc terminator terminator disks pc scsi adapter double scsi disks characteristics system 
commodity components important feature system built commodity shelf components 
lowers cost storage factors compared standard raid boxes 
time construction system summer large raid arrays cost cents megabyte system cost cents megabyte street prices components 
redundancy designing td prototype taken care ensure single point failure 
list places avoided creating single points failures 
ffl multiple ups units provide power 
power side rack connected different ups units 
ups units provide minutes standby power survive temporary glitches power 
ffl double ended pc pairs connected different power 
connected different network serial switches 
external feedthrough terminators scsi bus integrity preserved pcs completely loses power 
ffl enclosure power supplies 
connected power opposite sides 
power supply built fan third fan enclosure disks reduced half power supply fails 
ffl data mirrored 
stable data necessary system day day operation backed tapes cd roms 
software architecture aspects software architecture needs discussed 
handling user requests main application described section web server fine art images 
request image user comes frontend machine 
frontend look table returns redirect message user client subsequently connects backend machine holding image 
point client interacts backend machine directly user finished browsing image 
illustrates requests passed 
images search url images redirect request users fine arts museums san francisco frontends tertiary disk project berkeley search engine backends handling user requests masking failures levels masking done handle failures 
extreme system nonvolatile rams holding state information open tcp connections machine crashing rebooting cause connection lost 
nfs stateless server clients retrying server replies 
model causes client lock server comes back lose requests 
kind models required local area network environment correctness response valued 
premise mentioned section internet unreliable doesn sense try mask failures 
goal implement repair reload words sure system able mask failure seconds allow reads users 
illustrates mask machine scsi failures users 
frontends cs 
berkeley edu cs berkeley edu backing ip aliasing 
canonical address cs berkeley edu usually alias 
machine checks ethernet see seconds 
find take 
keep checking seconds release alias soon finds 
check servers seconds 
done fetching file machine file available server disk having problems 
discovers problems machines automatically forward subsequent requests users backups 
cpu load machines servers low scripts simple scripts detect problems prompt manner 
tricks cover cases users session server goes 
ways mask case similar frontends having servers back machine possibly frontends take ip address temporarily forward request backup 
planning implement 
operating system support section describe part operating system modify order build system 
scsi disk subsystems 
scsi disk subsystems ones caused problems 
understandable commodity hardware necessarily designed large server system mind 
place specialized storage system manufacturers advantage 
able fix problems help freebsd developers 
actual nature problems scope please see home page information 
user request query query take alias reply reply ip alias primary backup user reply masking failures disk identification 
problem having disk drives looking identical easy confuse 
scsi disks identified scsi ids bus identified host adapter number machine identified hostnames ip addresses 
problem disks accidentally exchanged operating system able tell difference try disks falls 
scsi ids set disk enclosures pair disks accidentally swapped instance replacement broken enclosure ids change disk location appearing having id 
different consequences ranging os crash application error extremely dangerous 
designing system system able tell disks installed incorrectly 
various ways implement trade offs effects complexity design 
alternatives considered 
serial numbers disk unique serial number permanent memory 
reading operating system aware disk moved keeping list serial numbers disks comparing disks boot 
comment easy implement simple safe guarding operator errors 
disk describes partitioning disks information disk rotational latency geometry 
possible expand format include information expected bus scsi ids 
comment previous option simple safe guarding bus scsi ids note doesn require table kept system disks know supposed appear system complex tasks automatic mounting 
fixed size limit complexity 
instance ll need add special fields describe disk part striped set disks set disk appears script option disk known partition filesystem exists script executed turn system boots 
comment option virtually unlimited 
check disk identity system boot process call disk script bus scsi ids arguments auto mount necessary filesystems construct complicated entities striped arrays 
note case modification whatsoever required boot disks boot disks just read scripts execute turn 
scripts written cleverly may matter order disks inserted particular enclosure 
disk moved different machine possible system rectify situation aid operator need kind distributed filesystem handle cases 
implemented third option script method 
possible move disks machine mounted correctly single filesystem case striped array case 
fast fsck 
important reduce time required rebooting system order minimize window vulnerability 
implemented methods outlined mary baker ph thesis largest amount time taken reboot fsck time 
takes minutes run disk striped arrays system crash 
dr mckusick author fsck working project called soft updates changing way dirty data written bsd filesystem performance reliability improves greatly 
filesystems need fsck run crash may lose space consistent 
need run fsck time time reclaim space done time right crash 
snapshots soft updates released freebsd 
machines months ill effects 
validation planning run simulations validate feasibility approach 
objective collect data failures prove simulation system run continuously existence failures 
able predict expected downtime depending parameters notably repair interval 
collecting data keeping log failures experienced 
distinct entries system logs modified system keep longer default 
addition observing components normal subjecting disks artificial loads see difference failure rates 
part augments low loads re seeing museum project 
logs 
various logs system observe component failures 
main system log var log messages kernel messages messages process syslog facility go 
disk failures show loud continuous stream retries failures 
see processes getting killed due various reasons 
segmentation faults due programming bugs swap pager faults caused hardware problems 
servers logs 
file access logs httpd access log file error logs httpd error log 
determine servers restarted error frequencies 
frequency errors seen far months operation shown 
failures include components bad installed 
components failures cpu enclosure fans shown 
component total failed scsi adapter scsi cable scsi disk ide disk enclosure scsi enclosure power ethernet adapter ethernet switch ethernet cable observations ffl ethernet switch obviously small sample size draw meaningful 
ffl hand disk enclosures scsi bus integrity ide hard drives major causes concern 
hardest components replace causing major headache system administrators 
investigating methods boot machines cd roms system disks avoid problem ide hard disks altogether 
thing note hard diagnose scsi bus integrity problems 
scsi host bus adapter cable disks enclosures terminator 
seen table problems due enclosures 
ffl compared ide drives scsi drives surprisingly reliable mtbf works hours 
suspect difference due factors ide drives lower quality general superior cooling external disk enclosures house scsi drives 
simulation planning write event driven simulator data collected experiment various design parameters 
design parameters include different repair intervals systems double systems fast reboot optimizations different disk failure rates different enclosure failure rates 
allow investigate radically different designs having significantly disks machine 
scaling level machine room meters side space hold disk systems 
introduced gb inch drives seagate give total capacity tb 
system able hold images tiff images similar quality 
design scale past current size nature application web image server 
believe answer 
machine web server real performance bottleneck frontends network connections outside world long keep pc disk ratio constant 
performance system performance limited external bandwidth 
synthetic workload measured freebsd system disks sustain kb random reads second translates mb sec megabits sec 
mb random reads number goes higher mb sec 
compared internal network bandwidth mbps switched ethernet external bandwidth mbps atm link clearly impossible users internet generate loads near maximum workload dozen pcs handle load extremely unbalanced 
having machines system going situation change 
frontends bottleneck 
loads frontends extremely low request user passes frontend image user transferred museum rest transactions including calls handled backend servers 
frontend simple table lookup determine right server 
images organized original contain images size table small lines far 
expect frontends handle load times servers easily 
situation changes easy add frontends parallel 
course depends lot nature application 
application require processing power handle user requests 
part nature backend image database museum site handles database queries 
reason design application 
mentioned section server requires little processing power 
cpu intensive application particularly require internal communication scale nearly 
maintenance overhead performance scales order magnitude terms number disks cost maintenance main problem 
system started system administrator spending hours day keep running improvements far hour day 
self maintaining system fully place expect come couple hours week 
workload believe fully possible operator handle system times size easily 
aspect simplicity modularity tools 
monitoring done small simple programs running locally node adding nodes little effect functionality 
having pairs machines back level redundancy additional overhead associated increasing number nodes 
summary built tb storage system commodity components web image database months 
despite frequent component failures able give illusion users internet system failed 
improving system reduce system administration cost 
believe design scales larger sizes 
acknowledgments bob hart sue fine arts museums san francisco cataloging images making project possible 
research funded darpa state california micro program 
ibm intel donating disk drives pcs respectively 
strategic research network buyer guide 
www com 
john wilkes 
private communication 
joel bartlett wendy bartlett richard carr dave garcia jim gray robert horst robert jardine dan lenoski dix mcguire 
fault tolerance tandem computer systems 
technical report tandem computers 
network appliance www 
com 
satoshi tom anderson david patterson 
large scale distributed storage 
technical report uc berkeley 
fine arts museums san francisco 
art 
www thinker org 
eric anderson dave patterson 
extensible scalable monitoring clusters computers 
proceedings th systems administration conference lisa pages october 
joel bartlett 
nonstop kernel 
acm symposium operating systems principles 
tandem computers white 
nonstop availability nonstop windows nt server systems 
technical report 
tandem computers white 
tandem maintenance diagnostic system 
technical report 
william bolosky tiger video fileserver 
proceedings th international workshop network operating system support digital audio video nossdav april 
william bolosky robert fitzgerald john douceur 
distributed schedule management tiger video fileserver 
acm symposium operating systems principles pages 
edward lee thekkath 
petal distributed virtual disks 
proceedings th international conference architectural support programming languages operating systems pages 
hui hsiao david dewitt 
chained declustering new availability strategy multiprocessor database machines 
technical report university wisconsin june 
thekkath timothy mann edward lee 
frangipani scalable distributed file system 
acm symposium operating systems principles pages 
garth gibson david nagle case network attached secure disks 
technical report carnegie mellon university 
tom anderson michael dahlin neefe david patterson drew roselli randy wang 
serverless network file systems 
acm symposium operating systems principles 
margo seltzer keith bostic marshall mckusick carl staelin 
implementation logstructured file system unix 
proceedings winter usenix pages june 
thomas anderson david culler david patterson team 
case networks workstations 
ieee micro pages february 
elizabeth borowsky richard golding merchant elizabeth shriver john wilkes 
eliminating storage headaches self management 
proceedings osdi october 
sun microsystems white jim waldo 
jini architecture overview 
technical report 
jim gray daniel siewiorek 
high availability computer systems 
ieee computer september 
mary baker 
fast crash recovery distributed file systems ph thesis 
technical report uc berkeley 
satoshi 
interactive tile image viewer 
technical report manuscript available cs berkeley edu td 
satoshi david patterson bob hart 
berkeley san francisco fine arts database 
proceedings fifteenth ieee symposium mass storage systems march 
read write disk pack label 
bsd system manager manual 
reilly associates 
marshall kirk mckusick 
fsck unix file system check program 
bsd system manager manual 
reilly associates 
marshall kirk mckusick 
private communication 
