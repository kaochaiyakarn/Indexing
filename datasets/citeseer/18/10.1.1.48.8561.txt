practical implementations arithmetic coding paul howard jeffrey scott vitter brown university department computer science technical report revised version april technical report 
cs appears image text compression james storer ed kluwer academic publishers norwell ma pages 
shortened version appears proceedings international conference advances communication control victoria british columbia canada october 
practical implementations arithmetic coding paul howard jeffrey scott vitter department computer science brown university providence provide tutorial arithmetic coding showing provides nearly optimal data compression matched probabilistic model 
indicate main disadvantage arithmetic coding slowness give basis fast space efficient approximate arithmetic coder minimal loss compression efficiency 
coder replacement arithmetic table lookups coupled new deterministic probability estimation scheme 
index terms data compression arithmetic coding adaptive modeling analysis algorithms data structures low precision arithmetic 
similar version appears image text compression james storer ed kluwer academic publishers norwell ma 
shortened version appears proceedings international conference advances communication control victoria british columbia canada october 
support provided part nasa graduate student researchers program ngt national science foundation presidential young investigators award matching funds ibm 
additional support provided universities space research association associate membership 
support provided part national science foundation presidential young investigator award ccr matching funds ibm nsf research ccr army research office daal office naval research defense advanced research projects agency contract arpa order 
additional support provided universities space research association associate membership 
data compression arithmetic coding data compressed data symbols 
shannon showed best possible compression code sense minimum average code length output length contains contribution gamma lg bits encoding symbol probability occurrence provide accurate model probability occurrence possible symbol point file arithmetic coding encode symbols occur number bits arithmetic coding encode symbol probability nearly gamma lg encoding nearly optimal probability estimates 
show theorems examples arithmetic coding achieves performance 
point drawbacks arithmetic coding practice propose unified compression system overcoming 
attempting clear false impressions commonly held arithmetic coding offers genuine benefits solution data compression problems 
important advantage arithmetic coding flexibility conjunction model provide sequence event probabilities 
advantage significant large compression gains obtained sophisticated models input data 
models arithmetic coding may adaptive fact number independent models may succession coding single file 
great flexibility results sharp separation coder modeling process 
cost associated flexibility interface model coder simple places considerable time space demands model data structures especially case multi symbol input alphabet 
important advantage arithmetic coding optimality 
arithmetic coding optimal theory nearly optimal practice sense encoding minimal average code length 
optimality important huffman coding nearly optimal cases 
probability single symbol close arithmetic coding give considerably better compression methods 
case highly unbalanced probabilities occurs naturally bilevel black white image coding arise decomposition multi symbol alphabet sequence binary choices 
main disadvantage arithmetic coding tends slow 
shall see full precision form arithmetic coding requires multiplication event implementations multiplications divisions event 
addition model lookup update operations slow input requirements coder 
huffman coding ziv lempel coding faster model represented directly data structures tutorial arithmetic coding coding 
reduces coding efficiency methods narrowing range possible models 
current research arithmetic coding concerns finding approximations increase coding speed compromising compression efficiency 
common method approximation multiplication operation alternative approach table lookups approximate probability estimation 
disadvantage arithmetic coding general produce prefix code 
precludes parallel coding multiple processors 
addition potentially unbounded output delay real time coding problematical critical applications practice delay seldom exceeds symbols major problem 
minor disadvantage need indicate file 
final minor problem arithmetic codes poor error resistance especially adaptive models 
single bit error encoded file causes decoder internal state error making remainder decoded file wrong 
fact drawback adaptive codes including ziv lempel codes adaptive huffman codes 
practice poor error resistance adaptive coding unimportant simply apply appropriate error correction coding encoded file 
complicated solutions appear errors easy detect detection error bits changed errors detected 
overview 
section give tutorial arithmetic coding 
include modeling text compression 
restate important theorems relating optimality arithmetic coding theory practice 
section current research practical ways improving speed arithmetic coding sacrificing compression efficiency 
center research reduced precision arithmetic coder supported efficient data structures text modeling 
tutorial arithmetic coding section explain arithmetic coding works give implementation details treatment witten neal cleary 
point usefulness binary arithmetic coding coding symbol alphabet discuss modeling issue particularly high order markov modeling text compression 
focus encoding decoding process similar 
arithmetic coding implementation basic algorithm 
algorithm encoding file arithmetic coding works conceptually follows arithmetic coding implementation old interval decomposition new interval probability subdivision current interval probability input symbol occurs 

current interval initialized 

symbol file perform steps see subdivide current interval subintervals possible alphabet symbol 
size symbol subinterval proportional estimated probability symbol symbol file model input 
select subinterval corresponding symbol occurs file new current interval 

output bits distinguish final current interval possible final intervals 
length final subinterval clearly equal product probabilities individual symbols probability particular sequence symbols file 
final step uses exactly gamma lg bits distinguish file possible files 
need mechanism indicate file special file symbol coded just external indication file length 
step need compute subinterval corresponding symbol occurs 
need cumulative probabilities pc gamma pn new subinterval pc gamma pn gamma 
need maintain supply cumulative probabilities requires model complicated data structure moffat investigates problem concludes multi symbol alphabet binary search trees twice fast move lists 
example illustrate non adaptive code encoding file containing symbols bbb arbitrary fixed probability estimates eof 
encoding proceeds follows tutorial arithmetic coding current subintervals interval action eof input subdivide subdivide subdivide subdivide eof final interval rounding binary approximately 
uniquely identify interval outputting 
fixed model probability particular file exactly size final interval code length bits gamma lg 
practice output bits 
idea arithmetic coding originated shannon seminal information theory 
rediscovered elias years briefly mentioned 
implementation details 
basic implementation arithmetic coding described major difficulties shrinking current interval requires high precision arithmetic output produced entire file read 
straightforward solution problems output leading bit soon known double length current interval reflects unknown part final interval 
witten neal cleary add clever mechanism preventing current interval shrinking endpoints close straddle 
case know output bit know bit opposite value merely keep track fact expand current interval symmetrically 
follow procedure may repeated number times current interval size longer 
mechanisms incremental transmission fixed precision arithmetic developed years rissanen rubin rissanen langdon guazzo witten neal cleary 
bit idea langdon ibm limits propagation carries additions roughly equivalent follow procedure described 
describe detail coding interval expansion 
process takes place immediately selection subinterval corresponding input symbol 
repeat steps illustrated schematically times possible new subinterval entirely intervals iterating return 
arithmetic coding implementation interval expansion process 
expansion 
interval 
interval 
interval follow case 
new subinterval lies entirely output left previous symbols double size interval expanding right 
new subinterval lies entirely output left previous symbols double size interval expanding left 
new subinterval lies entirely keep track fact output double size interval expanding directions away midpoint 
example show details encoding file example 
tutorial arithmetic coding current subintervals interval action eof input subdivide subdivide output expand subdivide follow expand subdivide eof output expand output expand output expand output expand output follow output sixth line indicates follow procedure keep track knowledge output bit followed opposite opposite bit output ninth line 
encoded file 
clearly current interval contains information preceding inputs information output think coder state 
length current interval state holds gamma lg bits output 
basic method illustrated example state contains information output output 
implementation illustrated example state contains fewer bits output information length current interval 
final state example contains gamma lg bits information 
integer arithmetic 
practice arithmetic done storing current interval sufficiently long integers floating point exact rational numbers 
think example integer interval omitting decimal points 
integers frequency counts estimate symbol probabilities 
subdivision process involves selecting nonoverlapping intervals length lengths approximately proportional counts 
encode symbol need cumulative counts gamma sum counts 
denote alphabet size 
new subinterval gammal gammal 
arithmetic coding implementation discussion continue half open intervals real arithmetic case 
implementations convenient subtract right endpoints closed intervals 
moffat considers calculation cumulative frequency counts large alphabets 
example suppose certain point encoding symbol counts eof current interval full interval 
input symbol cumulative counts new interval gamma gamma increment follow count expand interval midpoint giving 
possible maintain higher precision truncating adjusting avoid overlapping subintervals expansion process complete possible prove tight analytical bound lost compression caused integer arithmetic restated theorem 
practice refinement coding difficult improving compression 
analysis 
prove number theorems code lengths files coded arithmetic coding 
results involve arithmetic coding conjunction various models input discussed section 
note results apply implementations arithmetic coder 
shows integer arithmetic negligible effect code length 
theorem integers range high precision algorithm scaling subrange code length provably bounded ln bits input symbol ideal code length file 
typical value excess code length gamma bit input symbol 
second result shows indicate file encoding special symbol just entire file additional code length negligible 
theorem special file symbol coding file length integers range results additional code length ln lg bits 
extra code length negligible bit input symbol typical byte file 
seldom know exact probabilities process generated input file know errors estimated probabilities affect code length 
estimate extra code length straightforward asymptotic analysis 
average code length symbols produced model state gamma lg tutorial arithmetic coding actual probability ith alphabet symbol estimated probability 
optimal average code length symbols state entropy state gamma lg excess code length gamma gamma expand asymptotically obtain ln corrects similar derivation factor ln omitted 
vanishing linear terms means small errors probabilities coder lead small increases code length 
property coding method uses approximately correct probabilities achieve code length close entropy underlying source 
fact section design class fast approximate arithmetic coders small compression loss 
binary arithmetic coding preceding discussion analysis focused coding multi symbol alphabet principle applies binary alphabet 
useful distinguish cases coder interface model simpler binary alphabet 
coding bilevel images important problem natural symbol alphabet produces probabilities close indicating arithmetic coding obtain compression 
historically arithmetic coding research rissanen langdon ibm focused bilevel images 
coder binary arithmetic coder rissanen extends coder ideas multi symbol alphabets 
text image compression applications multi symbol alphabet natural map possible symbols leaves binary tree encode event traversing tree encoding decision internal node 
model longer maintain produce cumulative probabilities single probability suffices encode decision 
calculating new current interval simplified just endpoint changes decision 
hand usually encode event input symbol new data structure problem maintaining coding trees efficiently excessive space 
smallest average number events coded input symbol occurs tree huffman tree trees minimum average weighted path length maintaining trees dynamically complicated slow 
section new data structure compressed tree suitable binary encoding multi symbol alphabets 
modeling text compression modeling text compression arithmetic coding allows compress file possible model process generated file 
obtain maximum compression file need model efficient way representing learning model 
rissanen calls principle minimum description length principle investigated thoroughly theoretical point view 
allow passes file identify suitable model pass encode optimal coding second pass 
alternative approach allow model adapt characteristics file single pass effect learning model 
adaptive approach advantages practice coding delay need encode model decoder maintain model encoder synchronized fashion 
theorem compare context free coding method pass adaptive method 
pass method exact symbol counts encoded pass second pass symbol count decremented occurs point relative counts reflect correct symbol probabilities remainder file 
adaptive method symbols initial counts add symbol count occurs 
theorem input files adaptive code initial weights gives exactly code length semi adaptive decrementing code input model encoded assumption symbol distributions equally 
see adaptive code incur extra overhead eliminate cost describing model 
adaptive models 
simplest adaptive models rely contexts conditioning probabilities symbol probability just relative frequency part file coded 
need mechanism encoding symbol time frequency easiest way start symbol counts 
average code length input symbol file encoded order adaptive model close order entropy file 
shall see adaptive compression improved advantage locality especially higher order models 
scaling 
problem maintaining symbol counts counts arbitrarily large requiring increased precision arithmetic coder memory store counts 
periodically reducing symbol counts factor keep relative frequencies approximately fixed amount storage count 
process called scaling 
allows lower precision arithmetic possibly hurting compression tutorial arithmetic coding reduced accuracy model 
hand introduces locality recency effect improves compression 
discuss quantify locality effect 
text files find occurrences words clustered part file 
take advantage locality assigning weight occurrences symbol adaptive model 
practice ways ffl periodically restarting model 
discards information effective cormack horspool find gives results growing large dynamic markov models 
ffl sliding window text 
requires excessive computational resources 
ffl recency rank coding 
simple corresponds coarse model recency 
ffl exponential aging giving exponentially increasing weights successive symbols 
moderately difficult implement changing weight increments probability estimation method section uses approximate form technique 
ffl periodic scaling 
simple implement fast effective operation amenable analysis 
computationally desirable property keeping symbol weights small 
effect scaling practical version exponential aging 
analysis scaling 
give precise characterization effect scaling code length terms elegant notion introduce called weighted entropy 
weighted entropy file mth block denoted hm entropy implied probability distribution time computed scaling model described 
prove theorem file compressed arithmetic coding zero order adaptive model scaling 
counts halved rounded sum counts reaches effect divide file blocks length theorem compressed length file 
hm gamma gamma hm gamma lg min modeling text compression table ppm escape probabilities esc symbol probabilities 
number symbols occurred times denoted esc gamma gamma lg entropy initial model hm weighted entropy implied scaling model probability distribution block number different alphabet symbols appear file min smallest number different symbols occur block 
scaling done ensure symbol count easy way round fractional counts higher integer 
show theorem effect negligible 
theorem rounding counts higher integer increases code length file bits input symbol 
compare code lengths scaling find differences small theoretically practice 
high order models 
way obtain substantial improvements compression sophisticated models 
text files increased sophistication invariably takes form conditioning symbol probabilities contexts consisting symbols preceding text 
langdon bell witten cleary moffat proven ziv lempel coding dynamic markov coding method cormack horspool reduced finite context models despite superficial indications contrary 
significant difficulty high order models contexts occur provide reliable symbol probability estimates 
cleary witten deal problem technique called prediction partial matching ppm 
ppm methods maintain models various context lengths orders 
point highest order model symbol occurred current context special escape symbol indicating need drop lower order 
cleary witten specify ad hoc methods called computing probability escape symbol 
moffat implements algorithm proposes third method computing escape probability treats escape event separate symbol symbol occurs time adds escape count new symbol count 
practice compresses better 
appear assumption appearance symbols time fast arithmetic coding file approximately poisson process 
see table formulas probabilities different methods see detailed description ppm method 
section indicate methods provide improved estimation escape probability 
applications arithmetic coding nearly optimal compression performance arithmetic coding proposed enhancement compression methods activities related compression 
output values produced ziv lempel coding uniformly distributed leading researchers suggest arithmetic coding compress output 
compression improved cost slowing algorithm increasing complexity 
lossless image compression performed predictive coding prediction errors follow laplace distribution 
methods tables laplace distribution precomputed arithmetic coding obtain excellent compression ratios grayscale images 
distributions chosen guarantee variance estimate resulting code length exceeds ideal estimate small fixed amount 
especially encoding model parameters necessary encode arbitrarily large non negative integers 
witten note arithmetic coding encode integers distribution 
examples section show encodings integers literature derived low precision arithmetic codes 
point arithmetic coding generate random variables desired distribution produce nearly random bits output random process 
particular easy convert random numbers base convert random bits unknown fixed probability bits probability 
fast arithmetic coding section current research aspects arithmetic coding 
show construction fast reduced precision binary arithmetic coder indicate theoretical construct called ffl partition assist choosing representative set probabilities coder 
introduce data structure call compressed tree efficiently representing alphabet binary tree 
give deterministic algorithm estimating probabilities binary events storing bit locations 
give improved ways handling zero frequency problem symbols occurring context time 
show hashing obtain fast access reduced precision arithmetic coding contexts small loss compression efficiency 
components combined fast space efficient text coder 
reduced precision arithmetic coding noted earlier primary disadvantage arithmetic coding slowness 
seen small errors probability estimates cause small increases code length expect introducing approximations arithmetic coding process controlled way improve coding speed significantly degrading compression performance 
coder ibm time consuming multiplications replaced additions shifts low order bits ignored 
section take different approach approximate arithmetic coding recalling fractional bits characteristic arithmetic coding stored state information coder reduce number possible states replace arithmetic operations table lookups 
fast reduced precision binary arithmetic coder refer quasi arithmetic coding companion develop series examples 
noted compression completely reversible reduced precision merely affects average code length 
number possible states applying interval expansion procedure arithmetic coder integer interval 
reduce number states manageable level precompute state transitions outputs substitute table lookups arithmetic coder 
obvious way reduce number states reduce value computational convenience prefer multiple 
example simplest non trivial coders states 
applying arithmetic coding algorithm straightforward way obtain coding table 
follow output indicates application follow procedure described section 
input input state probf output state output state gamma ff gamma ff ff ff follow follow fast arithmetic coding value cutoff probability ff state clearly 
exact coder subintervals length correspond gamma lg bits output information stored state choose ff lg minimize extra code length 
approximate arithmetic optimal value ff depends distribution probf probf uniformly distributed find analytically excess code length minimized ff gamma 
fortunately amount excess code length sensitive value ff uniform distribution case value gives percent extra code length 
arithmetic coding mandate particular assignment subintervals input symbols required subinterval lengths proportional symbol probabilities decoder assignment encoder 
example uniformly assigned left subinterval symbol 
preventing longer subinterval midpoint possible obtain simpler coder requires follow procedure may fewer states 
example coder assigns right subinterval lines example eliminating need follow procedure example 
input input state probf output state output state gamma ff gamma ff ff ff langdon rissanen suggest identifying symbols probable symbol mps probable symbol lps 
doing combine transitions eliminate states 
example modify example mps lps idea 
able reduce coder just states 
reduced precision arithmetic coding lps input mps input state output state output state ff ff way simplifying arithmetic coder allow subset possible interval subdivisions 
integer arithmetic effect making symbol probabilities approximate especially integer range smaller limiting number subdivisions simply precise 
main benefit arithmetic coding ability code efficiently probabilities close usually want allow pairs unequal probabilities 
example know symbol occurs considerably eliminate transitions example approximately equal probabilities 
unnecessary coder decide transition pair state gives simple reduced precision arithmetic coder 
lps input mps input state output state output state simple code quite useful providing percent improvement unary code representing non negative integers 
encode unary output 
code just derived re encode unary coding treating mps 
resulting code consists bn followed odd 
better slightly complex codes shall see examples follow 
introduce maximally unbalanced subdivision show obtain excellent compression 
suppose current interval 
high subdivide interval gamma indicating gamma gamma gamma 
length current interval gamma subdivision indicates gamma choosing large value including maximally unbalanced subdivision coder ensure symbols appropriately high probability 
example mps 
obtain state code allow maximally unbalanced subdivision state 
fast arithmetic coding lps input mps input state output state output state code re encode unary coded non negative integers bn bits 
effect represent form encode unary bits encode binary 
current interval coincides full interval switch different code 
example derive elias code positive integers maximally unbalanced subdivision technique example doubling full integer range see output bit expand current interval coincides full range 
coder infinite number states state visited 
notation indicate subinterval selected range 
lps input mps input state output state output state 
code corresponds encoding positive integers follows code 
reduced precision arithmetic coding effect represent form encode unary bits encode binary 
essentially elias code requires lg nc bits encode design coder states obtain fine grained set probabilities 
example show state coder obtained letting allowing possible subdivisions 
indicate center probability range practice reasonable division give results 
output symbol indicates application follow procedure 
approximate lps input mps input state output state output state ff ff coder easily programmed extremely fast 
shortcoming average high probability symbols require bit corresponding gamma matter high actual probability design class reduced precision coders 
flexible simple coder design incorporating features just discussed 
choose power 
states coder form fast arithmetic coding number states 
intervals produce output interval expanded 
state include maximally unbalanced subdivision corresponds values gamma gamma include nearly balanced subdivision lose efficiency 
addition locate subdivision points subinterval expansion follows input symbol leaves coder state form choose correspond intermediate values 
simplicity denote state allow interval divided lps occurs output lg bits move state mps occurs simply move state new state output move state 
permitted subdivisions table 
cases additional output expansion may possible 
may necessary include subdivisions coder 
range subdivision lps input mps input states lps mps output state output state gamma gamma ff gamma fff gamma gamma example fifth line indicates states may subdivide interval 
lps occurs perform procedure twice leaves interval gamma output expand interval 
coder constructed procedure small number states state allow estimates near near 
choose large highly probable events require negligible code length keeping number states small allow table lookups arithmetic 
ffl partitions ae partitions section shown possible design binary arithmetic coder admits small number possible probabilities 
section give ffl partitions ae partitions theoretical basis selecting probabilities 
practical considerations limiting choices show reasonable expect choosing probabilities give close optimal compression 
binary alphabet equation compute extra code length resulting estimates gamma actual probabilities gamma respectively 
desired maximum excess code length ffl partition space possible probabilities guarantee approximate probabilities add ffl code length event 
select partitioning probabilities estimated probabilities 
probability encode events probability range compute partition call ffl partition follows 
set 
find value greater ffl 
estimated probability probabilities 
find value greater ffl 
compute step iteration estimate probabilities increment repeat steps reaches 
values symmetrical 
example show ffl partition ffl bit binary input symbol 
range actual probabilities probability probabilities guarantee excess code length exceed bit binary decision coded 
wish limit relative error code length exceed optimal factor ae 
compute ae partitions procedure similar ffl partitions unfortunately process terminate ae partitions finite 
approaches optimal average code length grows small obtain small relative loss close obtain partial ae partition 
fast arithmetic coding example show part ae partition ae maximum relative error percent 
range actual probabilities probability 

practice approximation ffl partition ae partition values maximum probability representable coder 
compressed trees reduced precision arithmetic coder described section symbol alphabet need efficient data structure map symbols sequence binary choices 
consider huffman trees minimize average number binary events encoded input symbol great deal effort required keep probabilities branches near 
arithmetic coding maintaining balance condition unnecessary wastes time 
section compressed tree space efficient data structure complete binary tree 
arithmetic coding allows obtain nearly optimal compression binary events probabilities unequal free represent probability distribution symbol alphabet complete binary tree probability internal node 
tree flattened linearized breadth traversal save space storing probability internal node say probability left branch 
probability stored sufficient precision just byte shall see section high order text models longer contexts occur times different alphabet symbols occur context 
cases linear representation wasteful space requiring gamma nodes regardless number alphabet symbols occur 
including pointers nodes compressed trees steps development compressed tree 
complete binary tree 
linear representation 
compressed tree 
double size 
compressed tree collapse breath linear representation complete binary tree omitting nodes zero probability 
different symbols non zero probability compressed tree representation requires lg gamma nodes 
example suppose probability distribution symbol alphabet symbol probability represent distribution tree rounding probabilities expressing multiples 
show linear representation compressed tree representation 
traversing compressed tree mainly matter keeping track omitted nodes 
process node tree lg gamma levels process node reach desired node level information directly index desired node lowest level 
operations simple involving test fast arithmetic coding increment operations node plus extra operations level 
including capability adding new symbols tree algorithm slightly complicated 
representing estimating probabilities binary coded representation context wish byte probability need probability limited precision 
represent probability node state finite state automaton states 
state indicates probability states indicate size sample estimate probability 
need method estimating probability node binary tree 
leighton rivest pennebaker mitchell describe probabilistic methods 
estimators finite state automata state corresponding probability 
new symbol occurs transition state may occur probability transition depending current state new symbol 
generally transition probability higher lps occurs 
transitions occur adjacent states 
lps causes transition possibly non adjacent state transition mps occurs adjacent state 
give deterministic estimator idea 
estimator input symbol causes transition mps occurs estimated probability maximum value 
probabilities represented states close transitions occur non adjacent states 
transitions selected compute new probability new left branch new old gamma left branch taken old right branch taken smoothing factor 
corresponds exponential aging probability estimate track changing probabilities benefit locality discussed section 
designing probability estimator type choose scaling factor set probabilities represented states 
guided requirements coder lack priori knowledge process generating sequence branches 
note number occurrences small estimates accurate 
laplace law succession gives estimate successes trials offers balance available information allowing random variation data effect gives bayesian improved modeling text compression estimate assuming uniform priori distribution true underlying probability recall values near require accurate estimate value give code length need states probability region 
closer estimate accurate allow arithmetic coder give near optimal compression assign states densely larger unfortunately case estimation means difficult occurrences lps infrequent 
note underlying probability branch coding tree may change time estimate adapt accordingly 
handle small sample cases reserve number states simply count occurrences small equation estimate probabilities 
larger values gamma provide fast convergence extreme values show underlying probability change expected value estimate events gamma converges 
rapid convergence misleading case estimate depending preceding event 
expected value clearly estimator useless 
value near provides resistance random fluctuations input estimate converges slowly initially underlying changes 
careful choice depend detailed analysis performed flajolet related problem approximate counting 
pragmatic decision 
know periodic scaling approximation exponential aging show scaling factor corresponds scaling block size approximately ln gamma 
works scaling choose 
improved modeling text compression obtain fast text compression wish multi symbol extension reduced precision arithmetic coder conjunction model 
ppm idea described section proven effective ad hoc nature escape probability calculation somewhat annoying 
section ad hoc method call complicated principled approach problem 

moffat method widely considered best method estimating escape probabilities 
symbol weight context taken number times occurred far context 
escape event fast arithmetic coding table 
compression figures bits input symbol 
improvement file text 
bib book book news geo obj obj pic trans hashed high order markov models 
occurrence symbol time context treated symbol count 
letter occurs time weight escape count incremented total weight increases 
times total weight increases 
developed new method call similar treatment new symbols consistent adding escape count new symbol count new symbol occurs total weight increases 
compared bell cleary witten corpus including papers described book 
table shows text files compresses consistently bit character better 
compression results differ reported implementation differences versions identical escape probability calculations 
added advantage making analysis tractable making code length independent appearance order symbols context 
indirect probability estimation 
faced situation theoretical basis estimating probability event know factors affect probability 
cases logical effective approach create conditioning classes values factors estimate probability adaptively class 
ppm method know number occurrences state number different alphabet symbols occurred factors affecting esc done experiments combinations conditioning classes group values greater values greater 
experiments third order model symbol occurred previously context length simply bits indicate ascii value symbol 
idea skipping shorter contexts speed space simplicity appears 
simplistic way dropping shorter contexts improved estimation esc gives slightly better compression book longest file bell cleary witten corpus 
expect indirect probability estimation conjunction full multi order ppm mechanism yield substantially improved compression 
hashed high order markov models 
finding contexts ppm method moffat bell give complicated data structures called backward trees vine pointers 
fast access minimal memory usage propose single hashing collision resolution 
expect bucket accumulating statistics unrelated contexts significantly degrade compression performance show case 
worst case symbols colliding contexts bucket mutually disjoint additional code length entropy ensemble probabilities occurrence contexts 
show conceptually dividing bucket disjoint subtrees corresponding various contexts noting cost identifying individual symbol just lc gamma lg cost identifying context occurred plus cost identifying symbol context 
extra cost just lc average extra cost gammap lg maximum value lg buckets contain data contexts extra code length bit input symbol 
fact number colliding contexts bucket large significant symbols bucket representing combination number contexts microcosm entire file bucket average code length approximately equal order entropy file 
hirschberg apply hashing collision resolution similar high order scheme 
shown details implementation arithmetic coding pointed advantages flexibility near optimality main disadvantage slowness developed fast coder reduced precision arithmetic coding gives minimal loss compression efficiency concept ffl partitions find probabilities include coder keep compression loss small 
companion refer fast coding method quasi arithmetic coding give implementation details performance analysis binary multi symbol alphabets 
prove analytically loss compression efficiency compared exact arithmetic coding negligible 
introduce compressed tree new data structure efficiently representing multi symbol alphabet series binary choices 
new deterministic probability estimation scheme allows fast updating model stored compressed tree byte node model provide reduced precision coder probabilities needs 
choosing new methods computing escape probability enables highly effective ppm algorithm hashed markov model keeps space time requirements manageable high order model 
abramson information theory coding mcgraw hill new york ny 
truong lu friedman multipurpose vlsi chip adaptive data compression bilevel images ibm res 
develop 
nov 
bell unifying theory improvements existing approaches text compression univ canterbury ph thesis 
bell moffat note dmc data compression scheme computer journal 
bell cleary witten text compression prentice hall englewood cliffs nj 
bell witten cleary modeling text compression comput 
surveys dec 
bentley sleator tarjan wei locally adaptive data compression scheme comm 
acm apr 
blumer mceliece enyi redundancy generalized huffman codes ieee trans 
inform 
theory sept 
giancarlo bounds redundancy huffman codes ieee trans 
inform 
theory nov 
high efficiency multiplication free approximation arithmetic coding proc 
data compression conference storer reif eds snowbird utah apr 
cormack horspool data compression dynamic markov modelling computer journal dec 
cormack horspool algorithms adaptive huffman codes inform 
process 
lett 
mar 
elias interval recency rank source coding line adaptive variable length schemes ieee trans 
inform 
theory jan 
elias universal codeword sets representations integers ieee trans 
inform 
theory mar 
adaptive system data compression record th asilomar conference circuits systems computers 
ph 
flajolet approximate counting detailed analysis bit 
ph 
flajolet martin probabilistic counting algorithms data base applications inria rapport de recherche june 
gallager variations theme huffman ieee trans 
inform 
theory nov 
guazzo general minimum redundancy source coding algorithm ieee trans 
inform 
theory jan 
hellman joint source channel encoding proc 
seventh hawaii international conf 
system sci 
horspool improving lzw proc 
data compression conference storer reif eds snowbird utah apr 
howard vitter analysis arithmetic coding data compression information processing management 
howard vitter new methods lossless image compression arithmetic coding information processing management 
howard vitter design analysis fast text compression quasi arithmetic coding proc 
data compression conference storer cohn eds snowbird utah mar apr 
huffman method construction minimum redundancy codes proceedings institute radio engineers 
knuth dynamic huffman coding algorithms june 
langdon probabilistic coder algorithms binary source adaptation proc 
data compression conference storer reif eds snowbird utah apr 
langdon note ziv lempel model compressing individual sequences ieee trans 
inform 
theory mar 
langdon rissanen compression black white images arithmetic coding ieee trans 
comm com 
leighton rivest estimating probability finite memory ieee trans 
inform 
theory nov 
hirschberg streamlining context models data compression proc 
data compression conference storer reif eds snowbird utah apr 
miller wegman variations theme ziv lempel combinatorial algorithms words apostolico galil eds nato asi series springer verlag berlin 
mitchell pennebaker optimal hardware software arithmetic coding procedures coder ibm res 
develop 
nov 
moffat predictive text compression past australian computer science communications 
moffat word text compression software practice experience feb 
moffat linear time adaptive arithmetic coding ieee trans 
inform 
theory mar 
moffat implementing ppm data compression scheme ieee trans 
comm com nov 
rissanen wax adaptive model nonstationary sources ibm technical disclosure bulletin apr 
parker conditions optimality huffman algorithm siam comput 
aug 
source coding algorithms fast data compression stanford univ ph thesis 
pennebaker mitchell probability estimation coder ibm res 
develop 
nov 
pennebaker mitchell software implementations coder ibm res 
develop 
nov 
pennebaker mitchell langdon overview basic principles coder adaptive binary arithmetic coder ibm res 
develop 
nov 
rissanen modeling shortest data description automatica 
rissanen universal prior integers estimation minimum description length ann 
statist 

rissanen universal coding information prediction estimation ieee trans 
inform 
theory july 
rissanen langdon universal modeling coding ieee trans 
inform 
theory jan 
rissanen generalized kraft inequality arithmetic coding ibm res 
develop 
may 
rissanen langdon arithmetic coding ibm res 
develop 
mar 
rissanen multiplication free arithmetic code ieee trans 
comm 
feb 
rogers thomborson enhancements ziv lempel data compression dept computer science univ minnesota technical report tr minnesota jan 
rubin arithmetic stream coding fixed precision registers ieee trans 
inform 
theory nov 
ryabko data compression means book stack 
shannon mathematical theory communication bell syst 
tech 
july 
vitter dynamic huffman coding acm trans 
math 
software june appears algorithm collected algorithms acm 
vitter design analysis dynamic huffman codes journal acm oct 
witten bell zero frequency problem estimating probabilities novel events adaptive text compression ieee trans 
inform 
theory july 
witten neal cleary arithmetic coding data compression comm 
acm june 
ziv lempel universal algorithm sequential data compression ieee trans 
inform 
theory may 
ziv lempel compression individual sequences variable rate coding ieee trans 
inform 
theory sept 
