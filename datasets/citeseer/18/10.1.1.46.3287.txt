dynamically forecasting network performance network weather service ucsd technical report tr cs appear cluster computing networks software tools applications rich wolski computer science engineering department university california san diego la jolla ca january network weather service generalizable extensible facility designed provide dynamic resource performance forecasts metacomputing environments 
outline design detail predictive performance forecasts generates 
forecasting methods general focus ability predict tcp ip throughput latency attainable application systems located different sites 
network forecasts needed support scheduling metacomputing software infrastructure develop quality service guarantees 
keywords scheduling metacomputing quality service statistical forecasting network performance monitoring network technology advances resulting improvements interprocess communication speeds possible interconnected separate computer systems high performance computational platform 
effective application scheduling particularly distributed parallel applications fundamental successfully 
supported nsf asc advanced research projects agency ito distributed object computation testbed arpa order 
issued esc ens contract 
email rich cs ucsd edu www cse ucsd edu users rich resources composing shared contention causes load availability vary time 
result performance resource deliver application varies time 
describe distributed service dynamically forecasts performance various networked resources deliver application 
service operates distributed set sensors gathers readings instantaneous conditions 
uses numerical models generate forecasts conditions time frame 
think functionality analogous weather forecasting term service network weather service nws 
developed nws schedulers networked computational environment 
apples scheduling methodology extensive facilities currently implementing versions legion globus nexus 
initial scheduling results nws promising 
focus problem network performance forecasting context scheduling predictive methodologies chosen explore initially 
developed prototype nws forecasts network performance latency bandwidth available cpu percentage machine monitors 
forecasting methods implemented fall categories ffl mean methods estimate sample mean forecast ffl median methods median estimator ffl autoregressive methods 
gauge effectiveness method report mean square prediction error mean percentage prediction error generated method accuracy measures 
mean predictive methods generally yield lower mean square error measures methods better terms mean percentage error best forecasting technique setting difficult predict 
system tracks accuracy prediction error accuracy measure predictors uses exhibiting lowest cumulative error measure moment generate forecast 
way nws automatically identifies best forecasting technique resource 
section section briefly describe structure implementation prototype 
section describes sensory mechanisms section describes forecasting methods currently implemented 
section compare nws measurements corresponding forecasts different network environments 
conclude section evaluation results description research 
structure implementation serve viable tool scheduling network weather service ffl sense resource performance system ffl forecast performance resource ffl disseminate forecast information interested client schedulers 
real world weather service operation nws significantly change conditions attempting forecast 
assume computational network resources system devoted exclusively nws resources constitute possible failure points performance bottlenecks 
view nws limit intrusiveness resource consumption adversely impact performance applications designed serve 
need limit intrusiveness nws influences implementation system forecasting techniques chosen 
problems non intrusive resource monitoring load forecasting pose open research questions separated sensory forecasting functions nws 
resulting modular design intended provide general cpu sensor network link sensor machine machine machine memory sensor sensory subsystem sensor data forecasting subsystem forecasting methods method method method structure network weather service 
facility variety different monitoring forecasting techniques employed easily 
depicts architecture system 
sensory data compiled logically central physically distributed database serve inputs collection forecasting models 
sensor periodically takes performance measurement resource monitoring stores time stamp database 
resulting collection measurements ordered time stamp form time series describing behavior resource taken 
resource characterized time series 
information history priori knowledge resource expected performance response nws forecasting subsystem generates prediction performance resource time frame 
generated current forecast data quality measures describing accuracy mean square prediction error mean percentage prediction error published specifications independent reporting interface 
sensory forecasting reporting functions implemented separate subsystem providing generalizable facility easily extended modified 
sensing nws sensors report observed performance resource able deliver time measurement taken 
network link sensor example reports periodic measurements latency bandwidth particular link 
measurements taken close application level possible goal forecast performance application obtain resource 
units measurement sensor uses depend general demands forecasting models machine monitored execute copy nws server 
depicts monitored hosts monitored region shown shaded 
hosts run copy nws server capable establishing maintaining connection tcp ip current implementation 
administrative client utility controls system may execute machine inside outside monitored network requiring connectivity nws servers 
currently server maintains network performance sensor cpu availability sensor 
servers system share common list hosts monitored tcp port number server attached 
periodically server chooses host list conducts communication experiment host 
experiment round trip time single word packet measured 
resulting value divided yield approximation initial sensory subsystem implementation tcp ip socket functionality provided netperf network performance utility modified code substantially 
netperf proved robust powerful substrate purposes encourage interested visit netperf world wide web site information 
tcp ip sockets nws server nws server nws server nws admin client host host host monitored network systems nws servers running monitored hosts latency start overhead associated communication 
immediately latency estimated initiating server sends predetermined parameterizable quantity data times transfer 
throughput calculated data size divided transfer time equation 
throughput data size data transfer time resulting measure includes overhead necessary initiate tcp ip communication stream significant 
calculate effective throughput rate latency subtracted time recorded data transfer result actual time transfer data see equation 
effective throughput data size data transfer time latency experiment complete latency throughput effective throughput recorded internal database 
server periodically records local cpu availability unix utilities uptime 
available sensor parses output determine percentage time system idle time spent machine executing system space percentage time spent executing user processes number running processes 
measures estimates percentage time system willing devote single application 
available cpu monitor uses uptime manner described local unix utility manual 
periodicity periodicity nws sensors take measurements synchronized external administrative client process 
notice communication experiments conducted strictly control server local clock servers choose test link simultaneously 
nws servers logical application level picture network topology consider links share common medium requiring exclusive access ethernet ones able handle simultaneous communication interference 
servers pass token contains right conduct single experiment 
holding token server free choose experiment wishes conduct 
token assures server may conducting communication experiment time 
central utility operated nws administrator controls rate token may passed server server 
controlling rate administrator control periodicity communication measurements 
note method controlling intrusiveness scale 
token active system time token handled system number systems monitored imposes maximum frequency measurements taken 
small collections machines adequate larger scale systems distributed object computational testbed way need mechanism 
storage requirements storage intrusiveness issue 
forecasting methods discussed section require history measurements 
order bound storage requirements system limit number measurements server allowed maintain fixed parameterized quantity 
server responsible maintaining history measurements takes 
history data collected servers utility human display purposes data remains distributed demanded 
forecasting nws operates set forecasting methods invoke dynamically passing parameters performance measurements taken resource 
section describe methods included current implementation 
new measurement taken passed methods new forecast generated 
forecasting method measurement time prediction method value history value measured value time prediction predicted value method measurement value history finite history measurements forecasts residuals generated previously time method method forecasting method values supplied sensory subsystem treated time series forecasting methods method maintains history previous activity accuracy information 
particular err value gamma prediction gamma error residual associated measurement prediction measurement generated method current implementation generates forecast time measurement taken 
method evaluated new datum available restrict methods implement limited computational complexity 
alternative implementation considering generates forecasts requested client approach may computationally complex methods feasible 
mean methods class predictors investigated uses arithmetic averaging estimate mean value portion measurement history predict value measurement 
running average defined run av value uses average measurement taken time previous measurements predictor measurement taken 
running average considers entire history measurements making forecast weight measurement decreases linearly time 
values better predict measurement average taken fixed length history fixing weight measurement better predictor 
fixed length sliding window average calculated sw av gammak value integer specifying number samples consider window 
note sw av uses measurement predictor 
sw av harchol balter downey indicates useful predictor cpu resources include separate method 
choice sw av may difficult determine priori resource fact may vary time 
set dynamically adapts time series employ gradient descent strategy 
value time err value gamma sw av define adapt av sw av gamma min gamma err err gamma sw av min gamma err err sw av min gamma err err gamma min gamma err err gamma min gamma err err min gamma err err value adjusted time step direction yields lowest error 
measure square error err arbitrarily 
possible measure absolute percentage error initial experiments indicate results similar 
note value carried part history adapt av set reasonable starting value 
arbitrarily restrict predetermined maximum minimum 
setting maximum threshold limits computational complexity predictor minimum value prevents stuck local minimum 
experiments section set 
stochastic gradient recursive prediction error estimators powerful predictive techniques recursive formulations 
example modern implementations tcp ip protocol include dynamic predictor round trip time stochastic gradient filter 
follow exposition technique provided includes description efficient implementation unix kernel 
define grad gamma grad gamma value gain 
choice controls accuracy grad estimates mean value time series lag time converges stable estimate 
grad oscillates randomly true average standard deviation oe grad oe value larger value yield widely varying estimate 
grad converges exponentially time constant true mean 
time series stationary grad mean moves 
convergence rate faster drift mean predictor fail converge 
empirically value works expect study problem finding appropriate 
experimented techniques dynamically adapt fly identify effective method resources currently monitor nws 
median methods median value serve useful predictor particularly measurement sequence contains randomly occurring asymmetric outliers 
presentation techniques follows exposition 
median sliding window fixed length leading edge measurement forecast measurement 
define sort sorted sequence measurement values sort jth value sorted sequence median sort odd sort 
sw av choice may difficult determine 
include adaptive median filter analogous adapt av equation 
adapt med median gamma min gamma err err gamma median min gamma err err median min gamma err err value time err value gamma median determined equation 
median filters attractive reject effects sharply outlying data points impulses forecasts produce 
lack smoothing power averaging methods resulting forecasts considerable amount jitter 
possible combine positive advantages classes methods form ff trimmed mean filter averages central gamma ff values sliding window size ff 
define bff kc window size trimmed mean trim mean gammat gamma sort possible consider gradient adaptation ff manner adapt adapt av adapt med relationship ff obvious 
autoregressive models shown aggregate internet packet traffic effectively modeled autoregressive integrated moving average arima models 
fitting models specific time series requires solution system potentially non linear simultaneous equations making difficult dynamic setting 
fitting purely autoregressive ar model requires solution strictly linear system equations solved recursively levinson recursion 
general form pth order autoregressive model ar value gamma time series stationary sequence fa minimizes error determined solution linear system autocorrelation function series measurements taken 
levinson recursion requires set partial correlation coefficients derived recursively 
burg haddad parsons describe recursive algorithm calculating autoregression coefficients derive current implementation 
omit details algorithm due space constraints implementation follows closely 
algorithm takes time delta measurements prohibitive length entire time series 
calculate fa coefficient sequence sliding window measurements entire series size measurement taken recompute autoregressive coefficients fa previous measurements approximation complete time series 
choice parameters determined computational complexity nws willing tolerate 
making large possible close size history possible yield best fit making large causes execution cost forecast prohibitive 
value set decay autocorrelation function values computed explicitly method autocorrelations computationally expensive compute choose arbitrary fixed values 
implementations plan derive algorithmically estimates autocorrelation values maximum computational complexity threshold 
autoregressive model applicable decay autocorrelation function exponential value set duration decay 
current implementation nws attempt determine suitability ar particular resource 
assumes autoregressive model applicable tracks prediction error ar error lower competing predictors see section 
dynamic predictor selection choosing correct predictive method resource nws monitors difficult 
may particular resource conforms assumptions method period time changes behavior best modeled different method 
attempting choose correct method priori initial implementation maintains predictive methods simultaneously resource 
uses error measure calculated equation produce fitness metric method 
method exhibiting best predictive performance time generate forecast measurement time 
initial implementation nws mean square prediction error mse err mean percentage prediction error mpe err value fitness metrics method time define min mse predictor mse minimum methods time min mpe predictor mpe minimum methods time 
time method yielding lowest mean square prediction error forecast measurement min mse 
similarly forecasting method time yielding lowest mean percentage prediction error min mpe forecast measurement 
scheduling context unclear fitness metric mean square error mean percentage error ultimately yield better schedule 
fitness forecasting technique may application specific 
current system maintains predictor description parameters run avg running average sw avg sliding window avg 
measurement adapt avg adaptive window average max min median median filter adapt med adaptive window median max min trim mean ff trimmed mean ff grad stochastic gradient ar autoregression min mse adaptive minimum mse min mpe adaptive minimum mpe table summary forecasting methods reports mean square error mean percentage error allowing specific scheduler choose 
table summarizes predictive methods implemented fixed values chosen parameters required method 
forecasting network performance section measurements corresponding forecasts latency throughput network connections machines 
experimental period nws monitored predicted cpu availability forecasting methods 
surprisingly network performance proved difficult predict cpu measurements slowly varying comparison 
network performance data illustrate forecasting functionality nws 
monitored tcp ip connectivity hosts shown table prototype nws hour period dynamically forecast latency throughput pair hosts 
chose collection systems study quality location host type ucsd parallel comp 
lab sparc sunos ucsd parallel comp 
lab sparc sunos san diego supercomputer center alpha dec osf california institute technology sunos university oregon power challenge sgi irix national center supercomputer app 
power challenge sgi irix table host locations types operating systems existing internet connectivity respect geographic proximity 
particular interested identifying representative examples connectivity different plausible metacomputing settings 
report data connectivity sparc located parallel computation lab pcl ucsd marked table systems 
intended serve representative example 
pcl machines connected ethernet segment representing intra lab connection 
pcl san diego supercomputer center sdsc located approximately quarter mile apart ucsd campus representing connectivity campus wide setting 
caltech located pasadena california approximately miles north san diego representing intra state connectivity 
connection ucsd university oregon located eugene oregon represents inter state connectivity connection national center supercomputing applications ncsa urbana illinois represents connectivity 
due space constraints show data sparc sending systems 
general connectivity systems symmetric respect sending receiving performance 
believe asymmetry results differences operating system implementations various machines inherent network characteristics working verify conjecture 
interested studying network performance available non privileged user process executing machine standard internet interface experiment 
special networking facilities predictor mse mpe run avg sw avg adapt avg median adapt med trim mean grad ar min mse min mpe table forecasting method error pcl throughput measurements exist sites study vbns processes equally special access rights 
data collected pm wednesday september pm day 
nws initiated experimental period forecasters access previous information start calibration effects visible 
measurements taken roughly second intervals latency measurement immediately preceded throughput measurement 
throughput measured byte data transfer socket buffers sending receiving ends 
report throughput measurements units megabits second mbits latency milliseconds ms 
pcl throughput table summarize accuracy forecasting method forecasting throughput pcl hour measurement period 
stochastic gradient grad predictor generates lowest mean square prediction error trimmed mean trim mean best terms lowest mean percentage prediction error shown boldface table 
min mse shows ability nws determine best predictive method terms mean square error dynamically knowing priori grad perform best 
similarly min mpe shows nws tracking mean percentage error 
methods yield error rates relatively close respective minima series forecasting methods ar perform reasonably 
show time series throughput measurements intra pcl connection 
pcl ethernet segment monitored isolated general internet traffic gateway 
pcl machines displays considerable performance variation 
predictions grad shown min mse 
initial part experiment prediction curves identical 
know ahead time grad accurate min mse predictive method automatically identifies having minimum mean square prediction error 
reason identical mean square error statistics min mse requires time recognize grad best predictor 
shows predictor selection function time min mse 
heavy horizontal lines indicate predictor min mse point time 
dotted vertical lines show predictor switched method 
notice initial start period lasting pm approximately am min mse uses values generated grad remainder experiment 
nws intended continuously available service lengthy calibration start period pose serious problem 
results similar min mpe start switches times identifying trim mean accurate predictor terms mean percentage error 
pm pm am am am pm pm time pm pm am am am pm pm time pm pm am am am pm pm time pcl throughput time series grad predictions min mse predictions pm pm am am am pm pm time run avg sw avg adapt avg grad ar median trim mean adapt med predictor selection min mse predictor mse mpe run avg sw avg adapt avg median adapt med trim mean grad ar min mse min mpe table forecasting method error pcl latency measurements pcl latency accuracy forecasting methods predicting latency pcl shown table 
pcl latency measurements median forecasters generate predictions having lowest mean percentage error nearly lowest mean square error 
run av slightly better median terms mean square error generates little twice mean percentage error versus respectively 
shows time series latency measurements compare predictions generated run av dotted line generated median solid line 
pm pm am am am pm pm time pm pm am am am pm pm time latency time series pcl run av dotted vs median solid contrast throughput time series latency measurements show intermittent outliers departing uniform value ms 
outliers generally form trackable trend duration short differ stable value order magnitude 
median forecasting method reject favor uniform tendency 
outliers constitute longer latencies measurements shorter ms mean method drawn direction outliers 
depicts relationship 
solid line shows forecasts generated median dotted line forecasts run av note changed scale graph difference easier discern 
run av forecasts closer outliers occur run av yields lower square error measure consequently lower mean square error 
run av consistently differs uniform ms value cumulative mean percentage error higher 
error terms squared calculating mean percentage error median accumulate error encounters outlier 
note exhibits poor forecasting performance time series presence outlier indicate outlier follow 
note min mse min mpe correctly identify track best predictor mean square error mean percentage error respectively 
sdsc throughput table shows accuracy throughput forecasts ucsd pcl sdsc 
true pcl throughput measurements grad yields lowest mean square error measure 
best mean percentage error comes adapt med 
show throughput time series predictions adapt med trace window size time figures respectively 
adapt med starts initial window size window eventually settles preset minimum value 
pm pm am am am pm pm time pm pm am am am pm pm time pm pm am am am pm pm time pcl sdsc throughput time series adapt med predictions adapt med window size predictor mse mpe run avg sw avg adapt avg median adapt med trim mean grad ar min mse min mpe table forecasting method error pcl sdsc throughput measurements predictor mse mpe run avg sw avg adapt avg median adapt med trim mean grad ar min mse min mpe table forecasting method error pcl sdsc latency measurements sdsc latency median methods similar results pcl perform best forecasters latency pcl ad sdsc 
table shows accuracy predictors 
median methodologies display lower mean square mean percentage error measures pcl run av yields lowest mean square error 
specifically trim mean achieves slightly smaller mean square error methods ar significantly accurate 
terms mean percentage error median performs slightly better trim mean adapt med 
median predictors general twice accurate mean ones regard mean percentage error 
similar pcl latency measurements latency time series characterized unpredictable outlying deviations relatively fixed uniform tendency 
deviations pm pm am am am pm pm time pcl sdsc latency measurements generally order magnitude greater typical value ms spikes extend ms orders magnitude greater 
deviations typically short sample cases median methods perform better rejecting unpredictable noise 
summary analysis network forecasting performance show forecasting accuracy pcl caltech connectivity tables pcl oregon connectivity tables pcl ncsa tables include measurement data appendix 
show minimum mean square error mean percentage error values table boldface type 
tables summarize performance best predictors network setting 
notice grad best predictor throughput mean predictor mse mpe run avg sw avg adapt avg median adapt med trim mean grad ar min mse min mpe table pcl caltech forecaster error throughput predictor mse mpe run avg sw avg adapt avg median adapt med trim mean grad ar min mse min mpe table pcl caltech forecaster error latency predictor mse mpe run avg sw avg adapt avg median adapt med trim mean grad ar min mse min mpe table pcl oregon forecaster error throughput predictor mse mpe run avg sw avg adapt avg median adapt med trim mean grad ar min mse min mpe table pcl oregon forecaster error latency predictor mse mpe run avg sw avg adapt avg median adapt med trim mean grad ar min mse min mpe table pcl ncsa forecaster error throughput predictor mse mpe run avg sw avg adapt avg median adapt med trim mean grad ar min mse min mpe table pcl ncsa forecaster error latency network connection minimum mse minimum mpe pcl grad trim mean pcl sdsc grad adapt med pcl caltech grad median pcl oregon grad adapt med pcl ncsa table summary best forecasters throughput network connection minimum mse minimum mpe pcl grad median pcl sdsc trim mean median pcl caltech run av median pcl oregon trim mean median pcl ncsa grad median table summary best forecasters latency square error accuracy measure 
fails yield lowest error connection table connection ranked fifth including min mse min mpe ranking 
general mean predictors tend outperform median ones throughput time series study mean square error measure prediction accuracy 
analogously median accurate predictor latency terms mean percentage error set latency measurements 
min mse min mpe correctly track leading predictor case knowing ahead time successful 
notice predictor network performance particularly latency cross country internet throughput measurements 
experiment performs best 
believe result supports reported demonstrate ability autoregressive models correctly reflect aggregate traffic patterns certain wide area network environments 
particular authors analyze packet data taken gateway sdsc nsfnet backbone 
pcl ncsa tcp connection monitored traverses gateway 
measuring effects protocol buffer processing connection expected aggregate packet behavior dominate settings network paths include heavily congested gateways 
pcl ncsa throughput measurements ar performs slightly worse predictor 
performance ar competitive forecasters terms mean square error pcl oregon throughput series 
summarize results noting ffl mean square error accuracy measure judge fitness forecasting method stochastic gradient predictor choice forecasting throughput internet connections ffl mean percentage error accuracy measure sliding window median choice forecasting method latency current internet technology ffl best predictor performance characteristic latency throughput study general obvious varies resource resource ffl dynamically selecting predictive methods successfully track best predictor case yielding forecast error rates close minimum 
predict performance resources metacomputing environment developed network weather service 
operates arbitrary set performance sensors dynamically generates forecasts periodic readings takes 
determining appropriate forecasting method resource priori difficult 
absence perfect generating model best forecasting method particular resource may change time 
illustrate tcp ip throughput latency performance application obtain ucsd parallel computation lab variety geographically dispersed computing sites 
nws able dynamic short term forecasts communication characteristics accuracy forecasts varies site site 
importantly system correctly identify best method fly running tabulation prediction error 
designed system extensible incorporate multitude techniques choose best resource time 
nws formative stages 
plan investigate system incorporate modeling techniques require computationally intensive fitting phase 
arima models described self similarity analysis outlined semi nonparametric techniques discussed provide immediately promising avenues investigation 
discern relationship computational complexity devoted making forecast accuracy 
plan integrate sensory mechanisms described investigate groups forecasts may composed yield higher level performance characteristics 
writing second generation implementations nws underway globus nexus legion metacomputing systems 
versions initially deployed part gusto globus ubiquitous testbed distributed object computational testbed metacomputing testbeds 
plan implementations investigate metacomputing scheduling apples development general quality service mechanisms 
nws part apples project owes existence berman members apples corps ucsd pearls wisdom plentiful enumerate 
chandra schopf ucsd allen downey ucb sdsc comments suggestions criticisms invaluable 
lastly reagan moore sdsc carl kesselman caltech allen sameer suresh university oregon jeff randy sharpe ncsa indispensable insights facilities debugging help 
distributed object computation testbed 
www sdsc edu html 
apples 
www cse ucsd edu groups apples apples html 
basu mukherjee time series models internet traffic 
tech 
rep git cc georgia technology 
berman wolski scheduling perspective application 
proceedings high performance distributed computing conference 
berman wolski schopf shao application level scheduling distributed heterogeneous networks 
proceedings supercomputing 
burg maximum entropy spectral analysis 
phd thesis stanford university 
carter crovella dynamic server selection bandwidth probing wide area networks 
tech 
rep tr boston university 
crovella bestavros self similarity world wide web traffic evidence possible causes 
proceedings acm sigmetrics conference measurement modeling computer systems 
crovella leblanc parallel performance prediction lost cycles analysis 
proceedings supercomputing 
defanti foster papka stevens overview wide area visual supercomputing 
international journal supercomputer applications appear 
defanti foster papka stevens overview wide area visual supercomputing 
international journal supercomputer applications appear 
gallagher wise theoretical analysis properties median filters 
ieee transactions assp december 
gallant tauchen snp program nonparametric time series analysis 
www econ duke edu papers abstracts html 
gallant tauchen estimation conditionally constrained heterogeneous processes asset pricing applications 
econometrica 
globus 
www mcs anl gov globus 
granger forecasting economic time series 
academic press 
grimshaw wulf french weaver reynolds legion logical step nationwide virtual computer 
tech 
rep cs university virginia 
polyzos time series model long term traffic nsfnet backbone 
proceedings ieee international conference communications icc may 
haddad parsons digital signal processing theory applications hardware 
computer science press 
harchol balter downey exploiting process lifetime distributions dynamic load balancing 
proceedings acm sigmetrics conference measurement modeling computer systems 
hollingsworth miller dynamic program instrumentation scalable performance tools 
proceedings 
jacobson congestion avoidance control 
proceedings sigcomm august vol 

keshav control theoretic approach flow control 
proceedings sigcomm august vol 

brown virtual environments distributed computing sc gii testbed hpc challenge applications way 
proceedings supercomputing 
legion 
www cs virginia edu mentat legion legion html 
leland self similar nature ethernet traffic 
ieee acm transactions networking february 
ljung theory practice recursive identification 
mit press 
reed performance measurement intrusion perturbation analysis 
ieee july 
available tech 
report csrd university illinois center supercomputing research development 
reprinted ieee cs press tutorial monitoring debugging distributed realtime systems jeffrey tsai yang eds pp 

netperf 
www cup hp com netperf html 
postel transmission control protocol specification 
arpa working group requests comment ddn network information center sri international menlo park ca rfc 
vbns 
www vbns net 
appendix appendix include throughput latency measurement data tcp ip communication streams sun sparc ucsd pcl sun sparc pcl figures dec alpha san diego supercomputer center figures sun located caltech figures sgi located university oregon figures sgi located national center supercomputing applications figures 
note scale magnitude differs graph latency magnitudes shown figures plotted log scale 
pm pm am am am pm pm time throughput mbits intra pcl throughput measurements pm pm am am am pm pm time intra pcl latency measurements pm pm am am am pm pm time throughput mbits pcl sdsc throughput measurements pm pm am am am pm pm time pcl sdsc latency measurements pm pm am am am pm pm time throughput mbits pcl caltech throughput measurements pm pm am am am pm pm time latency ms pcl caltech latency measurements pm pm am am am pm pm time throughput mbits pcl oregon throughput measurements pm pm am am am pm pm time latency ms pcl oregon latency measurements pm pm am am am pm pm time throughput mbits pcl ncsa throughput measurements pm pm am am am pm pm time latency ms pcl ncsa latency measurements 
