optimal decision trees kristin bennett jennifer blue department mathematical sciences rensselaer polytechnic institute troy ny math report propose extreme point tabu search epts algorithm constructs globally optimal decision trees classification problems 
typically decision tree algorithms greedy 
optimize misclassification error decision sequentially 
non greedy approach minimizes misclassification error decisions tree concurrently 
global tree optimization gto optimize existing decision trees 
capability classification data mining applications avoid overfitting transfer knowledge incorporate domain knowledge maintain existing decision trees 
method works fixing structure decision tree representing set disjunctive linear inequalities 
optimization problem constructed minimizes errors disjunctive linear inequalities 
reduce misclassification error nonlinear error function minimized polyhedral region 
show sufficient restrict search extreme points polyhedral region 
new epts algorithm search extreme points polyhedral region optimal solution 
promising computational results randomly generated real world problems 
key words decision trees tabu search classification machine learning global optimization 
knowledge discovery data mining group department mathematical sciences rensselaer polytechnic institute troy ny 
email rpi edu rpi edu 
material research supported national science foundation 
decision trees proven effective technique classification problems 
training set consisting samples points attributes class 
decision tree constructed discriminate sets 
new decision tree classify points 
tree interpreted rules membership classes 
decision trees readily interpretable logical structure provide insight characteristics classes 
propose non greedy non parametric approach constructing multivariate decision trees fundamentally different greedy approaches 
popular decision tree algorithms greedy 
greedy univariate algorithms cart construct decision attribute time 
greedy multivariate decision tree algorithms construct decisions time linear combinations attributes 
case optimization problem solved decision node determine locally best decision 
decision divides attribute space regions 
decisions constructed recursively regions 
process repeated points region leaf tree class 
approach possible construct tree discriminate disjoint sets 
resulting tree may may reflect underlying characteristics data set 
overfitting occurs tree may classify points 
avoid problem heuristics applied prune decisions tree 
optimization techniques minimize error entire decision tree 
global approach analogous widely back propagation algorithm constructing neural networks 
neural network specifies initial structure number units interconnections 
error function measures error neural network constructed 
decisions multivariate decision tree linear threshold units neural network 
global tree optimization gto initial structure number decision nodes class leaf nodes specified 
propose possible error functions measure error entire decision tree 
different optimization methods frank wolfe extreme point tabu search minimize error tree 
gto combines benefits decision trees neural network methods 
great strengths challenges decision trees logically interpretable constructing combinatorially difficult 
typically greedy methods constructed decision time starting root 
locally globally poor choices decisions node result excessively large trees reflect underlying structure data 
pruning may sufficient compensate overfitting 
problem readily shown multivariate decision trees 
pruning process frequently produces tree consisting single decision 
univariate algorithms appear susceptible problem 
murthy salzburg greedy heuristics worked lookahead algorithms offered little improvement 
believe univariate decision trees degree freedom decision 
problem univariate trees decisions required represent gto performance gto sample problem 
simple linear relations 
multivariate decisions powerful 
greedy methods easily led astray 
gto search best multivariate tree structure 
fixing structure prevents method overfitting data 
example seen 
algorithm gto algorithm applied sample data set points dimensions 
algorithm univariate decisions unable correctly classify points 
gto applied data set initial tree structure correctly classified points 
benefit gto existing trees may optimized 
typically greedy methods reconstruct tree scratch time algorithm run 
ability optimize existing tree useful classification data mining applications 
domain knowledge incorporated initial tree tree optimized 
knowledge transfer achieved starting tree related problem updating existing tree new data available 
gto prune restructure tree initially constructed greedy method 
error function gto customized meet client particular needs 
flexibility method promising 
just explore possibilities 
gto non parametric fundamentally different prior decision tree algorithms 
bayesian parametric approaches strict logical rules tree maintained 
gto idea formulating decision tree set disjunctive linear inequalities 
section show underlying problem finding decision tree fixed structure completely classifies sets equivalent finding solution set disjunctive linear inequalities 
section propose objective functions minimize error disjunctive inequalities 
problem nonlinear nonconvex optimization problem polyhedral region 
section show exist extreme point solutions proposed optimization problems better optimal solutions problems terms number points misclassified 
sections propose optimization algorithms minimizing error disjunctive inequalities traversing extreme point solutions 
frank wolfe algorithm gamma fl gamma fl gamma fl gamma fl gamma fl gamma fl multivariate decision tree decisions fw descent technique stops local minimum encounters 
extreme point tabu search epts global optimization technique 
guaranteed find global minimum robust frank wolfe algorithm 
addition frank wolfe algorithm limited differentiable objective functions 
epts objective function need differentiable continuous 
strong computational results algorithms section 
notation vector dimensional real space denotes th component denote vector components maxfx dot product vectors indicated xw 
outer product 
decision trees disjunctive inequalities goal formulate optimization problem construct decision tree structure recognizes points classes 
key idea multivariate decision tree represented set disjunctive linear inequalities 
find solution set disjunctive linear inequalities tree correctly classifies points 
note structure tree fixed actual decisions 
correspondence decision tree disjunctive inequalities conceptually simple intricate 
consider decision tree decisions shown 
decision tree corresponds linear inequality 
point traverses path root tree classification leaf decision corresponds inequality satisfied 
leaves may belong class 
point satisfies sets inequalities corresponding leaf appropriate class correctly classified 
set disjunctive inequalities satisfied 
wx gamma fl wx gamma fl multivariate decision tree decision sample problems restrict discussion class discrimination problem binary multivariate decision tree 
results generalized problems classes 
sets containing ma mb points respectively 
point real valued attributes 
attributes real valued techniques neural networks mapping symbolic attributes real attributes 
decision consists linear combination attributes 
simple case decision seen th point weights decision fl threshold 
gamma fl point follows left branch tree 
gamma fl point follows right branch tree 
gamma fl convention point follows left branch 
consider situation undesirable count error training 
investigate simple cases decision trees consisting decision decisions 
give formulation general multivariate binary decision trees 
decision tree decision consider simplest case class decision tree consisting single decision left leaf labeled right leaf labeled corresponds linear discriminant shown 
weights decision fl threshold 
decision accurately classifies points exist fl gamma fl points ma decision accurately classifies points gamma fl points mb remove strict inequalities adding constant term 
inequalities gamma fl gamma ma gamma fl mb easily determine polynomial time fl exist single linear program 
notice scaling fl constant case may positive number 
decision tree decisions consider problem tree multiple decisions decision tree 
order points correctly classified leaf nodes inequalities satisfied fa gamma fl gamma gamma fl gamma fa gamma fl gamma fl gamma ma order points correctly classified leaf nodes inequalities satisfied fb gamma fl gamma gamma fl fb gamma fl gamma fl mb fl exist satisfy disjunctive inequalities tree correctly classify points 
general case approach binary multivariate decision tree fixed structure 
trees may arbitrary depth need symmetric 
structure tree specified 
tree decision nodes leaf nodes 
assume decision nodes numbered leaf nodes numbered 
set leaf nodes classified set leaf nodes classified consider path traversed root leaf node 
leaf node define index set decisions right greater branch traversed reach leaf leaf node define index set decisions left branch traversed reach leaf example decision tree values point correctly classified inequalities root leaf node satisfied leaf node class similarly point correctly classified inequalities root leaf node class satisfied 
define correct classification points follows 
definition correct classifications points tree set disjunctive inequalities satisfied order correctly classify points tree fixed structure gamma fl gamma fl gamma ma set disjunctive inequalities satisfied order correctly classify points tree fixed structure gamma fl gamma fl gamma mb exist fl disjunctive inequalities satisfied points classified correctly tree 
general case initial tree structure chosen complete set disjunctive inequalities explicitly defined 
global tree error functions global tree optimization problem gto find feasible feasible solution disjunctive inequalities corresponding decision tree 
propose objectives property minimum objective value zero solution feasible disjunctive inequalities 
disjunctive inequalities feasible problem minimizes function classification error 
clarity discussion decision tree extend error functions general case 
sample case basic idea calculate error point minimize sums errors 
error broken parts error decision error leaf total point error 
decision look inequality satisfied measure violated 
assume point traverse right path greater path decision want gamma fl define error gammaa fl maxf 
note point decision class traverse left right path 
possible errors point decision gamma fl gammaa fl gamma fl gamma gamma fl gamma fl gammab fl gamma fl gamma gamma fl subscript represents traversing path decision represents traversing greater path decision error decision calculated power positive integer 
absolute error calculated 
squared error calculated 

leaf error function decision errors path root leaf 
take sum decision errors path calculate leaf error leaf node 
tree leaferr node leaferr node leaferr node leaferr node wish minimize leaf error point define point error function leaf errors 
possibilities define objective minimize leaf error 
possible objective minimizing leaf error count number points misclassified 
call count error function min fl ma count min leaferr node leaferr node mb count min leaferr node leaferr node count count 
minimum leaf errors zero point correctly classified leaf nodes class 
points correctly classified objective function zero 
number points misclassified 
possible objective minimizing leaf error winner take approach minimizing minimum leaf error point 
call minimum error function min fl ma min leaferr node leaferr node mb min leaferr node leaferr node point correctly classified minimum leaf error class zero 
points classified correctly objective function zero 
sum smallest leaf errors class 
third possible objective minimize product leaf errors class 
call product error function min fl ma leaferr node delta leaferr node mb leaferr node delta leaferr node function zero objective function value points correctly classified 
problems challenging solve 
problems nonconvex local minima 
product error function differentiable 
minimum error count error functions continuous 
simplify objective eliminate plus functions introducing linear constraints 
define nonnegative slack variables bounded leaf error 
objective minimized resulting polyhedral region 
product error problem math programming problem min fl ma leaferr node delta leaferr node mb leaferr node delta leaferr node subject gamma fl gamma fl gamma fl gamma fl gamma fl gamma fl gamma fl gamma fl ma mb similar transformations done count error problem minimum error problem 
formulate problems general tree fixed structure 
general case preceding derivation decision leaf total point errors extended multivariate binary decision tree 
done general case section tree decision nodes leaf nodes 
assume decision nodes numbered leaf nodes numbered 
set leaf nodes classified set leaf nodes classified consider path traversed root leaf node 
leaf node define index set decisions right greater branch traversed reach leaf leaf node define index set decisions left branch traversed reach leaf possible errors decision gamma fl gammaa fl gamma fl gamma gamma fl gamma fl gammab fl gamma fl gamma gamma fl positive integer 
recall absolute error calculated squared error calculated 

subscript represents traversing path decision represents traversing greater path decision leaf error sum decision errors path root leaf 
notation introduced leaf error defined definition leaf error leaf error point class leaf node defined leaferr node gammaa fl gamma fl positive integer 
leaf error point class leaf node defined leaferr node gammab fl gamma fl positive integer 
note leaf error point summands depth leaf tree 
plus function eliminated introducing linear constraints 
objective minimized resulting polyhedral region 
counting number points misclassified optimization problem definition count error problem fixed tree structure count error objective function counts number points misclassified fl min fl ma count min leaferr node mb count min leaferr node count count leaf error defined definition 
equivalent nonlinear programming problem fl min fl ma count min leaferr node mb count min leaferr node subject gamma fl gamma fl gamma fl gamma fl ma mb tree exists structure correctly classifies points problem optimal solution zero 
said formulations minimum error product error problems 
minimum error problem written follows definition minimum error problem fixed tree structure minimum error objective function minimizes smallest leaf error point fl min fl ma min leaferr node mb min leaferr node leaf error defined definition 
equivalent nonlinear programming problem fl min fl ma min leaferr node mb min leaferr node subject gamma fl gamma fl gamma fl gamma fl ma mb previous problems continuous 
product error problem produces continuous objective function differentiable 
product error problem written definition product error problem fixed tree structure product error objective function minimized sum products leaf errors leaf node fl min fl ma leaferr node mb leaferr node leaf error defined definition 
equivalent nonlinear programming problem fl min fl ma leaferr node mb leaferr node subject gamma fl gamma fl gamma fl gamma fl ma mb defined possible error functions minimize error general tree fixed structure 
problems np complete 
constraints linear objectives nonconvex 
justify examining extreme point solutions problems satisfactory 
extreme point solutions section show sufficient consider extreme point solutions different error functions introduced section 
theorem existence better extreme point solutions fl objective value feasible solution fl count error problem 
exists corresponding extreme point solution fl fl fl 
equivalently number points misclassified extreme point solution equal number points misclassified corresponding feasible solution 
proof 
consider feasible solution fl count error problem 
extreme point solution done 
assume extreme point solution 
definition point class correctly classified leaferr node leaf node class constraint implies leaf nodes leaf error zero 
similarly point class correctly classified leaferr node leaf node class constraint implies leaf nodes leaf error zero 
point correctly classified feasible solution fl find zero construction just described call index set form linear problem lp construction known optimal objective value zero 
min fl subject gamma fl gamma fl gamma fl gamma fl ma mb lp put standard form solved lp algorithm simplex method 
exists optimal basic feasible solution fl objective value zero 
solution extreme point 
count error problem lp constraints fl extreme point solution count error problem 
show count objective function value extreme point solution fl better count objective function value solution fl recall count objective function fl min fl ma count min leaferr node mb count min leaferr node count count 
assume points misclassified points correctly classified feasible solution fl count error problem ma mb points correctly classified feasible solution fl extreme point solution fl points classified correctly construction extreme point solution feasible solution 
optimized lp variables index set known zero valued feasible solution fl variables index set zero optimal extreme point solution lp 
points correctly classified feasible solution fl count error problem correctly classified extreme point solution fl lp 
extreme point solution points classified correctly feasible solution fl equivalently fl fl 
corollaries follow directly proof theorem 
corollary existence extreme point solution count error problem count error problem extreme point optimal solution 
points separable tree structure minimum error product error problems optimal extreme point solutions 
corollary zero objective value extreme point solution minimum error problem optimal objective value minimum error problem zero problem extreme point solution 
proof 
note optimal objective value zero minimum error problem implies points classified correctly points misclassified 
follows directly proof theorem exists extreme point solution problem 
corollary zero objective value extreme point solution product error problem optimal objective value product error problem zero problem extreme point solution 
points separable tree structure minimum error product error problems may optimal extreme point solution 
theorem know exists extreme point terms number points misclassified better optimal solution minimum error product error problems 
corollary better extreme point exists minimum error problem optimal solution fl minimum error problem exists extreme point solution fl number points misclassified extreme point solution equal number points misclassified corresponding feasible solution 
corollary better extreme point exists product error problem optimal solution fl product error problem exists extreme point solution fl number points misclassified extreme point solution equal number points misclassified corresponding feasible solution 
quality possessing extreme point solutions suggests problems solved algorithms traverse vertices 
finitely extreme points polyhedral region compared infinite number values possible fl 
sections describe algorithms exploring vertices frank wolfe algorithm extreme point tabu search algorithm 
optimization algorithms gto specialized algorithms developed searching extreme points polyhedral regions 
take advantage numerically efficient methods representing extreme points developed simplex method linear programming 
frank wolfe algorithm fw nonlinear problems solved series linear programs created linearizing objective function 
frank wolfe method successfully applied product error problem 
frank wolfe algorithm descent method stops local minimum encountered limited differentiable functions 
robust approach nondifferentiable objectives count objective 
developed extreme point tabu search epts algorithm 
brief review fw algorithm discuss epts 
frank wolfe algorithm frank wolfe algorithm applied product error problem 
consider general problem minimizing convex set differentiable 
frank wolfe algorithm problem algorithm frank wolfe algorithm start compute follows 
ffl arg vertex min ffl ffl gamma arg min gamma applied product error problem algorithm terminates point satisfying minimum principle necessary optimality condition gamma accumulation point sequence fx satisfies minimum principle 
fw gets stuck local minima apply nondifferentiable functions developed heuristic search approach 
extreme point tabu search developed extreme point tabu search epts algorithm solve gto problem 
tabu search ts heuristic achieved great success wide variety practical optimization problems 
extreme point tabu search previously applied extreme point tabu search problems 
basic ts search algorithm described 
point search space neighborhood defined 
algorithm moves best neighbor current solution tabu 
best neighbor tabu exceeds aspiration criteria move may taken tabu 
dynamically changing tabu lists neighborhoods help nonmonotonic algorithm move local minimum continue searching better solutions cycling 
basic tabu search 
find initial starting point 

iteration limit exceeded 

move chosen find best neighbor 
tabu take move 
tabu aspiration criteria met take move 
consider best neighbor possible move 

go step extreme point tabu search epts extension algorithm described 
versions tabu search applied extreme points 
description features algorithm 
algorithm utilizes recency frequency memory oscillates local improvement diversification phases 
resulting algorithm summarized algorithm 
epts tabu search extreme points optimization problem linear constraints general form min subject ax theta matrix 
standard procedures exist transforming problems linear inequalities unconstrained variables format 
objective function need linear continuous differentiable 
polyhedron formed linear constraints 
gammam 
extreme points 
extreme point polyhedral region formed constraints corresponds basic feasible solution 
basic feasible solution consists variables form basis 
remaining nonbasic variables set zero 
nonbasic variable selected basic ratio test select basic variable move basis 
pivot swaps incoming outgoing variables 
epts neighbors adjacent extreme points defined nonbasic variables 
pivoting variables move extreme point neighboring extreme point 
initial starting point basic feasible solution problem 
fred glover university colorado suggesting tabu search problem 
best neighbor move smallest objective function value 
number adjacent extreme points cost function evaluation quite large candidate list limit number function evaluations performed selecting move 
candidate list consists improving pivots identified entering variable iteration 
possible moves candidate list evaluated improving move aspiration criterion satisfied 
selected move removed candidate list 
improving non tabu moves candidate list 
improving moves tabu move taken 
candidate list original length 
choice variables basis uniquely determines extreme point memory structures need track variables basis 
recency memory iteration number recorded variable enters exits basis 
frequency memory keep count number times variable basis 
increment count variables basis iteration just critical events suggested 
explored critical event strategy enhance quality results 
best solution far terms objective function aspiration criterion 
number iterations variable remains tabu called tabu tenure 
moves tabu ways 
nonbasic variable required reenter basis tabu tenure expired move tabu 
move may tabu basic variable required leave basis tabu tenure expired 
tabu tenure nonbasic variables longer basic variables number possible entering variables larger exiting variables 
epts oscillates local improvement mode diversification mode 
local improvement mode objective function evaluate quality move 
diversification strategy variation approach suggested 
frequency penalty objective function force algorithm unexplored areas search space penalty ae iteration basis frequency belongs set indices variables current basis original objective function value ae large penalty constant iteration number current iteration frequency count number times variable appeared basis 
ranking adjacent extreme points iteration need calculate penalty ae iteration frequency entering gamma frequency exiting entering index entering variable exiting index departing variable sum frequencies variables old basis 
practice large constant provided sufficiently large avoid negative values penalty 
algorithm starts local improvement mode original objective function 
objective function values improved significantly iterations algorithm switches diversification mode 
mode objective function values obtained penalty 
epts continues diversification mode maximum number diversification iterations reached 
say objective improved changed ffi iterations 
algorithm extreme point tabu search start initial basic feasible solution problem 

start local improvement mode original objective 

iteration limit exceeded solution optimal 

local improvement mode progress switch diversification mode penalized frequency objective 
diversification mode maximum number diversification steps reached switch local improvement mode original objective 

move chosen candidate list small moves tabu candidate list 
candidate list just consider best move list find improving move candidate list 
tabu take move 
tabu aspiration criterion met take move 
moves tabu candidate list just take best tabu move 

perform move update frequency recency memories 

go step 
epts algorithm tabu search extreme points polyhedron 
algorithm applied problem formulated optimization problem linear constraints 
gto problem just problem epts applies 
computational results assess effectiveness global tree optimization performed different computational experiments 
experiment tried different error functions optimization methods solving gto problem 
randomly generated data known solutions determine globally optimal solution 
results experiment applied best gto methods wider set randomly generated real world problems 
algorithms quinlan baseline comparison powerful popular greedy univariate decision tree algorithm perform problem 
keep factors constant possible tree decisions gto 
methods described applicable general trees 
random data created generating decisions node decision tree 
weight threshold uniformly generated 
points randomly generated unit cube classified generated tree 
training set points generated testing set points 
different formulations gto investigated product error problem minimum error problem count error problem 
epts algorithm optimize formulations 
fw algorithm applied product error problem remaining problems differentiable 
results count error problem uniformly bad 
epts algorithm count error function performs poorly frequently moving adjacent extreme point change number points misclassified 
epts assess moves better 
results reported count error problem 
linear programming package minos implement fw epts 
fw implemented standard linear programming subroutines provided minos 
minos customized epts select pivots taken 
parameter setting epts algorithm chosen experimentation 
varied parameters function number variables problem 
objective changed iterations frequency moves taken 
tabu tenure nonbasic variables set basic variables tabu tenure nonbasic variables 
iteration limit data set 
starting point epts fw algorithms initial tree generated greedy decision tree algorithm 
linear program recursively construct decisions 
tree pruned decisions 
epts fw started random starting point starting point worked better 
results randomly generated data dimensions trained points tested points 
training set testing set errors reported 
fw outperformed training testing sets 
epts outperformed fw training testing sets 
averaged decisions tree solutions dimension problems respectively 
results fw epts algorithms gto formulation fixed decisions 
fw epts perform training testing set errors multivariate decisions univariate decisions 
product error function optimized epts performed best methods tested 
note method consistently achieved accuracy training set solution existed 
surprising fw epts optimal solution underlying problem np complete 
smallest gto problem solved dimensions training points order extreme points 
largest gto problem solved dimensions points dimension percent errors training set error points fw epts epts dimension percent errors testing set error points comparison methods fw epts randomly generated problems 
starting point fw epts 
epts results minimum error epts product error epts problems decision tree structure 
average training testing set error percent number method decisions data set dimension points set fw epts gto generated train test generated train test generated train test heart train test cancer train test diabetes train test liver train test table comparison classification error methods frank wolfe epts 
product error function fw epts decision tree structure seen 
order extreme points 
second experiment gto evaluated larger random problems real world datasets 
real world data consisted bupa liver disease dataset liver pima indians diabetes dataset diabetes wisconsin breast cancer database cancer cleveland heart disease database heart 
fold cross validation real life problems 
dataset divided parts 
training sets data testing done remaining 
repeated times leaving different test set run 
generated data sets pairs training testing data sets generated case dimensions points training set points testing set 
results averaged 
results second experiment summarized table 
minimum product error performed uniformly better experiment results minimum product error optimized fw epts shown 
dataset gto methods achieved better testing set accuracy 
trees gto dramatically smaller terms number decisions 
multivariate decisions approach gto produces trees arguably interpretable trees produced 
epts method performed better fw problems 
suggests hybrid approach datasets available machine learning repository university california irvine www ics uci edu mlearn machine learning html 
combining approaches may better 
fact approach investigated 
recall decision tree decisions gto datasets 
tree structures may better reflect underlying structure problems yield better results gto 
proposed family methods formulating decision tree construction optimization problem 
gto optimize decision trees maintaining logical structure 
greedy methods gto optimizes decisions multivariate decision tree concurrently 
multivariate decision tree represented set disjunctive linear inequalities 
characterized objective functions minimize infeasibilities disjunctive linear inequalities classification error 
error formulations proved extreme point solution exists better optimal solution terms number points misclassified 
methods searching extreme points examined frank wolfe algorithm new extreme point tabu search approach 
epts general purpose search algorithm problems extreme point solutions desired 
prior approaches epts nondifferentiable discontinuous objective function formulations 
computational results show gto methods performed better datasets attempted 
computationally gto method product error function optimized epts worked best 
gto great potential technique data mining practical classification problems 
techniques described applied size decision tree 
gto greedy algorithms construct prune trees 
incorporating domain knowledge transferring knowledge applications 
epts general purpose search algorithm create new error functions reflect applicationspecific criteria objectives ultimate user decision tree 
investigated family nonparametric error objective functions 
gto optimized epts technique adapted parametric formulations problem 

tabu search general zero integer programs pivot complement heuristic 
orsa journal computing 
bennett 
decision tree construction linear programming 
evans editor proceedings th midwest artificial intelligence cognitive science society conference pages illinois 
bennett 
global tree optimization non greedy decision tree algorithm 
computing science statistics 
bennett 
optimal decision trees multilinear programming 
manuscript rensselaer polytechnic institute troy new york 
bennett bredensteiner 
parametric optimization method machine learning 
math report rensselaer polytechnic institute troy new york 
appear informs journal computing 
bennett mangasarian 
robust linear programming discrimination linearly inseparable sets 
optimization methods software 
bennett mangasarian 
bilinear separation sets space 
computational optimization applications 
blue bennett 
hybrid extreme point tabu search 
math report rensselaer polytechnic institute troy ny 
appear european journal operations research 
breiman friedman olshen stone 
classification regression trees 
wadsworth international california 
brodley utgoff 
multivariate decision trees 
machine learning 
buntine 
learning classification trees 
artificial intelligence frontiers statistics ai statistics iii pages london 
chapman hall 
das goodrich 
complexity optimization problems dimensional convex polyhedra decision trees 
workshop algorithms data structures wads 
schmid sandhu guppy lee 
international application new probability algorithm diagnosis coronary artery disease 
american journal cardiology 
glover 
tabu search part orsa journal computing 
glover 
tabu search fundamentals uses 
technical report school business university colorado boulder colorado 
glover 
probabilistic tabu search zero mixed integer programming problems 
manuscript school business university colorado 
rivest 
constructing optimal binary decision trees np complete 
information processing letters 
jordan 
statistical approach decision tree modeling 
warmuth editor proceedings seventh annual acm conference computational learning theory new york 
acm press 
jordan jacobs 
hierarchical mixtures experts em algorithm 
neural computation 
stor tabu search pivot complement framework 
international transactions operations research 
megiddo 
complexity polyhedral separability 
discrete computational geometry 
mingers 
empirical comparison pruning methods decision tree induction 
machine learning 
murtagh saunders 
minos user guide 
technical report sol stanford university 
murthy kasif salzberg beigel 
oc randomized induction oblique decision trees 
proceedings eleventh national conference artificial intelligence pages boston ma 
mit press 
murthy salzburg 
decision tree induction effective greedy heuristic proceedings international conference knowledge discovery data mining 
murthy salzburg 
lookahead pathology decision tree induction 
proceedings fourteenth intl 
joint conference 
artificial intelligence 
murty 
linear programming 
wiley new york 
murty 
linear programming 
john wiley sons new york new york 
quinlan 
simplifying decision trees 
international journal man machine studies 
quinlan 
programs machine learning 
morgan kaufmann 
rumelhart hinton williams 
learning internal representations 
rumelhart mcclelland editors parallel distributed processing pages cambridge massachusetts 
mit press 
smyth gray fayyad 
retrofitting decision tree classifiers kernel density estimation 
proceedings twelfth international conference machine learning pages amherst ma 
street 
cancer diagnosis prognosis linear programming machine learning 
technical report computer sciences department university wisconsin madison wisconsin august 
ph thesis 
sun mckeown 
tabu search applied general fixed charge problem 
annals operations research 
wolberg mangasarian 
method pattern separation medical diagnosis applied breast 
proceedings national academy sciences 
