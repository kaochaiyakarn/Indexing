scam copy detection mechanism digital documents narayanan shivakumar hector garcia molina department computer science stanford university stanford ca cs stanford edu copy detection digital libraries may provide necessary guarantees publishers services offer valuable line data 
consider case registration server maintains registered documents new documents checked overlap 
new scheme detecting copies comparing word frequency occurrences new document registered documents 
report experimental comparison proposed scheme cops detection scheme sentence overlap 
tests involve comparisons netnews articles show general new scheme performs better detecting documents partial overlap 
keywords copy detection plagiarism registration ser ver databases 
digital library provides users line access digitized news articles books information 
material supported national science foundation cooperative agreement iri 
funding cooperative agreement provided arpa nasa industrial partners stanford digital libraries project 
opinions finding recommendations expressed material author necessarily reflect views national science foundation sponsors 
digital equipment 
environment user may easily redistribute digital information bulletin boards mailing lists 
problem solved publishers authors place valuable information digital libraries 
existing techniques address problem fall categories copy prevention copy detection 
copy prevention schemes include physical isolation information placing stand cd rom system specialpurpose hardware authorization active documents essentially documents encapsulated programs 
believe prevention techniques may cumbersome may get way honest user may difficult share information 
furthermore prevention schemes documents may recorded software emulators 
approach place restrictions distribution documents detect illegal copies 
detection schemes fall categories signature registration 
signature schemes signature added document signature trace origins document 
example popular approach incorporate watermarks word spacings checksum documents 
signature schemes weaknesses signatures removed automatically leading untraceable documents useful detecting partial overlap 
reasons advocate registration copy detection schemes 
schemes original documents registered stored repository 
subsequent documents produced compared pre registered documents partial complete overlap 
check initiated person program committee member checking conference submission overlaps significantly previous papers automatically program bulletin boards electronic mail gateway checking messages going see include copies copyrighted articles 
repository registered documents compacted variety ways periodically distributed mail gateways bulletin boards checks done locally 
application registration copy detection filtering duplicate messages newsgroups mailing lists 
number ways detect duplication registered documents 
cops registered documents broken sentences sequences sentences stored registration server 
subsequent query documents broken way compared registered documents 
query document shares threshold matching sentences sequences sentences registered document user notified 
scheme problem finding similar files addressed 
mechanism works selecting words anchors computing checksums window characters comparison 
mainly intended file management applications detection files similar detection small text overlaps 
registration schemes broken 
example cops user modify large number sentences adding changing word rendering new document untraceable original 
requires substantial manual reason believe registration copy detection superior signature schemes 
cops shown problems 
particular difficulties detecting sentences 
equations figures abbreviations confuse 
checking overlap involves random probes registration database expensive 
reasons explored alternative schemes 
comparison scheme word occurrence frequencies documents 
conceptually compute vector gives frequency possible word occurs new document 
compare vector similar vectors database registered documents 
similar information retrieval ir systems compute document similarities new similarity measure accurately characterizes copy overlap traditional ir systems look semantic similarity 
schemes proposed enhance ir schemes signature files lexical analysis stemming algorithms thesaurus ranking algorithms 
approach ir schemes orthogonal model schemes enhance document comparison mechanism 
scheme words easier detect sentences may accurate especially informal documents 
believe word access patterns locality sentence access patterns may lead improved performance cases 
main motivation choosing words sentence mechanisms cops detect partial sentence overlaps 
believe word schemes may superior sentence mechanisms detecting plagiarism documents 
support claims results comparing cops prototype scam stanford copy analysis mechanism theta netnews article pairs show general scam performs better cops detecting instances plagiarism 
note scam reports false positives cops false positives pairs documents reported possible instances plagiarism 
compare scam traditional vector ir scheme netnews articles show scam performs better detecting document overlaps 
copy detection preliminaries section architecture generic copy detection server introduce relevant documents registered chunker insert compare register stream documents generic copy detection server terminology 
give brief summary issues need considered building copy detection server data structures textual units comparison 
copy detection server architecture see architecture generic copy detection server repository registered documents 
repository shown centralized practice may distributed 
define chunking document process breaking document primitive units sentences words overlapping sentences 
documents registered chunked inserted repository 
new documents arrive chunked units compared pre registered documents overlap 
subsequent sections consider different chunking units document similarity measures 
represent vocabulary chunks set occurrences distinct chunks registered documents 
refer th chunk vocabulary 
size vocabulary number distinct chunks inverted index storage propose inverted index structure traditional ir systems storing chunks registered documents 
index chunks document document document index chunks inverted index storage mechanism 
vocabulary constructed maintained registration time 
entry chunk points set postings indicate documents chunk occurs 
posting chunk attributes frequency unique identifier registered document frequency number occurrences document id 
illustrate index structure registered documents 
letters represent chunks documents constitute vocabulary 
instance chunk postings representing occurs document twice document 
document compared pre registered documents chunks looked registered document index 
means documents overlap chunk level considered index mechanism 
total number lookups index number distinct chunks occur document units chunking defined earlier chunking involves breaking document primitive units paragraphs sentences words overlapping sentences 
unit chunking chosen copy detection critical shapes subsequent overlap search cost storage cost outlined 
ffl similarity level bigger chunking unit lower probability matching unrelated documents 
instance unrelated documents may sentence research funded nsf part paragraph 
chunking unit paragraph documents probably detected overlap detected chunking unit sentence 
hand bigger chunking unit higher probability missing actual overlaps 
instance consider paragraphs share identical sentences 
paragraph chunking match detected sentence chunking possible units detected matching 
ffl search cost larger chunk higher potential number distinct chunks stored 
instance collection documents grows expect number distinct sentences stored higher number distinct words 
certain point number new words introduced vocabulary low opposed near linear growth sentences paragraphs 
see potential size chunk index higher chunking unit chosen larger 
course number postings chunk larger chunking unit small words 
see advantage small chunking units 
small chunking unit increases locality 
documents relatively small working set words sentences 
consider frequency distribution words follow zipf law 
words ranked non increasing order frequencies probability word rank occurs assume vocabulary words words constitute nearly actual occurrences words increasing effects 
retaining popular words associated postings main memory may able reduce number accesses disk resident portion index 
sentence chunking expect access pattern random due large size sentence vocabulary 
investigate words unit chunking opposed sentence chunking cops 
argued word chunking may lead locality comparisons 
addition word chunking potential detect finer partial sentence overlap may especially important informal documents may clear sentence structure 
discussed earlier cops problems detecting sentence boundaries 
word chunking need determine scheme comparing documents 
recall sentence chunking comparison straightforward sentences document appear overlap 
unfortunately simple scheme breaks words fact words necessarily mean overlap 
section propose scheme relative frequency words empirically effective 
overlap measures traditional ir schemes queries arrive users query compared documents measure relevance document query obtained 
similarly need establish metric measures overlap incoming document pre registered document 
section consider popular model ir systems termed vector space model vsm relates documents queries see directly applicable copy detection 
propose relative frequency model rfm presents better framework detecting overlaps 
discussion refer generic docu ment registered new 
define occurrence vector listing chunks size frequency vector number occurrences chunk sim denote similarity measure documents computed 
illustrate similarity computations consider registered document new document compared denotes number occurrences chunk document 
assume vocabulary fa hg 
expect copy detection scheme report quite similar exact replicas somewhat similar low values similar high significant overlap vector space model popular model ir domain vsm model 
query corresponding weights dot product weighted occurrence vector query stored document computed dot product value exceeds certain threshold document flagged match query 
common weighting scheme normalized frequency count 
apply measure copy detection example normalized frequency vectors 


similarity sim 
similarly sim sim sim 
overlap significant overlap values reported acceptable 
popular weighting measure cosine similarity measure defines relevance document query sim ff ff ff ff weight associated occurence th chunk 
intuitively higher frequency word word contributes matching similarities 
measure example assume uniform weights words ff find sim sim 
computation un normalized frequency vectors result normalized 
case metric appears 
unfortunately sim 
means cosine measure independent actual number occurrences document unacceptable copy detection 
need metric gives decreasing similarity measure increases 
sim fairly low value considering entire registered document 
need metric detect subset overlaps instances plagiarism 
relative frequency model earlier examples see cosine similarity measure works word frequencies similar magnitudes magnitudes differ significantly 
properties cosine similarity measure remove insensitivity word frequency magnitudes define measure uses relative frequencies words indicators similar word usage combines cosine similarity measure 
define closeness set contain words similar number occurrences documents 
word satisfies condition ffl gamma ffl user tunable parameter 
zero say closeness condition satisfied 
notice word occurs number times documents occurs closeness set irrespective value ffl 
example measure computes ffl gamma ffl gamma 
ffl considered close closeness set 
intuitively closeness set determines set words extent documents forms common signature document pair ffl tolerance factor computing set 
define subset measure document subset document subset ff ff expression computes subset measure document pair considering close words 
note measure similar cosine similarity measure 
main motivation measure values reported symmetric cosine measure low document may subset document instance sim 
subset measure avoids problem normalizing numerator regular cosine measure respect document 
define similarity measure documents sim subset sim set sim 
extra information gathered sim computed greater documents denoted related anyway 
set maximum value merely able express similarity value range 
intuitively components new similarity measure fit follows 
value ffl leeway determining words computing subset measure document pair 
similarity documents determined higher pair wise subset measure maximum similarity value high values registered documents subset superset incoming document 
mentioned earlier feature desirable copy detection schemes missing traditional ir metrics 
examples set ff current implementation assumes uniform weighting words 
illustrate ffl get fa bg sim maxf 
get sim sim sim sim 
notice sim values decrease increases desired done original cosine measure 
sim high value indicating overlap ffl sim sim sim unchanged 
sim 
general similarity value drops increases difference count needs larger similarity drops 
general high value ffl increases tolerance level flagging common words partially overlapping documents 
increases chances matching unrelated documents false positives 
low value ffl decrease false positives decrease ability detect minor overlaps 
important question arises choose value ffl avoids missing partial overlaps reporting unrelated documents similar 
section address question empirically studying collection netnews articles 
experiments section define comparison tests documents empirical results comparing word chunking scam sentence chunking scheme cops 
highlight outlined disadvantages traditional ir measures subsequently results comparing document similarity model cosine similarity measure 
experiments netnews articles headers removed document set 
registered articles compared overlaps 
document comparison values document pair 
performed tests set conventional text documents draft versions conference papers journal papers written research group 
report results brevity 
general observed similar results report net news articles 
experiments value ffl scam set practice 
question consider cops scam differ documents report overlap 
show overlap values reported cops corresponding distribution values reported scam 
table comparing scam ir similar table 
readers convenience added super scripts certain elements tables shall refer 
instance cops reports entries overlap values 
documents scam reports entries range overlap 
table clear cops scam agree percentage diagonal elements document pairs 
significant differences documents report overlaps 
instance scam believes document pairs overlap cops reports overlap 
believe scam cops correct reported overlap value 
sampled document pairs manually category confirmed reasonable assumption 
scam cops differ significantly reported overlap document comparisons 
investigate system correct cases 
manually examined document pairs schemes differ 
notion correctness system scam cops depends ultimate goal goal specified manual test human decides pair documents involve plagiarism substantial overlap instance 
call possible manual tests document target tests 
goal scam cops predict outcome 
consider different 
document includes parts article denote article pair satisfied plagiarism test 
imply malicious copied text 

subset document completely included document possibly interspersed text denote document pair satisfied subset test 

copies documents appear exact copies denote article pair satisfied copies test 

related documents appear common thread relating denoted article pair satisfied related test 
questions non exclusive tests satisfied article pair 
general tests satisfied fourth test satisfied 
instances fourth test marked marked cases happened article judged response included part article 
general different humans may different responses subjective plagiarism related 
results described considered illustrative absolute sense 
figures results comparing scam cops differing document pairs numbering 
subsequent tables simplified table structure clarity 
document pairs similarity values classified lots full 
consider results document pairs satisfied dtt 
entry denotes document pairs denoted human instances plagiarism 
entry denotes cops reported documents substantial lots overlap 
similarly denotes scam reported documents identical copies 
results document pairs satisfy human dtt 
entry indicates document pairs denoted human instances plagiarism entry indicates scam reported documents overlap 
stated earlier ultimate goal scam cops able predict outcome cops total distribution scam results respect cops netnews articles 
test system satisfy test lots full cops scam subset cops scam copies cops scam related cops scam detection test comparison scam cops netnews articles 
test system satisfy test lots full cops scam subset cops scam copies cops scam related cops scam false positive test comparison scam cops netnews articles 
test system satisfy test lots full ir scam subset ir scam copies ir scam related ir scam detection test comparison scam ir netnews articles 
test system satisfy test lots full ir scam subset ir scam copies ir scam related ir scam false positive test comparison scam ir netnews articles 
described human tests 
threshold chosen value reported scheme ideally document pairs satisfy dtt scheme scam cops report value greater document pairs satisfy dtt scheme report value words ideal copy detection system report overlap values follows 

detection comparison documents reported values greater 
false positive comparison documents reported values instance assume copies chose decision threshold lots full overlap 
case scam success rate detection test cases documents copies reported overlap greater threshold 
similarly scam nearly success rate false positive tests cases documents copies overlap threshold 
cops divide clear copies dtt choose boundary cops success detection test nearly success false positive test 
choose lots boundary cops success detection test success false positive test 
similarly rest boundaries 
notice general scam performs better cops detecting document overlaps 
instance set threshold plagiarism test scam error documents reporting instances plagiarism cops detect documents disagreement set 
similarly threshold lots full cops detect exact copies article scam success rate copies 
enhanced detection document overlaps scam price higher percentage false positives 
example say set threshold plagiarism test 
case cops correctly report document pairs instances plagiarism 
scam incorrectly report documents instances plagiarism 
reader note percentage false positives lower figures consider problem document pairs 
example stated threshold scam incorrectly diagnose document pairs plagiarism 
pairs false positive rate closer 
fraction extra unnecessary documents reported plagiarism test low 
course fraction smaller higher threshold reduce number actual plagiarism cases detected scam 
incidentally notice showing ranges lots full tables may biasing 
example threshold give desirable results table limited threshold values 
spite show ranges showing ranges harder visualize results believe analyzing raw data ranges adequate roughly distinguish various cases 
summary see cops conservative denoting document pairs satisfy dtt misses real instances overlap 
hand scam liberal denoting document pairs satisfy dtt instances 
liberal scheme scam may appropriate catching cases overlap paramount 
case useful human check detected documents eliminate false positives 
hand overlap detection completely automated duplicate removal netnews articles cops advantage 
figures report tables similar comparing new document comparison measure traditional ir cosine measure 
choose boundary lots full breaking point subset dtt scam nearly success detection test success false positive test 
hand clear boundary ir subset dtt 
boundary lots full give success rate detection test false positive test 
boundary lots give success rate detection test success false positive test 
similarly boundaries 
general see scam performs better traditional ir measures separating document pairs thresholds 
number false positives lower scam ir 
instance threshold document pairs instances plagiarism filtered away scam opposed ir 
discussion see scam performs better cops examined cases detecting overlap values 
general cops performs worse detecting overlaps reasons 
cops problems small sentences handle current implementation documents multiple copies sentence 
cops classic sentence boundary problem hard detect sentence ends 
fairly sophisticated mechanisms detecting sentence boundaries scam clear advantage uses word chunking 
cops gets confused due signature files bottom news messages scam due word chunking 
experiments systems stripping signature files bottom files proved worsen behavior schemes cops scam 
users responding news article included part earlier message signature 
easy automatically detect remove signatures middle articles cops scam lesser associations root article due absence signature 
articles limited punctuation 
cops relies punctuation marks sentence chunking problems 
common rec sport 
columns included lists favorite players teams clari finance groups listed current gold prices currency conversion rates little punctuation 
biggest problems cops partial sentence overlaps expected 
users respond articles include parts sentences respond typically line comment occurred cops detect real overlaps documents 
highlights significant problem sentence chunking 
see scam reports false positives cops 
small documents similar vocabulary high values overlap 
expect overcome number false positives lower overlap values introducing weighting scheme words depending occurrence frequency documents 
may possible entirely drop low weight words improving scam performance 
weakness scam clear choose value ffl wide variety documents 
empirically value ffl works netnews articles small set conventional text documents clear value equally sets documents 
plan consider document sets check value universally acceptable large class document sets 
promising idea exploring combine copy detection schemes cops scam 
system provided schemes appropriate desired overlap test 
idea develop accurate tests expensive applied small subset documents identified cops scam order reduce number false positives 
consider copy detection problem perspective registration server analyzes documents overlap 
new similarity measure solely word frequencies documents 
results initial comparisons scam stanford copy analysis mechanism current prototype cops approach sentence comparisons 
results demonstrate general advantages word chunking detecting document overlap highlighting sentence chunking reduces number false positives 
comparisons relatively small netnews articles due easy availability related document sets 
expect explore applicability word chunking document comparison model larger conventional text documents addition set text documents draft conference papers experimented 
long run believe hybrid scheme uses word sentence chunking effective detecting overlap course cost may high 
detailed performance evaluation various overlap schemes 
aho corasick 
efficient string matching aid bibliographic search 
communications acm 
anderson 
stewart feder mechanized search 
nature april 
boneh shaw 
collusion secure fingerprinting digital data 
technical report computer science department princeton university january 
low maxemchuk gorman 
document marking identification line word shifting 
technical report bell 
may obtained ftp ftp research att com dist ps 
low maxemchuk gorman 
electronic marking identification techniques discourage document copying 
technical report bell 
brin davis garcia molina 
copy detection mechanisms digital documents 
proceedings acm sigmod annual conference san francisco ca may 
choudhury maxemchuk paul schulzrinne 
copyright protection electronic publishing computer networks 
technical report bell 
submitted ieee network magazine june 
faloutsos 
description performance analysis signature file methods 
acm transactions office information systems 
francis kucera 
frequency analysis english usage 
houghton mifflin new york 
griswold 
method protecting copyright networks 
joint harvard mit workshop technology strategies protecting intellectual property networked multimedia environment april 
li 
random texts exhibit zipf law word frequency distribution 
ieee transactions information theory 
lovins 
development stemming algorithm 
mechanical translation computational linguistics 
luhn 
statistical approach mechanized encoding searching literary information 
ibm journal research development 
manber 
finding similar files large file system 
usenix pages san francisco ca january 
paice 
stemmer 
acm sigir forum 
palmer hearst 
adaptive sentence boundary disambiguation 
proceedings anlp stuttgart germany october 
parker 
computer algorithms plagiarism detection 
ieee education may 
popek kline 
encryption secure computer networks 
acm computing surveys december 
salton buckley 
term weighting approaches text retrieval 
information processing management 
salton 
state retrieval system evaluation 
information processing management 

wang evens 
relationship thesauri information retrieval 
american society information science 
wheeler 
computer networks said offer new opportunities 
chronicle higher education pages june 
yan garcia molina 
index structures selective dissemination information boolean model 
ieee transactions database systems june 
yan garcia molina 
duplicate detection information dissemination 
proceedings large databases vldb conference zurich switzerland september 
yan garcia molina 
sift tool widearea information dissemination 
proceedings usenix 
zipf 
human behavior principle effort 
addison wesley press cambridge massachusetts 
