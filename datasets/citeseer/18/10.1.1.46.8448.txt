searching distributed collections inference networks james callan lu bruce croft computer science department university massachusetts amherst ma usa cs umass edu information retrieval systems networked environments raises new set issues received little attention 
issues include ranking document collections relevance query selecting best set collections ranked list merging document rankings returned set collections 
describes methods addressing issue inference network model discusses implementation inquery system presents experimental results demonstrating effectiveness 
retrospective document retrieval usually described task searching single collection documents produce list documents ranked order relevance particular query 
need search multiple collections distributed environments increasingly important sizes individual collections grow network information services proliferate 
distributed collections relatively homogeneous case large single collection partitioned distributed local network improve search efficiency 
heterogeneous wide area network services hundreds thousands collections available searching 
searching distributed collection presents number unique problems 
approach treat distributed collections single large virtual collection 
collection searched individually results combined merged produce single ranked list 
problem approach merge individual ranked lists 
problems economic aspects searching 
generally expensive terms computer communication resources user time search collection distributed environment 
systems clear making charges searching dependent number collections searched 
collections available distributed appear th annual international acm sigir conference research development information retrieval 
copyright fl association computing machinery 
rights reserved 
ronment decision search 
retrieval system provide techniques decision automatically users may unable unwilling selections exhaustively examining long lists available collections 
having selected collections search retrieval system provide techniques effectively merging individual ranked lists documents produced 
describes issues addressed retrieval system inference net probabilistic model information retrieval 
section describe related collection selection merging ranked results 
section describe inference network rank collections relevance query 
section presents method accurately merging results different collections collection ranking 
results section show possible select subsets available collections searching affecting retrieval effectiveness 
section describes efficiency optimizations distributed searching 
final section summarize results discuss unsolved problems 
related users commercial retrospective information retrieval systems faced collection selection problem 
user search collections choose subset searched 
experienced users example librarians acting intermediaries may draw past experience aids help deciding collections search 
experienced choose search available collections take time select subset trial error 
service providers manually group collections sets common themes example newspaper collections court decisions 
danzig showed automatically maintain similar groupings distributed environments 
broker agents maintained centralized indices particular subjects periodically querying remote collections 
approaches simplify collection selection users information needs anticipated extent 
expert retrieval system early example automating collection selection 
expert decided query query basis collections appropriate albeit relatively static set homogeneous personal communication commercial retrieval service 
collections 
rule inferencing match information need knowledge base describing document collections producing ranked list collections 
voorhees explored ranking collections similarity new query training queries 
relevance judgements similar training queries determine retrieve collection 
technique may practical relatively static collections obtaining relevance judgements problematic widely distributed dynamic collections 
gloss estimates number potentially relevant documents collection boolean query jcj delta pi df jcj term df number documents containing jcj number documents gloss approach easily applied large numbers dynamic collections gloss stores term frequency information collection 
effectiveness known due limited evaluation lack support forms query 
moffat centralized index blocks documents individual collections :10.1.1.53.7407
example block documents concatenated 
new query retrieves block identifiers centralized index searches highly ranked blocks retrieve documents 
approach worked retrieving small numbers documents caused significant decrease precision recall documents retrieved 
set collections chosen retrieval system decide combine search results collection single ranking 
task simple results unordered set documents difficult results ranked lists documents 
successfully document scores different collections create merged ranking problems approach 
voorhees call collection fusion problem describe solutions 
solution interleave rankings round robin fashion 
second solution uneven interleaving biased expected relevance collection query 
approach substantially effective experiments trec collection 
ranking collections inference networks inference networks probabilistic approach information retrieval 
traditional inference networks document retrieval directed acyclic graph documents represented leaves root node represents information need 
major part collection selection problem ranking collections information need 
ranking collections addressed inference network leaves nodes represent document collections representation nodes represent terms occur collection 
probabilities flow arcs statistics analogous tf idf normal document retrieval example document frequency df number documents containing term inverse collection frequency icf number collections containing term 
call type inference network collection retrieval inference network cori net short distinguish common document retrieval inference networks 
upsilon sigma xi pi upsilon sigma xi pi upsilon sigma xi pi gamma gamma gamma gamma gamma psi upsilon sigma xi pi document network upsilon sigma xi pi upsilon sigma xi pi upsilon sigma xi pi gamma gamma gamma gamma psi hj upsilon sigma xi pi upsilon sigma xi pi hj upsilon sigma xi pi upsilon sigma xi pi upsilon sigma xi pi phi phi phi phi phi phi phi phi phi query network upsilon sigma xi pi simple document retrieval inference network 
cori net moderate storage requirements document frequency df inverse collection frequency icf stored 
cori net gigabyte collection trec volume megabytes assuming simple compression algorithms 
case cori net size original collection 
advantage inference network ranking collections system ranking documents collections 
necessary design new file organizations algorithms 
document retrieval step process 
query retrieve ranked list collections 
select top group collections 
search top group collections parallel sequentially 
merge results various collections single ranking 
steps performed single algorithm operating different indices 
retrieval algorithm cori network looks document retrieval inference network big documents document surrogate complete collection 
search complexity comparable searching small collections abstracts 
cori network document collections comparable searching known collection cacm abstracts 
tf df idf icf values higher affect computational complexity retrieval 
inverted lists match terms query accessed 
effectiveness approach ranking collections evaluated inquery retrieval system gigabyte trec document collection :10.1.1.33.5416
trec collection heterogeneous containing subcollections different sources periods time table 
subcollections vary widely size number documents average document length 
experiments conducted queries developed trec topics previous trec tipster evaluations 
inference network incorporate proximity information operators impractical collection ranking 
table trec document collections experiments 
trec volume number shown parentheses 
docu mega name ments words bytes ap ap ap doe fed reg 
fed reg 
patent sjm wsj wsj wsj wsj wsj wsj ziff ziff ziff table average optimal rank trec volume collections topics 
wsj ap wsj wsj fr doe ziff mean squared error metric compare effectiveness variations basic collection ranking algorithms 
mean squared error collection ranking single query calculated jcj delta sigma gamma optimal rank collection number relevant documents contained collection largest number relevant documents ranked collection second largest number relevant documents ranked rank collection determined retrieval algorithm set collections ranked 
mean squared error metric advantage easy understand optimal result require labeling collection relevant relevant particular query 
average optimal rank collection trec volume shown table 
inquery algorithms ranking documents documented extensively discussion confined changes necessary rank collections :10.1.1.33.5416
changes confined initially replacing tf df idf icf discussed replacing maximum term frequency document statistic max tf maximum document frequency collection max df 
belief rk jc collection due observing term rk determined gamma delta log df log max df log gamma jcj cf delta log jcj rk jc gamma delta delta df number documents containing rk max df number documents containing frequent term jcj number collections cf number collections containing term rk minimum term frequency component term rk occurs collection db minimum belief component term rk occurs collection variation known tf idf approach ranking documents values normalized remain modified default term frequency default belief db values 
db default 
probabilistic query operators combine beliefs accruing query terms remained unchanged 
proximity operators replaced strict boolean operators due lack proximity information cori nets discussed section 
approach rank trec volume collections topics 
mean squared error averaged queries 
rankings queries nearly perfect rankings disorganized accounted error 
pattern apparent explain queries yielded poor rankings 
possible problem applying default formulas ranking documents ranking collections max df statistic scale df argued ranking collections analogous ranking documents differences 
reason ranking collections find collections particular subject find collections containing documents possible subject 
scaling df max df tends obscure small small sets interesting documents large collections 
experiments document retrieval suggest may better scale tf tf small 
analogue task scale df df replacing equation equation 
gamma delta df df ranking documents sense function document length 
ranking collections may sense sensitive number percentage documents subject 
may sense large df values generally large 
defined delta gamma delta cw cw constants cw number words collection cw mean cw collections ranked 
constant controls magnitude varying increases sensitivity size collection 
approach rank trec volume collections topics 
experiments conducted mean squared error queries mean squared error queries effect mean squared error varying trec volume collections topics 
varied 
varied 
values ranging values ranging 
best combination values set queries collections 
mean squared error averaged queries combination better mean squared error obtained scaling df max df collection rankings improved queries quite dramatically 
rankings queries deteriorated slightly 
rankings queries change 
mean squared error perfect 
analysis results reveals serious mistakes 
mistakes due mixing rankings collections containing nearly equal numbers relevant documents 
cases counted errors noticeable user 
improvement possible yield diminishing returns 
merging results ranking collections part problem 
set collections searched ranked results collection merged single ranking 
document rankings available results collection interleaved 
solution satisfying collections equal numbers proportions relevant documents 
difficult sophisticated information just document rankings 
ir systems return ranking documents numeric score indicates document matches query 
scores different collections comparable merge set rankings document scores raw score merge 
techniques scores different collections may directly comparable 
example idf weights words relatively consistent different collections idf weights words computer vary widely technical legal medical collections 
viewed desirable idf represents term importance particular collection 
viewed undesirable important query term behave rewarding random mention term collection penalizing common 
problem incomparable scores overcome cases normalizing statistics idf set collections searched 
intent normalize document scores obtain precisely results obtained individual document collections merged single unified collection 
difficulty normalizing document scores set collections depends retrieval algorithms employed 
inference network architecture normalizing scores requires preprocessing step prior query evaluation 
preprocessing step system obtains collection statistics documents query term proximity operator matches 
statistics merged obtain normalized idf 
query normalized sufficient retrieve documents comparable scores disparate collections 
normalizing document scores entail significant communication computational costs collections distributed wide area network 
alternative simple interleaving normalized scores merging weighted scores 
weights document score collection ranking information 
approach offers computational simplicity simple interleaving overcoming disadvantages 
weight example weight results different collections 
collection score rank believe similar collections similar weights 
jcj delta gamma jcj number collections searched collection score mean collection scores 
document ranked product score table different techniques merging results different collections trec volume topics 
interpolated recall precision averages queries normalized interleaved raw score weighted merge merge merge merge gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma average precision non interpolated rel docs gamma gamma precision docs gamma gamma gamma docs gamma gamma gamma docs gamma gamma gamma docs gamma gamma gamma docs gamma gamma docs gamma gamma precision precision num rel query docs retrieved exact gamma gamma weight collection 
algorithm favors documents collections high scores enables document poor collection ranked highly 
approaches merging results interleaving raw scores normalized scores weighted scores compared series experiments collections queries described section 
experiments conducted query sets trec volume collections volume collections volume collections volumes collections volumes collections 
results shown volume volumes 
normalized scores approach treated baseline equivalent single database paradigm norm information retrieval 
experimental results contained tables 
point recall precision absolute precision various cutoffs included give clear picture behavior low high recall 
recall precision calculated trec trec eval program just top documents merged ranking 
approach treats documents rank ranked giving pessimistic view high recall behavior 
experiment simple interleaving document rankings extremely ineffective producing dramatic losses average precision 
result surprising interleaving effect boosting rankings random documents collections relevant documents 
merging raw document scores collection significantly worse ranking normalized document scores causing losses average precision 
difference normalized unnormalized scores idf component 
result confirms previous research suggesting unnormalized give misleading results 
ranking document scores weights effective ranking normalized scores 
produced small improvements levels recall queries trec collections small losses levels recall queries trec collections small changes precision levels recall queries trec collections 
general experience weighted rankings small changes low recall occasionally erratic behavior high recall 
view results extremely encouraging 
suggest possible get accuracy rankings normalized scores computational effort 
collection selection experiments described collections searched results create final document rankings 
distributed environments rarely resources search collection 
searches index collections obtains ranking searches top collections interesting documents 
number ways decide far collection rankings go 
choose top collection score greater threshold top group defined clustering method 
investigated approach 
single pass algorithm cluster collection rankings query 
collections clustered basis scores determined collection ranking algorithm section 
cluster difference threshold low creating clusters tended smaller necessary 
trec volume collections produced average clusters topics clusters topics 
rare collection significant number relevant documents excluded top clusters 
table different techniques merging results different collections trec volume topics 
interpolated recall precision averages queries normalized interleaved raw score weighted merge merge merge merge gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma average precision non interpolated rel docs gamma gamma gamma precision docs gamma gamma gamma docs gamma gamma gamma docs gamma gamma gamma docs gamma gamma gamma docs gamma gamma gamma docs gamma gamma gamma precision precision num rel query docs retrieved exact gamma gamma gamma effect recall precision noticeable significant low recall 
summarize results providing complete recall precision tables due space limitations 
topics difference best clusters collections average collections collections gamma document cutoffs 
difference exact precision gamma 
difference average point precision gamma 
effect topics noticeable differences document cutoff 
difference exact precision gamma difference average point precision gamma reflecting significant deterioration high recall results 
surprising eliminating collections reduces recall 
occasionally errors collection rankings relevant documents marginal collections 
opinion significant encouraging precision low recall relatively unaffected number collections searched reduced 
interactive users care drop recall rank 
choose search collections 
optimization section discuss decisions affect efficiency collection ranking merging rankings 
represent collection subset terms create smaller collection retrieval inference net keeping subset terms appear collection 
example keep frequent 
experiment trec volume topics investigated effect building inference nets different percentages frequent terms collection 
shows mean squared error averaged queries 
shows effect average point precision 
results suggest necessary store frequent terms advantage storing terms 
proximity information inquery system inference network model extends inference network formalism include proximity operators 
term proximity information collection ranking require location term document collection stored cori index 
possible cori net collection size original collection 
retrieving fewer documents user wants retrieve documents set collections retrieve documents collection merge rankings discard rank approach costly collections distributed widely networks gamma delta documents retrieved sent network discarded user seeing 
cost raises question possible safely retrieve fewer documents collections low ranks scores 
experimented heuristic uses collection ranking information decide retrieve collection 
number documents retrieved th ranked collection delta delta gamma sigma delta delta delta gamma delta ffl delta number documents retrieved collections 
heuristic linear function allocates predetermined number document retrievals delta collections 
collection retrieves table different techniques merging results different collections trec volumes topics 
interpolated recall precision averages queries normalized interleaved raw score weighted merge merge merge merge gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma inf inf inf average precision non interpolated rel docs gamma gamma gamma precision docs gamma gamma gamma docs gamma gamma gamma docs gamma gamma gamma docs gamma gamma gamma docs gamma gamma docs gamma gamma precision precision num rel query docs retrieved exact gamma gamma gamma delta documents second retrieves delta documents third retrieves delta fourth retrieves delta fifth retrieves delta documents retrieved increased allowing user system trade cost safety 
experiments trec volume topics total number documents retrieved produce final list reduced savings minimal impact recall precision 
change documents ranked query 
average point precision changed gamma topics topics 
explored effect retrieving different numbers documents varying 
trec volume collections values produced nearly identical results ranks 
identical rank 
produced slightly better results ranks query sets smaller values similar results obtained slightly higher values full set trec collections 
results encouraging relatively accurate methods ranking selecting collections query 
accurate methods available computation communication costs minimized retrieving fewer documents collection 
doubt collection ranking may worth added cost retrieve documents collection 
information retrieval systems applied networked environments widely distributed document collections systems need provide collection ranking collection selection results merging capabilities 
desirable provide capabilities efficiently transparently users choose maintain illusion single virtual collection returning single coherent set results 
describes efficient algorithms providing capabilities systems inference network model information retrieval 
enable system automatically efficiently rank collections relevance query select subset search subset efficiently accurately merge results 
effectiveness algorithms demonstrated experiments inquery information retrieval system trec set document collections 
experimental results encouraging simple methods quite effective collections varied widely size content 
viewed preliminary collections involved 
methods equally efficient hundreds thousands collections known equally effective 
distributed collections problems addressed 
collections stemming algorithm stopword list query processing techniques 
differ collections wide area networks problems difficult 
obvious represent collection collection retrieval inference network 
clear provide information user information need transformed structured query transformation may 
unclear perform relevance feedback set relevant documents scattered set collections different representations 
described positive encouraging merely step 
research partially supported nsf center intelligent information retrieval university massachusetts amherst 
log df log max df df df percentage terms cori net accuracy collection rankings 
df df log df log max df percentage terms cori net average precision queries accuracy merged document rankings 
effect building cori nets frequent terms trec volume collections topics 
callan croft broglio 
trec tipster experiments inquery 
information processing management press 
callan croft harding 
inquery retrieval system 
proceedings third international conference database expert systems applications pages valencia spain 
springer verlag 
danzig ahn noll obraczka 
distributed indexing scalable mechanism distributed information retrieval 
bookstein chiaramella salton raghavan editors proceedings fourteenth annual international acm sigir conference research development information retrieval pages chicago il october 
association computing machinery 
dumais 
latent semantic indexing lsi trec 
harman editor second text retrieval conference trec pages gaithersburg md 
national institute standards technology special publication 
gravano garc ia molina tomasic 
effectiveness gloss text database discovery problem 
proceedings sigmod pages 
acm september 
kwok lewis 
trec ad hoc routing retrieval thresholding experiments 
harman editor third text retrieval conference trec gaithersburg md press 
national institute standards technology special publication 
marcus 
experimental comparison effectiveness computers humans search intermediaries 
journal american society information science 
moffat zobel :10.1.1.53.7407
information retrieval systems large document collections 
harman editor third text retrieval conference trec gaithersburg md press 
national institute standards technology special publication 
rasmussen 
clustering algorithms 
frakes baeza yates editors information retrieval data structures algorithms chapter pages 
prentice hall 
robertson walker jones 
okapi trec 
harman editor third text retrieval conference trec gaithersburg md press 
national institute standards technology special publication 
turtle croft 
evaluation inference network retrieval model 
acm transactions information systems 
howard turtle bruce croft 
efficient probabilistic inference text retrieval 
riao conference proceedings pages barcelona spain april 
voorhees gupta johnson laird 
collection fusion problem 
harman editor third text retrieval conference trec gaithersburg md press 
national institute standards technology special publication 

