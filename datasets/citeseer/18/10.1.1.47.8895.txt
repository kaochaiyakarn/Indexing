communication overhead space science applications beowulf parallel workstation thomas sterling center excellence space data information sciences code nasa goddard space flight center md gsfc nasa gov daniel savarese department computer science university maryland college park md dfs cs umd edu donald becker center excellence space data information sciences code nasa goddard md becker gsfc nasa gov bruce kevin olson institute computational science informatics george mason university olson gsfc nasa gov beowulf parallel workstation combines processing subsystems disk drives dual ethernet networks provide single user environment peak performance half gbyte disk storage times disk bandwidth conventional workstations 
beowulf architecture establishes new operating point price performance single user environments requiring high disk capacity bandwidth 
beowulf research project investigating feasibility exploiting mass market commodity computing elements support earth space science requirements large data set browsing visualization simulation natural physical processes assimilation remote sensing data 
reports findings series experiments characterizing beowulf dual channel communication overhead 
shown dual networks sustain greater throughput single network bandwidth achieved highly sensitive message size number messages peak demand 
overhead shown high global synchronization impact scalability real world applications computational fluid dynamics gravitational simulation shown modest 
beowulf parallel workstation defines new operating point price performance single user computing systems 
beowulf couples low cost moderate performance commodity personal computing subsystems emergence de facto standards message passing hardware software realize workstation exceptional local file storage capacity bandwidth 
experimental system motivated requirements nasa earth space science applications including data assimilation data set browsing visualization simulation natural physical systems 
exploits parallelism processor disk internal communication derived mass market commodity elements 
enabling large temporary data sets buffered workstation order reduce demand shared central file servers networks greatly improving user response time 
presents results experiments characterize communication overhead beowulf parallel workstation establish regime effective operation 
distributed computing systems provide general purpose multiuser environments beowulf distributed computing system specifically designed single user workloads typical high scientific workstation environments 
princeton shrimp project targeted parallel workstation systems comprising multiple personal computer proces sors 
pentium distributed computer employs custom communication unit support distributed shared memory model 
beowulf contrast incorporates special purpose parts depending parallel ethernet communication channels achieve adequate sustained interprocessor message transfer rates 
required software enhancements operating system kernel level achieved commercial shelf hardware elements specifically low cost ethernet cards 
workstation operational demand coarse grained job stream parallelism 
workstations required workload computationally intensive 
need exploit parallelism single application 
ironically solving parallel processing problem ordinarily prove challenge computational sciences community active applications crafted communicating sequential processes parallel programming style order run effectively larger distributed computers intel paragon tmc cm cri 
beowulf benefits parallel programming investment community intended serve provides equivalent programming compilation environment parallel workstation level 
number parallel applications successfully easily ported beowulf manner 
beowulf inter processor communications provided standard mbps ethernet dual channels channel connecting processing elements 
channels equally accessible processors operating system kernel linux modified dynamically distribute message packet traffic load balance networks 
interprocessor communications performance may characterized ways presents experimental results reflecting aspects communication execution performance 
basic network capacity characterized terms throughput byte transfer rate number messages passed unit time 
measurements functions message size message demand number channels employed 
impact parallel interprocessor communication explored real world application programs earth space sciences community 
problem computational fluid dynamics application employing regular static data structure suited system beowulf architecture 
second body gravitational simulation irregular dynamic global data challenges capabilities beowulf communication 
scaling properties applications communication overhead encountered 
beowulf architecture beowulf parallel workstation architecture comprises pc processor subsystems half gbyte disk controller 
beowulf prototype incorporates intel dx processor mhz clock rate kbytes secondary cache 
dx delivers greater computational power members family higher clock speed primary cache twice size primary caches 
processing subsystem installed mbytes dram total system main memory mbytes 
processing elements interconnected parallel ethernet networks peak capacity mbps network 
purposes experimentation network twisted pair small inexpensive hub thin net 
processor subsystems include separate ethernet interfaces external lan remote access data transfer 
additional processor subsystems include high resolution video controller drivers providing user keyboard mouse interface conventional single user workstation access 
beowulf prototype subsystems packaged single floor standing half height utility cabinet including secondary storage floppy drives cd rom drives fans power supplies 
beowulf parallel architecture respects conventional distributed structure developed meet specific critical requirements dictated earth space science community 
nasa hpcc program particular ess project involving nasa goddard space flight center caltech jpl identified need high performance workstations level large science applications 
class required system diverse included simulation physical processes data browsing navigation visualization large data sets 
processor performance large disk capacity high disk transfer rates determined essential 
necessity experimental nature project architecture base system software available provide robust sophisticated operating system support having available full source code docu mentation 
importantly nasa commitment technology transfer industrial academic sectors required aspects beowulf parallel workstation results easily available centers computer physical sciences benefit nasa results 
nature beowulf single user workstation demanded marginal replacement cost system consistent pricing contemporary high workstations lower performance anticipated beowulf 
beowulf applied research project devised explore operating point workstations addressed commercial marketplace particular interest high performance computational science community 
light requirements set architecture choices distinguishes beowulf conventional high workstations distributed computing systems 
apparent high degree parallelism exploited personal computing mass market subsystems somewhat higher performance workstation oriented microprocessors 
scale structure devices chosen careful analysis requirements technology opportunities 
particular class workload workstation different demanded typical distributed high performance computing system 
workstation workload may consist number decoupled loosely coupled tasks manage environment resources 
expected shared memory environment necessary effective workstation capability beowulf project tests viability serving role distributed memory logically related process name space message passing mechanisms 
distinguishes beowulf shrimp project provide distributed shared memory custom logic 
pc derived processors determined relatively low cost processors low cost full processing subsystems due true mass market scale fabrication distribution consumer level 
market orders magnitude larger workstation market cost benefits resulting economy scale provided new operating point largely unexplored scientific community 
full cots subsystems available networks anticipated impose bottleneck 
approaches identified alleviate problem achieve necessary interprocessor communication rates 
tested beowulf prototype explored parallel networks 
message packet traffic demand load balanced multiple ethernet networks bandwidth scaling achievable 
second approach exploitation emerging mbps ethernet networks 
integrated beowulf prototype exciting technology tested separately 
previous interprocessor communication shown constrain file transfer rates certain circumstances higher level bandwidth possible new technology largely alleviate problem resulting balanced architecture 
emergence de facto standards message passing hardware software mechanisms considerable investment scientific message passing application software development permits important parallel computations performed beowulf shared memory context 
exceptions exist hinder beowulf universal scientific workstation 
shown section important problems earth space sciences complex dynamic resource demands effectively accomplished beowulf architecture 
beowulf scalable communications implemented duplicating hardware address primary network adaptor secondary interfaces marking packets received internal networks coming single pseudo interface 
scheme constrains internal network connect node 
constraints ethernet packet contents independent actual interface avoid software routing overhead handling general interconnect topologies 
additional computation single network interface computationally simple task distributing packets available device transmit queues 
current method alternating packets available network interfaces 
communication channel capacity degree multiple processors combined perform single application ultimately limited capacity global interprocessor communication network 
series experiments conducted characterize capability multiple ethernet communication channels provided data transfer processors global synchronization 
complicated degrees freedom determine domain communication 
communication capability metric performance considered 
section communication capability investigated synthetic program purpose generate message traffic 
test program exchanges token message pair processors 
processor generates token comprise packets sends second processor 
second processor generates message returns 
minimum transfer time determined hardware software considerations accurately reflects factors contributing sustained communication performance 
demand rate increased adding processor pairs ping tokens back forth 
contention processors processor involved token global communication channels resources subject possible contention 
processors processor pairs range active tokens 
seen shortly reveal domain network performance behavior 
second parameter importance network performance size tokens measured bytes 
experiments token size varied bytes plus header information bytes 
ethernet packets contain bytes large tokens implemented system multiple packets 
third parameter number channels active time 
results channel configurations reported data collected channel organizations processors 
performance metrics examined sustained bandwidth information throughput measured mbytes second message throughput measured tokens second 
data bandwidth empirical results throughput mbytes sec plotted respect size tokens measured bytes log base 
chart shows separate curves divided groups solid lines represent runs ethernet lines show measurements experiments tow ethernet networks simultaneously 
groups curves distinguished level token demand active ping tokens 
legend relates plot point symbols token demand 
empirical results clearly demonstrate beowulf data bandwidth data rate strong relationship token size insensitive token demand 
token demand higher demands tightly clustered exhibiting throughput token size 
product contention network largely serializes communication 
demand stress network resources demand tokens resulting contention arbitration strategy 
networks similar clustering demonstrated significantly higher bandwidth token size 
spread behavior broader networks addition packet distribution algorithm included beowulf linux kernel 
packet dispatch algorithm employed processor simply network blindly 
exploit possibly useful information traffic patterns see generally dual network approach simple strategy returns times sustained bandwidth single network highest levels achieved 
scaling trivial dispatch strategy 
effectiveness networks demonstrated demand token 
token size exceeds single packet multiple packets take advantage availability dual channels showing improvement single channel case byte tokens 
certain packet size throughput dominated network bandwidth 
single channel case occurs token size bytes yielding sustained throughput mbyte second 
compared absolute peak mbytes second 
dual channels saturation reached token size bytes 
beowulf message throughput observed token demand single channel saturation level reached tokens bytes 
general behavior networking scheme better illustrated rate token transfer respect token size 
single dual network measurements plotted distinguished token demand 
number tokens transferred unit time insensitive token size small tokens size significantly exceeds packet send overhead token transfer rate declines network saturation forces direct tradeoff token size number tokens transferred unit time 
previously seen generally dual network configuration significantly performed single network system 
interesting anomaly exposed token demand case 
dual network system little better terms token transfer rate single network system token size exceeds bytes 
time submission research phenomenon understood requires study 
especially dual network configuration token transfer rate shows marked sensitivity token demand active tokens 
key drawn finding 
multiple channels scale terms data bandwidth token transfer rate 
second token size important token demand deriving best performance available communication resources 
motivates parallel communication channels 
second requires application programmers package data large aggregates sending smaller packets 
applications scaling communication overhead selected applications study stress computer architecture different ways 
solves equations compressible gas dynamics structured grid 
algorithm computationally intensive requires small amount local communication 
result parallelization overhead relatively small 
second code solves gravitational body problem tree algorithm 
tree unstructured code frequent indirect addressing requires global communication 
compressible gas dynamics code discussed solves euler equations compressible gas dynamics structured logically rectangular grid 
code named prometheus primarily computational astrophysics simulations supernova explosions non spherical flows nova 
euler equations solved piecewise parabolic method ppm hydrodynamics 
high resolution finite volume technique particularly suited calculation flows contain discontinuities shock fronts material interfaces 
systems studied spatial dimensions rectangular cylindrical spherical coordinates 
results discussed calculations performed dimensional rectangular grid 
code parallelized domain decomposition technique grid divided number rectangular tiles 
approach successfully large number parallel computers including cray maspar mp mp ibm sp sp cray intel paragon 
case beowulf processor assigned tiles calculate 
tile surrounded frame ghost points specifying boundary conditions 
formulation ppm algorithm prometheus scheme ghost points need updated time step frame grid points wide 
communication required approach rows values exchanged adjacent tiles time step 
floating point operations needed update zone single time step ratio communication costs computational costs quite low 
gravitational body problem tree codes collection algorithms find approximate solution equations force system interacting particles 
algorithms particles sorted spatial hierarchy forms tree data structure 
node tree represents grouping particles 
data represents average quantities particles total mass center mass high order moments mass distribution computed stored nodes tree 
forces computed having particle search tree pruning subtrees search average data stored node compute force searching particle user supplied accuracy limit 
fixed level accuracy algorithm scales log algorithms possible 
tree search particle known priori tree unstructured frequent indirect addressing 
presents problems distributed memory parallel implementations algorithm wishes minimize processor accesses data 
hand problem possess highly parallel component particle searches tree structure completely independently particles system 
performance scaling scaling characteristics application codes tested evaluated beowulf parallel workstation 
results shown 
body code problem size kept fixed processor numbers 
separate curves shown ppm gas dynamics code 
case problem size kept fixed second curve problem size scaled number processors amount assigned processor remained fixed 
codes run processors 
ppm code tile size kept fixed theta theta including ghost points 
fixed problem sizes codes showed significant performance degradation run processors 
performance increased number processors increased 
processors ess code scaling little left processor parallelization overhead 
single processor performance body code mflops ppm code achieved mflops single processor 
full processor beowulf speed attained mflops body code mflops ppm code 
comparison shared memory version body code convex spp processors yields performance mflops 
better characteristics obtained ppm code problem size scaled number processors 
processors performance decreased respect ideal 
single processor performance code mflops 
full processor beowulf delivered mflops 
compares favorably performance comparably sized tmc cm vector chips intel paragon 
cri achieved factor better beowulf number processors 
scaling performance body code improve problem size scaled number processors remains determined 
parallelization overhead codes plotted 
expected overhead body code quite high due large amount global communication required 
overhead exceeds processors meaning time spent overhead communication 
surprisingly ppm code fixed problem size situation worse 
processors overhead greater 
case overhead due communication time 
total time required communication routines wall clock time 
ma ess code communication overhead overhead time appears taken synchronization processors time step 
probably improved considerably modifying algorithm allow dynamic load balancing experiment attempted 
remains determined improved increasing tile size 
additional experiment performed determine multiple networks increase performance 
ppm code cases effect negligible expected communication overhead exceeds 
code improvement obtained networks percent 
dynamic load balancing portion algorithm tested network bandwidth constrained 
networks provided improvement portion code 
scaling experiments real problems showed surprisingly performance considering pc microprocessors 
case ppm code beowulf provided competitive performance weakest area floating point intensive application 
performance code improved discussed allowing larger problems executed 
body code attained performance 
cost considered beowulf delivered far better ratio general mpp 
true beowulf limited scope scaling 
configuration intended exploit order magnitude parallelism 
regime beowulf appears provide satisfactory scaling performance classes problems represented codes discussed section 
discussion key observation beowulf project peak performance implemented costs price range high workstations total cost beowulf prototype approximately 
low cost moderate performance moderate disk bandwidth elements distribute configuration elements demonstrates greater parallelism combined mass market subsystems provide superior capability certain types operation 
demonstrated utility employing linux operating system basis research distributed systems platform operational 
linux proved robust efficient ready 
availability source code licensing constraints permitted modification kernel support multichannel ethernet communications transparent user application 
provides ideal vehicle technology transfer new system software tools developed support distributed computing 
empirical results clearly demonstrate viability ease employing multi channel ethernet communications 
message packet dispatching strategy simple ethernet interface drivers cots elements saturation dual system sustainable bandwidth exceeded single channel configuration single unit sustained bandwidth achieved absolute peak bandwidth hardware 
experiments discussed extended results channels smaller configuration system showing continued scaling 
opens way multiple mbps ethernet technology just emerging 
analysis shows technology combined parallel exceed worst case communications requirements beowulf terms bandwidth latency considerations addressed 
behavior multi channel approach proved anomalous behaviors observed fully understood probably artifacts message scheduling policy adopted 
studies conducted determine precise causes 
severe test parallel workstation beowulf performing real world applications parallel 
findings extensive tests conducted space science applications 
different realistic conditions application codes demonstrated scaling processors useful additional performance achieved processors 
fact compared intel paragon comparable number processing nodes beowulf equally 
run cri comparable number processing elements beowulf delivered half performance seen 
cases possible optimizations change performance ratios way 
sustained performance compared favorably light relative costs respective systems 
communication overhead consumed considerable amount computing time target enhancement 
second generation beowulf parallel workstation production 
configuration software systems unchanged principal differences include replacing intel dx intel pentium replacing mbps ethernet networks mbps technology doubling disk capacity 
improvements expected double sustained floating point performance largely eliminate inter processor interconnects source performance constraint 
particular disk file transfer rates separate pairs disks significantly improved parallel application scaling characteristics enhanced 
studies resolve unanswered conditions network behavior test efficient methods achieving global operations 
broader base parallel applications developed including data intensive visualization applications real time requirements 
implementation mpi ported shortly evaluated performance achieved pvm 
advanced task scheduling parallel disk management techniques developed research centers integrated current system software framework tested needs workstation workload 
important outcome provide baseline measurements projects determine relative benefits incorporating custom hardware mechanisms better beowulf beowulf 
barnes hut nature 
li alpert felten sandberg virtual memory mapped network interface shrimp multicomputer proceedings international symposium computer architecture isca chicago april pp 

cray research cray system architecture overview minnesota 
colella woodward method hydrodynamics journal computational physics 
muller hydrodynamics nuclear burning max fur preprint 
intel dx processor data book 
intel paragon user guide beaverton oregon 
linux documentation project accessible internet world wide web url sunsite unc edu linux html 
olson implementation tree code simd parallel computer astrophysical journal supplement series september 
sterling savarese gardner initial evaluation convex spp earth space science applications proceedings international symposium high performance computing architecture january 
sterling savarese olson empirical evaluation convex spp hierarchical shared memory system appear proceedings international conference parallel architectures compilation 
sterling becker savarese beowulf parallel workstation scientific computation appear proceedings international conference parallel processing 
sunderam pvm framework parallel distributed computing concurrency practice experience december pp 

thinking machines connection machine cm technical summary cambridge ma 
