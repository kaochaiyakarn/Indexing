agent architecture line learning procedural declarative knowledge ron sun university alabama tuscaloosa cs ua edu order develop versatile cognitive agents learn situated contexts generalize resulting knowledge different environments explore learning declarative procedural knowledge hybrid connectionist architecture 
architecture level idea proposed earlier author 
declarative knowledge represented symbolically procedural knowledge represented 
architecture integrates reactive procedures rules learning decision making unified framework structures different learning components including learning rule induction synergistic way perform line integrated learning 
humans possess abilities develop set coping skills highly specific highly efficient geared particular situations survival time acquire sufficiently general knowledge readily applied variety situations 
artificial cognitive agent interacts world learn survive various environments 
existing systems fall far short 
balance sides specific procedural skills generic declarative knowledge believed essential development complex cognitive agents 
example learning navigate obstacles typical test domain way trial error repeated practice gives rise set procedural skills deal specifically practiced situations minor variations 
skills may transferable truly novel situations embedded specific contexts tangled 
deal novel situations agent needs discover general rules knowledge 
generic knowledge helps guide exploration reduces time number trials necessary develop specific skills new situations 
help communicating process skill navigation agents 
various deals type knowledge useful components integrated system reinforcement learning autonomous reactive systems robots connectionist rule learning extraction hybrid connectionist architectures 
existing proposals combining types knowledge usually simply handle learning especially perform integrated learning 
important considerations learning process line real time autonomous adapt changing environments integrated different types representations developed simultaneously side 
level architecture various level architectures proposed hendler gelfand sun 
sun integrated 
consists concept level feature level 
representation localist concept level node concept distributed feature level non exclusive set nodes concept 
way connections corresponding representations different levels generating variety reasoning patterns 
rules implemented concept level capture generic conceptual knowledge available agent diffused representation rules feature level captures associative embodied knowledge skills certain extent 
interaction levels architecture capable producing massively parallel manner number important commonsense reasoning patterns 
arguments level architectures 
firstly cognitive arguments related distinction declarative procedural knowledge reactive routine reactive routine reactive routine reactive level rule rule rule rule level architecture smolensky proposed distinction conceptual accessible subconceptual processing dreyfus dreyfus proposed distinction analytical intuitive thinking addition controversial distinction conscious subconscious processes known cf 
james 
strongly believed need incorporating cognitive models side dichotomy serves unique cognitive function indispensable 
secondly described damasio 
ample biological evidence indicates existence multiple pathways visual language modal processing lead conscious awareness type cortical 
example described pathway stimulus thalamus cortex produces conscious conceptual thoughts pathway stimulus thalamus lead directly brain stem effect actions conceptual processing 
level model approximates separation kinds pathways incorporating aforementioned distinctions 
ideas argue complete integrated architecture connectionist learning adaptive rule induction line tackle problem exploring types knowledge framework integrating reaction planning learning decision making 
consists levels see 
reactive level contains reactive routines agre chapman acquired connectionist reinforcement learning discussed rule level contains rules various kinds acquired variety different methods especially rule extraction 
reinforcement learning consider reactive level 
question appropriate learning procedure level develop specific reactive routines brooks agre chapman 
decision making situation seldomly uniquely correct action 
supervised learning procedures applicable require priori determination uniquely correct output input learning converge 
situation actions bad actions measure goodness action feedback signal reinforcement signal ranging say extremely extremely bad possibilities 
adopt reinforcement learning paradigm sutton barto difficult handle sequential nature world sequential behaviors necessary agent survive world 
agent needs way remembering past mere instantaneous feedback 
solution offered symbolic ai explicit symbolic planning 
problem approach fold high computational complexity inherent approach describing simple sequential behaviors agre chapman brooks 
need viable way 
better choice temporal difference learning method described sutton barto sutton watkins 
evaluation function generates value current state input measures goodness action chosen certain policy evaluation function leads new state reinforcement signal modify parameters evaluation function closer fle fl update function gamma fle smaller 
time action policy updated strengthen weaken tendency perform chosen action error evaluating state fle gamma situation getting better action increase tendency perform action reduce tendency 
words learning process dependent temporal difference evaluating state 
variation method learning watkins policy evaluation function merged function current state action chosen values considering possible updating done minimizing fle gamma max temporal difference evaluating current state action chosen 
ensure adequate explorations action policy needs deterministic 
stochastic decision process different actions chances tried accordance respective probabilities ensure various possibilities looked 
terms simplicity performance learning best options lin reactive routines developed reinforcement learning exhibit sequential behaviors explicit symbolic planning successive updates evaluation function agent learn take account steps longer longer sequences 
agent accomplishes sequential plans basis decision making moment moment environmental input 
direct psychological evidence learning se idea learning traced law effect thorndike 
sutton barto describe detail reinforcement learning algorithms account classical conditioning data 
biological intracellular substrate learning discussed anderson 
implement learning chose network layers form backpropagation network computing values fourth layer node performs stochastic decision making boltzmann distribution see 
constructing rules major aspect architecture rule acquisition refinement 
need simple efficient way acquiring rules structures suitable domain 
terms learning propositional rules substantial amount ai learning literature 
architecture especially important factor needs taken account connectionist network bottom level trained reinforcement learning procedure capable performing specific reactive routines 
embodied performance capability network extract information general rules 
way need separate learning mechanism top level extracting information bottom level 
learning reactive level serves dual purpose architecture parsimonious 
particular relevance rule extraction fu proposed search algorithm extract conjunctive rules towell shavlik rules form 
rule extraction algorithms applied training network 
extracted rules fixed dynamic modification fly course rules inserted back network retrained re extracted 
hand extract modify rules dynamically connectionist network trained 
way utilize synergy algorithms rule induction simpler extensive search needed 
basic idea follows action decided reactive level successful general knowledge extracted agent extracts rule corresponds reaction selected reactive level adds rule extracted rule network doing agent remove specialized rules rule network keep general details subsequent interactions world agent tries verify extracted rule considering result applying rule result negative rule specific exclusive current case result positive agent may try generalize rule universal 
algorithm specialization generalization done previously extracted rules search needed 
rule extraction algorithm coding rule network sun 
psychological data support rule induction process 
see sun sun 
putting things pseudo code algorithm describes operation follows 
observe state distributed representation 

compute network reactive level values possible actions 

choose output layer network reactive level appropriate action 
find possible actions bm rule level input rule network place 

compare choose appropriate action 
perform action observe state reinforcement 
update fle gamma 
update rule network rule extraction 

go back step 
step making final decision action take results rule level reactive level 
allows different operational modes relying rule level relying reactive level combining outcomes levels weighing differently weights final outcome strongly activated action weighted combination 
weights change time different situations 
different operational modes roughly correspond folk psychological notions intuitive reactive mode deliberative mode various mixture different percentage 
refined diagram shown 
example evaluation situations worse 
rule level reactive level refined architecture shares similarity anderson succeeds explaining issues anderson address 
firstly anderson takes top approach learning declarative procedural knowledge bottom procedural declarative rely existing externally verbally imparted knowledge act 
secondly act declarative procedural knowledge represented explicit symbolic form semantic networks plus production rules fails explain representational viewpoint differences conscious accessibility types knowledge 
declarative knowledge consciously accessible procedural knowledge inaccessible shiffrin schneider 
hand successful accounting difference judicious forms representation rule level clearly explicit symbolic level implicit embedded knowledge 
simulation demonstrated promise model 
simulation conducted domains maze running navigation 
see sun sun details experiments 
supported part office naval research susan chipman helen 
agre chapman 
plans 
maes ed 
designing autonomous agents 
elsevier new york 
anderson 
acquisition cognitive skill 
psychological review 
vol pp 
anderson 
neurobiological correlate trial error 
progress neural networks 
ablex 
brooks 
intelligence representation 
artificial intelligence 
pp 
damasio 
neural knowledge access 
cold spring harbor symp 
quantitative biology vol lv 
press 
dreyfus dreyfus 
mind machine free press new york ny 
fu 
rule learning searching adapted nets proc aaai pp 
gelfand lane 
integrating knowledge systems neural networks robotic skill acquisition proc ijcai pp 
hendler 
marker passing microfeature proc th ijcai pp morgan kaufman james 
principles psychology 
dover ledoux 
brain mechanisms emotion emotional learning 
current opinion neurobiology 
vol 
lin 
self improving reactive agents reinforcement learning planning teaching 
machine learning 
vol pp 
schneider oliver connectionist control architecture 
vanlehn ed architectures intelligence erlbaum hillsdale nj 
shiffrin schneider 
controlled automatic human information processing ii 
psychological review 


smolensky 
proper treatment connectionism 
brain sciences 
sun 
integrating rules connectionism robust commonsense reasoning 
john wiley sons new york ny 
sun 
robust reasoning 
artificial intelligence 
pp 
sun peterson merrill 
bottomup skill learning reactive sequential decision tasks 
proc th cognitive science conference lea sun 
learning action consciousness neural networks sutton barto 
modern theory adaptive networks expectation prediction 
psychological review vol pp 
towell shavlik 
extracting refined rules knowledge neural networks machine learning 
watkins 
learning delayed rewards 
ph thesis cambridge university cambridge uk 
