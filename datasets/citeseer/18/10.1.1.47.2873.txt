instruction level parallelism reconfigurable computing timothy callahan john wawrzynek university california berkeley berkeley ca usa www cs berkeley edu projects brass 
reconfigurable coprocessors exploit large degrees instruction level parallelism ilp 
compiling sequential code reconfigurable coprocessors convenient borrow techniques previously developed exploiting ilp long instruction word vliw processors 
minor adaptations techniques natural match automatic compilation reconfigurable coprocessor 
review techniques original context describe adapted reconfigurable computing preliminary results compiling application programs written programming language 
consider compilation hybrid reconfigurable computing platform consisting microprocessor coupled field programmable gate array fpga circuitry reconfigurable accelerator 
fpga configured provide customized accelerator compute intensive tasks 
acceleration results part parallel execution operations fpga von neumann instruction fetch bottleneck 
microprocessor random control intensive application code system management tasks 
provides binary compatibility existing executables eases migration path reconfigurable computing 
assume support rapid run time reconfiguration allow different tasks application accelerated 
ease programming systems best single software language describing entire application encompassing computation microprocessor fpga 
traditional imperative software languages basically sequential nature starting challenging task exploit reconfigurable hardware parallel nature 
previous efforts corrected mismatch languages constructs explicitly specify data parallelism general parallelism 
farther language semantics deviate sequential languages difficult train programmers efficiently involved porting deck sequential code 
investigates automatic extraction hardware compilation code regions deck code 
resulting performance human rewrote code parallel style approach advantages gives immediate performance benefit reconfigurable hardware just recompilation ii useful cases execution time spread kernels worth recoding hand 
automatic compilation sequential code hardware poses challenges 
code basic blocks typically small little parallelism 
operations difficult implement directly hardware subroutine calls sprinkled code 
loops contain conditionals rarely executed branches interfere optimization 
features sequential code similarly caused problems vliw machines 
key technique vliw compilers overcome obstacles optimize common execution paths exclusion rarely executed paths 
applying techniques allows accelerate loops mapped coprocessor due operation infeasible implement hardware 
exclusion ability infeasible operation uncommon path prevent loop accelerated 
furthermore excluding uncommon paths remaining paths typically execute quickly case reconfigurable computing reconfigurable hardware resources required 
approach greatly influenced target platform theoretical garp chip 
garp chip tightly couples mips microprocessor datapath optimized reconfigurable coprocessor 
coprocessor rapidly reconfigurable making possible speed dozens hundreds loops 
desired configuration configuration cache loaded just cycles 
row garp array accessible single bit coprocessor register transfers coprocessor register microprocessor register performed rate clock cycle 
coprocessor directly access main memory system including data cache quickly microprocessor 
features garp coprocessor accelerate loops impractical implement traditional fpga coprocessor 
due features easily load uncommon computations main processor allowing common cases execute faster coprocessor 
vliw background vliw processors possess number functional units utilized parallel connected register file 
builders machines long ago encountered difficulty extracting ilp sequential programs keep functional units busy 
studies shown amount ilp basic block typically 
trace scheduling technique enhance amount ilp combining sequences basic blocks commonly executed linear path 
forms larger unit scheduling called trace ilp available 
approach works single dominant sequence successful multiple paths executed comparable frequency 
hyperblock developed address situation central structure borrow vliw compilation 
hyperblock formed contiguous group basic blocks usually including basic blocks different alternative control paths 
optimization purposes hyperblock typically include common control paths rarely taken paths 
definition hyperblock single point entry typically entry inner loop may multiple exits 
exit may jump back hyperblock forming back edge loop exit may jump excluded path loop exit may continue code case normal loop exit 
basic blocks may need duplicated outside hyperblock order single entry constraint obeyed 
fig 
shows example hyperblock 
selection duplication conversion predicated execution fig 

hyperblock formation vliw compilation 
basic blocks selected form hyperblock merged converting control flow form predicated execution 
consider specifically partially predicated execution 
partially predicated execution instructions included control paths executed unconditionally exception memory stores select instructions inserted control flow merge points select correct results subsequent computation fig 

select instruction operand called predicate true result value second operand result value third operand 
predicate expression boolean values originally controlled conditional branches 
result essentially speculative execution included paths approach rapidly consumes resources gives best performance exposes ilp reduces critical path lengths 
select store fig 

code control flow graph partially predicated execution 
challenge vliw compiler deciding basic blocks included hyperblock 
general rarely taken paths excluded 
excluding allows common cases achieve higher performance expense causing rare paths execute slowly due branch penalty exiting hyperblock 
factors considered selecting basic blocks compose hyperblock include relative execution frequencies resource limitations impact critical path 
hyperblock reconfigurable computing compiler uses hyperblock structure deciding parts program executed reconfigurable coprocessor converting operations selected basic blocks parallel form suited hardware 
able exclude certain paths implementation reconfigurable coprocessor useful 
making configuration smaller faster allows ignore certain operations impossible implement coprocessor subroutine calls long uncommon paths 
loop body implemented coprocessor unit existence subroutine call uncommon path exclude entire loop consideration acceleration coprocessor 
accelerated loop form hyperblock portion loop body implemented reconfigurable coprocessor 
hyperblock exits points execution transferred reconfigurable coprocessor back main processor 
hyperblock eventually coprocessor configuration configuration accelerated loop 
partially predicated execution representation maps directly hardware select instructions implemented multiplexors 
resulting dataflow graph similar operator network prism ii compiler 
adjustment hyperblock loop back edge exit directly back top hyperblock considered internal hyperblock 
reflects fact normal loop iteration control performed reconfigurable coprocessor intervention main processor 
back edge considered exit 
remaining exits classified finished exceptional 
finished exits taken loop finished iterations exit fig 

exceptional exits taken excluded basic block executed exit fig 

exceptional exit taken hyperblock may iteration 
mf exit conf mt exit backedge mf conf configure coprocessor mt move values coprocessor mf move values coprocessor exit mf move values coprocessor exit fig 

hyperblock formation compilation reconfigurable coprocessor 
hyperblock executed reconfigurable coprocessor basic blocks executed microprocessor 
execution model unit code gets accelerated coprocessor loop general loop nesting currently supported 
accelerated loops contain inner loops included paths 
loop contains inner loops excluded paths accelerated 
accelerated loop reached program processor activates correct configuration coprocessor moves initial data fpga registers starts coprocessor 
processor suspends wake coprocessor finished 
coprocessor executes simple sequencer keeps track current cycle iteration 
sequencer activates functional units scheduled specific cycle 
particular memory operation execute correct cycle cycles address input may invalid 
sequencer determine iteration reached 
number cycles iteration determined critical path hyperblock iteration 
iteration loop carried values latched iteration 
execution model specific automatic compilation 
inferred model allowed garp architecture 
coprocessor execution continue indefinitely exit taken 
exit occur cycle iteration hyperblock may different exits 
exit activated builtin feature garp reconfigurable array halt array instantaneously freezing values registers 
action awakens processor 
processor determine exit taken hyperblock 
done moves live values coprocessor back main registers 
transfer depends exit taken different sets live variables different exits different values variable different exits 
exceptional exit taken remainder iteration completed processor start iteration control transferred coprocessor 
compiler flow front 
suif compiler system implement prototype compiler targeting garp chip 
suif standard parser front optimizations utilized 
basic block representation code constructed control flow graph library 
library includes natural loop analysis routines allow recognize process kind loop formed backwards goto statement original source code 
hyperblock selection 
loop attempt form hyperblock 
initially basic blocks loop marked included blocks systematically excluded 
basic block excluded hyperblock contains infeasible operation floating point division remainder subroutine call ii entry inner loop hyperblock iii needs excluded order configuration fit available resources iv simply improve performance remaining hyperblock 
currently ii operational heuristics iii iv development 
exclusion block implies exclusion blocks due trimming process 
dead basic blocks blocks ultimately lead excluded blocks trimmed 
trim unreachable blocks reached going excluded block 
trimming know remaining basic block cycle contained completely hyperblock 
hyperblock duplication 
find useful duplicate basic blocks selected hyperblock retaining complete original non hyperblock version loop 
contrast vliw approach duplicates basic blocks necessary avoid re entering hyperblock 
purposes non hyperblock version software version loop hyperblock copy hardware version 
exceptional exit control flows hardware version continues corresponding point software version 
hardware version loop temporary construction presence aids construction interface instructions dataflow graph 
ultimately basic blocks hardware version deleted computation performed fpga 
interface synthesis 
points hardware version loop interfaces rest program interface code synthesized 
includes instructions load correct configuration move values back forth coprocessor main processor registers determine exit taken coprocessor finishes 
data transfer code synthesized live variable analysis avoid unnecessary transfers 
dataflow graph formation 
computation basic blocks duplicated hyperblock converted partially predicated execution form shown fig 

creates dataflow graph control flow converted explicit data transfer 
form maps directly reconfigurable hardware 
select instructions implemented hardware multiplexors analogous merge muxes prism ii 
number optimizations performed dataflow graph written synthesis 
number multiplexors reduced expense small amount extra boolean logic 
boolean signals results comparisons identified simplify multiplexors gates simplify comparisons ops inversions 
cases arise frequently due complex logical expressions typically code 
dataflow graph may contain multiple memory access operations 
determined compile time memory operations access location executed order appear sequential program input loads 
orderings preserved precedence edges dataflow graph edges indicate source node execute destination node 
precedence edges needed exits memory writes assure writes don occur shouldn occur 
synthesis 
dataflow graph written fed gama datapath synthesizer create configuration coprocessor 
gama looks opportunities merge neighboring operations example addition exclusive form compound functional unit smaller faster implementing individually 
gama synthesizes sequencer counts cycles iteration activates modules appropriately 
final compilation linking 
assuming synthesis successful code patched direct control hardware version loop 
modified code converted suif back cross compiled modified version gcc understands garp extensions mips instruction set 
final executable links software object files coprocessor configurations form integer array initialization data 
execution 
hardware currently available executable run garp simulator accurately models cache misses configuration loading delays important features provide accurate prediction execution behavior 
preliminary results primary benefits approach increasing performance computation coprocessor ii increasing fraction program accelerated coprocessor 
able evaluate magnitude benefit complete development heuristics excluding basic blocks get better performance 
collected preliminary data regarding second benefit excluding parts loop implemented hardware order allow remainder loop accelerated 
results table 
execution cycles classified categories cumulative time cycles category reported application dataset combinations 
categories follows single exit loops single exit contain infeasible operation 
multi exit loops multiple exits contain infeasible operations 
hyperblock loops excluded blocks due infeasible operations 
loops execute cycles exit overcome overhead coprocessor 
estimate factor speedup coprocessor cycles overhead exit 
loops executed cycles fewer exit average slowed coprocessor fall category 
admittedly rough guess 
cycles included straight line code code library routines code infeasible loops loops infeasible operation inner loop path body 
gzip examples see large fraction computation cycles captured relatively simple classes loops 
indicates loops gzip don contain infeasible operations 
hyperblock ability exclude paths helps small degree 
cpp examples hyperblock approach allows significant increase amount computation accelerated coprocessor 
loops cpp contain subroutine calls report errors 
top time consuming loops cpp contained infeasible operations infeasible operations executed third rarely executed 
gives anecdotal support intuitive feeling infeasible operations occur rarely executed paths 
table 
execution time breakdown cycles 
categories explained text 
single exit multi exit hyperblock total test case loops loops loops loops gzip source gzip english text cpp input cpp input summary adapted hyperblock vliw compilation compiling reconfigurable coprocessor 
commonly executed basic blocks combined form large hyperblock exposing instruction level parallelism allowing speculative execution achieve high performance reconfigurable hardware 
excluding rarely executed basic blocks compiler produce configurations smaller faster accelerate greater number loops possible 
preliminary results show cases approach significantly increases fraction execution cycles accelerated coprocessor compiling deck code 
develop hyperblock formation heuristics integrate path profiling information hardware estimation 
evaluate performance benefit intelligently excluding computation accelerated loop coprocessor 
benefited discussions brass research group including john hauser andr dehon 
randy harr synopsys anonymous reviewers comments earlier drafts 
supported part darpa dabt darpa afrl office naval research national science foundation cda 
agarwal ghosh 
asynchronous approach efficient execution programs adaptive architectures utilizing fpgas 
proceed ings ieee workshop fpgas custom computing machines pages 
ieee comput 
soc 
press 

page randall saul watts 
handel language guide 
callahan chong dehon wawrzynek 
rapid module mapping placement fpgas 
proc 
acm sigda international symposium field programmable gate arrays pages monterey ca usa 
acm 
dehon 
dpga coupled microprocessors commodity ics early st century 
proceedings ieee workshop fpgas custom computing machines pages 
ieee comput 
soc 
press 
hutchings 
density enhancement neural network fpgas run time reconfiguration 
proceedings ieee workshop fpgas custom computing machines pages napa ca apr 
ellis 
bulldog compiler vliw architectures 
mit press cambridge ma 
fisher rau 
instruction level parallel processing 
vassiliadis editors instruction level parallel processors pages 
ieee computer society press 
gokhale 
data parallel reconfigurable logic array 
journal supercomputing pages 
gonzalez 
data parallel programming model reconfigurable architectures 
proceedings ieee workshop fpgas custom computing machines pages 
ieee comput 
soc 
press 
hall anderson amarasinghe murphy 
liao bugnion lam 
maximizing multiprocessor performance suif compiler 
ieee computer dec 
see suif stanford edu 
hauser wawrzynek 
garp mips processor reconfigurable coprocessor 
proceedings ieee symposium fpgas custom computing machines napa ca apr 
holloway young 
flow analysis transformation libraries machine suif 
proceedings second suif compiler workshop aug 
available www suif stanford edu 
mahlke hank mccormick august hwu 
comparison full partial predicated execution support ilp processors 
proceedings nd annual international symposium computer architecture pages santa margherita ligure italy june 
acm 
mahlke lin chen hank 
effective compiler support predicated execution hyperblock 
proceedings th international symposium microarchitecture pages dec 
page luk 
compiling occam fpgas 
fpgas 
international workshop field programmable logic applications pages oxford uk sept 
wirth 
hardware compilation translating programs circuits 
ieee computer june 
