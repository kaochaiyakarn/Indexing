new extension kalman filter nonlinear systems simon julier jeffrey uhlmann robots ox ac uk uhlmann robots ox ac uk robotics research group department engineering science university oxford oxford ox pj uk phone fax kalman filter kf widely methods tracking estimation due simplicity optimality tractability robustness 
application kf nonlinear systems difficult 
common approach extended kalman filter ekf simply nonlinear models traditional linear kalman filter applied 
ekf forms widely filtering strategy years experience led general consensus tracking control community difficult implement difficult tune reliable systems linear time scale update intervals 
new linear estimator developed demonstrated 
principle set discretely sampled points parameterise mean covariance estimator yields performance equivalent kf linear systems generalises elegantly nonlinear systems linearisation steps required ekf 
show analytically expected performance new approach superior ekf fact directly comparable second order gauss filter 
method restricted assuming distributions noise sources gaussian 
argue ease implementation accurate estimation features new filter recommend ekf virtually applications 
keywords navigation estimation non linear systems kalman filtering sampling 
filtering estimation pervasive tools engineering 
state system estimated noisy sensor information kind state estimator employed fuse data different sensors produce accurate estimate true system state 
system dynamics observation models linear minimum mean squared error mmse estimate may computed kalman filter 
applications interest system dynamics observation equations nonlinear suitable extensions kalman filter sought 
known optimal solution nonlinear filtering problem requires complete description conditional probability density maintained unfortunately exact description requires potentially unbounded number parameters number suboptimal approximations proposed gamma probably widely estimator nonlinear systems extended kalman filter ekf ekf applies kalman filter nonlinear systems simply nonlinear models traditional linear kalman filter equations applied 
practice ekf known drawbacks 
linearisation produce highly unstable filters assumptions local linearity violated 

derivation jacobian matrices nontrivial applications lead significant implementation difficulties 
derive new linear estimator yields performance equivalent kalman filter linear systems generalises elegantly nonlinear systems linearisation steps required ekf 
fundamental component filter unscented transformation uses set appropriately chosen weighted points parameterise means covariances probability distributions 
argue expected performance new approach superior ekf fact directly comparable second order gauss filter 
nature transform process observation models treated black boxes 
necessary calculate jacobians algorithm superior implementation properties ekf 
demonstrate differences performance example application argue ease implementation accurate estimation features new filter recommend ekf virtually applications 
structure follows 
section describe problem statement applying kalman filter nonlinear systems 
argue principle problem ability predict state system 
section introduces unscented transformation 
properties analysed full filtering algorithm includes effects process noise developed 
section example 
realistic data comparison unscented filter ekf tracking reentry body considered 
drawn section 
companion extends basic method shows judiciously selecting additional points lead desired level accuracy prior distribution 
estimation nonlinear systems problem statement wish apply kalman filter nonlinear discrete time system form dimensional state system timestep input vector dimensional state noise process vector due disturbances modelling errors observation vector measurement noise 
assumed noise vectors zero mean theta ffi ij theta ffi ij theta kalman filter propagates moments distribution recursively distinctive predictor corrector structure 
estimate observation information information including time 
covariance estimate 
estimate filter predicts state system process model 
ideally predicted quantities expectations theta jz fx gamma fx gamma jz delta delta nonlinear precise values statistics calculated distribution condition known 
distribution general form potentially unbounded number parameters required 
applications distribution approximated finite tractable number parameters need propagated 
conventionally assumed distribution gaussian reasons 
distribution completely parameterised just mean covariance 
second moments known gaussian distribution informative estimate updating prediction current sensor measurement 
kalman filter linear update rule specified weights chosen minimise mean squared error estimate 
update rule gamma gamma gamma important note equations function predicted values moments 
problem applying kalman filter nonlinear system ability predict moments 
problem specific case general problem able calculate statistics random variable undergone nonlinear transformation 
transformation uncertainty problem predicting state observation system expressed form 
suppose random variable mean covariance xx second random variable related nonlinear function wish calculate mean covariance yy statistics calculated determining density function transformed distribution ii evaluating statistics distribution 
special cases example delta linear exact closed form solutions exist 
solutions exist general approximate methods 
advocate method yield consistent statistics 
ideally efficient unbiased 
transformed statistics consistent inequality yy gamma fy gamma yg fy gamma yg holds 
condition extremely important validity transformation method 
statistics consistent value yy estimated 
kalman filter uses inconsistent set statistics place weight information estimate covariance raising possibility filter diverge 
ensuring transformation consistent filter guaranteed consistent 
consistency necessary imply usefulness calculated value yy greatly excess actual mean squared error 
desirable transformation efficient value left hand side equation minimised 
desirable estimate unbiased 
problem developing consistent efficient unbiased transformation procedure examined considering taylor series expansion equation series expressed informal notation ffi ffi ffix ffi ffix fffi ffi ffix 
fffi ffi ffi 
fffi ffi ffix delta delta delta ffi ffi ffix zero mean gaussian variable covariance xx fffi ffi ffix appropriate nth order term multidimensional taylor series 
expectations shown transformed mean covariance xx theta ffi ffi ffix delta delta delta yy rf xx rf theta 
theta ffi ffi ffix gamma theta ffi ffi ffix yy gamma theta yy ffi ffi ffix yy 
fe theta ffi ffi ffix rf delta delta delta words nth order term series function nth order moments multiplied nth order derivatives delta evaluated moments derivatives evaluated correctly nth order mean correct nth order 
similar comments hold covariance equation structure term complicated 
term series scaled progressively smaller smaller term lowest order terms series greatest impact 
prediction procedure concentrated evaluating lower order terms 
linearisation assumes second higher order terms ffi ffi ffix equation neglected 
assumption yy rf xx rf comparing expressions equations clear approximations accurate second higher order terms mean fourth higher order terms covariance negligible 
practical situations linearisation introduces significant biases errors 
extremely common important problem transformation information polar cartesian coordinate systems demonstrated simple example subsection 
example suppose mobile robot detects beacons environment range optimised sonar sensor 
sensor returns polar information range bearing converted estimate cartesian coordinates 
transformation cos sin rf cos gammar sin sin cos real location target 
difficulty transformation arises physical properties sonar 
fairly range accuracy cm standard deviation traded give poor bearing measurement standard deviation ffi 
large bearing uncertainty causes assumption local linearity violated 
true mean ekf mean mean standard deviation ellipses actual linearised form transformation 
true mean theta uncertainty ellipse solid 
linearisation calculates mean ffi uncertainty ellipse dashed 
appreciate errors caused linearisation values statistics compared calculated true statistics calculated monte carlo simulation 
due slow convergence random sampling methods extremely large number samples theta ensure accurate estimates true statistics obtained 
results shown 
shows mean oe contours calculated method 
oe contour locus points fy gamma gamma gamma graphical representation size orientation yy seen linearised transformation biased inconsistent 
pronounced range direction linearisation estimates position reality cm 
extremely substantial 
linearisation errors effectively introduce error times standard deviation range measurement 
bias arises transformation process error sign committed time coordinate transformation takes place 
bias transformation inconsistent 
ellipse long direction 
fact nature inconsistency compounds problem biased ness estimate error estimated mean squared error smaller true value 
practice inconsistency resolved introducing additional noise increases size transformed covariance 
possible difficult tune sufficient noise introduced offset defects linearisation 
introducing noise undesirable solution estimate remains biased general guarantee transformed estimate remains consistent efficient 
accurate prediction algorithm required 
unscented transform basic idea transformation nonlinear principle unscented transform 
unscented transformation new novel method calculating statistics random variable undergoes nonlinear transformation 
founded intuition easier approximate gaussian distribution approximate arbitrary nonlinear function transformation approach illustrated 
set points sigma points chosen sample mean sample covariance xx nonlinear function applied point turn yield cloud transformed points yy statistics transformed points 
method bares superficial resemblance monte carlo type methods extremely important fundamental difference 
samples drawn random specific deterministic algorithm 
problems statistical convergence issue high order information distribution captured small number points 
dimensional random variable mean covariance xx approximated weighted points xx gamma xx xx ith row column matrix square root xx weight associated ith point 
transformation procedure follows 
instantiate point function yield set transformed sigma points 
mean weighted average transformed points 
covariance weighted outer product transformed points yy fy gamma yg fy gamma yg properties algorithm studied detail summary results 
mean covariance captured precisely second order calculated values mean covariance correct second order 
means mean calculated higher order accuracy ekf covariance calculated order accuracy 
performance benefits 
distribution approximated delta series expansion truncated particular order 
shown unscented algorithm able partially incorporate information higher orders leading greater accuracy 

sigma points capture mean covariance irrespective choice matrix square root 
numerically efficient stable methods cholesky decomposition 

mean covariance calculated standard vector matrix operations 
means algorithm suitable choice process model implementation extremely rapid necessary evaluate jacobians needed ekf 

provides extra degree freedom fine tune higher order moments approximation reduce prediction errors 
assumed gaussian useful heuristic select 
different distribution assumed different choice appropriate 

positive negative negative choice lead non positive semidefinite estimate yy problem uncommon methods approximate higher order moments probability density distributions situation possible modified form prediction algorithm 
mean calculated covariance evaluated shown modified form ensures positive semi definiteness limit lim xx lim yy rf xx rf words algorithm perform exactly second order gauss filter need calculate jacobians hessians 
true mean ekf mean kappa mean unscented transform applied measurement example 
performance benefits unscented transform seen shows means oe contours determined different methods 
true mean lies theta dotted covariance contour 
position unscented mean indicated contour solid 
linearised mean ffi dashed contour 
seen unscented mean value true value scale graph points lie top 
unscented transform consistent fact contour slightly larger true contour direction 
properties superior estimation accuracy ease implementation unscented transform better suited linearisation filtering applications 
predict mean covariance second order accuracy filter uses unscented transform performance truncated second order gauss filter require derivation jacobians hessians 
subsection examines application unscented transform filtering problem develops unscented filter 
unscented filter transformation processes occur kalman filter consist steps ffl predict new state system associated covariance 
prediction take account effects process noise 
ffl predict expected observation innovation covariance 
prediction include effects observation noise 
ffl predict cross correlation matrix xz steps easily accommodated slightly restructuring state vector process observation models 
state vector augmented process noise terms give dimensional 
set sigma points created applying equation augmented system equation 

transformed set instantiating point process model 
predicted mean computed 
predicted covariance computed fx gamma fx gamma 
instantiate prediction points observation model 
predicted observation calculated 
observation noise additive independent innovation covariance fz gamma gamma fz gamma gamma 
cross correlation matrix determined fx gamma gamma fz gamma gamma box prediction algorithm unscented transform 
vector process model rewritten function unscented transform uses sigma points drawn theta xv xv matrices leading diagonal covariances diagonal sub blocks correlations state errors process noises 
method requires additional sigma points means effects process noise terms impact mean covariance introduced order accuracy uncertainty state 
formulation means correlated noise sources arise schmidt kalman filters implemented extremely easily 
expression unscented transform equations box 
various extensions modifications basic method take account specific details application 
example observation noise introduced nonlinear fashion correlated process observation noise augmented vector expanded include observation terms 
section developed unscented transform filtering tracking applications 
section demonstrates benefits ekf sample application 
example application km reentry problem 
dashed line sample vehicle trajectory solid line portion earth surface 
position radar marked ffi 
section consider problem illustrated vehicle enters atmosphere high altitude high speed 
position body tracked radar accurately measures range bearing 
type problem identified number authors particularly stressful filters trackers strong nonlinearities exhibited forces act vehicle 
types forces act 
dominant aerodynamic drag function vehicle speed substantial nonlinear variation altitude 
second type force gravity accelerates vehicle centre earth 
final forces random terms 
effect forces gives trajectory form shown initially trajectory ballistic density atmosphere increases drag effects important vehicle rapidly motion vertical 
tracking problem difficult fact drag properties vehicle crudely known 
summary tracking system able track object experiences set complicated highly nonlinear forces 
depend current position velocity vehicle certain characteristics known precisely 
filter state space consists position body velocity parameter aerodynamic properties 
vehicle state dynamics drag related force term gravity related force term delta process noise terms 
defining distance centre earth absolute vehicle speed drag gravitational terms gammafi exp ae gamma oe gamma gm fi fi exp example parameter values fi gamma gm theta reflect typical environmental vehicle characteristics parameterisation ballistic coefficient fi reflects uncertainty vehicle characteristics fi ballistic coefficient typical vehicle scaled exp ensure value positive 
vital filter stability 
motion vehicle measured radar located 
able measure range bearing frequency hz gamma gamma tan gamma gamma gamma zero mean uncorrelated noise processes variances respectively high update rate extreme accuracy sensor means large quantity extremely high quality data available filter 
bearing uncertainty sufficiently ekf able predict sensor readings accurately little bias 
true initial conditions vehicle gamma gamma gamma gamma gamma gamma words vehicle coefficient twice nominal coefficient 
vehicle random accelerations theta gamma theta gamma initial conditions assumed filter gamma gamma gamma gamma gamma gamma filter uses nominal initial condition offset uncertainty variance initial estimate 
filters implemented discrete time observations taken frequency hz 
due intense nonlinearities vehicle dynamics equations euler approximation equation valid small time steps 
integration step set ms meant predictions mean squared error variance time results mean squared error variance time results mean squared error variance time results mean squared errors estimated covariances calculated ekf unscented filter 
graphs solid line mean squared error calculated ekf dotted line estimated covariance 
dashed line unscented mean squared error dot dashed line estimated covariance 
update 
unscented filter sigma point applied dynamics equations twice 
ekf necessary perform initial prediction step re second step 
performance filter shown 
plots estimated mean squared estimation error diagonal elements actual mean squared estimation error evaluated monte carlo simulations 
shown results similar cases seen unscented filter estimates mean squared error accurately possible confident filter estimates 
ekf highly inconsistent peak mean squared error km estimated covariance times smaller 
similarly peak mean squared velocity error theta gamma km gamma times true mean squared error 
seen highly biased bias slowly decreases time 
poor performance direct result linearisation errors 
argued principle difficulty applying kalman filter nonlinear systems need consistently predict new state observation system 
introduced new filtering algorithm called unscented filter 
virtue unscented transformation algorithm great advantages ekf 
able predict state system accurately 
second difficult implement 
benefits algorithm demonstrated realistic example 
considered specific form unscented transform particular set assumptions 
companion extend development unscented transform yield general framework derivation application 
shown number sigma points extended yield filter matches moments fourth order 
higher order extension effectively de biases common nonlinear coordinate transformations 
athans 
suboptimal state estimation continuous time nonlinear systems discrete noisy measurements 
ieee transactions automatic control tac october 
austin 
statistically linearized estimation reentry trajectories 
ieee transactions aerospace electronic systems aes january 

estimation control discrete kalman filter 
applied mathematical sciences page 
springer verlag 
chang whiting athans 
state parameter estimation maneuvering reentry vehicles 
ieee transactions automatic control ac february 
costa 
adaptive model architecture extended kalman bucy filters 
ieee transactions aerospace electronic systems aes april 

new exact nonlinear filters 
editor bayesian analysis time series dynamic models chapter pages 
marcel 
gordon salmond smith 
novel approach nonlinear non gaussian bayesian state estimation 
iee proceedings april 

stochastic processes filtering theory 
academic press 
julier uhlmann 
general method approximating nonlinear transformations probability distributions 
www www robots ox ac uk 
julier uhlmann 
consistent method converting polar cartesian coordinate systems 
proceedings aerosense th international symposium aerospace defense sensing simulation controls orlando florida 
spie 
acquisition tracking pointing xi 
julier uhlmann durrant whyte 
new approach filtering nonlinear systems 
proceedings american control conference seattle washington pages 
julier uhlmann durrant whyte 
new approach nonlinear transformation means covariances linear filters 
ieee transactions automatic control 
kushner 
approximations optimal nonlinear filters 
ieee transactions automatic control ac october 
kushner 
dynamical equations optimum non linear filtering 
journal differential equations 
bar shalom 
tracking consistent converted measurements vs ekf 
ieee transactions aerospace electronics systems aes july 
maybeck 
stochastic models estimation control volume 
academic press 

comparison nonlinear filters reentry vehicle tracking 
ieee transactions automatic control ac august 
press teukolsky vetterling flannery 
numerical recipes art scientific computing 
cambridge university press edition 
schmidt 
applications state space methods navigation problems 
editor advanced control systems volume pages 
academic press 
sorenson editor 
kalman filtering theory application 
ieee 
sorenson 
non linear filtering approximation posteriori density 
international journal control 
uhlmann 
algorithms multiple target tracking 
american scientist 
uhlmann 
simultaneous map building localization real time applications 
technical report university oxford 
transfer thesis 
