kdd project report error correcting codes efficient text classification large number categories ghani center automated learning discovery school computer science carnegie mellon university pittsburgh pa investigate error correcting output codes ecoc efficient text classification large number categories propose extensions improve performance ecoc 
ecoc shown perform classification tasks including text classification remains explored area ensemble learning algorithms 
explore error correcting codes short minimizing computational cost result highly accurate classifiers real world text classification problems 
results show ecoc particularly effective classification 
addition develop modifications improvements ecoc accurate intelligently assigning codewords categories learning decoding combining decisions individual classifiers order adapt different datasets 
reduce need labeled training data develop framework ecoc unlabeled data improve classification accuracy 
assign codewords categories depending learning decoding function standard hamming distance 
develop framework ecoc enable small amount labeled training data augment large amounts unlabeled data approach tested real world text classification tasks find short codes results efficient highly accurate high precision text classifiers learning decoding function adapt various datasets 
combination ecoc training labeled unlabeled data performs outperforms algorithms designed combine labeled unlabeled data 

related wide range statistical machine learning techniques applied text categorization including multivariate regression models fuhr schutze nearest neighbor classifiers yang probabilistic bayesian models koller sahami mccallum decision trees lewis ringuette neural networks schutze weigend symbolic learning apte cohen singer ensemble learning schapire singer ghani berger support vector machines dumais joachims :10.1.1.22.4864
error correcting codes shown increase accuracy decision trees neural networks non text data sets available irvine repository murphy aha artificial neural networks decision trees kong dietterich 
tried different random assignments codewords categories see significant performance differences 
schapire showed adaboost combined ecoc yield method superior ecoc uci datasets 
propose method combining boosting ecoc weights individual weak learners differently schapire show method outperforms schapire adaboost oc 
