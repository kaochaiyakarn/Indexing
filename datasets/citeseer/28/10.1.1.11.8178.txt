decision tree confidence factors multiagent control peter stone manuela veloso computer science department carnegie mellon university pittsburgh pa veloso cs cmu edu www cs cmu edu mmv 
decision trees widely classification tasks typically agent control 
presents novel technique agent control complex multiagent domain confidence factors provided decision algorithm 
robotic soccer example domain incorporates previously trained decision tree full multiagent behavior capable controlling agents entire game 
decision trees control behavior ability reason action execution time eliminate options adequate time executed successfully 
multiagent behavior represents bridge low level high level learning layered learning paradigm 
little multiagent systems require real time control noisy adversarial environments 
inherent complexity type multiagent system machine learning interesting promising area merge multiagent systems 
machine learning potential provide robust mechanisms leverage experience equip agents large spectrum behaviors ranging effective individual performance team collaborative achievement independently jointly set high level goals 
especially domains include independently designed agents conflicting goals adversaries learning may allow agents adapt unforeseen behaviors parts agents 
layered learning approach complex multiagent domains involves incorporating low level learned behaviors higher level behaviors :10.1.1.1.6598
simulated robotic soccer see section example domain neural network nn learn low level individual behavior ball interception incorporated basic collaborative behavior passing 
collaborative behavior learned decision tree dt :10.1.1.1.6598
extends basic learned behaviors full multiagent behavior capable controlling agents entire game 
control decisions confidence factors associated dt classifications novel approach 
machine learning potential provide robust mechanisms leverage experience equip agents large spectrum behaviors ranging effective individual performance team collaborative achievement independently jointly set high level goals 
especially domains include independently designed agents conflicting goals adversaries learning may allow agents adapt unforeseen behaviors parts agents 
layered learning approach complex multiagent domains involves incorporating low level learned behaviors higher level behaviors :10.1.1.1.6598
simulated robotic soccer see section example domain neural network nn learn low level individual behavior ball interception incorporated basic collaborative behavior passing 
collaborative behavior learned decision tree dt :10.1.1.1.6598
extends basic learned behaviors full multiagent behavior capable controlling agents entire game 
control decisions confidence factors associated dt classifications novel approach 
operator success probabilities previously stored tree structures confidence measures originally derived learning classification tasks 
ability reason action execution time eliminate options adequate time executed successfully 
section gives overview foundational robotic soccer domain 
new behavior explanations dt control agents reason action execution time section 
extensive empirical results reported section section concludes 
foundational section presents brief overviews robotic soccer research layered learning 
details regards topics :10.1.1.1.6598
robotic soccer described robotic soccer exciting ai domain reasons 
fast paced nature domain necessitates real time sensing coupled quick behaving decision making 
furthermore behaviors decisionmaking processes range simple reactive behaviors moving directly ball arbitrarily complex reasoning procedures take account actions perceived strategies teammates opponents 
opportunities demands innovative novel techniques abound 
robotic soccer described robotic soccer exciting ai domain reasons 
fast paced nature domain necessitates real time sensing coupled quick behaving decision making 
furthermore behaviors decisionmaking processes range simple reactive behaviors moving directly ball arbitrarily complex reasoning procedures take account actions perceived strategies teammates opponents 
opportunities demands innovative novel techniques abound 
robotic soccer systems developed simulation real robots :10.1.1.1.6598:10.1.1.125.9772:10.1.1.57.1412
robotic systems difficult expensive time consuming provide certain degree realism possible simulation 
hand simulators allow researchers isolate key issues implement complex behaviors run trials short amount time 
past research machine learning constrained situations developed full behavior learning techniques successfully game situation 
soccer server serves substrate system research reported captures real world complexities challenging domain 
designed domains complex learn mapping straight sensors actuators 
hierarchical bottom approach 
low level behaviors previously learned 
reported creates team behavior higher level learning 
date levels learned behaviors implemented :10.1.1.1.6598
soccer server clients neural network nn learn low level individual skill intercept moving ball 
learned skill learned higher level social skill involves multiple players 
second skill ability estimate likelihood pass particular teammate succeed learned decision tree dt 
dt trained assumption player receiving ball uses trained nn trying receive pass 
dt algorithm automatically returns confidence factors classifications 
confidence factors useful incorporating dt higher level behavior capable controlling client game situations 
learned behaviors described section ml techniques studied soccer server isolated situations 
resulting behaviors tested full game situations 
examine effectiveness game situations dt learned :10.1.1.1.6598
knowledge reports confidence factors dts agent control 
particular confidence factors returned classifications differentiate precisely options 
receiver choice functions recall dt estimates likelihood pass specific player succeed 
client dt game additional aspects behavior defined 
