gaze focus attention rainer stiefelhagen michael finke jie yang alex waibel stiefel ira uka de cs cmu edu yang cs cmu edu cs cmu edu interactive systems laboratories university karlsruhe germany carnegie mellon university usa identifying human gaze eye movement ultimately serves purpose identifying individual focus attention 
knowledge person object interest helps effectively communicate humans allowing identify conversants interests state mind intentions 
propose track focus attention participants meeting 
attention necessarily coincide gaze perceptual variable opposed physical eye head positioning 
automatic tracking focus attention achieved modeling persons head movements relative locations probable targets interest room 
video sequences taken meeting situation focus attention identified time 

face face communication discussions meetings humans verbal means variety visual cues communication 
example people gestures look monitor facial expressions conversation 
research interested tracking person looking meeting 
step goal find direction person looking gaze 
person gaze determined head pose eye gaze consider head pose indicator gaze 
related estimating human head pose categorized approaches model example approaches model approaches usually number facial features eyes nostrils lip corners located 
knowing relative positions facial features head pose computed 
detecting facial features challenging problem tracking fail 
example approaches kind function approximation technique neural networks face database encode example images 
head pose new images estimated function approximator neural networks matching novel images examples database 
example approaches usually facial landmark detection needed facial image classification 
interactive systems lab worked approaches 
employed purely neural network model approaches estimate user head pose 
demonstrated hybrid approach enhance robustness model system 
extend neural network approach estimating head pose unrestricted situation 
major contribution hidden markov model hmm detect user focus attention observed sequence gaze estimates 
interested direction user looking meeting want know looking 
requires way incorporating knowledge world system interpret observed data 
hmms provide integrated framework probabilistically interpreting observed signals time 
incorporated knowledge meeting situation approximate location participants meeting hmms initializing states person dependent hmms appropriately 
applying hmms tracking participants meeting looking 
feasibility proposed approach evaluated experimental results 
shows overview system user neural nets produce sequence gaze observations preprocessed facial images sequence gaze observations hmm compute sequence foci attention user 
remainder organized follows section describes neural network head pose estimation approach 
section introduce idea interpreting observed sequence gaze directions find user focus attention frame define underlying probability model give experimental results 
summarize section 
anns hmm 
system overview user neural nets produce sequence gaze observations preprocessed facial images sequence gaze observations hmm compute sequence foci attention user 

estimating head pose neural nets 
data collection setup main advantage neural networks estimate head pose compared model approach robustness model approaches head pose estimation head pose computed finding correspondences facial landmarks points eyes nostrils lip corners image respective locations head model 
approaches rely tracking minimum number facial landmark points image correctly difficult task fail 
hand neural network approach doesn require tracking detailed facial features facial region estimating user head pose 
approach neural networks estimate pan tilt person head automatically extracted preprocessed facial images input neural net 
approach similar approach described schiele 
system described estimated head rotation pan direction 
research neural network estimate head rotation pan tilt directions 
addition studied different image preprocessing approaches 
rae describe user dependent neural network system estimate pan tilt person 
approach color segmentation ellipse fitting gabor filtering segmented face preprocessing 
report average accuracy degrees pan degrees tilt user user dependent system 
remainder section describe neural net approach estimate user head pose pan tilt 
collected data train test neural networks 
different image preprocessing approaches investigated neural network architecture described 
experimental results obtained different types combinations input images neural nets 
data collection person collected data sit chair specific location room eyes height approximately cm 
distance meter height meter video camera record images placed tripod 
placed marks walls floor user look 
marks placed way user look specific known directions 
marks ranged degrees degrees pan mark degrees degrees degrees tilt mark degrees 
means data collection user look specific points top bottom left right 
user looking mark press mouse button images recorded hard disk labels indicating current head pose 
resulted set images user 
order collect slightly different facial images pose user asked speak person assisting data collection 
shows example images recorded data collection 
way collected data male female subjects 
approximately half persons wearing glasses 

example images take data collection training testing neural nets 
preprocessing images investigated different preprocessing approaches normalized grayscale images user face input neural nets applying edge detection images feeding nets locate extract faces collected images statistical skin color model 
largest skin colored region input image selected face 
preprocessing approach histogram normalization applied grayscale face images means normalizing different lighting conditions 
additional feature extraction performed normalized grayscale images downsampled fixed size images input nets 
second approach applied horizontal vertical edge operator plus facial grayscale images 
resulting edge images downsampled pixels input neural nets 
show corresponding preprocessed facial images person depicted 
left right normalized grayscale image horizontal vertical edge images depicted 
person 
preprocessed images normalized grayscale horizontal edge vertical edge image left right person 
preprocessed images normalized grayscale horizontal edge vertical edge image left right 
ann architecture trained separate nets estimate pan tilt person head 
training done multilayer perceptron architecture hidden layer standard backpropagation momentum term 
output layer net estimating pan consisted units representing different angles degrees 
output layer tilt estimating net consisted units representing tilt angles 
degrees 
nets gaussian output representation 
gaussian output representation single correct output unit activated training neighbours receive training activation decreasing distance correct label 
input retina neural nets varied units units depending different number types input images training see 

training results trained separate user independent neural nets estimate pan tilt 
neural nets trained data twelve subjects database evaluated remaining subjects 
data user consisted images results training set size images test set size images 
input neural nets evaluated different approaches 
histogram normalized grayscale images input nets 
horizontal vertical edge images input 
normalized grayscale plus horizontal vertical edge images input 
table summarizes results obtained different types input images 
normalized grayscale images input obtained mean error degrees pan degrees tilt user test set 
horizontal vertical edge images input slightly worse accuracy estimating pan obtained 
normalized grayscale image edge images input neural net significantly increased accuracy led accuracy degrees degrees mean error pan tilt respectively 
results show feasible train person independent neural net system head pose estimation 
fact obtained results slightly worse results obtained user dependent neural net system described rae 
compared results observe serious degradation data new users 
contrary results indicate neural nets generalize new users 
net input pan tilt grayscale edges edges grayscale table 
person independent results mean error degrees di erent preprocessing input images 
training done twelve users testing users 
system developed far observed problem limits system significantly tested system previously recorded data meeting took place room accuracy estimation seriously degraded 
believe mainly due different lighting conditions room data collection training nets took place computer lab windows room meeting took place daylight artificial illumination 
shows example images recorded meeting 
possible solutions problem investigate preprocessing methods reduce influence changing illumination collecting training data different lighting conditions 

modelling focus attention hidden markov models idea research map observed variable time gaze direction discrete states person looking focus attention 
hidden markov models hmm provide integrated framework probabilistically interpreting observed signals time 
section describe designed hmms estimate user focus attention 
incorporated knowledge observed scene approximate location foci attention people room hidden markov models 
model looking certain target modelled certain state hmm observed gaze estimates considered probabilistic functions different states 
model observation sequence gaze directions provided neural nets possible find sequence hmm states produced observations 
interpreting certain state looking certain target possible estimate person focus attention frame 
furthermore iteratively reestimate parameters hmm maximize likelihood observed gaze directions leading accurate estimates foci attention 
tested models image sequences recorded meeting 
meeting people sitting table talking looking looking table 
meeting taped speakers camera standing top table having person field view 
shows example images taken data collection meeting 
speakers estimated gaze trajectory neural nets described previous section 
user applied hmm detect focus attention observed gaze directions time 
applied user dependent hmms detect foci attention observed gaze directions time 
remainder section describe design hmm adapted hmm parameters give evaluation results video sequences 

example images meeting data hmm evaluation 
hmm design knowing people sitting table modelled targets person states looking person sitting right looking person left looking person front looking table 
model observable symbols state pose estimation results neural nets angles pan tilt pan tilt 
parameterized state dependent observation probabilities 
state left right center table dimensional gaussian distributions diagonal covariance matrices 
pan tilt pan pan pan 
tilt tilt tilt assuming know approximate positions participants meeting relative initialized observation probability distributions different states means gaussians set expected viewing angle looking corresponding target 
table shows initial values chosen respective means 
variances set value initially 
transition matrix ij initialized em expectation framework iteratively computing state sequence adapting model parameters follows means pan 
pan pan tilt 
tilt tilt state pan tilt left center right table variances table 
hmm states high transition probabilities remaining state aii uniformly distributed state transition probabilities transitions 
initial state distribution chosen uniform 

probabilistic model sequence gaze direction observations 
pan 
tilt predicted neural nets 
probability observation sequence hmm sum possible state sequences xy 
qt 
qt qt find single best state sequence foci attention observation sequence need find max efficiently computed viterbi algorithm 
hmm observation sequence gaze directions efficiently find sequence foci attention viterbi algorithm 
far considered hmm initialized knowledge setup meeting 
furthermore possible adapt model parameters hmm maximize oj 
done pan ei 
pan ei 
pan tilt ei 
tilt ei 
tilt transition probabilities ai number transition state evaluation sequences parameter reestimation converged iterations respectively 

results evaluate performance proposed model compared state sequence viterbi decoding hand labels person looking 
evaluated sequences contained frames lasted half minute 
evaluated performance hmm model parameter adaption automatic parameter adaption 
furthermore evaluated results obtained directly mapping output neural nets different viewing targets 
mapping obtained assigning network output directly specific target described table 
table reports obtained results 
seen compared directly output neural nets significant error reduction obtained hmm parameter adaption top ann output 
parameter reestimation error furthermore reduced factor evaluation sequences 
performing parameter reestimation sequences significant improvement accuracy adapted hmms hmms initialized knowledge observed 
means gaussians represent viewing angles different targets shifted initial estimates values better matched observations time 
pan tilt assigned state left center right table table 
direct mapping ann output viewing targets seq 
hmm hmm 
hmm 
table 
percentage falsely labelled frames hmm hmm parameter reestimation 
addressed problem tracking person focus attention meeting situation 
proposed hmm framework detect focus attention trajectory gaze observations evaluated proposed approach video sequences taken meeting 
obtained results show approach 
compared hand labels accuracy obtained hmm estimation focus attention 
estimate person gaze trained neural networks estimate head pose facial images 
combination normalized grayscale images horizontal vertical edge images faces input neural nets obtained accuracy degrees degrees pan tilt respectively test set users training set neural nets 
observed changed lighting conditions neural network pose seriously degraded 
possible solutions problem methods reduce influence changing illumination collecting data different lighting conditions train neural nets 
gee cipolla 
non intrusive gaze tracking human computer interaction 
proc 
mechatronics machine vision practise pages 
jebara pentland 
parametrized structure motion adaptive feedback tracking faces 
proceedings computer vision pattern recognition 
pentland moghaddam starner 
view modular eigenspaces face recognition 
proceedings ieee conference computer vision pattern recognition 
rabiner 
readings speech recognition chapter tutorial hidden markov models selected applications speech recognition pages 
morgan kaufmann 
rae ritter 
recognition human head orientation artificial neural networks 
ieee transactions neural networks march 
schiele waibel 
gaze tracking 
international workshop automatic face gesture recognition pages 
stiefelhagen yang waibel 
model gaze tracking system 
proceedings ieee international joint symposia intelligence systems pages 
stiefelhagen yang waibel 
tracking interaction people 
proceedings aaai spring symposium intelligent environments pages 
aaai press march 
yang waibel 
real time face tracker 
proceedings pages 
beymer shashua poggio 
example image analysis synthesis 
proceedings siggraph 
