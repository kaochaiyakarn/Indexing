scalable association text classification dimitris cs ust hk dimitris gr computer science department hong kong university science technology clear water bay hong kong china na bayes nb classifier long considered core methodology text classification mainly due simplicity computational efficiency 
increasing need methods achieve higher classification accuracy maintaining ability process large document collections 
examine text categorization methods perspective considers tradeoff accuracy scalability large data sets large feature sizes 
start observation support vector machines best text categorization methods scale handle large document collections involved real word problems 
consider bayesian extensions nb achieve higher accuracy relaxing strong independence assumptions 
experimental results show lb association lazy classifier achieve tradeoff high classification accuracy scalability large document collections large feature sizes 
contrast relational data mining scalability main issue trade quality scalability largely ignored number studies text classification 
strikingly na bayes nb classifier probably studied longest method text classification information retrieval attributes success accuracy simplicity low computational requirements 
scales linearly number features number documents 
nb majority supervised ir long time number studies shown alternative complex algorithms outperform nb terms classification performance 
algorithms originate variety research areas nearest neighbor neural networks regression rule induction support vector machines :10.1.1.14.6535
accuracy improvements significant variety real world data sets see comparative study algorithms 
support vector machines svm recognized effective text classification methods 
unfortunately applied large volumes data training time quadratic number training examples 
investigate extensions nb achieve higher accuracy performance significant terms scalability 
unfortunately applied large volumes data training time quadratic number training examples 
investigate extensions nb achieve higher accuracy performance significant terms scalability 
careful examination successful text classification methods level abstraction suggests efficiency large extend attributed common properties nb focus ones methods deviate independence assumption capture relationships sets words 
relaxation independence assumptions allows complex models built expected capture aspects reality 
second number methods focus context important text classification :10.1.1.14.6535
context insensitive classifiers build global models data influence word final decision independent presence absence words document 
natural languages meaning words clearly affected context 
word adopt example totally different meaning presence word child presence word strategy 
context sensitive learning methods aim higher performance capturing properties data 
new examples classified time linear number features 
tan tan extends nb account additional dependencies features 
employs modified version method proposed learn restricted tree structured bayesian network captures important dependencies pairs features 
result learning phase bayesian network structure feature connected exactly class 
forcing creation network incorporating model pair wise note similarity representation ripper called learning set valued features see :10.1.1.14.6535
dependencies allows relaxing strong independence assumptions nb time prevents creation complex bayesian network structures computationally expensive paying terms classification accuracy 
learning phase tan measures degree dependence pair wj wk calculating conditional mutual information class wj wk log wk value quantifies degree dependence words class 
highest value independence assumption violated 
wj wk conditionally independent class zero 
william cohen learning set valued features proc 
th national conference artificial intelligence aaai 
chow liu approximating discrete probability distributions dependence trees ieee trans 
information theory 
cohen singer context sensitive learning methods text categorization acm tois vol pp :10.1.1.14.6535
duda hart pattern classification scene analysis new york john wiley sons 
dumais platt heckerman sahami inductive learning algorithms representations text categorization th acm cikm conference 
friedman geiger goldszmidt bayesian network classifiers machine learning 
han pei yin mining frequent patterns candidate generation acm sigmod 
