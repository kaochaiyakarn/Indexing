machine learning natural language processing centre de de inform lsi universitat de upc barcelona lsi upc es july report collaborative fields machine learning ml natural language processing nlp 
document structured parts 
part includes superficial comprehensive survey covering state art machine learning techniques applied natural language learning tasks 
second part particular problem word sense disambiguation wsd studied detail 
doing algorithms supervised learning belong different families compared benchmark corpus wsd task 
qualitative quantitative drawn 
core problems addressed machine learning techniques natural language disambiguation appearing levels language understanding process 
particularly appropriate easily recast classification problems generic type problem long tradition artificial intelligence ai area especially addressed ml community 
applied ml methods include traditional symbolic inductive learning paradigms instance learning decision trees threshold linear separators inductive logic unsupervised clustering number subsymbolic connectionist approaches neural networks genetic algorithms 
additionally new specific learning algorithms proposed years 
case transformation learning :10.1.1.11.7760
approach permits adaptation general purpose machine learning algorithms classification known widely studied methods aim providing general frameworks disambiguation problems addressed simultaneously homogeneous techniques 
concrete publication statistics clearly illustrate extent revolution natural language research 
example full papers proceedings annual meeting association computational linguistics papers journal computational linguistics concerned corpus research percentages 
furthermore connection collaboration nlp machine learning communities noticeable international conferences journals areas experimented proliferation special issues natural language learning applications ml techniques natural language processing despite growing collaboration research performed natural language learning carried computational linguistics research community 
lau rosenfeld roukos proposed new approach combining statistical evidence different sources maximum entropy principle 
originated speech recognition field successfully applied word morphology pos tagging pp attachment disambiguation identification clause boundaries partial general parsing text categorization machine translation 
see broad methods survey existing applications 
hidden markov models referenced previous section seen stochastic models learning 
hmms major success low level tasks language disambiguation speech recognition synthesis pos tagging named entity recognition classification :10.1.1.79.5346
efforts interested consult url find larger list related www lsi upc es html 
available format bibtex links provided help obtain postscript versions original papers 
roth points learning methods statistical sense attempt inductive generalization observed data inferences respect previously unseen data 
extend hmm wsd partial parsing tagging grammatical functions bracketing simple constituents 
decision trees way represent rules underlying training data hierarchical sequential structures recursively partition data 
years disciplines statistics engineering pattern recognition decision theory decision table programming signal processing 
renewed interest generated research artificial intelligence machine learning expert systems 
fields application decision trees data exploration purposes description reduce volume data transforming compact form classification discover data contains separated meaningful clusters objects generalization uncovering mapping independent dependent variables useful predicting value dependent variable 
application nlp noticeable find tree solutions address natural language ambiguity problems levels speech recognition pos tagging word sense disambiguation parsing text categorization text summarization dialogue act tagging resolution cue phrase identification machine translation verb classification :10.1.1.161.6020:10.1.1.14.1232
magerman approach decision trees number simultaneous different decision making problems assigning part speech tags words assigning classification extracted 
constituent labels determining constituent boundaries sentence deciding scope conjunctions previous mixed statistical tree approach pick correct parse possibilities 
mixed approaches schmid introduced decision trees estimating transition probabilities hmm taggers 
concept learning decision trees translated rules eventually pruned representing target concept 
major drawback tbl computational cost instantiations templates tested iteration find best rule 
samuel efficient approximation called lazy tbl restrict search small subset possible instantiations applying monte carlo sampling techniques slight decrease accuracy 
way complex problems faced 
particular samuel colleagues applied new algorithm dialogue act tagging label utterance conversational dialogue correct dialogue act concise abstraction speaker intention 
rule learning system successfully applied text categorization cohen ripper algorithm :10.1.1.14.6535
case algorithm learns classifier form boolean combination simple terms 
linear separators linear separators multiplicative weight update algorithms shown exceptionally behaviour applied high dimensional problems presence noise specially target concepts depend small subset features feature space 
clearly usual scenario text processing domain 
roth colleagues designed snow architecture sparse network linear separators feature space winnow algorithm line adaptive learning 
case algorithm learns classifier form boolean combination simple terms 
linear separators linear separators multiplicative weight update algorithms shown exceptionally behaviour applied high dimensional problems presence noise specially target concepts depend small subset features feature space 
clearly usual scenario text processing domain 
roth colleagues designed snow architecture sparse network linear separators feature space winnow algorithm line adaptive learning 
applied successfully broad spectrum natural language disambiguation tasks including context sensitive spelling correction pos tagging pp attachment disambiguation shallow parsing text categorization word sense disambiguation achieving state art accuracies alternative algorithms :10.1.1.11.5378
methods linear separators applied text categorization task 
cohen singer experts weighted majority algorithm lewis widrow hoff exponentially gradient algorithms text categorization routing :10.1.1.14.6535
variation winnow algorithm reported competitive results text categorization task :10.1.1.11.5378
algorithms proved overcome commonly techniques rocchio algorithm variants classifier uses vectors numeric weights represent data vector space model works relevance feedback context 
clearly usual scenario text processing domain 
roth colleagues designed snow architecture sparse network linear separators feature space winnow algorithm line adaptive learning 
applied successfully broad spectrum natural language disambiguation tasks including context sensitive spelling correction pos tagging pp attachment disambiguation shallow parsing text categorization word sense disambiguation achieving state art accuracies alternative algorithms :10.1.1.11.5378
methods linear separators applied text categorization task 
cohen singer experts weighted majority algorithm lewis widrow hoff exponentially gradient algorithms text categorization routing :10.1.1.14.6535
variation winnow algorithm reported competitive results text categorization task :10.1.1.11.5378
algorithms proved overcome commonly techniques rocchio algorithm variants classifier uses vectors numeric weights represent data vector space model works relevance feedback context 
instance learning instance learning algorithms appeared areas ai different names similarity example case memory exemplar analogical form supervised inductive learning examples keeping full memory training material classifying new examples sort nn nearest neighbours algorithm :10.1.1.138.635
find uses kind algorithms nlp tasks 
roth colleagues designed snow architecture sparse network linear separators feature space winnow algorithm line adaptive learning 
applied successfully broad spectrum natural language disambiguation tasks including context sensitive spelling correction pos tagging pp attachment disambiguation shallow parsing text categorization word sense disambiguation achieving state art accuracies alternative algorithms :10.1.1.11.5378
methods linear separators applied text categorization task 
cohen singer experts weighted majority algorithm lewis widrow hoff exponentially gradient algorithms text categorization routing :10.1.1.14.6535
variation winnow algorithm reported competitive results text categorization task :10.1.1.11.5378
algorithms proved overcome commonly techniques rocchio algorithm variants classifier uses vectors numeric weights represent data vector space model works relevance feedback context 
instance learning instance learning algorithms appeared areas ai different names similarity example case memory exemplar analogical form supervised inductive learning examples keeping full memory training material classifying new examples sort nn nearest neighbours algorithm :10.1.1.138.635
find uses kind algorithms nlp tasks 
particularly relevant cardie addressed lexical semantic structural disambiguation full sentences limited domains information extraction environment :10.1.1.30.3222:10.1.1.21.6779
methods linear separators applied text categorization task 
cohen singer experts weighted majority algorithm lewis widrow hoff exponentially gradient algorithms text categorization routing :10.1.1.14.6535
variation winnow algorithm reported competitive results text categorization task :10.1.1.11.5378
algorithms proved overcome commonly techniques rocchio algorithm variants classifier uses vectors numeric weights represent data vector space model works relevance feedback context 
instance learning instance learning algorithms appeared areas ai different names similarity example case memory exemplar analogical form supervised inductive learning examples keeping full memory training material classifying new examples sort nn nearest neighbours algorithm :10.1.1.138.635
find uses kind algorithms nlp tasks 
particularly relevant cardie addressed lexical semantic structural disambiguation full sentences limited domains information extraction environment :10.1.1.30.3222:10.1.1.21.6779
additionally instance system takes advantage decision trees identifying relevant attributes :10.1.1.30.1899
refers relative pronoun resolution description kenmore framework general framework embedded machine learning algorithms global treatment natural language problems 
variation winnow algorithm reported competitive results text categorization task :10.1.1.11.5378
algorithms proved overcome commonly techniques rocchio algorithm variants classifier uses vectors numeric weights represent data vector space model works relevance feedback context 
instance learning instance learning algorithms appeared areas ai different names similarity example case memory exemplar analogical form supervised inductive learning examples keeping full memory training material classifying new examples sort nn nearest neighbours algorithm :10.1.1.138.635
find uses kind algorithms nlp tasks 
particularly relevant cardie addressed lexical semantic structural disambiguation full sentences limited domains information extraction environment :10.1.1.30.3222:10.1.1.21.6779
additionally instance system takes advantage decision trees identifying relevant attributes :10.1.1.30.1899
refers relative pronoun resolution description kenmore framework general framework embedded machine learning algorithms global treatment natural language problems 
equally essential ilk group tilburg university 
daelemans colleagues developed tilburg memory learning environment general instance algorithm compression base examples tree structure igtree classifying new examples 
algorithms proved overcome commonly techniques rocchio algorithm variants classifier uses vectors numeric weights represent data vector space model works relevance feedback context 
instance learning instance learning algorithms appeared areas ai different names similarity example case memory exemplar analogical form supervised inductive learning examples keeping full memory training material classifying new examples sort nn nearest neighbours algorithm :10.1.1.138.635
find uses kind algorithms nlp tasks 
particularly relevant cardie addressed lexical semantic structural disambiguation full sentences limited domains information extraction environment :10.1.1.30.3222:10.1.1.21.6779
additionally instance system takes advantage decision trees identifying relevant attributes :10.1.1.30.1899
refers relative pronoun resolution description kenmore framework general framework embedded machine learning algorithms global treatment natural language problems 
equally essential ilk group tilburg university 
daelemans colleagues developed tilburg memory learning environment general instance algorithm compression base examples tree structure igtree classifying new examples 
trees proved reduce significantly space requirements efficient accurate domains including phonology stress word pronunciation morphology linear threshold algorithms winnow simple line learning algorithms class problems binary valued input features 
trees proved reduce significantly space requirements efficient accurate domains including phonology stress word pronunciation morphology linear threshold algorithms winnow simple line learning algorithms class problems binary valued input features 
classify new examples simply calculate weighted sum input features linear combination outputs result threshold 
wrongly predicted training examples weights model change multiplicative way better fit training set 
pos tagging pp attachment disambiguation shallow parsing smoothing probability estimates 
authors include applications partial parsing chunking context sensitive parsing wsd text categorization semantic interpretation machine translation lexical acquisition analogy :10.1.1.30.3222:10.1.1.14.9307:10.1.1.105.3093
inductive logic programming ilp discipline devoted inductive learning prolog programs examples 
relevant relation natural language learning carried mooney colleagues university texas 
general survey applications ilp nlp 
particular works include applications grammatical inference automatic induction natural language interfaces querying data bases information extraction tasks acquisition verbal properties text categorization generation natural language :10.1.1.35.6633:10.1.1.25.4340
authors include applications partial parsing chunking context sensitive parsing wsd text categorization semantic interpretation machine translation lexical acquisition analogy :10.1.1.30.3222:10.1.1.14.9307:10.1.1.105.3093
inductive logic programming ilp discipline devoted inductive learning prolog programs examples 
relevant relation natural language learning carried mooney colleagues university texas 
general survey applications ilp nlp 
particular works include applications grammatical inference automatic induction natural language interfaces querying data bases information extraction tasks acquisition verbal properties text categorization generation natural language :10.1.1.35.6633:10.1.1.25.4340
subsymbolic machine learning approaches neural networks relation nlp neural networks basically address low level problems ocr speech recognition synthesis pos tagging 
basic models refer feed forward multilayer neural networks trained backpropagation algorithm include examples recurrent networks ensembles single neural networks 
examples addressing complex problems combination symbolic approaches identification clause boundaries parsing sentence analysis grammatical inference pp attachment disambiguation wsd text categorization detecting spelling errors 
day survey neural networks application nlp genetic algorithms genetic algorithms basically language learning problems non informed perspective trying infer word categories syntactic structure sole source unannotated corpora priori knowledge 
ensembles classifiers ensemble classifiers set classifiers individual decisions combined way usually weighted unweighted voting classify new examples 
techniques mainly studied supervised learning area proven ensembles accurate individual classifiers 
voting variants approaches related nlp problems find ensembles applied part speech tagging context sensitive spelling correction word sense disambiguation shallow parsing anaphora resolution complex combination strategies algorithms constructing ensembles including stacking bagging boosting text categorization text filtering adapted version popular adaboost algorithm information retrieval tasks 
applications adaboost variants nlp tasks include pos tagging pp attachment disambiguation word sense disambiguation full parsing 
relevant example combination classifiers applied information retrieval combination classifiers allows big set unlabelled examples semi supervised approach iteratively improve classification accuracy task filtering web pages :10.1.1.114.9164
support vector machines support vector machines svm introduced vapnik gaining popularity learning community 
svms structural risk minimization principle computational learning theory basic form learn linear hyperplane separates set positive examples set negative examples maximum margin margin defined distance hyperplane nearest positive negative examples 
despite basic algorithm appropriate kernel functions svms extended learn polynomial classifiers radial basic function rbf networks layer sigmoid neural nets 
svms applied number problems related pattern recognition 
current section reversed summary indexing information type nlp task solved 
information form tables 
notation machine learning algorithms appearing tables dts stands decision trees hmms stands hidden markov models statistical approaches stands maximum entropy approach ibl stands instance memory learning nns stands neural networks tbl stands transformation error driven learning nb stands naive bayes classifiers derived approaches lsm stands linear separators line classifiers multiplicative updating functions gas stands genetic algorithms stands clustering algorithms dls stands decision lists ilp stands inductive logic programming rocchio stands rocchio algorithm text categorization ri stands rule induction algorithms ec stands algorithm uses ensembles classifiers simple combination heuristics svm stands support vector machines stands log linear models 
table contains information low level nlp tasks speech processing morphology pos tagging 
nb dts hmms tbl nns speech recognition synthesis morphology pos tagging ibl lsm ec pos tagging table corresponding low level nlp tasks table contains parsing shallow general structural ambiguity resolution :10.1.1.79.5346
table groups semantic discourse level nlp tasks sense disambiguation resolution anaphora resolution dialogue act tagging text filtering categorization nlp tasks usually associated information retrieval information extraction 
table summarizes corresponding different levels lexical syntactic semantic language acquisition 
dts hmms ibl clause shallow parsing parsing pp attachment disambiguation tbl nb nns lsm ec clause shallow parsing parsing pp attachment disambiguation table corresponding syntactic analysis structural ambiguity nlp problems dls dts nb tbl em wsd text categorization filtering dialogue act tagging anaphora resolution cue phrase identification ibl nns ec svm wsd text categorization filtering anaphora :10.1.1.161.6020
rocchio ri ilp lsm gas wsd text categorization filtering information extraction table corresponding discourse level semantics nlp problems 
table contains information low level nlp tasks speech processing morphology pos tagging 
nb dts hmms tbl nns speech recognition synthesis morphology pos tagging ibl lsm ec pos tagging table corresponding low level nlp tasks table contains parsing shallow general structural ambiguity resolution :10.1.1.79.5346
table groups semantic discourse level nlp tasks sense disambiguation resolution anaphora resolution dialogue act tagging text filtering categorization nlp tasks usually associated information retrieval information extraction 
table summarizes corresponding different levels lexical syntactic semantic language acquisition 
dts hmms ibl clause shallow parsing parsing pp attachment disambiguation tbl nb nns lsm ec clause shallow parsing parsing pp attachment disambiguation table corresponding syntactic analysis structural ambiguity nlp problems dls dts nb tbl em wsd text categorization filtering dialogue act tagging anaphora resolution cue phrase identification ibl nns ec svm wsd text categorization filtering anaphora :10.1.1.161.6020
rocchio ri ilp lsm gas wsd text categorization filtering information extraction table corresponding discourse level semantics nlp problems 
ibl ilp nns gas lexical acquisition pos acquisition grammatical inference semantic acquisition table corresponding automatic language inference tasks :10.1.1.30.3222
table contains nlp tasks related machine translation spelling correction dts ibl tbl nb acquisition verbal properties general machine translation spelling correction dls ilp nns gas lsm acquisition verbal properties general machine translation spelling correction generation table corresponding machine translation nlp tasks word sense disambiguation case study supervised machine learning section devoted explain comparison machine learning algorithms applied word sense disambiguation 
organized follows sections describes word sense disambiguation problem 
table groups semantic discourse level nlp tasks sense disambiguation resolution anaphora resolution dialogue act tagging text filtering categorization nlp tasks usually associated information retrieval information extraction 
table summarizes corresponding different levels lexical syntactic semantic language acquisition 
dts hmms ibl clause shallow parsing parsing pp attachment disambiguation tbl nb nns lsm ec clause shallow parsing parsing pp attachment disambiguation table corresponding syntactic analysis structural ambiguity nlp problems dls dts nb tbl em wsd text categorization filtering dialogue act tagging anaphora resolution cue phrase identification ibl nns ec svm wsd text categorization filtering anaphora :10.1.1.161.6020
rocchio ri ilp lsm gas wsd text categorization filtering information extraction table corresponding discourse level semantics nlp problems 
ibl ilp nns gas lexical acquisition pos acquisition grammatical inference semantic acquisition table corresponding automatic language inference tasks :10.1.1.30.3222
table contains nlp tasks related machine translation spelling correction dts ibl tbl nb acquisition verbal properties general machine translation spelling correction dls ilp nns gas lsm acquisition verbal properties general machine translation spelling correction generation table corresponding machine translation nlp tasks word sense disambiguation case study supervised machine learning section devoted explain comparison machine learning algorithms applied word sense disambiguation 
organized follows sections describes word sense disambiguation problem 
section defines general framework supervised learning classification section presents ml algorithms 
section general setting including corpora experimental methodology 
black jelinek lafferty magerman mercer roukos 
history grammars richer models probabilistic parsing 
proceedings darpa workshop speech natural language san mateo ca 
cmp lg 
blum mitchell :10.1.1.114.9164
combining labeled unlabeled data training 
proceedings th annual conference computational learning theory colt pages madison wisconsin 
van den bosch daelemans 
morphological analysis classification inductive learning approach 
brill 
automatic grammar induction parsing free text transformation approach 
proceedings st annual meeting association computational linguistics 
www cs jhu edu brill html 
brill :10.1.1.11.7760
transformation error driven learning natural language processing case study part speech tagging 
computational linguistics 
brill resnik 
rule approach prepositional phrase attachment disambiguation 

prospects practical parsing unrestricted text robust statistical parsing techniques 
de eds corpus research language 
amsterdam 
brown della pietra della pietra mercer :10.1.1.14.1232
word sense disambiguation statistical methods 
proceedings th annual meeting association computational linguistics acl pages 
bruce wiebe 
decomposable modeling natural language processing 
claire cardie 
case approach knowledge acquisition domain specific sentence analysis 
proceedings th national conference artificial intelligence aaai pages 
aaai press mit press 
claire cardie :10.1.1.30.1899
decision trees improve case learning 
proceedings th international conference machine learning icml pages amherst ma 
morgan kaufmann 
claire cardie :10.1.1.30.3222
claire cardie :10.1.1.30.1899
decision trees improve case learning 
proceedings th international conference machine learning icml pages amherst ma 
morgan kaufmann 
claire cardie :10.1.1.30.3222
domain specific knowledge acquisition conceptual sentence analysis 
phd 
thesis university 
available university massachusetts technical report 
cohen 
learning classify english text ilp methods 
de raedt editor advances inductive logic programming pages 
ios press amsterdam 
cohen singer :10.1.1.14.6535
context sensitive learning methods text categorization 
proceedings th annual inter 
acm conference research development information retrieval 
collins brooks 
van de tu delft 
daelemans 
memory part speech tagger generator 
proceedings th workshop large corpora pages copenhagen denmark 
dagan roth :10.1.1.11.5378
mistake driven learning text categorization 
proceedings nd conference empirical methods natural language processing emnlp brown university providence ri 
dempster laird rubin 
maximum likelihood incomplete data em algorithm 


classes winnow sense winnow sense sense maximum activation snow examples training 
features nuclear average 
nuclear average snow architecture training step repeated times better adjust weights network :10.1.1.11.5378
order clarify training step repetitions equivalent neural network learning epochs 
utility retraining step dubious mentioned papers snow applied 
retraining implies add new parameter system 
training process finishes :10.1.1.11.5378
nuclear average snow architecture training step repeated times better adjust weights network :10.1.1.11.5378
order clarify training step repetitions equivalent neural network learning epochs 
utility retraining step dubious mentioned papers snow applied 
retraining implies add new parameter system 
training process finishes :10.1.1.11.5378
mistakes training examples 
maximum number epochs achieved say 
classifying new example snow similar neural network takes input features outputs class highest activation 
table shows particular parameter values experiments values empirically determined lead better accuracy algorithm wsd task 
mistakes training examples 
maximum number epochs achieved say 
classifying new example snow similar neural network takes input features outputs class highest activation 
table shows particular parameter values experiments values empirically determined lead better accuracy algorithm wsd task 
snow proven perform high dimensional domains training examples target function reside sparsely feature space text categorization context sensitive spelling correction :10.1.1.11.5378
adaboost mh detail section describes schapire singer adaboost mh algorithm multiclass multi label classification exactly notation authors 
new connection feature class activated weight initialized value jj threshold value divided number active features current example 
parameter value promotion ff demotion fi threshold initial weights jj number training epochs table snow parameter values said purpose boosting find highly accurate classification rule combining weak hypotheses weak rules may moderately accurate 
assumed exists separate procedure called acquiring weak hypotheses 
