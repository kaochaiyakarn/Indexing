decision theoretic generalization line learning application boosting yoav freund robert schapire labs park avenue florham park nj research att com december part consider problem dynamically resources set options worst case line framework 
model study interpreted broad extension studied line prediction model general decision theoretic setting 
show multiplicative rule littlestone warmuth adapted model yielding bounds slightly weaker cases applicable considerably general class learning problems 
show resulting learning algorithm applied variety problems including multiple outcome prediction repeated games prediction points second part apply multiplicative weight update technique derive new boosting algorithm 
boosting algorithm require prior knowledge performance weak learning algorithm 
study generalizations new boosting algorithm problem learning functions range binary arbitrary finite set bounded segment real line 
advances neural information processing systems 
harris drucker robert schapire simard 
boosting performance neural networks 
international journal pattern recognition artificial intelligence 
yoav freund :10.1.1.37.1595
data filtering distribution modeling algorithms machine learning 
phd thesis university california santa cruz 
retrievable ftp cse ucsc edu pub tr ucsc crl ps yoav freund 
boosting weak learning algorithm majority 
