learning attractor landscapes learning motor primitives jan ijspeert jun nakanishi stefan schaal university southern california los angeles ca usa atr human information science laboratories kyoto japan epfl swiss federal institute technology lausanne switzerland ijspeert usc edu jun atr jp usc edu control problems take place continuous state action spaces manipulator robotics control objective defined finding desired trajectory reaches particular goal state 
reinforcement learning offers theoretical framework learn control policies scratch applicability higher dimensional continuous state action spaces remains limited date 
learning scratch suggest learn desired complex control policy transforming existing simple canonical control policy 
purpose represent canonical policies terms differential equations defined attractor properties 
nonlinearly transforming canonical attractor dynamics techniques nonparametric regression arbitrary new nonlinear policies generated losing stability properties canonical system 
demonstrate techniques context learning set movement skills humanoid robot demonstrations human teacher 
policies acquired rapidly due properties formulated differential equations re modified line dynamic changes environment 
linear parameterization nonparametric regression lends recognize classify previously learned movement skills 
evaluations simulations actual degree humanoid robot exemplify feasibility robustness approach 
learning control formulated general forms learning control policy maps state possibly time dependent way action vector denotes adjustable parameters optimize policy 
learning control policies cps atomic state action representations time consuming faces problems higher dimensional continuous state action spaces current topic learning control epfl ch ijspeert higher level representations achieve faster robust learning :10.1.1.32.7692:10.1.1.32.7692
suggest novel encoding higher level representations analogy cps differential equations formulations suggest change state current state system usually encode desired goal form attractor state 
shaping attractor landscape policy scratch traditional methods reinforcement learning suggest start differential equation encodes rough form attractor landscape adapt landscape suitable current movement goal 
representation keep policy linear parameters rapid learning accomplished parameter vector may serve classify particular policy 
sections develop learning approach shaping attractor landscapes means statistical learning building preliminary previous :10.1.1.16.2291
second particular form canonical cps suitable manipulator robotics demonstrate methods classify movement equip actual humanoid robot variety movement skills imitation learning 
learning attractor landscapes consider learning scenario goal control attain particular attractor state formulated point attractor discrete movements limit cycle rhythmic movements 
point attractors require cp reach goal state particular trajectory shape irrespective initial conditions tennis swing ball typical example movement 
limit cycles goal trajectory shape limit cycle needs realized start state example complex beat hitting multiple drums period 
assume seed learning obtain multiple example trajectories defined positions velocities time 
samples asymptotically stable cp generated prescribing desired velocity particular state various methods suggested solve control problems literature 
simplest approach just demonstrated trajectories track desired trajectory 
mimic particular trajectory scaling laws account different start positions resultant control policy require time explicit variable highly sensitive unforeseen perturbations environment disrupt normal time flow 
spline approaches similar problem 
recurrent neural networks suggested possible alternative avoid explicit time indexing complexity training networks obtain stable attractor landscapes prevented widespread application far 
possible prime reinforcement learning system sample trajectories pursue established continuous state action learning algorithms investigations approach demonstrated limited efficiency 
sections alternative surprisingly simple solution learning control problem 
portions published :10.1.1.16.2291
extend preliminary studies improvement simplification rhythmic system integrated view interpretation discrete rhythmic cps fitting complete alphabet characters implementation automatic allocation centers kernel functions locally weighted learning 
note restrict approach purely kinematic cps assuming movement system equipped appropriate feedback feedforward controller accurately track kinematic plans generated policies 
table discrete rhythmic control policies 
ci positive constants 
start state discrete system order allow nonzero initial conditions 
design parameters discrete system temporal scaling factor goal position 
design parameters rhythmic system ym baseline oscillation period divided ro amplitude oscillations 
parameters wi fitted demonstrated trajectory locally weighted learning 
discrete rhythmic iwt iwt ym cos sin exp hi ci exp hi mod ci ci ci dynamical systems discrete movements assume basic control policy cp instance instantiated second order attractor dynamics known goal state time constants temporal scaling factor see correspond desired position velocity generated policy movement plan :10.1.1.32.7692
appropriate parameter settings equations form globally stable linear dynamical system unique point attractor 
insert nonlinear function eq change trivial exponential convergence allow complex trajectories way goal 
change eq enters domain nonlinear dynamics arbitrary complexity resulting equations expected 
best knowledge prevented research employing generic learning nonlinear dynamical systems far 
additional canonical dynamical system nonlinear function exp hi ci alleviate problem 
eq second order dynamical system similar eq linear modulated nonlinear function monotonic global convergence guaranteed proper choice assuming initial conditions state variables initially zero quotient serve phase variable anchor gaussian basis functions characterized center ci bandwidth hi act gating term nonlinear function influence function vanishes movement :10.1.1.32.7692
assuming boundedness weights wi eq shown combined dynamical system eqs asymptotically converges unique point attractor normalized basis function representation linear parameterization obvious choice nonlinearity allows applying variety dy dt dy dt mod cos sin time time time time examples time evolution discrete cps left rhythmic cps right 
parameters wi adjusted fit sin exp discrete cps cos sin rhythmic cps 
learning algorithms find wi 
learning sample trajectory characterized trajectory duration supervised learning problem formulated target trajectory eq right obtained integrating eq left corresponding goal state sample trajectory translated start 
order nominal assuming dynamics eqs span duration sample trajectory temporal scaling factor adjusted nominal dynamics achieves convergence solving function approximation problem chose nonparametric regression technique locally weighted learning lwl allows determine necessary number basis functions centers ci bandwidth hi automatically essence basis function lwl performs locally weighted regression training data obtain approximation tangent function approximated scope kernel prediction query point achieved weighted average predictions local models :10.1.1.47.8934
explained parameters wi learned lwl independent number basis functions robustly categorization different learned cps 
summary anchoring linear learning system nonlinear basis functions phase space canonical dynamical system guaranteed attractor properties able learn complex attractor landscapes nonlinear differential equations losing asymptotic convergence goal state 
extension limit cycle dynamics system extended limit cycle dynamics replacing canonical system instance rhythmic system stable limit cycle terms polar coordinates similar discrete system rhythmic canonical system serves provide amplitude signal cos sin phase variable mod basis function control policy ym iwt ym anchor point oscillatory trajectory 
table summarizes proposed discrete rhythmic cps shows exemplary time evolutions complete systems 
special properties control policies dynamical systems spatial temporal invariance interesting property discrete rhythmic cps spatially temporally invariant 
scaling goal discrete cp amplitude rhythmic cp affect topology attractor landscape 
similarly period rhythmic system duration discrete system trajectory directly determined parameter 
means amplitude durations periods learned patterns independently modified affecting qualitative shape trajectory section exploit properties reuse learned movement tennis swing instance novel conditions new ball positions 
robustness perturbations considering applications approach physical systems robots humanoids interactions environment may require line modification policy 
obstacle instance block trajectory robot case large discrepancies desired positions generated control policy actual positions robot occur 
outlined dynamical system formulation allows feeding back error term actual desired positions cps time evolution policy smoothly paused perturbation desired position modified remain close actual position soon perturbation stops cp rapidly resumes performing time delayed planned trajectory 
note task specific ways cope perturbations designed 
line adaptations interesting properties autonomous differential equations cps 
movement recognition temporal spatial invariance policy representation trajectories topologically similar tend fit similar parameters wi similar trajectories different speeds different amplitudes result similar wi 
section property demonstrate potential cps movement recognition 
experimental evaluations learning rhythmic control policies imitation tested proposed cps learning demonstration task humanoid robot 
robot meter tall dofs hydraulic anthropomorphic robot legs arms jointed torso head 
recorded trajectories performed human subject joint angle recording system see top 
joint angle trajectories fitted cps cp degree freedom dof 
cps replay movement humanoid robot inverse dynamics controller track desired trajectories generated cps 
actual positions dof fed back cps order take perturbations account 
joint angle recording system recorded set rhythmic movements tracing air sequence sticks 
dofs arms recorded shoulder elbow wrist 
exemplary movement replication robot demonstrated top 
left shows joint trajectories period exemplary beat 
demonstrated learned trajectories superposed 
learning base frequency extracted hand provide parameter rhythmic cp 
rhythmic movement learned cp modulated ways 
manipulating dofs amounts simultaneously saa hr eb wr time saa eb wr hr time time top humanoid robot learning movement human demonstration 
left recorded movement performed arms dofs arm 
dotted lines continuous lines correspond period demonstrated learned trajectories respectively 
right modification learned rhythmic pattern flexion extension right elbow eb 
trajectory learned rhythmic cp temporary modification ym ym dotted line ym correspond modified parameters 
movies human subject humanoid robot epfl ch ijspeert humanoid html 
modulate amplitude period dofs keeping phase relation dofs 
particularly useful task order replay beat pattern different speeds amplitudes 
alternatively parameters modulated independently dofs arm order able change beat pattern doubling frequency arm instance 
right illustrates different modulations generated rhythmic cps 
reasons clarity dof showed 
rhythmic cp smoothly modulate amplitude frequency baseline oscillations 
learning discrete control policies imitation experiment task robot learn tennis swings demonstrated human wearing joint angle recording system 
particular swing learned robot able repeat swing motion different cartesian targets providing new goal positions cps different dofs 
system cameras position ball inverse kinematic algorithm computes new goals joint space 
new ball positions distant original cartesian target modified trajectories reach ball swing motions similar demonstration 
movement recognition discrete control policies learning algorithm locally weighted learning automatically sets number kernel functions centers ci widths hi depending complexity function approximated kernel functions highly humanoid robot learning swing human demonstration :10.1.1.47.8934
nonlinear details movement 
interesting aspect locally weighted regression regression parameters wi kernel depend kernels regression separate cost function kernel 
means kernel functions added removed affecting parameters wi kernels 
feature perform movement recognition large variety trajectories small subset kernels fixed locations ci phase space 
fixed kernels common fitting trajectories addition kernels automatically added lwl algorithm 
stability parameters wi kernels generated lwl suited comparing qualitative trajectory shapes 
illustrate possibility cps movement recognition recognition spatiotemporal patterns just spatial patterns traditional character recognition carried simple task fitting trajectories performed human user drawing dimensional single stroke patterns 
letters graffiti alphabet hand held computers chosen 
characters drawn single stroke fed dimensional trajectory fitted system 
examples character see examples 
fixed sets kernels dof set aside movement recognition 
correlation wt wb wa wb parameter vectors wa wb character classify movements similar velocity profiles right 
instance instances characters correlation systematically higher examples character 
similarities weight space serve basis recognizing demonstrated movements fitting comparing fitted parameters wi previously learned policies memory 
example simple nearestneighbor classifier weight space serve purpose 
classifier alphabet instances letter obtained recognition rate instances highest correlation instance letter 
studies required evaluate quality recognition larger training test sets wanted demonstrate ability recognition specific system tuning sophisticated classification algorithm 
analogy autonomous differential equations control policies novel approach learn control policies basic movement skills shaping attractor landscape nonlinear differential equations statistical learning techniques 
best knowledge approach realization generic learning system nonlinear dynamical systems time time time time left examples dimensional trajectories fitted cps 
demonstrated fitted trajectories shown dotted continuous lines respectively 
right correlation weight vectors characters letter fitted system 
gray scale proportional correlation black corresponding correlation max 
correlation white correlation smaller 
guarantee basic stability convergence properties learned nonlinear systems 
demonstrated applicability suggested techniques learning various movement skills complex humanoid robot imitation learning illustrated usefulness learned parameterization recognition classification movement skills 
consider learning multidimensional control policies assuming independence individual dimensions suitability linear parameterization control policies reinforcement learning 
acknowledgments possible support national science foundation awards kawato dynamic brain project funded japan science technology atr human information science laboratories communications research laboratory crl 
sutton barto 
reinforcement learning 
mit press 
mussa ivaldi 
nonlinear force fields distributed system control primitives representing learning movements 
ieee international symposium computational intelligence robotics automation pages 
ieee computer society los alamitos 
ijspeert nakanishi schaal 
movement imitation nonlinear dynamical systems humanoid robots 
ieee international conference robotics automation icra pages 

ijspeert nakanishi schaal 
learning rhythmic movements demonstration nonlinear oscillators 
proceedings ieee rsj int 
conference intelligent robots systems iros pages 

kawamura 
interpolation input torque patterns obtained learning control 
proceedings third international conference automation robotics computer vision 

miyamoto schaal koike osu nakano wada kawato 
learning robot bi directional theory 
neural networks 
schaal 
learning demonstration 
mozer jordan petsche editors advances neural information processing systems pages 
cambridge ma mit press 
schaal atkeson :10.1.1.47.8934
constructive incremental learning local information 
neural computation 
atkeson hale kawato riley schaal shibata vijayakumar 
humanoid robots study human behavior 
ieee intelligent systems 
