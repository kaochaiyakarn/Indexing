hierarchically classifying documents words daphne koller gates building computer science department stanford university stanford ca koller cs stanford edu sahami gates building computer science department stanford university stanford ca sahami cs stanford edu proliferation topic hierarchies text documents resulted need tools automatically classify new documents hierarchies 
existing classification schemes ignore hierarchical structure treat topics separate classes inadequate text classification large number classes huge number relevant features needed distinguish 
propose approach utilizes hierarchical topic structure decompose classification task set simpler problems node classification tree 
show smaller problems solved accurately focusing small set features relevant task hand 
set relevant features varies widely hierarchy relevant feature set may large classifier examines small subset 
reduced feature sets allows utilize complex probabilistic models encountering standard computational robustness difficulties 
reduced feature sets allows utilize complex probabilistic models encountering standard computational robustness difficulties 
past decade witnessed explosion availability online information millions documents topic easily accessible internet 
available information increases inability people assimilate profitably utilize large amounts information apparent 
successful paradigm organizing mass information making comprehensible people categorizing different documents topic topics organized hierarchy increasing specificity 
hierarchical classifications type long special purpose collections documents medline hersh collections patent documents self :10.1.1.92.8815
internet search engines yahoo yahoo 
infoseek infoseek categorize contents world wide web 
bottleneck classification tasks need person read document decide appropriate place hierarchy 
clearly avoid bottleneck automatically classifying new documents 
furthermore variance resulting classifier typically large model parameters need estimated easily lead overfitting training data 
result typically able simple classifiers naive bayes 
previous schutze hull pedersen shown feature selection useful tool dealing issues 
eliminate words appear corpus topic 
previous koller sahami showed obtain significant increase accuracy reducing number words classification :10.1.1.155.2293
features computational cost robustness pose significant limitations 
propose new approach classification structured hierarchy topics 
ignoring topical structure building single huge classifier entire task structure break problem manageable size pieces 
basic insight supporting approach topics close hierarchy typically lot common topics far apart 
probabilistic framework general approach described consists constructing hierarchical set classifiers set relevant features 
uses main subroutines feature selection algorithm deciding appropriate feature set decision point supervised learning algorithm constructing classifier decision 
general approach instantiated variety ways depending choice subroutines 
chosen focus probabilistic methods feature selection classification 
probabilistic framework provides efficient principled techniques pruning large feature sets koller sahami range classifiers varying complexities accuracies pazzani friedman goldszmidt sahami singh provan :10.1.1.155.2293
provide brief overview probabilistic framework application classification feature selection 
bayesian classifiers heart probabilistic framework idea model world represented probability distribution space possible states world 
typically state world described set random variables state assignment values variables 
bayesian network pearl allows provide compact descriptions complex distributions large number random variables 
