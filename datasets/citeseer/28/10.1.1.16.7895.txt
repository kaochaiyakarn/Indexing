algorithm directed exploration model reinforcement learning factored mdps carlos cs stanford edu department computer science stanford university stanford ca usa cs uwaterloo ca dale schuurmans dale cs uwaterloo ca department computer science university waterloo waterloo canada central challenges reinforcement learning balance exploration exploitation tradeoff scaling large problems 
model reinforcement learning prominent value methods addressing challenges progress generated renewed interest pursuing modelbased approaches theoretical exploration exploitation tradeoff yielded provably sound model algorithms rmax factored mdp representations yielded model algorithms scale large problems 
benefits achievements combined factored algorithm kearns koller 
address significant shortcoming factored requires oracle planner feasibly implemented 
propose alternative approach uses practical approximate planner approximate linear programming maintains desirable properties 
develop exploration strategy targeted improving performance linear programming algorithm oracle planner 
parallel development significant progress developing compact representations large mdps 
representations scale logarithmically linearly size state space polynomial size state description 
polynomial size representation thought essential scale model mdp planning realistic problems 
approaches factored mdp representation developed koller parr proven particularly convenient 
combined linear value function approximators allows practically efficient planning algorithms linear programming easily implemented :10.1.1.19.8601
lines research exploration exploitation compact representations brought factored algorithm kearns koller 
algorithm combines theoretical exploration exploitation guarantees ability scale large state spaces afforded factored mdp representations 
shortcoming result relies oracle planning algorithm guarantee approximately optimal plans exploration exploitation steps 
unfortunately known approximate planning inherently hard problem factored mdps factored algorithm feasibly implemented main contribution investigate practical approach implementing factored versions rmax approximate planning algorithms preserving theoretical guarantees 
lines research exploration exploitation compact representations brought factored algorithm kearns koller 
algorithm combines theoretical exploration exploitation guarantees ability scale large state spaces afforded factored mdp representations 
shortcoming result relies oracle planning algorithm guarantee approximately optimal plans exploration exploitation steps 
unfortunately known approximate planning inherently hard problem factored mdps factored algorithm feasibly implemented main contribution investigate practical approach implementing factored versions rmax approximate planning algorithms preserving theoretical guarantees 
specifically consider approximate linear programming practical planning algorithm efficiently applied large problems factored form difficulty :10.1.1.19.8601
second contribution take development step demonstrate exploration exploitation strategy tailored specific approximate planning algorithm 
exploration requirements near minimal terms scale problem size approximation accuracy terms constant factors 
target exploration unknown region domain unknown regions relevant oracle planner effectively direct exploration domain uncertainties affect results approximate planner direct way 
fact show linear programming offers particularly elegant avenue identifying relevant uncertainties domain directing exploration effectively 
linear program guaranteed feasible set basis functions 
analogous linear program proposed discounted infinite horizon case 
general guarantee quality approximation obtained approach discounted reward case provides analysis error relative best possible approximation subspace 
transformation effect reducing number free variables linear program number constraints remains 
fortunately algorithms exploit structure factored mdp see section obtain compact representation efficient solution linear program :10.1.1.19.8601
second limitation explicit mdp planning approach unknown model parameters focus extensive field reinforcement learning rl 
algorithms explicit exploit explore rmax obtain provably near optimal performance time polynomial number states quantities 
unfortunately number states usually large handled explicitly exponential methods usually practical 
exploit structure factored mdp algorithms feasible 
koller parr suggest domains value function close structured approximated linear combination functions refers small number state variables 
precisely definition factored linear value function linear function basis 
restricted subset variables value functions type long history area multi attribute utility theory 

solving factored mdps linear programming factored value functions provide key performing efficient computations exponential sized state spaces encountered factored mdps :10.1.1.19.8601
key insight restricted domain functions including basis functions allow certain operations implemented efficiently 
basic operations combined create various practical algorithms 
section briefly review linear programming approach outlined solved efficiently mdp represented factored model :10.1.1.19.8601
key operation computation backprojection basis function dbn action expectation summation exponential number states 

solving factored mdps linear programming factored value functions provide key performing efficient computations exponential sized state spaces encountered factored mdps :10.1.1.19.8601
key insight restricted domain functions including basis functions allow certain operations implemented efficiently 
basic operations combined create various practical algorithms 
section briefly review linear programming approach outlined solved efficiently mdp represented factored model :10.1.1.19.8601
key operation computation backprojection basis function dbn action expectation summation exponential number states 
shown simplified substantially 
recall assumption scope small subset variables scope parents 
specifically value 
basis functions precomputed write constraints exponentially constraints functions restricted scope depend small sets variables 
demonstrated constraints represented compactly exponentially smaller set constraints lp variables algorithm resembling variable elimination 
similarly schuurmans showed constraint sets built incrementally efficient constraint generation scheme 
unfortunately discussed section currently known obtain strong formal guarantees quality policies obtained approximate linear programming 
demonstrated linear programs efficient generate reasonable policies :10.1.1.19.8601
currently approach appropriate obtaining linear approximations factored mdps 

factored far described representation algorithm planning mdps exponentially large state spaces 
addressed concern standard mdp approach section scaling addressed second concern unknown model parameters 
policy quality legs network problem computers 
log resource problem tasks resources lp rmax exact 
resource allocation problem tasks resources 
mdps 
strategy addresses strong practical limitations factored algorithm assuming existence oracle perform near optimal planning factored mdps tailor exploration particular planning algorithm approximate linear programming shown scale large problems :10.1.1.19.8601
targeting exploration unknown region domain unknown regions relevant oracle planner algorithm effectively direct exploration domain uncertainties affect results approximate planner directly 
furthermore strategy better data collected 
labeling states known unknown transition probabilities known states factored incorporate confidence intervals estimates model parameters linear programming approach 
estimates sample efficiency number samples needed confidence level depends logarithmically number actions basis functions domain size basis functions 
