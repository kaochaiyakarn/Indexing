machine learning fl kluwer academic publishers boston 
manufactured netherlands 
text classification labeled unlabeled documents em kamal nigam cs cmu edu andrew mccallum mccallum justresearch com sebastian thrun thrun cs cmu edu tom mitchell tom mitchell cmu edu school computer science carnegie mellon university pittsburgh pa just research henry street pittsburgh pa received march revised february editor william cohen 
shows accuracy learned text classifiers improved augmenting small number labeled training documents large pool unlabeled documents 
important text classification problems obtaining training labels expensive large quantities unlabeled documents readily available 
introduce algorithm learning labeled unlabeled documents combination expectation maximization em naive bayes classifier 
keywords text classification expectation maximization integrating supervised unsupervised learning combining labeled unlabeled data bayesian learning 
consider problem automatically classifying text documents 
problem great practical importance massive volume online text available world wide web internet news feeds electronic mail corporate databases medical patient records digital libraries 
existing statistical text learning algorithms trained approximately classify documents sufficient set labeled training examples 
text classification algorithms automatically catalog news articles lewis gale joachims web pages craven dipasquo freitag mccallum mitchell nigam slattery shavlik rad automatically learn reading interests users pazzani muramatsu billsus lang nigam mccallum thrun mitchell cally sort electronic mail lewis knowles sahami dumais heckerman horvitz :10.1.1.16.3103:10.1.1.11.6124
key difficulty current algorithms issue addressed require large prohibitive number labeled training examples learn accurately 
labeling done person time consuming process 
take example task learning usenet newsgroup articles interest particular person reading usenet news 
systems filter pre sort articles ones user finds interesting highly desirable great commercial interest today 
fact estimate classification unlabeled documents find word lecture occurs frequently unlabeled examples believed belong positive class 
cooccurrence words homework lecture large set unlabeled training data provide useful information construct accurate classifier considers homework lecture indicators positive examples 
explain correlations helpful source information increasing classification rates specifically labeled data scarce 
uses expectation maximization em learn classifiers take advantage labeled unlabeled data 
em class iterative algorithms maximum likelihood maximum posteriori estimation problems incomplete data dempster laird rubin :10.1.1.133.4884
case unlabeled data considered incomplete come class labels 
algorithm trains classifier available labeled documents uses classifier assign probabilistically weighted class labels unlabeled document cal text classification labeled unlabeled documents em expectation missing class labels 
trains new classifier documents originally labeled unlabeled iterates 
maximum likelihood formulation em performs hill climbing data likelihood space finding classifier parameters locally maximize likelihood data labeled unlabeled 

discussion note assumptions generation text documents mixture model correspondence mixture components classes word independence document length distribution violated real world text data 
documents mixtures multiple topics 
words document independent grammar topicality 
despite violations empirically naive bayes classifier job classifying text documents lewis ringuette craven yang pederson joachims mccallum rosenfeld mitchell ng :10.1.1.21.7950:10.1.1.35.6633:10.1.1.35.6633
observation explained part fact classification estimation function sign binary classification function estimation domingos pazzani friedman 
word independence assumption causes naive bayes give extreme class probability estimates 
estimates poor classification accuracy remains high 
formulation naive bayes uses generative model accounts number times word appears document 
observation explained part fact classification estimation function sign binary classification function estimation domingos pazzani friedman 
word independence assumption causes naive bayes give extreme class probability estimates 
estimates poor classification accuracy remains high 
formulation naive bayes uses generative model accounts number times word appears document 
multinomial lan text classification labeled unlabeled documents em guage modeling terms unigram model classifier mixture multinomials mccallum nigam :10.1.1.13.8629:10.1.1.46.1529
formulation numerous practitioners naive bayes text classification lewis gale joachims li mitchell mccallum lewis :10.1.1.21.7950:10.1.1.21.7950:10.1.1.16.3103:10.1.1.16.3103
formulation naive bayes text classification uses generative model document representation word vocabulary binary feature modeled mixture multi variate robertson sparck jones lewis larkey croft koller sahami 
empirical comparisons show multinomial formulation yields classifiers consistently higher accuracy mccallum nigam :10.1.1.13.8629:10.1.1.46.1529

word independence assumption causes naive bayes give extreme class probability estimates 
estimates poor classification accuracy remains high 
formulation naive bayes uses generative model accounts number times word appears document 
multinomial lan text classification labeled unlabeled documents em guage modeling terms unigram model classifier mixture multinomials mccallum nigam :10.1.1.13.8629:10.1.1.46.1529
formulation numerous practitioners naive bayes text classification lewis gale joachims li mitchell mccallum lewis :10.1.1.21.7950:10.1.1.21.7950:10.1.1.16.3103:10.1.1.16.3103
formulation naive bayes text classification uses generative model document representation word vocabulary binary feature modeled mixture multi variate robertson sparck jones lewis larkey croft koller sahami 
empirical comparisons show multinomial formulation yields classifiers consistently higher accuracy mccallum nigam :10.1.1.13.8629:10.1.1.46.1529

incorporating unlabeled data em proceed main topic unlabeled data improve text classifier 
formulation naive bayes uses generative model accounts number times word appears document 
multinomial lan text classification labeled unlabeled documents em guage modeling terms unigram model classifier mixture multinomials mccallum nigam :10.1.1.13.8629:10.1.1.46.1529
formulation numerous practitioners naive bayes text classification lewis gale joachims li mitchell mccallum lewis :10.1.1.21.7950:10.1.1.21.7950:10.1.1.16.3103:10.1.1.16.3103
formulation naive bayes text classification uses generative model document representation word vocabulary binary feature modeled mixture multi variate robertson sparck jones lewis larkey croft koller sahami 
empirical comparisons show multinomial formulation yields classifiers consistently higher accuracy mccallum nigam :10.1.1.13.8629:10.1.1.46.1529

incorporating unlabeled data em proceed main topic unlabeled data improve text classifier 
naive bayes just small set labeled training data classification accuracy suffer variance parameter estimates generative model high 
augmenting small set large set unlabeled data combining sets em improve parameter estimates 

incorporating unlabeled data em proceed main topic unlabeled data improve text classifier 
naive bayes just small set labeled training data classification accuracy suffer variance parameter estimates generative model high 
augmenting small set large set unlabeled data combining sets em improve parameter estimates 
em class iterative algorithms maximum likelihood maximum posteriori estimation problems incomplete data dempster :10.1.1.133.4884
case unlabeled data considered incomplete come class labels 
applying em naive bayes quite straightforward 
naive bayes parameters estimated just labeled documents 
classifier assign probabilistically weighted class labels unlabeled document calculating expectations missing class labels jd 
example newsgroups data set classification error reduced trained labeled unlabeled documents 
certain data sets especially number labeled documents high incorporation unlabeled data basic em scheme may reduce increase accuracy 
show application em extensions described previous section increases performance naive bayes 

datasets protocol newsgroups data set joachims mccallum mitchell collected ken lang consists articles divided evenly different usenet discussion groups :10.1.1.21.7950
task classify article newsgroup posted 
categories fall confusable clusters example comp discussion groups discuss religion 
words stoplist common short words removed unique words occur feature selection 
tokenizing data skip usenet headers discarding subject line tokens formed contiguous alphabetic characters left unstemmed 
sets created equal numbers text classification labeled unlabeled documents em documents class 
experiments different labeled set sizes create sets size obviously fewer sets possible experiments labeled sets containing documents 
non overlapping training set comprises new trial experiment 
results reported averages trials experiment 
webkb data set craven contains web pages gathered university computer science departments :10.1.1.35.6633:10.1.1.35.6633
collection includes entirety departments additionally assortment pages universities 
pages divided categories student faculty staff course project department 
non categories student faculty course project containing pages 
task classify web page appropriate categories 
collection includes entirety departments additionally assortment pages universities 
pages divided categories student faculty staff course project department 
non categories student faculty course project containing pages 
task classify web page appropriate categories 
consistency previous studies data set craven tokenizing webkb data numbers converted time phone number token appropriate sequence length token :10.1.1.35.6633:10.1.1.35.6633
stemming stoplist stoplist hurt performance 
example excellent indicator student homepage fourth ranked word information gain 
limit vocabulary informative words measured average mutual information class variable 
feature selection method commonly text yang pederson koller sahami joachims :10.1.1.21.7950
consistency previous studies data set craven tokenizing webkb data numbers converted time phone number token appropriate sequence length token :10.1.1.35.6633:10.1.1.35.6633
stemming stoplist stoplist hurt performance 
example excellent indicator student homepage fourth ranked word information gain 
limit vocabulary informative words measured average mutual information class variable 
feature selection method commonly text yang pederson koller sahami joachims :10.1.1.21.7950
selected vocabulary size running leave cross validation training data optimize classification accuracy 
webkb data set collected part effort create crawler explores previously unseen computer science departments classifies web pages knowledge base ontology 
mimic crawler intended avoid reporting performance idiosyncrasies particular single department test leave university approach 
create test sets containing pages complete computer science departments 
test set unlabeled set pages formed randomly selecting remaining web pages 
non overlapping training sets formed method newsgroups 
results reported averages trials share number labeled training documents 
reuters distribution data set consists articles topic categories reuters newswire 
studies joachims liere tadepalli build binary classifiers classes identify news topic :10.1.1.11.6124:10.1.1.74.2349
words inside text 
tags including title remove reuter tags occur top bottom document 
stoplist stem 
reuters classifiers different categories perform best widely varying vocabulary sizes chosen average mutual information class variable 
tags including title remove reuter tags occur top bottom document 
stoplist stem 
reuters classifiers different categories perform best widely varying vocabulary sizes chosen average mutual information class variable 
variance optimal vocabulary size 
previously noted joachims categories wheat corn known strong correspondence small set words title words cate nigam mccallum thrun mitchell categories acq known complex characteristics :10.1.1.21.7950
categories narrow definitions attain best classification small vocabularies broader definition require large vocabulary 
vocabulary size reuters trial selected optimizing accuracy measured cross validation labeled training set 
newsgroups data set time dependencies reuters 
standard train test split divides articles time documents form test set earlier available training 
results reuters reported precision recall breakeven points standard information retrieval measure binary classification 
accuracy performance metric high accuracy achieved predicting negative class 
task data set classification filtering find positive examples large sea negative examples 
recall precision capture inherent duality task defined recall correct positive predictions positive examples precision correct positive predictions positive predictions classifier achieve trade precision recall adjusting decision boundary positive negative class away previous default jd 
precision recall breakeven point defined precision recall value equal joachims :10.1.1.11.6124
algorithm experiments em described table 
section leave cross validation performed conjunction em simplification computational efficiency 
run em convergence training data subtract word counts labeled document turn testing document 
performing cross validation specific combination parameter settings run em required run em labeled example 
research improved methods model selection algorithm area 

related expectation maximization known family algorithms long history applications 
application classification new statistics literature 
idea em procedure improve classifier treating unclassified data incomplete mentioned little published responses original em dempster :10.1.1.133.4884
discussion partial classification paradigm descriptions mclachlan book mixture models page 
nigam mccallum thrun mitchell studies machine learning literature em combine labeled unlabeled data classification miller 
naive bayes mixture gaussians miller mixtures experts 
demonstrate experimental results non text data sets features 
jaakkola jordan provide general discussion mixtures improve mean field approximations naive bayes example 
paradigm reduces need labeled training examples active learning 
scenario algorithm repeatedly selects unlabeled example asks human true class label classifier 
active learning algorithms differ methods selecting unlabeled example 
examples applied text query committee dagan engelson liere tadepalli relevance sampling uncertainty sampling lewis gale lewis :10.1.1.30.6148:10.1.1.16.3103:10.1.1.16.3103:10.1.1.16.3103:10.1.1.74.2349
authors combines active learning mccallum nigam :10.1.1.13.8629:10.1.1.46.1529
em applied unlabeled documents help inform algorithm choice documents labeling requests boost accuracy documents remain unlabeled 
experimental results show combination active learning em requires slightly half labeled training examples achieve accuracy active learning em 
text classification labeled unlabeled documents em effort unlabeled data support supervised learning training blum mitchell 
paradigm reduces need labeled training examples active learning 
scenario algorithm repeatedly selects unlabeled example asks human true class label classifier 
active learning algorithms differ methods selecting unlabeled example 
examples applied text query committee dagan engelson liere tadepalli relevance sampling uncertainty sampling lewis gale lewis :10.1.1.30.6148:10.1.1.16.3103:10.1.1.16.3103:10.1.1.16.3103:10.1.1.74.2349
authors combines active learning mccallum nigam :10.1.1.13.8629:10.1.1.46.1529
em applied unlabeled documents help inform algorithm choice documents labeling requests boost accuracy documents remain unlabeled 
experimental results show combination active learning em requires slightly half labeled training examples achieve accuracy active learning em 
text classification labeled unlabeled documents em effort unlabeled data support supervised learning training blum mitchell 
consider particular subclass learning problems distinct problems addressed 
text classification labeled unlabeled documents em effort unlabeled data support supervised learning training blum mitchell 
consider particular subclass learning problems distinct problems addressed 
particular consider problems target function learned attributes describing instance partitioned sets sufficient calculate redundancy attributes describing allows learning distinct classifiers train unlabeled data 
experimental results showing success approach web page classification task proof certain conditions target function pac learned initial weak classifier unlabeled data 
variety statistical techniques naive bayes applied text classification including support vector machines joachims nearest neighbor yang tfidf rocchio salton rocchio exponential gradient covering algorithms cohen singer :10.1.1.11.6124
naive bayes strong probabilistic foundation efficient large data sets 
furthermore thrust straightforwardly demonstrate value unlabeled data similar approach apply unlabeled data complex classifiers 

summary family algorithms address question unlabeled data may supplement scarce labeled data especially learning classify text documents 
believe algorithm unlabeled data require closer match data generative model labeled data 
intended target concept model differ actual distribution data strongly unlabeled data hurt help performance 
intend closer theoretical empirical study tradeoffs unlabeled data inherent model inadequacies 
see interesting directions unlabeled data 
task formulations benefit em active learning explicit model unlabeled data incorporate em improve selection examples request label improve classification accuracy examples remain unlabeled initial study area begun mccallum nigam incremental learning algorithm re trains testing phase unlabeled test data received early testing phase order improve performance test data :10.1.1.13.8629:10.1.1.46.1529
furthermore problem domains share similarities text domains limited expensive labeled data abundant inexpensive unlabeled data 
robotics vision information extraction domains 
applying techniques improve performance areas 
acknowledgments larry wasserman extensive help theoretical aspects 
