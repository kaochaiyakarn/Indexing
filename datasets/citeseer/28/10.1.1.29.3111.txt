hierarchical clustering datamining anna jan larsen lars kai hansen informatics mathematical modeling richard build 
technical university denmark dk denmark web imm dk email asz jl imm dk 
presents hierarchical probabilistic clustering methods unsupervised supervised learning datamining applications 
probabilistic clustering previously suggested generalizable gaussian mixture model 
soft version generalizable gaussian mixture model discussed 
proposed hierarchical scheme agglomerative distance metric 
focus agglomerative probabilistic clustering gaussian density mixtures 
probabilistic scheme enables automatic detection final hierarchy level 
order provide meaningful description clusters suggest interpretation techniques listing prototypical data examples cluster listing typical features associated cluster 
generalizable gaussian mixture model ggm soft generalizable gaussian mixture model addressed supervised unsupervised learning 
learning combined sets labeled unlabeled data relevant practical applications due fact labeled examples hard expensive obtain document categorization :10.1.1.1.5684
discuss aspects 
ggm models estimate parameters gaussian clusters modified em procedure disjoint sets observations ensures high generalization ability 
optimum number clusters mixture determined automatically minimizing generalization error :10.1.1.40.8941
focuses applications objective categorizing text topic spotting new topics providing short easy understandable interpretation larger text blocks broader sense create intelligent search engines provide understanding documents content webpages yahoo ontologies :10.1.1.1.5684
generalizable gaussian mixture model ggm soft generalizable gaussian mixture model addressed supervised unsupervised learning 
learning combined sets labeled unlabeled data relevant practical applications due fact labeled examples hard expensive obtain document categorization :10.1.1.1.5684
discuss aspects 
ggm models estimate parameters gaussian clusters modified em procedure disjoint sets observations ensures high generalization ability 
optimum number clusters mixture determined automatically minimizing generalization error :10.1.1.40.8941
focuses applications objective categorizing text topic spotting new topics providing short easy understandable interpretation larger text blocks broader sense create intelligent search engines provide understanding documents content webpages yahoo ontologies :10.1.1.1.5684
generalizable gaussian mixture model step approach probabilistic clustering flexible universal gaussian mixture density model generalizable gaussian mixture model ggm models density dimensional feature vectors kx xjk xjk exp kj xjk component gaussians mixed non negative proportions :10.1.1.20.7748
component described mean vector covariance matrix parameters estimated iterative modified em algorithm means estimated data set covariances independent set combined set :10.1.1.40.8941
prevents notorious overfitting problems standard approach 
learning combined sets labeled unlabeled data relevant practical applications due fact labeled examples hard expensive obtain document categorization :10.1.1.1.5684
discuss aspects 
ggm models estimate parameters gaussian clusters modified em procedure disjoint sets observations ensures high generalization ability 
optimum number clusters mixture determined automatically minimizing generalization error :10.1.1.40.8941
focuses applications objective categorizing text topic spotting new topics providing short easy understandable interpretation larger text blocks broader sense create intelligent search engines provide understanding documents content webpages yahoo ontologies :10.1.1.1.5684
generalizable gaussian mixture model step approach probabilistic clustering flexible universal gaussian mixture density model generalizable gaussian mixture model ggm models density dimensional feature vectors kx xjk xjk exp kj xjk component gaussians mixed non negative proportions :10.1.1.20.7748
component described mean vector covariance matrix parameters estimated iterative modified em algorithm means estimated data set covariances independent set combined set :10.1.1.40.8941
prevents notorious overfitting problems standard approach 
optimum number clusters components chosen minimizing approximation generalization error aic criterion negative log likelihood plus times number parameters 
discuss aspects 
ggm models estimate parameters gaussian clusters modified em procedure disjoint sets observations ensures high generalization ability 
optimum number clusters mixture determined automatically minimizing generalization error :10.1.1.40.8941
focuses applications objective categorizing text topic spotting new topics providing short easy understandable interpretation larger text blocks broader sense create intelligent search engines provide understanding documents content webpages yahoo ontologies :10.1.1.1.5684
generalizable gaussian mixture model step approach probabilistic clustering flexible universal gaussian mixture density model generalizable gaussian mixture model ggm models density dimensional feature vectors kx xjk xjk exp kj xjk component gaussians mixed non negative proportions :10.1.1.20.7748
component described mean vector covariance matrix parameters estimated iterative modified em algorithm means estimated data set covariances independent set combined set :10.1.1.40.8941
prevents notorious overfitting problems standard approach 
optimum number clusters components chosen minimizing approximation generalization error aic criterion negative log likelihood plus times number parameters 
unsupervised learning parameters estimated training set feature vectors ng number samples 
ggm models estimate parameters gaussian clusters modified em procedure disjoint sets observations ensures high generalization ability 
optimum number clusters mixture determined automatically minimizing generalization error :10.1.1.40.8941
focuses applications objective categorizing text topic spotting new topics providing short easy understandable interpretation larger text blocks broader sense create intelligent search engines provide understanding documents content webpages yahoo ontologies :10.1.1.1.5684
generalizable gaussian mixture model step approach probabilistic clustering flexible universal gaussian mixture density model generalizable gaussian mixture model ggm models density dimensional feature vectors kx xjk xjk exp kj xjk component gaussians mixed non negative proportions :10.1.1.20.7748
component described mean vector covariance matrix parameters estimated iterative modified em algorithm means estimated data set covariances independent set combined set :10.1.1.40.8941
prevents notorious overfitting problems standard approach 
optimum number clusters components chosen minimizing approximation generalization error aic criterion negative log likelihood plus times number parameters 
unsupervised learning parameters estimated training set feature vectors ng number samples 
supervised learning classification data set features class labels yn cg adapt gaussian mixture xjy class separately classify bayes optimal rule maximizing yjx xjy pc xjy loss 
nigam mccallum thrun mitchell text classification labeled unlabeled documents em machine learning 
miller mixture experts classifier learning labelled unlabelled data 
advances nips pp 

hansen nielsen larsen modeling text generalizable gaussian mixtures :10.1.1.40.8941
proc 
ieee icassp vol 
pp 

