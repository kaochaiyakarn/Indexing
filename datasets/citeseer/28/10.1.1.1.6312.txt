optimization global minimization methods suitable neural networks aw duch jerzy department computer methods nicholas university toru poland laboratoire des sciences de image de informatique de la cnrs universit louis blvd france neural networks usually trained local gradient procedures 
methods frequently find suboptimal solutions trapped local minima 
optimization neural structures global minimization methods applied network cost functions strong influence aspects network performance 
genetic algorithms frequently combined neural methods select best architectures avoid drawbacks local minimization methods 
global minimization methods suitable purpose rarely context 
provides survey global methods including aspects genetic algorithms 
obviously improvements proposed variable fast slow weights corresponding different fast slow synapses different annealing schedules may quite easily connection global minimization methods example genetic algorithms 
disadvantage algorithm weights updated saturate large positive negative values 
prune small weights enable feature selection better define conditions may vanish example penalty functions described article 
algorithm tested far problems results example learned solve quite large parity problems solved standard machine learning benchmark monk problems accuracy mlp ln approach network able results real world noisy data reported far 
reactive tabu search reactive tabu search spellings tabu simple idea :10.1.1.40.9592
search started random point best elementary move selected cycles avoided keeping neural computing surveys xxx yyy www icsi berkeley edu jagota ncs trajectory search system visiting regions 
context neural networks values adaptive parameters kept finite precision neighborhood defined change operations 
error function defined finite set points 
best operation lowest value selected error grows ties broken random way 
