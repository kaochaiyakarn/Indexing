combination text classifiers reliability indicators paul bennett computer science dept carnegie mellon university pittsburgh pa cs cmu edu susan dumais microsoft research microsoft way redmond wa microsoft com eric horvitz microsoft research microsoft way redmond wa horvitz microsoft com intuition different text classifiers behave qualitatively different ways long motivated attempts build better metaclassifier combination classifiers 
introduce probabilistic method combining classifiers considers context sensitive reliabilities contributing classifiers 
method harnesses reliability indicators variables provide signals performance classifiers different situations 
provide background procedures building take consideration reliability indicators classifier outputs review set comparative studies undertaken evaluate methodology 
keywords text classification classifier combination feature selection reliability indicators researchers long pursued promise harnessing multiple text classifiers synthesize accurate classification procedure combination outputs contributing classifiers 
studies classifier combination motivated primarily intuition overlaying classifiers related qualitatively different ways leverage distinct strengths method 
classifiers combined variety ways 
approach text classifier composed multiple distinct classifiers selecting best classifier different situations contexts 
example may perform analytical empirical studies identify accurate text classifier setting seeking learn accuracy output scores combination output scores features considered analysis 
procedures combining classifiers consider inputs generated contributing classifiers 
example voting analysis combination function considers final decisions classifier votes influence decision best classification 
finer grained approach combining multiple classifiers scores generated contributing classifiers taken inputs combination function 
whichever approach combination employed creation enhanced set text classifiers relies developing understanding different classifiers perform different informational contexts 
revises extends material originally bennett 

pursued development probabilistic combination procedures hinge learning harnessing context sensitive reliabilities different classifiers 
rely solely output scores set domain level features employed text classification introduce reliability indicator variables set features provide low dimensional abstraction discriminatory context learning reliability 
borrow reliability indicator methodology initially toyama horvitz context automated vision 
introduced reliability indicator learning inference framework showed approach applied vision integrate distinct scene analyses higher accuracy composite visual analysis 
reliability indicator methodology useful text classification providing context sensitive signals accuracy weave multiple classifiers coherent probabilistic manner boost accuracy 
review related combination text classification procedures 
introduce reliability indicators text classification show employ variables learn context sensitive reliabilities na bayes unigram support vector machine svm decision tree classifiers 
describe integrate indicator variables base level features scores output classifiers build improve text classification performance 
highlight methodology results reviewing sets experiments 
summarize contributions discuss directions 
related appropriately combining information sources form effective output individual sources problem investigated fields 
challenges integrating information gone labels diagnosis horvitz pattern recognition duda sensor fusion klein distributed data mining kargupta chan variety ensemble methods dietterich 
diagnosis centers identifying disorders multiple pieces evidence reasoning probability distributions patient diseases set symptoms test results 
pattern recognition sensor fusion typically address challenges integrating information multiple modalities auditory visual distributed data mining addresses results retrieved distinct training data sets unified provide coherent view user 
ensemble methods solve classification regression problem creating multiple learners attempt solve task independently procedure specified particular ensemble method selecting weighting individual learners 
ensemble methods include techniques bayesian averaging bagging boosting stacking cascade generalization hierarchical mixture experts 
text classification addresses task labeling text document labels set predefined content categories 
categories may primary document topics health fitness business finance hierarchical indices technical content medical hierarchies hersh genres legal fiction kessler variety distinctions normal mail vs junk mail sahami urgent mail vs non urgent mail explored horvitz 
text classification methods provide backend information retrieval tasks routing tagging filtering 
interested reader see sebastiani broad survey applications machine learning text classification 
overlaying multiple methodologies representations employed areas information retrieval 
example previous research information retrieval demonstrated retrieval effectiveness improved multiple distinct representations bartell croft multiple queries search strategies belkin shaw fox :10.1.1.52.5586
realm text classification researchers achieved improvements classification accuracy combining different classifiers hull larkey croft li jain yang 
similarly investigators enhanced classification performance applying instances classifier boosting procedures schapire singer weiss 
previous combining text classifiers centered basic policies selecting best classifier combining output multiple classifiers 
examples larkey croft weighted linear combinations system ranks scores hull 
linear combinations probabilities log odds scores yang 
linear combination normalized scores li jain voting classifier selection techniques lam lai category averaged features pick potentially different classifier category 
larkey croft rank measures performance interested interactive systems rank list codes document displayed users 
applications automatic routing tagging require binary class membership decisions document processed 
focus classifier combination enhance classification decisions 
goal challenging classifiers document ranking 
example hull 
combination techniques able improve document ranking considerably estimating probabilities required online classification decisions 
shall highlight contrast prior research classifier combination centers richer probabilistic combination inputs combination functions learned bayesian svm learning methods 
respect approach similar ting witten stacked generalization gama cascade generalization apply approach text problems 
report baseline comparisons voting classifier selection techniques 
problem approach distinguished earlier combination approaches text classification expressive probabilistic dependency models combine lower level classifiers leveraging special signaling variables referred reliability indicators focus measures classification performance common consideration ranking 
reliability indicators previous approaches classifier combination typically limited information considered metalevel output classifiers ting witten original feature space gama :10.1.1.16.1519
classifier rarely best choice domain intuitive alternative identify document specific context differentiates regions base classifier higher lower reliability 
shows example base classifiers decision tree svm na bayes unigram 
test document input base classifiers outputs probability distribution possible class labels depicted graphically histogram 
metaclassifier uses information document context described detail produce final classification document 
address challenge learning reliability different classifiers different neighborhoods classification domain introducing variables referred reliability indicators represent analytic psfrag replacements decision tree wn svm document specific context rn naive bayes unigram metaclassifier schematic characterization reliability indicator methodology 
methodology formalizes intuition shown document specific context improve performance set base classifiers 
output classifiers graphical representation distribution possible class labels 
context specific document 
reliability indicator evidential distinction states linked probabilistically regions classification problem classifier performs relatively strongly poorly 
reliability indicator methodology introduced toyama horvitz applied initially task combining probabilistically coherent manner distinct machine vision analyses system tracking head pose computer users 
researchers different visual processing modalities distinct context sensitive reliabilities depended dynamically changing details lighting color configuration visual scene 
authors introduced reliability indicators capture properties vision analyses scenes analyzed provided probabilistic indications reliability output modalities 
learn probabilistic models combining multiple modalities data collected ground truth observed states indicator variables outputs concurrent vision analyses 
data construct bayesian network model ability appropriately integrate outputs visual modalities real time providing higher accuracy composite visual analysis 
value indicator variable methodology machine vision stimulated explore approach representing learning reliability dependent contexts text classification problems 
task combining classifiers formulate include sets variables hold promise related performance underlying classifiers 
consider states reliability indicators scores classifiers directly bypass need ad hoc modifications base classifiers 
allows metaclassifier harness reliability variables contain useful discriminatory information fall back graceful manner output base classifiers 
example consider types documents words document uninformative strongly associated class words document weakly associated disjoint classes words document strongly associated disjoint classes 
classifiers unigram model demonstrate different patterns error different document types 
characterize document belonging model specific failure types assign appropriate weight classifier output kind document 
pursued formulation reliability indicators capture different association patterns words documents structure classes consideration 
seek indicator variables allow learn context sensitive reliabilities classifiers conditioned observed psfrag replacements wn rn portion decision tree learned strive norm business finance class msn web directory corpus representing combination policy metalevel considers scores output classifiers dark nodes values indicator variables lighter nodes 
states variable different settings 
highlight approach concrete example shows portion type combination function capture reliability indicator methodology 
nodes different branches decision tree include values output base classifiers values reliability indicators document classified 
decision tree provides probabilistic context sensitive combination rule indicated particular relevant branching values classifier scores indicator variables 
case portion tree displayed shows classifier combination function considers thresholds scores provided base level linear svm classifier base level unigram classifier uses context established reliability indicator variables final decision classification 
annotations show threshold tests performed number examples training set satisfy test graphical representation probability distribution leaves 
likelihood class membership indicated length bars leaves tree 
variable represents variance unigram weights words current document 
intuition formulation reliability indicator variable unigram classifier show tendency higher accuracies low variance weights 
variable percentage words feature selection occur documents target class classes 
classifiers weight positive negative evidence differently distinguished variable 
appendix gives details reliability indicators experiments 
indicator variables studies represent attempt formulate states capture influential contexts 
constructed variables represent variety contexts held promise predictive accuracy 
include variables number features document feature selection distribution features positive vs negative classes mean variance classifier specific weights 
broadly group reliability indicator variables types including variables measure amount information original document information loss mismatch representation classifier original document sensitivity decision evidence shift basic voting statistics 
example reliability indicator variable type 
performance classifiers correlated document length longer documents give information making classification 
informative classifiers perform poorly longer documents model influence document length classification performance double count evidence longer documents deviate correct determination 
serves example type 
variable represents percent features removed process feature selection 
document represented feature set employed classifier classifiers may unreliable 
classifiers decision trees model missing attributes may continue reliable 
base classifiers allowed different representations type features play important role 
example type variable 
low variance means decision classifier change small change document content high variance increases chances decision change small change document 
examples type reliability indicators 
simple voting statistics improve metaclassifier search space metaclassifier base classifier decisions input 
class case variable may provide little extra information greater number classes determine base classifiers votes small number classes wide array 
types reliability indicators useful final combination scheme preliminary analyses indicate type dominates combination models 
key difference semantics usage reliability indicator variables differ qualitatively variables representing output classifiers ways 
assume reliability indicators threshold point classifies examples better random 
assume classification confidence shows monotonicity trends classifiers 
strive metaclassifier reliability indicators refer classifier combination learning inference framework strive stacked reliability indicator variable ensemble 
select name approach viewed essentially extending stacking framework introducing reliability indicators metalevel 
strive architecture depicted graphically 
methodology maps original classification task new learning problem 
original learning problem base classifiers simply predict class word representation document generally base classifier outputs distribution possibly unnormalized class labels 
strive adds layer learning base problem 
set reliability indicator functions words document classifier outputs generate reliability indicator values ri particular document 
process viewed yielding new representation document consists values reliability indicators outputs base classifiers 
metaclassifier uses new representation learning classification 
enables metaclassifier employ model uses output base classifiers context established reliability indicators final classification 
require outputs base classifiers train metaclassifier 
perform cross validation training data resulting base classifier predictions obtained example serves validation item training inputs metaclassifier 
note case set reliability indicators restricted identity function original data resulting scheme viewed variant cascade generalization gama 
psfrag replacements svm rn wn class unigram typical application classifier text problem 
traditional text classification word representation document extracted class label learning phase classifiers svm unigram classifier learn output scores possible class labels 
shaded boxes represent distribution class labels 
frag replacements svm unigram reliability indicators wn rn class class metaclassifier architecture strive 
strive additional layer learning added metaclassifier context established reliability indicators output base classifiers improved decision 
reliability indicators functions document output base classifiers 
experimental analysis performed large number experiments test value probabilistic classifier combination variables 
describe corpora methodology results 
data examined corpora including msn web directory reuters trec ap 
msn web directory msn web directory large collection heterogeneous web pages may web snapshot hierarchically classified 
train test split documents reported dumais chen 
msn web hierarchy level hierarchy top level categories 
class proportions training set vary 
testing set range 
classes general subject categories health fitness travel vacation 
human indexers assigned documents zero categories 
experiments top words highest mutual information class approximately words appear training documents 
reuters reuters corpus lewis contains reuters news articles 
data set modapte standard train test split documents unused documents 
classes economic subjects acq acquisitions earn earnings human taggers applied document document may multiple subjects 
classes domain occur training testing set examined frequent classes small numbers testing examples estimating performance measures unreliable due high variance 
limiting largest classes allows compare results previously published results zhang oles dumais joachims mccallum nigam platt :10.1.1.11.6124:10.1.1.11.6124
class proportions training set vary 
testing set range 
experiments top words highest mutual information class approximately words appear training documents 
trec ap trec ap corpus collection ap news stories 
train test split documents lewis 

described lewis gale see lewis categories defined keywords keyword field 
title body fields experiments 
categories total 
frequencies classes reported lewis 

class proportions training set vary 
testing set range 
experiments described top words highest mutual information class approximately words appear training documents 
classifiers employed base level classifiers classifier combination methods comparative studies 
review classifiers combination methods 
base classifiers attempt isolate benefits gained probabilistic combination classifiers reliability indicators worked keep representations base classifiers experiments nearly identical 
expect varying representations different feature selection methods document representations improve performance decorrelate performance base classifiers 
selected classifiers traditionally text classification decision trees linear svms na bayes unigram classifier 
decision tree implementation employed decision networks toolkit refer dnet toolkit 
dnet builds decision trees bayesian machine learning algorithm chickering heckerman :10.1.1.157.3189
toolkit targeted primarily building models provide probability estimates dnet models usually perform acceptably goal minimizing error rate 
performance dnet regard measures poor 
linear svms smox toolkit platt sequential minimal optimization algorithm platt 
experimented binary continuous feature representations perform approximately level accuracy 
order keep base representations classifier similar possible continuous model 
na bayes classifier referred multivariate bernoulli model 
classifier smoothed word class probabilities bayesian estimate word prior laplace estimate respectively 
unigram classifier uses probability estimates unigram language model 
classifier referred multinomial na bayes classifier 
probability estimates smoothed similar fashion smoothing na bayes classifier 
basic combination methods performed experiments explore variety classifier combination methods 
considered different combination procedures 
combination method selecting classifier binary class problem performed best validation set 
refer method best class method 
combination method centers majority vote base classifiers 
approach popular methodology combination text classifiers 
performing majority vote ties broken variety ways breaking ties voting class 
experimented variants method results method relies breaking ties voting best class classifier procedure nearly outperformed majority vote methods 
refer method majority bbc 
hierarchical combination methods stacking investigate variants hierarchical models described earlier 
mentioned omitting reliability indicator variables transforms strive stacking methodology ting witten wolpert :10.1.1.16.1519
refer classifiers stack replaced letter classifier performing 
stack uses decision tree metaclassifier stack uses linear svm metaclassifier 
note stack weighted linear combination method linear svm uses classifier outputs 
challenging learn weights svm inputs vastly different scales 
times possible identify weights 
address problem handling inputs greatly varying scales input normalization procedure normalize inputs zero mean unit standard deviation 
order perform consistent comparisons perform alteration dnet 
give dnet variants results absence normalization procedure expected impact normalization decision tree learners relatively minimal positive negative influences 
denote inputs normalized manner append norm names 
strive similar notation described add letter strive denote particular metaclassifier method 
strive strive framework dnet metaclassifier 
comparison stacking methods evaluate strive strive 
normalization noted appending norm system names 
experiments reported total reliability indicators including specific examples section 
full list reliability indicators described detail appendix reliability indicators formulated hand initial pass representing potentially valuable contexts 
currently closer look fundamental informational properties different reliability indicators examined procedures identifying new reliability indicators 
delve deeply nature authoring reliability indicators forthcoming 
classifier study effectiveness strive methodology formulated simple optimal combination approach point 
upper bound useful benchmark experiments classifier combination procedures 
bound follows quite naturally classifier combination formulated process selecting best base classifier example basis 
classify document classifiers correctly predict document class best combination select correct classifiers 
classification combination errs base classifiers incorrect 
refer classifier classifier 
base classifiers better random theoretical upper bound performance combining set classifiers selection framework 
note pure selection approach framework allows possibility choosing class base classifiers predicted 
cases classifiers better random logically dependent upper bound may loose 
working pure selection framework rarely case metaclassifier outputs prediction base classifiers 
employed bound assist understanding performance strive 
performance measures compare performance classification methods look set standard performance measures 
measure van rijsbergen yang liu harmonic mean precision recall precision correct correct recall actual macro average micro average :10.1.1.11.9519
macroaveraging score computed separately class averaged tends weight rare classes heavily 
micro averaged values computed directly binary decisions classes places weight common classes 
evaluated systems macro micro averaged 
assess cost function classification settings described os cost false positive classification cost false negative classification 
commonly function literature error rate 
importance varying cost functions recognized researchers applications rarely equal costs different types errors provost fawcett 
order assess sensitive performance utility measure considered results 
addition computed displayed receiver operating characteristic roc curve represents performance classifier linear utility function provost fawcett 
report results area roc curve attempt summarize linear utility space functions 
experimental methodology categories consideration experiments mutually exclusive classification carried training binary classifiers number classes 
decision thresholds classifier set optimizing performance measure validation data 
classifier different thresholds separate performance measures class 
ensures base classifiers competitive possible various measures 
micro performance measures obtaining truly optimal performance requires optimizing thresholds corpus conjunction taken computationally efficient approach macro optimized thresholds class threshold set independently thresholds classes 
generate data training metaclassifier reliability indicators classifier outputs class labels fold cross validation training data corpora 
data set obtained process train 
resulting applied separate testing data described 
results tables main performance results corpora 
terms various performance measures better performance indicated larger roc area values smaller values 
best performance ignoring column bold 
determine statistical significance macro averaged measures sided macro sign test macro test performed yang liu :10.1.1.11.9519
micro sided micro sign test performed yang liu :10.1.1.11.9519
method macro micro error roc area dnet smox na bayes unigram best class majority bbc stack norm stack norm strive strive norm strive norm strive norm omit smox table performance msn web directory corpus 
best performance omitting oracle column bold 
summarize macro sign test micro micro sign test 
indicates method significantly outperforms level best base classifier 
addition variants stack strive indicates method outperforms basic combination methods 
differences level considered statistically significant 
explicitly report significance results test comparisons main performance results analysis follows macro micro sign test yield conservative comparisons test primarily increased number differences significant tables 
classifier combinations annotated indicate results macro sign test micro micro sign test 
indicates method significantly outperforms level best base classifier 
addition variants stack strive indicates method outperforms basic combination methods 
results remaining sign test comparisons omitted brevity 
tables performance results additional experiments described section conducted determine gained incorporating reliability indicators directly base classifier versus combining hierarchically classifier outputs strive 
ablation experiment aims empirically examine order information reliability indicators versus information conditioned classifier outputs 
best performance column bold 
significance tests ablation experiment summarized ordering systems table 
performance measure systems ordered best left worst right 
systems performance level significantly outperform lower performers denoted manner significant macro sign test separate columns significant macro test column separator significant tests 
micro uses micro sign test 
method macro micro error roc dnet smox na bayes unigram best class majority bbc stack norm stack norm strive strive norm strive norm strive norm omit smox table performance reuters corpus 
best performance omitting oracle column bold 
summarize macro sign test micro micro sign test 
indicates method significantly outperforms level best base classifier 
addition variants stack strive indicates method outperforms basic combination methods 
discussion note base classifiers competitive consistent previously reported results corpora zhang oles dumais chen dumais joachims lewis lewis gale mccallum nigam :10.1.1.11.6124
furthermore fact linear svm smox tends best base classifier consistent literature dumais joachims yang liu :10.1.1.11.9519:10.1.1.11.6124
msn web directory examining main results msn web directory corpus table highlights points 
basic combiners significant win majority bbc approach 
results directly support idea performance learner smox tends diminished combined majority vote scheme weak learners addition win results fact base learners smox tendency predict positively class 
false negatives weighed heavily shift predicting positive helps reduce number false negatives 
see stacking posts significant wins appears advantages base classifiers 
stacking combination shows little significant improvement basic combination methods 
strive strive norm show advantages robust variety performance measures 
shows small error reduction consistent improvement variety performance measures 
compared best theoretical performance achieved example selection model base results reported reuters directly comparable reported yang liu investigators report results classes give breakdown frequent categories zhang oles dumais joachims mccallum nigam platt provide published baselines largest classes :10.1.1.11.6124:10.1.1.11.6124
method macro micro error roc dnet smox na bayes unigram best class majority bbc stack norm stack norm strive strive norm strive norm strive norm omit smox table performance trec ap corpus 
best performance omitting oracle column bold 
summarize macro sign test micro micro sign test 
indicates method significantly outperforms level best base classifier 
addition variants stack strive indicates method outperforms basic combination methods 
classifiers established model error reduction provided strive combination methods greater portion total possible reduction 
inferred sign tests results consistent classes 
example roc area measure performance strive beats base classifiers basic combiners classes beats stacking methods classes 
notable exception performance strive norm roc area graphical inspection roc curves suggests result arises weight placed strong classifier curve 
crossover roc curve base classifiers false positives axis 
utility measures practice correspond early part curve depends particular features curve 
smox metaclassifier lock classifier strong early portion curve loses part curve 
portion curve rarely matters consider abbreviated version curve area assess systems 
see strive variants dominate base classifiers 
fact strive dominates quality greater curve point msn web directory corpus 
see note truncated scale base classifiers catching strive norm right side curve 
base classifiers fact surpass strive norm 
result strive usually appropriate choice utility function penalizes false negatives significantly heavily false positives 
cases develop understanding decision tree appropriate tracking crossovers 
case portrayed appears tree establishes score region smox score region dnet reliability indicators give information classify example 
linear svm weighted sum inputs represent crossovers dependent breaking single variable multiple regions information variables try distinguish psfrag replacements wn rn true positive rate dnet smox naive bayes unigram strive strive norm false positive rate roc curve health fitness class msn web directory corpus regions 
higher order polynomial kernels way allow svm represent type information 
performed ablation experiment determine strive behave presence extremely strong base classifier 
smox frequently outperforms base classifiers investigated level performance strive obtain output smox omitted inputs metaclassifier strive norm omit smox 
results show omit base classifier smox resulting combination improves large margin remaining base methods resulting classifier generally fails beat smox individual performance 
suggests indicator variables tied smox behavior alternatively classifiers group behave smox classify complementary fashion 
reuters trec ap results reuters trec ap tables consistent analysis 
note level improvement tends pronounced corpora 
common literature show results class top largest classes reuters provide detailed listing appendix additional experiments investigated reliability indicators directly incorporated base classifiers 
wanted understand extent information directly improve classification extent conditional presence classifier outputs 
examine issues performed experiment added reliability indicators standard document representation built model dnet 
resulting system denoted dnet riv 
reliability indicators contain information equivalent method macro micro error roc area dnet dnet riv dnet riv stack norm strive strive norm table results incorporating reliability indicators directly base classifier msn web directory corpus 
best performance column bold 
method macro micro error roc area dnet dnet riv dnet riv stack norm strive strive norm table results incorporating reliability indicators directly base classifier reuters corpus 
best performance column bold 
output classifiers built model uses reliability indicators standard document representation denoted dnet riv 
compare systems similar counterparts earlier results base classifier dnet stacking method decision tree metaclassifier stack norm normalized standard version strive 
expectation dnet outperformed systems dnet riv outperformed dnet 
quick examination results indicates generally case nearly performance measures 
amount improvement dnet riv dnet indicates extent reliability indicators give information directly improve classification quite large compared dnet 
remaining methods show significant improvement base classifier outputs 
experiment highlights rarity classes extremely challenging produce significant wins function places heavy penalty false positives emphasizing extremely high precision 
tried integrating reliability indicator variables directly smox classifier 
surprised observe tendency test performance decrease significantly level base smox system 
believe result representational inhomogeneity majority words define support vectors document reliability indicators values documents 
reliability indicators dominate influence words sheer magnitude necessarily reliability omitted variables type variables unigram na bayes variants type variable discussed appendix left variables related classifier models directly correlated outputs 
method macro micro error roc area dnet dnet riv dnet riv stack norm strive strive norm table results incorporating reliability indicators directly base classifier trec ap corpus 
best performance column bold 
information carry 
highlights value hierarchical modeling classifier combination hierarchical modeling allows variables type modeled layers 
highlights major advantage hierarchically combining systems variables type modeled layer 
excited opportunities probabilistic combination multiple classifiers reliability indicators 
pursuing research directions 
foremost believe functional search generates tests larger number reliability indicators provide valuable sets informative reliability indicators 
interested exploring value introducing flexibility set base classifiers 
experiments described classifiers purposely held constant attempt investigate influence reliability indicator variables 
studies allow representations vary induce variety base classifiers focused 
interested exploring classifiers 
metaclassifier classifier handles correlated input maximum entropy nigam classifiers performing better random necessarily correlated 
addition believe strive framework elucidate deeper information theoretic foundations classifiers leverage information text classification 
currently build metaclassifier binary topic problem corpus acquisitions vs acquisitions 
promising abstraction strive framework enables model structure parameters learned data binary task separate binary task different corpus 
experimentally tested coalescing metalevel training data different binary discrimination tasks building general metaclassifier 
approach treat metaclassifier abstraction moving focus analysis discriminating specific topic acquisitions vs acquisitions problem discriminating topic membership topic vs topic 
base level classifiers trained particular topic representation topic specific knowledge metaclassifier provides information leverage context topic classification general 
metaclassifier improves performance base classifiers reliability indicators inductively defined informational properties classifier combination text problems considered 
extension possible generalize reliability indicators away linkages precise words document 
consider shares occurs document acquisitions discrimination task corn occurs document corn futures discrimination task 
task invariant representation context metalevel transform word maximum mutual information current task document 
representation enables metaclassifier information document specific context influences topic discrimination wide variety text classification tasks 
experiments demonstrated methodology valuable enhancing performance classifiers bennett 
continuing pursue promising extension 
summary reviewed methodology building metaclassifier text documents centers combining multiple distinct classifiers probabilistic learning inference leverages reliability indicator variables 
reliability indicators provide information context sensitive nature classifier reliability informing metaclassifier best way integrate outputs base level classifiers 
reviewed popular text classification methods described combination schemes 
introduced strive methodology uses reliability indicators hierarchical combination model reviewed comparative studies comparing strive combination mechanisms 
conducted experimental evaluations text classification corpora msn web reuters trec ap variety performance measures 
measures selected determine robustness classification procedures different misclassification penalties 
empirical evaluations support simple majority vote situations classifiers performs strongly weaken best classifier performance 
contrast corpora measures strive methodology competitive failing produce top performer instances skewed linear utility measures trec ap corpus 
furthermore class class basis strive methodology produced receiver operating characteristic curves dominated classifiers nearly class msn web corpus demonstrating provides best choice possible linear utility function corpus 
experiments show stacking strive provide robust combination schemes variety performance measures 
acknowledgments max chickering robert special support toolkit john platt advice code support linear svm classifier 
anonymous reviewers useful suggestions provided 
second third fourth fifth sixth macro msn web strive norm strive dnet riv stack norm dnet riv dnet reuters stack norm strive strive norm dnet riv dnet riv dnet trec ap stack norm strive strive norm dnet riv dnet riv dnet micro msn web strive strive norm dnet riv stack norm dnet riv dnet reuters stack norm strive strive norm dnet riv dnet riv dnet trec ap strive stack norm strive norm dnet riv dnet riv dnet error msn web strive strive norm stack norm dnet riv dnet riv dnet reuters stack norm strive strive norm dnet riv dnet riv dnet trec ap strive strive norm stack norm dnet riv dnet riv dnet msn web strive strive norm dnet riv stack norm dnet riv dnet reuters stack norm dnet riv strive norm strive dnet riv dnet trec ap stack norm strive norm strive dnet riv dnet riv dnet msn web strive strive norm dnet riv dnet dnet riv stack norm reuters strive strive norm stack norm dnet riv dnet riv dnet trec ap strive norm dnet riv strive dnet riv dnet stack norm roc area msn web strive norm strive dnet riv dnet riv stack norm dnet reuters dnet riv strive strive norm stack norm dnet riv dnet trec ap strive stack norm strive norm dnet riv dnet riv dnet table ordered comparison classification models built reliability indicators directly added base classifier versus hierarchical combination models 
performance measure systems ordered best left worst right 
systems performance level significantly outperform lower performers denoted follows significant sign test separate columns significant macro test significant tests 
appendix detailed descriptions inputs strive appendix gives details inputs strive including base classifier outputs addition reliability indicator variables 
outputs base classifiers considered outputs base classifiers inputs strive 
output decision tree built dnet classifier available toolkit toolkit 
value estimated probability leaf node belonging class 
output linear svm model built smox toolkit 
probability estimate class membership obtained monotonic transformation fitted sigmoid platt raw score svm 
output na bayes model built multivariate bernoulli representation feature presence absence example modeled mccallum nigam 
log odds logistic model probability estimate class membership log direct probability estimate typically machine floating point precision available preserve ranking induced model cluster closely zero 
output unigram model referred multinomial model mccallum nigam 
log odds logistic model probability estimate class membership log direct probability estimate typically machine floating point precision available preserve ranking induced model cluster closely zero 
reliability indicator variables indicator variables currently broken roughly types amount information original document information loss mismatch representations sensitivity decision evidence shift basic voting statistics 
number parentheses number variables type experimental evaluation 
second number number effect metaclassifier model appears nonnegligible 
group reliability indicators primary type main reasons expect see link classifier reliability 
note soft clustering reliability indicators may provide context information way 
variables listed instantiation class learning problem variable counts report tallies instance separately 
variables list entry class name variable denote variable instantiation class 
methodology built binary classifier topic experiments positive negative class version 
class problem values instantiations may redundant 
retained classes discrimination distinct 
bullet number parentheses indicating number variables description includes 
total numbers parentheses 
type amount information original document reliability indicator variables primary type considered type counting instantiations class 
number words document feature selection 
presumably longer documents provide information base decision 
longer documents lead reliable decisions correctly modeled 
alternatively models correctly normalize document length may reliable extreme lengths short long documents 
minus number vocabulary words document 
model generalize strongly smoothing features seen training set variable may better indicator information document 
number distinct tokens document document opposed length counts repeats token document 
motivation similar variable counting new word indicator new information 
minus number unique vocabulary words 
analogue effective included similar reasons 
measure variety word choice document 
equal document length 
seen average number times word repeated document 
close means words repeated document close means documents consists unique words possibly repeated times 
essentially normalized version words variable show high variance short documents 
intuition complex documents providing information difficult classify may features carrying small weight 
percentage words document weren seen training set 
equal number vocabulary words divided 
similar variable show high variance short values 
intuition novel words document contains classifier incorrectly classify document priori prevalent class typically unseen words slightly favor minority classes samples 
variable essentially allows global smoothing model induced 
range 
approaches expect minority classes base models estimate 
percentage words counting duplicates document weren seen training set 
distinct token analogue 
motivations similar just different information model 
class words occurring training set vocabulary words ignored percentage words document occurred examples belonging class 
equal number words occurred class feature selection divided 
similar inductively learn smoothing behavior 
assumption variable high predictions example belongs class reliable 
binary case negative class effectively groups classes isn quite expected respect predictions negative expected reliable assumption 
class words occurring training set vocabulary words ignored percentage unique words document occurred examples belonging class 
analogue class unique tokens basis information model 
favoring class words occurring training set percentage words document occurred times examples belonging class examples belonging class 
essentially rough statistic unnormalized unigram model tied slightly smoothing related variables discussed gives rough sense evidential weight original document 
favoring class words occurring training set percentage unique words document occurred times examples belonging class examples belonging class 
analogue favoring class 
type information loss mismatch representations reliability indicator variables primary type considered type 
variables measure loss information generally paired variable type give direct measure information loss 
number words document vocabulary words removed feature selection performed 
similar measure information classifier sees respect document 
currently assumed metaclassifier combine infer information loss 
number unique words remaining document vocabulary words removed feature selection performed 
distinct token analogue similarly expected conjunction gauge information loss 
percentage document discarded vocabulary removed feature selection 
high variance short documents 
intuition reliability classifier higher low values 
percentage unique words document discarded vocabulary removed feature selection 
distinct token analogue information model unique words 
class words occurring training set percentage words remaining document feature selection occurred examples class 
class allows model inductively model shift information content feature selection 
class words occurring training set percentage unique words remaining document feature selection occurred class 
expected conjunction class model information loss 
favoring class words occurring training set percentage words remaining document feature selection occurred times examples class examples class 
counterpart essentially unnormalized unigram model 
expect conjunction favoring class measure feature selection method may biased information document particular class 
favoring class words occurring training set percentage distinct words remaining document feature selection occurred times examples class examples class 
type sensitivity decision evidence shift reliability indicator variables fall class 
unigram model probabilities words modeled na bayes multivariate bernoulli model document modeled terms probabilities word presence absence 
na binary class problem weight word contributes unigram model decision log current analysis metaclassifier models restricted attention set total variables experiments 
remaining variables eliminated study highly correlated reliability indicators little impact metaclassifier 
eliminated variables type variables listed section 
similarly word presence absence contributes weight log absent absent na bayes model 
ratio greater word gives evidence positive class zero word gives evidence negative class 
reliability indicators variance weights feature values word occurrences presence absence specific document 
variance close zero means words tended point class 
variance increases means large skew amount evidence various words possibly strong words pulling classes 
intuition reliability na bayes related classifiers tend decrease variable increases 
apply learning problems value class weight log log maxc second preferred 
class na class variables represent variance log conditional probabilities word class 
example variance log class positive words document 
class na class variables represent mean conditional probabilities word class 
example mean class positive words document 
variables impact metaclassifier model eliminated study result 
class na class variables represent mean conditional probabilities word class 
example mean log class positive words document 
essentially provides log scaling variables class na class described factor metaclassifier sensitive scaling 
variables impact metaclassifier model eliminated study result 
class na class variables represent variance log conditional probabilities word class 
example variance class positive words document 
essentially provides log scaling variables class na class described type section factor metaclassifier sensitive scaling 
sensitive scaling variables eliminated study counterparts retained 
na binary class problem weight word contributes unigram model decision log similarly word presence absence contributes weight log absent absent 
na bayes model 
ratio greater word gives evidence positive class zero word gives evidence negative class 
reliability indicators mean weights feature values word occurrences presence absence specific document 
variables eliminated study information highly correlated output scores unigram na bayes classifiers 
type basic voting statistics reliability indicator variables primary type considered type 
introduced mainly reduce data required learn rules decision tree metaclassifier 
refer main text 
variable percentage base classifiers base classifiers vote membership class 
experimental evaluation instantiation variable 
added help search space learning type feature require significant data decision tree learning algorithm specifically altered 
variable referred main text 
problems indicate classes classifiers fracture votes 
classes altered indicate percent agreement best base classifier classifier performed best training data 
appendix detailed results reuters common literature provide detailed performance results top frequent classes reuters breakdown class 
reader benefit give class name number training documents testing documents membership class train test 
best result class performance measure excluding bold 
table details reuters class class method error roc area acq dnet smox na bayes unigram best class majority bbc stack norm stack norm strive strive norm strive norm strive norm omit smox corn dnet smox na bayes unigram best class majority bbc stack norm stack norm strive strive norm strive norm strive norm omit smox crude dnet smox continued page continued previous page class method error roc area na bayes unigram best class majority bbc stack norm stack norm strive strive norm strive norm strive norm omit smox earn dnet smox na bayes unigram best class majority bbc stack norm stack norm strive strive norm strive norm strive norm omit smox grain dnet smox na bayes unigram best class majority bbc stack norm stack norm strive strive norm strive norm strive norm omit smox continued page continued previous page class method error roc area interest dnet smox na bayes unigram best class majority bbc stack norm stack norm strive strive norm strive norm strive norm omit smox money fx dnet smox na bayes unigram best class majority bbc stack norm stack norm strive strive norm strive norm strive norm omit smox ship dnet smox na bayes unigram best class majority bbc stack norm stack norm strive strive norm continued page continued previous page class method error roc area strive norm strive norm omit smox trade dnet smox na bayes unigram best class majority bbc stack norm stack norm strive strive norm strive norm strive norm omit smox wheat dnet smox na bayes unigram best class majority bbc stack norm stack norm strive strive norm strive norm strive norm omit smox tyrrell travers jackson combining multiple classifiers text categorization 
cikm proceedings th acm conference information knowledge management 
pp 

bartell bt cottrell gw belew rk automatic combination multiple ranked retrieval systems 
sigir proceedings th annual international acm conference research development information retrieval 
pp 

belkin cool croft callan effect multiple query representations information retrieval system performance 
sigir proceedings th annual international acm conference research development information retrieval 
pp 

bennett pn dumais st horvitz probabilistic combination text classifiers reliability indicators models results 
sigir proceedings th annual international acm conference research development information retrieval 
pp 

bennett pn dumais st horvitz inductive transfer text classification generalized reliability indicators 
working notes icml th international conference machine learning workshop continuum labeled unlabeled data 
pp 

chickering heckerman meek bayesian approach learning bayesian networks local structure 
uai proceedings th conference uncertainty artificial intelligence 
pp 

dietterich ensemble methods 
mcs proceedings st international workshop multiple classifier systems 
springer 
pp 

duda hart stork pattern classification 
new york ny john wiley sons dumais st chen hierarchical classification web content 
sigir proceedings rd annual international acm conference research development information retrieval 
pp 

dumais st platt heckerman sahami inductive learning algorithms representations text categorization 
cikm proceedings th acm conference information knowledge management 
pp 

gama combining classifiers constructive induction 
ecml proceedings th european conference machine learning 
pp 

gama local cascade generalization 
icml proceedings th international conference machine learning 
pp 

heckerman chickering meek kadie dependency networks inference collaborative filtering data visualization 
journal machine learning research 
hersh buckley leone ohsumed interactive retrieval evaluation new large test collection research 
sigir proceedings th annual international acm conference research development information retrieval 
pp 

horvitz breese henrion decision theory expert systems artificial intelligence 
international journal approximate reasoning special issue uncertain reasoning 
horvitz jacobs attention sensitive alerting 
uai proceedings th conference uncertainty artificial intelligence 
pp 

hull pedersen schuetze method combination document filtering 
sigir proceedings th annual international acm conference research development information retrieval 
pp 

joachims text categorization support vector machines learning relevant features 
ecml proceedings th european conference machine learning 
pp 

kargupta chan eds 
advances distributed parallel knowledge discovery 
cambridge massachusetts aaai press mit press 
mcgill tessier frakes dasgupta study overlap document representations 
information technology research development 
kessler nunberg sch tze automatic detection text genre 
acl proceedings th annual meeting association computational linguistics 
pp 

klein la sensor data fusion concepts applications 
society photo optical instrumentation engineers 
nd edition 
lam lai ky meta learning approach text categorization 
sigir proceedings th annual international acm conference research development information retrieval 
pp 

larkey ls croft wb combining classifiers text categorization 
sigir proceedings th annual international acm conference research development information retrieval 
pp 

lewis dd sequential algorithm training text classifiers corrigendum additional data 
acm sigir forum 
lewis dd reuters distribution 
www com resources reuters visited 
lewis dd gale wa sequential algorithm training text classifiers 
sigir proceedings th annual international acm conference research development information retrieval 
pp 

lewis dd schapire re callan jp papka training algorithms linear text classifiers 
sigir proceedings th annual international acm conference research development information retrieval 
pp 

li jain classification text documents 
computer journal 
mccallum nigam comparison event models naive bayes text classification 
working notes aaai th national conference artificial intelligence workshop learning text categorization 
pp 

nigam lafferty mccallum maximum entropy text classification 
working notes ijcai th international joint conference artificial intelligence workshop machine learning information filtering 
pp 

platt jc fast training support vector machines sequential minimal optimization 
sch lkopf burges smola eds 
advances kernel methods support vector learning 
mit press 
pp 

platt jc probabilistic outputs support vector machines comparisons regularized likelihood methods 
smola aj bartlett scholkopf schuurmans eds 
advances large margin classifiers 
mit press 
pp 

provost fawcett robust classification imprecise environments 
machine learning 
croft combining automatic manual index representations probabilistic retrieval 
journal american society information science 
sahami dumais heckerman horvitz bayesian approach filtering junk mail 
working notes aaai th national conference artificial intelligence workshop learning text categorization 
pp 

schapire re singer boostexter boosting system text categorization 
machine learning 
sebastiani machine learning automated text categorization 
acm computing surveys 
shaw fox combination multiple searches 
conference 
pp 

trec proceedings rd text retrieval ting witten issues stacked generalization 
journal artificial intelligence research 
toyama horvitz bayesian modality fusion probabilistic integration multiple vision algorithms head tracking 
proceedings th asian conference computer vision 
van rijsbergen cj information retrieval 
butterworths london 
weiss apte damerau johnson oles goetz maximizing text mining performance 
ieee intelligent systems 
toolkit research microsoft com dmax html visited 

microsoft wolpert dh stacked generalization 
neural networks 
yang pierce combining multiple learning strategies effective cross validation 
icml proceedings th international conference machine learning 
pp 

yang liu re examination text categorization methods 
sigir proceedings nd annual international acm conference research development information retrieval 
pp 

zhang oles fj text categorization regularized linear classification methods 
retrieval 
information 
