learning continuous state action spaces chris david alexander zelinsky robotic systems laboratory department systems engineering research school information sciences engineering australian national university canberra act australia cg alex anu edu au 
learning learn control policy maximises scalar reward interaction environment 
qlearning commonly applied problems discrete states actions 
describe method suitable control tasks require continuous actions response continuous states 
system consists neural network coupled novel interpolator 
simulation results non holonomic control task 
santamaria address pre state information priori knowledge important parts state space receive approximation resources 
ahc presents method combines learning actor critic learning 
learning chose set actor critic learners 
performance unsatisfactory 
general set actions constant settings making equivalent lin system generalising states actor critic modules making equivalent standard actor critic system :10.1.1.75.7884
problems may stem fulfilling evaluation action generalisation state generalisation criteria different actor critic learners 
system represent non piecewise constant policies continuity criteria 
kohonen describes learning system kohonen self organising map 
state action expected value elements feature vector 
