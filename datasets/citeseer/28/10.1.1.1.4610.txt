topic detection tracking pilot study final report james allan jaime carbonell george jonathan yamron yiming yang umass amherst cmu darpa topic detection tracking tdt darpa sponsored initiative investigate state art finding new events stream broadcast news stories 
tdt problem consists major tasks segmenting stream data especially recognized speech distinct stories identifying news stories discuss new event occurring news small number sample news stories event finding stories stream 
tdt pilot study ran september october 
primary participants darpa carnegie mellon university dragon systems university massachusetts amherst 
report summarizes findings pilot study 
tdt continues new project involving larger training test corpora active participants broadly defined notion topic pilot study 
language models essentially employed speech recognition system cmu entry trec evaluation spoken document information retrieval 
static trigram models cnn experiments reuters experiments 
cnn experiments static trigram model tri vocabulary roughly words trained approximately words half years transcripts various news broadcasts including cnn news excluding journal graphics transcriptions overlap time frame tdt corpus 
reuters experiments trigram model vocabulary words trained approximately words wall street journal data 
models katz backoff scheme smoothing :10.1.1.129.7219
method construct adaptive model treat static trigram model default distribution add certain features semantic word classes order form family conditional exponential models 
details model described 
adaptive model improve sees material current topic event segment boundary exist adaptive model suddenly shows dip performance lower assigned probability observed words compared short range model 
conversely adaptive model consistently assigning higher probabilities observed words partition 
domain reuters newswire hand originates written communication story introduced recording day event occurred texas air na tional guard fighter jet crashed friday re area texas 
lexical features enable presence absence particular words surrounding context influence statistical segmenter 
presence word reporting broadcast news domain presence word fri day newswire domain indicate segment boundary nearby 
way learning algorithm chooses uses features described briefly section 
feature induction procedure combining evidence language models lexical features statistical framework called feature induction random fields exponential models :10.1.1.43.7345
idea construct model assigns position data stream probability boundary belongs position 
probability distribution incrementally constructed loglinear model weighs different features data 
simplicity assumed features binary questions 
way cast problem determining segment boundaries statistical terms construct probability distribution random variable describing presence segment boundary context consider distributions linear exponential family prior default distribution presence boundary linear combination binary features real valued feature parameters normalization constants insure family conditional probability distributions 
