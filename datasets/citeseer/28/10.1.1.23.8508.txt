classi cation sparse grids simplicial basis functions jochen michael institut ur mathematik friedrich universit bonn bonn germany uni bonn de new approach classi cation problem arising data mining 
regularization network approach contrast methods employ functions associated data points grid usually high dimensional feature space minimization process 
cope curse dimensionality employ sparse grids 
grid points unknowns involved 
denotes dimension feature space hn gives mesh size 
sparse grid combination technique classi cation problem discretized solved sequence conventional grids uniform mesh sizes dimension 
set data points dimensional feature space class label 
data classi er constructed allows predict class newly data point decision making 
widely approaches decision tree induction rule learning adaptive multivariate regression splines neural networks support vector machines 
interestingly techniques interpreted framework regularization networks 
approach allows direct description important neural networks allows equivalent description support vector machines term approximation schemes :10.1.1.48.7480:10.1.1.48.7480
classi cation data interpreted scattered data approximation problem certain additional regularization terms high dimensional spaces 
new approach classi cation problem 
regularization network approach contrast methods employ global functions associated data points independent grid associated local functions minimization process 
similar numerical treatment partial di erential equations nite element methods 
nal remarks conclude 
problem classi cation data interpreted traditional scattered data approximation problem certain additional regularization terms 
contrast conventional scattered data approximation applications encounter quite high dimensional spaces 
approach regularization networks gives framework 
approach allows direct description important neural networks allows equivalent description support vector machines term approximation schemes :10.1.1.48.7480
consider set classi ed data training set rg assume data obtained sampling unknown function belongs function space de ned sampling process disturbed noise 
aim recover function data possible 
clearly ill posed problem nitely solutions possible 
get posed uniquely solvable problem assume knowledge regularization theory imposes additional smoothness constraint solution approximation problem regularization network approach considers variational problem min denotes error cost function measures interpolation error smoothness functional de ned rst term enforces closeness data second term enforces smoothness regularization parameter balances terms 
get posed uniquely solvable problem assume knowledge regularization theory imposes additional smoothness constraint solution approximation problem regularization network approach considers variational problem min denotes error cost function measures interpolation error smoothness functional de ned rst term enforces closeness data second term enforces smoothness regularization parameter balances terms 
typical examples jx yj jj pf rf pf 
denoting gradient 
laplace operator 
value chosen cross validation techniques principle structural risk minimization :10.1.1.37.3325:10.1.1.37.3325:10.1.1.183.534
note nd exactly type formulation case scattered data approximation methods see regularization term usually physically motivated 
discretization restrict problem nite dimensional subspace vn function replaced fn functions span vn preferably form basis vn coecients denote degrees freedom 
note restriction suitably chosen nite dimensional subspace involves additional regularization regularization discretization depends choice vn remainder restrict choice fn fn fn jj linear operator way obtain minimization problem feasible linear system 
minimize fn fn nite dimensional space vn plug obtain di erentiation respect fn 
data real data practical data mining applications 
data sets rescaled ease computation 
data sets small number data points map median attribute scale values accordingly 
bigger data sets just normalized evaluate method give correctness rates testing data sets available fold cross validation results 
details critical discussion evaluation quality classi cation algorithms see :10.1.1.37.3325
run times measured pentium iii mhz machine 
dimensional problems rst consider synthetic dimensional problems small sets data correspond certain structures 
spiral rst example spiral data set proposed mitre 
data points describe intertwined spirals see 
gerstner 
numerical integration sparse grids 

algorithms 
girosi :10.1.1.48.7480:10.1.1.48.7480
equivalence sparse approximation support vector machines 
neural computation 
girosi jones poggio 
regularization theory neural networks architectures 
