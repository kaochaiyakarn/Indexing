quickset multimodal interaction distributed applications philip cohen michael johnston david mcgee sharon oviatt presents emerging application multimodal interface research distributed applications 
developed quickset prototype pen voice system running hand held pc communicating wireless lan agent architecture number systems including system distributed interactive training simulator built marine 
describes system architecture novel multimodal integration strategy offering mutual compensation modalities provides examples multimodal simulation setup 
discuss applications experience evaluation 
key wo multimodal interfaces agent architecture gesture recognition speech recognition natural language processing distributed interactive simulation 

agent architecture offers flexible asynchronous framework build multimodal systems remainder section briefly multimodal integration method 
information johnston 
temporally sensitive unification architecture multimodal integration significant challenges facing development effective multimodal interfaces concerns integration input different modes 
quickset inputs mode need temporally semantically compatible fused integrated meaning 
temporal compatibility empirical oviatt discovered users speak gesture sequential manner gesture fit speak relatively short time window speech rarely precedes gesture :10.1.1.117.6842
consequence multimodal prefers integrate gesture speech follows short time interval preceding speech 
speech arrives interval gesture interpreted 
temporally sensitive architecture requires time stamps input stream 
strategy may difficult implement distributed environment speech recognition gesture recognition performed different machines network requiring synchronization clocks 
