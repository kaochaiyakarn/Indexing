hand speech input virtual environments joseph jr computer science florida atlantic university dissertation submitted partial ful llment requirements degree master science department computer science brown university providence rhode island december dissertation joseph jr accepted form department computer science satisfying thesis requirement degree master science 
date van dam director recommended graduate council date david reader date robert zeleznik reader date william buxton reader alias approved graduate council date dean graduate school research ii approaches providing users natural method interacting computer applications shown mode input bene cial intuitive communication medium humans computers 
modalities particular hand speech input represent natural form communication physical mental makeup birth 
thesis investigate hand speech input virtual environments context applications domains scienti visualization interior design 
examining modalities individually combination creation application prototypes multimodal scienti visualization tool room designer anumber contributions including set interface guidelines interaction techniques hand speech input 
iii wish members thesis committee robert zeleznik david van dam william buxton support direction guidance development ideas 
state hmm 
xi interaction represents important components virtual environment applications devices techniques models researched analyzed purpose nding usable robust interfaces 
interface style shown potential creating useful robust interfaces multimodal interaction 
multimodal interfaces existed computer ui early bolt put system early begun examined incorporated virtual environments applications 
di individual modalities combined form multimodal interfaces :10.1.1.138.635:10.1.1.15.3658
interesting hand speech input modalities represent natural form communication physical mental makeup birth 
person person level humans modalities everyday conversation interesting question arises best way hand voice input virtual environments human level 
main objective thesis development set practical guidelines interaction techniques hand speech input virtual environment applications 
focus domains scienti visualization interior design virtual environment virtual reality document 
technique users pull space hand 
pinch hands simultaneously rotation scaling translation operations performed movement 
traditional methods selecting manipulating objects pointing reaching grabbing 
sturman zeltzer explored pointing grasping postures gestures object selection manipulation hand postures logical buttons hand gestures menu operations sliders 
davis bryson pointing grabbing object interaction ves :10.1.1.138.635:10.1.1.32.4166
approach pierce image plane interaction techniques distinct hand postures object selection manipulation including lifting palm posture see handed framing posture see single nger head posture kanade hand posture gesture recognition create mouse object manipulation virtual environment 
lifting palm object selection technique 
hand input advantages object creation ves user directly create objects hands 
example krueger system allows users create objects silhouette hand pointing 
discrete hand data hand posture mapped directly manipulative task sturman claims category rarely applications direct robot control 
discrete mapped 
discrete hand data mapped discrete activation level object animated long user st discrete symbolic 
discrete hand data generate commands application user halt posture object moving 
mit gesture classi cation system gesture classi cation system rst discussed wexelblat indirectly discussed cassell wilson :10.1.1.138.635
classi cation system starts idea previous gesture classi cation systems efron kendon oriented psychological domain necessarily apply computer applications 
system broken major categories symbolic 
symbolic gestures essentially hand postures represent object concept directly mapped particular meaning instance thumbs posture means okay 
gestures gestures conjunction input modality speech 
gesture usually accompanies utterances show directionality metaphor 
beat butterworth self 
beats gestures emphasis especially speech 
beat gestures help speakers emphasize particular words concepts help direct listener attention 
butterworth gestures similar beats primarily mark :10.1.1.138.635
classic example butterworth gesture hand waving placeholder speaking thinking 
self gestures people example taps nger moves foot rapidly 
classi cations systems described previous section useful providing mappings human postures gestures computer interfaces theoretical nature result useful ui developers comes practical implementations 
required practical classi cation scheme account implementation speci details input devices 
exception digital data entry glove developed speci cally entering text single hand manual alphabet author knows done combining discrete continuous hand input devices extract geometrical topological data simultaneously 
order develop interface spans ig quadrants geometrical topological classi cation scheme built hardware prototyping system testing evaluating di designs 
hardware system provides number bene ts employs plug play strategy quickly adding removing button widgets components 
system enables users incorporate cloth sensors wearable interface 
cloth sensors provide important functions rst sensor knows comes contact sensor speci cally sensor contacts second nature cloth lends gloves clothing :10.1.1.20.5616
prototyping system constructed device pinch glove 
hardware input device provides functionality pinch glove uses cloth buttons allows button combinations 
general cloth buttons placed nger tips placed arbitrarily hand 
con guration represents possible combinations placement cloth buttons 
push part push talk mechanisms increasing user cognitive load 
foot fails cases cave display surface exists oor displays user see physical environment 
foot appropriate ves displays 
example recognizer thinks user said computer start listening really didn 
approach systems quickset speech recognition activates user screen virtual environments :10.1.1.138.635
example users want instantiate object place point place want object go act pointing triggered gesture button press example activate speech recognition 
pointing speech recognition moves non active mode 
approach works room designer described chapter gets close naturalistic style interaction described section possess drawbacks previous approaches 
microphone placement solutions 
best examples transfer multimodal interaction push talk interface described chapter speech modality receives information hand gesture telling speech activated 
multimodal combination types important building richer set interactions focuses complementarity concurrency specialization transfer 
di input mode combinations multimodal interaction 
zeleznik uses stylus tablet interact conceptual modeling application 
cohen uses pen gestures voice commands quickset system setup control distributed interactive simulations :10.1.1.138.635
waibel vo series input modes include speech pen gestures eye tracking lip reading handwriting recognition face recognition applications text editing calendar management 
common thread systems user hands input interact application 
context hand speech input multimodal interface integrates modalities traced back bolt put system developed 
system pointing hand postures voice commands create manipulate edit simple primitives squares circles large rear projected screen 
system menu driven take advantage hand input 
multimodal uses hand gestures speech 
important aspect multimodal interaction integration di erent input modes di strategies developed 
johnston developed uni cation integration scheme research conducted oviatt people integration patterns mode input 
scheme uses typed feature structures represent semantic contributions di erent modes allows individual modalities compensate errors :10.1.1.138.635
expert systems integrate multiple modes input shown billinghurst 
system set production rules encode domain knowledge integrate speech hand gesture 
rules map high level semantic information inputs generate somewhat intelligent response 
approach input integration frames 
approach input integration frames 
case frames consist slots hold information single input mode 
command interpreter takes frames determines appropriate action take 
advantage approach exibility incorporating modes input 
note strategies agent approaches guided propagation networks developed integrating multiple modes input :10.1.1.138.635
multimodal interaction provides bene ts traditional unimodal metaphors wimp windows icons menus point click interfaces 
combining speech input human computer interaction augmented users interact naturally human human interaction occurs combinations speech hand movement 
second application achieve better understanding user intended action providing multiple input streams speech hand input provide perfect recognition accuracy 
combining hand speech input advantages simplifying interface user perspective developer perspective 
default value set 
current grammar built rejection parameter value automatically set setting parameter case cause parameter setting command fail 
rejection sensitivity interface send speech start speech output speech activity heartbeat interval seconds default heartbeat heartbeat interval sec enable speech detector set default search speech speech detect speech detect sensitivity value insensitive sensitive default 
useful range speech detect sensitivity example parameter le 
application multimodal scienti visualization rst prototype application developed framework described previous chapter multimodal scienti visualization tool msvt exploring ow dataset see virtual project bryson :10.1.1.138.635
msvt uses rear projected display hardware con guration combines speech input postures gestures 
idea msvt build natural scienti visualization application explore multimodal input combination types speci cally complementarity concurrency specialization transfer 
important goal prototype determine far attaining human computer speech dialog communication shelf technology 
msvt gives users ability create modify drop pick delete small set visualization tools streamlines exploring ow eld dataset 
chair appears requested location facing user 
chair instantiated may appropriate type 
users cycle available chairs furniture database left hand body thumb 
beep indicates reached list depending direction hand moving 
techniques simply picking menu virtual palette want user look place object selection place object instantiation :10.1.1.138.635
technique user try di furniture having visually cognitively area interest time di erent piece furniture created 
note pictures created manner 
furniture interior manipulation placed furniture interior decorations moved architectural space simple direct manipulation 
left right hand users grab existing object hand approximate location object 
false positive recognition known insertion error system recognizes posture gesture generally applicable continuous recognition systems 
false negative recognition known deletion error system recognize particular posture gesture 
replacement recognition occurs system recognizes particular posture gesture di erent 
relative consequences associated di erent errors vary application types errors reported part accuracy metric 
unfortunately starner birk report done :10.1.1.51.6538
hand posture gesture recognition technology appendix discusses requirements hand posture gesture recognition 
describes main solutions collecting required data perform recognition glove solution camera vision solution looks advantages disadvantages 
rst step hand posture gestures computer applications gathering raw data 
raw data analyzed various recognition algorithms see appendix extract meaning context data order perform tasks application 
second consideration vision solution hand posture gesture recognition hands visible camera simpler extraction hand data 
rst ways doing place leds light emitting various points hand 
leds camera quickly pick feature points hand aid recognition 
common method literature simply colored gloves 
starner davis kuno shown solid colored gloves allows faster hand silhouette extraction simply wearing gloves gloves dicult recognize nger movement bending :10.1.1.51.6538:10.1.1.32.4166
order achieve fast silhouette extraction track nger developed complex encoding scheme sets colored rings nger joints solid colored gloves 
colored gloves wireless simple wear ideal situation hand tracking track hand gloves 
tracking hand presents interesting diculties skin color background environment issues 
cases solid colored screen placed user natural color hands features extracted 
vision solutions general calibration step wide variety users 
portability applications especially gesture speech systems freedom tied important 
glove solutions freedom generally available long hand tracking involved input devices plugged laptop computer 
vision solutions originally quite dicult mobile environment due camera placement issues computing power requirements 
computing powerful laptops built cameras mobile vision solutions practical :10.1.1.20.5616
noise glove solutions hand tracking required type noise bound associated data come variety sources depending tracking technology 
filtering algorithms necessary reduce noise jitter 
cases get computationally expensive predictive techniques kalman ltering 
vision solution noise problematic severe glove solutions 
technique places contour image roughly shape feature tracked 
contour manipulated iteratively nearby edges contour feature 
heap extend technique extract features recognizing hand postures gestures computer vision 
system apply active shape model frame position feature frame initial approximation frame 
point distribution model nd suitable model tracked object aids approximating position frame :10.1.1.138.635
analysis 
heap system runs real time frames second applicable vision solutions 
main disadvantages technique input classi cation algorithms see section currently track open hand severely limit number hand postures gestures recognized 
little empirical evidence literature support validity 
linear model assumes nger movements linear comprise little rotational movement 
assumption allows simpli ed hand model uses input data permits model represents trajectory space simple vector 
general features extracted linear models magnitude direction 
details examples 
davis shah approach vision solution puts glove colored user hand :10.1.1.32.4166
technique rst extracts positions histogram segmentation knowledge pixel intensity known signi cantly di erent mathematical description classi er reduced set mahalanobis distance measurements see birk 
remaining regions 
priori knowledge histogram created regions corresponding rightmost peak 
threshold established smoothing histogram nding valley peaks 
instance learning techniques advantage simplicity number disadvantages 
major disadvantage cost classifying new instances 
computation redone new instance classi ed means response time issues dealing large amount training examples 
disadvantage methods training examples may main memory increase response time 
note aha developed instance learning algorithms alleviate problems :10.1.1.138.635
rst saves space discarding instances correctly classi ed second assumptions data irrelevant instances 
aside little done instance learning recognizing hand postures gestures 
systems reported literature developed recognized discrete hand postures performing sign language recognition instance learning algorithms described aha :10.1.1.138.635
interesting feature system approximately accuracy power glove raw data collection unit 
disadvantage methods training examples may main memory increase response time 
note aha developed instance learning algorithms alleviate problems :10.1.1.138.635
rst saves space discarding instances correctly classi ed second assumptions data irrelevant instances 
aside little done instance learning recognizing hand postures gestures 
systems reported literature developed recognized discrete hand postures performing sign language recognition instance learning algorithms described aha :10.1.1.138.635
interesting feature system approximately accuracy power glove raw data collection unit 
analysis 
instance learning shows promise way recognize hand postures 
response time may important factor issuing posture commands due amount computation required instance generated especially instances generated second speed input devices 
linguistic approach appear accurate robust handle hand posture gesture recognition tasks 
strengths simple approach vision glove solution weaknesses poor recognition results limited simple hand postures little reported literature technique recognize hand postures gestures appearance motion analysis overview 
appearance motion analysis exploits observation humans recognize actions extremely low resolution images little information dimensional structure scene 
details examples 
observation davis developed recognition strategy human motion hypothesize test paradigm :10.1.1.32.4166
strategy recognizes motion patterns video stream rst creating lter called binary motion region describes spatial distribution motion energy action 
words lter highlights regions image form motion action 
acts index database binary motion regions collected training sessions 
current close stored current tested motion model action 
features single image extracted matched mahalanobis distance metric known movement system tested small set motions sitting arm waving results subjects included training phase 
subjects included training phase performed signi cantly lower claims representative training data 
analysis 
speci cally recognize hand gestures appearance motion analysis recognize simple ones technique gestures postures complicated nger movement 
research needed determine complex set motions recognized existing technique note detailed description recognition technique described previous paragraph davis :10.1.1.32.4166
hand gestures complicated set test motions davis evaluation 
strengths provides unobtrusive recognition accurate recognition small set motions trained user weaknesses recognizing hand posture gestures dicult detect small details nger movement statistical methods common technique popular pattern speech recognition communities probabilistic statistical models 
technique hand posture gesture recognition literature hidden markov models 
hidden markov models overview 
hidden markov models overview 
describing hidden markov models convenient rst consider markov chains 
simply nite state automata state transition arc associated arcs leaving single state sum 
impose restriction nite state automaton state transition arc output restriction markov chains deterministic 
hidden markov model hmm considered generalization markov chain restriction :10.1.1.138.635
hmms arc output symbol nondeterministic impossible directly determine state sequence set inputs simply looking output hidden hidden markov model 
detailed description see rabiner juang rabiner huang charniak :10.1.1.131.2084:10.1.1.138.635
details examples 
hmm de ned set states state initial state set output symbols set state transitions 
simply nite state automata state transition arc associated arcs leaving single state sum 
impose restriction nite state automaton state transition arc output restriction markov chains deterministic 
hidden markov model hmm considered generalization markov chain restriction :10.1.1.138.635
hmms arc output symbol nondeterministic impossible directly determine state sequence set inputs simply looking output hidden hidden markov model 
detailed description see rabiner juang rabiner huang charniak :10.1.1.131.2084:10.1.1.138.635
details examples 
hmm de ned set states state initial state set output symbols set state transitions 
state transition represented state transition starts state transition moves output symbol generated probability transition taken :10.1.1.138.635
context hand gesture recognition state represent set possible hand positions 
hmms arc output symbol nondeterministic impossible directly determine state sequence set inputs simply looking output hidden hidden markov model 
detailed description see rabiner juang rabiner huang charniak :10.1.1.131.2084:10.1.1.138.635
details examples 
hmm de ned set states state initial state set output symbols set state transitions 
state transition represented state transition starts state transition moves output symbol generated probability transition taken :10.1.1.138.635
context hand gesture recognition state represent set possible hand positions 
state transitions represent probability certain hand position transitions corresponding output symbol represents speci posture sequence output symbols represent hand gesture 
uses group hmms gesture runs sequence input data hmm 
input data derived pixels vision solution bend sensor values glove solution represented di common feature vectors :10.1.1.51.6538
state transition represented state transition starts state transition moves output symbol generated probability transition taken :10.1.1.138.635
context hand gesture recognition state represent set possible hand positions 
state transitions represent probability certain hand position transitions corresponding output symbol represents speci posture sequence output symbols represent hand gesture 
uses group hmms gesture runs sequence input data hmm 
input data derived pixels vision solution bend sensor values glove solution represented di common feature vectors :10.1.1.51.6538
hmm highest forward probability described section determines users gesture 
hmm hand posture recognition see liang details 
anumber important issues arise dealing hmms 
neural networks training hmms important increasing recognition accuracy model 
anumber important issues arise dealing hmms 
neural networks training hmms important increasing recognition accuracy model 
common approach adjust hmm transition probabilities order optimize training data set 
training data accurate representation particular gesture example hmm able recognize gesture new data 
baum welch algorithm uses training sequence probabilities state transitions hmm :10.1.1.131.2084:10.1.1.138.635
components baum welch algorithm forward probability forward probability alpha probability called probability hmm output sequence calculated incrementally computing probabilities output symbol symbol basis 
algorithm goes timestep examines state hmm 
state computes summation probability producing current output symbol moving algorithm state multiplied probability producing output note summation performing calculation iteratively output symbol yields probability hmm generate output sequence 
forward probability nd hmm highest probability matching output sequence 
algorithm goes timestep examines state hmm 
state computes summation probability producing current output symbol moving algorithm state multiplied probability producing output note summation performing calculation iteratively output symbol yields probability hmm generate output sequence 
forward probability nd hmm highest probability matching output sequence 
example hand gesture set contains gestures having hmm hmm highest forward probability score determine gesture recognize 
see charniak detailed description forward probability :10.1.1.138.635
stated previously drawbacks hmms directly determine state sequence set output symbols state arc output 
information approximated nding states hmm 
common technique nding best state sequence output viterbi algorithm uses calculations similar forward probability maximum taken summation viterbi algorithm useful fast method evaluating hmms 
detail viterbi algorithm see charniak :10.1.1.138.635
see charniak detailed description forward probability :10.1.1.138.635
stated previously drawbacks hmms directly determine state sequence set output symbols state arc output 
information approximated nding states hmm 
common technique nding best state sequence output viterbi algorithm uses calculations similar forward probability maximum taken summation viterbi algorithm useful fast method evaluating hmms 
detail viterbi algorithm see charniak :10.1.1.138.635
hidden markov models rst recognition community recognizing handwriting speech signi cant amount research done applying hmms hand posture gesture recognition 
starner hmms vision solution recognize subset american sign language :10.1.1.51.6538
di erent model sign recognition set starner minimum maximum number states required individual hmm skip transitions state transitions needed developed general hmm topology models system 
ample training hmms training samples sign system able achieve accuracies percent 
information approximated nding states hmm 
common technique nding best state sequence output viterbi algorithm uses calculations similar forward probability maximum taken summation viterbi algorithm useful fast method evaluating hmms 
detail viterbi algorithm see charniak :10.1.1.138.635
hidden markov models rst recognition community recognizing handwriting speech signi cant amount research done applying hmms hand posture gesture recognition 
starner hmms vision solution recognize subset american sign language :10.1.1.51.6538
di erent model sign recognition set starner minimum maximum number states required individual hmm skip transitions state transitions needed developed general hmm topology models system 
ample training hmms training samples sign system able achieve accuracies percent 
single hmm recognize hand gestures vision solution 
state hmm represents gestures observation symbols represent current static hand posture 
proceedings th international conference pattern recognition 
vol 

conference computer vision applications 
aha david dennis kibler marc albert :10.1.1.138.635
instance learning algorithms 
machine learning 
anderson james neural networks 
bradford books boston 
proceedings aaai conference 
lowe 
functional interpolation adaptive networks 
complex systems 
bryson steve :10.1.1.138.635
virtual reality scienti visualization 
communications acm 
bryson johan :10.1.1.138.635
extensible interactive visualization framework virtual 
complex systems 
bryson steve :10.1.1.138.635
virtual reality scienti visualization 
communications acm 
bryson johan :10.1.1.138.635
extensible interactive visualization framework virtual 
proceedings virtual reality annual international symposium 
butterworth :10.1.1.138.635
gesture silence indicators planning speech 
communications acm 
bryson johan :10.1.1.138.635
extensible interactive visualization framework virtual 
proceedings virtual reality annual international symposium 
butterworth :10.1.1.138.635
gesture silence indicators planning speech 
advances psychology language campbell smith eds plenum press new york 
carpenter logic structures cambridge university press cambridge england :10.1.1.138.635
cassell :10.1.1.138.635
proceedings virtual reality annual international symposium 
butterworth :10.1.1.138.635
gesture silence indicators planning speech 
advances psychology language campbell smith eds plenum press new york 
carpenter logic structures cambridge university press cambridge england :10.1.1.138.635
cassell :10.1.1.138.635
framework gesture generation interpretation 
computer vision human machine interaction 
cipolla pentland eds cambridge university press forthcoming 
butterworth :10.1.1.138.635
gesture silence indicators planning speech 
advances psychology language campbell smith eds plenum press new york 
carpenter logic structures cambridge university press cambridge england :10.1.1.138.635
cassell :10.1.1.138.635
framework gesture generation interpretation 
computer vision human machine interaction 
cipolla pentland eds cambridge university press forthcoming 
charniak eugene :10.1.1.138.635
cassell :10.1.1.138.635
framework gesture generation interpretation 
computer vision human machine interaction 
cipolla pentland eds cambridge university press forthcoming 
charniak eugene :10.1.1.138.635
statistical language learning 
mit press cambridge 
cheyer julia :10.1.1.138.635
multimodal maps agent approach 
cipolla pentland eds cambridge university press forthcoming 
charniak eugene :10.1.1.138.635
statistical language learning 
mit press cambridge 
cheyer julia :10.1.1.138.635
multimodal maps agent approach 
lecture notes arti cial intelligence multimodal human computer communication eds 

cohen johnston mcgee oviatt pittman smith chen :10.1.1.138.635
cheyer julia :10.1.1.138.635
multimodal maps agent approach 
lecture notes arti cial intelligence multimodal human computer communication eds 

cohen johnston mcgee oviatt pittman smith chen :10.1.1.138.635
quickset multimodal interaction distributed applications 
proceedings fifth annual international multimodal conference 
:10.1.1.138.635
virtual palette virtual remote control panel device interaction paradigm 

cohen johnston mcgee oviatt pittman smith chen :10.1.1.138.635
quickset multimodal interaction distributed applications 
proceedings fifth annual international multimodal conference 
:10.1.1.138.635
virtual palette virtual remote control panel device interaction paradigm 
ieee vr 
cootes taylor cooper graham :10.1.1.138.635
active shape models training applications 
proceedings fifth annual international multimodal conference 
:10.1.1.138.635
virtual palette virtual remote control panel device interaction paradigm 
ieee vr 
cootes taylor cooper graham :10.1.1.138.635
active shape models training applications 
computer vision image understanding january 
cootes taylor 
active shape models smart snakes 
proceedings siggraph 
davis james william 
appearance motion recognition human actions 
master thesis massachusetts institute technology 
davis james william shah :10.1.1.32.4166
gesture recognition 
technical report department computer science university central florida cs tr 
thomas daniel 
final report national arts 
intelligent environments aaai spring symposium series 

validity assessment hand master linkage system measurement joints hand 
abstracts world congress volume la jolla california 
mann steve :10.1.1.20.5616
wearable computing step personal imaging ieee computer 
daniel michael 
handed interface object manipulation virtual environments 
teleoperators virtual environments 
journal optical society america 
starner thad alex pentland 
real time american sign language recognition video hidden markov models 
mit media laboratory perceptual computing section technical report 
starner thad :10.1.1.51.6538
visual recognition american sign language hidden markov models 
master thesis massachusetts institute technology 
state andrei david chen william garrett mark livingston 
superior augmented reality registration landmark tracking magnetic tracking 
