multimedia systems manuscript nr 
inserted hand spatial cognition neuro mimetic navigation model hippocampal place cell activity gerstner centre neuro mimetic systems swiss federal institute technology lausanne ch lausanne epfl switzerland 
october 
computational model hippocampal activity spatial cognition navigation tasks 
spatial representation model rat hippocampus built line exploration processing streams 
vision representation built unsupervised hebbian learning extracting spatio temporal properties environment visual input 
allows correlate cues drive place cell activity 
proposed model results neural spatial representation consisting population localized overlapping place fields modeling activity ca ca cells 
interpret ensemble place cell activity spatial location apply population vector coding scheme 
order accomplish functional role spatial behavior proposed hippocampal model incorporate knowledge relationships environment obstacles specific target locations 
brown sharp burgess apply reinforcement learning enable navigation hippocampal place cell activity :10.1.1.17.3013:10.1.1.32.7692
focus specific neural pathway projection connecting hippocampus particular ca region nucleus accumbens 
extra hippocampal structure probably involved reward goal memory behavior 
place cell activity drives population action neurons nucleus accumbens 
synaptic efficacy ca cells action cells changed function target related reward signals 
internal movement related information provided dead reckoning odometry 
robotics offers useful tool validate models functionalities neuro physiological processes 
artificial agents simpler experimentally transparent biological systems appealing understanding nature underlying mechanisms animal behavior 
approach similar spirit earlier studies 
contrast burgess recce keefe directly metric information distance visual cues input model :10.1.1.17.3013
interpret visual properties learning pop commercial robotic platform team www team com 
neurons sensitive specific visual stimulation 
path integration model burgess 
contrast model consider vision path integrator important constituent hippocampal model 
soon finds calibration location open field exploring behavior resumed 
gerstner spatial behavior learning navigation maps hippocampal model allows robot environment fig 

order provide cognitive support spatial behavior place cell activity guide navigation 
derive navigational maps applying reinforcement learning map ca ca ensemble activity behavior :10.1.1.32.7692
navigation part implemented robot done simulation 
reinforcement learning continuous space nucleus accumbens thought play important role reward spatial learning 
receives place coding information hippocampal formation rewarding stimulation neurons area 
consider population action cells nucleus accumbens activity provides directional motor commands 
navigation part implemented robot done simulation 
reinforcement learning continuous space nucleus accumbens thought play important role reward spatial learning 
receives place coding information hippocampal formation rewarding stimulation neurons area 
consider population action cells nucleus accumbens activity provides directional motor commands 
type target food water action cells coding north south west east actions driven population ca ca place cells :10.1.1.17.3013
synapses hippocampal place cells action cells modified learn continuous location action mapping function goal directed tasks 
occurs associate spatial locations rewarding actions takes place fig 

learning action value function continuous location space endows system spatial generalization capabilities 
denote activation ca ca place cell activity action cell robot position encoded place cell activity number ca ca place cells 
synaptic projections hippocampal place cells action cell fig 

activity depends linearly robot position synaptic weights learning task consists updating approximate optimal goal oriented function maps states action cell activity 
linear gradient descent version watkins qlearning algorithm :10.1.1.32.7692
robot position interpret neural activity expected gain action location environment 
training robot behaves order consolidate goal directed paths exploitation find fig 

ca ca place cells project action cells target type nucleus accumbens 

ca ca place cells project action cells target type nucleus accumbens 
reinforcement learning find function maps continuous spatial locations actions 
novel routes exploration 
exploitation exploration trade determined ffl greedy action selection policy ffl :10.1.1.32.7692
time robot takes optimal action probability gamma ffl exploitation arg max resort uniform random action selection probability equal ffl exploration 
time step deltat synaptic efficacy projections changes deltaw ff ffi terms eq :10.1.1.32.7692
interpretation factor ff ff constant learning rate 
ii term ffi prediction error defined ffi fl max gamma actual reward delivered internal brain signal fl fl constant discount factor 
reinforcement learning find function maps continuous spatial locations actions 
novel routes exploration 
exploitation exploration trade determined ffl greedy action selection policy ffl :10.1.1.32.7692
time robot takes optimal action probability gamma ffl exploitation arg max resort uniform random action selection probability equal ffl exploration 
time step deltat synaptic efficacy projections changes deltaw ff ffi terms eq :10.1.1.32.7692
interpretation factor ff ff constant learning rate 
ii term ffi prediction error defined ffi fl max gamma actual reward delivered internal brain signal fl fl constant discount factor 
temporal difference ffi estimates error expected actual reward location time robot takes action reaches location time 
training trials allow robot minimize error signal 
temporal difference error ffi update synaptic weights may thought teaching signal 
iii training paths eq 
allows robot memorize action sequences 
taken actions relevant earlier ones need memory trace mechanism weight actions function occurrence time 
vector called eligibility trace provides mechanism :10.1.1.32.7692
update eligibility trace depends robot selects exploratory exploiting action 
specifically vector changes spatial cognition neuro mimetic navigation model hippocampal place cell activity ae fle gamma exploiting exploring trace decay parameter ca ca vector activity :10.1.1.32.7692
start 
behavioral experiments experimental setup shown fig 
allows robot memorize action sequences 
taken actions relevant earlier ones need memory trace mechanism weight actions function occurrence time 
vector called eligibility trace provides mechanism :10.1.1.32.7692
update eligibility trace depends robot selects exploratory exploiting action 
specifically vector changes spatial cognition neuro mimetic navigation model hippocampal place cell activity ae fle gamma exploiting exploring trace decay parameter ca ca vector activity :10.1.1.32.7692
start 
behavioral experiments experimental setup shown fig 
define specific target region feeding location environment 
apply reward learning scheme build navigational strategy leading robot target location avoiding obstacles 
redundancy place cell activity considered crucial property yield robustness 
learning model developed spatial representation consisting large population overlapping place fields covering environment uniformly densely 
interpret ensemble place cell activity spatial locations apply population vector coding 
hippocampus projects nucleus accumbens structure involved spatial behavior 
consider population action neurons nucleus accumbens apply reward learning adjust synapses ca ca cells action cells :10.1.1.17.3013
target location results learning mapping function continuous space physical locations activity space action cells 
allows accomplish goal oriented navigation neural activity nucleus accumbens 
navigation maps derived interpreting ensemble action cell activity means population coding :10.1.1.17.3013
note population vector decoding allows interpretation place cell activity interpretation necessary action learning reinforcement learning place cells simply set basis functions high dimensional input space 
hippocampus projects nucleus accumbens structure involved spatial behavior 
consider population action neurons nucleus accumbens apply reward learning adjust synapses ca ca cells action cells :10.1.1.17.3013
target location results learning mapping function continuous space physical locations activity space action cells 
allows accomplish goal oriented navigation neural activity nucleus accumbens 
navigation maps derived interpreting ensemble action cell activity means population coding :10.1.1.17.3013
note population vector decoding allows interpretation place cell activity interpretation necessary action learning reinforcement learning place cells simply set basis functions high dimensional input space 
burgess previously postulated goal memory system consisting population goal cells gc driven hippocampal place cells :10.1.1.17.3013
goal cell activity encodes animal position respect goal north east south west 
model activity hippocampal cells place field contains target correlated gc activity hebbian learning 
target location results learning mapping function continuous space physical locations activity space action cells 
allows accomplish goal oriented navigation neural activity nucleus accumbens 
navigation maps derived interpreting ensemble action cell activity means population coding :10.1.1.17.3013
note population vector decoding allows interpretation place cell activity interpretation necessary action learning reinforcement learning place cells simply set basis functions high dimensional input space 
burgess previously postulated goal memory system consisting population goal cells gc driven hippocampal place cells :10.1.1.17.3013
goal cell activity encodes animal position respect goal north east south west 
model activity hippocampal cells place field contains target correlated gc activity hebbian learning 
results gc limited attraction radius animal navigation large distances target allow obstacles 
addition burgess propose re learning mechanism cope targets location change :10.1.1.17.3013
burgess previously postulated goal memory system consisting population goal cells gc driven hippocampal place cells :10.1.1.17.3013
goal cell activity encodes animal position respect goal north east south west 
model activity hippocampal cells place field contains target correlated gc activity hebbian learning 
results gc limited attraction radius animal navigation large distances target allow obstacles 
addition burgess propose re learning mechanism cope targets location change :10.1.1.17.3013
robotic platform validate computational model real task environment contexts 
course body robot navigation neural networks authors authors previously implemented hippocampal models real robots 
understanding underlying mechanisms hippocampal place cell activity offers attractive prospect developing control algorithms directly emulate navigational abilities 
hand simplicity transparency artificial agents suitable studying understanding processes 
