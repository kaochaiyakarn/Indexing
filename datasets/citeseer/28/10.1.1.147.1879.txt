consistent hashing random trees distributed caching protocols relieving hot spots world wide web david karger eric lehman tom leighton matthew levine daniel lewin rina panigrahy describe family caching protocols distrib networks decrease eliminate occurrence hot spots network 
protocols particularly designed large networks internet delays caused hot spots severe feasible server complete information current state entire network 
protocols easy implement existing network protocols tcp ip require little overhead 
protocols local control efficient existing resources scale gracefully network grows 
caching protocols special kind hashing call consistent hashing 
roughly speaking consistent hash function changes minimally range function changes 
development consistent hash functions able develop caching protocols require users current consistent view network 
believe consistent hash functions may eventually prove useful applications distributed name servers quorum systems 
describe caching protocols distributed networks decrease eliminate occurrences hot spots 
hot spots occur time large number clients wish simultaneously access data single server 
site provisioned deal clients simultaneously service may degraded lost 
experienced hot spot phenomenon context web 
web site suddenly extremely popular receive far requests relatively short time research supported part darpa contracts dabt army contract daah nsf contract ccr laboratory computer science mit cambridge ma 
email lehman ftl theory lcs mit edu full version theory lcs mit edu lehman ftl department mathematics mit cambridge ma originally configured handle 
fact site may receive requests swamped typically renders unusable 
making site inaccessible heavy traffic destined location network near interfering traffic nearby sites 
web increased occurrence impact hot spots 
famous examples hot spots web include jpl site levy comet struck jupiter ibm site deep blue kasparov chess tournament political sites night election 
cases users denied access site hours days 
examples include sites identified web site ofthe day sites provide new versions popular software 
originally motivated problem hot spots world wide web 
believe tools develop may relevant client server models centralized servers internet domain name servers multicast servers content label servers susceptible hot spots 
past approaches overcoming hot spots proposed 
kind replication strategy store copies hot pages internet spreads serving hot page servers 
approach wide clients share proxy cache 
user requests forwarded proxy tries keep copies frequently requested pages 
tries satisfy requests cached copy failing forwards request home server 
dilemma scheme benefit users share cache cache liable get swamped 
problem making group caches function 
user request page directed arbitrary cache 
page stored returned user 
cache forwards request caches special protocol called ip multicast 
page cached request forwarded home site page 
disadvantage technique number participating caches grows multicast number messages caches unmanageable 
tool develop consistent hashing way implement distributed cache requiring caches communicate time 
discuss section 
chankhunthod developed harvest cache scalable approach tree caches :10.1.1.21.1584
user obtains page asking nearby leaf cache 
cache siblings page request forwarded cache parent 
page stored cache tree request eventually reaches root forwarded home site page 
cache retains copy page obtains time 
advantage cache tree cache receives page requests children siblings ensuring requests arrive simultaneously 
requests page short period time cause request home server page won overload caches 
disadvantage theory tree pages meaning root receives request distinct page requested entire cache tree 
swamp root number distinct page requests grows large meaning scheme suffers potential scaling problems 
plaxton rajaraman show balance load caches randomization hashing 
particular hierarchy progressively larger sets virtual cache sites page random hash function assign responsibility virtual site actual cache network 
clients send request random element set hierarchy 
caches assigned set copy page members larger set discover load heavy 
gives fast responses popular pages largest set page overloaded 
gives load balancing machine small loaded set page large unloaded set 
plaxton rajaraman technique fault tolerant 
plaxton rajaraman algorithm drawbacks 
example algorithm sends copy page request random element set small sets popular page guaranteed swamped 
fact algorithm uses swamping feature swamping trigger replication 
works model synchronous parallel system swamped processor assumed receive subset incoming messages continues function normally 
internet swamping serious consequences 
swamped machines relied recover quickly may crash 
intentional swamping large numbers random machines viewed owners machines 
plaxton rajaraman algorithm requires communications synchronous messages priorities set caches available fixed known users 
contribution describe tools data replication give caching algorithm overcomes drawbacks preceding approaches additional desirable properties 
tool random cache trees combines aspects structures chankhunthod plaxton rajaraman 
chankhunthod tree caches coalesce requests 
plaxton rajaraman balance load different tree page assigning tree nodes caches random hash function 
combining best features chankhunthod plaxton rajaraman methods prevent server swamped high probability property possessed chankhunthod plaxton rajaraman 
addition protocol shows minimize memory requirements significantly increasing cache rates caching pages requested sufficient number times 
believe extra delay introduced tree caches quite small practice 
time request page multiplied tree depth 
page request typically takes little time extra delay great 
return page pipelined cache need wait receives page sending data child tree 
return page takes slightly longer 
altogether added delay seen user small 
second tool new hashing scheme call consistent hashing 
hashing scheme differs substantially plaxton rajaraman practical systems 
typical hashing schemes job spreading load known fixed collection servers 
internet fixed collection machines 
machines come go crash brought network 
worse information machines functional propagates slowly network clients may incompatible views machines available replicate data 
standard hashing useless relies clients agreeing caches responsible serving particular page 
example feeley implement distributed global shared memory system network workstations uses hash table distributed machines resolve 
time new machine joins network require central server redistribute completely updated hash table machines 
consistent hashing may help solve problems 
hashing schemes consistent hashing assigns set items buckets bin receives roughly number items 
standard hashing schemes small change bucket set induce total remapping items buckets 
addition hashing items slightly different sets buckets gives slightly different assignments items buckets 
apply consistent hashing tree caches scheme show scheme client aware constant fraction caching machines 
litwin proposes hash function allows buckets added time sequentially 
hash function allows buckets added arbitrary order 
scheme improve devine 
addition believe consistent hashing useful applications quorum systems distributed name servers multiple machines different views network agree common storage location object communication 
presentation section describe model web hot spot problem 
model necessarily simplistic rich develop analyze protocols believe may useful practice 
section describe random tree method caching protocol effectively eliminates hot spots simplified model 
independent section section consistent hashing method solve hot spots different simplified model involving inconsistent views 
section show techniques effectively combined 
section propose simple delay model captures hierarchical clustering machines internet 
show protocol easily extended realistic delay model 
sections consider faults behavior protocol time respectively 
section discuss extensions open problems 
note randomization hashing places hash functions map objects range 
clarity assume functions map objects truly random fashion uniformly independently 
practice hash functions limited independence plausible space randomness 
proven theorems limited independence methods similar 
extended state degree independence required results hold 
proofs assuming limited independence appear full version 
model section presents model web hotspot problem 
classify computers web categories 
requests web pages initiated browsers 
permanent homes web pages servers 
caches extra machines protect servers browser requests 
set caches number caches server home fixed set pages 
caches able store number pages set may change time dictated caching protocol 
generally assume content page unchanging section contains discussion issue 
set pages denoted machine send message directly restriction machine may aware existence caches require machine aware fraction caches constant typical types messages requests pages pages 
machine receives messages quickly ceases function properly said swamped 
latency measures time message machine arrive machine 
denote quantity 
practice course delays internet simply characterized 
value regarded best guess optimize lack better information correctness protocol depend values measure throughput price connection congestion exactly accurate 
note latency function message size issue discussed section 
cache server behavior browser behavior specified protocol 
particular protocol specifies caches servers respond page requests pages stored cache 
protocol specifies cache server browser sends page request 
control local behavior machine depend messages receives 
adversary decides pages requested browsers 
adversary see random values generated protocol adapt requests observed delays obtaining pages 
consider models 
consider static model single batch requests processed require number page requests constant number caches 
consider temporal model adversary may initiate new requests pages rate time interval may initiate requests 
objective hot spot problem satisfy browser page requests ensuring high probability cache server swamped 
phrase high probability means probability confidence parameter 
basic requirement prevent swamping additional objectives 
minimize cache memory requirements 
protocol requiring cache store large number pages 
second objective naturally minimize delay browser experiences obtaining page 
random trees section introduce tool random trees 
simplify presentation give simple caching protocol simpler world 
particular simplifications model 
machines know caches 

mi mj 
requests time 
restricted model static sense batch requests need consider long term stability network 
restrictions show protocol behavior 
high probability machine swamped 
achieve total delay log prove optimal 
total cache space fraction number requests evenly divided caches 
subsequent sections show extend protocol preserve behavior simplifying assumptions 
basic idea protocol extension tree caches approach discussed 
tree ensure cache children asking particular page 
discussed levels near root get requests page page relatively unpopular root pages causes swamping 
technique similar plaxton rajaraman different randomly generated tree page 
ensures machine near root pages providing load balancing 
note analysis plaxton rajaraman main concern prevent swamping allow machines swamped 
section define protocol precisely 
section analyze protocol bounding load cache storage cache uses delay browser experiences getting page 
protocol associate rooted ary tree called tree page 
term nodes nodes trees 
number nodes tree equal number caches tree balanced possible levels bottom full 
refer nodes tree rank breadth search order 
protocol described running trees support requests pages take form tuple consisting identity requester name desired page sequence nodes request directed sequence caches act nodes 
determine sequence cache node nodes mapped machines 
root tree mapped server page 
nodes mapped caches hash function distributed browsers caches 
order create copies pages requests parameter requests cache see store copy page 
hash function parameters protocol follows browser browser wants page picks random leaf root path maps nodes machines asks leaf node page 
request includes name browser name page path result mapping 
cache cache receives request checks see caching copy page process getting cache 
returns page requester gets copy necessary 
increments counter page node acting asks machine path page 
counter reaches caches copy page 
case cache passes page requester obtained 
server server receives request sends requester copy page 
analysis analysis broken parts 
showing latency processing request small assumption server swamped 
show machine swamped 
conclude showing cache need store pages protocol properly 
analysis swamping runs way weights nodes number requests arriving nodes 
number requests hit machine bounded weight nodes mapped 
latency protocol delay browser experiences obtaining page determined height tree 
request forwarded leaf root latency twice length path log request satisfied cached copy latency 
request stops cache waiting cache copy latency request started tree 
note probably large practice latency quite small 
note practice time required obtain large page multiplied number steps path travels 
reason page transmitted path pipelined fashion 
cache middle path start sending data cache soon receives need wait receive page 
means protocol increase delay getting small pages overhead large pages negligible 
existence tree schemes harvest cache suggests acceptable practice 
bound optimal constant factors protocol forbids swamping 
see consider making requests single page 
look graph nodes corresponding machines edges corresponding links page sent 
small latency implies graph small diameter implies node high degree implies swamping 
swamping intuition analysis 
analyze number requests directed tree nodes various pages 
give weights tree nodes 
analyze outcome tree nodes mapped hash function actual caching machines machine gets requests total weight nodes mapped 
bound projected weight give bound case node assigned random machine 
weighted version familiar balls bins type analysis 
analysis gives bound exponential tail 
argue applies balls assigned bins log way independently 
achieved universal hash function map tree nodes machines 
analyze protocol simplified model 
static analysis assume caches space evict pages means cache requests page request page 
theorem provide high probability bounds number requests cache gets assuming outputs function independent random 
theorem extends high probability analysis case way independent function 
particular show suffices logarithmic system parameters achieve high probability bounds full independence 
analysis random theorem chosen uniformly random space functions 
probability number requests cache gets log log log log dq log log dq log log note logd average number requests cache browser request give rise logd requests log trees 
log log term arises leaf nodes tree log page cache occur log log times balls bins adversary choose devote requests page 
prove theorem rest section 
split analysis parts 
analyze requests cache due presence leaf nodes trees analyze requests due presence internal nodes add 
requests leaf nodes due space limitations give proof applies extension small straightforward long 
observe requests page mapped randomly leaf nodes tree 
leaf nodes mapped randomly set caches 
look collection leaf nodes number requests weight associated 
variance weights leaf nodes maximized requests page 
case maximizes number leaf node requests cache 
page tree leaf nodes 
machine chance occurring particular leaf node log probability occur log log leaf nodes 
log fact requests occur log log times requested pages trees probability assignment machines leaf nodes occurs log times tree expected number requests log log gets log log log log 
assignment machine leaf nodes fixed number requests gets sum independent bernoulli variables 
cher log bounds gets log requests probability log log log log log conclude gets log log log probability replacing assuming say bound holds probability easy extend proof bound holds requests internal nodes think protocol running trees 
internal node gets dq requests child node gives requests page 
consider arbitrary arrangement paths requests respective trees 
requests bound number nodes get dq requests 
fact bound number nodes trees receive requests qj log dq 
nj denote number nodes receive requests 
rp number requests page rp requests gives rise log requests trees total number requests log log dq nj log lemma total number internal nodes receive qx requests proof sketch look tree induced request paths contract degree nodes count internal nodes 
clearly logd requests 
preceding lemma tells nj number nodes receive requests forj nj logd probability machine assumes nj nodes assignments nodes machines independent probability machine receives nodes nj small cz order right hand side log log log 
note term log 
nj probability log log log probability log dq total number requests received due internal nodes order log dq nj log log log log dq log log dq log log combining high probability bounds internal leaf nodes say machine gets log log log log dq log log dq log log log dq requests probability 
replacing log dq ignoring log log dq comparision dq get theorem 
tightness high probability bound section show high probability bound proven number requests received machine tight 
lemma exists distribution requests pages log machine gets logd log log dq log requests probability dq log log proof full 
analysis way independent extend high probability analysis functions chosen random universal hash family 
theorem chosen random universal hash family probability cache receives logd dq log log requests 
proof full proof deferred final version 
result follow immediately results involves similar argument 
setting log get corollary 
corollary high probability bound proved theorem number requests cache gets holds selected log universal hash family 
fact shown true bounds prove suffices logarithmic system size 
storage section discuss amount storage cache order protocol 
amount storage required cache simply number pages receives requests 
lemma total number cached pages machines log log probability cache log cached copies high probability 
proof sketch analysis similar proof theorem 
play protocol trees 
page cached requested times assign node weight gets requests zero 
nodes mapped randomly set caches 
bound total weight received particular cache exactly number pages caches 
consistent hashing section define new hashing technique called consistent hashing 
motivate technique simple scheme data replication internet 
consider single server large number objects clients want access 
natural introduce layer caches clients server order reduce load server 
scheme objects distributed caches responsible roughly equal share 
addition clients need know cache query specific object 
obvious approach hashing 
server hash function evenly distributes objects caches 
clients hash function discover cache stores object 
consider happens set active caching machines changes client aware different set caches 
situations plausible internet 
distribution done classical hash function example linear congruential function 
ax mod inconsistencies catastrophic 
range hash function example changed item hashed new location 
suddenly cached data useless clients looking different location 
consistent hashing solves problem different views define view set caches particular client aware 
assume views inconsistent substantial machine aware constant fraction currently operating caches 
client uses consistent hash function map object caches view 
analyze construct hash functions consistency properties 
smoothness property 
machine added removed set caches expected fraction objects moved new cache minimum needed maintain balanced load caches 
second client views total number different caches object assigned small 
call property spread 
similarly client views number distinct objects assigned particular cache small 
call property load 
consistent hashing solves problems discussed 
spread property implies presence inconsistent views world object directed small number caching machines 
distributing object small set caches insure access clients lot storage 
load property implies cache assigned unreasonable number objects 
smoothness property implies smooth changes set caching machines matched smooth evolution location cached objects 
ways formalize notion consistency described commit precise definition 
section define ranged hash function precisely define quantities capture different aspects consistency 
section construct practical hash functions exhibit extent 
section discuss aspects consistent hashing germane indicate richness underlying theory 
de nitions section formalize relate notions consistency 
set items set buckets 
jij number items 
view subset buckets ranged hash function function form 
function specifies assignment items buckets possible view 
bucket item 
notation fv place 
items assigned usable buckets require fv view ranged hash family family ranged hash functions 
random ranged hash function function drawn random particular ranged hash family 
remainder section state relate reasonable notions consistency regarding ranged hash families 
notational conventions hash function view item bucket 
balance ranged hash family balanced particular view set items randomly chosen function selected hash family high probability fraction items mapped bucket jv 
balance property standard hash functions distribute items buckets balanced 
monotonicity ranged hash function monotone views fv implies fv fv 
ranged hash family monotone ranged hash function property says items initially assigned set buckets new buckets added form item may move old bucket new bucket old bucket 
reflects intuition consistency set usable buckets changes items move necessary preserve distribution 
spread vv set views altogether containing distinct buckets individually containing buckets 
ranged hash function particular item spread quantity spread hash function maximum spread item 
spread hash family high probability spread random hash function family idea spread people see constant fraction buckets visible 
person tries assign item bucket consistent hash function 
property says entire group different opinions bucket contain item 
clearly consistent hash function low spread items 
load define set views 
ranged hash function bucket quantity load hash function maximum load bucket 
high probability randomly cho set items load hash family 
note assigned bucket view 
load property similar spread 
people back time consider particular bucket item 
property says distinct items person thinks belongs bucket 
consistent hash function low load 
main result consistent hashing theorem shows existence efficiently computable monotonic ranged hash family logarithmic spread balance 
construction give construction ranged hash family properties 
suppose random functions rb ri 
function rb maps buckets randomly unit interval ri items 
fv defined bucket minimizes ri bucket closest reasons apparent need point unit interval associated bucket 
assuming number buckets range need log points bucket constant easiest way view bucket replicated log times rb maps replicated bucket randomly 
order space represent function family random bits demand functions rb ri map points log way independently uniformly 
note point pick unit interval need pick random bits distinguish point points 
need log number points bits point 
denote described hash family theorem ranged hash family described properties 
monotone 
jvj 
balance fixed view pr fv conditioned choice rb assignments items buckets log way independent 

spread number views constant number items log probability greater 
load log probability greater proof sketch monotonicity immediate 
new bucket added items move closest new bucket associated points 
items move old buckets 
spread load properties follow observation high probability point view falls interval length 
spread follows observing number bucket points fall size interval item point upper bound spread item bucket closer view 
standard chernoff arguments apply case 
load follows similar argument count number item points fall region owned bucket associated points 
balance follows fact log points randomly mapped unit interval bucket probability responsible fraction interval 
key count number jvj distinct ways assigning large fraction log points associated bucket 
turns polynomial argue high probability possibilities occur showing additional bucket point fall 
deduce actual length smaller jvj 
proofs done log way independent mappings 
corollary immediate useful rest 
corollary conditions previous theorem log pr fv view 
jvj implementation section show hash family just implemented efficiently 
specifically expected running time single hash computation 
expectation choice hash function 
expected running time adding deleting bucket log upper bound total number buckets views 
simple implementation uses balanced binary search tree store correspondence segments unit interval buckets 
buckets log intervals search tree depth log 
single hash computation takes log time 
time addition removal bucket log delete log points bucket 
trick reduces expected running time hash computation 
idea divide interval roughly log equal length segments keep separate search tree segment 
time compute hash function time determine interval ri plus time lookup bucket corresponding search tree 
time 
expected number points segment second time expectation 
caveat number buckets grows size subintervals needs shrink 
order deal issue intervals length choose largest log 
points added bisect segments gradually reach power divided segments 
way amortize dividing search trees additions removals 
point search trees adjacent empty intervals may need updated bucket added may closest bucket 
expected length run empty intervals small additional cost negligible 
complete analysis running time refer complete version 
theorems consistent hashing section discuss additional features consistent hashing remainder demonstrate interesting properties 
give insight monotone property define new class hash functions show equivalent class monotone ranged hash functions 
hash function hash function familiar form 
constructed follows 
item associate permutation buckets bucket permutation contained view note permutations need chosen uniformly independently 
theorem monotone ranged hash function function vice versa 
hash proof sketch ranged hash function associate item permutation fb bj fb fb bj 
suppose bj element arbitrary view permutation 
fb bj 
bj monotonicity implies fv bj 
fv equivalence stated theorem allows reason monotonic ranged hash functions terms permutations associated items 
universality ranged hash family universal restricting function family single view creates universal hash family 
property way requiring ranged hash function behaved view 
condition stringent says view fixed items assigned randomly bins view 
implies view expected fraction items assigned buckets jvj 
monotonicity fact uniformity assignment determine expected number items reassigned set usable buckets changes 
relates informal notion smoothness 
theorem monotonic universal ranged hash function 
views 
expected fraction items jv fv fv jv proof sketch count number items move add buckets view delete buckets note monotonicity show upper bound number items reassigned new bucket implies obtain consistent universal hash function relaxing monotone condition 
shown monotone ranged hash function obtained associating item random permutation buckets 
natural monotone consistent hash function obtained choosing permutations independently uniformly random 
denote function theorem function monotonic universal 
item bucket hold probability log nv ti log nv 
proof monotonicity universality immediate leaves spread load 
define log nv ti log nvi ti denote list buckets vv ordered 
consider spread 
recall particular view item assigned bucket 
view contains buckets view item assigned buckets 
implies item assigned distinct buckets views 
show high probability view contains buckets 
showing complement low probability probability view contains buckets probability particular view contain bucket view contains fraction buckets 
fact bucket view reduces probability subsequent buckets view 
probability particular view contains buckets log nv nv 
union bound probability views contains buckets consider load 
similar reasoning item view assigned log nvi buckets probability 
show fixed bucket appears log nv buckets items probability 
union bound events occur high probability 
implies items assigned bucket views 
remains prove second statement 
expected number items bucket appears log nv buckets ti log nvi chernoff bounds find bucket appears log nv buckets items probability nv 
simple approach constructing consistent hash function assign random scores buckets independently item 
sorting scores defines random permutation properties proved section 
finding bucket item belongs requires computing scores 
slow large bucket sets 
random trees inconsistent world section apply techniques developed section simple hot spot protocol developed section 
relax assumption clients know caches 
assume machine knows fraction caches chosen adversary 
difference protocol mapping consistent hash function 
change affect latency 
analyze effects swamping storage 
basic properties consistent hashing crucial showing protocol works 
particular blowup number requests storage proportional maximum hash function 
swamping theorem implemented log way independent consistent hash function theorem view consists caches probability arbitrary cache gets logd log log log requests 
proof sketch look different trees caches different views page denote number caches tree 
overlay different trees get new tree node set caches 
due spread property consistent hash function log caches appear node combined tree high probability 
fact requests true nodes trees requested pages 
ep denotes event appears th node combined tree page know probability event load log high probability 
condition event log happens high probability 
cache node sends requests node combined tree sends requests 
adapt proof theorem case 
theorem machine aware caches node assigned machine probability assign node machine probability 
scenario caches node sends requests parent occurs node independently probability 
proof similar theorem 
storage techniques similar proof theorem get lemma 
proof deferred final version 
lemma total number cached pages machines log logd probability cache log cached copies high probability 
nonuniform communication costs far assumed pair machines communicate equal ease 
section extend protocol take latency machines account 
latency request sum latencies links crossed request 
simplicity assume section clients aware caches 
extend protocol restricted class functions particular assume ultrametric 
formally ultrametric metric obeys strict form triangle inequality max 
ultrametric natural model internet distances essentially captures hierarchical nature internet topology example machines university equidistant farther away university farther continent 
logical point topoint connectivity established atop physical network generally case latency sites determined highest level physical communication link traversed path 
definition ultrametric hierarchical clustering points 
distance ultrametric points completely determined smallest cluster containing points 
protocol modification protocol browser maps tree nodes caches uses caches close server desired page 
doing insure path server contain caches unnecessarily far away metric 
mapping done consistent hash function vital element solution 
clearly requiring browsers nearby caches cause swamping cache server near browsers 
order avoid cases degenerate browsers close cache clusters ultrametric caches restrict set may protocol 
restriction cluster ratio number caches number browsers may fall recall 
restriction sense real world caches evenly spread internet 
necessary prove large number browsers clustered cache forced swamp cache circumstances 
analysis clear protocol definition ultrametric latency depth tree log times latency browser server 
need look swamping storage 
intuition inside cluster bounds proved unit distance model apply 
monotone property consistent hashing allow restrict analysis log clusters 
summing clusters log blowup bound 
swamping theorem ultrametric 
suppose browser request 
protocol arbi log cache gets log logd dq log log dq log parameter 
log log log requests probability proof sketch intuition proof 
bound load machine consider ranking machines distance suppose mi asks page machine closer modified protocol involve request 
need consider machine mi asks page far away follows definition mj revised protocol mi 
intuitively original protocol spread load machines probability machine got path particular page requests logd 
ultrametric protocol mi plays protocol set machines 
path request mi probability log 
summing expected load log 
stating things slightly formally consider set log nested virtual clusters ci fm ig 
note browser ci ci machines ci protocol 
modify protocol machine uses machines ci 
reduces number machines uses 
monotonicity property consistent hash functions increases load machine consider ci separately apply static analysis 
total number requests arriving clusters modified protocol proportional number caches cluster static analysis applies cluster 
gives bound log load induced ci 
log clusters proves theorem 
storage techniques similar proof theorem get lemma 
lemma total number cached pages machines log logd log probability cache log log cached copies high probability 
fault tolerance basically plaxton rajaraman fact protocol uses random short paths server fault tolerant 
consider model adversary designates caching machines may ignore attempts communication 
remember adversary get see random bits simply designate machines top tree 
restriction specified fraction machines view 
protocol preemptive caching pages done 
server goes pages distributed inaccessible algorithm 
problem eliminated standard techniques rabin information dispersal algorithm 
ignore server faults 
observe request satisfied caches serving nodes tree path 
node mapped machine wise independently trivial standard chernoff bounds lower bound number nodes working paths root 
leads lemma lemma suppose log 
high probability fraction tree leaves working path root logd 
particular logd fraction constant 
modification protocol quite simple 
choose parameter simultaneously send requests page 
logarithmic number requests sufficient give high probability requests goes 
change protocol course impact system 
impact described full 
note communication thing internet failure get quick response machine particularly indication 
focused tolerance faults detection 
way decide machine consistent hash functions trivial reassign machines 
decide machine remove view 
adding time model far omitted real mention time analyses 
considered analyzed single batch requests argued batch causes limited amount caching storage usage machine simultaneously arguing machine gets swamped batch 
section show static analysis carries implications temporal model requests arrive time 
recall temporal model says browsers issues requests certain rate time problematic issue modeling internet communication protocols guarantees regarding time delivery 
request take arbitrarily long 
consider rate servers receive requests 
overly simplistic measure rate machine receive requests fact statistic hardware manufacturers advertise 
consider interval time apply requests come analysis requests come interval 
write bounds static analysis requests follows cache size asr bs cache load bl suppose machines cache size consider time interval small small asr bs 
words number requests arrive interval insufficient static analysis storage exceeding machine 
machine caches page interval keeps remainder interval 
static analysis apply interval 
gives bound requests arrive interval 
dividing interval length get rate caches see requests blas bs 
plugging bounds section get theorem machines log storage constant probability bound rate new requests cache machines size logd dq observe tradeoffs implicit theorem 
increasing causes load decrease proportionately log 
increasing increases load linearly reduces number hops request path 
increasing hurt suggesting take 
analysis rate requests issued measure rate connections established machines 
assume connection lasts finite duration immediately translates bound number connections open machine time 
focused particular caching problem handling read requests web 
believe ideas broader applicability 
particular consistent hashing may useful tool distributing information name servers dns label servers pics load balanced faulttolerant fashion 
schemes may provide interesting method constructing multicast trees 
important way ideas extended handling pages information changes time due server client activity 
augment protocol server know machines currently caching page server notify caches data pages changes 
particularly conjunction currently development multicast protocols broadcast information server client members multicast group protocol mapped model assume machine caching page joins multicast group page 
multicast cache keeps track page caches caches page notification changes sent tree caches copies 
remains open deal time modeling internet communication protocols guarantees regarding time delivery 
packet level guarantees regarding eventual delivery 
suggests modeling internet kind distributed system 
clearly model guarantees regarding delivery times best hope prove classical liveness safety properties underlying distributed algorithms 
clear prove caching swamping model 
think significant research done proper way model aspect internet 
believe interesting open questions remain regarding method consistent hashing 

universal consistent hash function evaluated efficiently 
tradeoffs achieved spread load 
kind perfect consistent hash functions constructed deterministically spread load bounds give 
theoretical problems consistent hashing give handle 
chankhunthod peter danzig chuck neerdaels michael schwartz kurt worrell :10.1.1.21.1584
hierarchical internet object cache 
usenix proceedings 
robert devine 
design implementation ddh distributed dynamic hashing algorithm 
proceedings th international conference foundations data organizations algorithms 
feeley morgan karlin levy thekkath 
implementing global memory management workstation cluster 
proceedings th acm symposium operating systems principles 
sally floyd van jacobson steen mccanne ching gung liu lixia zhang 
reliable multicast framework light weight sessions application level framing sigcomm witold litwin marie anne neimat donovan schneider 
lh scalable distributed data structure 
acm transactions database systems dec jacob lorch david berger 
making world wide web caching servers cooperate 
proceedings world wide web conference 
naor wool 
load capacity availability quorum systems 
proceedings th ieee symposium foundations computer science pages november 
peleg wool 
availability quorum systems 
information computation 
greg plaxton rajaraman 
fast fault tolerant concurrent access shared objects 
proceedings th ieee symposium foundations computer science 
rabin 
efficient dispersal information security load balancing fault tolerance 
journal acm 
schmidt alan siegel aravind srinivasan 
chernoff hoeffding bounds applications limited independence 
proc 
th acs siam symposium discrete algorithms 
