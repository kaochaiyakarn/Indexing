reinforcement learning vision mobile robot chris luke fletcher alexander zelinsky reinforcement learning systems improve behaviour scalar rewards critic 
vision behaviours servoing wandering learned learning method handles continuous states actions 
requirement camera calibration actuator model knowledgeable teacher 
learning observing actions behaviours improves learning speed 
experiments performed mobile robot real time vision system 
collision free wandering visual servoing building blocks purposeful robot behaviours foraging target pursuit landmark navigation 
requirement camera calibration actuator model knowledgeable teacher 
learning observing actions behaviours improves learning speed 
experiments performed mobile robot real time vision system 
collision free wandering visual servoing building blocks purposeful robot behaviours foraging target pursuit landmark navigation 
visual servoing consists moving part robot desired position visual feedback :10.1.1.54.2876
wandering environment exploration behaviour 
demonstrate real time learning wandering servoing real robot 
learning eliminates calibration process leads flexible behaviour 
reinforcement learning systems improve behaviour learning act way brings rewards 
expressed step update equation max xt ut ut expected value performing action state reward learning rate controls convergence discount factor 
discount factor rewards earned earlier valuable received 
implicitly describe controller measure state choose action highest continuous states actions learning methods best understood discrete case state actions symbolic numerical continuous 
real sensors commands motors concerned leads problems state aliasing poor scaling number states actions poor generalisation coarse control 
continuous state action learning methods briefly described earlier :10.1.1.34.9502
methods described :10.1.1.137.4324
continuous state continuous action reinforcement learning algorithm artificial neural network combined interpolator 
approach investigated simulation 
combination neural network interpolator holds values actions states 
discount factor rewards earned earlier valuable received 
implicitly describe controller measure state choose action highest continuous states actions learning methods best understood discrete case state actions symbolic numerical continuous 
real sensors commands motors concerned leads problems state aliasing poor scaling number states actions poor generalisation coarse control 
continuous state action learning methods briefly described earlier :10.1.1.34.9502
methods described :10.1.1.137.4324
continuous state continuous action reinforcement learning algorithm artificial neural network combined interpolator 
approach investigated simulation 
combination neural network interpolator holds values actions states 
input neural network state output set real valued actions values sample function 
wire fitter required stage calculation forward pass neural network 
wire fitting works dimensional scattered data remaining computationally tractable inversion matrices required 
interpolation local near wires influence value areas far wires value average wild occur 
suffer oscillations polynomial schemes 
importantly partial derivatives terms point quickly calculated :10.1.1.34.9502:10.1.1.34.9502
partial derivatives allow error output function propagated neural network chain rule 
training procedure shown 
training single hidden layer feedforward neural network done incremental backpropagation 
learning rate kept constant 
advantage learning value optimal action learning lesser value non optimal actions emphasised scaling factor 
efficient approximation resources available 
equation advantage learning update 
quantity analogous 
max ut xt ut max xt ut ut simulation experiments advantage learning improved convergence speed reliability :10.1.1.34.9502
learning wander purpose wandering behaviour explore environment colliding obstacles 
hardwired algorithm uses matrix correlations carpet template guide movement robot robot moves direction longest uninterrupted strip carpet rotates carpet detected 
conjectured successful wandering involves maximising amount carpet view maximising forward velocity 
table shows state actions reward reinforcement learning algorithm 
position metres start position metres path wandering experiment open plan office 
plant pot avoided 
total trial time minutes actions 
trial ended robot clipped view detected infra red bumper 
learned visual servoing visual servoing useful capability manipulators mobile robots :10.1.1.54.2876:10.1.1.54.2876
visual servoing requires ability track position object vision control effector feedback tracking 
area correlation tracking process locates objects successive frames gauge effect robot motion image space 
image template captured particular region image space stored buffer 
template compared video frame neighbourhood location previous frame 
template compared video frame neighbourhood location previous frame 
various methods measure degree similarity images 
difference location template current frame best match template frame forms vector indicates motion target 
track object template captured starting original location motion vectors successive frame added 
tracking failure indicated measure difference template closest match current image great :10.1.1.54.2876
basic approaches control part visual servoing position image 
generally require form calibration 
position systems error signal defined robot coordinate system 
model describing relationship visual coordinates robot coordinate system required 
chris luke fletcher alexander zelinsky 
reinforcement learning visual servoing mobile robot 
proc 
australian conference robotics automation 
chris david alexander zelinsky :10.1.1.34.9502
learning continuous state action spaces 
proc 
th australian joint conference artificial intelligence sydney australia december 
lecture notes computer science springer verlag 
hosoda asada 
versatile visual servoing knowledge true jacobian 
proc 
ieee rsj international conference intelligent robots systems iros 
hutchinson hager :10.1.1.54.2876
tutorial visual servo control 
ieee transactions robotics automation october 
jordan jacobs 
learning control unstable system forward modeling 
