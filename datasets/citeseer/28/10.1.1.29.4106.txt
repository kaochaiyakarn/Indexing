hierarchical control learning markov decision processes ronald edward parr 
princeton university dissertation submitted partial satisfaction requirements degree doctor philosophy computer science graduate division university california berkeley committee charge professor stuart russell chair professor malik professor thomas dissertation ronald edward parr approved chair date date date university california berkeley hierarchical control learning markov decision processes ronald edward parr doctor philosophy computer science university california berkeley professor stuart russell chair dissertation investigates hierarchy problem decomposition means solving large stochastic sequential decision problems 
problems framed markov decision problems mdps 
new technical content dissertation begins discussion concept temporal abstraction 
temporal abstraction shown equivalent transformation policy defined region mdp action semi markov decision problem smdp 
algorithms performing transformation efficiently 
model stochastic implementation exponentially decaying average implicit fi models 
note similarity interpretation full fi models unreliable robot actuation earlier chapter 
cases infinite summation time turns equivalent smdp model extra uncontrolled states 
interpretation fi models easier amenable algorithms chapter 
macros options precup sutton singh precup sutton sutton precup singh considered general case agent may choice executing temporally extended policies form described :10.1.1.37.2027
policies actions called macros precup sutton spirit macro operators classical planning sutton options :10.1.1.37.2027
options essentially formal version 
lin robot subtasks reinforcement learning lin 
lin specified fixed points subtasks terminated options exponentially decaying stopping conditions specified full fi models 
note similarity interpretation full fi models unreliable robot actuation earlier chapter 
cases infinite summation time turns equivalent smdp model extra uncontrolled states 
interpretation fi models easier amenable algorithms chapter 
macros options precup sutton singh precup sutton sutton precup singh considered general case agent may choice executing temporally extended policies form described :10.1.1.37.2027
policies actions called macros precup sutton spirit macro operators classical planning sutton options :10.1.1.37.2027
options essentially formal version 
lin robot subtasks reinforcement learning lin 
lin specified fixed points subtasks terminated options exponentially decaying stopping conditions specified full fi models 
effect 
strategies just car parking lot building 
new situation encountered generic strategy modified small fraction effort required achieve new task prior knowledge 
description language actions kind generic structure 
artificial intelligence methods temporal abstraction incorporate prior knowledge 
example lin robot subtasks lin avenues explored singh macros options precup sutton sutton construct actions making guess particular subset states constitute achievement subtask way relevant task :10.1.1.37.2027
approaches action constructed guessing value subtask states solving mdp subtask states absorbing values fixed guessed value see chapter 
approach require lot domain specific knowledge subtasks subtask values 
ham approach takes different strategy producing complex behavior 
approach rooted observation engineers control theorists generally quite designing controllers realize specific low level behaviors 
example machine call machine move immediately state return control proceed infinite loop 
straightforward particularly interesting generalize results developed machines top level states infinite non action loops 
mentioned hams encode types actions described chapter 
encode null action contains choices original mdp loop containing single choice state chooses possible action opportunity 
hams designed permit concurrent actions low level actions macros precup sutton options sutton choice states select actions call states execute temporally actions :10.1.1.37.2027
formal properties hams section presents formal optimality convergence properties ham language applied mdp 
theorem mdp ham exists smdp called ffi solution defines optimal choice function choose maximizes expected discounted sum rewards received agent executing proof proof proceeds constructing smdp follows refer closure states reachable initial machine state space smdp pairs theta state written state mdp machine state 
new transition function constructed transition function transition functions cases transitions 
action state possible action ffi 
