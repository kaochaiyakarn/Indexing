ieee transactions neural networks new evolutionary system evolving artificial neural networks xin yao ieee yong liu presents new evolutionary system epnet evolving artificial neural networks anns 
evolutionary algorithm epnet fogel evolutionary programming ep 
previous studies evolving anns puts emphasis evolving ann behaviours 
primary reasons ep adopted 
mutation operators proposed epnet reflect emphasis evolving behaviours 
close behavioural links parents offspring maintained various mutations partial training node splitting 
attempts designing ann architectures especially connectivity automatically supported australian research council small scheme 
authors computational intelligence group school computer science university college university new south wales australian defence force academy canberra act australia email cs oz au url www cs oz au xin phone fax weights indicate connection weights biases 
concerned connectivity architecture connectivity interchangeably 
evolving connectivity node transfer functions reported 
various constructive pruning algorithms :10.1.1.125.6421
roughly speaking constructive algorithm starts minimal network network minimal number hidden layers nodes connections adds new layers nodes connections necessary training pruning algorithm opposite deletes unnecessary layers nodes connections training 
indicated angeline structural hill climbing methods susceptible trapped structural local optima 
addition investigate restricted topological subsets complete class network architectures 
design near optimal ann architecture formulated search problem architecture space point represents architecture 
evolving artificial neural network architectures major approaches evolving ann architectures 
evolution pure architectures architectures weights 
connection weights trained near optimal architecture 
simultaneous evolution architectures weights 
schaffer yao provided comprehensive review various aspects evolutionary artificial neural networks eanns :10.1.1.13.957:10.1.1.13.957:10.1.1.13.957
evolution pure architectures major issue evolving pure architectures decide information architecture encoded chromosome genotype 
extreme detail connection node architecture specified genotype binary bits 
kind representation schemes called direct encoding scheme strong specification scheme 
extreme important parameters architecture number hidden layers hidden nodes layer encoded 
kind representation schemes called direct encoding scheme strong specification scheme 
extreme important parameters architecture number hidden layers hidden nodes layer encoded 
detail architecture pre defined left training process decide 
kind representation schemes called indirect encoding scheme weak specification scheme 
shows evolution pure architectures direct indirect encoding scheme :10.1.1.13.957:10.1.1.13.957

decode individual chromosome current generation architecture 
indirect encoding scheme detail architecture specified developmental rules training process 


typical cycle evolution architectures weights 
word genetic loose interpreted strict biological sense 
genetic operators just search operators 
evolution ann architectures general suffers permutation problem called competing conventions problem :10.1.1.31.6731
caused mapping genotypes phenotypes anns order hidden nodes differently may different genotypes equivalent 
problem evolution inefficient crossover operators difficult produce highly fit offspring 
unclear building blocks situation 
example anns shown equivalent different representations shown direct encoding scheme 
bit disables connections node connectivity matrix 
connection deletion addition involve flipping bit connectivity matrix 
bit automatically disables corresponding weight entry weight matrix 
weights updated hybrid algorithm described 
fitness evaluation selection mechanism fitness individual epnet solely determined inverse error value defined eq validation set containing patterns delta max gamma delta gamma maximum minimum values output coefficients problem representation number output nodes actual desired outputs node pattern eq suggested error measure dependent size validation set number output nodes :10.1.1.115.5355:10.1.1.115.5355
mean squared error percentage adopted 
max maximum minimum values outputs :10.1.1.115.5355
fitness evaluation epnet different previous eanns determined validation set overlap training set 
validation set evolutionary learning system improves generalisation ability evolved anns introduces little overhead computation time 
bit automatically disables corresponding weight entry weight matrix 
weights updated hybrid algorithm described 
fitness evaluation selection mechanism fitness individual epnet solely determined inverse error value defined eq validation set containing patterns delta max gamma delta gamma maximum minimum values output coefficients problem representation number output nodes actual desired outputs node pattern eq suggested error measure dependent size validation set number output nodes :10.1.1.115.5355:10.1.1.115.5355
mean squared error percentage adopted 
max maximum minimum values outputs :10.1.1.115.5355
fitness evaluation epnet different previous eanns determined validation set overlap training set 
validation set evolutionary learning system improves generalisation ability evolved anns introduces little overhead computation time 
selection mechanism epnet rank 
sorted individuals numbered gamma th fittest 
population size epochs mbp partial training initial number hidden nodes mutated hidden nodes initial connection density mutated connections initial learning rate temperatures sa range learning rate iterations temperature validation sets 
parameters experiments table runs conducted value parity problem 
results summarised table ii number epochs indicates total number epochs taken epnet best network obtained 
results obtained epnet quite competitive comparison obtained algorithms 
table iii compares epnet best results algorithm cca perceptron cascade algorithm pca tower algorithm ta :10.1.1.125.6421
algorithms produce networks short cut connections 
observations table 
epnet evolve compact networks 
fact generated smallest ann algorithms compared 
best network evolved epnet parity problem 
table iv connection weights biases represented network 
gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma domain breast cancer problem diabetes problem heart disease problem thyroid problem 
date sets obtained uci machine learning benchmark repository 
medical diagnosis problems common characteristics ffl input attributes similar human expert order solve problem :10.1.1.115.5355
ffl outputs represent classification number understandable classes prediction set understandable quantities 
ffl practice problems solved human experts 
ieee transactions neural networks table ii summary results produced epnet parity problem 
results averaged runs 
percent patients classifier significantly better 
experimental setup data sets epnet partitioned sets training set validation set testing set 
training set train anns mbp validation set evaluate fitness anns 
best ann evolved epnet trained combined training validation set applied testing set 
indicated insufficient indicate number examples set partition experimental results may vary significantly different partitions numbers set :10.1.1.115.5355:10.1.1.115.5355
imprecise specification partition known data set sets frequent obstacles reproduce compare published neural network learning results 
experiments data set partitioned follows ffl breast cancer data set examples training set examples validation set final examples testing set 
ffl diabetes data set examples training set examples validation set final examples testing set 
ffl heart disease data set examples training set examples validation set final examples testing set 
best latest results available literature regardless algorithm evolutionary bp statistical comparison 
possible papers compared overlooked 
aim compare epnet exhaustively algorithms 
breast cancer problem setiono hui published new ann constructive algorithm called 
reported results manually constructed anns :10.1.1.115.5355:10.1.1.115.5355
tested number different ann architectures breast cancer problem 
best results produced hand designed anns denoted compared average results produced epnet table viii :10.1.1.115.5355
epnet evolve compact anns generalise come cost additional computation time order perform search 
total time epnet estimated adding initial training time theta epochs evolving time approximately epochs generation maximally generations final training time epochs 
aim compare epnet exhaustively algorithms 
breast cancer problem setiono hui published new ann constructive algorithm called 
reported results manually constructed anns :10.1.1.115.5355:10.1.1.115.5355
tested number different ann architectures breast cancer problem 
best results produced hand designed anns denoted compared average results produced epnet table viii :10.1.1.115.5355
epnet evolve compact anns generalise come cost additional computation time order perform search 
total time epnet estimated adding initial training time theta epochs evolving time approximately epochs generation maximally generations final training time epochs 
require roughly epochs single run 
actual time runs reached maximal number generations 
actual time runs reached maximal number generations 
similar estimations applied problems tested 
applications training time im ieee transactions neural networks table vi architectures evolved artificial neural networks 
number number number connections hidden nodes generations breast mean cancer sd data min set max diabetes mean data sd set min max heart mean disease sd data min set max thyroid mean data sd set min max table vii accuracies evolved artificial neural networks 
training set validation set test set error error rate error error rate error error rate breast mean cancer sd data min set max diabetes mean data sd set min max heart mean disease sd data min set max thyroid mean data sd set min max table viii comparison hand designed ann epnet breast cancer problem :10.1.1.115.5355
anns designed manually connections evolved epnet number hidden nodes epnet generate sparsely connected anns 
average results epnet shown 
epnet best results clearly superior indicated table vii 
best results best results average results runs trial error epnet runs hidden nodes testing error rate minimum error rate achieved number hidden nodes 
unreasonable algorithm relies training data improve generalisation 
table ix compares epnet result produced number algorithms 
worth pointing results obtained fold cross validation 
represented best algorithms tested 
terms best results produced tried different anns manually problem hidden node ann achieved testing error rate epnet achieved testing error rate :10.1.1.115.5355:10.1.1.115.5355
largest ann evolved epnet runs hidden nodes 
average 
heart disease problem table shows results epnet neural non neural algorithms 
gm algorithm construct rbf networks 
heart disease problem table shows results epnet neural non neural algorithms 
gm algorithm construct rbf networks 
produced rbf network gaussians testing error 
mangasarian reported testing error rate method method bp worse worst ann evolved epnet 
best manually designed ann achieved testing error worse best result epnet :10.1.1.115.5355
thyroid problem tried problem network 
learning passes necessary achieve testing error rate network 
genetic algorithm train multilayer anns reduced training data set containing examples 
obtained network hidden nodes connections testing error rate 
learning passes necessary achieve testing error rate network 
genetic algorithm train multilayer anns reduced training data set containing examples 
obtained network hidden nodes connections testing error rate 
results worse generated worst ann evolved epnet 
best manually designed ann testing error rate better epnet best result :10.1.1.115.5355
case best manually designed ann outperforms epnet best :10.1.1.115.5355
table xi summarises results 
australian credit card assessment problem things overlooked evolutionary algorithms information contained final population evolution 
people just best individual population thinking exploring possible useful information rest population 
genetic algorithm train multilayer anns reduced training data set containing examples 
obtained network hidden nodes connections testing error rate 
results worse generated worst ann evolved epnet 
best manually designed ann testing error rate better epnet best result :10.1.1.115.5355
case best manually designed ann outperforms epnet best :10.1.1.115.5355
table xi summarises results 
australian credit card assessment problem things overlooked evolutionary algorithms information contained final population evolution 
people just best individual population thinking exploring possible useful information rest population 
epnet simulated evolution driven ep algorithm recombination operator 
may training validation set may 
order avoid overfitting achieve better generalisation second validation set proposed training step epnet 
experiment original validation set divided equal subsets set fitness evaluation second set step epnet 
step ieee transactions neural networks table ix comparison epnet terms average testing error rate diabetes problem 
algorithm epnet smart rbf testing error rate algorithm bp cal cart castle testing error rate table comparison hand designed ann epnet heart disease problem :10.1.1.115.5355
smallest error rate achieved epnet 
table means available 
results best results average results trial error epnet runs hidden nodes testing error rate table xi comparison best results hand designed ann epnet thyroid problem :10.1.1.115.5355
smallest error rate achieved epnet 
step ieee transactions neural networks table ix comparison epnet terms average testing error rate diabetes problem 
algorithm epnet smart rbf testing error rate algorithm bp cal cart castle testing error rate table comparison hand designed ann epnet heart disease problem :10.1.1.115.5355
smallest error rate achieved epnet 
table means available 
results best results average results trial error epnet runs hidden nodes testing error rate table xi comparison best results hand designed ann epnet thyroid problem :10.1.1.115.5355
smallest error rate achieved epnet 
results best results average results trial error epnet runs hidden nodes testing error rate final population trained mbp combined training set set 
produced minimum error rate set chosen final output epnet tested testing set 
ties broken favour network minimum number connections 
liu yao evolutionary design artificial neural networks different nodes proc 
ieee int conf 
evolutionary computation nagoya japan pp 
ieee press new york ny 
fahlman lebiere learning architecture advances neural information processing systems touretzky ed pp :10.1.1.125.6421
morgan kaufmann san mateo ca 

nadal study growth algorithm feedforward network international journal neural systems vol 
pp 
ieee computer society press los alamitos ca 
yao evolution connectionist networks preprints int symp 
ai reasoning creativity ed queensland australia pp 
griffith university 
yao review evolutionary artificial neural networks international journal intelligent systems vol :10.1.1.13.957
pp 

yao evolutionary artificial neural networks international journal neural systems vol :10.1.1.13.957
pp 
griffith university 
yao review evolutionary artificial neural networks international journal intelligent systems vol :10.1.1.13.957
pp 

yao evolutionary artificial neural networks international journal neural systems vol :10.1.1.13.957
pp 

yao evolutionary artificial neural networks encyclopedia computer science technology kent williams eds vol :10.1.1.13.957
pp 

yao evolutionary artificial neural networks international journal neural systems vol :10.1.1.13.957
pp 

yao evolutionary artificial neural networks encyclopedia computer science technology kent williams eds vol :10.1.1.13.957
pp 
new york ny marcel dekker 
whitley genetic algorithms neural networks optimizing connections connectivity parallel computing vol 
pp 
maniezzo genetic evolution topology weight distribution neural networks ieee trans 
neural networks vol 
pp 

belew mcinerney schraudolph evolving networks genetic algorithm connectionist learning tech :10.1.1.31.6731
rep cs revised computer science 
dept 
univ california san diego la jolla ca usa february 
hancock genetic algorithms permutation problems comparison recombination operators neural net structure specification proc 
pp 

werbos roots backpropagation ordered derivatives neural networks political forecasting 
new york ny john wiley sons 
proben set neural network benchmark problems benchmarking rules tech :10.1.1.115.5355
rep fur informatik universit karlsruhe karlsruhe germany september 
yao empirical study genetic operators genetic algorithms vol 
pp 

