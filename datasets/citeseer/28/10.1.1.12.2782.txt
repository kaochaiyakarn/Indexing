ieee transactions systems man cybernetics making population information evolutionary artificial neural networks xin yao yong liu concerned simultaneous evolution artificial neural network ann architectures weights 
current practice evolving anns choose best ann generation final result 
proposes different approach form final result combining individuals generation order best information contained population 
approach regards population anns ensemble uses combination method integrate 
integrating ann modules little done evolutionary learning best population information :10.1.1.34.3566
linear combination methods investigated illustrate ideas 
keywords evolutionary programming evolutionary artificial neural networks module combination learning behavioural evolution 
evolutionary anns eanns refer special class anns evolution fundamental form adaptation addition learning 
evolution introduced various levels anns 
evolve weights architectures learning parameters rules 
eanns studied widely years :10.1.1.13.957:10.1.1.13.957
provide automatic method design anns approach study evolution learning framework :10.1.1.13.957:10.1.1.13.957
mainly concerned evolution ann architectures weights including biases evolutionary algorithm evolve ann architectures weights 
studies evolve anns effectively efficiently issue generate final result evolutionary process overlooked :10.1.1.13.957:10.1.1.13.957
final result best individual generation generations 
evolutionary anns eanns refer special class anns evolution fundamental form adaptation addition learning 
evolution introduced various levels anns 
evolve weights architectures learning parameters rules 
eanns studied widely years :10.1.1.13.957:10.1.1.13.957
provide automatic method design anns approach study evolution learning framework :10.1.1.13.957:10.1.1.13.957
mainly concerned evolution ann architectures weights including biases evolutionary algorithm evolve ann architectures weights 
studies evolve anns effectively efficiently issue generate final result evolutionary process overlooked :10.1.1.13.957:10.1.1.13.957
final result best individual generation generations 
attempts partially supported australian research council small scheme 
evolve weights architectures learning parameters rules 
eanns studied widely years :10.1.1.13.957:10.1.1.13.957
provide automatic method design anns approach study evolution learning framework :10.1.1.13.957:10.1.1.13.957
mainly concerned evolution ann architectures weights including biases evolutionary algorithm evolve ann architectures weights 
studies evolve anns effectively efficiently issue generate final result evolutionary process overlooked :10.1.1.13.957:10.1.1.13.957
final result best individual generation generations 
attempts partially supported australian research council small scheme 
part results ieee international conference evolutionary computation nagoya japan may 
authors computational intelligence group school computer science university college university new south wales australian defence force academy canberra act australia 
argue difference learning optimisation exploited evolutionary computation learning optimisation population 
shows population contains information single individual population 
information improve generalisation learned systems 
proposes linearly combine different individuals generation form final integrated system 
idea combining different modules studied ann field statistics attempts evolutionary learning population information forming final system :10.1.1.34.3566
carried experimental studies real world problems demonstrate effectiveness proposed approach 
epnet automatic ann design tool evolutionary programming algorithm evolve population anns :10.1.1.12.3134
performance best individual evolved compared integrated system linearly combined individuals generation 
integrated system linear combination weights rls algorithm pp outperformed best individual terms generalisation problems tested 
information improve generalisation learned systems 
proposes linearly combine different individuals generation form final integrated system 
idea combining different modules studied ann field statistics attempts evolutionary learning population information forming final system :10.1.1.34.3566
carried experimental studies real world problems demonstrate effectiveness proposed approach 
epnet automatic ann design tool evolutionary programming algorithm evolve population anns :10.1.1.12.3134
performance best individual evolved compared integrated system linearly combined individuals generation 
integrated system linear combination weights rls algorithm pp outperformed best individual terms generalisation problems tested 
reason consider linear combination simplicity 
purpose find best combination method show importance population information advantage combining eanns 
population contains information single individual 
combining different individuals generation form integrated system expected produce better results 
confirms true conducting set computational studies 
iii 
evolutionary design system anns epnet epnet automatic system evolutionary programming ep designing feed forward anns :10.1.1.12.3134
main structure system described 
hybrid training addition connection node deletion hidden node deletion random initialisation anns initial partial training rank selection obtain new generation 
successful 
successful 
successful 
mutations training fig 

main structure epnet 
epnet recombination operators simulated evolution order avoid permutation competing conventions problem :10.1.1.31.6731
relies novel mutations rank selection scheme 
epnet evolves architectures connection weights anns simultaneously order reduce noise fitness evaluation :10.1.1.12.3134
previous studies eanns evolution ann architectures separated evolution connection weights training approach introduced noises fitness evaluation aim evaluate ann architecture weights ann trained weights eventually evaluated :10.1.1.13.957
fitness architecture affected random initial weights training training algorithm 

main structure epnet 
epnet recombination operators simulated evolution order avoid permutation competing conventions problem :10.1.1.31.6731
relies novel mutations rank selection scheme 
epnet evolves architectures connection weights anns simultaneously order reduce noise fitness evaluation :10.1.1.12.3134
previous studies eanns evolution ann architectures separated evolution connection weights training approach introduced noises fitness evaluation aim evaluate ann architecture weights ann trained weights eventually evaluated :10.1.1.13.957
fitness architecture affected random initial weights training training algorithm 
essence noise caused mapping genotype phenotype 
common method reduce noise evaluate phenotypes mean fitness genotype fitness 
main structure epnet 
epnet recombination operators simulated evolution order avoid permutation competing conventions problem :10.1.1.31.6731
relies novel mutations rank selection scheme 
epnet evolves architectures connection weights anns simultaneously order reduce noise fitness evaluation :10.1.1.12.3134
previous studies eanns evolution ann architectures separated evolution connection weights training approach introduced noises fitness evaluation aim evaluate ann architecture weights ann trained weights eventually evaluated :10.1.1.13.957
fitness architecture affected random initial weights training training algorithm 
essence noise caused mapping genotype phenotype 
common method reduce noise evaluate phenotypes mean fitness genotype fitness 
method computationally expensive eanns 
search point view training plays role local search ep conducts global search 
fitness evaluation local optimum individual find training starting state individual quite poor due architectural mutation 
node deletion epnet done totally random node selected uniformly random deletion 
architectural mutations uniformly random 
connection deletion addition non uniform probability distribution decide connection delete add importance connection :10.1.1.12.3134
node addition achieved splitting existing node introducing random 
nodes obtained splitting existing node connections existing node 
weights new nodes values ij ij ij ki ff ki ki ki weight vector existing node weight vectors new nodes ff mutation parameter may take fixed random value indicate nodes connection node method helps greatly maintaining behavioural link parent offspring 
reduces caused random node 
order attempting mutations hybrid training node deletion connection deletion connection addition node addition 
deletions attempted additions 
particular deletion successful new offspring better worst individual current population additions applied 
ordering implies small network preferred job 
experimental studies benchmark problems shown effectiveness method :10.1.1.12.3134
validation sets epnet improve generalisation evolved anns 
epnet trains individual training set evaluates validation set 
fitness values calculated validation training set 
simulated evolution individuals generation trained modified bp combined training validation set 
tie exists individual minimum error combined training set set final result 
final individual tested unseen testing set 
experiments data set randomly partitioned subsets training set set set testing set 
size training set set testing set examples respectively 
partition follows previous suggestions benchmarking :10.1.1.115.5355
input attributes eanns rescaled linear function 
output attributes problems encoded output representation classes 
winner takes method eanns output highest activation designates class 
parameters experiments set problems population size generations initial number hidden nodes means number hidden nodes initial individual generated random initial connection density means probability having connection nodes 
parameters selected modest search 
epnet sensitive parameters 
experimental results tables ii show experimental results problems runs 
error rate table refers percentage wrong classifications produced eanns 
comparison error rates obtained methods epnet results quite competitive :10.1.1.115.5355
size eanns measured number hidden nodes connections small 
useful ann execution phase hardware implementation 
table iii compares epnet results produced hand designed bp network best table terms average testing error rates network sizes :10.1.1.115.5355
table size eanns problems 
error rate table refers percentage wrong classifications produced eanns 
comparison error rates obtained methods epnet results quite competitive :10.1.1.115.5355
size eanns measured number hidden nodes connections small 
useful ann execution phase hardware implementation 
table iii compares epnet results produced hand designed bp network best table terms average testing error rates network sizes :10.1.1.115.5355
table size eanns problems 
results averaged runs 
mean sd min max indicate mean value standard deviation minimum maximum value respectively 
card diabetes heart mean number sd connections min max mean number sd hidden nodes min max table ii accuracies eanns problems 
best result runs chosen output rls algorithm 
results ensemble formed rls algorithm table viii 
clear ensemble performed better best individual problems 
results indicate better combination method produce better ensembles 
fact rls algorithm recommended algorithms performing linear combinations :10.1.1.34.3566
algorithms 
table ix shows results test comparing best individual ensemble formed rls algorithm 
ensemble better best individual level significance australian credit card diabetes problems better level significance heart disease problem 
ieee transactions systems man cybernetics table viii accuracies ensemble formed rls algorithm 
evolutionary computation nagoya japan pp 
ieee press new york ny 
optimal linear combinations neural networks 
phd thesis school industrial engineering purdue university december 
perrone improving regression estimation averaging methods variance reduction extensions general convex measure optimization :10.1.1.34.3566
phd thesis department physics brown university may 
yao evolutionary artificial neural networks international journal neural systems vol :10.1.1.13.957
pp 

optimal linear combinations neural networks 
phd thesis school industrial engineering purdue university december 
perrone improving regression estimation averaging methods variance reduction extensions general convex measure optimization :10.1.1.34.3566
phd thesis department physics brown university may 
yao evolutionary artificial neural networks international journal neural systems vol :10.1.1.13.957
pp 

yao evolutionary artificial neural networks encyclopedia computer science technology kent williams eds vol :10.1.1.13.957
pp 
phd thesis department physics brown university may 
yao evolutionary artificial neural networks international journal neural systems vol :10.1.1.13.957
pp 

yao evolutionary artificial neural networks encyclopedia computer science technology kent williams eds vol :10.1.1.13.957
pp 
new york ny marcel dekker 
schaffer whitley eshelman combinations genetic algorithms neural networks survey state art proc 
int workshop combinations genetic algorithms neural networks whitley schaffer eds pp 
new york ny marcel dekker 
schaffer whitley eshelman combinations genetic algorithms neural networks survey state art proc 
int workshop combinations genetic algorithms neural networks whitley schaffer eds pp 
ieee computer society press los alamitos ca 
yao liu new evolutionary system evolving artificial neural networks ieee transactions neural networks :10.1.1.12.3134
accepted 
yao liu designing artificial neural networks evolution applied mathematics computation 
accepted 
liu yao population learning algorithm learns architectures weights neural networks chinese journal advanced software research press new york ny vol 
fogel owens walsh artificial intelligence simulated evolution 
new york ny john wiley sons 
fogel evolutionary computation new philosophy machine intelligence 
new york ny ieee press 
belew mcinerney schraudolph evolving networks genetic algorithm connectionist learning tech :10.1.1.31.6731
rep cs revised computer science 
dept 
univ california san diego la jolla ca usa february 
hancock genetic algorithms permutation problems comparison recombination operators neural net structure specification proc 

zhang muhlenbein evolving optimal neural networks genetic algorithms occam razor complex systems vol 
pp 

proben set neural network benchmark problems benchmarking rules tech :10.1.1.115.5355
rep fur informatik universit karlsruhe karlsruhe germany september 
michie spiegelhalter taylor machine learning neural statistical classification 
london ellis horwood limited 
roy algorithm generate radial basis function rbf nets classification problems neural networks vol 
