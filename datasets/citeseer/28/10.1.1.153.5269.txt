class phrase models language modeling klaus ries finn dag bu alex waibel ries cs cmu edu ira uka de cs cmu edu interactive system labs carnegie mellon university usa university karlsruhe germany previous attempts automatically determine multi words basic unit language modeling successful extending bigram models improve perplexity model word accuracy speech decoder 
ofthese techniques gave improvements trigram model far controlled atis task 
propose algorithm minimizes perplexity improvement ofa bigram model directly 
new algorithm able reduce trigram perplexity andalso achieves word accuracy improvements verbmobil task 
natural counterpart successful word classi cation algorithms language modeling minimize leaving bigram perplexity 
give details usage class nding techniques gram models crucial successful applications technique 

selection basic unit language modeling necessarily naturally 
languages german focus investigation word level useful abstraction 
asian languages chinese korean japanese basic basic unit usually chosen level 
selection basic units advantage bias simple segmentation criteria relaxed important longer units modeled explicitly 
select basic unit successive joins basic units english resp 
german words 
applications xed context language model enhanced dynamically depending units xed expressions pronunciations di erent individual words going know output decoder contains linguistic information word string rst item help bigram models past lot researchers reported improvements arena 
second application realized introducing specialized pronunciation variants basic units going merely concatenating pronunciations going 
achieved manual dictionary modi cation dictionary learning clustering 
third application speculative mutual information nd linguistically motivated segments calls grammar inference methods nd simple syntactical nite 
successive joins basic units produces possibly large number types basic units data sparseness problem serious 
approach problem classes words word classes basic units join 
approach want follow nd little evidence searching phrases words improved searching phrases word classes purpose language modeling speech recognition 

bigram leaving perplexity criterion objective nding procedure pair basic units cooccur frequently joining occurrences corpus useful operation 
pair selected replace occurrences pair anew phrase symbol 
past implementations idea measures cooccurrence useful domains pair chosen maximization criterion 
known measures mutual information mi frequency iterative marking frequency backward bigram bb jw backward perplexity bp log jw measure see contrast criteria try maximize desired criterion directly perplexity 
maximum likelihood estimate bigram probability set ny wi wi ml wi logarithm rearranging term get fml log log probabilities determined separate cross validation set minimize leaving oneout bigram perplexity ofthe resulting model lines flo log log log absolute discounting factor isthe bigram table number bigrams occuring exactly number bigrams occuring atleast number bigrams occuring inthe corpus 
flo calculated original corpus corpus selected pair ha bi joined 
general interested change flo joining ha bi relative tothe old corpus call quantity ha 
flo stated valid measure wrong corpora require smoothing 
practical purposes interested ha term drops course attempt minimize corresponding gram perplexity reasons computational tractability bigram case 
case criterion similar multigram model usingthe viterbi assumption model evaluation done usingthe convenient leaving criterion 
bigram leaving perplexity criterion pp re ect information obtained context phrase 
traditional criteria grammar inference evaluate just gain rule constituents join pp applies simple ective statistical model measure local ects neighboring words 
noting ha allows reject word pairs considered candidates possible join maximize di erent measure say resulting measure called hybrid 
assumption simply go bi trigram table calculate ha ha bi 
similar technique applied implementations elaborated 
furthermore trigram table calculated incrementally pair ha bi joined trigram table trigrams contain ha bi 
small sacri ce procedure bigram prediction ha bi ha bi ha 
show principle ignore tedious cases ignore log term 
initialize ha log trigram corpus add hw similarly hw terms 
new model bigram hw log 
new model bigram log 
old model bigram log leaving criterion dictate phrase nding procedure described 
corpora worked technique su ciently fast 
procedure possible applications large corpora wall street journal try scan corpus phrase 
spirit iterative marking frequency framework scans corpus frequently look 
find large ranked list candidate phrases ha criterion 

calculate bigram table corpus list join basic units 

calculate flo splits phrases 

exclude phrases improve perplexity calculate ranked list phrases flo 
goto 
list calculated step join list phrases corpus 
add list phrases 
corpus current corpus goto 
crucial point flo step 
flo possible ways splitting phrase convenient restrict pairs word 
calculation done just examining bigram table fashion similar shown 
perplexity switchboard pp bp hybrid bp hybrid mi hybrid bb class pp perplexity verbmobil hybrid bp pp class hybrid bp class pp sequences sequences perplexity results switchboard verbmobil graphs show results di erent phrase nding criteria word class phrases switchboard verbmobil corpora 
newly proposed pp compares favorable 
small verbmobil corpus class phrases show smoother plot word phrases 

data driven word classi cation words classi ed unsupervised word classi ation tothe bigram perplexity criterion 
authors xed number classes criterion decide classes choose 
current formulation model prior uniform distribution 
added gaussian prior number classes cases optimal number classes trigram model higher uniform prior 
added phase allows clusters 

gram training decoding phrase model decoder include phrases words hw wli class class phrases hc cli class phrase model decoder dictionary language model vocabulary 
word phrases hw wli belong cli belong denoted label hc cli 
class phrase trigram model join word phrases joined class phrases 
simply train trigram model corpus classes original classes just classes phrases classes words phrases 
calculation class trigram model calculate wjc 
classes phrases quantity estimated data directly calculated hw cli jc 
linear interpolation scheme combine di erent models 

experiments experiments switchboard verbmobil corpus 
switchboard corpus collection english spontaneous dialogs unknown parties telephone topic selection topics 
training corpus roughly words long 
verbmobil corpus training contains words collection spontaneous german appointment negotiations 
naturally expect corpus verbmobil corpus pro class methods 
expectation restricted domain verbmobil pro phrase models restricted 
mi bb bp hybrid variants pp delivered competitive performance 
train trigram model improved backo model 
gure perplexity results switchboard corpus shown 
see perplexity criterion performs best criteria observe usingthe hybrid model considerably restricts problems original criterion 
class pp model shows classes change shape curve advantages class model 
shown gure interpolation experiment class class phrase model interpolated corresponding class phrase trigram model classes 
interpolating class model phrases perplexities resp 
yields model 
perplexity phrase model reduced interpolating model classes 
achieved roughly performance model word phrases class trigram model class word phrase model 
verbmobil corpus signi cant improvement interpolating class non class models 
class model far better standard model favorable conjunction phrase model 
qualitative result pp criterion superior models terms perplexity 
gure rst word phrases inthe verbmobil corpus seen 
verbmobil able improve word accuracy decoder standard trigram model achieves phrase model classes achieves class trigram model phrases achieves 
class word phrase trigram model achieve accuracy 
able produce word accuracy results class phrase model verbmobil corpus 
variation tested accurate set word classes 
automatically derived classes encoded days week months ordinal numbers morning afternoon variations noise words 
class phrases containing non single word classes types monday 
type phrases inthe word phrases 
ich bin ich name ist urd ich mit bis zum bei der wir uns wir das das ich kann ich sie wir hier ist lassen sie wir eden wir att ich habe ich ar da bei mir aus bis wir ich wir atten sie tre en wir uns tre en uns wir bis sie mir es ich sie ein un ur mich ich ich mu ich ur ein word phrases verbmobil rst phrases inthe verbmobil corpus tothe pp criterion shown 
vocabulary verbmobil corpus contains phrases uhr termin clock appointment lot 

research shown leaving bigram perplexity criterion ective perplexity criteria proposed far wehave shown ective procedure calculate 
turn improvements perplexity word accuracy verbmobil corpus 
combination class phrase models proven combine 
little evidence searching class phrases word phrases helpful terms perplexity haven able achieve word accuracy results model 
seen class phrases just smoothing technique nd important word phrases nd di erent phrases 
similar experiments applied word phrase models corpus spontaneous spanish appointment negotiations similar perplexity accuracy results model 
investigated word phrase class phrase models switchboard corpus similar reduction perplexity turned word accuracy improvements 
main reason regularity ofthe verbmobil task lower word accuracy rates current switchboard speech decoders 
proposed framework criterion large corpora wall street journal 
application phrase gram models large corpora promising simply xed length gram models may appropriate dynamic notion context achievable phrases 
application criterion inference syntactical grammars large corpus word tags 
pilot experiment verbmobil corpus shown able produce similar perplexity improvements type corpus 
application hybrid salience model phrases enhance salience text 

acknowledgments research partly funded iv german federal ministry education science research bmbf part verbmobil project 
views contained document authors 


steven abney 
corpus methods language speech chapter part speech tagging parsing 

kluwer academic publishers dordrecht 

sabine deligne bimbot 
language modeling length sequences theoretical formulation evaluation multigram 
icassp 

allen gorin 
automated language 
journal acoustical society america june 

reinhard kneser herman ney 
improved clustering techniques class statistical language modeling 
eurospeech berlin germany 

reinhard kneser hermann ney 
improved gram language modeling 
icassp 

david magerman mitchell marcus 
parsing grammar induction 
pages 

sven martin joerg hermann ney 
algorithms bigram trigram clustering 
eurospeech 

michael james glass 
empirical acquisition language models speech recognition 
icslp yokohama japan 

klaus ries finn dag bu ye yi wang 
improved language modeling acquisition structure 
icassp 

suhm waibel 
better language models spontaneous speech 
icslp yokohama japan 


methode rage de recherche en linguistique 
ta 
