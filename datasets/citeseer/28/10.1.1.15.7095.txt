metacost general method making classifiers cost sensitive pedro domingos artificial intelligence group instituto superior lisbon portugal ist pt www ist pt research machine learning statistics related fields produced wide variety algorithms classification 
algorithms assume errors cost seldom case kdd prob lems 
individually making classification learner laborious non trivial 
propose principled method making arbitrary classifier cost sensitive wrapping cost minimizing procedure 
procedure called metacost treats underlying classifier black box requiring knowledge functioning change 
stratification metacost applicable number classes arbitrary cost matrices 
tests identify key components metacost varied substantial loss 
experiments larger database indicate metacost scales 
classification primary tasks data mining 
subject research machine learning statistics pattern recognition networks areas decades 
result developed approaches exist including rule induction decision tree induction instance learning linear neural classifiers bayesian learning :10.1.1.40.1930
classification problems goal correctly assign examples typically described vectors attributes finite number classes 
currently available algorithms classification designed minimize zero loss error rate number incorrect predictions equivalently probability making incorrect prediction 
implicitly assumes errors costly kdd applications far case 
example database marketing cost mailing non small cost mailing respond entire profit lost 
discussed section related turney provides online bibliography topic 
gone making individual algorithms cost sensitive 
doing ll available literature time consuming enterprise far obvious best perform conversion 
potentially better solution procedure converted broad variety error classifiers cost sensitive ones 
knowledge currently available procedure type stratification changing frequency classes training data proportion cost :10.1.1.47.7199
approach shortcomings 
distribution examples may seriously affect performance algorithms 
reduces data available learning stratification carried 
increases learning time done 
classifiers yield class probability estimates product learning poor 
example decision tree rule learners attempting drive class probabilities zero lea rule resulting estimates correspondingly 
classifiers may produce class probabilities metacost allows require 
robust generally applicable method obtaining class probability estimates classifier suggested research model ensembles 
authors breiman modern learners highly unstable applying slightly different training sets tends produce different models correspondingly different predictions examples accuracy remains broadly unchanged :10.1.1.32.9399
accuracy improved learning models way variations combining predictions example voting 
metacost estimates class probabilities learning multiple classifiers example class fraction total vote estimate probability example 
learners unstable fashion described methods applying metacost learners discussed section 
specifically metacost uses variant breiman bagging ensemble method :10.1.1.32.9399
authors breiman modern learners highly unstable applying slightly different training sets tends produce different models correspondingly different predictions examples accuracy remains broadly unchanged :10.1.1.32.9399
accuracy improved learning models way variations combining predictions example voting 
metacost estimates class probabilities learning multiple classifiers example class fraction total vote estimate probability example 
learners unstable fashion described methods applying metacost learners discussed section 
specifically metacost uses variant breiman bagging ensemble method :10.1.1.32.9399
bagging procedure training set size bootstrap resample constructed samples replacement training set 
new training set size produced original examples may appear 
procedure repeated times resulting models aggregated uniform voting unclassified example ensemble labels class predicted greatest number models 
metacost differs bagging number examples resample may smaller training set size allows efficient 
uci repository machine learning databases 
dept information computer science university irvine ca 
www ics uci edu mlearn mlrepository 
ht ml 
breiman :10.1.1.32.9399
bagging predictors 
machine learn ing 
breiman 
pasting bites prediction large data sets line 
