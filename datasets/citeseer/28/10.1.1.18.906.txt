comparison usage evaluation inspection methods assessing groupware usability michelle potts morse national institute standards technology gaithersburg maryland usa morse nist gov researchers believe groupware evaluated studying real collaborators real contexts process tends expensive timeconsuming 
believe practical evaluate groupware usability inspection methods 
deciding approaches difficult unclear compare real evaluation situation 
address problem carried dual evaluation groupware system evaluation applying user techniques inspection methods 
compared results evaluations concluded methods strengths weaknesses trade offs complementary 
methods overlapping problems expect tandem effect applying discount method prior field study expectation system deployed expensive field study better chance doing pertinent usability problems addressed 
address problem carried dual evaluation groupware system evaluation applying user techniques inspection methods 
compared results evaluations concluded methods strengths weaknesses trade offs complementary 
methods overlapping problems expect tandem effect applying discount method prior field study expectation system deployed expensive field study better chance doing pertinent usability problems addressed 
keywords evaluation groupware usability inspection evaluation techniques usage evaluation techniques 
evaluation groupware received attention researchers computer supported cooperative cscw groupware communities :10.1.1.21.754
evaluation considered difficult problem researchers feel way get true picture groupware system study actual context real users 
field methods able copyright association computing machinery 
acm acknowledges contribution authored authored contractor government 
government retains free right publish reproduce article allow government purposes 
government retains free right publish reproduce article allow government purposes 
group sept oct boulder colorado usa 
copyright acm 
carl gutwin saul greenberg department computer science university saskatchewan canada university calgary canada gutwin cs ca saul cpsc ucalgary ca evaluation timeconsuming expensive addition difficult impossible perform system fully developed 
different types groupware evaluation methods usability inspection techniques utilize real situation proposed :10.1.1.21.754:10.1.1.39.1667
techniques costly field methods earlier frequently development cycle 
techniques actual context unclear usability information provide valid real users 
studies compared various evaluation methods 
wish build determining inspection methods complement field methods evaluating group software 
participants ranked importance individual mechanics collaboration welding 
ranking order identified usability issues respect welding researchers priorities 
analysis 
survey data examined statistical analysis determine trends satisfaction group 
system data explored log visualization tool called statistical analysis :10.1.1.36.6458
additionally chat logs recorded system analyzed determine major topics conversation general communication pathways 
main findings user study user study time consuming set analyze 
preparatory activities carried including customizing tw augment logging capabilities developing log visualization tool preparing training materials questionnaires interviews 
study produced large amount information analysts spent months compiling analyzing data 
