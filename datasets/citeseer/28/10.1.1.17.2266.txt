accelerated focused crawling online relevance feedback soumen chakrabarti iit bombay iit bombay university texas austin organization html tag tree structure rendered browsers roughly rectangular regions embedded text href links greatly helps locate click links best satisfy information need 
automatic program emulate human behavior learn predict relevance unseen href target page information need information limited href source page 
capability great interest focused crawling resource discovery fine tune priority unvisited urls crawl frontier reduce number irrelevant pages fetched discarded 
show great deal usable information href source page relevance target page 
information encoded suitably exploited supervised apprentice takes online lessons traditional focused crawler observing carefully designed set features events associated crawler 
apprentice gets sufficient number examples crawler starts consulting better prioritize urls crawl frontier 
surfing user typically topic specific information need explores known relevant starting points web graph may query responses seek new pages relevant chosen topic deciding clicking specific link humans variety clues source page estimate worth unseen target page including tag tree structure text embedded various regions tag tree link relative remote 
click link leap faith humans discriminating links clues 
making educated guess worth clicking link knowledge target central surfing activity 
automatic programs learn capability valuable number applications broadly characterized personalized topic specific information 
large scale topic specific information gatherers called focused crawlers :10.1.1.107.9226:10.1.1.43.1111:10.1.1.12.8656:10.1.1.1.7474
contrast giant purpose crawlers process large portions web centralized manner distributed federation focused crawlers cover specialized topics depth keep crawl fresh cover crawler 
simplest form focused crawler consists supervised topic classifier called learner controlling priority unvisited frontier crawler see 
classifier trained priori document samples embedded topic taxonomy yahoo 
dmoz 
effort relevant pages spent reduction loss rate primary goal appropriate merit 
focused crawling applications succeed leap faith pay frequently 
words pr preliminary estimate pr great deal network traffic cpu cycles wasted eliminating bad pages 
experience random walks web show walks away fixed page relevant topic relevance successive nodes 
drops dramatically hops :10.1.1.43.1111
means fraction outlinks page typically worth 
average degree web graph 
large number page fetches may result disappointment especially wish push utility focused crawling topic communities densely linked 
topics narrow number distracting outlinks emerging fairly relevant pages grown substantially early days web authoring 
davison early measurements node web subgraph collected system 
standard notion vector space tfidf similarity endpoints hyperlink similar random pages hrefs close page link documents similar targets far apart 
menczer similar observations 
hypertext classifier uses locality patterns better learning topics ibm automatic resource compilation arc clever topic distillation systems 
important advances baseline best focused crawler context graphs reinforcement learning rennie mccallum :10.1.1.107.9226:10.1.1.1.7474
techniques trained learner features collected paths leading relevant nodes relevant nodes 
paths may collected backlinks 
classifier learner text estimated link distance relevant page relevance outlink case baseline crawler 
lets system continue expanding reward link immediate links away 
classifier learner text estimated link distance relevant page relevance outlink case baseline crawler 
lets system continue expanding reward link immediate links away 
favor links payoffs closest 
specifically useful conjunction context graphs context graph learner predicts goal links away crucial offer additional guidance crawler local structure pages fan radius enormous 
rennie mccallum collected paths leading relevant nodes trained slightly different classifier instance single href link :10.1.1.1.7474:10.1.1.1.7474
features terms title headers text near anchor 
directories 
know precise definition near features encoded combined 
prediction discretized estimate number relevant nodes reachable reward goals distant geometrically discounted factor hop 
property holds intelligent crawler proposed aggarwal single learner drift controlled precise relevance predicates provided user 
manual feature tuning tune ad hoc notions proximity text hyperlinks encode features link dom tree automatically learn robust definition nearness textual feature 
contrast aggarwal tuned constants combining strength link predictors rennie domain knowledge select paths goal nodes word bags submitted learner 
methodology algorithms review baseline focused crawler describe enhanced crawler set apprentice critic mechanism 
baseline focused crawler baseline focused crawler described detail sketched :10.1.1.107.9226:10.1.1.43.1111
review design operation briefly 
inputs baseline crawler 
topic taxonomy hierarchy example urls topic 
topics taxonomy marked topic focus 
apprentice learner feature pair 
nb classifiers predict discrete set classes prediction continuous probability score 
bridge gap simple bucket low high relevance special case gama technique classifiers discrete labels continuous regression equally probable intervals far possible 
gama recommend measure centrality median interval predicted value class 
rennie mccallum corroborate bins adequate :10.1.1.1.7474:10.1.1.1.7474
clear experiments medians low high classes close zero respectively see 
simply take probability high class prediction naive bayes apprentice 
prior probability class denoted pr fraction training documents labeled class nb model parameterized set numbers roughly rate occurrence feature class exactly vc vc set web pages labeled entire vocabulary 
nb learner assumes independence features estimates pr pr pr pr nigam provide details 
fast gb html text processed rainbow 
complete listing topics obtained authors 
choice topics depending focus topic prioritization strategy focused crawlers may achieve diverse harvest rates 
early prototype yielded harvest rates typically 
rennie mccallum reported recall harvest rates :10.1.1.1.7474
focused specific topics harvest rate low :10.1.1.107.9226
obviously maximum gains shown new idea focused crawling sensitive baseline harvest rate 
avoid showing new system unduly positive negative light picked set topics fairly diverse appeared broad useful arts science narrow baseline crawler reasonable adversary 
list topics 
complete listing topics obtained authors 
choice topics depending focus topic prioritization strategy focused crawlers may achieve diverse harvest rates 
early prototype yielded harvest rates typically 
rennie mccallum reported recall harvest rates :10.1.1.1.7474
focused specific topics harvest rate low :10.1.1.107.9226
obviously maximum gains shown new idea focused crawling sensitive baseline harvest rate 
avoid showing new system unduly positive negative light picked set topics fairly diverse appeared broad useful arts science narrow baseline crawler reasonable adversary 
list topics 
chose topics prior estimates new system list topics 
de bra post 
searching arbitrary information www fish search mosaic 
second world wide web conference mosaic web chicago oct 
online archive ncsa uiuc edu sdg proceedings searching article html citeseer nj nec com html 
coetzee lawrence giles gori :10.1.1.107.9226
focused crawling context graphs 
abbadi brodie chakravarthy dayal kamel 
whang editors vldb proceedings th international conference large data bases september cairo egypt pages 
morgan kaufmann 
stochastic models web graph 
focs volume pages 
ieee nov 
online www cs brown edu people eli papers focs ps 
rennie mccallum :10.1.1.1.7474
reinforcement learning spider web efficiently 
icml 
online www cs cmu edu mccallum papers icml ps gz 
salton mcgill 
