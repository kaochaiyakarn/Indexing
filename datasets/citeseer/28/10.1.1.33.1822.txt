layered learning peter stone research att com labs research park ave room florham park nj usa manuela veloso veloso cs cmu edu computer science department carnegie mellon university pittsburgh pa usa proceedings ijcai workshop learning agents 
presents layered learning hierarchical machine learning paradigm 
layered learning applies tasks learning direct mapping inputs outputs intractable existing learning algorithms 
hierarchical task decomposition subtasks layered learning seamlessly integrates separate learning subtask layer 
learning subtask directly facilitates learning higher subtask layer determining components set training examples ii input representation iii output representation 
introduce layered learning domainindependent general form 
layered learning assumes appropriate aspects task learned determined function speci domain 
include automated hierarchical decomposition task 
layer learned applying ml algorithm appropriate speci subtask characteristics 
apply layered learning complex multiagent learning task simulated robotic soccer 
previously individual learned tasks domain stone veloso stone veloso preliminary version concept layered learning stone veloso :10.1.1.34.8820
contributes concrete domainindependent speci cation layered learning sections 
section reviews machine learning research simulated robotic soccer domain terms new layered learning speci cation 
layered learning example fully implemented tested 
succeeds robotic soccer domain compressing large state space described section 
subtasks increasingly complex individual multiagent behaviors 
purpose section illustrate layered learning fully implemented system 
full details domain individual learned subtask previously reported 
represented terms formalism section 
simulated robotic soccer robocup soccer server noda basis successful international competitions research challenges kitano :10.1.1.11.6142
detail stone fully distributed multiagent domain teammates adversaries enormous state space 
hidden state meaning agent partial world view moment 
agents noisy sensors actuators meaning perceive world exactly ect world exactly intended 
addition perception action cycles asynchronous prohibiting traditional ai paradigm perceptual input trigger actions 
sigmoid hidden units learning rate weights connecting input hidden layers linearly decreasing weight decay starting 
linear output unit weight decay 
neural network trained epochs 
trained interception behavior table shows ect number training examples learned save percentage 
training examples defender able shots goal saves goals misses omitted comparable save rate achieved analytic ball interception behavior stone veloso :10.1.1.34.8820
training saves examples saves goals goals saves table defender performance neural networks trained di erent numbers training examples 
pass evaluation multiagent behavior 
second agents learned ball interception skill part behavior training multiagent behavior 
agent ball option pass particular teammate useful idea pass succeed executed teammate successfully receive ball 
evaluation depends teammate opponents positions abilities receive intercept pass 
consequently creating training examples function equip intended pass recipient opponents previously learned ball interception behavior chose agents learn pass evaluation capability easier collect training data construct hand 
de ned follows 
set continuous ordinal features features possibly affect pass evaluation 
encode large set attributes representing relative positions teammates opponents eld statistical counts re ecting relative positioning stone veloso :10.1.1.34.8820
features carefully chosen 
contrary possibly irrelevant features included leaving ml algorithm select proper ones 
full list attributes stone veloso :10.1.1.34.8820
potential pass particular receiver classi ed success con dence factor failure con dence factor 
set continuous ordinal features features possibly affect pass evaluation 
encode large set attributes representing relative positions teammates opponents eld statistical counts re ecting relative positioning stone veloso :10.1.1.34.8820
features carefully chosen 
contrary possibly irrelevant features included leaving ml algorithm select proper ones 
full list attributes stone veloso :10.1.1.34.8820
potential pass particular receiver classi ed success con dence factor failure con dence factor 
training procedure pass evaluation involves passer kicking ball teammates interspersed opponents 
training scenario illustrated screen shot soccer server 
dashed line indicates region teammates opponents randomly placed 
drastically reduce input space help previously learned decision tree considering positions players eld pass evaluations possible passes teammate considered 
de ned follows 
choose shoot 
purposes behavior agents option dribble 
fp input representation consists coarse geographical component action dependent feature stone veloso possible pass :10.1.1.34.8820
action dependent features precisely result executed possible receiver 
result pass selection decision shot goal pass particular teammate 
training examples gathered line individual team members real games 
individual agent learns separate partition position eld 
training examples gathered line individual team members real games 
individual agent learns separate partition position eld 
agents learn observed long term ects actions stone 
particular action decision eligible members pruned passes predicted succeed considered 
tpot rl training pass selection tpot rl stone veloso online multiagent reinforcement learning method motivated learning applicable team partitioned opaque transition domains simulated robotic soccer :10.1.1.34.8820
default parameters reported stone veloso :10.1.1.34.8820
distributed pass selection policy test pass selection learning directly comparing teams identical behaviors pass selection policies 
agents teams passing randomly agents team adjust behavior experience tpot rl 
agents continue passing randomly 
individual agent learns separate partition position eld 
agents learn observed long term ects actions stone 
particular action decision eligible members pruned passes predicted succeed considered 
tpot rl training pass selection tpot rl stone veloso online multiagent reinforcement learning method motivated learning applicable team partitioned opaque transition domains simulated robotic soccer :10.1.1.34.8820
default parameters reported stone veloso :10.1.1.34.8820
distributed pass selection policy test pass selection learning directly comparing teams identical behaviors pass selection policies 
agents teams passing randomly agents team adjust behavior experience tpot rl 
agents continue passing randomly 
demonstrates effectiveness learned passing policies 
distributed pass selection policy test pass selection learning directly comparing teams identical behaviors pass selection policies 
agents teams passing randomly agents team adjust behavior experience tpot rl 
agents continue passing randomly 
demonstrates effectiveness learned passing policies 
additional tests goal directed opponents reported stone veloso :10.1.1.34.8820

discussion section analyze key bene ts limitations layered learning 
empirical results pertaining layered learning implementation 
analysis learned layers described section illustrate principles layered learning paradigm section goals game number cumulative goals vs game number learning random total goals scored learning team playing randomly passing team 

decomposition task smaller subtasks enables learning complex behavior possible learning straight agents sensory inputs 
attempts monolithic learning agent behaviors soccer server 
luke 
luke set create completely learned team agents genetic programming koza :10.1.1.36.1280:10.1.1.100.6544
eventually scaled back low level player skills created hand basis learning 
resulting learned team won games international robocup robotic soccer simulator competition losing second round 
year robocup genetic programming attempt learning entire team behavior andre teller 
time agents allowed learn directly sensory input representation 
results layered learning approach contributed success rst international robocup robotic soccer competitions 
competitions controlled testing scenarios provide means isolating positive negative aspects approach allow evaluation implementation 
results competitions supporting evidence proof layered learning ective 
note individual learned layers described section validated controlled experiments 
robust low level skills sophisticated team member agent architecture stone veloso contributed signi cantly :10.1.1.34.8820
patrick riley implementation low level skills stone 
rst robotic soccer world cup competition robocup kitano team semi eld teams 
robocup asada kitano team won eld teams 
robocup veloso team repeated champion eld teams 
boosting stacked generalization potentially layer di erent layers 
line type hierarchical learning discussed hierarchical reinforcement learning algorithms 
known curse dimensionality reinforcement learning rl researchers interested hierarchical learning approaches 
surveyed kaelbling hierarchical rl approaches behaviors collection behaviors map environment states low level actions gating function decides state environment behavior actions switched executed 
kaelbling cases behaviors learned mahadevan connell cases gating function learned maes brooks cases learned lin :10.1.1.160.8786
example behaviors learned xed prior learning gating function 
hand feudal qlearning dayan hinton maxq algorithm dietterich learn levels hierarchy simultaneously :10.1.1.9.313:10.1.1.19.8208
constant approaches behaviors gating function control tasks similar inputs actions abstracted 
rl layer layered learning implementation input representation learned 
known curse dimensionality reinforcement learning rl researchers interested hierarchical learning approaches 
surveyed kaelbling hierarchical rl approaches behaviors collection behaviors map environment states low level actions gating function decides state environment behavior actions switched executed 
kaelbling cases behaviors learned mahadevan connell cases gating function learned maes brooks cases learned lin :10.1.1.160.8786
example behaviors learned xed prior learning gating function 
hand feudal qlearning dayan hinton maxq algorithm dietterich learn levels hierarchy simultaneously :10.1.1.9.313:10.1.1.19.8208
constant approaches behaviors gating function control tasks similar inputs actions abstracted 
rl layer layered learning implementation input representation learned 
addition methods implemented large scale complex domain 
rl approaches layered learning task decomposition constructed manually 
rl layer layered learning implementation input representation learned 
addition methods implemented large scale complex domain 
rl approaches layered learning task decomposition constructed manually 
attempt challenging task learning task decomposition 
nested learning generates hierarchical control structure learns low level skills time learns select :10.1.1.187.8212
far hierarchical rl approaches tested small problems order states case 

layered learning paradigm illustrated fully implemented example robotic soccer domain 
layered learning implementation robust low level skills sophisticated team member agent architectures incorporates exible teamwork structure stone veloso contributed success complete team simulated robotic soccer competitions :10.1.1.34.8820
nested learning generates hierarchical control structure learns low level skills time learns select :10.1.1.187.8212
far hierarchical rl approaches tested small problems order states case 

layered learning paradigm illustrated fully implemented example robotic soccer domain 
layered learning implementation robust low level skills sophisticated team member agent architectures incorporates exible teamwork structure stone veloso contributed success complete team simulated robotic soccer competitions :10.1.1.34.8820
important direction apply layered learning new domain 
example apparently orthogonal robotic soccer consider natural language understanding application layered learning 
natural language understanding clear hierarchical task decomposition 
example learned word sense disambiguation facilitate learned sentence parsing turn facilitate semantic encoding sentences paragraphs see table 
