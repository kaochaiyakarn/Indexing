error correcting codes text classification ghani cs cmu edu center automated learning discovery school computer science carnegie mellon university pittsburgh pa explores detail error correcting output coding ecoc learning text classifiers 
show accuracy naive bayes classifier text classification tasks significantly improved advantage error correcting properties code 
explore different kinds codes error correcting codes random codes domain data specific codes give experimental results 
ecoc method scales large data sets large number classes 
experiments real world data set show reduction classification error traditional naive bayes classifier 
compare empirical results results find closely agree 
learning algorithm handle class learning problems decision tree algorithm quinlan applied learn problems 
thought length codewords bit codeword classifier 
error correcting codes bakiri decision trees neural networks glass vowel soybean letter nettalk data sets available irvine repository machine learning databases murphy aha 
artificial neural networks functions implemented output units single network 
decision trees separate decision trees learned bit position output code kong :10.1.1.72.7289
shown ecoc approach improve performance learning algorithms provide improvements small sample sizes 
berger applies ecoc approach text classification reports results datasets encouraging 
give theoretical evidence random codes 
differs berger gives detailed experimental study various types codes gives empirical evidence error correcting codes random codes 

experimental results section describes experiments performed ecoc contains explanation results 
compare results performance naive bayes classifier commonly algorithms text classification 
experiments classification accuracy evaluation measure 
papers proposed different performance measures precision recall graphs break point recall precision lewis goal classification algorithm achieve low misclassification rate test set schapire accuracy best measure performance purposes :10.1.1.31.2869
experiments naive bayes classifier learn individual functions bit code 
class unique binary code length 
classify test instance test individual bit classifiers combine output compare codes class 
test instance assigned class nearest codeword ties broken randomly 

examined error correcting output coding improving text classification 
demonstrated error correcting codes reduce text classification error 
reduction error naive bayes classifier sparse training data large training data method training data difficult expensive gather 
analyzing ecoc approach comparing voting methods schapire boosting bagging nave bayes classifier open problem provide valuable insight extensibility approach :10.1.1.31.2869
needed experiment various types codes analyze changes performance ecoc 
currently process experimenting automatically constructing codes perform better random algebraic ones 
method start random code choose column worst classification accuracy modify column randomly minimum hamming distance code reduced accuracy bit increased 
repeated increase accuracy preset threshold 
