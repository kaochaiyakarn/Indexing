chapter constrained genetic algorithms applications nonlinear constrained optimization benjamin wah yi xin chen department electrical computer engineering coordinated science laboratory university illinois urbana champaign urbana il usa chapter presents framework unifies various search mechanisms solving constrained nonlinear programming nlp problems 
problems characterized functions necessarily differentiable continuous 
proposed framework order necessary sufficient condition developed constrained local minimization discrete space shows equivalence discrete neighborhood saddle points constrained local minima 
look discrete neighborhood saddle points formulate discrete constrained nlp augmented lagrangian function study various mechanisms performing augmented function original variable subspace lagrange multiplier subspace 
results show csaga combined constrained simulated annealing genetic algorithm performs crossovers mutations annealing generate trial points 
apply iterative deepening determine optimal number generations csaga show performance robust respect changes population size 
point called constrained global minimum discrete neighborhood cgm dn iff feasible feasible point 
set cgm dn opt definitions cgm dn clm dn similar way definitions continuous neighborhood constrained local minima clm cn constrained global minima cgm cn 
shown earlier necessary sufficient condition point clm dn satisfies discrete neighborhood saddle point condition section 
extended simulated annealing sa greedy search look discrete neighborhood saddle points sp dn section 
time new problem dependent constraint handling heuristics developed ga community handle nonlinear constraints section :10.1.1.13.9279
clear understanding unify algorithms applied find cgm dn wide range problems 
vectors number elements means element corresponding element defined similarly 
compared vector stands null vector 
constrained genetic algorithms applications nonlinear constrained optimization pr pr pr approaches asymptotically existence absolute minimum pr 
clear understanding unify algorithms applied find cgm dn wide range problems 
vectors number elements means element corresponding element defined similarly 
compared vector stands null vector 
constrained genetic algorithms applications nonlinear constrained optimization pr pr pr approaches asymptotically existence absolute minimum pr 
example showing application csaga solve discretized version :10.1.1.13.9279
previous goal chapter develop effective framework unifies sa ga greedy search finding cgm dn particular propose constrained genetic algorithm cga combined constrained sa ga csaga look sp dn study algorithms optimal average completion time finding cgm dn algorithms studied chapter stochastic searches probe search space random order probe neighboring point examined algorithm independent accepted 
assuming probability algorithm finds cgm dn th probe simplistic assumption probes independent performance run algorithm characterized number probes cpu time taken pr reachability probability cgm dn hit probes pr gamma gamma reachability maintained reporting best solution algorithm stops 
example plots pr csaga see section run various number generations fixed population size 
graph shows pr approaches asymptotically increased 
dynamic penalty methods guarantee convergence clm dn cgm dn example consider problem constraints 
assuming search stuck infeasible point dn jh jh jh jh jh fi jh fi jh fi jh fi search escape matter large theta ff grows 
way ensure convergence dynamic penalty methods different penalty constraint lagrangian formulation 
previous example search escape assigning larger penalty 
variants penalty methods annealing penalties adaptive penalties self adapting weights :10.1.1.13.9279
addition problem dependent operators studied ga community handling constraints 
include methods preserving feasibility specialized genetic operators methods searching boundaries feasible regions methods repair infeasible solutions evolutionary methods strategic oscillation 
methods require domain specific knowledge problem dependent genetic operators difficulties finding feasible regions maintaining feasibility nonlinear constraints 
general local minima penalty functions necessary sufficient constrained local minima original constrained optimization problems penalties chosen properly 
cga csaga iterative deepening section method determine optimal number generations run cga csaga order find cgm dn method iterative deepening determines upper bound order minimize expected total overhead number generations run cga 
number probes expended run cga csaga population size 
fixed pr pr pn reachability probability finding cgm dn expected total number probes multiple runs cga csaga fixed pr pr pr order optimal number generations gopt minimizes ng pr ng absolute minimum 
condition true pr cga similar behavior constrained genetic algorithms applications nonlinear constrained optimization pr csa 
verified statistics collected pr various cga csaga solve discretized benchmark problems :10.1.1.13.9279
illustrates existence absolute minimum csaga applied solve 
similar design csa id apply iterative deepening estimate gopt cga id uses set geometrically increasing find cgm dn ae small initial number generations 
cga run maximum times stops immediately feasible solution better solution successive generations number iterations increased geometrically times 
conditions ensure iterative deepening applied adequately 

experimental results section experimental results evaluating csa id cga id csaga id discrete constrained nlps 
framework determine best combination strategies generating probes organizing candidates 
best combination strategies show experimental results constrained nlps 
due lack large scale discrete benchmarks derive benchmarks sets continuous benchmarks problem pardalos problems :10.1.1.13.9279:10.1.1.13.9279

implementation details theory algorithms derived framework csa cga csaga look sp dn practice important choose appropriate neighborhoods generate proper trial points subspaces order solve constrained nlps efficiently 
important component methods frequency updated 
csa set experimentally cga csaga ratio generating trial points subspaces current point number variables number constraints 
gamma greedy deterministic deterministic gamma sec 
gamma sec 
sec 
gamma 
evaluation results due lack large scale discrete benchmarks derive benchmarks sets continuous benchmarks problem pardalos problems :10.1.1.13.9279:10.1.1.13.9279
generating discrete constrained nlp discretize continuous variables original continuous constrained nlp discrete variables follows 
discretizing continuous variable range lower upper bounds respectively force take values set gammaa delta delta delta gamma phi delta delta delta gamma sc psi gamma theta table shows results evaluating various combinations strategies csa id cga id csaga id discretized version :10.1.1.13.9279
show average time runs combination order reach solution quality levels worse cgm dn assuming value cgm dn known 
evaluation results benchmark problems similar shown due space limitations 
sec 
gamma 
evaluation results due lack large scale discrete benchmarks derive benchmarks sets continuous benchmarks problem pardalos problems :10.1.1.13.9279:10.1.1.13.9279
generating discrete constrained nlp discretize continuous variables original continuous constrained nlp discrete variables follows 
discretizing continuous variable range lower upper bounds respectively force take values set gammaa delta delta delta gamma phi delta delta delta gamma sc psi gamma theta table shows results evaluating various combinations strategies csa id cga id csaga id discretized version :10.1.1.13.9279
show average time runs combination order reach solution quality levels worse cgm dn assuming value cgm dn known 
evaluation results benchmark problems similar shown due space limitations 
results show cga id usually efficient csa id csaga id csa id csaga id better performance probes generated subspace accepted annealing deterministic rules prevents search getting stuck local minima infeasible points 
hand little difference performance new probes generated subspace accepted probabilistic greedy rules new candidates inserted annealing deterministic rules 
results show cga id usually efficient csa id csaga id csa id csaga id better performance probes generated subspace accepted annealing deterministic rules prevents search getting stuck local minima infeasible points 
hand little difference performance new probes generated subspace accepted probabilistic greedy rules new candidates inserted annealing deterministic rules 
short generating probes subspaces probabilistically inserting candidates subspaces annealing rules leads stable performance 
reason combination strategies experiments 
test algorithms constrained nlps :10.1.1.13.9279
problems objective functions various types linear quadratic cubic polynomial nonlinear constraints linear inequalities nonlinear equalities nonlinear inequalities 
number variables constraints including simple bounds 
ratio feasible space respect search space varies topologies feasible regions quite different 
problems originally designed solved evolutionary table 
columns show performance csaga id average times number evaluations constant show average times opt enumeration 
results show little improvements opt csaga id improvement id compared csa id problems 
comparing cga id csaga id ea see ea able find problems despite extensive tuning problem specific heuristics cga id csaga id find problems problem dependent strategies 
possible report timing results ea results best runs extensive tuning 
table shows results selected discretized pardalos benchmarks variables equality inequality constraints :10.1.1.13.9279
columns show problem ids known number variables 
constrained genetic algorithms applications nonlinear constrained optimization table 
results solving selected pardalos discretized constrained nlp benchmarks nv variables 
problem especially large difficult search rarely reach true consider solution quality true cpu times seconds averaged runs collected pentium iii mhz computer solaris 
zs 

self adaptivity constraint satisfaction learning penalty functions 
proceedings rd ieee conference evolutionary computation pages 
pardalos :10.1.1.13.9279
collection test problems constrained global optimization algorithms volume lecture notes computer science 
springer verlag 

non stationary penalty functions solve nonlinear constrained optimization problems gas 
addison wesley publishing reading ma 
michalewicz 
genocop iii evolutionary algorithm numerical optimization problems nonlinear constraints 
proceedings ieee international conference evolutionary computation 
michalewicz schoenauer :10.1.1.13.9279
evolutionary algorithms constrained parameter optimization problems 
evolutionary computation 
wah chen 
optimal anytime constrained simulated annealing constrained global optimization 
