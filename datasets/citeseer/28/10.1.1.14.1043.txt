machine learning fl kluwer academic publishers boston 
manufactured netherlands 
learning classify text labeled unlabeled documents kamal nigam cs cmu edu andrew mccallum mccallum justresearch com sebastian thrun thrun cs cmu edu tom mitchell mitchell cs cmu edu school computer science carnegie mellon university pittsburgh pa just research henry street pittsburgh pa editor 
shows accuracy learned text classifiers improved augmenting small number labeled training documents large pool unlabeled documents 
significant important text classification problems obtaining classification labels expensive large quantities unlabeled documents readily available 
theoretical argument showing common assumptions unlabeled data contain information target function 
keywords text classification expectation maximization combining supervised unsupervised learning bayesian learning 
consider problem training computer automatically classify text documents 
growing volume online text available world wide web internet news feeds electronic mail digital libraries problem great practical significance 
statistical text learning algorithms trained approximately classify documents sufficient set labeled training examples 
text classification algorithms automatically catalog news articles web pages automatically learn reading interests users automatically sort electronic mail :10.1.1.48.284:10.1.1.35.6633:10.1.1.22.6286:10.1.1.16.3103
key difficulty current algorithms issue addressed require large prohibitive number labeled training examples learn accurately 
take example task learning newsgroup articles interest person reading usenet news examined lang 
reading classifying articles precision learned classifier top documents ranked classifier 
practical user filtering system obviously prefer learning algorithms nigam mccallum thrun mitchell provide accurate classifications hand labeling dozen articles thousands 
brief provide information joint probability distribution words documents 
suppose example labeled data determine documents containing word learn tend belong positive class 
fact estimate classification unlabeled documents find word teach occurs frequently unlabeled examples believed belong positive class 
occurrence words learn teach large set unlabeled training data provide useful information construct accurate classifier considers learn teach indicators positive examples 
specific approach describe combination wellknown learning algorithms naive bayes classifier expectation maximization em algorithm :10.1.1.49.860
naive bayes algorithm class statistical text classifiers uses word frequencies features 
examples include tfidf rocchio regression models nearest neighbor support vector machines 
em class iterative algorithms maximum likelihood estimation problems incomplete data 
result combining algorithm extends conventional text learning algorithms em dynamically derive pseudo labels unlabeled documents learning providing way incorporate unlabeled data supervised learning 
argue results significant practical importance text learning domains web unlabeled data available free labeling data truly expensive 

probabilistic framework ground theoretical aspects provide setting algorithm section presents probabilistic framework characterizing nature documents classifiers 
introduce classifier show unlabeled data improve classification 
framework follows commonly assumptions data text produced mixture model correspondence mixture components classes :10.1.1.144.7475:10.1.1.49.860
setting document generated probability distribution mixture model parameterized 
mixture model consists mixture components fc jcj component parameterized disjoint subset 
document created selecting component priors second having mixture component generate document parameters distribution jc 
characterize likelihood document sum total probability mixture components jcj jc document class label 
naive bayes text classification section naive bayes classifier known probabilistic algorithm classifying text special case mixture model 
algorithm forms foundation incorporate unlabeled data 
continue assumptions data generation documents produced mixture model correspondence classes mixture components 
motivational result previous section holds unlabeled documents beneficial 
naive bayes additional assumption probability seeing word document independent context position :10.1.1.144.7475:10.1.1.49.860
learning task set training documents order form estimates parameters generative model 
naive bayes forms bayes optimal estimates parameters uses estimated model classify new documents 
generative model describe full generative model documents learning text classifiers 
specialization mixture model section 
task classify test document single class simply select class highest posterior probability arg max jd 
note assumptions generation text documents mixture model correspondence mixture components classes word independence document length distribution violated practice 
documents fall overlapping categories 
words document independent grammar topicality ensure 
despite violations empirically naive bayes classifier job classifying text documents :10.1.1.21.7950:10.1.1.35.6633:10.1.1.49.860
paradox explained fact classification estimation function sign binary cases function estimation function approximation poor classification accuracy remains high :10.1.1.144.7475:10.1.1.101.6820
formulation naive bayes assumes generative model accounts number times word appears document 
equivalent multinomial event model factorial terms account event ordering :10.1.1.46.1529
formulation numerous practitioners naive bayes text classification :10.1.1.21.7950:10.1.1.16.3103:10.1.1.14.7461
note assumptions generation text documents mixture model correspondence mixture components classes word independence document length distribution violated practice 
documents fall overlapping categories 
words document independent grammar topicality ensure 
despite violations empirically naive bayes classifier job classifying text documents :10.1.1.21.7950:10.1.1.35.6633:10.1.1.49.860
paradox explained fact classification estimation function sign binary cases function estimation function approximation poor classification accuracy remains high :10.1.1.144.7475:10.1.1.101.6820
formulation naive bayes assumes generative model accounts number times word appears document 
equivalent multinomial event model factorial terms account event ordering :10.1.1.46.1529
formulation numerous practitioners naive bayes text classification :10.1.1.21.7950:10.1.1.16.3103:10.1.1.14.7461
formulation naive bayes text classification assumes generative model document representation word vocabulary binary feature modeled bernoulli trial :10.1.1.21.988
words document independent grammar topicality ensure 
despite violations empirically naive bayes classifier job classifying text documents :10.1.1.21.7950:10.1.1.35.6633:10.1.1.49.860
paradox explained fact classification estimation function sign binary cases function estimation function approximation poor classification accuracy remains high :10.1.1.144.7475:10.1.1.101.6820
formulation naive bayes assumes generative model accounts number times word appears document 
equivalent multinomial event model factorial terms account event ordering :10.1.1.46.1529
formulation numerous practitioners naive bayes text classification :10.1.1.21.7950:10.1.1.16.3103:10.1.1.14.7461
formulation naive bayes text classification assumes generative model document representation word vocabulary binary feature modeled bernoulli trial :10.1.1.21.988
empirical comparisons show multinomial formulation yields higher accuracy classifiers :10.1.1.46.1529
nigam mccallum thrun mitchell 
despite violations empirically naive bayes classifier job classifying text documents :10.1.1.21.7950:10.1.1.35.6633:10.1.1.49.860
paradox explained fact classification estimation function sign binary cases function estimation function approximation poor classification accuracy remains high :10.1.1.144.7475:10.1.1.101.6820
formulation naive bayes assumes generative model accounts number times word appears document 
equivalent multinomial event model factorial terms account event ordering :10.1.1.46.1529
formulation numerous practitioners naive bayes text classification :10.1.1.21.7950:10.1.1.16.3103:10.1.1.14.7461
formulation naive bayes text classification assumes generative model document representation word vocabulary binary feature modeled bernoulli trial :10.1.1.21.988
empirical comparisons show multinomial formulation yields higher accuracy classifiers :10.1.1.46.1529
nigam mccallum thrun mitchell 
em incorporate unlabeled data naive bayes just small set labeled training data classification accuracy suffer variance parameter estimates generative model high 
paradox explained fact classification estimation function sign binary cases function estimation function approximation poor classification accuracy remains high :10.1.1.144.7475:10.1.1.101.6820
formulation naive bayes assumes generative model accounts number times word appears document 
equivalent multinomial event model factorial terms account event ordering :10.1.1.46.1529
formulation numerous practitioners naive bayes text classification :10.1.1.21.7950:10.1.1.16.3103:10.1.1.14.7461
formulation naive bayes text classification assumes generative model document representation word vocabulary binary feature modeled bernoulli trial :10.1.1.21.988
empirical comparisons show multinomial formulation yields higher accuracy classifiers :10.1.1.46.1529
nigam mccallum thrun mitchell 
em incorporate unlabeled data naive bayes just small set labeled training data classification accuracy suffer variance parameter estimates generative model high 
augmenting small set large set unlabeled data combining sets em improve parameter estimates 
formulation naive bayes assumes generative model accounts number times word appears document 
equivalent multinomial event model factorial terms account event ordering :10.1.1.46.1529
formulation numerous practitioners naive bayes text classification :10.1.1.21.7950:10.1.1.16.3103:10.1.1.14.7461
formulation naive bayes text classification assumes generative model document representation word vocabulary binary feature modeled bernoulli trial :10.1.1.21.988
empirical comparisons show multinomial formulation yields higher accuracy classifiers :10.1.1.46.1529
nigam mccallum thrun mitchell 
em incorporate unlabeled data naive bayes just small set labeled training data classification accuracy suffer variance parameter estimates generative model high 
augmenting small set large set unlabeled data combining sets em improve parameter estimates 
em concurrently generates probabilistically assigned labels unlabeled documents probable model smaller parameter variance predicts probabilistic labels 
em incorporate unlabeled data naive bayes just small set labeled training data classification accuracy suffer variance parameter estimates generative model high 
augmenting small set large set unlabeled data combining sets em improve parameter estimates 
em concurrently generates probabilistically assigned labels unlabeled documents probable model smaller parameter variance predicts probabilistic labels 
section describes em probabilistic framework previous section 
special case general missing values formulation :10.1.1.56.6066
theory em works particularly simple resulting algorithm straightforward 
algorithm outlined table 
set training documents task build classifier form previous section 
previously section assume subset documents come class labels rest documents subset class labels unknown 
em finds locally maximizes probability data labeled unlabeled 
nigam mccallum thrun mitchell 
experimental results section give empirical evidence algorithm table labeled unlabeled documents outperforms naive bayes unlabeled documents 
experimental results different text corpora domains usenet news articles newsgroups web pages webkb newswire articles reuters 
datasets protocol newsgroups data set collected ken lang consists articles divided evenly different usenet discussion groups :10.1.1.21.7950
words stoplist common short words removed unique words occur 
categories fall confusable clusters example comp discussion groups discuss religion 
tokenizing data skip usenet headers discarding subject line tokens formed contiguous alphabetic characters left unstemmed 
best performance obtained feature selection normalizing word counts document length 
categories fall confusable clusters example comp discussion groups discuss religion 
tokenizing data skip usenet headers discarding subject line tokens formed contiguous alphabetic characters left unstemmed 
best performance obtained feature selection normalizing word counts document length 
accuracy results reported averages test train splits documents randomly selected placement test set 
webkb data set contains web pages gathered university computer science departments :10.1.1.35.6633
departments web pages included additionally pages assortment universities 
pages divided categories student faculty staff course project department 
non categories student faculty course project containing pages 
stemming stoplist stoplist hurt performance example fourth ranked word information gain excellent indicator student homepage 
departments web pages included additionally pages assortment universities 
pages divided categories student faculty staff course project department 
non categories student faculty course project containing pages 
stemming stoplist stoplist hurt performance example fourth ranked word information gain excellent indicator student homepage 
done previously informative words measured average mutual information class variable :10.1.1.35.6633:10.1.1.35.6633
feature selection method commonly text :10.1.1.21.7950
accuracy results average test train splits randomly holding documents testing 
train test split reuters distribution data set consists articles topic categories reuters newswire 
studies classes build binary classifiers class :10.1.1.74.2349
pages divided categories student faculty staff course project department 
non categories student faculty course project containing pages 
stemming stoplist stoplist hurt performance example fourth ranked word information gain excellent indicator student homepage 
done previously informative words measured average mutual information class variable :10.1.1.35.6633:10.1.1.35.6633
feature selection method commonly text :10.1.1.21.7950
accuracy results average test train splits randomly holding documents testing 
train test split reuters distribution data set consists articles topic categories reuters newswire 
studies classes build binary classifiers class :10.1.1.74.2349
words inside text 
done previously informative words measured average mutual information class variable :10.1.1.35.6633:10.1.1.35.6633
feature selection method commonly text :10.1.1.21.7950
accuracy results average test train splits randomly holding documents testing 
train test split reuters distribution data set consists articles topic categories reuters newswire 
studies classes build binary classifiers class :10.1.1.74.2349
words inside text 
tags including title remove reuter tags occur top bottom document 
stoplist stem 
vocabulary selection performed average mutual information class variable 
category nb em em em em diff acq corn crude earn grain interest money fx ship trade wheat left column table shows average precision recall breakeven points trials experiment naive bayes 
numbers best vocabulary size task indicated parentheses 
classifiers different categories performed best widely varying vocabulary sizes 
variance optimal vocabulary size 
previously noted categories wheat corn known strong correspondence words categories categories acq known subtle class definition :10.1.1.21.7950
categories narrow definitions require small vocabularies best classification broader definition require large vocabulary capture category 
second column table shows results performing em data single negative centroid previous experiments 
expected fit assumed model reuters data poor results em dramatically worse simple naive bayes 
negative class truly multi modal fitting single naive bayes class em data accurately capture distribution 
naive bayes mixture gaussians miller mixtures experts 
demonstrate experimental results non text data sets features 
contrast textual data sets orders magnitude features 
example applying em fill missing values missing values class labels unlabeled training examples 
ghahramani jordan em mixture models fill missing values :10.1.1.56.6066
emphasis missing feature values focus augmenting small complete set labeled data 
autoclass project investigated combination em algorithm underlying model naive bayes classifier 
emphasis research discovery novel clusterings unsupervised learning unlabeled data 
autoclass applied text classification 
emphasis research discovery novel clusterings unsupervised learning unlabeled data 
autoclass applied text classification 
approaches reducing need labeled training examples active learning algorithm iteratively selects unlabeled example asks human classification classifier 
approaches differ methods selecting unlabeled example request label 
examples relevance sampling uncertainty sampling query committee approach :10.1.1.74.2349
statistical text classifiers variety domains naive bayes strong probabilistic foundation em efficient large data sets :10.1.1.11.6124:10.1.1.14.6535
thrust straightforwardly demonstrate value unlabeled data similar approach apply unlabeled data complex classifiers 

summary explored question unlabeled data may supplement scarce labeled data machine learning problems especially learning classify text documents 
autoclass applied text classification 
approaches reducing need labeled training examples active learning algorithm iteratively selects unlabeled example asks human classification classifier 
approaches differ methods selecting unlabeled example request label 
examples relevance sampling uncertainty sampling query committee approach :10.1.1.74.2349
statistical text classifiers variety domains naive bayes strong probabilistic foundation em efficient large data sets :10.1.1.11.6124:10.1.1.14.6535
thrust straightforwardly demonstrate value unlabeled data similar approach apply unlabeled data complex classifiers 

summary explored question unlabeled data may supplement scarce labeled data machine learning problems especially learning classify text documents 
important question text learning high cost hand labeling data availability huge volumes unlabeled data 
