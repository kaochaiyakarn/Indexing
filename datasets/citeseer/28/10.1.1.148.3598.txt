domain specific keyphrase extraction eibe frank gordon paynter ian witten department computer science university waikato hamilton new zealand carl gutwin department computer science university saskatchewan canada keyphrases important means document summarization clustering topic search 
small minority documents author assigned keyphrases manually assigning keyphrases existing documents laborious 
highly desirable automate keyphrase extraction process 
shows simple procedure keyphrase extraction naive bayes learning scheme performs comparably state art 
goes explain procedure performance boosted automatically tailoring extraction process particular document collection hand 
results large collection technical reports computer science show quality extracted keyphrases improves significantly domain specific information exploited 
keyphrases give high level description document contents intended easy prospective readers decide relevant 
applications 
keyphrases summarize documents concisely low cost measure similarity documents making possible cluster documents groups measuring overlap keyphrases assigned 
related application topic search entering keyphrase search engine documents particular keyphrase attached returned user 
summary keyphrases provide powerful means sifting large numbers documents focusing relevant 
unfortunately small fraction documents keyphrases assigned authors provide keyphrases explicitly instructed manually attaching keyphrases craig nevill manning department computer science rutgers university piscataway new jersey usa existing documents laborious task 
ways automating process artificial intelligence specifically machine learning techniques interest 
different ways approaching problem keyphrase assignment keyphrase extraction 
keyphrase assignment known text categorization dumais assumed potential appear predefined controlled vocabulary categories 
learning problem find mapping documents categories set training documents accomplished training classifier category documents belong positive examples rest negative ones 
new document processed classifiers assigned categories classifiers identify positive example 
second approach keyphrase extraction pursue restrict set possible keyphrases selected vocabulary 
contrary phrase new document identified extracted keyphrase 
set training documents machine learning determine properties distinguish phrases keyphrases ones 
turney describes system keyphrase extraction genex set parametrized heuristic rules fine tuned genetic algorithm 
genetic algorithm optimizes number correctly identified keyphrases training documents adjusting rules parameters 
turney compares genex straightforward application standard machine learning technique bagged decision trees breiman concludes gives superior performance 
shows genex generalizes collections trained collection journal articles successfully extracts keyphrases web pages different topic 
important feature training genex new collection computationally expensive 
briefly summarizes kea keyphrase extraction algorithm goes show generalizes genex collections 
con trast genex employ specialpurpose genetic algorithm training keyphrase extraction known naive bayes machine learning technique 
training quicker 
main finding performance boosted significantly kea trained documents domain keyphrases extracted 
allows capitalize speedy training deriving domainspecific models practical original lengthy genetic algorithm approach 
section summarizes kea algorithm keyphrase extraction shows performs comparably genex domain independent setting 
section explains simple enhancement enables kea exploit collection specific information keyphrases shows addition boosts performance large collection computer science technical reports 
main findings summarized section 
keyphrase extraction naive bayes keyphrase extraction classification task phrase document keyphrase problem correctly classify phrase categories 
machine learning provides shelf tools kind situation 
machine learning terminology phrases document examples learning problem find mapping examples classes keyphrase keyphrase 
machine learning techniques automatically generate mapping provided set training examples examples class labels assigned 
context simply phrases identified keyphrases 
learning method generated mapping training data applied unlabeled data words extract keyphrases new documents 
generating candidate phrases phrases document equally keyphrases priori 
order facilitate learning process phrases appear eliminated set examples learning scheme 
input text split phrase boundaries punctuation marks dashes brackets numbers 
non alphanumeric characters apart internal periods numbers deleted 
kea takes subsequences initial phrases length candidate phrases 
eliminates phrases stopword 
deletes phrases consist merely proper noun 
step words case folded stemmed iterated lovins stemmer lovins stemmed phrases occur document removed 
building model far shown candidate phrases generated 
conventional machine learning terms phrases useless properties attributes important 
plausible attributes immediately spring mind number words phrase number characters position phrase document experiments attributes turned useful discriminating keyphrases non keyphrases tf idf score phrase distance document phrase appearance 
explain attributes computed naive bayes model domingos pazzani built 
tf idf score phrase standard metric information retrieval 
designed measure specific phrase document tf idf pr phrase document 
probability equation estimated counting number times phrase occurs document second counting number documents training corpus contain excluding 
distance phrase document calculated number words precede appearance divided number words document 
resulting feature number represents proportion document preceding phrase appearance 
attributes real numbers 
naive bayes learning method process numeric attributes assuming example normally distributed 
obtained better results discretizing attributes prior applying learning scheme domingos pazzani 
indicates normal distribution appropriate application 
discretization numeric attribute ranges resulting new attribute treated nominal value represents range values original numeric attribute 
kea uses fayyad irani discretization scheme minimum description length principle 
recursively splits attribute intervals stage minimizing entropy class distribution 
stops splitting total cost encoding discretization class distribution reduced 
naive bayes learning scheme simple application bayes formula 
assumes attributes case tf idf distance independent counters initialized avoid logarithm zero 
class 
making assumption probability phrase keyphrase discretized tf idf value discretized distance pr key pr key pr key pr key pr pr key probability keyphrase tf idf score pr key probability distance pr key priori probability phrase keyphrase pr normalization factor pr key lie zero 
probabilities estimated reliably counting number times corresponding event occurs training data 
shown naive bayes accurate classification method independence assumption correct domingos pazzani 
argued attributes tf idf distance close independent class 
implies naive bayes close optimum classification method application reason performs better learning methods investigated 
particular performs better bagged decision trees show section extracting keyphrases kea uses procedure described generate naive bayes model set training documents keyphrases known typically author provided 
resulting model applied new document keyphrases extracted 
kea computes tf idf scores distance values phrases new document procedure described discretization obtained training documents 
attributes computed knowing phrase keyphrase 
naive bayes model applied phrase computing estimated probability keyphrase 
result list phrases ranked associated probabilities 
assuming user wants extract keyphrases kea outputs highest ranked phrases 
special cases addressed order achieve optimum performance 
phrases equal probability quite happen due discretization ranked tf idf score pre discretized form 
second phrase subphrase phrase accepted keyphrase ranked higher deleted list top ranking phrases output 
experimental results evaluated kea different document collections author assigned keyphrases 
cri naive bayes implementation kea initializes counts 
success extent kea produces stemmed phrases authors 
method evaluation turney directly compare kea performance results 
comparison genex compared kea genex experimental settings turney 
involves training testing journal articles 
setting articles training journal international academy hospitality research journal computer aided molecular design behavioral brain sciences testing 
second setting documents training fips web pages testing 
table shows number correctly identified author provided keyphrases fifteen top ranking phrases output extraction algorithms 
extraction algorithms represented genex bagged decision trees quinlan turney kea kea bagged trees naive bayes learning scheme 
results methods turney 
third scheme standard kea algorithm described 
fourth bagged trees discretization naive bayes standard pre post processing done kea 
variation kea computationally expensive factor 
turney bagged trees perform universally worse genex experimental settings table journal fips cutoff difference statistically significant 
kea performs worse genex better differences statistically significant level test 
kea performs better turney case significantly worse genex 
conclude genex kea perform level kea slightly worse difference statistically significant datasets 
statistically significant result poor performance turney observed case 
difference turney findings bagged trees deserves explanation 
turney uses attributes distance tf idf 
performs post processing genex author assigned keyphrases course deleted documents kea 
compare kea document collections turney access corpus email messages contains confidential information 
get number correctly identified keyphrases turney precision figures multiplied cutoff employed fifteen 
experimental conditions turney results kea results training testing cutoff genex kea kea journal journal journal fips table experimental results different extraction algorithms remove subphrases perform better 
appear main differences way applying 
changing amount training data interesting question kea performance scales amount training data available 
order investigate performed experiments large collection computer science technical reports cstr new zealand digital library www nzdl org 
documents cstr fairly noisy partly source files extracted automatically postscript 
contain average fewer keyphrases collections 
keyphrase extraction domain difficult corpuses 
potential ways corpus documents available influence kea performance fresh data 
training documents computing discretization attributes corresponding counts naive bayes model 
essential documents keyphrases assigned learning method needs labeled examples 
second document corpus supports learning process phrase document frequency calculated deriving tf idf score 
case documents need labeled 
experiments showed performance improvement gained increasing number documents compute document frequencies 
illustrate effect training set size shows kea performance independent set test documents 
plots number correct keyphrases fifteen phrases extracted number documents training files 
error bars give confidence intervals derived training kea different training sets size 
independent documents calculating document frequencies particular experiment 
seen documents training little gained increasing number 
documents performance improvement 
results show kea performance close optimum training documents words labeled documents sufficient push performance limit 
section demonstrates case domain specific information exploited learning extraction process 
case larger amounts labeled training documents prove beneficial 
subject area training documents investigate extent models formed kea transfer subject domain 
collection journal articles described collections web pages turney aliweb nasa keyphrases assigned 
basic procedure train collections test producing combinations 
collection chose training documents random rest testing journal articles aliweb nasa 
training documents compute document frequencies entire keyphrase assignment model training documents 
journal articles test set ran experiments training testing division turney test set comprising articles journal 
shows average number correct keyphrases returned keyphrases retrieved twelve cases 
represent combination training testing sets drawn collections represents test set training sets number correct keyphrases phrases output phrases output number training documents performance cstr corpus different numbers training files error bars show confidence intervals articles journal training set different composition journal training set cases 
bars give confidence intervals mean performance test sets 
dark bars highlight cases test training documents drawn population 
note cases shown show statistically significant difference results training sets confidence intervals overlap substantially 
cases slightly better results obtained test training documents drawn population dark bars 
fourth case corresponds turney experiment anomalous regard suggests test set case journals differs character training set case journals 
test set produces considerably statistically significantly better results set trained 
authors specified keyphrases papers average 
conclude little difference training testing documents come different subject areas certainly differences statistically significant test sets small safe side recommend documents subject area possible 
finding leads idea directly exploiting fact different keyphrases different subject areas 
explore kea 
exploiting domain specific information simple modification kea enables exploit collection specific knowledge likelihood particular phrase keyphrase 
necessary keep track number times candidate aliweb aliweb nasa journals nasa journals aliweb nasa journals aliweb training documents effect training documents subjects different test documents nasa journals aliweb nasa journals phrase occurs keyphrase training documents information form additional third attribute learning extraction processes 
extending model phrase document new attribute call keyphrase frequency simply number times occurs author assigned keyphrase training documents new attribute integer valued discretize procedure section 
making naive bayes assumption independence discretized value keyphrase frequency attribute probability phrase keyphrase pr key pr key pr key pr key pr key pr pr key probability keyphrase discretized keyphrase frequency value probabilities discussed section pr key estimated reliably counting number times corresponding event occurs training data 
new attribute sense documents keyphrases extracted come domain training documents 
reason bias extraction algorithm choosing phrases occurred keyphrases training 
order information provided new attribute necessary re train extraction algorithm keyphrases extracted documents different topic 
training time critical factor 
kea generate model new set training documents far faster genex simple learning methods employs 
asymptotically spends time sorting attribute values discretization 
sorting log number values kea log number phrases contained training documents 
collection journal articles section kea needs minutes training genex needs approximately hours turney 
note times measured different computers 
kea implemented combination perl java genex written expect difference pronounced systems compared level footing 
experimental evaluation empirically verified exploiting domain specific information increases number correctly extracted keyphrases performing experiments cstr collection described 
order isolate effect genex kea extract keyphrases quickly model generated 
number correct keyphrases size keyphrase frequencies size kea particularly suited making information trained quickly new domain 
experiments large collection computer science technical reports confirm modification significantly improves quality keyphrases extracted 
making knowledge keyphrases frequently particular domain additional advantage extracted keyphrases uniform 
property easier categorize documents keyphrases extracted beneficial topic search document clustering 
number phrases output performance cstr corpus different numbers phrases output 
results keyphrase frequencies keyphrase frequency corpuses documents 
error bars confidence intervals 
changing number documents computing keyphrase frequency attribute separate set documents keyphrase frequency corpus counting number times phrase occurs keyphrase 
actual set training documents held constant 
set test documents experiment 
shows number correctly identified keyphrases varies amount domain specific information available 
worst performance obtained information words keyphrase frequency attribute excluded model 
performance improves documents included keyphrase frequency corpus 
results shown corpuses size 
error bars included case keyphrase frequency corpus corpus size give confidence intervals number keyphrases correctly extracted test document show possible get significantly better results exploiting domain specific information keyphrases 
contrast results section pays documents author assigned keyphrases available fact moving documents improves results remarkably 
evaluated simple algorithm keyphrase extraction called kea naive bayes machine learning method shown performs comparably state art represented turney genex algorithm 
proceeded show kea performance boosted exploiting domainspecific information likelihood keyphrases 
acknowledgments peter turney making document collections drafts available john cleary independently suggesting keyphrase frequency attribute 
breiman leo breiman 
bagging predictors 
machine learning 
domingos pazzani domingos pazzani 
optimality simple bayesian classifier zero loss 
machine learning 
dumais dumais platt heckerman sahami 
inductive learning algorithms representations text categorization 
proceedings th international conference information knowledge management 
fayyad irani usama fayyad irani 
multi interval discretization attributes classification learning 
proceedings th international joint conference artifical intelligence pages 
morgan kaufmann 
lovins lovins 
development stemming algorithm 
mechanical translation computational linguistics 
quinlan quinlan 
programs machine learning 
morgan kaufmann los altos ca 
turney turney 
learning extract keyphrases text 
technical report erb national research council institute information technology 
