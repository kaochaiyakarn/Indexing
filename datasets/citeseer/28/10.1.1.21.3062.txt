document clustering word clusters information bottleneck method naftali tishby school computer science engineering interdisciplinary center neural computation hebrew university jerusalem israel email cs ac il novel implementation introduced information bottleneck method unsupervised document clustering 
joint empirical distribution words documents cluster words obtained word clusters maximally preserve information documents 
resulting joint distribution contains original information documents sparse noisy 
procedure cluster documents information word clusters preserved 
find word clusters capture mutual information set documents find document clusters preserve information word clusters 
tested procedure document collections subsets taken standard newsgroups corpus 
double clustering procedure improves distributional clustering methods examined 
document clustering long important problem information retrieval 
early works suggested improving efficiency increasing effectiveness document retrieval systems grouping documents clusters cf 

document clustering put forward important tool web search engines navigating browsing document collections distributed retrieval :10.1.1.136.7906:10.1.1.34.6233
types clustering studied context information retrieval systems clustering documents basis distributions words occur documents clustering words distributions documents occur see depth review 
propose new method document clustering combines approaches single information theoretic framework 
introduced principle termed information bottleneck method simple idea 
empirical joint distribution variables variable compressed mutual information preserved possible 
new document representation clustering procedure obtain desired document clusters 
main advantage double clustering procedure lies significant reduction inevitable noise original occurrence matrix due high dimension 
reduced matrix word clusters robust providing better reflection inherent structure document corpus 
main concern method discovers inherent structure 
evaluating procedure effectiveness ir system evaluate method standard labeled corpus commonly evaluate supervised text classification algorithms :10.1.1.136.7906
way circumvent bias caused specific ir system 
addition view correct labels documents objective knowledge inherent structure dataset 
specifically newsgroups dataset collected lang contains articles evenly distributed usenet discussion groups :10.1.1.22.6286
corpus generated subsets measured clustering performance correlation obtained document clusters original newsgroups 
main concern method discovers inherent structure 
evaluating procedure effectiveness ir system evaluate method standard labeled corpus commonly evaluate supervised text classification algorithms :10.1.1.136.7906
way circumvent bias caused specific ir system 
addition view correct labels documents objective knowledge inherent structure dataset 
specifically newsgroups dataset collected lang contains articles evenly distributed usenet discussion groups :10.1.1.22.6286
corpus generated subsets measured clustering performance correlation obtained document clusters original newsgroups 
compared clustering algorithms including single stage information bottleneck algorithm ward method complete linkage standard tf idf term weights 
double clustering information bottleneck method significantly superior examined algorithms 
addition double clustering procedure improved performance algorithms experiments 
general framework applied agglomerative greedy hierarchical clustering algorithm 
algorithm starts trivial partitioning jxj singleton clusters cluster contains exactly element step merge components current partition single new component way locally minimizes loss mutual information 
merger formally defined equations jx yj yj yj decrease mutual information due merger defined information values merger respectively 
little algebra see 
djs yj yj functional djs jensen shannon js divergence see defined djs dkl dkl case fp fp yj yj yj yj js divergence non negative equals zero arguments identical :10.1.1.127.9167
upper bounded symmetric metric 
note merger cost interpreted multiplication weight merged elements distance djs yj yj introducing information optimization criterion resulting similarity measure directly emerges analysis 
input joint probability distribution output partition clusters initialization construct jxj calculate djs yj yj loop jxj find indices fi jg minimized merge update gg update costs pseudo code agglomerative information bottleneck algorithm 
algorithm simple step perform best possible merge merge clusters minimize 
algorithm simple step perform best possible merge merge clusters minimize 
provide pseudo code agglomerative procedure 
clustering methods general framework agglomerative clustering algorithm applied similarity criteria construct algorithms purposes comparison 
common natural distance measure probability distributions norm variational distance defined jp js divergence norm distance measure satisfying metric properties including triangle inequality 
approximates js divergence close distributions :10.1.1.127.9167
second clustering algorithm distributional similarity measure 
yj yj note multiplication weight clusters merged crucial 
strong bias assigning objects cluster 
algorithms motivated probability theory third comparison algorithm standard ward method euclidean distance 
addition describe datasets experiments standard ir corpus newsgroups corpus 
evaluation method general measuring clustering effectiveness trivial issue 
standard measures average distance data points candidate class centroids needs furthermore mentioned clear distance measure 
previous document clustering performance clustering measured terms effectiveness information retrieval system 
specifically clustering results reorder list documents returned ir system assumption user able select clusters highest relevant document density :10.1.1.136.7906:10.1.1.27.8901:10.1.1.34.6233
problems evaluation method 
noted empirical tests shown users fail choose best cluster time :10.1.1.136.7906:10.1.1.34.6233
second generating document collections results obtained ir system queries sensitive specific ir system queries may result unclear bias datasets 
third evaluation method measure directly inherent structure document corpus revealed clustering procedure provide indirect estimates ir system performance 
standard measures average distance data points candidate class centroids needs furthermore mentioned clear distance measure 
previous document clustering performance clustering measured terms effectiveness information retrieval system 
specifically clustering results reorder list documents returned ir system assumption user able select clusters highest relevant document density :10.1.1.136.7906:10.1.1.27.8901:10.1.1.34.6233
problems evaluation method 
noted empirical tests shown users fail choose best cluster time :10.1.1.136.7906:10.1.1.34.6233
second generating document collections results obtained ir system queries sensitive specific ir system queries may result unclear bias datasets 
third evaluation method measure directly inherent structure document corpus revealed clustering procedure provide indirect estimates ir system performance 
overcome problems propose simple solution essentially estimating document clustering performance tools supervised text classification tasks 
words interest measuring clustering process reveal inherent structure document collection standard labeled text classification corpus construct datasets labels clear objective knowledge reflecting dataset inherent structure 
overcome problems propose simple solution essentially estimating document clustering performance tools supervised text classification tasks 
words interest measuring clustering process reveal inherent structure document collection standard labeled text classification corpus construct datasets labels clear objective knowledge reflecting dataset inherent structure 
addition adopt accuracy measure supervised learning algorithms needs 
specifically measure clustering performance accuracy contingency table obtained clusters real document categories 
datasets constructed different document subsets newsgroups corpus collected lang :10.1.1.22.6286
corpus contains articles evenly distributed usenet discussion groups usually employed evaluating supervised text classification techniques :10.1.1.42.7488:10.1.1.42.7488:10.1.1.48.6710
groups similar topics groups discuss different issues concerning computers 
addition pointed schapire singer documents corpus group people tend post articles multiple newsgroups :10.1.1.48.6710
real clusters inherently fuzzy 
words interest measuring clustering process reveal inherent structure document collection standard labeled text classification corpus construct datasets labels clear objective knowledge reflecting dataset inherent structure 
addition adopt accuracy measure supervised learning algorithms needs 
specifically measure clustering performance accuracy contingency table obtained clusters real document categories 
datasets constructed different document subsets newsgroups corpus collected lang :10.1.1.22.6286
corpus contains articles evenly distributed usenet discussion groups usually employed evaluating supervised text classification techniques :10.1.1.42.7488:10.1.1.42.7488:10.1.1.48.6710
groups similar topics groups discuss different issues concerning computers 
addition pointed schapire singer documents corpus group people tend post articles multiple newsgroups :10.1.1.48.6710
real clusters inherently fuzzy 
tests different randomly chosen subsets corpus 
specifically measure clustering performance accuracy contingency table obtained clusters real document categories 
datasets constructed different document subsets newsgroups corpus collected lang :10.1.1.22.6286
corpus contains articles evenly distributed usenet discussion groups usually employed evaluating supervised text classification techniques :10.1.1.42.7488:10.1.1.42.7488:10.1.1.48.6710
groups similar topics groups discuss different issues concerning computers 
addition pointed schapire singer documents corpus group people tend post articles multiple newsgroups :10.1.1.48.6710
real clusters inherently fuzzy 
tests different randomly chosen subsets corpus 
details subsets table 
pre processing included ignoring file headers lowering upper case characters ignoring words contained digits non alpha numeric characters 
method shown provide document classification accuracy newsgroups dataset fully unsupervised manner training labels 
argue results demonstrate validity information bottleneck method power double clustering procedure problem 
agglomerative procedure time complexity jxj suitable large datasets 
techniques proposed dealing issue employed 
example somewhat similar clustering procedure baker mccallum finding word clusters supervised text categorization :10.1.1.42.7488
avoid high complexity suggested fixed small number clusters step similar clusters joined new word added new cluster 
pointed distributional clustering useful significant reduction feature dimensionality minor decrease classification accuracy 
contrast shows unsupervised document classification word clusters efficient leads significant improvement performance 
double clustering procedure stage process 
note similarity accuracy averaged results 

cluster analysis applications 
academic press 
baker mccallum :10.1.1.42.7488
distributional clustering words text classification acm sigir 
brown della pietra lai mercer 
class gram models language 
computational linguistics pages cover thomas 
advances neural information processing nips pages 

adaptive cluster browsing incrementally expanded queries effects 
acm sigir pages 
hearst pedersen :10.1.1.34.6233
cluster hypothesis scatter gather retrieval results 
acm sigir pages 
hofmann 
probabilistic latent semantic indexing 
acm sigir pages 
tokunaga 
cluster text categorization comparison category search strategies 
acm sigir pages 
lang :10.1.1.22.6286
learning filter netnews 
proc 
th int 
conf 
proc 
th int 
conf 
machine learning pages 
lin :10.1.1.127.9167
divergence measures shannon entropy 
ieee transactions information theory 
mccallum andrew 
bow toolkit statistical language modeling text retrieval classification clustering 
salton 
developments automatic text retrieval 
science vol 
pages 
schapire singer :10.1.1.48.6710
boostexter system multiclass multi label text categorization 
schutze silverstein :10.1.1.27.8901
projections efficient documents clustering acm sigir pages 
silverstein pedersen 
science vol 
pages 
schapire singer :10.1.1.48.6710
boostexter system multiclass multi label text categorization 
schutze silverstein :10.1.1.27.8901
projections efficient documents clustering acm sigir pages 
silverstein pedersen 
constant time clustering arbitrary corpus subsets 
acm sigir pages 

xu croft 
cluster language models distributed retrieval 
acm sigir pages 
zamir etzioni :10.1.1.136.7906
web document clustering feasibility demonstration 
acm sigir pages 
