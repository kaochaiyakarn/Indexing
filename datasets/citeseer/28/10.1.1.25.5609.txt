reasoning intentions uncertain domains michael wooldridge simon parsons department computer science university liverpool liverpool zf fm wooldridge csc liv ac uk 
design autonomous agents situated real world domains involves dealing uncertainty terms dynamism observability non determinism 
types uncertainty combined real time requirements application domains imply agent capable ectively coordinating reasoning 
situated belief desire intention bdi agents need ecient intention reconsideration policy de nes computational resources spent reasoning deliberating intentions resources better spent object level reasoning action 
presents implementation policy modelling intention reconsideration partially observable markov decision process pomdp 
motivation pomdp implementation intention reconsideration processes similar properties functions demonstrate 
situated belief desire intention bdi agents need ecient intention reconsideration policy de nes computational resources spent reasoning deliberating intentions resources better spent object level reasoning action 
presents implementation policy modelling intention reconsideration partially observable markov decision process pomdp 
motivation pomdp implementation intention reconsideration processes similar properties functions demonstrate 
approach achieves better results existing intention reconsideration frameworks demonstrated empirically 
key problems design belief desire intention bdi agents selection intention reconsideration policy :10.1.1.34.3464
policy de nes circumstances bdi agent expend computational resources deliberating intentions 
wasted ort deliberating intentions unnecessarily undesirable deliberating deliberation fruitful 
currently consensus exactly agent reconsider intentions 
current approaches problem simply dictate commitment level agent ranging cautious agents reconsider intentions possible opportunity bold agents reconsider fully executed current plan 
providing background information bdi framework problem intention reconsideration arises 
section discuss markov decision framework approach builds implementation intention reconsideration pomdp 
section empirically evaluate model agent testbed 
section describe related 
belief desire intention agents idea applying concepts beliefs desires intentions agents originates bratman rao george :10.1.1.55.3666
conceptual model bdi agency developed wooldridge parsons :10.1.1.44.5649
model distinguishes main data structures agent belief set intention set agent beliefs represent information agent environment may partial incorrect 
intentions seen states airs agent committed bringing 
regard intention simple unconditional plan behaviour agent generated main components state function updates agent beliefs basis observation environment deliberation function constructs set appropriate intentions basis agent current beliefs intentions action function selects executes action ultimately satis es agent intentions meta level control function sole purpose decide pass control deliberation action subsystems 
section discuss markov decision framework approach builds implementation intention reconsideration pomdp 
section empirically evaluate model agent testbed 
section describe related 
belief desire intention agents idea applying concepts beliefs desires intentions agents originates bratman rao george :10.1.1.55.3666
conceptual model bdi agency developed wooldridge parsons :10.1.1.44.5649
model distinguishes main data structures agent belief set intention set agent beliefs represent information agent environment may partial incorrect 
intentions seen states airs agent committed bringing 
regard intention simple unconditional plan behaviour agent generated main components state function updates agent beliefs basis observation environment deliberation function constructs set appropriate intentions basis agent current beliefs intentions action function selects executes action ultimately satis es agent intentions meta level control function sole purpose decide pass control deliberation action subsystems 
control cycle agent begins updating beliefs state function basis current beliefs meta level control function decides pass control deliberation function case agent computational resources deliberating intentions action subsystem case agent acts 
intentions seen states airs agent committed bringing 
regard intention simple unconditional plan behaviour agent generated main components state function updates agent beliefs basis observation environment deliberation function constructs set appropriate intentions basis agent current beliefs intentions action function selects executes action ultimately satis es agent intentions meta level control function sole purpose decide pass control deliberation action subsystems 
control cycle agent begins updating beliefs state function basis current beliefs meta level control function decides pass control deliberation function case agent computational resources deliberating intentions action subsystem case agent acts 
general rule thumb agent meta level control system pass control desires directly contribute analytical discussion intention reconsideration left conceptual bdi model 
decision clari ed :10.1.1.44.5649
deliberation function agent change intentions result time spent deliberating wasted 
investigating choice rationally eciently main motivation 
consider agents operate isolation situated environments environment denotes external agent 
set propositions denoting environment variables 
agent wastes ort deliberating intentions unnecessarily 
agent deliberate necessary agent wrong intentions 
reward acting worth state agent intends reach reward deliberation worth state currently structure reward agrees intuition agent eventually receives reward correct intentions receives reward wrong intentions receives direct reward deliberation 
respect intuition mention real reward deliberation indirectly de ned nature pomdps expected worth states agent correct intentions 
intentions resist reconsideration agent prefers action deliberation implementation reward structure favour action rewards equivalent :10.1.1.55.3666
illustrative purposes consider simple deterministic mdp 
shows gridworld agent move right left stay current location 
agent current location indicated del del del del currently intention act act act del act act act act act act act act del del del del del act act del act act del act act del fig 

solving bdi pomdp means obtaining optimal intention reconsideration policy possible state agent nd policy tells agent act deliberate 
main contribution approach gives founded means establishing domain dependent optimal reconsideration strategy 
agent programmed domain independent strategy uses compute domain dependent strategy line executes line 
empirical research meta level reasoning aimed ecient intention reconsideration best knowledge involved agents domain dependent strategies 
important deciding reconsider intentions computationally cheap compared deliberation process just ecient deliberate possible moment :10.1.1.44.5649
pomdp determine reconsideration policy satis es criterion clearly distinguishes design time computation computing policy run time computation executing policy 
recognise design time problem computing policy hard problem corresponds general problem solving pomdps attempt solve problem 
computation concerns run time computation model merely boils looking current state executing action assigned state act deliberate 
computationally cheap operation suitable run time execution 
explanation observation solving tileworld domain delivers optimal domain dependent reconsideration strategy optimal bdi pomdp policy lets agent deliberate hole appears closer intended hole path intended hole intended hole disappears 
kinny george concluded best agent reconsider closer hole appears intended hole disappears 
observation see bdi pomdp agent able determine plan commitment run time depending state environment 
ability contributes increasing agent level autonomy pushes choice commitment level design time run time 
experimental results con rm results obtained previous investigations selecting intention reconsideration strategy agent ectiveness level commitment decrease dynamism planning cost increases cost acting decreases dynamism planning cost increases :10.1.1.34.3464:10.1.1.25.4448:10.1.1.25.4448
focus previous research investigating ectiveness xed strategies di erent environments aim investigation illustrate applicability bdi pomdp model 
kinny george included empirical results agent occurrence certain events environment see figures respectively :10.1.1.34.3464
results best agent reconsider agent observes closer hole appears intended hole disappears mentioned 
implemented strategy agent testbed yielded identical results 
observation see bdi pomdp agent able determine plan commitment run time depending state environment 
ability contributes increasing agent level autonomy pushes choice commitment level design time run time 
experimental results con rm results obtained previous investigations selecting intention reconsideration strategy agent ectiveness level commitment decrease dynamism planning cost increases cost acting decreases dynamism planning cost increases :10.1.1.34.3464:10.1.1.25.4448:10.1.1.25.4448
focus previous research investigating ectiveness xed strategies di erent environments aim investigation illustrate applicability bdi pomdp model 
kinny george included empirical results agent occurrence certain events environment see figures respectively :10.1.1.34.3464
results best agent reconsider agent observes closer hole appears intended hole disappears mentioned 
implemented strategy agent testbed yielded identical results 
observed agent bdi pomdp model performs better agent mentioned xed strategy realistic planning cost 
having compared results results xed strategies conclude mentioned ect agent adopts strategy delivers maximum ectiveness 
results best agent reconsider agent observes closer hole appears intended hole disappears mentioned 
implemented strategy agent testbed yielded identical results 
observed agent bdi pomdp model performs better agent mentioned xed strategy realistic planning cost 
having compared results results xed strategies conclude mentioned ect agent adopts strategy delivers maximum ectiveness 
context exible strategies compare results results ectiveness alternative exible strategy discrete deliberation scheduling explored :10.1.1.25.4448
main draw comparing results strategies empirical outcomes analogous 
comparing graphs result graphs observe agent ectiveness generally higher bdi pomdp model compare graphs cost acting graphs see cost acting lower discrete deliberation model :10.1.1.25.4448
bdi pomdp model level commitment constant bdi pomdp agent decision mechanism depends predictions appearances holes 
discussion formalisation intention reconsideration process bdi agents theory pomdp planning 
observed agent bdi pomdp model performs better agent mentioned xed strategy realistic planning cost 
having compared results results xed strategies conclude mentioned ect agent adopts strategy delivers maximum ectiveness 
context exible strategies compare results results ectiveness alternative exible strategy discrete deliberation scheduling explored :10.1.1.25.4448
main draw comparing results strategies empirical outcomes analogous 
comparing graphs result graphs observe agent ectiveness generally higher bdi pomdp model compare graphs cost acting graphs see cost acting lower discrete deliberation model :10.1.1.25.4448
bdi pomdp model level commitment constant bdi pomdp agent decision mechanism depends predictions appearances holes 
discussion formalisation intention reconsideration process bdi agents theory pomdp planning 
motivation formalism bdi agents real world application domains reconsider intentions eciently order ective possible 
important reconsideration happens autonomously agent commitment tasks changes depending environment changes 
bdi agent concerned management simple plans time intelligence located meta reasoning capabilities planning capabilities 
shown agent designed formalism able dynamically change commitment plans run time current state environment 
experiments described assumed environment fully observable completely accessible order compare results previous results 
agent achieves better performance existing planning frameworks level plan commitment imposed agent design time 
model advantage deliberation scheduling model computes substantial part reconsideration strategy design time computations deliberation scheduling run time :10.1.1.25.4448
contrast deliberation scheduling model supposedly exible changing reconsideration strategy run time 

boutilier dean hanks 
decision theoretic planning structural assumptions computational leverage 
