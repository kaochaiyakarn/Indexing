recognizing temporal trajectories condensation algorithm michael black allan xerox palo alto research center coyote hill road palo alto ca computer science university toronto toronto ont black parc xerox com jepson vis toronto edu recognition human gestures image sequences important enables host human computer interaction applications 
describes incremental recognition strategy extension condensation algorithm proposed isard blake eccv 
gestures modeled temporal trajectories estimated parameter time case velocity 
condensation algorithm incrementally match gesture models input data 
method demonstrated example augmented office whiteboard user simple hand gestures grab regions board print save recognition human gestures image sequences important challenging problem enables host human computer interaction applications 
dominant paradigm involves computing low level feature information frame derived motion model matching 
parameters low level features evolve time form temporal trajectories 
recognition typically performed trajectories hidden markov models hmm dynamic time warping dtw 
dtw explicitly matches stored trajectory input trajectory allowing local deformations curves produce best match 
hmm typically maintain detailed trajectory information break trajectories discrete states represented mean covariance parameters state 
advantage hmm provide probabilistic framework gesture recognition 
goal combine best features dtw hmm seek recognition method capture detailed trajectory information dtw probabilistic framework hmm method probabilistically matches model trajectories input trajectories line fashion 
proposed method exploits condensation conditional density propagation algorithm proposed isard blake extended 
variety parameters estimated match model trajectory input trajectory 
match parameters represented discrete random samples 
distribution evolves time input data changes 
condensation algorithm uses stochastic dynamics random sampling techniques track distribution evolves 
authors simple temporal model represented mean covariance velocity tracked object 
impoverished temporal model authors demonstrated simple forms gesture recognition 
method proposed allows powerful temporal models recognize complex gestures 
experiments gesture data gathered computer vision system observing office whiteboard 
describe vocabulary gestures user perform whiteboard extend functionality 
system recognize sorts gestures line handwriting 
section describe extended condensation algorithm 
section presents whiteboard application experimental results 
condensation algorithm goal take set match input trajectory see 
models taken discretely sampled curves may continuous phase parameter max representing current position model 
model values position vector ofn values stored discrete curve linearly interpolated phase input trajectory observation vector zt zt zt 
parameters need estimate match model data integer indicating model matched position phase model aligns model data timet amplitude parameter scale model vertically match data third ieee int 
conf 
automatic face gesture recognition april nara japan ieee models model scale amplitude input trajectories state scale rate match 
time st goal incrementally trajectory models input data 
zt ni zt rate parameter scale model time dimension 
define state vector parameters 
pw find state rise observed zt zt 
zt vector observations particular trajectory time 
define probability observation state stas size temporal window backwards time want curves match 
estimates standard deviation 
value model interpolated time scaled 
iis simply probability cumulative probability py max min max py states states selected state psi biased illustrated 
sample states constructing cumulative probability distribution sampling uniformly 
uniform distribution gives corresponding state 
definition forp construct discrete representation entire probability distribution possible states 
initially sample uniformly form note prediction initial phase wards small values 
compute probability 
order 
gives normalize probabilities sum producing weights samples 
condensation algorithm uses information sample states weights predict entire probability distribution time instant 
traditional tracking methods kalman filtering approach deal ambiguous data distribution possible matches propagated time 
algorithm stages selection prediction updating 
outline construct new probability distribution distribution timet 
selection choose state timet probability distribution timet 
current probability distribution states choose states predict 
done constructing cumulative cumulative probabilities third ieee int 
conf 
automatic face gesture recognition april nara japan ieee sample distribution uniformly choosing value zero 
find start cut pause statet selected propagation time instant 
start cut sampling method states selected estimated probability 
avoid getting trapped local maxima deal sudden changes input data randomly choose fraction states tjs replaced random initial guesses initialized described 
typically take random guesses print save samples 

prediction statet predict parameters new quit clear gestures 
parameters depth 
note simulated annealing method search start wheren normal distribution represent high values equation lower time 
uncertainty prediction 
note prediction finite state extension viewed sampling probability distribution 
time change extended method allow compound mod time extend method allow transition els hidden markov models probabilities take new state 
state hmm trajectory models 
letm prediction ift model recognized state initialized described 
parameters draw samples predicted value parameter allowed range 
interesting note tool locally searching parameter space 
thought diffusion parameters blur probability distribution predicted time 
provide way performing local search state 
allow local deformations trajectories moving window 

updating new state evaluate probability parent state consists set event model transition states 
prediction step tis chosen sampling transition probabilities 
new random state chose parent uniform distribution 
initial event type defined parent 
remaining parameters chosen described 
gesture models test condensation trajectory recognition algorithm consider problem recognizing set gestures context augmented whiteboard 
number generated data equa authors looked problem scanning whiteboards tion 
likelihood zero threshold high resolution mosaicing interacting return step new prediction 
repeat board making hand drawn marks 
look fixed number tries 
prediction problem recognizing dynamic gestures 
isard cient probability generate random initial sample 
blake condensation algorithm recognize states generated compute simple drawing gestures 
extension temporal normalized weights equation repeat allows complex gestures recognized 
process time instant 
scenario user wants perform com note condensation pick gesture physical icon depth breadth search 
distinctive color easy locate match input data method resorts uni track 
motion tracked color form sampling breadth 
probability mass histogram tracker real time 
tracking performed centered set parameters resources roughly hz 
tracking rate varies slightly re automatically spent explore neighborhood sample locations fixed time instants lin third ieee int 
conf 
automatic face gesture recognition april nara japan ieee ear interpolation 
horizontal vertical velocity gesture recognition 
define set gestures useful purpose see start start gesture tells system pay attention start recognizing gestures 
gesture simply waving motion similar person get human attention 
cut region cut gesture indicate region whiteboard scanned possibly higher resolution 
gesture consists primitive gestures pauses arbitrary duration 
refer complete cut gesture parent gesture events 
cut gesture begins upside check mark cut gesture marks upper left corner scanning region 
cut user moves relatively straight line lower right corner region 
cut gesture cut image region user right side check mark 
print send cut region printer user gesture letter 
save save region file user gesture letter 
clear sharp diagonal motion clears current stored whiteboard region 
think cut region stored 
gesture thought throwing cut region away 
quit user mark wish gesture recognition function 
stationary addition gesture models represent stationary 
construct models gestures gesture performed approximately half dozen times trajectories saved 
gesture training trajectories manually aligned mean trajectories computed 
standard deviation mean trajectory computed curve 
trajectory models gesture shown 
initial alignment curves performed dtw 
addition computing just mean curve compute eigen curves 
experiments primitive events max min allow scaling max min temporal scaling 
standard deviations model trajectories taken 
diffusion parameters example cut gesture 
user gesture 
image right region cut larger image 
ut taken temporal window 
illustrates performance cut gesture 
bright red block gesture 
black dots represent tracked locations 
image right region cut algorithm 
shows horizontal vertical velocities function time 
input data incrementally match gesture models 
estimated value horizontal vertical velocity taken estimated velocity sample statet 
represents fit models data shown 
shows probability individual event function time 
similarly shows probability composite parent gestures 
probability particular event taken sum normalized probabilities figures show probability events parent gestures completed respectively 
probability sample considered completed estimated phase parameter time instant maximum phase event parent 
figures show clear spikes individual events cut cut cut 
similarly spike parent cut gesture ends 
ifp consider recognized 
cut region original image carry state time tand max third ieee int 
conf 
automatic face gesture recognition april nara japan ieee velocity velocity velocity velocity time time time cut cut cut start time velocity velocity velocity velocity time time time time clear save print gesture models 
temporal trajectories horizontal solid vertical broken velocity 
primitive event ended 
information gesture determine stationary mark points located 
enclosed region pixels extracted 
multiple gesture experiment consider complex experiment involves series gestures cut save clear cut print clear 
input curves represent samples horizontal vertical velocities top 
sequence addition actual gestures user moves gestures 
possible event types possible gestures 
input data frame matched models data explained model 
normalized probabilities bottom show non gesture motions receive high normalized probabilities expect 
probability gestures completed successfully recognize completion gestures shown bottom 
described extension condensation algorithm performs probabilistic matching model curves input curves 
method allows recognition complex gestures possible standard condensation algorithm 
described application method gesture recognition office whiteboard scanner 
note condensation algorithm perform recognition gesture trajectories algorithm extended perform tracking 
currently method significantly slower real time 
blake isard demonstrated realtime versions similar algorithm suggests method suitable real time recognition appropriate optimizations 
current segmented aligned training data provided 
transition probabilities set hand 
method parameters worth exploring learning techniques generate models automatically 

francois rard providing real time tracking discussions whiteboards gesture interfaces 
coutaz rard crowley 
coordination perceptual processes computer mediated communication 
int 
conf 
auto 
face gesture recog pp 

isard blake 
contour tracking propagation conditional density 
eccv pp 
cambridge uk 
isard blake 
mixed state condensation tracker automatic model switching 
iccv pp 
mumbai india jan 
ishii ullmer 
tangible bits seamless interfaces people bits atoms 
proc 
chi 
stafford fraser 
video augmented environment 
proc 
chi 
szeliski 
image mosaicing tele reality applications 
ieee pp 
fl 
yacoob black 
parameterized modeling recognition activities 
iccv pp 
mumbai india jan 
third ieee int 
conf 
automatic face gesture recognition april nara japan ieee estimated velocity model probability probability cut input velocity velocity cut velocity velocity stationary velocity velocity cut cut clear print save start time time time probability parent probability cut print save start clear time probability events cut stationary cut cut time probability parent probability cut print save start clear time cut gesture 
input horizontal vertical velocity estimated horizontal vertical velocity probability event type probability parent gesture type probability current state completion event probability current state completion parent 
input velocity velocity velocity probability cut recognized gestures cut save save clear clear cut print cut print clear clear cut clear print save time multiple gesture experiment 
top input horizontal vertical velocity bottom probability parent gesture type 
frame number recognized gesture completes 
