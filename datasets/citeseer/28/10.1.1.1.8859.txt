multiagent systems survey machine learning perspective peter stone manuela veloso labs research computer science department park ave room carnegie mellon university florham park nj pittsburgh pa research att com veloso cs cmu edu www research att com www cs cmu edu mmv appear autonomous robotics volume number 
july 
distributed artificial intelligence dai existed subfield ai decades 
dai concerned systems consist multiple independent entities interact domain 
traditionally dai divided sub disciplines distributed problem solving dps focuses information management aspects systems branches working common goal multiagent systems mas deals behavior management collections independent entities agents 
survey mas intended serve field organizational framework 
difficult problem splitting single agent time different parts task solves 
choice multiagent system single agent system mas simpler option 
course domains naturally approached omniscient perspective global view central ized control parallel actions possible action uncertainty decker 
single agent systems cases 
multiagent systems useful fundamental problems social sci ences life sciences cao including intelligence decker :10.1.1.16.3358
wei put deeply inevitably coupled interaction wei 
fact proposed best way develop intelligent machines start creating social machines 
theory socio biological theory primate intelligence evolved need deal social interactions 
reasons mas apply generally arguments favor multi robot systems particular 
fact remaining dimensions prominent article degree heterogeneity major mas dimension methods distributing control appear major issues 
parunak taxonomy mas application perspective 
perspective important characteristics mas system function agent architecture degree heterogeneity reactive vs deliberative system architecture communication protocols human involvement 
useful contribution dimensions divided agent system characteristics 
overviews dai mas include lesser durfee durfee bond gasser :10.1.1.40.5782
existing surveys specific multi robot systems 
dudek pre sented detailed taxonomy multiagent robotics dimensions including robot size various communication parameters unit processing 
cao taxonomy problems solutions axes group architecture resource conflicts ori cooperation learning geometric problems 
specifically consider competitive multi robot scenarios 
point view system designer characteristics domain important 
moving agent categorization field range domain characteristics considered 
relevant domain characteristics include number agents amount time pressure real time domain new goals arrive dynamically cost communication cost failure user involvement environmental uncertainty 
characteristics self explanatory need mention 
respect cost failure example domain high cost failure air traffic control rao georgeff :10.1.1.37.7970
hand directed improvisation domain considered hayes roth low cost failure 
domain entertainment agents accept improvisation suggestions 
idea agents afraid mistakes just words flow hayes roth 
multiagent systems include humans agents 
reactive vs deliberative agents designing agent system important determine sophisticated agents rea 
reactive agents simply retrieve pre set behaviors similar reflexes maintaining internal state 
hand deliberative agents behave thinking searching space behaviors maintaining internal state predicting effects actions 
issues techniques reactive vs deliberative agents local global perspective modeling agents states affect homogeneous non communicating learning opportunities reactive behaviors formation maintenance 
balch arkin deliberative behaviors pursuit :10.1.1.110.3459
levy rosenschein mixed reactive deliberative behaviors 
sahota rao georgeff local knowledge better :10.1.1.37.7970:10.1.1.37.7970
limited recursive modeling method rmm 
durfee don model just pay attention reward 
hand deliberative agents behave thinking searching space behaviors maintaining internal state predicting effects actions 
issues techniques reactive vs deliberative agents local global perspective modeling agents states affect homogeneous non communicating learning opportunities reactive behaviors formation maintenance 
balch arkin deliberative behaviors pursuit :10.1.1.110.3459
levy rosenschein mixed reactive deliberative behaviors 
sahota rao georgeff local knowledge better :10.1.1.37.7970:10.1.1.37.7970
limited recursive modeling method rmm 
durfee don model just pay attention reward 
schmidhuber stigmergy 
goldman rosenschein holland learning behaviors foraging homing mataric enable actions sensor data agent sensor data table issues techniques learning opportunities homogeneous mas reflected literature :10.1.1.29.5356
sahota rao georgeff local knowledge better :10.1.1.37.7970:10.1.1.37.7970
limited recursive modeling method rmm 
durfee don model just pay attention reward 
schmidhuber stigmergy 
goldman rosenschein holland learning behaviors foraging homing mataric enable actions sensor data agent sensor data table issues techniques learning opportunities homogeneous mas reflected literature :10.1.1.29.5356
line reactive deliberative agents somewhat agent internal state cer reactive bases actions predicted actions agents deliberative 
describe system extreme mix reactive deliberative reasoning 
balch arkin homogeneous reactive non communicating agents study formation maintenance autonomous robots 
robots goal move military formation diamond column wedge 
agents assume act service goals 
game theoretic techniques find equilibrium points decide act 
agents clearly deliberative considering search actions simply retrieving 
existing systems techniques mix reactive deliberative behaviors 
example oasis system reasons reactive follow goal directed plans rao georgeff :10.1.1.37.7970
example reactive deliberation sahota 
name implies mixes reactive deliberative behavior agent reasons reactive behavior follow constraint choose actions rate hz 
reactive deliberation developed robotic soccer platform 
reactive deliberation explicitly designed mas designed real time control dynamic environments extendible multiagent scenarios 
issues existing techniques deal learning opportunities described summarized table 
issues techniques heterogeneous non communicating benevolence vs competitiveness learning opportunities stable vs evolving agents arms race credit assignment modeling goals actions knowledge credit assignment competitive scenarios resource management interdependent actions behaviors blend team social conventions prediction actions roles dynamic role assumption game theory iterative play 
mor rosenschein sandholm crites minimax 
littman competitive evolution 
belew haynes sen grefenstette stone deduce intentions abilities observation :10.1.1.47.4109
huber durfee wang autoepistemic reasoning ignorance 
model team individual role 
tambe social reasoning depend goal game theory 
demazeau gas deal paradox resource worse 
issues techniques communication raises issues addressed multiagent systems 
cases addressed literature heterogeneous communicating agents 
section consider limited number issues addressed homogeneous communicating agents indicated table 
communication related issues addressed section devoted communicating multiagent systems 
issues techniques distributed sensing communication content homogeneous communicating mas learning opportunities active sensing query propagation distributed traffic mapping moukas maes state vs goal communication balch arkin stone veloso communicate table issues techniques homogeneous communicating multiagent systems reflected literature :10.1.1.110.3459
distributed sensing cooperative distributed vision project aims construct monitor broad visual scene dynamic dimensional scene understanding multiple cameras stationary mobile robots 
example consider problem tracking individual car cameras mounted urban intersections 
car leaves camera range enters needs way identifying images representing car probably looks different cases driving away camera 
project combines active sensing ability shift attention area higher uncertainty interest communication multiple sensing agents 
issues techniques heterogeneous communicating agents choose communicate cases choose homogeneous minimize heterogeneity issues discussed pre scenarios apply 
studied issues communication protocols theories commitment 
discussed context heterogeneous non communicating mas scenario issue benevolence vs competitiveness complicated current con text 
issues existing techniques deal described summarized table 
issues techniques heterogeneous communicating learning opportunities understanding planning communicative acts evolving language benevolence vs competitiveness effects speech acts global dynamics negotiation communication utility resource management schedule coordination commitment utility commitment decommitment collaborative localization changing shape size language protocols kif genesereth fikes kqml finin cool :10.1.1.54.8601
barbuceanu fox grounding meaning shared experience 
jung zelinsky legacy systems integration 
jennings wittig language learning 
grand cliff speech acts 
barbuceanu fox grounding meaning shared experience 
jung zelinsky legacy systems integration 
jennings wittig language learning 
grand cliff speech acts 
cohen levesque steiner learning social behaviors :10.1.1.29.6467
mataric reasoning :10.1.1.29.5356
rosenschein zlotkin sandholm lesser multiagent learning :10.1.1.30.9028
tan wei training agents functions track driving :10.1.1.55.8066
minimize need training 
jung zelinsky legacy systems integration 
jennings wittig language learning 
grand cliff speech acts 
cohen levesque steiner learning social behaviors :10.1.1.29.6467
mataric reasoning :10.1.1.29.5356
rosenschein zlotkin sandholm lesser multiagent learning :10.1.1.30.9028
tan wei training agents functions track driving :10.1.1.55.8066
minimize need training 
potter cooperative evolution 
jennings wittig language learning 
grand cliff speech acts 
cohen levesque steiner learning social behaviors :10.1.1.29.6467
mataric reasoning :10.1.1.29.5356
rosenschein zlotkin sandholm lesser multiagent learning :10.1.1.30.9028
tan wei training agents functions track driving :10.1.1.55.8066
minimize need training 
potter cooperative evolution 
bull contract nets electronic commerce 
grand cliff speech acts 
cohen levesque steiner learning social behaviors :10.1.1.29.6467
mataric reasoning :10.1.1.29.5356
rosenschein zlotkin sandholm lesser multiagent learning :10.1.1.30.9028
tan wei training agents functions track driving :10.1.1.55.8066
minimize need training 
potter cooperative evolution 
bull contract nets electronic commerce 
sandholm lesser market systems :10.1.1.42.237
tan wei training agents functions track driving :10.1.1.55.8066
minimize need training 
potter cooperative evolution 
bull contract nets electronic commerce 
sandholm lesser market systems :10.1.1.42.237
huberman clearwater bayesian learning negotiation model 
zeng sycara market methods distributed constraints 
parunak generalized partial global planning gpgp 
decker lesser lesser learning choose coordination methods :10.1.1.32.8351
sandholm lesser market systems :10.1.1.42.237
huberman clearwater bayesian learning negotiation model 
zeng sycara market methods distributed constraints 
parunak generalized partial global planning gpgp 
decker lesser lesser learning choose coordination methods :10.1.1.32.8351
sugawara lesser query response information networks 
sycara division independent tasks 
parker internal social collective role commitments 
castelfranchi commitment states potential pre actual planning states 
sycara division independent tasks 
parker internal social collective role commitments 
castelfranchi commitment states potential pre actual planning states 
haddadi belief desire intention bdi model oasis 
rao georgeff bdi commitments intentions :10.1.1.37.7970
rao georgeff locker room agreements :10.1.1.37.7970:10.1.1.37.7970
stone veloso coalitions 
zlotkin rosenschein shehory kraus sandholm lesser fusing uncertain sensor data 
fox inter component communication robots 
parker internal social collective role commitments 
castelfranchi commitment states potential pre actual planning states 
haddadi belief desire intention bdi model oasis 
rao georgeff bdi commitments intentions :10.1.1.37.7970
rao georgeff locker room agreements :10.1.1.37.7970:10.1.1.37.7970
stone veloso coalitions 
zlotkin rosenschein shehory kraus sandholm lesser fusing uncertain sensor data 
fox inter component communication robots 
table issues techniques learning opportunities heterogeneous communicating multiagent systems reflected literature 
fox inter component communication robots 
table issues techniques learning opportunities heterogeneous communicating multiagent systems reflected literature 
understanding communicating multiagent systems particularly domains agents built different de signers set language protocol agents interacting 
independent aspects protocols information content message format coordination conventions 
existing protocols levels kif content genesereth fikes kqml mes sage format finin cool coordination barbuceanu fox :10.1.1.54.8601
lot research done refining communication protocols 
challenge arises symbolic communication agents making sure sym grounded similarly internal representations different agents 
approach related social conventions discussed section possible shared past experiences ground symbolic representation 
technique heterogeneous multi robot vacuum cleaning task jung zelinsky 
agents ability grow learn including simple verb object language interactions human user agents environment 
planning communicative acts agent transmits information agent effect just action 
planning framework define preconditions effects communicative acts 
combined model agents effect communication act alter agent belief state agent agents 
theory communication action called speech acts cohen levesque steiner :10.1.1.29.6467:10.1.1.29.6467
mataric adds learning dimension idea speech acts 
starting foraging behavior men mataric agents learn choose set social behaviors includes broadcasting listening mataric 
learning extended reinforcement received direct rewards obtained agent rewards obtained agents 
communication planning action possibility arises communicating tion order satisfy particular goal 
consider case agent truthful decommitment hoping agent decommit 
situations agents consider communications believe rosenschein zlotkin 
benevolence vs competitiveness studies involving competitive agents described heterogeneous non communicating sce see section 
current scenario examples competitive agents 
similar tan multiagent rl pursuit domain tan wei competing learners :10.1.1.55.8066
agents compete earn right control single system wei 
highest bidder pays certain amount allowed act receives reward results action 
learning approach time benevolent agents explore interesting idea having agent teach agent communication 
starting trainer moderate expertise task learner rewarded mimicking trainer 
negotiation drawing inspiration competition human societies researchers designed negotiating multiagent systems law supply demand 
contract nets framework smith agents goals self interested limited reasoning resources 
bid accept tasks agents perform tasks proper resources subcontract agents 
agents pay contract tasks shop lowest bidder 
multiagent issues arise contract nets sandholm lesser :10.1.1.42.237:10.1.1.42.237
similar spirit implemented multiagent system controls air temperature different rooms building huberman clearwater 
person set thermostat temperature 
depending actual air temperature agent room tries buy hot cold air room excess 
time agent sell excess air current temperature rooms 
zeng sycara study competitive negotiation scenario agents bayesian learning techniques update models bids counter bids negotiation process 
system parunak uses market methods distributed constraint prob lems 
designers different points supply chain negotiate characteristics design buying selling characteristics propagating resulting constraints 
resource management example multiagent resource management design characteristics desired agent may consume resources 
similarly generalized partial global planning gpgp allows heterogeneous agents post con straints commitments task time local schedulers coordinate aid centralized agent decker lesser :10.1.1.32.8351
proposed general multiagent ar gpgp contains components local agent scheduling multiagent coordination organizational design detection diagnosis lesser heterogeneous communicating multiagent system applied diagnosis local area network agents learn choose different coordination strategies current situation sugawara lesser 
sophisticated coordination methods require fewer network time resources may lead tasks failing executed redundant actions multiple agents 
retsina sycara uses classes heterogeneous communicating agents deliver information response specific user queries information networks 
retsina able satisfy information requests multiple users searching multiple information sources considering network constraints resource limitations information agents 
agents means ends analysis plan goals terms com opportunities 
conducted model called belief desire intention bdi 
bdi popular technique modeling agents 
agents domain knowledge beliefs goals desires modeled intentions goals currently trying achieve methods trying achieve 
bdi model build system air traffic control oasis rao georgeff implemented testing parallel human operators retain full control airport sydney australia :10.1.1.37.7970:10.1.1.37.7970:10.1.1.37.7970
aircraft represented controlling agent deals global sequencing agent 
oasis mixes reactive deliberative actions agents break planned sequences coming situations demand immediate reaction 
agents control beliefs desires commitments regarding intentions 
locker room agreements stone veloso form commitment communi agents 
predators prey pursuit domain complex simulate real world 
robotic soccer game real world complexities retained 
key aspect soccer complexity need agents control control ball passive part environment 
overview robotic soccer played real robots simulator 
robotic soccer system system sahota :10.1.1.125.9772
sahota built vs version game 
robotic issues studied real world instantiation issues studied simulation 
particularly simulator purpose soccer server developed noda pictured 
simulator realistic ways players vision limited players communicate posting blackboard visible players players controlled separate processes player teammates opponents player limited stamina actions sensors noisy play occurs real time 
foundations producing natural language commentary real time input soccer system andre ai research related soccer 
soccer analyzed human soccer games 
looking triggers events player running ball passed soccer aims announce important events redundancy 
robotic soccer introduced interesting promising domain ai research vision interface conference june mackworth 
dynamite working robotic soccer sys tem sahota described time :10.1.1.125.9772:10.1.1.125.9772
ground breaking system robotic soccer served inspiration basis authors robotic soccer domain dynamite test bed designed capable supporting robots team done vs scenario 
uses overhead camera color tion provide global sensory information robots 
dynamite introduce decision making strategy called reactive deliberation choose hard wired behaviors sa 
subsequently rl approach high level sensory predicates choose hard wired behaviors ford 
asada developed robots equipped board sensing capabilities 
robots learning easy missions rl training technique learn hit stationary ball goal 
contribution construction state action spaces reduce complexity learning task asada 
opposed action dependent features tpot rl create feature space prior learning states clustered learning best action take state 
contribution combination low level behaviors shooting avoiding opponent learned rl asada uchibe :10.1.1.44.9137
building learned behaviors different behavior levels layered learning previously learned control strategies produce new replaces original 
minimax learning markov games applied simulated soccer game littman :10.1.1.135.717
version domain simpler soccer server having states actions hidden information 
player team moves grid world ball possessed players 
contribution construction state action spaces reduce complexity learning task asada 
opposed action dependent features tpot rl create feature space prior learning states clustered learning best action take state 
contribution combination low level behaviors shooting avoiding opponent learned rl asada uchibe :10.1.1.44.9137
building learned behaviors different behavior levels layered learning previously learned control strategies produce new replaces original 
minimax learning markov games applied simulated soccer game littman :10.1.1.135.717
version domain simpler soccer server having states actions hidden information 
player team moves grid world ball possessed players 
minimax players learn optimal probabilistic policies past ball 
authors conducted machine learning experiments simulator closely sim sahota simulates dynamite robots mentioned 
version domain simpler soccer server having states actions hidden information 
player team moves grid world ball possessed players 
minimax players learn optimal probabilistic policies past ball 
authors conducted machine learning experiments simulator closely sim sahota simulates dynamite robots mentioned 
memory learning allow player learn shoot pass ball stone veloso :10.1.1.1.5959
neural networks teach player shoot moving ball particular parts goal stone veloso :10.1.1.1.5959
training small region field agent able learn successfully time approach moving ball score areas field 
experiments served basis initial learning experiments soccer server stone veloso :10.1.1.1.5959
early learning experiment soccer server player learned shoot pass matsubara :10.1.1.57.1412
player team moves grid world ball possessed players 
minimax players learn optimal probabilistic policies past ball 
authors conducted machine learning experiments simulator closely sim sahota simulates dynamite robots mentioned 
memory learning allow player learn shoot pass ball stone veloso :10.1.1.1.5959
neural networks teach player shoot moving ball particular parts goal stone veloso :10.1.1.1.5959
training small region field agent able learn successfully time approach moving ball score areas field 
experiments served basis initial learning experiments soccer server stone veloso :10.1.1.1.5959
early learning experiment soccer server player learned shoot pass matsubara :10.1.1.57.1412
agent bases decision positions ball goaltender teammate 
authors conducted machine learning experiments simulator closely sim sahota simulates dynamite robots mentioned 
memory learning allow player learn shoot pass ball stone veloso :10.1.1.1.5959
neural networks teach player shoot moving ball particular parts goal stone veloso :10.1.1.1.5959
training small region field agent able learn successfully time approach moving ball score areas field 
experiments served basis initial learning experiments soccer server stone veloso :10.1.1.1.5959
early learning experiment soccer server player learned shoot pass matsubara :10.1.1.57.1412
agent bases decision positions ball goaltender teammate 
competition years research reported section confirmed potential robotic soccer ai research domain justified value having large scale competitions research perspective 
starting competitions held pre robocup continuing great deal robotic soccer related research 
memory learning allow player learn shoot pass ball stone veloso :10.1.1.1.5959
neural networks teach player shoot moving ball particular parts goal stone veloso :10.1.1.1.5959
training small region field agent able learn successfully time approach moving ball score areas field 
experiments served basis initial learning experiments soccer server stone veloso :10.1.1.1.5959
early learning experiment soccer server player learned shoot pass matsubara :10.1.1.57.1412
agent bases decision positions ball goaltender teammate 
competition years research reported section confirmed potential robotic soccer ai research domain justified value having large scale competitions research perspective 
starting competitions held pre robocup continuing great deal robotic soccer related research 
dedicated robotic soccer workshops held conjunction competitions scientific 
tpot rl stone mentioned learned layers layered learning implementation 
learning approaches described learn portions agent behavior 
aspects created manually 
contrast entirely learned soccer behaviors created 
veloso extension grid world soccer game described littman :10.1.1.135.717
square grid locations world defined lattice 
action space increased geometric constraints altered 
added complexity necessitates development generalized trees allow agents learn successful policies veloso 
possible agents learn straight sensors actuators littman simulation smaller state space soccer server agents hidden state 
added complexity necessitates development generalized trees allow agents learn successful policies veloso 
possible agents learn straight sensors actuators littman simulation smaller state space soccer server agents hidden state 
robocup robocup competitions included team created genetic program ming koza 
cases goal learn entirely agent sensors actuators soccer server 
attempt luke eventually scaled successful team created manually created low level skills :10.1.1.36.1280
year darwin united andre teller entered entirely learned team 
survey description field mas 
designed serve tion people unfamiliar field organizational framework system designers 
framework series increasingly complex powerful scenarios 
