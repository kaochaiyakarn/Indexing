multimodal system processing mobile environments sharon oviatt department computer science engineering oregon graduate institute science technology walker road oregon usa oviatt cse ogi edu www cse ogi edu major goal multimodal system design support robust performance achieved unimodal recognition technology spoken language system 
years multimodal literatures speech pen input speech lip movements begun developing relevant performance criteria demonstrating reliability advantage multimodal architectures 
studies utterances processed multimodal pen voice system collected mobile stationary 
new data collection infrastructure developed including instrumentation worn user roaming researcher field station multimodal data logger analysis tool tailored mobile research 
speech recognition stand failed mobile system results confirmed stable multimodal architecture decreased error rate 
furthermore findings replicated different types microphone technology 
order connect user hand held display observation station nearly real time visual replica devised user interactions monitor observation station 
accomplish screen replication hand held pc equipped wireless local area network card base station connected hub observation station 
resulted hand held pc observation station private network eliminated traffic minimized delays transmitting ink 
addition copies quickset user interface run user station observation station 
basically quickset agents send data adaptive agent architecture facilitator agent multicasts agents requesting type data permits multiple user interface replicas perform actions :10.1.1.32.1015:10.1.1.32.1015
result capabilities researcher able observe user actions performed 
observing user electronic ink context hand held interface voice transmission needed researcher hear user corresponding speech 
support user speech fed audio output vcr small wireless microphone transmitter sr backpack 
multimodal data logger display system processing multimodal utterance summarized set best lists signal noise snr estimates collected mobile corresponding receiver located near observation station fed audio signal headphones worn researcher 
supports map applications ranging real estate health care selection community rescue operations military simulations 
example quickset interface community fire flood management tasks shown 
vocabulary spoken words types gestures conjunction tasks studies 
grammatical combinations possible speech gesture vocabulary unique multimodal utterances available 
quickset integrates spoken pen input natural language processing multimodal integration subsystems distributed agent architecture :10.1.1.32.1015
system architectural flow processing components illustrated 
process multimodal input quickset uses joint interpretation strategy parallel processing spoken signals 
processing best lists generated speech gesture input signals natural language parsing completed 
produce final multimodal interpretation natural language processing involves statistically ranked unification spoken gestural semantic interpretations :10.1.1.15.398
quickset integrates spoken pen input natural language processing multimodal integration subsystems distributed agent architecture :10.1.1.32.1015
system architectural flow processing components illustrated 
process multimodal input quickset uses joint interpretation strategy parallel processing spoken signals 
processing best lists generated speech gesture input signals natural language parsing completed 
produce final multimodal interpretation natural language processing involves statistically ranked unification spoken gestural semantic interpretations :10.1.1.15.398
process best lists produced illustrated 
detailed description quickset system see :10.1.1.15.3658
dependent measures users multimodal commands scored measures outlined human performance error technical problem occurred 
mutual disambiguation rate mutual disambiguation subject md calculated percentage integrated commands rank correct lexical choice multimodal best list mm lower average rank correct lexical choice speech gesture best lists minus number commands rank correct choice higher multimodal best list average rank speech gesture best lists multimodal information processing flow handling signal language processing parallel speech gesture input 
process multimodal input quickset uses joint interpretation strategy parallel processing spoken signals 
processing best lists generated speech gesture input signals natural language parsing completed 
produce final multimodal interpretation natural language processing involves statistically ranked unification spoken gestural semantic interpretations :10.1.1.15.398
process best lists produced illustrated 
detailed description quickset system see :10.1.1.15.3658
dependent measures users multimodal commands scored measures outlined human performance error technical problem occurred 
mutual disambiguation rate mutual disambiguation subject md calculated percentage integrated commands rank correct lexical choice multimodal best list mm lower average rank correct lexical choice speech gesture best lists minus number commands rank correct choice higher multimodal best list average rank speech gesture best lists multimodal information processing flow handling signal language processing parallel speech gesture input 
md count mm count mm multimodal input user interface speech recognition spoken language interpretation gesture recognition gestural language interpretation multimodal integrator multimodal bridge system confirmation user md calculated signal processing level rankings speech gesture signal best lists parse level natural language processing spoken gestural parse lists 
commands included system integrated successfully contained correct lexical information speech gesture multimodal best lists 
