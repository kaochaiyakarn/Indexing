maximum entropy discrimination jaakkola ai mit edu marina ai mit edu tony jebara jebara media mit edu mit ai lab technology square cambridge ma mit media lab ames street cambridge ma august general framework discriminative estimation maximum entropy principle extensions 
calculations involve distributions structures parameters speci settings reduce relative entropy projections 
holds data separable chosen parametric class context anomaly detection classi cation labels training set uncertain incomplete 
support vector machines naturally subsumed class provide extensions 
able estimate exactly eciently discriminative distributions tree structures class conditional models framework 
preliminary experimental results indicative potential techniques 
barber williams 

gaussian processes bayesian classi cation hybrid monte carlo 
nips 
blum mitchell :10.1.1.18.3303

combining labeled unlabeled data training proceedings th annual conference computational learning theory 
chickering geiger heckerman 

