comparative study chinese text categorization methods ji ah tan lim tan school computing national university singapore kent ridge singapore comp nus edu sg kent ridge digital labs singapore org sg 
reports comparative evaluation machine learning methods chinese text categorization 
wide range methods applied english text categorization relatively studies done chinese text categorization 
people daily news corpus series controlled experiments evaluate machine learning methods nearest neighbor knn algorithm support vector machines svm adaptive resonance associative map aram terms capabilities mining categorization knowledge high dimensional sparse relatively noisy document feature vectors 
experiments reveal methods produce satisfactory performance test corpus aram exhibits marginally better generalization capability especially relatively small noisy training sets 
text categorization refers task automatically assigning multiple predefined category labels free text documents 
people daily news corpus series controlled experiments evaluate machine learning methods nearest neighbor knn algorithm support vector machines svm adaptive resonance associative map aram terms capabilities mining categorization knowledge high dimensional sparse relatively noisy document feature vectors 
experiments reveal methods produce satisfactory performance test corpus aram exhibits marginally better generalization capability especially relatively small noisy training sets 
text categorization refers task automatically assigning multiple predefined category labels free text documents 
extensive range methods applied english text categorization relatively chinese text categorization 
typical approaches chinese text categorization naive bayes nb vector space model vsm linear list square fit llsf studied theoretical basis derived information retrieval research known best classifiers :10.1.1.11.9519
addition lack publicly available chinese corpus evaluating chinese text categorization systems 
reports applications statistical machine learning methods nearest neighbor system knn support vector machines svm adaptive resonance associative map aram chinese text categorization :10.1.1.11.9519:10.1.1.50.2161
knn svm reported top performing methods english text categorization :10.1.1.11.9519
aram belongs known family predictive self organizing neural networks document classification 
text categorization refers task automatically assigning multiple predefined category labels free text documents 
extensive range methods applied english text categorization relatively chinese text categorization 
typical approaches chinese text categorization naive bayes nb vector space model vsm linear list square fit llsf studied theoretical basis derived information retrieval research known best classifiers :10.1.1.11.9519
addition lack publicly available chinese corpus evaluating chinese text categorization systems 
reports applications statistical machine learning methods nearest neighbor system knn support vector machines svm adaptive resonance associative map aram chinese text categorization :10.1.1.11.9519:10.1.1.50.2161
knn svm reported top performing methods english text categorization :10.1.1.11.9519
aram belongs known family predictive self organizing neural networks document classification 
people daily news corpus employed evaluate machine learning methods 
benchmark experiments examine compare capabilities methods mining categorization knowledge high dimensional sparse relatively noisy document feature vectors 
extensive range methods applied english text categorization relatively chinese text categorization 
typical approaches chinese text categorization naive bayes nb vector space model vsm linear list square fit llsf studied theoretical basis derived information retrieval research known best classifiers :10.1.1.11.9519
addition lack publicly available chinese corpus evaluating chinese text categorization systems 
reports applications statistical machine learning methods nearest neighbor system knn support vector machines svm adaptive resonance associative map aram chinese text categorization :10.1.1.11.9519:10.1.1.50.2161
knn svm reported top performing methods english text categorization :10.1.1.11.9519
aram belongs known family predictive self organizing neural networks document classification 
people daily news corpus employed evaluate machine learning methods 
benchmark experiments examine compare capabilities methods mining categorization knowledge high dimensional sparse relatively noisy document feature vectors 
rest article organized follows 
lexicon segmentation model contains words classes 
high precision segmentation focus 
aim compare di erent classifier performance noisy document set long errors caused word segmentation reasonably low 
select keyword features classification standard chi statistics adopted ranking metric experiments 
prior study known corpora including reuters ohsumed proven chi statistics generally outperforms feature ranking measures term strength ts document frequency df mutual information mi information gain ig :10.1.1.32.9956
keyword extraction document segmented converted keyword frequency vector tf tf 
tf tf document term frequency keyword number keyword features 
term weighting method inverse document frequency idf normalization applied frequency vector produce keyword feature vector :10.1.1.101.9086:10.1.1.101.9086
xm norm function defined vector computed log tf log number documents training set number training documents keyword occurs 
select keyword features classification standard chi statistics adopted ranking metric experiments 
prior study known corpora including reuters ohsumed proven chi statistics generally outperforms feature ranking measures term strength ts document frequency df mutual information mi information gain ig :10.1.1.32.9956
keyword extraction document segmented converted keyword frequency vector tf tf 
tf tf document term frequency keyword number keyword features 
term weighting method inverse document frequency idf normalization applied frequency vector produce keyword feature vector :10.1.1.101.9086:10.1.1.101.9086
xm norm function defined vector computed log tf log number documents training set number training documents keyword occurs 
classifiers nearest neighbor nearest neighbor knn traditional statistical pattern recognition algorithm 
studied extensively text categorization applications :10.1.1.11.9519
essence knn prediction training patterns closest unseen test pattern distance metric 
tf tf document term frequency keyword number keyword features 
term weighting method inverse document frequency idf normalization applied frequency vector produce keyword feature vector :10.1.1.101.9086:10.1.1.101.9086
xm norm function defined vector computed log tf log number documents training set number training documents keyword occurs 
classifiers nearest neighbor nearest neighbor knn traditional statistical pattern recognition algorithm 
studied extensively text categorization applications :10.1.1.11.9519
essence knn prediction training patterns closest unseen test pattern distance metric 
distance metric measures similarity normalized patterns simple distance function distance function plain euclidean distance defined 
class assignment test pattern class assignment closest training patterns 
commonly method label test pattern class instances nearest neighbors 
class assignment test pattern class assignment closest training patterns 
commonly method label test pattern class instances nearest neighbors 
specifically class index assigned test pattern argmax knn number training pattern nearest neighbor set associated class drawback knn di culty deciding optimal value 
typically determined conducting series experiments di erent values 
support vector machines support vector machines svm relatively new class machine learning techniques introduced vapnik :10.1.1.11.9519
structural risk minimization principle computational learning theory svm seeks decision surface separate training data points classes decisions support vectors selected ective elements training set 
set linearly separable points 
point belongs classes labeled 
separating hyper plane divides sides side containing points class label 

separating hyperplanes set solid lines optimal separating hyperplane bold solid line support vectors data points dashed lines 
dashed lines identify max margin 
svm problem extended linearly non separable case nonlinear case 
various quadratic programming algorithms proposed extensively studied solve svm problem :10.1.1.11.9519:10.1.1.15.9362:10.1.1.101.9086
classification svm decision training set 
simply finds side test pattern located 
property svm highly competitive compared traditional pattern recognition methods terms computational ciency predictive accuracy :10.1.1.11.9519
years joachims done research application svm text categorization :10.1.1.11.6124
svm problem extended linearly non separable case nonlinear case 
various quadratic programming algorithms proposed extensively studied solve svm problem :10.1.1.11.9519:10.1.1.15.9362:10.1.1.101.9086
classification svm decision training set 
simply finds side test pattern located 
property svm highly competitive compared traditional pattern recognition methods terms computational ciency predictive accuracy :10.1.1.11.9519
years joachims done research application svm text categorization :10.1.1.11.6124
sv light system published 
cs uni dortmund de forschung svm light svm light 
eng html benchmark experiments 
various quadratic programming algorithms proposed extensively studied solve svm problem :10.1.1.11.9519:10.1.1.15.9362:10.1.1.101.9086
classification svm decision training set 
simply finds side test pattern located 
property svm highly competitive compared traditional pattern recognition methods terms computational ciency predictive accuracy :10.1.1.11.9519
years joachims done research application svm text categorization :10.1.1.11.6124
sv light system published 
cs uni dortmund de forschung svm light svm light 
eng html benchmark experiments 
adaptive resonance associative map adaptive resonance associative map aram class predictive selforganizing neural networks performs incremental supervised learning recognition categories pattern classes multidimensional maps patterns 
training set testing set overlap containing repetitive document set 
knn experiments plain euclidean distance defined equation similarity measure 
pattern set containing varying number documents di erent values ranging tested best results reported 
odd ensure prediction equation 
svm experiments default built inductive svm parameter set sv light described detail sv light web site :10.1.1.101.9086
aram experiments parameter values learning rates contribution parameter vigilance parameters category prediction 
voting strategy aram systems trained set patterns di erent orders presentation 
classification output vectors multiple aram combined yield final prediction vector output prediction vector produced voting aram number voting 
prediction vector thresholded cut point produce binary class prediction 
