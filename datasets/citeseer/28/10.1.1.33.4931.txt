automated text categorization support vector machine james tin kwok email comp edu hk department computer science hong kong university hong kong study support vector machine text categorization 
machine learning techniques allows easy incorporation new documents existing trained system 
dimension reduction usually imperative optional 
svm adapts efficiently dynamic environments require frequent additions document collection 
empirical results reuters collection discussed 

usually linear regression linear discriminant analysis logistic regression iterative learning algorithms rocchio algorithm traditional information retrieval 
full set terms general computational problems slow convergence large matrix resultant linear model prone fitting 
dimension reduction usually required 
neural networks decision boundary text categorization problem may linear nonlinear classifiers artificial neural networks may produce better results linear models 
alleviate problem high dimensionality large network size wiener weight elimination early stopping addition dimension reduction :10.1.1.54.6608
experimental results suggest nonlinearity neural networks yield substantial gain linear models 
probabilistic models 
widely text categorization experiments 
examples include naive bayes classifier hierarchical bayesian classifiers 
techniques exception nn classifiers best static 
dynamic environments require frequent additions document collection incorporating new documents existing trained system difficult 

support vector machine continuous improvement dimension reduction techniques promising approach text categorization integrate dimension reduction classification 
support vector machine svm new machine learning technique line svm group classification problems :10.1.1.15.9362
training set input output label sigma 
svm performs mapping oe input space feature space consider case data linearly separable exists vector scalar oe oe gamma gamma elements training set 
svm constructs hyperplane oe separation positive negative examples maximized 
note hyperplane may correspond nonlinear decision surface shown optimal hyperplane minimizing kwk resultant solution written linear combination oe ff oe ff 
helps alleviate problem synonymy textual documents 
apply lsi set support vectors run svm resultant lsi representation 
sense data separable support vectors lie margins decision boundary 
contain essential features shape define boundary important patterns away 
alternatively may view svm pre processing step extract crucial subset documents lsi performed similar idea local regions :10.1.1.54.6608
improving quality resultant lsi components compared performing lsi corpus computational demand significantly reduced set support vectors usually small fraction corpus 
compared approach disciplined size subset membership determined learning process svm :10.1.1.54.6608
may data separable support vectors may lying margin decision boundary 
applicability lsi circumstances investigation 
sense data separable support vectors lie margins decision boundary 
contain essential features shape define boundary important patterns away 
alternatively may view svm pre processing step extract crucial subset documents lsi performed similar idea local regions :10.1.1.54.6608
improving quality resultant lsi components compared performing lsi corpus computational demand significantly reduced set support vectors usually small fraction corpus 
compared approach disciplined size subset membership determined learning process svm :10.1.1.54.6608
may data separable support vectors may lying margin decision boundary 
applicability lsi circumstances investigation 

mis labeled documents human errors may introduced manual process categorizing documents training set svm help locating errors 
results topics reuters data set turn linearly separable tf delta idf space 
separable listed table 
suspect text categorization data sets linearly separable 
case may explain success popularity linear techniques text categorization 
agrees observation nonlinear classifiers usually outperform linear classifiers :10.1.1.54.6608
shows micro averaged recall precision curves 
svm refers basic svm 
svm refers svm combined lsi section removal large lagrangian multipliers section 
comparison plot performance nn classifier set 
memo mit december 
vapnik 
nature statistical learning theory 
springer verlag 
wiener weigend :10.1.1.54.6608
neural network approach topic spotting 
proceedings fourth annual symposium document analysis information retrieval pages las vegas april 
yang 
expert network effective efficient learning human decisions text categorization retrieval 
