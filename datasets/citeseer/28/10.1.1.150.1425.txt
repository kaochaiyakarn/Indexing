usenix association proceedings general track usenix annual technical conference san antonio texas usa june advanced computing systems association usenix association rights reserved information usenix association phone fax email office usenix org www www usenix org rights individual papers remain author author employer 
permission granted noncommercial reproduction educational research purposes 
copyright notice included reproduced 
usenix acknowledges trademarks 
application specific delta encoding resemblance detection fred douglis ibm watson research center hawthorne ny douglis acm org objects les electronic messages web pages contain overlapping content 
numerous past research projects observed compress object relative computing differences delta encoding systems invariably required knowledge speci relationship commonly versions name different points time 
consider cases relationship determined dynamically ef ciently determining suf cient resemblance exists objects relatively large collection 
look speci examples technique web pages email les le system evaluate potential data reduction factors uence reduction 
nd delta encoding resemblance detection technique improve simple compression factor depending workload small fraction objects potentially account large portion savings 
delta encoding act compressing data object le web page relative object 
usually temporal relationship objects object exists subsequently modi ed changes represented small fraction size entire object 
naming relationship objects modi ed le name original copy 
cases identifying base version compute delta straightforward 
delta encoding particularly attractive situations information updated network limited bandwidth 
example web sites replicated higher performance availability 
bandwidth replicas limited 
example replicated mail systems 
electronic mail systems allow clients replicate copies mail messages locally 
clients may connected network phone lines limited bandwidth 
email client connected mail server arun iyengar ibm watson research center hawthorne ny ibm com slow link techniques minimize bandwidth required updates highly desirable 
environments possible identify appropriate base version take advantage delta encoding 
addresses domain objects arbitrary overlap different pairs objects relationships pairs known priori 
identify pairs suitable candidates delta encoding reduce size relative reducing storage transmission costs exchange computation 
consider application domains technique refer delta encoding resemblance detection web traf email les le system 
defer additional discussion research detailed discussion delta encoding resemblance detection appears subsection 
section describes framework analysis greater detail including metrics consider 
section presents various datasets 
section describes experiments section provides results experiments 
section discusses resource usage issues arise practical implementation 
section surveys related section summarizes describes possible 
background dif cult describe approach providing general overview delta encoding resemblance detection 
cover areas set stage combining return comprehensive comparison related 
deltas useful reducing resource requirements existing applications deltas generally fall categories storage networking 
storage stores base version le subsequent versions represented changes 
lowers storage demands le systems revision control system rcs longstanding example backup restore systems similar environ usenix association usenix annual technical conference ments 
network transmitting data known recipient avoided 
common approach case common base version known sender recipient compute delta transmit 
technique applied web traf ip level network communication domains :10.1.1.31.5701:10.1.1.32.323
extension traditional web delta encoding approach select base version nding similar identical urls 
wishes nd similar le content name large collection les 
manber devised method extracting features les contents order nd les overlapping content ef ciently 
computed hashes overlapping sequences bytes known shingles looked hashes shared different les 
manber indicated clustering similar les improved compression application technique 
broder similar approach deterministic sampling hash values dramatically reduce amount data needed le :10.1.1.24.779
approach subset features le represent le les share features common high probability signi cant content common 
common technique suppress near duplicates search engine results variations technique link level duplicate suppression le systems :10.1.1.18.8085:10.1.1.32.323:10.1.1.101.3227
technique seen systems community late refrain providing detailed description 
brie uses rabin ngerprints compute hash consecutive bytes key properties rabin ngerprints ef cient compute sliding window uniformly distributed possible values 
broder approach selecting ngerprints smallest values effectively selects random features deterministic fashion documents features common hopefully features common 
goals manber suggested features documents identify les overlap pairs overlapping les save space bandwidth 
goal assess technique generally applicable identify speci instances applicable 
second goal evaluate number parameters process size shingle amount overlap features necessary get suf ciently small delta number les similar overlap necessary get close best delta selection delta encoding algorithms parameters algorithms delta encoding contents specially formatted les zip les method bene cial metrics 
summary results bene ts application speci deltas vary depending mix content types 
example html email messages display great deal redundancy large datasets resulting deltas signi cantly smaller simply compressing data mail attachments dominated non textual data lend technique 
large les contribute total savings particularly amenable delta encoding 
application speci techniques delta encoding version zip gzip le zipping result signi cantly improve results particular le entire dataset consists les results improve just couple percent 
numerous parameters varied assessing bene ts deltas context evaluated 
results appear sensitive size shingles delta encoding algorithm reason 
extent match number features predictor delta size 
importantly multiple les match number features minimal difference best delta smallest delta obtained les average delta 
results suggest bene cial determine le maximal number matching features delta need computed 
crucial nding matching features precomputed database features les dynamically computed feature set le delta encoded far ef cient computing actual delta 
framework section describes approach problem delta encoding resemblance detection greater detail 
discuss types data considered way evaluate potential bene ts 
types data past delta encoding types data numerous environments 
interest fo usenix annual technical conference usenix association data located meaning belong single user reside single server 
earlier demonstrated potential bene ts deltas object modi ed time consider different objects exist time 
far analyzed web data primarily html email le system 
research report coauthored phong vo labs previously argued broder technique ef ciently selecting features objects determine dynamically suitable candidate serve base delta encoding 
extension proposed standard described rfc 
report described possible protocol gave statistics support utility idea practice 
case individual web clients objects large justify added overheads transmitting features comparing features client possibly computing new response client request reconstructing page client 
proposal similarity different web pages ef cient distribution new pages caches content distribution network cdn replicas case transmitting pages overheads minimized 
estimated best case bene ts web system downloading numerous pages sites single point time comparing page 
practice pages cached individual client cached cdn completely dynamic 
parallel assessing overlap content real web sites identi ed overlap content email local le system content appropriate application domain 
instant les available theory le represented delta les 
new les created encoded earlier stored les especially previous version le exist 
live le system uses approach techniques copy write counting ensure base version delta computed modi ed deleted delta longer needed 
approach ef ciently back le system delta encoding updates incremental backup entire le system compressed identifying similarity exists 
techniques useful signi cant reduction le sizes primary focus study evaluate reductions 
earlier study deltas consider regular compression basis comparison compressing object remove internal redundancy trivial :10.1.1.31.5701
analyzed datasets contents usr redhat linux pc totaling nearly gbytes data contents user mh mail repository message stored separate le possibly including mime attachments totaling mbytes data contents users lotus notes mail message bodies attachments separated distinct les 
section describes datasets detail 
evaluation metrics practical considerations noted size reduction crucial determining factor success proposal 
reduction considered relative original content relative size content traditional compression tools gzip 
considering reconstructing original requires le available favor compressed version delta encoded version marginally larger 
furthermore effect reduction dependent environment individual le encoded delta simple compression stored disk block medium gain exactly number bytes le reduced 
function number blocks taken le encoding 
instance le rounded nearest kbyte boundary shrinking le bytes bytes saves block bytes 
typically le encoded number blocks disk 
similarly reducing traf network low marginal bene ts number packets number round trips communication decreased improvement response time signi cant 
les encoded full backup web server replication bene ts directly related actual le gains rounding effects amortized entire dataset 
evaluation metrics interest including computation overheads due computing features le comparing features candidate stored les encoding delta base version selected 
extensive research making resemblance detection ef usenix association usenix annual technical conference cient enormous datasets internet search engines prototype geared assessing space reduction bene ts speed report timings :10.1.1.24.779
discuss performance issues general terms section 
space overheads system selecting base version set features able compare features large set existing les 
overhead le may bytes depending information stored turn affects quality comparison 
execution parameters number run time parameters affect performance effectiveness system 
consider size number features le creates enormous number ngerprints features representing sequences data 
broder technique selects small number small parameterizable :10.1.1.24.779
evaluated sensitivity results parameter 
require minimal fraction features match computing delta see poorer matches demonstrate bene ts 
number bytes create single feature vary 
best matches multiple les match number features exhaustive computation determine base le produces smallest delta 
fact le matching fewer features produce smaller delta matching features 
practice want consider base versions possible 
possible perform exhaustive search large datasets sampled les equal number matching features determine signi cant variance candidate base les 
interaction number features quality match 
features compared different base les distinguished nely possibly resulting smaller delta 
lastly les may produce particularly large savings relative entire dataset may contribute relatively little 
assuming les sorted savings encoding analyze les need delta encoded produce fraction total bene unzip small change le result signi cant differences compressed version le 
example copy redhat usr share dict words bytes word lines changed line abandon 
call copy words 
words words generated les kbytes difference just bytes size 
encoding differences uncompressed words words represented differences just bytes 
stark contrast words gz words gz generated kbytes 
delta encoding compressed les encoding uncompressed versions compressing result needed potential signi cant gains 
zip store arbitrarily large number les directories single compressed le comparing contents individually zip ing results single zip le similar bene ts 
assume tar need handled specially concatenates input compression 
nd hypothesis incorrect delta encoding programs tried 
datatypes effects depend mix data practice number size compressed les bene approach may data 
delta encoding algorithm parameters possible delta encoding programs 
nd signi cant differences output sizes available programs approach delta encoding report numbers korn vo :10.1.1.31.5701
delta encoding versus compression vary parameter speci es smaller delta simply compressing le delta 
delta small les potential base versions compressed version 
compression le dev null due historical reasons 
data reduction comparable gzip typically slightly worse 
identical files identical le appears multiple times dataset trivially encoded instance hash functions md 
past stud usenix annual technical conference usenix association datasets ies investigated prevalence mirrors web techniques suppressing duplicate payloads 
chose suppress duplicates consideration analysis trivially handled means le contained zip archive duplicated zip les may identical les changed content unzip procedure match identical les 
separate analyses types data web pages les le system 
lump email category general expect bene ts greater static encoding space reduction network transmission 
note datasets analyzed discussed include tables give sense variability results 
web data ideally analyze bene ts web study live implementation extended time full content traces simulate implementation 
approach effectively study delta encoding identical urls traces dif cult obtain :10.1.1.31.5701
get program download small set root web pages recursively pages linked levels 
speci cally excluded le suf xes suggested image data jpg gif focusing base pages 
partly delta encoding demonstrated ineffective different image les having name partly images change slowly html cached rst place :10.1.1.31.5701
periodic downloads speci web pages past evaluate delta encoding cross page comparisons require single snapshot large number pages 
believe pages results obtained demonstrate high degree overlap content pages site observed research due high templates creating dynamic pages 
table lists sites accessed july number pages total size 
note case yahoo download aborted mbytes downloaded offered suf cient data perform analysis unclear additional data retrieved left unchecked 
file data types le data summarized table 
scanned entire usr directory nearly unmodi ed redhat linux distribution totaling just gbytes data les 
second examined email users formats 
analysis mbytes user unix email stored individually separate les mh mail system 
remaining data came lotus notes stores message bodies attachments separate objects le document database 
studied attachments users message bodies 
experiments described section varied number parameters delta encoding resemblance detection process 
general goals determine data eliminated deltas just compression sensitive result set parameters 
particular wanted estimate minimal system get reasonable bene point diminishing returns 
general xed parameters common set 
varied parameter evaluate effect 
table lists parameters brief description default value boldface tested parameters 
parameters clustered sets rst controls pass data compute features second controls comparison features computation deltas 
cases due space constraints additional details variations parameters signi cantly affect results denoted italic text 
additional descriptions parameters section 
note min features ratio special possible compute savings number matching features compute cumulative bene number matches stage demonstrated section 
implementation details encode differences similarity performed pair perl scripts 
recursively descends set directories invokes java program compute features 
computation separate invocation java optimized 
le features computed cached separate le 
script takes precomputed set features le determines usenix association usenix annual technical conference name files 
files size mbytes delta comp yahoo yahoo com ibm ibm com masters masters com cnn cnn com com table web datasets evaluated 
delta compression percentages refer size encoded dataset relative original 
name files 
files size included excluded mbytes delta comp usr usr mh user mh directory user bod user notes mail bodies user att user notes mail attach 
user bod user notes mail bodies user att user notes mail attach 
user att user notes mail attach 
user att user notes mail attach 
table file datasets evaluated 
excluded encoded dataset relative original 
les explained text 
delta compression percentages refer size les maximum number matching features 
currently done identifying features le incrementing counters les feature common value feature hash key 
records features common point features processed les feature common sorted number matching features 
typically les match exactly features considered base versions max comparisons parameter best matches fail produce small delta poorer matches considered maximum reached 
methods optimize comparison precomputing overlap les estimation intend integrate date 
delta encoding performed set programs written pair les encoded size output cached 
occasionally delta encoding program generate delta larger compressed le larger original le 
cases minimum values 
dataset results reported listing les maximum features match number features statistics aggregated les original size size delta encoded output size output compression delta encoding dev null comparable gzip 
table example output 
rows top show dissimilar les deltas difference rows bottom greatest similarity smallest deltas 
columns show general difference size relative original le best matching les average 
characteristic common datasets 
correspondingly ures curves savings delta encoding depict average cases 
apparent anomalies table worth noting 
substantial jump size complete features match despite consistent number les showing higher average le size 
skewed large number nearly identical les resulting form letters attaching manuscripts review manuscript sent persons features large common data selected minimization process match feature 
desirable behavior may typical datasets 
second les features matching dramatically worse compression ratio data 
believe attributable types data match les great extent exhibit particularly compressibility internally repeated text usenix annual technical conference usenix association processing stage preprocessing encoding parameter description values shingle size number bytes shingle num features number features compared min size minimum size individual le include statistics bytes unzip zip les comparison gunzip gz les comparison static files encoding precludes encoding web les program program perform delta encoding exhaustive search compare les just best matches maximum number les compare max comparisons equal maximal matching features min features ratio fraction features match cumulative compute delta 
distribution maximum size delta improvement relative simple compression threshold 
table parameters evaluated 
boldface represents defaults italics represent evaluated cases reported 
matches files size mbytes compressed 
table delta encoding compression results mh directory 
percentages relative original size means deltas save thirds original size 
boldfaced numbers explained text 
table corresponds graphical results 
strings 
mime encoded compressed data attribute compressed le appear multiple messages 
analyze bene ts les encoding zipping results take approaches 
zip les contain entire directory hierarchies gzip les compress just le 
zip les create special directory contents features calculated 
assume additional bene ts compression zip taken care 
deltas delta encode le directory storing results second temporary directory zip results 
gzip les gunzip les compute usenix association usenix annual technical conference features discard uncompressed output 
time delta encode le version uncompress uncompressed version le cached reused encoding 
section discusses added bene ts approaches 
cases features les single dataset run time state resulted virtual memory image exceeded mbytes physical memory machine performing comparisons artifact perl prototype inherent methodology evidenced scale search engines resemblance detection suppress duplicates 
usr mh datasets preprocessed data separate manageable subdirectories merged results 
result les different partitions compared example le mail conferences compared le mail projects 
general spatial locality suggest best matches le mail conferences mail conferences 
subsequently validated theory rerunning script mh directories capable machine signi cant difference bene ts 
partitions subdirectories single root usr result partitions having les perform meaningful comparisons skipped subdirectories fewer les resulting small fraction les omitted listed table 
results analyses 
start bene ts different types data describe varying certain parameters impacts results 
benefits goal reduce le sizes evaluate sensitive reduction different data types amount effort expended considerations 
table gives sense results tabular form dataset particularly conducive approach shows data graphically 
plots compressed sizes delta encoded sizes original total le sizes number matching features 
possible number matching features plot total data les having number matching features maximum match 
expected features match smaller delta size 
cumulative effect shown 
graph subsequent ones label axis point shows total data size obtained particular technique compression delta encoding les maximal matching features encoded 
instance value point compressed curve value percent total data size obtained les matching le features compressed 
shows bene tis derived including les zero matches cases bene ts come compression deltas recall size delta larger delta encoding empty le compressing 
shows cumulative bene ts deltas compression static datasets usr mh data 
web datasets ibm yahoo 
graphs limited datasets order avoid cluttering overlapping lines bottom line savings datasets reported table table respectively 
different datasets show different bene ts due amount data compared nature contents 
speci cally graphs different shapes les web datasets high degrees overlap 
contributions large files graphs far emphasized effect statistics number features match 
consideration skew savings small number files contribute benefits delta encoding 
case mh dataset skew suggested statistics table showed mbytes matching features delta encoding virtually 
visualize answer question considering le particular dataset sorting bytes saved delta obtained plotting cumulative distribution savings function original les 
plots cumulative savings mh dataset fraction original data fraction files produce savings fraction bytes les 
case savings strict compression shown separate curves 
points plotted loglog scale emphasize differences small values note comp byte curve starts just axis 
results dataset clearly show signi cant skew 
example deltas les account total saved encoding bytes save data 
compression shows skew les extremely compressible 
compressed best les containing bytes save data 
degree usenix annual technical conference usenix association mh sizes feature mh cumulative sizes features total size mb original compressed maximum number matching features relative size compressed matching features total data sizes original dataset compression individual numbers matching features 
data match features le match features 
axis log scale 
cumulative bene ts 
axis shows relative size percent compressing delta encoding le 
point axis shows bene performing les match features 
effect matching features mh data 
gures graphically depict data table 
cumulative sizes multiple static datasets cumulative sizes multiple web datasets ibm comp ibm yahoo comp yahoo relative size relative size usr comp usr mh comp mh matching features matching features static datasets 
web datasets 
effect matching features cumulative datasets 
skew suggests heuristics intelligently selecting subset potential delta encoded pairs compressed les quite bene cial 
effects file blocking section referred impact size reduction rounding xed block sizes 
workloads le backups non issue moderate impact small blocks substantial impact large ones 
shows varying blocksize affects savings mh dataset 
plots cumulative savings sorted contribution accounts block rounding effects 
kbyte minimum blocksize typical unix systems fragmented le blocks reduces total possible bene delta encoding assuming rounding kbyte blocksize brings bene messages smaller kbytes 
handling compressed files section provided justi cation comparing uncompressed versions zip gzip les hypothesis tar les need special treatment 
workloads irrelevant example mh repository stored messages full usenix association usenix annual technical conference cumulative savings contribution cumulative savings contribution block size savings file comp file byte comp byte percent original files bytes obtain savings savings blocking kbyte blocks kbyte blocks percent original bytes obtain savings relative savings function cumulative bytes 
plotted log log scale 
les count relative savings assuming kbyte kbyte units 
le blocking rounding cumulative savings mh les sorted order contribution total savings 
bodies uncompressed 
attachment contain mime encoded compressed les part single le examined sophisticated extracting attachments 
fact single workload study large numbers zip gzip les bene ts including feature original data size dataset 
example user attach workload zip les saved additional case special handling 
zip les reduced third storage dominated le types 
expected directly delta encoding tar le similar tar le generate small delta individual les overlap case limited experiments 
generated delta size original tar le delta programs ibm performed similarly 
tried sample test email tar le attachments unpacked directories encode les directories 
selected delta encoded compressed sizes individual les smaller tar les delta encoding saved bytes compared simple compression individual les entire tar le compressed 
depending extends entire workload just zip gzip savings may justify added effort 
deltas versus compression default experiments assumed delta smaller just compression delta 
reasons desirable web server cached compressed version computing specialized delta request 
example consider le system backup require base le delta retrieved producing saved le compressed version larger delta consume extra storage restoring le involve retrieving delta size delta base version undoubtedly larger 
varied threshold delta compressed size increments 
shows result experiment mh dataset 
dramatic increase relative size delta encoded data higher numbers matching features cases longer usable match level 
interesting metric savings les included longer suffers shift relative size increases threshold reduced 
shingle size parameters choice shingle size reason minimal effect performance 
example shows size reduction varies shingle sizes versus bytes 
les encoded minimal matches total size reduction 
higher value min features ratio byte shingles produce smaller deltas threshold reasonable range features matching 
usenix annual technical conference usenix association mh feature threshold traditional method 
meta feature match subset regular features match exactly suggesting higher degree overlap felt appropriate 
relative size minimum size relative compression matching features effect limiting deltas fraction compressed le mh dataset 
relative size mh feature shingle size bytes shingle bytes shingle matching features effect varying shingle size bytes mh dataset 
number features number features comparisons represents tradeoff accuracy resemblance detection computation storage overheads 
extreme case manber approach computing comparing feature excellent estimate overlap les 
extreme resemblance detection just handful features 
fair amount discrimination default features considered fewer features compute savings mh dataset features 
results virtually indistinguishable cases leading features preferable due lower costs storing comparing number features 
broder described way store features compactly bytes le treating features aggregates multiple features computed resource usage system techniques ef ciently delta encode les web documents compute features objects rst aware 
cost determining features high amortized time 
system tuned perform delta encoding space critical resource store things conventional manner cpu resources bottleneck 
features bytes apiece space overhead le bytes 
large les insigni cant 
features le determined requires operations determine maximum number matching features existing les total number les 
get reasonably number matching features necessary examine features existing les 
reasonable number matching features determined examining fraction objects number objects large 
way number comparisons needed performing ef cient delta encoding bounded 
delta encoding extremely ef cient usually bottleneck extremely high bandwidth environments 
early demonstrated feasibility wireless networks showed processors order magnitude slower current machines support deltas network speeds speeds :10.1.1.31.5701
systems rsync lbfs inclusion ajtai delta encoding commercial backup system support argument limited delta encoding bandwidth 
related mogul analyzed potential bene ts compression delta encoding context :10.1.1.31.5701
delta encoding dramatically reduce network traf cases client server shared past version web page termed response 
delta available reduced network bandwidth requirements order magnitude 
traces evaluated study responses delta eligible small fraction time trace excluded binary data images 
hand resources compressible estimated compressing re usenix association usenix annual technical conference sources dynamically offer signi cant savings bandwidth transfer times factors improvement size typical 
chan woo devised method increase frequency delta eligible responses comparing resources cached resources similar urls 
assumption resources near server pieces common validated experimentally 
described algorithm comparing le les comparison typically performed context 
explain server select particular related resources practice assuming speci knowledge client cache 
believe implicit assumption approach fact limited personal proxies exact knowledge client cache case limited applicability 
similarly clustered related web pages url tried select best base version cluster computing deltas small sample 
focused caching context similar general applications described initially efcient resemblance detection methods manber broder best select base versions 
subsequently applied resemblance detection techniques scale technique larger collections 
roughly concurrent similar general approach 
largest dataset analyzed just web pages consider types data email 
possibly signi cant distinction shingle sizes bytes bytes 
obtain time repeat analyses small shingle size 
spring essentially generalized chan woo applying data sent speci communication channel resemblance detection detect duplicate sequences collection data :10.1.1.32.323
done computing ngerprints shingles selecting predetermined number zeroes low order bits deterministically selecting fraction features scanning matching shingle nd longest duplicate data sequence 
chan woo system worked close coupling clients servers sides know redundant data existed client 
addition communication channel approach requires separate cache packets exchanged past may compete browser cache applications resources 
cases suppression redundancy coarse level instance identifying entire payload identical earlier payload particular region le changed 
examples system approach include rsync popular protocol remote le copying file system lbfs 
applications identifying appropriate base version dif cult available redundancy ignored 
instance lbfs exploits similarities different versions le les 
identify similar les hashes contents blocks data block boundary usually de ned subset features spring wetherall approach features determine block boundaries indices data compared 
variable block boundaries allow change block affect neighboring blocks 
venti archival system pastiche peer peer backup system examples content de ned blocks identify duplicate content lbfs canonical example technique :10.1.1.18.8085:10.1.1.101.3227
similarly possible ensure sides network connection share single common base version 
rsync allows communicating parties ascertain dynamically blocks le contained version le receiving side 
lbfs rsync suited compressing large les long sequences unchanged bytes granularity change ner block boundaries get bene delta encoding algorithms remove redundancy large amortize overhead pointers meta data identify redundancy 
resemblance detection procedure suited delta encoding algorithm size contents data 
demonstrates ne grained deltas variety environments head head comparison lbfs rsync environments help determine approach best context 
delta encoding number applications limited general contexts encoding le earlier version le encoding les data blocks sides communication channel consistent view cached data 
generalized approach web context features web content identify appropriate base versions quanti ed potential reductions transfer sizes system 
extended manber technique single server quanti ed potential bene ts general le system speci email 
usenix annual technical conference usenix association web content substantial overlap pages single site 
consistent chan woo automatic detection common fragments pages 
web datasets considered deltas reduced total size dataset original data compared compression 
les email variability bene ts dramatic signi cant largest datasets reduced storage needs compression 
signi cant skew dataset small fraction les accounting large portion savings 
factors shingle size number features compared dramatically affect results 
particular number maximal matching features wide variation base les size resulting deltas 
created making small number changes older le new le may name old le 
cases new le delta encoded old le minimal overhead 
part datasets consider scenarios 
situations type update prevalent bene ts higher 
demonstrated potential savings implement underlying systems technology 
smaller deltas web data suggest obvious approach integrate web server cache live system time 
supporting resemblance deltas involves extra overheads protocol support affect applications backups 
interested methods reduce storage network costs email systems hope implement approach commonly mail platforms 
system scales larger datasets add heuristics ef cient resemblance detection feature computation 
evaluate additional application speci methods encoding individual elements tar les compare various delta approaches systems lbfs rsync greater depth 
acknowledgments phong vo jointly developed idea web resulting research report small amount text manuscript taken 
andrei broder extremely helpful understanding intricacies resemblance detection randal burns phong vo similarly helpful providing helping understand delta encoding software packages laurence marks guru 
ziv bar yossef sridhar rajagopalan ramaswamy provided code computing features 
people permitted analyze data including lisa amini frank andy walter 
ramesh agarwal andrei broder ron fagin chris ray jennings jason lavoie srini seshan john tracey andrew tridgell provided helpful comments ideas earlier drafts 
anonymous reviewers shepherd darrell long advice feedback 
ajtai burns fagin long stockmeyer 
compactly encoding unstructured input differential compression 
journal acm may 
gaurav banga fred douglis michael rabinovich 
optimistic deltas www latency reduction 
proceedings usenix technical conference pages january 
ziv bar yossef sridhar rajagopalan 
template detection data mining applications 
proceedings eleventh international conference world wide web pages 
acm press 
bharat broder 
mirror mirror web study host pairs replicated content 
proceedings th international world wide web conference pages may 
andrei broder :10.1.1.24.779
resemblance containment documents 
compression complexity sequences sequences 
andrei broder 
identifying ltering documents 
combinatorial pattern matching th annual symposium pages june 
mun chan thomas woo 
compaction new technique optimizing web transfer 
proceedings infocom pages 
cox murray noble :10.1.1.101.3227
pastiche making backup cheap easy 
proceedings th symposium operating systems design implementation osdi pages 
usenix december 
fred douglis anja feldmann balachander krishnamurthy jeffrey mogul 
rate change metrics live study world wide web 
usenix association usenix annual technical conference proceedings symposium internet technologies systems pages 
usenix december 
fred douglis arun iyengar phong vo 
dynamic suppression similarity web case deployable detection mechanisms 
technical report rc ibm research july 
barron david 
web express system optimizing web browsing wireless environment 
proceedings second annual international conference mobile computing networking pages 
acm november 
terence kelly jeffrey mogul 
aliasing world wide web prevalence performance implications 
proceedings th international world wide web conference may 
david korn phong vo 
engineering differencing compression data format 
proceedings usenix conference 
usenix association june 
manber 
finding similar les large le system 
proceedings usenix winter technical conference pages january 
mogul krishnamurthy douglis feldmann goland van hoff hellerstein 
delta encoding january 
rfc 
jeffrey mogul fred douglis anja feldmann balachander krishnamurthy :10.1.1.31.5701
potential bene ts delta encoding data compression 
proceedings acm sigcomm conference pages september 
muthitacharoen chen david mazieres 
low bandwidth network le system 
symposium operating systems principles pages 
zan memon torsten suel 
delta encoding compressing related web pages 
data compression conference page march 
poster 
zan memon torsten suel lov 
cluster delta compression collection les 
international conference web information systems engineering wise december 
quinlan dorward :10.1.1.18.8085
venti new approach archival storage 
proceedings usenix conference file storage technologies monterey ca 
michael rabin 
fingerprinting random polynomials 
technical report tr center research computing technology harvard university 
sridhar rajagopalan 
personal communication 
ramaswamy arun iyengar ling liu fred douglis 
techniques ef cient detection fragments web pages 
manuscript november 
neil spring david wetherall :10.1.1.32.323
technique eliminating redundant network traf proceedings acm sig comm august 
tichy 
rcs system version control 
software practice experience july 
andrew tridgell 
efficient algorithms sorting synchronization 
phd thesis australian national university 
usenix annual technical conference usenix association 
