efficient learning reactive robot behaviors neural learning approach marc joan institute informatics automation university spain eia es purpose propose neural learning approach designed online learning simple reactive robot behaviors 
approach function generalized multi layer neural network allowing continuous states actions 
algorithm uses database learning samples accelerate guarantee convergence 
neural learning function represents independent reactive adaptive behavior maps states robot control actions 
group behaviors constitutes reactive control scheme designed fulfill simple missions 
centers description neural learning behaviors showing performance underwater robot target task 
centers description neural learning behaviors showing performance underwater robot target task 
real experiments demonstrate convergence stability learning system pointing suitability online robot learning 
advantages limitations discussed 

commonly methodology robot learning reinforcement learning rl :10.1.1.32.7692
rl agent tries maximize scalar evaluation reward punishment interaction environment 
goal rl system find optimal policy maps state environment action turn maximize accumulated rewards 
rl techniques finite markov decision processes causing finite state action spaces 
main advantage rl knowledge database forms machine learning making class learning suitable online robot learning 
task hierarchical memory rl proposed 
common approach learning base learning algorithm due learning capabilities discrete domains online policy 
generalization techniques applied learning 
memory implementation proposed vision guided behavior acquisition shows state action quantification set triangular patches 
proposals combine learning neural networks nn see overview :10.1.1.34.9502
publications pointed possibility solving rl problem estimating policy function value function 
practical application controlling autonomous helicopter 
proposes neural learning approach designed online learning simple reactive robot behaviors 
approach differentiates proposals implement nn directly breaking problem finite set actions features clusters 
publications pointed possibility solving rl problem estimating policy function value function 
practical application controlling autonomous helicopter 
proposes neural learning approach designed online learning simple reactive robot behaviors 
approach differentiates proposals implement nn directly breaking problem finite set actions features clusters 
implementation known direct learning simplest way generalize nn :10.1.1.48.3256
implies learning capabilities causes instability learning optimal state action mapping 
avoid problem proposed algorithm introduces database representative learning samples state action space 
samples repeatedly nn weight update phase assuring convergence nn optimal function 
preserve real time execution behavior different execution threads learning output generation 

neural learning behaviors neural learning approach learn mapping state action spaces policy 
state space sensor information perceived robot needed behavior order accomplish goal 
action space velocity robot follow 
learning learning temporal difference algorithm see designed solve reinforcement learning problem :10.1.1.32.7692
temporal difference algorithms solve knowing transition probabilities states finite markov decision problem context dynamics robot environment known 
temporal difference methods suitable learning incrementally online robot learning 
importance online learning resides possibility executing new behaviors previous phases site manual tuning data collection offline learning 
important characteristic learning policy algorithm 
repeat current state choose action maximizes greedy action carry action world probability apply random action exploration short term reward new state max learning algorithm 
neural learning working continuous states actions usual robotics function table large required state action resolution 
cases tabular learning needs long learning time memory requirements implementation algorithm real time control architecture impractical 
neural network nn generalize states actions reduces number values stored function table set nn weights 
implementation feed forward nn backpropagation algorithm known direct learning :10.1.1.48.3256:10.1.1.32.7692
direct learning algorithm convergence proofs turned unstable tried learn behavior 
instability caused lack weight updating state action space 
optimal function learnt current state zone 
values learnt past states maintained learnt time causing instability 

arkin behavior robotics 
mit press 
schneider autonomous helicopter control reinforcement learning policy search methods ieee international conference robotics automation korea 
baird residual algorithms reinforcement learning function approximation machine learning twelfth international conference san francisco usa :10.1.1.48.3256
hybrid coordination reinforcement learning behaviors auv control ieee rsj iros hawaii usa 
zelinsky learning continuous state action spaces proc :10.1.1.34.9502
th australian joint conference artificial intelligence sydney australia 
haykin neural networks comprehensive foundation :10.1.1.32.7692
mit press 
schneider autonomous helicopter control reinforcement learning policy search methods ieee international conference robotics automation korea 
baird residual algorithms reinforcement learning function approximation machine learning twelfth international conference san francisco usa :10.1.1.48.3256
hybrid coordination reinforcement learning behaviors auv control ieee rsj iros hawaii usa 
zelinsky learning continuous state action spaces proc :10.1.1.34.9502
th australian joint conference artificial intelligence sydney australia 
haykin neural networks comprehensive foundation :10.1.1.32.7692
prentice hall nd ed 
hernandez mahadevan hierarchical memory reinforcement learning fifteenth international conference neural information processing systems denver usa 
baird residual algorithms reinforcement learning function approximation machine learning twelfth international conference san francisco usa :10.1.1.48.3256
hybrid coordination reinforcement learning behaviors auv control ieee rsj iros hawaii usa 
zelinsky learning continuous state action spaces proc :10.1.1.34.9502
th australian joint conference artificial intelligence sydney australia 
haykin neural networks comprehensive foundation :10.1.1.32.7692
prentice hall nd ed 
hernandez mahadevan hierarchical memory reinforcement learning fifteenth international conference neural information processing systems denver usa 
smart kaelbling practical reinforcement learning continuous spaces intern 
conference machine learning 
prentice hall nd ed 
hernandez mahadevan hierarchical memory reinforcement learning fifteenth international conference neural information processing systems denver usa 
smart kaelbling practical reinforcement learning continuous spaces intern 
conference machine learning 
sutton barto reinforcement learning :10.1.1.32.7692
mit press 
takahashi asada continuous valued learning vision guided behavior acquisition 
intern 
conference multisensor fusion integration intelligent systems 
