computers seeing people essa college computing gvu center georgia institute technology atlanta ga cc gatech edu www cc gatech edu exciting challenging research years building machines see 
effort expended automatic deduction structure possibly dynamic dimensional world dimensional images 
considerable progress areas object recognition image understanding scene reconstruction single multiple images 
progress coupled improvements computational power prompted new research focus making machines see people recognize interpret gestures expressions actions 
methods give machines ability see people interpret actions interact 
motivating factors examples computational methods developed applications 
people tracking simplest methods tracking people scene image differencing 
methods background image acquired person enters scene person segmented image background subtraction 
extracts silhouette moving person 
general method tracking people type background subtraction requires modeling scene set distinct classes including background class classes cover person foreground 
pfinder system uses background foreground classes distinguish foreground silhouette fixed background :10.1.1.47.9503
operation provides system background class person modeled connected set blobs foreground connected set defining class 
blob spatial color properties 
image scene pixel belong classes 
aid tracking low level description model person hands sides head highest point moving blobs 
somewhat robust methods compared simple color tracking methods computationally complex require special hardware achieve real time implementations 
finding faces important note described methods people located simply looking specific colors detection change image 
real sense person defined apriori context aid tracking 
completely different type method aimed locating people uses apriori model face features search face image 
methods features associated facial shape determine number faces scene :10.1.1.12.7580:10.1.1.110.5546:10.1.1.53.869
methods really realtime way extracting faces static complex scenes 
available computation power increases methods combined described color tracking motion change detection algorithms reduce search space discussed section 
significant advantage systems serve precursor face recognition system aims answer scene 
frame frame frame frame frame original image sequence frames 
brief overview follows 
pattern recognition methods face recognition stated earlier face recognition methods resulted significant developments various pattern recognition methods 
need suitable representation faces recognition gener ated renewed interest karhunen loeve kl expansion methods 
kl expansion principal component analysis pca methods widely pattern recognition literature 
pentland students turk moghaddam pioneered methods face recognition shown high recognition accuracy databases face images people :10.1.1.53.869
approach faces aligned treated highdimensional pixel vectors eigenvectors called eigenfaces eigenvalues computed 
alignment done automatically similar representation features eyes nose mouth 
eigenvalue decomposition allows representing probe face small number expansion coefficients recognition 
extensions methods proposed malsburg research group done extensive amounts recognition faces 
shows model analysis synthesis shows motion energy 
peak muscle actuation motion energy recognition expressions 
hardware multiple processor aid computations 
considering employing probabilistic labeling appearance methods reduce computation required detailed analysis expressions 
developed method facial tracking interactive animation faces runs real time :10.1.1.43.9981
basic idea kind method fine grained analysis subject expression store spatio temporal representation expression generic model face 
fairly simple visual measurements establish relationship image dynamic motion parameters model 
simple visual measurements appearance view feature blob motion 
measurements coupled parameters physics model interpolation process resulting real time passive observations drive model facial tracking animation system 
gesture recognition facets modeling tracking recognition human gesture body motion gestures hands faces entire body strong spatial temporal characteristics person culture specific tied linguistic basis spoken conversations meaningful right 
reason research domains vision linguistics robotics relevant automatic understanding gesture 
researchers vision community attempted automatic gesture recognition body tracking video 
efforts pattern recognition methods applied extract spatio temporal image streams recognition 
learning algorithms interpolation interpretation gestures :10.1.1.51.6538
area research successful attempts appearance view methods tracking recognition human motion 
importance time analysis recognition hand body movements resulted hidden markov models hmms recognition training views model 
example recognizes tennis shots training time sequential images different tennis shots 
starner pentland hmms recognition american sign language :10.1.1.51.6538
learning algorithms interpolation interpretation gestures :10.1.1.51.6538
area research successful attempts appearance view methods tracking recognition human motion 
importance time analysis recognition hand body movements resulted hidden markov models hmms recognition training views model 
example recognizes tennis shots training time sequential images different tennis shots 
starner pentland hmms recognition american sign language :10.1.1.51.6538
bobick shown unique way representing gesture captures repeatability variability gestures training set example trajectories gesture states 
gesture understanding requires interpretation spatio temporal patterns extracted video scene constraints imposed dynamic representation human action linguistic context action 
achieve need develop theory human action inherent computational value 
similar idea interpretation facial expressions reduced dimensional representation facial action developed causal reconstruction scene produced 
dynamic motion generators human actions extended provide higher level representation behavior activity level lower level description space time joint angles positions additional behaviors appropriate application domain 
additional behaviors sitting walking pointing dancing gesturing force address stylistic issues 
studying generated motion appearance motion extraction events video signal 
activity recognition stated previously computer vision critical mechanism creating systems interact naturally intelligently people 
addition finding tracking people recognizing computer vision techniques recognition human activities environment :10.1.1.42.4401
recognition human activities requires study dynamic relationship human motion objects scene 
exciting contributions characterizing complex motion hidden markov models hmms modeling spatio temporal characteristics motion :10.1.1.51.6538
address issue recognition human actions activities developing adaptive approach uses context means deciding appropriate representation employed recognition 
context management plays critical role process supplying maintaining discovering information relationships people objects 
studying generated motion appearance motion extraction events video signal 
activity recognition stated previously computer vision critical mechanism creating systems interact naturally intelligently people 
addition finding tracking people recognizing computer vision techniques recognition human activities environment :10.1.1.42.4401
recognition human activities requires study dynamic relationship human motion objects scene 
exciting contributions characterizing complex motion hidden markov models hmms modeling spatio temporal characteristics motion :10.1.1.51.6538
address issue recognition human actions activities developing adaptive approach uses context means deciding appropriate representation employed recognition 
context management plays critical role process supplying maintaining discovering information relationships people objects 
objects provide clues human motions anticipate making powerful tools discriminating actions activities 
building formal context model people surroundings provides architecture acquired visual data analyzed shared effectively 
essa basu darrell pentland 
modeling tracking interactive animation faces heads input video 
proceedings computer animation conference pages 
ieee computer society press june 
essa darrell pentland :10.1.1.43.9981
tracking facial motion 
proceedings workshop motion nonrigid articulated objects pages 
ieee computer society 
essa pentland 
journal optical society america 
starner 
mit wearable computing web page 
wearables www media mit edu projects wearables 
starner pentland :10.1.1.51.6538
visual recognition american sign language hidden markov models 
proceedings international workshop automatic face gesture recognition zurich switzerland 
essa 
system tracking recognizing multiple people multiple cameras 
journal cognitive neuroscience 
kruger von der malsburg 
face recognition elastic bunch graph matching 
pattern analysis machine intelligence july 
wren azarbayejani darrell pentland :10.1.1.47.9503
pfinder real time tracking human body 
proceedings second international conference automatic face gesture recognition 
ieee computer society press 
yacoob davis 
