boosting stochastic problem solvers online self analysis performance vincent cicirello cmu ri tr submitted partial fulfillment requirements degree doctor philosophy robotics 
robotics institute carnegie mellon university pittsburgh pennsylvania july vincent cicirello research funded part department defense advanced research projects agency air force rome research laboratory contracts nasa contract ncc 
views contained document interpreted necessarily representing official policies endorsements expressed implied nasa arpa air force government 
combinatorial domains simple stochastic algorithms exhibit superior performance compared highly customized approaches 
simple algorithms outperform sophisticated approaches difficult benchmark problems lead better solutions algorithms taken world benchmarks real world 
simple stochastic algorithms robust scalable problem solvers 
thesis explores methods combining sets heuristics single stochastic search 
ability stochastic search amplify heuristics key factor success 
heuristics domains single heuristic dominates 
desirable gain collective power set heuristics design search control framework capable producing hybrid algorithm component heuristics ability customize problem instance 
primary goal explore learned quality distributions iterative stochastic search combinatorial optimization domains exploit models quality distributions enhance performance stochastic problem solvers 
hypothesize models solution quality lead effective search control mechanisms providing general framework combining multiple heuristics enhanced decision making process 
goals lead development search control framework called qd beacon uses online generated statistical models search performance effectively combine search heuristics 
prerequisite goal develop suitable stochastic sampling algorithm combinatorial search problems 
goal leads development algorithm called vbss better general discriminatory power search heuristic compared existing sampling approaches 
search frameworks thesis evaluated combinatorial optimization problems 
specifically show vbss effective method amplifying heuristic performance weighted tardiness sequencing problem sequence dependent setups qd beacon enhance current best known algorithm weighted tardiness sequencing qd beacon vbss provide new best heuristic algorithm constrained optimization problem known rcpsp max 
people support guidance form helped dissertation reality 
acknowledge possible 
advisor steve smith wisdom guidance years cmu encouragement explore research directions lead previously interesting new territories 
express gratitude members thesis committee andrew moore cmu ri norman sadeh cmu carla gomes cornell university 
advice guidance thesis research 
members icl laboratory past discussions lead thoughts directions may considered fully sharing comments suggestions practices defense talk 
specifically acknowledge dave larry kramer heng cao ibm research susan charlie collins gabriella dave peter li li jean oh nicola wang chris young qu joe zhou canada 
go members fire federation intelligent robotic explorers project 
working develop scheduling component fire project algorithms thesis benefitted greatly insightful discussions 
fire project members include jeff schneider reid simmons tony stentz goldberg drew dias smith roth brennan david 
members research qualifier committee tucker balch georgia tech rizzi feedback earlier research lead foundation whistling algorithm 
acknowledge chris atkeson insights discussion period thesis proposal july lead explore concepts extreme value theory greatly added theoretical foundation thesis research 
go robotics institute giving opportunity support pursue degree robotics cmu 
ri individuals support time cmu 
matt mason periodic graduate student source intellectually stimulating discussion leads unpredictable iii directions 
suzanne muth students robotics institute 
research secretary carol administrative support time robotics institute icl laboratory 
special go family especially mom dad sisters donna mom dad soon sister support long process 
especially michelle love support encouragement putting frequent drives philadelphia pittsburgh simply michelle 
iv pop pop gene archibald mouse 
contents motivation 
overview 
advantage leverage stochastic sampling algorithm 
descriptive problem solving analysis characterization 
online prescriptive guidance descriptive analysis 
evaluation 
organization 
related search algorithms overview 
systematic search procedures 
discrepancy search 
incremental search 
stochastic sampling algorithms 
iterative sampling 
heuristic biased stochastic sampling 
heuristic 
nested partitions 
stochastic local search techniques 
hill climbing 
simulated annealing 
threshold accepting 
tabu search 
genetic algorithms 
success local search 
vii search algorithm design motivated search space analysis 
rapid randomized restarts 
combining multiple search algorithms 
algorithm portfolios 
asynchronous teams 
meta planner 
summary 
related metareasoning metalevel search control overview 
metalevel control parameter optimization 
search control guided learned models 
stage algorithm 
expected cost improvement distributions 
ant colony optimization 
adaptive probing 
hyperheuristics 
wasp inspired scheduling 
interval estimation 
metareasoning anytime computation 
anytime algorithms 
performance profiles 
deliberation scheduling 
compilation anytime algorithms 
anytime computation negotiation 
summary 
vbss value biased stochastic sampling overview 
value biased stochastic sampling 
whistling 
proof dominance tournament roulette wheel decision 
choosing bias function 
summary 
viii application weighted tardiness scheduling sequence dependent setups overview 
problem formalization 
state ad hoc art solution methods 
dispatch scheduling policies 
dispatch policy starting configuration local search 
search space 
problem set 
performance criteria 
value bias rank bias 
value biasing local search starting configurations 
comparison systematic heuristic search methods 
summary 
aqdf algorithm quality density function overview 
quality density function 
algorithm quality density function 
relation performance profiles 
summary 
qd beacon quality distribution search control overview 
qd beacon 
estimating aqdf 
normal estimates 
kernel density estimation 
generalized extreme value distribution 
illustrative comparison aqdf estimation methods 
exploration versus exploitation 
armed bandit armed bandit problems 
max armed bandit problem 
qd beacon exploration strategy 
summary 
ix application sequencing minimize weighted tardiness revisited overview 
problem formalization 
state art solution methods 
branch bound 
myopic dispatch policies 
local search 
iterated dynasearch 
benchmark problem set 
performance criteria 
vbss qd beacon enhance multistart dynasearch 
qd beacon enhance iterated dynasearch 
comparison local search algorithms 
summary 
application resource constrained project scheduling time windows overview 
problem formalization 
state art solution methods 
branch bound 
priority rule methods 
local search 
iterative sampling earliest solutions 
benchmark problem set 
performance criteria 
qd beacon vbss iterative priority rule method 
results 
summary 
summary 
contributions 
vbss whistling 
qd beacon framework aqdf 
applications 
refinements extensions 
bibliography weighted tardiness scheduling sequence dependent setups benchmark set overview 
instance file format 
best known solutions 
xi list tables hbss preliminary results sampling results applying hbss various bias functions iterations 
snapshot data choose bias function hbss algorithm experiments 
vbss preliminary results sampling results applying vbss various bias functions iterations 
snapshot data choose bias function vbss algorithm experiments 
vbss vs hbss various numbers iterations 
atcs deterministic heuristic result 
lee hill climber non randomized lee 
vbss plus local hill climb vbss hc vs iterative sampling plus local hill climb hc 
vbss hc uses polynomial bias function degree 
algorithms perform hill climb results iterations 
atcs deterministic heuristic result 
lee hill climber single start non randomized lee sa simulated annealing specified number restarts atcs solution 
vbss vbss hc compared discrepancy search procedures 
descriptive comparison aqdf 
descriptive comparison performance profile aqdf 
comparison aqdf estimation methods instance weighted tardiness scheduling problem iterative stochastic search algorithms referred simply algorithm algorithm 
xiii job set qd beacon vbss enhanced multistart dynasearch vs original multistart dynasearch 
number restarts bold indicates best terms number optimal solutions italics indicates best terms percentage deviation 
job set qd beacon vbss enhanced multistart dynasearch vs original multistart dynasearch 
number restarts bold indicates best terms number optimal solutions italics indicates best terms percentage deviation 
job set qd beacon vbss enhanced multistart dynasearch vs original multistart dynasearch 
number restarts bold indicates best terms number best known solutions italics indicates best terms percentage deviation 
tracking number samples allocated heuristics qd beacon kde single job problem instance 
job set qd beacon enhanced iterated dynasearch vs original iterated dynasearch 
number iterations kicks bold indicates best terms number optimal solutions italics indicates best terms percentage deviation 
job set qd beacon enhanced iterated dynasearch vs original iterated dynasearch 
number iterations kicks bold indicates best terms number optimal solutions italics indicates best terms percentage deviation 
job set qd beacon enhanced iterated dynasearch vs original iterated dynasearch 
number iterations kicks bold indicates best terms number optimal solutions italics indicates best terms percentage deviation 
job set comparison qd beacon enhanced iterated dynasearch various local search algorithms 
job set comparison qd beacon enhanced iterated dynasearch various local search algorithms 
job set comparison qd beacon enhanced iterated dynasearch various local search algorithms 
xiv new best known solutions qd beacon vbss randomized iterative priority rule method 
lb lower bound makespan 
summary results vbss priority rule method qd beacon vbss iterative priority rule method 
comparison qd beacon vbss iterative priority rule method various algorithms rcpsp max problem 
xv list figures search space stochastic sampler simple city tsp 
probe indicated arrows represents tour cities example local search algorithm city tsp initial state modified sequence operations 
rapid randomized restarts heavy tailed nature backtrack search constraint satisfaction domains 
example performance profile 
shown example quality map quality results produced anytime algorithm set random instances random amounts compute time 
pp expected quality function time 
example decision contexts discriminating 
tournament wasp dominance contests 
illustration search space weighted tardiness scheduling problem 
particularly note sequence dependent size setup times indicated size gray boxes 
histogram approximations instances weighted tardiness scheduling problem loose duedate problem tight duedate problem 
histogram approximations aqdfs instance weighted tardiness scheduling problem sequence dependent setups loose whistling algorithm atcs heuristic weaker bias function strong bias function 
xvii histogram approximations aqdfs instance weighted tardiness scheduling problem sequence dependent setups tight whistling algorithm atcs heuristic weaker bias function strong bias function 
histogram approximations aqdfs instance weighted tardiness scheduling problem loose wide duedate range whistling algorithm heuristics earliest duedate weighted shortest processing time 
histogram approximations aqdfs instance weighted tardiness scheduling problem tight whistling algorithm heuristics earliest duedate weighted shortest processing time 
relationship aqdf concept performance profile 
aqdf problem instance dependent detailed model expected quality solutions generated single iteration runs stochastic sampling algorithm essentially time slice indicated 
qd beacon framework provides methodology choosing set search heuristics learned statistical models performance problem instance hand 
result iteration search provides feedback qd beacon refine statistical models 
comparison aqdf estimation methods instance weighted tardiness scheduling problem iterative stochastic search algorithms referred simply algorithm algorithm 
estimation methods shown normal distribution kernel density estimator gev distribution 
estimation method superimposed histogram estimate 
comparison aqdf estimation methods instance weighted tardiness scheduling problem iterative stochastic search algorithms referred simply algorithm algorithm 
algorithm estimation methods compared single graph 
xviii comparison aqdf estimation methods instance weighted tardiness scheduling problem iterative stochastic search algorithms referred simply algorithm algorithm 
estimation method aqdf algorithms shown graph 
xix list algorithms iterative sampling 
heuristic biased stochastic sampling hbss 
value biased stochastic sampling vbss 
wasp behavior inspired stochastic sampling whistling 
integrated whistling qd beacon 
normal estimation aqdf qd beacon 
kernel density estimation aqdf qd beacon 
generalized extreme value distribution qd beacon maximum likelihood estimation parameters generalized extreme value distribution 
qd beacon exploration strategy 
multistart dynasearch weighted tardiness sequencing 
iterated dynasearch weighted tardiness sequencing 
qd beacon vbss enhanced multistart dynasearch weighted tardiness sequencing 
qd beacon enhanced iterated dynasearch weighted tardiness sequencing 
priority rule method rcpsp max serial schedule generation scheme 
priority rule method rcpsp max step 
vbss enhanced priority rule method rcpsp max serial schedule generation scheme 
qd beacon vbss iterative priority rule method 
xxi chapter motivation combinatorial optimization domains simpler stochastic algorithms exhibit superior performance compared carefully refined highly customized approaches problem hand 
examples success stochastic search algorithms abound space telescope scheduling project scheduling solid model similarity assessment satisfiability vlsi channel routing graph coloring constraint satisfaction queens just mention :10.1.1.17.5283:10.1.1.44.3898
numerous successes arena little way formal analysis success 
potential explanation offered researchers issue fitting algorithms benchmark instances design time 
example watson studied effects problem structure variety algorithms flow shop scheduling problem observed simple stochastic algorithms iterative sampling heuristic biased stochastic sampling outperformed carefully tuned search procedures considered study real world problem structure added problems 
explanation authors study carefully refined approaches fitted benchmark instances problem simpler stochastic algorithms robust variation problem structure 
similarly hooker argues prime problem heuristic search algorithm research emphasis placed beating existing algorithms problem interest 
potential unfortunate outcomes competitive view heuristic search algorithm development tuning set benchmarks 
watson study shown sophisticated algorithms overfitted benchmark instances fail live expectations faced problems consisting real world structure satisfying explanation really provided simpler knowledge poor stochastic algorithms better 
suggest issue scalability 
example consider complete systematic backtrack search procedures 
matter intelligently complete backtrack algorithms may search space solutions heuristics search space pruning tricks faced exponential problem 
consequence systematic algorithms particularly prone exponential growth mistakes early search result exhausting large portion unpromising search space backtracking correct particularly poor choice early search 
simpler stochastic algorithms scale better problem size due lack completeness 
memoryless care systematically exploring search space 
iteratively probe root search space leaf making decisions randomly iteratively modify current search state simulated annealing tabu search stochastic manner 
expect algorithms consider amounts small amount exponentially sized search space perform combinatorial optimization problems 
look closely behavior simple stochastic algorithms gain insight questions 
example consider stochastic sampling algorithms 
iterative sampling stochastic sampling algorithm iteratively probes root search space making decisions unbiased random 
terminal node reached search begins anew root search space completely forgetting search branches followed previous iterations 
algorithm clearly fitted benchmarks parameters tune 
heads unpromising branch search space going forget followed path place systematically exploring region 
naive approach heuristic biased stochastic sampling hbss 
hbss decision randomly uses heuristic order choices decision point uses ordering means biasing stochastic decisions 
hbss allows heuristic guidance randomization expand focused search region 
hbss assumption search heuristic mistakes 
ran heuristic method hbss handle tradeoff heuristic advice possibility missing better solutions search space 
iterative sampling hbss iteratively probes root forgetting previous search trajectories avoiding unnecessary systematic exploration unpromising search regions 
stochastic elements search algorithms performance formal highly analyzed explanations motivation 
example field constraint satisfaction gomes set explain motivate practice cutting systematic randomized backtrack search procedure pre specified runtime prior finding solution randomly restarting search different search trajectory :10.1.1.21.4367
practice referred rapid randomized restarts 
illustrate backtrack search algorithms randomized heuristic select systematic search order branches decision points exhibit formally heavy tailed behavior runtime distributions 
large number solution trajectories backtrack algorithm requires exponentially long runtimes find solution heavy tail distribution exists problem high density solution trajectories lead directly solution 
provides rationale rapid randomized restart technique 
cutting search specified time limit restarting algorithm new trajectory abandon runs belong heavy tail favor promising runs may lead solution time 
runs heavy tail runtime distribution runs stuck exhausting unpromising portions search space 
rapid randomized restarts gives search way bad search space region requiring exhaust 
general heavy tailed nature runtime distributions provide rationale prescribing fixed restart cutoffs certain assumptions provide rationale schedules cutoffs 
chen gomes selman illustrated formal search space models exhibit heavy tailed phenomena illustrated search space models heavy tailed behavior exhibited backtrack search balanced search trees consequently experience runtime boost rapid randomized restarts 
thesis explores methods set heuristics combining single stochastic search 
success stochastic search algorithms due ability effectively amplify performance search heuristics 
heuristics domains exist single dominating heuristic 
desirable able gain collective power set heuristics 
idea carefully customizing algorithm design search control framework capable simple search heuristics turning hybrid algorithm ability customizing problem instance basis 
primary goal thesis explore learned looking quality distributions iterative stochastic search algorithms 
specifically focus combinatorial optimization domains quality refer objective values solutions produced algorithms multiple iterations 
goal thesis explore ways exploiting models quality distributions enhance performance stochastic problem solvers 
gomes study runtime distributions lead success constraint satisfaction domains 
hypothesis thesis models distributions solution qualities iterative stochastic search algorithms optimization domains lead development effective search control mechanisms enhance problem solving ability algorithms provide general framework combining multiple search heuristics enhanced decision making process 
goals lead development search control framework uses online generated statistical models search performance effectively combine multiple search heuristics search algorithms 
prerequisite goal thesis develop suitable stochastic sampling algorithm combinatorial search problems explore effectiveness stochastic heuristic guided sampling algorithms domains combinatorial optimization 
prerequisite goal leads development algorithm called value biased stochastic sampling better general discriminatory power search heuristic compared existing rank biased approaches 
overview thesis analyzes offers characterization inner workings simple iterative stochastic search techniques combinatorial optimization domains 
sense research proposes iterative stochastic optimization algorithms gomes doing backtrack constraint satisfaction search algorithms 
offer formal descriptive model search performance specifically focusing stochastic sampling algorithms 
go step done backtrack search resulting formal model operation search provide optimizing search online prescriptive guidance 
thesis threefold 
advantage leverage stochastic sampling algorithm 

descriptive problem solving analysis characterization 

online prescriptive guidance descriptive analysis 
advantage leverage stochastic sampling algorithm research specifically study performance algorithms iterative sampling algorithm 
iterative sampling decisions unbiased random root search space leaf 
iterated 
cases may heuristics available problem hand lend guidance problem 
iterative sampling defined follow guidance approaches iterative sampling 
crucial aspect search procedure approach taken randomizing base search heuristic 
conceptually goal perturb choice order prescribed heuristic decision point way preserves heuristic original bias 
simple non interfering strategy simply break ties randomly decision contexts top choices ranked equivalently making random decisions heuristic fails selection 
somewhat aggressive approach called heuristic chooses randomly choices having heuristic value highest 
general framework called heuristic biased stochastic sampling hbss utilizes specified bias function basis deviating choice order base heuristic 
different bias functions wide range randomization strategies realized 
alternative approach randomizing search heuristics iterative sampling framework 
approach taken thesis common hbss important difference 
operating respect rank ordering choices implied application heuristic approach biases selection actual values assigned heuristic possible choice 
smith assume heuristic discriminating different decision contexts argue heuristic degree preference choice impact random selection process 
designate algorithm value biased stochastic sampling vbss 
define specific mode computation stochastic decisions vbss inspired stochastic model wasp colonies self organize order dominance hierarchies 
technique lifted biological context reformulated general framework randomizing heuristics stochastic search context 
designate approach wasp behavior inspired stochastic sampling whistling 
vbss whistling greater detail chapter 
descriptive problem solving analysis characterization bresina introduced idea quality density function 
distribution quality solutions obtained sampling uniformly solution space 
sense characterizes space solutions qualities 
particular problem domain satisfies certain conditions generated performing large number iterations iterative sampling algorithm making search decision random uniform distribution possible choices 
bresina uses compare performance various algorithms particular problem domain 
computes estimate problem instance iterative sampling 
solves instance algorithms wishes benchmark 
scores algorithm number standard deviations away mean algorithm quality 
allows statistically meaningful algorithmic comparison problem instances simply saying algorithm produced solution quality better algorithm view quality distributions perspective particular stochastic sampling algorithm giving idea algorithm expected perform various problem instances 
inspiration bresina define algorithm quality density function aqdf obtained sampling solution space particular stochastic search algorithm uniform samples 
problem instances particular iterative stochastic search algorithm may lead high density solutions successive iterations algorithm instances may 
similarly algorithms particular class problem instances may solved algorithms may difficult time finding solution instances 
aqdf offers methodology modeling performance stochastic search algorithm specific problem instance 
aqdf greater detail chapter 
online prescriptive guidance descriptive analysis crucial aspect iterative sampling approach heuristic information hbss vbss whistling choice base heuristic 
problem domain may exist number carefully designed heuristics 
heuristics may particular classes problem instances highly regarded deterministically search 
interesting problem domains rare heuristic dominate general dispatch scheduling policies 
example particular scheduling objective heuristic may perform better general lightly loaded problem instances may perform better general heavily loaded instances 
employing iterative sampling search procedure may clear heuristics lead better results domain problem characteristics lead informed algorithmic choice may available execution time 
state theart heuristics particularly dispatch scheduling policies parameterized parameters fitted set benchmark problems priori 
practice set parameters heuristic may appropriate may lead better solutions 
heuristic different sets parameters seen different heuristics problem may appropriate different problem characteristics factory load tightness approach stochastic sampling allow multiple base search heuristics 
approach thesis adaptively chooses base search heuristics iterations algorithm 
adaptive decision estimates probability finding better solutions best far iterative samples base heuristic 
relatively samples iterative algorithm approach estimates aqdf 
estimates aqdfs base heuristics adapt iterations algorithm performed decide heuristic fruitful iterative samples 
take descriptive analysis algorithm operation turn prescriptive guidance remainder search 
aqdfs consider computation time solution quality tradeoff performing iterations algorithm heuristic 
aqdfs may deemed search find significantly better solution reasonable number additional iterations 
example problems solve limited time solve 
spend number iterations problem aqdfs decide problem appears leading fruitful direction 
designate approach quality distribution search control qd beacon 
qd beacon acronym serve analogy just boats lighthouse beacons guidance aircraft radar beacons guidance stochastic search methods vbss whistling qd beacon guidance 
qd beacon greater detail chapter 
evaluation framework thesis validated evaluated various combinatorial optimization problems 
specific problems experimentation focuses weighted tardiness scheduling sequence dependent setups see chapter see chapter problem setups resource constrained project scheduling time windows see chapter 
difficult real world relevant scheduling problem insufficient coverage literature competitive approach problem significant contribution right 
adds interesting challenging dimension study involves solving np hard constraint satisfaction problem confines optimization process 
evaluate performance framework optimal best known solutions benchmark problems available 
unfortunately problems interest study optimal solutions costly compute 
comparison realistically possible performance framework compared related algorithms current best known algorithms 
organization remainder thesis organized follows chapter 
chapter overviews related area search algorithms 
specifically focuses stochastic search algorithms heuristic guided search 
topics discussed detail include discrepancy search stochastic sampling stochastic local search problem space motivated search algorithm design methods combining multiple search algorithms concept algorithm portfolio 
chapter 
chapter overviews related areas metareasoning metalevel search control 
topics discussed include metalevel control parameter optimization learning models search control body done anytime computation 
chapter 
chapter presents vbss framework algorithmic details including presentation specific mode computation stochastic decisions vbss framework called whistling 
chapter 
chapter conducts analysis performance vbss difficult combinatorial optimization problem known weighted tardiness scheduling sequence dependent setups 
specifically potential benefits approach rank biased alternative explored 
second topic discussion value biasing starting solution configurations local search approach problem 
comparison vbss systematic heuristic guided search algorithms discrepancy search 
chapter 
chapter defines algorithm quality density function key underlying characterization tool chapters guide search control decisions 
chapter 
chapter details quality distribution search control framework 
qd beacon framework provides stochastic search algorithms functionality necessary modeling quality distributions associated searching different heuristics models aqdfs functionality necessary exploiting models enhance search performance 
alternative modeling techniques aqdf 
defined chapter exploration exploitation strategy framework 
presentation exploration strategy new variation bandit problem call max armed bandit problem analyzed 
chapter 
chapter revisits weighted tardiness scheduling problem discussed earlier chapter 
chapter consider somewhat easier version problem sequence dependent setups 
easier difficult np hard optimization problem 
due multiple heuristics available problem considered candidate problem test efficacy qd beacon framework 
qd beacon enhance performance state art solution procedures problem 
particular qd beacon enhanced version previous best known algorithm problem new best known algorithm problem 
chapter 
chapter explores vbss qd beacon domain resource constrained project scheduling time windows 
problem finding feasible solutions np hard 
solution procedures faced difficult optimization problem difficult constraint satisfaction problem 
state art priority rule search algorithm problem enhanced vbss qd beacon 
resulting algorithm superior current best performing heuristic algorithm ises problem competitive number truncated branch bound approaches problem 
qd beacon vbss iterative priority rule method able improve best known solutions problem instances benchmark set 
chapter 
final chapter contributions thesis larger research community discussed 
additionally potential directions research building frameworks results thesis considered 
chapter related search algorithms overview chapter discuss related search algorithms 
section describes systematic search procedures developed constraint satisfaction 
section discusses stochastic sampling algorithms 
section discusses stochastic local search methods 
section discusses studies problem space characteristics motivation effective search algorithm design 
particularly successful example discussed detail heavy tailed nature runtime distributions backtracking search constraint satisfaction motivation rapid randomized restarts 
section frameworks collections search algorithms parallel described 
summary concludes chapter section 
systematic search procedures discrepancy search harvey ginsberg consider idea constraint satisfaction problems successor ordering heuristics tree search lead directly solution cases heuristic fails lead directly solution may succeeded mistakes path search tree 
limited discrepancy search lds designed rationale mind 
lds begins successor ordering heuristic search tree leaf 
leaf solution search ends 
systematically considers paths search tree discrepancy ordering heuristic decision contrary choice heuristic 
fails find solution considers paths discrepancies heuristic forth solution search space exhausted 
improved limited discrepancy search ilds eliminates redundancy lds algorithm ensuring leaf node visited 
walsh similar motivation design depth bounded discrepancy search dds 
walsh acknowledges idea search heuristics top search tree informed near leafs tree 
deal combines aspects lds aspects iterative deepening search 
iteration dds follows heuristic advice leaf 
iteration dds considers discrepancies depth systematically order increasing discrepancy 
lds dds motivated rationale thesis goals somewhat different suited types problems am concerned 
lds dds concerned finding feasible solution opposed finding optimal near optimal solution 
consider problem leaf node solution drastically differing objective values 
lds dds idea searching instance 
advantage complete search procedures guaranteed find solution exists advantage disadvantage scalability large problem instances considered due worst case exponential complexity 
non systematic search procedures ones scale best larger combinatorial problems 
thesis results comparing lds dds stochastic sampling algorithm vbss illustrates limitations systematic search procedures combinatorial optimization domains 
incremental search pemberton korf consider variations known systematic search algorithms real rime decision making 
specifically incremental versions depth branch bound best search 
define algorithms iterative deepening branch bound iteratively performs depth branch searches progressively greater depths time runs 
see operations research literature detailed description branch bound search 
incremental branch bound maximum depth depth branch bound guaranteed complete available time branching factor search space worst case conditions 
executes depthfirst branch bound precomputed maximum depth 
bounded memory best search bounds size open list search nodes 
search proceeds time runs open list exceeds maximum allowed size 
incremental recursive best search incremental version algorithm called recursive best search rbfs 
rbfs maintains current search path heuristic values siblings nodes current path 
incremental rbfs performs rbfs node expansion backtracking step time time runs 
stochastic sampling algorithms stochastic sampling algorithm constructs solution scratch iteration probing root search tree iteratively 
decisions stochastically 
details stochastic decision process dependent particular algorithm interest 
shows example search space stochastic sampler simple city tsp 
probe indicated arrows represents tour cities similarly possible probes root search tree terminal node represents tour cities 
iterative sampling iterative sampling simple algorithm begins root search tree chooses branch follow root random 
successor node search space chooses randomly branch follow forth finds solution hits dead 
begins top search tree iterates process 
simply looking solution done 
looking best solution find process iterates number times satisfied quality best representation tsp search tree may multiple probes root correspond tour cities 
example path equivalent search space stochastic sampler simple city tsp 
probe indicated arrows represents tour cities solution 
simple easy implement algorithm naive consider search state information consider existing heuristics problem 
ability find solutions relies entirely assumption may exist solutions search space 
furthermore ability find solutions optimization context relies entirely assumption exists high density solutions 
domains practical interest assumptions tend overly optimistic promising results obtained flow shop scheduling problem 
algorithm shows iterative sampling algorithm generic search tree 
heuristic biased stochastic sampling indicated chapter bresina hbss framework provides general basis amplifying heuristic performance randomization 
hbss operates global iterative sampling outperformed highly customized problem specific algorithms real world problem structure added problem 
problem specific heuristic algorithms fitted benchmark set 
algorithm iterative sampling input number iterations objective function search tree output solution objective bestsofar nil repeat times root search node decision node select uniformly random choice successor objective superior objective bestsofar bestsofar return bestsofar search paradigm partial solutions extended adding new decision step search 
iterative sampling random choice process invoked decision iterative sampling process biased pre specified heuristic problem hand 
specifically heuristic prioritize alternatives remain feasible decision point bias function superimposed ranking stochastically select ranked set 
complete solution generated evaluated global optimization criteria 
search process repeated number times best solution generated taken final result 
specific problem considered bresina telescope observation scheduling 
set potential observation tasks objective criterion maximize viewing time problem produce schedule sequence tasks execution period 
formulated hbss generation schedule proceeds forward dispatching manner repeatedly ranking subset tasks remain unscheduled choosing task append current partial schedule 
process iterates potential tasks scheduled time frame exhausted 
resulting schedule evaluated globally search process restarted 
hbss algorithm illustrated general search context algorithm 
re ranking necessary step state position telescope current time heuristic ordering change time new task added tentative schedule 
contributing context dependent nature ranking fact observation tasks schedulable specific time windows feasible choices 
cases possible schedule desired observations bresina domain allotted time window 
algorithm heuristic biased stochastic sampling hbss input number iterations heuristic function bias function objective function search tree output solution hbss heuristic bias objective bestsofar solution obtained heuristic followed repeat times root search node decision node foreach choice score heuristic sort choices score foreach choice rank sort position weight bias rank weight foreach choice prob weight select randomly choice biased prob successor objective superior objective bestsofar bestsofar return bestsofar ability different bias functions hbss provides means placing emphasis advice base heuristic 
number polynomial bias functions form exponential bias function form proposed explored bresina rank choice question 
pointed bresina choice bias function confidence base heuristic 
heuristic deemed strong sense follow heuristic weak disruptive bias called 
potential problem heuristics typically informed different decision contexts possible calibrate degree randomness allowed dynamic aspect problem solving state 
capability requires movement away approach random bias strictly rank order approach heuristic valuations 
heuristic heuristic chooses randomly choices having heuristic value highest 
gomes employ heuristic systematic backtracking search 
discussed purpose randomizing systematic backtrack search constraint satisfaction domains take advantage high variability runtime distribution results 
cutting search runs completion restarting search procedure lead algorithm large improvement runtime 
smith explored heuristic stochastic sampling process solving generalized job shop scheduling problem 
important distinction approach compared rank approaches stochastic sampling hbss acknowledgment fact heuristic may informed different decision making contexts degree confidence heuristic vary decision decision 
rely static bias function hbss smith bias decisions dynamically 
define non deterministic variants search control heuristics vary degree randomness function informed heuristic heuristic 
variant idea exploited cesta solving resource constrained project scheduling problem 
drawback argued feature heuristic choices threshold preferred choice considered stochastic decision 
probability choosing choices 
require careful tuning threshold choices considered equivalent 
nested partitions shi proposed randomized algorithm optimization problems call nested partitions 
describe steps uses stochastic sampling evaluate promising region search space algorithm works follows term acceptance band place heuristic 
algorithm detail chapter benchmark experiments 

partitioning step current promising region 
root search entire search space region entire search space 
subregions 
partition subregions 
define region search space excludes 

random sampling step conduct random sampling points region 
shi iterative sampling experiments restrictions sampling algorithm 
sophisticated procedure uses heuristic guidance hbss may lead better results investigated 

estimate promising index step random samples obtained previous step define promising index partition 
promising index objective values points region obtained random sampling 
shi define value best point region sampling step 

backtracking step determine promising region iteration 
take region best value 
regions appear equally promising choose random 
region subregion promising region iteration 
promising region appears surrounding region backtrack super region 
note root search space surrounding region partition entire promising region 
note maximum depth search space promising region partitioned search point 
continue iterating compute promising indices current promising region surrounding region 
current promising region maximum search space depth continues remain promising continue iteration promising 
behavior may mean algorithm converged converging global optimal global optimal lies region 
case global optimal lie surrounding region 
sampling procedure required give positive probability sampling point region positive probability backtrack eventually explore search space regions 
shi prove nested partitions method converges global optimum finite time 
example nested partitions may applied combinatorial optimization problem easily tsp 
promising region partitioned city visited th position tour 
sampling subregions straightforward 
cities fixed chain 
city fixed subregions 
simply necessary conduct random sampling procedure city positions greater tour purpose estimating promising indices 
stochastic local search techniques search techniques far discussed constructive 
empty solution root search space decision adds piece current solution 
example bresina telescope scheduling domain node search space hbss randomly chooses observation add schedule constructing 
entire collection stochastic search techniques lumped category called local search 
local search method begins complete randomly generated solution iteratively modifies solution algorithm dependent ways search solution optimizes problem objective function 
local search algorithms iterated number times randomly chosen starting configurations 
illustrates example local search 
hill climbing relatively straightforward local search technique hill climbing 
hillclimbing algorithm considers space candidate solutions laid landscape altitude point landscape determined objective value candidate solution located point 
set allowed local moves hillclimbing chooses move advances current solution highest neighboring point landscape continues locally optimal peek reached example local search algorithm city tsp initial state modified sequence operations 
iterates process randomly chosen starting configuration 
sense starting random point search space hill climbing follows uphill greedy heuristic 
usually referred steepest ascent hill climbing 
variation hill climbing ascent hill climbing move improves position fitness landscape 
simple example swapping elements sequencing problem complex example approach sequencing problems known dynasearch best set independent pairwise swaps dynamic programming 
dynasearch discussed detail specific problem domain context 
iteration hill climbing search finds locally optimal peek objective landscape algorithms usually iterated large number times returning best solution iterations hopes stumbling global optimum 
simulated annealing popular local search technique simulated annealing sense viewed randomized heuristically biased variant hill climbing algorithm 
simulated annealing begins hill climbing randomly chosen candidate solution configuration 
potential moves configuration chosen set allowed moves random 
move improves search current position objective landscape 
move takes search downhill direction objective landscape probability decreases degree downhill movement increases decreases search length increases 
words consider heuristic values downhill moves steep descent stochastic decision simulated annealing biased heuristic 
probability move accepted boltzmann distribution exp 

cost associated making move amount downhill movement maximization problem uphill movement minimization problem current temperature 
simulated annealing allows fewer downhill moves search progresses 
accomplished cooling schedule decreases temperature parameter periodically updating positive constant 
final stages simulated annealing search essentially correspond ascent hill climb 
simulated annealing allowance downhill moves moves seemingly take optimal solution serves purpose providing escape routes local extrema 
great deal success applying simulated annealing difficult important optimization problems 
successful applications simulated annealing algorithms include vlsi design call routing telecommunications networks clustering spect image reconstruction digital filter design graph drawing job shop scheduling vehicle routing radio network base station positioning 
threshold accepting threshold accepting local search algorithm closely related simulated annealing 
threshold accepting begins randomly chosen candidate solution configuration 
potential moves chosen set allowed moves random 
move improves search current position objective landscape 
move takes search downhill direction objective landscape provided degrade current solution state threshold value threshold decreased time search analogously decreasing temperature parameter simulated annealing 
tabu search tabu search local search technique closely related hill climbing incorporates concept tabu list list moves disallowed period time search 
tabu search randomly generated initial solution iteratively modify solution set moves 
move selected improves position objective landscape move exists 
move exists move bad 
choice moves step consists remains eliminating set tabu moves complete 
example tabu list includes inverse moves steps 
wandering disallowing moves aggressive way avoiding local optima 
example consider case bad move current search state improving moves consider best move resulting state returns state disallowing move adding tabu list avoid cycles search escape local optimum 
tabu search returns best solution state course search 
genetic algorithms genetic algorithms stochastic search algorithms come broader category evolutionary computation genetic algorithm ga inspired field evolutionary computation broad properly survey entire field require volume 
sake brevity chosen simply describe commonly employed evolutionary computation algorithms genetic algorithm 
evolution theory sense solves problems means artificial evolution solutions 
problem interest encoded chromosomes 
common representation chromosome bit string 
tentative solution configurations mapped bit strings 
example problem function optimization problem real valued parameters potentially represent problem configuration bit string length real valued parameters represented bits 
fitness chromosome defined objective value solution represented chromosome 
chromosomes higher fitness values correspond solutions better objective value 
ga evolves population chromosomes 
begins population randomly generated chromosomes iterates number generations 
generation chromosomes selected population previous generation replacement copied initial population current generation 
selection process typically stochastic biased manner fitness values 
example common selection method weights roulette wheel fitness values population spins wheel times 
chromosome new initial population paired exactly chromosome 
pair chromosomes mates probability crossover rate 
crossover amount genetic material bits swapped pair 
various methods selecting bits bits swap 
crossover phase bit chromosome mutated small probability mutation rate 
mutation occur value bit flipped 
process iterated large number generations best solution final generation returned 
consider ga uses selection expensive way choosing best solution initial random population high probability 
consider ga uses selection mutation crossover equivalent population variation simulated annealing 
mutation operator considers random moves fitness landscape selection keep uphill moves high probability non zero probability keeping chromosomes corresponding downhill moves 
consider complete ga selection mutation crossover common representations include permutations vectors reals case genetic programming program trees 
chromosome chance selected multiple times possibly 
essentially equivalent population version simulated annealing way jumping potentially interesting explored hills fitness landscape crossover 
success local search successful examples stochastic local search algorithms satisfiability traveling salesperson largest common subgraph graph coloring 
successful walksat algorithm satisfiability 
best example simple highly successful stochastic search algorithm 
walksat begins random initial assignment variables 
iteratively picks random unsatisfied clauses 
randomly selected unsatisfied clauses probability flips value randomly selected variable clause probability flips value variables clause greedy heuristic 
greedy heuristic chooses variable reduces global number unsatisfied clauses greatest amount 
amount negative improvement flipping variables clause heuristic favors bad 
search algorithm design motivated search space analysis number researchers studying characteristics search spaces identify particularly difficult easy problem instances influence development new algorithms exploit problem space features 
example frank studied characteristics plateaus encountered local search strategies 
argued studying characteristics plateaus problem results study design local plateau search space local search algorithm region search space member state plateau objective value member states member state direct neighbor member state exist neighbor member state plateau neighbor better objective value plateau 
local optima example plateau size 
bench related plateau additional characteristic members plateau neighbor states better objective values 
words bench flat region search space exits 
search technique problem 
example problem spaces relatively small plateaus methods tabu search similar algorithms disallow revisiting search states may effective problem spaces large difficult escape plateaus restarting local search algorithm encountering plateau may effective spending search time plateau 
number studied various problem domains identify search space features correlated problem difficulty 
examples characteristics classes difficult problem instances identified characteristics potentially lead new improved algorithms problems 
rapid randomized restarts particularly successful example search space analysis motivating algorithm design heavy tailed runtime distributions motivation rapid randomized restarts 
constraint satisfaction problem solving csp domains gomes observed heavy tailed nature search runtime distributions different solution trajectories search space 
csp instance distribution runtimes backtrack search procedures multiple runs exhibits formally heavy tailed behavior 
heavy tailed distributions extremely non standard distributions capture high variability erratic behavior random processes 
distributions characterized infinitely long tails infinite mean infinite variance 
heavy tailed nature offers explanation high variability runtimes exhibited backtrack search procedures 
provides conceptual rationale adopting approach cuts search specified computational time limits essence abandoning trials belong heavy tail repeatedly restarting different solution paths 
approach allows search process reach productive regions search space sooner 
gomes call approach rapid randomized restarts 
approach shown significantly reduce run times complete search procedures hard problem instances range problem domains 
illustrates rapid randomized restarts motivation procedure heavy tailed nature runtime distributions backtrack search constraint satisfaction domains 
major design consideration rapid randomized restart search strategy defining search cutoff point 
luby showed provably optimal restart policies bounded search spaces bounded heavy tailed runtime distribution exponentially long righthand tail size space exponential mean size space exponential variance 
rapid randomized restarts heavy tailed nature backtrack search constraint satisfaction domains 
assumptions runs independent feasible observation length run 
complete knowledge runtime distribution optimal restart policy set fixed cutoff point backtracks expected time find solution minimized cutoff 
luby showed known runtime distribution schedule cutoffs gives expected total runtime log factor optimal fixed cutoff 
considering features problem solver state search addition length run horvitz kautz showed bayesian models constructed lead dynamic restart policies solver state observations superior optimal static policy 
ruan relaxed run independence assumption considered restart policies dependent runs 
combining multiple search algorithms section overview general methods combining multiple stochastic search algorithms single stochastic problem solver 
different algorithms problem perform better problem instances different characteristics 
example lagoudakis considered problem sorting array numbers markov decision process model determine optimal policy particular computer archi tecture choosing insertion sort merge sort quicksort sorting performed recursive step size subset numbers sorted recursive step 
complex difficult problems problem combining search algorithms leverage advantages simple 
overview general methods search algorithm combination 
algorithm portfolios algorithm portfolio collection different algorithms different copies algorithm running different processors interleaved execution processors 
primary motivation approach combine algorithms portfolio portfolio approach gives superior performance compared component algorithms 
combining algorithms large variance runtime distributions portfolio algorithms possible take advantage non negligible probability finding solution really short run algorithms 
example systematic backtrack search randomized heuristic constraint satisfaction domains exhibits high variability distribution runtimes multiple runs search 
running copies algorithm parallel take advantage runtime variability improve probability finding feasible solution quickly short run copies algorithm similarly running different risky algorithms parallel 
gomes selman demonstrate efficacy algorithm portfolio approach showing mixed integer programming mip running single process best bound approach superior depth strategy portfolio high variance depth runs outperforms portfolio best bound runs 
rapid randomized restart approach gomes discussed takes similar advantage variability cutting randomized systematic search procedure pre specified runtime prior finding solution restarting 
hoos similarly shown stochastic local search algorithms domains sat csp exhibit run time speed parallelization portfolio 
domains stochastic local search algorithms characterized exponential run time distributions account effectiveness parallelization 
asynchronous teams similarly combinatorial optimization domains acknowledged available search algorithms strengths weaknesses 
produce solutions slow fast tradeoff solution quality 
developed framework allows number algorithms search solutions cooperatively 
call framework asynchronous team 
essentially team set memories set autonomous agents 
memory may comprised set complete tentative solutions problem partial solutions problem 
memory may problem representation memory may representation 
subset agents implementations various search algorithms constructive agents 
example agent may simulated annealing algorithm agent may hill climber 
agent takes input tentative solutions selected input memory improves tries improve solutions outputs solutions output memory 
input output memories agent multiple agents may share input output memory input memory agent may output memory agent vice versa 
addition constructive agents destructive agents 
destructive agent removes memory tentative solutions deems promising 
example destructive agent may procedure similar roulette wheel selection ga select solutions delete memory biased unfit 
example may mechanism similar tabu lists tabu search delete solution configurations satisfy criteria 
agents team execute asynchronously centralized control governing amount execution time granted 
shown framework give superior performance compared underlying component algorithms 
teams appear effective framework building hybrid search algorithm collection search algorithms problem 
team essentially algorithm portfolio ability algorithms communicate improve solutions 
meta planner related idea ai planning community meta planner howe combines planning algorithms sort algorithm portfolio term 
howe performed study number planning algorithms suite benchmark planning problems 
showed planner dominated problem set planners performed best problem instances compared planners study 
showed problem features number actions number predicates number goals number predicates initial condition number objects predictive performance particular planner problem instance 
data study howe developed meta planner 
meta planner orders component planning algorithms expected probability success algorithm expected runtime 
models linear regression models performance data study 
ordering algorithms executed round robin control strategy 
algorithm executed time slice equal expected time required solve problem 
solves problem planning comes 
fails planner removed round robin 
uses allocated time slice finding solution failing suspended control passes planner 
continues solution planners fail preset threshold amount time exceeded 
summary chapter various related search algorithms discussed 
discrepancy search algorithms lds dds motivated idea may search ordering heuristic problem heuristic may small number mistakes course search 
lds dds systematic search algorithms designed constraint satisfaction domains mind attempt ensure completeness exhausting search space necessary 
optimization domains systematic procedures may suffer scalability issues 
stochastic sampling algorithms closely related thesis 
underlying motivation similar lds dds 
trying guarantee completeness optimality stochastic sampling algorithms trade favor scalability trying find solutions quickly 
novel algorithm thesis falls category stochastic sampling 
stochastic local search class stochastic search algorithms initial complete solution solutions iteratively modified various operators building solutions scratch iteration done stochastic sampling search 
approach search control taken thesis designed stochastic sampling mind may relevant local search techniques 
example thesis results involving hybrid algorithm solutions generated stochastic sampler taken local extrema hillclimbing algorithm 
resulting algorithm controlled search control framework qd beacon thesis 
search space analysis proven fruitful providing motivation search algorithm design 
example saw gomes rapid randomized restart technique complete randomized backtrack search abandoned restarted prespecified runtime exceeded 
practice motivated heavy tailed nature runtime distributions backtrack search problem domains 
algorithm portfolios offer method advantage high variance runtime distributions combining risky algorithms parallel interleaved execution create single meta algorithm reduced variance significantly shorter expected runtime 
similarly teams seen potentially effective framework allowing collection stochastic search procedures collaborate search solution problem effectively aspects component algorithms 
architectures agents search algorithms autonomously essentially equal priority execution architecture 
search control framework thesis qd beacon may possible effectively coordinate share execution time subset components algorithm portfolio 
important aims thesis qd beacon potentially effective mechanism combining multiple stochastic samplers single hybrid search algorithm way algorithm portfolios teams provide architecture combining multiple search algorithms 
chapter related metareasoning metalevel search control overview chapter discuss related metareasoning metalevel search control 
section discusses done metalevel control parameter optimization particularly done gas considering metalevel problem static optimization 
section discusses research dealing making search control decisions models search performance learned execution deciding restart search heuristics adapt search progress 
section discusses metareasoning done anytime algorithms 
summary concludes chapter section 
metalevel control parameter optimization important issue needs resolved design phase stochastic search algorithm set various control parameters algorithm 
genetic algorithm ga case example consider due large number parameters involved 
example mutation rate crossover rate various choices crossover operator population size potentially specialized parameters depending choice operators advanced issues ga researchers considered issue ga control parameter selection :10.1.1.33.1702
earliest studies ga control parameters de jong 
analyzed class gas function optimization 
de jong optimal control parameters widely despite lack knowledge optimality respect problems outside test collection 
schaffer expanded de jong test suite performed systematic study effects control parameters 
grefenstette saw problem tuning control parameters primary ga secondary metalevel optimization problem apply metalevel ga approach 
grefenstette metalevel ga parameterized de jong optimal control parameters population cross rate mutation rate generation gap scaling window elitist strategy 
grefenstette results showed slight improvement de jong control parameters population size cross rate mutation rate elitist strategy 
applied meta level gas control parameter optimization 
presents modified methods selecting initial populations mutation operators improving performance gas function optimization 
tests techniques meta level ga optimize control parameters ga wu chow apply meta level ga approach optimizing control parameters gas nonlinear mixed discrete integer optimization problems 
cicirello smith acknowledge computational expense associated computing fitness function metalevel ga requires executing primary ga number times build neural network model performance primary ga fitness function metalevel 
apply approach optimizing control parameters ga largest common subgraph problem 
metalevel optimization limited ga control parameters 
koch control parameters evolution strategy 
de jong applies ga approach control parameter optimization dynamical systems necessarily control parameters ga 
morley uses ga optimize parameters bidding rules market mechanism dynamically assigning trucks paint vehicle 
campos likewise biologically motivated multi agent system problem 
examples metalevel control parameter optimization 
search control guided learned models stage algorithm success local search algorithms hill climbing simulated annealing depends largely characteristics objective function landscape problem hand example quantity frequency local optima size plateaus 
boyan observes possible define alternative objective function consisting global optima may landscape suitable effective local search original objective function 
boyan stage algorithm designed motivation 
stage algorithm takes input various problem state features including original objective function value problem state 
takes input local search algorithm simulated annealing hill climbing 
proceeds stages name stage 
stage algorithm follows local search original objective landscape 
local optima encountered stage uses statistical learning linear regression locally weighted regression learn value function mapping problem state features local search start state objective value expected local optima encountered search state 
learning stage stage applies local search new objective landscape learned model 
cycles back stage performing local search original objective function domain forth 
search learned evaluation function space move search new local optima stage restarts randomly determined starting solution 
expected cost improvement distributions sadeh define call expected cost improvement distribution tool motivate restarting simulated annealing search 
recognize finding near optimal solutions combinatorial optimization problems simulated annealing expensive process computationally requiring large number restarts 
deal computational expense procedure learns recognize abandon runs look promising favor restarting search 
multiple runs simulated annealing problem instance build probabilistic models set temperature checkpoints 
distribution expected improvement cost continuing search temperature threshold 
assume distributions modeled normal distributions 
mean distribution standard deviation cost best solution check point temperature th run cost best solution obtained temperature th restart simulated annealing search distribution computed check point results restarts 
current run abandoned cost best solution previous runs threshold value 
run abandoned completed sadeh approach uses decide fresh run simulated annealing solution previous run checkpoint temperatures 
consider possibilities making decision 
chooses restart point expected maximize rate cost current best solution improve 
second chooses randomly threshold restart point expected maximize criteria 
third chooses boltzmann distribution weighting higher choices higher expected rate improvement best solution 
ant colony optimization heuristic biased stochastic search technique gained popularity computational intelligence community years ant colony optimization aco meta heuristic 
aco uses population ant agents communicate indirectly trail laying build solutions optimization problem hand 
ant agents builds solution stochastically biases random decisions values heuristic values artificial quantities pheromone evolve time obtained solution quality 
instance variation aco artificial ant chooses search space branch set alternatives fb probability returns heuristic value choice returns quantity artificial pheromone located search space branch system parameters trade heavily heuristic pheromone influence bias stochastic search 
pheromone quantities updated methods ants update search space branches quality respective solutions 
numerous applications aco various combinatorial optimization problems including sequential ordering problem job shop scheduling flow shop scheduling vehicle routing bus driver scheduling tardiness scheduling problems resource constrained project scheduling 
extensions aco designed dynamically changing optimization problems domains 
example schoonderwoerd developed effective system called ant control abc adapting routing tables circuit switched networks aco framework 
similarly di caro dorigo developed system called antnet artificial ants adapt routing tables packet switched networks 
aco paradigm cicirello smith developed method routing jobs multi purpose machines dynamic flow shops minimize setups called ac 
unfortunately prone convergence sub optimal equilibrium game theoretic sense 
aco framework improvement hbss uses actual heuristic values stochastic decisions capable varying degree randomness informed heuristic general evolution artificial pheromone quantities convergence solution slow suited applications desire solution quickly 
best suited problems interested finding near optimal solutions afford extra computation time 
performance compared evolutionary methods genetic algorithms 
adaptive probing describes stochastic sampling method calls adaptive probing 
adaptive probing search builds online probabilistic model cost choosing action depth search 
adaptive probing assumes effects choosing th preferred action depth search states depth estimated cost assumed mean normal distribution action costs depth search space having variance 
cost action depth 
depth search tree branching factor necessary maintain db cost models 
uses perceptron learning rule update parameters probe root space leaf observed leaf cost objective value solution 
actions taken probe fi cost means fa updated observed leaf cost estimated leaf cost learning rate respectively 
probe actions chosen probability leads solution lower cost lower objective value 
sense adaptive probing seen stochastic sampling method attempts learn search heuristic problem online 
heuristic incorporated method specifying initial probing policy heuristic slowly discounting favor learned model 
shows adaptive probing competitive systematic search procedures dfs lds dds cases heuristic strong 
case suffers need learn heuristic 
domains know heuristic scheduling domains community spent time effort designing strong dispatch heuristics 
furthermore search space grows number parameters need maintain learn search 
db parameters get difficult deal problems large branching factors large depths 
example city tsp require maintaining cost models 
assumes actions costs actions particular depth search independent previous actions arrived level search 
impractical assumption 
example tree search tsp actions cities available visit available search node depth dependent path taken root node depth cities visited 
technique interesting just attempts closely related approach thesis 
adaptive probing builds utilizes online model costs choosing actions learned search approach builds utilizes online model objective values leaf nodes feasible solutions search space 
hyperheuristics hyperheuristics represent new type local search algorithm 
hyperheuristic method combining multiple local neighborhood search operators insertions removes adds swaps single local search algorithm 
basic form hyperheuristic cowling define call simple hyperheuristics 
specifically define simple hyperheuristic algorithms repeatedly chooses local operator uniformly random applying repeatedly chooses operator uniformly random applying iteratively improvement chooses random permutation local operators applies consecutively chosen order cycling local operator applied repeatedly improvement moving operator permutation 
simple hyperheuristics listed particularly interesting light topic chapter 
far described hyperheuristics better fit discussion chapter 
cowling define call choice function hyperheuristic adapts functional ranking low level search operator 
choice functions calculated individual performance low level operator joint performance pairs operators particular operator help operator improve current solution operator lead improvement amount time elapsed operator 
choice function local neighborhood operator defined previous operator applied 
function individual performance operator updated search new old change objective value time operator applied amount cpu time taken 
function joint performance updated search follows new old change objective value time called immediately amount cpu time taken 
function amount cpu time elapsed time local neighborhood operator applied 
parameters determine degree parts play role determination choice function 
parameters fixed ad hoc tuning procedure adjusted search simple reinforcement learning update rules 
furthermore approach called hyper ga considered genetic algorithm evolve sequences local neighborhood operators 
hyper ga chromosome population represents sequence local neighborhood operators 
goal hyper ga search find sequence local neighborhood operators applied problem manner analogous simple hyperheuristic leads solutions 
adaptive length chromosome hyper ga ga extends idea fixed length sequences local neighborhood operators allows ga search length sequence addition sequence 
begun hyperheuristic approaches combine multiple problem specific heuristics improved problem solvers 
example ross consider binpacking problem 
hyperheuristic approach bin packing problem uses learning classifier system learn choice function deciding set binpacking heuristics apply current search state 
specifically search space constructive search local search heuristics choice set decide things item place bin 
rossi paechter evolutionary algorithm solving timetabling problems 
approach genetic representation encodes sequence problem specific heuristics encoding solution configuration 
fitness individual chromosome population quality solution sequence heuristics construct solution problem instance 
system closely related hyperheuristics epstein forr architecture 
forr combines advice multiple heuristics weighted voting mechanism learning weights voting 
epstein forr domain constraint programming adaptive constraint engine 
related hyperheuristics engine nareyek uses local search method solve constraint programming problems 
system constraint problem cost determined degree satisfied time search 
example constraint satisfied cost unsatisfied constraints positive cost value 
step search constraints positive cost selected 
selection heuristic chosen improve cost constraint changing values set variables 
constraint may heuristics improve selected constraint cost 
heuristics assigned weight system weights adapted search simple reinforcement learning rules 
constraint chosen improvement weight heuristic chosen constraint adjusted current cost constraint cost constraint time selected 
cost showed improvement weight heuristic increased decreased 
adjusting weight chosen heuristic heuristic highest weight selected constraint applied improve current cost constraint 
nareyek considers alternatives weight adjustment rules 
wasp inspired scheduling theraulaz model self organization takes place colony wasps 
interactions members colony local environment result dynamic distribution tasks foraging brood care 
addition hierarchical social order wasps colony formed interactions individual wasps colony 
emergent social order succession wasps dominant dominant 
model wasp behavior describes nature interactions individual wasp local environment respect task allocation 
model colony self organized allocation tasks refer response thresholds 
individual wasp response threshold zone nest 
wasp threshold zone amount stimulus brood located zone wasp may may engaged task foraging zone 
lower threshold zone amounts higher likelihood engaging activity stimulus 
bonabeau theraulaz deneubourg discuss model thresholds remain fixed time 
consider threshold task decreases time periods task performed increases 
give examples different insect species mathematical models closely agree 
bonabeau demonstrate model leads distributed system allocating mail retrieval tasks group mail carriers 
deal toy problem successfully illustrate potential systems inspired underlying wasp behavioral model 
campos take model step illustrating connection market mechanisms wasp inspired systems 
apply system inspired natural model simulation real world vehicle problem morley 
insect inspired bidding rules campos result slight improvement market mechanism morley 
similarly cicirello smith adopt task allocation model routing wasps assign route jobs machines distributed factory setting :10.1.1.26.6429
noted actual search performed select machine assign job 
simple update rules response thresholds adapt time 
adaptation response thresholds thought learning heuristic evaluates trade associated bidding bidding particular job 
heuristic followed stochastically machine agent single sample drawn stochastic sampling procedure decide bid job 
model wasp behavior describes nature wasp wasp interactions take place nest 
individuals colony encounter may probability interact 
interaction takes place wasp higher social rank higher probability dominating interaction 
interactions wasps colony self organize dominance hierarchy 
theraulaz bonabeau deneubourg discuss number ways modeling probability interaction encounter range interacting interacting certain tendencies individuals 
scheduling wasp definition cicirello smith concept model job priority prioritize jobs machine queue 
scheduling wasps basis whistling algorithm thesis 
interval estimation reinforcement learning especially exploration policies considered related thesis 
summarize exploration strategy relevant deals issue selecting multiple actions reinforcement learning domain 
similar need select multiple heuristics stochastic search algorithm 
kaelbling introduced reinforcement learning strategy known interval estimation 
interval estimation action confidence interval expected reward computed 
action largest upper bound confidence interval selected executed 
rationale action large expected reward large upper bound confidence interval 
action tried sufficiently tend large upper bound width confidence interval larger fewer samples 
metareasoning anytime computation anytime algorithms anytime algorithm algorithm result expected improve terms quality function increasing computation time 
dean boddy originated term anytime algorithm 
term name class algorithms properties algorithm suspended resumed minimal overhead 
algorithm terminated time return answer 
behaved improvement answers returned improve behaved manner function time 
horvitz simultaneously developed related ideas referred algorithms properties flexible inference strategies 
number properties desirable number reasons researchers 
zilberstein outlines additional properties measurable quality quality approximate result determined precisely 
recognizable quality quality approximate result easily determined runtime constant time 
monotonicity quality result nondecreasing function time input quality 
consistency quality result correlated computation time input quality 
diminishing returns improvement solution quality larger early stages computation diminishes time 
noted additional properties various combinations give specific definitions dean boddy third property 
types algorithms fall class anytime algorithms 
example algorithms discussed chapter employed anytime algorithm 
discrepancy search methods lds dds implemented way allow interruption return best solution time interruption 
stochastic sampling algorithms implemented way 
local search algorithms designed iteratively improve initial solution set initial solutions 
types algorithms develop anytime computation procedures include limited numerical approximation algorithms taylor series approximation dynamic programming 
general truncated complete search procedure anytime setting 
performance profiles means quantitatively expressing effects computation time solution quality required effective metareasoning anytime algorithms 
dean boddy time dependent planning tool called performance profile pp 
pp anytime algorithm function maps computation time expected example performance profile 
shown example quality map quality results produced anytime algorithm set random instances random amounts compute time 
pp expected quality function time 
quality result 
typically generated set problem instances considered representative types problem instances encountered 
instances set random amount computation time chosen result computed anytime algorithm amount time 
quality results computation times generate results compute pp anytime algorithm 
quality terms pp typically lines percent improvement initial solution 
horvitz uses similar construct describe terms object related value flexible computation 
example pp seen 
deliberation scheduling dean boddy consider problem deliberation scheduling time dependent planning problems 
define planning problem time dependent time spent planning cost 
deliberation scheduling procedure allocating computational resources set anytime algorithms expectations regarding performance 
example time dependent planning problem set events agent respond 
events corresponding anytime algorithm purpose choosing action take response event 
job deliberation scheduling algorithm allocate computa tional resources anytime algorithms maximize agent expected utility 
dean boddy give polynomial time algorithm optimally solving problem performance profiles anytime algorithms monotonically increasing continuous piece wise differentiable functions 
time spent algorithm assumed negligible 
deliberation scheduling algorithm call expectation driven iterative refinement applied robot courier problem 
horvitz similarly presents deliberation scheduling algorithms 
compilation anytime algorithms generalized metareasoning problem concerns anytime algorithms components larger system 
component may take input output anytime components 
deliberation scheduling problem arises system allocate computation time various components maximize expected output quality complete system 
deal problem zilberstein defines conditional performance profile cpp anytime algorithm function mapping input quality computation time probability distribution quality results 
anytime algorithm composition problem np complete 
local compilation approach zilberstein lead linear time offline compilation certain assumptions result guaranteed globally optimal 
local compilation quality output component optimized considering performance profiles immediate sub components 
subcomponents treated elementary anytime algorithms local compilation 
sub component elementary performance profile determined recursively local compilation 
anytime computation negotiation larson sandholm consider problems negotiation agents assumed bounded rational 
specifically consider agent may intractable individual problem potential gain pooling resources solve joint problem comprised individual problems 
joint problem intractable 
deliberation agents choose compute solution problem compute solution agent problem compute solution joint problem 
reaching deliberation deadline bargaining phase begins agent offer divide value joint solution agent accepts rejects offer decides implement proposed joint solution individual problem solutions 
larson sandholm consider problem game theoretically define deliberation equilibrium perfect bayesian equilibrium game deliberation actions part agent strategy 
algorithms finding equilibria number situations deadline known proposer known advance performance profiles deterministic stochastic 
negotiation problem somewhat related ideas thesis 
negotiation problem decided intractable problems compute performance profiles anytime algorithms problems 
thesis interested choosing heuristics stochastic sampler choosing variations anytime algorithm solving single intractable problem 
solving negotiation problem larson sandholm define tree structured performance profile call performance profile tree 
tree structure allows condition results computation far 
node tree represents solutions particular quality 
example quality defined percent improvement initial solution configuration root performance profile tree represent solutions quality 
paths tree may nodes different levels quality multiple nodes level quality 
edges tree represent probability reaching tree node child edge current node parent edge 
multiplying probabilities paths rooted current node compute probability reaching node performance profile tree 
summary chapter related metareasoning metalevel search control discussed 
optimizing control parameters various search algorithms genetic algorithms metalevel 
focused optimization parameters priori 
discussed metareasoning approaches learn models search performance online execution purpose search performance enhancement 
example saw sadeh expected cost improvement distributions identify abandon promising runs simulated annealing 
ant colony optimization adaptive probing hyperheuristics similarly weights type adjust search performance improve search control decision making policies 
boyan stage algorithm learns alternative evaluation function search place original objective function 
approach thesis closely related hyperheuristics adapt control policies effective choice heuristics search framework 
final part chapter gave overview related area anytime computation 
relevant concept performance profile variations larson sandholm performance profile trees 
aqdf chapter viewed discussed detailed model particular time slice pp 
aqdf differs pp ways including problem instance dependent pp problem class dependent 
chapter vbss value biased stochastic sampling overview chapter novel approach stochastic sampling 
acknowledging fact heuristic may discriminating context context define value biased stochastic sampling vbss section 
method computing stochastic sampling decisions vbss inspired computational model wasp behavior recall section 
novel stochastic sampling algorithm known whistling wasp behavior inspired stochastic sampling section 
section provides proof equivalence wasp inspired dominance tournament roulette wheel decisions vbss 
section discusses issues associated choosing appropriate bias function problem choice heuristic function 
summary concludes chapter section 
value biased stochastic sampling fundamental flaw hbss framework bresina ignores discriminatory power inherent heuristic 
stochastic decisions rank order choices choice highest value heuristic choice lowest value heuristic 
chooses choice roulette wheel probability bias rank heuristic bias rank heuristic example decision contexts discriminating 
bias bias function rank returns rank assigned choice set choices sorted heuristic 
sort choices heuristic values utilized full potential 
occasions rank approach may beneficial 
example genetic algorithms benefit rank selection strategy 
order fully utilize discriminatory power heuristic inherent heuristic values define call value biased stochastic sampling vbss 
vbss decisions manner analogous roulette wheel choice probability bias heuristic bias heuristic vbss shown algorithm 
consider decision context choices preferred equivalently heuristic quite equal heuristic values 
consider second decision context choices choices heavily preferred higher heuristic value choice 
hbss decision contexts regarded equivalently 
choice higher heuristic value gets ranked choice gets ranked second bias function applied decision 
ranked choice probability contexts 
vbss heuristic algorithm value biased stochastic sampling vbss input number iterations heuristic function bias function objective function search tree output solution vbss heuristic bias objective bestsofar solution obtained heuristic followed repeat times root search node decision node foreach choice score heuristic foreach choice weight bias score weight foreach choice prob weight select randomly choice biased prob successor objective superior objective bestsofar bestsofar return bestsofar values explicitly stochastic decisions rank imposed ranked choice discriminating context chosen higher probability discriminating context 
seen see example decision contexts heuristic values second heuristic values drastically different 
second decision context value biased approach higher probability choosing heuristic preferred choice compared decision context rank biased approach treats decision contexts exact way 
whistling stochastic search framework derives naturally inspired computational model self organization takes place colony wasps 
nature whistling algorithm stochastic search extension scheduling wasps 
whistling algorithm originally cp 
hierarchical social order wasps colony formed interactions individual wasps colony 
emergent social order succession prioritization wasps dominant dominant 
model theraulaz results interactions determined stochastically force variables wasps involved 
probability wasp winning dominance contest wasp defined force variables wasps interaction value force variable winner increased value force variable loser decreased 
time interactions hierarchical social order formed dominant dominant wasp 
map model problem randomizing heuristic choices associating wasp proxy possible choice decision context defining force wasp function heuristic value assigned corresponding choice 
precisely define force wasp fw bias heuristic choice choice choice represented wasp heuristic function returns heuristic value choice bias bias function hbss framework variable non negative initialized varies results dominance contests run algorithm see 
mimics fluctuations occur force variable values dominance contests real wasps won lost nature 
definition fw includes explicit bias factor choose simplify stochastic rule choosing winner dominance competition equation follows coupling new definition equation appropriate bias function force definition equation express original rule equation 
hbss reformulation allows expression range bias functions 
algorithm wasp behavior inspired stochastic sampling whistling input number iterations heuristic function bias function objective function search tree output solution whistling heuristic bias objective bestsofar solution obtained heuristic followed evaluate bestsofar objective bestsofar repeat times root search node decision node foreach choice force bias heuristic arbitrary choice set choices foreach choice set probability force force see eq 
force force force force force force successor evaluate objective evaluate superior evaluate bestsofar bestsofar return bestsofar bonabeau generalize definition parameter 
motivation somewhat different 
discuss formula models behavior real insect societies different values may closely model particular society behavior 
furthermore force variable model adapts wins losses dominance contests explicitly defined functionally 
definition allows spectrum polynomials bonabeau allows expression exponentials logarithms expressed bonabeau generalization 
definitions fw sampling algorithm concrete defining specific competition structure 
follows assume style tournament 
initial wasp choice selected arbitrarily proceeds engage successive competitions wasps choices 
initial wasp continues compete long wins 
defeated new winner takes place tournament wasp dominance contests 
proceeds face remaining candidates 
winning competition winning wasp variable updated accumulate force variable value loser loser drops 
wasp choice remaining tournament returned final selection 
tournament structure illustrated 
shown computation equivalent selecting standard roulette wheel decision possible choice choice chunk wheel proportional bias heuristic choice 
advantage method computing roulette wheel decision usual single pass set choices required 
alternative initial pass compute bias heuristic choice followed second pass choose probability bias heuristic bias heuristic choice proof equivalence tournament dominance contests roulette wheel decision provided section 
whistling algorithm algorithm 
line algorithm initial definition force variables wasps see equation 
line line represent increase value equation winning wasp 
dominance contests see equation take place line algorithm 
computationally whistling algorithm general vbss algorithm selects choice time choices current search node 
times sequencing problem core sampling procedure algorithmic complexity 
fact complexity corresponding deterministic dispatch scheduling procedure 
whistling vbss adds constant factor computational time required strict deterministic application heuristic 
compare complexity hbss algorithm algorithm see whistling asymptotically efficient 
hbss biases stochastic decisions rank ordering choices obvious implementation sorts choices heuristic values time search decision log operation 
decisions sequencing problem algorithmic complexity hbss log 
see whistling hbss compare experimentally particular scheduling domain 
proof dominance tournament roulette wheel decision dominance tournament roulette wheel decision structure tournament dominance contests whistling algorithm choice chosen probability bias heuristic bias heuristic choice tournament choice chosen roulette wheel decision choice takes chunk wheel proportional bias heuristic choice 
proof induction proof fw bias heuristic choice initial value force choice force choice including accumulation force variables choices defeated tournament 
pointed worst case complexity choosing th largest element unsorted list 
theory stochastic selection operation done linear time 
assumption choices ranks select winning rank looking actual elements 
winning rank linear time selection algorithm decision 
linear time algorithm selection operation theoretical interest practical interest 
large constant factor results log sort select algorithm dominating large problem instances 
second problem assumption elements ranks hold element may heuristic value rank 
may possible clever devise linear time method finding ties heuristic value 
method certainly non obvious probably non trivial adding significant constant factor 
may possible compute hbss decisions linear time probably desirable search space particularly large branching factor 
base case dominance tournament choices 
choice wins probability wins new force choice wins probability wins new force base case choices equivalent roulette wheel decision 
inductive step assume case tournament dominance contests choices tournament equivalent roulette wheel decision 
assume completion tournament winning choice choice force value consider addition th choice choice list choices initial force winner choice sub tournament consisting choices compete dominance contest choice choice wins dominance contest tournament contests choices probability wins new force choice wins dominance contest choice probability probability fw winning sub tournament choices wins tournament choices probability fw fw new force wins case tournament choices equivalent roulette wheel decision 
choosing bias function vbss hbss necessary specify bias function applied heuristic values case hbss ranks 
bias function viewed system parameter requires amount tuning 
couple issues consider selecting bias function vbss stronger knowledge rich heuristics probably conjunction stronger bias functions polynomials high degree 
rationale large amount effort expert knowledge went heuristic design search benefit advice 
similarly weaker knowledge poor heuristics probably weaker bias functions low degree polynomials 
second heuristics generally give values small range small positive real values require strong bias function spread values roulette wheel decisions 
heuristics give values wider range sufficiently spread require weaker bias function 
issues mind little fine tuning bias function choice generally needed 
generally sufficient try range decided considering types values heuristic strength heuristic 
alternatively employ computationally heavy approach tuning bias function meta optimization approach done tune genetic algorithms 
experiments thesis computational method employed 
cases handful bias functions tried small set problem instances small number iterations 
bias functions tried preliminary tuning runs chosen rationale cases give nearly numerically indistinguishable results 
summary chapter vbss defined saw heuristic values stochastic decisions rank order imposed heuristic values better able full discriminatory power inherent heuristic function 
furthermore longer require ranking choices gain computational efficiency added bonus best case eliminating log ranking step hbss worst case simplifying streamlining multiplier issues necessarily involved selecting bias function hbss 
linear time operation hbss decision computed linear time 
defined efficient approach computing roulette wheel decisions inspired computational model wasp social hierarchy formation resulting novel stochastic sampling algorithm call whistling defined 
chapter application weighted tardiness scheduling sequence dependent setups overview demonstrate experimentally evaluate vbss framework turn domain factory scheduling fairly broad body area dispatch scheduling heuristics 
specifically chapter explore possibility amplifying dispatch scheduling heuristic performance addition search component vbss search framework 
scheduling problem tackled chapter weighted tardiness scheduling problem sequence dependent setups formalized section 
existing methods problem literature section 
search space discussed section 
description specific set problem instances generated section 
performance criteria experimental comparisons chapter defined section 
section compare performance hbss vbss demonstrate power value biasing rank biasing 
go illustrate effective value biasing means generating initial configurations multi start local hill climbing framework section 
difficulties faced related systematic search procedures lds dds domain considered comparison section 
summary concludes chapter section 
problem formalization weighted tardiness scheduling problem sequence dependent setups sequencing problem encountered number real world problem applications turbine component manufacturing packaging industry 
specifically set jobs fj jobs weight duedate process time furthermore defined amount setup time required immediately prior start processing job follow job machine 
necessarily case th job non physical job representing starting point problem 
purpose allow specification setup time jobs sequenced position 
sequence dependent nature setup times primary source problem difficulty 
particular version problem concern case jobs sequenced single machine preemption job setup processing permitted 
furthermore machine processing setting operation completed 
objective problem sequence set jobs machine minimize total weighted tardiness max tardiness job completion time duedate job completion time job equal sum process times setup times jobs come sequence plus setup time process time job 
specifically position sequence job define state ad hoc art solution methods done weighted tardiness scheduling problem versions problem sequence dependent setup times 
problem exist libraries benchmark instances large number algorithms compare new approaches 
unfortunately sequence dependent setups commonly appear real world scheduling problems ignored development algorithms solution procedures 
common practice assume setup time reintroduced problem solving setup free version 
example dispatch heuristics sequence dependent setup case discuss variations known state art heuristic setup free version problem 
terms including setup time added heuristic seemingly ad hoc manner 
time ad hoc heuristic procedures local improvement search algorithms applied results best sequence dependent setup version problem current state art 
example complete guaranteed optimal algorithms currently limited solving problems jobs size necessitating heuristic guided search meta heuristic approaches larger problems 
subsections overview existing dispatch policies sequence dependent setup weighted tardiness scheduling problem local hillclimber designed specifically intentions improving solutions produced heuristics 
chapter vbss search stochastic neighborhood heuristic prescribed solution path vbss alternative hill climber 
define systematic heuristic guided alternatives dispatch policies section guidance 
dispatch scheduling policies dynamic factory environments dispatch scheduling heuristics provide practical robust basis managing execution environments plagued large number dynamic characteristics difficult accurately model mckay provides model complex dynamic factory environment 
scheduling decisions job assign machine online manner needed current state factory 
dispatch heuristics information jobs expected processing time setup time due date priority typically designed optimize performance objective 
virtue simplicity insensitivity environmental dynamics reasons commonly employed 
time localized myopic nature decisions schemes inherently susceptible sub optimal decision making exhibit formally chaotic tendencies 
problem domain weighted tardiness scheduling sequence dependent setups apparent tardiness cost setups atcs dispatch heuristic strongest heuristic available 
atcs builds earlier research weighted tardiness problem arguably current best performing dispatch policy class scheduling problem 
atcs defined follows atcs exp max current time sum process setup times sequenced jobs index job just completed job added schedule average processing time jobs average setup time 
parameters tuning heuristic 
lee defines values parameters problem instance characteristics specifically due date range factor due date tightness factor setup time severity factor 
defined section 
job added schedule atcs heuristic simply arg max atcs atcs heuristic presentation lee best performing dispatch heuristic problem raman raman exp max job chosen arg max raman parameter requires tuning 
comparison atcs raman lee suggest setting 
thing noted raman dispatch policy atcs dispatch policy modifications dispatch policy developed variation problem sequence dependent setup constraints exp max heuristic discussed chapter considers problem sequence dependent setup times 
dispatch policy starting configuration local search lee original describing atcs heuristic local hillclimber designed specifically intentions applied solution results directly deterministic application dispatch policy atcs 
hillclimber refer experimental study lee assumes starting configuration vicinity optimal near optimal solution 
assumption lee hill climber uses fairly small operator set 
operator set includes types local moves 
swaps choose job adds total weighted tardiness objective arg max max 
consider swapping job nearest jobs current sequence 

insertions choose job adds total weighted tardiness objective arg max max 
consider removal job followed insertion job nearest jobs current sequence 
couple things note operator set consider moving jobs large distances jobs fixed job adds objective function value 
fall assumption having initial solution 
assumed jobs near optimal location sequence moving jobs large distances sequence considered assumed jobs need moved fixing jobs adds objective function 
operator set hill climber step move gives illustration search space weighted tardiness scheduling problem 
particularly note sequence dependent size setup times indicated size gray boxes 
greatest improvement objective function evaluation ends search improvement operator set 
atcs dispatch policy coupled hill climber currently operation scheduling system number factories packaging industry 
search space search space explore experiments remainder chapter viewed tree 
root node tree represents empty sequence empty schedule 
search node child jobs sequence 
child search node represents adding job sequence 
problem instance jobs root node children represents sequence jobs 
children root node children forth 
leaf node tree represents possible sequences jobs 
leaf node represents feasible solution path root guaranteed find feasible solution 
illustration shown 
particularly note size setup times indicated gray boxes dependent sequence jobs 
problem set problem instances consider generated procedure described lee analysis dispatch scheduling policy atcs 
unfortunately actual problem set available unable compare exact problem instances study 
problem set generated prescribe 
problem instances available internet 
appendix provides location details file format best known solutions 
problem instance characterized parameters due date tightness factor due date range factor setup time severity factor 
parameters defined follows max max min max average duedate average process time average setup time max min maximum minimum max makespan completion time job 
makespan depends sequence estimator suggested lee max number jobs problem instance 
specifically consider problem sets characterized parameter values 
twelve combinations parameter values generate problem instances jobs 
generally speaking problem sets cover spectrum loosely tightly constrained problem instances 
processing times uniformly distributed interval 
mean setup time determined setup times uniformly distributed interval 
duedate job uniformly distributed probability uniformly distributed max probability weights jobs distributed uniformly 
performance criteria experimental results follow performance criteria average percent improvement api solution deterministic heuristic policy 
percent improvement defined objective value problem instance deterministic dispatch heuristic atcs objective value search algorithm 
averaged problem instances get api 
stochastic algorithms considered api averaged results independent runs problem instance 
parentheses average runs api best run problem instance 
atcs dispatch policy currently best known problem 
lee hill climber uses atcs determine initial starting configuration currently best known heuristic search algorithm problem lee report results api atcs 
ideally set problems optimal solutions known bounds current best known solutions 
unfortunately setup problem benchmark set problems existence currently 
reason comparative results criteria set forth original discussion current best known algorithm problem 
chapter discuss setup free version problem benchmark library problems optimal solutions known number instances best known algorithmic results available comparative purposes 
average cpu time time seconds sun ultra mhz 
average number search nodes generated gen search 
table hbss preliminary results sampling results applying hbss various bias functions iterations 
snapshot data choose bias function hbss algorithm experiments 
api average number search nodes visited visits search 
average number solution nodes considered sols search 
value bias rank bias 
value bias rank bias question 
tis search rank order choices ignoring utterly context decisions take arms sea troubles value biasing 
chapter saw example decision contexts value bias approach better discriminatory power inherent heuristic values compared rank bias approach stochastic sampling 
compare vbss hbss experimentally weighted tardiness scheduling problem setups 
goal see gained heuristic values bias biasing rank order 
order properly compare hbss vbss problem set applying wide range bias functions atcs dispatch heuristic earlier 
table shows results hbss algorithm polynomial bias functions degrees bias rank degree polynomial 
similarly table shows results vbss polynomial bias functions bias value degree polynomial value heuristic value 
bias functions considered brevity excluded tables 
values tables averages problem instances runs 
values table vbss preliminary results sampling results applying vbss various bias functions iterations 
snapshot data choose bias function vbss algorithm experiments 
api table vbss vs hbss various numbers iterations 
atcs deterministic heuristic result 
lee hill climber non randomized lee algorithm api time gen visits sols atcs lee vbss hbss vbss hbss vbss hbss vbss hbss parentheses results best run runs problem instance 
hbss algorithm degree polynomial gives highest average percent improvement deterministic heuristic solution api statistically significant compared degree polynomials 
comparisons involving hbss results degree polynomial bias function 
vbss results best bias function clear 
statistical significance polynomial bias functions degrees 
comparisons results degree polynomial bias function 
turn direct comparison vbss hbss table 
compare algorithms numbers iterations 
compare deterministic heuristic solution listed row labeled atcs hill climber proposed lee applied result deterministic heuristic solution listed table lee 
note rows table necessarily give improved performance compared atcs 
due fact hbss vbss implemented compute atcs solution lee hill climbs atcs solution 
observations vbss hbss outperforming lee iterations computed 
single iteration hbss vbss solutions lee require time lee 
hbss vbss appear useful improving solutions provided cpu time available 
desire solution instantaneously lee better choice 
slightly seconds iterations vbss achieve twice api compared api lee 
consider number iterations note vbss heuristic values bias gives better results hbss rank bias number iterations 
examining cpu times noted job problems vbss exhibits greater fold speedup hbss 
due need hbss sort choices heuristic 
compare iterations vbss iterations hbss similarly iterations vbss iteration hbss 
mind clearly find significantly better results value biasing fraction time required rank bias stochastic search 
value biasing clear winner rank biasing terms solution quality terms computational efficiency search problem domain 
may wonder circumstances better abandon discriminatory advice heuristic values favor rank biased approach 
genetic algorithms benefit rank selection strategy 
bresina original telescope scheduling problem rank biased stochastic sampling performed mention considering obvious value biased alternative 
note possible compute hbss decisions linear time sorting necessary speedup may fold seen experiment 
depending significance constant factor linear time version problem domain branching factor best hbss terms cpu time log results reported 
table vbss plus local hill climb vbss hc vs iterative sampling plus local hc 
vbss hc uses polynomial bias function degree 
algorithms perform hill climb results iterations 
atcs deterministic heuristic result 
lee hill climber single start non randomized lee sa simulated annealing specified number restarts atcs solution 
algorithm api time gen visits sols atcs lee sa sa vbss hc vbss hc vbss hc vbss hc vbss hc vbss hc vbss hc vbss hc vbss hc hc hc hc hc hc hc hc hc hc value biasing local search starting configurations previous section observed lee requires tiny fraction cpu time required perform multiple iterations vbss observed extra time find significantly better solutions lee vbss 
vbss means extending lee hill climber multi start algorithm 
examine vbss mechanism seeding starting solutions lee local hill climber 
added point comparison consider simulated annealing search solution atcs dispatch policy 
implemented computationally intense simulated annealing procedure uses modified lam schedule see description modified lam schedule allowed run total evaluations 
table compare vbss seeded hill climber vbss hc hill climber unbiased random starting configurations hc lee deterministic dispatch policy atcs 
observations unbiased hill climber finds solution better atcs 
fact cases shown best solution unbiased hill climber problem instance far worse atcs solution 
primary reason lee hill climber assumes starting configuration limited operator set 
unbiased random starting solutions highly starting solutions problem instances problem set 
vbss seed starting configurations requires approximately half cpu time search compared unbiased random starting configurations 
takes time generate starting solutions vbss evident higher number search nodes generated vbss hc underlying assumption lee hill climber starts solution holds case vbss 
hill climb short note lower numbers search nodes solutions nodes visited vbss hc compared hc 
contrast takes nearly negligible time generate unbiased random starting solutions solutions far local optima hill climb takes significantly time 
comparison systematic heuristic search methods consider computational comparison vbss vbss hc various versions discrepancy search 
purpose comparison explore power stochastic sampling combinatorial domains systematic search gets bogged considering large number un promising solutions 
example limited discrepancy search required systematically exhaust solution path containing single discrepancy heuristic advice considers solution path discrepancies 
search decision contexts heuristic strongly prefers choice strongly prefers choices decision contexts 
lds way skipping single discrepancy solution paths clear heuristic choices bad systematically considers anyway 
similarly depth bounded discrepancy search unable consider solution discrepancies depth greater exhausts solution paths possible discrepancy combinations root including depth 
assumption heuristic tendency fallible start search cases time search space large branching factor considering large number solution paths clearly un promising heuristic 
hypothesis stochastic sampling approaches able better tune heuristic advice context incomplete capable finding better solutions limited time systematic approaches lds dds domains branching factor high 
specifically consider variations discrepancy search lds single limited discrepancy search considering single discrepancy solution paths 
solution states job problem instances 
lds limited discrepancy search considering discrepancy solution paths 
solution states 
dds depth depth bounded discrepancy search considering discrepancies depth 
solution states considered 
dds depth depth bounded discrepancy search considering discrepancies depth 
solution states considered 
results comparison table 
observations vbss average finds better solutions lds single time iterations vbss better solutions slightly time lds iterations vbss 
approximately half time vbss seeded hill climber vbss hc iterations finds solutions better dds dds depth 
improved version ilds korf 
improved version ilds korf 
table vbss vbss hc compared discrepancy search procedures 
algorithm api time gen visits sols vbss vbss vbss vbss hc vbss hc vbss hc vbss hc lds single lds dds depth dds depth minutes vbss seeded hill climber vbss hc iterations finds solutions average better solutions allowing lds run hour instance lds average better allowing dds run minutes dds depth 
vbss hc find better solutions generating visiting far fewer search nodes lds dds visiting far fewer solution nodes lds dds 
particular compare vbss hc iterations lds dds depth 
example considering solution paths discrepancies heuristic advice lds generates nearly search nodes visiting evaluating half solution nodes iterations vbss hc generates just search nodes visiting approximately evaluating solution nodes 
theme observations far cpu time vbss find significantly better solutions average compared systematic discrepancy search procedures 
clearly case domains problem domain large branching factor problems optimization lds dds better suited constrained problem domains example constraint satisfaction domains looking feasible solution constrained optimization domains objective criteria problem search space cumbersome size large sequencing problem 
summary chapter considered problem weighted tardiness scheduling constraint sequence dependent setups 
problem little prior 
dealing weighted tardiness scheduling problem assume away setup costs reintroduce sequence dependent setups ad hoc modifications 
dispatch policy atcs coupled local hill climber best available heuristic method problem 
problem experimentally compared number heuristic guided search algorithms atcs heuristic search 
comparison showed value biased approach vbss better inherent discriminatory power heuristic compared approach hbss 
vbss exhibited solutions better objective values able find solutions significantly cpu time 
findings surprising 
assumption heuristic sense able better value biasing making information contained rank biased approach essentially throws away heuristic information 
furthermore vbss dominating hbss terms cpu time falls directly need hbss rank order choices decision step 
second comparison considered idea vbss seeding mechanism starting configurations multi start extension lee hill climber 
lee hill climber designed assumption search state previously applied solution atcs dispatch policy 
procedure gives results negligible computational overhead 
cpu time showed possible improve results vbss generate starting configurations applying lee hill climber vbss generated solutions 
final comparison considered hypothesis large branching factor un constrained sequencing problems vbss effective heuristic guidance compared truncated systematic approaches lds dds 
lds dds defined systematically exhaust search space considering solution nodes order increasing discrepancy heuristic prescribed path 
problem domains large number choices decision point choices deemed un promising heuristic values example lds forced systematically consider discrepancy solutions single discrepancy un promising choices considering solution discrepancies 
seen number nodes generated visited number solution states evaluated lds dds overwhelmed search space size 
consequently vbss vbss hc power ignore un promising discrepancies better able reach productive regions domains large branching factor 
chapter aqdf algorithm quality density function overview chapter define descriptive tool call algorithm quality density function aqdf 
foundation aqdf bresina concept quality density function 
importantly study analysis aqdf motivated gomes studied runtime distributions backtrack search constraint satisfaction domains offered rationale rapid randomized restarts heavy tailed nature runtime distributions 
similar way examine quality distributions stochastic sampling search combinatorial optimization domains examine aqdfs may tell search behavior 
section describes bresina concept quality density function aqdf 
section defines discusses aqdf 
section relates aqdf concept performance profile body done anytime algorithms 
summary concludes chapter section 
quality density function bresina introduce idea quality density function 
distribution quality solutions obtained sampling uniformly solution space see examples 
bresina characterizes feasible solution space problem instance terms distribution solution qual weighted tardiness weighted tardiness histogram approximations instances weighted tardiness scheduling problem loose duedate problem tight duedate problem 
table descriptive comparison aqdf 
aqdf sampling uniform particular algorithm characterizes problem space algorithm performance algorithm independent dependent ities 
bresina computes number standard deviations away mean solution produced particular algorithm 
compares measure algorithms scheduling problem benchmark performance algorithms terms solution quality problem instance 
incorporated broader measure calls expected solution quality includes computation time comparison 
algorithm quality density function basis descriptive analysis whistling algorithm define algorithm quality density function aqdf distribution quality solutions obtained sampling solution space particular stochastic sampling algorithm uniform samples 
example heuristic particular scheduling problem bias function compute aqdf whistling algorithm weighted tardiness weighted tardiness histogram approximations aqdfs instance weighted tardiness scheduling problem sequence dependent setups loose whistling algorithm atcs heuristic weaker bias function strong bias function 
instance scheduling problem 
show example aqdfs whistling algorithm problem instances loose duedate instance tight duedate instance weighted tardiness scheduling problem respectively 
aqdf characterizes performance particular stochastic sampling algorithm problem instance terms distribution solution qualities obtained algorithm 
table compares contrasts aqdf 
illustrates approximation aqdf whistling strong bias shows approximation aqdf whistling somewhat weaker bias 
problem instance optimal solutions weighted tardiness 
stronger bias whistling tends favor suboptimal heuristic solution heavily find optimal solution frequently require iterations somewhat weaker bias allows whistling widen search finds nearby optimal solutions frequently problem instance 
contrast stronger bias see approximation aqdf allows whistling reach deeper better region search space concentrated closely heuristic solution whistling weaker bias wander bit far heuristic solution 
problem instance heuristic appears informed problem weighted tardiness weighted tardiness histogram approximations aqdfs instance weighted tardiness scheduling problem sequence dependent setups tight whistling algorithm atcs heuristic weaker bias function strong bias function 
instance 
aqdf data ahead time allowed informed choice bias function chosen stronger bias function productive search 
shows approximations aqdfs whistling algorithm earliest duedate edd heuristic weighted shortest processing time wspt heuristic weighted tardiness problem instance loose wide duedate range setup times instance 
whistling edd finds better solutions problem instance whistling wspt 
shows equivalent aqdfs instance problem tight 
example contrast see wspt significantly better edd 
serve example problems may instances whistling heuristic may perform better time may instances second heuristic superior 
thesis develop algorithms computing approximations aqdf online search help heuristic choice decisions informed way 
weighted tardiness weighted tardiness histogram approximations aqdfs instance weighted tardiness scheduling problem loose wide duedate range whistling algorithm heuristics earliest duedate weighted shortest processing time 
weighted tardiness weighted tardiness histogram approximations aqdfs instance weighted tardiness scheduling problem tight whistling algorithm heuristics earliest duedate weighted shortest processing time 
table descriptive comparison performance profile aqdf 
performance profile aqdf problem class dependent instance dependent generated random instances single instance generated ahead time online quality means percent improvement objective value models quality function time quality single iterations relation performance profiles familiar concept performance profile may desirable consider relationship aqdf performance profile 
recall chapter performance profile function maps runtime algorithm expected quality result obtained executing algorithm amount time 
furthermore performance profile continuous function 
quality specifies amount improvement initially generated solution 
consider anytime algorithm repeatedly generates solutions saves best solutions encountered way 
consider partial solutions valued time required generate complete solution invariant 
example time construct single solution sequencing problem whistling algorithm doesn vary iterations single problem instance 
amount computational effort choose element sequence choose second element sequence forth complete sequence obtained 
computational effort vary iteration iteration 
performance profile example track expected quality best solution function time 
expected quality best solution change discrete time intervals time units length time generate single solution 
rest performance profile smoothed continuous function intents purposes completely irrelevant 
lastly detailed model expected solution quality time interval necessary successive numbers iterations 
algorithm single time slice performance profile relevant 
illustrated 
aqdf acknowledges relevant algorithms approxi assumption heuristic value function linear number choices 
argument heuristics greater complexity 
relationship aqdf concept performance profile 
aqdf problem instance dependent detailed model expected quality solutions generated single iteration runs stochastic sampling algorithm essentially time slice indicated 
mate computation time single iteration invariant 
redefines quality simply objective value terms improvement initial solution 
generated single problem instance set random instances deemed indicative problems generate pp 
aqdf described problem instance dependent detailed model expected quality solutions generated single iteration runs stochastic sampling algorithm 
table summarizes similarities differences aqdf pp 
summary chapter descriptive tool algorithm quality density function 
aqdf model distribution quality solutions obtained single iteration runs stochastic sampling algorithm 
problem instance dependent algorithm dependent descriptive tool 
aqdf related concept performance profile 
aqdf described detailed model time slice performance profile representing single iteration runs stochastic sampling algorithm 
aqdf problem instance dependent detailed model performance profile problem class dependent model 
chapter qd beacon quality distribution search control overview definition aqdf previous chapter consider method estimating aqdf relatively samples estimation effective search control 
example approximate aqdfs whistling algorithm problem instance number heuristics 
estimates aqdfs choose heuristic iterations probability finding better solution best far 
estimates aqdfs continue refined iterate search 
chapter define qd beacon quality distribution search control framework 
provides functionality compute models aqdfs online search functionality exploit models effective search control guidance 
functionality provided search algorithms qd beacon summarized section 
implement framework method estimating aqdf needed 
section presents methods estimation normal distributions kernel density estimators generalized extreme value distributions 
framework method needed balancing tradeoff exploiting current estimates aqdfs exploring improve estimates 
section discusses tradeoff theoretically terms armed bandit problem presents exploration strategy analysis new problem call max armed bandit problem 
summary concludes chapter section 
search space set search heuristics heuristic heuristic heuristic heuristic qd beacon qd beacon framework provides methodology choosing set search heuristics learned statistical models performance problem instance hand 
result iteration search provides feedback qd beacon refine statistical models 
qd beacon qd beacon framework provides functionality necessary model aqdfs online search exploit models effective search control guidance 
example set search heuristics problem qd beacon provides method learning statistical models distributions solution qualities heuristics set 
statistical models qd beacon allows stochastic sampling algorithm informed choice search heuristic 
example illustrated 
qd beacon framework primarily provides functionality modeling aqdfs models select search heuristic iteration search heuristic quality function allows stochastic sampling algorithm give feedback quality solution heuristic bias function pair update appropriate aqdf 
function returns heuristic bias function iteration algorithm 
pair chosen aqdf data probability finding solution better best far heuristic bias function pairs exploration strategy described section 
qd beacon provides functionality stopping criterion considering infeasible search trajectories constrained optimization domains setting set heuristics combined framework continue function returns true probability finding better solution best far aqdf data observed best false 
allows alternative stopping criteria addition maximum number iterations 
heuristic function allows stochastic sampling algorithm report infeasible solution state current iteration heuristic bias function pair 
problems function may necessary 
problems constraint satisfaction problem domains probe root search tree leaf node guaranteed find feasible solution necessary consider failed samplings heuristic bias function choices 
heuristic bias function pair function maintain variable infeasible count number infeasible solution nodes qd heuristics biases function performs necessary initialization required qd beacon framework 
takes input array heuristic functions array bias functions 
lists paired meaning th element list heuristics th element list bias functions wish consider heuristic multiple bias functions heuristic list heuristics multiple times 
qd beacon framework described extended version whistling algorithm incorporates qd beacon algorithm 
algorithm integrated whistling qd beacon input number iterations array heuristic functions array bias functions objective function probability search tree output solution whistling qd beacon heuristics biases objective qd heuristics biases bestsofar solution obtained heuristic followed evaluate bestsofar objective bestsofar foreach heuristic heuristics solution obtained heuristic followed evaluate objective evaluate superior evaluate bestsofar bestsofar repeat times continue root search node decision node foreach choice force bias heuristic arbitrary choice set choices foreach choice set probability force force see eq 
force force force force force force successor feasible solution state heuristic bias evaluate objective heuristic bias evaluate evaluate superior evaluate bestsofar bestsofar return bestsofar estimating aqdf example aqdfs previous chapter generated relatively large number iterations 
design criteria qd beacon framework capable roughly estimating aqdf stochastic search algorithm online search samples samples 
example consider case scheduling problem solve sufficient computation time available approximately iterations whistling algorithm 
consider heuristics problem know heuristic appropriate problem instance time necessary computation determination 
desirable qd beacon capable estimating aqdf heuristic relatively samples whistling algorithm 
aqdfs desirable qd beacon capable deciding heuristic continue remaining samples whistling algorithm probabilities finding better solution best far 
important qd beacon capable estimating aqdfs efficiently capable efficiently choosing competing heuristics possibly bias functions successive iterations 
sections follow describing methods estimating aqdf assume dealing problem domain smaller objective values better 
normal estimates possibility estimating aqdf fit normal distribution data 
advantage approach computed quickly online search little difficulty 
disadvantage aqdf gaussian estimated probability finding better solution inaccurate qd beacon may suggest suited heuristic remainder search 
estimate aqdf normal distribution qd beacon framework 
aqdf required qd beacon problem maintain number samples estimation aqdf number samples th heuristic bias function pair 
algorithm normal estimation aqdf qd beacon input heuristic bias function quality solution just obtained output description updates appropriately 
note assumes smaller objective values qualities better 
global best solution far value persists calls 
heuristic quality quality quality quality quality foreach heuristic bias function pair sum samples objective value th solution obtained th heuristic bias function pair 
sum squares samples 
initialized qd heuristics biases 
heuristic quality updated appropriately 
updating heuristic quality continues updating probability heuristic bias function pair finding better solution best far 
quality new best solution heuristic bias function pairs probability finding better solution best far aqdf updated mean standard deviation computed quality new best solution need updated heuristic bias function pair 
lookup table cumulative distribution standard normal 
algorithm shows algorithm updating aqdfs qd beacon normal estimation 
kernel density estimation second possibility estimating aqdf kernel density estimation see 
kernel density estimator little assumptions regarding underlying distribution models 
provides non parametric framework estimating arbitrary probability densities 
terms estimating aqdf provides qd beacon framework non parametric method estimation relies limited distributional assumptions 
advantage approach possible closely estimate arbitrary aqdfs 
disadvantage additional computational overhead associated kernel density estimates compared normal distribution previous section 
kernel density estimation takes local averages estimate density function placing smoothed quantities mass data point 
kernel density estimator defined nh 
kernel function called bandwidth called scale parameter spreading coefficient 
sample values 
kernel function chosen qd beacon framework epanechnikov kernel jxj epanechnikov showed risk optimal kernel estimates smooth kernels usually numerically indistinguishable 
form kernel cho sen best address computational efficiency concerns 
case epanechnikov kernel clear winner computationally reasons easy integrate 
interested density estimate ultimately compute probability finding better solution best far kernel function choice allows easily compute cumulative probability distribution arbitrary aqdfs 
bounded 
due condition jxj limited number sample values considered computing value kernel function 
useful reducing computational overhead 
choice kernel function critical terms numerical results choice bandwidth hand crucial 
epanechnikov showed optimal choice bandwidth nm dx dx number samples 
unfortunately computation dependent knowing true distribution depends 
commonly assumed underlying distribution normal chosen kernel function epanechnikov results sample standard deviation 
standard deviation usually replaced minf interquartile range yielding sn 
choose assumption underlying distribution gumbel distribution exp exp called location parameter scale parameter 
reasoning assumption motivated extreme value theory discussed greater detail section 
gumbel distribution types extreme value gaussian kernel assumption underlying normal distribution algorithm kernel density estimation aqdf qd beacon input heuristic bias function quality solution just obtained output description updates appropriately 
note assumes smaller objective values qualities better 
global best solution far value persists calls 
heuristic quality quality quality insert quality sorted interquartile range min quality quality foreach heuristic bias function pair result equation result equation distributions 
gumbel distribution assumption note standard deviation gumbel distribution 
write terms sample standard deviation epanechnikov kernel results value computed sn minf 
qd beacon interested cumulative distribution function purpose computing probability finding better solution best far 
obtained integrating kernel density estimator 
probability finding solution better best far aqdf dx best solution far equals dx choice epanechnikov kernel evaluates bs noted maintain samples sorted order equal smallest value list compute sum reach sample 
sample condition holds reached list summation 
sorted list maintain samples sorted histogram maintaining counts number samples discrete values 
compute compute previous section normal distribution readily accessible samples maintain sorted order 
kernel density estimator version qd beacon heuristic quality shown algorithm 
generalized extreme value distribution consider solutions problem hand computed iteration stochastic sampling algorithm iterative stochastic search algorithm fact extreme solution space considered 
sample solutions uniformly random probability low find solutions generated whistling strong heuristic 
words solutions problem instance class problems interested sense rare phenomena space feasible solutions 
consider example illustrated previously weighted tardiness scheduling instance loose 
solution space instance mean objective value standard deviation assumes minimization problem lower bound value objective function 
assuming minimizing objective function 
optimal solution problem instance standard deviations better mean solution problem space 
mean objective value single iteration solutions generated whistling problem instance standard deviations better mean solution problem space 
optimal solution problem instance rare considering problem space single iteration solutions generated whistling 
easy problem instance 
consider harder problem instance illustrated 
problem instance tighter 
solution space problem instance mean objective value standard deviation know optimal solution problem instance best known solution objective value equal standard deviations better mean solution problem space 
mean objective value single iteration solutions whistling standard deviations better mean solution problem space 
far proof solutions sampling whistling stochastic sampling algorithms fact rare phenomena terms problem space serve illustrate aqdfs modeling represent distributions solution values sampled extremes solution space 
noted sense turn field extreme value theory concerns techniques models describing unusual usual 
specifically shall turn extreme value analog central limit theory 
consider maxfx sequence independent random variables having common distribution function example represent mean temperatures days year correspond annual maximum temperature 
model extreme value theorists turn extremal types theorem theorem exists sequences constants fa fb non degenerate distribution function belongs families exp exp ii exp iii exp parameters cases 
known extreme value distributions types gumbel ii iii weibull 
distributions commonly reformulated generalization known generalized extreme value distribution gev exp fz 
case treated limit approaches arrive gumbel distribution 
assumption theorem large equivalent member generalized extreme value distribution family 
preceding argument regarding rarity solutions produced iteration whistling strong heuristic larger solution space argue gev distribution sensible assumption regarding distribution samples represented aqdf 
theorem explicitly applies modeling distribution block maxima 
assumption aqdf stochastic sampling algorithm strong heuristic behaves similar distribution block maxima cumulative distribution function aqdf modeled gev distribution 
gev modeling recognize assuming thesis interested minimizing objective function need block minima analog equation 
want 
maxfx 
assuming distribution function associated aqdf behaves gev distribution probability finding better solution best far defined exp estimated negative sample values 
compute parameters qd beacon framework hosking maximumlikelihood estimator gev parameters 
implementation algorithm available statlib 
original code fortran algorithm generalized extreme value distribution qd beacon input heuristic bias function quality solution just obtained output description updates gev parameters appropriately 
note assumes smaller objective values qualities better 
global best solution far value persists calls 
heuristic quality quality quality add quality interquartile range fb min quality quality foreach heuristic bias function pair exp exp converted purposes fortran utility bell labs 
gev version qd beacon heuristic quality shown algorithm 
calls compute maximum likelihood estimate gev parameters 
described algorithm 
computing maximum likelihood estimate gev parameters hosking algorithm called multiple times necessary 
call uses initial estimates parameters recommended hosking set assuming gumbel distribution 
hosking algorithm fails converge additional calls random initial values parameters 
convergence fails returns values parameters estimated assuming type extreme value distribution gumbel distribution 
netlib bell labs com netlib algorithm maximum likelihood estimation parameters generalized extreme value distribution input sample mean standard deviation 
list data points estimation output maximum likelihood estimates hosking success return random value random value random value hosking success return return illustrative comparison aqdf estimation methods subsection take look strengths weaknesses aqdf estimation methods 
specifically consider single problem instance set benchmark instances weighted tardiness scheduling problem 
benchmark set comparison algorithms applied problems set discussed detail chapter 
sufficient know problem minimization current best known solution problem instance objective value 
analysis consider algorithms referred algorithm algorithm 
necessary know algorithms iterative stochastic search algorithms algorithm general tends produce better solutions algorithm 
individual problem instance level may known assumption true priori 
algorithm algorithm weighted tardiness histogram weighted tardiness histogram weighted tardiness histogram weighted tardiness histogram weighted tardiness histogram weighted tardiness histogram comparison aqdf estimation methods instance weighted tardiness scheduling problem iterative stochastic search algorithms referred simply algorithm algorithm 
estimation methods shown normal distribution kernel density estimator gev distribution 
estimation method superimposed histogram estimate 
graphs shown 
histogram graph estimate aqdf indicated algorithm iterations 
normal distribution estimates aqdfs superimposed histograms 
likewise shown kernel density estimates aqdfs shown gev distribution estimates 
normal distribution estimates see left hand tail significant density left best solutions respective algorithms 
note aqdf appears normal distribution viewing histogram estimates 
kernel density estimates see right hand tail appears capture behavior right aqdf better normal estimates 
interested behavior left hand side 
appears better estimation kde algorithms left hand tail trails far left histogram estimate 
essentially kde risk putting density regions data points 
gev distribution estimates find algorithms aqdf drops completely zero bound 
algorithm produces solutions close optimal solution problem instance intuitively expect aqdf behave 
aqdf bounded optimal solution 
algorithm analysis produces high density solutions near optimal solution sharp drop aqdf near bound 
known best known solution optimal problem instance best solution large number search algorithms available literature 
best solution iterations algorithm algorithm 
aqdfs algorithms appear behave producing solutions near theoretical bound solution quality making resulting gev estimate reasonable 
see algorithms graph showing comparison estimation methods 
algorithm gev distribution estimates see sharp peak near bound gev 
kde see significant density left mean aqdf see normal position mean density kde right bound seen gev relatively small amount probability density left bound 
kde appears behave gev time tails left slower rate 
normal estimates see significant probability density left hand tail 
fact algorithm algorithm weighted tardiness normal kde gev weighted tardiness normal kde gev comparison aqdf estimation methods instance weighted tardiness scheduling problem iterative stochastic search algorithms referred simply algorithm algorithm 
algorithm estimation methods compared single graph 
table comparison aqdf estimation methods instance weighted tardiness scheduling problem iterative stochastic search algorithms referred simply algorithm algorithm 
algorithm estimator best algorithm normal kde gev algorithm normal kde gev significant amount probability density left best known solution 
case reality aqdfs large number state art algorithms went production best known solution 
see estimation methods graph showing comparison aqdfs algorithms problem instance 
normal distribution estimates see algorithm appears find high density solutions near current best known solution algorithm aqdf higher density region left current best known solution due high standard deviation solution qualities produced algorithm 
just discussed case reality problem instance 
normal distribution gev distribution weighted tardiness algorithm algorithm weighted tardiness algorithm algorithm kernel density estimator weighted tardiness algorithm algorithm comparison aqdf estimation methods instance weighted tardiness scheduling problem iterative stochastic search algorithms referred simply algorithm algorithm 
estimation method aqdf algorithms shown graph 
problem instance appears chance normal distribution estimates lead search astray recommending heavier algorithm compared algorithm 
gev kde estimates sharp peak density near bound algorithm 
likewise sharp sharp peaks algorithm slightly right algorithm peaks 
may indicate kde gev lead recommendation algorithm frequently 
explore looking closer exactly aqdf estimates tell numerically 
table shows number things algorithms estimators best solution algorithm probability improving best solution algorithms algorithm probability finding solution better current best known solution probability finding solution quality equal current best known 
note normal estimates far overly optimistic especially algorithm giving probability greater finding solution better current best known solution single iteration algorithm 
note gev distribution estimates possibly pessimistic 
specifically observe gev estimate gives probability event algorithm improving best solution algorithms 
kernel density estimator offers nice mix behaviors methods 
appears overly optimistic overly pessimistic 
interesting compare performance methods greater detail specific problem domains thesis 
exploration versus exploitation qd beacon framework method needed balancing tradeoff exploiting current estimates solution qualities algorithm choices need exploration improve estimates 
develop strategy turn section holland analysis armed bandit problem demonstration near optimal tradeoff exploration exploitation genetic algorithm 
section pose new variation armed bandit problem call max armed bandit problem detail solution 
section discusses relevance solution qd beacon framework presents exploration strategy motivates 
armed bandit armed bandit problems armed bandit problem theoretical analogy problem balancing tradeoff exploration exploitation search problems 
problem allocating trials arms armed bandit slot machine arms different unknown pay distributions goal maximizing expected reward time 
analyses various bandit problems bandit problems inspiration justification exploration strategies application domains reinforcement learning see genetic algorithms see 
analysis section newly posed variation armed bandit problem inspired holland analysis armed bandit connection genetic algorithm giving overview holland findings 
armed bandit armed bandit problems major part theoretical underpinning genetic algorithm 
certain assumptions holland demonstrates bandit problems ga achieves near optimal tradeoff exploration exploitation 
holland analysis bandit problems serve basis design exploration policy qd beacon framework 
armed bandit problem stated simply 
consider slot machine arms 
reward playing arms variance reward playing arm variance furthermore know arm 
problem maximize expected reward series trials armed bandit 
solve problem necessary determine optimal tradeoff exploratory actions trying discover payoffs arms versus exploitation actions playing arm appears best 
armed bandit problem obvious generalization 
armed bandit problem holland showed optimal allocation trials terms minimizing expected loss trials worse arms allocates trials worse arms ln ln total number trials arms number trials better arms optimal allocation ln 
exp increases exp dominates equation simplify expression exp cn constant 
important point number trials allocated see holland complete derivation 
observed better arm increase exponentially number trials allocated observed worse arm 
holland analysis armed bandit problem significantly complex 
arms expected payoffs variances holland analysis showed worst case expected loss problem occurs best arm allocated trials total number trials arms allocated trials 
optimal number trials allocated worse arms shown holland bound ln ln ln number trials allocated observed best arm bound ln 
exp ln ln 
exp armed bandit case exponential bounds dominates simplified exp cm main point number trials allocated observed best arm optimal allocation increase exponentially number trials allocated arms 
max armed bandit problem problem choosing competing heuristics stochastic sampling algorithm qd beacon framework closely related armed bandit problem 
iteration qd beacon choose set heuristics different unknown expected payoffs 
goal quite armed bandit problem 
armed bandit problem wishes maximize sum expected rewards series trials 
qd beacon goal bit different 
qd beacon concerns best single reward receives series trials 
assuming higher rewards better leads pose max armed bandit problem 
max armed bandit problem faced series trials 
trial choose arms 
arms expected payoff probability distribution 
goal maximize value best single reward received trials 
detail solution special case arms generalize armed case 
specifically show maximize expected max single sample reward trials number samples taken observed best arm grow double exponentially number samples taken observed second best 
derivation relevant qd beacon framework assume arms sampling extreme distribution 
specifically assume arms sampling gumbel distribution type extreme value distribution 
gev general unnecessarily complicate analysis 
gev special case gumbel allows easily determined mean standard deviation distribution terms parameters distribution 
exist straightforward estimators parameters sample mean sample standard deviation prove useful derivation 
stating arms rewards arm drawn gumbel distribution location parameter scale parameter mean reward single sample arm euler number standard deviation order fully state problem want maximize expected largest single sample series trials need expression expected value max single sample series trials 
samples fx xn distribution probability maximum samples equals max assumption samples drawn gumbel distribution max exp exp exp exp exp simplifies max exp ln exp exp ln see distribution max samples drawn gumbel distribution location parameter scale parameter gumbel distribution location parameter max ln scale parameter max expected max reward samples arms problem ln consider arm better arms problem 
necessitates defining mean better 
specifically ln ln implies greater equal great inequality fail hold 
armed problem know certainty arm expected max reward access omniscient observer tell clearly ln expected max reward giving trials better arm 
know certainty arm exploration necessary 
consider draw samples observed second best arm samples observed best arm 
consider loss reward associated sampling second best arm 
cases consider 
observed best arm really best arm 
case loss comes giving samples best arm expected loss equal ln ln 

observed best arm really second best 
loss case bit complicated depends expected value giving samples second best arm greater giving samples best arm 
mathematics simplified assume higher expected value associated samples best arm compared samples second best 
see analysis probability second source loss decreases exponentially furthermore form loss maximum expected value max samples best arm equals samples second best 
said consider expected loss case ln ln 
probability observed best arm really second best arm 
probability observed best arm really best arm 
expected loss sampling times observed second best times observed best arm function ln ln ln ln simplified ln ln ln ln order select value minimizes expected loss need define function arm perceived best arm perceived highest expected max single sample reward series trials mw arm perceived second best 
probability stated probability expected max value samples mw greater expected max value samples note parameters gumbel distribution estimated data sample mean sample standard deviation define ln aw ln ln xw ln xw ln central limit theorem says approaches normal distribution mean variance similarly xw approaches normal distribution mean variance distribution xw convolution distributions xw convolution distributions definition normal distribution mean variance approximation tail normal distribution define exp ln definitions see decreases exponentially allows simplify simplification holland note matter value large close optimal value leads ln select value minimize loss derivative respect dl dn dq dn ln ln dq dn dx dn dx dn optimal value occurs dl dn get bound optimal solving inequality dx dn ln ln collect logarithmic terms left obtain ln ln dx dn recalling decreases exponentially rapidly approaches 
noting arrive ln ln dx dn substitute expressions dx dn ln ln exp ln exponentiating sides inequality get exp ln exp ln troubled recursive expression especially case note grows double exponentially appears decreases exponentially seemingly implies decreases triple exponentially increasing double exponentially triple exponential decrease defined recursively 
decrease decreased double exponentially longer triple exponential decrease question remains term dominates expression 
take fraction involving exponential gain insight answer question exp ln exp ln ln looking determine part double exponential dominates total number samples gets large 
consider limits lim ln lim ln note expression dominated ln logarithm second expression denominator dominates 
large sufficient consider ln ln dominates 
consider lim ln ln lim ln ln ln ng lim fln ln account making obvious simplifications get exp exp cn shows number trials observed best arm grow double exponentially maximize expected max single sample reward 
conjecture max armed bandit case result asymptotically identical armed case 
number samples observed best arm grow double exponentially number samples arms 
weak argument leap result arm case arm case follows 
worst case loss armed case occur worst arms identical case holland analysis original armed bandit problem 
trials worse arms analysis armed case loosely thought terms special case analysis armed problem 
specifically observed best arm meta arm comprised aggregation arms 
meta arm trials uniformly distributed arms 
arms identical worst case meta arm behave way second best arm arm case 
number samples observed best arm grow double exponentially 
analysis max armed bandit problem just holland analysis original armed bandit central limit theorem similar assumptions 
result directly applies limit relevance finite models 
finite time analysis appropriate directly apply knew number trials 
follows analysis provide motivation exploration qd beacon 
qd beacon exploration strategy defining exploration strategy qd beacon framework consider analysis max armed bandit problem 
maximize expected max single sample reward series trials give double exponentially increasing number samples observed best arm relative number samples arms 
specific problem qd beacon means sampling observed best heuristic frequency increasing double exponentially relative number samples heuristics 
noted analysis max armed bandit observed best meant arm perceived highest expected max series trials 
compute expectations analysis assumed output arm followed type extreme value distribution 
seen distribution max samples arm follows type extreme value distribution 
fact earlier saw extremal types theorem independent distribution samples drawn arm distribution max samples follows gev distribution types extreme value distribution 
type gumbel distribution leads closed form expression expected max samples reasons assumed analysis max armed bandit 
note couple things regarding qd beacon framework 
distribution best samples stochastic sampling algorithm necessarily follow type extreme value distribution may follow type ii type iii extreme value distribution 
second follow type ii type iii extreme value distribution easily compute expected value best samples 
third easily certainly efficiently compute extreme value distribution types distribution best samples follows models underlying distribution samples 
fourth analysis max armed bandit concerns happens limit qd beacon faced finite potentially unknown number trials 
points particularly leads qd beacon concern primarily trying improve current best solution choice heuristic stochastic search algorithm apply problem 
choice considers past trials trial attempt projection result trials 
definition observed best arm heuristic algorithm highest estimated probability improving current best solution 
incorporating myopic definition observed best analysis max armed bandit allow clean analysis best require closed form expression convolution gev distributions 
discrepancy definition observed best may troublesome readers exploration strategy qd beacon motivated analysis max armed bandit 
keep mind analysis limit number samples goes infinity qd beacon exploration strategy assumes sample sample 
sense consider observed best heuristic higher probability improving best solution far single sample attempting project expected best growing series samples 
qd beacon 
consider exploration strategy qd beacon framework boltzmann exploration commonly reinforcement learning simulated annealing 
boltzmann exploration strategy choose heuristic probability exp exp probability finding solution better best far defined previously methods estimating aqdf ratio number feasible solutions estimating total number samples heuristics choose temperature parameter 
consider number samples expected observed best heuristic algorithm qd beacon exploration strategy input output heuristic bias function pair 
true arg max return foreach heuristic bias function pair exp overflow conditions true true arg max return underflow true select probability weighted return relative heuristic exp total number samples 
observed best means probability finding better solution best far greater 
implies give exponentially increasing decreasing number samples relative get double exponential sampling increase need decrease exponentially 
example exp number samples taken sample probability exp exp exp exp qd beacon chosen increase frequency samples observed best heuristic slightly double exponentially 
fol lowing cooling schedule alternative tn tn equivalent reasons slower double exponential increase sampling observed best include 
acknowledgment analysis max armed bandit number simplifying assumptions including regarding underlying distributions samples arms 

cooling schedule potentially lead trivial improvement implementation efficiency allowing adjusted bit shifts maintain integer 

allows longer search denominator calculations exp 
qd beacon framework reach point underflow value overflows value exp overflows framework begins chose heuristic sample deterministically arg max probability heuristic finding solution better best far fraction feasible solutions 
words search lasts sufficiently long qd beacon switches complete exploitation policy 
exploration policy choosing heuristic bias function pair iteration search described algorithm 
summary chapter defined functionality qd beacon framework 
includes functions allow stochastic sampling algorithms report quality solutions obtained iteration specific heuristic bias function pair allow reporting infeasible solution nodes 
domains constrained optimization iteration stochastic search algorithm necessarily leads feasible solution 
includes functions allow stochastic sampling algorithm choose heuristic bias function pair iterations probability finding better solution best far 
modified version whistling integrates qd beacon functionality example framework 
reporting solution quality qd beacon uses methods update appropriate aqdf estimate 
simplest model aqdf normal distribution 
model discussed kernel density estimation 
specifically kde aqdf selects value bandwidth assumption sampling type extreme value distribution gumbel distribution 
third model discussed argued stochastic sampling algorithms strong heuristics sampling extreme problem instance underlying solution space 
argument lead motivation generalized extreme value distribution model aqdf data 
comparison models single instance scheduling problem stochastic search algorithms 
analysis showed normal distribution overly optimistic model aqdf gev overly pessimistic behavior kde offer reasonable modeling methodology aqdf overly optimistic pessimistic 
whichever model normal kde gev aqdf method exploration exploitation needed desire generate models online searching best solution find 
inspiration holland analysis armed bandit problem defined new problem call max armed bandit problem 
analysis max armed bandit problem showed optimal number trials observed best arm increase double exponentially number trials observed best arm 
derivation motivation choice boltzmann exploration exponentially decaying temperature parameter implementation efficiency reasons ultimately decided slightly exponentially decaying temperature parameter 
chapter application sequencing minimize weighted tardiness revisited overview chapter revisit problem sequencing set jobs single machine minimize weighted tardiness scheduling objective 
goal chapter explore benefit combining multiple search heuristics iterative stochastic search algorithm qd beacon framework 
set heuristics problem bad points qd beacon effectively combine enhance search performance compared single heuristic compared naive strategy sampling uniform number times heuristic compared state art problem 
questions explore chapter 
remainder chapter organized follows 
section problem formalization 
reader chapter fresh mind may skip section provided note chapter considering problem sequence dependent setups 
section overviews state art problem solving weighted tardiness sequencing problem 
section describe benchmark problem sets experimental comparison 
section defines performance criteria 
section comparison number local search algorithms variation multistart dynasearch enhanced vbss qd beacon framework 
section enhance current best algorithm problem iterated dynasearch qd beacon framework 
section shows resulting algorithm compares local search algorithms available comparison 
conclude chapter summary section 
problem formalization weighted tardiness scheduling problem sequencing problem 
specifically set jobs fj jobs weight duedate process time particular instance problem concern case jobs sequenced single machine preemption job processing permitted 
furthermore machine processing job operation completed 
objective problem sequence set jobs machine minimize total weighted tardiness max tardiness job completion time duedate job completion time job equal sum process times jobs come sequence plus processing time job 
specifically position sequence job define state art solution methods section overview number solution methods available literature weighted tardiness scheduling problem 
include branch bound procedure originally find optimal solutions problem instances benchmark problem set myopic dispatch policies problem number local search approaches 
final algorithm described section iterated dynasearch currently best known algorithm problem 
branch bound optimal solutions available job problem instances library originally branch bound algorithm potts van 
unable tackle job problem instances due computational complexity problem 
prior branch bound algorithm previous approach applied problems greater jobs 
branch bound algorithm despite age years new approach heuristic local search non systematic approaches able optimally solve guarantees problems larger jobs 
narayan morton claim exact methods impractical weighted tardiness problems larger advocate dispatch policies 
lower bounding scheme gives tighter lower bounds branch bound algorithm appearance literature 
branch bound algorithm potts van known dominance rules generate precedence relations prune branches search tree see 
search strategy explores newest active node order 
backward sequencing assumed branching 
search node level search tree consists jobs sequenced positions 
sub problems level form original problem fewer jobs 
addition precedence relations algorithm prunes search nodes noting sub problem possible sequence job zero tardiness sequenced sub problem 
search space pruning occurs considering final job sequences pairs search nodes 
final sequences contain subset jobs lower weighted tardiness subset jobs kept pruned 
weighted tardiness subset jobs final sequences discarded 
lower bound nodes sequence search node level computed solving lagrangian relaxation problem 
see original publication algorithm details relaxation solution 
myopic dispatch policies recall earlier discussion dispatch policies chapter dispatch policies heuristic rules choosing job sequence current local char problem 
dispatch heuristics literature problem grounded basis 
include wspt weighted shortest process time rule optimizes weighted tardiness job possibly scheduled earlier duedate 
considered heuristic highly constrained problems jobs scheduled earlier duedate 
defined wspt edd earliest duedate rule optimal possible sequence jobs job tardy 
unweighted version problem edd optimizes total tardiness job tardy 
edd considered rule loosely constrained problems problems jobs scheduled duedate 
define edd edd covert cost time rule complex dispatch policy attempts combine aspects edd wspt 
defined covert max kp current time parameter requires tuning 
usually set ad hoc way 
typical values 
policy morton referred apparent urgency apparent tardiness cost attempt combine aspects edd wspt 
defined exp max average processing time current time parameter requires tuning 
typical ad hoc values 
dispatch policy methods due robustness particularly dynamic variation problem jobs arrive dynamically problem constantly changing 
dispatch methods narayan morton heuristic extended allow insertion idle time processing jobs dynamic case handle case particularly important job arrive unexpectedly 
consider dynamic problem 
heuristics job sequenced job highest value heuristic 
name edd may imply smallest value heuristic earliest defined allow choosing job max heuristic values independent heuristic 
potts van suggest strategy sequences jobs times heuristics edd wspt covert takes best solution 
take idea heuristics conjunction qd beacon framework stochastic sampling 
local search currently exist complete optimal algorithms weighted tardiness sequencing problem years number successful applications local search algorithms problem 
potts van compare local search methods 
local search approaches considered study include strict descent allows operations improve objective value 
uses permutation representation pairwise interchanges jobs sequence allowed moves 
alternative considered binary encoding problem single bit flips local operator 
descent neutral moves allowed dn allows local moves solutions objective value 
simulated annealing sa representation alternatives operator sets 
threshold accepting ta representation alternatives operator sets 
algorithm multistart dynasearch weighted tardiness sequencing input number restarts instance weighted tardiness sequencing problem output solution multistart dynasearch bestsofar empty solution random sequence jobs false compute recursion equation compute sequence change local optima true better bestsofar bestsofar return bestsofar tabu search ts representation alternatives operator sets 
genetic algorithm ga uses binary encoding 
claim considered ga permutation encoding appropriate operators report results 
results chapter algorithms referred abbreviations 
square brackets abbreviation indicating results shown permutation representation binary representation refer strict descent permutation representation 
iterated dynasearch current best performing algorithm weighted tardiness scheduling problem arguably iterated dynasearch potts van de velde 
falls category local search singled due particular success 
chapter consider vbss method generating initial solution states improvement dynasearch 
describe iterated dynasearch algorithm describing dynasearch 
dynasearch essentially local hill climber 
name comes local operator set accurately name comes method compute operator set 
algorithm iterated dynasearch weighted tardiness sequencing input number kicks kick length start best kicks instance weighted tardiness sequencing problem heuristic generate initial solution 
output solution iterated dynasearch heuristic bestsofar jobs sequenced heuristic bestsofar false compute recursion equation compute sequence change local optima true better bestsofar bestsofar mod bestsofar compute random set independent swaps move neighboring return bestsofar common operator set local search algorithms problems represented permutations sequences pairwise swapping pairwise interchanging 
commonly changes objective value results swapping pairs jobs considered best swap taken 
dynasearch best set independent swaps 
words move search space dynasearch swaps 
set independent swaps dynamic programming 
th job current sequence 
initialize max recursion min max min max max max recursion computed search state best sequence reachable set independent swaps determined backtracking 
determined term minimization job swapped proceed determine computed 
computed second term minimization index swap jobs proceed determine computed forth 
jobs swapped procedure local optima 
repeat dynamic programming step compute set independent swaps 
potts van de velde describe iterated dynasearch 
iterated mean repeating described process randomly chosen starting configuration 
iterated dynasearch series randomly chosen sets independent swaps current local optima 
call kick 
iterations iterated dynasearch performs kick best far local optima current local optima 
begins iteration dynasearch resulting sequence 
initial solution configuration iteration iterated dynasearch generated dispatch policy 
iterated dynasearch seen algorithm 
additionally describe algorithm call multistart dynasearch restarts dynasearch randomly generated initial starting configuration local optima reached shown algorithm 
multistart version algorithm heuristic seed starting configurations 
state unbiased random starts effective presenting evidence 
results chapter show assumption false vbss qd beacon framework seed starting solution configurations multistart version dynasearch 
results significant improvement unbiased starts 
furthermore shown iterated dynasearch performed better multistart version 
qd beacon able improve iterated dynasearch performance 
benchmark problem set problem sets chapter library 
problem sets available library jobs jobs jobs 
integer process time job uniformly distributed interval 
integer weight job uniformly distributed interval 
integer duedate uniformly distributed interval tf rdd tf rdd average processing time tf average tardiness factor rdd relative range 
problem instances generated consider rdd tf 
combinations parameters problem instances generated 
done numbers jobs resulting instances jobs instances jobs instances jobs 
optimal solutions known job problems job problems 
job problems unsolved job problems current best known solutions available library 
performance criteria experimental results follow performance criteria number optimal best known solutions problem instances 
job problem set best known solutions prior iterated dynasearch allow consistent comparison solution methods currently available 
job problem set number previous best known solutions 
problem instances jobs reports new best known solutions 
cases approach finds new best known improve 
average relative percentage deviation solution value algorithm optimal solution value best known 
na listed divide zero occur 
maximum relative percentage deviation solution value algorithm optimal solution value best known 
na listed divide zero occur 
algorithm qd beacon vbss enhanced multistart dynasearch weighted tardiness sequencing input number restarts instance weighted tardiness sequencing problem output solution vbss qd beacon multistart dynasearch qd wspt bias bestsofar best solutions direct heuristics sequence jobs obtained iteration vbss false compute recursion equation compute sequence change local optima true heuristic bias objective better bestsofar bestsofar return bestsofar criteria average runs algorithm problem instances size 
tables sections values parentheses average indicate best runs 
vbss qd beacon enhance multistart dynasearch multistart version dynasearch described begins restart algorithm unbiased random starting configuration discussed 
stated advantage biasing starting configurations evidence 
section consider vbss existing dispatch policies problem edd wspt covert bias starting solutions restart vbss qd beacon heuristics bias starting solutions restart 
results contradict untested hypothesis 
significant improvement results multistart dynasearch vbss qd beacon bias starting solution configurations 
algorithm shows enhanced multistart algorithm 
bias function tuned heuristics relatively small number iterations set bias functions chosen rationale chapter 
bias functions vbss heuristic edd wspt covert covert stronger heuristics compared wspt stronger bias functions 
edd defined gives small real values relatively small range 
requires stronger bias function spread values vbss edd roulette wheel decisions 
scale parameter covert heuristics set 
qd beacon uses heuristics bias functions 
refer various algorithms considered abbreviations edd vbss edd heuristic seed restarts multistart dynasearch 
wspt vbss wspt heuristic seed restarts multistart dynasearch 
covert vbss covert heuristic seed restarts multistart dynasearch 
rm vbss heuristic seed restarts multistart dynasearch 
naive vbss seed restarts multistart dynasearch restarts heuristics 
norm qd beacon vbss heuristics normal distribution estimates aqdfs seed restarts multistart dynasearch 
kde qd beacon vbss heuristics kernel density estimates aqdfs seed restarts multistart dynasearch 
gev qd beacon vbss heuristics gev distribution estimates aqdfs seed restarts multistart dynasearch 
dyna restarts multistart dynasearch unbiased starting configurations specified originally 
results comparison algorithms job problems job problems job problems table table table respectively 
general observations results dyna original multistart dynasearch algorithm unbiased random starting solution configurations second worst algorithm considered comparison number restarts able defeat wspt multistart dynasearch starting configurations seeded vbss wspt heuristic poorly average 
previously untested hypothesis falsified benefit heuristic knowledge seed starts multistart dynasearch algorithm 
job problem set table combining multiple heuristics search necessary 
vbss covert heuristic seed starting solution configurations performs best number restarts considered restarts able consistently solve optimality instances job problem set 
turning job problem set table see restarts seeding starting configurations vbss covert best terms number instances solved optimality see seeding restarts vbss edd best terms relative percentage deviation 
problem instance seeding restarts vbss covert poorly see high covert value 
combining heuristics combine problem solving strengths 
see results restarts best strategy combining heuristics kde 
strategy able consistently solve optimality problem instances jobs 
combining heuristics effective solving instances job problem set table 
particular qd beacon kernel density estimates performs best terms number best known solutions numbers restarts considered marginally second best terms relative percentage deviation 
restarts qd beacon gev table job set qd beacon vbss enhanced multistart dynasearch vs original multistart dynasearch 
number restarts bold indicates best terms number optimal solutions italics indicates best terms percentage deviation 
algorithm covert kde norm gev edd rm dyna wspt covert kde gev norm edd rm dyna wspt covert naive kde gev norm edd rm dyna wspt naive gev kde norm dyna naive gev kde norm dyna table job set qd beacon vbss enhanced multistart dynasearch vs original multistart dynasearch 
number restarts bold indicates best terms number optimal solutions italics indicates best terms percentage deviation 
algorithm covert norm kde gev edd rm dyna wspt na na covert kde norm gev edd rm dyna wspt na na kde naive covert norm gev edd rm dyna wspt kde naive norm gev dyna kde gev naive norm dyna table job set qd beacon vbss enhanced multistart dynasearch vs original multistart dynasearch 
number restarts bold indicates best terms number best known solutions italics indicates best terms percentage deviation 
algorithm kde gev norm covert na na na na rm edd dyna wspt na na na na kde norm gev covert na na na na rm edd dyna wspt na na na na kde norm gev naive covert na na na na rm edd dyna wspt na na na na kde norm gev naive dyna kde norm gev naive dyna table tracking number samples allocated heuristics qd beacon kde single job problem instance 
covert rm edd wspt distribution best terms relative percentage deviation qd beacon normal distributions best terms relative percentage deviation restarts 
table show tracking number samples allocated heuristics qd beacon kde single job problem instance 
particular problem instance qd beacon strongly favors covert heuristic seen number samples allocated covert 
exploration strategy entirely abandon heuristics 
particular heuristic allocated samples run 
edd wspt far fewer samples totally abandoned wspt additional sample iteration despite sampled iteration 
lesson taken home study easier problems job instances multiple heuristic approach may necessary 
searching neighborhood single heuristic may sufficient 
case 
increase problem difficulty job problem set job problem set advantage incorporating multiple heuristics search routine 
difficult problem instances job problem set gain benefit qd beacon framework 
algorithm qd beacon enhanced iterated dynasearch weighted tardiness sequencing input number kicks kick length start best kicks instance weighted tardiness sequencing problem output solution qd beacon iterated dynasearch best edd jobs sequenced edd best wspt jobs sequenced wspt best rm jobs sequenced best covert jobs sequenced covert bestsofar best best edd best wspt best rm best covert edd best edd wspt best wspt rm best rm cov ert best covert edd wspt rm covert qd wspt functions heuristic heuristic false compute recursion heuristic equation heuristic compute sequence heuristic heuristic change local optima true heuristic bias objective heuristic heuristic better bestsofar bestsofar heuristic heuristic better best heuristic best heuristic heuristic heuristic mod heuristic best heuristic compute random set independent swaps move neighboring heuristic return bestsofar qd beacon enhance iterated dynasearch iterated dynasearch algorithm current best performing algorithm weighted tardiness sequencing problems 
vbss qd beacon enhanced multistart dynasearch better plain multistart dynasearch compare iterated dynasearch 
question consider iterated dynasearch improved qd beacon way 
recall iterated dynasearch algorithm seeds initial solution direct deterministic application dispatch policy 
dispatch policy chosen best heuristics heuristics edd wspt covert 
recall initial start iterated dynasearch local improvements sets independent swaps local optima reached 
local optima reached kicks current search state series random sets independent swaps 
iterations kicks current best solution current local optima 
modify iterated dynasearch algorithm interleave execution simultaneous iterated 
searches begins initial starting configuration dispatch policies 
qd beacon framework model distributions local optima encountered independent searches 
qd beacon control number iterations independent searches probability finding better solution best far implied aqdfs independent search 
hypothesis different starting configurations spread far apart objective landscape may able conduct local search different regions search space expending effort region looks promising 
qd beacon enhanced version iterated dynasearch shown algorithm 
results table job problems table job problems table job problems 
compare dyna original iterated dynasearch starting configuration search best solution deterministic application dispatch policies 
number kicks 
norm dyna iterated dynasearch enhanced qd beacon 
independent iterated interleaved dispatch policy originally table job set qd beacon enhanced iterated dynasearch vs original iterated dynasearch 
number iterations kicks bold indicates best terms number optimal solutions italics indicates best terms percentage deviation 
algorithm dyna kde dyna gev dyna norm dyna kde dyna dyna norm dyna gev dyna kde dyna dyna gev dyna norm dyna kde dyna dyna gev dyna norm dyna norm dyna kde dyna gev dyna dyna solution heuristics 
qd beacon normal distribution estimates control proportion computation time allocated searches algorithm 
total number kicks allocated searches 
kde dyna iterated dynasearch enhanced qd beacon 
independent iterated interleaved dispatch policy solution heuristics 
qd beacon kernel density estimates control proportion computation time allocated searches algorithm 
total number kicks allocated searches 
gev dyna iterated dynasearch enhanced qd beacon 
independent iterated interleaved dispatch policy table job set qd beacon enhanced iterated dynasearch vs original iterated dynasearch 
number iterations kicks bold indicates best terms number optimal solutions italics indicates best terms percentage deviation 
algorithm kde dyna dyna norm dyna gev dyna norm dyna kde dyna gev dyna dyna norm dyna gev dyna kde dyna dyna gev dyna norm dyna kde dyna dyna norm dyna gev dyna kde dyna dyna solution heuristics 
qd beacon gev distribution estimates control proportion computation time allocated searches algorithm 
total number kicks allocated searches 
results comparison algorithms job problems job problems job problems table table table respectively 
general observations results job problem set table small number total kicks original iterated dynasearch dyna able find optimal solutions average compared algorithms qd beacon enhance search result improved relative percentage deviation optimal solution values 
importantly total kicks qd beacon kernel density estimation enhance search kde table job set qd beacon enhanced iterated dynasearch vs original iterated dynasearch 
number iterations kicks bold indicates best terms number optimal solutions italics indicates best terms percentage deviation 
algorithm dyna kde dyna norm dyna gev dyna dyna kde dyna norm dyna gev dyna kde dyna norm dyna dyna gev dyna norm dyna kde dyna gev dyna dyna kde dyna dyna gev dyna norm dyna dyna consistently solve optimality problem instances 
original iterated dynasearch requires kicks dyna begins consistently solve problem instances optimality 
job problem set table version qd beacon enhanced algorithm best performer number kicks considered number optimal solutions relative percentage deviation 
stronger observation number kicks greater equal original iterated dynasearch worst performer algorithms considered terms number solutions solved optimality qd beacon enhanced algorithm better dyna independent estimation methods aqdfs 
job problem set table dyna best kicks table job set comparison qd beacon enhanced iterated dynasearch various local search algorithms 
algorithm time kde kde dyna dn dn sa sa ta ta ts ts ga terms number best known solutions qd beacon enhanced algorithm kernel density estimation best terms relative percentage deviation 
kicks algorithms qd beacon enhanced approach best number best known solutions kicks 
qd beacon enhanced approach benefit 
job problems allows consistently solve problem instances optimality fewer iterations kicks cpu time 
job problems qd beacon enhanced approach best independent number iterations algorithms 
difficult problem set job problems qd beacon enhanced approach performs best longer searches 
comparison local search algorithms section compare qd beacon enhanced iterated dynasearch local search algorithms listed earlier section 
local search algorithms originally tested hp ran mhz 
crude conversion cpu times reported equivalent cpu times sun ultra mhz 
multiplied times reported table job set comparison qd beacon enhanced iterated dynasearch various local search algorithms 
algorithm time kde gev dyna dn dn sa sa ta ta ts ts ga table job set comparison qd beacon enhanced iterated dynasearch various local search algorithms 
algorithm time kde kde dyna dn dn sa sa ta ta ts ts ga results comparison various local search algorithms seen table table table job job job problem sets respectively 
table list local search results reported cpu times adjusted stated 
listed table best variation multistart dynasearch algorithm comparable cpu time best variation iterated dynasearch algorithm comparable cpu time 
observations job problems table kde dyna clear winner comparison 
mentioned earlier kicks iterations kde enhanced iterated dynasearch algorithm optimally solve job instances 
done fraction time algorithms require 
best algorithm qd beacon vbss enhanced multistart dynasearch restarts kde algorithm requires significantly time kde dyna 
job problems table gev dyna clear winner 
gev enhanced iterated dynasearch algorithm iterations kicks optimally solves job problems relative percentage deviation optimal cpu time local search algorithms 
amount cpu time time restarts multistart algorithm kicks iterated algorithm lead better results 
job problems table half amount time kde able find significantly best known solutions local search algorithms 
fact qd beacon kde enhanced iterated dynasearch iterations kicks requires time restarts qd beacon kde enhanced multistart dynasearch time able find approximately best known solutions 
result qd beacon enhanced iterated dynasearch algorithm clearly dominant algorithm problem compared local search algorithms available benchmarks 
summary chapter considered problem weighted tardiness sequencing 
np hard optimization problem complete search algorithms currently unable guarantee finding optimal solutions problems larger jobs 
enhanced versions current best local search algorithms problem qd beacon framework combine different dispatch policies vbss framework seed starting solution configurations multistart version dynasearch algorithm 
result contrary untested hypothesis able obtain better results heuristic guidance seeding restarts 
able improve performance combining multiple heuristics qd beacon framework 
second qd beacon framework enhance iterated dynasearch algorithm 
iterated dynasearch best performing algorithm problem 
enhanced version uses qd beacon control amount search allocated independent iterated execution interleaved 
iterated begins different initial starting solution provided dispatch policies 
qd beacon model distribution local optima encountered control number iterations kicks 
allows search explore different regions search space concentrating effort promising regions search continues 
original iterated dynasearch algorithm began search single starting solution state 
qd beacon enhanced version exhibits improved performance shows benefit approach 
additionally qd beacon enhanced iterated dynasearch new best algorithm problem 
chapter application resource constrained project scheduling time windows overview chapter consider resource constrained project scheduling problem time windows rcpsp max 
rcpsp max rcpsp generalized precedence relations start times activities 
difficult makespan minimization problem studied operations research community 
finding feasible solutions instances rcpsp max np hard making optimization problem difficult 
rcpsp max problem adds interesting dimension analysis qd beacon vbss framework solving problem requires handling difficult csp problem context optimization process 
rcpsp max problem applicable project cmu robotics institute 
continuous mixed initiative resource management system collaborative incremental development plans schedules dynamic resource constrained domains 
lightweight plug applications objective deliver wide range web planning scheduling services 
vbss qd beacon framework simple fast effective stochastic search abilities valuable addition system provided capable efficiently solving rcpsp max problem 
rcpsp max problem applicable cmu robotics institute project fire 
fire federation intelligent robotic explorers project team developing market distributed multi robot coordination architecture 
architecture comprised layers planning executive behavior layers 
planning layer subdivided various components 
primary components planning layer include responsible activities bidding tasks conducting auctions responsible activities evaluating cost associated scheduling potential new task savings associated removing task current schedule 
rcpsp max problem relevant 
current instantiation fire system scheduler faced need frequently solve numerous scheduling problems essentially instances traveling salesperson problem tsp 
goals project incorporate complex scheduling constraints temporal constraints start times pairs tasks coordinated execution tasks involving multiple robots ability robot execute multiple tasks parallel provided resources 
constraints specified formalization rcpsp max problem 
algorithms developed chapter plugged scheduling component fire system need arises 
remainder chapter organized follows 
section formalize rcpsp max problem 
section overviews state art solution methods available rcpsp max problem 
section describes set benchmark instances experiments studied chapter 
section defines performance criteria 
section details qd beacon vbss iterative priority rule method 
section presents comparison number different algorithms approach combining multiple search heuristics qd beacon 
conclude chapter summary section 
problem formalization rcpsp max problem defined formally follows 
define 
instance rcpsp max 
set activities fa activity dummy activity representing start project similarly project 
activity fixed duration start time satisfy constraint 
set temporal constraints activity pairs form min max 

generalized precedence relations activities 
min max minimum maximum time lags start times pairs activities 
set renewable resources fr resource integer capacity 
execution activity requires resources 
resource activity requires integer capacity rc duration execution 
assignment activities time feasible temporal constraints satisfied resource feasible resource constraints satisfied 
schedule feasible sets constraints satisfied 
problem find feasible schedule minimum makespan maxfc wish find set assignments sol arg min 
maximum time lag constraints problem especially difficult 
particularly due maximum time lag constraints finding feasible solutions problem np hard 
state art solution methods neumann schwindt zimmermann give thorough exhaustive overview rcpsp max problem solution techniques solve 
detail algorithms mentioned section see individual papers describing see neumann survey 
algorithms section organized branch bound approaches section priority rule methods section local search section iterative sampling section 
branch bound large number branch bound approaches rcpsp max problem 
give details unnecessary 
simply point success applying branch algorithms problem 
problem instances costly execute branch bound long prove optimality solutions obtained reasonable amount computation time truncation allowing search run completion 
list branch bound approaches abbreviations results section results available benchmark set chapter de herroelen branch bound algorithm 
branch bound algorithm 
schwindt branch bound algorithm 
dorndorf branch bound algorithm 
priority rule methods section overview priority rule methods problem 
noted priority rule method chapter thing dispatch policy 
refers backtracking csp search uses priority rules heuristics choose activity schedule 
schedule mean sequencing sort way mean fixing start time variable place 
recall rcpsp max just optimization problem 
constraint satisfaction problem 
start time fixed amount constraint propagation takes place constraining domains start time variables 
priority rule method described section important method randomized vbss qd beacon section 
specific priority rule method describe referred direct method serial schedule generation scheme 
exist couple decomposition methods parallel schedule generation scheme franck direct method serial generation scheme perform better general 
priority rule method graph representation temporal constraints 
graph representation called project network 
nodes represent activities 
directed edges positive weights represent minimal time lag constraints directed edges negative weights represent maximal time lags 
priority rule method begins preprocessing phase consists propagating constraints tricks 
strong components project network schedule generation activity scheduled activities strong component referred cycle structure scheduled time 
pair activities combined resource requirement greater resource capacity temporal constraint added problem break pair element forbidden set 
constraint propagation propagate temporal constraints adjust domains start times activities 
preprocessing phase complete priority rule method begins serial generation scheme 
serial generation scheme backtracking csp search proce algorithm priority rule method rcpsp max serial schedule generation scheme input initial earliest latest start times activities es ls weights project network immediate predecessors activities pred maximum number steps backtracks max heuristic output set assignments start times serial schedule generation es ls pred max add scheduled set initialize resource profiles activities scheduled activities cycle structure cs scheduled eligible set unscheduled activities cs predecessors scheduled eligible set activities predecessors scheduled predecessors activities cycle structure scheduled cycle structure eligible activity preferred heuristic earliest resource feasible start time es ls max maximum number steps reached return empty solution ls schedule time add scheduled set update resource profiles foreach scheduled activity es max es ls min ls algorithm priority rule method rcpsp max step input activity value 
output set scheduled activities ls feasible schedule return terminate foreach es 
remove scheduled set foreach scheduled activity min remove scheduled set update resource profiles foreach scheduled activity es max max es ls foreach scheduled activity es max es ls min ls dure 
decision point search chooses activity schedule set eligible activities 
activity eligible temporal predecessors scheduled 
decision priority rule possible heuristics decision discussed 
selected start time activity scheduled earliest time resource feasible time 
point constraint propagation takes place adjust domains start times scheduled activities 
time resource feasible time start selected activity serial generation scheme performs calls step 
step essentially backtrack 
finds scheduled activity activities maximal time lag constraints involving activity unable schedule 
constrains start times occur late allow scheduling activity 
activities scheduled unscheduled activities 
appropriate constraint propagation takes place point 
serial generation scheme shown algorithm step backtracking step shown algorithm 
neumann recommend setting maximum number steps equal serial schedule generation scheme requires priority rule activity selection heuristic 
wide variety heuristics available literature 
neumann recommend particular 
heuristics vbss qd beacon lst smallest latest start time lst ls mst minimum slack time mst ls es mts total successors mts successors set necessarily immediate successors project network 
lpf longest path lpf length longest path rsm resource scheduling method rsm max max eligible set es ls note rephrased heuristics neumann definitions eligible activity highest heuristic value chosen 
heuristics available literature see example 
available rcpsp generalized precedence constraints obviously apply rcpsp max problem 
discussion results refer multiple run priority methods pr fns executing direct method serial generation scheme times heuristics described best solution 
frank originally suggested best heuristics solutions 
results shown implementation 
pr fn similarly best heuristics 
results shown reported dorndorf cesta franck neumann best heuristics method 
local search franck describe number local search algorithms problem 
leave reader details algorithms 
simply state constructing schedules direct priority rules method improve schedules local search 
algorithms comparison include ga genetic algorithm 
ts tabu search 
sa simulated annealing iterative sampling earliest solutions cesta algorithm rcpsp max problem call iterative sampling earliest solutions ises 
ises begins finding time feasible solution maximum horizon initially large project makespan assuming exists 
resulting time feasible solution interesting problem instance generally resource feasible 
ises proceeds iteratively leveling resource constraint conflicts 
detects sets activities temporally overlap total resource requirement exceeds resource capacity 
set resource constraint conflicts chooses conflicts heuristic chooses randomly resource conflicts acceptance band heuristic value franck neumann technical report describing best strategy longer available library institution secretary lab 
unable find heuristics produce results 
heuristic preferred choice 
levels chosen conflict posting precedence constraint activities conflicted set 
continues time feasible resource feasible solution resource conflict leveled 
iterated fixed number times stochastic sampling framework 
best solution stochastic sampling process entire algorithm repeated iteratively smaller smaller horizons specifically horizon makespan time feasible solution equal makespan best feasible solution far 
rest low level details ises algorithm 
cesta show ises better previous best heuristic algorithm rcpsp max problem pr fn 
benchmark problem set set benchmark problem instances experimental study chapter schwindt available www 
de ls neumann forschung html 
problem set generated problem generator known progen max 
approaches rcpsp max problem problem set large number approaches compare qd beacon vbss approach 
furthermore lower bounds current best known solutions cases optimal solutions available problem instances benchmark set 
problem instances problem set 
problem instances feasible solutions provably infeasible 
instance activities renewable resources 
difficulty problem instances controlled number parameters problem generator 
primary parameters govern problem difficulty order strength project network resource strength network 
order strength measure project network strictly ordered 
order strength means temporal constraints allow activities executed simultaneously resource constraints necessarily allow 
order strength equal means pair activities minimal time lag start activities start resulting strict order activities project 
projects lower order strengths progen max problem generator largely problem generator version problem generalized precedence constraints progen problem generator 
generally difficult 
resource strength measure scarcity resources 
resource strength means resources minimum capacity necessary process single activity time 
resource strength means schedule results starting activity earliest temporally feasible start time resource feasible optimal 
projects smaller values resource strength parameter generally difficult case resource strength equal close resource conflicts dealt fairly easily 
see complete detailed description problem generator detail generator parameters 
performance criteria experiments follow performance criteria compare performance algorithms rcpsp max problem 
lb average relative deviation known lower bound averaged problem instances feasible solution 
note number problem instances algorithm able find feasible solution different number problem instances algorithm compared 
criteria defined exactly approaches problem available literature 
number optimal solutions 
currently known optimal solutions problem instances 
nf number feasible solutions 
problem instances possess feasible solution 
proven infeasible preprocessing step priority rule method 
time cpu time seconds 
stochastic algorithms values shown averages runs 
values parentheses best runs 
results added comparison point list criteria current best known solutions best 
note best best known prior algorithms thesis 
improve best known solutions problem instances considered best 
qd beacon vbss iterative priority rule method section detail qd beacon vbss iterative priority rule method 
modifying serial generation scheme vbss randomize heuristic choose activity schedule eligible activities 
modified serial generation scheme algorithm 
change algorithm vbss randomize choice eligible activities 
step described earlier 
detail qd beacon vbss iterative priority rule method algorithm 
algorithm iteratively calls vbss randomized priority rule serial generation scheme algorithm heuristic bias function pairs chosen qd beacon framework updates aqdf appropriate heuristic bias function pair iteration 
results follow refer stochastic sampling framework vbss priority rule method iterations lst sampling lst heuristic polynomial bias function degree 
mst sampling mst heuristic polynomial bias function degree 
mts sampling mts heuristic polynomial bias function degree 
lpf sampling lpf heuristic polynomial bias function degree 
rsm sampling rsm heuristic polynomial bias function degree 
naive sampling equal number times heuristics iterations total 
depth tuning process performed determine bias functions 
tried small set problem instances 
range bias functions simple tuning determined general guidelines outlined chapter 
lst mst heuristic considered stronger bias functions polynomial degree way heuristics defined 
defined fraction potentially large number tend small real values small range require stronger bias spread values 
mts lpf values fairly spread somewhat weaker bias functions considered 
initial intuition regarding rsm heuristic require algorithm vbss enhanced priority rule method rcpsp max serial schedule generation scheme input initial earliest latest start times activities es ls weights project network immediate predecessors activities pred maximum number steps backtracks max heuristic bias function output set assignments start times vbss serial schedule generation es ls pred max add scheduled set initialize resource profiles activities scheduled activities cycle structure cs scheduled eligible set unscheduled activities cs predecessors scheduled eligible set activities predecessors scheduled predecessors activities cycle structure scheduled cycle structure eligible activity chosen randomly vbss heuristic bias function earliest resource feasible start time es ls max maximum number steps reached return empty solution ls schedule time add scheduled set update resource profiles foreach scheduled activity es max es ls min ls algorithm qd beacon vbss iterative priority rule method input initial earliest latest start times activities es ls weights project network immediate predecessors activities pred maximum number steps backtracks max heuristic bias function pairs fh maximum number iterations output set assignments start times qd beacon iterative priority rule method es ls pred max fh qd fh bestsofar best calls serial schedule generation es ls pred max schedule vbss serial schedule generation es ls pred max heuristic bias heuristic bias makespan schedule makespan schedule makespan bestsofar bestsofar schedule stronger bias function order required lst mst heuristics turns rsm heuristic generally perform randomized 
refer qd beacon vbss iterative priority rule method heuristic bias function pairs iterations aqdf estimation method follows norm iterations normal distribution estimates 
kde iterations kernel density estimates 
gev iterations gev distribution estimates 
results table shows summary results vbss priority rule method qd beacon vbss iterative priority rule method 
table lists problem instances able improve current best known solutions 
number observations looking vbss enhanced priority rule method results see number iterations best single heuristic terms number optimal table new best known solutions qd beacon vbss randomized iterative priority rule method 
lb lower bound makespan 
instance lb previous best new best algorithm mts norm kde norm kde gev lpf kde gev lpf norm kde gev solutions method longest path lpf heuristic 
furthermore vbss lpf able improve best known solutions couple problem instances 
observe vbss method lpf worst terms number feasible solutions 
lpf vbss appears perform problem instances find feasible solutions time having difficulties finding feasible solution large number problem instances 
observe similar behavior second best heuristic terms number optimal solutions vbss total successors mts considered 
vbss mts able improve best known solutions couple problem instances 
vbss lpf vbss mts performs poorly terms finding feasible solutions problems benchmark set 
vbss heuristics perform terms finding optimal solutions compared lpf mts heuristics allows search find feasible solutions problem instances 
see combining heuristics naive strategy qd beacon find feasible solutions nearly problem instances average time combining strengths individual heuristics terms finding optimal near optimal solutions 
comparing qd beacon guide choice search heuristic naive strategy giving equal number iterations heuristics see qd beacon method estimation models performs better naive strategy 
number iterations considered naive strategy worst terms number optimal solutions 
furthermore somewhat interestingly worst terms cpu time 
despite overhead required qd beacon estimation aqdfs naive strategy appears generally slower seconds slower iteration case 
reason qd beacon extra computational overhead modeling aqdfs able take advantage models giving iterations heuristics appear find feasible solution 
naive strategy results iterations find feasible solution performing maximum number steps allowed serial generation scheme infeasible iterations 
methods estimating aqdfs considered kernel density estimation performs best rcpsp max problem 
kde finds optimal solutions considered methods 
furthermore kde requires significantly cpu time gev particular estimation procedure gev distribution employed 
additional overhead kde compared norm appears negligible cpu timing results 
table lists results comparison qd beacon vbss iterative method various algorithms including branch bound approaches stochastic search algorithms 
observations best performing heuristic method clearly kde 
approximately cpu time previous best performing heuristic method ises kde finds optimal solutions significantly lower average deviation known lower bounds 
cpu time required ises kde consistently finds feasible solutions ises kde consistently finds optimal solutions ises kde average finds solutions deviate significantly known lower bounds compared ises 
branch bound algorithms considered able find optimal solutions kde 
approximately amount cpu time kde average performs best branchand bound algorithm terms deviation known lower bounds better best run kde 
kde table summary results vbss priority rule method qd beacon vbss iterative priority rule method 
algorithm 
lb nf time lpf lst mts mst rsm lpf mts lst mst rsm lpf mts lst mst rsm lpf mts lst mst rsm gev kde norm naive kde norm gev naive kde gev norm naive kde norm gev naive table comparison qd beacon vbss iterative priority rule method various algorithms rcpsp max problem 
algorithm 
lb nf time best pr fns pr fn ts sa ga ises kde kde adjusted original publication factor branch bound algorithms implemented mhz pentium algorithms sun ultra mhz 
adjusted original publication factor ises originally implemented sun ultrasparc mhz algorithms sun ultra mhz 
timing results available cases 
indicated 
competitive alternative truncated branch bound requires solutions necessarily optimal solutions highly limited amount time 
summary chapter considered rcpsp max problem 
rcpsp max difficult makespan minimization scheduling problem finding feasible solutions np hard 
vbss qd beacon enhance priority rules method problem 
resulting algorithm call qd beacon vbss iterative method new best performing heuristic method rcpsp max problem 
outperforms previous best heuristic algorithm ises finding optimal solutions problem instances cpu time ises 
qd beacon vbss iterative priority rule method competitive best branch bound approaches problem finding average solutions deviate known lower bounds compared branch bound algorithms fraction time despite branch bound algorithms ability find significantly optimal solutions qd beacon approach 
requires solutions necessarily optimal solutions highly limited amount time qd beacon vbss iterative priority rule method viable effective alternative truncated branch bound 
vbss iterative priority rule method able improve current best known solutions problem instances problem instances optimal solution currently known 
chapter summary thesis considered stochastic search algorithms strength robust scalable problem solvers 
tools algorithms designed analyzed allow effective performance enhancement existing stochastic search algorithms design new hybrid search algorithms combine problem solving strengths multiple heuristics 
ideas encapsulated thesis closely related concept algorithm portfolio 
fact qd beacon framework thesis viewed extension algorithm portfolio concept 
may recall algorithm portfolio executes multiple search algorithms parallel multiple processors interleaved single processor 
qd beacon framework thesis effective search control mechanism algorithm portfolio 
prior algorithm portfolios gives equal amount computation time algorithms portfolio 
qd beacon framework statistical models quality solutions generated algorithms computed online control strategy algorithm portfolio determining cycles allocate interleaved search strategies 
algorithmic exploration thesis began presenting new stochastic sampling algorithm called vbss 
vbss value biased alternative rank biased stochastic sampling algorithm known hbss 
considered novel mode computation stochastic decisions vbss computational model wasp social hierarchy formation 
lead variation vbss call whistling 
power vbss whistling algorithm compared hbss ity better discriminatory power inherent search heuristics stochastic sampling framework 
superior search performance demonstrated showed vbss framework able find significantly better solutions weighted tardiness sequencing problems significantly computation time compared hbss 
showed vbss seed starting solution configurations multistart hill climber enhance search performance local search algorithm 
somewhat contrary popular belief multistart hill perform better starting configurations random unbiased 
problems considered thesis strong heuristics disposal 
heuristics appear informed large number cases 
randomization strong heuristics multistart hill climber see benefit unbiased random starts stochastic samples start search near solution 
weighted tardiness sequencing sequence dependent setups saw approach ability find better solutions compared truncated systematic heuristic search algorithms lds dds significantly cpu time 
part reason result size problem space domain 
lds dds forced explore heuristically unattractive solution trajectories solution trajectories discrepancies discrepancies large heuristic value due systematic nature vbss avoid solution trajectories 
variation problem setups vbss seen able enhance algorithm called multistart dynasearch contrary untested claim authors multistart dynasearch algorithm 
defined algorithmic tool call aqdf distribution solution qualities produced iterative stochastic search algorithm 
algorithm dependent model modeling performance single algorithm 
problem instance dependent model modeling performance algorithm single problem instance 
aqdf related concept performance profile pp viewed detailed model time slice pp associated single iteration runs iterative stochastic search algorithm especially stochastic sampling algorithms 
aqdf model quality solutions produced iterations stochastic sampling algorithm model quality local optima discovered hill climbing algorithm 
final central algorithmic tool developed thesis qd beacon framework 
qd beacon provides functionality estimate statistical model aqdf online search 
furthermore qd beacon provides functionality models guide stochastic search algorithms effective search control 
example qd beacon choose multiple search heuristics iteration iteration basis stochastic sampling algorithm 
weighted tardiness sequencing problems showed qd beacon manner lead effective search algorithm compared single heuristic compared naive strategy giving equal number iterations heuristic 
showed qd beacon model local optima single start local search algorithm ability escape local optima 
ability able interleave execution multiple copies algorithm copy algorithm begins different region search space 
qd beacon allocate compute time multiple interleaved copies distributions local optima encountered 
technique enhance previous best performing algorithm weighted tardiness scheduling problem 
qd beacon conjunction vbss algorithm enhance backtracking heuristic guided csp search algorithm rcpsp max problem 
vbss randomize heuristic activity selection heuristics select set state art heuristics 
resulting algorithm call qd beacon vbss iterative priority rule method new best performing heuristic algorithm rcpsp max problem 
section summarize contributions thesis 
conclude thesis section considers possible refinements extensions research thesis 
contributions vbss whistling exploiting inherent discriminatory power heuristics 
vbss framework developed value biased alternative rank biased hbss algorithm 
actual heuristic values stochastic decisions sampling algorithm vbss better able leverage inherent discriminatory power search heuristic 
theoretically experimentally valid 
theory hbss uses order choices heuristic vbss uses heuristic values directly incorporating complete information available heuristic 
experimentally demonstrated improved search performance weighted tardiness scheduling problem 
improved decision making efficiency 
need rank order choices step alleviated value biased approach vbss stochastic decisions computed efficient time small constant multiplier log time required obvious implementation rank biased approach hbss 
rule possibility developing rank biased decision scheme scheme necessarily operate larger constant multiplier compared value biased approach 
pass computation 
dominance tournaments whistling allow search decision single pass choices small useful speedup 
qd beacon framework aqdf descriptive tool analysis quality distributions 
aqdf tool model distribution solutions single iteration runs stochastic search algorithm 
algorithm dependent model modeling performance single algorithm 
problem instance dependent model modeling performance algorithm single problem instance 
aqdf related concept performance profile pp viewed detailed model time slice pp associated single iteration runs iterative stochastic search algorithm especially stochastic sampling algorithms 
ability aqdf online prescriptive search guidance 
qd beacon framework provides number functions allow iterative stochastic search algorithms model aqdfs online effective search guidance 
methods estimating aqdf 
different methodologies developed estimating aqdf 
assumed aqdf normal distribution 
second distribution assumption kernel density estimation kde 
kde approach computes window width assumption type extreme value distribution gumbel distribution 
third method inspired body extreme value theory models aqdf maximum likelihood estimate generalized extreme value gev distribution 
method kde approach best 
normal estimates leads overly optimistic view heuristic performance heuristics high variance quality results produced provides search misleading guidance 
gev distribution offers closer fit actual distributions modeled aqdf 
theoretically true argued aqdf stochastic sampler guided strong heuristic samples extreme underlying distribution search space similarly distribution local optima encountered state theart local search algorithm extreme search space 
maximum likelihood estimated gev algorithms thesis turn follow type extreme value distribution bounded minimization problem 
number samples interested model aqdfs small relative theory gev 
result tends gev bounded tightly set samples offering search guidance pessimistic 
kde approach appears nice balance approaches 
scale parameter motivated gev kde approach produces aqdf estimates characteristics similar gev preserving amount optimism left hand tail aqdf 
theoretically motivated exploration policy 
new bandit problem max armed bandit problem posed analyzed 
result maximize expected max single sample reward series pulls bandit number samples observed best arm grow double exponentially number samples arms 
result motivated boltzmann exploration exponentially decreasing temperature parameter exploration policy choice qd beacon framework empirically worked better conservative cooling schedules 
applications weighted tardiness sequence dependent setups 
demonstrated vbss able find better solutions problem cpu time rank biased approach hbss proof inherent hypothesis design vbss 
saw results greatly improved minimal additional computational overhead applying simple local hill climber solutions iteration 
significant result multistart hill climber able find better solutions truncated systematic search procedures lds dds significantly time exploring small fraction sized search space 
systematic procedures get bogged exploring poor regions search space stochastic samplers vbss able avoid poor regions search space considering discriminatory power heuristic values 
lds dds systematically consider solutions order increasing discrepancy heuristic path small discrepancy discrepancies solution paths lead poor solutions 
evident values strong heuristic high value choice extremely small value discrepancy 
weighted tardiness setups 
contrary assumptions authors multistart dynasearch algorithm vbss qd beacon search heuristics bias starting solution configurations results significant improvement performance compared unbiased starting solution configurations 
effectively qd beacon enhance performance previous best known algorithm problem iterated dynasearch 
new algorithm qd beacon enhanced iterated dynasearch current best performing algorithm widely set benchmarks weighted tardiness sequencing problem 
rcpsp max 
vbss qd beacon enhanced state art priority rule search algorithm problem 
resulting algorithm superior previous best performing heuristic search algorithm ises problem competitive number truncated branch bound approaches problem 
vbss iterative priority rule method able improve best known solutions problem instances benchmark set 
refinements extensions applying framework additional problem domains 
thesis qd beacon vbss frameworks design enhance problem solving performance stochastic search algorithms number optimization domains including weighted tardiness sequencing problem sequence dependent setups weighted tardiness sequencing problem setups resource constrained project scheduling time windows 
volumes combinatorial optimization problems potentially benefit solution procedures involving vbss qd beacon framework 
evolving scheduler component fire system new problems 
components planning layer rovers fire architecture scheduler 
scheduler component charge solving scheduling problem rover requires order place bids tasks order evaluate bids rovers tasks 
currently particular scheduling problems faced scheduler component fire system essentially tsp instances 
scheduler component solves tsp instances vbss algorithm chapter thesis 
volumes existing tsp problem current instantiation scheduler component fire system obviously ground breaking 
goal develop best tsp algorithm 
goal develop scheduling component flexibility adapt different complex scheduling constraints objective functions 
fire project progresses vbss scheduler component easily adapted need solve complex scheduling problems arises 
example optimization objective changed minimizing weighted tardiness simply pull tsp search heuristic plug heuristics chapter chapter potentially combine qd beacon framework 
complex timing constraints considered tightly coupled rover coordination timing constraints new results obtained rcpsp max chapter plugged scheduler component rovers 
enhancing types search algorithms qd beacon 
qd beacon framework limited boosting performance stochastic sampling algorithms 
fact thesis seen examples qd beacon enhance performance number stochastic search algorithms 
saw qd beacon combine multiple search heuristics stochastic sampling algorithm 
second saw qd beacon vbss multiple search heuristics enhance multistart hill climbing algorithms example qd beacon vbss enhanced multistart dynasearch algorithm 
third qd beacon outside domain multistart algorithms interleave control amount cpu time multiple simultaneously executing iterated qd beacon enhanced iterated dynasearch algorithm 
qd beacon vbss create iterative multi pass version priority rule method constrained optimization domain rcpsp max qd beacon vbss iterative priority rule method 
algorithm combines stochastic sampling backtracking heuristic guided csp search algorithm uses qd beacon select competing heuristics 
stochastic search algorithms benefit application qd beacon framework 
example genetic algorithm choose multiple crossover mutation operators 
algorithm portfolio essentially done qd beacon enhanced iterated dynasearch algorithm control amount computation algorithm portfolio 
may useful revisit related ideas detailed models available qd beacon framework 
example sadeh expected cost improvement distributions detect unpromising runs simulated annealing may benefit extreme value theory motivation qd beacon framework 
learning bias functions 
qd beacon framework designed allow consider multiple bias functions heuristic modeling aqdf heuristic bias function pair 
extent necessary 
example rationale selecting bias function vbss algorithm types values choice heuristic function 
may easy decision priori 
possible solution qd beacon framework heuristic bias function pairs 
possibility adapt bias function learned model range heuristic values tracking heuristic values adapting bias function distribution quality solutions weakening bias expand search aqdf hitting wall 
asymmetric kernel functions 
demonstrated best performing estimation method aqdf qd beacon framework kernel density estimation 
recall kernel function chosen kde qd beacon epanechnikov kernel 
chosen primarily computational efficiency reasons outlined bounded easy compute integral 
desirable consider asymmetric kernel density estimator 
problem domains considered thesis theoretical lower bound problem instance bounded zero 
aqdfs modeled framework problem domains strongly skewed right appear bounded left 
asymmetric kernel density estimators specifically designed densities defined 
couple examples include gamma kernel inverse gaussian reciprocal inverse gaussian 
purposes may may required computations complex 
possible design asymmetric kernel suit computational needs 
going assumption search time iteration invariance 
qd beacon framework defined assumes amount search time required possible choice search heuristic approximately choices 
algorithms thesis holds part 
example sequencing problems vbss compute single solution requires approximately amount cpu time 
adding hill climber top vbss solution adds negligible cpu time due short hill climbs typically required algorithms thesis reach local optima invariance assumption approximately holds case 
qd beacon enhanced iterated dynasearch algorithm dynasearch local optima requires steps qd beacon interleave simultaneous iterated invariance assumption approximately holds 
case thesis search time iteration invariance assumption hold qd beacon vbss iterative priority rule method rcpsp max problem 
algorithm heuristics lead infeasible solutions sampled frequently find feasible solutions 
infeasible runs require time 
invariance assumption hold behavior algorithm favorable just 
cases detriment problem solving performance invariance assumption hold 
example sequencing problem vbss algorithm possible heuristics require drastically different amounts cpu time call heuristic function 
case important extend qd beacon framework consider addition model aqdf choosing heuristic iteration vbss 
example vbss heuristic takes twice time iteration compared heuristic want consider probability finding better solution best far iterations compared probability single iteration qd beacon distribute search solving multiple problem instances 
potentially interesting problem apply qd beacon framework distributing limited amount computation time solving multiple problem instances 
problem anytime computation community spent great deal effort 
modeling methods exploration strategy qd beacon framework conjunction anytime computation tools performance profiles enhance distribution compute time multiple problem instances 
bibliography adler wu 
scheduling system packaging industry 
operations research 

new lower bounding scheme total weighted tardiness problem 
computers operations research 
auer cesa bianchi fischer 
finite time analysis bandit problem 
proceedings th international conference machine learning pages 
morgan kaufmann 
auer cesa bianchi fischer 
finite time analysis bandit problem 
machine learning 
bauer bullnheimer hartl strauss 
ant colony optimization approach single machine total tardiness problem 
cec proceedings congress evolutionary computation pages july 
beasley 
library distributing test problems electronic mail 
journal operational research society 
www ms ic ac uk info html 
beasley 
weighted tardiness 
library 
imperial college management school 
available ms ic ac uk html 

attractors manufacturing systems chaotic tendencies 
presentation informs new orleans www informs org conf talks tb html 

dynamic programming 
princeton university press 
piazza 
finite digital filter design annealing algorithm 
proceedings icassp ieee international conference acoustic speech signal processing pages may 
berry 
bandit problems sequential allocation experiments 
chapman hall london uk 
boddy dean 
solving time dependent planning problems 
proceedings eleventh international joint conference artificial intelligence pages 
morgan kaufmann august 
boddy dean 
decision theoretic deliberation scheduling problem solving time constrained environments 
artificial intelligence 
bonabeau dorigo theraulaz 
swarm intelligence natural artificial systems 
santa fe institute studies sciences complexity 
oxford university press 
bonabeau theraulaz deneubourg 
adaptive task allocation inspired model division labor social insects 
olsson editors bio computation emergent computing pages 
world scientific 
bonabeau theraulaz deneubourg 
fixed response thresholds regulation division labor insect societies 
bulletin mathematical biology 

nonparametric statistics stochastic processes estimation prediction 
lecture notes statistics 
springer 

consistency asymmetric kernel density estimators smoothed histograms application income data 
technical report stat dp universite catholique de louvain 
boyan 
learning evaluation functions global optimization 
phd thesis school computer science carnegie mellon university pittsburgh pennsylvania 
boyan moore 
prediction improve combinatorial optimization search 
proceedings sixth international workshop artificial intelligence statistics 
boyan moore 
learning evaluation functions global optimization boolean satisfiability 
proceedings fifteenth national conference artificial intelligence aaai 

initialization mutation selection methods genetic algorithms function optimization 
belew booker editors proceedings fourth international conference genetic algorithms pages san mateo ca 
morgan kaufmann 
bresina drummond swanson 
search space characterization telescope scheduling application 
working notes aaai fall symposium planning learning real applications 
aaai press 
bresina drummond swanson 
expected solution quality 
proceedings fourteenth international joint conference artificial intelligence pages 
morgan kaufmann 
bresina 
heuristic biased stochastic sampling 
proceedings thirteenth national conference artificial intelligence eighth innovative applications artificial intelligence conference volume pages 
aaai press 
bullnheimer hartl strauss 
improved ant system algorithm vehicle routing problem 
annals operations research 
campos bonabeau theraulaz deneubourg 
dynamic scheduling division labor social insects 
adaptive behavior 
cao wu 
optimization control parameters genetic algorithms stochastic approach 
international journal systems science may 
carroll 
heuristic sequencing single multiple components 
phd thesis massachusetts 
cesta smith :10.1.1.44.3898
iterative sampling procedure resource constrained project scheduling time windows 
proceedings sixteenth international joint conference artificial intelligence pages 
morgan kaufmann 
cesta smith 
constraint method project scheduling time windows 
technical report cmu ri tr robotics institute carnegie mellon university pittsburgh pa february 
cesta smith 
constraint method project scheduling time windows 
journal heuristics 
chen gomes selman 
formal models heavy tailed behavior combinatorial search 
uncertainty computation papers aaai fall symposium technical report fs 
aaai press november 
chen 
probability density function estimation gamma kernels 
annals institute statistical mathematics 
chen sadeh 
job shop scheduling asynchronous team optimization agents 
ijcai workshop knowledge production planning scheduling control workshop notes pages august 
chiang fox ow 
factory model test data descriptions experiments 
technical report cmu ri tr robotics institute carnegie mellon university march 
cicirello 
intelligent retrieval solid models 
master thesis department mathematics computer science drexel university philadelphia pa june 
cicirello 
game theoretic analysis multi agent systems shop floor routing 
technical report cmu ri tr robotics institute carnegie mellon university pittsburgh pa september 
cicirello regli 
resolving non uniqueness design feature histories 
anderson editors fifth acm siggraph symposium solid modeling applications pages 
acm press june 
ann arbor mi 
cicirello regli 
machining feature comparison mechanical parts 
international conference shape modeling applications pages 
acm siggraph computer graphics society eurographics ieee computer society press may 
genova italy 
cicirello regli 
approach feature comparison solid models machined parts 
artificial intelligence engineering design analysis manufacturing november 
cicirello smith 
modeling ga performance control parameter optimization 
whitley goldberg cantu paz spector parmee beyer editors gecco proceedings genetic evolutionary computation conference pages 
morgan kaufmann publishers july 
las vegas nv 
cicirello smith 
ant colony control autonomous decentralized shop floor routing 
international symposium autonomous decentralized systems pages 
ieee computer society press march 
dallas tx 
cicirello smith 
improved routing wasps distributed factory control 
ijcai workshop artificial intelligence manufacturing working notes pages 
aaai sigman august 
seattle wa 
cicirello smith 
randomizing dispatch scheduling policies 
uncertainty computation papers aaai fall symposium technical report fs pages 
aaai press november 
north massachusetts 
cicirello smith 
wasp agents distributed factory coordination 
technical report cmu ri tr robotics institute carnegie mellon university pittsburgh pa december 
cicirello smith 
wasp nests self configurable factories 
muller andre sen editors proceedings fifth international conference autonomous agents pages 
acm sigart acm siggraph acm sigchi acm press may june 
montreal quebec canada 
cicirello smith 
amplification search performance randomization heuristics 
van hentenryck editor principles practice constraint programming cp th international conference proceedings volume lncs lecture notes computer science pages 
springer verlag september 
ithaca ny 
clark frank gent macintyre walsh 
local search number solutions 
proceedings second international conference principles practices constraint programming cp pages 
coles 
statistical modeling extreme values 
springerverlag 
potts van de velde 
iterated dynasearch algorithm single machine total weighted tardiness scheduling problem 
informs journal computing winter 
cormen leiserson rivest 
algorithms 
mcgraw hill 
cowling kendall han 
investigation hyperheuristic genetic algorithm applied trainer scheduling problem 
proceedings congress evolutionary computation cec pages may 
cowling kendall soubeiga 
adaptively parameterised hyperheuristics sales summit scheduling 
selected papers th metaheuristics international conference 
kluwer july 
cowling kendall soubeiga 
hyperheuristic approach scheduling sales summit 
practice theory automated timetabling iii third international conference selected papers number lncs lecture notes computer science pages 
springer verlag august 
cowling kendall soubeiga 
parameter free hyperheuristic scheduling sales summit 
proceedings th metaheuristics international conference pages july 
cowling kendall soubeiga 
hyperheuristics robust optimisation method applied nurse scheduling 
merelo beyer editors parallel problem solving nature ppsn vii th international conference proceedings number lncs lecture notes computer science pages 
springer verlag september 
cowling kendall soubeiga 
hyperheuristics tool rapid prototyping scheduling optimisation 
gottlieb hart middendorf editors applications evolutionary computing proceedings number lncs lecture notes computer science pages 
springer verlag april 
potts van 
local search heuristics single machine total weighted tardiness scheduling problem 
informs journal computing summer 
davidson harel 
drawing graphs nicely simulated annealing 
acm transactions graphics october 
de jong 
adaptive system design genetic approach 
ieee transactions systems man cybernetics 
de jong 
analysis behavior class genetic adaptive systems 
phd thesis university michigan ann arbor mi 
de herroelen 
branch bound procedure project scheduling problem generalized precedence constraints 
european journal operational research 
dean boddy 
analysis time dependent planning 
proceedings seventh national conference artificial intelligence pages 
aaai press august 
den stutzle dorigo 
ant colony optimization total weighted tardiness problem 
schoenauer deb rudolph yao lutton merelo schwefel editors proceedings ppsn vi sixth international conference parallel problem solving nature volume lecture notes computer science pages 
springer verlag 
di caro dorigo 
antnet distributed stigmergetic control communications networks 
journal artificial intelligence research 
dorigo di caro 
ant colony optimization meta heuristic 
corne dorigo glover editors new ideas optimization pages 
mcgraw hill 
dorigo gambardella 
ant colonies traveling salesman problem 
biosystems 
dorigo gambardella 
ant colony system cooperative learning approach traveling salesman problem 
ieee transactions evolutionary computation 
dorndorf pesch phan 
time oriented branch bound algorithm resource constrained project scheduling generalised precedence constraints 
management science 
dueck 
threshold accepting general purpose optimization algorithm appearing superior simulated annealing 
journal computational physics 
eiben michalewicz 
parameter control evolutionary algorithms 
ieee transactions evolutionary computation july 

machine sequencing minimize certain functions job tardiness 
operations research 
epanechnikov 
non parametric estimation multivariate probability density 
theory probability applications 
epstein 
right reasons forr architecture learning skilled domain 
cognitive science 
epstein freuder wallace samuels 
adaptive constraint engine 
van hentenryck editor principles practice constraint programming cp th international conference proceedings volume lncs lecture notes computer science pages 
springerverlag 
mohring stork 
resource constrained project scheduling time windows branching scheme dynamic release dates 
technical report technische universitat berlin berlin germany 
forsyth wren 
ant system bus driver scheduling 
technical report university leeds school computer studies july 
th international workshop computer aided scheduling public transport boston july 
franck neumann 
priority rule methods resource constrained project scheduling problem minimal maximal time lags empirical analysis 
th international workshop project management scheduling pages 
franck neumann 
resource constrained project scheduling time windows structural questions priority rule methods 
technical report universitat karlsruhe karlsruhe germany 
franck neumann schwindt 
truncated branch bound schedule improvement procedures resource constrained project scheduling 
spektrum 
franck 
metaheuristics resource constrained project scheduling schedule dependent time windows 
technical report universit karlsruhe karlsruhe germany 
frank cheeseman stutz 
gravity fails local search topology 
journal artificial intelligence research 
freuder dechter ginsberg selman tsang 
systematic versus stochastic constraint satisfaction 
proceedings fourteenth international joint conference artificial intelligence pages 
morgan kaufmann 
gambardella dorigo 
sop hybrid ant system sequential ordering problem 
technical report idsia istituto molle di studi idsia lugano switzerland 
gambardella taillard 
macs multiple ant colony system vehicle routing problems time windows 
technical report idsia istituto molle di studi idsia lugano switzerland 
glover 
tabu search part orsa journal computing summer 
glover 
tabu search part ii 
orsa journal computing winter 
goldberg cicirello dias simmons smith smith stentz 
distributed layered architecture mobile robot coordination application space exploration 
rd international nasa workshop planning scheduling space october 
houston tx 
goldberg cicirello dias simmons smith stentz 
multi robot planning distributed layered architecture 
multi robot systems swarms intelligent automata proceedings international workshop multi robot systems volume pages 
kluwer academic publishers march 
washington dc 
goldberg 
genetic algorithms search optimization machine learning 
addison wesley 
gomes selman kautz 
boosting combinatorial search randomization 
proceedings fifteenth national conference artificial intelligence tenth innovative applications artificial intelligence conference pages 
aaai press 
gomes selman 
algorithm portfolio design theory vs practice 
proceedings th conference uncertainty artificial intelligence uai morgan kaufmann 
gomes selman 
algorithm portfolios 
artificial intelligence 
gomes selman crato 
heavy tailed distributions combinatorial search 
principles practices constraint programming cp lecture notes computer science pages 
springer verlag 
gomes selman crato kautz 
heavy tailed phenomena satisfiability constraint satisfaction problems 
journal automated reasoning 
gray moore 
rapid evaluation multiple density models 
bishop frey editors proceedings ninth international workshop artificial intelligence statistics january 
grefenstette 
optimization control parameters genetic algorithms 
ieee transactions systems man cybernetics jan feb 
han kendall cowling 
adaptive length chromosome hyperheuristic genetic algorithm trainer scheduling problem 
proceedings th conference simulated evolution learning seal pages november 
harvey ginsberg 
limited search 
proceedings fourteenth international joint conference artificial intelligence pages 
morgan kaufmann 
holland 
genetic algorithms optimal allocations trials 
siam journal computing 
holland 
adaptation natural artificial systems introductory analysis applications biology control artificial intelligence 
university michigan press 
second edition mit press 
hooker 
testing heuristics wrong 
journal heuristics 
hoos stutzle 
characterizing run time behavior stochastic local search 
technical report aida darmstadt university technology germany 
hoos 
stochastic local search 
phd thesis darmstadt university technology germany november 
horvitz ruan gomes kautz selman chickering 
bayesian approach tackling hard computational problems 
proceedings th conference uncertainty artificial intelligence uai pages 
horvitz 
reasoning beliefs actions computational resource constraints 
proceedings third workshop uncertainty artificial intelligence pages 
aaai association uncertainty artificial intelligence july 
horvitz 
reasoning varying uncertain resource constraints 
proceedings seventh national conference artificial intelligence pages 
aaai press august 
hosking 
algorithm maximum likelihood estimation generalized extreme value distribution 
applied statistics 
hosking macleod 
maximum likelihood estimation parameters generalized extreme value distribution 
statlib applied statistics algorithms 
cmu 
lib stat cmu edu 
howe hansen von mayrhauser 
exploiting competitive planner performance 
fox editors advances ai planning th european conference planning ecp proceedings volume lncs lecture notes computer science pages 
springer verlag 
huberman lukose hogg 
economics approach hard computational problems 
science january 
kaelbling 
learning embedded systems 
phd thesis department computer science stanford university stanford california 
kaelbling littman moore 
reinforcement learning survey 
journal artificial intelligence research may 
kautz horvitz ruan gomes selman 
dynamic restart policies 
proceedings eighteenth national conference artificial intelligence 
aaai press july 

chaotic behavior manufacturing systems 
aaai workshop program reasoning shop floor workshop notes pages 
aaai press 
kendall soubeiga cowling 
choice function random hyperheuristics 
proceedings th asia pacific conference simulated evolution learning seal pages november 
kirkpatrick gelatt vecchi 
optimization simulated annealing 
science may 
koch scheer 
parallel hybrid meta optimization finding better parameters evolution strategy real world optimization problems 
wu editor proceedings genetic evolutionary computation conference workshop program pages july 
evolutionary computation parallel processing workshop 
farkas nagy 
base station positioning simulated annealing 
th ieee international symposium personal indoor mobile radio communications september 
kolisch hartmann 
heuristic algorithms solving project scheduling problem classification computational analysis 
technical report christian universitat zu kiel kiel germany february 
kolisch hartmann 
heuristic algorithms solving project scheduling problem classification computational analysis 
editor project scheduling models algorithms applications pages 
kluwer amsterdam netherlands 
kolisch sprecher 
project scheduling problem library 
technical report christian universitat zu kiel kiel germany march 
kolisch sprecher drexl 
characterization generation project scheduling problems 
management science 
korf 
depth iterative deepening optimal admissible tree search 
artificial intelligence 
korf 
improved limited discrepancy search 
proceedings thirteenth national conference artificial intelligence eighth innovative applications artificial intelligence conference volume pages 
aaai press 
korf 
linear space best search summary results 
proceedings national conference artificial intelligence aaai july 
koza 
genetic programming programming computers means natural selection 
mit press 
lagoudakis littman parr 
selecting right algorithm 
uncertainty computation papers aaai fall symposium technical report fs pages 
aaai press november 
langley 
systematic nonsystematic search strategies 
artificial intelligence planning systems proceedings international conference pages 
larson sandholm 
deliberation equilibrium bargaining computationally complex problems 
proceedings seventeenth national conference artificial intelligence aaai pages july august 
larson sandholm 
bargaining limited computation deliberation equilibrium 
artificial intelligence 
larson sandholm 
costly valuation computation auctions 
proceedings eighth conference theoretical aspects reasoning knowledge tark pages july 
lee 
heuristic minimize total weighted tardiness sequence dependent setups 
iie transactions 
lin kernighan 
effective heuristic traveling salesman problem 
operational research 
lopez molina katsaggelos 
spect image reconstruction prior models 
international journal pattern recognition artificial intelligence 
luby sinclair zuckerman 
optimal speedup las vegas algorithms 
information processing letters 
macleod 
algorithm maximumlikelihood estimation generalized extreme value distribution 
applied statistics 
bandyopadhyay 
clustering annealing evolution application pixel classification satellite images 
rd indian conference computer vision graphics image processing online proceedings december 
www ee iitb ac 
mckay 
factory hell modelling benchmark 
proceedings nsf workshop intelligent dynamic scheduling manufacturing systems pages june 
merkle middendorf 
ant colony optimization project scheduling 
gecco proceedings genetic evolutionary computation conference pages 
morgan kaufmann july 
mitchell 
genetic algorithms 
mit press 
morley 
painting trucks general motors effectiveness approach 
embracing complexity exploring application complex adaptive systems business pages 
ernst young center business innovation 
morley 
analysis plant specific dynamic scheduler 
proceedings nsf workshop intelligent dynamic scheduling manufacturing systems pages june 
morton 
heuristic scheduling systems applications production systems project management 
john wiley sons 
morton 
myopic heuristics single machine weighted tardiness problem 
technical report cmu ri tr carnegie mellon university pittsburgh pa november 
narayan morton 
dispatch methods weighted tardiness job shops 
working carnegie mellon university pittsburgh pa july 
nareyek 
global constraints local search 
freuder wallace editors constraint programming large scale discrete optimization volume dimacs pages 
american mathematical society publications 
nareyek 
choosing search heuristics non stationary reinforcement learning 
resende de sousa editors metaheuristics computer decision making 
kluwer academic publishers 
neumann schwindt zimmermann 
project scheduling time windows scarce resources temporal resource constrained project scheduling regular nonregular objective functions 
lecture notes economics mathematical systems 
springer verlag 
neumann zhan 
heuristics minimum project duration problem minimal maximal time lags fixed resource constraints 
journal intelligent manufacturing 
nist 
handbook statistical methods 
nist 
www itl nist gov div handbook 
smith 
stochastic procedures generating feasible schedules 
proceedings fourteenth national conference artificial intelligence ninth innovative applications artificial intelligence conference pages 
aaai press 
parkes 
clustering phase transition 
proceedings fourteenth national conference artificial intelligence aaai pages 
aaai press 
pemberton korf 
incremental search approach real time planning scheduling preliminary results 
proceedings nsf workshop intelligent dynamic scheduling manufacturing systems pages june 
potts van 
branch bound algorithm total weighted tardiness problem 
operations research 
potts van 
single machine tardiness sequencing heuristics 
iie transactions december 
press teukolsky vetterling flannery 
numerical recipes art scientific computing 
cambridge university press 
second edition 

local search backtracking vs non systematic backtracking 
uncertainty computation papers aaai fall symposium technical report fs pages 
aaai press november 
morton 
myopic heuristics single machine weighted tardiness problem 
working carnegie mellon university pittsburgh pa 
raman talbot 
real time scheduling automated manufacturing center 
european journal operational research 
ross mar hart 
hyper heuristics learning combine simple heuristics bin packing problem 
gecco proceedings genetic evolutionary computation conference pages 
morgan kaufmann 
rossi paechter 
hyperheuristic approach course timetabling problem evolutionary algorithm 
st multidisciplinary international conference scheduling theory applications august 
ruan horvitz kautz 
restart policies dependence runs dynamic programming approach 
van hentenryck editor principles practice constraint programming cp th international conference proceedings volume lncs lecture notes computer science pages 
springer verlag 

incomplete tree search adaptive probing 
proceedings seventeenth international joint conference artificial intelligence pages august 

prior knowledge adaptive probing 
uncertainty computation papers aaai fall symposium technical report fs pages 
aaai press november 

adaptive tree search 
phd thesis harvard university may 
russell norvig 
artificial intelligence modern approach 
prentice hall upper saddle river new jersey 

explorations asynchronous teams 
phd thesis department electrical computer engineering carnegie mellon university pittsburgh pa december 
sadeh 
learning recognize un promising simulated annealing runs efficient search procedures job shop scheduling vehicle routing 
annals operations research 

density estimation inverse reciprocal inverse gaussian kernels 
technical report dp universite catholique de louvain 
schaffer caruana eshelman das 
study control parameters affecting online performance genetic algorithms function optimization 
schaffer editor proceedings third international conference genetic algorithms san mateo ca 
morgan kaufmann 
schoonderwoerd holland bruten 
ant agents load balancing telecommunications networks 
agents proceedings international conference autonomous agents pages 
acm press 
schoonderwoerd holland bruten rothkrantz 
ant load balancing telecommunications networks 
adaptive behavior 
schwindt 
progen max new problem generator different project scheduling problems minimal maximal time lags 
technical report universitat karlsruhe karlsruhe germany july 
schwindt 
generation resource constrained project scheduling problems minimal maximal time lags 
technical report universitat karlsruhe karlsruhe germany november 
schwindt 
branch bound algorithm resource constrained project duration problem subject temporal constraints 
technical report universit karlsruhe karlsruhe germany 
schwindt 
generation resource constrained project scheduling problems subject temporal constraints 
technical report universitat karlsruhe karlsruhe germany november 
schwindt 
project generator progen max psp max library 
www uni karlsruhe de ls neumann forschung 
selman kautz cohen 
local search strategies satisfiability testing 
johnson trick editors cliques coloring satisfiability second dimacs implementation challenge october volume dimacs series discrete mathematics theoretical computer science 
american mathematical society 
sen bagchi 
graph search methods non order preserving evaluation functions applications job sequencing problems 
artificial intelligence september 
shi 
nested partitions method global optimization 
operations research may june 
silverman 
algorithm kernel density estimation fast fourier transform 
applied statistics 
silverman 
density estimation statistics data analysis 
monographs statistics applied probability 
chapman hall 
singer gent smaill 
backbone fragility local search cost peak 
journal artificial intelligence research 
smith 
design web planning scheduling services 
proceedings ecp planet workshop automated planning scheduling technologies new methods electronic mobile collaborative september 
smith 
interactive resource management planner 
proceedings ijcai workshop intelligent systems august 
smith 
various optimizers single stage production 
naval research logistics quarterly 
stutzle 
ant approach flow shop problem 
proceedings th european congress intelligent techniques soft computing volume pages 
verlag mainz aachen 
sutton barto 
reinforcement learning 
mit press cambridge ma 
gove de souza 
asynchronous teams cooperation schemes autonomous agents 
journal heuristics 

asynchronous teams 
technical report engineering design research center department electrical computer engineering carnegie mellon university pittsburgh pa 
tapia thompson 
nonparametric probability density estimation 
johns hopkins university press baltimore london 
theraulaz bonabeau deneubourg 
self organization hierarchies animal societies case wasp christ 
journal theoretical biology 
theraulaz bonabeau deneubourg 
response threshold reinforcement division labour insect societies 
proceedings royal society london february 
theraulaz goss deneubourg 
task differentiation wasp colonies model self organizing groups robots 
animals animats proceedings international conference simulation adaptive behavior pages 
mit press 
van der marques 
ant colony optimisation job shop scheduling 
proceedings workshop genetic algorithms life lisbon portugal march 
van laarhoven aarts 
simulated annealing theory applications 
reidel publishing kluwer academic publishers 
walsh 
depth bounded search 
proceedings fifteenth international joint conference artificial intelligence pages 
morgan kaufmann 
wasserman 
lecture notes 
nonparametric methods 
www stat cmu edu larry stat 
watson barbulescu howe whitley 
algorithm performance problem structure flow shop scheduling 
proceedings sixteenth national conference artificial intelligence aaai eleventh innovative applications artificial intelligence conference iaai pages 
aaai press 
watson beck howe whitley 
understanding local search cost job shop scheduling 
proceedings sixth european conference planning 
watson beck howe whitley 
problem difficulty tabu search job shop scheduling 
artificial intelligence february 
wong leong liu 
simulated annealing vlsi design 
kluwer academic 
wu chow 
genetic algorithms nonlinear mixed discrete integer optimization problems meta genetic parameter optimization 
engineering optimization 
yao 
call routing simulated annealing 
international journal electronics 
zilberstein 
operational rationality compilation anytime algorithms 
phd thesis university california berkeley 
zilberstein 
anytime algorithms intelligent systems 
ai magazine fall 
zilberstein russell 
optimal composition real time systems 
artificial intelligence 
appendix weighted tardiness scheduling sequence dependent setups benchmark set overview appendix details set problem instances experiments chapter 
problem instances available online www cs cmu edu vincent benchmarks html www ozone ri cmu edu benchmarks html file format problem instance file described section 
current best known solutions instances various algorithms discussed chapter listed section 
instance file format instance benchmark library stored separate file file format problem instance problem size generator parameters tau eta bar min max bar max weight max bar generator parameters problem specification process times 
weights 

setup times indicates setup time job problem specification best known solutions list best known solutions list problem instance number best objective value instance algorithm 
algorithms referred follows lds lds limited discrepancy search allowed run long consider discrepancy solutions 
hbss hbss specified number iterations bias function equal rank bias vbss vbss specified number iterations bias function equal value bias vbss hc random restart hill climber vbss seed starting solutions specified number iterations bias function equal value bias sa simulated annealing modified lam schedule specified number total evaluations 
search begins atcs solution 
algorithms described detail chapter thesis 
algorithms considered including dds variations lds lee single start hill climber deterministic atcs policy best known solutions exclusively find best known solutions 
best known solutions follows problem instance objective value algorithm vbss hc vbss hc vbss hc sa vbss hc vbss vbss hc vbss hc lds vbss hc vbss hc lds vbss hc vbss vbss hc vbss hc vbss hc vbss vbss hc vbss hc lds lds lds sa sa lds sa sa lds sa problem instance objective value algorithm lds lds lds lds lds lds vbss hc lds lds lds sa vbss hc lds sa vbss sa sa lds sa sa vbss hc vbss hc vbss hc vbss vbss sa vbss vbss hc vbss hc vbss hc problem instance objective value algorithm sa sa vbss sa sa sa sa sa sa sa vbss hc vbss hc lds vbss hc lds vbss hc sa sa vbss vbss vbss vbss sa vbss sa vbss sa vbss vbss hc lds problem instance objective value algorithm vbss vbss vbss vbss vbss lds vbss vbss vbss vbss hc lds lds vbss vbss vbss lds vbss vbss vbss lds vbss vbss hc vbss vbss hc vbss lds vbss hc lds vbss vbss hc 
