support vector online detection abrupt changes fr ric manuel davy umr cnrs rue de la bp nantes cedex france frederic manuel davy ec nantes fr machine learning technique aimed detecting abrupt changes sequence vectors 
algorithm requires mercer kernel corresponding feature space 
stationarity index designed feature space consists comparing circles corresponding sv novelty detectors fisher ratio 
abrupt change corresponds large distance circles centers radii 
show index computed input space simulation results show efficiency front real data 

abrupt changes detection signals studied problem various approaches proposed 
rely knowledge signal statistical model generalized likelihood ratio glr techniques bayes detection theory excellent performance 
applications may difficult design accurate tractable statistical model model free approaches need considered 
propose model free machine learning online algorithm abrupt changes detection signals 
algorithm step 
informative descriptors vectors localised time denoted extracted online signal 
cepstral coefficients computed sliding window short time fourier transforms second define kernel online stationarity index computed descriptors space input space denoted geometrically defined feature space induced mercer kernel selected 
time support vector sv novelty detector trained descriptors yielding decision region vector considered similar iff second sv novelty detector trained descriptors roughly computed follows 
kernel yielding regions rep probability density functions pdfs generated sets comparing geometries locations robust way compare show easily done feature space computed input space remainder organized follows 
section recall basic elements sv novelty detection 
relation mercer kernels feature spaces exposed :10.1.1.11.2062
section algorithm described 
particular explain stationarity index defined feature space computed input space 
simulation results section perspectives section 
sv novelty detection assume set training points available input space define learning algorithm hypothesis space indicator functions subsets define mapping called feature space assume endowed dot product restrict indicator functions decision regions form decision function defined eq 
linear combination mapped training points parameters completely define training set determined solving subject dual formulation obtain directly minimizing subject training points called support vectors svs points sv algorithms yield eq 
svs determine svs divided sets margin svs non margin svs proved upper bound fraction non margin svs lower bound fraction support vectors addition asymptotically equal fraction svs fraction non margin svs probability mild conditions probability distribution generating data 
note need compute mapping eq 
follows computed dot product function ker nel represents dot product feature space fulfills mercer conditions 
conditions satisfied wide range kernels including gaussian radial basis functions 
online abrupt changes detection algorithm section introduce main result algorithm aimed detecting online abrupt changes distribution vec tors observed sequentially time 
sequence produced directly system 
signal processing applications typically results preprocessing step aimed extracting descriptors signal time instant 
algorithm description consider time subsets size subsets train independently sv novelty detectors yielding parameters decision regions idea underlying abrupt changes detector sudden change time distribution vectors may result different locations geometries depicted input space fig 
practice time want build index reflects dissimilarity measure dissimilarity 
computation described subsection 
computed subsets updated time corresponding parameters updated online sv novelty detection technique 
online technique avoids computing sv novelty detec tion parameters scratch time abrupt changes detected index peaks threshold similar abrupt changes detection techniques 
subsection propose original stationarity index induced geometrical considerations feature space 

geometry feature space consider normalized mercer kernel mapped training vectors located hy centered origin denoted radius training set say optimisation problem eq 
admits geometrical interpretation 
parameters hyperplane define orthogonal distant see fig 

separates mapped training vectors 
mapped region portion delimited located opposite 
boundary hypersphere radius entirely defined similarly ing eq 
hyperplane yields defined feature space shapes mapped regions simple boundaries 
fully compared center locations radii computed compare simple way build consists considering ratio distance circle centers radius radius means training sets located position expect exists triplet situations 
assume circle radius center respectively points located intersection line passing oriented respec tively see fig 

geometrical centers region occupied feature data possess properties similar mapped margin support vectors lie separating hyperplane 
points possibly pre images input space 
expressed terms dot products feature space kernels input space 
note written located circle angle denotes circle arc radius eq 
circle arc resp 
correspond resp 
resp 

similar computations express circle arc obtain similar result function computed shows positive kernel mapped data lie orthant angle 
fig 

feature space training data mapped hypersphere radius center 
sv novelty detector related resp 
yields resp hyperplane resp 
exceed angle lower especially abrupt change 
case cosine bijective consider modified index 
discussion eq 
see fisher ratio 
abrupt changes detected correspond abrupt change means due term scale data 
note robust liers due abrupt changes sv novelty detection rejects outliers 
fundamentals rayleigh coefficient kernel fisher discriminant kfd analysis coefficient different kfd rayleigh coefficient maximized projection direc tion technique yielded sv novelty detectors :10.1.1.11.2062
approach sv classification consid ered seen training sets different classes 
train svm classifier sets consider margin stationarity index 
approach suffers drawbacks 
abrupt change occurs mixed designing classifier somewhat artificial meaningless 
second vectors considered outliers sv classification different considered outliers sv novelty detectors 
way selected set governed set behavior process third computational burden higher sv classification training vectors costs training independently vectors 
approach addresses related different problem early abnormality detection detection delay tolerated 
candidate tested respect fig 

input space evolution separating curves yielded sv novelty detectors mean subsets change top left top right bottom left bottom right 
surfaces small overlap correspond change 
novelty detector trained set sta index built output detector simulations music signals yielded results abnormality early detection adequate context music segmentation detection delay accepted 

simulations section compare algorithm standard signal processing methods aimed detecting abrupt changes generalized likelihood ratio glr see detailed presentation technique distance time frequency subimages 
opposed glr technique model free 
techniques tested artificial real data 
set artificial data composed realisations white gaussian noise length filtered order model moduli equal frequencies drawn signals ar parameters abrupt change point kept change 
techniques tuned follows 
depicted previous sections algorithm fed subsets descriptors extracted smoothed pseudo wigner ville input signal time window length frequency window length 
training vec tor tfr subimage width training set size support vector parameters rbf gaussian kernel tfr distance method tfr subimage width equal select kolmogorov distance 
glr correct autoregressive model different orders correct order input signal method yields index maximum higher method dependent threshold corre sponds estimated abrupt change time instant 
define false alarms fas detection change outside neighborhood true change time instant true alarms tas correct detection abrupt change inside neighborhood 
fig 
plots roc curves tas vs fas methods 
autoregressive model orders yield true alarm rate false alarm rate fig 

roc curves distance method dot glr lower order dash dot svm method dash glr correct superior orders solid 
accurate performances yielded glr correct superior order svm method 
accurate results expected correct model 
svm detector behaves accurately cent true positives cent false positives priors analyzed data 
tf distance method glr lower order yield poor performances 
similar results observed histograms time instants corresponding true positives fig 

note svm fig 

histograms estimated change time instant percentage detected time instant inside admissible neighborhood theoretic change time instant distance method left svm method middle glr correct order right 
method gives better results tf distance technique descriptors input 
tested algorithm music signals proved quite efficient 
displays index obtained music signal 
change dynamics properly detected confirmed listening piece case distance index see 
index smoother abrupt changes corresponding sharp peaks high constrast areas changes 
fig 

music signal top corresponding svm abrupt change detection index bottom 
threshold equal changes dashed lines correctly detected false positive circled 

introduced original kernel technique detecting abrupt changes signals 
simulations show behavior algorithms synthetic data superior performance music signals terms accuracy detection constrast 

basseville detection abrupt changes theory application prentice hall april 
smola sch lkopf learning kernels mit press 
sch lkopf platt shawe taylor smola williamson estimating support highdimensional distribution neural computation vol 
pp 

vapnik nature statistical learning theory springer 
line class support vector machines 
application signal segmentation ieee icassp hong kong china april submitted 
davy godsill detection abrupt spectral changes support vector machines 
application audio signal segmentation ieee icassp orlando usa may 
laurent stationarity index abrupt changes detection time frequency plane ieee signal processing letters vol 
pp 
february 
