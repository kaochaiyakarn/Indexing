scalable approach thread level speculation gregory christopher zhai todd mowry computer science department carnegie mellon university pittsburgh pa cs cmu edu architects build cost effective parallel machines wide spectrum machine sizes ranging single chip large scale servers real challenge easily create parallel software effectively exploit raw 
promising technique overcoming problem thread level speculation tls enables compiler optimistically create parallel threads despite uncertainty threads independent 
propose evaluate design supporting tls seamlessly scales machine size straightforward extension writeback invalidation cache coherence scales 
experimental results demonstrate scheme performs single chip multiprocessors larger scale machines communication latencies times larger 

machines simultaneously execute multiple parallel threads increasingly commonplace wide variety scales 
example techniques simultaneous multithreading alpha single chip multiprocessing sun ibm power suggest thread level parallelism may increasingly important single chip 
chip boundaries personal computers sold days configurations 
high machines sgi origin long exploited parallel processing 
greatest stumbling block exploiting raw performance potential ability automatically convert single threaded programs parallel programs 
despite significant progress automatically parallelizing regular numeric applications compilers little success automatically parallelizing highly irregular numeric especially non numeric applications due complex control flow memory access patterns 
particular fact memory addresses difficult impossible statically predict part depend run time inputs originally appeared acm ieee international symposium computer architecture isca vancouver canada june 
reprinted permission 
definitive copy available acm digital library located www acm org dl 
acm copyright notice 
copyright association computing machinery permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copyrights components owned acm honored 
abstracting credit permitted 
copy republish post servers redistribute lists requires prior specific permission fee 
request permissions publications dept acm fax permissions acm org 
behavior extremely difficult compiler statically prove potential threads independent 
architectural technique may help overcome problem thread level speculation 
thread level speculation thread level speculation tls allows compiler automatically parallelize portions code presence statically ambiguous data dependences extracting parallelism dynamic dependences exist run time 
illustrate tls works consider simple loop accesses elements hash table 
loop statically parallelized due possible data dependences array hash 
possible iteration depend data produced immediately preceding iteration dependences may fact infrequent hashing function effective 
mechanism speculatively execute loop iterations parallel squashing iterations suffer dependence violations potentially speed loop significantly illustrated 
read write raw data detected epoch epoch epoch squashed restarted produce correct result 
example demonstrates basic principles tls applied regions code loops 
example assume program running shared memory multiprocessor number processors case allocated program operating system 
processors assigned unit epoch case single loop iteration 
timestamp epoch epoch number indicate ordering original sequential execution program 
say epoch logically earlier epoch epoch numbers indicate epoch preceded epoch original sequential execution 
violation data dependences imposed original program order detected runtime tls mechanism 
epoch guaranteed violated data dependences epochs commit speculative modifications say epoch 
provide guarantee passing token epoch 
examples thread level speculation exploration interface tls hardware software earlier publication 
related example code continue condition hash index hash index execution thread level speculation epoch epoch epoch epoch hash hash hash hash hash hash hash hash attempt commit attempt commit attempt commit attempt commit violation 
redo processor processor processor processor epoch hash hash attempt commit 
epoch hash 
epoch hash 
epoch hash 
time 
example thread level speculation 
knight propose hardware support form thread level speculation context functional languages 
multiscalar architecture complete design evaluation architecture tls 
proposals extend basic idea thread level speculation 
nearly cases target architecture tightly coupled machine threads executed chip 
proposals exploited tight coupling help track preserve dependences threads 
example stanford hydra architecture uses special write buffers hold speculative modifications combined write coherence scheme involves snooping write buffers store 
approach may perfectly reasonable single chip designed scale larger systems 
exception prior publication proposal zhang form tls large scale numa multiprocessors 
approach potentially scale large machine sizes evaluated matrix programs success handling pointer codes demonstrated 
addition appear choice small scale machines single chip 
concurrent study proposed hierarchy memory disambiguation tables support tls numa multiprocessor comprised speculative chip multiprocessors 
subtle differences respective approaches striking difference hardware enforces hierarchical ordering threads level inside speculative multiprocessor chip level chips 
contrast separate ordering physical location explicit software managed integrate tracking directly cache coherence may may implemented hierarchically speculation occurs single flat speculation level described section impose ordering scheduling constraints threads 
objectives study goal study design evaluate unified mechanism supporting thread level speculation handle arbitrary memory access patterns just array appropriate scale architecture parallel threads including simultaneous multithreaded processors single chip multiprocessors traditional shared memory multiprocessors size multiprocessors built software distributed shared memory 
approach scales architectures built writeback invalidation cache coherence scales machines 
unified approach supporting thread level speculation offers advantages 
build large scale parallel machine single chip multiprocessors processors building blocks seamlessly perform thread level speculation entire machine subset processors machine 
second compile program exploit thread level speculation run directly machines recompiled 
demonstrate experimental results executables buk equake exploit unified thread level speculation mechanism achieve speedup single chip multiprocessor multi chip multiprocessors inter chip communication latencies times larger 
remainder organized follows 
section describes invalidation extended detect data dependence violations section gives possible hardware implementation scheme 
describe experimental framework section evaluate performance scheme section conclude section 
coherence scheme scalable speculation support thread level speculation perform difficult task detecting data dependence violations run time involves comparing load store addresses may occurred order respect sequential execution 
comparisons relatively straightforward instruction level data speculation single thread load store addresses compare 
thread level data speculation task complicated addresses compare relative interleaving loads stores different threads statically known 
solution leverage invalidation cache coherence 
recall invalidation cache coherence processor invalidate cached copies line get exclusive ownership modify line 
key insight scheme extend existing invalidation messages detect data dependence violations noticing invalidation arrives logically earlier epoch line speculatively loaded past 
epoch violation 
false processor processor cache 
store 
speculative load 
attempt commit cache read request invalidation epoch epoch epoch fail epoch violation 
true sl sm speculatively loaded 
speculatively modified 
time 
cache coherence detect raw dependence violation 
example illustrate basic idea scheme show example detects read write raw dependence violation 
recall speculative load violates raw dependence memory location subsequently modified epoch store preceded load original sequential program 
shown augment state cache line indicate cache line speculatively loaded sl speculatively modified sm 
cache maintain logical timestamp called epoch number indicates sequential ordering epoch respect epochs flag indicating data dependence violation occurred 
example epoch performs speculative load corresponding cache line marked speculatively loaded 
epoch stores cache line generating invalidation containing epoch number 
invalidation received things true raw dependence violation 
target cache line invalidation cache 
second marked having speculatively loaded 
third epoch number associated invalidation logically earlier epoch 
conditions true example raw dependence violated epoch notified setting violation flag 
show full coherence scheme handle cases concept analogous example 
sections follow define new speculative cache line states actual cache coherence scheme including actions occur epoch notified violation occurred 
describing underlying architecture assumed coherence scheme 
underlying architecture goal coherence scheme general scalable size machine 
want coherence mechanism applicable combination single threaded multithreaded processors shared memory multiprocessor restricted simply single chip multiprocessors 
simplicity assume shared memory architecture supports invalidation hierarchies enforce inclusion property 
shows general architecture private caches shared caches interconnection network external actions processor actions physically physically simplified architecture external actions processor actions cache cache shared memory 
base architecture tls coherence scheme 
generalization underlying architecture 
may number processors single multithreaded processor followed arbitrary number levels physically private caching 
level interest level invalidation cache coherence begins refer speculation level 
generalize levels speculation level away processors interconnection network providing access main memory arbitrary number levels caching 
amount detail shown necessary purposes describing cache coherence scheme 
shows simplified model underlying architecture 
speculation level described happens physically shared cache simply referred cache 
caches number processors caches implementation shared memory 
coherence recursive speculation occurs speculation level 
speculation level closer processors maintain speculative state buffer speculative modifications 
speculation level processors simply propagate speculative coherence actions enforce inclusion 
overview scheme remainder section describes important details coherence scheme requires key elements notion cache line speculatively loaded speculatively modified ii guarantee speculative cache line propagated regular memory speculation fail speculative cache line replaced cache line states state description invalid exclusive shared dirty spe speculative sm sl exclusive sps speculative sm sl shared coherence messages message description read read cache line 
read exclusive return copy cache line exclusive access 
upgrade upgrade request gain exclusive access cache line 
inv invalidation 
writeback supply cache line relinquish ownership 
flush supply cache line maintain ownership 
notify cache line shared 
read exclusive speculative return cache line possibly exclusive access 
upgrade request speculative request exclusive access cache line 
invalidation speculative invalidate cache line logically earlier epoch 
condition description shared request returned shared access 
excl request returned exclusive access 
request logically epoch 
earlier request logically earlier epoch 
responses processor events excl read excl shared read shared shared shared store load store load read excl load load sps spe store upgrade excl excl load read shared upgrade update store responses external coherence events flush read flush inv inv earlier inv inv writeback earlier inv spe sps viol 
coherence scheme supporting thread level speculation 
iii ordering speculative memory provided token 
description baseline scheme discuss additional support potentially improve performance 
cache line states cache line basic invalidation coherence scheme states invalid exclusive shared dirty 
invalid state indicates cache line longer valid 
shared state denotes cache line potentially cached cache exclusive state indicates cached copy 
dirty state denotes cache line modified written back memory 
processor attempts write cache line exclusive access obtained line exclusive state invalidations sent caches contain copy line invalidating copies 
detect data dependences buffer speculative memory modifications extend standard set cache line states shown 
cache line need track speculatively loaded sl speculatively modified sm addition exclusiveness 
enumerating possible permutations sl sm exclusiveness summarize having speculative states spe speculative shared sps 
speculation succeed cache line speculative state remain cache corresponding epoch 
speculative modifications may propagated rest memory hierarchy cache lines speculatively loaded tracked order detect data dependence violations occurred 
speculative cache line replaced treated violation causing speculation fail epoch re executed note affect performance correctness forward progress 
previous shown kb way cache entry victim cache sufficient avoid nearly failed speculation due replacement 
coherence messages support thread level speculation add new speculative coherence messages shown speculative invalidation speculative speculative 
new speculative messages behave similarly non speculative counterparts important distinctions 
epoch number requester piggybacked receiver determine logical ordering requester 
second speculative messages hints compel cache relinquish copy line indicated acknowledgment message 
baseline coherence scheme coherence scheme supporting tls summarized state transition diagrams shown figures 
shows transitions response processor initiated events speculative non speculative loads stores shows transitions response coherence messages external memory system 
briefly summarize standard invalidation cache coherence 
load suffers issue read memory system store misses issue read exclusive 
store hits cache line shared state issue upgrade request obtain exclusive access 
note upgrade request messages sent memory hierarchy cache underlying coherence mechanism receives message generates invalidation message travels cache memory hierarchy cache containing copy line enforce exclusiveness 
having summarized standard coherence describe highlights extend support tls 
highlights coherence scheme speculative memory issued transition speculative exclusive spe speculative shared sps state appropriate 
speculative load set sl flag speculative store set sm flag 
speculative load misses issue normal read memory system 
contrast speculative store misses issue read exclusive speculative containing current epoch number 
speculative store hits cache line shared state issue upgrade request speculative contains current epoch number 
cache line speculatively loaded spe sps state sl flag set susceptible read write raw dependence violation 
normal invalidation arrives line clearly speculation fails 
contrast invalidation speculative arrives violation occurs logically earlier epoch 
cache line dirty cache owns date copy cache line preserve 
speculative store accesses dirty cache line generate flush ensure date copy cache line corrupted speculative modifications 
simplicity generate flush speculative load accesses dirty cache line describe section case optimized 
goal version avoid slowing non speculative threads extent possible 
cache line non speculative state invalidated invalidation speculative arrives external memory system 
example line shared state remains state invalidation speculative received 
alternatively cache line relinquished give exclusiveness speculative thread possibly eliminating need speculative thread obtain ownership 
superior choice unclear concrete data compare performance approaches section 
speculation succeeds scheme depends ensuring epochs commit speculative modifications memory logical order 
implement ordering waiting passing token epoch 
token arrives know logically earlier epochs completely performed speculative memory operations pending incoming coherence messages processed memory consistent 
point epoch guaranteed suffer dependence violations respect logically earlier epochs commit speculative modifications 
receiving token line speculatively loaded immediately state transitions speculative exclusive spe exclusive speculative shared sps shared 
describe section operations implemented efficiently 
line speculative shared sps state speculatively modified sm flag set issue upgrade request acquire exclusive ownership 
owned exclusively line may transition dirty state effectively committing speculative modifications regular memory 
maintaining notion exclusiveness important speculatively modified line exclusive spe sm set commit results immediately simply transitioning directly dirty state 
obviously take far long scan entire cache speculatively modified shared lines ultimately delay passing token hurt performance scheme 
propose addresses lines added ownership required buffer orb line speculatively modified shared 
token arrives simply generate entry orb pass token epoch completed 
speculation fails speculation fails epoch speculatively modified lines invalidated speculatively loaded lines state transitions speculative exclusive spe exclusive speculative shared sps shared 
section describe operations implemented efficiently 
performance optimizations methods improving performance baseline coherence scheme 
forwarding data epochs regions parallelize contain predictable data dependences epochs 
avoid violations due dependences inserting wait signal synchronization 
producing final value variable epoch signals logically epoch safe consume value 
coherence scheme extended support value forwarding regular memory allowing epoch non speculative memory accesses speculative 
epoch perform store value propagated epoch causing dependence violation 
dirty speculatively loaded state described baseline scheme speculative load store accesses dirty cache line generate flush ensuring todate copy cache line corrupted speculative modifications 
speculative load corrupt cache line safe delay writing line back speculative store occurs 
minor optimization supported addition dirty speculatively loaded state indicates cache line dirty speculatively loaded 
trivial add support state include baseline scheme evaluate section 
suspending violations recall speculatively accessed line replaced speculation fail longer track dependence violations 
baseline scheme epoch evict speculative line cache simply proceed signal dependence violation 
epoch guaranteed non speculative scheme deadlock 
alternatively suspend epoch point safely allow replacement occur line longer speculative 
support multiple writers epochs speculatively modify cache line ways resolve situation 
option simply squash logically epoch case baseline scheme 
alternatively allow epochs modify copies cache line combine real copy cache line commit done multiple writer coherence protocol 
support multiple writers coherence scheme allowing multiple speculatively modified copies single cache line exist need new features 
invalidation speculative cause violation logically earlier epoch line speculatively loaded allows multiple speculatively modified copies cache line exist 
second differentiate normal invalidations triggered remote stores invalidations enforce inclusion property triggered replacements deeper cache hierarchy 
normal invalidation invalidate speculative cache line speculatively modified epoch commit speculatively modified cache line memory invalidating logically epochs speculatively modified cache line 

implementing scheme describe potential implementation coherence scheme 
hardware implementation epoch numbers 
give encoding cache line states describe organization epoch state information 
describe allow multiple speculative writers support speculation shared cache 
epoch numbers previous sections mentioned epoch numbers determine relative ordering epochs 
coherence scheme epoch number associated speculatively accessed cache line speculative coherence action 
implementation epoch numbers address issues 
epoch numbers represent partial ordering total ordering epochs independent programs independent chains speculation program unordered respect 
implement having epoch number consist parts thread identifier tid sequence number 
tids epoch numbers match exactly epochs unordered 
tids match signed difference sequence numbers computed determine logical ordering 
signed differences preserve relative ordering sequence numbers wrap 
second issue comparison epoch numbers performed quickly 
time flexibility large epoch numbers bits simplifies tls code generation aggressive control speculation 
frequently computing signed differences large sequence numbers precompute relative ordering current epoch currently active epochs resulting logically mask perform simple bit level comparisons discussed section 
third issue storage overhead 
storing large epoch numbers cache line tag exploit logically mask store epoch numbers just chip 
implementation speculative state encode speculative cache line states bits shown 
bits encode basic coherence state exclusive ex dirty di valid va 
bits speculatively loaded sl speculatively modified sm differentiate speculative non speculative states 
shows state encoding designed useful properties 
epoch transition appropriate speculative non speculative states simply resetting sm sl bits 
second violation occurs want invalidate cache line speculatively modified accomplished setting valid va bit va bit complement sm bit va va sm 
illustrates speculative state arranged 
notice small number bits associated cache line copy epoch number needed 
sl sm bit columns implemented flash reset single control signal 
sm bits wired appropriately corresponding va bits simultaneously invalidated epoch squashed 
associated speculative state epoch number ownership required buffer orb addresses cancel violation routines violation flag indicates violation occurred 
allowing multiple writers mentioned earlier section may advantageous allow multiple epochs speculatively modify cache line 
supporting multiple writer scheme requires ability merge partial modifications line previous copy line turn requires ability identify partial modifications 
possibility replicate sm column bits sm columns words bytes cancel violation routines manage unwanted violated epochs respectively 
see details 
cache line state bits bit description va valid di dirty ex exclusive sl speculatively loaded sm speculatively modified state encoding state sl sm ex di va spe sps hardware support tags data ex di va cache line state speculative context orb cancel handler epoch number address violation handler address sl logically mask violation flag sm sm speculative context orb cancel handler epoch number address violation handler address sl violation flag sm logically mask 
encoding cache line states 
sm data original cache line sm data epoch sm data epoch sm data combined copy 
support combining cache lines 
cache line shown 
call finegrain sm bits 
write occurs appropriate sm bit set 
write occurs lower granularity sm bits resolve conservatively set sl bit cache line longer perform combine operation cache line setting sl bit ensures violation raised logically earlier epoch writes cache line 
shows example combine speculatively modified version cache line non speculative 
epochs speculatively modify cache line simultaneously setting fine grain sm bit location modified 
speculatively modified cache line committed updating current non speculative version words finegrain sm bits set 
example epochs modified location 
epoch logically value takes precedence epoch value 
dependence violations normally tracked cache line granularity potential performance problem false violations disjoint portions line read written 
help reduce problem observe line needs marked speculatively loaded sl epoch reads location previously overwritten load exposed 
fine grain sm bits allow distinguish exposed loads help avoid false violations 
support speculation shared cache support multiple speculative contexts shared cache reasons 
want maintain speculative state os level context switches support tls multiprogramming environment 
second multiple speculative contexts allow single processor execute epoch current suspended suspending violation 
multiple speculative contexts allow tls simultaneous multithreading smt 
tls shared cache allows epochs program access cache lines exceptions epochs may modify cache line ii epoch may read modifications logically epoch 
enforce constraints suspending violating appropriate epochs cache line replication 
approach speculatively modified line replicated epoch attempts speculatively modify line 
replicated copy obtained external memory system copies kept associative set shared cache 
run associative entries replication fails suspend violate logically latest epoch owning cache line associative set 
suspending epoch case implemented carefully avoid deadlock 
shows hardware support shared cache speculation implement speculative contexts 
ex di va bits cache line shared speculative contexts speculative context sl sm bits 
fine grain sm bits implemented group necessary cache line shared speculative contexts epoch may modify cache line 
single sm bit speculative context indicates speculative context owns cache line simply computed fine grain sm bits 
determine speculative access requires replication compare epoch number speculative state bits speculative contexts 
epoch number comparisons may slow want bit mask compare speculative contexts quick operation 
maintain logically mask speculative context shown indicates speculative contexts contain epochs logically allowing quickly comparisons simple bit operations 
preserving correctness addition data dependences issues related preserving correctness tls 
speculation fail speculative state lost replacement speculatively accessed cache line overflow orb 
second forms speculation speculative thread immediately invoke exception dereferences bad pointer divides zero wait confirm exception really taken place exception precise 
third epoch relies polling detect failed speculation contains loop poll inserted inside loop avoid infinite looping 
system calls generally performed speculatively special support 
explore issue aggressively simply stall speculative thread attempts perform system call 

experimental framework evaluate coherence protocol detailed simulation 
simulator models way issue order superscalar processors similar mips 
register renaming reorder buffer branch prediction instruction fetching branching penalties memory hierarchy including bandwidth contention modeled parameterized shown table 
simulate applications completion 
baseline architecture tightly coupled singlethreaded processors primary data instruction caches 
connected crossbar bank unified secondary cache 
simulator implements defined section hardware support described section 
faithfully simulate coherence traffic scheme model bytes overhead coherence messages contain epoch numbers 
epoch numbers compared lazily parallel cache accesses impact memory access latency 
simulated execution model assumptions respect management epochs speculative threads 
epochs assigned processors round robin fashion epoch spawn epoch lightweight fork instruction 
baseline architecture assume fork takes cycles delay applies synchronizing epochs forwarding occurs 
violations detected polling epoch runs completion checking violation occurred 
epoch suffers violation squash logically epochs 
simulating real mips binaries contain tls instructions 
unused coprocessor instruction encodings table 
simulation parameters 
pipeline parameters issue width functional units int fp mem branch reorder buffer size integer multiply cycles integer divide cycles integer cycle fp divide cycles fp square root cycles fp cycles branch prediction gshare history bits memory parameters cache line size instruction cache kb way set assoc data cache kb way set assoc banks unified secondary cache mb way set assoc banks handlers data insts crossbar interconnect cycle bank minimum latency cycles secondary cache minimum latency cycles local memory main memory bandwidth access cycles intra chip cycles inter chip communication latency cycles tls primitives added applications gcc asm statements 
produce code set tools suif compiler system 
tools complete help analyze code insert tls primitives loops perform loop unrolling insert synchronization code 
choice loops parallelize optimizations described hand plan fully automatic compiler soon 
parallelize regions code provably parallel compiler 
table shows applications study buk implementation bucket sort algorithm compress performs data compression decompression equake uses sparse matrix computation simulate earthquake ijpeg performs various algorithms images 
buk application reduced kernel removing data set generation verification code applications run entirety 
compress certain loop carried dependences occur frequently hoist outside loop explicitly forward wait signal synchronization 

experimental results results simulation studies 
quantify effectiveness support tls explore impact various aspects design performance applications 
initial sets experiments single chip multiprocessor section evaluate larger scale machines cross chip boundaries 
performance baseline scheme table summarizes performance application baseline architecture processor single chip multiprocessor implements baseline coherence scheme 
speedups statistics relative single processor respect original executable tls instructions overheads running single processor 
speedups absolute speedups table 
applications speculatively parallelized regions 
speculative region unrolling avg 
insts 
parallel suite application input data set src file line loop type factor epoch coverage nas parallel buk mb buk loop buk loop spec compress test test compress loop compress loop ijpeg test loop ppm loop quality loop smoothing factor loop spec equake test inp quake loop table 
performance impact tls baseline architecture processor single chip multiprocessor 
region parallel program application speedup coverage speedup buk compress equake ijpeg self relative speedups 
see table achieve speedups regions code parallelized ranging 
program speedups limited coverage fraction original execution time parallelized range 
simplify discussion focus speculatively parallelized regions code remainder section 
shows performance varies number different processors different perspectives 
shows execution time normalized original non tls sequential execution 
note processor bars original executable tls executable running single processor 
shows aggregate cycles simply normalized number cycles multiplied number processors 
ideally aggregate cycles remain achieved linear speedup reality increases processors efficient 
bars broken segments explaining happened potential graduation slots 
top segments represent slots instructions graduate tls related reasons waiting new epoch spawn waiting synchronization forwarded location sync waiting 
remaining segments represent regular execution busy segment number slots instructions graduate dcache segment number non graduating slots attributed data cache misses segment slots instructions graduate 
idle segment represents slots processor execute 
somewhat easier directly compare categories increase size segment means problem getting worse 
note time wasted failed speculation contribute segments 
number graduation slots product issue width case ii number cycles iii number processors 
execution time normalized region execution time buk compress equake ijpeg spawn sync idle dcache busy aggregate cycles normalized aggregate cycles regions buk compress equake ijpeg spawn sync idle dcache busy 
performance tls scheme single chip multiprocessor 
part shows normalized execution time part scaled number processors multiplied number cycles 
number processors baseline architecture indicated 
looking single processor results see buk equake limited memory performance large dcache segments applications computationally intensive relatively large busy segments 
increase number processors speculatively execute parallel achieve speedup cases 
applications exception compress experience increase time spent waiting lightweight fork spawn fork epochs sequential order 
compress overhead hidden synchronization synch forwarded values increases quickly number processors 
see buk continues enjoy speedups processors 
cases performance levels starts degrade prior processors 
table 
tls overhead statistics baseline architecture processor single chip multiprocessor 
dynamic misses orb statistics instr 
avg 
flush size entries application overhead caches latency cycles avg 
max 
buk compress equake ijpeg dramatic case ijpeg performance degrades sharply processors reasons speculative regions ijpeg contain epochs loop unrolling ii unfortunate mapping conflict cache causes violations due replacements 
general epochs attempts execute parallel greater likelihood dependence violations 
fortunately applications scale processors tls see section 
overheads thread level speculation investigate overheads baseline scheme greater detail statistics table 
column table shows tls instruction overhead percentage original dynamic instructions 
instruction overhead significant compress due large amount data forwarding relatively small size epoch 
instruction overheads smaller remaining applications 
second potential source overhead tls decreased cache locality due data distributed multiple processors 
second column table shows percentage cache misses tls processors data processor cache 
rough indication cache locality suggests cases buk ijpeg may significant room improvement intelligent data placement thread scheduling 
orb presents third potential source overhead 
recall orb maintains list addresses cache lines speculative shared sps state 
token arrives issue complete upgrade requests obtain exclusive ownership lines committing results memory prior passing token logically epoch 
addition speculation fails orb overflows 
reasons hope average number orb entries epoch remains small 
see table average number orb entries fact small buk cases 
translates average orb flush latency roughly fourteen cycles buk roughly cycle cases 
despite buk fourteen cycle orb flush latency speeds quite 
mitigate impact latency performance design hardware flushing orb soon token arrives experiments take aggressive approach waiting epoch finishes flushing orb 
rightmost column table shows twelve entry orb sufficient eliminate possibility orb overflow applications 
shows breakdown causes viola percent violations buk compress equake ijpeg replacement invalidation speculative invalidation 
breakdown causes violations baseline architecture 
ratio violations epochs committed shown bar 
normalized region execution time buk compress equake ijpeg spawn sync idle dcache busy 
impact varying communication latency cycles 
baseline architecture communication latency cycles indicated 
tions vary applications 
bar show ratio number violations number epochs committed 
note ratio greater epoch suffer multiple violations prior committing 
violations broken categories due replacement speculatively accessed lines cache ii due normal invalidations correspond logically earlier epochs flushing address orb commit time iii due speculative invalidations correspond epoch speculatively modifying line epoch speculatively loaded earlier 
see compress suffer violations part due explicit data forwarding violations occur ijpeg due cache replacements 
violations occur far frequently buk equake caused primarily normal speculative invalidations 
choice speculative invalidations preferable normal ones help reduce size orb give earlier notification violations 
summary overheads tls remain small enjoy significant performance gains 
focus aspects design 
impact communication latency shows impact varying communication latency single chip multiprocessor cycles baseline architecture cycles 
see buk equake insensitive communication la normalized region execution time base spi buk base spi compress base spi ijpeg base spi equake spawn sync idle dcache busy 
benefit allowing speculative invalidations invalidate non speculative cache lines spi vs baseline coherence scheme base 
range performance limited data cache capacity misses inter epoch communication 
compress ijpeg latency sensitive suffer increased synchronization thread spawning times respectively 
region program speedups table observe applications enjoy speedups higher communication latencies cycles assumed baseline architecture 
support multiple writers discussed earlier sections potential enhancement baseline coherence scheme allow multiple writers cache line 
simulated scheme offered performance benefit applications 
hardly sufficient evidence claim negative result offer insights applications require multiple writer support write write rarely occurred 
buk equake see fairly random access patterns stores cases problem likelihood successive epochs storing cache line low 
case see bad ijpeg loop iteration stores sequential element array 
fortunately case easy identify fix simply unroll strip mine loop body epoch gets block iterations perform sequential stores cache line 
words cyclic aka round robin scheduling common technique avoiding analogous problem false sharing traditional shared memory multiprocessors 
loop unrolling strip mining attractive tls sake creating larger epochs help reduce relative communication overhead may valuable technique machines support tls multiple writers 
speculative invalidation non speculative cache lines discussed earlier section design choice speculative invalidation invalidate cache line non speculative state 
recall baseline scheme allow goal impeding progress epoch 
see buk ijpeg normalized region execution time spawn sync idle dcache busy single node nodes nodes buk single node nodes nodes equake 
region performance buk equake variety multiprocessor architectures means nodes processors 
achieve significantly better performance allow speculative invalidations non speculative lines reduces average number orb entries latency flushing orb passing token 
additional speedups roughly parallelized regions buk ijpeg translate program speedups vs vs respectively 
allowing speculative invalidations invalidate non speculative lines clearly worthwhile enhancement baseline scheme 
scaling chip boundaries having demonstrated effectiveness tls scheme single chip multiprocessors evaluate scales larger scale multi chip multiprocessors node system single chip multiprocessor 
shows performance buk equake range architectures 
starting single node performance notice applications speed single chip equake shows diminishing returns processors 
note results differ slightly earlier section simulating extra level interconnection memory hierarchy 
consider multi node architectures communication latency nodes times larger node vs cycles 
see buk equake speed multi node architectures 
fixed total number processors advantages disadvantages splitting processors multiple nodes 
advantage total amount secondary cache storage increases fixed amount chip reason configurations faster configuration equake 
hand obvious disadvantage having nodes increases average cost inter processor communication reason configurations slower configuration buk 
observe best performance application achieved multi node architecture buk equake 
region speedups buk equake respectively translate program speedups 
results demonstrate mechanisms flushing orb passing token scalable limit scope tls scheme 

cache coherence scheme supports thread level speculation wide range different parallel architectures single chip multiprocessors simultaneously multithreaded processors large scale machines single chip multiprocessors building blocks 
experimental results demonstrate baseline tls scheme offers absolute program speedups ranging single chip multiprocessor applications studied achieve larger speedups multi chip architectures 
observe overheads scheme reasonably small particular orb mechanism commit speculative modifications epoch performance bottleneck relatively small orb twelve entries necessary 
observations regarding applications studied 
notice applications sensitive communication latency perform environment compress ijpeg suitable larger scale multiprocessors longer communication latencies buk equake 
second observe applications benefit tls special support multiple speculative writers part loop unrolling avoid problems false 
scheme require large amount new hardware fact currently implementing purely software version scheme software dsm system 
parallel architectures increasingly commonplace wide variety scales expect thread level speculation increasingly important technique helping compilers automatically create parallel programs exploit processing potential 

acknowledgments research supported nasa 
todd mowry partially supported alfred sloan research fellowship 
aho sethi ullman 
compilers principles techniques tools 
addison wesley 
driscoll 
dynamic multithreading processor 
micro december 
dwarkadas cox zwaenepoel 
software dsm protocols adapt single writer multiple writer 
proceedings third high performance computer architecture conference pages february 
carter bennett zwaenepoel 
techniques reducing consistency distributed shared memory systems 
acm transactions computer systems august 
torrellas 
architectural support scalable speculative parallelization shared memory multiprocessors 
proceedings isca june 
franklin sohi 
arb hardware mechanism dynamic reordering memory 
ieee transactions computers may 
gopal smith sohi 
speculative versioning cache 
proceedings fourth international high performance computer architecture february 
gupta nim 
techniques speculative run time parallelization loops 
supercomputing november 
hammond olukotun 
data speculation support chip multiprocessor 
proceedings asplos viii october 
kahle 
power dual cpu processor chip 
microprocessor forum october 
keleher cox dwarkadas zwaenepoel 
treadmarks distributed shared memory standard workstations operating systems 
proceedings winter usenix conference january 
knight 
architecture functional languages 
proceedings acm lisp functional programming conference pages august 
krishnan torrellas 
need fast communication hardware speculative chip multiprocessors 
international conference parallel architectures compilation techniques pact october 
laudon lenoski 
sgi origin ccnuma highly scalable server 
proceedings th isca pages june 

clustered speculative multithreaded processors 
proc 
acm int 
conf 
supercomputing june 
olukotun hammond wilson chang 
case single chip multiprocessor 
proceedings asplos vii october 
heine lam 
search speculative thread level parallelism 
proceedings international conference parallel architectures compilation techniques pact october 
sohi breach 
multiscalar processors 
proceedings isca pages june 
mowry 
architectural support thread level data speculation 
technical report cmu cs school computer science carnegie mellon university november 
mowry 
potential data speculation facilitate automatic 
proceedings fourth international symposium highperformance computer architecture february 
tremblay 
microprocessor architecture java computing 
august 

tsai huang lilja 
yew 
processor architecture 
ieee transactions computers special issue multithreaded architectures september 
tullsen eggers levy 
simultaneous multithreading maximizing chip parallelism 
proceedings isca pages june 

mips superscalar microprocessor 
ieee micro april 
zhang rauchwerger torrellas 
hardware speculative parallelization partially parallel loops dsm multiprocessors 
fifth international symposium high performance computer architecture hpca pages january 
