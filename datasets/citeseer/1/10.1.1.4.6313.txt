object recognition mobile robot omni directional vision henrik tom duckett dept technology university se 
proposes new method recognizing typical objects indoor office environments tables chairs mobile robot equipped omni directional vision sensor requiring pre installed geometric models objects 
approach utilizes motion robot acquire internal representation object structure motion optic flow 
set low level point features selected segmented area image containing object 
low level features tracked set independent kalman filters robot moves environment order extract positions points 
set high level features extracted input pattern recognition system spatial distribution low level point features 
feature extraction method applied recognition learned objects 
results experiments real robot laboratory environment 
problem object recognition central topic interest researchers computer vision artificial intelligence cognitive sciences robotics 
ability possibilities robots carry useful tasks remain limited 
years research exists general purpose algorithm object recognition autonomous robots 
problem usually solved system system basis recognition techniques hand crafted small class objects particular application 
improvement object recognition technology useful significant advance revolutionize study embodied intelligent systems robots 
number useful properties object recognition method intelligent robot order useful applications real world environments 
able take care objects kinds shapes sense objects cluttered occluded world 
invariant variations scale translation lighting conditions robust extra noise caused motion robot 
furthermore need pre installed object models algorithm able run real time 
ideal approach robot drive environment learn internal models detected objects sensory perceptions able recognize types objects perceptual apparatus 
presents effort building complete object recognition system mobile robot omni directional vision main sensory input 
approach exploits mobility robot information extract structure motion sequence images 
consider recognition typical objects indoor office environments state art mobile robots currently able navigate object classification pattern recognition features histogram high level feature extraction tracking set points points low level feature extraction bird view image image transform segmented omni image segmentation robots odometry omni cam image th left overview recognition algorithm 
boxes indicate main steps intermediate data structures 
dashed boxes indicate steps performed manually current implementation 
right robot platform 
omni directional camera mounted top robot 
including tables chairs trash cans 
assumed objects oriented consistently vertical axis chairs tables remain upright fall recognition algorithm invariant rotations vertical axis 
current implementation area image containing object segmented hand investigate fully automatic system 
overview recognition algorithm detailed description component functions section see fig 

followed experimental results section suggestions section 
related common approach object recognition collect set representations object different views requiring deep understanding underlying structure object 
views represented aspect graph left original image omni cam 
right transformed bird view image size pixels resolution pixels meter 
view connected closest neighbours 
features recognition global shape models hot curves local representations edges 
recognition methods require explicit geometric information colour luminance information colour histograms phase local features principal components analysis 
surface model object available representation spin images 
spin images representations surfaces constructed dense collection points suitable registration matching surfaces 
technique shown cluttered environments 
kinds sensors rangefinder sensors extract surface models object recognition 
motion detect structure called structure motion sfm 
topic see 
focus usually detect motion camera object prior information correspondence information 
research sfm concerns finding corresponded structure motion assumes camera parameters motion camera object unknown case method 
method approach mobile robot single camera requiring models objects 
camera omni directional viewing angle degrees 
placed top robot looking downwards floor 
camera fixed robot moves 
current experiments robot travels forwards rotation 
sensors omni cam plus odometry estimating self motion training classifiers recognition objects 
moving robot known manner measuring pixel displacement sequence images structure object estimated 
overview recognition algorithm fig 

area image containing object segmented manually 
transformation image bird eye view bird view fig 
set low level point features extracted fig 

left right segmented omni image bird view low level point features tracked high level feature extraction pattern recognition 
point features tracked set independent kalman filters order estimate coordinates ground velocity robot 
tracked points grouped histogram relative height world fig 
right order obtain set high level features input pattern recognition system 
individual steps algorithm described detail follows 
segmentation experiments objects manually segmented original omni cam images 
images collected robot driving past stationary object standing front white background robotics laboratory institute 
border object manually selected gnu image manipulation program rest image filled white 
image transformation due curvature mirror omni cam difficult extract geometrical features directly raw images horizontal surfaces appear twisted 
transformation bird view defined image taken view located high surface 
bird view transforms image order keep physical shape intact ground plane 
example chess board lying horizontal height give non twisted chessboard bird view transformation 
size object bird view increase height 
means horizontal areas change bird view transformation 
lines real world transform lines bird view compared arcs original omni cam image 
areas higher bigger away image center 
resolution bird view pixels meter ground level pixel coordinates mapped directly world coordinate system 
detailed description transformations omni cam images see 
transform image bird view transformation function converts coordinate real world pixel omni cam image known 
pixel meter pixel calibration omni cam find bird view transformation function 
meter distance invariant orientation camera transformation function written distance center camera point ground level real world distance calculated pixels omni cam image center pixel corresponding point real world 
function calculated analytically parameters mirror camera known rarely case 
function experiments polynomial degree interpolated standard square fitting algorithm images distance corresponding pixels known 
speed transformation look table memory pointers pixels omni cam image created 
low level feature extraction points track selected image sequence 
points located corners objects easy track 
select points strong matching neighbourhood capabilities pixels selected pixel im derivatives age 
calculated sobel operator pixels block minimum eigenvalue calculated matrix performed neighbourhood pixels highest values selected thresholding 
details see function opencv library 
tracking low level features stage track points robot drives past object constant speed sequence images 
tracking points bird view projection possible estimate height coordinate point directly relative velocity image sequence information estimate horizontal position coordinates 
approach points tracked iterative lucas kanade bird view origin bv tk tk estimation position tracked point corresponding coordinate 
method pyramids 
idea find displacement minimizes time image time image track point refer size area minimized 
experiments values 
handle large pixel displacements requiring computation images divided images sub sampled factor 
minimization estimation performed lowest sub sampled image 
minimization performed iteratively level previous estimates 
possible track points large displacements high precision 
full description algorithm see 
remove noise estimate velocity points independent kalman filter applied points tracked 
assume robot travels forward rotation odometry height estimate tracked point 
high level feature extraction height point space function apparent velocity image sequence 
point higher velocity located higher point lower velocity assuming corresponding object stationary 
points higher located away origin bird view apparent velocity estimate coordinates projection shown fig 

ground level pixel estimated odometry robot 
pixel displacement height distance tracked point velocity bird view center calculated 
distance point moved origin bird view order give corresponding position ground level calculated obtain high level feature values required input pattern recognition system histogram constructed velocity distribution tracked points see fig 

experiments histograms bins corresponding speed intervals pixels frame pixels frame 
approach simple nr points pixel velocity pixels frame nr points pixel velocity pixels frame histogram showing number points different pixel velocities left cone right chair 
left right chair chair chair table table bottle cone 
effective provided objects oriented vertical axis 
invariant rotations vertical axis fail object knocked turned upside sophisticated methods feature extraction subject research example possible recover information orientation objects recognised appropriate representation 
pattern recognition pattern recognition method simple intuitive classifier known minimum distance classifier mdc 
method mean vectors calculated training data class assumed ideal prototypes objects 
classify new input vector euclidean distance prototypes calculated vector assigned class shortest distance 
equivalently decision function minimum distance classifier written pattern vector classified mean vector class 
classification object determined class produces highest decision value 
experimental results method tested image data recorded mobile robot different objects see fig 
shown number views data collected driving robot past north south east west side object total name description 
views 
images correct classification chair office chair chair regular chair chair office chair table square table table round table chest bottle cylinder cone plastic cone green table objects classification results 
number images recorded 
sequence images object separated smaller sequences containing images 
sequence pixels speeds estimated histogram created 
classification repeated times randomly selected set data training remaining data testing 
average results table 
chair lowest rate correct classifications due fact initial distribution low level features varied lot different views 
needed address problem 
total computation time iteration algorithm excluding hand segmentation ms ghz pentium indicates recognition real time possible 
attempt recognition typical objects indoor office environments mobile robot 
robot learns internal representation object sensory perceptions travels past object combining sensory information omni directional camera proprioceptive sensory information self motion odometry 
method constrains object recognition problem exploiting physical properties robot interaction environment 
considered recognition selected objects laboratory environment hand segmentation images experiments demonstrate concept recognising object structure motion embodied intelligent system 
pattern recognition system uses information concerning height tracked point features point distribution horizontal planes considered 
include improvements levels recognition algorithm example automatic segmentation objects clustering low level point features similar attributes exploitation embodiment robot attempting push objects learning affordances objects better high level features allow greater level discrimination different object types sophisticated pattern recognition techniques integration different sensor modalities foveal vision thermal vision laser ultrasonic range finder sensors discrimination moving objects humans non moving objects experiments cluttered environments 
jean yves 
pyramidal implementation lucas kanade feature tracker description algorithm 
technical report intel microprocessor research labs 
bowyer dyer 
aspect graphs survey results 
international journal systems technology 
gary 
open source computer vision library 
intel 
gustavo allan jepson 
multi scale phase local features 
volume pages 
ieee computer vision pattern recognition 
chang krumm 
object recognition wih color cooccurrence histograms 
ieee computer vision pattern recognition 
kimia 
object recognition shape similarity aspect graph 
international conference computer vision 

comparison fast vision object recognition methods 
proceedings international conference robotics automation pages 
ieee 
richard duda peter hart david stork 
pattern classification 
wiley interscience 
arthur gelb editor 
applied optimal estimation 
mit press 
christopher geyer kostas 
camera calibration 
ieee transactions pattern analysis machine intelligence 
tony jebara ali azarbayejani alex pentland 
structure motion 
andrew johnson martial hebert 
spin images efficient object recognition cluttered scenes 
ieee transactions pattern analysis machine intelligence may 
kriegman vijayakumar ponce 
reconstruction hot curves image sequences 
cvpr pages 
arthur pope david lowe 
probabilistic models appearance object recognition 
international journal computer vision 
rajesh rao dana ballard 
object indexing iconic sparse distributed memory 
technical report tr 
jianbo shi carlo tomasi 
features track 
ieee conference computer vision pattern recognition cvpr seattle june 
