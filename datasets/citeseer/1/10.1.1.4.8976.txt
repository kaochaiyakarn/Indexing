operating system speculation invocations faster fraser university cambridge computer laboratory fay chang google fraser cl cam ac uk fay google com kernel disk prefetcher uses speculative execution determine data application require near 
placing design operating system provide bene ts compared previous application level design 
system easier implement deploy handling page faults traditional le access methods able apply speculative execution swapping applications spend majority execution time fetching non resident pages 
new os features improve performance speculative execution applications large page tables working sets 
fast method synchronizing errant speculative process normal execution modi ed form copy write preserves application semantics delaying normal execution 
leveraging os knowledge memory usage contention design mechanism estimating limiting memory overhead speculative executions 
implementation linux provides bene ts wide range swapping applications 
results show support mechanisms swapping applications provide signi cant performance bene ts cases prevent speculative execution hurting performance 
demonstrate memory control mechanism ectively limits speculative overheads allowing bene cial speculative executions proceed 
past decade gap processing speeds disk access times increased performed authors compaq systems research center 
order magnitude 
time memory sizes increased substantially application data requirements 
systems continue swap data sets disk large memory 
recognition problem great deal research automating disk prefetching algorithms dramatically accurate standard heuristics current operating systems 
mowry demonstrated impressive performance results compiler techniques 
system wide approach require recompiling application 
compiler analyses limited looping array codes 
address problem chang gibson proposed discover data accesses application stalled executing ahead code ignoring non memory resident data 
proposed design automatically modifying application binaries apply speculative execution approach 
design demonstrated speculative execution deliver substantial performance bene ts diverse set applications issue explicit le read calls 
unfortunately user level design major disadvantages 
design relies correct implementation complex binary modi cation tool 
second design require application source code applications transformed receive bene third design issue prefetches disk reads caused explicit le page faults trapped application 
system applied swapping outof core applications leverage le virtual memory avoid complexity explicit design measure limit memory speculative execution resulting ect system performance 
poorly suited realistic systems abundant memory 
demonstrate problems overcome kernel design automating speculative execution 
design leveraging existing operating system features substantially easier implement may provide bene arbitrary unmodi ed application binaries 
exploiting knowledge typically unavailable outside operating system design automates disk prefetching virtual memory accesses explicit calls enabling provide bene regardless access methods applications 
addition propose new operating system features substantially improve performance speculative execution swapping applications 
describe mechanism estimating impact memory speculative executions system performance controlling speculative execution memory resources abundant 
implemented design linux kernel evaluated applications include explicit applications swapping applications application performs substantial amount forms demonstrate basic design provides similar bene prior design explicit applications requiring implementation ort 
demonstrate design provides bene swapping applications particularly assistance new features identi ed 
varying amount usable memory system demonstrate bene mechanism controlling memory usage speculative execution 
remainder organized follows 
section describes speculative execution approach automating prefetching 
section describes testbed benchmarks evaluate proposals 
section presents evaluates baseline version new kernel design implementation 
sections proceed describe improvements swapping applications mechanism controlling memory overhead 
section contrasts kernel design prior user level design 
sections discuss related 
speculative execution speculative execution approach exploits increasing abundance spare processing cycles automate prefetching applications stall disk usually application needs data memory issue disk request stall waiting request complete 
simply wasting unused processing cycles applications stalled speculative execution approach uses cycles try discover initiate prefetching data needs stalled applications running ahead stalled executions 
particular approach assumes speculative pre execution application code suciently similar application normal non speculative execution encounter accesses non resident data 
assumption speculative execution attempts improve application subsequent performance converting accesses prefetches 
illustrates approach deliver substantial performance improvements hypothetical application accesses data pages spread disks 
simplicity assume application executes cycles access disk service request cycles 
application executed execution ordinarily alternate processing stalling speculative execution approach applied normal execution stalls rst request execution continue speculatively 
speculative execution encounters access non resident data issue non blocking prefetch call 
manner may able initiate prefetching application subsequent data accesses 
original disk request completes normal execution resume 
subsequent data accesses serviced main memory halving application execution time 
worth noting speculative execution ective cases 
example obviously er bene systems cpu memory disk fully utilised 
speculative process incorrectly predict accesses depend non resident data 
success applying speculative execution wide range benchmark applications indicates independent accesses common 
experimental setup evaluate successive design proposal describing proposal demand request prefetch request disk disk disk normal disk disk disk normal time cycles speculative fig 
example speculative execution approach reduce stall time 
shows execution ordinarily proceed hypothetical application 
shows execution proceed application speculative execution approach 
normal execution stalled rst request speculative execution may able initiate prefetching non resident data application access 
halve application execution time 
der isolate performance impact motivate re nements 
assist progressive unfolding design experimental setup upfront section 
evaluate design proposals mhz pentium iii con gured mb memory running modi ed linux kernel 
modern desktop computers memory 
restricted memory size deliberately facilitate comparison prior compensate established benchmarks data sets updated re ect growth data set sizes 
storage system consists compaq rz cb ultra scsi disks ms average access time 
le system striped disks kb stripe unit 
central cylinders disks designated swap space 
maximum transfer rate supported disks scsi interface mb results averages runs 
le swap backed pages ushed memory run 
benchmark applications benchmark applications evaluation 
benchmark applications explicit applications swapping applications performs substantial amount types assist comparison prior benchmarks similar cases identical prior evaluations tip prefetching caching manager userlevel speculative execution compiler prefetching 
benchmarks summarized table described greater detail 
agrep version fast pattern matching utility 
agrep opens le command line turn reads sequentially start nish 
benchmark agrep searches les linux source tree exact matches simple string occur les 
version free software foundation object code linker 
rst reads object le le header uses nd symbol header turn provides sets symbol string tables 
small number small non sequential reads gather debugging information required le sets determined symbol tables 
sequentially reads non debugging sections object le 
benchmark alpha cross linker link object les produce digital unix kernel 
postgresql version enhanced version original postgres database management system 
tests subset open source database benchmark implements industry standard ap benchmark suite 
data set consists relations conforming ap speci cation reside mb disk space 
benchmark generates set indexes relation 
version data visualization package allows users view false color representation arbitrary slices threedimensional data set 
original application limited data sets memory version modi ed tip benchmark suite load data dynamically large data sets 
benchmark retrieves random slices set bit values resides mb disk space 
mgrid applications nas parallel benchmark suite modi ed mowry data sets main memory 
applications looping array accesses stride length bounds vary dynamically execution 
lack predictability hard conventional prefetcher prevent stalls 
matrix vector multiplication kernel obtained directly mowry compiler prefetch benchmark description run time read calls data set size agrep text search mb object code linker mb postgresql ap benchmark database queries mb visualization data sets mb fft solver pdes mb mgrid multigrid solver potential mb matrix vector multiplication mb sphinx line speech recognition mb table benchmark characteristics 
run time unmodi ed kernel speculative execution 
ing memory management 
sphinx speech recognition application 
original application modi ed load data dynamically disk tip benchmark suite 
benchmark recognize second recording commonly sphinx regression testing 
benchmark contains phases rst phase reads mb sequential fashion data les second phase seemingly random accesses mb le 
kernel speculative execution section evaluate basic design leveraging speculative execution operating system 
design similar spirit previous user level design advantages easier implement accessible users 
demonstrate design provide large bene ts similar prior system explicit applications provide substantial bene ts swapping applications 
basic design add new type process system speculative process 
speculative process created forking normal process rst time blocks disk request 
speculative process completely destroyed parent process exits 
operating system treats speculative processes differently normal processes order enable speculative processes issue prefetches behalf parent processes ensure speculative execution safe speculative processes produce output change results executing applications restrict resource utilization speculative processes hurt performance normal processes 
notice speculative processes created normal processes perform disk allow users opt speculative execution setting speci environment variable 
safety easy ensure speculative execution safe operating systems severely restrict ways di erent processes ect 
result system needs restrict speculative processes simple ways ensure safety 
systems forked process shares le pointers parent process inherits write access mapped les shared memory segments 
ensure safety forking speculative processes le pointers copied write access mapped les shared memory segments changed copy write access 
second systems typically establish relationship parent child process information child process propagated parent 
example child process destroyed operating system typically delivers signal parent 
ensure safety sever ordinary relationships speculative processes parents 
system restrict system calls speculative processes perform 
example speculative process allowed modify le system send signals normal processes 
speculative processes required perform access checks proceeding system calls 
requested system call safe may safe implementations conservative access checks cause speculative thread return immediately alter requested system call safe 
example requests map le regions write ac cess converted requests map le regions privately copy write semantics 
easy implement forcing speculative processes return immediately large number unsafe system calls operating systems contain single access point system calls operating system software trap handler 
trap handler modi ed speculative processes perform table lookup indexed system call number depending value encoded table return immediately continue system call 
altering system calls issued speculative processes requires slightly ort form individually modifying call speci handler call 
prefetching speculative process generates prefetches behalf parent process initiating non blocking prefetch normal process blocked disk read 
speculative execution proceeds non resident data 
disk read resulted explicit le read call memory resident data speci ed call copied speci ed user bu er regions bu er ordinarily lled non resident data unchanged 
allows speculative process available data subsequent execution 
disk read resulted page fault system usual allocate page frame initiate disk read appropriate data 
blocking disk read completes immediately update appropriate page table entry subsequent accesses page generate page fault 
return fault 
possible speculative process execute succeed generating accurate prefetches parent 
may occur execution depends non resident data system call speculative processes allowed perform inter process communication shared memory discussed prior section shared pages mapped copy speculative processes 
increase chances speculative process generate useful prefetches parent process block waiting data speculative child failed generate prefetch attempts synchronize speculative child synchronizing just forking reuse speculative child process structure 
parent process easily detect speculative child failed generate prefetch process rst allocate page frame hold data issuing disk read data 
page frame allocated data prefetch issued data 
attempt hide observed cost synchronization time fetch data disk parent process ordinarily block issuing disk request synchronizing 
typical system process initiate le readahead servicing le read system call initiate page cluster reads faults page memory fetched disk 
speculative process issuing correct prefetches default prefetch heuristics best redundant waste memory disk bandwidth prefetching unneeded data 
disable heuristics speculative process prefetched data parent process requesting 
basic resource control supporting speculative execution consumes processing cycles disk bandwidth memory 
ideally speculative execution uses resources wasted hurt system performance 
section describes restrict processing time speculative processes disk bandwidth memory speculative prefetches 
processor cycles 
ensure speculative execution steal processing cycles normal processes scheduling speculative processes runnable 
furthermore speculative processes preempted soon normal process runnable 
relying operating system existing priority mechanism guarantee desired behavior implement simple modi cation additional lines kernel scheduler code 
prefetching resources 
speculative prefetch steal disk bandwidth normal processes delaying disk request normal process 
premature prefetching hurt performance prefetches accurate causing useful data unnecessarily ejected memory 
suggested patterson limit maximum delay normal request issuing prefetch disk request outstanding 
idea prefetch horizon system dependent calculable agrep postgres fft mgrid sphinx speculative execution base design fig 
performance basic kernel design 
maximum number prefetches advance bene initiating prefetch throttle speculative processes generating prefetches quickly 
speculative process attempts prefetch ahead prefetch horizon marked non runnable parent process accesses data prefetched synchronizes 
avoid wasting resources speculative process begins executing process termination code result issuing exit system call generating terminating exception operating system checks parent process terminating 
speculative process allowed terminate memory reclaimed marked non runnable parent process synchronizes 
performance basic design shows performance basic design 
explicit applications shown leftmost section kernel design delivers large improvements reducing elapsed times 
bene ts comparable delivered user level design achieved reasons 
particular le readahead speculative execution approach enables prefetching les leverage decision paths encoded applications generate accurate prefetches accesses seemingly random 
results swapping applications shown central section combination application sphinx varied 
deliver substantial bene ts degrade performance mgrid sphinx 
base design performs poorly compared compiler approach delivered substantial performance bene mgrid 
table provides detailed information executions 
unsurprisingly results applications mgrid sphinx speculative execution signi cantly reduces number stalls stall time experienced normal execution 
potential concern speculative execution generate prefetches early hide substantial amount stall time 
gures full speculative prefetches show vast majority speculative prefetches complete data accessed normal execution words partial stalls progress prefetches 
potential concern heuristic approach speculative execution may generate prefetches data wasting memory disk bandwidth 
gures unused speculative prefetches show speculative execution perfectly accurate agrep 
benchmarks generates needless prefetches notice accurate operating system default le readahead page cluster heuristics 
furthermore speculative prefetches disable operating system default prefetching heuristics able avoid large proportion needless prefetches 
helps performance reducing contention memory disk bandwidth 
hand comparing gures explicit swapping applications reveals synchronization substantially expensive swapping applications 
particular comparing synchronization times original execution times shown rst column reveals mgrid synchronizing half original execution time 
suggests way base design inecient swapping applications ine ective mgrid particular 
applications notice substantial increase number copy write faults 
sphinx demonstrates di erent potential problem speculative execution 
memory speculative execution cause useful data prematurely ejected memory 
revealed speculative execution increases total number stalls sphinx 
address weaknesses basic design sections 
improved prefetching swapping applications basic design discussed previous section works explicit applications benchmark stalls spec prefetches unused prefetches sync cow enabled 
total time total full spec readahead delay faults agrep postgresql mgrid sphinx table ectiveness prefetching basic design compared system performs speculative execution 
stalls number elapsed time stalls experienced normal execution 
speculative prefetches number speculative prefetches percentage prefetches completed data requested normal execution 
unused speculative prefetches number speculative prefetches prefetched data ejected memory 
unused readahead prefetches statistic prefetches generated operating system le readahead page clustering heuristics 
sync delay total time synchronize speculative child process hidden disk access latency 
cow faults total number copy write faults experienced normal execution 
hurt performance applications exploit virtual memory 
section discuss simple additions standard operating system mechanisms greatly improve prefetching performance memory intensive applications 
fast preemptible rely le swap backed virtual memory hide swapping applications typically large page tables 
presents problems 
synchronizing speculative child parent process substantially delayed time required release speculative child old state fresh copy parent process state 
second cycles consumed reduce number spare processing cycles speculative execution progress 
reduce cost synchronization adding fast preemptible operation 
recall section parent process begins synchronizing speculative child issuing disk request ordinarily cause block 
synchronization operation complete disk request completes parent process longer need block synchronizing child 
speculative process allowed steal cycles non speculative processes means speculative process able run ahead parent process 
best multiprocessor may run tandem parent 
bene requiring parent complete synchronization better ensuring synchronization needlessly delay parent process 
accomplish periodically checking disk request completed 
read completed parent simply stops synchronization attempt speculative child continues non runnable 
parent attempt complete synchronization time delayed disk usually hides cost synchronization parent may increase synchronization delay perceived child 
observe parent process attempt synchronize child time needs access data memory 
swapping applications typically large working set synchronize quite page tables changed signi cantly 
allows reduce synchronization time releasing updating page table entries changed parent speculative child synchronization 
optimization complements preemptible parent complete synchronization disk requests serviced partial synchronization reduce amount perform complete synchronization time delayed disk way copy write synchronization follows usual forking semantics parent process experience copy page fault page attempts modify speculative child 
copy write faults introduce substantial delay page allocation data copy required 
particular cost page allocation generally quite low increase dramatically memory contention high 
observing safety requires page copied child attempts modify avoid adding page allocations parent processes adding support way copy write allow normal processes modi cations may observed speculative process 
supporting way copy write requires modi cations 
synchronizing speculative child page table entries memory region mappings marked copy write 
add speculative count page frames swap slots track number speculative processes 
servicing page fault normal execution resident swap backed page subtract speculative count total count determine page copied 
speculative process services copy write fault decrement count original page 
swapping application performance shows degree swapping applications bene fast preemptible way copy write 
mechanisms substantially ect performance explicit applications smaller amount virtual memory 
contrast swapping applications run signi cantly faster compared baseline approach speedup applications equally attributed mechanisms 
mgrid runs slower baseline speculative prefetching fast preemptible way copy write eliminate overhead 
fft mgrid sphinx normalized elapsed time speculative execution base design fast re fork way cow fig 
performance speculative prefetching fast way copy write 
detailed information bene ts fast preemptible table 
improvement scienti applications dramatic total time reduced factor 
importantly normal average fast time shorter average disk access benchmarks 
faster enables high proportion preemptible attempts complete provides speculative execution time run preempted normal execution 
fast preemptible increase number synchronization attempts mgrid preempted attempts quickly retried time normal execution stalls 
mechanism increases number completed synchronizations mgrid 
terms execution time increase far outweighed reduced time 
examination detailed application traces reveal improved performance sphinx due preemptible 
prevent normal execution needlessly delayed reduces time speculative process runnable 
sphinx large memory footprint leaving speculative execution non runnable substantially reduce memory contention main reason degraded performance benchmark 
table shows way copy write mechanism delivers dramatic reductions number copy write faults normal execution mgrid 
performance bene reductions seen results 
performance improvements due direct bene fewer copy benchmark time attempts type total mean total completed normal ms fast ms mgrid normal ms fast ms normal ms fast ms sphinx normal ms fast ms table synchronization cost ect fast preemptible re fork 
benchmark cow faults basic way mgrid sphinx table ect way copy write number copy write faults experienced normal execution 
basic base speculative execution design 
way includes way copy write optimization 
speculative execution disabled 
write faults indirect bene decreasing memory contention requiring fewer page allocations 
sphinx gain noticeable bene way copy write mechanism disabled normal execution experiences copy write faults due speculative execution 
benchmark experiences unavoidable number copy write faults result write accesses shared libraries seen count write faults speculative execution disabled 
controlling memory overhead simple resource control mechanisms basic design section sucient system abundant memory 
systems supplied 
performance memory intensive applications harmed ine ective speculative execution 
section describe mechanism controlling memory overhead incurred speculative processes 
mechanism enables practical speculative execution systems may experience memory contention 
dicult control memory overhead enabling ective speculative execution processor disk bandwidth usually possible determine resource wasted hurting system performance 
example memory mapped extant processes total amount memory system chance page contains le data re accessed 
previous user level design relied tip prefetching caching manager 
tip performs cost bene analysis determine allocating memory prefetching bene cial allowing lru le cache retain memory 
tip complete memory management solution speculative execution speculative processes need allocate memory hold prefetched data dynamically allocate memory modi able copies pages copy write access 
furthermore bene allowing speculative process allocate memory depends entirely subsequently able issue useful prefetches depends factors control preempted 
preserve principle idea cost bene framework building complicated system model predict bene speculative allocation request propose simpler reactive approach controlling memory overhead 
specifically estimate bene speculative process provided prefetching data cost incurred memory consumption 
allows estimate current bene cost speculative process disabling processes accordingly restrict overhead incurred ine ective speculative execution 
disk read matches eviction list 
read initiated speculative process decrement entry list count remove list read initiated normal process remove entry list evicted non speculative page add eviction list speculated speculated speculated allocation size allocation speculative process normal page normal page normal page normal process normal page pool 
eviction list pages absence speculation prefetched add eviction list speculative page normal process target size speculative page pool entry limit removed list page allocation addition eviction list fig 
eviction list calculate added removed stalls 
page allocations evictions update query eviction list 
diagram enumerates possible transitions occur 
dotted lines represent page identi ers added removed eviction list 
reactive cost bene analysis estimate cost bene speculative process assistance eviction list ghost bu er 
eviction list tracks pages memory speculative execution taken place 
list entry uniquely identi es disk block page 
determine entries list contain track number speculative pages memory speculative execution 
eviction list fifo add entry non speculative page evicted memory remove entry fifo full new page added 
eviction list allows system estimate number stalls speculative executions added removed normal executions 
particular normal process requests disk read matching entry eviction list identi ed added stall occurred absence speculative execution 
conversely normal process avoids disk read speculative page identi ed removed stall prevented speculative execution 
eviction list aids accurate identi cation removed stalls allowing system detect speculative prefetch merely previously resident data evicted speculative memory 
describes updates accesses occur eviction list associated performance counts greater detail 
resulting process counts removed stalls system wide count added stalls estimate net overhead speculative process cost bene entire execution 
measure disable speculative process net estimated overhead selected threshhold 
unfortunately approach unresponsive changes ectiveness speculative process 
changes caused di erent phases application ect prefetching accuracy simply varying memory contention concurrent processes 
approach bounds estimated overhead enabled speculative processes responsive changes estimated overhead speculative processes 
remainder section describes reactive approach implemented evaluated 
possibilities exist survey scope 
divide system time periodic intervals denotes current interval 
interval pair cost bene estimates updated speculative process estimates accumulated stall counts previous interval speculative process enabled disabled interval 
estimates accumulated stall counts interval estimate overhead time order decide enable disable speculative process follows 
speculative process enabled marked runnable exponentially decay previous stall estimates interval process counts removed stalls maintained directly observing speculative pages rst referenced normal process 
calculate process added stalls system wide total interval divided speculative processes proportion memory combine cost bene estimates simplest manner obtain overhead enabled speculative process speculative process estimated overhead nonnegligible mark non runnable reclaim memory 
memory tight speculative processes consume memory need prefetch ectively remain runnable 
speculative process disabled marked non runnable simply add previous cost bene estimates interval overhead calculation includes period process stopped 
interval non runnable process executed decay overhead estimate time allows system set upper bound net estimated overhead speculative process allowed run 
notice property independent manner stall counts decayed enabled speculative processes 
tuning decay method ect prior estimated bene smooths burstiness removed stalls 
evaluation memory control shows performance bene memory control swapping applications 
fft mgrid sphinx normalized elapsed time speculative execution base design fast re fork way cow mem control fig 
bene memory control swapping applications default machine con guration 
memory size mb normalized elapsed time sphinx speculation disabled memory control memory control fig 
ect memory control sphinx benchmark range memory con gurations 
run times memory size normalized execution time speculation 
times shown corresponding bar seconds 
benchmarks memory control signi cant ect sphinx 
indicates desired memory control diminish performance bene speculative execution speculative execution ective 
shows sphinx results system con gured di ering amounts usable memory 
memory con gurations mechanism provides bene sphinx compared having memory control mechanism 
mb mb con gurations memory control able eliminate signi cantly reduce performance penalty occurs memory control 
results suggest mechanism ectively prevent speculative execution harming performance cases speculative prefetching resources provide bene mem spec threshold syncs stall size crossings time mb mb mb mb mb table ect memory control synchronization attempts syncs stall time 
sets results shown memory con gurations speculation disabled speculation enabled speculation memory control enabled 
threshold crossings number times speculative execution disabled due intolerable memory overhead 
execution times speculative execution shown 
important requirement prefetching system deployed ubiquitously system 
detailed information listed table evident performance bene comes reduced stall time 
gains possible due reduced memory contention absence speculative execution 
example reduce number soft page faults experienced normal execution pages process reduce cost page allocations 
adverse ects speculative execution linger time disabled resulting gap memory immediately lled useful data 
furthermore estimating overhead mechanism currently assumes average stall times 
actual stall times vary greatly memory control entirely eliminate penalty speculative execution mb results 
mechanism disables speculative execution quite infrequently 
number synchronization attempts considerably reduced indicating speculation disabled remains disabled considerable period time 
due sub exponential decay overhead estimate ensures speculation net estimated overhead negligible 
surprisingly speculative execution improves application performance mb system bene memory control mechanism 
due accurate prefetching compared default readahead heuristic memory cost speculative execution set reduction needlessly prefetched data 
case memory control provides gain nearly disabling speculative execution ective 
mb mb results basic speculative execution memory available provide bene control mechanism able identify handful places bene cial temporarily disable speculative execution 
comparison previous design describes kernel design applying speculative execution approach arbitrary unmodi ed executables 
contrast previous design called speci es automatable procedure modifying application binaries apply speculative execution approach 
design advantages compared kernel design 
requires operating system support speci speculative execution allowing deployment systems os modi cations feasible 
second exploit static analyses transformations specialize application code speculative execution 
example calls expensive library functions printf removed speed speculative execution 
complex analysis remove loops data dependent bounds trap speculative execution prevent generating hints 
addition increasing accessibility speculative execution providing operating system service kernel design major advantages relative design 

design applied applications implicitly generate page faults swap space mapped les 

assumed systems abundant spare memory design estimate ect memory performance non speculative executions 

discussed previous report assumptions attempts ensure modi ed binary produce di erent results original binary 
assumptions hold cases kernel design guarantee adding speculative executions introduce errors normal execution 

binary modi cation tools dicult implement correctly compiler independent manner 
chang reports implementation required lines code lines assembly code 
implementation transformed statically linked single process alpha binaries produced native cc compiler digital unix 
contrast implementation required lines code lines assembly code con ned new les memory management modi cations applied arbitrary linux executables 
implementation contains fewer lines speci code easily extend handle arbitrary linux executables platforms 
related common access pattern heuristics prefetch small set access patterns occur frequently sequential access 
system checks accesses known pattern issues prefetches extrapolating pattern 
simplicity approaches advantage 
accesses known pattern heuristic help may hurt application performance 
dynamic history approaches initiate prefetching patterns inferred previous access sequences 
systems discover new patterns exploit knowledge multiple applications help non repetitive accesses may need observe large number data accesses accurate pattern inferred 
furthermore history data occupy large amount memory 
static analysis approaches compiler analyzes application deduce accesses execution 
inserts hints application inform run time prefetcher 
approaches low run time overhead required interprocedural analysis di cult 
result existing systems bene looping array codes 
furthermore system wide deployment require applications recompiled 
cao note aggressive prefetching strategies harm evicting data memory accessed 
propose set rules integrated prefetching caching policy follow avoid hurting performance suggest conforming policies 
policies assume perfect knowledge application streams 
mentions evaluate possible heuristics imperfect streams 
tip prefetching system uses cost bene model control prefetching eviction le cache limited size 
application provides access hint possible bene prefetching block weighed cost evicting valuable block cache 
tip deals bu er allocation prefetched data cost bene analysis simpler deal page allocations direct bene normal execution 
aspect design improve memory management 
mowry demonstrate substantial bene ts proactively evicting pages memory memory contention high 
describe compiletime technique deduces accesses application execution inserts release hints blocks accessed near 
coupled compiletime prefetch hints run time system approximate cao scheduling rules 
unfortunately static insertion release hints limited dicult interprocedural analysis 
hypothesize speculative execution approach may able expand range applications release hints automatically generated 
chang demonstrates speculative execution improve system performance concurrent processes contend processing cycles disk bandwidth 
memory control mechanism designed multi process systems mind example speculative process overheads measured individually evaluated multi programming environment 
demonstrated speculative execution potential greatly improve performance intensive applications overcoming limitations compiler assisted prefetching approaches 
previous user level design requires implementation complex architecture speci binary modi cation tool bene ts explicit applications transformed tool limit overhead incurred increased memory contention 
kernel design capturing bene ts speculative execution overcoming limitations 
demonstrate explicit applications simple design leverages existing operating system mechanisms delivers bene ts comparable prior user level design 
show specialized versions standard os mechanisms fast preemptible operation directional copy write greatly increase bene ts provided swapping applications 
demonstrate mechanism limiting speculative overhead impeding bene cial speculative execution scheduling speculative executions memory impact 
experience implementing evaluating speculative execution linux suggests providing speculative execution operating system feasible ective 

ibm magnetic hard disk drive technology 
www almaden ibm com sst html leadership leadership htm 
brown mowry 
taming memory hogs compiler inserted releases manage physical memory intelligently 
proceedings th usenix symposium operating systems design implementation 
chang gibson 
automatic hint generation speculative execution 
proceedings rd usenix symposium operating systems design implementation 
mowry brown krieger 
automatic compiler inserted prefetching core applications 
proceedings nd usenix symposium operating systems design implementation 
patterson gibson zelenka 
informed prefetching caching 
proceedings th acm symposium operating system principles 
bitton ll 
ap benchmark 
database transaction processing sys 
performance handbook 
morgan kaufmann 
bailey barton simon 
nas parallel benchmarks 
technical report rnr nasa ames research center 
ebling steere 
overcoming network bottleneck mobile computing 
workshop mobile computing systems applications 
chang 
speculative execution automatically hide latency 
technical report carnegie mellon university 

multics input output system 
proceedings rd acm symposium operating systems principles 
mckusick joy le er fabry 
fast le system unix 
acm transactions computer systems 
kotz ellis 
practical prefetching techniques parallel le systems 
proceedings st international conference parallel distributed information systems pdis 
gibson faloutsos 
informed prefetching collective requests 
proceedings acm ieee sc conference 
tait duchamp 
detection exploitation le working sets 
proceedings th international conference distributed computing systems 
palmer zdonik 
fido cache learns fetch 
proceedings conference large data bases 
krishnan vitter 
practical prefetching data compression 
proceedings acm conference management data sigmod 
appleton 
reducing le system latency predictive approach 
proceedings usenix summer technical conference 
lei duchamp 
analytical approach le prefetching 
proceedings usenix winter technical conference 
kroeger long 
case ecient le access pattern modeling 
proceedings th workshop hot topics operating systems hotos 
trivedi 
paging performance array algorithms 
ieee transactions computers 
cao felten karlin li 
study integrated prefetching caching strategies 
proceedings acm sigmetrics conference measurement modeling computer systems 
cao felten karlin li 
implementation performance integrated application controlled le caching prefetching disk scheduling 
acm transactions computer systems 
