robust anomaly detection support vector machines hu liao rao vemuri department applied science department computer science department applied science university california davis university california davis university california davis ucdavis edu ucdavis edu ucdavis edu darpa bsm data set collected mit lincoln labs study intrusion detection systems performance robust support vector machines rsvms compared conventional support vector machines nearest neighbor classifiers separating normal usage profiles intrusive profiles computer programs 
results indicate superiority rsvms terms high intrusion detection accuracy low false positives terms generalization ability presence noise running time 
index terms intrusion detection computer security robust support vector machines noisy data 
rapid increase connectivity accessibility computer systems resulted frequent opportunities intrusions attacks 
anomaly detection misuse detection general approaches computer intrusion detection 
misuse detection generates alarm known attack signature matched anomaly detection identifies activities deviate normal behavior monitored system users potential detect novel attacks 
past decade anomaly detection techniques including neural networks nns support vector machines svms data mining proposed capture system user normal usage pattern classify new behavior normal abnormal 
techniques categorized generative discriminative approaches 
generative approach builds model solely normal training examples evaluates testing case see fits model :10.1.1.46.2976
discriminative approach hand attempts learn distinction normal abnormal classes 
normal attack examples attack examples usually rare training discriminative approaches 
regardless approach methods currently assumption training examples intrusion detector untainted labels training samples absolutely right 
practice data sets obtained real world systems audit trails application logs network packet sniffing hardly satisfies assumption 
clean data easy obtain 
training examples may unclear boundary normal anomalous behavior 
importantly usually initial training period anomaly detector learn monitored system behavior samples collected training phase presumed normal 
normal behavior changes time new examples periodically incorporated training data anomaly detector undergoes frequent retraining 
attack occurred training process undesired intrusive behavior get established part anomaly detector model normal behavior undermine ability detect subsequent occurrences 
machine learning techniques anomaly detection neural networks support vector machines sensitive noise training samples 
presence data result highly nonlinear decision surface fitting training set 
leads poor generalization ability classification accuracy 
new approach robust support vector machines rsvms anomaly detection noisy data 
rsvms effectively address fitting problem introduced noise training data set 
rsvms incorporation averaging technique form class center standard support vector machines decision surface smoother controls amount regularization automatically see appendix details 
number support vectors rsvms significantly compared standard svms leads faster running time rsvms 
evaluate method darpa bsm data 
compare rsvms standard svms nearest neighbor classifier knn 
experiments show superiority rsvms terms high intrusion detection accuracy low false positives terms generalization ability presence noise running time 
rest organized follows 
section ii review related 
section iii describes method rsvms anomaly detection data set mit lincoln laboratory 
summarize discuss section iv 
brief mathematical description svms differ rsvms appendix section 
ii 
related idea anomaly detection computer security proposed anderson 
various anomaly detection approaches implemented establishing statistical models user program network behavior 
goal machine learning techniques anomaly detection develop generalization capability limited training data able correctly classify data normal abnormal 
clean training data usually assumed 
eskin proposed unsupervised anomaly detection algorithms unlabelled data assumption number normal instances significantly larger number anomalies anomalies appear outliers data 
forrest introduced idea building program profiles short sequences system calls issued running programs intrusion detection 
underlying premise sequences system calls intrusion noticeably different normal sequences system calls 
lee extended forrest group applied ripper rule learning program program execution audit data 
introduced new data modelling method hidden markov model hmm compared ripper simple enumeration method 
ghosh employed artificial neural network techniques learn normal sequences system calls specific unix system programs darpa bsm data 
liao drew interesting analogy text document sequence system calls issued program 
system call frequencies short sequences system calls represent program behavior 
nearest neighbor classifier employed classify new program behavior normal intrusive 
extends liao compares intrusion detection performance rsvms standard svms knn classifier clean training data program behavior profiles 
importantly deliberately form noisy training data show robustness rsvms 
iii 
rsvms darpa data set rsvms svms brief mathematical description svms differ rsvms appendix 
elaborate tutorial papers literature simple terms svm perceptron neural network ideally suitable binary pattern classification patterns linearly separable 
perceptron solution unique draw number possible hyperplanes classes 
main idea svm derive unique separating hyperplane maximizes separating margin classes 
feature vectors lie boundary defining separating margin jargon linear algebra called support vectors 
classifiers exploit property called support vector machines 
original idea modifications improvements hard margin svms separable cases soft margin svms non separable cases robust svms exhibit generalization properties handling noisy mis labelled data 
mathematical differences formulations pointed appendix 
order test properties rsvms necessary training data sets carefully prepared noise explicitly incorporated 
darpa data starting point noisy data sets prepared described 
pre processing darpa data darpa intrusion detection system evaluation program provides large corpus computer attacks embedded normal background traffic 
tcpdump bsm basic security module audit data collected simulation network simulated traffic air force local area network 
consisted weeks training data weeks testing data 
bsm audit data collected victim solaris machine 
bsm audit logs contain information system calls produced programs running solaris machine 
data labelled session numbers 
session corresponds tcp ip connection computers 
simulation day sessions recorded bsm tool solaris machine 
pre processing bsm audit data described 
sake completeness outline procedure 
names system calls extracted session bsm audit logs 
session usually consists processes 
complete ordered list system calls generated process 
buffer overflow attack session named eject list system calls processes shown table numbers occurrences individual system calls execution process counted 
liao text weighting techniques frequency weighting tf idf weighting transform process vector 
dimension process vector equal number unique system calls 
adopted frequency weighting method simply assigns number occurrences system call process execution vector entry 
clean noisy data careful study darpa bsm data revealed simulation days free attacks week training period 
picked days data days normal samples training 
distinct processes drawn sessions days 
training normal data set contains processes 
simulation day third day seventh training week chosen normal testing examples attack launched day 
contains sessions normal processes require testing processes distinct order count false alarms day 
reason chose processes mitigate imbalance normal intrusive examples 
table intrusive session eject sample corresponding processes 
list system calls associated process carefully selected distinct intrusive processes training ones intrusion sessions week training data 
processes cover attack types darpa training data including clearly malicious processes 
intrusive session small part activities intrusive 
example session eject table processes 
selected intrusive sample 
intrusive sessions week testing data intrusive samples testing purpose 
demonstrate robust property prepared different training data sets illustrated table ii 
noisy data set original intrusive training processes disguised normal incorporated normal examples testing subset remains 
table ii clean noisy data sets clean data noisy data normal processes normal processes training intrusive processes intrusive processes testing normal processes intrusion sessions rsvms clean data intrusion detection receiver operating characteristic roc curve usually measure performance intrusion detection method 
roc curve plot intrusion detection accuracy false positive probability 
experiments individual processes classified normal intrusive 
process categorized intrusive session process associated classified attack session 
intrusion detection accuracy calculated rate detected attacks 
false positive probability hand defined rate misclassified normal processes 
pwd session eject process name pwd close close close close login open close close execve open mmap open mmap quota mmap mmap close cat open mmap mmap mail mmap mmap close open cat mmap mmap mmap gcc close open mmap close cpp open mmap mmap cc mmap close close stat stat open ld close open open ioctl lstat lstat close close pwd close close close exit shows performance rsvms svms rbf kernel width knn expressed roc curves clean training data set 
rsvms svms implemented rbf kernel function 
curves obtained varying regularization parameters 
knn algorithm described 
cosine similarity measure distance processes form vectors 
testing process compared intrusive training processes 
perfect match cosine similarity equal new process labelled intrusive behavior 
testing process compared normal training process 
similarity score normal training process equal new process classified normal process immediately 
calculate average similarity value nearest neighbors highest similarity scores set threshold 
average similarity value threshold new process considered normal 
set value varied threshold get roc curve 
depicted attack detection rate rsvms zero false positive rate 
detection rate reached rapidly false positive rate remained low 
svms detect nearly attack sessions false positive rate detection rate reached false positive rate 
knn method gave relatively poor performance 
attained low attack detection rate zero false positives 
attack detection rate reached false positive rate 
table iii attack detection rate rsvms svms knn methods clean training data set false positive rate 
attack detection rate false positive rate rsvms svms knn intrusion detection system typically aimed false positive rate false alarms fig 

performance rsvms svms knn expressed roc curves clean training data noisy training data 
system useless 
table iii shows attack detection rates rsvms svms knn methods clean training data set stipulation false positive rate exceed 
rsvms svms showed competitive results attack detection rate 
rsvms noisy data presents roc curves rsvms svms rbf kernel width knn methods noisy training data 
attack detection rate rsvms zero false positives 
reached false positive rate 
svm detect attacks zero false positive rate attack detection rate reach false positive rate approached useless practice 
table iv shows attack detection rates rsvms svms knn methods noisy training data set stipulation false positive rate exceed rsvms showed slight decline performance presence noise 
svms experienced severe performance deterioration due noisy training data 
results indicate rsvms effectively suppressed effect introduced training examples conventional svms gave poor generalization ability noise 
table iv attack detection rate rsvms svms knn methods noisy training data set false positive rate 
attack detection rate false positive rate rsvms svms knn knn method manifest decline false positive rate 
surprising considering fact generally intrusion detection systems aimed false positive rate 
results showed table iv indicate slight deterioration performance presence noisy training data 
average neighbors nearest testing process smooth impact isolated noisy training examples 
testing process happened match intrusive processes 
classified normal immediately finding nearest neighbors 
testing process process testing attack session 
attack session detected knn classifier attack detection rate reached 
table comparison number support vectors experimental ratio running time rsvms svms clean noisy training data sets 
rsvms svms rsvms svms clean data noisy data classification accuracy problem needs addressed running time intrusion detector 
computational complexity rsvms svms linear proportion number support vectors shown equation classifying new examples 
shown appendix number support vectors rsvms standard svms 
rsvms require running time 
table shows number support vectors rsvms svm clean noisy data ratio experimental testing time normal testing processes 
clean training data case rsvms number support vectors third vs testing time svm 
noisy data case testing time rsvms svm due greater difference decision surfaces 
knn classifier cost classifying new examples higher rsvms svms 
due fact nearly computation takes place classification time 
iv 
proposed new approach robust support vector machines anomaly detection computer security 
experiments darpa bsm data set show rsvms provide generalization ability effectively detect intrusions presence noise 
running time rsvms significantly reduced generate fewer support vectors conventional svms 
involves quantitatively measuring robustness rsvms noisy training data addressing fundamental issue unbalanced nature normal intrusive training examples discriminative anomaly detection approaches 
reported supported part center digital security university california davis afosr institute scientific computing research lawrence livermore national laboratory 
appendix svm vs main idea support vector machines svms derive hyperplane maximizes separating margin classes positive negative 
tutorial svm 
promising property svm approximate implementation structure risk minimization principle statistical learning theory empirical risk minimization method classification function derived minimizing mean square error training data set 
main assumptions svm samples training set independently identically distributed 
practice training data contaminated noise 
noisy data validity assumption questionable 
standard svm training algorithm decision surface deviate optimal position feature space 
mapped back input space results highly nonlinear decision boundary 
standard svm sensitive noise leading poor generalization ability 
consider training samples yi xi yi feature vectors yi corresponding labels 
positive class represents normal behavior negative class represents anomalous behavior 
classification problem posed constrained optimization problem 
primal problems svm robust svm shown table vi weight vector decision hyperplane 
terms table explained 
vapnik proposed initial idea svm separable case hard margin svm positive negative samples definitely separated unique optimal hyperplane largest margin 
algorithm find feasible solution applied non separable case 
cortes vapnik extended idea non separable case soft margin svm called standard svm introducing positive slack variables 
admit training errors find best tradeoff training error margin choosing appropriate constant associated slack value error tolerant property soft margin svm useful applications due generalization ability 
trained noisy data decision hyperplane deviate optimal position maximized separating margin slack term sum misclassification errors objective function soft margin svm 
leads complicated decision surface 
known fitting problem 
song proposed robust svm aimed address fitting problem minimizing margin weight minimizing margin sum misclassification errors 
new slack term xi yi introduced place soft margin svm 
pre selected regularization parameter measuring influence averaged information distance class center xi yi represents normalized distance data point xi center respective classes yi yi feature space 
xi yi xi yi max xi xi xi yi yi yi max xi xi xi yi yi yi max xi denotes set nonlinear transformations input space feature space xi xj xi xj represents inner product kernel function dmax max xi yi maximum distance center training data respective classes feature space xi xi kernel function feature space 
illustrates meanings terms case linear separating hyperplane non separable case 
situations distance point solid dot class class center threshold value decision function summarized schematically 
formulas discussed primal space 
solution obtained solving optimization problem dual space space lagrange multipliers 
table vii shows dual problems svm robust svm quadratic programming qp optimization problems 
decision function class yi yj xj number data class class yj xj number data class 
table vi primal problems standard svm robust svm objective function constrains hard margin svm wt yif xi soft margin standard svm wt yif xi robust svm wt yif xi xi fig 

linear separating hyperplane non separable case 
star point represents center solid points class 
points circled support vectors 
values computing sign support vectors xi threshold value decision function 
sample data corresponding lagrange multiplies called support vectors 
table vii see dual problem associated hard margin svm identical robust svm additional term xi yi maximization functional 
justify slack variable xi yi account part margin 
data point separation margin thought xi yi adaptive margin soft margin svm algorithm 
suppose data point outlier located wrong side far away separable hyperplane 
distance point center class longer normal point class 
augmented term xi yi relatively large 
inequality constraint shown table vi robust svm satisfied coefficient associated data point moves zero result derived karush kuhn tucker condition dual form 
see details 
data point may support vector 
number support vectors algorithm reduced decision boundary smoother 
debar dacier wespi 
taxonomy intrusion detection systems computer networks pp april 
ghosh 
study neural networks anomaly misuse detection proceedings th usenix security symposium pp washington 
dao vemuri 
performance comparison different back propagation neural networks methods computer network intrusion detection differential equations dynamical systems vol pp jan april 
sung 
intrusion detection support vector machines proceedings high performance computing symposium hpc pp san diego april 
lee stolfo mok 
data mining flow environments experiences intrusion detection proceedings conference knowledge discovery data mining kdd 
forrest pearlmutter 
detecting intrusions system calls alternative data models proceedings ieee symposium security privacy pp oakland 
johnsson anomaly intrusion detection privacy concern problems computer networks vol 
pp 
eskin 
anomaly detection noisy data learned probability distributions proceedings international conference machine learning icml 
palo alto ca july 
qing song hu xie 
robust support vector machine bullet hole image classification ieee transaction systems man cybernetics part vol 
issue pp 
nov 
anderson computer security threat monitoring surveillance technical report james anderson fort washington pennsylvania april 
javitz valdes nides statistical component description justification technical report computer science laboratory sri international menlo park ca march 
lane brodley 
application machine learning anomaly detection proceedings th national information systems security conference pp baltimore md oct 

applying machine learning solaris audit data proceedings annual computer security application conference pp 
los alamitos ca 
dec 
dao vemuri 
profiling users unix os environment international icsc conference intelligent systems applications pp university australia dec 
forrest hofmeyr somayaji longstaff 
sense self unix process proceedings ieee symposium privacy 
pp 
ieee computer society press los alamitos ca 

lee stolfo chan 
learning patterns unix process execution traces intrusion detection proceedings aaai workshop ai methods fraud risk management pp rhode island july 
ghosh 
learning program behavior profiles intrusion detection proceedings st usenix workshop intrusion detection network monitoring pp santa clara ca 
liao vemuri 
nearest neighbor classifier intrusion detection computers security pp october 
eskin arnold stolfo 
geometric framework unsupervised anomaly detection detecting intrusions unlabeled data barbara jajodia editors applications data mining computer security kluwer 
table vii dual problems svm robust svm xi 
objective function constraints hard margin svm soft margin standard svm xi xj yi robust svm xi xj yi xi xj yi burges 
tutorial support vector machines pattern recognition knowledge discovery data mining 
cortes vapnik 
support vector network machine learning vol 

pp 
vapnik 
statistical learning theory 
john wiley sons new york 
lippmann fried graf haines kendall webber webster 
evaluating intrusion detection systems darpa line intrusion detection evaluation proceedings darpa information survivability conference exposition ieee computer society press los alamitos ca 
kendall 
database computer attacks evaluation intrusion detection systems master thesis massachusetts institute technology 
www ll mit edu ist ideval pubs thesis pdf 
