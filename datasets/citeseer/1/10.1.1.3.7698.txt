evaluating relationship usefulness accuracy profiles geoff carnegie mellon university pittsburgh pa cs cmu edu relationship accurately profile predicts program behavior useful profile directed optimization straightforward 
gathered extensive data results profile driven optimization different optimization systems cc alto selected benchmarks benchmark runs spec spec suites 
traditional spec guidelines training designated train profiles gathering performance statistics designated benchmark runs evaluate nearly possible combinations training evaluation runs 
summarize usefulness basic block profiles wider context evaluate reliability results derived range evaluation runs evaluate apparently uncontroversial claim accurate basic block profiles connected better profile driven optimization performance 
find optimization context significant correlation accurate profiles useful profiles correlation existed system 
profile directed compiler optimization commonly implemented technique considered effective 
profile directed optimization pdo depends research supported part intel mrl microprocessor research lab 
thomas gross eth rich rich switzerland trg inf ethz ch assumption having accurate predictions behavior result better optimization performance 
assumption effectiveness optimization assumption connection accurate profiles better profile driven optimization performance require quantification 
attempt evaluate assumptions 
methodology evaluating effectiveness profile directed optimization determining significance variability profile directed optimization performance measuring strength connection profile accuracy profile usefulness 
methodology analyze profile driven optimization optimization systems cc alto 
profile driven optimization systems profile information provide significantly better performance resulting code 
derive somewhat cautionary results concerning commonly held assumption profile accuracy strongly predicts profile directed optimization weak connection profile usefulness accuracy alto whatsoever cc 
wishing discover assumptions hold optimizers programs profiling methods need repeat analyses 
evaluate metrics attempt measure accurately profile predicts program execution 
suppose training profiles evaluation run profiled produces profile pe 
suppose binary produced profile driven optimization performs better evaluation run binary produced 
profile comparison metric case shows accurate prediction pe metric correlates strongly profile usefulness 
immediately clarify scope 
derive results apply profile gathering techniques benchmarks optimizers 
context profiles directly gathered basic block profiling opposed approximate methods statistical sampling profiles entirely synthetic generated static estimation 
optimizers wide range benchmarks generalize optimizers benchmark programs hypothetical universe benchmarks optimizers 
methodology analyzing profile driven optimization performance relationship accuracy applicable optimizers architectures benchmark sets profiling methods 
feel applying methodology domain exact basic block profiles logical starting point analysis relationship profile usefulness profile accuracy 
choice training profiles fundamental choice profiling methods regardless profiling methods available issue training profiles 
experimentation framework definitions process profile driven optimization run deterministic execution benchmark program certain input produces profile associated run 
profile input profile driven optimizer called training profile 
resulting binary evaluated evaluation run 
type run profile associated evaluation profile basic block profile results profiling binary evaluation run 
draw benchmarks spec spec benchmarks benchmark exists benchmark sets spec version append benchmark name 
spec bench marks define standard runs test train combinations multiple program runs 
profile driven optimizations allowed context spec benchmarks involve train training run evaluation run test may relatively short running test correctness benchmarking setup 
available runs training evaluation runs combinations 
spec benchmarks call aggregating multiple runs single evaluation training run consider run individually 
testing single training profile evaluation run profile driven optimization may gather information possible combinations training profiles evaluation runs different evaluation runs different training profiles spec benchmark perl resulting possible combinations 
commonly standard spec runs available gather information combinations 
presenting names non standard spec runs runs simply spec training testing runs indicate source run needed 
perl benchmark runs involve calculation perfect numbers 
refer run multiple runs spec benchmark ref perfect run part spec training benchmark train perfect 
generally names runs significant included 
define profile usefulness terms evaluation run 
meaningless say profile useful useful respect evaluation run 
profile accuracy measured profile comparison metrics measures behavior associated training profile predicts behavior associated evaluation profile strictly terms contents profiles 
accuracy defined terms evaluation profile 
accuracy profile comparison metric calculated strictly comparing profile data associated profile data associated evaluation run 
profile driven optimization platform implemented system evaluating profile usefulness accuracy 
system consists set profile gathering tools profile manipulation tool optimization platforms system standard digital unix compiler profiles gather 
steps outline operation system 
produce base binaries digital unix compiler dec subsequently referred 
second gather profile information build control flow graph cfg 
base binaries instrumented gather profile information various runs benchmark 
third profiles benchmark control flow graph passed profile manipulation tool may apply transformations real profiles generate new profiles scratch 
profile optimization tool generate profiles alto format standard pixie format 
stage gather data profile characteristics comparisons profiles 
fourth new profiles inputs profile driven optimization process 
profiles alto full optimizations switched digital compiler see details optimizations performed produce optimized binary 
profile driven optimizations provide substantial improvements similar code placement optimizations procedure inlining super block formation profile driven optimization steps super block formation affect subsequent optimizations profile driven 
produce binaries set optimization flags profile information comparison 
optimized binary run compute cycle counts ev performance counters currently missing data points including spec version gcc due bugs optimizers including number baseline non profile directed optimization case results 
missing entire benchmarks optimization context 
results significantly altered restricting benchmark sets benchmarks worked optimization environments opted information benchmarks worked alto environment 
evaluation runs time 
measuring subtly different binaries small variations run time 
run benchmarks mhz ev machine gb memory running digital unix 
machine old highly accurate performance counters mature tuned optimizers 
focused producing peak optimization performance 
focus studying effects profile driven optimization methods evaluating effectiveness implementing fastest possible optimizations 
general optimization performance system path path 
usually optimization performance dec compiler highest level optimization faster due mainly aggressive program optimizations implemented 
technique evaluation profile training profile case call young resubstitution :10.1.1.37.4396
valid practical technique run exact program execution twice resubstitution frequently generates interesting results allowing insight benefit results having perfect information 
cases reporting average benefits profile directed optimization 
goal investigate usefulness accuracy profiles generate superior spec results find ideal representative training profile 
non standard spec training profiles evaluation runs means results considered valid spec results 
render results invalid research sense 
stated highly questionable benchmarking sense resubstitution generate interesting data 
carry analyses determine observed performance effects shorter running evaluation runs spec ref benchmarks represent real effects effects simply due experimental error true nearly combinations optimizer benchmark evaluation run 
results usefulness profile directed optimization gathered cycle counts combination optimizer benchmark training profile evaluation run 
repeated evaluation run times discarding cycle count score due significant differences run certainly due page faults program binary brought memory disk 
calculated average cycle counts evaluation runs 
average cycle counts normalized average cycle counts comparison binaries optimized binaries profile directed optimization 
evaluation run binary produced profile directed optimization runs faster binary produced non profile directed optimization assigned score table 
table results showing relative performance profile directed optimization different benchmarks compared benchmarks optimized profile directed optimization 
benchmark multiple evaluation training runs average profile driven optimization performance combinations evaluation training runs excluding resubstitution case 
profile directed optimization effective technique average improvement results sharply variable benchmarks training profiles program slower evaluation run 
majority benchmarks optimizers combination training profile evaluation run profile directed optimization performs badly 
examining individual benchmark runs observe wide range performance variability 
table presents top bottom benchmark runs profile driven optimization variability 
huge range variability evaluation runs 
cycle counts degree variability due experimental error simple technique oneway anova determine eval results way anova far verbose details scope 
way anova merely detects exists significant difference uation run differences cycle counts binaries trained different training profiles significant 
observing real differences training runs differences observed entirely due experimental error 
issue somewhat pressing conventional profile driven optimization research runs evaluation runs comparatively brief compared standard spec ref runs 
way anova procedure way vary single variable anova short analysis variance attempts determine set experimental results gathered different levels case different training profiles statistically significant differences results different levels 
attempt disprove null hypothesis average cycle counts evaluation run regardless training profile 
probability case sufficiently low reject null hypothesis conclude fact statistically significant differences profile driven optimization effects different training profiles 
able reject null hypothesis significant difference exists effect training profiles significance level effect training profiles seen pattern variability evaluation runs alto runs art spec benchmark run compress parser cc run 
vast majority benchmark runs probability observed variability due factors training profile negligible 
tween training profile rest yield results analyzing training profiles differ significantly 
results way anova treated degree caution say significant difference exists evaluation run different training profiles allowed say difference exists usefulness profiles opposed stronger statement profiles significantly different intermediate possibilities 
carried post hoc analyses distinguish set details scope 
optimizer benchmark number runs normalized execution time minimum maximum mean alto ammp bzip compress crafty gap go gzip ijpeg li ksim mcf parser perl twolf vortex cases cc ammp bzip compress crafty equake gap go ijpeg li ksim mcf perl twolf vortex cases table execution time pdo binaries evaluation runs training profiles set evaluation run results normalized non profile directed optimization case equal evaluation run 
optimizer benchmark evaluation run fastest case slowest case mean standard deviation alto perl train alto perl ref alto perl ref perfect cc perl train scrabble cc go ref cc go train cc go test alto perl ref 
alto gzip program alto parser ref alto ijpeg train alto ammp train cc mcf ref alto parser train alto ammp ref table evaluation runs highest lowest variability due profile directed optimization profile choice units normalized table 
connection usefulness accuracy profile accuracy metrics comparison metrics compare list basic block counts training profile list basic block counts evaluation profile 
return single number score indicates basic block counts training profile predict basic block counts evaluation profile 
accurate training profile better predicts cfg level behavior evaluation run 
metrics asymmetric 
profile comparison metric consists comparison type way applying program 
comparison types key matching static coverage relative entropy 
key matching introduced 
uses parameter determines blocks selected 
example function blocks matching level perform top blocks follows key match score number blocks top blocks training profile top evaluation profile 
key matching metrics denoted km level level 
static coverage denoted measures proportion blocks executed covered evaluation profile executed training profile 
relative entropy denoted ent method comparing profiles introduced young fully described :10.1.1.37.4396
relative entropy treats profiles compared distributions random variables uses information theoretic approach measure difference distributions 
methods applying comparisons programs 
firstly apply program set basic block counts directly 
default method 
secondly apply entry counts functions ignoring basic block data denoted prefixing fe comparison name results 
evaluating connection comparison metrics usefulness measure association profile usefulness profile comparison metric spearman rank correlation coefficient rs 
rs calculated assigning ranks values compared scoring ties average rank values tie top values assigned rank calculating familiar pearson correlation coefficient ranks 
calculations rs discard magnitude differences data points 
rs weaker real effect pearson correlation coefficient robust presence non linear relationships outliers generally data hold bi variate normal distribution 
analyzing correlation profile accuracy usefulness aware natural population profiles benchmark 
benchmarks limited number runs available chosen artificially 
include profile types profiles derived directly real runs introducing artificial biases population 
admittedly choice benchmark runs spec benchmark sets artificial artificial choices authors hand picked advance favored hypotheses 
proceed show example evaluate connection profile usefulness accuracy 
firstly average cycle count scores usefulness scores perfect benchmark evaluation run 
training profile average cycle count reflecting cycles binary produced profile driven optimization profile took run evaluation run accuracy score reflecting close training profile profile produced evaluation run 
example accuracy scores provided relative entropy table shows cycle counts relative entropy scores list training runs names refer different benchmark runs available perl interest aside fact label cases 
calculate score closely relative entropy predicts scaled cycle counts take rs value variables cycle count relative entropy list cases training profiles turns rs 
value statistically significant accurate profiles produce lower relative entropy scores zero represents perfect match training run cycle count relative entropy ref ref ref perfect train train perfect train scrabble table example perl scaled cycle counts accuracy metrics single evaluation run ref perfect level association whatsoever variables expect see rs value high times 
fact chance see strong association unconnected variables list cases 
proportion scaled cycle count variation explained relative entropy variation average profile driven optimization performance particular case explained terms relative entropy 
note benchmark quite large number possible training profiles 
benchmarks runs available situation calculating correlations tiny set cases 
circumstance possible apparently strong correlations fact statistically meaningless occur pattern multiple evaluation runs benchmarks attach weight results 
table shows analysis repeated evaluation runs perl 
see larger set results table rs numbers evaluation run 
correlations significant level marked level marked 
example value rs seen evaluation fairly low chance unconnected variables show rank correlation equal greater value evaluation runs fall category evaluation run name rs score ref ref ref perfect train train scrabble table example evaluation runs rank correlation values cycle counts relative entropy calculated training run significant level 
considering values isolation see correlations positive range rs relative entropy average cycle count connection relative entropy average cycle count runs 
fact chance correlations strong stronger arisen chance connection relative entropy cycle count 
note quite possible negative rs scores case accurate profiles result worse profile driven optimization performance 
compute summary value connection usefulness accuracy benchmark averaging rs values evaluation run yielding aggregate correlation mean rs perl benchmark 
procedure gather aggregate numbers benchmark time range comparison metrics derive table 
table shows aggregate rs scores comparison benchmark optimizer mean scores rs generally practice statistically rigorous transform rs value score normal score take average scores transform back range rs 
procedure complex results average rs scores little different derive simple averaging 
similarly significance results aggregate rs scores statistical justification results scope 
son optimizer 
clear benchmark particularly perfect evaluation run represent quite favorable case note large number benchmarks table aggregate rs scores low correlation negative accurate profiles worse profile driven optimization performance 
particularly results optimizer show pattern connection profile usefulness profile accuracy 
case profile comparison metrics yielded small significant correlations profile accuracy scores profile usefulness scores 
performed slightly worse profile accuracy metrics entropy static coverage 
function entry versions accuracy metrics performed slightly better versions considered basic blocks program small difference significant 
substantial amount variability aggregate rs scores benchmark 
variability simply random aggregate rs scores benchmarks small number runs subject great deal randomness involve comparisons values 
benchmarks clearly far stronger associations usefulness accuracy 
recall correlation coefficients table rank profile usefulness correlates profile accuracy say profile directed optimization works 
major weakness approach evaluating connection profile directed optimization performance profile accuracy due nonparametric methods averaging different benchmarks small variations benchmark weighted heavily huge variations 
simple way avoid problem recourse parametric correlation methods 
derive results useful restricting analyses evaluation runs greater variability due profile directed optimization 
optimizer results restricting analysis top half evaluation runs highest level profile directed optimization variability shown table 
failure profile accuracy metrics explain optimizer benchmark mean rs ent stc km fe ent fe stc fe km alto ammp art bzip compress crafty equake gap go gzip ijpeg li ksim mcf parser perl twolf vortex vpr alto mean cc ammp bzip compress crafty equake gap go ijpeg li ksim mcf perl twolf vortex cc mean table connection usefulness accuracy aggregated rs scores optimizers benchmarks different comparison metrics optimizer ent stc km fe ent fe stc fe km alto mean cc mean table aggregated rs scores optimizers considering top half evaluation runs pdo variability cc profile directed optimization performance turns unconnected profile directed optimization variability 
considering benchmarks benchmark runs large variations profile directed optimization performance improve connection profile accuracy profile usefulness cc 
results substantially stronger eliminate benchmark runs small variations profile usefulness 
entropy methods particular improve markedly 
fe ent accuracy metric predicts variation profile directed optimization results alto modest result strongest far 
similar improvements restricting analysis smaller top quarter pdo variability subgroups evaluation runs 
bottom half evaluation runs pdo variability showed significant correlation alto cc profile accuracy profile usefulness 
discussion reason suppose reliable connection accuracy usefulness existed cc optimization context whatsoever 
conjecture extensive high level optimizations cc sufficiently transform control flowgraph point relatively subtle differences training profiles irrelevant 
mean profile driven optimization cc mean inaccurate profiles produce profile driven optimization performance indistinguishable ones 
mean fairly narrow range profiles benchmarks tested accuracy shown connection usefulness 
evaluated profile comparison metrics carrying key multiple levels dynamic coverage performed better comparison metrics 
results alto optimization context encouraging relatively weak 
restricting analysis benchmarks large optimization variability explain third variation average cycle counts accuracy metric 
startling results fact accuracy metric fe stc performed despite fact ignores away nearly information block profile 
extremely simple metric calculated determining number functions entered training profile evaluation run divided total number functions entered evaluation run 
effectiveness metric similarly restricted metrics result little variation function behavior run run profiles produced benchmark runs differ cover different set functions radically different behavior functions 
alternate possibility optimizations alto really effectively worked function level little block information code placement optimizations level procedure inlining examples optimizations function information benefit knowledge call site counts nearly equivalently call graph edge counts 
possibilities easily separated fact function entry comparison metrics strongly correlated rs program counterparts nearly benchmarks suggestive possibility true optimizers bzip exceptions 
related wall systematic attempt evaluate profile accuracy 
wall compares real profiles static estimates accuracy key weight matching compare profiles 
comparisons key fixed levels top similar levels proportional total number blocks top 
shows strong improvements accuracy real profiles static estimates 
briefly analyzes theoretical optimization algorithms showing weaker results warns unrealistic expectations concerning profile driven optimization 
wu larus discuss static estimation dempster shafer theory combine branch prediction heuristics 
key weight matching evaluate accu racy static profiling methods 
wagner similar analysis wall 
works attempt establish connection profile accuracy profile driven optimization performance 
diverges works connecting accuracy metrics actual profile driven optimization performance mature optimizers 
fisher freudenberger report profile data gathered previous runs yields branch predictions 
mention possibility differences real benchmark runs related benchmark coverage program opposed differences behavior code covered runs 
interesting observation unfortunately able quantify 
results suggest intuition correct terms information alto able effectively comparatively strong predictive value accuracy metric fe stc function entry static coverage supports 
extensive treatment information theoretic methods comparing combining profiles including relative entropy comparison appears young :10.1.1.37.4396
validates relative entropy profile comparison metric 
cohn lowney compare differences usefulness profile driven optimization static estimation compaq alpha 
report substantial speedup spec integer benchmarks feedback directed optimization 
results show larger effect profile driven optimization aggressive optimizations iteration alpha architecture 
difference wider variety benchmarks including spec floating point benchmarks benchmark runs may contribute performance gap 
statistical data analysis techniques cluster similar program input pairs terms pairs consisting benchmark evaluation run 
concentrate benchmark characteristics opposed profile accuracy profile usefulness analyses little need reduce number program input pairs cover hopefully representative set benchmarks training profiles evaluation runs analyses benefit data points fewer 
true training profiles evaluation runs produce similar effects 
profile directed optimization worthwhile technique average optimizers evaluated 
average saw improvement non profile directed optimizations cc aggregate numbers concealed substantial variations best case optimizer approximately better non profile directed optimization worst case approximately worse 
nearly benchmark runs showed significant variation profile directed optimization performance 
evaluation runs unable detect significant variation profile directed optimization performance variation due profile directed optimization existed small unable separate variation experimental error 
large differences existed evaluation runs largest amount profile directed optimization variability smallest standard deviations speed non profile case ranged effectively zero nearly 
profile accuracy weakly associated profile usefulness optimizers alto connected profile usefulness cc set benchmarks benchmark runs 
considering benchmarks runs higher variability profile driven optimization performance improved connection connection usefulness accuracy accounted observed variation profile driven optimization performance 
comparatively weak non parametric correlation methods may caused overly conservative accuracy metric whatsoever explain excess variation 
variation profile usefulness explainable profile accuracy metrics explainable fairly simple profile accuracy metrics notably static coverage function entries fe stc 
find quantitative support fisher berger claim differences exact profiles mainly due different set functions covered different runs opposed different behavior functions run run 
results negative cc weak entirely 
variation training profiles necessarily cause different optimization outcomes 
necessarily help 
optimization decision produces better performance regardless information compiler optimizations truly optimizations particularly interacting optimizations 
see substantial significant variations due profile choice profile driven optimization benchmarks variation explainable terms profile accuracy 
suggests large component randomness outcome profile driven optimization process 
major contributions twofold 
firstly developed methodology evaluation profile driven optimization performance connection profile accuracy applied combination processor architecture optimizer set benchmarks 
secondly results show exists optimizer usefulness accuracy correlated experimental context correlation exists fails explain bulk optimization performance 
claims profile directed optimization techniques accurate profiling techniques necessity obtaining accurate precise basic block profiles dynamically evaluated experimentally terms profile accuracy 
shown range cases little connection profile accuracy profile usefulness exists 
incumbent designers profile directed optimization systems demonstrate profile directed optimizations systems effective wide range benchmarks merely showing profiles gathered high accuracy 
cohn lowney 
feedback directed optimization compaq compilation tools alpha 
proc 
nd workshop feedback directed optimization 

workload design selecting representative program input pairs 
eleventh international conference parallel architectures compilation techniques pact 
fisher freudenberger 
predicting conditional branches previous runs program 
proc 
architectural support programming languages operating systems asplos pages 
muth debray de 
alto link time optimizer dec alpha 
technical report tr department computer science university arizona 
young :10.1.1.37.4396
comparing combining profiles 
proc 
second workshop feedback directed optimization fdo 
wagner graham harrison 
accurate static estimators program optimization 
acm sigplan notices 
wall 
predicting program behavior real estimated profiles 
june 
proceedings acm sigplan conference programming language design implementation 
walpole myers myers 
probability statistics engineers scientists 
prentice hall 
wu larus 
static branch frequency program profile analysis 
th international symposium microarchitecture pages 
