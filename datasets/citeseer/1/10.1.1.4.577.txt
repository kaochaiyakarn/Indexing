copyright ying wu vision learning intelligent human computer interaction ying wu university science technology tsinghua university thesis submitted partial fulfillment requirements degree doctor philosophy electrical engineering graduate college university illinois urbana champaign urbana illinois dream computers see 
research computer vision provides promising technologies capture analyze transmit retrieve interpret visual information 
due richness large variations visual inputs practice statistical learning techniques visual motion capturing recognition confronted similar problems making intelligent visually capable machines challenging task 
dissertation concentrates important problems capturing recognizing human motion video sequences crucial research applications intelligent human computer interaction multimedia communication smart environments 
dissertation presents effective techniques visual motion analysis tasks non stationary color model adaptation efficient localization multiple visual cues integration robust tracking learning motion models capturing articulated hand motion 
dissertation describes novel statistical learning method discriminant em em algorithm framework self supervised learning paradigm 
em employs labeled unlabeled training data converges supervised unsupervised learning 
topics dissertation unified problems self supervised learning transduction transduction model transduction inferencing 
extensive experiments pro systems validated proposed approaches domain vision human computer interaction 
iii parents iv acknowledgments express sincere advisor professor thomas huang insightful guidance enlightening advice endless encouragement ph study great opportunity explore various difficult problems 
lucky am proud student great man extraordinary vision wisdom 
especially mentors microsoft research dr toyama dr zhengyou zhang discussions sug possible 
ph advisory committee members professor narendra ahuja professor david kriegman dr toyama inspiring constructive discussions study 
colleagues image formation processing group friends microsoft research 
particular dr steve shafer dr ying shan dr harry shum dr john krumm dr rick szeliski erik hanson dr vladimir pavlovic greg berry dr jojic dr liu john lin qi tian sean xiang zhou chen 
special john lin hard collecting finger motion data help finger tracking experiments proofreading 
wish family endless love support encouragement time study abroad 
express deep dear wife love sacrifice understanding help felt word 
table contents chapter page 
background 
virtual environments 
human computer interaction 
vision human computer interaction 
gesture interfaces 
visual learning 
motivation 
organization 
contributions 
vision gesture interfaces review 

gesture representation 
hand modeling 
modeling shape 
modeling kinematic structure 
modeling dynamics 
capturing human hand motion 
formulating hand motion 
localizing hands video sequences 
selecting image features 
capturing hand motion full dof 
data preparation recognition 
features gesture recognition 
data collection recognition 
static hand posture recognition 
model approaches 
appearance approaches 
temporal gesture recognition 
recognizing low level motion 
vi recognizing high level motion 
gesture recognition hmm 
techniques 
sign language 
research directions 
robust hand localization 
modeling motion constraints 
motion editing animation 
recognizing temporal patterns 
open questions 
nonstationary color tracking 

nonparametric density representations 
histogram vector quantization 
self organizing map 
adaptive self organizing map 
model transduction color model adaptation 
som transduction algorithm 
experiments 
performance image segmentation 
performance hand tracking 
discussion 
multiple cues integration robust tracking 

multiple cues integration 
graphical models tracking 
sequential monte carlo techniques 
factored sampling 
importance sampling 
inference tracking algorithm 
implementation 
shape representation 
shape observation 
color representation 
color observation 
experiments 
single cue 
multiple cues 
discussion 
vii capturing human hand motion 

hand motion hand model 
capturing global motion 
hand pose determination 
iterative closed points algorithm 
capturing local motion 
sequential monte carlo techniques 
model matching 
divide conquer 
experiments 
simulation 
real sequences 
discussion 
discriminant em algorithm 

learning hybrid data sets 
setting learning 
approaches 
svm approaches 
em approaches 
training approaches 
generative model 
expectation maximization 
em algorithm density estimation 
dealing missing values 
problems 
model assumption 
learning high dimensions 
linear em algorithm 
linear multiple discriminant analysis 
expectation discrimination maximization 
kernel em algorithm 
nonlinear discriminant analysis 
kernel approach 
kernel mda 
sampling data efficiency 
pca kernel vector selection 
evolutionary kernel vector selection 
kernel em algorithm 
experiments 
viii benchmark tests 
view independent hand posture recognition 
transductive content image retrieval 
discussion self supervised learning 
new learning paradigm 
fundamental questions 
self supervised learning 
problem formulation 
induction 
deduction 
transduction 
vision gesture interface systems 
rock scissors interactive video game 
system framework 
localization system 
motion capturing system 
posture recognition system 
animation system 
system performance demos 
visual panel vision mobile input system 
homography 
tracking quadrangle 
tracking fingertip 
fingertip representation 
tracking tip pointer 
maintaining background re initialization 
action detection recognition 
mouse clicking modes 
mouse motion types 
demos 
calculator controlling 
finger painting 
virtual keyboard 
extensions 
potential applications 
research 
summary 
research directions 
appendix derivation fixed point equations 
ix appendix solving rotation matrix depth 

vita 
list tables table page benchmark test kernel mda algorithm average test error standard deviation 
view independent hand posture recognition comparison multiplayer perceptron mlp nearest neighbor growing templates nn em linear em 
error rate comparison different algorithms 
comparisons time relevance feedback relevant irrelevant images 
em outperforms methods 
typical problems self supervised learning 
xi list figures page various hand models 
cardboard model wireframe model model 
hand skeleton structure 
generally assume dof mcp tm joint dof joints 
hand roughly dof local finger motion 
hand localization 
input image segmentation result hand blob located analyzing segmented image pixels 
capturing articulate hand motion cardboard hand model 
hand pose finger joint angles recovered fitting model images 
fitting minimizes discrepancy image feature observations projected models 
recognizing different hand postures 
som structure 
growing scheme 
wi weight vector input vector 
left input vector far weight vector output value neurons nearly current input data cluster represented neurons say weight vector neuron misplaced unnecessarily right situation new neuron created weight set 
training algorithm structure adaptive self organizing map 
illustration transduction classifiers 
results color image segmentation structural adaptive selforganizing map 
left column source color images middle column segmented images right column interested color regions 
results hand tracking frames taken image sequences 
moving hand interference book localized 
blue boxes bounding box interested color region 
tracking problem represented graphical model similar hidden markov model 
factorized graphical models states target decomposed shape states color states factorized graphical model 
observation separated 
xii importance sampling 
samples drawn distribution adjusted weights represent density 
inference tracking algorithm top 
inference tracking algorithm ii combining top bottom 
shape observation measurement 
set observations applied contour shape hypothesis 
measurement calculates likelihood segment shape contour observing edges 
condensation shape observation hypotheses generated clutter 
tracking hand 
keyboard area produces false shape hypotheses 
tracking head 
bookshelf area highly cluttered hypotheses incorrect shape measurements 
condensation color observation color nonstationary environments tracking difficult 
tracking face 
hypotheses generated wooden door area hypotheses survive color measurements 
tracking shoulder dynamic environment 
due changing illumination conditions color measurements accurate anymore 
hand clutter 
moving face office environment 
testing sequence courtesy dr stan birchfield 
head lecture room dramatic lighting variations 
testing sequence courtesy dr toyama 
shoulder cave large virtual environment lighting diffused screen displays 
face occluded moving face office environment 
testing sequence courtesy dr stan birchfield 
hand model kinematical chain finger cardboard hand model 
hand articulation configuration space characterized set basis configurations linear manifolds 
subset basis configurations linear manifolds configuration space 
generating hypotheses bi bi 
shape measurements 
sample results synthetic sequences 
synthetic image image model aligned 
comparison results ground truth synthetic sequence 
dashed curves ground truth solid curves estimates 
comparison different methods real sequences 
method accurate robust methods experiments 
represents unlabeled sample 
denote labeled sample 
samples labeled 
solid lines bayesian classifier dashed lines iteration results em 
data drawn gaussian distributions 
em converges bayesian classifier 
class data drawn component gaussian mixture em assumes gaussian 
component mislabeled 
em fails unlabeled data help 
xiii em algorithm 
class nonlinearly separable example 
original data kernel features data normalized coefficients pca small number large black nonlinear mapping 
evolutionary kernel vector selection 
fourteen different postures 
row posture different views 
effect labeled unlabeled data em 
effect dimension pca mda em 
comparison linear em kernel em 
correctly classified images 
images mislabeled correctly labeled 
images correctly classify 
data distribution projected subspace 
linear 
kernel 
different postures separated clustered nonlinear subspace 
effect labeled unlabeled data em 
error rate decreases adding unlabeled data 
combining unlabeled data largely reduce classification error 
framework vision gesture interface 
hand localization system framework 
hand posture recognition subsystem 
children game rock scissors 
system virtual panel consists panel tracker pointer tracker action detector message generator 
tracking visual panel system 
input image 
tracking outputs tracked panel tracked fingertip 
tracking quadrangle dynamic programming technique 
fingertip detection conic fitting 
foreground hand segmented background current position panel tracked background template maintained 
simulating clicking mode dragging mode ii 
controlling calculator 
finger painting 
virtual keyboard 
illustration typical problems self supervised learning transduction model transduction transduction inferencing 
xiv background virtual environments chapter years virtual reality technologies taken dimensional vir tual worlds pushed develop new concept human computer interaction 
electronic visualization lab university illinois chicago na tional center supercomputing applications ncsa university illinois urbana champaign developed family virtual environments ves including cave infinity wall hive paris 
ves aim give users feeling immersion allowing explore virtual worlds 
evolution user interfaces keyboards primary devices text user interfaces invention mouse brought graphical user interface 
counterpart mouse trying explore virtual environments ves 
current applications keyboards mice joysticks common controlling navigating devices 
extent mechanical devices inconvenient unsuitable natural direct interaction difficult devices provide high degrees freedom inputs 
cave ves inputs obtained magnetic sensors prone magnetic interference unable give feeling immersion due cable connections natural interaction achieved 
human computer interaction traditionally main task human computer interaction hci focused designs ma computers 
simple controlling tasks fulfilled interacting ves appropriate way 
intuitive concept interaction needed 
obviously intuitive direct interaction achieved computers cap ture human movements recognize understand meanings movements 
example computers estimate user pointing detect user hands interpret user waves hands understand user happy concept bring revolution human computer interaction 
early practice idea concentrated design motion sensors attached human body parts measure motions transfer measurements signals 
commercial products available market 
nowadays wireless techniques embedded motion sensors get rid cable connections 
motion sensors important collecting human motion data 
invasive sensors quite cumbersome real interactions cause people reluctant wear forcing researchers explore noninvasive ways natural human computer interaction 
vision human computer interaction electromagnetic sensors vision interaction aims develop natural intuitive convenient interfaces computers live video inputs 
computers able see recognize user physical actions 
furthermore user psychological status estimated 
early research vision motion capturing usually needed help color markers 
current state art vision interaction research focusing tracking people directly recognizing faces understanding facial expressions interpreting gestures body motion 
vision interaction challenging interdisciplinary research area involves com puter vision graphics image processing machine learning psychology 
working system requirements robustness real world visual information rich noisy incomplete due changing illumination clutter dynamic backgrounds occlusion able automatically recover failure 
systems user independent 
computational efficiency generally requires real time systems 
vision learning techniques effective cost efficient 
user tolerance malfunctions mistakes tolerated 
mistake incur loss 
users asked repeat actions letting computer wrong decisions 
scalability system easily adapted different scales applications 
fox example core desktop environments cave environments 
gesture interfaces hand gestures important part human computer interaction years :10.1.1.53.6402
human hands natural interface glove devices employed capture human hand motion attaching sensors measure joint angles spatial positions hands directly 
unfortunately devices expensive cumbersome 
rich visual information provides strong cue infer inner states object vision techniques provide promising alternatives capture human hand motion 
time vision systems cost efficient noninvasive 
facts serve motivating forces research modeling analysis animation recognition hand gestures 
vision gesture interface promising direction hci 
achieve natural intelligent interaction important research issues gesture interface gesture modeling gesture complicated phenomenon 
meaningful information ex pressed gestures embedded static temporal characteristics ges tures 
gesture modeling basis gesture interface 
involves gesture representation studying hand shape modeling kinematic modeling temporal modeling semantic modeling 
gesture tracking hand highly articulated range movement hand large 
hand motion consists global hand motion local finger motion 
gesture tracking involves hand localization capturing articulated finger motion 
gesture recognition static gestures postures represent static con cepts temporal gestures represent dynamic movements 
recognizing postures temporal gestures challenging problems 
realistic animation ability produce responses human actions 
response avatar realistically animated 
visual learning achieve intelligent interaction computers humans computers capacity learn 
large variation visual inputs nearly impossible explicitly represent rule interaction knowledge obtained set examples machine learning techniques 
due richness visual inputs gap low level visual features high level concepts difficult perform visual tracking analysis recognition retrieval 
various learning techniques employed deal large variety visual content vision tasks face gesture recognition visual tracking image video databases learning offers flexible tractable means address problems training data implicitly represent priori knowledge domain hard model explicitly 
motivation core problems vision human computer interaction human tracking motion capturing 
step human motion recognition understanding 
specifically vision gesture interfaces need localize hands video sequences robustly capture global hand poses local finger articulations accurately 
need develop effective methods efficient localization efficiency localization system depends de liberated implementation efficient techniques 
computationally intensive processes carried locating object interest videos lo computational resource economically possible 
robust tracking visual tracking involves fundamental problems computer vision matching recognition 
tracking robust key real systems vision interaction 
integration multiple visual cues powerful way achieve goal 
accurate motion capturing human motion quite complex 
example hand mo tion highly articulated hand roughly degrees freedom 
capturing finger articulations challenging problem 
motivates develop new learning paradigm visual learning gesture interface learning approaches confront nearly difficulties practice vision applications 
labeled samples supervised learning techniques widely visual learning tasks insufficiency labeled training data problems practice supervised learning 
current time hard deal uncertainty pure unsupervised learning due lack supervised information 
feature extraction selection due rich content image feature extraction finds compact representation object scene lower dimensional space 
feature selection selects features relevant learning tasks 
difficulties confront automatically achieve representation 
learning high dimensionality visual leaning tasks high dimensional due richness visual inputs 
perform effective efficient learning high dimensional spaces challenging problem 
incremental line learning achieve intelligent interaction machine capacity incremental line learning process learn new knowledge learned knowledge 
examples illustrate common problems visual learning tasks 
example invariant object recognition requires recognition object view direction 
task view independent hand posture recognition difficult variation different users 
pure supervised techniques need huge labeled training database 
manually label large data set time consuming tedious 
example task image retrieval find maximum possible similar images query images database :10.1.1.35.7769
information retrieval problems labeled training samples queries 
interesting example comes nonstationary color model adaptation 
tech niques plagued large variation skin tone unknown lighting conditions dynamic scenes 
color classifier trained specific condition may scenarios 
learning task old color model new environment 
discussion enhancing generalization looking training algorithm schemes proposed avoid overfitting 
fewer concerns training data set 
drawbacks pure supervised pure unsupervised learning paradigms motivate develop new paradigm 
organization dissertation novel techniques nonstationary color tracking multiple cues integration articulated hand motion capturing serve basis development vision gesture interfaces 
dissertation new learning paradigm self supervised learning account labeled unlabeled training data 
development interesting gesture interface systems described 
dissertation organized follows chapter gives comprehensive overview state art research vision interface 
research gesture representation section 
vari ous aspects hand modeling discussed section 
discuss feature data collection gesture recognition sections respectively 
sec tion discusses techniques tracking hand global motion section reviews compares model appearance approaches capturing articulated hand motion 
various methods hand posture recognition temporal gesture recognition sections 
research directions described section 
chapter presents nonparametric color model transduction method self organizing map 
adaptive self organizing map technique proposed section 
general technique model transduction section 
som transduction technique discussed section 
segmentation tracking results section 
chapter focuses multiple cues integration robust tracking 
graphical model described section section presents inferencing approach sequential monte carlo techniques section 
mathematical details inferencing appendix implementation inferencing tracking section 
section describes experimental results 
chapter describes model approach capturing articulated hand motion 
hand motion hand model section 
methods capturing global hand motion local finger articulation sections 
section describes step iteration approach combine global local motion estimation 
experiments section 
chapter presents linear em kernel em algorithms self supervised learn ing 
review state art learning hybrid data set section 
em algorithm discussed section problems em approach addressed section 
linear em algorithm kernel em algorithm proposed sections respectively 
extensive experiments invariant hand posture recognition content image retrieval section 
sec tion discusses proposed self supervised learning 
fundamental questions paradigm raised section 
proposed self supervised learning paradigm section includes induction transduction deduction 
chapter describes development interesting vision gesture interfaces 
design vision system interactive game rock scissors design visual panel system remote display control sections respectively 
chapter summarizes dissertation typical self supervised learning problems transduction transduction model transduction inferencing serve clues glue different parts 
interesting research topics 
contributions original contributions dissertation span areas visual motion cap turing learning techniques vision human computer interaction 
particular issues addressed 
novel nonparametric algorithm som transduction developed conduct model transduction dynamic learning environment 
non stationary color tracking tasks 
novel approach inferencing algorithm proposed integrate multiple cues robust visual tracking 
inferencing technique extended sensor fusion problems 
effective model approach visual motion capturing developed analyze global hand motion local finger articulation 
originality lies employment finger motion model learned motion data 
novel self supervised algorithm em algorithm proposed integrating discriminant analysis em 
algorithm employs labeled unlabeled train ing data 
linear em nonlinear kernel em investigated 
em successfully applied invariant hand posture recognition tasks content image retrieval tasks 
self supervised learning techniques potential applications learning tasks 
interesting prototypes vision gesture interfaces developed integrating algorithms dissertation 
dissertation mainly concentrates issues vision intelligent human computer interaction 
techniques developed easily extended tasks areas 
example som transduction algorithm extended distribution adaptation tasks inferencing algorithm ready sensor fusion tasks 
self supervised learning new learning paradigm 
means confined specific area 
dissertation described application image retrieval task 
em algorithm easily extended infor mation retrieval applications 
completely develop theory self supervised learning paradigm motivate investigation new research topic near 
chapter vision gesture interfaces review chapter surveys studies vision gesture recognition techniques 
sec tion discusses human gesture representation paradigms psycholinguistic cog nitive studies high level temporal gesture recognition tasks represented paradigms serve cognitive model complicated temporal hand ges tures 
recognition method needs feature extraction data collection section discusses gesture features current studies section provides brief overview tracking techniques serve data collection process vision gesture recog nition 
meaningful hand gestures classified static hand postures temporal gestures sections discuss various techniques hand posture recognition temporal gesture recognition respectively 
sign language recognition important task section discusses studies related 
gesture representation psycholinguistic studies human gestures 
represents gestures aspects hand shape position orientation movement 
kendon de gesture consists language gestures pan sign language 
sign languages characterized specific set vocabulary grammar 
informal gestural expressions meaning depends convention culture lexicon 
different application scenarios hand gestures classified categories conversational gestures controlling gestures manipulative gestures com gestures 
sign language important case communicative gestures 
sign languages highly structural suitable test beds vision algorithms 
time way help disabled interact com 
controlling gestures focus current research vision interface 
virtual objects located analyzing pointing gestures 
display control applica tions demonstrate potential pointing gestures hci 
controlling gesture navigating gesture 
orientation hands captured directional input navigate ves 
manipulative gesture serve natural way interact virtual objects 
teleoperation virtual assembly examples appli cations 
communicative gestures subtle human interaction involves psychological studies vision motion capturing techniques help studies 
communicative gestures decomposed motion phases preparation stroke retraction 
psycholinguistic studies show stroke may distinguished gesture phases stroke contains information 
model taken quek 
distinction presentation gestures repetitive gestures 
bobick emphasizes dynamical part gestures 
represents gestures movement activity action 
movements typically atomic primitive form motion interpreted semantically 
activity sequence movements static configurations 
dynamic models may recognize activities 
actions high level entities people typically describe happening 
time context fundamental reason context unclear 
hand modeling human hand motion highly articulate hand consists connected parts leading complex kinematics 
time hand motion highly constrained difficult model 
usually hand modeled aspects shape kinematic structure dynamics semantics 
hand models hand animation applications employed analyze hand motion 
different models suitable different hci applications 
modeling shape hand shape models classified groups geometrical models physical models statistical models 
geometrical models suitable rendering hand animation applications 
employed analyze hand motion approach analysis synthesis :10.1.1.32.4166
physical models statistical models emphasize hand deformation 
difference physical models aim explicit representation deformation statistical models characterize hand deformation implicitly learning set examples 
spline geometrical surface models represent surface splines approximate arbitrarily complicated geometrical surfaces 
spline surface models realistic possible parameters control points need specified 
alternative approximate homogeneous body parts simpler parameterized geometric shapes generalized cylinders super quadrics 
advantage method achieve equally surface approximation complexity :10.1.1.32.4166
para metric models free form hand models defined set points 
polygon meshes formed points approximate hand shape computationally efficient 
computational efficiency cardboard models visual motion cap turing 
piece cardboard model dimensional plane joint angles adjusted 
examples different hand models shown 
cyber scanner mri techniques space may obtain range data directly 
way reconstruct hand model multiple images different views 
physical hand shape models emphasize deformation hand shape action various forces 
motion model governed newtonian dynamics 
internal forces applied hold shape model external forces fit model image data 
examples simplex mesh model finite element method model 
various hand models 
cardboard model wireframe model polygon mesh model 
statistical hand shape models learn deformation hand shape set training examples images range images 
mean shape modes variation principal component analysis pca 
hand shape generated adding linear combination significant modes variation mean shape 
modeling kinematic structure shows skeleton hand 
finger consists joints names indicated 
thumb degrees freedom dof mcp joints dof proximal pip joints distal dip joints 
simplicity thumb modeled dof kinematic chain dof tm mcp joint ip joint 
considering global hand poses human hand motion roughly dof 
challenge hand motion analysis lies fact hand motion highly articulated 
finger modeled kinematic chain palm base frame fingertip effector 
write mcp aa mcp ip dip fingertip dip frame fingertip base frame 
coordinate transformation transforms frame frame 
fixing joint length hand kinematics characterized joint angles 
inverse kinematics problem involved calculate joint angles analyzing finger motion 
generally gradient methods solve problem deriving distal phalanx ip proximal phalanx mcp metacarpal tm thumb index middle ring distal phalanx distal dip middle phalanx proximal pip proximal phalanx mcp metacarpal hand skeleton structure 
generally assume dof mcp tm joint dof joints 
hand roughly dof local finger motion 
kinematical jacobian 
alternatives literature genetic algorithms :10.1.1.38.2855
inverse kinematics problem ill posed unique solution guaranteed analysis formidable 
fortunately natural hand motion highly constrained 
set constraints usually referred static constraints consists limits range finger motions result hand anatomy mcp constraints limit hand articulation boundary 
type constraint describes correlations different joints reduces dimensionality hand articulation 
example motions dip joint pip joint generally independent described dip ip study biomechanics 
constraint intentionally invalid approximation natural finger motion 
unfortunately constraints quantified closed forms 
studies finger motion constraints literature 
preliminary investigation learning techniques employed model hand configurations space directly collecting large set hand motion data 
computational complexity finger motion analysis reduced significantly considering motion constraints 
modeling dynamics capture complex hand motion recognize continuous hand gestures dynamics semantics hand motion modeled 
kalman filtering extended kalman filtering ekf techniques widely adopted model dynamics 
ekf works tracking tasks 
small motion assumption fails hold hand motion 
simple hand gestures modeled finite state machine insufficient represent complex hand dynamics 
rule approaches applied model complex hand movements 
heuristics needed construct rules 
considering similarities sign languages spoken languages hidden markov model hmm variants model hand dynamics 
generalization hmm dynamic bayesian net promising approach model hand dynamics 
methods essentially learning methods learn intrinsic dynamics set training data 
knowledge dynamics semantics explicitly expressed methods implicitly stored structures learning models 
learning results methods depend training data set structures learning models training methods 
common problems learning approaches generalization learning results largely depends training data 
obtaining training samples trivial problem 
currently research learning dynamics behaviors semantics human motion drawn attention researchers hci computer vision computer graphics psychology 
capturing human hand motion hand motion capturing finding global local motion hand movements 
different model approaches discussed section 
formulating hand motion highly articulated human hand motion consists global hand motion local finger motion expressed mg ml hand motion mg global motion ml local motion 
global hand motion presents large rotation translation written mg rotation translation respectively 
important issue reliably track global motion image sequences 
local hand motion articulated self occlusion detection tracking local hand motion challenging 
local hand motion parameterized set joint angles hand state ml joint angle set 
consequently hand motion expressed 
possible way analyze hand motion appearance approach sizes analysis hand shapes images :10.1.1.53.6402
local hand motion hard estimate means 
possible way model approach :10.1.1.32.4166
single calibrated camera local hand motion parameters estimated fitting model observation images 
multiple camera settings helpful deal occlusion 
model largely alleviate problem depth ambiguity structure hand included model 
localizing hands video sequences hand localization locates hand regions image sequences 
skin color offers effective efficient way fulfill goal 
core color tracking color segmentation 
representation color distribution certain color spaces current techniques color tracking classified general approaches nonparametric parametric 
gives example segmentation hand localization input image segmented color hand blob localized grouping skin color pixels 
hand localization 
input image segmentation result hand blob located analyzing segmented image pixels 
nonparametric approaches color histograms 
color space quantized structure histogram technique shares problem nonparametric density estimation level quantization affect esti mation 
select quantization level color histogram trivial 
nonuniform quantization perform better uniform quantization complicated 
nonparametric approach proposed self organizing map unsupervised clustering algorithm approximate color distribution 
generally nonparametric approaches effectively quantization level properly set sufficient data 
parametric approaches model color density parametric forms gaussian dis tribution gaussian mixture models 
expectation maximization em offers way fit probabilistic models observation data 
difficulty model order selection handled heuristics cross validation 
try apply techniques track human hand face virtual environment applications problem challenging special difficulties large variation skin tone unknown lighting conditions dynamic scenes 
order achieve user independence tracking algorithm able deal large variation skin color different people 
possible solution generic statistical model skin color collecting huge training data set generic color model works user 
collecting labeling huge database trivial 
generic color model obtained face difficulty color tracking generic color models incapable handle changing lighting conditions invariants 
color tracking techniques assume controlled lighting 
cases interested object may shadowed objects object color looks different 
assume constant lighting sources lighting directions intensities tones change 
applications graphics rendered display keep changing reflective lights change apparent color objects 
color constancy problem trivial color tracking 
dynamic scenes changing lighting conditions color distribution time nonstationary statistics color distribution change time 
color classifier trained specific condition may scenarios 
researchers looked nonstationary color distribution problem color tracking 
methods proposed approach problem 
scheme color model adaptation addressed gaussian mixture model represent color distribution linear extrapolation employed adjust parameters model set labeled training data drawn new frame 
new image segmented labeled data set reliable 
scheme transduction som proposed update weights structure trained som capture new color distribution set new training data consists labeled unlabeled samples 
transduction som combines unsupervised supervised updating large amount labeled training data required 
lead robust efficient localization color cue hand shape motion employed localization 
important research problem integration fusion multiple cues 
color hand localized cues motion shape 
scheme tracking contours hands 
color localization computationally efficient integrating cues enhance robustness localization 
selecting image features estimate parameters model image features extracted tracked serve observation estimators 
hand image features geometric features points lines contours silhouettes 
fingertip frequently features positions fingertips sufficient recognize gestures due highly constrained hand motion 
color markers help track positions fingertips :10.1.1.32.4166
researchers estimate positions orientations fingertips fitting cylinder images 
line fitting frequently technique detect fingertips 
capturing hand motion full dof capture articulated hand motion full dof global hand motion local finger motion determined video sequences 
challenging problem analyze capture hand motion hand highly articulated 
different methods approach problem 
possible method appearance approach deformable hand shape templates track moving hand 
method insufficient recover full articulations difficult infer finger joint angles appearances 
possible way model approach takes advantages priori knowledge built models 
approach aligns model images range data estimating parameters model 
model methods image features looked image evidence image observation model projected image plane 
model different parameters produce different image evidence 
model methods recover joint angles minimizing discrepancy image feature observations projected model hypotheses challenging optimization problem :10.1.1.21.3461
important tasks model approach determining match searching hand joint angles space 
examples shown parameters cardboard hand model adjusted match input images 
generally due huge search space hand articulation optimization involved difficult computationally intensive 
capturing articulate hand motion cardboard hand model 
hand pose finger joint angles recovered fitting model images 
fitting minimizes discrepancy image feature observations projected models 
methods tend estimate global local hand motion simultaneously 
hand modeled articulated stick point line image features registration 
hand motion capturing formulated constrained nonlinear programming problem 
drawback approach optimization trapped local minima 
idea model surface hand hand configurations estimated analysis synthesis approach candidate models projected image plane best match respect similarity measurements :10.1.1.32.4166
surface model fine accurate estimation obtained 
hand models user dependent 
rough models give approximate estimations 
ease optimization decomposition method adopted analyze articulate hand motion decoupling hand motion global motion local finger motion 
global motion parameterized pose palm local motion parameterized set joint angles 
step iterative algorithm find accurate estimation :10.1.1.38.2855
initial estimation hand pose estimated median squares joint angles fixed 
joint angles recovered genetic algorithm global hand pose fixed 
steps alternately iterated solution converges :10.1.1.38.2855
data preparation recognition selecting features crucial gesture recognition hand gestures rich shape variation motion textures 
features gesture recognition static hand posture recognition possible recognize hand posture extracting geometric features fingertips finger directions hand contours features available reliable due self occlusion lighting conditions 
features color silhouette textures 
inadequate recognition 
easy specify features explicitly image transformed image taken input features selected implicitly automatically recognizer 
cui weng investigate difference discriminating features mdf expressive features 
extracted projection 
may best classification features describe major variations class typically irrelevant subclasses divided 
selected multiclass multivariate discriminate analysis significantly higher ca catch major differences classes 
experiments showed superior automatic feature selection classification 
recognizing temporal gestures needs spatial features requires temporal features 
possible recognize gestures locations hands 
general view dependent 
fundamental feature location interested blob 
wren multiclass statistical model color shape obtain representation head hand wide range viewing conditions tracking system pfinder 
order achieve spatial invariant recognition features necessary 
campbell investigated invariant features comparing recognition performance different feature vectors derived single set ai chi gestures staying alive application developed becker pentland 
hidden markov model hmm recognizer 
reported dr dz best recognition rates 
time experiments highlight fact choosing right set features crucial performance 
features temporally invariant gesture recognition hard specify depend temporal representation gestures 
features handled implicitly recognition approaches finite state machine hmm discussed section 
data collection recognition collect data temporal gesture recognition trivial task 
hand localized image sequences segmented background 
dimensional tracking supplies localized information hand bounding boxes centroid hand blobs 
simple motion trajectories extracted image sequences 
cases features sufficient gesture recognition 
tracking algorithms color tracking motion tracking template matching blob tracking multiple cues integrating 
tracking gives position information hand recognition appli cations need features hand orientation hand shape 
dimensional tracking approaches try locate hand space giving position tation hand 
hand treated rigid object hard estimate hand orientation 
dimensional position hand achieved stereo camera model approaches 
hand highly articulated shape depends viewpoint hand shape hard describe 
studies try recover state hand represented set joint angles full dof tracking 
hand configuration esti mated recognizing finger spelling may easier 
estimate configuration articulated objects needs study 
static hand posture recognition hand gestures complicated model meanings hand gestures depend people cultures specific hand gesture vocabulary predefined applications virtual environment applications ambiguity limited 
generally hand gestures static hand postures temporal hand gestures 
hand postures express concepts hand configurations hand shapes temporal hand gestures represent actions hand movements 
hand postures act special transition states temporal gestures supply cue segment recognize temporal hand gestures 
research results show static hand signs temporal hand gestures seldom simultaneously suggests study static hand gestures temporal gestures separately 
contrast sign languages gesture vocabulary applications structured disambiguated 
scenarios simple controlling commanding manipulative ges tures defined fulfill natural interaction pointing navigating moving rotating stopping starting selecting gesture commands simple sense mo tion different hand postures differentiate switch commanding modes 
example sense estimate gesture pointing direction know pointing gesture 
problem empirical problem applications 
problem formulated classification problem different predefined static hand postures difficulties 
view independent hand posture recognition means hand postures recognized view direction 
natural requirement applications 
cases users know cameras naturalness users obliged issue commands unknown direction 
difficulty human hand highly articulated deformable large variation hand postures handled user independent system 
hand postures express concepts act special transition states temporal gestures recognizing estimating hand postures human postures main topics gesture recognition 
done area 
model approaches approach model approach hand configuration estimated advantage hand models :10.1.1.38.2855:10.1.1.53.1449
hand configura tions independent view directions methods directly achieve view independent recognition 
different models take different image features construct feature model corre 
joint angles estimated minimizing projected surface model image evidence silhouettes light analysis synthesis 
approach needs surface models process projection comparison expensive 
alternatively point line features employed kinematical hand mod els recover joint angles :10.1.1.38.2855
hand postures estimated accurately correspondences model observed image features established 
physical models statistical models employed estimate hand configurations 
ill posed problem estimating hand configuration trivial 
current methods require reliable feature detection plagued self occlusion 
draw back trivial achieve user independence models calibrated user accuracy sacrificed 
appearance approaches accurate estimation hand configuration important applications manipulating virtual objects multi dof input devices classification hand postures applications commands switching 
appearances different different hand postures differences large different people alternative approach appearance approach aims characterize mapping image feature space possible hand configuration space directly set training data 
approach involves learning techniques 
images different hand postures shown 
recognizing different hand postures 
cui weng discriminating features classify hand signs partitioning mdf space 
manifold interpolation scheme introduced generalize variations limited number learned samples 
algorithm handle complex backgrounds 
triesch von de malsburg employ elastic graph matching technique classify hand postures complex backgrounds 
hand postures represented labeled graphs underlying dimensional topology 
attached nodes jets sort local image description gabor filters 
recognition rate complex background 
approach achieve scale invariant user independent recogni tion need hand segmentation 
graph hand posture insufficient approach view independent 
quek zhao introduced inductive learning system able derive rules disjunctive normal form formulate 
dnf describes hand pose conjunct dnf constitutes single rule 
features area bounding box compactness hand normalized moments served input feature vector learning algorithm 
obtained recognition rate 
ritter detected location fingertips local linear mapping lln neural network locations mapped position parametric self organizing map neural network ability perform asso completion fragmentary input 
means approach recognize hand pose different views 
easier appearance approach achieve user independence model approach major difficulties approach automatic feature selection training data collection 
discussion feature extraction selection little addressed training data 
generalization current methods largely depends training data sets 
general generalization requires large representative labeled training data set 
manually label large data set time consuming tedious 
unsupervised schemes proposed cluster appearances objects hard pure unsupervised approaches achieve accurate classification supervision 
hybrid learning approach proposed employ large set unlabeled images training 
temporal gesture recognition similarities temporal gestures speech techniques hmm applied gesture 
temporal gesture complicated speech 
low level movements recognized dynamic models 
gesture semantics exploited recognize high level activities 
example learning methods 
techniques developed years 
recognizing low level motion modeling low level dynamics human motion important human track ing human motion recognition 
serves quantitative representation simple movements simple movements recognized reduced space tra motion parameters 
low level dynamics models sufficient represent complicated human motions 
low level motions represented simple dynamic processes kalman filter technique employed estimate interpolate predict motion parameters 
simple dynamic model sufficient model cases human motion gaussian assumption kalman filtering usually invalid 
black jepson extended condensation algorithm recognize temporal tra 
sampling technique represent probability density con algorithm approach avoids difficulties kalman filtering 
gesture recognition achieved matching input motion trajectories model trajectories dynamic time warping dtw 
pentland liu try represent human behavior complex model 
alternative models represent human dynamics class re sponse 
model switching observation state dynamics 
approach produces generalized maximum likelihood estimate current values state variables 
recognition achieved determining model best fits observation 
blake push technique combining idea model switching condensation 
mixed discrete continuous states couple perception clas continuous variable describes motion parameters discrete variable labels class motion 
arma model represent dynamics 
approach achieve automatic temporal sequence segmentation 
dealing specific gestures 
cohen dynamic model represent circle line gestures generate recognize basic oscillatory gestures crane control gestures 
recognizing high level motion applications need recognize complex gestures include semantic meaning movements 
modeling dynamics sufficient tasks 
finite state machine commonly employed technique handle situation 
davis shah technique recognize simple hand gestures 
jo kuno shirai take approach recognize manipulative hand gestures grasping holding extending 
task knowledge represented state transition diagram state indicates possible gesture states moment 
rest state unintentional actions ignored 
pavlovi berry take approach 
approach rule modeling 
quek uses extended variable valued logic rule induction algorithm build inductive learning system recognize gestures 
cutler turk build set simple rules recognize gestures waving jumping marching pinhanez bobick develop new representation temporal gestures valued domain past fut pnf network 
occurrence action computed minimizing domain pnf network constraints imposed current state sensors previous states network 
promising approaches modeling semantics temporal gestures bayesian networks dynamic bayesian networks 
pavlovi pushed ideas forward 
gesture recognition hmm pentland liu hmm model state transitions set dynamic models 
bregler takes approach 
hmm capacity model low level dynamics semantics gestures 
stoll ohya employ hmm model semantically meaningful human movements hmm learned motion class 
data modeling human motions approximate pose derived image sequence 
nam hmm method recognize controlling gestures 
approach takes account hand movement hand postures palm orientations 
variations hmm 
yang model gesture employing multidimensional hmm contains observation symbol time 
approach able model multipath gestures provides means integrate multiple modalities increase recognition rate 
output probability feature vectors state hmm unique hmm handle piecewise stationary processes adequate gesture modeling 
kobayashi introduce partly hidden markov model temporal matching 
darrell pentland introduce hidden state reinforcement learning paradigm partially observable markov decision process gesture recognition active camera guided 
markov condition violated conventional hmms fail 
hmms ill suited systems compositional states 
brand algorithm coupling training hmms model interactions processes may different state structures degrees influence 
problems occur vision speech 
coupled hmms suited applications requiring sensor fusion modalities 
wilson bobick extended standard hmm method include global parametric variation output probabilities hmm handle parameterized movements musical conducting driving em algorithm 
results different movements size gesture point gesture show robustness respect noise input features 
techniques statistical learning techniques applied gesture recognition 
described cui weng multiclass multidimensional discriminant anal ysis automatically select discriminating features gesture recognition 
polana nelson attempt recognize motion low level statistical features image motion information 
simple nearest centroid algorithm serves classifier 
experiments show approach suitable repetitive gesture recognition 
watanabe yachida introduce eigenspace constructed multiple input image sequences recognize gestures 
eigenspace represents approximate information gestures approach handle self occlusion 
bobick ivanov model low level temporal behaviors hmm techniques 
outputs hmm serve input stream stochastic context free grammar parsing system 
grammar parser provide longer range temporal constraints 
uncertainty low level movement detection disambiguated high level parser includes priori knowledge structure temporal actions 
yang ahuja time delay neural networks tdnn classify motion patterns 
tdnn trained database asl signs 
input tdnn motion trajectories extracted multiscale motion segmentation 
sign language general gestures sign languages highly structured provide ap test bed understanding general principles 
clear boundaries individual signs recognition sign languages difficult 
speech recognition sign language recognition parallels 
time varying processes show statistical variations making hmms plausible choice modeling processes 
devise ways cope context coarticulation effects 
hmms provide frame capturing statistical variations position duration movement 
addition segment gesture stream implicitly 
kinds gestures recognized isolated gesture continuous gesture 
presence silence boundaries isolated gestures easy spot 
sign extracted trained hmms individually 
continuous sign recognition hand harder silence signs 
hmms offer compelling advantage able segment streams signs automatically viterbi algorithm 
coarticulation difficult handle continuous recognition results insertion extra movement signs 
starner employ hmm recognize american sign language asl 
sume detailed information hand shape necessary humans interpret sign language coarse tracking system studies 
possible approaches deal coarticulation problem 
context dependent hmms modeling coarticulation 
idea context dependent hmms train bi sign tri sign context dependent hmms 
method 
vogler metaxas study coarticulation sign language recognition 
propose unsupervised clustering scheme obtain necessary classes phonemes modeling movements signs 
phonemes signs basic units asl signs broken phonemes movements holds hmms trained recognize phonemes 
number phonemes limited possible hmms recognize large scale vocabularies 
liang take hmm approach recognition continuous tai sign language vocabulary signs 
temporal segmentation performed explicitly discontinuity movements gesture parameters posture position orientation motion 
research directions progress years issues related gesture analysis recognition need adequately addressed 
robust hand localization idea localizing hand tracking skin color straightforward practice challenging problems color tracking 
color tracking techniques assume controlled lighting 
due dynamic scenes changing lighting conditions color distribution time nonstationary 
color classifier trained specific condition may scenarios 
large variation skin colors applications graphics rendered display keep changing reflected lights probably change skin color 
color consistency problem trivial tracking skin color 
researchers begun look nonstationary color distribution problem color tracking 
color model updating methods proposed solve problem 
handling nonstationary color open research problem 
mean time achieve robust hand localization system multiple cues integrated 
better approaches integration studied 
modeling motion constraints hand highly articulated natural finger motion highly constrained 
constraints largely reduce possible hand configuration space 
consequently search space significantly reduced hand posture estimation articulate motion capturing efficient 
unfortunately constraints impossible represent explicitly partly due large variation finger motion 
achieve robust efficient estimation hand configuration realistic hand animation constraints modeled 
explicit modeling learning tech niques taken characterize hand configuration space 
profound investi gation conducted 
motion editing animation realistic articulated hand animation considered 
human imation produced current animation systems looks unrealistic looks robots due fact current motion model simplified largely depen dent kinematics 
achieve realistic animation natural motion constraints integrated animation systems 
research direction achieve personalized ani mation different styles motion produced low cost 
schemes avoiding violation body constraints collision detection built animation systems 
recognizing temporal patterns hmm widely speech recognition researchers applying hmm temporal gesture recognition current examples gesture recognition hmm limited vocabularies 
compared hmm speech recognition data collection hmm training temporal gesture recognition difficult part reason large vocabularies prevented 
crucial issue training data collection motion capturing 
due lower cost noninvasive nature vision motion capturing ideal approaches collect motion training data 
challenging unsolved problems vision motion capturing techniques 
issue gesture coarticulation extraction segmentation gesture commands harder continuous hand movements 
word representation temporal gestures needs research 
different representation speech signals 
motion interpretation quite ill posed problem cognitive science psychological studies may combined 
near possible develop task specific gesture systems far general purpose temporal gesture recognition understanding system 
open questions achieve immersive interaction multimodality integrating hand gestures speech adequately addressed 
research shows complementarity different modalities hand gestures speech 
profound research conducted 
current research focuses single hand gestures simplicity 
handed ges tures studied expressive allow natural interaction 
chapter nonstationary color tracking vision interaction systems localizing tracking targets video sequences important related issues steps provide inputs processing steps target recognition action recognition 
generally target localization achieved estimating bounding box target image sequences 
visual tracking includes tracking estimates motion parameters tracking gives positions orientations target space high dof tracking tracks deformation articulation target 
difficulties visual tracking lie complex backgrounds unknown lighting conditions complex target movements 
multiple objects handled simultaneously problem challenging different objects cause occlusion 
robustness accuracy speed important evaluate tracking algorithms 
different image features object supply different cues tracking algorithms 
edge approaches match edges images target images region approaches image templates matching 
small motion assumption assumes little difference consecutive image frames approaches achieve accurate results 
assumption hold practice tracking algorithms lose track tracking recovery depend remedies 
time edge region tracking methods generally need computational resources real time systems difficult achieve 
alternative blob approach local image information edge region represents target color motion target segmented background localization tracking 
example need localize human hand video sequences difficult represent hand edges image appearances hand highly articulated due finger movements large variations hand appearances different viewpoints 
notice skin color tones different fingers uniform color segmentation approaches afford efficient robust implementation real time localization tracking hand 
skin color strong cue human tracking 
combining approaches integrating multiple visual cues result robust tracking results 
efficient segmentation desirable tracking bootstrapping cases small motion assumption hold tracking reinitialization loses track 
successful tracking systems built color segmentation 
simple approach collect skin color pixel samples user train color classifier skin color regions segmented background classifying grouping similar color pixels 
approach problem large variation skin color different people solutions tune color classifier large training data set collected people 
unfortunately practice complications 
color distributions may change lighting conditions case fixed skin color model may time 
difficulty collecting large labeled training data set trivial 
discuss issues details sections 
study new representation color distributions model tasks adaptive color segmentation nonstationary color tracking 
inter aspect neural network structure learned training 
analysis stationary status self organizing map neural network section 
color model transduction algorithm 
contrast methods constructing specific skin color model proposed approach tries adapt models nonstationary color distributions trans learned color model image sequences 
section report experiments proposed color model 
nonparametric density representations contrast parametric representation density nonparametric approaches assume distribution models require parameter estimation 
consequently flexible able model complex data distributions 
sacrifice analyzability cost flexibility 
time nonparametric techniques require large number samples 
histogram vector quantization histogramming simple widely technique nonparametric modeling density 
density particular point represented number samples falling volume point 
parzen window method looked generalization histogramming 
histogramming able model density plagued curse dimen 
dimensional space order bins quantization level dimension 
example component color histogram 
bins hs histogramming hsv histogramming 
huge data set turn needed obtain histograms 
vector quantization vq technique overcome difficulty tessellating data space 
cell tessellation represented code vector 
clustering techniques achieve vector quantization turn representation data density similar histogramming 
major factors histogramming vq quantization level resolution 
quantization level large low resolution density estimation rough smooth 
hand quantization level small high resolution density estimation accurate noisy 
important find quantization level difficult determine advance 
methods proposed deal difficulty multiresolution approaches adaptive approaches 
self organizing map self organizing map som mainly visualizing interpreting large high dimensional data sets mapping low dimensional space competitive learn ing scheme 
som consists input layer output layer 
shows structure som 
number nodes input layer dimension input vector structure output layer connected nodes connected input node weights 
competition index win ing node taken output som 
hebbian learning rule adjusts weights winning node neighborhood nodes 
som highly related vector quantization vq mean clustering 
characteristic som partial data density preservation properly trained 
adaptive self organizing map outputs som structure 
weights inputs problems clustering algorithms number clusters specified advance 
success clustering algorithm depends specified number clusters 
case basic som algorithm 
output neurons higher resolution output neurons correspond clusters 
different numbers clusters lead different results tessellation pattern space 
fewer neurons data lower density dominated patterns higher density 
hand nodes ordered mapping hard obtain 
possible approach problem cross validation 
structure som number output neurons fixed time structure determined validating different structures 
approach offer flexibility find appropriate structure som fast 
alternative embed heuristics dynamically change structure som training 
algorithm automatically find appropriate number clusters schemes growing pruning merging 
growing scheme algorithm competitive learning scheme deals problem find competition winner 
som algorithm output node distance input vector weight vector node 
distance measurement defined wi wi distance measurement input vector weight vector wi ith neuron som 
call output value output neuron 
measurement euclidean distance distance measurements employed 
standard som neuron smallest output value taken winner arg min wi cases output values neurons nearly determining winner finding smallest value suitable 
situation input vector may far weight vector center convex hull weight vectors 
current input sample drawn data cluster represented output neurons weight vector neuron misplaced unnecessarily training adjusting weight 
robust way take neuron smallest output value winner 
situation new neuron generated inserting current structure input vector initial weight illustrated 
comparing mean value median value output values neurons rule detect situation new neuron created 
competition growing scheme 
wi weight vector input vector 
left input vector far weight vector output value neurons nearly current input data cluster represented neurons say weight vector neuron misplaced unnecessarily right situation new neuron created weight set described vi wi 
vi output value ith neuron weight vector wi number neurons 
competition winner null mean median arg mini vi 
vm current number neurons 
pruning scheme training process neuron rarely winner means data cluster represented neuron low density taken noise 
neuron pruned 
practice threshold set determine neurons 
merging scheme training process distances weight vectors neurons calculated 
weight vectors near merge neurons assigning average weights new 
algorithm summarized 
perform color image segmentation color model 
segmentation algorithm training data set collected color image data vector weighted hsi vector set 
pixels large small intensities included training data set hue saturation unstable range 
trained label pixel hsi value 
pixel label index node 
initially set number neurons randomly initialize weights wi wi wi represents weight vector ith node kth iteration 
draw input training sample set randomly 
find winner neurons equation 
winner null adjust weights winner neuron neighborhood neurons 
wc wc wc wc wc wc wc wc wc step size learning neighborhood function counter iteration 
winner grow new neuron growing scheme 
wm set 
neuron rarely win delete pruning scheme 
calculate distance neurons perform merging scheme 
training algorithm structure adaptive self organizing map 
model transduction color model adaptation practice learn generic color classifier color segmentation collecting large labeled data set 
color invariants learning color classifier suggest direct robust way color tracking 
consider nonstationary color distribution time generally expect find invariants 
approach taken inductive learning approach color classifier learned able classify pixel image 
generally color classifier highly nonlinear huge labeled training data set required achieve generalization 
fact learning highly nonlinear color classifier lighting conditions images may necessary requirement generalization relaxed subset data space 
color tracking color classifier mt time frame classify pixel xj current specific image feature data set specific classifier mt simpler 
new image time specific classifier mt new classifier mt works just new image 
classification described yi arg max yj xi mt xi yi label xi number classes 
sense care performance classifier mt outside 
call problem classifier mt mt model transduction 
shows transduction color classifiers 
illustration transduction classifiers 
model transduction may feasible know joint distribution 
unfortunately joint probability generally unknown may priori knowledge transition color space time 
approach assume transition model case motion tracking kalman filter explicitly model 
difficulties approach fixed transition model unable capture dynamics 
issue motion model switching learning transition models addressed scheme general 
difficulty may easy identify parameters tran sition models due insufficient labeled training data 
approach assumes linear transition model 
transition updating color models plagued newest image segmented 
assumption different transition model assumption 
assume classifier mt time give confident labels samples data divided parts labeled data set xj yj 
unlabeled set xj 
size labeled set unlabeled set respectively xj color feature vector yj label skin non skin 
distribution 
consequently transductive classification written yi arg max yj xi xi formulation specific classifier mt classifier mt com large unlabeled data set 
time classifier model learned fully labeled data set yt 
density conditional density known 
time just set unlabeled data 
point know 
conditional density transduction 
new classifier model learned term calculated density estimation techniques 
som lvq easily applied 
term difficult deal involves dynamics explicit model transition 
transition model assumptions transition transduction sense transition arbitrary 
assume confidently give true observations classify samples consist true labels time 
assumption reasonable means difference small transition large 
means estimate oy 
labels hidden variables basically em iteration taken fulfill transition 
step kth iteration find argmax step learn som transduction algorithm solution problem called transduction som update weights structure trained som set new training data som captures new distribution 
new training data set transduction consists labeled unlabeled samples 
algorithm described 
weights som time frame 
training data set drawn randomly image time frame represent som time frame training data set classified som partitioned parts labeled data set unlabeled data set sample confidently classified put sample set index winning neuron put label unlabeled 
unsupervised updating algorithm described section employed date unlabeled data set supervised updating labeled data set step 
xk lk drawn lk label xk 
winning neuron input xk xk lk xk lk iterations som time frame experiments color segmentation algorithm tested large variety pictures 
localization system integrates color segmentation algorithm run wide range operating conditions 
real time system employed vision gesture analysis :10.1.1.38.2855
extensive experiments show color segmentation algorithm fast automatic accurate proposed localization system ro bust real time reliable 
color segmentation algorithm applied segmentation tasks 
performance image segmentation parameter specify maximum number neurons 
scene simple set maximum number 
scene complex set 

results color image segmentation structural adaptive selforganizing map 
left column source color images middle column segmented images right column interested color regions 
shows segmentation results 
left column source color images middle column segmented images right column separated color regions 
colors segmented color regions average colors regions 
pixel source images assigned label algorithm label mask separate corresponding color region 
segmentation algorithm works experiments 
background color distraction algorithm finds exact color regions 
texture segmentation segmentation results noisy color texture background 
hand face images taken cheap camera indoor environment labs 
algorithm successfully segment hand face regions 
performance hand tracking typical hand tracking scenario controlling display simulating mouse desktop environments 
camera mounted top desktop computer looks keyboard area give image sequence moving hand 
typical application track human face 
localization system able simultaneously localize multiple objects useful tracking moving human 
localization system essentially global segmentation algorithm largely rely tracking results previous frames 
reason tracker gets lost frames recover interfering subjects 
sense tracking algorithm robust 
proposed system handle changing lighting condition extent transduction color classifier 
time hue saturation weight intensity system insensitive changes lighting intensity objects shadowed intensity light source changes 
problems 
insufficient lighting strong lighting dark bright backgrounds may cause trouble color segmentation algorithm hue saturation unstable system give weight intensity 
lighting condition changes dramatically color segmentation algorithm may fail transduction guaranteed 
hand tracking results experiments 
experiment hand moving interference moving book 
book shading light color skin changing 
blue boxes bounding boxes interested color region 
results hand tracking frames taken image sequences 
moving hand interference book localized 
blue boxes bounding box interested color region 
tracking system robust efficient experiment back ground scene cluttered 
book interfering hand shading light system find correct bounding box 
due sudden change lighting conditions tracker may lost 
quickly recover continue working 
different skin tones affect system 
image interested demo sequence downloaded www ifp uiuc edu 
color region initially train nearly users tested extensive experiments 
discussion computer vision techniques supply ways improve human computer interaction visually understanding human movements requires robust accurate tracking parts human body hands face 
cluttered backgrounds un known lighting conditions multiple moving objects tracking tasks challenging 
chapter mainly concentrated color image segmentation color target tracking 
new representation color models proposed structure adaptive self organizing neural network structure som trained 
representation afford efficient image segmentation competitive process neurons 
investigated color tracking task 
challenge task lies fact lighting conditions background may static color distributions image sequence stationary 
order capture nonstationary color distribution combing supervised unsupervised learning paradigms called transduction 
model achieved robust real time tracking system widely research 
color model looked parametric approach gaussian mixture model 
nonstationary color tracking formulated model transduction problem study focused problem learning new gaussian mixture model old set training data color pixel data 
assuming transition model assume unlabeled pixels new image frame confidently labeled weak classifier preset confidence level 
noticed transduction mature needs efforts find better way combine supervised unsupervised learning schemes 
process competition neurons essentially parallel tracking system faster parallel implementation competition process 
currently localization system offers bounding box interested objects 
shape analysis localized objects extended estimate motion target 
chapter multiple cues integration robust tracking rapid enhancement computational power provided computer hardware easier afford visual capacities computers 
years witnessed development research applications visual surveillance vision interfaces 
visual tracking important part topics 
vision systems able localize moving targets video sequences 
large amount research effort devoted visual tracking analysis human motion 
natural immersive human computer interactions developed visually recognizing interpreting human actions 
afford interactions human motion tracked visually provide sensory inputs recognition 
purposes visual tracking infer states targets image sequences 
positions visual tracking expected recover states poses articulation deformations depend different applications 
tracking problem formulated control signal processing research visual tracking involves fundamental research problems object representation image measurement matching 
states target hidden inferred observable image features difficulties visual tracking lies fact crucial difficult measure state hypotheses image evidence 
bottom top approaches kinds methodologies approach visual tracking problem 
bottom approaches generally tend construct object states ing content images 
basically segmentation methods categorized bottom approaches 
example blob tracking techniques group similar image pixels blobs estimate positions shapes target 
contrast top approaches gen erate candidate hypotheses target state previous time frames parametric representation target 
tracking achieved measuring verifying hypotheses image observations 
model template matching methods cate top approaches 
certainly bottom approaches top approaches combined 
bottom methods computationally efficient robustness largely limited ability image analysis processing grouping tracing image pixels overwhelmed image 
hand top approaches depend image analysis target hypotheses serve strong constraints analyzing images 
performances top approaches largely determined methods generating verifying hypotheses 
achieve robust tracking large number hypotheses may maintained computation involved measuring 
combination methodologies keep robustness reduce computation 
visual tracking techniques generally elements target representation observation representation hypotheses generating hypotheses measurement roughly characterize tracking performances limitations 
discriminate target objects target representation include different modalities shape geometry motion appearance characterizes target state space explicitly implicitly 
find target rep resentation fundamental problem computer vision visual tracking research generally employs concise representations facilitate computational efficiency 
example parame shapes color distributions employed target representations :10.1.1.37.1434
provide constrained description target methods em shape color :10.1.1.47.9503
obviously unique characterization target quite helpful visual tracking general involve high dimension ality 
add uniqueness target representation methods employ target appearance image templates eigenspace representation target representation 
example know person bit easier track person crowd 
motion taken account target representations different objects discriminated differences motions 
hand objects share representation difficult correctly track close state space priors dynamics targets movements 
closely related target representation observation representation defines image evidence object representation image features observed images 
example target represented contour shape expect observe edges contour image 
target characterized color appearance certain color distribution patterns images observation target 
hypotheses measurement evaluates matching target state hypotheses image observations 
measure probability state hypotheses generate image observations 
similarly question ask certain image observation hypothesis produce image observation 
cases obtain exact probability measurements approximate pseudo probabilities 
example template matching tracking method takes ssd measurement 
fewer ssd measurement higher probability hypothesis 
evaluation quite challenging measuring shape hypothesis cluttered background 
analytical results reported current tracking methods take ad hoc measurements 
hypotheses generating produce new state hypotheses old estimation target representation old observation implies evolution dynamic pro cess 
target dynamics embedded predicting process 
certain time instant target state random variable 
posteriori probability distribution target state history observations changes time 
tracking prob lem viewed problem conditional probability density propagation 
estimation target state certain time instance approximated estimating condi tional probability density 
hypotheses generating basically describes evolution posterior density statistics 
kalman filtering technique gives classical example hypotheses generating gaussian assumptions due density characterized mean covariance 
case hypotheses generating characterizes search range confidence level tracking 
gaussian assumption hold case tracking cluttered backgrounds represent density target state nonparametric form 
circumstance hypotheses generating viewed process evolution set hypotheses state samples particles facilitates monte carlo approach tracking 
condensation algorithm example 
image sequences contain rich visual information single object representa tion robust target clutter 
example shape models represent target measure edges images tracking quite unstable target moves clutter 
false edges incurred clutter distract tracker 
approach problem robust tracking integrating multiple cues chapter formulates inference problem factorized graphical model 
due complexity graphical model variational method taken approximate bayesian inference 
different modalities model inference phenomenon 
analysis factorized model presents efficient monte carlo tracking algorithm integrate multiple visual cues inference different modalities achieved em iterations 
chapter give brief overview research multiple cues integration robust tracking section 
factorized graphical model tracking formulation section inference phenomenon ana explained section 
section describes techniques sequential monte carlo approaches tracking problems 
importance sampling technique de scribed details 
proposed approach implementation inference transductive importance sampling section details tracking implementation experiments described section 
section discusses proposed approach points possible directions research 
multiple cues integration elements visual tracking described section notice state hypothesis richer target representation better opportunities verified various aspects image observations 
example combining color distribution target largely enhance robustness contour tracking heavily cluttered background integrating shape color representations incur better tracking color 
hand target clutter indistinguishable terms representations tracking determined prior knowledge dynamics short period time 
prior dynamics available assume random walk target say target terms 
aperture problem motivates research tracking integrating multiple visual cues 
hand observe accurate dynamics model quite important successful tracking existing visual tracking algorithms generally provides tracker prediction target 
approximation assume constant velocity models constant acceleration models target dynamics short period time 
cases parameters dynamic models set advance 
tracking risk dynamic model properly set 
interesting question way enhance robustness dynamic model accurate 
investigation answer solution richer target representation integrate multiple visual cues sections chapter 
intuitions 
suppose represent target modalities shape color appearance 
modalities dynamics models means target deformable lighting change difficult know advance shape deform lighting change 
assume rough dynamics models approximation 
rough dynamics models violated predictions dynamics models largely deviate causing tracking fail 
reason modalities treated separately 
main idea modalities interact 
example target shape changes little lighting changes lot estimation target color appearance fulfilled advantage shape estimation relying dynamics models color appearance 
hand lighting changes slowly target deforms lot deformation robustly localized looking color appearance strong prior prediction dynamics model deformation 
naturally shall ask deformation lighting changes quite large 
described problem sort problem approach estimation maximizes joint probability modalities 
exact formulation analysis 
multiple cues integration done terms object representation observation representation 
approaches perform multiple observation measurements accumulate measurements hypothesis 
robust extent methods combining measurements different sources ad hoc 
integrate shape color tracking algorithms assume fixed color distribution target enable efficient color segmentation 
assumption invalid practice 
literature nonstationary color tracking methods reported 
assuming fixed color representation methods include color modality target representation multivariable gaussian represent color motion parameters 
enable robust tracking capacity reinitialization re searchers investigated combination switch different trackers track different modalities 
generally different modalities updated sequentially methods 
hand tracking shape color simultaneously formidable prob lem increases dimensionality state space target 
tries investigate relationship different modalities visual tracking identify efficient way facilitate robust simultaneous tracking modalities 
graphical models tracking section shall formulate visual tracking problem probabilistic framework 
integration multiple cues characterized factorized graphical model variational analysis approximate inference task 
dynamic system states target image observations represented xt zt respectively 
history states measurements denoted 
xt 
zt 
tracking problem formulated inference problem prior xt prediction density 
xt zt xt xt xt xt xt xt dxt zt xt represents measurement observation likelihood xt xt dynamic model 
probabilistic formulation tracking problem represented graphical models similar hidden markov model 
time observation zt independent previous states previous observations current state xt zt zt xt states markov property xt xt xt 
tracking problem represented graphical model similar hidden markov model 
tracking problem approached inference techniques graphical model 
consequently dimensionality hidden states increases inference learning difficult due exponential increase required computational resources 
distributed state representation largely ease difficulty decoupling dynamics 
fox example target states decomposed shape states color states architecture shown 
furthermore observation separated shape color respectively 
observation depends color shape states 
due complex structure factorized network exact inference formidable 
approach problem statistical sampling methods gibbs sampling 
approach approximate posterior probability hidden factorized graphical models states target decomposed shape states color states factorized graphical model 
observation separated states tractable distribution 
lower bound log likelihood log achieved approximation log xt kl xt log log generally choose simpler structure eliminating de minimizing kullback leibler divergence equation :10.1.1.16.2929:10.1.1.16.2929
achieved structured variational inference 
basic idea markov chains replace true observation probability hidden state distinct variational parameter varied minimization 
supposing target state includes modalities write zq zq xt xm number modalities factorized markov chains state mth modality time frame xt variational parameters zq normalization constant 
general continuous analysis approach unavailable method employed structured variational analysis case discrete hidden state observation 
assumption linear observation set fixed point equations xt minimize kl obtained xt zt function details appendix estimation hidden state nth uncoupled markov chain variational parameters variational parameters new set expectations hidden states fed back equation solved iteratively 
similar em algorithm 
clear explicitly write equation fixed point equations equation case modalities example shape color xt zt xt zt shape state color state xt hc xt color variational parameters respectively 
represent shape noted original densely connected graphical model uncoupled 
hidden states uncoupled markov chain estimated separately set variational parameters 
estimation variational parameters chains depends hidden states chains 
phenomenon quite clear equation iteration fixed point equations estimation shape state xs hs calculate variational parameters color modality hc xt estimation color state calculate variational parameters shape modality hs xt call interesting phenomenon inference modality inferred iteratively modalities 
variational analysis factorized model meaningful problem multiple cues integration reveals interactions different modalities 
suggests efficient approach track multiple cues section 
sequential monte carlo techniques described previous sections visual tracking problem formulated probabilistic framework representing tracking process conditional probability density propagation 
denote target state observation time xt zt respectively 
xt 
zt 
tracking problem formulated xt zt xt xt closed form solutions dynamic systems generally intractable cases monte carlo methods offer way approximate inference characterize evolution dynamic systems 
statistics sampling techniques widely approximate complex probability density 
sequential monte carlo methods dynamic systems studied area statistics 
set weighted random samples 
properly weighted respect distribution integrable function lim ef sense distribution approximated set discrete random samples having probability proportional weight posteriori density xt represented set weighted random samples sample set evolve new sample set representing posterior xt time 
sense tracking characterized evolution set weighted samples state space 
factored sampling represent posteriori density xt set random samples 
drawn prior xt weighted measurements zt xt posteriori density xt represented set weighted random samples 
sampling scheme called factored sampling statistics 
shown sample set properly weighted 
sample set evolve new sample set time new sample set represents posteriori density xt time 
sequential monte carlo method employed condensation algorithm :10.1.1.37.1434
condensation achieved quite robust tracking results 
robustness monte carlo tracking due maintaining pool hypotheses 
hypothesis needs measured associated likelihood value computational cost mainly comes image measurement processes 
generally samples better chance obtain accurate tracking results slower tracking speed 
consequently number samples important factor monte carlo tracking determines tracking accuracy speed 
unfortunately dimensionality state space increases number samples increases exponentially 
phenomenon observed different methods taken reduce number samples 
semiparametric approach taken retained modes peaks probability density represented local neighborhood surrounding mode gaussian distribution 
approach eliminated need large number samples representing distribution mode 
different sam pling techniques investigated reduce number samples 
partitioned sampling scheme proposed track articulated objects 
basically hierarchical method generate hypotheses 
similar approach taken track multiple objects 
annealed particle filtering scheme taken search global maximum posteriori probability density 
exclusion scheme proposed approach occlusion problem multiple target tracking 
importance sampling practice difficult draw random samples distribution 
sam ples drawn distribution weights properly adjusted 
basic idea technique importance sampling 
samples drawn weights compensated proved sample set properly weighted respect 
illustrated 
importance sampling 
samples drawn distribution adjusted weights represent density 
employ importance sampling technique dynamic systems need ft xt ft tracking prior prediction density 
want approximate posterior xt draw random samples distribution gt xt prior density ft xt 
sample weights compensated evaluate ft xt zt xt ft xt xt xt approximate posterior xt sampling directly prior xt samples drawn source gt xt weight sample ft gt zt xt ft xt 
notice order sample gt xt ft xt ft gt 
importance sampling technique important part proposed inference tracking section 
dynamic system formulated probabilistic framework sampling techniques approximate probabilistic inferences 
inference tracking algorithm structured variational analysis factorized graphical model section suggests way dynamics states 
section efficient algorithm approximate inference variational analysis statistical sampling sequential monte carlo technique 
ss denote nth sample target state time represent shape color states sample respectively 
denote sample weight shape observation color observation combination shape color observation respectively 
time set samples associated weights 


generate samples time sc 
iterative procedure shown generate sc 
step initialization step shape samples generating ss step shape observation shape ss step color samples generating sampling sc step color observation color sc inference tracking algorithm top 
basic idea iteration modality receives priors modalities training modalities tend maximize 
specifically shape samples drawn color measurements importance sampling shape samples drawn gs fs 
clutter incur high shape measurements sampling shape measurements difficult handle cluttered backgrounds especially generic shape representation taken 
sampling color measure ments largely ease difficulty samples higher color measurements higher probability propagate 
weight corrections fs fs st gs zt xt symmetrically color samples drawn shape measurements importance sampling color samples drawn gc fc 
step color samples higher shape measurements better chance propagate time step 
fc fc st gc zt xt xct steps approximate inference 
iteration increase likelihood observations 
simplicity shape color states estimates approach different algorithm 
method fixed color distribution color extra prior approach track shape color due inference 
color dynamics fixed approach similar method 
algorithm takes top approach shape color generating samples joint shape color state space 
notice efficient combine top bottom approaches color state estimated bottom approach 
basic idea generate shape samples train color model target color data collected shape samples em framework 
em iteration color model maximizes likelihood color observation 
time generating samples time shown 
color model mt procedure step calculates observation probability color model hypotheses respect current color model different positions different shapes 
step trains new color model observations 
em iteration algorithm generate mt mt 
step shape samples generating sampling ss step shape observation shape ss step collecting initial color observations color collect ss mt step re training color model step step mt inference tracking algorithm ii combining top bottom 
basically bottom routine learn new color model old set training data obtained shape model 
similar transductive learning approach color tracking 
implementation section proposed framework tracking integrating multiple cues importance sampling technique 
remainder presents specific implementation real time tracker 
shape representation detailed shape model splines employ conics model general purpose flexible 
conics model suitable certain specific applications tracking human heads fingertips 
take generic form conics ax bx shape template initialized conics fitting 
deformation shape governed affine transformation ax characterizes shape space dimensionality shape space 
idea shape space determine conic shape template affine transformation 
shape samples algorithms drawn shape space shape observation crucial accurate shape observation tracking 
implementation takes similar approach 
edge detection performed normal lines hypothesized shapes shown 
observation reduces set scalar positions 
zm due presence clutter 
true observation 
qp clutter zm zm point shape contour probability positions viewed observation 
zm assume true observation unbiased normally distributed standard deviation zm zm clutter poisson process density exp zm edge observation normal lines shape hypothesis shape observation measurement 
set observations applied contour shape hypothesis 
measurement calculates likelihood segment shape contour observing edges 
measure shape hypothesis apply set observations 
shape contour 
measurements obtained set normal lines contour 
experiments ellipse target shape representation general shape convex objects human head 
example shown red line shape hypothesis curves edges detected line segments normal lines ellipse 
assuming indi vidual observations independent obtain measurement shape hypothesis color representation take parametric color representation normalized rgb color space 
object uniform color gaussian distribution taken model color distribution 
simplicity represent color state 
target salient colors mixture gaussians model distribution 
keep dimensionality small represent color state 
take nonparametric representation color histogram uses colors bins 
set approach approach ii 
color observation set color pixels collected inside shape contour 
parametric approach taken parametric color model estimated color pixels mahalanobis distance measure similarity distributions 
nonparametric approach taken color histogram built color pixels histogram intersection computed hypothesis color model observed histogram min histogram intersection approximate color likelihood experiments section reports experimental results sequential monte carlo tracking techniques tracking algorithm inference learning 
tracking performances signal cue multiple cues examined section 
single cue implement condensation algorithm run different methods hypotheses measurements shape color respectively 
condensation maintains set particles hypotheses represent posterior probability target state xt 
shape representation 
generally expectation xt calculated factored monte carlo sampling approximate target estimation 
shape hypotheses solely measured edge observation tracking algorithm works simple backgrounds strong edges observed 
background cluttered tracking fails hypotheses high probability distractors terms shape 
red ellipses represent shape hypotheses 
brighter red ellipse higher likelihood hypothesis 
blue ellipse shape estimation target 
examples observed hypotheses high probability cluttered backgrounds keyboard area bookshelf area 
condensation shape observation hypotheses generated clutter 
tracking hand 
keyboard area produces false shape hypotheses 
tracking head 
bookshelf area highly cluttered hypotheses incorrect shape measurements 
part reason tracking failure generic shape model accurately align contours target 
advantage generic model allow shape deformation 
hand specific shape model employed spline model largely alleviate difficulty clutter uniqueness shape representation 
direct reason leaf tracked background full leafs 
difficult handle large shape deformation caused plane rotation affine shape space 
experiment color observations shape hypotheses 
constructed color model target initialization step tracking example histogram target 
shape hypothesis measured likelihood color model produces color distribution inside shape hypothesis 
hypotheses solely measured color distributions tracking algorithm succeeds background comparable area similar color target 
tracking fails background similar colors targets 
shows case wooden color similar skin tone false hypotheses generated 
lighting conditions change dramatically difficult track shoulder person 
condensation color observation color nonstationary environments tracking difficult 
tracking face 
hypotheses generated wooden door area hypotheses survive color measurements 
tracking shoulder dynamic environment 
due changing illumination conditions color measurements accurate anymore 
multiple cues tracking algorithm applied variety environments tracking tasks 
experiments show tracking algorithm multiple cues performs robustly 
tracking algorithm runs processor piii mhz pc hz 
inference tracking algorithm successfully applied different tracking sce 
shows example tracking hand fist large rotations cluttered background 
shows example tracking head plane rotations office environment 
task track speaker head lecture room lighting changes dramatically 
shows example tracking person shoulder top view virtual environment 
experimented occlusions shown 
hand moving rotating cluttered background 
tracking solely shape edge lost hand leaves keyboard area shown previous section 
algorithm employs shape color representation shape color observations overcome difficulty 
reason success different modalities provide reinforcement inference fashion 
including shape color results richer target representation tracking algorithm complex environment 
demo sequences obtained www ifp uiuc edu 
testing sequences obtained robotics stanford edu birch 
hand clutter 
dimensionality state space higher case single modality inference different modalities explore high dimensional state space efficiently 
moving face office environment 
testing sequence courtesy dr stan birchfield 
shows result algorithm track head office 
obviously color distribution girl head components skin color tone black hair tone 
turns head nonstationary color changes visible side head 
scenario sense construct fixed color model head color distribution visible side head varies rotates head 
solutions head model color features 
similar texture model reported 
approach adapt color model lighting changes 
inference tracking algorithm adapts nonstationary color distribution assumption changing color distribution slow 
generally assumption valid scenarios 
algorithm tracks head accurately moves front wooden door 
reason shape modality provides external constraint color modality 
head lecture room dramatic lighting variations 
testing sequence courtesy dr toyama 
shows case lecture room lighting changes dramatically due overhead projector 
color speaker head varies wide range intensities 
algorithm tracks speaker head pretty robustly fail reasonably due large movements camera speaker uncertain movements dim light 
shoulder cave large virtual environment lighting diffused screen displays 
shows tracking scenario large virtual environment displays sides floor 
camera mounted ceiling 
interest estimate user position orientation tracking head shoulder 
difficulty displays diffuse large amount lighting environments 
tracking shoulder harder tracking head shoulder deforms rotates addition produce strong edges head 
difficult scenario methods single modality 
employing multiple modalities target representation algorithm works robustly parameters properly set 
face occluded moving face office environment 
testing sequence courtesy dr stan birchfield 
shows example algorithm handling occlusion 
example boy moving front target girl causes occlusion girl face period time 
inference tracking algorithm keeps tracking girl occlusion occurs 
reason example occluding object boy different size target girl avoids generating hypotheses occluding object 
extensive experiments live video recorded sequences inference tracking algorithm performed robustly clutter backgrounds non stationary color changes slow dynamic illumination environments occlusion scenarios 
discussion visual tracking fundamental problem computer vision 
receives attention due rapid development visual surveillance vision human computer interaction robust tracking methods desirable 
difficulties confronting measure tracking hypothesis image observations 
richer target representation accurate measure likelihood hypothesis 
basically tracking process search best match target state space 
multiple modalities target representation tracking methods condensation algorithm involve exponential increases computation dimensionality state space 
inference approach integrating tracking multiple cues 
tracking problem formulated inference problem graphical model 
approach structured variational analysis factorized graphical model suggests inference higher dimensional state space factorized lower dimensional state spaces iterative fashion 
call inferencing 
sequential monte carlo tracking algorithm importance sampling technique proposed approximate inference process different modalities 
tracking algorithm robust dealing target deformation color variations richer representation target taken 
inferencing phenomenon interesting involves information fusion exchanges different modalities 
see general phenomenon learning high dimensional space 
area text classification involve dynamics similar approach called training taken explore correlation different modalities :10.1.1.114.9164
investigate occlusion problem extend case tracking multiple objects articulated objects 
chapter capturing human hand motion hand gestures natural articulate way human computer inter action applications 
example people hands manipulate virtual objects directly virtual environments 
difficulties confronting capture human hand motion 
alternative glove techniques require users wear special glove vision techniques noninvasive affordable 
capturing hand finger motion video streams quite challenging task 
typical hand motions include global translation rotation natural finger movements 
hand rotation incur self occlusion fingers may invisible 
finger motion high de freedom techniques estimating finger articulations involve formidable search problem high dimensional space 
different methods proposed analyze human hand motion 
approach deformable hand shape models hand shape deformation gov newtonian dynamics statistical training methods principal component analysis pca technique 
accurate estimates hand poses hard obtain methods 
approach appearance approach tries establish mapping image feature space hand motion space 
appearance approach generally involves quite difficult learning problem trivial collect large sets training data 
methods categorized model approach 
hand motion recovered matching projected model observed image features problem search problem high dimensional space 
construct correspondences model images different image observations studied fingertips line features silhouettes :10.1.1.21.3461
methods tackle global hand motion local finger motion simultaneously optimization high chance get local minima 
hand divide conquer approach taken separate hand pose tion articulation estimation :10.1.1.38.2855
general method articulate objects 
proposes approach capture hand pose finger articulation divide conquer framework 
propose algorithm combining iterative closed points icp algorithm factorization method determine global hand pose 
section describe approach 
fact natural finger motion highly constrained helps reduce dimensionality feasible hand configuration space 
propose set linear manifolds characterize hand configuration 
details hand motion model section 
efficient algorithm sequential monte carlo techniques finger motion section 
enhance accuracy iteration pose estimation finger articulation tracking performed em fashion 
details section 
experiments including simulation real sequences shown section 
hand motion hand model hand motion consists global hand pose mg local finger articulation ml 
global pose mg translation rotation palm finger motion ml represented set joint angles 
see finger hand model names joints shown 
task motion capturing estimate image sequences 
hand modeled cardboard model finger represented set connected planar patches 
length width patch calibrated individual people 
cardboard model shown 
simplification real hand offers approximation motion capturing 
mcp pip mcp dip hand model kinematical chain finger cardboard hand model 
integrating finger motion constraints reducing dimensionalities employ hand configuration space represent local finger motion joint angle particularly interested dimensionality topology 
collected set joint angle data represent finger motion constraints 
pca technique employed eliminate redundancy 
project dimensional subspace maintain information 
furthermore define basis configurations 
bm bk characterize configuration space 
basis configurations identified clustering data selecting intuitively 
shown 
surprisingly examining data natural hand articulation lies largely linear manifolds spanned basis configurations 
example hand moves basis configuration bi basis bj intermediate hand configuration lies approximately linear manifold spanned bi bj lij sbi bj 
consequently hand articulation characterized configuration space lij lij span bi bj lower dimensional illustration shown black dots real finger motion data points 
hand articulation configuration space characterized set basis configurations linear manifolds 
subset basis configurations linear manifolds configuration space 
capturing global motion global hand motion defined pose palm 
treat palm rigid planar object 
pose determination formulated scaled orthographic projection section global motion computed iterative closed points approach section 
hand pose determination section assume correspondences constructed pose tion 
process building correspondences section 
point plane xi xi yi image point mi ui vi scaled orthographic projection ui vi xi yi ui vi xi yi mi axi subtract centroids projection points model points mi mi xi xi gives mi xi 
mi xi denoting vk ith image point kth frame write 




xn yn write ms factorization method taken solve svd write known factorization recover motion shape matrix md ms constraints construct feature points correspondences image frames structure motion technique allow calibrate hand model automatically desirable manually calibrating hand model 
model calibrated computed calculation motion straightforward 
solve ss ss motion solved md ss contains appendix show estimate rotation matrix depth translation computed easily compute simplicity frame shows front palm calibration take image points palm contour model points 
iterative closed points algorithm pose determination method previous section assumes point correspon dences 
section describe method establishing point correspondences adapting idea iterative closed points icp algorithm 
comprehensive description icp free form curve registration 
basic idea refine correspondences motion parameters iteratively 
treat palm rigid planar object represent contour curve 
curve represented set points 
xj chained points curve model edges observed image 
objective construct correspondences curves wjd rx minimized denotes distance point curve wj takes value match xj takes represents image formation 
icp algorithm takes image edge point closest projected model point rx correspondence 
image edge points far projection model point xk matched set wk 
motion computed temporary correspondences pose determination method section 
computed motion result new matching 
iteratively applying procedure icp yield better better pose estimation 
pointed icp procedure converges local minima means need close initial start 
obviously icp algorithm easily extended frame registration 
capturing local motion section presents method tracking local finger motion 
articulated finger motion highly constrained propose sequential monte carlo algorithm advantage constraints 
sequential monte carlo techniques tracking problem formulated process conditional probability density propagation 
denote target state image observation xt zt respectively 
xt 
zt 
tracking problem formulated xt zt xt xt monte carlo methods offer way approximate evolution densities 
posteriori density xt represented set weighted random samples 
sample set evolve new sample set time new sample set represents posteriori density xt time 
source sampling priors sequential monte carlo different sampling schemes including factored sampling condensation algorithm samples directly prediction prior xt importance sampling samples outside density 
importance sampling provides flexible way choose tracking priors extra computation compensate weights samples 
finger articulation high degrees freedom condensation requires huge amount samples density propagation intensive computation involved 
fortunately take advantage constrained finger motion model described section represents finger configuration space set linear manifolds 
representation perfectly accurate serve outside prior importance sampling technique reduce computational complexity 
ft xt ft prediction tracking prior 
want approximate posterior xt draw random samples distribution gt xt prior density ft xt 
sample weights compensated zt xt natural finger motion hand configuration basis state bk manifold lij suppose time frame hand configuration xt basis states 
process generating new hypotheses shown 
find projection xt xt nearest manifold ij accordingly st xt bi bj bi bj bi random samples drawn manifold lij density pij pij st perform random walk bi bj importance function gt st 
gt weight sample obtain hypothesis write st exp ft gt zt xt previous hand configuration basis configurations say xt bk process generating hypotheses illustrated 
reasonable assume takes manifolds equal probability 
consequently random samples drawn mixture density pk 
details algorithm 
model matching employ edge silhouette observations measure likelihood articulate motion hypotheses zt xt 
self occlusion handled constructing occlusion map xt generating hypotheses edges normal line shape model shape measurements 
bi bi 
hand model 
hand represented cardboard model expected observe edges planar patch 
observation process illustrated 
cardboard model sampled set points patches 
sample edge detection performed points normal sample 
assume edge points zm observed clutter poisson process density xk eq exp zm xk consider silhouette measurements calculating difference areas image ai projected cardboard model am pa exp ai am likelihood written divide conquer sections treat global hand poses local finger articulations independently 
method local finger motion capturing global hand pose model projection depends hand pose finger joint angles 
inaccuracy global pose estimation induce errors estimating local articulation method mistakenly try stretch bend fingers match observation errors global pose 
unfortunately pose determination method section induce inaccuracies method matches palm edges observed images 
inaccuracy occurs index finger straight result wrong scaling rotation 
observe phenomena experiments 
basic idea tackle difficulty introduce feature points pose nation 
extra feature points largely reduce ambiguity 
pick points local finger motion known 
example know mcp joint index finger nonzero point mcp joint 
know fingers straight fingertip 
principle points lie plane palm outside palm certainly 
generally points provide bounds model matching 
extensive experiments verified usefulness extra points 
obviously find extra points know local finger configurations 
iterate steps pose determination palm contour extra points method section tracking local finger configuration method section finding extra points 
iterations global local motion estimation converge stationary point locally minimizes discrepancy observations model projections 
shall see reason 
human hand special articulated object role fingers motion different palm 
observation global hand motion represented position orientation palm define global hand motion exact pose palm 
local hand motion largely determined motion fingers 
problem hand motion capturing specifically formulated arg min pmg ml mg global motion ml local finger motion perspective pro approximated scaled orthographic projection 
possible estimate mg ml 
specific local motion define operation estimate global motion arg min global motion operation defined estimate local motion error measurement defined arg min pmg ml propose step iterative algorithm estimate global hand motion mg local motion ml time frame track features time previous hand model 
features detected tracked feature tracking algorithm prediction time 
iterative algorithm applied estimate global motion hand state time represent short 

take motion parameters time initial values 

estimate global motion parameters kth iteration 
keep local motion previous iteration 
estimate local motion parameters hold global motion kth iteration th iteration 

terminate iteration change error falls preset threshold 
estimations obtained time update model process time frame 
proof convergence 
ideas step iterative algorithm operation finds best global motion known local motion operation finds best hand state known global motion 
convergence theorem step iterative algorithm converges monotonically limit point respect certain nonnegative error measurements mean square error 
proof suppose error measurement mean square error xi pmg ml apply operation estimate global motion kth iteration 
error kth iteration arg min min obviously operation applied estimate local motion th iteration arg min keep global motion error th iteration obviously min error measurement negative lower bound occurs 
error sequence nonincreasing bounded step iterative algorithm converge limit point 
furthermore shown algorithm converges stationary point 
divide conquer approach lot advantages methods treating hand motion optimization problem hard handle 
decoupled problem alternatives deal subproblem 
example simple effective ga method estimate local finger motion sequential monte carlo tracking method :10.1.1.38.2855
experiments performed simulation experiments evaluate proposed algorithm applied algorithm real image sequences 
simulation generally difficult get ground truth hand motion real video sequences produced synthetic sequence frames containing typical hand motions 
synthetic sequence facilitate quantitative evaluations algorithm 
sample results synthetic sequences 
synthetic image image model aligned 
examples shown 
shows motion parameters comparison 
solid curves estimates dashed curves ground truth 
plots translation average error pixels rotation average error pip joint index finger average error mcp flexion middle finger average error pip joint ring finger average error mcp abduction ring finger average error real sequences performed motion capturing algorithm real video sequences 
compared different schemes local motion capturing 
random search scheme space 
experiment random samples 
scheme consider finger motion constraints performed poorly local motion estimation destroyed global pose determination 
second scheme condensation samples performed better method robust 
samples task 
third scheme proposed method 
pip mcp pip mcp aa frame number comparison results ground truth synthetic sequence 
dashed curves ground truth solid curves estimates 
method worked accurately robustly 
articulation model computation efficient local motion estimation enhances accuracy hand pose determination 
results shown 
discussion difficult problem capture global hand poses local finger articulations video sequences high degrees freedom articulated hand 
chapter divide conquer approach problem separating hand poses finger articulations 
treat palm rigid planar object cardboard hand model determine hand pose icp algorithm 
local finger articulation tracked sequential monte carlo technique 
iteration estimation global hand pose local finger motion results accurate motion capturing 
current technique assumes clean backgrounds largely simplify image obser vation processes 
shall investigate problem clutter backgrounds 
cardboard model difficult tackle large plane rotations 
includes better hand model plane rotations 
current method needs manual initialization tracking 
interesting achieve automatic initialization combining model approach appearance approach 
random search points 
condensation samples 
approach samples 
comparison different methods real sequences 
method accurate robust methods experiments 
chapter discriminant em algorithm invariant object recognition fundamental challenging computer vision task finding effective object representations generally difficult problem 
object reconstruc tion suggests way invariantly characterize objects 
alternatively objects represented visual appearance explicit reconstruction 
representing objects image space formidable dimensionality image space tractable 
dimension reduction achieved identifying invariant image features 
cases domain knowledge exploited extract image features visual inputs cases need learn features set examples image features difficult define 
successful examples learning approaches area face gesture recognition literature 
generally characterizing objects examples requires huge training data sets input dimensionality large variations object classes undergo significant 
labels supervised information training samples needed recognition tasks 
gen abilities current methods largely depend training data sets 
general generalization requires large representative labeled training data sets 
unfortunately collecting labeled data tedious altogether impossible process 
clustering schemes proposed difficult pure unsupervised approaches achieve accurate classification supervision 
problem alleviated semisupervised self supervised learning techniques take hybrid training data sets 
learning paradigm viewed integration pure supervised unsupervised learning 
algorithms assume fraction data labeled ground truth take advantage entire data set generate classifiers assumption nearby data generated class 
area successfully applied text classification 
expectation maximization em powerful technique self supervised learning cause handle missing values hidden variables probabilistic interference 
generally parametric generative models concise efficient approximation probability densities 
parametric generative models include strong assumptions probabilistic structures distribution models na combination em generative model confronts difficulties practice 
discriminant em em section self supervised learning algorithm purposes small set labeled data large set unlabeled data 
basic idea algorithm learn discriminating features classifier simultaneously inserting multiclass linear step standard expectation maximization iteration loop 
em assumption probabilistic structure data distribution lower dimensional discrimination space simplified captured lower order gaussian mixtures 
discrimination step em linear difficulty handling data sets linearly separable input data highly nonlinearly separable regardless features input 
nonlinear kernel discriminant analysis section kernel em algorithm 
kernel discriminant analysis transforms original data space higher dimensional kernel feature space projects lower dimensional discrimination space nonlinear discriminating features identified training data better classified nonlinear feature space 
novel algorithms sampling training data efficient learning nonlinear kernel discriminants 
experiments include standard benchmark testing view independent hand posture recognition invariant fingertip tracking 
chapter em framework parametric generative model investigate self supervised learning 
section gives brief description generative model 
section briefly reviews em algorithm 
pointing possible problems na usage em generative model linear em kernel em section respectively 
experiments invariant object recognition content image retrieval described section 
discussions self supervised learning section 
learning hybrid data sets setting learning different pure supervised unsupervised learning training data set hybrid labeled unlabeled data 
learning task learner learn function hypothesis space functions set labeled training data set lx ly 
data point label size classification problems discrete set 
regression problems time learner unlabeled data set 
size 
cases assume data points labeled set drawn distribution unlabeled set assumption 
cases labeled data perform pure supervised learning successfully generalization poor 
large set unlabeled data distribution performance learner expected boosted unlabeled set 
cases distribution assumption sense unlabeled data prior unlabeled data zero 
cases assume lx distribution 
order take advantage unlabeled data know joint probability lx 
case learner optimal learner aims learn function hypothesis space risk unlabeled data set minimized 
dp 
dp dp 
dp vapnik gives bounds relative uniform deviation training error test error satisfy confidence interval depends number training examples number working samples vc dimension hypothesis space approaches theoretical basis constructed vapnik statistical learning theory structural risk minimization srm 
interesting algorithms proposed learning hybrid data 
approach svm study transductive learning 
approach em principle induction hybrid data sets 
methods proposed investigate interaction multiple learners 
svm approaches constructed mixture labeled data training set unlabeled data working set 
working set labeled working set empty standard svm training set empty form unsupervised learning 
mentioned authors viewed form semisupervised clustering working set large training set small form transductive problem hand 
learning find classification function minimizes empirical misclassification rate maximizes capacity classification function 
constraints added sample working set 
constraint calculates misclassification error point class constraint calculates misclassification error point class 
objective function contains minimum possible misclassification errors 
new optimization problem formulated integer programming problem min min zj problem authors look transductive problem including small set unlabeled date unlabeled points 
formulation works linear case far 
svm proposed text classification 
problem type problem learning small training set 
specification type learning problem learner best working set database 
sense transductive learning 
inductive learning unnecessarily complex type problem 
type transductive learning training set small 
learn model solely training set inductive learning apply testing set 
generalization training samples 
common problem svm methods involve formidable expensive optimization problem 
em approaches em approach taken deal inductive learning problem 
application background text classification 
situation training set small large unlabeled data set freely available 
objective augment accuracy classifier 
means reduction number labeled samples needed dramatic 
basic em scheme easy apply problem labels unlabeled data treated missing values estimated em algorithm :10.1.1.56.6066
combing set unlabeled data training classifier accuracy improved em 
assumptions 
assumption data generated mixture model 
assumption correspondence mixture components classes 
may discrepancy generative model ground truth data distribution na em risk fail 
em extensions em proposed research alleviate misfit modeling assumption unlabeled data 
em approach sound basis intuition poses dif parametric generative models 
develop robust methods true data distribution disagrees generative model 
able handle learning high dimensional space 
training approaches interesting approach learning hybrid data exploit cross modality structure training data 
unlabeled samples labels obtained making structure pattern distributions different sensory modalities 
situation classification achieved combining different different modalities 
showed minimizing disagreement approximation minimizing number misclassification 
approach som lvq 
similar idea method described training approach web page classification :10.1.1.26.6299:10.1.1.114.9164
gave bipartite graph representation problem 
basic idea train independent classifiers 
initially classifiers trained labeled training examples available 
results fect classifiers 
classifier allowed examine unlabeled data pick confidently predicted positive negative examples add set labeled ex amples 
classifiers retrained augmented set labeled data set process repeated converges 
algorithm assumption features train classifiers redundantly sufficient classification problem 
application examples approach 
blum mitchell apply web page classification 
page classifier hyperlink classifier trained 
riloff jones employ approach learn classify noun phrase positive negative examples locations 
de sa ballard employ approach classify speech phonemes audio signal video signal watching speaker lips 
learning hybrid data investigating interaction different interesting promising approach integration multiple cues 
generative model assume hybrid data set drawn mixture density distribution components cj 
parameterized 

mixture model represented cj cj sample drawn hybrid data set assump tion component mixture density corresponds class yj cj 

generative model represents strong assumption parts proba structure data distribution known 
expectation maximization practice learning approaches face imperfection training testing data 
imperfections missing sensor information specific learning set variables unobservable partially observable 
hidden variables recovered learning 
expectation maximization em powerful way deal situations 
em algorithm density estimation em algorithm widely approach learning presence unobserved variables 
train bayesian belief networks 
basis unsupervised learning algorithms 
essentially learning problems approached density modeling estimation 
density approach tries estimate joint density allows representation related variables inference possible 
density approach applicable supervised unsupervised learning exactly way able naturally handle incomplete data 
assume data 
xn generated independently mixture density equation 
log likelihood parameters data set log xi cj cj best density model data set maximizes log likelihood 
function difficult maximize numerically due log summation 
considering nature mixture density model introduce hidden indicator variable 
zc indicates component generates data point zk data point generated kth component zk 
means maximization problem decouple set simple 
zn 
indicator obtain log likelihood complete data lc zij log xi zi zi unknown lc directly :10.1.1.16.2929
expectation lc lc shown dempster maximized iterating steps step lc step arg max step computes expected complete data log likelihood step finds parameters maximize likelihood 
case step just compute expectation zj data point xj model previous iteration hij zij xi lc zij xi log xi zi zi assume generative model mixture gaussians closed form solution density estimation obtained :10.1.1.16.2929
kth iteration step computes hij exp xi xi exp xi xi step re estimates means covariances gaussians data set weighted hij hij hij xi xi hij em powerful tool estimate density probabilistic structure data distribution 
approach similar soft means algorithm unsupervised clustering 
dealing missing values labels unlabeled data treated missing values expectation maximization em approach applied self supervised learning problem 
self supervised learning training data set union set labeled data set unlabeled data joint probability density hybrid data set written xi cj xi cj yi ci xi yi ci equation holds assume sample independent 
part equation unlabeled data set second part labeled data 
parameters estimated maximizing posteriori probability 
equiv done maximizing lg 
lg xi xi lg lg cj xi cj lg yi ci xi yi ci xi log sum hard deal binary indicator zi introduced zi zi 

zij iff yi cj zij lg xi zij lg oj xi oj em algorithm estimate probability parameters iterative hill climbing procedure alternatively calculates expected values unlabeled data estimates parameters 
em algorithm generally reaches local maximum 
consists iterative steps step set step set arg max denote estimation kth iteration respectively 
problems model assumption probabilistic structure number components mixture models known em estimate true probabilistic model parameters 
generative model capture underlying data distribution performance approach bad 
assume number components known gaussian mixture gaussians distribution 
unfortunately assumption invalid practice 
generally priori knowledge data distribution gaussian distribution assumed represent class 
assumption invalid practice partly reason unlabeled data hurt classifier 
shows simple example 
classes data drawn gaussian distributions samples labeled 
em assumes gaussian classes 
iteration begins weak classifier learned labeled samples 
weak classifier estimate labels unlabeled samples 
data employed learn new classifier labels unlabeled samples iteration 
special case em converges bayesian classifier 
hand guess probabilistic structure correct em may give estimation 
class data drawn component gaussian mixture model assumes gaussian distribution 
em fails give classifier 
bayesian classifier em iterations bayesian em iterations represents unlabeled sample 
denote labeled sample 
samples labeled 
solid lines bayesian classifier dashed lines iteration results em 
data drawn gaussian distributions 
em converges bayesian classifier 
class data drawn component gaussian mixture em assumes gaussian 
component mislabeled 
em fails unlabeled data help 
learning high dimensions em general solid approach deal hidden variables 
model distribution data parametric generative models employed analyzable flexible 
mixture gaussians frequent choice 
parametric generative models offer analytical properties bring problems 
section explained structure generative model factor affecting result em iteration 
practice especially vision problems learning techniques performed high dimensional space 
consequently dimension generative model high step estimate numerous parameters model 
training data set large estimation highly biased numerically unstable 
regularization approaches proposed handle circumstances ask necessary perform learning high dimensional space 
possible reduce dimensions 
linear em algorithm generally know probabilistic structure data distribution em fails structure assumption hold 
approach problem try possible structure select best 
requires computational resources 
alternative find mapping data clustered mapped data space probabilistic structure simplified captured simpler gaussian mixtures 
multiple discriminant analysis mda technique offers way relax assumption probabilistic structure em supplies mda large labeled data set select discriminating features 
linear multiple discriminant analysis multiple discriminant analysis mda natural generalization fisher linear discrimination lda case multiple classes 
mda offers advantages successfully applied tasks face recognition 
basic idea mda find linear transformation map original dimensional data space new space ratio class scatter class scatter maximized new space 
arg max suppose dimensional random vector drawn classes original data space 
ith class probability pi mean vector mi 
class scatter matrix sw defined sw pie mi mi ci ci denotes ith class 
class scatter matrix sb defined sb pi mi mi grand mean defined 
details 
mda offers means catch major differences classes discount factors related classification 
features relevant classification automatically selected combined linear mapping mda features may substantial physical meanings 
advantage mda data clustered extent projected space easier select structure gaussian mixture models 
apparent mda supervised statistical method requires labeled samples estimate statistics mean covariance 
combining mda em framework proposed method discriminant em algorithm em way combine supervised unsupervised paradigms 
basic idea em enlarge labeled data set identifying similar samples unlabeled data set supervised techniques possible enlarged labeled set 
expectation discrimination maximization em begins weak classifier learned labeled set 
certainly expect weak classifier 
unlabeled sample xj classification confidence wj 
probabilistic label lj 
assigned weak classifier 
xj ck ck xj ck ck lg xj ck 
equation unlabeled sample weighted mahalanobis distance class center 
just heuristic weight unlabeled data xj may choices 
mda performed new weighted data set xj lj wj xj data set linearly projected new space dimension unchanging labels weights xj yj xj xj lj wj xj 
parameters probabilistic models estimated probabilistic labels bayesian classifier equation 
algorithm iterates steps expectation discrimination maximization 
describes em algorithm 
noted simplification probabilistic structures guaranteed linear mda 
components data distribution mixed find linear mapping 
case nonlinear mapping simple discriminant em algorithm em inputs labeled set unlabeled set output classifier parameters initialize number components mda map iteration step labeling weight weight step mda weight step map return em algorithm 
probabilistic structure approximate data distribution mapped data space 
generally gaussian second order gaussian mixtures 
experiments show em works better pure em 
kernel em algorithm section try extend linear discriminant analysis nonlinear analysis order achieve better discrimination power 
take kernel approach 
em algorithm generalized kernel em algorithm section 
nonlinear discriminant analysis linear discriminant analysis lda linear projection obtained original data space linearly transformed new space classifier designed new space cases find linear projection discriminate different patterns 
natural extend linear approach nonlinear realm 
nonlinear discriminant analysis finds nonlinear mapping nonlinearly transform original data space feature space space linear discriminant analysis performed vt 
vc vk linear subspace span 
vc feature space 
patterns feature space linearly projected subspace corresponding patterns original data space projected nonlinearly 
quadratic polynomial mapping investigated 
example space quadratic mapping space complete quadratic mapping generally decision boundary feature space linear corresponding decision boundary original space highly nonlinear complex 
problems related approach 
curse dimensionality approach impractical 
quadratic mapping involves terms order polynomial mapping involves terms 
nonlinear mapping transforms original space higher dimensional feature space 
unfortunately dimensions feature space high handle 
second parameter estimation high dimensional feature space impossible require unrealistic computation data 
may want transform original data space infinite dimensional space 
example exponential mapping 
nearly impossible perform analysis feature spaces impossible explicitly represent transformed pattern 
kernel approach dot product form represented kernel kernel presentation able calculate value dot product feature space mapped having find mapped data explicitly 
mercer theorem mercer theorem gives conditions construct mapping eigenfunction decomposition kernel 
continuous kernel integral operator dx positive dx expanded uniformly convergent series 
case 
map acts dot product 
example simple second order polynomial kernel represented general polynomial kernel corresponds dot product space order monomials input coordinates 
forms kernels employed community 
example radial basis functions sigmoid kernels exp tanh employed support vector machines kernel pca invariant feature extraction 
choice kernel implicitly determines mapping feature space kernel mda nonlinear discriminant analysis possible kernel approach 
assume dimensional original data space number classes size training data set nj class nj try find nonlinear mapping transform original data space higher dimensional feature space dimension 
linear discriminant analysis performed feature space find linear subspace feature space linear projection discriminate different patterns pattern feature space pattern subspace feature space 
space 
reformulate class scatter sb class scatter sw feature sb sw mj mj nj xk mj xk mj mj xk nj nj xk 
mj total mean class mean respectively 
feature space solution linear discriminant analysis 
vc vi known solution vi lie span training samples xk 

xn 
find projection data point coordinate linear subspace xk xk xk xn xk xk xn xk xk xn xk intuitively sort representation xk feature space 
mj nj nj nj nj xk xn xk xk nj nj xn xk nj nj xk nj nj xn xk xk nj nj xk nj nj xn xk view counterpart mean class data space feature space 
find kw sbv sw mj mj kb kb nj nj xk mj xk mj kw kw write kernel mda nj kb kw projection data point direction feature space obtained kk xk involves set kernel computations easily achieved 
sampling data efficiency kb kw matrices size training set nonlinear mapping dependent entire training samples 
large solution generalized eigensystem costly 
approximate solutions obtained sampling representative sub sets training data pk 
xk xm xk take place pca kernel vector selection approach propose blind class labeling 
select representatives kernel vectors identifying training samples play key role 

matrix rank size training data set large 
fact suggests training samples ignored calculating kernel features 
compute principal components 
denote matrix concatenated eigenvectors thresholding elements abs fraction largest element allows identify salient pca coefficients 
column corresponding non zero eigenvalue choose training samples correspond salient pca coefficient choose training samples corresponding rows survived thresholding 
doing nonzero eigenvalue arrive decimated training set represents data periphery data cluster 
illustrated 
evolutionary kernel vector selection approach take advantage class labels data 
maintain set kernel vectors iteration meant key pieces data training 
initial kernel vectors kv chosen random 
iteration set kernel vectors kv perform nonlinear projection xi opt original data xi obtained 
assume gaussian distribution class nonlinear discrimination space parameters estimated labeling training error obtained arg maxj lj yi 
class nonlinearly separable example 
original data kernel features data normalized coefficients pca small number large black nonlinear mapping 
randomly select training samples correctly classified training samples kernel vector kv iteration 
possibility current kernel vector correctly classified randomly select sample topological neighborhood replace kernel vector iteration 
terminate 
evolutionary kernel vector selection algorithm summarized 
kernel em algorithm extension expectation maximization em wu huang proposed step algorithm em loops expectation step discrimination step mda maximization step 
em estimates parameters generative model discrimination space 
apply em 
kernel em generalization em simple linear transformation data project data nonlinearly feature space data better separated linearly 
nonlinear mapping implicitly determined kernel function determined advance 
transformation original data space discrimination space linear subspace feature space implicitly explicitly 
evolutionary kernel vector selection set training data xi li 
identify set kernel vectors kv 

kv random pick init opt kv perform proj opt project bayes bayesian classifier labeling classification error calculate error kv kv kv random pick xi li kv kv break return kv evolutionary kernel vector selection 
low dimensional generative model capture transformed data 
cj cj empirical observations suggest transformed data approximates gaussian current implementation low order gaussian mixtures model transformed data 
kernel em initialized selecting labeled data kernel vectors training weak classifier unlabeled samples 
steps kernel em iterated appropriate convergence criterion step set step set opt arg maxa kba kw step set arg max identify kernel vectors kv step gives unlabeled data probabilistic labels step separate data 
mentioned assumes class distributions moderately smooth 
experiments section compared supervised learning techniques standard data sets section 
experimental results em kernel em algorithms hand posture recognition content image retrieval sections respectively 
benchmark tests verify ability data sampling algorithms 
benchmark data sets experiments 
benchmark data different realizations 
results different approaches data sets reported 
proposed algorithms compared single rbf classifier rbf support vector machine svm adaboost kernel fisher discriminant kfd 
rbf kernels kernel algorithms 
table benchmark test kernel mda algorithm average test error standard deviation 
benchmark banana cancer heart thyroid sonar rbf adaboost svm kfd pca evol table pca pca selection evol evolutionary selection number kernel vectors 
benchmark tests show proposed approaches achieve results comparable state art techniques spite decimated training set 
standard benchmark data sets experiments obtained www gmd de 
view independent hand posture recognition view independent hand posture recognition identifies posture view direction 
hand posture images shown 
row classified posture class 
fourteen different postures 
row posture different views 
gesture vocabulary gesture interface 
hand localization system employed automatically collect hand images serve unlabeled data lo system outputs bounding boxes hand regions regardless hand postures 
large unlabeled database easily constructed 
currently unlabeled hand images database 
noted bounding boxes images tight introduces noise training data set 
posture class samples manually labeled 
investigate effect unlabeled data compare different classification algorithms construct testing data set consists labeled images 
image eigen features hand representation experiments 
gabor wavelet filters levels orientations extract texture features standard deviation wavelet coefficients filter 
coefficients fourier descriptor represent hand shapes 
statistics hand area contour length total edge length density second order moments edge distribution 
low level image features total 
resizing images eigen features extracted pca 
feed algorithm different number labeled unlabeled samples 
ex periment unlabeled samples labeled data respectively 
experiment eigen features extracted pca principle components dimension mda set 
shown general combining unlabeled data reduce classification error 
error rate number unlabeled data unlabeled data unlabeled data unlabeled data unlabeled data unlabeled data error rate dimension pca dim mda dim mda dim mda dim mda dim mda effect labeled unlabeled data em 
effect dimension pca mda em 
study effect dimension parameters pca mda 
fewer principle components pca minor important discriminating features may neglected principle components may insufficient discriminate different classes 
hand principle components pca include noise 
number principle components pca important parameter pca 
dimension mda ranges number classes 
interested lower dimensional space different classes classified 
experiment labeled data unlabeled data find dimension parameter pca mda 
classification algorithms compared experiment 
features number principle components pca set set labeled data perform mda dimension 
labeled training data multilayer perceptron experiment hidden layer nodes 
experiment schemes nearest neighbor classifier 
just labeled samples uses labeled samples bootstrap classifier growing scheme newly labeled samples added classifier labels 
labeled unlabeled data em em respectively 
table shows comparison 
table view independent hand posture recognition comparison multiplayer perceptron mlp nearest neighbor growing templates nn em linear em 
algorithm mlp nn em feature feature observed multilayer perceptrons trapped local minima nearest neighbor suffers sparsity labeled templates 
poor performance pure em due fact generative model capture ground truth distribution underlying data distribution highly complex 
surprising outperform methods step optimizes separability classes 
typical images classified misclassified shown 
note effectiveness 
find appears project classes approximately gaussian clusters transformed space facilitates modeling gaussians 
shows typical transformed data sets linear non linear discriminant analysis projected subspace different hand postures 
comparison linear em kernel em 
correctly classified images 
images mislabeled correctly labeled 
images correctly classify 
data distribution projected subspace 
linear 
kernel 
different postures separated clustered nonlinear subspace 
transductive content image retrieval order give analysis compare different methods manually label image database images subset corel database 
dataset classes airplane bird car church painting flower mountain view tiger 
images database labeled classes 
experiments labels unlabeled data calculate classification error 
investigate effect unlabeled data em feed algorithm different number labeled unlabeled samples 
labeled images obtained relevance feedback 
unlabeled samples error rates drop 
find em brings accuracy 
general combining unlabeled data largely reduce classification error labeled data 
error rate number unlabeled data labeled data labeled data labeled data labeled data effect labeled unlabeled data em 
error rate decreases adding unlabeled data 
combining unlabeled data largely reduce classification error 
test compare methods 
weight feature relevance feedback image features precalculated :10.1.1.35.7769
top similar images obtained ranking image comparing mahalanobis distances means query images 
second method simple probabilistic method sp classes relevant irrelevant assumed gaussian distributions model parameters estimated feedback images 
third method basic em em algorithm assumes gaussian distributions classes 
fourth em algorithm 
probabilistic methods label image maximizing posteriori probability lj arg max ck xj compare set image features features eigen features features 
image features :10.1.1.35.7769
eigen features extracted pca number principle components image resolution reduced 
features features tested 
methods compared fully labeled database 
results shown table 
classification error method calculated evaluation errors available training 
suppose database samples classes kth class nk samples nk 
method calculate error different methods 
query images belong jth class mj samples top nj belong jth class error query defined ej nj mj methods samples total correctly labeled error defined ej average error obtained averaging experiments ej table error rate comparison different algorithms 
comparisons time relevance feedback relevant irrelevant images 
em outperforms methods 
algorithm features features sp em em algorithm tested large databases 
corel database contains images wide range categories resolution 
vistex database collection texture images 
discussion self supervised learning previous sections linear em kernel em self supervised learning tech niques 
extensive experiments show effectiveness em approach learning tasks 
section give discussion self supervised learning 
new learning paradigm cognitive processes human beings highly complicated 
difficult represent processes explicitly 
general measurements cognitive ability 
induction learn model set examples 
obviously result inductive learning largely depends training examples 
deduction learn better model specific domain generic knowledge 
interestingly human beings able conduct transduction specific domain model unknown domain 
supervised learning unsupervised learning main learning paradigms current machine learning research 
look supervised learning learning extremes supervised learning tries teach learner examples unsupervised learning leaves studying learner teaching 
pure supervised learning probably able perform transduction incapable unknown world 
hand pure unsupervised learning able perform effective induction lack supervision 
paradigms middle reinforcement learning supervised clustering 
reinforcement learning tries tell learner correct incorrect supervised clustering essentially unsupervised learning technique 
techniques start find answer question teach learner 
answer vapnik support vector machine theory classi fication boundary depends support vectors training data set means support vectors minimum training samples needed 
fact suggests necessary sample labeled supervised learning 
identification support vectors trivial motivates think roles vectors 
probabilistic structure data distribution known parameters probabilistic mod els estimated unsupervised learning impossible assign class labels labeled data 
fact suggests labeled unlabeled training data need learning labeled data label class unlabeled data estimate parameters generative models 
introduce new learning paradigm called self supervised learning ssl unify tion deduction transduction labeled unlabeled training data 
labeled training data sets represent knowledge teach learner unlabeled set inputs unknown world explored learner 
fundamental questions raised section new self supervised learning paradigm section 
fundamental questions unlabeled data contain information joint distribution features 
para metric forms probability densities known parameters estimated un supervised learning impossible assign class label labeled data 
assumption generative model held reach strong 
conclu sion suggests labeled data label class component unlabeled data estimate parameters model 
assumption distribution unlabeled data set 
possibilities 
unlabeled set distribution labeled set may know exactly form distribution density 
second distribution unlabeled set deviation labeled set know relationship distributions joint density conditional density 
answer important questions unlabeled data sets supervised learning 
objectives advantages 
assumptions unlabeled data 
unlabeled data help hurt 
roles labeled unlabeled data 
necessary conditions successful model transduction 
unlabeled data set 
self supervised learning problem formulation self supervised learning ssl employs hybrid training data set consists labeled data set xi yi 
xi feature vector yi label size set unlabeled data set xi 
size set 
generally assumption distribution 
risk function df loss function 
learning find function minimizing risk knowing joint 
function depends labeled unlabeled training data sets 
essentially classification represented yi arg max yj xi xi subset data space number classes 
consequently decision inputs classifier drawn 
different self supervised learning different special cases 
induction self supervised learning inductive learning 
yi arg max yj xi xi different conventional learning paradigms inductive learning depends supervised data set unsupervised data set degenerates pure unsupervised learning 
degenerates pure supervised learning 
necessary training sample labeled interesting question inductive learning supervised information needed 
generally large unlabeled training set employing relatively small labeled set 
deduction subset problem degenerates ssl deduction 
yi arg max yj xi xi rough generic model domain deduction learn specific model works specific subdomain rough model 
deduction treated special case transduction 
example generic model classifies men women deduction learns specific model differentiate asian men asian women 
transduction self supervised learning transductive learning 
yi arg max yj xi xi generally classifier obtained inductive learning highly nonlinear huge labeled training set required achieve generalization 
requirement generalization relaxed subset data space 
generalization transductive learning defined unlabeled training set data space 
human cognition usually learn model specific domain subset 
model may domains 
model adapted solve problems similar domains 
cognition process captured ssl transduction specific model specific model 
example specific model classify asian men asian women transduction learns specific model recognize european men european women 
illustrated example nonstationary color model adaptation chapter 
chapter vision gesture interface systems chapter interesting prototype vision gesture interface systems 
called rock scissors people play simple interactive video game computers 
called visual panel people control remote display fingers arbitrary 
rock scissors interactive video game design interesting interactive video game rock scissors section 
live video inputs system localize user hand recognize hand postures 
framework design described section 
subsystems hand localization motion capturing posture recognition hand animation section respectively 
system framework gesture interface consists subsystems hand localization system articulate motion capturing system gesture recognition system animation system 
framework shown 
localization system localization system color segmentation 
motion segmentation region growing method employed system robust accurate framework vision gesture interface 
introducing computation cost 
shows overview localization system 
hand localization system framework 
frame taken camera initially train som proposed self organizing clustering algorithm described section 
initialization stage color distribution scene initially mapped 
experiments training fast second color image 
inputs som hsi value pixels outputs indexes winning nodes som competition 
typically takes fewer nodes segment indoor working environments 
newly captured color image time frame som algo rithm described section 
som segment input image find different color regions 
stage done lower resolution image segmentation faster 
morphology operators get rid noise 
pixel labeled som updated supervised updating scheme described section 
labeled training data set randomly selected segmented image ignoring bright dark 
may different colors working space system specify color track determine track problem 
possible solution specify color region human hand face 
solution rules automatically find interested color motion intention 
detect motion region examining frame difference optic field color region taken interested color 
cases objects nearly color 
instance tracking faces hands needed recognizing sign languages 
color segmentation algorithm separates background ways locate region 
method scheme self organizing clustering find centroid isolated blob 
way region growing technique label blob heuristics find bounding boxes 
typical hand tracking scenario controlling display simulating mouse desktop environments 
camera mounted top desktop computer looks keyboard area give image sequence moving hand 
typical application track human face 
localization system able simultaneously localize multiple objects useful tracking moving human 
localization system essentially global segmentation algorithm largely rely tracking results previous frames 
tracker may reason gets lost frames recover interfering subjects 
sense tracking algorithm robust 
proposed system handle changing lighting conditions extent transduction som color classifier 
time hue saturation weight intensity system insensitive changes lighting intensity objects shadowed intensity light source changes 
problems 
insufficient lighting strong lighting dark bright backgrounds may pose problems color segmentation algorithm hue saturation unstable system give weight intensity 
lighting conditions change dramatically color segmentation algorithm may fail transduction guaranteed 
motion capturing system model approach taken capture articulated hand motion employing hand model 
kinematical hand model employed 
articulated hand motion decoupled global hand motion local finger motion global motion parameterized rotation translation palm local motion parameterized state hand 
global hand poses captured robust pose determination algorithm icp local finger articulations estimated sequential monte carlo tracking algorithm respectively iterative fashion 
posture recognition system hand posture recognition system recognizes static hand postures hand im ages located hand localization system 
frame localization system gives bounding box hand hand posture recognition cropped hand image 
look fourteen different hand postures shown section 
eigen features hand representation due simplicity feature extraction 
feature extractors pca mda 
training algorithms take linear kernel em algorithms 
generative model gaussian mixture model 
training line parameters generative model mda projection matrix estimated 
recognition line bayesian decisions 
experiments section 
illustrates hand posture recognition subsystem 
animation system hand posture recognition subsystem 
hand animation system hand model animated keyframe methods 
starting transitions hand states keyframes 
animation sequences obtained cubic spline interpolation scheme 
model driven set joint angles represents state hand hand states interpolated prespecified key frame states 
model driven position fingertips inverse kinematics problem solved 
simple implement drawback approach apparent 
order obtain realistic effect large number control points specified fitting curves 
reduce amount motion specification knowledge hand motion built animation system execute certain aspect movement autonomously 
high level control schemes physical rules achieve goal disadvantage lack interactivity 
system performance demos system implemented sgi machines 
som hand localization system runs hz hand posture recognition subsystem runs hz 
articulated motion capturing expensive far real time 
animation looks natural realistic 
simple demo show capacity gesture interface 
virtual game rock scissors uses hand signs rock scissors shown 
children game rock scissors 
traditional children game hand signs rock beats scissors scissors beats beats rock 
demo person play computer second computer tracks recognizes sign human keeps score 
computer player randomly generates hand signs transition shown window animation system 
visual panel vision mobile input system goal virtual panel system arbitrary quadrangle shaped plane object tip pointer fingertip pen serve natural convenient input device accurately controlling remote displays computer vision techniques 
fingertips natural body part developed intuitive immersive way accurate interaction remote large displays 
system consists virtual panel tracking tip pointer tracking homography tion updating action detection recognition 
system shown 
part user input analyzed video sequences panel tracker tip pointer tracker 
panel tracker accurately track arbitrary quadrangle shaped plane object outputting positions corners 
edge dynamical programming technique employed panel tracker quite robust reliable corners panel occluded 
time positions corners calculated intersecting lines quadrangle positions calculated calculation homography accurate 
system virtual panel consists panel tracker pointer tracker action detector message generator 
mapping constructed panel remote display calculating homography transformation point panel mapped corre sponding position remote display 
obviously remote mouse remote keyboard control remote display 
devices expensive emit electromagnetic radiation 
virtual panel system users fingertip mouse simulate cursor remote display 
consequently tracking tip pointer quite accurate stable small error tip position magnified remote large screen 
instance assume resolution input video remote display 
generally panel image roughly half size image obvious tracking error pixel incur pixels error large display mapped cursor position 
problem solved system representing tip pointer conic fitting parametric conic image observations 
tip position calculated error reduced 
current system simulates clicking pressing gestures holding tip pointer position 
means system capable having inputting methods virtual mouse virtual keyboard 
obviously position tip pointer mapped remote display cursor simulated 
keyboard pattern printed virtual keyboard users point keys input texts 
message generator system gets inputs action detector issues various mouse keyboard events different user input methods 
shows basic idea visual tracking virtual panel system 
frame video input shows tracking results panel fingertip 
tracking visual panel system 
input image 
tracking outputs tracked panel tracked fingertip 
virtual panel system scaleable extendable system portable easy cost efficient 
camera setting setting camera quite flexible 
long panel totally occluded 
camera fixed panel move far field view camera 
mount camera ceiling 
user rotate translate tilt panel reach comfortable pose 
obviously users normal panel vertical optical axis camera 
circumstances user wants walk mount camera top head wearing hat shoulders user interact computer 
quite useful speaker wishes walk giving powerpoint presentation 
panel design time panel long quadrangle shaped 
example white printing widely available offices homes 
tip pointers system allows arbitrary tip pointers fingertips pens 
usability studies users prefer pens fingertips applications finger painting pens intuitive fingertips fun 
clicking current virtual panel system simulates clicking pressing holding tip pointer means easy reliable vision techniques 
alternatively system natural gestures act clicking 
homography arbitrarily rectangle shaped panel control cursor position remote display know mapping point panel point display 
furthermore available image sequence panel may undergo arbitrary motion long image panel degenerate line point need know mapping point image plane point panel 
assume camera performs perspective projection 
display panel image plane planes relationships described plane perspectivity explained 
point plane denote homogeneous coordinates 
plane perspectivity planes described matrix arbitrary nonzero scalar 
implies homography matrix defined scale factor degrees freedom 
couples corresponding points collinear homography matrix determined 
difficult see composition plane plane perspectivity 
mapping images remote display described homography matrix 
important really need detected tip position image control cursor position remote display 
composed homography easily determined corners panel located image 
know dimension display compute homography mapping corner panel corner display 
tracking quadrangle panel represented quadrangle li margin line 
represented corners 
set image edge features associated line 
gradient pixel edge represented ek eki eki 
spite location appearance edge represented set statistics edge length average gradient 
represent appearance edge random vector gradient intensity 
assume distribution gaussian time frame location quadrangle appearance quadrangle 
assume time corner points range di pi respectively 
tracking formulated map problem arg max problem approximated arg max obviously formidable searching problem 
illustrate assume size search area di complexity exhausted search problem 
margins quadrangle sequentially connected problem solved dynamic programming technique 
arg max illustrated xi xi qi di qi arg max xi xi qi tracking quadrangle dynamic programming technique 
implementation search region corner point approximated line segment region 
equivalent searching side lines 
corner points computed intersections lines 
criterion 
mentioned earlier appearance side line quadrangle mod contains gradient information color information 
maximizing probability equation implies finding pair line segments appearances closest 
done minimizing relative entropy distributions 
assume gaussian distribution relative entropy lg px px du lg py py lg lg symmetric distance metric means find best matched edge time tracking fingertip arg min qi qi qi qi section presents method determining exact tip tip pointer conic fitting tip pointer tracking method reinitialization tracking background subtraction technique 
fingertip representation tip pointer fingertip represented conic say xy know set positions xn yn edge pixels fit conic data lse 
explicitly xn yn concisely equation written ma lse solution conic fitting shown 
tracking tip pointer tracking tip pointer quite intuitive cost efficient 
assume position tip time 
kalman filtering technique employed predict tip fingertip detection conic fitting 
position time 
small window say identify edge pixels possible probably belong edge tip thresholding gradient advantage color previous tracked tip edge 
fit conic edge pixels solve exact tip time 
maintaining background re initialization system robust easy scheme automatic tracking initial ization tracking recovery embedded system 
developed means reinitialization task dynamic background subtraction technique 
assume registered panel application position panel time known 
time system track panel position homography easily calculated 
homography pixels pt panel time mapped panel time pb pb pt pb background time obviously foreground pf time calculated subtracting pb current image shows basic idea approach 
pf pb pt foreground hand segmented background current position panel tracked background template maintained 
action detection recognition section presents techniques action detection recognition 
virtual panel system clicking modes clicking mode dragging mode mouse types ab type relative type 
mouse clicking modes enable system clicking dragging modes virtual mouse mode clicking mode mode ii dragging mode shown 
current implementation clicking pressing simulated holding tip pointer say second 
simulating clicking mode dragging mode ii 
state variable maintains states dn simulate natural state button 
variable 
clicking mode mode system detects tip pointer fixed place second amount time prespecified state variable set keeps 
second state variable automatically set simulate button release 
state change dn detected clicking action detected 
obviously clicking mode mode limited ability drag release automatic 
simulate dragging dragging mode mode ii uses state variable memorize flip clicking 
previous state current click dn current click 
state change dn detected pressing action detected state change dn detected releasing action detected 
means facilitate system ability dragging 
mouse motion types virtual panel system simulate mouse types absolute type relative type 
absolute type panel mapped remote display point panel mapped corresponding point display 
discussed type needs accurate tracking small tracking error panel tip pointer magnified 
absolute type intuitive 
type relative type sensitive tracking results cursor controlled relative motion tip pointer 
assume motion direction tip pointer dp time moving direction cursor dd dp 
amount movement cursor determined velocity tip pointer vp 
alternatives relative mouse movements 
instance panel simply mapped window area centered previous cursor position remote display 
method center panel corresponds previous cursor position 
tip pointer moves center left cursor move left 
obviously window area smaller panel image tracking error minimized 
relative type brings smooth movement cursor due tracking error 
compared absolute type relative type intuitive 
demos virtual panel system applications demonstrate capacity system 
applications shows remote display freely accurately controlled 
finger draw picture demo 
input text keyboards third demo 
calculator controlling application demonstrates accuracy stability virtual panel system 
calculator buttons takes small part area display 
demo user freely fingertip click buttons menus calculator shown 
tracking error pixel motion cursor smooth 
finger painting controlling calculator 
application demonstrates different clicking modes 
paint windows application user finger select tools draw see 
usability study shows users quite adaptive system 
minutes training users freely fingers draw picture control remote display 
virtual keyboard finger painting 
application demonstrates physical keyboard replaced printed virtual keyboard virtual panel system 
print keyboard pattern panel shown 
user points keys panel key message sent operating system current active application receive key 
example notepad receive text user 
virtual keyboard 
current implementation users fingers 
typing speed slow 
claiming get rid physical keyboard 
system promising alternative physical keyboard available circumstances 
extensions developed prototype vision gesture interface system virtual panel capable performing accurate control remote display simulating mouse keyboard input 
virtual panel system employs arbitrary quadrangle shaped planar object panel viewed display keyboard 
users fingers tip pointers simulate cursor pointer issue clicking pressing instructions 
system robustly accurately track panel tip pointer 
action detected various events generated sent operating system 
vision gesture interface achieve natural intuitive interaction humans computers 
applications described controlling calculator painting fingers inputting text virtual keyboard 
virtual panel system leaves lot room extensions improvements various aspects especially action recognition 
current implementation action triggered tip point stays immobile short duration 
investigating natural ways example combining hand gesture recognition 
potential applications potential application systems developed capacity gesture interface 
navigating ves hand robustly efficiently tracked cursor pointer replaced natural hand 
applications map navigation battlefield navigation easily developed 
color hand local ization algorithm easily extended locate hands simultaneously localization cameras full dof pose parameters obtained hands position hands determines line turn determines plane 
technique developed lab ui chicago 
switching commanding modes applications different commanding modes needed 
example modes navigating selecting differentiated 
previously switching achieved speech recognition 
gesture interface alternative way switching recognizing different hand postures 
combining visual recognition speech recognition largely enhance robustness command switching 
controlling displays speaker powerpoint presentation large confer ence room inconvenient control slides clicking mouse 
better users hands 
fact gesture interface integrated powerpoint presentations 
manipulating virtual objects articulated motion algorithm efficiently imple mented run nearly real time hand high dof input tool 
research supplies initial study direction 
chapter research role functionality computers changing boom computer hardware technology 
computer longer just machine scientific computation longer just machine saving labor trivial daily routines 
indispensable part information age information acquisition storage analysis organization distribution 
requires different levels intelligence 
cutting edge speech technology achieved big step making computers dumb deaf 
extent computers able listen speak need computers see think specifically natural immersive interaction human beings computers need able visually perceive understand human activities 
exam ple relying devices mouse computers understand meanings conveyed human body movements gestures 
far goal 
main challenges lie richness visual inputs large variations hu man movements 
achieve immersive intelligent human computer interaction need investigate problems visual motion capturing visual learning 
summary dissertation addressed aspects difficult problems human hand hand gestures case study hand important part human communication 
important problems regarding visual motion capturing dissertation nonstationary color tracking chapter integration multiple cues robust tracking chapter capturing hand articulation chapter 
techniques developed chapters easily extended visual motion capturing tasks 
noticeable learning problems vision interaction share common difficulty lack supervised information 
learning problems range invariant object recognition color model adaptation feature selection sensor fusion 
chapter proposed study new learning paradigm self supervised learning employs supervised unsupervised training data sets 
visual learning problems unified learning paradigm 
source labeled data set unlabeled data set different pdf feature modalities unimodal multimodal self supervised learning typical learning problems transduction transduction model transduction inferencing shown table 
table typical problems self supervised learning 
source pdf different pdf unimodal transduction model transduction multimodal transduction inferencing typical learning problems illustrated respectively 
means learning model jth modality time lt ut represent labeled unlabeled data time transduction problem fundamental learning task self supervised learning 
assumes labeled unlabeled training data drawn distribution 
task learn classifier significance investigating transduction save tedious labeling huge training data set 
partially labeled training set expect transduction algorithm propagate labeling unlabeled data 
integrating discriminant analysis em algorithm em algorithm chapter combines supervised unsupervised learning 
example view independent hand posture recognition requires recognition specific hand postures different view directions 
collecting images covering nearly possible viewpoints may need label fraction images lt ut lt ut mt mt lt ut lt ut illustration typical problems self supervised learning transduction model transduction transduction inferencing 
typical view directions 
example content image retrieval cbir 
problems studied chapter 
model transduction problem assume come distribution assume known relationship distributions introduces dynamics self supervised learning 
learning task old model new 
tasks vision interaction represented model transduction 
easy see automatic adaptation face head models example 
interesting problem color model adaptation nonstationary environments 
chapter investigated color model transduction non stationary color tracking 
transduction problem takes multimodal training data assumes distribution 
significance problem fuse multiple modalities reduce computational complexity 
simple example comes cbir problem 
difficult represent concept large number features fed learner 
considering different modalities color texture structure layout images retrieval problem easier 
dissertation study transduction ideas easily extended learning problem 
inferencing problem complicated problems 
takes mul training data assumes different distributions 
combination model transduction transduction 
learning task old model new model partially labeled multimodal training data 
chapter investigated problem example integrating multiple cues robust visual tracking 
important different modalities inferencing phenomenon model modalities learned modalities iteratively 
mathematically inferencing described set fixed point equations 
chapter gives implementation inferencing robust tracking sequential monte carlo techniques 
dissertation interesting prototypes vision gesture interface 
allows users play simple interactive video game computer allows users control remote display just fingers piece 
research directions research combining labeled unlabeled training data infancy 
research effort area theoretical foundation realistic applications 
interesting important issues self supervised learning investigated 
chapter proposed novel learning algorithm named em algorithm 
notice lack analysis algorithm 
study convergence property 
preliminary experiments em may converge classes may dominate classification iterations 
labeled data affects convergence 
necessary condition convergence obtained study 
study convergence rate 
study stability em 
role unlabeled data self supervised learning unclear 
give intuitive explanation 
unlabeled set helps hurts mystery 
self supervised learning captures human cognition processes extent human cognition model unknown psychology ai 
expect model self supervised transduction strong tool active learning incremental learning 
investigation self supervised learning dissertation mainly concentrates classification problems 
useful extend approach regression problems 
fact regression problems vision applications 
head pose estimation example need regress head orientations head observation head model 
expensive time consuming collect large annotated training data set problem 
consider fewer annotated samples combined large set un annotated samples rough head model 
proposed vision gesture interfaces focus temporal gesture mod eling recognition 
reasons concentrate hand fingers hand global motion 
generally temporal gestures sense hand finger motion meaningful gestures represented large number hand postures 
temporal gestures useful interesting applications 
important issue recognition temporal gestures motion modeling 
motion models learned training samples 
different modeling approaches hidden markov model hmm dynamic time warping dtw finite state machine fsm ex tended kalman filtering ekf dynamic bayesian networks dbn dynamic self organizing map investigated 
basically self supervised learning tech niques applied problem motion modeling problem essentially regression problem 
techniques developed dissertation general extended research topics 
author hopes study motive investi gation self supervised learning serve important step realizing dream making computers see think appendix derivation fixed point equations appendix presents details variational analysis factorized graphical model derivation fixed point equation described chapter 
purpose illustrate called inference phenomenon presents interaction different modalities 
visual tracking scenario state variables continuous difficult analyze graphical model 
investigation case takes discrete states described 
simplify analysis assume state multinomial random variable takes discrete states 

represent random variable vector 
element vector means state variable discrete states 
setting approximate continuous case tracking scenario 
system dynamics approximated transition matrix 
exp constant normalize probabilities zt log zt log observation matrix covariance matrix assume linear observation model ease derivation 
linear observation assumption may true visual tracking take approximation ease analysis 
hand write inference probability graphical model structured variational approximation similarly hq log kl divergence written xm kj kj zq kl hq log zq log log exp hq log tc zt tr tr diag log zq log log tc minimize kl divergence distributions take derivative respect log kl log xm log log hm zt setting derivatives zeros log zt set fixed point equations exp zt xm xm zt set fixed point equations written exp zt zt see clearly represent set fixed point equation zt function 
obviously equation equation section 
appendix solving rotation matrix depth appendix describes details solving rotation matrix depth matrix solve motion factorization method contains assume orthographic projection 
show estimate rotation depth translation scaled orthographic projection 
clear property obtain equation equation obtain substitute equation get may solutions usually positive 
solutions possibly resolved checking resulting matrix rotation matrix reflection determinant equal 
aggarwal cai human motion analysis review proc 
ieee nonrigid articulated motion workshop pp 

kjeldsen finding skin color images proceedings second international conference automatic face gesture recognition pp 

pavlovi sharma huang visual interpretation hand gestures human computer interaction review ieee trans 
pami vol 
pp 
july 
wu huang human hand modeling analysis animation context hci proc 
ieee int conf 
image processing vol 
oct pp 

wu huang vision gesture recognition review gesture communication human computer interaction richardson teil eds lecture notes artificial intelligence berlin springer verlag pp 

wu huang hand modeling analysis recognition vision human computer interaction ieee signal processing magazine vol 
pp 
may 
gavrila visual analysis human movement survey computer vision image understanding vol 
pp 
jan 
liu levinson wu huang interactive incremental learning mixture supervised unsupervised learning strategies proc 
joint conf 
information systems feb pp 

rui huang ortega mehrotra relevance feedback power tool interactive content image retrieval ieee trans :10.1.1.35.7769
circuits systems video technology vol 
pp 

santini jain similarity measures ieee trans 
pattern analysis machine intelligence vol 
pp 

swets weng hierarchical discriminant analysis image retrieval ieee trans 
pattern analysis machine intelligence vol 
pp 

sign language structure 
buffalo ny university buffalo press 
kendon current issues study gesture biological foundation gestures motor semiotic aspects perron eds hillsdale nj lawrence erlbaum associate pp 

quek unencumbered gesture interaction ieee multimedia vol 
pp 

bobick ivanov action recognition probabilistic parsing proc 
ieee conf 
computer vision pattern recognition pp 

davis shah visual gesture recognition vision image signal processing vol 
pp 
april 
huang vision hand modeling tracking virtual teleconferencing proc 
ieee int conf 
computer vision june pp 

shimada shirai kuno miura hand gesture estimation model refinement monocular camera ambiguity limitation inequality constraints proc 
rd conf 
face gesture recognition pp 

heap hogg hand tracking deformable model proc 
ieee int conf 
automatic face gesture recognition pp 

vogler metaxas asl recognition coupling hmms motion analysis proc 
ieee int conf 
computer vision jan pp 

goldgof sarkar human skin hand motion analysis range image sequences nonlinear fem proc 
ieee nonrigid articulated motion workshop pp 

rehg kanade model tracking self occluding articulated objects proc 
ieee int conf 
computer vision pp 

wu huang capturing articulated human hand motion divide andconquer approach proc :10.1.1.38.2855
ieee int conf 
computer vision sept pp 

lee kunii model analysis hand posture ieee computer graphics applications vol 
pp 
sept 
lin wu huang modeling human hand constraints proc 
workshop human motion dec pp 

davis bobick representation recognition action temporal templates proc 
ieee conf 
computer vision pattern recognition pp 

starner weaver pentland wearable computer american sign language recognizer proc 
ieee int symposium wearable computing oct pp 

wilson bobick recognition interpretation parametric gesture proc 
ieee int conf 
computer vision pp 

pavlovi dynamic bayesian networks information fusion applications human computer interfaces ph dissertation university illinois urbana champaign urbana il 
jones rehg statistical color models application skin detection compaq cambridge research lab cambridge ma tech 
rep crl 
wu liu huang adaptive self organizing color segmentation algorithm application robust real time human hand localization proc 
asian conference computer vision jan pp 

raja mckenna gong colour model selection adaptation dynamic scenes proc 
european conf 
computer vision pp 

wren azarbayejani pentland pfinder real time tracking human body ieee trans 
pattern analysis machine intelligence vol 
pp 
july 
sharma reliable tracking human arm dynamics multiple cue integration constraint fusion proc 
ieee conf 
computer vision pattern recognition pp 

blake isard active contours 
london springer verlag 
isard blake condensation conditional density propagation visual tracking int journal computer vision vol 
pp 

wu lin huang capturing natural hand articulation proc 
ieee int conference computer vision vol 
ii july pp 

cui swets weng learning hand sign recognition proc 
int workshop automatic face gesture recognition pp 

wren pentland dynamic modeling human motion proc 
ieee int conf 
automatic face gesture recognition pp 

campbell becker azarbayejani bobick pentland invariant features gesture recognition proc 
ieee int conf 
automatic face gesture recognition pp 

becker real time recognition feedback training system ai chi gestures thesis media lab mit cambridge ma 
wu huang view independent recognition hand postures proc 
ieee conf 
computer vision pattern recognition vol 
ii june pp 

wu huang self supervised learning visual tracking recognition human hand proc 
aaai national conf 
artificial intelligence july pp 

vision hand modeling gesture recognition human computer interaction thesis university illinois urbana champaign urbana il 
ritter illumination independent recognition deictic arm posture proc 
th annual conf 
ieee industrial electronics society pp 

cui weng hand segmentation learning prediction verification hand sign recognition proc 
ieee conf 
computer vision pattern recognition pp 

quek zhao inductive learning hand pose recognition proc 
ieee int conf 
automatic face gesture recognition pp 

rosales sclaroff inferring body pose tracking body parts proc 
ieee conf 
computer vision pattern recognition vol 
pp 

triesch von de malsburg robust classification hand postures complex background proc 
int conf 
automatic face gesture recognition pp 

basri roth jacobs clustering appearances objects proc 
ieee conf 
computer vision pattern recognition pp 

black jepson recognition temporal trajectories condensation algorithm proc 
ieee int conf 
automatic face gesture recognition pp 

pentland liu modeling prediction human behavior proc 
ieee intelligent vehicles sept pp 

blake classification human body motion proc 
ieee int conf 
computer vision pp 

cohen conway koditschek dynamical system representation generation recognition basic oscillation motion gestures proc 
ieee int conf 
automatic face gesture recognition pp 

jo kuno shirai manipulative hand gestures recognition task knowledge human computer interaction proc 
ieee int conf 
automatic face gesture recognition pp 

berry small wall multimodal human computer intelligent interaction test bed applications thesis university illinois urbana champaign urbana il 
cutler turk view interpretation real time optical flow gesture recognition proc 
ieee int conf 
automatic face gesture recognition pp 

pinhanez bobick human action detection pnf propagation temporal constraints proc 
ieee int conf 
computer vision pp 

bregler learning recognition human dynamics video sequences proc 
ieee conf 
computer vision pattern recognition pp 

stoll ohya application hmm modeling recognizing human gestures image sequences man machine interface proc 
ieee int workshop robot human communication pp 

nam recognition space time hand gestures hidden markov model proc 
acm symposium virtual reality software technology pp 

yang xu chen gesture interface modeling learning proc 
ieee int conf 
robotics automation vol 
pp 

kobayashi partly hidden markov model application gesture recognition proc 
ieee icassp vol 
vi pp 

darrell pentland active gesture recognition partially observable markov decision processes proc 
ieee int conf 
pattern recognition vol 
pp 

brand oliver pentland coupled hidden markov models complex action recognition proc 
ieee conf 
computer vision pattern recognition pp 

cui weng hand sign recognition intensity image sequences complex background proc 
ieee int conf 
automatic face gesture recognition pp 

polana nelson low level recognition human motion proc 
ieee workshop motion non rigid articulated object pp 

watanabe yachida real time gesture recognition eigenspace multi input image sequences proc 
ieee int conf 
automatic face gesture recognition pp 

yang ahuja extraction classification visual motion patterns hand gesture recognition proc 
ieee conf 
computer vision pattern recognition pp 

vogler metaxas scalability asl recognition breaking signs phonemes gesture communication human computer interaction richardson teil eds lecture notes artificial intelligence berlin springer verlag 
liang real time continuous gesture recognition system sign language proc 
ieee int conf 
automatic face gesture recognition pp 

wu huang color tracking transductive learning proc 
ieee conf 
computer vision pattern recognition vol 
june pp 

quek mcneill mccullough ansari gesture speech gaze cues discourse segmentation proc 
ieee conf 
computer vision pattern recognition vol 
ii pp 

isard blake unifying low level high level tracking stochastic framework proc 
european conf 
computer vision vol 
pp 

wu huang robust visual tracking inference learning proc 
ieee int conference computer vision vol 
ii july pp 

lu igi color hands tracking system sign language recognition proc 
int conf 
face gesture recognition pp 

toyama wu bootstrap initialization nonparametric texture models tracking proc 
european conf 
computer vision 
duda hart pattern classification scene analysis 
new york wiley 
wu image compression structural adaptation self organizing vq algorithm thesis tsinghua university beijing china 
wu li yan nonparametric density estimation wavelet transformation scale space zero crossing reconstruction proc ieee int conf 
signal vol 
october pp 

kohonen self organized formation topologically correct feature maps biological cybernetics vol 
pp 

cottrell fort stochastic model self organizing process biological cybernetics vol 
pp 

statistical analysis self organization neural networks vol 
pp 

ritter schulten stationary state kohonen self organizing sensory mapping biological cybernetics vol 
pp 

zheng effect concave convex weight adjustment self organizing maps ieee trans 
neural networks vol 
pp 

choi park self creating organizing neural networks ieee trans 
neural networks vol 
pp 

fritzke growing cell structures self network unsupervised supervised learning neural networks vol 
pp 

fritzke growing neural gas network learns topologies advances neural information processing systems tesauro touretzky leen eds pp 


lee structure level adaptation artificial neural networks 
boston ma kluwer academic publishers 
wu liu huang robust real time human hand localization selforganizing color segmentation proc 
iccv workshop recognition analysis tracking face gestures real time systems sept pp 

isard blake contour tracking stochastic propagation conditional density proc 
european conf 
computer vision pp 

comaniciu ramesh meer real time tracking non rigid objects mean shift proc 
ieee conf 
computer vision pattern recognition vol 
ii pp 

toyama krumm brumitt meyers wallflower principles practice background maintenance proc 
ieee int conf 
computer vision pp 

birchfield head tracking intensity gradient color histograms proc 
ieee conf 
computer vision pattern recognition pp 

rasmussen hager joint probabilistic techniques tracking multi part objects proc 
ieee conf 
computer vision pattern recognition pp 

hager belhumeur real time tracking image regions changes illumination proc 
ieee conf 
computer vision pattern recognition pp 

li simultaneous tracking verification sequential posterior estimation proc 
ieee conf 
computer vision pattern recognition vol 
ii pp 

tao sawhney kumar dynamic layer representation applications tracking proc 
ieee conf 
computer vision pattern recognition vol 
pp 

black jepson eigentracking robust matching tracking articulated object view representation proc 
european conf 
computer vision vol 
pp 

toyama hager incremental focus attention robust visual tracking proc 
ieee conf 
computer vision pattern recognition pp 

rabiner tutorial hidden markov models selected applications speech recognition proceedings ieee vol 
pp 

ghahramani factorial learning em algorithm advanced neural information processing systems tesauro touretzky leen eds pp 

ghahramani jordan factorial hidden markov models machine learning vol 
pp 

jordan ghahramani jaakkola saul variational methods graphical models machine learning vol 
pp 

saul jordan exploiting tractable substructures intractable networks advances neural information processing systems touretzky mozer hasselmo eds pp 

dempster laird rubin maximum likelihood incomplete data em algorithm royal statistical society series vol 
pp 

doucet godsill andrieu sequential monte carlo sampling methods bayesian filtering statistics computing vol 
pp 

liu chen sequential monte carlo methods dynamic systems amer 
statist 
assoc vol 
pp 

liu chen theoretical framework sequential importance sampling resampling sequential monte carlo practice doucet de freitas gordon eds new york springer verlag 

cham rehg multiple hypothesis approach tracking proc 
ieee conf 
computer vision pattern recognition vol 
pp 

maccormick isard partitioned sampling articulated objects hand tracking proc 
european conf 
computer vision vol 
pp 

tao sawhney kumar sampling algorithm detecting tracking multiple objects proc 
iccv workshop vision algorithm 
deutscher blake reid articulated body motion capture annealed particle filtering proc 
ieee conf 
computer vision pattern recognition vol 
ii pp 

maccormick blake probabilistic exclusion principle tracking multiple objects proc 
ieee int conf 
computer vision pp 

swain ballard color indexing int journal computer vision vol 
pp 

blum mitchell combining labeled unlabeled data training proc :10.1.1.114.9164
conf 
computational learning theory pp 

rosales sclaroff athitsos hand pose reconstruction specialized mappings proc 
ieee int conf 
computer vision july 
kumar shadow gesture hand pose estimation single camera proc 
ieee conf 
computer vision pattern recognition pp 

tomasi kanade shape motion image streams orthography factorized method int journal computer vision vol 
pp 

zhang iterative point matching registration free form curves surfaces int journal computer vision vol 
pp 

belhumeur hespanha kriegman eigenfaces vs fisherfaces recognition class specific linear projection proc 
european conference computer vision april 
weber welling perona automatic discovery object categories proc 
ieee conf 
computer vision pattern recognition vol 
pp 

bennett demiriz semi supervised support vector machines advances neural information processing systems kearns solla cohn eds pp 

joachims transductive inference text classification support vector machines proc 
int conf 
machine learning pp 

nigam mccallum thrun mitchell text classification labeled unlabeled documents em machine learning vol 
pp 

wu toyama huang self supervised learning object recognition kernel discriminant em algorithm proc 
ieee int conference computer vision vol 
july pp 

vapnik nature statistical learning theory 
new york springer verlag 
bennett combining support vector mathematical programming methods classification advances kernel methods support vector learning cambridge ma mit press 
ghahramani jordan supervised learning incomplete data em approach advances neural information processing systems cowan tesauro alspector eds pp 

tresp ahmad efficient methods dealing missing data supervised learning advances neural information processing systems tesauro touretzky leen eds pp 

de sa learning classification unlabeled data advances neural processing systems cowan tesauro alspector eds pp 

de sa ballard category learning multi modality sensing neural computation vol 

mitchell role unlabeled data supervised learning proc 
sixth int colloquium cognitive science 
riloff jones learning dictionaries information extraction multi level bootstrapping proc 
aaai national conf 
artificial intelligence pp 

courant hilbert methods mathematical physics vol 

new york interscience publishers 
sch lkopf smola robert ller nonlinear component analysis kernel eigenvalue problem neural computation vol 
pp 

mika tsch weston sch lkopf smola 
ller fisher discriminant analysis kernels ieee workshop neural networks signal 
mika tsch weston sch lkopf smola 
ller invariant feature extraction classification kernel spaces advances neural information processing systems solla leen muller eds pp 

roth steinhage nonlinear discriminant analysis kernel functions advances neural information processing systems solla leen muller eds pp 

roth steinhage schr der cremers pattern recognition combing de noising linear discriminant analysis real world application computer analysis image patterns lecture notes computer science springer verlag 
wu liu huang tracking analyzing recognizing gesture commands proc 
th annual federated laboratory symposium march 
wu huang unlabeled data supervised learning discriminant em algorithm neural information processing systems workshop unlabeled data supervised learning nov 
wu tian huang integrating unlabeled images image retrieval relevance feedback proc 
ieee int conf 
pattern recognition vol 
sept pp 

tian wu huang incorporate discriminant analysis em algorithm image retrieval proc 
ieee int conf 
multimedia expo vol 
pp 

wu tian huang discriminant em algorithm application image retrieval proc 
ieee conf 
computer vision pattern recognition vol 
june pp 

wu toyama huang wide range person illumination insensitive head orientation estimation proc ieee int conf 
face gesture recognition march pp 

vita ying wu received degree university science technology china degree tsinghua university beijing china electrical engineering 
graduate research assistant department electrical computer engineering university illinois urbana champaign pursuing ph degree 
summer research intern vision technology group microsoft research redmond wa 
august faculty assistant professor department electrical computer engineering northwestern university evanston il 
current research interests include computer vision computer graphics machine learn ing human computer intelligent interaction image video processing multimedia virtual environments 
published technical papers areas 
received fellowship tsinghua university schneider fellowship tsinghua university robert chien award university illinois urbana champaign 

