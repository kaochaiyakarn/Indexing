fabri moore hobbs mediating expression emotion educational collaborative virtual environments experimental study international journal virtual reality springer verlag london received september accepted october published online february dx doi org mediating expression emotion educational collaborative virtual environments experimental study 
marc fabri david moore isle research group leeds metropolitan university fabri ac uk moore ac uk tel fax dave hobbs school informatics university bradford hobbs bradford ac uk tel fax avatars emotionally expressive faces potentially highly beneficial communication collaborative virtual environments cves especially distance learning context 
little known emotions effectively transmitted medium cve 
avatar head model limited human expressive abilities built designed enrich cve communication 
facial action coding system facs head designed express readily recognisable manner universal emotions 
experiment conducted investigate efficacy model 
results indicate approach applying facs model virtual face representations guaranteed expressions particular emotion category 
appropriate model emotions effectively visualised limited number facial features 
set exemplar facial expressions 
keywords avatar collaborative virtual environment emotion facial expression document outlines experimental study investigate facial expressions humanoid user representations means non verbal communication cves 
intention establish detailed knowledge facial expressions effectively efficiently visualised cves 
start arguing insufficiency existing distance communication media terms emotional context means emotional expression propose problem overcome enabling people meet virtually cve engage quasi face face communication avatars 
argue avatars emotionally expressive faces potentially highly beneficial communication cves 
research field cves proceeding time representation user embodiments avatars systems relatively simple rudimentary 
particular virtual environments poor terms emotional cues convey 
accordingly need sophisticated ways reflect emotions virtual embodiments pointed repeatedly investigations 
light controlled experiment conducted investigate applicability non verbal means expression particularly facial expressions avatars cve systems 
purpose experiments establish emotions effectively transmitted medium cve 

case cve education today information society provides numerous technological options facilitate human interaction distance real time asynchronously telephony electronic mail text chat video conferencing systems 
tools useful crucial people come physically need discuss collaborate dispute certain matters 
distance learning programmes extensive technologies enable communication spatially separated tutors learners learners fellow learners 
extensive research shown interaction crucial learning process purpose mutual reflection actions problem solutions motivation stimulation assessment control progress 
rise growing body literature computer supported collaborative learning cf 
communicating distance media tools emotional context lost ability express emotional states way accustomed face face conversations 
text tools important indicators accentuation emotion change emotion intonation difficult mediate 
audio conferencing tools alleviate difficulties lack ways mediate non verbal means communication facial expressions posture gesture 
channels play important role human interaction argued socio emotional content convey vital building relationships need go purely factual task oriented communication 
video conferencing alleviate shortcomings concerning body language visual expression participant emotional state 
daly jones identify advantages video conferencing high quality audio conferencing particular vague awareness interlocutor attentional focus 
non immersive character typical video interfaces conversational threads meetings easily break people distracted external influences change active window example handle electronically shared data 
cves potential alternative communication tools aiming overcome lack emotional social context whilst time offering stimulating integrated framework conversation collaboration 
argued cves represent communication technology right due highly visual interactive character interface allows communication representation information new innovative ways 
users actively engaged interaction virtual world inhabitants 
distance learning discipline particular high level interactivity users senses engaged action feel participating seen essential factor effective efficient learning 

need emotionally expressive avatars term non verbal communication commonly describe human communication events transcend spoken written word 
plays substantial role human interpersonal behaviour 
social psychologists argue information exchanged person person conversation carried non verbal band 
argyle sees non verbal behaviour place person influences means facial expressions gestures body posture bodily contact gaze pupil dilation spatial behaviour clothes appearance non verbal 
particularly important aspect non verbal communication convey information concerning emotional state interlocutors 
interacts person person emotional expressions monitored interpreted person doing 
ability judge emotional state considered important goal human perception argued evolutionary point view probably significant function interpersonal perception 
different emotional states lead different courses action crucial survival able recognise emotional states particular anger fear person 
similarly argyle argues expression emotion face body part wider system natural human communication evolved facilitate social life 
showed example embarrassment signal helps reconcile relations gone way making social faux pas 
findings psychology neurology suggest emotions important factor decision making problem solving cognition intelligence general see 
particular importance point view education argued ability show emotions empathy understanding facial expressions body language central ensuring quality tutor learner learner learner interaction 
acceptance understanding ideas feelings encouraging silence questioning involve non verbal elements interaction 
argued cscl technologies ought provide degree non verbal particular emotional communication 
instance pedagogical agent steve virtual training environment control panel operation 
steve ability give instant praise express criticism hand head gestures depending student performance 
concerning cve technology particular mcgrath prinz call appropriate ways express presence awareness order aid communication inhabitants full verbal communication nonverbal presence silence 
thalmann sees direct relation quality user representation ability interact environment 
avatars primitive expressive abilities potentially cause strong emotional responses people cve system 
appears avatar readily take personal role increasing sense community feeling 
potentially genuine representation underlying individual visually social context 
argued people naturally developed skill read emotional expressions potentially highly beneficial communication cves general educational cves particular 
emotionally expressive nature interlocutor avatar may able aid communication process provide information difficult mediate 

modelling emotionally expressive avatar emotional expressiveness desirable attribute cve issue emotional expressions mediated 
whilst different channels non verbal communication face gaze gesture posture principle mediated cves certain degree current focuses face 
real world face immediate indicator emotional state person 
physiology looks beneath skin stays surface studying facial features 
art judging character emotional state individual features face 
face reflects interpersonal attitudes provides feedback comments regarded primary source information human speech 
production encoding recognition decoding distinct facial expressions constitute signalling system humans 
see facial expressions emotion clearly dominating vocal expressions emotion knapp generally considers facial expressions primary site communication emotional states 
researchers suggest ability classify facial expressions interlocutor necessary pre requisite inference emotion 
appears certain key stimuli human face support cognition 
example case infant appearance key stimuli trigger favourable emotional responses 
points humans responses expression believed meaning expression 
concentrates face 
model emotionally expressive avatar face followed 
universal facial expressions corresponding emotions surprise anger fear happiness disgust sadness 
categorisation widely accepted considerable research shown basic emotions accurately communicated facial expressions 
held expression extent recognition emotions innate basis 
cultures correspond distinctive patterns arousal 
shows sample photographs depicting universal emotions neutral expression permission 
universal emotions neutral expression describing facial expression great effort gone development scoring systems facial movements 
systems attempt objectively describe quantify visually discriminable units facial action seen adults 
purpose analysis face typically broken areas 
brows forehead 
eyes eyelids root nose 
lower face mouth nose cheeks chin areas appear capable independent movement 
order describe visible muscle activity face comprehensively facial action coding system facs developed 
facs highly detailed anatomical studies human faces results major body 
formed basis numerous series experiments social psychology computer vision computer animation cf 

facial expression high level description facial motions decomposed certain muscular activities relaxation contraction called action units aus 
facs identifies action units separately various combinations capable characterising human expression 
au corresponds action produced group related muscles 
action unit example inner brow raiser contraction central muscle 
action unit lid tightening eyelids narrowing eye opening 
facs usually coded video photographs trained human facs coder decomposes observed expression specific aus occurred duration onset offset time 
system specific details learnt facial movement different emotional expressions humans real world 
instance brow capable fewest positions lower face 
certain emotions manifest particular areas face 
best predictors anger example lower face brows forehead area sadness revealed area eyes 
current modelling facs adapted generate expression emotions virtual face applying limited number relevant action units animated head 
shows photographs alternative expressions anger emotion category corresponding virtual head expressions modelled avatar 
equivalent representations exist remaining universal emotions neutral expression 
photographs taken pictures facial affect 
photographs showing variations anger corresponding virtual heads keeping simple interest modelling human face strong computer graphics community 
muscle model animated face geometric deformation operators control large number muscle units developed platt badler 
developed modelling anatomical nature facial muscles elastic nature human skin resulting dynamic muscle model 
approach adopted study feature complex realistic simulation real life physiology 
argued necessary may counter productive assume avatar realistic accurate representation real world 
argue partly ground early evidence suggested approaches aiming reproduce human physics detail may fact wasteful 
described valley originally created predict human psychological reaction humanoid robots see adapted 
plotting human reaction robot movement curve initially shows steady upward trend 
trend continues robot reaches reasonably human quality 
dramatically evoking negative emotional response 
nearly human robot considered irritating repulsive 
curve rises robot eventually reaches complete resemblance humans 
valley postulated human reaction avatars similarly characterised valley 
avatar designed suspend disbelief nearly realistic may equally confusing accepted considered repulsive 
event suggest full realism full perceptual capabilities physical human bodies virtual space opportunities employing evocative ways expression probably lost focus merely simulating real world rules habits limitations 
may appropriate supportive perception cognition represent issues simple unusual ways 
minimalist drawings body parts showing gestures generally easier recognise complex representations 
donath warns face highly expressive humans adept reading level detail facial rendering potentially provoke interpretation various social messages 
messages unintentional face arguably hindering helping communication 
evidence particularly distinctive faces convey emotions efficiently normal faces detail regularly employed 
human perception system recognise clues particular facial expressions visual stimuli 
summarise simulating real world accurately aim take advantage humans innate cognitive abilities perceive recognise interpret distinctive clues 
regard avatar expressiveness valley targeting summit curve see human emotional response maximised employing relatively simple avatar model 
modelling facial expression order realise approach avatar developed animated virtual head limited number controllable features 
loosely anim specification developed international panel develops virtual reality modeling language vrml 
anim specifies control parameters 
left eyeball 
right eyeball 
left eyebrow 
right eyebrow 
left upper eyelid 
right upper eyelid 
moving jaw early investigation evident eyeball movement necessary virtual head direct eye contact observer 
aiming simple model single parameter moving animating mouth area insufficient variety expressions required lower face area 
consequently anim basis developed additional features derived closely mapped facs action units 
allowed greater freedom especially mouth area 
noted facs describes muscle movement animated head designed necessarily emulate muscle movement faithfully achieve visual effect similar result muscle activity human face 
turned necessary entire set action units reproduced order achieve level detail envisaged current face model 
fact reducing number relevant action units uncommon practice simple facial animation models see study subset action units see table 
table reduced set action units au facial action code muscular basis inner brow raiser pars outer brow raiser pars brow upper lid raiser lid pars upper lip raiser lip corner major lip corner chin raiser lips part relaxation jaw drop mouth relaxation temporal internal relevant animation control parameters required model facial features correspond action units illustrated 
controllable features virtual head example shows variations sadness emotion experiment 
note wider eye opening change angle position eyebrows 
variations emotion category sadness certain facial features deliberately omitted keep number control parameters action units low 
example au lip corner normally involves change cheek appearance 
virtual head shows au mouth corners 
virtual head showing au jaw drop involve movement characterised solely relaxation muscle resulting characteristic opening mouth 
omissions considered tolerable appear change visual appearance expression significantly 
accordingly statistical analysis feedback participants indicated disadvantage doing 
summary argue virtual face model introduced potentially effective efficient means conveying emotion cves 
reducing facial animation minimal set features believed display distinctive area segments universal expressions emotion take account findings cognitive social psychology 
findings suggest internal probably innate schemata support face perception emotion recognition face 
recognition process works limited set simple distinctive visual clues 

experimental investigation argue strong prima facie case proposed virtual head limited human expressive abilities potentially effective efficient means convey emotions virtual environments reduced set action units resulting facial animation control parameters sufficient express readily recognisable manner universal emotions 
experimentally investigated prima facie argument comparing recognition rates virtual head expressions recognition rates photographs faces facs action unit coding recognition rates human participants available 
photographs taken 
detailed description experimental setup section 
aims experiment investigate simple distinctive visual clues mediate emotional social state cve user establish distinctive essential features avatar facial expression 
aims experiment designed address working hypothesis defined subset includes expression emotion category recognition rates virtual head model corresponding photographs comparable 
design independent variable iv study stimulus material participants 
facial expressions emotion different ways facs training photographs displayed animated virtual head 
factors sub levels universal expressions emotion neutral 
dependent variable dv success rate achieved assigning expressions emotion respective categories 
control variables cvs identified cultural background participants previous experience similar psychological experiments 
cultural background participants potentially may affect ability recognise certain emotions face factor ensuring participants broadly ability concerning recognition emotion 
manner checked participants previous experience facs coding related psychological experiments may influence perception abilities due specifically developed skills 
adopted factor subjects design known repeated measures design experiment 
factor comprises levels photograph virtual face participant performs conditions condition emotions depicted virtual head condition emotions shown persons facs photographs participants took part experiment female male age range years old 
participants volunteers 
classified facial expressions facs 
participants worked facial animation familiar modelling techniques general 
procedure experiment involved phases pre test questionnaire recognition exercise post test questionnaire 
participant welcomed researcher seated workstation experiment conducted 
researcher gave participant overview expected expect experiment 
care taken give information bias user 
participants assured evaluation leave experiment point felt uncomfortable 
participants pre test questionnaire lead recognition exercise 
moment experiment ran automatically software application experimenter intervention required 
actual experiment preceded pilot test single participant 
participant part participant group experiment 
pilot run confirmed software designed stimulus material collect data functioning correctly minutes duration time participant realistic 
gave indications questionnaire items possess desired qualities measurement discriminability 
pre test questionnaire collected information participant relation applicability experiment 
pre test questionnaire cancel button allowed abortion experiment stage case data collected far deleted 
back buttons displayed depending current context 
screen collecting data participant background facs possible involvement similar experiments followed pre test questionnaire 
recognition task started practice screen illustrating actual recognition screen giving information choice emotion categories functionality buttons screen element shown participant 
recognition task participant shown photographs corresponding virtual head images mixed randomly generated order participants 
emotion categories represented variations variations neutral face shown 
variations defined intensity differences expression emotion 
controllable parameters virtual head adjusted corresponded photographs 
material digitised form virtual head screenshots scanned photographs respectively 
emotion categories represented variations 
addition variations neutral face 
participant asked classify expressions conditions emotion categories variations category 
virtual head images depicted male model photographs showed people expressing varying number emotions images showing male persons female 
order expressions terms categories variations randomised participants 
facial atlas provide distinctive variations particular emotion category virtual head show variation limited set animation parameters similar face repeated 
face images task cropped display full face including hair 
photographs scaled pixels virtual head images slightly smaller pixels 
data collected facial expression emotion consisted type stimulus material expression depicted facial areas emotion category expected emotion category picked participant recognition screen displayed images provided buttons participants select emotion category 
addition aforementioned categories choices offered 
choice allowed entry term participant described shown emotion best part categories offered 
emotions offered appeared apply emotion named participant able choose don know 
recognition screen completion recognition task software post test questionnaire participant 
collected various quantitative qualitative data view complementing data collected recognition task 
button enabled completion rows 
post test questionnaire 
results number pictures shown participants pictures participant 
average participant took minutes complete experiment including pre test post test questionnaire 
results show recognition rates vary emotion categories conditions 
summarises summary recognition rates surprise fear happiness neutral show slightly higher recognition rates photographs categories anger sadness virtual faces easily recognised counterparts 
disgust stands shows low scoring virtual faces contrast result photographs disgust 
results clearly suggest recognition rates photographs significantly higher virtual heads 
mann whitney test confirms significance level 
closer look recognition rates particular emotions reveals emotion category photograph virtual head pair comparable results demonstrating recognition successful virtual head directly corresponding photographs 
shows recognition rates top virtual heads category 
disgust stands category poor results virtual head 
summary recognition rates selected images results indicate recognition rates vary significantly participants 
lowest scoring individual recognised emotions correctly highest score 
achieved better results homogeneously virtual heads photographs 
lower scoring participants fail recognising virtual heads photographs 
expressions emotion identified distinctive shown 
expression coded facs corresponding action units 
action units binary applied action units associated intensity scoring 
intensity vary weakest strongest 
study results recommend particular expressions exemplars models similarly limited number animation control parameters distinctive expressions surprise aus brief emotion shown eyes 
exemplary surprise face features high raised eyebrows raised upper lids 
lower eyelids remain relaxed position 
open mouth relaxed tense 
typical human surprise expression virtual head drop jaw bone 
evidence adverse effect considering participants classified expression correctly 
fear aus usually distinctive appearance areas face 
variation proved successful study characterised raised slightly eyebrows 
eyes wide open surprise lips tense 
contrast open relaxed surprise mouth 
asymmetry left upper lip slightly raised 
disgust aus typically shown mouth nose area 
variation best results characterised mainly raised upper lip au tightened eyelids 
stressed disgust successful category participants assigning expression correctly 
anger face aus features lowered brows drawn 
accordingly eyelids tightened eyes appear staring penetrating fashion 
lips pressed firmly corners straight result chin raiser au 
happiness aus turned easy recognise cases cheek raiser au sufficient 
exemplary face eyes relaxed mouth corners pulled 
virtual head allow change cheek appearance allow wrinkles appear underneath eyes 
smiles cheek eye involvement referred non enjoyment smiles duch smiles th century french duch de cf 

sadness expression aus successful characteristic brow eye features 
brows raised middle outer corners lowered 
affects eyes triangulated inner corner upper lids raised 
slightly raised lower eyelid necessarily typical case increases sadness expression 
corners lips 
recognition errors errors participants assigning expressions categories table 
matrix shows categories confused compares virtual heads photographs 
rows give cent occurrence response 
confusion values shaded light grey dark grey black table error matrix emotion categorisation category response virtual photograph surprise fear disgust anger happiness sadness neutral don know surprise fear disgust anger happiness sadness neutral disgust anger table shows majority confusion errors category disgust emotion frequently confused anger 
examining results virtual heads anger picked twice disgust 
faces showing disgust participants felt unable select category picked don know suggested alternative emotion 
alternatives example aggressiveness irritation self 
ekman friesen describe disgust emotion carries element object 
people feeling people behaviour tend feel morally superior 
observations confirm tendency selected expected disgust suggested alternative line ekman friesen interpretation 
fear surprise error matrix table reveals fear mistaken surprise tendency observed studies see 
stated distinction emotions observed high certainty literate cultures pre literate visually isolated cultures 
social psychology states experience expression fear surprise happen simultaneously fear felt suddenly due unexpected threat 
appearance fear surprise similar fear generally producing tense facial expression 
fear differs surprise ways 
whilst surprise necessarily pleasant unpleasant mild fear unpleasant 

afraid familiar certainly going happen example visit familiar expected hardly surprising 

whilst surprise usually disappears soon clear surprising event fear longer nature event fully known 
indicators allow differentiating person afraid surprised 
context timing fear inspiring event factors perceivable image 
accordance poggi emotional information contained facial expression performatives communicative act suggesting warning ordering approving 
similarly observed significantly higher recognition rates images facial expressions shown dice game context compared display context 
words meaning interpretation emotional expression depend situation shown 
strongly suggests situations facial expression animated displayed context recognition rates expected higher 
fear anger relationship fear anger similar fear surprise 
occur simultaneously appearance blends 
striking confusions virtual faces whilst fear photographs categorised anger 
may suggest fear category contained relatively unsuitable examples modelled facial expressions 
examination results shows artefact particular regularly mistaken anger 
shows expression appearance eyes characteristic fear 
lower eyelid visibly drawn appears tensed 
eyebrows slightly raised drawn 
lower area face shows clear characteristics fear slightly opened mouth stretched lips drawn 
contrast angry mouth lips pressed firmly open shape shout 
fear expression variation times expression categorised anger 
anger fear eyebrows drawn 
fearful face shows raised eyebrows angry face features lowered brow 
generally subtle changes upper eyelids brows significant effect expression line findings real life photographs 
eyebrows slightly raised relaxed position give desired impression 
confusing indicator shape eyebrows straight line brows typical fear 
fear expression variation contrast expression identical expression apart eyebrows raised changing facial expression significantly making ambiguous distinctively fearful 
post experiment questionnaire results completing recognition task participants asked complete questionnaire invited comment aspect experiment 
responses discussed section 
questionnaire comprised eleven questions answered scale total disagreement total agreement 
table shows average values question 
table post experiments questionnaire results 
statement score disagree agree 
interface easy 

emotion categories better 

emotions easy recognise 

real people showed natural emotions 

responded emotionally pictures 

difficult find right category 

emotions varied lot 

real life photographs looked posed 

choice emotions sufficient 

virtual faces showed easily recognisable emotions 

virtual head looked 

discussion experiment followed standard practice expression recognition experiments preparing universal emotions pictures avatar faces photographs real human faces showing participants asked say emotion think photograph picture portrays 
photographs selected pictures facial affect solely high recognition rates 
believed appropriate method aiming avoid factors potentially disturb results gender age ethnicity 
photographs considered standardised facial expressions emotions exact au coding available 
ensures concurrent validity performance test virtual head related test facs coding recognition 
potential order effects induced study repeat measures design presenting artefacts conditions mixed random order 
confidence results derives fact participants interface easy table statement implying results distorted extraneous user interface factors 
similarly participants tended feel photographs looked posed table statement tended see showing real emotion table statement 
despite matter table statements participants happy number categories emotion offered experiment 
unexpected facial expressions showing merely offered range emotions supports validity results 
slight agreement indicates categories potentially produced satisfaction participants making choice 
participants noted comments explicitly preferred wider choice categories 
having established validity experimental procedure results important drawn approach applying reduced facs model virtual face representations guaranteed expressions variations particular emotion category 
implied finding recognition rates photographs significantly higher virtual heads section 
evidence supplied post experiment questionnaire data 
participants example noted occasions virtual face expression distinctive virtual head showed lines wrinkles recognition easier visual cues 
data suggests applying facs model virtual face representations emotions effectively visualised limited number facial features action units 
example respect top scoring virtual heads emotion recognition rates exception disgust emotion comparable corresponding real life photographs 
top scoring expressions exemplar models detailed au scoring available 
potentially build basis emotionally expressive avatars collaborative virtual environments advantages emotionally enriched cves argued earlier 
categorisation system complete 
accepted categories exist emotions vary intensity inevitably subjective element recognition 
modelling animating facial features results suggest ambiguity interpretation minimised focussing emphasising visual clues particularly distinctive 
remains corroborated studies believed simple pure emotional expressions fulfil useful role displaying explicit intended communicative acts help interaction cve 
provide basis emotionally enriched cves benefits technology example distance learning argued earlier 
noted pure forms emotion generally seen real life expressions occurring face face communication humans unintended automatic reactions 
caused complex interaction simultaneous emotions illustrated picard example runner winning race experiences range emotions tremendously happy winning race surprised believed win sad race bit fearful race acute abdominal pain 
regards instinctive reactions captured control avatar directly potentially allowing varying intensities blends facial expressions recognised modelled avatar faces 
study deliberately opted avatar express clearly unambiguously controlling individual exactly wants express way people may want cve technology 
issue concerns consistency 
social psychology suggests findings emotion depends consistently shown face 
emotions exception sadness clearer distinctive intensity increases 
indications cases emotion appeared ambiguous photographs contained subtle clues emotion displayed enabling viewer assign closer inspection 
clues appear missing virtual head artefacts suggesting need emphasise distinctive unambiguous features enhance model adding visual cues help identify variations emotion clearly 
emotions realtime virtual environment interactions authors aim concentrate 
noted artefacts classified participants choice close emotion category expected confirming facial expressions cases necessarily badly depicted 
highlights importance having defined vocabulary investigating emotions problem new research community discussed length years see early comparison emotion dimensions vs categories experimental discussed provides strong evidence creating avatar representations facs model limited number facial features allows emotions effectively conveyed giving rise recognition rates comparable corresponding real life photographs 
effectiveness demonstrated recognition rates emotion categories efficiency established reduced feature set sufficient build successfully recognised core set avatar facial expressions 
consequence top scoring expressions illustrated earlier may taken provide sound basis building emotionally expressive avatars represent users may fact agents cves 
modelling animating facial features potential ambiguity interpretation minimised focussing emphasising particularly distinctive visual clues particular emotion 
proposed set expressions fulfil 
necessarily distinctive clues particular emotion distinctive emotion category 

planned extend variety ways 
data reveals certain emotions confused notably disgust anger 
particularly case virtual head expressions 
wang observed similar link emotions showing photographs faces children 
younger children aged particular tended group certain emotions older children aged typically ability differentiate correctly 
view findings current study may indicate adults differentiate emotions day day social interaction limited clues provided virtual head observers revert back experience manner categorising 
necessary investigate possibility 
studies disgust confused anger concluded lack morph targets visual clues nose cause 
humans disgust typically shown mouth nose model features slightly raised lip au movement nose 
strongly suggests improve distinctiveness disgust expression real time animated model nose included animation relevant action unit au responsible nose 
developed animated model virtual head capable lifting nose express disgust 
experimental results particular relatively high number don know responses indicate limiting number categories emotion negative effect recognition success rates 
allowing categories offering range suitable descriptions emotion category joy delight complement happiness yield higher recognition rates experiments address 
similarly concentrating face primary channel conveying emotions seen wider context entire humanoid representation user principle act communication device cves 
experiments discussed set foundation emotional postures expression attitude virtual embodiment drawing example posture gestures spatial behaviour gestures 
contextual aspect emotional recognition concerns conversational milieu emotions expressed recognised 
context plays crucial role emotion expression recognition effective accurate mediation emotion closely linked situation related communicative signals 
reliable interpretation facial expressions fails take context displayed possible 
expect recognition avatar representations emotion higher contextualised 
assumption requires empirical investigation experiments planned address 
distinguishes facial expression emotion seeing important experimental enable study distinction plays virtual world 
predicted timing affect virtual world 
example showing surprise period say minute send confusing contradictory signals 
possible investigate generally impact mediation emotions conversational interchanges 
contextual issue concerns culture 
emotions exist universally cultural differences concerning emotions displayed 
appears people various cultures differ taught managing controlling facial expression emotion 
ekman friesen call cultural norms display rules 
display rules prescribe emotion supposed fully expressed masked lowered 
instance observed male japanese reluctant show unpleasant emotions physical presence 
interestingly cultural differences affect recognition emotions 
particular japanese people reportedly difficulty recognising negative expressions emotions effect may reflect lack perceptual experience expression cultural displaying 
cultural differences play virtual world important open question 
authors wish explore results concerning mediation emotions avatars beneficially help people autism 
commonly universally held view nature autism involves triad impairments 
social impairment person autism finds hard relate people 
secondly communication impairment person autism finds hard understand verbal non verbal communication 
tendency rigidity inflexibility thinking language behaviour 
current thinking triad underpinned theory mind deficit people autism may difficulty understanding mental states ascribing 
cve technology sort discussed potentially provide means people autism communicate autistic non autistic circumvent social communication impairment sense isolation 
role technology purposes practice rehearsal 
help combat theory mind problem users need able recognise emotions displayed avatars 
findings reported current give grounds confidence technology useful role needs investigated practice cf 

remains investigated concerning educational emerging cve technology 
hoped reported help set foundation mediation emotions virtual worlds 
photographs cd rom pictures facial affect permission 
original virtual head geometry 
detailed results study virtual head prototypes available online www ac uk ies comp staff emotion 
thalmann role virtual humans virtual environment technology interfaces 
frontiers human centred computing online communities virtual environments 
earnshaw eds 
london springer verlag 

fleming animating facial features expressions 
charles river media boston 
dumas interface cooperative 
collaborative virtual environments proceedings 
manchester 

non verbal communication forms multi player game sessions 
people computers xvi memorable invisible 
faulkner eds 
london bcs press 
isbn 

atkins moore hobbs sharpe learning style theory computer mediated communication 
ed media proceedings 

rethinking university teaching 
routledge london 
moore types interaction 
distance education new perspectives 
harry john eds 
london routledge 

johnson johnson cooperative learning culturally diverse classroom 
cultural diversity schools 
cummins eds 
albany state university new york press 

webb constructive activity learning collaborative small groups 
educational psychology 
wu farrell scaffolding group learning collaborative networked environment 
cscl proceedings 
boulder colorado 

douglas intelligent affective interfaces user modeling approach telemedicine 
proceedings international conference universal access hci 
new orleans la elsevier science publishers 

daly jones monk watts advantages video conferencing high quality audio conferencing fluency awareness attentional focus 
int 
journal human computer studies 
jennings characterising user control video conferencing distance education 
cal proceedings 
exeter university 

fabri gerhard virtual student user embodiment virtual learning environments 
international perspectives tele education virtual learning environments 
orange hobbs eds 

knapp nonverbal communication human interaction 
holt rinehart winston new york 
morris collett marsh gestures origin distribution 
jonathan cape london 
argyle bodily communication second edition 
methuen new york 
psychology emotion fourth edition 
wiley sons new york 
dittrich lea morgan perception emotion dynamic point light displays dance 
perception 
signs evidence distinct displays embarrassment amusement shame 
personality social psychology 
picard affective computing 
mit press 
facial expression recognition human computer interaction artificial intelligence cognitive science intersect 
pragmatics cognition 
dam sio error emotion reason human brain 
avon new york 
cooper brna martins effective affective intelligent systems building evidence empathy teaching learning 
affective interactions new generation computer interfaces 
paiva ed 
london springer verlag 

johnson pedagogical agents 
computers education proceedings 
beijing china 

mcgrath prinz solid software 
collaborative virtual environments digital places spaces interaction 
churchill munro eds 
london springer 

durlach slater meeting people virtually experiments shared virtual environments 
social life avatars 
schroeder ed london springer verlag 

ekman friesen face 
prentice hall new jersey 
new oxford dictionary english 
oxford university press 
russell psychology facial expression cambridge university press 
facial emotional reactions duch non duch smiles 
international journal psychophysiology 
reading faces window soul 
press boulder colorado 
ekman friesen emotion human face guidelines research integration findings 
pergamon press new york 
ekman facial expressions 
handbook cognition emotion 
power eds 
new york wiley sons 

ekman friesen pictures facial affect cd rom 
university california san francisco 

ekman friesen facial action coding system 
consulting psychologists press 
bartlett face image analysis unsupervised learning redundancy reduction ph thesis 
university california san diego 

badler steedman generating facial expressions speech 
cognitive science 
ekman eds 
face reveals basic applied studies spontaneous expression facial action coding system 
oxford university press 

terzopoulos waters analysis synthesis facial image sequences physical anatomical models 
pattern analysis machine intelligence 
platt badler animating facial expression 
acm siggraph 
parke parameterized modeling facial animation 
ieee computer graphics applications 
benford bowers user embodiment collaborative virtual environments 
chi proceedings 
denver colorado acm press 
mori buddha robot 
tuttle publishing 
robots fact fiction prediction 
london hudson 
fraser heath benford virtually missing point configuring cves object focused interaction 
collaborative virtual environments digital places spaces interaction 
churchill munro eds 
london springer verlag 

strothotte rendering gestures line drawings 
gesture workshop 
bielefeld germany 
springer verlag 
donath mediated faces 
cognitive technology instruments mind 
nehaniv dautenhahn eds 
warwick uk 

affective expressions machines 
chi proceedings 
seattle usa 

ellis developmental trends face recognition 
psychologist bulletin british psychological society 
dittrich facial motion recognition emotions 
ge 
anim working group 
specification standard vrml humanoid 
www anim org 
yacoob davis computing spatio temporal representations human faces 
computer vision pattern recognition proceedings 
ieee computer society 
essa pentland coding analysis interpretation recognition facial expressions 
ieee transactions pattern analysis machine intelligence 

neisser cognition reality 
freeman san francisco 
poggi emotional meaning expression animated faces 
affective interactions new generation computer interfaces 
paiva ed 
london springer verlag 

non verbal communication 
blackwell dictionary cognitive psychology 
ed 
blackwell publishers oxford 

kaiser emotion facial expression 
affective interactions new generation computer interfaces 
paiva ed 
london springer verlag 

wang recognition emotion chinese australian children 
cross cultural psychology 
spencer smith ker wild townsend making faces action unit morph targets 
aisb symposium animating expressive characters social interactions 
isbn 
london 

coulson expressing emotion body movement component process approach 
artificial intelligence simulated behaviour proceedings 
imperial college london 

thalmann thalmann realistic avatars autonomous virtual humans networked virtual environments 
virtual worlds internet 
earnshaw eds 
ieee computer science press 

wing autism spectrum disorders 
constable 
moore mcgrath thorpe computer aided learning people autism framework research development 
innovations education training international 
moore taylor interactive multimedia systems people autism 
educational media 
