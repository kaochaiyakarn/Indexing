distributed architecture dynamic analyses user profile data antoniol massimiliano di antoniol ieee org research centre software technology university department engineering ex italy combining static dynamic information highly relevant reverse engineering program comprehension maintenance task 
dynamic analysis particularly effective information collected long period time real user environment 
poses challenges 
foremost necessary model extraction relevant dynamic information execution traces avoiding collect large amount unmanageable data 
second need distributed architecture allows collect compress information geographically distributed users 
propose probabilistic model representing dynamic information web service distributed architecture collection compression 
new architecture instantiated collect interprocedural program execution traces selectable level calling context sensitivity 
details role responsibilities architecture components performance compression ratios achieved set java programs 
keywords user profiling dynamic analysis trace collection 
dynamic information essential software engineering activities software testing architectural recovery software refactoring user profiling approaches solely static information exist hybrid approaches integrating static dynamic information provide accurate faster solution 
example combining static dynamic analysis aimed improving precision design pattern recovery 
eisenbarth applied concept analysis information obtained static dynamic analysis understand features source code 
syst tool extracting scenarios traces obtained debugging java bytecode 
similarly authors dynamic information recover collaboration diagrams roles 
automatic technique extracting operation sequences shown described approach trace analysis discover thread interactions 
cases dynamic information obtained exercising instrumented applications functional test suite included software distribution mysql bzip samba 
presents pros cons 
allows depending test suite exercise application functionalities amount traces obtained reasonable stored handled 
collected dynamic information may properly reflect real usage scenarios 
example analyze file sharing system samba expect discover functionalities file transfer frequently password change 
functional test suite may allow obtain similar results 
consider example industrial interest porting existing software systems conceived developed traditional hardware platforms workstations laptops hand held devices personal digital assistants pda wireless devices multimedia general devices limited resources 
applications meet new constraints imposed devices miniaturization activities required 
case user profiles reveal valuable resource ensured reflect customers field usage 
matter fact accurate user profiles seldom available need collect dynamic information effective way 
poses challenges especially devices limited involved 
compromise detail level collected information required storage space decrease application performance pursued 
proposes architecture web services collect program dynamic information 
new architecture relies web services idea published allows easily deal firewall non persistent connections 
responsibilities roles differently distributed architecture components 
new architecture dynamic information summarized user workstations applications may consist limited resource device java enabled cell phone pda connectivity available transmitted central collection facility 
presents novel approach summarize compress dynamic information inspired stochastic language models developed natural language processing counting events frequencies function methods call 
calling context may saved required specified detail allowing balance amount collected information accuracy trace representation 
collected dynamic information represents approximation restricted view execution behavior 
term approximation underline probabilistic nature collected information 
clearly summary information collected general may impossible claim calling context exercised 
words proposal grounded assumption summary information suffices purposes mentioned analysis task may may case 
example values set variables set program points need monitored saved summary information suffice 
proposed approach main advantages 
foremost single application collects summarizes dynamic information collected information sent local queue precise execution points application exit point transmission overhead minimized advantage lower performance decrease 
furthermore traces summary information saved required bandwidth storage resources greatly reduced 
remainder organized follows overview related section outlines dynamic information probabilistic model 
section details information collection architecture commenting encountered challenges 
figures model performance obtained java programs shown discussed section progress 

related source source translation common technique instrument program purpose collecting dynamic information 
example focuses dynamic techniques discovering invariants execution traces 
subject program instrumented daikon front source source translation instrumentation point values variables scope saved 
program profiling trace collection intraprocedural level dense efficient intra procedural path numbering allows collect detailed information procedural level 
interprocedural path profiling addressed reps devise modified ball larus algorithm accounting context sensitive interprocedural profiling 
authors underline approach path numbering may prohibitive theoretically exponential number inter procedural paths representing paths limited length machine words 
hash table approaches algorithm may lead save executed path remains seen approach works scales empirical data reported literature 
harrold approach empirical analysis analyzing relationship existing program spectra distributions program execution paths program behavior 
problem handling large amounts data performing dynamic analysis discussed authors algorithm detecting patterns traces procedure calls 
worth pointing approach easily define model 
non loss approach trace compression oriented performance analysis proposed 
ernst discussed synergies dualities static dynamic analysis 
reiss approach encode dynamic information explore program traces discussed languages dynamic instrumentation 
jeffery ufo dynamic analysis framework 
stated commonalities 
responsibilities different architecture components different novel approach dynamic information encoding proposed 

dynamic information model perform effective dynamic analysis need accumulate usage profile certain resources func tion calls object instantiations method calls main drawback dynamic information execution traces tends increase unacceptable rate 
furthermore need record transmit collected data tends significantly slow application execution decreasing user perceived application quality 
non trivial side effects synchronization inter process communication problems considered 
sake simplicity ground approach realistic setting describe motivate choice collect summary information detailed information context program profiling purpose executable footprint reduction 
user perspective invokes functionality accesses resource fact functionality code resource readily available undergo unnoticed 
save space user automatic installation wizard may decide tailor application installing frequently exercised functionalities delaying invocation time installation rarely infrequently invoked components 
event rare event times user tasks carried need accessing remote resources slow media cdrom requiring intervention 
described scenario collecting complete execution traces may impractical may unnecessary increase application execution times 
unacceptable especially instrumenting interactive applications applications production environment 
represent legal sequence methods functions calls carried accomplish user defined task 
interested task frequency detailed statistics required involving analysis program execution traces 
assume call method function depend previously called ones influence subsequent calls method function calls independent events problem collecting traces dramatically simplified 
simplified assumption statistical independence probability estimation term frequency function method call obser vation time period 
collecting frequency information requires limited amount resources accomplished constant time adopting hash table locally store application process space frequency counts 
model thought level approximation obtained collecting frequency counting detailed information sequences invocations length collected 
furthermore augmenting signature functions methods call site information unique identifier context sensitivity needed may retained 
clearly long sequences accumulated problems alike execution traces memorization experienced 
general sequence probabilities computed estimating stochastic language model collected summary information 
construction written increases conditioned probabilities involved equation quickly difficult estimate due exponential increase possible sequences calls constructed software system 
simplification introduced conditioning dependence call calls follows approximation formally assumes time invariant markov process greatly reduces volume statistics collected order compute clearly introduces imprecision 
models difficult estimate contains system functions methods worst case possible sequences calls considered 
occurrence sequence calls trace rare event feasible paths executed sequences occur due source code structure sparseness data 
words number represented considerably lower order largely depends resource constraints larger values require memory accumulate store frequency counters 
hand increasing example allows distinguish calling contexts 
bigram model couples collected saved 
calling context higher represented bigrams model level calling context may modeled price storage space 

architecture component responsibilities trace collection architecture designed meet different requirements overcome challenges 
allow collect information useful different purposes 
able deal trace collection scenario typically composed geographically distributed users 
efficient heuristics adopted compress collected data 
highlighted dynamic analysis different purposes 
implies different scenarios source code instrumented differently resulting data collected exhibit different format 
affect architecture 
second issue related collect traces distributed environment 
collecting dynamic information field requires instrumented software executed users belonging working teams organization possibly geographically distributed 
typical scenario instrumented software installed users workstations provided daemon periodically sends traces centralized repository 
opinion effective way build distributed system web services 
main advantage communication performed standard protocols smtp avoiding problems firewalls 
data encoded xml schema exchange different analysis environments eased 
attention paid amount data exchanged known xml representations characterized high overhead 
important challenge represented amount data terms traces generated prolonged execution instrumented systems 
size trace dump obtained functional test suite considered reasonable collecting traces weeks result expensive terms mass storage bandwidth needed transmit data centralized repository 
requested forms compression information relevant particular analysis performed kept sending data repository 
architecture proposed shown 
shown composed 
nodes instrumented code runs traces compressed 
central repository collects data distributed executions performs merging 
detail instrumented program sends traces local ipc queue 
viewed instrumented code normal file allowing transparently wrap commercial cots 
architecture conceived independent trace format 
allows 
kind code available 
produce dynamic information different purposes words may decide obtain information sequence calls functions methods control flow graph nodes visited variables attributes 
feasibility study collected function method call traces 
example trace fragment shown notice entry exit points start function highlighted 
xml translation map uncompressed traces trace encoder ngram applic node void node void ngram 

trace encoding translation map 
successively local trace encoder gets traces queue summarizes user machine instrumented application fifo queue uncompressed traces trace encoder ipc xml schema encoded traces web service client communication soap dynamic analysis machine collector web service merger 
dynamic information collection architecture 
model explained section 
shown done means translation map provides encode traces xml schema representing model 
course model length depends kind dynamic analysis performed 
xml schema encoding representing sequences method calls shown example encoded data 
highlighted trace composed composed nodes indicating names methods functions called 
contains xml tag attributes information application executed sequence number times occurrences sequence executed 
xml schema encoded data sent web service client collector web service 
xml schema constitutes agreement point necessary distributed clients service 
data collected merged stored centralized repository 
locally unique id assigned collector client ensuring traces different running instances mixed 
separation instrumented code trace encoder worth discussion 
generating plain execution traces may decide summarize relevant information data structure properly interfaced instrumentation code program execution 

example uncompressed traces 
analyzer database centralized database encoded dynamic information avoid writing traces disk saving space execution instrumented program 
shown section updating occurrence hash table significantly faster writing line file 
main disadvantage approach need customized instrumentation strongly depends particular information need 
require change time instrumentation tool worse exclude possibility commercial instrumentation tool 

feasibility study purpose feasibility study demonstrate data compressed approach detailed section possible instrumented applications run days real execution environment collecting data centralized repository causing excessive degradation system performance 
collecting dynamic information executing instrumented programs inevitably leads dedicate resources monitoring activity 
resources space required store gathered information cpu time needed different phases profiling process 
instrumentation phase performed line sys 
xml schema encoding grams call sequences 
software system version description language bzip compression utility gzip compression utility unix diff cmp diff unix find utility grep unix file search utility indent program samba file sharing mysql database management system chat java javacc java java java tem compilation time affect user perceived system performance overhead induced collecting managing storing information worsens execution time perceived unacceptable loss performance 
words basic characteristics assessed space required store information achievable compression ratios performance degradation instrumented original version system 
purpose families applications considered non interactive applications shell utilities interactive applications chat software 
choice motivated consideration time overhead due collecting dynamic information kept low perceived interactive service easily measured batch tasks compressing large bulk data 
aim approach collect dynamic information case studies function method calls users considerably long time intervals designed tests quantify different factors po table 
case study software systems 
affecting system performance 
purpose instrumented set java applications different characteristics quantify achieved compression ratios execution times 
characteristics instrumented software systems case studies reported table 
performance degradation subsection aims analyze performances instrumented applications 
timings measured utility gives user cpu time 
measures performed pentium mobile cpu ghz ata hitachi disk performing mbytes sec 
buffered disk reads 
quantify effect ascii versus binary representation exchanging information locally application machine simple compression task bzip self test different configurations writing sending ascii traces local server application id file name method function name entering exiting function method writing sending binary block encoding ap 
example xml encoded dynamic information xml schema 
plication id function method local ipc queue 
information sent blocks kbytes writing sending grams 
task time baseline table 
time spent different phases bzip application self test times sec 
clearly encoding function method name adopted example progressively numbering functions encountered instrumenting code mapping table saved reconstruct actual sequence executed functions methods 
mapping table produced instrumentation time small part trace encoder application remaining operations performed transparently 
table reports times corresponding configurations time test 
performances obtained running times configuration averaging execution account slight fluctuations 
worth noting appreciable degradation observed binary encoding locally exchanging data 
similar results obtained compressing decompressing mbytes iso image file 
similar comparison java batch command 
developed javacc instrumented recursively instrument source java files 
execution task subject case study instrumentation ast visitor devoted instrument source code java source file locs 
objective case study compare timing 
execution non instrumented program 
traditional trace generation long application takes instrument visitor generating plain ascii traces method entry exit point 
extraction dynamic information discussed section directly instrumented execution particular automatic generation bigrams respect bzip case study util hashtable stack encode information 
original version took sec instrumented minutes automatic generation bigrams took sec 
biggest overhead traditional trace generation due expected writing file stream instrumented version writing operations took time sec 
original version 
instrumented version automatic generation bigrams took sec 
time due access data structures compute bigrams 
smart automatically summarizes dynamic information adopted better performances instrumented version required course possible modify 
javacc ended simply subclassing class responsible trace writing creating class stores bigrams hash table prints application execution 
program task time 
version baseline gzip compression mbytes gunzip decompression mbytes find searching gbytes grep self test table 
time spent performing tasks instrumented non instrumented utilities times sec 
table shows different tasks tools appreciable performance degradation execution different instrumented applications 
measures performed machine configuration corresponding 
table shows performance degradation kept quite low clearly higher degradation experienced general purpose instrumentation tool configuration similar adopted custom tool built case differences may may perceived user 
achieved compression achievable compression assessed measuring size trace files number unigrams bigrams trigrams file sizes 
preliminary task different orders computed trace data server 
considered representative different situations corresponding software self test bzip field usage 
samba server installed server machine data collected days typical 
reports increase systems number times number unigrams 
words space severe issue high context sensitivity accuracy required bigram trigram representation reasonable compromise 
worth pointing difference behavior bzip samba 
authors opinion bzip instrumentation exercised application functionalities bzip simply performs compressions functions possibly excluding options exercised compressing large amount data case function gram increase gram order bzip self test samba server 
percentage increase gram number respect unigrams bzip samba server 
calls related frequently tasks file transfer number perform significant 
table table summarize compression achieved representing traces unigrams bigrams trigrams interactive table java applications table 
program size collected traces kilobytes number file size reported 
compression ratios fairly spread orders magnitude 
dramatic compression ratios obtained considering batch system tools particular gzip 
program instrumented exercised self test contained tool distribution carry simple tasks 
tasks chosen representative tool usage searching file directory tree find strings ascii files grep sources indent computing diff file recursive diff directory trees diff 
results shown table may considered representative command line application usage 
caution adopted extend program trace size unigram size bigram size trigram size samba mysql table 
trace sizes ascii files number size unigrams bigrams trigrams programs sizes reported kbytes bigrams trigrams context insensitive 
program trace size unigram size bigram size trigram size server server client client client client table 
trace sizes number size unigrams bigrams trigrams java chat software sizes reported kbytes bigrams trigrams context insensitive 
compression ratios applications investigations needed confirm results 
example compressing mbytes gzip recursively calls huge number times functions 
example function send bits invoked millions time function ct tally millions times 
send bits recursively call compression achieved run length encoding rle 
approach relies assumption call graph fully connected function method limited number called function method 
furthermore assume precise context information relevant limit say accumulate lower order statistics 
case may exponential growth corresponding exponential number interprocedural paths 

architecture collect field dynamic information novel approach compress program traces representing models 
worth pointing purposes different mentioned architecture xml schema data transfer suitable different trace encoding approaches proposed 
data obtained instrumenting exercising interactive batch software systems support feasibility applying approach distributed environment collect accurate usage profile information 
noticeably overhead obtained custom instrumentation tools directly encoding information program execution quite acceptable 
furthermore achieved compression ratios orders magnitude essential accumulate store sizeable dynamic information long observation period 
possible xml schema encoding data allowing exchange open distributed web service environment 
time writing proposed architecture compression approach successfully applied tasks 
automatic design pattern detection proceedings ieee international workshop program comprehension portland usa may 
eisenbarth koschke simon aiding program comprehension static dynamic feature analysis proceedings ieee international conference software maintenance florence italy pp 
ieee computer society press nov 
eisenbarth koschke simon locating features source code ieee transactions software engineering vol 
pp 
mar 
syst relationships static dynamic models reverse engineering java software proceedings ieee working conference reverse engineering atlanta ga usa oct 
ducasse dynamic information iterative recovery collaborations roles proceedings ieee international conference software maintenance montr qc canada oct 
eisenbarth koschke vogel static trace extraction proceedings ieee working confer program task trace size unigram size bigram size trigram size bzip self test gzip compressing mbytes gunzip decompressing mbytes find searching gbytes grep self test diff recursive diff indent indent java instrumenting visitor table 
trace sizes number size unigrams bigrams trigrams batch tools sizes reported kbytes bigrams trigrams context insensitive 
ence reverse engineering richmond va usa pp 
oct 
cook du discovering thread interactions concurrent system proceedings ieee working conference reverse engineering richmond va usa pp 
oct 
antoniol di library miniaturization static dynamic information proceedings ieee international conference software maintenance amsterdam netherlands pp 
ieee press sep 
de mori spoken dialogues computers 
orlando florida academic press 
ernst cockrell griswold notkin dynamically discovering program invariants support program evolution international conference software engineering pp 

ball larus efficient path profiling international symposium microarchitecture pp 

reps interprocedural path profiling computational complexity pp 

harrold rothermel wu yi empirical investigation program spectra workshop program analysis software tools engineering pp 

lethbridge compression techniques simplify analysis large execution traces proceedings th international workshop program comprehension paris france pp 
jun 
lethbridge efficient algorithm detecting patterns traces procedure calls icse workshop dynamic analysis portland usa may 
samples loss trace compaction tech 
rep university berkley california 
ernst static dynamic analysis synergy duality icse workshop dynamic analysis portland usa may 
reiss encoding program executions international conference software engineering pp 

reiss exploring program traces workshop kansas city mo usa pp 
nov 
reiss languages dynamic instrumentation icse workshop dynamic analysis portland usa may 
jeffery axioms issues ufo dynamic analysis framework icse workshop dynamic analysis portland usa may 
di antoniol merlo knowledge library re factoring open source project proceedings ieee working conference reverse engineering richmond va pp 
oct 
antoniol di moving smaller libraries clustering genetic algorithms european conference software maintenance reengineering italy pp 
mar 
cover thomas elements information theory 
new york ny wiley series telecommunications john wiley sons 
