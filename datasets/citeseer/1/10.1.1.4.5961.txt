restart policies dependence runs dynamic programming approach ruan eric horvitz henry kautz university washington seattle wa usa cs washington edu microsoft research redmond wa usa horvitz microsoft com 
time required backtracking search procedure solve problem reduced employing randomized restart procedures 
date researchers designing restart policies relied simplifying assumption runs probabilistically independent 
relax assumption independence runs address challenge identifying optimal restart policy case dependent runs 
show ine dynamic programming generate ideal restart policy policy conjunction real time observations control timing restarts 
results experiments applying methods create ideal restart policies challenging problems di erent solvers 
combinatorial search algorithms domains exhibit high variance running time xed sets problems 
cases probability distribution running time search algorithm problem set heavy tailed having nite mean variance :10.1.1.112.8065
investigators pursued understanding basis great variation run time sought exploit uncertainty execution time develop predictable ecient procedures 
investigators explored value randomized restarts 
area randomness overlayed branching heuristic systematic search algorithm 
search algorithm terminate number backtracks referred cuto run halted algorithm restarted new random seed 
randomized restart method demonstrated reduce total execution time wide variety problems scheduling theorem proving circuit synthesis planning hardware veri cation 
horvitz 
introduced general paradigm building probabilistic models predict search algorithm performance problem instance basis algorithm behavior rst search steps 
asserted bayesian models provide foundation speed learning control problem solvers 
related kautz 
showed predictive models design superior dynamic restart strategies randomized problem solvers case runs probabilistically independent 
extend results general complex situation runs probabilistically dependent run provide update nature probability distribution generated problem instance 
shall rst review details prior de ne problem dynamic restarts dependencies 
show optimal restart policy dependent case modeled dynamic programming dp problem 
method centering ine dp generate ideal restart policy 
show observations incorporated restart policy 
illustrate ecacy restart policies experiments representative problems 
research restart policies basis randomized restarts straightforward longer backtracking search algorithm runs nding solution algorithm exploring part search space branching early states critical variables necessary solution 
designers restart policies grapple minimization total run time tradeo cuto time reduced probability particular run reach solution diminished runs shorter numerous 
previous theoretical problem determining ideal cuto assumptions rst feasible observation length run second runs independent 
conditions luby described provably optimal restart policies 
case complete knowledge distribution optimal policy xed cuto minimizes expected time solution restarting backtracks 
case knowledge distribution luby showed universal schedule cuto values form gives expected time solution log factor optimal xed cuto universal schedule better constant factor 
results luby taken research community settled open issues restart strategies real life scenarios violate assumptions 
horvitz kautz demonstrated features run time restart control policy backtrack solvers 
introduced framework constructing bayesian models predict run time problem solvers showed observations various features capturing state solver rst steps run fused predict length run useful degree accuracy 
described approaches apply observation restart control policies showed dynamic restart policies observations beat static optimal policy luby 
papers retained limiting assumption runs probabilistically independent 
assumption runs independent violated number settings 
consider case knowledge existence di erent probability distributions run time 
problem instance drawn distributions prior probabilities run performed instance 
setting observations time exhibited restart prior runs instance provides probabilistic update probability distribution run time current runs 
easy see restart policies independent dependent runs di er 
consider simple case distributions point probabilities 
suppose independent case run ends steps equal probability 
case optimal policy restart steps problem solved 
hand consider dependent case runs take steps runs take steps xed instance chosen distributions equal probability 
optimal policy run cuto 
problem solved steps know problem requires steps solver continue 
xed cuto gives nonzero probability solving problem nite expected run time 
addresses challenge designing restart policies dependent runs 
speci contributions include modeling optimal restart policy dependent runs dp problem speci cation di erent predictive models showing dynamic restart policies evaluating optimal restart policies empirically runtime observations comparing results best xed cuto policies universal restart policy luby 
dependent restarts observations simplify presentation focus dependent runs case run time distributions shall denote source distributions results extended straightforward manner case distributions 
outset problem solving distributions chosen prior probability choice revealed solver 
run specify cuto sample drawn chosen rtd 
sample run time problem solved perform run new sample distribution 
unsuccessful run gain additional information distribution initially chosen 
analysis characterizes problem solving scenarios including scenarios rtd single instance randomized solver ii corresponds ensemble instances similar rtd iii rtd heterogeneous ensemble solver gets new problem instance run 
scenario interest corresponds heterogeneous ensemble instances problem instance run 
analysis single instance scenario requires additional mathematical machinery relates rtd ensemble rtd individual instances randomized solver explain forthcoming 
perfect knowledge distribution generated instance problem collapse independent case described luby consider case uncertain source distribution 
goal nd optimal policy cuto th run total number steps solution minimized 
unsuccessful run solver beliefs source distribution updated 
shall rst consider situation limited solely evidence time spent prior runs 
formulate problem nding optimal restart policy dependent case markov decision process mdp 
formally dependent restart problem described markov decision process follows prior probability run chosen distribution probability run selected stopping exactly cumulative function 
assume non trivial sense inf 
state tuple set actions states set possible cuto action cuto state possible state problem solved termination state updated probabilities 
solver reaches termination state denoted remains cost 
optimal restart control policy expected cost reach termination state minimum 
denote event run solution cuto denote event instance distribution 
analysis considering prior run times updating jd jd 
immediate cost setting cuto state expected length run state cuto denoted state depends previous state corresponding cuto true immediate cost state space satis es markov property 
nding optimal restart policy dependent runs mdp 
cuto transition probabilities termination state js js transition probability state 
optimal expected solution time state optimized sum immediate cost optimal expected solution time possible states denoted bellman equation min fr js js min fr js min relation equation 
computed dp 
experimented policy iteration value iteration dp 
restart policy said proper state select cuto js state positive transition probability termination state 
policy iteration value iteration proved converge ideal optimal value theory assumption proper restart policies 
studies policy iteration converges faster value iteration 
choose policy iteration experiments 
practical problem state space continuous potentially solve problem nite state space 
computational tractability transform continuous space discrete state space apply nite state dp methods 
shall review experiments case dependent runs observation section 
reviewing results shall explore case consider observations gathered run time addition time taken previous runs 
dependent restarts observations run time evidence behavior solver may valuable updating beliefs source distribution 
watching trace visualization backtracking search engine action provide updates run time 
mentioned earlier provides general framework constructing bayesian models predict run time problem solvers shows probabilistic models create optimal dynamic restart policies case independent runs 
consider situations system observations update beliefs current explore case evidential feature solver state observed run 
taken function initial trace solver calculated decision tree low level variables 
may providing example update current run steps 
multi valued example feature may indicate leaf predictive decision tree model infer rtd associated set features observed initial portion run 
simplicity exposition shall consider case binary valued 
analysis assumptions meaning practice need choose helps choose better cuto value run 
natural choice output decision tree trained discriminate instances call distribution predictor 
experiments sat unsat distribution predictor discriminates satis able unsatis able instances 
natural choice base decision tree trained discriminate short median run time verses long greater median run time runs prior weighted union call run time predictor 
intuitively distribution predictor provides probabilistic information tune cuto predicted distribution run time predictor allow discard runs predicted long 
important understand dynamic programming procedure calculating optimal sequence cuto values rely explicit semantics predictive models simply determines optimal cuto speci ed predictor 
section compare sat distribution run time predictors benchmark test suite 
addition run time evidence include information observation include extended de nition state 
extended state described described previous section 
de ne transition probability state transition corresponding cost follows de ned fn denote feature observed nth run fn 
derive transition probabilities state transitions compute interim probability fn jf 
interim probability probability instance generated distribution fn observed th run th run observation fn solution steps 
fn jf fn jf jf obtain rst part right side formula probability observing fn run conditioning assumptions instance distribution fn observed th run solution steps fn jf fn jd assert probability observation independent previous observations selected cuto conditioned assumption instance drawn second part right side formula jf probability instance distribution assuming fn observed solution steps 
jf jf jf jf jf jf combining parts fn jf jf fn jd jf note jf fn jd jf derived data 
transition probability state sn fn action sn fn sn js fn jf fn jf jf fn jd jf state sn fn jf fn fn jf fn jf jf fn jd jf fn jd binary valued state sn fn cuto know solver states solution solver termination state solution true solution false 
fn fn denote states respectively 
transition probability sn states 
immediate cost sn expected length nth run associated setting cuto state sn equation 
similar observation analysis optimal expected solution time state sn fn denoted sn optimized sum immediate cost sn plus optimal expected solution time possible states bellman equation sn min fr sn js js js min fr sn js js min fr sn js js min js js js js computed equation 
similar case observation dynamic dependent restart policy case run time observations computed dp described section 
experiments results performed set experiments explore approach nding optimal restart policies observations 
investigated dependent restart policies multiple instance problem solving scenario described case iii section 
multiple instance situation choose instance prior probabilities 
run new instance distribution randomly selected 
draw attempt solve instances goal solve instance soon possible 
considered benchmark domains quasigroup completion problem graph coloring problem 
experiments performed earlier horvitz considered satis able problems 
experiments performed considered distributions containing unsatis able satis able problem instances 
described section investigated dependent restart policies multiple instance problem solving scenario heterogeneous ensemble new instance drawn run 
noted forthcoming explore complex case xed instance drawn heterogeneous ensemble 
background benchmark domains quasigroup ordered pair 
set 
binary operation equations 

uniquely solvable pair elements order quasigroup cardinality set incomplete partial latin square partially lled table symbol occurs twice row column 
quasigroup completion problem problem determining remaining entries table lled way obtain complete latin square 
studies generated total instances satis able 
instances order unassigned variables holes 
second problem domain explored solving propositional satis ability sat encodings graph coloring problem gcp 
graph coloring problem known combinatorial problem graph theory 
graph fv vn set vertices set edges connecting vertices seek nd coloring connected vertices di erent colors 
challenge decide coloring graph exists particular number colors 
strategy encoding graph coloring problem instances sat assignment color single vertex represented propositional variable coloring constraint edge graph represented set clauses ensuring corresponding vertices di erent colors 
additional sets clauses ensure valid sat assignments assign exactly color vertex 
instances studies generated culberson graph generator 
challenge decide instances colorable 
instances contain satis able instances unsatis able instances 
instances generated way colorable instances instances colorable 
third domain explored planning problem logistics domain 
kautz selman showed propositional sat encodings planning problems eciently solved sat engines 
logistics domain involves moving packages trucks airplanes locations di erent cities 
logistics domain state particular con guration packages vehicles 
generated instances cities packages planes truck city 
generated total instances instances satis able 
decrease variance instances satis able instances solved parallel steps solved steps 
unsatis able instances solved steps solved steps 
learning predictive models satz rand randomized backtracking search engine problems encoded sat 
satz rand randomized version satz system li anbulagan 
problems experimented specialized randomized csp solver built ilog constraint programming library 
implemented methods described horvitz learn predictors run time observations feature described section 
solvers instrumented low level observational variables collected observational horizon solver choice points 
choice point state backtracking search procedure algorithm variable assignment heuristically making assignment forced propagation previously set values 
types value propagation include unit propagation backtracking lookahead forward checking 
employed bayesian learning procedures developed chickering heckerman meek induce predictors form decision trees built summary statistics low level variables training sets generated approximately runs 
mentioned section experimented kinds predictors sat unsat distribution predictors classifying instance satis able unsatis able instance run time predictors classifying run short long depending run time greater median time training set 
details procedure learning predictive models described 
comparing policies dynamic dependent restarts described earlier optimal restart policy dependent runs constructed ine policy iteration dp transform continuous nite state space discrete state space apply dp methods 
experiments search space uniformly segments consideration tradeo computational eciency accuracy 
policy construction dp policy iteration required hour pentium machine gigabyte memory 
characterize improvements associated dynamic dependent restart policies ran comparative experiments xed cuto restart policy cuto run 
optimal xed cuto restart policy selects xed cuto minimizes expected solution time min case universal restart policy luby constructed optimal restart policies training data tested policies test data training 
results comparing optimal restart policy predictive models optimal restart policy observation best xed cuto restart policy shown table 
problem domains studied expected run time dynamic restart policies observation lower optimal dynamic restart policy observations 
attribute improvement solution time ranging domains ectively harnessing predictive models di erentiating runs 
problems run time predictive model yields faster solution times sat unsat distribution predictive model 
believe di erentiating short runs long runs endows solver ability avoid expending time non promising long runs 
graph coloring planning restart policy ert improvement ert improvement ert improvement optimal predictor optimal run time optimal distribution best xed cuto luby universal table 
comparative results optimal policies observation best xed cuto luby universal restart policy ert expected run time choice points improvements measured luby universal policy 
note cuto usually di erent optimal cuto distributions luby universal restart policy change distribution distribution 
summary directions described challenge relaxing assumption independence randomized restart procedures backtracking search 
de ned dynamic dependent restart problem showed employ dynamic programming ine procedures generate ideal real time restart policies 
rst explored case solver considers information execution time previous runs extended analysis include evidence problem solving behavior observed runs 
results experiments domains including quasigroup completion graph coloring logistics planning problems 
pursuing extensions results 
ongoing includes development dynamic dependent restart procedures single instance scenario 
setting seek relate rtd ensemble rtd individual instances randomized solver 
studying generalization methods scenarios weaker assumptions nature underlying rtd 
part exploring methods reinforcement learning infer underlying distribution previous search trajectories 
believe great opportunity continuing take bayesian perspective tackling combinatorial problems develop machinery methods allows solvers believers take consideration evidential observations problem solving consider probabilistic dependencies multiple solving sessions 

dimitris achlioptas carla gomes henry kautz bart selman 
generating satis able problem instances 
aaai iaai pages 

bertsekas tsitsiklis 
neuro dynamic programming 
athena scienti 

chen carla gomes bart selman 
formal models heavy tailed behavior combinatorial search 
lecture notes computer science 

david maxwell chickering david heckerman christopher meek 
bayesian approach learning bayesian networks local structure 
proceedings thirteenth conference uncertainty arti cial intelligence uai pages providence ri 
morgan kaufman publishers 

joseph culberson feng luo 
exploring colorable landscape iterated greedy 
david johnson michael trick editors dimacs series discrete mathematics theoretical computer science vol 
pages 

gent walsh 
easy problems hard 
arti cial intelligence 

carla gomes bart selman 
problem structure presence perturbations 
proceedings fourteenth national conference arti cial intelligence aaai pages new providence ri 
aaai press 

carla gomes bart selman nuno crato 
heavy tailed distributions combinatorial search 
gert smolka editor principles practice constraint programming cp lecture notes computer science pages linz austria 
springer verlag 

carla gomes bart selman nuno crato henry kautz 
heavy tailed phenomena satis ability constraint satisfaction problems 
automated reasoning 

carla gomes bart selman henry kautz 
boosting combinatorial search randomization 
proceedings fifteenth national conference arti cial intelligence aaai pages new providence ri 
aaai press 

carla gomes bart selman henry kautz 
boosting combinatorial search randomization 
aaai iaai pages 

aaai workshop leveraging probability uncertainty computation 

hogg huberman williams eds 
phase transitions complexity special issue 
arti cial intelligence 

eric horvitz ruan carla gomes henry kautz bart selman max chickering 
bayesian approach tackling hard computational problems 
proceedings th conference uncertainty arti cial intelligence uai pages seattle usa 

howard 
dynamic programming markov processes 
mit press 

kautz selman 
pushing envelope planning propositional logic stochastic search 
proceedings thirteenth national conference arti cial intelligence aaai pages portland 
aaai press 

henry kautz eric horvitz ruan bart selman carla gomes 
dynamic randomized restarts optimal restart policies observation 
appear aaai 

henry kautz ruan achlioptas carla gomes bart selman mark stickel 
balance ltering structured satis able problems 
proceedings sixteenth international joint conference arti cial intelligence ijcai pages 

kirkpatrick selman 
critical behavior satis ability random boolean expressions 
science 

chu min li anbulagan 
heuristics unit propagation satis ability problems 
proceedings international joint conference arti cial intelligence pages 
aaai 

luby sinclair zuckerman 
optimal speedup las vegas algorithms 
information process 
letters pages 

matthew moskewicz conor madigan ying zhao zhang sharad malik 
cha engineering ecient sat solver 
design automation conference pages 

selman kautz cohen 
local search strategies satis ability testing 
johnson trick editors dimacs series discrete mathematics theoretical computer science vol 
pages 
ams 

walsh 
search small world 
proceedings international joint conference arti cial intelligence pages stockholm sweden 
