active learning automatic classification software behavior james college computing georgia institute technology atlanta georgia cc gatech edu program behavior ultimately collection executions 
collection diverse unpredictable generally unbounded 
especially suited statistical analysis machine learning techniques 
primary focus automatic classification program behavior execution data 
prior classifiers software engineering adopts classical approach 
contrast explore active learning paradigm behavior classification 
active learning classifier trained incrementally series labeled data elements 
secondly explore thesis certain features program behavior stochastic processes exhibit markov property resultant markov models individual program executions automatically clustered effective predictors program behavior 
technique models program executions markov models clustering method markov models aggregates multiple program executions effective behavior classifiers 
evaluate application active learning efficient refinement classifiers conducting empirical studies explore scenario illustrating automated test plan augmentation 
categories subject descriptors software engineering software program verification mathematics computing probability statistics artificial intelligence learning general terms measurement reliability experimentation verification keywords software testing software behavior machine learning markov models permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
issta july boston massachusetts usa 
copyright acm 
james rehg college computing georgia institute technology atlanta georgia rehg cc gatech edu mary jean harrold college computing georgia institute technology atlanta georgia harrold cc gatech edu 
software engineers seek understand software behavior stages development 
example requirements analysis may formal behavior models analysis rapid prototyping specify software behavior 
implementation engineers aim assess reliability software behavior testing analysis 
approaches evaluates behavior relative particular development phase limiting range behaviors considered 
believe program behavior richer complex characterization provided perspectives 
software behavior ultimately collection executions embodying diversity users inputs execution environments copies program 
collection unpredictable generally unbounded requires data driven approach analysis 
approach understanding behavior build behavior models data statistical machinelearning techniques 
program exist numerous features collect aggregate statistical measures branch profiles 
features accurate predictors program behavior broad range statistical machine learning techniques aid analysis tasks automated oracle testing evaluation test plans detection behavior profiles deployed software reverse engineering 
focus automatic classification program behavior execution data 
context classifier map execution statistics branch profiles label program behavior pass fail 
issues addressed classifier design set features classifier architecture learning technique training classifier labeled data 
example podgurski colleagues classifier logistic regression uses composite features execution profiles identify failures may share common fault 
application machine learning techniques classification software engineering problems relatively new representative examples :10.1.1.14.8279
prior adopts classical approach fixed quantity training data collected start learning process 
contrast focus paradigm behavior classification 
active learning classifier trained incrementally series labeled data elements 
iteration learning current classifier applied pool unlabeled data predict elements significantly extend range behaviors classified 
selected elements labeled added training set round learning 
potential advantage active learning context ability effective limited resources available analyzing labeling program execution data 
evolving classifier useful predictions data items correspond new behaviors items selected preferentially 
result scope model extended batch method yield amount labeling effort 
empirically active learning yield classifiers comparable quality produced batch learning significant savings data labeling effort 
addition data items selected active learning efficiently extend scope test plans 
important findings human analysis program outputs inherently expensive machine learning techniques depend success amounts labeled data 
second contribution investigation features derived markov models program execution adequately characterize specific set behaviors induced test plan 
specifically explore thesis sequence method calls branches executing program stochastic process exhibits markov property 
markov property implies predictions program states depend current state 
method caller callee transitions branches form basic set arcs interprocedural control flow graphs 
features part larger feature set 
furthermore branch profiles shown detectors presence faults researchers 
specify markov models program behavior features 
previous works demonstrated power clustering techniques developing aggregate descriptions program executions 
automated clustering method markov models aggregates multiple program executions 
resulting cluster markov model statistical description collection executions represents 
approach train classifiers recognize specific behaviors emitted execution knowledge inputs outcomes 
main benefits 
show modeling certain event transitions markov processes produces effective predictors behavior automatically clustered behavior classifiers 
secondly show classifiers efficiently evolved application active learning techniques 
interprocedural control flow graph directed graph consisting control flow graph method plus edges connecting methods call sites returns calls 
control flow graph directed graph nodes represent statements basic blocks edges represent flow control 
contributions technique automatically clusters markov models program executions build classifiers 
application technique efficiently refines classifiers active learning bootstrapping demonstration application example automated test plan augmentation 
set empirical studies demonstrate classifiers built technique markov models predictors program behavior detectors unknown behaviors 

related previous closest spirit method podgurski colleagues 
uses clustering techniques build statistical models program executions applies tasks fault detection failure categorization 
primary differences technique previous central role markov models approach active learning techniques improve efficiency behavior modeling 
additional difference explore utility features large set features 
dickinson leon podgurski demonstrate advantage automated clustering execution profiles random selection finding failures 
feature profiles basis cluster formation 
concentrate features summarize event transitions method caller callee profiles branch profiles 
show utility markov models profiles predictors program behavior 
podgurski clustering combined feature selection multidimensional scaling visualize resulting grouping executions 
works clusters formed batch learning subsequent analysis 
contrast explore active learning technique interleaves clustering evaluation greater efficiency 
group related papers share approach markov models describe stochastic dynamic behavior program executions 
whittaker markov chains model software usage specifications prior implementation 
contrast markov models describe statistical distribution transitions measured executing programs 
cook wolf confirm power markov models encoders individual executions study automated process discovery execution traces 
concentrate transforming markov models finite state machines models process 
comparison technique uses markov models directly classify program behaviors 
jha tan maxion markov models event traces basis intrusion detection 
address problem scoring events encountered training focus role clustering techniques developing accurate classifiers 
final category related uses wide range alternative statistical learning methods analyze program executions 
models methods works differ substantially detail share common goal developing useful characterizations aggregate program behaviors 
harder ernst automatically classify software behavior operational program test plan behavior oracle instrument profile event transitions stage 
prepare training instances execute label behaviors training instances event transition profiles behavior labels group behavior labels stage 
train classifier behavior groups bn train classifier group classifiers cb cbn assemble classifier building classifier stage prepare training instances stage train classifier 
differencing technique 
method extracts formal operational abstractions statistical summaries program executions uses automate augmentation test suites 
comparison modeling program behavior exclusively markov statistics events 
ernst dynamic invariant detection extract program properties relevant revealing faults apply batch learning techniques rank select properties 
properties select formed large number disparate features authors focus fault localization program behavior general 
contrast seek isolate features critical describing various behaviors 
additionally apply active learning construction classifiers contrast batch learning authors 
gross colleagues propose software dependability framework monitors running programs collects statistics multivariate state estimation automatically builds models predicting failures execution 
framework discriminate features consequently markov statistics events multivariate estimates model program behavior 
models built batch learning demonstrate advantages active learning 
munson posit actual executions final source reliability measures 
model program executions transitions program modules additional terminal state represent failure 
focus reliability estimation modeling transition probabilities failure state 
focus behavior classification programs may defined failure state 
ammons bodik larus describe specification mining technique extracting formal specifications interaction traces learning probabilistic finite suffix automata models 
technique recognizes stochastic nature executions focuses extracting invariants behavior mappings execution event statistics behavior classes 

modeling software behavior goal build simple models program behavior reliably summarize predict behavior 
classifier focus subset features profile event transitions program executions 
event transition transition program entity types st order event transitions include branches source statement sink statement method calls caller callee definition pairs definition type nd order event transition branch branch 
event transition profile frequency event transition occurred execution 
show event transition features describe stochastic processes exhibit markov property building markov models effectively predict program behavior 
markov property provides probability distribution states process depends current state 
markov model captures time independent probability state time state time 
relative frequency event transition program execution provides measure probability 
instance branch event transition control flow graph cfg program source node sink node 
source sink nodes states markov model 
source node predicate branches true false representing transition different sink node 
transition probabilities markov model source node sink nodes relative execution frequencies profiles branches 
general state variables represent events variable definitions variable uses 
state variables represent complex event sets paths length events 
paths length referred nd order event transitions 
profiling mechanism collect frequency data transitions events markov models 
area research examine trade offs costs collecting higher order event transition profiles benefits provided predictive abilities 
technique builds classifier software behavior stages 
initially model individual program executions markov models built profiles event transitions branches 
mod control flow graph directed graph nodes represent statements basic blocks edges represent flow control 
els represents instance program behavior 
technique uses automatic clustering algorithm build clusters markov models form classifier tuned predict specific behavioral characteristics considered program 
shows data flow diagram technique 
data flow diagram boxes represent external entities inputs outputs circles represent processes 
arrows depict flow data parallel horizontal lines center database 
reading diagram left right technique takes inputs subject program test plan behavior oracle outputs classifier test plan contains test cases detail inputs expected outcomes 
behavior oracle evaluates execution ek induced test case tk outputs behavior label bk restricted pass fail stage prepare training instances technique instruments get executes records profiles 
execution ek test case tk behavior oracle uses outcome specified tk evaluate label ek 
produces training instance consisting ek event transition profiles behavior label stored database 
stage train classifier technique groups training instances distinct behavior labels 
bn generated behavior oracle 
example behavior labels pass fail result behavior groups 
technique converts training instance behavior group markov model 
technique initially uses batch learning paradigm train classifier cb behavior group bk 
technique assembles behavior group classifiers cb 
cbn assemble classifier exploring algorithm shown discuss markov model building 
building markov models central technique markov models encode event transition profiles produced transformation straightforward mathematical process important understand mapping program events concept state building markov models 
illustrate consider cfg 
branch profiles arbitrary example execution shown labels branch 
example branch profile denotes exercised times 
markov model built execution shown matrix 
models program states identified source sink nodes branch 
transitions read row column 
markov model built branch profiles simply adjacency matrix cfg entry equal row normalized profile 
instance node source transitions branches occur total times 
example implementation transformation algorithm shown 
build model constructs matrix representation markov model event transition profiles 
note number states specified markov model increases efficiency dictate sparse representation conventional matrices 
entry arc profile branch profile branch profile entry markov model branch profiles entry exit entry exit branch profile exit branch profile representing branch profiles markov model 
inputs set states events specify event transitions 
contains event transitions profiles stored ordered triples describing transition state state sto corresponding profile sto profile 
behavior label model 
output triple model profile data behavior label 
line matrix model initialized cardinality lines transition involves states recorded lines row matrix normalized dividing element row sum elements row sum zero 
execution shown inputs st order event transitions entry exit entry exit 
pass case output component markov model shown 
training classifier approach train behavior classifier training instances markov models constructed execution profiles 
training process adaptation established technique known algorithm input 
sn set states including final exit state sto profile 
list ordered triples transition profile string representing behavior label output markov model new float array initialized foreach sto profile sto sto profile return algorithm build model 
agglomerative hierarchical clustering 
technique initially training instance considered cluster size 
technique proceeds iteratively finding clusters nearest similarity function 
clusters merged technique repeats 
stopping condition desired number clusters valuation quality remaining clusters 
specification similarity function typically done heuristically application domain 
case need specify markov models compared 
empirical studies choose simple comparison hamming distance models 
compute hamming distance markov models mapped binary representation entered values certain threshold entered 
threshold value determined experimentally 
label comparison function sim supply input algorithm shown discussed 
binary transformation models done temporarily sim order compute hamming distance 
merged cluster markov model 
example iteration merged model built combining execution profiles form basis models merged 
profiles combined forming union summing values redundant entries 
executions identical profiles result combining profiles profile entry containing value twice corresponding entry single execution 
referring merged profile copies execution entry exit 
merged profile generates markov model represents new cluster 
stopping criterion developed simple heuristic evaluates stability standard deviation set similarity measures obtains iteration 
standard deviation begins hamming distance binary numbers count bit positions differ 
algorithm sim input 
sn set states including final exit state di bk 
list ordered triples sto profile 
string representing behavior label sim function compute similarity markov models output set markov models initially foreach di bk behaviors cb initialize classifier behavior foreach cb behaviors foreach di bk cb cb di bk deltas empty set collect pair wise deltas stats new array cb cluster statistics cb agglomerative hierarchical clustering foreach mi di bk cb cb foreach mj dj bk cb cb deltas deltas sim mi mj stats cb deltas knee stats break mx min deltas dx dy bk cb cb mx cb add behavior models return algorithm train classifier 
change markedly pattern established previous iterations clustering technique clustering stopped 
event standard deviation change markedly clusters 
area research evaluate formed cluster map specific sub behaviors behavior consideration research turn may guide refinement stopping criterion 
algorithm leverages priori knowledge specific behaviors study order direct classifier learning process 
described stage train classifier training instances segregated behavior labels 
allows agglomerative hierarchical clustering training instances representing labeled behavior 
form final classifier union constituent clusters classifiers 
example classifier learned behavior pass composed clusters 
classifier pass trained instances behavior pass clusters contain examples behavior fail hand training done training instances behaviors clusters contain examples behaviors 
way direct classifier learn discriminate behaviors initially possess labels 
algorithm shown trains classifier models generated 
train classifier inputs sim 
set states identify event transitions build model called 
list triples containing test case index data structure defined build model behavior label bk 
sim takes markov models arguments returns real number computed difference models 
lines empty classifier cb initialized discrete behavior bk line begins processing bk 
lines classifier cb populated models built applying training instance exhibiting bk 
lines initialize deltas stats explained 
remainder algorithm clusters models cb reduce population merge similar redundant models sim described 
line establishes default stopping criterion clusters 
lines sim calculate pair wise differences accumulate deltas line 
iteration algorithm calculates standard deviation values deltas stores stats cb line 
cardinality cb decreases iteration serves index stats 
stopping criterion quality standard deviations implemented function knee 
knee checks set standard deviations accumulating stats line determine rate change slope line fit values stats 
knee detecting bend graph standard deviations stats 
knee detection done hand graph plotting program instance knee provides automatic detector empirical evaluations 
knee detects knee sum standard error sse linear regression data points stats increases factor value previous iteration 
knee detected clustering stops behavior group models cb added final classifier 
absence knee process stops model constraint line 
closest models merged lines calling union corresponding profile sets 
note clusters formed new models contains profiles training instances contributing cluster 
line clustered models cb added classifier 
behavior groups processed final returned 
discussed previously classifier composed markov models representing cluster similar executions 
classifier classifier label executions training set 
want classify behavior execution ek report particular behavior label 
constituent models rates ek probability score 
model highest probability score ek provides behavior label ek 
probability score probability model produce sequence event state transitions execution ek 
example refer consider execution program execution trace branches including entry arc entry arc 
calculate probability score markov model produced compute product successive probabilities transitions entry arc 

profile branches trace 
probability directly calculated profiles exponents general qualify calculation specifying model report execution unknown behavior calculated probability threshold 
note probabilities calculated multiplication small 
overcome difficulty standard technique markov models converting probabilities negative natural logarithms summing 
transformation preserves relative ordering results 
bootstrapping classifier number learning strategies training classifiers addition batch learning technique researchers initially 
concentrate type active learning called bootstrapping 
application bootstrapping uses classifier score new executions collect executions remain unknown 
unknown executions considered candidates represent new behaviors evaluated behavior label identified new training instance classifier 
classifier retrained expanded set training instances 
active learning techniques employ interactive approach control costs training classifiers 
techniques especially wellsuited environments scope data fully known generally case software behaviors 
initial set behaviors may known software testing process instance exhaustive testing usually practical possible 
consequence software engineers advance knowledge specific behaviors observed 
new behaviors occur active learning environment provides qualitative feedback oracle case test evaluator allow refinement classifier include new behavior 
new instances behavior recognized classifier need considered source cost savings 
active learning techniques provide way design classifiers better suited ongoing detection behaviors classifiers built initial batch data 
inputs oracle alter variance bias sample batch learner encounter 
describe application bootstrapping classifier training scenario section 
scenario inform empirical studies subsequent section 

scenario scenario serves illustrate developer dev combine technique classifying behaviors active learning strategy reduce cost extending scope existing test plan 
dev designed implemented version program dev developed test plan plans test data generator execute classify unknown behaviors test plan building classifier stage 
evaluate label outcome training instances building classifier stage 
see 
building classifier stages 
automating test case selection 
expand test releases dev interested measuring quality test plan terms coverage potential behaviors 
test plan development testing expensive developers release software tested accepted core functionality 
measure test plan quality dev estimate risks involved releasing current test plan 
goal creating new test cases test plan test additional behaviors 
design test case involves selecting test data induce new behavior evaluating outcome executing test data 
measure quality test plan expressed indirectly rate growth new behaviors discovered 
sense dev find difficult add test cases new behaviors high quality test plan 
general dev wants augment test plan new test cases seeks way reduce cost doing 
dev may automated test data generator relies test engineers evaluate execution 
provide solution dev combines technique building classifiers application bootstrapping dynamically refines classifiers 
dataflow diagram application 
diagram stage technique produces instrumented set training instances initial test plan 
stage technique produces classifier application executes test data generated behalf dev classifies execution bootstrapping process application selects candidates processed set executions executions remain unknown classifier 
candidates dev evaluation subsequently behavior label 
candidates stored new training instances database training corresponding test case candidate added test plan 
application refines certain intervals augmented database training instances 
iteration bootstrapping process stops rate detection unknown executions falls threshold set dev 
application provides economic benefits dev 
application builds classifier cost built batch learning 
simplest form batch learning testing context conventional method accumulating test cases evaluated hand 
training classifier batch learning improves behavior detection rate simple look reduce cost evaluating new test cases 
new test case evaluated regardless induces new behavior 
hand active learning combined robust classifier provide cost savings 
application new test cases induce unknown behaviors evaluated added test plan 
test plan grows test cases extend coverage program behaviors 
secondly dev rate unknown executions produced relative measure quality describing test plan 
revisions program dev target value rate previous version 
comparing rates dev estimate risks associated current test plan informed business decision estimate 
explore economic benefits empirical study section 

empirical studies validate technique explore described scenario performed empirical studies 
infrastructure subject studies program space interpreter antenna array definition language written european space agency 
space consists procedures loc versions containing fault discovered development set tests cases 
studies chose event transition features models method caller callee transitions branches 
branches occur inside methods method calls provide accounting intra program transitions 
aristotle analysis system instrument fifteen randomly chosen versions space profile transitions executed version test cases stored results relational database 
built tool argo implements algorithms technique application 
empirical method empirical method evaluates classifiers built technique application bootstrapping 
studies chose behavior labels pass fail 
method steps database profiles branches method call event transitions space 
select version space 
select set test cases training 
build classifier 

evaluate classifier remaining test cases 
evaluations standard classification rate measure quality classifier 
define metric classifier precision 
classifier precision ratio number unknown executions number classifications attempted 
classifier precision measures ability classifier recognize behaviors 
classification rate measures quality behavior detection 
example suppose scores total executions correctly classifies incorrectly classifies leaving unknown 
classifier precision classification rate 
possible classifier recognize executions incorrectly yielding maximum precision zero classification rate 
note classification rate improves approaches classifier precision improves approaches 
technique requires definition similarity function sim 
sim inputs models compared 
developed definition sim space trial error 
discovered agglomerative clustering binary metric hamming distance performed 
sim manipulates models permanently alter 
sim converts transition probability binary value threshold 
best empirical results transition probabilities method calls effective threshold calculating hamming distance 
sim follows steps 
set entries branch transitions keeping method transitions 
set non zero entries 
calculate binary matrix difference sim ij ij final model clusters classifier defined models reconstructed event transition profile information populate transition probabilities 
experience complex representations better predictors behavior models clustering 
study batch learning goal study evaluate technique training classifiers batch learning 
selected versions space repeated process times 
select random training sets sizes 

build classifier training set 

evaluate classifiers 
summarizes results classifiers evaluated 
graph horizontal axis represents size training set vertical axis represents classifier precision 
graph box plot summarizes distribution results classifiers built training set size 
top bottom box represent third quartiles respectively additional horizontal line box locates median 
instance training set size median quartile third quartile 
whiskers box mark extent iqr iqr inter quartile range vertical dimension box 
test comparative passive variables training set size performed jim classifier precision size classifier precision batch learning training set size training number standard confidence set size classifiers mean deviation interval mean study classifier precision batch learning 
training number standard confidence set size classifiers mean deviation interval mean study classification rate 
page individual points whiskers shown outliers 
trend line fit medians shown graph quadratic coefficient determination 
table summarizes parametric statistics 
training set size listed left column table shows number classifiers mean standard deviation confidence interval mean 
size training set increases classifier precision improves size mean 
mean represents unknown test cases 
likewise standard deviation represents test cases 
quadratic trend line decreasing variation distribution classifier precision values increasing training set size suggest rate improvement continue decrease 
result property space distribution behaviors test suite 
results indicate classifier model able learn continuously improve data albeit slowing rate 
page table summarizes parametric statistics classification rate 
means uniformly high 
possible larger training set sizes reveal trend classification rate current high value room improvement 
mean value training set size represents misclassified behaviors 
test comparative active variables training set size performed jim classifier precision size classifier precision bootstrapping training set size training number standard set size classifiers mean deviation interval mean study classifier precision bootstrapping 
training number standard confidence set size classifiers mean deviation interval mean study classification rate 
page study bootstrapping classifiers goal second study evaluate application bootstrapping refining classifiers built technique 
order compare results study chose approach bootstrapping gives classifier new executions number unknown executions reaches threshold 
study set threshold 
labeled executions database lookup added training set classifier 
retrained classifier augmented set training instances repeated search unknown executions 
training set size increments parallel study 
instance study exact initial training set size study 
summarizes results classifiers evaluated graph table similar 
variation distribution classifier precision values decreases increasing training set size 
classifier precision approaches training set size mean represents unknown executions page 
quadratic trend line fit medians graph asymptotic classifier precision 
result property space distribution behaviors test suite 
results indicate study classifier model able learn continuously improve data albeit slowing rate 
table summarizes parametric statistics classification rate 
study means uniformly high 
possible larger training set sizes reveal trend classification rate current high value room improvement 
mean value training set size represents wrongly classified behaviors 
mean value slightly study comparison appropriate small size training set 
study batching vs bootstrapping goal third study compare rates growth classifier precision batch learning bootstrapping 
comparison motivates scenario 
comparison results study study shown 
dotted curve shows means study solid curve shows means study 
sets classifiers initialized training set size 
training set size increases gain classifier precision bootstrapping batch learning 
example consider size difference executions 
imagine developer dev scenario space built initial classifier test cases test plan 
additional investment evaluations executions giving training set size classifier study yields average unknown executions 
corresponding classifier study yields average unknown executions 
benefit application bootstrapping batch learning classified executions investment evaluating executions 
graph clear rate improvement continues increase training set size 
second economic benefit dev estimation risks involved releasing current test plan 
simply technique build classifier test plan measuring rate unknown executions produces additional test data dev rate quality test plan 
instance fixed time new test data produce unknown executions dev confidence test plan 
hand high rate detection unknown behaviors expressed classifier precision signals risk deployment 
classifier precision batch learning vs bootstrapping training set size study comparison learning techniques 

discussion fu ture technique automated modeling classification software behaviors equivalence markov models event transition profiles program executions 
application technique efficiently refines classifiers bootstrapping illustrated scenario application reduce costs help quantify risks software testing development deployment 
performed empirical studies validate technique application support scenario 
threats validity results 
threats arise fifteen versions medium sized program finite set test cases 
space commercial program versions contain actual faults development 
furthermore specific structure space may uniquely suited technique 
empirical studies fifteen versions space demonstrated application technique effective building training behavior classifiers space 
suggests number research questions additional applications 
systematically explored feature set investigate class features measuring event transitions 
prepares investigate individual features may exhibit markov property variable definition pairs 
investigate predictive power higher order event transitions 
case evaluate costs trade offs involved leveraging explored feature modeling behaviors 
additional features explored examine combinations features affect predictive power generated models 
second discovered agglomerative hierarchical clustering effective technique building classifiers 
investigate additional clustering algorithms similarity metrics 
evaluate formed cluster map specific sub behaviors guide refining stopping criteria clustering 
third empirical studies demonstrate effectiveness behavior labels pass fail saw classifiers behaviors composed models 
suggests may able automatically identify fine grained behaviors including sub behaviors inside individual modules 
interested relationship markov models specific behaviors representation requirements specifications program 
relation may lead techniques evaluating quality test plan tools aid reverse engineering 
fourth empirical studies show subject bootstrapping improves rate classifier learns behaviors 
investigate machine learning techniques possible application training behavior classifiers 
particular interest determining best set event transitions colleagues suggest best set features train classifiers 
examine techniques scale large programs 
fifth empirical studies show effectiveness application classifying behavior subject 
need determine application perform programs 
formulate explore additional applications techniques detection behavioral profiles deployed software anomaly intrusion detection testing non testable programs 
explore ways provide programs self aware behaviors having access models behavior 
plan explore hidden markov models hmms simplicial mixtures markov models extend behavior modeling technique 
hidden markov model state variable markov chain assumed unobservable measured directly 
time instant hidden state emits observation variable measured 
hmm specifies statistical relationship hidden state observation addition usual transition probabilities hidden state 
parameters model learned data powerful inference techniques viterbi algorithm estimate sequence hidden states sequence observations 
learning hmm case uses expectation maximization technique complex standard parameter estimation markov chain 
consequence widespread automatic speech recognition established body practice training hmms leveraged application 
hmms interesting perspectives 
describe complex probability distributions simple markov chains 
branch transitions taken states markov chain statistical distribution follows standard secondorder dependencies 
transitions taken observations hmm secondorder hidden state dependency marginalization hidden state induces complex distributions branches 
particular branch distribution obey markov property 
context hidden states correspond higher level categories transitions 
second potential benefit hmms ability couple multiple aspects program execution statistical model 
example advanced hmm models factorial hmms input output hmms conditional random fields support complex coupling execution events associated data program inputs outcomes 
advanced tools may enable powerful models program behaviors 
simplicial mixtures markov models generalization basic markov chains demonstrated ability capture common behavioral patterns event streams 
data program executions event streams real possibility adding technique family statistical methods 
supported part national science foundation awards ccr ccr ccr eia georgia tech state georgia georgia tech mission office naval research national defense science engineering graduate fel 
william ribarsky provided key insights support 
alberto frankl filip provided space test cases 
gregg rothermel provided additional test cases advice experimental protocols 

ammons bodik larus 
mining specifications 
proceedings acm sigplan sigact symposium principles programming languages popl pages january 
aristotle research group 
aristotle software engineering tools 
www cc gatech edu aristotle 
booch rumbaugh jacobson 
unified modeling language user guide 
addison wesley boston 
ernst 
finding latent code errors machine learning program executions 
proceedings th international conference software engineering 
cohn atlas ladner 
improving generalization active learning 
machine learning 
cook wolf 
automating process discovery event data analysis 
proceedings th international conference software engineering icse pages january 
dickinson leon podgurski 
finding failures cluster analysis execution profiles 
proceedings rd international conference software engineering icse pages may 
dietterich 
machine learning sequential data review 
caelli editor structural syntactic statistical pattern recognition volume lecture notes computer science pages 
springer verlag 
duda hart stork 
pattern classification 
john wiley sons new york 
girolami 
simplicial mixtures markov chains distributed modelling dynamic user profiles 
thrun saul sch lkopf editors advances neural information processing systems 
mit press cambridge ma 
gross mcmaster porter votta 
proactive system maintenance software telemetry 
proceedings st international conference remote analysis measurement software systems pages may 
harder ernst 
improving test suites operational abstraction 
proceedings rd international conference software engineering icse pages may 
harrold rothermel wu yi 
empirical investigation relationship fault revealing test behavior differences program spectra 
journal software testing verifications reliability september 
ilgun kemmerer porras 
state transition analysis rule intrusion detection approach 
software engineering 
jha tan maxion 
markov chains classifiers intrusion detection 
proceedings th ieee computer security foundations workshop csfw pages june 

behavior models specifying user expectations 
prentice hall englewood cliffs new jersey 
mitchell 
machine learning 
mcgraw hill boston 
munson 
software reliability function user execution patterns 
proceedings second annual hawaii international conference system sciences january 
musa 
software reliability engineering reliable software faster development testing 
mcgraw hill new york 
podgurski leon francis sun wang 
automated support classifying software failure reports 
proceedings rd international conference software engineering icse pages may 
linger 
cleanroom software engineering technology process 
addison wesley reading mass 
rabiner juang 
fundamentals speech recognition 
prentice hall new jersey 
reps ball das larus 
program profiling software maintenance applications year problem 
acm software engineering notes november 
whittaker 
markov analysis software specifications 
acm transactions software engineering methodology january 
