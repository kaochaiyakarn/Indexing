ranking interesting subspaces clustering high dimensional data karin hans peter kriegel peer kr ger stefanie institute computer science university munich 
munich germany kriegel dbs informatik uni muenchen de 
application domains life sciences molecular biology produce tremendous amount data longer managed help efficient effective data mining methods 
primary data mining tasks clustering 
traditional clustering algorithms fail detect meaningful clusters high dimensional inherently sparse feature space real world data sets 
data sets contain clusters hidden various subspaces original feature space 
pre processing step traditional clustering algorithms detects interesting subspaces high dimensional data containing clusters 
purpose define quality criterion interestingness subspace propose efficient algorithm called ris ranking subspaces examine subspaces 
broad evaluation synthetic real world data sets empirically shows ris suitable find relevant subspaces large high dimensional sparse data rank accordingly 
tremendous amount data produced nowadays various application domains molecular biology fully exploited efficient effective data mining tools 
primary data mining tasks clustering task partitioning objects data set distinct groups clusters objects cluster similar objects distinct clusters 
considerable done area clustering 
clustering real world data sets raises problems data space usually high dimensional feature space 
prominent example application cluster analysis gene expression data 
depending goal application dimensionality feature space clustering supported part german education science research technology bmbf bioinformatics functional analysis mammalian genomes project part german genome analysis network 
genes range clustering samples 
general common clustering algorithms fail generate meaningful results inherent sparsity data space 
high dimensional feature spaces data cluster anymore 
usually clusters lower dimensional subspaces 
addition objects clustered differently varying subspaces objects may grouped different objects subspaces vary 
gene expression data prominent example 
clustering genes detect regulated genes cope problem usually regulation genes detected subsets samples attributes 
words different subsets samples responsible different regulations genes 
clustering samples situation worse 
different phenotypes hidden varying subsets genes samples usually clustered differently various phenotypes varying subspaces 
related common approach cope curse dimensionality data mining tasks dimensionality reduction methods 
general methods map feature space lower dimensional subspace relevant attributes principal component analysis pca singular value decomposition svd 
transformed attributes intuitive meaning resulting clusters hard interpret 
cases dimensionality reduction yield desired results presents example pca reduce dimensionality 
addition dimensionality reduction techniques data clustered particular subspace 
information objects clustered differently varying subspaces lost 
case common feature selection methods 
second approach coping clustering high dimensional data projected clustering aims computing pairs ci si ci set objects representing th cluster si set attributes spanning subspace ci exists optimizes clustering criterion user defined integer 
representative algorithms include means related proclus orclus density approach 
projected clustering approach flexible dimensionality reduction suffers fact information objects clustered differently varying subspaces lost 
illustrates problem feature space attributes subspace ab objects cluster objects subspace cd cluster objects 
information cluster subspace ab subspace cd lost 
informative approach clustering high dimensional data subspace clustering task automatically identifying general subspaces high dimensional data space allow better clustering data objects original space 
approaches subspace clustering clique grid algorithm apriori method fig 

drawbacks existing approaches see text explanation 
recursively navigate set possible subspaces bottom way 
dataspace partitioned axis parallel grid equi sized blocks width called units 
units densities exceed threshold retained 
input parameters clique 
cluster defined maximal set connected dense units 
successive modifications clique include enclus mafia 
information gain approaches sub optimal 
provide clusters complete partitionings subspaces get information subspaces dataset clusters best 
drawback methods caused grids 
general grid approaches heavily depend positioning grids 
clusters may missed inadequately oriented shaped 
illustrates problem clique grid dense cluster 
hand cell objects lower right corner just axis reported cluster 
approach called doc proposes mathematical formulation notion optimal projected cluster regarding density points subspaces 
doc grid density subspaces measured hypercubes fixed width similar problems 
cluster bigger hypercube objects may missed 
furthermore distribution inside hypercube considered need necessarily contain objects cluster 
contributions propose new approach eliminates problems mentioned enables user gain clustering information contained high dimensional data 
preprocessing step selects interesting subspaces density connected clustering notion 
able detect subspaces containing clusters arbitrary size shape 
define interestingness subspaces section provide quality criterion rank subspaces interestingness 
traditional clustering algorithm user accustomed applied subspaces 
section efficient density algorithm called ris ranking subspaces computing subspaces 
broad experimental evaluation ris artificial gene expression data section 
section draws 
ranking interesting subspaces preliminary definitions db data set objects dimensionality assume db database feature vectors db ir 
feature vectors normalized values values fall fixed ir 
ad set attributes ai db 
subset called subspace 
projection object subspace denoted 
distance function denoted dist assume dist lp norms 
neighborhood object defined db dist 
neighborhood object subspace denoted db dist 
interestingness subspace approach rate interestingness subspaces notion clusters 
notion common approach clustering various clustering algorithms dbscan optics :10.1.1.121.9220
methods search regions high density feature space separated regions lower density 
adopt notion define dense regions means core objects definition 
core object ir minpts 
object called core object minpts 
core object property key concept formal density connected clustering notion :10.1.1.121.9220
property deciding interestingness subspace 
obviously subspace contains core object contains dense region cluster contains relevant information 
observation 
number core objects dataset db wrt 
minpts proportional number different clusters db size clusters db density clusters db 
observation rate interestingness subspaces 
simply counting core objects subspace delivers information 
subspaces contain number core objects quality may differ lot 
dense regions contain objects core objects lie neighborhood core object vital part dense region 
interesting core objects subspace contains objects lie neighborhood core objects 
variable count denotes sum points lying neighborhood core objects subspace number core objects denoted core 
measure interestingness subspace count value rank subspaces quality value problems 
naturally dimension number expected objects neighborhood object decreases naive quality value favors lower dimensional subspaces higher dimensional ones 
overcome problem introduce scaling coefficient takes dimensionality subspace account 
take ratio count value count value get data objects uniformly distributed purpose compute volume dimensional neighborhood denoted vol number objects lying vol assuming uniform distribution 
definition 
quality subspace measuring interestingness defined count quality dist norm vol hypercube computed vol dist euclidian distance norm vol hypersphere computed vol 
second problem phenomenon high dimensional spaces points located boundary data space 
neighborhoods objects smaller exceed borders data space 
authors show average volume intersection data space hypersphere radius expressed integral piecewise defined function integrated possible positions neighborhood core objects 
implementation choose complex heuristics eliminate effect periodical extensions data space cf 
section details 
arbitrary subspaces ir quality criterion complementary effects observation observation 
inequalities hold 
core core count count 

core core count count quality quality 
fig 

visualisation lemma minpts feature space 
observation states navigating subspaces bottom certain point core objects loose core object property due addition irrelevant features quality decreases 
hand long case features relevant cluster quality increases 
general idea finding interesting subspaces straightforward approach examine possible subspaces bottom 
problem number subspaces basically subspaces contain core object dropped contain clusters 
furthermore core object condition decreasing strictly monotonic lemma 
monotonicity core object condition db attribute subset 
core object core object subspace wrt 
minpts formally minpts minpts 
proof 
holds dist ai ai ai ai ai ai dist follows minpts lemma visualized 
reverse lemma illustrated states object core object core object super space sections detail property helps eliminate lot subspaces process generating relevant subspaces bottomup process 
ris eps minpts subspaces emptyset size object get object subspaces add subspaces prune subspaces sort ris implementation ris algorithm fig 

ris algorithm 
set objects db density parameters minpts ris finds interesting subspaces presents user ordered relevance 
object ris computes set relevant subspaces 
sets merged 
pruning sorting procedure applied resulting set subspaces 
pseudocode algorithm ris 
object db subspaces core object condition holds computed 
step described detail section 
note algorithm applied sample db performance reasons cf 
section 
detected subspace statistical data accumulated 
detected subspaces pruned certain criteria 
section criteria discussed 
subspaces sorted comprehensible user presentation 
clustering subspaces done clustering algorithm 
efficient generation subspaces object db method finds subspaces core object condition holds wrt 
minpts 
formally computes set ko minpts 
problem finding set ko equivalent problem determining frequent itemsets context mining association rules norm distance function computed efficiently db transaction tx defined ai tx ai ai 

note norm serious constraint 
difference norm may find additional core objects additional subspaces 
additional subspaces get low quality values anyway 
lemma 
ko supp db minp ts db supp db tx db db proof 
minpts db distl minpts db 
ai ai ai minpts db tx minpts supp db minpts db method extends apriori algorithm accumulating statistical information measuring subspace quality monotonicity core object condition cf 
lemma 
mentioned extending data space periodically ensure neighborhoods size 
done easily changing way transactions defined 
checking ai ai check ai ai ai ai 
pruning subspaces interested subspaces provide information perform downward pruning step eliminate redundant subspaces exists dimensional subspace higher quality dimensional subspace delete second pruning assume data set dimensional subspace reflects clustering special data set best possible way 
quality value quality values dimensional subspaces 
tm high 
hand combine dimensional subspaces 
tm dimensional subspace lower quality quality resulting dimensional subspace 
know reflect clustering best possible way interested dimensional subspace 
heuristic upward pruning eliminates subspaces 
dimensional attribute space sk dim set dimensional subspaces count mean count value sk standard deviation 
maxdiff max count count sk maximum deviation count values sk mean count value 
called bias value computed follows bias maxdiff bias value falls certain threshhold prune dimensional subspace experimental evaluations indicate value bias criterion 
determination density parameters heuristic method experimentally shown sufficient suggests minpts ln size database 
picked depending value minpts 
simple heuristics determine cluster database minpts 
know subspaces clusters determine find single subspace particular clustering 
quite contrary want choose parameters ris detects subspaces clusters different density different dimensionality 
determine upper bound value minpts 
take uniform distribution worst case neighborhood object contain minpts objects full dimensional space 
objects core objects 
case norm upper bound computed follows vol minp ts dim minpts dim knowledge dimensionality subspaces want find decrease upper bound setting dim highest dimension subspace 
upper bound rough 
provides indication choice 
empirically turned upperbound reasonable choice 
experiments synthetic data sets show suggested criteria choice density parameters sufficient detect relevant subspaces containing clusters 
performance evaluation tested ris synthetic real world data set 
experiments run workstation ghz cpu gb ram 
synthetic data sets generated self implemented data generator 
permits control size structure generated data sets parameters number dimensionality subspace clusters dimensionality feature space density parameters data set cluster 
subspace contains cluster average density data points cluster larger density points belonging cluster subspace 
addition ensured synthetically generated data sets clustered full dimensional space 
real world data set studied gene expression data set spellman analyzing yeast mitotic cell cycle 
chose data cdc mutant eliminated genes having missing attribute values 
resulting test data set consists approximately genes expressed different time spots 
subsequent clustering data sets detected subspaces performed experiment mentioned algorithm optics validate interestingness subspaces computed ris 
effectiveness evaluation synthetic data sets 
evaluated effectiveness ris synthetic data sets varying dimensionality 
data sets contained overlapping clusters varying subspaces 
experiments ris detected correct subspaces clusters exist assigned highest quality values 
higher dimensional subspaces generated removed upward pruning procedure 
gene expression data 
applied ris described gene expression data set 
clustering optics top ranked subspaces provided clusters 
subspace spanned time spots contains biologically relevant clusters genes playing central role mitosis example cluster consists genes cdc starting point mitosis known active role mitosis various transcription factors cha elp necessary cell cycle 
cluster contains gene ste identified important transcription factor regulation cell cycle 
addition genes cdc emp possible ste sites regulated ste cluster 
cluster completed transcription factors ssl 
cluster consists genes known play role cell cycle dom cpa mip 
second subspace spanned time spots consists clusters similar characteristics subspace 
addition fourth cluster contains related genes similar functions regulated 
example genes mitochondrial large ribosomal subunits genes ubc ubc subunits certain genes snf vps direct interaction partners genes code mitochondrial proteins phb cyc atp 
indicates higher activity time spots explained higher demand biological energy cell cycle energy metabolism located 
summary ris detects subspaces containing biologically relevant regulations 
efficiency evaluation results efficiency evaluation depicted 
evaluation synthetic data sets 
experiments run minpts ln choosen suggested section 
run times seconds 
ris scales dimensionality relevant subspaces 
increasing dimensionality relevant subspaces runtime ris grows linear factor 
hand scalability ris size analysis clusters partly saccharomyces genome database sgd available genome www stanford edu saccharomyces fig 

efficiency evaluation 
dimensionality input data set linear 
increasing runtime ris grows quadratic factor large respectively 
reason scalability vs size ris performs multiple range queries index support due fact neighborhoods points arbitrary subspaces computed 
index structure efficiently support range queries arbitrary subspaces 
observed scalability respect explained apriori navigation search space subspaces 
speed large data sets runtime ris high especially large data sets applied random sampling accelerate algorithm 
shows large data set data objects sampling yields speed 
data set contained overlapping dimensional subspace clusters containing approximately points 
sample points ris problem detect subspaces clusters 
sample sizes subspaces far highest quality values 
experiments empirically show random sampling successfully applied ris order speed runtime algorithm paying minimum loss quality 
introduced preprocessing step clustering high dimensional data 
quality criterion interestingness subspace efficient algorithm called ris compute interesting subspaces containing dense regions arbitrary shape size 
furthermore wellestablished technique random sampling applied ris order speed runtime algorithm significantly minimum loss quality 
effectiveness evaluation shows ris succesfully applied high dimensional real world data gene expression data order find regulated genes 

agrawal gehrke gunopulos raghavan automatic subspace clustering high dimensional data data mining applications 
proc 
acm sigmod int 
conf 
management data seattle wa 

aggarwal procopiuc fast algorithms projected clustering 
proc 
acm sigmod int 
conf 
management data philadelphia pa 

aggarwal yu finding generalized projected clusters high dimensional space 
proc 
acm sigmod int 
conf 
management data dallas tx 

hinneburg keim optimal grid clustering breaking curse dimensionality high dimensional clustering 
proc 
th int 
conf 
large databases edinburgh scotland 

cheng fu zhang entropy subspace clustering mining numerical data 
proc 
acm sigkdd int 
conf 
knowledge discovery databases san diego fl 

choudhary mafia scalable subspace clustering large data sets 
tech 
report 
tr center parallel distributed computing dept electrical computer engineering northwestern university 
procopiuc jones agarwal murali monte carlo algorithm fast projective clustering 
proc 
acm sigmod int 
conf 
management data madison wi 

ester kriegel sander xu density algorithm discovering clusters large spatial databases noise 
proc 
nd int 
conf 
knowledge discovery data mining portland 

hinneburg keim efficient approach clustering large multimedia databases noise 
proc 
th int 
conf 
knowledge discovery data mining new york city ny 

ankerst breunig kriegel sander optics ordering points identify clustering structure 
proc 
acm sigmod int 
conf 
management data philadelphia pa 

berchtold hm keim kriegel cost model nearest neighbor search high dimensional data space 
proc 
acm pods symp 
principles database systems tucson az 

agrawal srikant fast algorithms mining association rules 
proc 
acm sigmod int 
conf 
management data minneapolis mn 

spellman sherlock zhang iyer anders eisen brown botstein comprehensive identification cell cycle regulated genes yeast saccharomyces cerevisiae microarray hybridization 
molecular cell 
