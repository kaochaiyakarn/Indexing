automatic reassembly document fragments context statistical models shanmugasundaram isis poly edu reassembly fragmented objects collection randomly mixed fragments common problem classical forensics 
address digital forensic equivalent reassembly document fragments statistical modelling tools applied data compression 
propose general process model automatically analyzing collection fragments reconstruct original document placing fragments proper order 
probabilities assigned likelihood fragments adjacent original context modelling techniques data compression 
problem finding optimal ordering shown equivalent finding maximum weight hamiltonian path complete graph 
heuristics designed explored implementation results provided demonstrate validity proposed technique 

reassembly fragments objects collection randomly mixed fragments problem arises applied disciplines forensics archaeology failure analysis 
problem studied disciplines tools developed automate tedious reassembly process 
digital forensic equivalent problem call reassembling scattered documents explored 
digital evidence nature easily scattered forensic analyst may come scattered evidence variety situations 
forensic analyst comes problem recovering deleted files faces difficult task reassembling file fragments collection randomly scattered data blocks storage media 
especially true fat fat filesystems memon memon poly edu department computer information science polytechnic university brooklyn ny due popularity windows operating system widely file systems personal computers 
furthermore due ubiquitous presence windows easier implementation considerations fat file systems adopted consumer storage media devices compact flash cards digital cameras usb mini storage devices 
fat filesystem efficient maintaining continuity data blocks disk 
performance degradation due file fragmentation common problem fat systems 
due fragmentation file stored data blocks scattered disk 
adequate file table information difficult put fragments back original order 
critical file table information lost overwritten new entries 
fact widely disk forensics tools tct dd utility kit recover data blocks deleted files automatically 
data blocks contiguous tools reassemble blocks correct order reproduce original file proper file table entries 
job reassembling fragments usually tedious manual job carried forensic analyst 
situation forensic analyst come scattered evidence swap file 
system swap file critical areas lot useful forensic information gathered 
swap file contains critical information latest events occurred computer 
reconstructing contents swap file vital forensic standpoint 
order achieve better performance operating systems maintain swap file state addressing information page tables stored volatile memory 
computers secured evidential purposes simply sent forensic lab 
unfortunately contents volatile memory usually lost recovery evidence collection 
addressing information page table dif rebuild contents swap file 
forensic analyst left collection randomly scattered pages memory 
popular naive approach hiding evidence store slack space filesystem 
files assigned certain number disk blocks storage 
files fit exactly allocated blocks 
cases files portion block 
unused space block known slack space 
modifying contents slack space affect integrity data stored filesystem read operation read data slack space 
criminal modify file hiding program choose blocks files hidden sequence numbers generated password 
knowing password reconstruct original document forensic analyst left randomly mixed fragments document need reassembled 
ubiquitous networking growing adoption peer peer systems give easy access computers world 
peerto peer systems enable users store data network computers easy reliable access anytime 
freenet gnutella better known systems millions users world oceanstore chord pastry development research laboratories 
systems designed provide reliable distributed anonymous storage networks 
criminal systems hide software tools documents useful just easily user save file 
peer peer systems associate unique key assigned user generated automatically document store 
person split document fragments store fragment peer peer system sequence secret phrases keys easily splice fragments knowing proper sequence secret phrases 
instance freenet assign fragment unique url 
urls user friendly keywords easy recall proper sequence retrieve splice fragments 
difficult reconstruct original document knowledge proper sequence keywords known 
discussion clear digital evidence easily take variety forms scattered hundreds fragments making reassembly daunting task human analyst 
address problem propose general process model specific solution reassembling scattered evidence 
assuming necessary evidence collected entirely proposed model steps 
preprocessing encrypting compressing digital evidence removes structural details assist analyst reassembling evidence 
preprocessing evidence transformed original form 
cryptographic schemes derive keys user passwords 
users tend choose dictionary passwords quite feasible attack password obtain key regardless size key 
brute force attacks sophisticated cryptographic algorithms des shown feasible 
note forensic analyst may constrained time making cryptanalysis feasible process 

collating consider reassembling single document reality evidence usually collection mixed fragments documents different types 
reassemble evidence efficiently fragments belong document grouped 
hierarchical approach collating effectively group similar fragments 
fragments initially grouped superficial characteristics binary plain text document sophisticated text categorization techniques special knowledge fragments refine results 

reassembling final step process reassemble document original form provide information original form reduce forensic analyst 
ideally obtain proper sequence fragments resembles original document 
process identifies small number potential orderings forensic analyst derive proper ordering result considerable savings time effort analyst 
focus final step reassembling document preprocessed fragments document 
rest organized follows section describe problem formally introduce general technique document reassembly 
section presents specific realization general technique initial experimental results conclude section discussion 

fragment reassembly problem section formulate document fragment reassembly problem rigorous manner describe general approach solution problem 

statement problem problem reassembly scattered document stated follows suppose set 
fragments document compute permutation 
denotes concatenation operator 
words determine order fragments ai need concatenated yield original document assume fragments recovered loss data concatenation fragments proper order yields original document intact 
note order determine correct fragment reordering need identify fragment pairs adjacent original document 
simple technique dictionary underlying language document 
approach fragment aj considered candidate fragment follow ai word straddles boundaries ai aj dictionary 
example suppose fragment ai ends phrase quick bro fragment aj ak phrase wn fox jumps lazy dog respectively 
clear aj better candidate follow ai ak word straddles boundary fragments ai aj forms dictionary word word straddles boundary fragments ai ak 
dictionary approach language specific feasible variety documents forensic analyst may come field 
furthermore non textual files executables dictionary may readily available easy construct 
dictionary matches forensic analyst select 
quantify likelihood adjacency linguist may assign candidate probabilities representing probability fragment aj follows ai syntactic semantic analysis pair fragments 
probabilities assigned permutation fragments leads correct reassembly possible permutations maximize product candidate probabilities adjacent fragments 
observation gives technique identify correct reassembly high probability 
formally want compute permutation value maximized possible permutations degree permutation leads correct reconstruction document 
note maximizing product equation equivalent maximizing sum log problem finding permutation maximizes sum equation abstracted graph problem 
take set candidate probabilities ci form adjacency matrix complete weighted graph vertices vertex represents fragment edge weights quantify candidate probability corresponding fragments adjacent 
proper sequence path graph traverses nodes maximizes sum candidate probabilities path 
problem finding path equivalent finding maximum weight hamiltonian path complete graph see optimum solution problem turns intractable 
heuristics known literature employ heuristic discussed section 

complete graph fragments hamiltonian path maximizes weight noted optimal solution may necessarily result reconstruction original document 
candidate probabilities properly assigned optimal solution large number fragments right place 
better automated document reassembly tool forensic analyst small number reorderings correct reordering manually arrived 
question remains assign candidate probabilities pair fragments adjacent efficient meaningful manner 
address question subsection context statistical models 

context statistical models model assigning candidate probabilities pair fragments needs independent language format 
data compression literature explores powerful statistical modelling techniques build data models effectively compress data 
modern data compression paradigm divides compression process components modelling coding 
modelling process constructing statistical representations input data coding process mapping information generated statistical representations bit sequences produce compressed data 
modelling represents critical step data compression system years variety modelling techniques devised 
modelling techniques essentially build statistical model input predict occurrence probabilities symbols 
specifically realization 
xm finite sequence random variables 
xm discrete alphabet model essentially assigns conditional probability mass function current symbol event previously processed symbols 
line applications sequence 
xm processed sequential manner symbol xi encoded immediately symbol xi 
case need estimate distributions xi xi 
xi xi average number bits needed encode realization 
xm online bounded xi 
xi 
shannon conditional entropy function 
coding techniques achieve rates close optimal known 
conditional distribution xi equation best estimated principle entire past sequence xj 
practice knowledge statistics source sequence complete 
practical compression techniques usually impose structural limitations source sequence arrive model realistically represent sequence 
particularly popular model widely context model 
context model assumes distribution current symbol depends limited context occurs 
particular associated context model finite set contexts conditioning events context determining rule function maps symbols source sequence context symbol xi said appear context th order context model uses previous symbols order estimate probability symbol 
context model may blended model incorporates probability estimation different orders 
usually number distinct contexts size set smaller length source sequence 
associated context probability distribution encode pixel xj context pdf estimated maintaining counts symbol occurrences context estimating parameters assumed pdf 
context models especially intuitive text compression probability occurrence letter clearly depends context immediately preceding letters 
example probability symbol document written english may 
preceding symbol probability go follows english words 
idea context consisting previous symbols intuitive models representing natural languages 
empirical results show context modelling provides better models compressing natural language variety data formats including images executables 

approach pieces required describe general approach reassembling document fragments 
build order context model document accumulating context models individual fragments single model 
model ordered pair fragments consider sliding window size place window fragment slide window position time fragment position estimating probability upcoming character characters window current context context model obtained total pool fragments purpose probability estimation 
see continuing process subsequent characters gives candidate probability fragment pair equation 
repeating process fragments results complete graph edges quantify candidate probabilities adjacency corresponding nodes original document 
heuristic solution compute small number near optimal reorderings fragments 
actual re ordering contained set worst easily derived set forensic analyst 
note analyst identify subsequence reorderings correct combine fragments belong subsequence form unit fragment repeat process 
iteration analyst successfully find correct subsequences merged process eventually converge original document 
fragment fragment sliding window size 
sliding window size 
implementation experiments section describe implementation approach employs known context modelling technique known prediction partial matching ppm build context model compute candidate probabilities possible adjacency document fragments 
alpha beta pruning heuristic solve hamiltonian path problem compute small set nearoptimal candidate reorderings 
experimental results different types data demonstrate validity approach 

prediction partial matching prediction partial matching ppm finite order context modelling technique introduced cleary witten benchmark lossless data compression techniques 
ppm employs suite fixed order context models predetermined maximum predict upcoming characters 
order context model statistics kept symbols followed length subsequence observed far input number times occurred 
prediction probabilities computed statistics way model order order separate predicted probability distribution obtained effectively combined single 
largest order model default initially predict symbol 
novel symbol encountered escape symbol returned smaller model prediction 
process continues fixed order models predicts upcoming symbol 
ensure process terminates model assumed order symbols coding alphabet 
note don need order model knows entire alphabet encounter novel symbol 
mechanism effectively blends prediction probabilities different order models proportion depends values escape probabilities 
model fragment document individually processed ppm resulting statistics combined form single model 
assuming data loss evidence collection believe resulting model statistical representation original document 
suppose order ppm model sliding window size predict upcoming symbol discussed section 
prediction probabilities model combined single probability method described 
resulting probability candidate probability adjacency pair fragments 

tree pruning discussed section problem finding optimal solution hamiltonian path intractable 
assuming know fragment document represent paths underlying graph tree see 
assumption identify fragment practical files headers uniquely identify filetype 
finding optimal solution tree simply means examining path tree finding maximizes sum candidate probabilities path 
see tree expands exponentially number levels increase 
case number levels equals number fragments run hundreds 
approach problem tractable prune tree stage expansion removing paths appear promising 
way look prune tree level keeping promising paths obtain set near optimal heuristic solutions 
pruning approach adopt uses approach adopted pruning game theory 
pruning try avoid examining paths believe may contribute solution 
naive approach pruning tree choose node maximum candidate probability level 
greedy method lead poor solutions 
greedy method extended look current level levels deep choose node cur 
tree fragments path pruned rent level maximizes sum candidate probabilities 
addition choosing single node level limits results single sequence choose best matches level resulting best sequences 
employed tree pruning approach implementation report results obtained 

experiments results section presents experimental results discussion results 
collection documents experiments type samples log files log history files various users source code java lisp source code executables executable object code binary files ms office documents pdf unformatted text unformatted plain text chat transcripts random text encrypted compressed files table 
documents experiments document collection randomly split pieces context model built document 
model pruning identify promising reorderings 
accuracy reassembly measured number adjacent fragments reassembled documents fact adjacent original document 
presents average ac reassembly process document type presents average compression ratio type indicator structure documents 
reassembled fragments logs source code binary code binary docs raw text encrypt compress 
average reassembly fragments single pass log files operating system related files reassembled accurately structure data repeated predictable manner 
likewise source code standard keywords broken keywords matching fragment easily 
binary code binary documents predictable patterns binary files file holes large regions filled fragments split file holes multiple candidates adjacent fragment candidate probabilities uniformly distributed 
case breaking ties arbitrarily fragments chosen increasing value helps choose fragment competing fragments looking path 
addition file holes binary documents compressed regions inline images affects accurate reassembly 
unformatted plain text chat transcripts proved difficult reassemble transcripts contain unpredictable words fragments split large portions empty spaces 
shows average compression ratio sample document types compare clear structure document better accuracy reassembly 
table presents accurate reassembly top candidate reorderings 
sight numbers table may appear low 
noted forensic analyst examine top potential orderings system identify proper subsequences subse compression ratio logs source code binary code binary docs raw text encrypt compress 
compression ratio various document types type top top top top log files executables binary files unformatted table 
reassembled document fragments top candidates single pass quences correspond proper reassembly 
fragments subsequences recombined unit fragments entire reassembly process reiterated 
iteration process eventually converge proper reordering effort perform entire task manually 
table lists average number iterations required reconstruct various document types 
seen unformatted files binary files iterations sufficient converge correct reordering 
data set fragments file reasonably small effort compared manual analysis 
general smaller order contexts performed various document types 
illustrates optimal context orders log files source code executable files 
increasing size context effect cases 
candidate probabilities distributed properly fragment candidate probability significantly larger rest fragments increasing yields better results 
candidate probabilities uniformly distributed fragment equally prob reassembled fragments type iterations log files source code executables binary files unformatted table 
iterations required reconstruct entire document logs source code binary code context model order 
influence context orders reassembly various document types able candidate adjacent fragment tweaking influence results 
believe preprocessing heuristics vital part process enhance accuracy reassembly 
furthermore domain knowledge binary documents code valid instructions valid tags incorporated model accurately compute candidate probabilities 

digital evidence nature easily scattered forensic analyst may come scattered evidence variety situations 
example forensic analyst comes problem recovering deleted files faces difficult task reassembling file fragments collection randomly scattered data blocks storage media 
introduce general framework reassembling scattered evidence context statistical models 
formulate problem reconstructing reordering fragments graph problem showed computing optimal solution involves solving maximum weight hamiltonian path problem known intractable 
proposed heuristic compute set near optimal solutions 
implemented framework ppm known context modelling technique data compression literature show approach gives promising results 
investigation necessary establish effective preprocessing heuristics various document types 
reassembly process independent document types incorporating meta information syntax language instruction set program certain document type level abstraction help reassemble document accurately 
images implicated criminal investigations types documents currently investigating reassembling various image formats fragments 
planning investigate methods collate fragments documents mixed fragments document types text classification methods 
cleary teahan 
unbounded length context ppm 
computer journal 
cormen leiserson algorithms 
mit press 

www com 
freenet 
org 
gnutella 
gnutella wego com 
chow 
des cracking 
cryptographic hardware embedded systems lncs springer verlag pages 
kit 
www org 
knuth moore 
analysis alpha beta pruning 
artificial intelligence pages 
kubiatowicz bindel 
oceanstore architecture global scale persistent storage 
proceedings ninth international conference architectural support programming languages operating systems 
stolfi 
multi scale re assembly fragmented objects 
proc 
british machine vision conference bmvc 
moffat 
implementing ppm data compression scheme 
ieee transactions communications 
www org 
rissanen 
universal data compression system 
ieee transactions information theory 
rissanen langdon 
arithmetic coding 
ibm res 
dev 
rissanen langdon 
universal modelling coding 
ieee transactions information theory 
rowstron druschel 
pastry scalable distributed object location routing large scale peer peer systems 
ifip acm international conference distributed systems platforms pages 
stoica morris 
chord scalable peer peer lookup service internet applications 
acm sigcomm pages 

tct 
www porcupine org forensics tct html 
