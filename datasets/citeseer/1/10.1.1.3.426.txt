network coding correlated sources tracey ho dard michelle ralf koetter consider ability distributed randomized network coding approach multicast receivers correlated sources network compression may required 
give arbitrarily correlated sources general network upper bounds probability decoding error receiver terms network parameters 
special case slepian wolf source network consisting link source receiver error exponents reduce known error exponents linear slepian wolf coding 
achievable capacity multicast networks independent sources employing network coding 
showed achieve capacity distributed setting randomized linear codes gave error bounds transmission independent linearly correlated sources 
considers linear network coding context distributed source coding problem compression may required transmit information correlated sources network receivers 
example problem 
demonstrate distributed randomized network coding approach adaptation performs compression necessary multicast network generalizing known error exponents linear slepian wolf coding natural way 
specifically arbitrarily correlated discrete memoryless sources general network give error bounds minimum entropy maximum posteriori probability decoding receiver 
special case slepian wolf source network consisting receiver connected directly capacitated link source error exponents reduce corresponding results linear slepian wolf coding 
scenario may considered degenerate case network coding 
approach nodes receiver nodes independently select random linear mappings vectors input bits vectors output bits 
illustration 
receivers need know linear combination source processes incoming signals 
information transmitted receivers sending canonical basis network 
overhead transmitting coefficients decreases increasing length blocks codes network state constant 
tracey ho dard laboratory information decision systems massachusetts institute technology cambridge ma mail trace mit edu michelle data compression laboratory california institute technology pasadena ca mail caltech edu ralf koetter coordinated science laboratory university illinois urbana il mail koetter csl uiuc edu research supported part nsf ccr ccr nsf itr network coding university illinois hewlett packard lee center advanced networking 
rcv rcv rcv fig 

example network correlated sources transmitted distributed randomized network coding 
label link represents capacity link 
rcv rcv fig 

example distributed randomized network coding 
xn vectors source bits multicast receivers matrices matrices random bits 
label link represents signal carried link 
distributed randomized network coding approach effectively removes adds redundancy different parts network depending available capacity 
achieved knowledge source entropy rates interior network nodes 
compression done simultaneously multiple receivers multicast session 
overview brief overview related section 
section ii provide coding network model analyses 
main result section iii give directions section iv 
related ahlswede showed network coding symbol size approaches infinity source multicast infor mation rate approaching smallest minimum cut source receiver 
li showed linear coding finite symbol size sufficient multicast 
koetter dard algebraic framework network coding extended previous results arbitrary networks robust networking proved time invariant solutions min cut max flow bound networks delay cycles :10.1.1.135.6797
ho introduced distributed randomized network coding efficient robust way approach capacity decentralized settings giving error bounds independent linearly correlated sources 
concurrent independent sanders considered single source multicast acyclic delay free graphs giving centralized deterministic randomized polynomialtime algorithms finding network coding solutions subgraph consisting flow solutions receiver 
need vector coding solutions non multicast problems considered lehman lehman dard riis 
ii 
model represent network directed graph 
discrete memoryless random processes observable source nodes receiver nodes 
multicast connection problem transmit source processes receiver nodes 
koetter give algebraic framework network coding considers unit capacity links independent unit entropy rate sources :10.1.1.135.6797
assumed information transmitted vectors bits 
length vectors equal transmissions links assumed synchronized respect symbol timing 
linear coding sufficient multicast 
signal link scalar linear combination finite field incoming links signals observable source processes 
slightly different model lends naturally consideration compressible arbitrarily correlated sources 
network model allows links integer capacities sources integer bit rates 
randomized linear network coding done vectors bits finite field size 
vector coding model vector lengths brought scalar algebraic framework conceptually expanding source multiple sources link multiple links new source link corresponds bit code vectors :10.1.1.135.6797
describe scalar framework analyze operation interior network nodes 
note linear decoding strategies apply consider compressible arbitrarily correlated sources :10.1.1.135.6797
link incident outgoing link node tail incident incoming link head 
call incident outgoing link source node source link incident incoming link receiver node terminal link 
edge carries random process 
path subgraph network consisting sequence links 
ek ei incident incoming link ei node visited 
scalar linear codes signal link linear combination processes xi generated node fig :10.1.1.135.6797

illustration linear coding node 
tail signals incident incoming links delay free case represented equation ai jxi fl jy xi generated head illustrated 
network link delays link assumed unit delay links longer delay modeled links series 
corresponding linear coding equation yt ai fl xi generated head equation random processes network represented algebraically terms delay variable dai jxi xi xi generated head xi td dfl jy yt coefficients ai fl collected matrices ai fl structure constrained network 
acyclic graphs number links lower numbered links upstream higher numbered links matrix upper triangular zeros diagonal 
notation acyclic delay free case df case delay gh submatrix consisting columns corresponding links set matrix ag gives transfer matrix input processes signals link 
iii 
main result consider transmission arbitrarily correlated sources network linear network coding show error bounds probability successful non linear decoding receiver 
analogously slepian wolf consider inverse exists nilpotent 
inverse exists determinant nonzero polynomial problem distributed encoding joint decoding sources output symbols unit time period drawn joint distribution difference problem transmission occurs network intermediate nodes perform linear transformations inputs outputs 
special case network consisting set parallel links reduces original slepian wolf problem 
decoder may minimum entropy maximum probability decoder receiver maps block received signals corresponding minimum entropy maximum probability inputs 
derive error probability terms block length non receiver nodes independently randomly choose vector linear mappings inputs outputs 
theorem bounds probability successful minimum entropy maximum posteriori probability decoding receiver sources output values unit time period drawn joint distribution denote ri bit rate source xi suppose linear coding done vectors nr nr bits source respectively 
minimum cut capacities receiver sources respectively minimum cut capacity receiver sources 
denote maximum source receiver path length 
theorem distributed randomized network coding arbitrarily correlated sources arbitrary network error probability pie exp min px log log exp min px log log exp min px log error exponents log min px log min px log min px log generalize slepian wolf error exponents linear coding min px min px min px ri rate code xi 
proof encoding network represented transfer matrix agt specifying mapping vector source signals vector signals set terminal links incident receiver 
error analysis method types similar 
type vector xi nri distribution defined relative frequencies elements xi joint types px analogously defined 
decoder maps vector received signals vector minimizing px subject agt minimum entropy decoder px px maximum probability decoder px log qn 
consider types errors type decoder correct value outputs wrong value second decoder correct value outputs wrong value third decoder outputs wrong values 
error probability upper bounded sum probabilities types errors pie 
defining sets types xi nri sets sequences tx px px pr tx agt similarly min pr agt px min pr agt px min pr agt probabilities taken realizations network transfer matrix agt corresponding random network code 
probabilities pr agt pr agt pr agt nonzero calculated network bounded terms parameters network show 
apply simple cardinality bounds tx exp nh tx exp nh identity exp px obtain exp min tx px exp exp log log min px px log log min px px log log exponents logs taken base 
minimum entropy decoder px gives exp exp exp min px log log min px log log min px log log 
show bounds hold maximum probability decoder px px 
gives px 
show min px px log min px px log min px log considering possible cases satisfying case log 
px log px log min px log case log 
px log px log px log px log gives px log px log px log min px log similar proof holds 
show min px px log min px px log min px log considering possible cases satisfying case log 
px log px log min px log case log 
px log px log px log px log gives px log px log px log min px log bound probabilities pi terms network parameters mi minimum cut capacity receiver source xi minimum cut capacity receiver sources maximum source receiver path length 
subgraphs graph consisting links downstream sources respectively equal follows algebraic coding model section ii random linear network code arbitrary network link nonzero incoming signal carries zero signal probability nc capacity link 
probability pair distinct values link inputs mapped output link 
pair distinct source values el event corresponding inputs link distinct corresponding values 
event el occurs link source receiver path graph pi equal probability event gi 
graph consisting mi node disjoint paths consisting links unit capacity 
show induction mi pi upper bounded probability event 
graphs gi turn consider particular source receiver path pg distinguish cases case el occur links path pg 
case event occurs probability 
case exists link path pg el occurs 
pr pr case pr case 
pg links pr case forg pr case gi 
show pr case pr gi case induction hypothesis pr pr gi follows 
mi hypothesis true pr case 
mi case removing link leaves effective equivalent graph consisting mi length paths gi graph minimum cut mi 
result follows applying induction hypothesis resulting graphs 
pr gives upper bound probability pi pi mi mi substituting error bounds gives desired results 
iv 
shown distributed randomized network coding approach effectively compresses correlated sources network providing error bounds exponents generalize corresponding results linear slepian wolf coding 
randomized network coding approach carries positive number sources give detailed treatment case sources 
give error bounds terms minimum cut capacities maximum source receiver path length network 
bounds terms network parameters number links upstream receiver particular network topologies obtained similar means 
includes extensions non uniform code distributions possibly chosen adaptively rudimentary coordination optimize different performance goals 
question concerns selective placement randomized coding nodes 
randomized distributed nature approach leads naturally consider applications network security 
ahlswede cai 
li yeung 
network information flow 
ieee transactions information theory 
csiszar 
linear codes sources source networks error exponents universal coding 
ieee transactions information theory 
ho koetter dard karger 
benefits coding routing randomized setting 
proceedings ieee international symposium information theory june 
chou jain 
low complexity algebraic network codes 
proceedings ieee international symposium information theory 
koetter dard 
algebraic approach network coding 
ieee acm transactions networking appear 
lehman lehman 
complexity classification network information flow problems 
symposium discrete algorithms 

li yeung cai 
linear network coding 
ieee transactions information theory 
dard ho karger 
coding networks 
proceedings st annual allerton conference communication control computing october 
riis 
linear versus non linear boolean functions network flow preprint november 
sanders 
polynomial time algorithms network information flow 
th acm symposium parallel algorithms architectures pages 
slepian wolf 
noiseless coding correlated information sources 
ieee transactions information theory 

