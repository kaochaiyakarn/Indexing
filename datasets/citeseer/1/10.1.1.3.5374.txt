ieee transactions image processing vol 
november image denoising scale mixtures gaussians wavelet domain javier portilla martin wainwright eero simoncelli describe method removing noise digital images statistical model coefficients overcomplete multiscale oriented basis 
neighborhoods coefficients adjacent positions scales modeled product independent random variables gaussian vector hidden positive scalar multiplier 
modulates local variance coefficients neighborhood able account empirically observed correlation coefficient amplitudes 
model bayesian squares estimate coefficient reduces weighted average local linear estimates possible values hidden multiplier variable 
demonstrate simulations images contaminated additive white gaussian noise performance method substantially surpasses previously published methods visually terms mean squared error 
index terms bayesian estimation gaussian scale mixtures hidden markov model natural images noise removal overcomplete representations statistical models steerable pyramid 
artifacts arising imaging devices quite different images contaminate difference allows humans see past artifacts underlying image 
goal image restoration relieve human observers task improve abilities reconstructing plausible estimate original image distorted noisy observation 
prior probability model noise uncorrupted images central importance application 
modeling statistics natural images challenging task partly high dimensionality signal 
manuscript received september revised april 
development leave drexel university supported ams fellowship 
wainwright supported nserc fellowship 
portilla simoncelli supported nsf career alfred sloan fellowship simoncelli howard hughes medical institute 
portilla supported fpi fellowship subsequently ram spanish government 
associate editor coordinating review manuscript approving publication dr mario figueiredo 
portilla department computer science artificial intelligence universidad de granada granada spain mail javier es 
department mathematics computer science drexel university philadelphia pa usa mail mcs drexel 
edu 
wainwright electrical engineering computer science department university california berkeley berkeley ca usa mail eecs berkeley edu 
simoncelli center neural science courant institute mathematical sciences new york university new york ny usa mail eero simoncelli nyu edu 
digital object identifier tip ieee basic assumptions commonly order reduce dimensionality 
probability structure may defined locally 
typically markov assumption probability density pixel conditioned set neighbors independent pixels neighborhood 
second assumption spatial homogeneity distribution values neighborhood neighborhoods regardless absolute spatial position 
markov random field model results assumptions commonly simplified assuming distributions gaussian 
assumption problematic image modeling complexity local structures described gaussian densities 
power statistical image models substantially improved transforming signal pixel domain new representation 
past decade standard initiate computer vision image processing tasks decomposing image set multiscale bandpass oriented filters 
kind representation loosely referred wavelet decomposition effective decoupling high order statistical features natural images 
addition shares basic properties neural responses primary visual cortex mammals presumably adapted efficiently represent visually relevant features images 
number researchers developed homogeneous local probability models images multiscale oriented representations 
specifically marginal distributions wavelet coefficients highly described suitable long tailed distributions 
investigated dependencies coefficients amplitudes coefficients similar position orientation scale highly correlated 
higher order dependencies higher order marginal statistics may modeled augmenting simple parametric model local dependencies gaussian set hidden random variables govern parameters variance 
hidden markov models widely example speech processing 
article develop model neighborhoods oriented pyramid coefficients gaussian scale mixture product gaussian random vector independent hidden random scalar multiplier 
previously demonstrated model account marginal pairwise joint distributions wavelet coefficients 
develop local denoising solution bayesian squares estimator demonstrate performance method images corrupted simulated additive white gaussian noise known variance 
portilla image denoising scale mixtures gaussians wavelet domain background statistical image models denoising contemporary models image statistics rooted television engineering see review relied characterization autocovariance function purposes optimal signal representation transmission 
nearly assumes image statistics spatially homogeneous strict sense stationary 
common assumption image modeling statistics invariant suitably normalized changes spatial scale 
translation scale invariance assumptions coupled assumption gaussianity provides baseline model engineering literature images samples gaussian random field variance falling frequency domain 
context denoising assumes noise additive independent signal gaussian sample optimal estimator linear 
modeling non gaussian image properties years models developed account non gaussian behaviors image statistics 
see casual observation individual images highly inhomogeneous typically contain regions smooth interspersed features contours surface markings 
reflected observed marginal distributions bandpass filter responses show large peak zero tails fall significantly slower gaussian variance see fig 

seeks linear transformation maximizes non gaussianity marginal responses result basis set bandpass oriented filters different sizes spanning roughly octave bandwidth 
due combination qualitative properties elegant mathematical framework multiscale oriented subband decompositions emerged representations choice image processing applications 
subbands representations behaviors coefficients allow remove noise point nonlinearity 
approaches quite popular image denoising literature typically chosen perform type thresholding operation suppressing low amplitude values retaining high amplitude values 
concept developed originally television engineering literature known coring specific shrinkage functions derived variety formulations including minimax optimality smoothness condition bayesian estimation non gaussian priors :10.1.1.29.4107:10.1.1.29.4107
addition non gaussian marginal behavior responses bandpass filters exhibit important non gaussian joint statistical behavior 
particular secondorder decorrelated coefficients corresponding pairs basis functions similar position orientation scale exhibit striking dependencies 
casual observation indicates large amplitude coefficients sparsely distributed different authors different measures non gaussianity obtained similar results 
fig 

comparison coefficient statistics example image subband vertical subband boats image left panels arising simulation local gsm model right panels 
model parameters covariance matrix multiplier prior density estimated maximizing likelihood observed set wavelet coefficients 
log marginal histograms 
conditional histograms spatially adjacent coefficients 
brightness corresponds probability column independently rescaled fill range display intensities 
image tend occur clusters 
conditional histograms pairs coefficients indicates standard deviation coefficient scales roughly linearly amplitude nearby coefficients see fig 

dependency local coefficient amplitudes associated marginal behaviors modeled random field spatially fluctuating variance 
particularly useful example arises product gaussian vector hidden scalar multiplier known gaussian scale mixture gsm 
gsm distributions represent important subset symmetric distributions defined functions quadratic norm random vector 
embedded random field kinds models useful speech processing community 
related set models known autoregressive conditional arch models proven useful real signals suffer abrupt fluctuations followed relative calm periods stock market prices example 
kinds ideas effective describing visual images 
example baraniuk colleagues state hidden multiplier variable characterize modes behavior corresponding smooth low contrast textured regions features :10.1.1.117.1177
assumes local variance governed continuous multiplier variable 
model capture strongly behavior marginal densities natural image wavelet coefficients correlation local amplitudes illustrated fig 

ieee transactions image processing vol 
november empirical bayes denoising variance adaptive models years ago lee suggested step procedure image denoising estimates local signal variance neighborhood observed pixels proceeding true variance applies standard linear squares lls solution 
method type empirical bayes estimator parameter local model estimated data estimate subsequently estimate signal 
step denoising solution applied variance adaptive models described section substantially powerful applied multiscale oriented representation 
specifically number authors estimated local variance collection wavelet coefficients nearby positions scales orientations estimated variances order denoise coefficients 
solutions gsm models different prior assumptions hidden variables produced effective methods removing homogeneous additive noise natural images date 
initial area developed maximum likelihood ml estimator 
ak maximum posteriori map estimator exponential marginal prior li orchard portilla lognormal prior 
wainwright developed tree structured markov model provide global description set multiplier variables 
despite successes step empirical bayes approach suboptimal local variance estimator optimal second step take account uncertainty associated variance estimated step 
derive squares optimal single step bayesian estimator 
ii 
image probability model described section multiscale representations provide useful front representing structures visual images 
widely orthonormal biorthogonal wavelet representations problematic applications including denoising 
specifically critically sampled number coefficients equal number image pixels constraint leads disturbing visual artifacts aliasing ringing 
widely followed solution problem basis functions designed orthogonal biorthogonal systems reduce eliminate decimation subbands 
constraint critical sampling dropped need limit oneself basis functions 
significant improvement comes representations higher degree redundancy increased selectivity orientation 
current particular variant overcomplete tight frame representation known steerable pyramid :10.1.1.18.6984
basis functions multiscale linear decomposition spatially localized oriented span roughly octave bandwidth 
polar separable fourier domain related translation dilation rotation 
authors developed representations similar properties 
details steerable pyramid representation provided appendix gaussian scale mixtures consider image decomposed oriented subbands multiple scales 
denote coefficient corresponding linear basis function scale orientation centered spatial location denote neighborhood coefficients clustered coefficient general neighborhood may include coefficients subbands corresponding basis functions nearby scales orientations subband 
case neighborhood coefficients drawn subbands adjacent scales advantage strong statistical coupling observed scale multiscale representations 
details provided section iv 
assume coefficients local neighborhood coefficient pyramid subband characterized gaussian scale mixture gsm model 
formally random vector gaussian scale mixture expressed product zero mean gaussian vector independent positive scalar random variable indicates equality distribution 
variable known multiplier 
vector infinite mixture gaussian vectors density determined covariance matrix vector mixing density dimensionality case size neighborhood 
loss generality assume implies conditions random vector may represented gsm studied 
gsm family includes variety known families random variables stable family including cauchy distribution generalized gaussian stretched exponential family symmetrized gamma family 
gsm densities symmetric zero mean marginal densities heavier tails gaussian 
key property gsm model density gaussian conditioned normalized vector gaussian 
notational simplicity drop superscripts indices development 
portilla image denoising scale mixtures gaussians wavelet domain gsm model wavelet coefficients explained section illustrated fig 
gsm model account shape wavelet coefficient marginals strong correlation amplitudes neighbor coefficients 
order construct global model images local description specify neighborhood structure coefficients distribution multipliers 
definition calculations global model considerably simplified partitioning coefficients nonoverlapping neighborhoods 
specify marginal model multipliers treating independent variables specify joint density full set multipliers 
unfortunately disjoint neighborhoods leads noticeable denoising artifacts discontinuities introduced neighborhood boundaries 
alternative approach gsm local description behavior cluster coefficients centered coefficient pyramid 
neighborhoods overlap coefficient member neighborhoods 
local model implicitly defines global markov model described conditional density coefficient cluster surrounding neighborhood assuming conditional independence rest coefficients 
structure resulting model performing statistical inference computing bayes estimates exact way quite challenging 
simply solve estimation problem coefficient center neighborhood independently 
prior density multiplier complete model need specify probability density multiplier 
authors suggested generalized gaussian stretched exponential family densities appropriate description wavelet coefficient marginal densities scaling variable controls width distribution exponent controls shape particular tails typically estimated lie range image subbands 
expressed gsm density associated multiplier closed form expression solution difficult implement 
previous noted case density log coefficient magnitude may written convolution densities density known means estimation density may framed deconvolution problem 
resulting estimated density may approximated gaussian corresponding lognormal prior solution important drawbacks 
case neighbors marginal statistics practice requires belong subband 
second estimated noise free coefficients difficult extend noisy case 
investigated direct maximum likelihood approach estimating nonparametric observed set neighborhood vectors sum neighborhoods 
note estimate constrained positive values unit area 
developed efficient algorithm computing solution numerically 
advantage ml solution easily extended noisy observations replacing noisy observation 
fourth choice called noninformative prior advantage require fitting parameters noisy observation 
solutions establishing marginal priors image denoising 
examined widely solution known jeffrey prior see 
context estimating multiplier coefficients takes form fisher information matrix 
computing gsm model straightforward square root expectation fact obtain jeffrey prior corresponds constant prior note improper probability density 
common ignore fact long create computational problems estimation stage 
case set prior zero interval prevent problems small positive constant see section iv details 
alternatives described expected ml estimated nonparametric prior produces best results denoising pyramid coefficients 
squares optimal estimate pyramid coefficients necessarily lead squares optimal estimate image pixels pyramid representation overcomplete 
surprised find noninformative prior typically leads better denoising performance image domain roughly average 
simpler efficient implement results shown sections iii 
ieee transactions image processing vol 
november iii 
image denoising procedure image denoising uses top level structure previously published approaches decompose image pyramid subbands different scales orientations denoise subband lowpass residual band invert pyramid transform obtaining denoised image 
assume image corrupted independent additive white gaussian noise known variance note method handle gaussian noise known covariance 
vector corresponding neighborhood observed coefficients pyramid representation expressed note assumed gsm structure coefficients coupled assumption independent additive gaussian noise means random variables right side independent 
zero mean gaussian vectors associated covariance matrices density observed neighborhood vector conditioned zero mean gaussian covariance neighborhood noise covariance obtained decomposing delta function pyramid subbands image dimensions 
signal power spectrum noise free random fluctuations 
elements may computed directly sample covariances averaging products pairs coefficients neighborhoods subband 
procedure easily generalized noise replacing delta function inverse fourier transform square root noise power spectral density 
note entire procedure may performed line 
signal covariance computed observation covariance matrix compute expectations loss generality set resulting force positive semidefinite performing eigenvector decomposition setting possible negative eigenvalues negligible cases zero 
bayes squares estimator neighborhood wish estimate coefficient center neighborhood set observed noisy coefficients 
bayes squares bls estimate just conditional mean assumed uniform convergence order exchange order integration 
solution average bayes squares estimate conditioned weighted posterior density describe individual components 
local wiener estimate key advantage gsm model coefficient neighborhood vector gaussian conditioned fact coupled assumption additive gaussian noise means expected value inside integral simply local linear wiener estimate 
writing full neighborhood vector simplify dependence expression diagonalizing matrix specifically symmetric square root positive definite matrix eigenvector eigenvalue expansion matrix note diagonalization depend need computed subband 
simplify follows restrict estimate coefficient needed solution represents element th row th column matrix diagonal elements elements index coefficient neighborhood vector 
portilla image denoising scale mixtures gaussians wavelet domain posterior distribution multiplier component solution distribution multiplier conditioned observed neighborhood values 
bayes rule compute discussed section ii choose noninformative jeffrey prior corrected origin function conditional density computation may simplified relationship definition summarizing denoising algorithm decompose image subbands 
subband lowpass residual compute neighborhood noise covariance image domain noise covariance 
estimate noisy neighborhood covariance estimate 
compute section iii 
neighborhood value integration range compute 
compute 
ii compute 
iii compute numerically 
reconstruct denoised image processed subbands lowpass residual 
iv 
implementation decompose image subbands specialized variant steerable pyramid 
representation consists oriented bandpass bands orientations scales oriented highpass residual subbands lowpass residual band total subbands 
detailed description decomposition appendix hand optimized neighborhood structure choice spatial positions scales orientations 
region surrounding coefficient coefficient location orientation coarser scale parent maximizes denoising performance average 
inclusion parent coefficient provide significant improvement performance number applications :10.1.1.117.1177
note parent subband sampled half density subband interpolated order obtain values neighborhoods choice coefficient 
exceptions applied highpass oriented subbands parents number samples interpolation required parents subbands coarsest scale parent subband simply spatial neighborhood subbands 
note terms image pixels spatial extent neighborhood depends scale subband basis functions grow size appropriate assumption image statistics scale invariant :10.1.1.50.3343
implementation integral computed numerically 
range sample spacing integration chosen compromise accuracy computational cost 
specifically sample logarithmically uniform spacing observed require fewer samples quality linear sampling 
note jeffrey improper prior constant logarithmic representation 
samples interval steps size 
chosen value chosen minimal value guarantees practice right tails posteriors properly covered integration interval 
contrast plays role ensuring left tail posterior integrable 
hand optimized maximize performance algorithm denoising performance relatively insensitive changes parameter 
slightly worse results result choosing interval reasonable performance obtained values low corresponds 
computational cost pyramid transform forward inverse scales dimensions image 
computational cost estimation procedure scales dimensions spatial subband neighborhood case dimensions bandpass convolution kernels roughly implementation full size neighborhood case number orientations number samples distributions terms added image dimensions correspond padded boundary region estimated order properly reconstruct image 
guide running times current unoptimized matlab implementation linux workstation ghz intel pentium iii cpu roughly seconds images 
primary memory cost due storage pyramid coefficients roughly floating point numbers 
ieee transactions image processing vol 
november table denoising performance expressed peak signal noise ratio ph db error standard deviation 
entry average different noise samples 
column shows estimated standard deviation results noise level fig 

nonlinear estimation functions resulting restriction method smaller neighborhoods 
neighborhood size coefficient neighborhood size coefficient plus parent 
results tested method set bit grayscale test images size pixels contaminated computer generated additive gaussian white noise different variances 
information images provided appendix table shows error variances denoised images expressed peak signal noise ratios psnr decibels full range input noise levels 
note images little improvement lowest noise level 
sense clean images fact include quantization errors implicit psnr db 
extreme improvement substantial roughly db best cases 
comparison model variants order understand relative contribution various aspects method considered restricted versions model representative primary denoising concepts literature 
gaussian model arising restriction model prior density delta function concentrated 
model variance adaptive globally gaussian 
note signal covariance modeled locally extent neighborhood pyramid subband 
denoising solution may viewed regularized version classical linear wiener filter solution 
order implement simply estimate coefficient set 
second restricted form model uses neighborhood containing coefficient 
conditions model describes marginal density coefficients estimator reduces application scalar function observed noisy coefficients 
function resulting reduction model single element neighborhood shown fig 

similar bls solutions derived generalized gaussian prior independent clean signal statistics normalized form scales noise standard deviation subband 
instructive examine nonlinear estimator associated case neighbors 
fig 
shows estimator obtained function coefficient portilla image denoising scale mixtures gaussians wavelet domain fig 

performance denoising methods relative method 
curves depict psnr differences db averaged representative images lena barbara boats function input psnr 
comparison restricted cases nonadaptive globally gaussian gsm model resulting ia diamonds gsm model neighborhood size circles 
comparison hard thresholding undecimated minimum phase daubechies tap scales wavelet decomposition diamonds local variance adaptive method image domain circles implemented matlab wiener function 
parameters methods optimized image noise level threshold level method neighborhood size ranging second 
denoising algorithms applied steerable pyramid representation adaptive wiener hand optimized size neighborhood images noise levels circles hard thresholding optimizing threshold image noise level diamonds 
application bls gsm estimation method coefficients different representations undecimated minimum phase daubechies tap wavelet scales diamonds decomposition original decimated version circles 
coarse scale parent coefficient 
loosely speaking coefficient suppressed amplitude parent amplitude small 
adjacent neighbors subband similar effect estimation 
developed map estimator circular symmetric laplacian density model coefficient parent 
resulting shrinkage function qualitatively similar fig 
smoother due covariance adaptation dead zone necessary aligned input axes 
fig 
shows comparison full model reduced forms explained 
note shrinkage solution outperforms jointly gaussian nonadaptive solution provides relatively results especially low snr rates 
full model adaptive context sensitive incorporates advantages subcases outperforms 
examined relative importance aspects method 
table ii shows decrease psnr results set features removed 
columns correspond features representation features model estimation method 
group decreasing number orientation bands ori leads significant drop performance 
increasing number orientations leads additional psnr improvement expense considerable computational storage cost 
second column shows effect partitioning highpass residual band oriented components standard form pyramid previous denoising single highpass residual band 
third column bdry shows reduction performance results switching mirror reflected extension periodic boundary handling 
feature model examined inclusion coarse scale parent coefficient neighborhood 
fourth column shows eliminating coarse scale parent neighborhood decreases performance significantly high noise levels 
taken mean parent coefficient provide information coefficient information somewhat redundant provided neighbors 
column cov demonstrates result assuming uncorrelated gaussian vectors describing noise signal 
coefficients representation strongly correlated inherent spectral features image redundancy induced overcomplete representation ignoring correlation model leads ieee transactions image processing vol 
november table ii reduction denoising performance db resulting removal model components shown different noise contamination rates 
results averaged lena barbara boats 
see text information significant loss performance 
column bls demonstrates substantial reduction performance replace full bls estimator step estimator map estimation local multiplier followed linear estimation coefficient 
comparison standard methods compared method known widely available denoising algorithms local variance adaptive method pixel domain implemented matlab function wiener hard thresholding method undecimated representation scales minimum phase daubechies tap wavelet filter 
cases single parameter neighborhood size common threshold subbands optimized independently image noise level 
results shown fig 

method seen clearly outperform entire range noise levels 
see superiority multiscale methods pixel domain method 
fig 
provides visual comparison example images denoised algorithms 
method produces artifacts significantly visible time able better preserve features original image 
natural ask extent results previous comparison due representation steerable pyramid opposed estimation method bls gsm 
order answer performed sets experiments comparing performance different combinations representation estimator 
applied estimation methods fig 
coefficients steerable pyramid representation 
adaptive wiener method hand optimized neighborhood size subbands roughly larger pixel domain 
translation invariant hard thresholding method optimized common threshold image noise level note steerable pyramid subband impulse responses normalized energy common threshold needs properly re scaled subband 
results plotted fig 

clear new representation improves results reduces difference methods 
adaptive wiener method seen outperform high input snr significant differences performance remain due entirely bls gsm estimation method 
second experiment compared performance estimation method applied coefficients dif fig 

comparison denoising results images cropped visibility artifacts 
boats image 
top left original image 
top right noisy image pha 
bottom left denoising result adaptive local wiener image domain bottom right method 
fingerprint image 
top left original image 
top right noisy image 
bottom left denoising result hard thresholding undecimated wavelet single optimized threshold bottom right method ferent representations 
chosen widely multiscale representations decimated undecimated versions separable wavelet decomposition 
order bls gsm method aliasing free version orthogonal wavelet fully undecimated levels highest frequency scales decimated factors rest scales producing little aliasing reconstruction error 
representation analogous steerable pyramid highpass oriented subbands bandpass highest frequency oriented subbands kept full resolution rest downsampled dyadic scheme 
results plotted fig 
indicate somewhat modest decrease performance replacing steerable pyramid portilla image denoising scale mixtures gaussians wavelet domain fig 

comparison denoising performance published methods 
curves depict output psnr function input psnr 
square symbols indicate results taken table 
circles crosses asterisk crosses diamonds 
undecimated separable wavelet transform 
decrease substantial case critically sampled representation 
comparison outcomes sets experiments may conclude representation estimation strategy contribute significantly performance advantage shown fig 

comparison state art methods compared method best available published results shown fig 

different versions test images available internet possible verified directly authors images authors data included previous comparisons authors see appendix details origin images 
fig 
provides visual comparison example image barbara denoised algorithm li variance adaptive model overcomplete separable wavelet representation 
note noisy images created different samples noise artifacts images appear different locations 
method seen provide fewer artifacts better preservation edges details 
separation diagonal orientations steerable pyramid allows selective removal noise diagonally oriented image regions see parallel diagonal lines left side face 
plotted psnr values obtained starck standard lena image provided differs version 
ieee transactions image processing vol 
november fig 

comparison denoising results barbara image cropped visibility artifacts 
left right top bottom original image noisy image ps results li method 
vi 
denoising method local gaussian scale mixture model overcomplete oriented pyramid representation 
statistical model differs previous models number important ways 
previous models separable orthogonal wavelets redundant versions wavelets 
contrast model overcomplete tight frame free aliasing includes basis functions selective oblique orientations 
increased redundancy representation higher ability discriminate orientations results improved performance 
second model explicitly incorporates covariance neighboring coefficients signal noise opposed considering marginal responses local variance 
model captures correlations induced overcomplete representation correlations inherent underlying image handle gaussian noise arbitrary power spectral density 
third included neighbor orientation spatial location coarser scale parent opposed considering spatial neighbors subband 
modeling choice consistent empirical findings strong statistical dependence scale natural images 
note inclusion parent results modest increase performance compared elements shown table ii 
believe impact including parent limited simplicity model characterizes correlation coefficients correlation amplitudes see 
addition modeling differences differences denoising method previous methods continuous hidden variable models 
compute full optimal local bayesian squares solution opposed estimating local variance estimate coefficient 
shown empirically approach yields important improvement results 
vectorial form lls solution full advantage information provided covariance modeling signal noise 
enhancements convenient choice prior hidden multiplier noninformative prior independent observed signal result substantial improvement quality denoised images keeping computational cost reasonably low 
currently working extensions estimator 
begun developing variant method denoise color images taken commercial digital camera 
find sensor noise cameras important features characterized calibration measurements spatial cross channel correlation signal dependence 
extending denoising solution address complete image restoration problem incorporating model image blur 
developing ml estimator noise variance normalized power spectral density portilla image denoising scale mixtures gaussians wavelet domain fig 

system diagram extended version steerable pyramid 
input image split lowpass band set highpass oriented bands 
lowpass band split lower frequency band set oriented subbands 
pyramid recursion consists inserting diagram contents shaded region lowpass branch solid circle 
basis function corresponding example oriented subband idealized depiction frequency domain partition apa gray region corresponding basis function 
noise assumed known 
preliminary results extensions appear promising 
believe current image model improved number ways 
desirable develop method efficiently estimating prior multiplier maximizing joint likelihood observed subbands opposed somewhat heuristic choice noninformative prior corrected origin 
similarly desirable minimize expected quadratic error image domain doing subband coefficients 
addition worth exploring transformation local gsm model explicit markov model overlapping neighborhoods opposed nonoverlapping treestructured models previously developed 
conceptual simplification facilitate applications requiring conditional local density model synthesis coding 
longer term perspective major improvements come statistical models capture important structural properties local image features including additional dependencies phase congruency coefficients complex multiscale oriented transforms 
appendix steerable pyramid transform known steerable pyramid decompose images frequency subbands :10.1.1.18.6984
transform implemented fourier domain allowing exact reconstruction image subbands flexible choice number orientations scales software implementation matlab available www cns nyu edu software html 
conventional orthogonal wavelet decompositions pyramid implemented recursively splitting image set oriented subbands lowpass residual band subsampled factor axes 
conventional orthogonal wavelet decompositions oriented bands subsampled subsampling lowpass band produce aliasing artifacts lowpass filter designed obey nyquist sampling criterion 
performing convolutions boundaries handled mirror extension reflection image maintaining continuity 
tight frame transformation may inverted convolving subband associated complex conjugated filter adding results 
redundancy factor overcomplete representation system diagram transform shown fig 

filters polar separable fourier domain may written polar frequency coordinates recursive procedure initialized splitting input image lowpass oriented highpass portions filters fig 
shows impulse response example bandpass oriented filter highest resolution level purely imaginary fourier transform 
ieee transactions image processing vol 
november appendix origin test images bit grayscale test images obtaining results available internet es javier denoise 
images commonly known lena barbara boats house peppers widely image processing literature 
unfortunately test images available version differences due cropping scanning resizing compression conversion color gray level 
versions 
included image fingerprint images homogeneous texture 
versions bit gray level lena chose standard www ece rice edu images lena bmp 
comparison fig 
starck generously offered run algorithm test image li kindly confirmed version image 
barbara image obtained schmidt standard test images database sourceforge net index html 
version previously turn comparison 

boats image taken university southern california image database usc edu services database database cgi 
version 
house peppers images kindly provided pi proper comparison results reported 
andrews mallows scale mixtures normal distributions statist 
soc vol 

wainwright simoncelli scale mixtures gaussians statistics natural images adv 
neural information processing systems solla leen ller eds 
cambridge ma mit press vol 
pp 

wainwright simoncelli willsky random cascades wavelet trees modeling analyzing natural imagery appl 
comput 
harmon 
anal vol 
pp 
july 
ruderman statistics natural images network comput 
neural syst vol 
pp 

field relations statistics natural images response properties cortical cells opt 
soc 
amer 
vol 
pp 

daugman entropy reduction decorrelation visual coding oriented neural receptive fields ieee trans 
biomed 
eng vol 
pp 

mallat theory multiresolution signal decomposition wavelet representation ieee pattern anal 
machine intell vol 
pp 
july 
olshausen field emergence simple cell receptive field properties learning sparse code natural images nature vol 
pp 

bell sejnowski independent components natural scenes edge filters vis 
res vol 
pp 

rossi digital techniques reducing television noise vol 
pp 

donoho johnstone ideal spatial adaptation wavelet shrinkage biometrika vol 
pp 

multiscale regularization besov spaces proc :10.1.1.29.4107
st asilomar conf 
signals systems computers pacific grove ca nov 
simoncelli adelson noise removal bayesian wavelet coring proc 
rd int 
conf 
image processing vol 
lausanne switzerland sept pp 

chipman kolaczyk mcculloch adaptive bayesian wavelet shrinkage amer :10.1.1.29.5390
statist 
assoc vol 
pp 

abramovich silverman wavelet thresholding bayesian approach statist 
soc 
vol 
pp 

simoncelli bayesian denoising visual images wavelet domain bayesian inference wavelet models ller vidakovic eds 
new york springer verlag vol 
ch 
pp 

moulin liu analysis multiresolution image denoising schemes generalized gaussian complexity priors ieee trans 
inform 
theory vol 
pp 

hyvarinen sparse code shrinkage denoising non gaussian data maximum likelihood estimation neural comput vol 
pp 

starck donoho curvelet transform image denoising ieee trans 
image processing vol 
pp 
june 
wegmann statistical dependence orientation filter outputs human vision image code proc 
visual comm 
image processing vol 
lausanne switzerland pp 

simoncelli 
statistical models images compression restoration synthesis 
proc 
st asilomar conf 
signals systems computers 
online 
available www cns nyu edu eero publications html simoncelli image compression joint statistical characterization wavelet domain ieee trans 
image processing vol 
pp 
dec 
description generation spherically invariant speech model signals signal process vol 
pp 

engle nelson arch models handbook econometrics engle mcfadden eds 
crouse nowak baraniuk wavelet statistical signal processing hidden markov models ieee trans 
signal processing vol 
pp 
apr 
romberg choi baraniuk bayesian tree structured image modeling wavelet domain hidden markov models ieee trans :10.1.1.117.1177
image processing vol 
july 
ramchandran orchard wavelet image coding new generalized gaussian mixture model proc 
data compression conf snowbird ut mar 
ak ramchandran moulin image denoising statistical modeling wavelet coefficients ieee trans 
signal processing vol 
pp 
dec 
lee digital image enhancement noise filtering local statistics ieee pattern anal 
machine intell vol 
pami pp 
mar 
robbins empirical bayes approach statistical decision problems ann 
math 
statist vol 
pp 

wavelet image denoising markov random field priori model ieee trans 
image processing vol 
pp 
apr 
chang yu vetterli spatially adaptive wavelet thresholding context modeling image denoising proc 
th ieee int 
conf 
image processing chicago il oct 
abramovich empirical bayes approach block wavelet function estimation comput 
statist 
data anal vol 
pp 

portilla simoncelli image denoising local gaussian scale mixture model wavelet domain proc 
spie wavelet applications signal image processing viii vol 
pp 
dec 
li orchard spatially adaptive image denoising overcomplete expansion proc 
ieee int 
conf 
image processing vancouver bc canada sept 
portilla wainwright simoncelli adaptive wiener denoising gaussian scale mixture model wavelet domain proc 
th ieee int 
conf 
image processing thessaloniki greece oct pp 

portilla image denoising scale mixtures gaussians wavelet domain coifman donoho translation invariant de noising wavelets statistics antoniadis oppenheim eds 
san diego ca springer verlag lecture notes 
simoncelli freeman adelson heeger shiftable multi scale transforms ieee trans 
inform 
theory vol 
pp 
mar 
freeman adelson design steerable filters ieee pattern anal :10.1.1.18.6984
machine intell vol 
pp 

watson cortex transform rapid computation simulated neural images comput 
vis 
graphics image process vol 
pp 

donoho ridgelets key higher dimensional intermittency phil 
trans 
soc 
lond vol 
pp 

kingsbury complex wavelets shift invariant analysis filtering signals appl 
comput 
harmon 
anal vol 
pp 
may 
denoising block wiener filtering wavelet domain proc 
rd eur 
congr 
math barcelona spain july 
box tiao bayesian inference statistical analysis 
reading ma addison wesley 
figueiredo nowak wavelet image estimation empirical bayes approach jeffrey noninformative prior ieee trans 
image processing vol 
pp 
sept 
shapiro embedded image coding wavelet coefficients ieee trans 
signal processing vol 
pp 
dec 
ruderman origins scaling natural images vis :10.1.1.50.3343
res vol 
pp 

portilla navarro duality log polar image representations space spatial frequency domains ieee trans 
signal processing vol 
pp 
sept 
bivariate shrinkage functions wavelet denoising exploiting dependency ieee trans 
signal processing vol 
pp 
nov 
bivariate shrinkage local variance estimation ieee signal processing lett vol 
pp 
dec 
pi philips joint statistical model bayesian wavelet image denoising ieee trans 
image processing vol 
pp 
may 
starck donoho high quality image restoration proc 
spie vol 
pp 
august 
portilla wainwright simoncelli image denoising gaussian scale mixtures wavelet domain courant inst 
math 
sci new york university tech 
rep tr 
portilla simoncelli image restoration gaussian scale mixtures wavelet domain proc 
ieee int 
conf 
image proc barcelona spain sept 
image features phase congruency comput 
vis 
res vol 
summer 
portilla simoncelli parametric texture model joint statistics complex wavelet coefficients int 
comput 
vis vol 
pp 

chambolle devore lee lucier nonlinear wavelet image processing variational problems compression noise removal wavelet shrinkage ieee trans 
image processing vol 
pp 
mar 
vidakovic nonlinear wavelet shrinkage bayes rules bayes factors amer 
statist 
assoc vol 
pp 

javier portilla received degree ph degree electrical engineering universidad polit cnica de madrid 
research assistant instituto de superior de cient ficas madrid 
research associate simoncelli laboratory center neural science new york university 
currently associate investigator visual information processing group computer science artificial intelligence department universidad de granada 
research focused visual statistical representation models natural images textures application image processing synthesis 
dissertation 
received ph massachusetts institute technology 
held visiting positions university south carolina imperial college dartmouth college new york university assistant drexel university 
currently working industry 
research interests include wavelet multiwavelet theory signal processing financial mathematics 
martin wainwright received ph electrical engineering computer science eecs massachusetts institute technology mit cambridge january 
currently postdoctoral research associate eecs university california berkeley 
interests include statistical signal image processing variational methods convex optimization machine learning information theory 
dr wainwright received george award mit eecs department doc eero simoncelli received degree physics harvard university cambridge ma 
studied applied mathematics cambridge university year half received degree ph degree electrical engineering massachusetts institute technology 
assistant professor computer information science department university pennsylvania philadelphia 
moved new york university september currently associate professor neural science mathematics 
august associate investigator howard hughes medical institute new program computational biology 
research interests span wide range issues representation analysis visual images machine biological vision systems 
