brief overview hand gestures wearable human computer interfaces technical report issn thomas moeslund lau laboratory computer vision media technology aalborg university denmark mail tbm dk technical report provides brief overview human hand gestures wearable human computer interfaces hci 
report divided parts dealing different technologies detect recognise hand gestures wearable hci systems part focusing particular technology computer technology 
part describes number wearable hci systems different technologies order include gestures interface 
furthermore compares different technologies respect certain general hci aspects 
second part describes class taxonomy computer vision technology gives examples classes 
research part funded arthur project european commissions ist program ist 
support gratefully acknowledged 
chapter purpose technical report provide brief overview human hand gestures wearable human computer interfaces hci 
context report ec project laboratory computer vision media technology part 
project know arthur project short augmented round table architecture urban planning 
purpose project bridge gap real virtual worlds enhancing users current working environment virtual objects 
arthur project responsible computer vision algorithms 
include tracking recognizing placeholder objects head tracking gesture recognition 
algorithms input head mounted cameras 
fall spring master student lau working gesture recognition context arthur project head mounted cameras 
documented thesis probabilistic hand tracking wearable gesture interfaces 
main text technical report taken thesis 
report divided parts dealing different technologies detect recognise hand gestures wearable hci systems part focusing particular technology computer vision technology 
chapter different technologies including gestures wearable hci chapter describe number wearable hci systems different technologies order include gestures interface 
description compare different technologies respect certain general hci aspects 
summaries different systems hand glove gesture interface system augmented virtual reality 
system provides types interaction 
menu system menu item assigned finger item selected touching conducting pads matching fingertip pad thumb 
second mode interaction manipulation virtual objects 
done computer vision tracking markers hands degrees freedom 
main application hand outdoor augmented reality modeling architecture 
existing virtual reality data gloves evaluated criticized expensive bulky widespread mobile 
lightweight input device described bend sensor index finger acceleration sensor hand micro switch activation 
user test indicates developed interface simple gestures controlling information appliances intuitive easy learn 
test persons complained necessary cables physical properties input device 
wireless finger tracker 
ultrasonic emitter worn index finger receiver capable tracking position emitter mounted hmd 
provides excellent head relative tracking finger expected resolution mm distance mm hmd 
avoid placing sensors hand fingers uses capacitive sensors determine configuration fingers 
done measuring cross sectional shape wrist cavities moving skin 
sensitive positioning sensors wrist differentiate gestures fist point 
hand necessary sensors including acceleration sensor mounted normal wristwatch highly unobtrusive 
furthermore article proposes combined wireless body networking avoid cables going 
active infrared imaging simplify task separating hands handheld objects background wearable gesture interface systems 
source infrared illumination mounted near camera fitted infrared pass filter 
light source significantly stronger infrared part ambient illumination image captured camera mainly produced light head mounted illuminant 
intensity infrared light decrease distance source relatively simple separate objects close head objects farther away 
hmd mounted active infrared setup fingertip drawing recognition objects held hand 
object recognition possible adding color camera infrared camera hmd beam splitter give cameras exact image 
object extracted color image depth information infrared image 
gesture pendant demonstrated active infrared camera necklace 
gesture interface primarily designed home automation aid disabled elderly people 
combining active infrared principle fisheye lens excellent image wearer hands obtained 
gesture recognition performed hidden markov models done mobile interpretation sign language 
multimodal interfaces proposed combining gesture pendant voice recognition tracking persons position home 
apart control home information appliances gesture pendant monitors health wearer observing pathological gestures 
performance prototype system proved excellent preliminary experiments 
vision systems processing power battery life issues solved mobile possible 
wearable computer vision gesture recognition hand tracking active infrared requiring hand marked 
combine shape skin color tracking create mouse interface distinct point click gestures 
applications implemented mouse universal remote control electronic appliances 
secure password input augmented reality 
real world ocr translator capable selecting signs text pointing translating japanese english 
provide necessary computing power system distributes processing hand tracking algorithm wearable computer remote host wireless lan 
performing processing locally wearable provide faster response times robustness instabilities lan due roaming interference 
presents finger menu similar hand interface vision needs clear view hand fingers 
menu item selected simply bending corresponding finger 
detection hand fingers accomplished pixel level color segmentation adaptive color model cope variations skin color changes lighting 
specifically interface modality contextual awareness major area research field wearable computers 
idea computer observe user surroundings 
knowledge enable intelligent interfaces adapt user immediate needs 
example computer know interrupt phone calls email middle meeting emergency 
hand driving car system notify user incoming emails spoken summary 
long term goal computer model user surroundings 
predictions model enable system retrieve information needed ready user asks 
computer vision obtain contextual awareness 
cameras mounted users head pointing forward surroundings looking hands body wearer 
estimates users location current actions hidden markov models 
example contextual awareness dynamic personal enhanced reality system audio video messages associated images real world objects 
head mounted camera sees known object computer plays back associated media 
possible applications listed ranging note visual arts gallery aid persons poor vision 
comparing different technologies seen previous section different interface technologies modalities tried wearable computers 
importance different characteristics vary greatly application seen advantage disadvantage 
general advantages disadvantages common interface technologies summarized table 
interface technologies divided groups devices data entry devices selection free form input 
desktop environment exemplified keyboard mouse respectively 
data input technologies table mature state development need research technical level 
vision solutions hand need ultimately intuitive interface modalities 
free form input technologies table significant drawbacks 
systems active infrared pose smallest problems regards image processing 
direct sunlight applicable wearable computers outdoor 
glove solutions considered unfit general wearable computers prevent user unrestricted hands 
consequently vision gesture interfaces relying active infrared generally applicable solutions 
pose largest technical challenges 
technological maturity processing requirements power consumption ease free form input text input body attachments hands free possible low high production hard learn low production forearm low production poor low low usable sensors cables interface modality voice recognition keyboard half qwerty glove gesture vision gesture active ir gesture table strengths weaknesses common interface technologies 
poor high high experimental poor high high experimental chapter computer vision gesture recognition chapter briefly describe computer vision gesture recognition applied gesture recognition 
structure description class taxonomy 
insight research field please refer surveys 
gesture recognition systems general divided main components image preprocessing tracking gesture recognition 
individual systems components may merged missing basic functionality normally 
image preprocessing task preparing video frames analysis suppressing noise extracting important clues position hands bringing symbolic form 
step referred feature extraction 

tracking basis preprocessing position possibly attributes hands tracked frame frame 
done distinguish moving hand background moving objects extract motion information recognition dynamic gestures 

gesture recognition collected position motion pose clues decided user performing meaningful gesture 
knowledge hands tracking recognition exist different levels abstraction 
main approaches exist regard dif system model hand knowledge appearance hand image 
model approach model hand created 
model matched results preprocessing determine state tracked hand 
model elaborate model degrees freedom dof digiteyes system cardboard model contour model hand seen straight 
addition model hand model features image corresponding real hand produced required 
measurement model needed order determine state hand model appearance hand image 
continuously fitting model hand video frames process tracking complete state hand just position 
process consequently called state tracking 
model contains sufficient number internal degrees freedom recognition static gestures reduced inspection state 

appearance approach tracking representation learned large number training images 
explicit model hand exists internal degrees freedom specifically modeled 
appearance hand video frames known differentiating gestures straight forward model approach 
gesture recognition typically involve sort statistical classifier set features represent hand see 
gesture interfaces large part literature gesture recognition deals recognizing sets dynamic gestures individual commands computer ultimate goal understanding sign language 
example proposes recognise sign language desktop wearable computers 
obtained results better head mounted downward looking camera static desk camera head mounted camera insensitive body posture 
recognition skin color segmentation extract position shape motion orientation hands 
hands modeled ellipses system able obtain performance modeling individual fingers 
hidden markov models hmm continuous recognition full sentences sign language accomplished vocabulary limited words 
appearance recognition static gestures letters hand alphabet recognized principal component analysis pca classifier 
appearance individual signs learned large number training images 
pca create low dimensional feature space hands located video frames compared classes representing defined gestures 
classes corresponding classifier created line learning process 
principle eigen hands inspired eigen faces face recognition see 
main problem appearance models view dependent require multiple views training see 
addition detect recognize gestures research done designing intuitive natural gesture sets gestures body language part inter person communication 
hand finger tracking briefly exemplify class taxonomy detail 
image preprocessing pixel level segmentation regions pixels corresponding hand extracted color segmentation background subtraction 
detected regions analyzed determine position orientation hand 
color human skin varies greatly individuals changing illumination 
advanced segmentation algorithms handle proposed computationally demanding sensitive quickly changing mixed lighting conditions 
addition color segmentation confused objects background color similar skin color 
background subtraction works known static background consequently usable mobile wearable 
alternatives markers fingers infrared lighting enhance skin objects image see 
motion segmentation moving objects video stream detected calculation inter frame differences optical flow 
system capable tracking moving objects moving background hand held camera 
system detect stationary hand determine moving objects hand 
contour detection information obtained just extracting contours objects image 
contour represent shape hand directly dependent skin color lighting conditions 
extracting contours edge detection result large number edges tracked hand background 
form intelligent post processing needed reliable system 
correlation hand fingertip sought frame comparing areas frame template image hand fingertip 
determine target template translated region interest correlated neighborhood pixel 
pixel resulting highest correlation selected position target object 
apart computationally expensive template matching cope scaling rotation target object 
problem addressed continuously updating template risk tracking hand 
tracking top low level processing methods tracking layer needed identify hands follow frame frame 
depending nature low level feature extraction done directly tracking prominent feature inferring motion position hand entire feature set 
tracking kalman filter way solving problem tracking movement object frame frame kalman filter 
kalman filter models dynamic properties tracked object uncertainties dynamic model low level measurements 
consequently output filter probability distribution representing knowledge uncertainty state object 
estimate uncertainty select size search area look object frame 
kalman filter elegant solution easily computable real time 
probability distribution state object assumed gaussian 
generally case especially presence background clutter kalman filter basic form robustly handle real world tracking tasks unknown background 
controlled background results obtained 
condensation attempt avoid limiting assumption normal distribution inherent kalman filter introduced denoted condensation algorithm 
approach model probability distribution set random particles perform involved calculations particle set 
group methods condensation algorithm belongs generally refereed random sampling methods sequential monte carlo methods particle filters 
promising results obtained random sampling variety applications complex backgrounds 
propose combination appearance eigen tracking condensation gesture recognition 
sequential monte carlo methods adaptive color models providing robust tracking objects undergoing dramatic changes shape 
task face hand tracking motion clues combined color information eliminate stationary skin colored objects wooden doors desks 
skin color segmentation region growing condensation simultaneous tracking hands 
solutions handle occlusions proposed resulting reliable operation blobs corresponding hands merge extended periods 
hand model consisting blobs ridges different scales representing palm fingers fingertips particle filtering track position hand configuration fingers 
real time performance obtained model state space limited translation planar rotation scaling number fingers 
propose method called partitioned sampling tracking articulated objects particle filters requiring unreasonable amount particles cope resulting high dimensional state space 
solution locate base object determine configuration attached links hierarchical way 
example hand drawing application 
partitioned sampling locating palm subsequently determining angles palm thumb index finger 
angles differentiate small number gestures corresponding drawing commands 
tracking spline description contour hand fitted edges image combined skin color matching 
detailed motion models background subtraction limit effect clutter 
recognition usually classical algorithms field pattern recognition applied 
hidden markov models correlation neural networks 
especially success neural networks problem modelling non gestural patterns 
inside hidden markov models correlation applied gesture recognition see respectively 
chapter discussion report done things 
firstly tried give brief overview different technologies applied wearable hci order include gestures 
secondly tried give brief overview computer vision gesture recognition 
surprised see great variety different technologies including gestures hci 
reason fact current state art computer vision gesture recognition impressive 
getting overview reading literature allowed identify desirable characteristics technology wearable hci 
listed 

robust initialization reinitialization hand expected enter exit view frequently 
tracker able quickly reinitialize reliable estimation hand obtainable 

robustness background clutter objects background distract tracker objects skin color 

independence illumination tracker wearable applications able cope changing mixed lighting conditions 

computationally effective mobile processors tend significantly powerful desktop counterparts 
algorithms requiring extensive computational resources avoided 
bibliography henrik birk thomas moeslund claus madsen 
realtime recognition hand alphabet gestures principal component analysis 
th scandinavian conference image analysis finland 
michael black allan jepson 
eigentracking robust matching tracking articulated objects view representation 
international journal computer vision 
justine cassell 
framework gesture generation interpretation 
cipolla pentland editors computer vision human machine interaction pages 
cambridge university press new york 
james crowley coutaz 
finger tracking input device augmented reality 
international workshop gesture face recognition zurich switzerland 
sylvia ali 
robust finger tracking wearable computer interfacing 
workshop perspective user interfaces orlando fl 

extraction hand shape posture image sequences sign language recognition 
international workshop analysis modeling faces gestures nice france october 
eric michael harrington 
self referenced head hand tracker wearable computers portable vr 
international symposium wearable computing pages atlanta ga 
gupta mittal dutta roy banerjee 
condensation predictive eigentracking 
indian conference computer vision graphics image processing 
gupta mittal dutta roy banerjee 
developing gesture interface 
journal research special issue visual media processing 
giancarlo massimo lorenzo vita 
hand tracking human computer interaction graylevel turning back simple way 
workshop perceptive user interfaces 
acm digital library november 
isbn 
michael isard andrew blake 
contour tracking stochastic propagation conditional density 
eccv pages 
tony jebara bernt schiele oliver alex pentland 
dynamic personal enhanced reality system 
perceptual computing technical report 
mit 
kohler 
survey video gesture recognition stereo mono systems 
technical report research report nr 
fachbereich informatik university dortmund 
kato jung ken endo 
functionally distributed hand tracking method wearable visual interfaces applications 
iapr workshop machine vision applications pages nara japan 
ivan tony lindeberg 
tracking multi state hand models particle filtering hierarchy multi scale image features 
editor scale space volume lecture notes computer science pages 
springer 

survey hand posture gesture recognition techniques technology 
technical report cs department oc computer science brown university providence rhode island 
lee kim 
hmm threshold model approach gesture recognition 
transactions pattern analysis machine intelligence 
lin wu huang 
capturing human hand motion image sequences 
workshop motion video computing orlando florida december 
john maccormick 
stochastic algorithms visual tracking probabilistic modelling stochastic algorithms visual localisation tracking 
springer verlag new york 
john maccormick andrew blake 
probabilistic contour discriminant object localisation 
proc 
int 
conf 
computer vision 
john maccormick michael isard 
partitioned sampling articulated objects interface quality hand tracking 
european conf 
computer vision volume pages 
james chaudhuri tushar agarwal 
simultaneous tracking hands estimation erroneous observations 
british machine vision conference bmvc manchester uk 
michael nielsen thomas moeslund erik granum 
procedure developing intuitive ergonomic gesture interfaces hci 
th int 
workshop gesture sign language human computer interaction genova italy april 
lau 
probabilistic hand tracking wearable gesture interfaces 
master thesis laboratory computer vision media technology aalborg university denmark 
hagan alexander zelinsky 
finger track robust realtime gesture interface 
australian joint conference artificial intelligence perth australia 
oka sato koike 
real time tracking multiple fingertips gesture recognition augmented desk interface systems 
international conference automatic face gesture recognition washington usa may 
pavlovic sharma huang 
visual interpretation hand gestures human computer interaction review 
transactions pattern analysis machine intelligence 
perez hue 
color probabilistic tracking 
european conference computer vision volume pages copenhagen denmark 
wayne bruce thomas 
system demonstrating new techniques mobile augmented reality modelling 
third australasian conference user interfaces pages 
australian computer society 
james rehg takeo kanade 
digiteyes vision hand tracking human computer interaction 
workshop motion non rigid articulated bodies pages 
jun rekimoto 
unobtrusive wearable interaction devices 
international symposium wearable computing pages 

high performance real time gesture recognition hidden markov models 
technical report gerhard mercator university duisburg 
thad starner jake daniel gandy 
gesture pendant self illuminating wearable infrared computer vision system home automation control medical monitoring 
international symposium wearable computing atlanta ga october 
thad starner bernt schiele alex pentland 
visual contextual awareness wearable computing 
second international symposium wearable computers pages 
thad starner joshua weaver alex pentland 
real time american sign language recognition desk wearable computer video 
ieee transactions pattern analysis machine intelligence 

finger gesture input device mobile 
information processing society japan journal 
turk pentland 
eigen faces recognition 
cognitive neuro science 

wearable vision interfaces wearable information playing daily life 
st crest workshop advanced computing communicating techniques wearable information playing pages 

finger tracking interaction augmented environments 
international symposium augmented reality new york new york october 
watson 
survey gesture recognition techniques 
technical report tcd cs department computer science trinity college dublin 
king yuen wong minas 
motion segmentation tracking 
th international conference vision interface pages calgary canada 
wu huang 
vision gesture recognition review 
editor international workshop number lnai 
springer 
zhu jie yang alex waibel 
segmenting hands arbitrary color 
international conference automatic face gesture recognition pages grenoble france 
ieee computer society 

