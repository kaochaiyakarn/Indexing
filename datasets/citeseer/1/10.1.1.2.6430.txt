seeing believing 
recommender interfaces affect users opinions dan lam albert joseph konstan john riedl department computer science engineering university minnesota minnesota mn usa lam konstan riedl cs umn edu recommender systems people opinions items information domain help people choose items 
systems succeeded domains diverse movies news articles web pages wines 
psychological literature conformity suggests course helping people choices systems probably affect users opinions items 
opinions influenced recommendations valuable making recommendations users 
manipulators seek system generate artificially high low recommendations benefit efforts influence users change opinions contribute recommender 
study aspects recommender system interfaces may affect users opinions rating scale display predictions time users rate items 
find users rate fairly consistently rating scales 
users manipulated tending rate prediction system shows prediction accurate 
users detect systems manipulate predictions 
discuss designers recommender systems react findings 
keywords recommender systems collaborative filtering personalization persuasive computing commerce conformity humans ability locate information desire grows slowly rate new information available 
recommender systems tool help bridge gap 
systems people opinions items information domain order help people decisions items consume 
example amazon com allows user rate books suggests books user ratings 
permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
chi april ft lauderdale florida usa 
copyright acm 

recommender systems valuable competitive advantage retail companies especially commerce 
system produces recommendations inspire trust help users find products truly want 
time engaging interface collecting recommendations allows gather preference information customers tailor offerings customer 
customers stand benefit 
researchers investigated effect interfaces recommendations 
herlocker studied explaining recommendations convince users trust system swearingen sinha find users trust systems recommend items users know :10.1.1.15.7347
research recommender systems focused discovering algorithms :10.1.1.37.8212:10.1.1.21.4665:10.1.1.30.6583:10.1.1.38.6498
lack attention interface poses danger users 
focus rating interface may affect users opinions ability express 
recommendations may influence users ratings recommender systems generally provide information items recommend 
may include item descriptions reviews written users professional critics average user ratings predicted personalized ratings user 
fact item recommended provides information system thinks user item 
recommender systems provide way users rate item recommended 
shows movielens interface including predictions ratings interface screen 
showing information item time user rates affect user opinion leading potential problems 
altered opinion provide recommender accurate preference information leading accurate predictions 
second altered opinions hard evaluate quality system recommendations 
system interface steers users predictions score better accuracy metrics system neutral interface second system produce useful recommendations 
interface viewing predictions rating movies movielens 
predictions displayed right rating interface 
third agents take advantage effect amplify false opinions inject system 
opinions artificially inflated leading unusually positive recommendations may turn induce unusually positive ratings users 
agent attempt prevent item recommended giving falsely low opinions 
rate item may give lower ratings 
system interface influences users opinions effective tempting shilling attacks particularly users tell predictions manipulated 
mapping opinions ratings complex recommenders represent user opinion item single number rating scale 
scales vary widely granularity 
commerce systems purchase decisions proxy ratings resulting unary scale bought items liked unknown binary scale bought items liked items disliked 
systems ask users rate star likert style scale 
launch com allows users rate songs scale plus control call britney spears button allows user hear particular song 
jester joke rating system lets users click continuous bar generating ratings 
moviecritic com point scale 
asks ratings right 
generally qualities rating scale possess 
ideally rating scale allow users express opinions meaningful way effort 
tricky opinions complex 
consider user research recommender trying assign rating 
opinion depends importance topic quality originality research quality writing relevance research mood reading 
recommender systems despite asking users map complex opinions number suspect identifying values help recommender systems better 
presumably high users create correct number categories distinguish levels liking high users judgments categories 
scale allow system accurate predictions 
user able sensible evaluations trust predictions recommender 
intuitively fine grained rating scale properties 
movielens users number request rate movies half star scale swearingen sinha find users prefer continuous feel interface :10.1.1.15.7347
finer granularity lead better recommendations happier users 
users able fine distinctions levels liking 
additional expressiveness just produce noise 
contributions best knowledge studied recommendations affect users opinions items recommended 
extent effects occur practice may dramatic importance design recommender system interfaces practical implementation 
believe important characterize publish effects recommender systems designers users plan 
conduct experiments total users order answer questions consistent users re rating items 
users want rating scale 
different rating scales affect users ratings 
rating scale affect prediction accuracy common collaborative filtering algorithms 
showing predictions affect users ability re rate items consistently 
happens system shows deliberately incorrect predictions users re rate movies 
system user rate bad movie 
happens recommender shows deliberately correct predictions movies rated 
users notice predictions manipulated 
remainder addresses questions 
survey related establish theoretical basis research questions 
outline experiments performed address questions tackle questions 
discuss implications answers recommender system designers researchers 
related recommender systems recommender systems number strategies modeling users 
common model users assign ratings items 
target user wants recommendations system calculates predictions estimates target user rate items 
typically recommends items high predicted ratings 
content filtering collaborative filtering cf broad classes strategies computing predictions 
content systems build profile keywords items users recommend new items match profile 
strategy works text domains content hard analyze 
finding similarity content items cf systems find similar users target user comparing users opinions items 
common cf systems compute similarity users comparing vectors ratings pearson correlation cosine similarity distance metrics 
systems predictions computing weighted average votes similar users 
collaborative filtering works number domains 
resnick approach filter usenet news grouplens system 
shardanand maes built ringo music recommender hill built early recommender movies 
number systems built cf widely strategy recommending items commerce 
introduce basic ideas collaborative filtering experiments movielens cf recommender system movies 
believe results apply recommender systems general 
ratings consistency hill asked users re rate movies rated weeks earlier 
users responded strong correlation earlier ratings 
pennock assume users give ratings gaussian probability distribution personality diagnosis algorithm explicitly recognizing people may rate item differently different times 
extends hill measuring consistently users re rate items different scales seeing predictions rating affects users consistency 
recommenders influencing users angry movielens user complains giving high ratings bad movies attempt deceive system 
seen little evidence attacks movielens attacks plausible detrimental users 
dellarocas outlines possible attacks recommender systems strategy minimizing impact attacks 
domingos richardson explore target marketing users recommender system looking members influential generating recommendations users 
look impact successful attack users decisions seeing ratings change predictions artificially manipulated 
newly added movies receive higher ratings 
believe users apt movie tend users see rate movie 
design rating scales choice rating scales major concern survey design 
friedman examine aspects designing likert style scales including labels associated choice question interpretation rating scale balance ordering choices number choices 
friedman show changing scale range affect distribution responses 
garland suggests excluding middle choice reduce respondents bias providing positive replies doing produce distorted results 
suggests effectiveness rating scales domain dependent 
empirically investigate effect different rating scales user satisfaction prediction accuracy area recommender systems 
conformity persuasive computing psychologists studied people opinions may affect 
classic conformity study asked subjects compare lines line choose line length line 
subject performed task times 
answer easy see cases 
subjects choices sitting small group experimenter deliberately wrong choices 
third trials ended subject making incorrect choice subjects wrong choice 
factors contribute conformity including desire fit group norms fact receiving information opinions experiment information incorrect 
course computers people 
conformity effect appear information provided computer person 
people feel urge fit computer opinions movies 
studies area persuasive computing suggest answer 
nass moon survey number experiments 
instance people react interfaces gender ethnicity computer actual people gender ethnicity 
people polite computers give critical evaluations computer performance computer asks evaluation compared different computer asking evaluation 
literature conformity persuasive computing provides theoretical framework research questions 
experiments conducted series experiments movie lens recommender system uses collaborative filtering recommendations 
movielens users movies ratings 
experiment asked users rate set movies 
movie chose baseline user prior rating movie rated best prediction rating movie hadn 
compared ratings experiment baseline 
cases baseline computing prediction show users rated item 
describe experiments detail 
re rate re rating movies showing predictions user experiment randomly selected movies previously rated stars 
limited movies ratings middle star scale ratings change positively negatively 
asked users re rate movies recording original rating re rating pair 
system screens movies 
predictions shown screen 
screens showed movies prediction equal user original rating prediction star original rating prediction star original rating 
balancing manipulation leaves mean prediction unchanged variance increases 
movies predictions randomly distributed screens effort disguise manipulation 
unrated manipulating predictions unrated movies experiment similar re rate 
user selected movies rated 
movielens normally rounds predictions nearest half star wanted experiment similar possible re rate chose movies best prediction stars stars 
users divided experimental group control group 
experimental group divided movies sets prediction actual prediction prediction plus star prediction minus star 
movies displayed similarly re rate 
compared experimental users ratings actual predictions 
control group performed task shown predictions actual predictions 
surveyed groups satisfaction experimental predictions movielens predictions general 
scales re rating movies rating scales user chose movies rated 
required user rated movies different ratings movielens rating scale 
randomly divided movies sets asked users rate set rating scales binary thumbs thumbs 
zero scale zero 
half star star scale half star increments 
different movies scale set movies scales afraid rating movie times bias way users mapped ratings scale 
looked new ratings mapped original ratings 
follow survey month asked users liked scale 
user selection movielens provides infrastructure conducting experiments real users 
user logs experiment active user qualified experiment user sees link main movielens page asking participate 
clicks link system presents consent form 
users consent experiment randomly assigned experimental group 
process easy conduct experiments real users movielens 
bias selection process users log willing participate experiments 
re rate users re rated movies 
total users participated unrated experimental group users giving total new ratings 
users re rated movies scales scales 
user participated experiment 
answering questions set answer questions posed earlier 
consistent users re rating items 
hill correlation users original ratings set movies users ratings movies weeks 
interested seeing correlation held ratings months years users tastes opinions change 
looked consistently users re rated movies showed prediction re rate 
users provided total ratings portion experiment 
users re rated original rating time time 
mean new rating stars mean original rating 
correlation original ratings re ratings 
data suggest users reasonably consistent re rating movies 
correlation lower hill quite strong 
possible explanation reduced correlation limited set re rated movies original ratings allowed users err directions 
users want rating scale 
previous suggested users prefer rating scales 
verify conducted followup survey users scales 
asked users liked rating binary zero half star scales original movielens scale 
asked rank scales order preference 
users responded survey 
users liked half star scale average satisfaction followed binary zero half star total ratings original mean new mean correlation table user ratings new scales versus original ratings 
scales normalized zero range 
users rate significantly higher binary scales 
ratings correlate strongly scales 
users mapped original ratings binary scale 
original ratings predominantly thumbs higher ratings map thumbs 
original movielens scale average zero scale binary scale 
appears users finer grained scale best 
granularity factor users zero scale better original movie lens scale 
may users comfortable familiar original scale 
possibility scale put emphasis bad movies 
user said zero scale goes deep ratings bad movies deep movies 
don go see movies expect really bad need point scale rate movies different rating scales affect users ratings 
look rating scale affects way users map opinions ratings 
scale table shows ratings users gave scale mean original rating movies rated scale mean new rating correlation old new ratings 
users gave higher mean ratings binary zero scales 
new ratings correlate strongly original ratings scales binary scale 
shape distributions similar finer grained scales 
shows users mapped original ratings binary scale 
users generally mapped original ratings thumbs original ratings binary zero half star total predictions original mae new mae table recommendation accuracy ratings new scales versus accuracy original ratings 
scales normalized zero range 
mae significantly higher binary scale lower half star scale 
thumbs 
tendency rate thumbs binary scale explains increase average rating 
users give borderline movies benefit doubt forced rate coarse scale 
rating scale affect prediction accuracy common collaborative filtering algorithms 
looked scale difference accuracy collaborative filtering predictions 
protocol breese 
protocol remove rating entire dataset prediction remaining data compute absolute error prediction rating left 
averaging absolute error items system predictions gives system mean absolute error mae dataset 
mae comparable different scales normalized scale continuous zero scale 
table compares mae predictions new scales versus predictions old scales 
number predictions original mae differs scale scales asked users rate different set movies scale 
compared star scale mae worse binary scale point scale better point scale 
hesitate draw mae results differences statistically significant binary half star scales 
relatively small datasets collected experiment produced mae values higher normally expect collaborative filtering system 
mae original ratings higher half star scale 
mae fall scale granularity increases 
size prediction errors drop quantum rating smaller bringing average error 
showing predictions affect users ability items consistently 
turn back re rate see showing predictions users rate movies affects ratings 
compare movies users re rated seeing predictions movies re rated seeing accurate prediction user original rating 
ratings re shown 
percentage re ratings original ratings broken original rating shown prediction 
showing predictions causes users rate significantly original rating 
shows users re rated movies original rating depending saw prediction 
users average re rating average original rating cases 
users re rated original rating significantly saw predictions 
interpretation fact users rate lower variance see predictions helps remember old rating reducing noise re ratings 
different interpretation lower variance means influencing people beliefs convincing rate prediction shown system 
happens system shows deliberately incorrect predictions users re rate movies 
decide interpretation correct looked users gave movies system altered prediction star user original rating 
re rate experiment users saw total movies accurate conditions 
movies randomly ordered disguise manipulation 
users gave total ratings condition 
shows users re rated movies original rating system showed predictions star star original rating 
users rate original rating higher lower mean ratings system shows higher mean lower mean predictions compared system shows accurate predictions 
differences statistically significant 
system user rate bad movie 
wondered sticking points rating scale hard influence people cross 
remember scales users mapped star ratings thumbs star ratings thumbs 
system get users rate star movies lower star movies higher reverse 
ratings re accurate percentage re ratings original ratings broken prediction manipulated 
showing predictions altered downward upward causes users rate significantly lower higher 
accurate ratings percentage re ratings predictions rating previously unrated movies depending prediction manipulated 
showing predictions altered downward upward causes users rate significantly lower higher accurate predictions shown 
case 
matter original rating stars effect new ratings re rate 
suggests recommender system influence users move negative positive rating 
happens recommender shows deliberately incorrect predictions movies rated 
user may chosen star rating movies seen expect showing predictions users rate movies time stronger effect 
turn unrated explore question 
un rated similar re rate movies user rated movies user rated 
original rating baseline prediction computed net perceptions recommender engine baseline 
shows users rated predictions shown prediction lowered star accurate raised star 
users gave ratings condition 
users rated actual prediction cases pattern users rat experiment movielens accurate useful accurate useful excellent fair poor awful table user opinions accuracy usefulness experimental recommendations movielens recommendations general expressed percentages 
excellent positive fair negative control group significantly positive evaluations experimental group questions 
ing shown prediction clear 
compared actual predictions shown users mean rating stars higher seeing inflated predictions stars lower seeing lowered predictions 
differences statistically significant 
users rated prediction significantly predictions shown compared 
users notice predictions manipulated 
appears showing predictions unrated movies lead users rate direction prediction 
bad news users news users detect manipulation 
unrated control group performed exactly rating task experimental group system showed prediction showed actual prediction 
asked groups complete survey accuracy usefulness recommendations received experiment accuracy usefulness movielens recommendations general 
table shows users responses 
control group expressed significantly satisfaction experimental group 
believe experimental users sensed predictions inaccurate inaccuracy led decrease liking movielens 
putting shown recommender predictions influence way users rate movies 
mean changing user opinion just affecting expression opinion rating 
believe showing predictions change people opinions 
addition findings reports people believed longer line shorter gave wrong answers 
decided judgment wrong adopt group judgment 
don know long change opinion lasts 
interesting change lasts longer just moment rating 
believe change lasting person rated movie stars tend think star movie 
system influences user opinion matter long change opinion lasts effect ratings difference practical standpoint making recommendations 
system receives higher ratings car tend calculate higher predictions movie recommend users 
increases value manipulating recommender manipulator 
long believed recommender systems artificially high ratings item users give true ratings item cause recommended 
results suggest self correction may reduced influence manipulated predictions ratings 
open season manipulate users 
accurate predictions error users detect additional error manipulated predictions 
hersh users search engines better showed equal satisfaction systems suggesting users sensitive differences search engine quality 
contrast results show experienced users recommender system sensitive quality 
mean designers 
movielens users ask ability hide predictions rating items 
rightly suspected seeing prediction influence rating 
users happy learn preferences accurately designers accommodate 
convenient users allow rate item system shows item 
interface designers consider designs allow users concentrate rating ignoring prediction 
users prefer finer grained rating scales 
adverse effect prediction accuracy idea 
fact user ratings correlate scales designer choose allow users rate scale wish computing recommendations normalized scores 
designers take care scale allows users meaningful distinctions 
instance users may need distinguish degrees badness 
launch com interface allows rating plus play option fits model 
system clear rating scale measuring levels goodness 
authors launch 
launch plays song explanation rated song rating 
thought low rating system apparently 
appears users sensitive manipulation predictions 
sensitivity manipulation suggests sensitive inaccuracy important choose algorithm 
just depends sensitive users inaccuracy open question know thirds items star 
showing predictions users rate movies changes ratings don know long change opinion lasts 
show bias 
matter sort item system recommends 
users may rate movies carefully rate say computer monitor 
case users influenced predictions computer hardware recommender 
intriguing question manipulating predictions affect users opinions movies haven seen 
presumably users go see movies higher recommendations 
users see movies receiving artificial positive recommendation movies saw artificial negative 
saw user satisfaction suffered manipulated ratings probably due lower accuracy 
interesting see just sensitive users inaccuracy react differently manipulation known unknown vs forms inaccuracy 
recommender systems designers researchers primarily focused delivering accurate recommendations 
accuracy problem solved tuned algorithms produce similar error patterns wide range algorithmic approaches data sets 
delivering accurate predictions users way creates best experience remains open problem 
effect presentation interface studied area significant improvements 
supported national science foundation iis iis iis iis 

friedman 
numeric values influence subjects responses rating scales 
journal international marketing marketing research february 


effects group pressure modification distortion judgements 
groups leadership men pages 

breese heckerman kadie 
empirical analysis predictive algorithms collaborative filtering 
proc 
uai pages july 

dellarocas 
online reputation reporting systems unfair ratings discriminatory behavior 
proc 
nd acm conference electronic commerce pages minneapolis 

domingos richardson 
mining network value customers 
proc 
sigkdd pages san francisco 
acm press 

friedman 
rating rating scales 
journal marketing management 

garland 
mid point rating scale desirable 
marketing bulletin 

goldberg roeder gupta perkins 
eigentaste constant time collaborative filtering algorithm 
information retrieval 

herlocker konstan riedl 
explaining collaborative filtering recommendations 
proc 
cscw pages 

hill stead rosenstein furnas 
recommending evaluating choices virtual community 
proc 
chi pages 

nass moon 
machines social responses computers 
journal social issues 

pennock horvitz lawrence giles 
collaborative filtering personality diagnosis hybrid memory model approach 
proc 
uai pages san francisco july 

resnick iacovou suchak bergstrom riedl 
grouplens open architecture collaborative filtering netnews 
proc 
cscw pages 

sarwar karypis konstan 
item collaborative filtering recommendation algorithms 
www pages 

shardanand maes 
social information filtering algorithms automating word mouth 
proc 
chi pages 

swearingen sinha 
interaction design recommender systems 
designing interactive systems dis london june 

hersh 
batch user evaluations give results 
proc 
sigir pages new orleans sept 
