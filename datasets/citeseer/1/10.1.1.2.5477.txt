automatic mood detection acoustic music data dan liu department automation tsinghua university beijing china mails tsinghua edu cn music mood describes inherent emotional meaning music clip 
helpful music understanding music search music related applications 
hierarchical framework automate task mood detection acoustic music data music psychological theories western cultures 
feature sets intensity timbre rhythm extracted represent characteristics music clip 
mood tracking approach piece music 
experimental evaluations indicate proposed algorithms produce satisfactory results 
music databases personal computer internet people start realize importance creating metadata allow users access musical works easily 
traditional information name artist title remains important tags limited applicability music related queries 
nowadays users expect semantic metadata archive music similarity style mood 
compared works focused mood detection 
common opinion mood detection emotional meaning music subjective depends factors including culture 
music psychologists agree culture great importance people mood response music factors including education previous experiences 
cultural context agreement individuals mood elicited music boyle 
krumhansl krumhansl pointed musical sounds inherently emotional meaning 
example music patterns represent relaxing individual feel anxious permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
johns hopkins university 
lie lu microsoft research asia sigma center district beijing china microsoft com hong jiang zhang microsoft research asia sigma center district beijing china microsoft com 
possible build mood detection system concrete environment example classical music western culture 
works touched field 
liu liu zhang zhu mood recognition system fuzzy classifier adopted classify mood johann strauss waltz clusters 
system tempo loudness pitch change note density timbre extracted midi file primitives recognize mood music 
imai inokuchi sentiment extraction system pop music monophonic acoustic data firstly transcribed music codes 
primitives music melody rhythm harmony form extracted music codes 
works led impressive results concentrated midi symbolic representations due difficulty extracting useful features acoustic data 
music real world symbolic form existing transcription system translate symbolic representations scheirer 
necessary deal acoustic data directly 
mood detection algorithm classical music acoustic data 
mood taxonomy issue mood detection mood taxonomy music psychology traditional approach describing mood response adjective descriptors hopeful adjectives varied quite freely different researches liu zhang zhu imai inokuchi 
standard mood taxonomy system accepted currently adjective checklist served basis subsequent research mood response music 
checklist composed adjectives clusters include sober robust 
adjectives cluster approximately meaning difficult discriminate 
ambiguity performed microsoft research asia difficult obtain ground truth 
doesn indicate underlying stimulus influences responses great importance computational modeling 
late thayer thayer proposed dimensional mood model 
checklist uses individual adjectives collectively form mood pattern dimensional approach adopts theory mood entailed factors stress happy anxious energy calm energetic divides music mood clusters depression anxious shown fig 

energy fig 
refers happy calm music bach jesus joy man desiring depression refers calm anxious music opening refers happy energetic music william tell anxious refers anxious energetic music berg 
definitions clusters explicit dimensional structure gives importance cues computational modeling 
applied mood detection system 
hierarchical framework group little feature music clip intensity anxious depression stress thayer model mood big depression group feature anxious mood detection framework thayer hierarchical model mood thayer hierarchical framework proposed mood detection illustrated fig 

pointed factors thayer model mood energy computationally tractable estimated simple amplitude measures 
fact energy depression usually anxious 
features representing energy firstly classify mood clusters groups 
energy little classified group depression classified group anxious 
features determine exactly mood type framework music psychological theory 
performance different features discriminating different mood clusters pairs framework making possible suitable features different tasks 
hierarchical methods better sparse training data non hierarchical counterparts mccallum 
structured follows 
section describes extraction features 
detailed mood detection process section 
section automatic segmentation approach mood tracking piece music 
section deals empirical experiments performance evaluations proposed algorithms section directions 
feature extraction indicated mode intensity timbre rhythm great significance different music moods boyle krumhansl 
example major keys consistently associated positive emotions minor ones associated negative emotions 
mode difficult obtain acoustic data 
rest features extracted mood detection system 
compared dimensions thayer model mood intensity corresponding energy timbre rhythm corresponding stress 
input music clip sampled uniform format hz bits mono channel divided non overlapping ms long frames 
frame filter bank divide frequency domain sub bands refers sampling rate number sub band filters 
real implementation sub bands 
timbre features intensity features extracted frame 
means variances calculated music file timbre intensity features sets rhythm features extracted directly music clip 
order remove relativity raw features karhunen loeve transform performed feature set 
transform feature vectors mapped orthogonal space covariance matrix diagonal new feature space 
procedure helps achieve better classification performance gmm classifier 
detailed feature extractions follows 
timbre features existing results show timbre sound determined primarily spectral information different sub bands zhang kuo 
spectral shape features spectral contrast features 
spectral shape features spectral contrast features detail features listed table 
spectral shape features include centroid bandwidth roll spectral flux widely represent characteristics music signals tzanetakis cook 
important mood detection 
example centroid music usually higher depression generally associated high pitch depression low pitch 
octave spectral contrast features represent relative spectral distributions due properties music genre recognition jiang lu zhang tao cai 
intensity features intensity approximated signal root mean square rms level decibels 
essential mood detection intensity music depression usually little anxious usually big 
system intensity subband sum 
rhythm features feature name definition aspects rhythm closely related people mood response strength regularity tempo 
example cluster rhythm usually strong steady tempo fast depression music usually slow distinct rhythm pattern 
features extracted accordingly 
drum bass instruments important components represent rhythm show properties mainly lower sub bands system lowest sub band extract rhythm features 
amplitude envelope extracted sub band half hamming raise cosine window canny estimator estimate difference curve represent rhythm information 
peaks threshold rhythm curve detected bass instrumental onsets 
features extracted follows centroid mean short time fourier amplitude spectrum 
bandwidth amplitude weighted average differences spectral components centroid 
roll th percentile spectral distribution 
spectral flux norm distance frame frame spectral amplitude difference 
sub band peak sub band valley sub band average average value small neighborhood maximum amplitude values spectral components sub band 
average value small neighborhood minimum amplitude values spectral components sub band 
average amplitude spectral components subband 
table definition timbre features average strength average strength bass instrumental onsets 
average correlation peak average maximum peaks auto correlation curve 
regular rhythm higher value average tempo common divisor peaks auto correlation curve 
mood detection feature sets extracted section mood detection process performed hierarchical framework illustrated fig 

compared nonhierarchical counterpart shown fig 
hierarchical framework stress different features different classification tasks better sparse training data mccallum 
system gaussian mixture model gmm utilized model feature set 
constructing gmm expectation maximization em algorithm estimate parameters gaussian component mixture weights 
initialization performed means algorithm 
music clip firstly classified group depression group anxious intensity information classification performed group timbre rhythm features fig 
illustrates 
classify music clip groups simple bayesian criteria employed select select gi represents different mood group represents intensity feature set 
group probability exact mood timber rhythm features calculated music clip mi mood cluster represent timbre rhythm features respectively weighting factors emphasize different features mood detection different mood groups 
group tempo mood clusters usually slow rhythm pattern generally steady timbre usually brighter harmonic depression 
timbre features important rhythm features classification group 
contrary group rhythm features important 
usually distinguished steady rhythm anxious timbre features similar instruments mood clusters mainly brass 
facts usually set larger 
detailed values experiments section 
probability obtained bayesian criterion similar equation employed classify music exact mood cluster 
mood tracking intensity gmm group group previous sections algorithm mood detection music clip mood type consistent 
mood usually changeable piece classical music timbre gmm rhythm gmm timbre gmm rhythm gmm mood mood mood mood layer layer layer music clip hierarchical mood detection framework intensity timbre rhythm gmm depression anxious non hierarchical mood detection framework depression anxious appropriate detect mood range song 
fact necessary divide music independent segments contains constant mood detect mood type segment respectively 
way mood tracked piece music 
changes intensity timbre main cues new sound event important segmentation tzanetakis cook features complement improve performance segmentation method 
music theory paragraph usually bars fast tempo bar second classical music 
assume minimum segment length seconds set basic processing unit seconds window second temporal resolution 
find segment boundary divergence shape campbell measure dissimilarity contiguous windows supposing features gaussian distributed tr ci cj estimated covariance matrix ith th window respectively 
base dissimilarity measure confidence boundary defined conf dt exp conf exp mean variance intensity dissimilarity contiguous windows mean variance timbre dissimilarity contiguous windows ai normalization 
total confidence conf conf conf weighting factor set 
real implementation 
potential chance boundary ith th window conditions satisfied conf conf conf conf conf th conf confidence segment boundary ith jth window thi threshold 
conditions guarantee local peak exists condition prevent low peaks detected 
threshold adaptively set context th conf number previous succeeding distances predict threshold amplifier 
algorithm set 
obtain optimal result 
threshold automatically set neighborhood second assumed minimum length segment 
threshold works song need refine boundaries potential boundaries exit second assumption minimum length segment 
case distances current segment neighbor segments compared combined similar 
experiments experiments section evaluate proposed mood detection system 
experiment shows performance selected music clips inside mood type consistent 
second experiment mood tracking method evaluated famous music works 
mood detection music clips database contains pieces music composed mainly classical period romantic period 
orchestra piano string quartet included ensure diversity music style database 
music experts participated selecting annotating representative music clips seconds long database mood clusters depression anxious 
music clips evaluation 
clusters clips cluster mainly selected christian music clips mainly march dancing music 
depression anxious clusters music selected broader music genres dominant genres clusters 
mood usually changeable piece classical music mentioned music clip seconds long selected carefully ensure perceived mood consistent representative 
example light contains clips depression clips 
classification results calculated crossvalidation evaluation dataset evaluated randomly partitioned testing training 
process iterated different random partitions results averaged table table iterations performed 
ensures calculated accuracy biased particular partitioning training testing 
part shows standard deviation classification accuracy 
order emphasize importance timbre rhythm features different mood groups different weighting factors equation achieved optimal average accuracy 

confirms timbre features important classify depression group rhythm features important discriminate anxious group 
depression anxious depression anxious table mood detection confusion matrix hierarchical framework depression anxious depression anxious table mood detection confusion matrix nonhierarchical framework table shows detailed results form confusion matrix row corresponds actual mood cluster column predicted cluster 
seen table music group depression classified group anxious music group classified group 
accuracy rate reaches step intensity features classify music clips groups 
result confirms performance intensity features discriminating groups mood clusters basis classification timbre rhythm features 
order compare performance hierarchical framework non hierarchical counterpart comparative experiment performed framework shown fig 
integrates feature sets carries classification directly 
corresponding results shown table 
comp table table seen classification accuracy proposed hierarchical framework better non hierarchical framework 
standard deviation classification accuracy decreases indicates framework constant 
seen adopting proposed framework classification accuracies clusters improved especially 
non hierarchical framework clips classified anxious decreased hierarchical framework 
experimental results show proposed hierarchical framework better performance non hierarchical counterpart efficient features different mood clusters 
mood tracking mood cluster mood tracking ground truth mood tracking segment mood tracking clip potential boundary refined boundary proposed mood tracking method evaluated pieces classical music achieved satisfactory result 
example correctly detect constantly second movement beethoven symphony mainly depression 
time index mood tracking results part fig 
shows results mood tracking part composed 
shows potential boundaries refined boundaries 
seen correct boundaries recalled exist false alarms 
ensures mood inside segment consistent 
compared mood tracking results approach clips ground truth seen approach detect boundaries resulting mood tracking performance better detecting mood seconds 
mood detection approach classical music acoustic data 
thayer model mood adopted mood taxonomy efficient feature sets extracted directly acoustic data representing intensity timbre rhythm respectively 
hierarchical framework detect mood music clip 
order detect mood piece music segmentation scheme mood tracking 
algorithm achieves satisfactory accuracy experimental evaluations 
improvements proposed algorithm 
extracting powerful features better represent music primitives music perception 
furthermore try efficient ways mood tracking 
extent mood detection algorithm styles pop music 
campbell 

speaker recognition tutorial 
proceeding ieee 

content classification search retrieval audio 
ieee trans 
multimedia 


expression music discussion experimental studies theories 
psychological review 


effect major minor mode music mood induction procedure 
master thesis virginia polytechnic institute 


ramp archetype maintenance auditory attention 
music perception 


perceptual cognitive applications music information retrieval 
international symposium music information retrieval ismir 
jiang lu zhang tao cai 

music type classification spectral contrast features 
proceeding int 
conf 
multimedia expo 


music appreciation th edition 
mcgraw hill imai inokuchi 

sentiment extraction music proceeding int 
conf 
pattern recognition pp 

krumhansl 

music link cognition emotion 
current directions psychological science 
liu zhang zhu 

form mood recognition johann strauss waltz 
chinese journal electronics 
press mccallum 
improving text classification shrinkage hierarchy classes 
proceeding 
int 
conf 
machine learning pp 

boyle 

psychological foundations musical behavior 
illinois charles thomas 
scheirer 

music listening systems 
ph 
thesis mit media lab 
thayer 

mood arousal 
oxford university press 
tzanetakis cook 

audio segmentation browsing annotation 
ieee workshop applications signal processing audio acoustics pp 

tzanetakis cook 

music genre classification audio signals ieee trans 
speech audio processing 
zhang kuo 

hierarchical system content audio classification retrieval 
proceeding spie conference multimedia storage archiving systems iii pp 

