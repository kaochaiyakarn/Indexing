discrete event simulation bulk synchronous parallel model mauricio mar st cross college computing laboratory oxford university wolfson building parks road oxford ox qd uk supervisor prof mccoll submitted faculty mathematical sciences partial fulfillment requirements degree doctor philosophy university oxford november bulk synchronous parallel bsp model computing proposed enable development portable software achieves scalable performance diverse parallel architectures 
number applications computing science demonstrated efficiently supported bsp model practice 
thesis study efficient realisation parallel discrete event simulation pdes bsp model 
focus design analysis implementation bsp synchronisation protocols pdes 
show possible achieve efficient performance important classes irregular systems 
practical results enable development portable scalable parallel simulation kernels discrete event simulation 
topics studied involve efficient administration pending events arising large scale simulations sequentially parallel ii analysis relevant factors leading efficient scalable pdes bsp computers iii development optimistic synchronisation protocols adaptively tune operation evolution simulation load iv comparative evaluation optimistic conservative synchronisation protocols efficient parallel simulation class complex systems 
contribute topic new insights techniques 
main result thesis new optimistic synchronisation protocol general purpose pdes call bsp time warp 
contents bsp pdes 
new bsp protocol general purpose pdes 
thesis organisation 
background bsp model 
theoretical cost model 
empirical cost model 
programming model 
parallel discrete event simulation 
conservative asynchronous protocols 
conservative synchronous protocols 
optimistic asynchronous protocols 
optimistic synchronous protocols 
bsp framework pdes 
asynchronous protocols 
synchronous protocols 
parallel min reduction 
double buffering 
advantages bsp model 
basic guidelines efficient simulation 
previous 
conservative simulation 
optimistic simulation 
conservative simulation revisited 
sequential simulator bsp protocols 
tournament event queues 
tournaments 
average case bounds 
contents empirical results 
tournaments 
empirical results 
single item operations erew prams 
average path 
parallel priority queues crew prams 
parallel priority queues bsp computers 

analysis synchronisation methods 
previous 
load 
bsp hold model phold 
analysis technique 
approaches time advance 
average case analysis supersteps 
synchronous time advance 
asynchronous time advance 
average case analysis load balance 
synchronous time advance 
asynchronous time advance 
bsp cost synchronisation protocols 
comparisons 
comments 

bsp time warp 
previous 
basic bsp time warp engine 
adaptive synchronisation method 
oracle simulation 
sequential event list sizes 
flow control 
recovery memory stalls 
protocol instance results 

contents evaluation optimistic protocols 
performance metrics load 
optimistic protocols 
bsp time warp tw 
moving time window mtw 
filtered roll back 
bounded time warp btw 
breathing time buckets btb 
time warp stw 
breathing time warp 
comparative study 
symmetric hold model 
asymmetric hold model 
reducing slackness 
reducing oracle predictions 
increasing processors 

evaluation conservative protocols 
performance synchronisation protocols 
performance metrics load 
conservative protocols 
time buckets tb 
cmb deadlock recovery cmb dr 
cmb null messages cmb nm 
bounded lag bl 
conservative time windows shortest paths ctw sp 
yawns 
comparative study 
comparison time warp 
increasing lookahead asymmetry 
speedups 
asymptotic trend 

experience special purpose protocols 
basic bsp simulation algorithms 
ising spin systems 
contents hard disk fluids 

summary results concluding remarks 

benchmark methodology feasible speedups 
example 
validation 
load balancing strategies evaluation practical methods 
loads 
load balancing methods 
experiments 
results bsp time warp 
results moving time window 
practical realisation 
automatic mode 
research 
regression analysis supersteps 
sync 
async 
event efficiency 
sync 
async 
contents main abbreviations symbols bsp bulk synchronous parallel model 
pdes parallel discrete event simulation 
lp logical process 
sync synchronous simulation time advance 
async asynchronous simulation time advance 
sstep superstep 
time simulation time 
tw time warp protocol 
gvt global virtual time 
cmb chandy misra bryant protocol 
phold parallel hold model 
pes pending event set 
pq priority queue 
cbt tournament complete binary tree 
ln logarithm base lg logarithm base 
bsp parameters 
number processors 
number lps processor 
total number lps 
number events lp 
total number pending events 
total number simulated events 
upper limit events processor superstep 
number simulated events superstep 
speedup 
event efficiency oracle 
supersteps unit simulation time 
event efficiency synchronisation protocol 
balance computation 
message efficiency synchronisation protocol 
balance communication 
ratio protocol async oracle 
ratio committed events simulated events 
number normal events superstep 
software overheads 
base lookahead 
chapter discrete event simulation widely technique study dynamic systems complex modelled realistically analytical numerical methods 
refer systems represented collection state variables values change instantaneously occurrence events simulation time 
methodology empirical analysis deserved intensive research activity years 
similar application areas computing science main objective realise sophisticated easy software environment provides non expert user complete assistance iterative process involved simulation study model specification implementation ii verification validation iii experimentation data analysis 
results active research areas computing science far develop increasingly better approximations software environments graphical modelling animation cf 
expert systems assisting model definition process data analysis cf 
model component experimental result databases cf 
object oriented simulation languages cf 
data structures algorithms sequential parallel implementation simulation kernels cf 

difficult find real life systems associated simulation programs computationally intensive consider parallel computing parallel discrete event simulation feasible form computation parallel discrete event simulation attracted considerable amount interest years 
pragmatic standpoint interest arises fact large simulations engineering computer science economics military applications mention consume enormous amounts time sequential machines 
academic point view parallel simulation interesting represents problem domain contains substantial amounts chapter 
parallelism paradoxically surprisingly difficult practice 
sufficiently general solution parallel discrete event simulation problem may lead new insights parallel computation 
similar parallel software development decade prevalent approach parallel discrete event simulation followed machine dependent trend solutions tailored specific architectures 
currently greatest challenges parallel computing establish solid foundation guide rapid process convergence observed field parallel computer systems enable architecture independent software developed emerging range scalable parallel systems 
bulk synchronous parallel bsp model proposed provide foundation demonstrated successful bridge hardware software number important applications 
thesis presents new challenge bridging model efficient realisation parallel discrete event simulation 
results show possible achieve objective profit crucial advantage bsp model scalable performance portability diverse parallel architectures 
bsp pdes bsp model parallel computer seen composed set processor components communicate messages 
computation organised sequence supersteps 
superstep processors may perform sequential computations local data send messages processors 
messages available processing destinations superstep superstep ended barrier synchronisation processors 
modes bsp programming envisaged direct mode programmer deals explicitly placement data distributed memory automatic mode memory management transparent programmer means shared memory implemented hashing techniques 
thesis focus mainly bsp algorithms direct mode practical mode current parallel computers enables design algorithms near optimal efficiency cases 
parallel discrete event simulation pdes hand adopts view systems chapter 
composed set logical processes lps send timestamped messages 
lps encapsulate state variables system messages contain events scheduled occur specific points simulation time 
events may modify lp state variables may schedule occurrence new events lps 
lps placed processors faced problem synchronising occurrence events take place parallel 
non trivial task necessary ensure simulation event taken place chronological timestamp order respective lp 
events associated effects user defined constructs depend particular features system simulated 
words fixed patterns data dependencies exploited define parallel algorithm 
contrary dependencies change system dynamically simulation system complicates synchronisation parallel events 
substantial amount research pursued decade solve event synchronisation problem efficiently 
number synchronisation protocols far proposed classified conservative optimistic protocols asynchronous synchronous modes operation identified 
cases synchronous protocols operate bulk synchronous fashion similar promoted bsp model 
conservative view synchronisation problem events allowed take place respective lps certainty earlier events take place lps 
identifying events safe process requires information events lps may schedule case insufficient information lps simply block 
blocked lps cause deadlocks cost mechanisms avoid detect break significantly high 
hand optimistic simulation adopts view letting events take place available processing lps executing correction procedure case missing simulation earlier events 
correction consists performing roll back simulation past re starting simulation involved lps point onwards 
addition erroneous event messages sent lps cancelled cause roll back lps 
simulation enter thrashing behaviour number length simulation time roll backs grow unboundedly 
specific solutions inefficiency problems conservative optimistic simulation greatly influenced underlying model parallel computing 
literature contains plenty methods devised approaches asynchronous message passing shared memory models 
thesis focus design analysis implementation synchronisation protocols bsp model parallel computing 
main results enable development portable scalable general purpose parallel simulation kernels 
chapter 
new bsp protocol general purpose pdes important part thesis devoted performance analysis synchronisation protocols pdes bsp 
analysis suggests bsp protocols advance simulation time asynchronous manner effective way achieve scalable performance 
consequently concentrate efficient realisation bsp simulations asynchronous time advance approach 
conservative case method time advance requires explicitly consider particular communication topology lps 
see restriction serious obstacle development general purpose simulation environments 
focus efficient realisation optimistic simulation bsp computers 
case classical algorithm advances asynchronously simulation time time warp protocol 
attempting fit message passing minded protocol bsp setting idea protocol asynchronous time advance roll backs simulation past formulate efficient algorithm pure bsp concepts 
result new technique optimistic simulation call bsp time warp 
despite importance development general purpose time warp systems topic received limited attention 
refer systems automatically tune particular features simulation load adaptively follow changes dynamic evolution 
efforts development automatic systems message passing shared memory environments 
approaches adopt lp oriented view problem attractive bsp setting organisation supersteps provides designer different view problem 
bsp time warp system proposed thesis idea global priority queue pq bsp superstep enables selection events timestamps system 
superstep events simulated roll backs processed accordingly 
newly generated rolled back events placed global pq roll back thrashing occur slow lps processing time fast lps 
small simulation requires large number supersteps complete 
reduces rate roll backs increases imbalance result small number simulated events superstep 
hand large number supersteps reduced near optimal values rate roll backs increases significantly 
propose novel method determining optimal simulation model 
method automatic require manual tuning user method adapts follow dynamic changes evolution simulation model 
unique feature proposed method bases operation statistics collected simulation ideal asynchronous bsp synchronisation protocol call oracle 
chapter 
oracle simulation performed fly time warp engine statistics collected periodically regular intervals supersteps 
method independent current tuning time warp engine oracle simulation independent tuning 
design oracle global computations required perform respective simulation 
enables processors decide locally number events simulated superstep 
key point simulation synchronised global level oracle processors need mimic local oracle computations 
existence global pq sense bsp operating direct mode distributed memory emulate global pq maintaining local pq processor 
task novel realisation hybrid pq proposed thesis 
hybrid pq particularly efficient optimistic simulation provides low cost buffering areas speculative events 
oracle simulation tells events retrieved local hybrid pqs superstep 
bsp operating automatic mode shared memory global pq implemented parallel pq 
paradoxically conservative optimistic synchronous protocols regard bsp ones efficient ones bsp setting 
theoretical empirical results thesis confirm claim 
thesis suggests asynchronous time advance realised truly bulk synchronous algorithms effective way achieve scalable efficient performance complex large scale systems 
bsp time warp provides practical realisation idea 
thesis organisation remainder thesis organised follows chapter presents brief survey bsp pdes pioneering provided basis research 
describe sequential simulator bsp protocols experimental studies 
chapter studies tournament tree basic data structure build efficient priority queue speculative events generated bsp time warp 
tree implement parallel priority queues 
chapter presents analysis synchronisation protocols pdes bsp 
analysis observation synchronisation protocols common synchronise events imposing specific method advance simulation time asynchronous synchronous 
study consequences advancing asynchronously synchronously simulation time bsp computer 
enables chapter 
identify approach allows development protocols efficient scalable performance 
chapter describes bsp time warp protocol proposed thesis 
design time warp engine introduces number optimisations grouped roll back processing tournament event management 
adaptive controller optimistic execution described 
main feature mechanism operation guided simulation idealised synchronisation protocol oracle 
design completed solution recover simulation transitory memory exhaustion 
chapter compares performance bsp time warp number alternative optimistic protocols 
protocols automatic adaptive implementing oracle simulation method proposed chapter 
comparative study set metrics provide implementation architecture independent information performance protocols 
chapter studies performance conservative protocols architecture independent performance metrics evaluating asymptotic cost model size architecture scale simultaneously 
establish comparisons bsp time warp 
chapter proposes special purpose bsp protocols class complex systems 
study systems colliding hard spheres ising spin models 
chapter example bsp protocols tailored specific applications simulated optimistic techniques crucial reduce memory overheads 
chapter presents suggests research pdes bsp 
appendix proposes benchmark methodology pdes bsp 
appendix describes implementation automatic load balancing methods bsp time warp 
study realisation optimistic simulation bsp automatic mode load balancing strategy 
appendix presents simulation results validate theoretical analysis chapter 
number results thesis conferences published journal see 
chapter background different approaches synchronising parallel simulation events classified conservative optimistic protocols 
identify asynchronous synchronous algorithms 
chapter discuss fundamental ideas supporting implementation protocols bsp model 
bsp model bulk synchronous parallel bsp computer consists set processor memory pairs communication network mechanism barrier synchronising processors 
bsp program consists sequence supersteps superstep ended barrier synchronisation processors 
superstep processors perform computations data held local memories send receive messages corresponding transfers non local data processors 
messages available processing superstep 
basic model specialised broadcasting combining facilities original proposal considered barrier synchronisation sub sets processors 
addition modes operation proposed bsp computer direct mode programmer responsible distribution management data processors distributed memory programming ii automatic mode bulk synchronous shared memory provided maintain global data application program 
chapter 
background network ring array butterfly log log hypercube log table bsp parameters communication networks 
theoretical cost model define time step real time required perform basic operation local data comparison multiplication 
performance bsp computer characterised architecture dependent parameters number processors ii processor speed measured number time steps second iii minimal number time steps elapsed successive barrier synchronisations processors iv ratio total number local operations performed processors second total number words delivered communication network second situation continuous traffic communication network normalised measure time steps required send receive word message 
table presents bounds values different communication networks 
cost superstep bsp algorithm determined follows 
maximum number local computation steps executed processor maximum number messages sent processor maximum number messages received processor cost time steps 
cost bsp algorithm sum costs supersteps 
empirical cost model table presents benchmark values bsp parameters parallel computers 
column represents average speed processors mflops 
parameter calculate parameter machine number transmitted words 
practical bsp parameters values follows 
suppose bsp algorithm empirical average maximum cost computation superstep ibm sp ii average maximum messages size words received sent chapter 
background machine mflops words words ibm sp sgi cray table bsp parameters parallel computers 
superstep iii algorithm executes total supersteps 
table enables estimate total running time algorithm running time algorithm cray estimated conservative estimation running times amplify cost communication receive send separately 
programming model currently bsp programs implemented bsp library called bsplib provides facilities barrier synchronising processors performing data transfers 
bsplib supports spmd style parallel programming set program copies running different processors 
programs execute sequence supersteps private data space 
supersteps programs follow different execution paths reach current superstep proceeding superstep 
bsplib composed routines spawn processes processors spmd ii barrier synchronise processors iii perform direct remote memory access data located processors iv perform bulk synchronous message passing processors 
enable processor declare register public memory chapter 
background operation routine semantics initialisation start spmd mode spmd mode synchronisation barrier synchronise communication write remote memory read remote memory declare public memory remove public memory communication send remote queue receive local queue declare length messages inquire local queue table bsplib main routines 
address processors read write data directly 
remote accesses take effect barrier synchronisation processors superstep 
organised set message queues processor processors perform non blocking send operations 
messages received target processors superstep sent 
bsplib programs written fortran 
table presents brief description main bsplib routines 
parallel discrete event simulation section brief survey synchronisation protocols parallel discrete event simulation pdes 
describe basic ideas details relevant thesis separately respective chapters 
thesis focus simulation systems state may change discrete points simulation time 
points associated timestamped events basic computational problem consists processing occurrence events nondecreasing timestamp order 
sequential approach problem straightforward data structure keep list pending events called event list exists cycle extracts chronological event event list 
simulation ends number cycles executed 
cycle occurrence event processed simulation clock instantaneously advanced timestamp event 
addition processing current event may cause insertion new events event list 
chapter 
background events affect small portion system state potential opportunities performing event processing parallel 
sequential event list distributed set parallel objects called logical processes lps 
lps interact messages contain events senders schedule occur receivers specific points simulation time 
called application lps 
addition special purpose lps source lps send messages sink lps receive messages 
lp maintains local simulation clock 
way process designing parallel simulation model consists basically defining behaviour lps interactions 
parallel event processing performed distributing lps processors 
constraint ensures final result equivalent sequential event list strategy lp cause event occurrences nondecreasing timestamp order 
adherence constraint trivial sort mechanism called synchronisation protocol introduced order synchronise simulation parallel events 
conservative asynchronous protocols approach synchronising parallel event processing conservative chandy misra bryant cmb protocol 
cmb lp process event certainty message earlier timestamp arrive lps 
safe events processed 
application lp set input output links defined accordance communication topology lps 
input link associated input message queue 
lps restricted send messages nondecreasing timestamp order output links 
link clock associated input link registers timestamp message respective input queue message received link queue empty 
lps perform cycle link clock smallest timestamp message stored respective input queue simulated called input rule 
input queue link clock empty lp block knowledge timestamp message arrive input queue 
blocking lps may lead deadlocks 
solution deadlock problem relies ability lps predict concept called lookahead 
null messages approach 
processing event lp sends timestamped null message output links inform downstream lps lower bound timestamp message 
downstream lps lower bound advance link clocks cause occurrence new events 
strategy mechanism deadlock detection recovery 
chapter 
background simulation allowed deadlock exists mechanism detects instant lps blocked messages transit 
event timestamp system safe process timestamp advance link clocks empty input queues 
lp un blocked approach 
distributed environment deadlock detection recovery implemented special message called marker 
marker visits lp periodically detect global deadlock determines pending event timestamp system 
new reception message lp verify processed message visit marker 
marker keeps flag lp deadlock detected flags set 
point lp advance link clocks time event system 
conservative synchronous protocols cmb approach example asynchronous protocol 
case lps advance local clocks independently local information messages received point simulation time 
synchronous protocols follow different approach imposing global synchronisation lps simulation time 
event processing restricted global interval simulation time window defined event window safe process 
synchronous protocols differ way perform global synchronisation simulation time barrier synchronisation processors main tool supporting schemes 
instance yawns protocol works cycles delimited synchronisation processors lps real simulation time respectively 
time window defined timestamp messages sent current cycle 
completing simulation events cycle lps engage computation timestamped message cycle 
operation carried parallel min reduction 
way protocol works cycles stages event processing followed min reduction 
chapter describe details protocol kind 
optimistic asynchronous protocols time warp tw representative optimistic asynchronous protocol lps optimistically process available events correction procedure executed time causality error takes place 
causality errors detected reception message contains event timestamp current simulation clock lp 
simulation event missed correction procedure consists rolling back lp state just occurrence 
chapter 
background arrives lp gamma arrives lp gamma eq eq discard gamma discard gamma insert eq insert gamma eq gamma eq eq discard gamma discard gamma rollback insert eq rollback insert gamma eq table rules message reception time warp normal message gamma timestamp eq event queue local virtual time time event simulated lp 
simulating occurrence lp allowed continue normal event processing may involve re simulation events simulated prematurely disposal invalidated 
premature events may sent messages lps making necessary cancellation 
performed sending anti messages respective lps 
table describes rules message processing 
support roll backs necessary keep copies processed events messages states 
lps rolled back earlier pending event time system 
quantity called global virtual time gvt represents global advance simulation 
point simulation speculative sense simulated events rolled back 
earlier point simulated events rolled back states events messages time gvt removed system fossil collection 
note tw may enter thrashing behaviour result imbalance speed propagation erroneous computations correction 
case number participating lps simulation time length roll backs may grow unboundedly 
counterpart deadlocks cmb protocols 
number solutions proposed avoid problem 
chapter review schemes 
optimisations original optimistic algorithm proposed literature 
instance lazy cancellation scheme attempts reduce number anti messages sent result processing roll back 
roll back re simulation event generates exactly output message sending respective anti message newly generated message avoided 
lazy re evaluation scheme attempts reduce chapter 
background number state re calculations roll back 
simulation event rolled back event produces exactly previous state roll back finished 
cost state saving reduced performing incremental state saving 
case portion state modified event occurrence saved 
frequency state saving reduced provided mechanism re calculate missing states case roll backs 
gvt calculation poses difficult problem asynchronous message passing sharedmemory multi processors pausing simulation instant real time implies dealing messages anti messages transit working way communication hardware roll backs progress 
instance proposes maintaining message counters processor called respectively 
processor sends receives message increments counter 
gvt calculation simulation paused global sum equal global sum actual gvt calculated performing min reduction operation 
asynchronous distributed memory environments performing min reduction quite expensive operation 
basic requirement gvt valid calculation predefined interval real time 
instance token passing gvt algorithm organises processors ring topology 
gvt start message token sent periodically processor ring 
message returned processor gamma processor certainty processors interval real time waiting calculate gvt 
processor sends local estimation gvt processor ring processor turn calculates new estimation gvt send value processor 
cycle processor gets new gvt value 
values communicated processors sending final token ring 
optimistic synchronous protocols protocols optimistic version conservative synchronous protocols 
define optimistic global time windows employ roll back mechanism correct causality errors 
instance breathing time buckets btb protocol optimistic counterpart mentioned yawns protocol 
calculating time window start new cycle processors optimistically proceed forward simulating events believe reached upper border window 
point local estimations upper border decides true window lps globally synchronised simulation time 
details protocol protocols kind described chapter 
chapter 
background bsp framework pdes section describe fundamental ideas supporting implementation synchronisation protocols bsp setting 
assume set logical processes lps distributed processors bsp computer 
exists virtual link vl lp lp sends messages simulation 
note term real time refer execution running time time refers simulation time 
messages contain events scheduled occur time say timestamp virtual link vl variable tl stores timestamp message sent protocols virtual links explicitly implemented irrelevant 
asynchronous protocols bulk synchronous view conservative simulation lps stated follows lp set lps send messages lp send messages non decreasing timestamp order links vl specific point real time say lp safely spend delta units real time trying process messages received period lp take consideration messages received ii processes messages satisfy constraint tl updated iii sends new messages links vl lps point delta marks message commitment barrier synchronisation processors 
note lps simultaneously interval delta message processing lp strict non decreasing timestamp order 
statement implies repetitive cycle performed simulation 
emphasise simulation correct establish particular ordering real time messages processed ordering simulation time causality constraints events take place remains unchanged 
event ordering simulation time conservative asynchronous protocol statement protocol shown correct 
optimistic simulation hand stated similar manner relaxing requirement dealing possibility roll backs simulation time 
view bulk synchronous event processing fits naturally concept superstep bsp model 
barrier synchronisation real time automatic chapter 
background operation facility provided machine messages sent superstep available superstep 
basic cycle performed bsp computer carry computations associated asynchronous protocol consists receiving new messages superstep ii processing available messages satisfy causality restrictions iii buffering messages sent processors superstep 
asynchronous protocol mapped bsp machine way guaranteed superstep lp processes messages simulation finishes executing number event processing supersteps 
note barrier synchronisation processors necessarily affect asynchronous nature protocol 
loss gain local asynchrony comes fact messages managed blocks 
preservation asynchrony simulation time crucial fact enables superstep advance simulation 
necessarily case synchronous protocols implemented bsp model 
synchronous protocols implementation protocols follows cycle synchronous protocol mapped number supersteps bsp machine 
supersteps dedicated process occurrence events current window compute parallel min reduction determines window cycle 
clearly trade number events processed cycle running time spent computing min reduction 
application small number events lie current window necessary process large number supersteps attain simulation 
parallel min reduction bsp computer operation straightforward 
describe practical methods 
example assume min reduction global minimum set local minima distributed processors 
simplest method superstep processor computes local estimation global minimum sends value chapter 
background 
superstep processor computes simultaneously global minimum estimation value local minima received processors 
bsp cost associated operation 
scheme scale efficiently practice efficient strategy systems small number processors 
alternative method takes log supersteps complete min reduction 
assume different pairs processors send partial minima superstep cost message transmission superstep 
supersteps pairs change explain 
superstep processor compares partial minimum received current partner current partial minimum cost sends new estimation global minimum processor new partner pair assignment 
rule pair assignment better understood example 
consider processors numbered supersteps complete min reduction 
pairs superstep 
pairs second superstep third 
third superstep processor knows global minimum 
example generalised considering superstep processor communicates processor gamma bi gamma gamma gamma bi gamma odd 
method takes exactly supersteps complete 
scalable lg supersteps min reduction method formulate additional strategies synchronous protocols standard synchronism 
processing superstep events current global window processors engage min reduction lg supersteps 
call set supersteps prefix period 
controlling message traffic 
similar case sending normal event messages distributed lg supersteps prefix period 
short term speculation 
completing processing events current window sending messages target lps processors continue speculatively receiving processing event messages prefix period 
superstep prefix period processors window increment instance lg fraction global window 
prefix period new value global window known processors determine speculative computations correct adjust degree optimism prefix period 
chapter 
background double buffering bsp inter processor communication handled direct remote memory access routines 
coherence data lost message buffers read locally written remotely superstep 
solution double buffering scheme pair communicating processors 
buffer keeps messages received current superstep keeps messages sent processor superstep 
buffers alternately supersteps 
advantages bsp model optimistic simulation ffl bsp concept messages transit 
start superstep messages sent previous superstep available processing 
simplifies gvt calculation operation reduced simple bsp min reduction performed pausing simulation event processing supersteps chapter 
ffl messages take superstep reach destinations 
feature exploited reduce speed propagation erroneous computations 
detecting high rate roll backs switch stepped operation 
superstep dedicated process events anti messages released 
second superstep anti messages associated roll backs processed messages new anti messages released 
doubling total number supersteps unacceptably expensive reduce frequency operations executing roll back processing superstep supersteps 
ffl messages anti messages processed groups supersteps 
feature exploited reduce number roll backs lp 
start superstep messages anti messages mark roll back respective lps 
roll backs executed processing earliest chapter 
ffl messages sent target processors superstep 
enables design sophisticated message management scheme lazy cancellation implemented processor level avoiding sending message pairs identical messages previously sent systems rolled back events necessarily re simulated superstep chapter scheme simplifies implementation lazy cancellation noticeably ii sending messages timestamps far simulation delayed supersteps contain erroneous events chapter 
chapter 
background conservative simulation ffl null messages take advantage fact messages sent superstep 
case reduce message traffic preventing sending null messages increase respective link clocks ii sending null message link largest timestamp chapter 
ffl superstep organise conservative simulation events sensible way 
know start superstep messages receive lp avoid calling input rule messages determining local window lp 
value equivalent call input rule minimum message input queues 
ffl conservative asynchronous protocols ideas execute periodical min reductions repeatedly calculate pending event timestamp system 
lps constantly advance link clocks values order prevent deadlocks 
avoids overheads separate deadlock detection procedure information required break deadlocks pre computed advance 
min reductions carried normal event processing supersteps overheads repeated executions minimal 
ffl superstep processor computation completely sequential 
messages processors interrupt simulation 
sense increase overheads implementing process scheduling message passing lps hosted processor 
just simulated sequentially letting events take place chronological simulation time order 
reduces deadlocks rollbacks resident lps conservative optimistic simulation 
note sequential algorithms perform computations necessarily cause degradation level parallelism introduced asynchronous lps chapter 
basic guidelines efficient simulation finish section basic guidelines design efficient parallel simulation bsp computers 
load balance aimed order processor simulate occurrence similar number events superstep 
partitioning system available processors determines degree load balance simulation 
computational overheads arise implementation synchronisation protocol kept low possible 
involves design efficient algorithms data structures performing sequential computations associated superstep 
chapter 
background event granularity effect cost communication synchronisation 
terms speedup better performance achieved systems computations performed event takes place 
addition large granularity tends computational overheads 
note event granularity increased artificially result overheads introduced high level constructs simulation language object oriented programming language 
locality aims reduce message traffic processors overheads associated administration processors 
addition increase locality produce reduction total number supersteps required complete simulation 
slackness refers selecting proper number processors order simulate sufficient number events superstep 
aim cost communication synchronisation 
increase slackness may cause reduction amount parallelism ii inter processor communication iii number supersteps required complete simulation 
systems reduction supersteps feasible actual number supersteps depends communication pattern processors 
general amount slackness exploited simulation tradeoff depends particular values bsp computer 
goal processors possible efficient manner 
previous efficient realisation pdes bsp computers studied 
pioneering bsp implementation classic conservative optimistic asynchronous message passing protocols studied 
solution deadlock detection recovery devised shared memory multi processors adapted bsp setting 
showed software systems devised models computing clearly different bsp implemented bsp computer efficiently 
empirical results cmb protocol showed reasonable speedups feedforward networks cycles cycle 
simplicity networks allowed application bsp cost model illustrative manner 
note fundamental ideas described section taken study 
conservative simulation cmb protocol retains main message passing features superstep lp processing time store incoming messages input queues ii update link clocks timestamp message received respective input queues iii calculate minimum current link clock values iv remove chapter 
background messages input queues chronological timestamp order simulate associated events provided timestamps equal send messages downstream lps 
note combination steps ii iii iv takes advantage bulk synchronous computation defines conservative local time window lp 
algorithm deadlock detection recovery proposed guardian processor 
processor reports guardian status simulation resident lps 
processor detects current superstep events simulated sends deadlock message guardian 
message carries value pending event timestamp processor 
processors deadlock state guardian calculates broadcasts minimum values link clocks lps advanced event timestamp simultaneously 
experiments performed load consisting sequence messages flowing processor zero feed back loop processor 
amount computation performed processors superstep controlled varying size buffers dedicated keep inter processor messages 
observed size buffers increased speedup improved 
expected computations performed superstep easier overheads associated message passing constructs 
complicated systems multiple feed back loops method overheads amount computation superstep depends system 
systems multiple feed back loops tend reduce noticeably number simulated events superstep chapter 
amount computation superstep increased certain limit 
option reduce number processors 
leads focus purely bulk synchronous implementation protocol eliminate message passing overheads order reduce slackness requirement enable processors efficiently 
optimistic simulation optimistic protocol described essentially original protocol asynchronous message passing architectures 
superstep lp processing time store incoming messages event queue chronological timestamp order ii cause occurrence messages iii process roll backs caused messages send respective anti messages 
scheme problem source lp feeding messages resident application lp generate messages single superstep 
certainly cause memory stall processor 
chapter 
background class parallel prefix methods proposed calculate gvt 
range min reductions pipelining min reduction operations new gvt value available superstep 
method avoid roll back thrashing proposed 
optimistic protocol lps tend simulate incoming messages send newly generated messages destinations superstep anti messages achieve objective stopping propagation erroneous computations lag respective messages supersteps indefinitely 
proposed method fact causality dependencies events form trees order sustain existence large tree necessarily cycles events tree take place lps different points simulation time 
causality tree initiated single event root root invalidated due roll back tree removed simulation 
lps able identify events invalid tree remove events simulation waiting arrival respective anti messages 
method assigns identifiers causality trees maintains tables invalidated tree identifiers determined lps 
tables maintained lps union points cycles communication topology lps 
items tables removed fixed number supersteps 
number bounded total number lps system method roll backs evolve farther quantity 
disadvantage proposed method necessary consider explicit communication topology lps designate lps maintain tables tree identifiers 
topology may change dynamically simulation 
note main advantages optimistic simulation avoids burden considering communication topology implementation protocol 
scheme maintaining tables lp introduces considerable overheads 
method may allow roll back extend amount simulation time increasing function total number lps system 
length rollbacks may significantly large system multiple feedback loops queuing networks communication topology 
conservative simulation revisited initial stages research studied bsp implementation classical cmb tw protocols 
proposed modifications original protocols attempt take advantage bulk synchronous nature model computing 
observation computations performed processors superstep chapter 
background speeded noticeably efficient sequential algorithms data structures processor level proposed treat processor supra lp contains single event list resident lps 
scheme avoids burden performing message passing resident lps deadlocks rollbacks lps 
addition result event list processor events tend processed chronological order global level reduces probability deadlocks rollbacks 
synchronisation parallel events means local time barrier 
minimum timestamps messages received input queue processor start current superstep 
defines conservative time barrier events timestamps equal simulated safely superstep 
processors send null messages increase values downstream supra lps 
null message traffic reduced letting processor predict locally lp produces actual superstep null message sent lp believed owner deadlock takes place supra lps increase time barriers scheme guardian processor break deadlock 
way protocol combines null messages deadlock detection recovery 
semi optimistic version protocol proposed 
null messages deadlock detection recovery scheme new version protocol 
supra lps optimistically increase time barriers receive messages increase local barriers 
roll back mechanism employed recover simulation causality errors 
roll back global supra lps anti messages avoided 
developing thesis came realise soon proposed supra lps reduce noticeably level parallelism available simulation 
major impact total number supersteps required complete simulation systems multiple feed back loops 
supersteps reduce average number simulated events superstep load imbalance increase significantly 
protocol null messages supra lps problem exploit main purpose null messages 
standard protocol null messages propagate lower bounds occurrence events lps 
lower bounds incremented gradually cycles lps processing events 
proposed scheme null messages sent particular lps attempt increment time barrier systems multiple feedback loops scheme prevent deadlock occurrences 
performing global roll back causality error find justification systems errors frequent simulation models containing lps 
chapter 
background efficient incremental state saving techniques cost global roll backs significantly high 
optimistic simulations systems multiple feedback loops expected quite prone roll backs 
semi optimistic protocol number global roll backs reduced reducing amount time values increased optimistically 
increase total number supersteps significantly 
important issues addressed preliminary described 
important topics require research 
criticism schemes restricted particularly simple systems feed back loops communication topology lps 
view schemes achieve reasonable performance restricted classes systems 
thesis focus techniques devised wider class systems 
sequential simulator bsp protocols thesis presents great amount experimental results 
cases needed collect complicated statistics variance average observed maxima supersteps 
cases needed measure running time sequential algorithms excluding overheads bsplib 
library differing implementations determined particular low level mechanisms communication synchronisation parallel computer 
experiments studied impact different costs communication synchronisation running time synchronisation protocols 
debugging implementation protocols convenient direct access information event trace processor superstep 
bsp model organises parallel computation structured manner facilitates simulation sequential computer 
straightforward simulate sequentially execution bsp synchronisation protocols 
reward designer full access global memory simulation whilst implementation operation actual protocol affected significant way 
simplifies tasks debugging collection statistics 
simulator implemented defining proper organisation data pointers dynamic memory data structures identical actual bsp implementation protocol 
instance simulation optimistic synchronisation protocol processors represented collection state variables defined pointers event lists ii incoming message queues iii outgoing message queues iv roll back queues pool free memory 
pointers put array processors 
actual bsp implementation protocol pointers maintained physical processor 
chapter 
background sstep gvt endtime processor sstep mod endfor sstep mod sstep sstep endwhile simulating bsp supersteps time warp simulation 
lps represented similar method array elements element containing pointers state queue ii processed events queue iii queue 
pointers necessary actual bsp implementation difference array lps distributed physical processors 
algorithms processing events states anti messages communication buffers roll backs exactly values pointers respective data structures change processor 
shows simulation sequence event processing supersteps bsp time warp simulation 
min reduction associated gvt calculation replaced simple sequential minimum calculation 
example gvt calculated supersteps 
note messages sent processors finished current superstep receive new messages superstep 
overheads associated simulation bsp protocols low 
conservative protocols obtained running times slightly smaller running times sequential simulation simulation model 
memory events assigned global pool memory sequential simulated parallel simulation effect cache faults machine expected little influence running times free memory blocks returned global pool assigned new events 
chapter tournament event queues modern heaps fastest general purpose priority queue realisations usually implement pending event set discrete event simulation 
optimal structures skew heap efficient alternative special purpose structures calendar queue lazy queue 
conversely special purpose queues heaps exhibit valuable attributes simplicity independence event time distribution 
binary tournaments genesis heaps known 
chapter study performance tournament complete binary tree 
focus simulation results show predecessor heaps efficient alternative fastest pending event set implementations reported literature 
study realisation parallel priority queues data structure 
pending event set pes defined set events generated simulation occurrence simulated 
order determine event take place necessary extract event time pes 
call operation extract min 
hand occurrence event simulation may produce insertion new events pes insert operation deletion events scheduled pes delete operation 
basic operations define pes priority queue pq data type 
number near optimal alternatives implementation general purpose pqs solutions specially devised pes cf 

result large number alternatives theoretical empirical studies performance pqs 
embedded proposal new pqs chapter 
tournament event queues pes implementations find analyses comparisons 
studies show single pq implementation best cases applications 
chapter introduce tournament complete binary tree cbt basic data structure implement pqs pes 
variant sequential hold model includes deletion arbitrary items events show cbt outperforms fastest alternatives implement pes 
cbt inherent lg performance hold operation number events pq property low cost update step leads efficient performance practice 
words event item synonymous priority values associated event timestamps highest priority corresponds event timestamp higher priority implies lesser numerical timestamp value 
discrete event simulation seen large sequence operations acting pes 
practical terms means interested reducing cost sequence cost individual operations 
average case bounds useful context provide realistic measure performance achieved pq large sequences operations 
cases extract min operation frequent sequence lg extract min amortised dominating operations 
show average case performance bounds cbt nature timestamps new events pes particularly efficient demanding simulations various types operations acting pes 
particular show extract min lg average cost low constant factors insert intuitively delete average cost 
empirical results confirm 
extend idea binary tournaments tournament structure exhibits property delaying processing events larger timestamps whilst keeps similar theoretical performance bounds native structure cbt 
property certainly useful systems pending events expected deleted rescheduled simulation time warp simulation 
structure implement pending event set bsp time warp system proposed chapter 
investigate realisation parallel priority queues cbt 
worst case insert takes parallel time extract min takes lg lg parallel time lg processors erew pram model parallel computing 
previous solutions achieve lg lg parallel time operations 
addition show context parallel priority queues sets items inserted retrieved data structure cbt ability reducing cost communication synchronisation chapter 
tournament event queues processors 
algorithms crew pram bsp models parallel computing pram algorithms implemented bsp operating automatic mode 
cases improvement commonly implicit heap just factor 
improvement significant applications large sequences operations executed ppq parallel discrete event simulation bsp automatic mode shared memory multi processors 
systems small event granularity cost ppq easily dominate total running time 
claim cbt best choice classes simulations 
particular heap structures cbt guarantee stability priority values identical priority values retrieved fcfs order queue 
believe data structure represents alternative complex systems keeps heaps attributes simplicity independence event time distribution achieves better performance modern heaps specially devised pes implementations 
note basic form cbt described chapter early approximation description implicit heap 
best knowledge cbt received attention deserves literature pqs pes implementations discrete event simulation 
tournaments cbt realisation pq idea binary tournaments 
item stored pq consists priority value identifier 
associate leaf cbt item internal nodes maintain continuous binary tournament items 
match internal node consists determining item higher priority lesser numerical value children writing identifier winner tournament set matches played internal node located path leaves root 
see time change priority associated leaf tournament updated performing matches unique path root tree 
see call operation update cbt 
operations extract min delete insert implemented update cbt basic primitive 
pq items implemented array cbt 
gamma integers maintain results matches items ii array prio priority values iii array leaf integers map items leaves 
node position array cbt children positions 
parent node position internal nodes stored positions gamma cbt 
highest priority pq prio cbt identifier cbt associated leaf position chapter 
tournament event queues cbt priority values parentheses 
cbt updated changing priority item 
leaf cbt 
note necessary explicitly maintain leaves tree array cbt simple integer arithmetic array prio calculate priority associated leaf 
enable dynamic reusing item identifiers pq array leaf maintain single linked list available item identifiers note cbt implemented dynamic structure pointers children father heap ordered priority queues 
deletions cbt performed removing child lower priority children parent rightmost leaf exchanging target leaf deleted 
example delete item father leaf item leaf holding item call update cbt needed new leaf ii item moved leaf holding item iii cbt updated starting leaf right child root cbt 
hand insertions performed appending new rightmost leaf updating cbt 
done expanding leaves leaf tree 
example insert priority cbt leaf numbered chapter 
tournament event queues new internal node tree child leaves numbered reuse identifier hold priority ii cbt updated starting position leaf root cbt cbt 
cost step extract min delete insert operations constant cost update cbt operation 
section analyse cost worst case obviously lg 
average case bounds average cost update cbt reaches root cbt calculated follows 
leaves lowest level level rest level level gamma 
cost updating tree leaf root lg nc level ii lg nc level gamma 
furthermore number leaves level gamma lg nc level gamma lg nc gamma average obtain lg nc gamma lg nc integer power optimal cost lg achieved worst case comes updating level root cost lg nc 
calls update cbt involve average cost units time 
true update cbt operations reach root cbt case extract min 
calls update cbt example part insert operations expect lower cost update cbt 
obtain better average cost update assuming starting leaves going root cbt lowest level leaves total elements comparison elements total winners 
level root total elements comparison winners 
average form lg hand variance calculated considering total elements just comparison total comparisons 
gives lg gamma independent probability distribution assumed priority values results assume static scenario priorities drawn universe values ranging chapter 
tournament event queues zero infinity 
known case access patterns similar ones produced hold model see subsection priority values measured relative priority retrieved extract min discussions hold model validity discrete event simulation 
conclude cbt pes implementation average cost lg extract min insert worst case lg operations 
note constant factors involved quite small sense update step cbt takes just comparison assignment additional swaps implicit heap exchange children skew heap update step 
intuitively cost delete operation equivalent insertion leaf associated item deleted 
tournament updated till internal node root reached item effect hard estimate 
average cost extract min delete insert respectively 
pes point view discrete event simulation seen large sequence random accesses pq random combination extract min delete insert 
denote average cost access pq sequence pe pd pe pd probabilities fraction occurrences different operations acting pq 
emphasise increasing nature priority values new items inserted pq priority value event timestamp retrieved extract min random increment sequence described empirically observed ranging exponential distribution smaller values observed increased 
experiments counted number comparisons priority values performed sequence observe effect increasing priorities average cost delete insert repeated experiments insertions 
results showed strong lg average value 
show running times different pqs sequences empirical results hold model compared running times different pqs pes implementations cbt described chapter 
basically hold model random event generator consists inserting items pq performing repetitive loop cycle called hold operation extract min followed insert performed 
priority value event timestamp new item inserted pq computed priority item dequeued extract min random priority increment sampled probability distribution 
chapter 
tournament event queues exponential triangular distributions 
included model delete followed insert sequence occurs predetermined probability pd sequence extract min insert 
experiment repeated times observing error rate 
measuring running time pq initialised items loop hold operations performed order reach steady state pq 
new loop hold operations performed void pq operations functions code measure overhead involved code related pq main loop random number generation 
loop hold operations performed measure total running time demanded sequence operations 
dynamic memory required pq pre allocated start experiment 
programming style traditional minimal calls subroutines recursive algorithms 
item deletion immediately followed insertion implemented versions cbt cbt cbt explicit deletion items 
explicit item deletion cbt general method described 
second case cbt operation extract min retrieves priority associated leaf cbt leaf host item inserted 
call update cbt performed case 
delete operation performs computation similar sequence insert assign leaf new item 
empirical results pd pd shown 
note results shown ratio pq cbt item deletions cbt 
results show cbt achieves better performance heaps cases triangular distribution fast special purpose queues calendar queue 
range cbt clearly efficient heaps accounts differing programming styles comparative efficiency improves increases initial overhead involved leaf management amortised increases low cost tree updating 
cbt achieves competitive performance respect calendar queue wide range values observed better performance ratio calendar queue exponential distribution remained fairly stable delta delta comparison cbt calendar queue biased results useful see best possible performance cbt 
suggests search cbt realisation performance range cbt cbt hopefully long periods sequences operations performance near cbt attempt direction section 
chapter 
tournament event queues exponential pd theta theta theta theta theta theta theta theta exponential pd theta theta theta theta theta theta theta theta triangular pd theta theta theta theta theta theta theta theta triangular pd theta theta theta theta theta theta theta theta total running time hold operations executed ibm sp computer dedicated processor micro second resolution clock 
curve shows ratio pq running time priority queue pq running time complete binary tree node deletions cbt 
axis indicates values 
pq identified letter complete binary tree item deletions complete binary tree item deletions calendar queue queue implicit heap pairing heap variant skew heap top variant splay tree bottom 
chapter 
tournament event queues tournaments deal efficiently large sequences pq operations expected remain fairly constant long periods situations rescheduling cancellation events highly occur extend basic idea binary tournaments tournament structure follows 
leaf cbt maintain set lg items elected representative participate continuous binary tournament maintained internal nodes 
election doing gamma comparisons items stored leaf order determine item highest local priority 
call item local minimum 
internal nodes cbt determine item highest priority local minima 
items stored leaves maintained unsorted double linked lists leaf local insertions deletions take time 
average cost update cbt till root cbt lg gamma lg calls update cbt cost similar effect mentioned deletions cbt considered cost 
discussion going assume keys evenly distributed lists hold model negative exponential distribution 
insertion probability new item coming reside target leaf highest local priority unsorted linked list associated comparison needed know maintain elected item head list consequently average cost insertion necessary execute update cbt worst case attain root cbt 
worst case insertion 
hand probability deletion arbitrary item produces search new list representative call 
average cost deletion gamma worst case 
extract min implies searching new representative list associated leaf cbt executing update cbt total cost gamma lg average worst case 
note assumptions previous analysis conservative insertions deletions probability hitting local minimum practice smaller increasing nature new priority values inserted queue deletions items farther simulated time 
addition insertions deletions expect update cbt operations cost update cost lg 
keep theoretical average cost operation structure similar cbt set lg ne 
evaluation chapter 
tournament event queues gamma ranging gives 
note average cost delete structure lower cbt operation ratio 
example sequence gamma pd pd exponential distribution pd observed empirically cbt 
additional numbers useful see key property structure 
example items maintained call overflow area union lists excluding local minima 
items overflow area 
maintaining items overflow area low cost clear advantages simulations events expected deleted rescheduled combinations place 
benefits particularly evident occurs events larger timestamps 
cases structure seen lazy structure delays processing events occur whilst focuses ones local minima 
unsorted linked lists size low cost buffering large number items get priorities changed simply deleted selected representatives lists 
note avoid probability distribution dependence coming linked lists distributing random items lists independently priority values timestamps discussed 
demonstrated previous section cbt particularly efficient item deletions performed tree number items maintained constant cbt 
example operation extract min retrieves priority associated leaf cbt leaf host key inserted 
binary tournament performed pq operations 
performance achieved example follows 
structure double halve number leaves lists attains threshold value 
case item deletions performed tree go level tree resize operation 
example assuming cbt leaves restricting double soon equal halve equal resize queue gamma resize operation occurs pq operations cost resize calls update cbt needed process 
amortised cost resize operations 
items distributed randomly hashing function mod item identifier current number leaves stands insertion list 
assume lists maintained local min operation determines item highest priority list sets head chapter 
tournament event queues save calls local min update cbt queue qz pending local min operations 
qz enqueue list identifiers positive negative stands local min update cbt gammai means update cbt 
queue qz allow duplicated values attempt enqueue value qz gammai positive enqueuing gammai gammai qz change gammai 
number leaves cbt simple array flags bits leaf decide time pq operation enqueued list identifier sigmai qz flags reset requests enqueued qz served 
qz follows 
insertion item qz compare priority value priority stored head 
set head enqueue gammai qz store tail deletion head list produces enqueuing qz execute pending local min update cbt enqueued qz extracting item highest priority structure 
general organisation achieves performance close cbt simulations number events pes long periods simulated time 
empirical results hold model show average overhead structure total cost cbt empirical results empirical results provide implementation independent performance tournament structure proposed chapter 
results obtained cases lists leading respectively ii lists leading respectively 
load experiments described sequence delta delta pd delta delta gamma pd delta performed experiments pd ranging values random variable taken probability distributions 
analysis previous section proposed structure average cost insert delete cost lg extract min 
particular average cost sequence ch delta delta pd delta delta gamma pd delta lg gamma lg 

probability operations insert delete introduce lg gamma terms cost chapter 
tournament event queues cases considered constant expect experimental values displaced constant factors ch performed experiments test validity statement 
charged unit call insert delete extract min 
addition charged unit comparison priority values performed local min update cbt operations 
call units average count units pq operation executed sequence 
evaluate ch average value observed ratio units shown cases inflection points curves occur 
follows 
performance structure independent probability distribution random variable cases ratio units tends constant indicating effect lg gamma terms significant increases whilst pd kept fixed 
ratio units slightly better 
cases best results obtained pd worst results pd 
insert observed probability distributions insertions produced enqueuing sequence schedule 
discussed new items inserted pq priority values probability inserting list item priority value head extremely low pd values 
case deletions selected uniformly random item pq 
probability deleting head list explains ratio tends increase pd increases set values associated remained constant different values pd 
pd increases greater effect terms lg gamma introduced delete operations 
pq values greater case explains better results ratio units average probability distributions deletions falling outside head lists greater case probability greater 
note real discrete event simulations reasonable expect greater amount elimination events large timestamps cases simulated experiments 
practice expect smaller values probability deleting head list show similar results ratio units lg 
ratio units increases pd shows effect negligible compared independent function lg fact performance versions structure increases noticeably pd example pd structure reduces number accesses hypothetical lg tree 
note performance structure slightly better case high pd chapter 
tournament event queues ra pd pd pd pd uniform biased bimodal ra pd pd pd pd uniform biased bimodal ra units ch axis divided parts ra values shown different pd values 
chapter 
tournament event queues rb pd pd pd pd uniform biased bimodal rb pd pd pd pd uniform biased bimodal rb units lg axis divided parts rb values shown different pd values 
chapter 
tournament event queues single item operations erew prams worst case cost extract min delete insert lg cbt 
cost reduced parallel algorithms 
previous solutions parallel implementation extract min insert 
algorithms described deal pipelining operations single operations lg 
parallel random access machine pram processors synchronised access shared memory 
erew exclusive read exclusive write pram processors may read write simultaneously shared memory cell 
parallel algorithms speed individual operations processor erew pram 
approaches extract min insert require lg lg parallel time lg processors 
cbt improve results insert lg lg reduced constant factors extract min lg processors 
solution avoid communication demanding primitives broadcast algorithms noticeably simpler previous approaches 
cope reading restriction associated processor erew pram slightly modify data structure 
eliminate array prio defined section expand array cbt array gamma tuples item identifier associated priority 
case results matches performed cbt written internal node root 
cost extract min insert constant cost update cbt 
problem consists computing effects update cbt operation erew pram algorithms extended cbt array 
split operation update cbt called insert update cbt called extract min 
description operations going assume lg note similar considering lg cost broadcasting key processors 
insert operation creating new leaf position cbt hold new item update cbt operation simultaneously compares priorities stored path root 
shown 
note operation takes parallel time lg processors 
cost lg lg details extract min operation follows 
define cbt cbt leaf tuple selected replace leaf making effective replacement update cbt operation proceeds main steps 
internal node path leaf till root write tuple stored children recall item duplicated chapter 
tournament event queues procedure update cbt lg kc hg parallel div gammap cbt cbt cbt endif endfor pseudo code parallel update cbt operation 
path 
secondly parallel prefix operation operator phi min performed nodes path root order re establish binary tournament invariant similar operation calculates prefixes phi phi delta delta delta phi delta delta delta height cbt 
attempt storing node path root replacement performed leaf update cbt operation described similar auxiliary arrays size lg perform parallel prefix operation 
cost update cbt dominated cost parallel prefix lg lg lg processors 
cost extract min lg lg lg lg similar approaches construction cbt set priority values takes lg parallel time parallel processor takes subset elements level level leaves root matches simultaneously performed internal nodes 
average path context parallel operations described sections relevant know number item identifiers path leaves root 
worst case number lg average case show case gamma random assignment results matches performed cbt equivalently seen numbering nodes left right level level root follows 
start leaves level gamma numbering continue level gamma numbering chapter 
tournament event queues procedure update cbt lg kc hg parallel div gammap cbt cbt cbt cbt endfor prefix min hg parallel endif endfor hg parallel div gammap cbt cbt endfor pseudo code parallel update cbt operation 
gamma level gamma numbering gamma till root 
numbering exposes recursive relation frequency number item identifiers paths leaves root relation remains unchanged gives valid tournament tree 
assuming select leaves level target leaf insertion define total number paths distinct item identifiers 
number paths identifiers numbers paths level gamma include identifier th level plus number paths level gamma including level identifier note sets disjoint 
gamma gamma gamma easy verify gamma gamma gamma delta induction known equality gamma delta gamma gamma delta gamma gamma gamma delta average number item identifiers path gamma delta chapter 
tournament event queues gamma delta gamma gamma gamma gamma gamma gamma gamma lg problem relevant sections efficient parallel implementation priority queue operations items inserted retrieved queue elements 
specifically parallel priority queue ppq basic operations defined insert set items inserted ii retrieves smallest items parallel priority queue operations discussed :10.1.1.17.2756
randomised algorithms tree deterministic algorithms discussed 
algorithms chapter deterministic algorithms tournament tree 
parallel priority queues crew prams parallel priority queues introduced 
crew concurrent read exclusive write pram processors may read simultaneously shared memory cell may write simultaneously cell 
implicit data structure proposed implement 
ppq delta items lg processor crew pram structure supports insertion deletion items lg lg lg parallel time respectively 
performance bounds achieved standard implicit heap node able store items 
heap invariant extended considering item lowest priority items stored node higher priority items stored descendants assume items duplicated queue 
section implement tournament cbt 
assume item consists sub items priorities total items holding total delta priority values associated data 
data structure similar defined section difference array prio able store item set priorities 
item priority values maintained sorted prio 
winner match sibling nodes node associated priority values higher priority sibling 
similar parallel primitives sort jsj merge processor crew pram complexities lg je je lg lg chapter 
tournament event queues procedure update cbt lg kc hg parallel cbt div gammap endfor build array duplicates set prio sort merge set prio prio update cbt operation parallel pqs 
respectively 
notice replace expensive operations parallel select proposed section 
sequential case insertion set priorities associated new item accomplished transforming internal node leaf children leaf located position cbt 
insert setting cbt cbt cbt leaf update cbt leaf operation executes steps shown 
construction array takes parallel time array takes sequential time duplicated values successive positions set involves parallel time processors jd parallel merge takes time nh lg lg lg lg parallel sort takes time lg 
updating array prio takes parallel time 
cost insert lg 
extraction set containing highest priorities cbt performed follows 
assume position leaf holds item contains item selected stored extract min setting leaf cbt update cbt operation execute steps shown 
step operation dominated complexity merge 
operation takes lg lg parallel time 
note case necessary execute merge operation called twice 
claims lg lg complexity extract min ways parallelisation procedure update path insertion leaf root 
implicit heap enables parallelisation 
cbt possible necessary update sequentially tournament insertion leaf root shown 
chapter 
tournament event queues procedure update cbt lg kc downto div gammaj cbt cbt swap cbt div gammaj merge prio prio left right halves prio prio endfor update cbt operation parallel pqs 
parallel priority queues bsp computers bsp implementation ppq introduced proposed 
bsp ppq uses novel mapping nodes processors reduces amount inter processor communications needed maintain extended heap invariant 
addition uses parallel select operation merge sort increases efficiency bsp ppq modifications claims better performance previous approaches improving communication slackness requirements 
items stored node implicit heap randomly evenly distributed processors processor reduction communication comes fact administration items essentially parallel select operation 
select determines th smallest item set requires sel jsj jsj jsj lg bsp parallel time 
addition selection uses parallel prefix operation cost ppf lg 
ary parallel heap implements operations insert extract min costs ht sel gamma sel ppf chapter 
tournament event queues procedure bsp update cbt lg kc cbt div gammaj build array duplicates jd select prio prio prio prio endfor prio bsp update cbt operation parallel pqs 
respectively lg depth heap 
cbt improve bounds constant factors reducing number parallel primitive operations product amount inter processor communication executed insert extract min 
performance bounds sel sel ppf insert extract min respectively 
imply average particular number different item identifiers path leaf root cbt 
worst case average case occurs probability see section 
build basic ideas cbt bottom tournaments 
maintain arrays cbt leaf processor 
maintain instance array prio processor elements prio randomly evenly distributed processors 
item maintain processor total priorities associated respective segment prio stored processor similar select operation redistribute contents prio associated item path leaf root cbt 
addition parallel operation max cost jsj ppf obtains maximum priority value set jsj priorities distributed processors executing max maximum known processors 
insertion set priorities associated new item transforming chapter 
tournament event queues procedure bsp update cbt lg kc downto div gammaj max prio cbt max prio cbt swap cbt div gammaj select prio prio prio prio prio prio prio prio endfor bsp update cbt operation parallel pqs 
internal node leaf children leaf located position cbt 
insert setting cbt cbt cbt leaf operation bsp update cbt leaf executed processor shown 
construction arrays update array prio product select takes time 
worst case size array average jd initial random distribution processors takes time extraction set containing highest priorities cbt performed follows 
assume position leaf holds item contains new item selected stored extract min setting leaf cbt bsp update cbt operation execute parallel steps shown 
product select update operations distributed array prio take time 
performance bound follows 
note algorithms proposed designed ary implicit heap 
extract min implicit heap necessary perform calls select node located root target insertion leaf 
ary implementation cbt requires similar procedure 
case necessary determine child extended priority compare current winner item 
gamma calls select needed ary cbt 
chapter 
tournament event queues described complete binary tree cbt data structure algorithms implement priority queues 
results show cbt effectively efficient implementation pending event set associated discrete event simulation 
structure keeps heaps attributes simplicity efficient behaviour demanding simulations 
observed empirically cbt achieves better performance heaps domain discrete event simulation 
average performance bounds cbt confirm suitability task lg extract min low constant factors amortised dominating operations insert delete 
operations find min increase priority value 
pending event set implementations calendar queue expected achieve optimal performance operation large scale real life simulations 
shown calendar queue noticeably inefficient determined probability distributions 
empirical results confirm fact 
shown lazy queue 
structures robust terms delivering efficient performance load 
reason organise pending events set small linked lists accessed timestamp events 
list stands interval simulation time 
example may happen period simulation time timestamps tend group lists move subset lists unpredictable manner 
worst case cost happens events placed single list 
contrast tournament structure proposed chapter independent probability distribution events placed random small linked lists 
addition structure efficient simulation model worst case lg 
note small lists quite useful practice provide low cost buffering area events deleted re scheduled 
turn enables structure cost large sequences insert delete operations occur practical applications time warp system proposed chapter 
standard pq realisations suited servicing sequences efficiently known pes implementations lose efficiency dramatically certain loads 
parallel priority queue algorithms cbt 
build ideas similar previous solutions cases data structure enables efficient implementation extract min insert operations 
particular reduce amount communication synchronisation processors reducing number calls cost dominating primitive parallel operations merge select 
operations twice faster simple parallel algorithms cbt usual data structure implicit heap 
chapter analysis synchronisation methods event dependencies associated correct parallel discrete event simulation pdes preserved synchronisation protocols 
protocols ensure simulation event taken place chronological time order respective logical process lp 
synchronisation case refers synchronisation events simulated time achieved imposing specific method advance simulation time 
chapter analyse methods simulation time advance call asynchronous synchronous time advance respectively 
asynchronous time advance refers simulations synchronisation events locally lp level 
bryant cmb time warp tw protocols approach 
synchronous time advance hand refers time stepped advance means globally defined time intervals fixed variable length 
called event horizon concept realisation synchronous time advance 
yawns breathing time buckets btb protocols event horizon time advance 
asynchronous synchronous approaches time advance considered different schools thought solution problem synchronising execution parallel simulations 
asynchronous time advance genesis early attempts perform parallel discrete event simulation asynchronous distributed message passing systems 
synchronous time advance protocols philosophical shift away roots parallel simulation 
closely related parallel computing distributed computing 
chapter 
analysis synchronisation methods pure asynchronous time advance simulation events synchronised lp level 
lp decides simulation events current state messages received lps 
global information driving simulation events lps different points simulation time instant real time 
hand synchronous time advance allows occurrence events globally defined simulation time intervals 
interval implies synchronisation processors real time 
simulation proceeds forward advancing step step intervals 
pure synchronous time advance length intervals constant small 
case agreed approach useful general purpose methodology pdes important classes systems able process sufficient amount events step 
intervals variable length adjust simulate sufficient amount events step solution general purpose protocols 
particular protocols called event horizon concept demonstrated suitable general purpose pdes 
bsp bulk synchronous model parallel computing natural approach pdes model realisation simulations synchronous time advance 
case synchronisation protocols yawns btb considered perfect candidates perform bsp simulations large scale systems 
looking algorithmic details protocols designer find differences bsp way protocols organise main computation cycles composed event processing phase followed barrier synchronisation processors 
barrier synchronisation processors considered synonymous global synchronisation time 
chapter introduced fundamental concepts bsp implementation synchronisation protocols asynchronous time advance cmb tw protocols 
case synchronisation time barrier synchronisation processors 
bsp provides method organising computation inherently asynchronous bulk synchronous groups messages events processed superstep synchronisation time occurs logical process level 
natural question method simulation time advance lead lowest running times 
note overheads involved implementation protocols btb tw similar protocols implement roll back state saving mechanisms 
argued btb reduces message traffic require show appendix cost associated message traffic significant costs barrier synchronising processors load imbalance 
note show chapter tw simulation realised bsp represent small fraction message traffic processors important classes systems 
chapter 
analysis synchronisation methods vein difficult see software overheads similar conservative synchronisation protocols yawns cmb 
glance obvious approach time advance leads efficient simulations 
intuition indicates asynchronous time advance efficient periodical global synchronisation time required 
achieve better performance avoiding execution parallel min reductions 
extent processors bsp computers say cost barrier synchronisation scalable synchronous time advance protocols lg times higher protocols asynchronous time advance 
assuming cost barrier synchronisation order magnitude approaches question approach complete simulation amount event processing supersteps 
closely related question effects load balance simulation 
believe answers questions trivial 
find literature analyses related synchronous time advance useful context problem analysing asynchronous time advance may mathematically intractable general form 
intractability recognised literature usual find analyses overcome problem introducing highly simplifying assumptions 
reason simple dealing application type computation inherently irregular 
way choose advance simulation time synchronously asynchronously significant impact total running time bsp simulations section 
relevant attempt form comparative analysis approaches 
step analyses characterisation load executed synchronisation protocol 
space simulation models operational parameters infinite 
particular model instance specific input parameter values represents point space defines specific load instance underlying synchronisation protocol 
particular model instances sensible approach synthetic loads devised demanding benchmarks synchronisation protocols 
instance load generator widely empirical theoretical studies closed queuing network cf 
lps represent single servers events mark instants jobs enter service placed respective queues 
service non preemptive duration assumed exponentially distributed 
receiving service new destination job selected uniformly random lps 
represents fully connected communication topology lps topologies hypercube toroidal wrap links employed particularly performance evaluation conservative protocols 
chapter 
analysis synchronisation methods show simulation results comparing asynchronous async synchronous sync approaches time advance synthetic queuing network simulation data obtained programs similar described section modified queuing network context 
results suggest asynchronous time advance leads bsp simulations supersteps better load balance large scale queuing systems 
queuing network certainly represents important class applications fairly light load asynchronous time advance bsp setting explain reasons section 
analysis chapter similar approach uses demanding load phold defined section 
convenient feature workload enables focus relevant factors determining performance simulations bsp 
similar comparative performance shown 
particular asynchronous time advance achieves optimal number supersteps fact enables improve load balance small sized systems low cost 
synchronous time advance looks particular case situations worst case general form time advance asynchronous 
quantify comparative performance approaches 
case results suggest average simulation asynchronous time advance pending events lps tends behave event horizon simulation just events 
quantitative results enable model bsp cost number synchronisation protocols 
previous attempt analyse comparative performance asynchronous synchronous pdes 
analytical model assumes set processors executing nk tasks events sequentially 
real time spent task random variable synchronous time advance processors barrier synchronise complete single task 
cost step average maximum random variables total cost simulation nk times quantity 
hand asynchronous time advance modelled assuming best case scenario processors require synchronisation 
total running time lower bound asynchronous approach average maximum random variables sum nk random variables results exponential distribution values show asynchronous approach better synchronous approach modest ln factor 
uniform distribution difference performance chapter 
analysis synchronisation methods theta theta theta theta theta theta theta theta re theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta re theta theta theta theta theta theta theta theta non preemptive single server queuing network exponential service times 
figures show data fully connected topology figures show data toroidal topology 
symbols employed supersteps sync supersteps async re sync async average maximum number simulated events processor superstep number lps servers processor initial number jobs lp number processors 
approaches factor 
emphasise results upper bound improvement asynchronous approach synchronous 
results applicable case different models parallel computing assumed 
context results tell synchronous machine bsp perform computational task efficiently asynchronous machine 
analytical model misleading causality dependencies events taken consideration 
bsp barrier synchronisation applied points necessary inter change causally related data processors 
communication required barriers needed 
problem compare approaches simulation time advance model parallel computing 
existence causality threads evolving supersteps processors complicate quantitative analysis noticeably 
instance asynchronous time advance need consider effect increased number processors chapter 
analysis synchronisation methods accounted look large number supersteps single superstep 
case take advantage assumptions statistical independence referred single supersteps case synchronous time advance analyses 
note important point separation analysis previous analyses ignore real time considerations 
real time accounted bsp cost model considers costs computation communication synchronisation 
respect bsp cost model enables focus counting event occurrences 
counting process independent implementation architecture issues turn enables predict total number supersteps load balance 
numbers plugged expressions predicting total bsp cost simulation 
assumptions statistical independence constrained single time steps successfully employed analyses synchronisation protocols event horizon concept synchronous time advance 
approaches relatively easier analyse completely asynchronous algorithms attention need focused representative window superstep 
main concern analyses determination average number events processed superstep 
reason simple sufficiently large costs communication synchronisation iteration algorithm 
model employed uses exponential time increments shifted constant defines general differential equations phold section 
exponential distribution approaches analytically obtain constant event population 
result lower bound average case approximation 
addition numerical integration differential equations determines similar asymptotic commonly probability distributions uniform distribution 
mention load balance sufficiently large ensure balance claim follows theorem section 
underlying assumption analyses load globally balanced 
analysis shows communication synchronisation costs greater event list management sequential simulations constant number processors assumed synchronous event horizon protocol studied yawns asymptotically optimal 
optimality result comes fact cost processed event constant factor cost event sequential simulation 
optimality holds large events processed processor cycle 
bsp cost model realised expression feasible speedups appendix assumption constant result straightforward 
expression feasible speedups tells simulation able operate reasonable load balance optimal sense 
chapter 
analysis synchronisation methods show section event horizon simulations optimal terms bsp cost model 
particular simulation model necessarily complete simulation optimal number supersteps 
optimality bsp cost model refers algorithms achieve optimal cost computation communication synchronisation 
show asynchronous time advance optimal synchronisation 
approaches studied bsp optimal realised actual synchronisation protocols 
instance time warp realised bsp achieve optimal number supersteps optimal communication anti message traffic computation roll back processing 
protocol bsp cost model predicts relevant parameters optimise number supersteps load balance conjecture time warp simulation proper tuning optimism proposed chapter achieve near optimal running times 
analysis compares yawns bounded time warp time warp realisation advances synchronously simulation time 
analysis numerical model synthetic queuing network model described section concludes conservative protocol yawns outperform bounded time warp large number logical processes processor 
analytical assumptions bounded time warp protocol works point pure asynchronous time advance event horizon synchronous time advance 
point trade widening event horizon window events processed parallel cost rolling back fraction events processed optimistically 
extent analysis considered comparison asynchronous synchronous time advance 
results mapped directly context bounded time warp cope requirement global synchronisation time 
simulation advances window events current window correctly processed 
case asynchronous time advance impose global synchronisation time analysis different 
load section describe load analyse performance approaches simulation time advance 
load quite simple fact just bsp realisation phold known synthetic load turn parallelisation classic sequential hold model 
argued phold unrealistic best just particular case queuing network described system infinite servers lp show section phold represents quite demanding load pdes bsp 
imply loads considered demanding chapter 
analysis synchronisation methods phold models parallel computing expected equally demanding bsp setting 
true general specific factors affecting performance model necessarily 
key advantage phold loads captures essential factors determining performance parallel simulations bsp computers 
review factors 
explain fundamental ideas 
shows particular assignment events coloured black white processors 
simulation time represented vertical line horizontal ticks unit 
events colour causally related shown represents simulation starts initial events time zero proceeds forward processing chronological occurrence events generated 
simulation ends units time time increment consecutive events assumed constant equal 
say simulation causality threads defined streams black white events 
note processors similar load roughly process number events simulation 
note ticks simulation time line necessarily indicate real time occurrence events processed computer 
assume simulations executed bsp computer 
problem decide processor level cause occurrence subset events available superstep 
instance events black coloured thread available processing superstep 
events processed superstep depends new events arriving processors supersteps times general unpredictable 
obviously particular event sequence depicted sensible approach process event thread superstep 
general processors global view system evolution causality threads evolve gradually event event 
define relevant performance metrics load balance total cost barrier synchronisation apply example assuming possible configurations supersteps 
models example models start causality threads uniformly distributed random processors threads processor measure load balance terms event efficiency follows 
total ae events processed complete simulation processors sum supersteps maximum number events processed processor superstep cumulative sum maximum superstep 
measure cost barrier synchronisation supersteps unit simulation time chapter 
analysis synchronisation methods ffi ffi bw wb wb sstep figures vertical lines represent simulation time events put arbitrarily time processors 
shows number events simulated superstep processor indicated number associated event 
case simulation events delayed supersteps earlier events available processing 
total number supersteps simulation time tick time line marks superstep events processed load balance cost supersteps 
shows possible superstep demarcation causality constrains respected 
processing available events delayed supersteps wait earlier events arrive supersteps 
decisions local level 
assume case underlying synchronisation protocol processes events soon causally correct 
numbers events points indicate supersteps events processed letters wb indicate event processing order ambiguity 
case superstep demarcation produces larger imbalance note processors process events half supersteps alternately shows number events processed superstep processor 
event efficiency case sequential event chapter 
analysis synchronisation methods processing supersteps unit simulation time smaller previous 
simple example shows crucial factors determining performance bsp simulations total number causality threads migrating processor ii time interval successive events thread iii rate thread migration takes place simulation 
best case maximum locality causality thread moves processor 
leads simulations superstep events take place evenly distributed processors efficiency optimal 
hand difficult find worst case situations supersteps efficiency example simulation single causality thread moves processor small time advance successive events 
note worst case systems offer little opportunity exploiting parallelism believe model parallel computing 
example worst case leading thread determines critical path simulation 
view point studying performance worst best case loads known simulation models lead reasonable speedups having sufficient amount parallelism 
define load degree parallelism ensures average events take place processor 
intentionally define instance phold assigning identical load processor global level 
local level individual supersteps previous example load balance depends type time advance employed service load 
bsp hold model phold model similar depicted 
processors hosting lps 
initially causality threads scheduled lp dd time increment consecutive events causality threads continuous random variable probability distributions shown table assign values random variable distributions number performance studies cf 
considered representative typical event time increments real life simulations 
column table shows bias distribution 
quantity better understood context sequential hold model 
consider set pending events chronological order simulation time 
suppose want store chronological order new event time pending event set 
bias distribution measure average fraction pending events time chapter 
analysis synchronisation methods distribution expression compute bias random increments exponential exp gamma ln uniform uni biased bimodal bim triangular tri table probability distributions random value uniformly distributed 
mean case 
threads independent events take place strict chronological order lps 
event takes place lp event thread scheduled take place time lp lp selected uniformly random lps system probability gamma event takes place different processor 
represents fully connected communication topology lps 
simulation ends event time te processed 
consider te ae lps selected uniformly random may assume similar number events take place processor 
claim supported theorem theorem ln increasing function objects placed uniformly random buckets probf max ip jb 
ln gamma omega gamma theorem follows chernoff bounds binomial random variables 
words large size bucket approximates optimal high probability 
formalises intuitive fact processor processes similar number events large addition may assume processor advances simulation te units simulation time 
true average causality thread generates similar number events simulation finishes causality threads processor 
particular average length causality threads te events 
load defined processors advance uniformly time 
synthetic load ideal properties global load balance important realise previous discussions related causality chapter 
analysis synchronisation methods dependencies events quite demanding load pdes bsp 
mainly due reasons practically consecutive events belonging causality thread take place processor ii events scheduled probability distributions small bias 
discussion explain points 
consider instance bimodal distribution 
case time intervals events belonging causality thread described large sequences small time intervals approx 
mixed comparatively small number large time intervals approx 

way varying intervals interleaved random long simulation runs expect large number different configurations 
consider cardinality events causality threads 
think terms large number causality threads difficult see steady state cardinality events covering region time space lp quite different 
increases processing events distributed supersteps 
addition decreases partitioning set events general non uniform may exist supersteps lp processes events 
factors increase variance number events processed superstep processor reduced average maximum number events superstep increased 
expect pessimistic values load 
macroscopic level values parameters directly related values basic parameters enable investigate performance systems varying sizes 
measure particular interest scalability system 
behaviour size system architecture scale simultaneously 
model scaled increasing issue related extension load mixing distributions mean values time increments model 
hand net effect mixing distributions modification average bias 
theorem see average bias maximum bias participating distributions 
chapter number distributions differing bias 
hand previous discussion see mixing different mean values effect tuning simulation smaller mean values 
prefer keep model simple constant mean value probability distribution experiment 
regarding comparison phold queuing network load described section interesting note queuing network number causality threads migrating processors severely reduced result queuing 
queuing network heavy load approximates phold demanding load ae case 
chapter 
analysis synchronisation methods analysis technique analysis primarily concerned costs scalability asynchronous synchronous time advance 
performance measure interest average interested total running time long simulations 
results average number events processed event horizon window easily transformed arguments similar employed sequential hold model directly obtain synchronous event horizon time advance 
analytically advance arguments 
order avoid simplifications purpose achieving mathematical tractability simple load resorted simulation approach validation comes different sources numerical monte carlo methods 
validated simulation data derive expressions describing functional relations input output parameters squares regression analysis 
obviously approach interest mainly centred general trend functions 
large scale systems practice candidate efficient parallelisation results give quite accurate picture comparative performance approaches time advance 
details regression analysis appendix note empirical results independent real time interference process load computer particular programming style employed implementation programs 
just count events count events sequential programs simulate operation approaches time advance hypothetical bsp machine 
simplifies collection statistics 
algorithmic details programs section 
experimental values calculated straightforward manner maintaining superstep counters 
experimental values obtained event trace sequential simulation 
maintain matrix event counters counter registers number events occurred particular processor superstep columns represent processors rows supersteps 
counters average maximum number events calculated supersteps 
experiment involves large simulation run events causality thread average matrix periodically shifted forward follow superstep progression hypothetical bsp machine 
shift forward partial statistics collected order obtain final average maximum number events superstep simulation 
depending type probability distribution event time increments run involves simulation determined number supersteps 
chapter 
analysis synchronisation methods experiment set simulation units time actual number causality threads migrating processors ranges cope high requirements memory running time executed experiments parallel processors ibm sp processors sgi power challenge parallel computers 
random time increments obtained functions described table 
functions random number generator produce numbers uniformly distributed 
experimented realisations generator seeds 
particular performed experiments improved library function available unix systems generators library simulation kernel 
results different experiments agreed 
surprising executed large runs measures independent software hardware platforms 
observed short simulations events thread results quite similar large runs 
approaches time advance approaches event horizon concept advance synchronously simulation time consuming supersteps shown note consider additional supersteps required min reductions compute new global event horizon cycle 
cycle pseudo code shown followed min reduction 
approaches pure asynchrony hand consume supersteps shown note silent min reductions needed approaches values global virtual time tw calculated pausing simulation 
min reductions carried supersteps simulate event occurrences 
call styles simulation time advance sync async respectively 
lemma total number supersteps required async optimal 
proof dependencies events form trees 
occurrence event generates event child scheduled occur different processor takes place superstep processed superstep 
simulation may delayed superstep earlier events take place processor superstep case descendant may take place superstep descendant takes place processor may occur superstep 
superstep event takes place async simulation 
total number supersteps async maximum values events events branches respective causality trees 
event branches takes place minimum possible superstep follows value minimum possible 
chapter 
analysis synchronisation methods async ensures events take place strict chronological order lp 
addition value event takes place lps calculated async maximum values processor parent causality tree event immediate chronological predecessor respective lp 
event takes place superstep simulation follows induction event branch causality trees achieves minimum possible simulation mapped processors completed minimum number supersteps 
note superstep counters sstep maintain current maximum values 
lemma sync generally optimal total number supersteps 
proof subset eh simulation events events mark event horizon times 
events necessarily causally related may generated different processors timestamped messages buffered respective sync supersteps 
size je subset total number supersteps required sync construction events occur superstep 
consider simulation async 
chronological event eh necessarily event processed processors second superstep 
remaining processors may advance farther time superstep barrier synchronised event horizon times 
implies horizon event may processed second superstep async 
similar argument applies supersteps general sync optimal supersteps 
approaches require identical number supersteps example event eh causally related simulated sequentially 
lemma assumption unlimited memory time warp realised bsp approximate supersteps async lg supersteps 
proof lemma follows trivially letting bsp time warp process available event time simulation period correct erroneous computations accordingly start new gvt calculation superstep 
gvt value simulation time obtained processing lg supersteps 
note processing available event superstep may lead large roll back overheads 
near optimal supersteps achieved low overheads limiting number events processed superstep proposed chapter 
chapter 
analysis synchronisation methods generate initial pending events event time tz event horizon time sz phi buffer loop tz sstep sstep schedule tz sz phi endif occurs processor sz sz feg tz mintime sz schedule endif endloop generate initial pending events indicates minimal superstep event may take place processor loop occurs processor sstep sstep endif sstep sstep endif schedule endloop total number supersteps maximum values array sstep 
sync async sequential programs describing rate superstep advance approaches simulation time advance 
schedule stores events set pending events 
retrieves set event time 
returns random time values 
returns number gamma selected uniformly random 
variable array sstep maintains current number supersteps simulated bsp machine 
assume programs 
case async algorithm lp maintains superstep counter sstep counter values carried events unit larger respective sstep counter event sent lp located processor 
sync case difference algorithm associated increase event horizon time calculated events sent processors 
chapter 
analysis synchronisation methods average case analysis supersteps actual number supersteps required synchronous time advance sync asynchronous time advance async complete simulation depends obviously degree locality system extreme case inter processor messages leading simulations superstep 
intuitive fact total number supersteps depends kind time increments applied new events 
example difficult see number supersteps unit simulation time deterministic time increment say unit sync async identical optimal 
fully connected communication topology 
probability distributions orders magnitude larger 
synchronous time advance analysis results sequential hold model 
suppose initial event list pending events timestamps continuous random variable 
hold operation consists retrieving event timestamp event list ii creating event timestamp iii storing event list 
event discarded remains constant sequence hold operations 
known executing long sequence hold operations probability distribution times approaches steady state distribution gamma 
represent values random variable values measured relative timestamp event retrieved hold operation 
random time increments calculate sync denoted follows 
defined probability density functions 
minimum random variables prob ma gamma minimum random variables resulting sum variable represents time event horizon 
say calculated gamma dt gamma dt 
mb gamma note gamma average time advance superstep 
simulation ends time te ae require average te gamma supersteps complete 
gamma consider negative exponential distribution mean time increments case gammax dt gamman dt chapter 
analysis synchronisation methods gammat gammat dt gamman dt 
approximation pp 
obtain probabilistic distributions calculations involved 
appendix section study probability distributions squares regression analysis 
observed similar fi ff trend different constant factors ff fi 
validate previous results related average number events take place event horizon sync 
numerical results suggest ffi fl types distributions hold model constants ffi fl 
results related follows 
suppose simulation finishes simulation time te ae 
average initial events generate te new events simulation 
mean value distribution assume 
total number events occur simulation te obtain ffi gamma fl fi ff results section confirm intuition supersteps unit simulation time depends number causality threads locality bias time increment distribution 
regarding bias best case occurs bias conjecture ff worst case bias conjecture ff 
situations close best case may arise deterministic time increments lower bounded time increments constant 
exponential distribution bias considered average extreme scenarios 
analysis mainly results distribution 
practical formula exponential distribution asynchronous time advance assume lp processor exponential distribution 
async global synchronisation simulation time global event horizon 
superstep lp simulates events time chapter 
analysis synchronisation methods minimum event time new events messages arriving lps superstep 
large number lps justifies parallel simulation reasonable assume significant amount lps statistically independent local event horizon 
average instance local event horizon average minimum independent random variables large 
previous results sync comments lead view async say fixed number lps conjecture ae ae asymptotically tends value sync simulation events 
provide evidence supporting claim scalability factor introduced 
lps advance simulation generally different amount time superstep 
homogeneous nature load imposed hold model implies existence average time advance superstep similar processor 
asynchronous advance time contradict fact superstep processor advances comparatively farther time increased probability superstep advance time comparatively probably order wait new events arriving superstep 
conversely modest advance time superstep increases probability farther advance superstep 
note average time advance superstep consider lower bound gamma time advance 
consider order statistics associated set random variables defined particular global event horizon sync approach 
gamma average values lower bound gamma comes assumption order statistics located different processor 
steady state just completing processing current event steady state time zero set random variables assumed uniformly distributed random processors 
current superstep processor simulates events time minimum subset variables located objects thrown uniformly random buckets expected maximum bucket size ln ln ln 
actual average time advance superstep expected larger gamma trivial upper bound achieved distributions bias 
actual value average time advance larger gamma difference gamma increases slowly maximum zn increases logarithmically 
exponential distribution claim true average time advance superstep compare gamma quantity 
unfortunately calculating gamma mathematically intractable 
hand numerical evaluation offers little opportunity credible results require ae known precision lost calculating terms form small large 
resorted monte chapter 
analysis synchronisation methods average order statistics exponential distribution 
carlo experiment 
large say generated different instances set random values exponentially distributed 
instance calculated partial sums sum gamma particular gamma sum experimented different seeds random numbers different random number generators 
results error cases 
results ranging shown show curve facts gamma gamma clearly observed 
interested ae case arises particular difference curves see range 
gamma behaves assuming gamma fi ff range fixed applied squares regression points ln gamma ln obtaining ff fi compared values ff fi resulting curve note qualitative gamma valid large studying ratio consider effect constant 
behaviour size system number processors scale simultaneously 
suppose steady state time zero processors start processing events superstep processor advances local simulation determined time gamma sum random variables represent time increments events forming thread causally related events 
positive difference lp time advances say delta gamma gamma gamma non zero probability chapter 
analysis synchronisation methods gamma gamma ffl gamma ffl ffl ffl gamma ffl time event lp superstep event processed superstep processes events superstep 
ideal case processor simulating superstep occurrence events generated processors superstep increase implies increase diversity gamma values increase probability events type 
particular interval delta gamma increasing function fixed may increase consider occurrence instance 
probability processed superstep directly related probability exists sufficient number processors gamma values small event thread takes place processors 
probability increases time events thread tend level time advance processors 
superstep variance gamma values involved processors expected smaller superstep words threads large increase time tend synchronise time advance processors region time space reduces probability new threads 
reasons existence threads 
expected increase slowly difficulty estimate 
exponential distribution random variable poisson distribution interval delta 
mean value single gamma assuming thread goes lp lp maximum delta 
assume fk threads created simultaneously fk increasing function mean expected maximum fk poisson variables ln ln ln estimation ln ln ln 
maximum zn bounded ln upper bound ln known function zn ln suppose case fk conservative estimation ln 
assume fk constant ln ln ln monte carlo experiment shows ln ln generated instances random variables exponentially distributed calculated average instances figures show comparisons function ln ln range interest 
assuming large interval delta fk poisson variables fk expected quite actual function bounded ln ln chapter 
analysis synchronisation methods ln ln th order statistic exponential distribution 
appendix explore validity conjecture 
simulation data obtained algorithm confirm quite accurately bound appendix study case lp processor 
data suggest ln ln practical formula exponential distribution case ln ln ln ln note simulation data show practice ratio average case analysis load balance load balance superstep level featured event efficiency metric defined section 
compare approaches time advance terms cases broad arguments type objects placed random buckets confirm intuition optimal large 
provide insight actual factors leading load balance practice 
synchronous time advance consider sync event efficiency say average total events take place superstep 
sensible distribution lps available processors theorem section see average maximum number events superstep chapter 
analysis synchronisation methods tend optimal scales 
large efficiency close high probability 
empirical results outline mean large 
note deterministic distribution sync async processes optimal number events superstep shows data deterministic det distribution 
validated data evaluating numerically average maximum events take place processor superstep 
calculated 
calculate average maximum assumed number events occur processor random variable binomial distribution 
value obtained calculating average maximum random variables results approximated simulation data error range assumption binomial distribution accurate 
obvious fact improves increases clearly observed practice larger order achieve efficiency 
scale need value comparatively smaller function example shows require slackness achieve need slackness consequence logarithmic scalability known asymptotics expected maximum bucket occupancy objects placed buckets large omega gamma ln ln ln ln small explain behaviour writing lnp ln lnp deterministic distribution 
note probability distributions small bias reduce significantly number events processed superstep 
shows efficiency results exponential exp distribution 
efficiency values clearly smaller shown identical reason exponential distribution reduces effective say efficiency values smaller lnp ln lnp exponential distribution 
new poses demanding requirement slackness omega gamma ln comparison slackness omega gamma ln required deterministic distribution 
chapter 
analysis synchronisation methods det theta theta theta theta theta theta theta theta theta theta theta theta exp theta theta theta theta theta theta theta theta theta theta theta results efficiency sync 
appendix section study behaviour simulation data 
obtained practical regression formula gamma ln gamma note formula tells practice slackness requirements sync higher predicted asymptotic formula 
asynchronous time advance drawback async comparative poor efficiency sync effects associated increase 
shows data async say exponential distribution 
shows smaller values sync instances compared 
seen efficiency increases quite slowly large systems reaches 
interesting situation arises 
superstep processor processes events processes 
result sequential event processing 
explain phenomenon assume new event scheduled occur processor different parent event 
case processors expected different time advance superstep probability processor delay superstep processing available events order wait arrival event lesser time 
soon occurs simulation degenerates sequential processor forced wait superstep 
example phenomenon shown section 
probability waiting event small consider process equivalent bernoulli trial performed superstep typical simulations chapter 
analysis synchronisation methods exp theta theta theta theta theta theta theta theta theta theta theta bim exp tri theta theta theta theta theta theta theta uni upper limit events exp upper limit events exp event limit exp theta theta theta theta theta theta theta exp theta theta theta theta theta theta theta theta efficiency async 
chapter 
analysis synchronisation methods demand execution thousands supersteps 
shows phenomenon occurred experiments performed exponential distribution 
observed phenomenon bimodal triangular uniform distributions 
exception biased distribution identical deterministic event scheduling 
distributions small bias processors tend significative differences time advance superstep 
symmetry broken threads constrained zig zag route 
shows ratio greater wide range parameters 
simulation data show ratio decreases fixed number processors increases ii scales proportionally 
point imply large systems efficiency async expected similar sync 
study behaviour exponential distribution large lp processor 
appendix section obtain regression formula constants omitted ln deterministic distribution 
sync exponential distribution effective reduced ln async assume set independent lps executing sync approach just events 
effective exponential distribution ln ln ln ln ln ln ln presents async better efficiency sync large asymptotic formula deterministic distribution conclude fact effective relevant factor comparison ln represents sort best case example consider defined order statistics section reduced factor gamma 
experiments similar shown predicts factor practical ranges factor consider effect void supersteps arising lps wait supersteps arrival events chapter 
analysis synchronisation methods lesser times 
existence void supersteps differing time advance superstep increase variance number simulated events 
example typical event trace exponential distribution looks sstep sstep indicates current superstep simulation identifiers represent processors values square brackets indicate number events simulated respective processor superstep 
studied ratio appendix section obtained regression formula constants omitted ln ln ln ln ln regression formulae provide information ratio fixed large values sync event efficiency better async efficiency 
particular achieve near optimal values 
large values function goes faster ln ln ln large small efficiency async expected better sync efficiency 
direct evaluation regression formulae constants confirm 
ranges efficiency values 
efficiency sync poor async large fairly small 
values 
addition values nearly sequential simulation 
sync achieve near optimal efficiency increasing async outperforms sync case approaches low efficiency 
event trace suggests straightforward solution efficiency problem async distribute event peaks consecutive supersteps 
effected setting upper limits number events allowed take place processor superstep 
value small limit may increase chapter 
analysis synchronisation methods number supersteps significantly point sync async similar figures show effect upper limits events 
shows efficiency improves noticeably limits reduced 
note case sequential phenomenon disappears completely 
hand shows cost increase supersteps associated respective improvement efficiency 
represents achieved upper limit instance 
value choice upper limit events cost increase observation agreement data values 
suggests upper limit processor superstep factor average number simulated events lp superstep event limit ln ln exponential distribution 
efficiency improves shown upper limit events imposed experiments 
data indicated maximum ratio shows improves increasing values shows large async similar near optimal efficiency sync 
reason related objects buckets problem larger values cause greater diversity time advances gamma superstep sum resident gamma tends processor reduces variance number simulated events processor level 
note observed sequential phenomenon occurs 
problem related number causality threads travelling zig zag fashion processors number lps processor 
statistical terms sense system behaves set processors sub systems 
event trace simulation indicates cases depicted take place gradually lp lp lps processor wait events lps processor 
soon happens complete simulation degenerates sequential 
practice near optimal efficiency achieved imposing upper limits events assigning lp processor 
appendix section derive regression formula exponential distribution ln ln ln chapter 
analysis synchronisation methods bsp cost synchronisation protocols section regression formulae establish comparisons known synchronisation protocols 
bsp cost protocol normalised metric cost unit simulation time 
load phold exponential distribution 
compare protocols yawns btb tw bsp tw proposed chapter 
yawns conservative protocol btb tw optimistic ones 
phold model processors lps processor initial threads lp 
event population dd homogeneous nature load average events processed unit simulation time 
events take place uniformly distributed processors processor 
event sends single message processor selected uniformly random 
total nm gamma messages sent unit simulation time assume processor sends nm messages 
lower bound cost processing event constant equal unit real time 
event granularity considered parameter 
optimistic protocols increase cost processing event units order include effect state saving 
roll backs cause re simulation events consider operation increases total number events oe events oe 
asynchronous protocol roll backs increase message traffic oe gamma nm conservative protocol overheads set oe 
synchronous time advance protocols require min reduction operation event processing superstep 
assume bsp cost operation rd lg gamma efficient scalability factor comes empirical observations 
alternative rd synchronisation operation performed event processing supersteps 
total bsp cost sync protocol yawns btb sync oe nm rd assuming large nm asymptotic cost sync oe lg lg lg alternative rd sync oe hand total bsp cost async protocol tw async oe oe gamma nm chapter 
analysis synchronisation methods large asymptotic cost async oe oe gamma ln ln note async better asymptotic cost sync 
sync protocols outperform async protocol determined situations 
describe cases 
note benchmarks known machines tell reasonable assume small number processors size typical event message 
assume holds assume processors connected butterfly topology provides asymptotics ln ln demanding case tw topology hypercube provides ln 
normalised bsp parameters ln ln ln ln note cost synchronisation ranges experiments described 
performed experiments non scalable min reduction results detrimental performance sync 
comparisons claim btb outperform tw ae lg ae overheads computation communication synchronisation irrelevant respect dominant cost processing events unit simulation time 
case relevant parameters comparison oe small may btb works smaller time window tw may oe oe shows asynchronous oe values btb outperforms tw 
point oe value solves equation btb gamma tw case oe 
shows btb strongly impacted increase cost barrier synchronisation processors increase 
produces unrealistic oe values 
claim yawns outperform tw similar conditions claim ae 
shows asynchronous values solution yawns gamma tw oe emulate queuing network load phold simulated yawns 
similar btb large values unrealistic 
figures seen increases sync requires smaller oe outperform chapter 
analysis synchronisation methods oe theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta points sync outperforms async 
async 
consequence near optimal efficiencies approaches 
illustrates fact overheads irrelevant load balance crucial comparative performance approaches 
comments experiments assumed unfavourable scenarios async approach 
evident sync protocols outperform async protocols conditions practice 
claim protocols avoid excessive roll backs chapter show tw achieves smaller number roll backs adaptive realisation btb 
clear btb smaller oe practice note straightforward bsp implementation btb leads poor load balance 
bsp tw uses upper limits events processor superstep basic synchronisation strategy 
achieves load balance 
observed values event limits reduced significantly increasing noticeably total number supersteps 
smaller limits reduce number roll backs 
note experimental data actual implementations protocols tell cost communication cost computation current machines 
irrelevant cost sending anti messages 
claim case assumed unrealistically large rate roll backs tw observed necessary increase significantly cost state saving order yawns outperform tw 
situations practice 
addition yawns protocol restricted needs sophisticated kind lookahead achieve reasonable performance chapter reviews issue 
note conservative realisation async cmb protocol included comparisons restricted systems communication topology lps small fan fan 
phold chapter 
analysis synchronisation methods fully connected communication topology 
chapter compare cmb protocols context simulation queuing network toroidal topology 
moral analysis btb yawns require large slackness outperform tw 
leads claim tw able exploit parallelism simulation model comparatively larger number processors efficiently 
validated assumptions 
sgi processors obtained hold model calendar queue exponential distribution word blocks size words respectively communicate data bsplib bsp operation 
machine comparative analysis pessimistic tw protocol cost barrier synchronisation higher assumption analysed approaches time advance fundamental simulation strategies important conservative optimistic synchronisation protocols pdes 
analysis focused realisation simulations bsp computers observed facts 
asynchronous time advance optimal total number supersteps required complete load mapped processors 
result respective synchronisation protocols require slackness properly costs communication synchronisation allowed process near maximal number events superstep 
turn allows efficient processors 
synchronous time advance may achieve optimal number supersteps particular load instances 
typical simulation models approach expected require comparatively larger number supersteps 
reduces number simulated events superstep increases slackness requirement achieve load balance 
furthermore associated protocols required perform min reduction operation supersteps increases synchronisation communication costs 
quantitative analysis suggests fixed number processors conservative optimistic synchronous protocols may outperform optimistic asynchronous protocols cases large slackness 
assumptions operation asynchronous protocols quite pessimistic practice 
analysis reveals simulation models partitioned large number lps appear particularly suitable efficient asynchronous simulation bsp model 
chapters investigate comparative performance synchronisation protocols actual implementations 
chapter bsp time warp chapter propose general purpose time warp system bsp computers 
similar time warp realisations reduce overheads exploiting particular features model computing employed 
model independent actual architecture parallel computer 
mere existence model consistent time warp system guarantee realisation efficient simulations 
focus key issues related performance time warp systems tuning optimistic execution memory management 
propose automatic method adaptively avoids thrashing behaviour due overly optimistic execution reduces probability recovers transitory memory exhaustion 
computer memory large simulation progresses near optimal event processing rate limited memory scheme allows simulation progress reasonable rate 
time warp protocol believed greatest hope general purpose simulation mechanism offers potential possibilities exploit entire parallelism available simulation model way transparent user 
numerous practical experiences tell efficiency scalability achieved number overheads performance degradation sources time warp kept reasonable control 
literature contains plenty different kinds optimisations fixing methods useful determined conditions particular parallel architectures 
important performance issues cost state saving thrashing behaviour arising propagation erroneous events faster cancellation leads increasingly long frequent roll backs 
case fraction running time spent rolling back erroneous computations dominates running time simulation chapter 
bsp time warp degrades performance noticeably 
solutions problem form limitation amount optimistic execution allowed time warp system 
addition time warp simulation requires memory respective sequential simulation necessary save past information states events messages support roll backs 
distributed memory system problem may exacerbated single processor required allocate amount memory similar sequential simulation 
case shared memory systems advantage allowing memory allocation global pool memory optimal techniques developed architectures 
possible implement software shared memory distributed memory system widely accepted cost incurred managing shared memory prohibitively high 
practice approach adopted distributed memory systems reduce onset memory exhaustion memory stall 
actual implementation time warp system may quite different forms depending approach optimistic execution memory management employed 
respect underlying model parallel computing crucial design system reasonable performance achieved model computing method simulation consistent 
chapter focuses efficient realisation time warp simulation bsp computers 
emphasise proposed bsp time warp system general purpose strong sense self tuning simulation model tuning may change adaptively execution follow evolution model 
bsp time warp system works follows 
bsp computation simulation carried executing supersteps 
superstep processor simulates occurrence events accordance messages received start current previous superstep 
simulation effected sequentially processor event list 
addition processor adaptive upper limit number events allowed take place superstep 
newly generated rolled back events treated identically kept respective processor event lists selected processing chronological timestamp order 
means rolling back lp events unprocessed re inserted processor event list ii events take place superstep roll back 
superstep events arriving processors may cause insertion rolled back events event list processor 
upper limit events superstep remains regardless number rolled back events processor 
net effect stragglers actual reduction speed simulation time advance processor cause chronological occurrence comparatively larger number rolled back events superstep 
turn leads relative synchronisation simulation time processor executing events far time expected receive chapter 
bsp time warp significant amount stragglers supersteps bring processor back synchronisation processors 
scheme tends emulate global event list gives priority processing timestamped events entire system 
rollback thrashing avoided way 
consider example multi producer consumer system processors labelled 
source lps processor send event messages sink lp located processor 
source lps roll back receive messages lps 
processing event occurrence source lp schedules new event random timestamp sends copy event sink lp 
note size event list associated sequential simulation system parallel simulation half list processor 
suppose efficiency goal process sequential event list superstep set upper limit events superstep processor 
simulation works follows 
superstep processor simulates occurrence events sends messages processor 
processor simulates events 
superstep processors simulate events 
superstep processor may suffer roll back new messages receives stragglers may arrive 
roll back processor imply simulate events 
processes events causes producer consumer imbalance 
time roll back reduces speed advance simulation time processor events simulates rolled back events 
reduction speed may continue point stragglers received 
case timestamp event source lp timestamp previous event 
superstep processor accumulated event list sufficient amount messages point onwards safe process chronological events 
way processor finds steady state simulation time advance rollback takes place 
course example simple simplicity illustrates approach synchronising optimistic execution processors proposed bsp time warp system 
general larger upper limits events larger may number stragglers roll back overheads number times events committed 
processors advance arbitrarily far simulated 
hand smaller upper limits smaller may overheads due roll backs event re simulations average gvt advance superstep slower total number barrier synchronisation processors executed larger 
clearly optimal value limits values may change dynamically simulation 
key achieving performance scheme set suitable upper limits chapter 
bsp time warp events near optimal gvt progression superstep achieved low overheads ii limits adaptive follow significant change evolution simulation model iii avoid situations producer consumer imbalance lead memory exhaustion 
propose adaptive method determining values upper limits 
method automatic unique feature information sequential simulation optimal bsp synchronisation protocol adaptively tune operation time warp engine 
sequential simulation performed time warp system execution 
key feature proposed system lps allowed advance asynchronously simulation time 
global window limiting optimism simulation time warp systems 
implies simulation periodically paused perform min reduction operations values define global windows 
proposed system bulk synchronous computation clear advantages terms grouping communication roll backs asynchronous time advance leads simulations better scalability lower slackness requirements simulations synchronous time advance shown chapter 
previous number factors reduce onset memory exhaustion time warp simulation increasing frequency fossil collection ii reducing frequency state saving iii saving portion state modified event occurrence iv pointers events anti messages resident lps reducing amount uncommitted events reducing degree optimism vi re allocating memory saved states accommodate new events 
case memory exhaustion scheme allows lps recover space sending back messages received lps 
lps forced roll back turn recovers space 
messages largest send times sent back incorrect 
idea enhanced selecting element message anti message saved state largest time 
element message returned sender scheme 
element anti message sent destination 
saved state simply discarded 
shows schemes may fail recover simulation organise operation lp level 
scheme solves problem selecting largest timestamped element lps 
artificial rollback scheme works similar idea causing roll back lps far simulated 
pragmatic strategy adopted detection memory stall involved processor broadcasts sync message processors discard simultaneously elements greater sync chapter 
bsp time warp timestamp 
idea introducing adaptiveness operation classical message passing time warp engine proposed 
adaptive time warp execution lps excessive rate roll backs suspended interval real time 
length interval determined statistics collected execution specific value intends minimise cost remain blocked process roll backs 
proposes probabilistic cost model calculate optimal blocking interval simulating event lp calls decision function determine block 
proposes alternative method computing probability event critical path simulation probability roll back 
event simulated high probability correct critical path combined probability overwhelms probability may incorrect 
schemes line proposed 
scheme proposed controls indirectly optimistic execution limiting number memory buffers assigned keep uncommitted events 
lps block buffers available wait fossil collection 
defines moving window length composed sequential part amount memory required sequential simulation system ii gvt part additional amount memory required advance gvt events committed instant take place iii optimistic part determines degree optimism allowed lp 
parts calculated statistics collected execution third part determined searching execution point running time near optimal 
ranking lps global progress window 
lps local virtual time closer lower border window allowed process events unit real time 
lps far simulation time allowed process events blocked 
avoids overly optimistic execution fast lps allowed advance far simulation time processors mainly dedicated advance slow lps 
lower border window gvt upper border largest 
quantities linear equation defines number events allowed take place lp accordance current 
memory management scheme control memory consumption optimistic execution shared memory multi processors 
rationale setting excessive amount memory events may degrade performance may cause page faults virtual cache memory systems ii overly optimistic execution rollback thrashing 
scheme sets limited amount memory events allows simulation progress calls 
execution total processed uncommitted events free memory buffers left system 
chapter 
bsp time warp controls degree optimism allowed simulation controls frequency executed 
parameters adaptive values call degree optimistic execution reduced extent events critical path rolled back artificially ii overhead associated execution procedure kept small percentage running time 
basic bsp time warp engine conventional time warp arrival message anti message timestamp past produces roll back previous state 
erroneous computation corrected advancing forward occasion including effect 
events may processed times committed 
lazy aggressive cancellation may employed recomputations view oriented message anti message 
bsp deal groups messages anti messages arriving constantly superstep impose upper limit number events allowed take place processor 
facts important consequences design time warp system aggressive cancellation upper limits events may happen re simulation rolled back events takes supersteps complete 
lazy cancellation employed speed propagation erroneous events 
similar reasons discard lazy re evaluation schemes applied sub set rolled back events take place current superstep see subsection 
aggressive cancellation full access processor local memory reduce overheads implementing direct cancellation events processors pointers causally related events 
standard method anti messages employed processors 
sequential simulation sequences causally related events spread processors 
messages charge scheduling events take superstep travel processor 
building right sequence events take place interval simulation time may take supersteps complete 
pointless consume events available superstep contribute building right sequence events 
certainly problem determine number events processed superstep processor system intended general purpose section address problem 
define suitable upper limits number simulated events processor superstep sensible approach give preference simulation current timestamped events processors 
sequential simulation processor cause chronological occurrence events supersteps 
chapter 
bsp time warp uniform event treatment avoid complications overheads associated identification rolled back events processing events keep sorted input queues treat events manner pending events stored processor event list 
return event list events pending events roll backs 
newly generated arriving events stored event list 
events placed event list may invalid due internal roll backs anti messages may chase respective messages event list 
efficiency process achieved means novel realisation event list performs event management operations amortised cost chapter 
result processor event list provides chronological event processing supersteps low cost manner independently number extent supersteps roll backs 
local minima event list eliminate conventional method sorted input queues attached lp events processor level determined priority queue 
system data structure processor event list composed tournament complete binary tree attached small linked list leaf 
lists kept unsorted events distributed lists uniformly random means hashing function list may contain events lps events lp may placed lists 
hashing function enables system perform fast searching events cancelled anti messages 
list maintain information smallest timestamped event 
events called local minima 
tree determine global minimum event processor 
new local minimum path respective leaf root tree updated 
insertion deletion operations take place groups supersteps implement data structure lazy mechanism attempts reduce number times tree updated number times local minima calculated lists details section 
mechanism ensures groups insertions deletions actual computation takes time event 
achieved letting insertions deletions take place low cost unsorted linked lists ii calculating local minima global minimum necessary determine event processor comparatively frequent operation 
number leaves tree doubled halved order keep lists small sizes 
event management independent specific rate events particular lps input queues large small number events kept sorted 
addition random placement events lists avoids dependence event time distribution unsolved problem multi lists pending event set implementations 
controlled optimism upper limits events ii distinction newly generated rolled back events iii chronological event processing processor chapter 
bsp time warp level length number roll backs severely restricted 
processor arbitrarily advance forward simulation time synchronised superstep amount superstep limited processor finds way advance far simulation time supersteps processor receive bring back synchronisation relative processors 
processor simulate comparatively larger number rolled back events superstep whilst upper limit events remains 
processors give preference processing timestamped events superstep leaving little space processing events far simulation time 
speed propagation erroneous events tends potentially lower speed correct computations 
grouped roll backs reduce overheads associated roll back processing take advantage fact messages anti messages arrive groups processors superstep 
reception process messages anti messages number stragglers expected arrive 
stragglers received put respective lps roll back priority queue registers earliest time roll back 
message stragglers stored event list anti message stragglers mark invalid respective messages 
lps rolled back processing earliest roll back 
process events need re simulated returned event list 
events generated events rolled back marked invalid lps put roll back priority queue 
message reception process completed event processing phase starts simulating timestamped event 
new roll backs occur phase employ similar mechanism roll backs distributed message passing environment arrival stragglers unpredictable number times lp rolled back expected larger bsp 
messages packed single units sent target processors superstep 
silent global virtual time calculation gvt calculation initiated periodically number supersteps executed 
gvt calculated min reduction operation starts processor determined local estimation gvt 
local gvt estimations calculated right finishing message reception process 
gvt defined minimum timestamps events processor anti messages buffered message reception process 
time warp systems simulation paused whilst calculating gvt 
min reduction carried event processing supersteps 
chapter 
bsp time warp adaptive synchronisation method proposed synchronisation scheme upper limits number events simulated processors superstep 
synchronisation relative processors comes fact event processing chronological distinction newly generated rolled back events 
reduction rate roll backs superstep comes fact upper limits suitable adaptive values proposed section 
section described simulation simple system synchronisation processors achieved setting sequential event list sizes upper limits events superstep 
note event list sizes determined automatically method proposed 
study complicated system phold synthetic load section processors lps processor initial events lp 
instantaneous size sequential event list dd dd large event list assumed uniformly distributed processors time dd pending events processor average 
suppose events scheduled deterministic distribution constant value 
case processors safely simulate dd events superstep 
roll back takes place event timestamps arriving superstep unit larger processed current superstep 
particular case efficient process sequential event list superstep 
events scheduled real probability distribution processing dd events superstep bad idea newly arriving events smaller timestamps events simulated previous superstep 
degrade performance significantly shown experiments 
obtained empirical results executing phold simulations processors size piece sequential event list located processor events scheduled exponential probability distribution mean 
show data experiments defined pairs dd 
value upper limit processor denoted set manually experiment 
shows gvt advance superstep achieved value data show optimal gvt advance superstep achieved value smaller different configuration 
small gvt advance modest large gvt advance reaches saturation point 
shows total running time increases extreme situations small large values 
particular running time increase linearly chapter 
bsp time warp notation gvt advance superstep total running time sec upper limit number events superstep 
curve data different relation number lps processor number events lp 
curve pair values 
random event time increments generated exponential distribution mean 
large indicating cost executing events optimistically rolling back dominates running time 
common practice pdes try find optimal phold gvt advance sense simulation performing binary search le le size sequential event list located processor 
bsp method basically set particular simulation operate supersteps whilst collecting statistics 
statistics enable definition new 
best searching method find near optimal lg le supersteps 
note practice large provide reasonably accurate statistics 
searching methods unstable behaviour due cyclical dependencies processors setting particular processor affect meaning processors receiving messages turn cyclically affect decisions taken processor clearly difficult obtain steady state results cases outcome stage search depends current tuning time warp engine 
propose method determining near optimal values independent actual tuning time warp engine 
method takes constant time produce results searching performed 
sufficiently large method predicts similar independently time warp system currently operating high low degree optimism 
note instantaneous sequential event lists property independent current tuning time warp engine measure sequential simulation parallel simulation 
chapter 
bsp time warp oracle simulation approach idea information sequential simulation order determine proper tuning parallel simulation 
unique feature actual time warp simulation execute code associated sequential simulation ideal bsp asynchronous protocol parallel simulation simulation model bsp time warp simulation roll backs take place 
bsp protocol call oracle ability completing parallel simulation minimum number supersteps achieves optimal gvt advance superstep 
note sequential algorithm simulates actions protocol phold chapter async algorithm 
achieve optimal gvt advance rate oracle processes average number events superstep processor 
obtain averages processor oracle simulation set upper limits events superstep processor actual time warp simulation 
calculate fresh averages regular intervals supersteps 
averages previous interval values current interval 
provides required adaptiveness scheme 
initially set oracle simulation effected executing lp asynchronous superstep counter code driven event messages carrying superstep counts lps 
maintain superstep counter sstep lp event message carries integer indicating minimum superstep event may take place parallel simulation synchronised oracle protocol actual time warp simulation 
say superstep counters describe superstep advance virtual bsp machine 
message received lp execute code sstep sstep new event scheduled lp lp carries superstep count sstep located processor sstep resident lp 
addition counters sstep 
considered part states respective lps values corrected roll backs 
time warp mechanism ensures events timestamps gvt taken place strict chronological order lp lp states counters just gvt provide accurate indication supersteps executed virtual bsp machine gvt 
point total number supersteps executed processor virtual machine maximum superstep counters maintained resident lps 
averages define values calculated intervals supersteps 
quantity defined start superstep interval new gvt value available 
fossil collection procedure executed superstep chapter 
bsp time warp sim 
time gvt gvt lp lp lp lp gamma gamma oracle superstep count gvt committed event processor calculating supersteps bsp time warp initially 
way particular processor interval supersteps calculated number events committed superstep processor increment oracle supersteps current interval processor calculations locally processor completing fossil collection procedure 
increment oracle supersteps calculated difference maxima lp superstep counter values just gvt supersteps gamma superstep previous interval 
see example 
show effectiveness oracle scheme phold simulations 
simulation starts shows system rapidly automatically finds suitable operational values compared values 
sampling interval supersteps shows method able extract near optimal gvt advance superstep quite small note real life simulations easily require execution supersteps 
shows total running time complete simulation performed oracle shown separate runs 
shows near optimal running time achieved phold comparison minima 
shows adaptiveness scheme 
case timestamp increments events scheduled exponential distribution simulation period biased distribution period center 
shows ratio number committed events number simulated events 
measure degree optimism chapter 
bsp time warp sample number sample number notation upper limit number events superstep total running time sec 
separate runs 
curve data different relation number lps processor number events lp 
curve pair values 
random event time increments generated exponential distribution mean 
initially sampling supersteps 
simulation 
emphasise oracle simulation carried locally processor level 
global computations required async algorithm execute lp driven asynchronous message passing process lps 
sequential event list sizes discussed oracle achieves optimal minimum number supersteps required complete simulation mapped processors 
imply speedup running time optimal system 
fact running time order sequential simulation 
consider example system lps lp processor lp send messages lp lp source lp lp sink lp 
case optimal number supersteps oracle indicates superstep lp processes events lps process 
result sequential simulation overheads parallel 
systems feature cycles formed oracle superstep counters repeatedly incremented simulation instantaneously achieve final values soon processors receive message processors gamma 
processor level case easily detected oracle simulation increment supersteps zero sampling intervals 
processor detects increment oracle supersteps interval supersteps defined adopt strategy simulating sequential event list superstep 
chapter 
bsp time warp gvt exp exp gvt upper limit number events processor superstep gvt global virtual time experiment virtual time exponential distribution biased distribution 
total number committed events total number simulated events similar experiment 
particular systems impediment process sequential event lists superstep memory available simulation simple pipelining process 
general may happen combination cases takes place 
processors receive messages increment local oracle superstep counters 
approach processors decide locally process sequential event list superstep process average number events produced oracle observed superstep increments oracle simulation 
size le piece sequential event list located processor calculated fossil events formula proposed le se delta se sum differences gamma fossil events delta gvt increment interval supersteps send receive times simulation times event generated takes place respectively 
formula derived modelling event scheduling process queue infinite servers 
average number active servers le queue defined ratio arrival rate events service rate events 
events scheduled delta arrival rate delta average service rate server se shows le values processor phold simulation event population doubled second half simulation 
related subsection 
chapter 
bsp time warp gvt le superstep gvt shows curves le indicates size piece sequential event list formula le se delta oracle upper limits events processor load similar processor 
experiments number scheduled events suddenly doubled gvt greater units simulation time 
shows curves axis simulation time 
top bottom curves show values time barriers processor timestamp event processed superstep timestamp event processed superstep gvt advance 
experiments 
flow control synchronisation scheme possible processors set upper limits events accordance averages produced oracle sequential event list sizes 
long term producer consumer imbalances arise processors leading memory exhaustion 
simple example system gamma processors send messages phold th processor send messages group receive messages 
case th processor sets size piece sequential event list located event limit may certainly cause memory stall group gamma processors operating comparatively smaller event limits 
similar situation occur processors upper limits oracle simulation 
difficult see simulation model particular patterns communication topology eliminated distributing lps uniformly random processors sensible approach load balancing systems probability memory exhaustion due producer consumer imbalance quite low 
form flow control needed system intended general purpose 
note producer consumer imbalance arises event scheduling rate higher rate events committed 
straightforward approach avoid memory exhaustion imbalance set upper limit number chapter 
bsp time warp events processor may scheduled time 
local time barriers perform flow control processor level superstep events timestamps allowed take place processor emphasise local time barriers primary tool synchronise lps simulation time emphasise processor works locally defined time barrier 
words proposed method uses time barriers necessary adaptively rein advance fast processors 
example presents empirical results phold increasing time barrier values processor shown time event simulated processor 
shows phold producer consumer imbalance time barriers restrain advance simulation time processors 
define time barrier processor assumes locally processors simulating sequential event list superstep 
means best exactly entire global sequential event list committed superstep 
necessary schedule events maximum rate 
ffi gvt increment fossil collection number fossil collected events 
quantity ffi ffi average time increment events belonging piece sequential event list located processor le size piece event list define delta ffi delta le maximum event processing rate processor simulates le events advances delta units simulation time superstep average 
superstep processor allowed advance say gvt delta gvt estimation gvt specific superstep time new value gvt available local time barrier superstep set gvt delta number supersteps required complete gvt min reduction 
supersteps follow gvt set delta way time barriers incremented observed gvt advance advance fast processors 
note sudden increase time pending events entire system may current delta values comparatively small 
values small gvt increment gvt calculations zero deadlock takes place 
avoided adopting rule gvt calculations events processed number supersteps elapsed gvt values 
gradually incremented supersteps requirement easily met simulation models 
alternatively gvt increment zero values may set infinity upper limits events may set 
causes fresh start simulation sensible approach follow past information longer useful predict near dramatic change evolution simulation model taken place 
achieve processor utilisation upper limits events processor chapter 
bsp time warp ne superstep ne superstep results processors 
processors works phold th processor contains source lps send messages phold lps 
shows number events ne processed superstep th processor time barrier shows number events ne processed superstep upper limit events processor set observed average number events superstep 
case upper limit events processor set size piece sequential event list soon gvt regulator 
occurs periodically supersteps maximum reduction upper limit events allowed respective sequential event list 
experiments 
reduced observed average superstep gvt calculations 
processors simulate events upper limits due hits time barriers strategy tends rapidly distribute events supersteps evenly manner 
necessary detect points processor gvt regulator restore current upper limit events processor slow gvt advance 
see 
recovery memory stalls simulation recovered memory exhaustion occurrence possible barrier synchronising lps gvt events send time greater gvt discarded 
memory stalls come sources memory requirements simulation larger available processor memory permanent memory stall ii simulation peaks memory requirements produce transitory memory stalls 
messages calculate gvt enhanced flag indicating processor detected memory stall interval gvt calculations 
average memory requirement time warp simulation reduced decreasing number supersteps elapsed fossil collections decreasing number events simulated superstep reduction upper limits events 
gvt advance forward factors minimum values memory chapter 
bsp time warp perform simulation permanent memory error communicated user simulation aborted 
transitory memory errors recovered noticing fossil collection time warp simulation allocates memory uncommitted events gradually supersteps 
implies forced reduction average memory consumption overcome transitory peak memory allocation gvt advance successive memory stalls 
barrier synchronisation gvt repeatedly applied gvt continues advancing forward 
timeout number supersteps simulation performed reduced values upper limits events 
enables simulation return normal operation transitory peak memory consumption vanished 
gvt advance successive synchronisation gvt permanent memory error declared 
protocol instance results show details adaptive protocol proposed chapter 
table show speedups different event granularities phold bsp time warp processor ibm sp 
introduced artificial delay micro seconds event simulate effect local events events larger computational requirements 
sequential simulator uses event list bsp time warp 
table shows measures total number supersteps anti message traffic roll backs memory requirements details table 
tables shows results processors sgi phold low high locality communication 
experiments granularity events minimal artificial delays 
column ro shows precision oracle simulation see table 
experiments table simulation performed oracle upper limits events reduced factor 
positive effect reducing number roll backs see column values speedup row table 
calculate speedups sequential simulator table 
simulator contain overheads parallel simulator roll backs state saving communication synchronisation 
shows effect efficient realisation message communication bsplib operation bsp send 
shows effect highly optimised realisation operation performs direct data transfer user memory spaces different processors bsp 
chapter 
bsp time warp upper limit events superstep init 
oracle supersteps increment processor 
le size piece sequential event list processor 
nc total number fossil collected events init nc 
time barrier flow control init 
delta time increment superstep init delta 
supersteps required perform gvt min reduction 
number supersteps fossil collections 
number simulated events 
event takes place time 
superstep delta 
new gvt value gvt delta 
fossil collection nc nc 
update delta le nc le delta nc le nc 
gvt increment zero nc delta gvt 
memory stall max min max min min min gvt increment set timeout reduced values gvt 
protocol events processor 
chapter 
bsp time warp sstep msg mem table speedups different event granularities phold processors ibm sp 
event granularity increased artificial delays micro seconds event 
column sstep ratio total number supersteps simulation total number supersteps simulated oracle 
column msg ratio total number anti messages total number messages sent processors 
column ratio total number committed events total number simulated events including re simulations 
column mem ratio total memory parallel simulation total memory sequential simulation fossil collection performed supersteps 
shows impact software overheads performance protocol 
speedup calculated parallel simulator uni processor implementation bsp time warp cost communication synchronisation zero overheads roll backs state saving message management 
processor maintain lps messages lps send supposedly processors re directed lps selected uniformly random 
note uni processor bsp time warp program equivalent bsp time warp implemented sequential simulator bsp protocols described section chapter 
interested comparing exactly programs including processor memory utilisation differing bsp realisations re directs messages single processor standard bsplib function 
speedup 
calculated sequential simulator uni processor realisation bsp time warp described 
case running time amplified parallel simulator normal processors bsp time warp program bsplib 
shows effect cost communication synchronisation performance protocol sequential parallel simulators software overheads 
chapter 
bsp time warp tw ro low locality tw ro high locality table speedups sgi processors phold load 
notation tw number supersteps unit simulation time achieved bsp time warp upper limit events determined simulated oracle ro ratio total number supersteps simulated oracle total number supersteps async oracle algorithm chapter ratio total number committed events total number simulated events 
speedups defined subsection 
table shows results case new events scheduled processors probability table shows results case probability 
chapter 
bsp time warp automatic method efficient time warp simulation bsp computers 
method adaptive uses information past predict operation time warp engine near 
information gathered simulation ideal synchronisation protocol called oracle able complete parallel simulation minimal number supersteps 
simulation fly time warp engine oracle statistics enable setting suitable upper limits number events simulated processor superstep 
asynchronous nature oracle algorithm allows operations locally processor level 
superstep events simulated chronologically processor upper limits modified result roll backs 
combination factors tends emulate parallel event list gives preference processing timestamped events system 
effectively avoids roll back thrashing fast lps processing time advance far simulation 
simulation models oracle simulation fails provide useful information avoid roll back thrashing memory stalls due consumer producer imbalance 
special cases standard approach load balance bsp break particular communication patterns distributing processes uniformly random processors 
random allocation lps processors convenient produces oracle simulations non zero superstep increments 
special cases set local time barriers allow processors advance predefined distance gvt superstep 
processor sets time barrier finds superstep increment oracle simulation 
define extent time barrier processor locally assumes committing sequential event list superstep 
defines upper bound gvt advance superstep quantity define extent time barrier 
view implementation schemes artificial rollback recover simulation temporary memory exhaustion attractive bsp setting due overheads associated selection elements individual roll backs 
simply synchronise lps newly calculated gvt re start simulation mode operation demanding terms memory requirements 
provides basic memory management scheme 
emphasise column mem table shows values quite similar achieved time warp systems said efficient memory requirements 
note average amount memory required bsp time warp simulation reduced increasing fossil collection frequency reducing upper limits events 
chapter evaluation optimistic protocols assess empirically performance number synchronisation protocols suitable optimistic pdes bsp computers 
performance metrics bsp cost model independent particular implementation protocols 
metrics identify protocols near optimal performance 
protocols convenient general purpose simulation environments leave user responsibility tuning critical operational parameters simulation model 
solve problem implementing protocols method automatic tuning optimistic execution proposed chapter 
way study chapter focuses performance protocols devised general purpose simulation environments 
bsp computations basically organised supersteps delimited barrier synchronisation processors messages available processing superstep 
associate points barrier synchronisation processors global synchronisation logical processes lps simulation time learn number optimistic synchronisation techniques bulk synchronous method parallel simulation 
cases schemes define cycles events timestamps globally defined window simulation time allowed take place min reduction operation local information executed order move forward window start new cycle 
apparently techniques implemented directly bsp computer slight modification 
protocols suitable bsp basic form computation bulk synchronous rely non bsp features remain efficient asynchronous message passing cycles preemptive non blocking barrier synchronisation processors 
investigated methods chapter 
evaluation optimistic protocols overcome limitations underlying strategy promoted protocols efficiently implemented architecture independent model bsp 
way provide portability protocols 
chapter empirical results compare performance protocols modified suitable bsp context 
study aims independent actual implementation protocols particular data structures programming 
consequently avoid running time measures justify decision noting protocol process basic set events perform state saving roll backs sum software overheads similar 
protocols differ number event re simulations processed result roll backs differing requirements communication synchronisation processors 
factors real difference terms total running time assess set performance metrics specially devised purpose 
performance metrics load performance synchronisation protocols characterised implementation independent metrics ratio total number supersteps executed synchronisation protocol complete simulation minimum number supersteps required complete simulation value obtained sequential simulation async oracle described chapter 
measure maximum speedup protocol consider cost communication synchronisation 
set events processed simulation ratio cumulative sum maximum number events simulated processor superstep number processors 
refer event efficiency 
parameter includes re simulation events due roll backs number events processed sequential simulation system 
ratio total number committed events total number simulated events 
gamma indicates fraction anti messages messages sent simulation 
similar counting maximum number messages sent superstep 
purpose comparison assume event sequential simulation generates single message sent processor probability gamma chapter 
evaluation optimistic protocols refer message efficiency 
indicate values exclude anti messages 
assume size anti message half size event message 
computing consider factor anti messages weighted sum messages anti messages 
measures related event processing supersteps 
exclude effect supersteps perform min reduction operations synchronous protocols 
experiments consider symmetric asymmetric instances hold model 
data reported section come executions standard symmetric bsp hold model defined chapter data asymmetric version description section 
experiments define constant number processors vary number lps processor number initial events lp 
define pairs configurations ranging 
results subset pairs shown tables section pairs shown figures section 
section figures data small instance hold model pairs ranging 
simulation time units timestamp increments events take values negative exponential distribution mean 
optimistic protocols bsp time warp tw time warp basic method simulation employed approaches discussed chapter 
chapter call tw optimistic synchronisation method proposed chapter 
table shows results pairs delta delta delta 
obtained empirical results versions bsp tw tw uses upper limits events determined oracle tw reduces limits factor aim reduce roll backs anti message traffic 
column table shows supersteps twice optimal number supersteps load instance 
particular tw improves performance indicator tw cost small increment supersteps 
observed values achieved tw noticeably better achieved async oracle 
pairs delta delta delta oracle event efficiency values 
column shows effect anti messages message efficiency 
values contrast values column show normal event message traffic chapter 
evaluation optimistic protocols tw tw tw tw tw tw tw tw tw tw table bsp time warp reasonably balanced 
anti messages responsible degradation protocol send larger number messages sequential counterpart 
fraction anti messages gamma tw 
moving time window mtw moving time window mtw protocol processing events driven time interval delta 
processor allowed process occurrence events timestamps delta 
addition scheme tries optimise processors utilisation moving forward window soon number candidate events falls certain threshold value original mtw devised shared memory multi processors 
lower border window set equal current timestamped pending event entire system 
width delta window parameter defined user 
scheme automatic adaptive 
proposed bsp implementation mtw update lower border window gvt values 
scheme automatic information simulation oracle define window width delta 
messages sent supersteps time window globally defined quantity delay sending normal event messages point timestamps scope time window 
reduces anti message traffic erroneous events cancelled actual sending 
evaluate implementations mtw call mtw mtw respectively 
mtw event processing superstep processors simulate available events timestamps current window 
min reduction operation executed order calculate gvt move forward window updating lower border new gvt value 
gvt calculation events processed 
upper border gvt delta delta periodically updated follows interval event processing supersteps oracle executed total supersteps average chapter 
evaluation optimistic protocols gamma table moving time window processors gvt increment period ffi delta ffi mtw scheme uses superstep process events 
gvt min reduction operation embedded normal event processing supersteps 
assume supersteps new gvt value available 
time gvt min reduction produces new gvt value set upper border window gvt delta delta updated mtw oracle simulation 
supersteps gvt values upper border window updated delta upper border window previous superstep 
supersteps processors estimation gvt advance factor prevent estimations actual gvt advance 
small avoid estimations value 
table shows results realisations mtw mtw mtw 
results show mtw achieves slightly better performance mtw terms event message efficiency 
mtw advantage performing pausing gvt min reduction operations mtw requires slightly fewer event processing supersteps 
regarding comparison mtw tw table event processing supersteps required mtw slightly larger cases 
tw outperforms mtw event efficiency mtw outperforms tw message efficiency 
facts expected roll back mtw processes events including re simulations current upper border window tends degrade event efficiency ii mtw delays sending messages timestamps greater upper border window reduces message traffic 
results suggest best strategy loads similar hold model systems processors advance rate simulation time combination approaches 
tw time barriers set delay sending speculative event messages 
note event efficiency values achieved tw indicate speculative events take place cancel events processor event lists 
note event efficiency chapter 
evaluation optimistic protocols relevant metric optimise message efficiency systems small event granularity cost communication expected comparatively smaller cost causing occurrence events messages sent blocks superstep reduces amount real time spent communication ii size messages small 
clear substantial reduction running time achieved just reducing anti message traffic event efficiency noticeably affected messages 
anti messages represent small fraction total message traffic 
filtered roll back similar idea mtw cycles filtered roll back protocol 
case cycle composed phases delimited barrier synchronisation processors 
phase lp estimation lower bound delta timestamps events scheduled neighbouring lps determined 
second phase events timestamps delta simulated 
may selectively simulation events delta particular lps addition lp receives processes associated roll back phase 
third phase performs min reduction operation order determine current pending event timestamp system gvt 
lower border window set value moves forward window cycle 
values delta communication topology lps defined user 
bsp implementation cycle composed supersteps plus supersteps required min reduction operation 
contrast mtw requires superstep cycle 
additional superstep gather information neighbouring lps hosted processors order calculate lower bounds lower bounds removed algorithm convenient general purpose simulation environment avoids burden dealing explicit communication topology lps identical mtw approach difference supersteps lps process roll backs 
may efficient dedicate supersteps process roll backs individual lps tends increase significantly total number supersteps required complete simulation 
supersteps tend reduce speed propagation erroneous events efficient process roll backs aggressively start cycle process available timestamped events gvt advance cycle 
erroneous computations propagate far simulated global time window 
performance better performance mtw exclude approach discussion relevant chapter 
note chapter results conservative version chapter 
evaluation optimistic protocols bounded lag protocol 
bounded time warp btw bounded time warp btw protocol defines barrier simulation time moving time window 
barrier time tb cycle btw consists processing events time tb cycle finishes events barrier 
cycle starts increasing barrier new value tb tb delta point messages currently buffered processors satisfying tb sent respective destinations 
value delta defined user 
bsp implementation btw supersteps process events current cycle messages take superstep arrive destinations ii events may schedule new events time current barrier processors 
event processing supersteps simulation 
barrier increased soon processors pending events buffered messages timestamps time barrier 
detect instant quite efficient solution bsp 
scheme master processor processors send status master broadcasts increment barrier message 
scheme perform successive operations emulate preemptive min reduction operation proposed 
min reduction returns value indicating processor ready increment barrier simulation proceeds cycle 
case number supersteps dedicated operation expected larger ones required standard bsp min reduction operation 
experiments btw expression tb tb delta increment barrier delta updated mtw oracle simulation 
factor search near optimal barrier increment hold model instance 
run experiments values ranging 
table show results 
sections table show data pairs 
third section shows data 
expected small values increase noticeably total number supersteps 
hand large values decrease supersteps decrease noticeably event message efficiency 
gamma values show occurs large number roll backs take place 
value appears choice roll backs competitive values moderate number event processing supersteps 
chapter 
evaluation optimistic protocols gamma table bounded time warp breathing time buckets btb breathing time buckets btb adaptive protocol event horizon eh concept 
assuming processors synchronised time processed events eh defined time timestamp new events generated pending events processed new events generated set pending events existing instant 
value eh defines upper border time window current cycle cycle starts eh 
instant processors know advance value eh 
start current cycle processing events optimistically whilst keeping information local event horizons similar definition eh processor level 
soon processor reaches learns smaller engages min reduction operation processors order determine global eh 
note messages known safe sent cycle anti messages required 
described value eh enables protocol identify messages 
bsp implementation btb straightforward cycle mapped event processing superstep followed min reduction operation 
serious load imbalance problems arise due differing values event processing superstep 
explore realisations btb bsp 
btb implementation derived simple reading mapping description superstep semantic bsp btb cycle superstep simulate events time local event horizon chapter 
evaluation optimistic protocols updated minimum receive times messages buffered previous cycles current cycle 
start min reduction calculate global event horizon eh 
superstep min reduction send messages send time equal eh update messages remain buffer send time greater current eh 
start new cycle superstep onwards 
events managed usual roll back procedure sending anti messages 
btb cycle btb attempts follow ideas barrier lps eh start new cycle 
eh known processor simultaneously discard pending events processed events buffered messages send time greater eh 
btb aims improve load balance btb 
scheme proposed processors allowed process events cycle 
processor reaches limit delivers eh min reduction time pending event 
defined user 
introduce adaptiveness scheme obtaining suitable simulation variant async oracle 
obviously event efficiency improved noticeably setting sufficiently small cost significantly large total number supersteps 
aim improve load balance cost small increase supersteps factor 
note maintain async oracle algorithm global superstep counter asynchronous counters total number supersteps registered counter simulation equal total number supersteps ideal event horizon simulation sync oracle described chapter simulated bsp 
bsp memory distributed machine global counter unfeasible 
approximate values global counter advantage fact simulation paused min reduction messages sent operation 
processor maintains local superstep counter updated events take place resident lps 
eh min reduction calculate maximum superstep value achieved local counters event processing superstep 
local counters updated maximum message sent processor gets minimum superstep value occurrence updated maximum plus 
simulation results show chapter 
evaluation optimistic protocols btb btb btb btb table breathing time buckets scheme approximate actual minimum number supersteps btb determined sync oracle described chapter error 
adaptive values obtained samples event processing supersteps 
interval count total number fossil collected events determine maximum oracle superstep events took place 
quotient quantities produces event processing supersteps 
experimented time intervals event intervals length case virtual time increment sampling interval determine width moving time window event processing superstep 
lower border window set current eh start event processing superstep 
obtained slightly better results event limits time window counterpart 
btb similar btb local roll backs btb 
table shows results versions btb 
rows indicate supersteps noticeably larger btb previous protocols 
actual number supersteps fairly constant pairs total number supersteps standard async oracle increases decreases increases 
table shows pairs 
metrics show data pair values similar pairs 
best performance obtained btb 
experimental data show btb btb achieve performance bsp computer 
due significant load imbalance introduced processors going eh boundaries cycle 
schemes suitable bsp computers reasonable performance achieved proposed btb cost barrier synchronisation processors small 
chapter 
evaluation optimistic protocols time warp stw cycle time warp stw processor simulates events gvt calling non blocking synchronisation function 
executing function processor may continue simulating events maximum events point processor blocks 
event processing globally paused perform gvt calculation processor called non blocking function 
new gvt value available fossil collection procedure performed processor commits events enables start new cycle 
start new cycle simulated events timestamps greater gvt 
events considered part events gvt new cycle prevents overly optimistic execution 
values defined user 
note approach event window counterpart time window employed mtw similarities approach proposed chapter bsp tw 
enumerate differences stw bsp tw 
point take consideration stw assumes asynchronous message passing environment 
cycle messages sent asynchronously 
non blocking synchronisation function sense bsp 
stw necessary keep information events gvt bsp tw upper limits events related gvt 
avoid optimism keeping fixed upper limits events making distinction rolled back events events whilst counting number events simulated chronologically current superstep 
hand stw avoids optimism imposing upper limit number events simulated gvt 
prone deadlocks counted events events increase gvt 
note mtw prone deadlocks suppose event times suddenly increase time window events processed cycle gvt advance 
synchronisation strategy bsp tw deadlock free operation gvt advance 
approach able advance gvt gives priority simulation timestamped events superstep considering flow control component protocol works larger scale time 
bsp implementation stw assign superstep process events gvt 
automatic values oracle simulation average number oracle events processor superstep 
event processing superstep followed gvt min reduction operation 
cycle algorithm processors cause occurrence events 
second cycle obtaining new gvt value possible processors remain uncommitted events simulated chapter 
evaluation optimistic protocols previous cycle 
addition processor event list new pending events events arrived associated roll backs invalidated uncommitted events transformed ones pending events 
scenario trivial keep track events new uncommitted considered events gvt new cycle 
note naive strategy maintaining simulated events counter processor value reduced fossil collection clearly prone deadlock counted events timestamps greater current pending events processor block processing events increase gvt 
deadlock cleared synchronising lps gvt setting counters zero 
performance metrics btb show efficient associated increase number event re simulations preliminary experiments showed deadlocks take place frequently case 
suggests list processed events processor level 
size list comparisons 
guarantee deadlock avoidance 
worked correct solution employing idea processed events list processor 
treat processed events list linear list kept sorted event timestamps insertions starting tail efficient strategy events take place chronologically superstep deadlock free solution comes considering explicit position new insertion list 
insertion position deduced size list number comparisons performed insertion operation 
time insertion position occurrence respective event simulated 
committed events rolled back events removed accordingly list provides required movement event window size 
note possible size list larger extent equivalent considering second limit 
impose specific upper limit size list leads deadlocks 
alternative synchronise lps gvt size lists reaches predefined upper limit meaning lps far simulation time convenient globally synchronise simulation 
table shows results described bsp implementation stw 
results compared mtw shown table 
approaches fairly performance stw shows slightly better event efficiency comes cost slightly larger number supersteps 
advantage mtw stw reduction anti message traffic 
chapter 
evaluation optimistic protocols gamma table time warp breathing time warp approach combines described stw btb protocols 
breathing time warp cycle composed phases stw btb gvt fossil collection phases 
means events processed gvt messages sent aggressively 
model computation employed phase asynchronous message passing 
starting event processed gvt switches btb mode meaning messages retained processor event horizon known processor 
stw btb messages received target processors simulation paused gvt calculation fossil collection performed 
bsp setting combination stw btb attractive reasons 
asynchronous message passing single superstep sense bsp setting 
bsp implementation btb calculating event horizon equivalent calculating gvt processing number events 
basically stw 
bsp implementation stw processors simulate comparatively larger number events btb superstep unnecessary btb 
exclude discussion relevant chapter 
comparative study symmetric hold model show data comparing tw mtw stw btw btb 
figures show results symmetric hold model axis indicates pairs 
missing values supersteps btb 
results show bsp tw achieves better reasonable btb achieves event efficiency result adaptive upper limits events 
shows requirements synchronisation high 
chapter 
evaluation optimistic protocols results suggest cases close lp processor large number events lp btb outperform protocols 
similar performance may achieved halving upper limits events tw advantage avoiding pausing operations 
note message efficiency btb better achieved mtw btw 
realisation adaptive mtw competitive alternative systems large number lps processor 
number lps processors decreases number roll backs increases 
case figures show tw performs clearly better mtw situations large number roll backs 
case mtw pays cost blindly attempting process rolled back events processing event upper border current window 
degrades event efficiency number event re simulations increases valid btw 
note approaches tw mtw working oracle simulation data initial delta mtw reduced factor 
performed experiments setting delta initially delta supersteps gvt values 
event efficiency values improve noticeably 
example event efficiency pair increased 
similar experiment delta performed btw 
case increased pair 
investigate issue 
note stw achieves better event efficiency values mtw small number lps 
asymmetric hold model compare tw mtw stw btw btb asymmetric realisation hold model 
model introduce special events called events intended increase load imbalance probability occurrence rollbacks 
initial pending event set populated events normal hold model events events 
events operate pairs occurrence causes scheduling event takes place lp located processor selected uniformly random 
event takes place lp located processor specific processor lp selected uniformly random 
initially pending event starts rule applied onwards 
way events take place processor produces severe load imbalance 
order increase number roll backs take place simulation timestamp increments events mean value timestamp increments events mean value sum timestamps mean value consecutive normal events ensures simulation causality threads produced similar number events 
event scheduled chapter 
evaluation optimistic protocols processor high probability causing roll back timestamp increment comparatively smaller normal events place processor 
results expressed ratio protocol tw shown figures tw ratio supersteps protocol supersteps tw 
similar ratios defined cumulative sum maximum number events messages superstep 
qualitative similar symmetric hold model figures 
reducing slackness similar experiments shown performed small instance hold model pairs 
results shown describe similar comparative performance shown 
reducing oracle predictions previous figures showed data realisation tw working oracle defined upper limits events 
similar factor employed mtw protocol reduce width oracle defined time window 
show effect modifying oracle results factors ranging 
shows results protocols tw mtw mtw stw btw 
results btb 
set figures show metrics respectively pair 
case roll backs simulation 
factor appears quite reasonable tw reduced increasing supersteps noticeably 
cases supersteps tw smallest ones 
observed performance protocols falls dramatically factors 
maxima shown figures factor 
second set figures show results pair 
case amount roll backs significantly larger case 
shows tw achieves highest event efficiency 
factor reasonable choice suggests high rate roll backs convenient factor 
case efficiency values noticeably better reasonable increase supersteps 
cases figures show convenient reduce factor increases dramatically supersteps 
efficiency values reduced result imbalance introduced smaller number simulated events superstep 
chapter 
evaluation optimistic protocols increasing processors show data symmetric hold model pairs number processors 
case number events system increases proportionally kept fixed 
means event efficiency decreases system scales larger need larger slackness achieve similar efficiency see section chapter 
experiments useful evaluate scalability protocols protocol able remain efficient small slackness implies protocol able exploit available parallelism simulation model processors efficiently 
experiments included mtw protocol uses pausing min reduction operation 
figures show results pair figures show results pair 
cases results show tw achieves small number supersteps significantly better event efficiency values 
case intensive roll backs pair message efficiency tw decreases significantly result high anti message traffic 
results pair show btb inefficient large scale systems 
case total number supersteps large reduces average number events supersteps noticeably event message efficiency poor 
mtw outperforms mtw low rate roll backs event efficiency inverse occurs high rate roll backs 
case fact mtw keeps event processing superstep close gvt effect event efficiency 
performance btw similar mtw mtw performance stw similar mtw cases 
described bsp implementation number optimistic synchronisation protocols evaluated performance instances hold model load 
symmetric asymmetric instances load considered configurations ranged cases high rate roll backs small number lps processor large number causality threads lp cases low rate roll backs large number lps processor small number causality threads lp 
performance protocols characterised respective costs computation communication synchronisation 
results show case high rate roll backs tw bsp time warp achieves best event efficiency values 
comes cost modest increase total number supersteps 
note tw reduces factor upper limits events chapter 
evaluation optimistic protocols produced oracle simulation 
low rate roll backs event efficiency values tw slightly smaller approaches achieves smallest number supersteps cases 
message efficiency tw degrade significantly result comparatively higher anti message traffic 
mtw time window counterpart tw 
approach reduces anti message traffic delaying sending event messages 
combination approaches appears strategy systems resembling hold model instances studied chapter 
emphasise tw mtw execute pausing min reduction operations event processing superstep 
positive effects performance shown 
shows predicted speedup values divided number processors 
metric called efficiency combines metrics note equal situation cost communication synchronisation large event granularity 
load described previous subsection 
calculate speedups assumptions section chapter min reduction bsp cost rd lg gamma bsp parameters costs ln ln ln ln running times normalised lower bound cost processing occurrence event 
cost state saving assumed figures show results pair 
figures show values differing event processing costs respectively 
figures show similar cases pair 
show tw protocol achieves best performance 
mtw alternative efficient performance 
note assumptions calculation values pessimistic tw 
cost fairly large overheads alternative protocols considered mtw mtw require additional computations organise event messages retained sending processors ii stw keep list processed events non decreasing timestamp order processor iii btw detect message exhaustion assumed min reduction suffices effect task 
simulations small event granularity overheads significant 
tw overheads associated oracle simulation employed protocols chapter evaluate overhead oracle simulation 
advantage tw approaches reduce frequency gvt calculation fossil collection rely increasing gvt values advance simulation 
qualitative tw protocol expected achieve better performance systems remains efficient cases high rate roll backs small slackness 
features optimistic synchronisation protocols studied chapter chapter 
evaluation optimistic protocols ffl tw uses local limits number simulated events superstep 
limits independent gvt advance 
rolled back events necessarily re simulated superstep positive effects event efficiency total number supersteps 
ffl mtw uses global time window allows substantial reduction anti message traffic 
advance window driven gvt 
ffl btw uses global time barrier driven gvt 
detecting instant barrier moved forward efficient solution bsp 
ffl btb uses global event horizon time window tends increase significantly total number supersteps required complete simulation 
btb require anti messages 
ffl stw defines limit number events simulated gvt superstep 
identifying events speculative events fairly involved costly 
chapter 
evaluation optimistic protocols pair number tw mtw stw btw theta theta theta theta theta theta theta theta theta theta theta theta theta btb sp tw pair number mtw stw btw theta theta theta theta theta theta theta theta theta theta theta theta theta btb pair number theta theta theta theta theta theta theta theta theta theta theta theta wx tw pair number theta theta theta theta theta theta theta theta theta theta theta theta pair number theta theta theta theta theta theta theta theta theta theta theta theta mx tw pair number theta theta theta theta theta theta theta theta theta theta theta theta symmetric figures asymmetric figures hold model results 
experiments pairs ranging take values 
figures pair number pair number 
chapter 
evaluation optimistic protocols pair number tw mtw stw btw theta theta theta theta theta theta theta theta theta btb sp tw pair number mtw stw btw theta theta theta theta theta theta theta theta theta btb pair number theta theta theta theta theta theta theta theta wx tw pair number theta theta theta theta theta theta theta theta pair number theta theta theta theta theta theta theta theta mx tw pair number theta theta theta theta theta theta theta theta symmetric figures asymmetric figures hold model results 
experiments pairs ranging take values 
figures pair number pair number 
chapter 
evaluation optimistic protocols factor tw mtw mtw stw btw theta theta theta theta theta theta theta theta theta theta theta theta factor tw mtw mtw stw btw theta theta theta theta theta theta theta theta theta theta theta theta factor theta theta theta theta theta theta theta theta theta theta theta factor theta theta theta theta theta theta theta theta theta theta theta factor theta theta theta theta theta theta theta theta theta theta theta factor theta theta theta theta theta theta theta theta theta theta theta results extreme pairs symmetric hold model 
figures show data pair figures show data pair 
axis shows factors oracle simulation data modified 
data btb pair pair 
chapter 
evaluation optimistic protocols tw mtw mtw stw btw theta theta theta theta theta theta theta theta btb theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta results pairs symmetric hold model number processors ranging 
figures show data pair figures show data pair 
missing points btb 
chapter 
evaluation optimistic protocols theta theta theta theta theta theta theta tw mtw mtw stw btw theta theta theta theta theta theta theta theta btb theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta predicted speedups divided denoted pairs symmetric hold model number processors ranging 
figures show data pair figures show data pair 
figures respectively show results cases cost processing event lowest possible twice times quantity respectively 
chapter evaluation conservative protocols chapter study efficient realisation conservative simulation bsp computers 
describe bsp algorithms different synchronisation protocols evaluate comparative performance 
number optimisations introduced result improved algorithms 
establish comparisons bsp time warp system proposed chapter 
chapter assess performance protocols implementation architecture independent performance metrics 
quantify empirically metrics executing demanding load different conditions 
enables identify relevant factors affecting total running time protocols 
study scalability protocols terms asymptotic costs model size number processors scale simultaneously 
evaluate synchronous asynchronous protocols previous comparative studies compare protocols model parallel computing bsp model study includes protocols compared far literature 
synchronous protocols straightforward implementation bsp bulk synchronous operation 
asynchronous protocols hand roots asynchronous message passing shared memory systems require radically different algorithmic design order avoid overheads inherited simple mapping model computing 
quantitative results mainly empirical usual practice kind study restricted particular demanding load 
chapter 
evaluation conservative protocols results combination existing knowledge performance synchronisation protocols enable draw qualitative provide general view comparative performance protocols 
results chapter study asymptotic bsp cost protocols model size number processors scale simultaneously 
enables identify slackness requirements 
empirical methodology unique features 
previous studies mainly running times bsp cost model characterise performance different protocols implementation architecture independent manner 
mainly count events messages supersteps different load instances 
provide estimation software overheads associated practical implementation protocols 
provides useful information actual costs associated synchronisation strategy affect noticeably comparative performance 
software overheads estimated executions sequential simulator bsp protocols described section chapter 
simulator include actual implementations protocols studied chapter overheads estimated simulator running times obtained optimised sequential simulation program load 
empirical results independent particular realisation bsplib 
size load employed experiments small avoid cache fault effects simulation programs require similar amounts memory accesses memory random random nature load 
data consistent expected overhead costs protocol 
performance synchronisation protocols known performance conservative protocols depends ability lps predict time events sent downstream lps advance 
called lookahead 
cases values times lower bounds times actual events exact values known parent events take place 
hand known optimistic protocols may achieve reasonable performance models little lookahead 
agreed performance optimistic protocols improve noticeably large lookahead 
review previous performance synchronisation protocols relevant scope chapter 
positive effect large lookahead conservative simulations investigated 
proposes techniques increase lookahead queuing network models 
chapter 
evaluation conservative protocols empirical study analyses detail effects various levels lookahead models kind 
protocols considered chandy misra bryant cmb nm time warp tw implemented classical asynchronous message passing setting 
qualitative study mainly ffl lookahead incorporated model fewer number messages computations needed complete simulation 
cmb nm sends fewer null messages larger timestamps turn enables downstream lps decide earlier real time events safe simulate 
tw sending events earlier real time improves performance reduces roll back occurrences increases parallelism 
ffl number customers circulating queuing network increased load increases significant improvement performance level lookahead 
case number pending events lp increases predictions event times unit real time 
ffl fan communication increased smaller impact lookahead 
case number outgoing events increases meaning necessary predictions event times result performance decreases 
increasing fan reducing level lookahead 
empirical results show tw outperforms cmb terms message event counts 
expected cmb advance forward simulation time processing comparatively larger number messages 
necessarily imply tw outperforms cmb actual running time software overheads protocol different 
markov chain model processors lp processor concludes similar facts analytically 
analysis compares cmb tw concludes tw outperforms cmb lookahead ii cmb lookahead outperforms tw lookahead ii tw outperforms cmb protocols lookahead 
purpose mathematical tractability analysis number unrealistic assumptions zero cost state saving rollbacks deadlock detection recovery 
regarding tw vs cmb nm presents comparison assuming worst case scenario 
example tw arbitrarily outperform cmb letting tw aggressively compute critical path simulation shown example exists cmb 
cmb outperform tw constant factor 
main argument great amount roll backs tw able advance gvt chapter 
evaluation conservative protocols gvt lag cmb constant factor 
moral cmb may little information determine safe events lps may remain blocked significant part running time sequential simulation whilst tw able exploit available parallelism 
comparison yawns bounded tw btw 
comparison synchronous algorithms conservative optimistic 
analysis concludes low level aggregation lps processors btw better asymptotic cost yawns log vs respectively number lps 
expected cost state saving btw large yawns may outperform btw 
hand large level aggregation lps processors shows yawns achieves constant asymptotic cost outperforms btw asymptotically 
refute result showed chapter synchronous protocols yawns achieve asymptotic constant cost total number synchronisation barriers needs execute increasing function analysis assumes cost barrier synchronising processors zero unrealistic assumption 
studies performance conservative protocols 
sections study validity bsp setting 
issue model computing may affect facts especially related conservative vs optimistic simulation 
performance metrics load evaluate performance different protocols studied chapter workload regarded demanding benchmark conservative synchronisation protocols contains multiple feedback loops 
refer simulation non preemptive single server queuing network fcfs discipline 
servers lps organised theta toroidal grid node server neighbouring nodes see 
communication neighbouring nodes bi directional may send messages reporting arrival jobs respective queues 
fixed number jobs kept flowing constantly network defining initial number jobs server routing jobs uniformly random neighbours 
basic events simulation model job arrival arrival service service completion 
sequential simulation queuing model described 
parallel simulation performed processors queuing servers processor 
empirical data shown chapter obtained instances queuing chapter 
evaluation conservative protocols toroidal topology wrap links 
define event type source server event time destination server sim case event arrival jobs jobs server idle goto service service jobs jobs server busy service time schedule completion neighbor random schedule arrival completion jobs server idle goto service endcase endwhile sequential simulation 
chapter 
evaluation conservative protocols id loc table queuing network instances oracle results async 
network see table 
table describes cases servers low high load 
parameter number jobs server start simulation 
table column loc locality instance model define fraction messages sent processors 
remaining columns table show results obtained oracle simulations queuing network version async algorithm shown chapter 
column average number supersteps unit simulation time load instance 
values minimum possible oracle results 
column shows event efficiency defined case measure load balance oracle computations note variance increases load 
column shows average number events superstep simulated processor 
oracle results show best protocol terms supersteps number events processor superstep 
note model instances table range small large slackness 
case unrealistic current computers provides indication maximum parallelism available model 
service times queuing servers sum constant base lookahead continuous random variable exponentially distributed mean 
basic amount lookahead experiments reported chapter oracle results table obtained 
note pseudo code designed pre sending jobs exploited 
jobs receiving service preempted completion arrival events scheduled time 
feature sequential simulation equivalent scheduling arrival event right associated completion event increases available parallelism model completion arrival events processed parallel job pre sending increases lookahead 
chapter 
evaluation conservative protocols id async sync sync id async sync sync table effect job pre sending async sync oracles 
bsp job pre sending effect reducing total number supersteps required complete simulation 
events scheduled far simulation time expected processed far superstep count turn increases superstep descendant events processed 
pairs completion arrival processed superstep total number supersteps expected decrease 
effect pre sending total number oracle supersteps observed table 
table shows results obtained execution async oracle sync algorithms described chapter adapted queuing network context note phold job pre sending intrinsic load 
table columns async sync show total number supersteps achieved performing job pre sending divided total number supersteps achieved async job pre sending 
results show dramatic effect absence pre sending sync 
async affected smaller degree 
column sync total number supersteps achieved sync job pre sending divided supersteps async job pre sending 
note sync algorithm iteration delimited minimum timestamp newly generated events scheduled processors 
reduces total number supersteps small minima tend larger calculated smaller number events 
performance metrics evaluate performance synchronisation protocols discussed chapter defined follows ratio total number supersteps required synchronisation protocol minimum number supersteps load instance async oracle supersteps 
set events processed simulation defined cumulative sum observed maximum number events processor superstep number processors 
refer event efficiency 
calculating include protocol overheads processing cmb nm protocol described 
additional computations cost processing normal simulation events proposed bsp chapter 
evaluation conservative protocols algorithms reduce noticeably cost operations cases factor pessimistic 
weighted sum superstep number events type define maxima 
call null event null message event message part synchronisation strategy supported protocol 
events associated simulation model called normal events 
total number normal events 
software overheads protocol considered parameter defined 
computation balance synchronisation protocol measured ratio average number events processor superstep average maximum number events processor superstep 
null events values include overhead processing null events 
measure effect null events balance parallel simulation metric compares sequential simulation parallel simulation 
note balance supersteps may result processing large number null events event efficiency may poor 
ratio total number normal events weighted sum normal null events 
provides information amount auxiliary necessary perform order complete conservative simulation 
show average load instance observed values similar case 
total normal event messages sent simulation defined cumulative sum observed maximum number messages sent processor superstep 
refer message efficiency 
calculating include effect sending null messages processors 
existence messages reduces message efficiency important take consideration size null message smaller size normal event message 
value weighted sum normal null messages sent processor 
assume cost transmitting null message cost normal message 
software overheads associated administration messages considered parameter defined 
note event efficiency measure compares sequential event processing parallel 
hand sequential message sending sense 
optimal achieved cumulative sum average maxima optimal way sending messages required complete simulation model balanced definition 
balance communication defined ratio average number messages processor superstep average maximum number messages processor superstep 
null messages differ sense metrics chapter 
evaluation conservative protocols rm ratio total number normal event messages total number normal null messages sent simulation 
cost sending null message cost normal message 
average load instance 
average number normal events simulated processor superstep 
defined total number normal events simulated system divided product total number supersteps processors 
measure slackness available processor 
situation perfect load balance processor simulate normal events superstep 
provides information software overheads involved practical implementation different protocols 
implementation dependent metric specific values depend particular implementation issues data structures message treatment 
data reported measure obtained optimised implementations different protocols 
defined ratio total running time sequential simulator bsp conservative protocols total running time optimised sequential simulation program queuing network 
running time values obtained executing simulations sgi power challenge 
running times measured function clock provides amount cpu time program precision micro seconds 
values provided clock quite independent actual process load computer observed standard deviation average 
note measures refer event processing supersteps 
explicitly exclude cost periodical min reduction operations executed synchronous protocols 
conservative protocols time buckets tb defined service times values constant straightforward method parallel simulation consists defining moving time window width 
window defined equal simulation floor time event system 
events time simulated event processing superstep 
event processing supersteps executed order calculate simulation floor cycle tb conservative version mtw algorithm discussed chapter 
note job pre sending compulsory case sending arrival events right respective completion events produces 
chapter 
evaluation conservative protocols id id table time buckets 
results queuing model shown table 
software overheads associated protocol negligible implementation similar features sequential event list processor maintains events associated resident lps 
superstep events time removed event list occurrences simulated chronological timestamp order 
software overheads similar sequential simulation see column table 
expected total number supersteps large small 
addition load balance computation communication large number processors events superstep processed processor 
values table show trade event lists small number events poor locality event lists large number events locality 
cmb deadlock recovery cmb dr chandy misra bryant cmb protocol described section chapter 
bsp implementation protocol replace input queues single local event list implemented sorted linked list size list small 
output queues removed lps insert events directly event lists resident lps 
event messages lps located different processors sent bulk current superstep insertion events respective event lists effected start superstep 
emulate input rule maintaining variable input channel registers timestamp event message received respective input channel 
smallest values defines local time barrier lp events times barrier safely simulated 
equivalent testing input rule event selection avoids overhead repeated tests 
deadlocks extremely frequent toroidal queuing network avoid associated deadlock detection procedure anticipating pre computing information needed break deadlocks 
similar tb scheme simulation floor calculated start event processing superstep 
cmb input rule chapter 
evaluation conservative protocols id id table cmb deadlock recovery 
extended allow processing events times floor manner number events processed superstep events processed tb 
addition parallel min reduction takes supersteps complete avoid pausing simulation whilst performing operation simulating events time floor current superstep min reduction 
table shows results queuing model 
results disappointing similar tb additional overheads introduced combination input rule deadlock recovery procedures 
overheads decrease high load cmb dr processes comparatively larger number events 
systems feedback loops bulk synchronous realisation cmb dr achieve better performance 
cmb null messages cmb nm queuing model time null message time current completion event plus null message time plus server idling 
proposed bsp implementation cmb nm actual null messages sent lps located different processors 
suffices send just null message lps superstep largest time lp pair 
addition sending null message avoided timestamp greater timestamp previous null message sent channel 
combination schemes reduces significantly null message traffic processors 
input channel maintain variable registers time null message received input channel 
call input variables 
minimum input variable values defines local time barrier lp current superstep 
resident lps directly update respective input variables message reception routine performs similar operations receives null messages start superstep 
maintain event list lp sorted linked list stores normal events scheduled respective lp 
null messages removed system chapter 
evaluation conservative protocols processed message reception routine 
superstep resident lps scheduled event processing arbitrary manner particular timestamp order 
lp algorithm calculates local time barrier ii simulates events times barrier iii sends null message output channel direct updating input variables resident lps buffering null messages provided timestamps greater previous ones 
algorithm performs operation lp superstep 
note null messages sent lps processed current superstep enabled event processing 
observed queuing model attempting simulate maximum number events superstep degrades significantly event efficiency benefit modest reduction total number supersteps cases processors alternately process events large number events 
results shown table 
low load ratio similar cmb dr software overheads larger due increased null message management see rm 
expected null messages decrease event message efficiencies shown columns table 
table shows computation communication balance comparatively near optimal small 
result balanced computation communication null messages 
performance cmb nm improves high load 
case proportion normal events messages processed superstep increases see rm 
result total number supersteps decreases significantly software overhead achieves levels similar cmb dr cost null messages amortised larger number normal events messages 
bounded lag bl bounded lag bl protocol works bulk synchronous fashion combines lookahead mtw approach 
bl concept minimum propagation delay defined minimum time increment events scheduled lp lp event time takes place lp schedules event lp 
lps explicit communication link quantity shortest path algorithm executes cycles safe events simulated 
cycle occurrence event lp simulated iff ff min fd minft gg chapter 
evaluation conservative protocols id rm id rm table cmb null messages 
times event lps start current cycle 
testing lp takes time total number lps lps located pre defined neighbourhood considered 
user defined time bound define extent neighbourhood calculating ff quantity consider subset lps keeping invariant start cycle requires global synchronisation lps simulation floor defined pending event time system 
simulation floor obtained executing parallel min reduction cycle 
way cycle lp set events satisfying ff floor simulated ff considers lps bsp implementation bl necessary additional superstep communicate time events neighbouring processors order calculate ff values current cycle 
count additional superstep event processing superstep consider messages null messages cost normal event message 
consider null event occurrence lp cost calculating ff value 
normal event operations kind take place processor superstep 
message traffic reduced sending messages cycle cycle values different 
value defines lps considered neighbours lp note equivalent tb increased software overheads 
consider involves chapter 
evaluation conservative protocols id rm id rm table bounded lag 
neighbouring lps neighbouring lps neighbouring lps 
results shown table 
exceptions performance metrics bl poorer cmb nm particular software overheads message traffic 
considering additional superstep required communicate values protocol efficient cmb nm queuing model 
results shown table 
data show number neighbouring lps increases total number supersteps decreases slightly 
software overheads increase noticeably best choice queuing model 
conservative time windows shortest paths ctw sp conservative time windows ctw extension previous conservative protocol called distance objects 
ctw determines time window lp time event lower bound time lp system schedule event equivalent local time barrier cmb nm algorithm 
algorithm calculate values designed shared memory locks 
algorithm recursively visits lp update variables tmin minimum time event take place lp algorithm cause excessive number variables 
efficient single source shortest paths algorithm depicted lst current send time message sent lp superstep perform ctw cycle 
start superstep algorithm chapter 
evaluation conservative protocols id id table bounded lag 
receives events null messages determines estimations tmin values 
calculates upper borders local windows processes new set safe events 
initial tmin values defined minimum event lp timestamped null message received processors 
time null message maximum lower bound calculated shortest paths algorithm respective lst value superstep 
tends increase values cycle turn increases number simulated events superstep 
algorithm employed protocol asynchronous message passing environments 
setting shortest paths algorithm executed demand provide lower bounds time event input channel scheme null messages 
scheme evaluated section combines features ctw 
queuing model observed shortest paths algorithm increases number events superstep faster original recursive algorithm ctw 
results ctw shortest paths ctw sp shown table 
exception performance metrics quite similar cmb nm ctw sp improves slightly supersteps event message efficiencies 
software overheads quite high ctw sp result executing shortest paths algorithm superstep 
cmb nm expected achieve better performance queuing model 
note cmb nm may considered randomised counterpart ctw sp cmb nm selects arbitrarily lp event processing finished event processing lp cmb nm immediately sends null messages neighbouring lps 
hand ctw sp organise computation superstep deterministic manner 
calculates chapter 
evaluation conservative protocols init max tmin lst lp insert values priority queue pq 
notempty pq pq neighbors tij tij tij tm max tij lst tm tm delete pq insert pq endif endfor endwhile single source shortest paths algorithm 
local time windows cmn nm fly performs event processing 
superstep approaches achieve similar results ctw sp incurred overhead executing shortest paths algorithm 
yawns yawns protocol conservative counterpart btb protocol reviewed chapter 
important feature protocol require explicit consideration communication topology lps 
restrictive assumptions features system simulated job pre sending times events scheduled lps 
factors increase lookahead simulation 
operation yawns follows 
define ff departure time job receive service non preemptive server lp exclude job currently service 
time process job arrival event lp pre compute service time instant calculate ff ff gamma tg residual time job receiving service arrival time job receive service 
addition time job starts receiving service event message indicating arrival job server sent immediately chapter 
evaluation conservative protocols id rm id rm table ctw shortest paths 
respective lp job pre sending 
way simulation barrier synchronised simulation time new cycle initiated processing events time satisfying min servers fff events safe minimum ff minimum time lp affected lp 
pre sending jobs ensures lp able compute value potentially real minimum ff minimal arrival time job entire system 
minimum ff obtained executing parallel min reduction start cycle 
yawns protocol executes steps perform parallel min reduction calculate ff minf ff servers 
process events time ff processing event puts new job service followed sending corresponding event message reporting arrival job respective destination server 
barrier synchronise processors 
lps receive event messages sent step compute service times arriving jobs insert events internal event lists 
goto step 
chapter 
evaluation conservative protocols id id table yawns protocol 
id id ctw sp cmb nm table exploiting yawns lookahead 
results yawns shown table 
values performance metrics tell yawns achieves better performance cmb nm cost min reductions considered discussion 
biased comparison yawns takes advantage larger lookahead cmb nm 
kind increased lookahead yawns conservative protocols 
table show results obtained ctw sp cmb nm kind lookahead yawns 
scenario changes radically 
supersteps software overheads decrease efficiencies improve significantly recall charging pessimistic cost handling null messages reduces event efficiency 
particular cmb nm achieves near optimal performance high load 
ctw sp achieves slightly better event message efficiencies cmb nm software overheads larger cmb nm 
conservative simulation setting results suggest situations lookahead asynchronous time advance realised ctw sp cmb nm efficient alternative synchronous time advance imposed yawns 
protocols ctw cmb restricted communication topologies small fan fan 
chapter 
evaluation conservative protocols id id rm rm table bsp time warp 
comparative study comparisons conservative synchronisation protocols including large asymmetry workload 
comparison optimistic simulation 
comparison time warp performed similar queuing network simulations bsp time warp bsp tw system proposed chapter 
results job shown table 
bsp tw achieves smallest number supersteps competitive event message efficiencies 
note anti messages normal event messages contrast factor applied null messages conservative simulation 
event efficiency includes effect event re simulations due roll backs identical cost normal events factor turn contrast factor applied null events conservative simulation 
interesting observe table software overheads proposed bsp tw system quite similar conservative simulation ctw cmb 
particular results suggest cmb nm yawns lookahead outperform bsp tw machine low cost barrier synchronisation processors queuing network simulation high load mapped small number processors 
bsp tw depend communication topology sense cmb 
hand yawns independent communication topology 
results table show bsp tw software overheads compare favourably yawns overheads table difference bsp tw requires smaller number supersteps pause simulation perform min reduction operations 
conservative protocols rely job pre sending increase lookahead 
table shows chapter 
evaluation conservative protocols id id rm rm table time warp job pre sending 
bsp tw job pre sending performs minimal lookahead situation 
number supersteps increases software overhead increases 
event message efficiencies remain similar job pre sending case 
performance tw competitive unfavourable setting 
results reinforce qualitative bsp tw suitable candidate general purpose pdes 
queuing model necessary exploit specific knowledge model order achieve performance conservative protocols job yawns lookahead small fan communication lps 
bsp tw may achieve reasonable performance knowledge introduced user simulation model 
increasing lookahead asymmetry show effect increasing minimum lookahead tables show results respectively 
table show data model instances numbered see table represent cases theta theta 
columns data tb cmb nm nm bl ctw sp cw bsp tw tw cmb nm yawns lookahead nm ctw sp yawns lookahead cw yawns 
results confirm section 
performance improves increases conservative optimistic simulation 
conservative protocols nm achieves best performance 
nm outperforms tw depends particular bsp parameters parallel computer 
data show tb nm bl cw affected increase performance improves significantly 
cases total number supersteps reduced dramatically result larger number events simulated superstep 
synchronous protocols expected increases whilst mean value exponential distribution remains unchanged time increment events tends similar 
synchronous asynchronous time advance similar terms chapter 
evaluation conservative protocols supersteps chapter 
nm cw observed null messages comparatively larger timestamps significant impact performance 
nm cw achieve similar performance including software overheads sibling nm cw 
event message efficiencies software overheads improve noticeably result increase number simulated events superstep 
suggests models larger event granularities internal event occurrences lps algorithms cmb nm ctw sp achieve performance small lookahead 
results show performance synchronisation protocols asymmetric version queuing network model 
case initialisation lp selects random output links 
favourite link 
simulation lps put messages favourite links probability 
remaining output links selected uniformly random 
results shown table instructive compare table table asymmetric model total number oracle supersteps similar oracle supersteps symmetric model rows show protocols achieve similar cases 
asymmetric model possible lp select favourite lp 
means favourite lp contain comparatively larger number jobs queue waiting receive service 
possible observe cycles lps send larger number messages 
macroscopic level result reduction total number events processed superstep 
shown rows fewer events superstep asymmetric model supersteps symmetric model software overheads significant total running time 
see rows table event message efficiencies degrade fewer events processor superstep increases imbalance 
shown rows addition number null messages processed superstep remains constant contributes increase relative weight software overheads 
impact asymmetry significant cmb ctw 
rows show synchronous protocols process events superstep contrast comparatively larger number events processed tw 
results table show tw achieves best performance asymmetric model particular provides evidence bsp tw robust conservative protocols 
tw remains efficient conservative protocols fail 
chapter 
evaluation conservative protocols tb nm bl cw tw nm cw tb nm bl cw tw nm cw asymmetric tb nm bl cw tw nm cw table lookahead asymmetry model instances 
chapter 
evaluation conservative protocols speedups simulation results determine values performance metrics enable predict feasible speedups different synchronisation protocols 
simulation data obtained executing sequential simulator bsp protocols 
executions real time measure collected total running time required sequential bsp simulator complete simulation 
produced measures software overheads involved proposed bsp implementation protocols 
measures came counters located different points bsp simulator counters removed simulator measuring actual running time 
bsp parameters predict speedup simulation data 
aim study qualitative effects various scenarios speedup situation favourable conservative protocols 
tabulated data easy see order achieve reasonable performance machine high need look protocols low requirements synchronisation communication bsp tw 
case software overheads crucial issue selecting synchronisation protocol 
hand simulations machine low software overheads important issue selecting synchronisation protocol 
extreme case assume unrealistic 
section values machine low cost synchronisation communication slow processors compared sgi processors sequential bsp simulations executed 
provides proper emphasis software overheads whilst real life values 
refer cray processors average performance mflops processor values ranging values word word 
values obtained running benchmark bsplib programs machine 
sgi machine average performance mflops amplified sgi running time measures factor 
cost processing event sequential simulation sequential bsp simulation queuing network sgi 
event granularity cray twice cost barrier synchronising processors 
set predicted speedups shown figures figures show speedups instances load 
data represented collection segments delimited points 
segment point left right speedup value low load second point speedup high load 
protocol segments representing speedups processors bottom top 
protocols identified axis chapter 
evaluation conservative protocols tb cmb nm nm bl ctw sp cw bsp tw tw bsp tw job tw cmb nm yawns lookahead nm ctw sp yawns lookahead cw yawns 
axis indicates specific speedup values associated segment points 
shows speedup values small lookahead 
cases best speedups achieved tw bsp tw nm cmb nm yawns lookahead 
high load nm outperforms tw 
particular nm achieves speedup result sequential bsp simulator running times respective sequential simulation running times 
shows synchronisation communication costs small case study data indicate cost synchronisation communication total running time 
note figures assume cost min reductions zero 
shows different situation terms comparative performance protocols 
base lookahead large equal mean value exponential distribution 
case total number supersteps developed protocol fairly experimental data show differences factor 
small proportion cost communication participates total running time protocol describes happens situation software overheads dominant factor speedups 
shows synchronous protocols low software overheads small requirements communication tb yawns achieve better speedups asynchronous protocols 
speedups consider cost performing periodical min reductions associated synchronous protocols 
assume operation requires lg gamma supersteps complete minimum calculation respective broadcast 
bsp cost method lg small constant factors computation communication 
consider cost synchronisation operation 
shows significant reduction speedups synchronous protocols result additional supersteps introduced min reductions 
fact observed large lookahead conservative protocols identified nm cw achieve reasonable performance 
protocols knowledge simulation model increase lookahead counterparts nm cw 
cases nm cw outperforms tw 
shows speedups asymmetric favourite link version queuing network 
speedups values decrease noticeably load 
tw remains comparatively efficient demanding case 
synchronous protocols achieve reasonable performance 
small number processors tb outperforms tw 
chapter 
evaluation conservative protocols symmetric tb nm bl cw tw tw nm cw symmetric tb nm bl cw tw tw nm cw symmetric lg min reduction tb nm bl cw tw tw nm cw predicted speedups processors 
segments represent speedups processor protocol data low load segment left point high load segment right point 
axis shows speedups axis identifies protocols 
chapter 
evaluation conservative protocols figures show effects increasing values parameters 
speedups compared shown presents speedups case synchronisation cost times larger benchmark values cray 
shows smaller speedup values expected greater reductions speedups observed synchronous protocols require event processing supersteps complete simulation load 
penalty performance independent min reduction realisation 
asynchronous protocols tw nm get speedups degraded smaller degree 
asynchronous protocols higher requirements communication synchronous ones send anti messages null messages 
shows effects increasing times cost communication see greater degradation speedups asynchronous protocols 
reduction protocols significantly efficient synchronous ones 
asymptotic trend derive expressions describe asymptotic cost synchronous asynchronous protocols model size number processors scale simultaneously 
formulae supersteps unit simulation time derived chapter 
keep expressions simple assume event efficiencies close assume number lps events processor large 
constant factors omitted scale model setting constant number lps processor increasing number processors 
study queuing network toroidal topology server high load idle 
service times exponential mean assume base lookahead simulating model time te requires processing te events arrival completion total number lps 
define number processors 
queuing model defined lps processor perfect squares 
service entry message sent lp reporting arrival job serviced job pre sending 
processor lps send messages lps located processors probability 
total number events unit simulation time total number messages unit simulation time nm assume cost processing event constant 
chapter 
evaluation conservative protocols asymmetric tb nm bl cw tw tw nm cw symmetric tb nm bl cw tw tw nm cw symmetric tb nm bl cw tw tw nm cw predicted speedups part processors 
segments represent speedups processor protocol data low load segment left point high load segment right point 
axis shows speedups axis identifies protocols 
chapter 
evaluation conservative protocols yawns total number supersteps unit simulation time required yawns queuing model behaves hold model event lp see chapter 
reduce supersteps assuming time window calculated considering messages sent processors exclude messages resident lps 
total messages sent processors unit simulation time total bsp cost unit simulation time yawns nm delta min reduction assuming min reduction cost lg alternative method cost asymptotic bsp cost yawns lg lg lg cmb assume cmb nm yawns lookahead large lookahead assume cmb approximates supersteps asynchronous oracle constant factor 
supersteps unit simulation time asynchronous oracle ln ln value hold model event lp fully connected topology total causality threads migrate processors unit simulation time 
total asymptotic cost unit simulation time computation plus communication normal events superstep cmb process null events null messages 
null events processed processor superstep null messages sent processors superstep 
operations perfectly balanced 
asymptotic bsp cost null events null messages asymptotic bsp cost cmb cmb ln ln ln ln ln ln ctw similar arguments cmb applied ctw 
ctw execute shortest paths algorithms superstep 
cost algorithm lg asymptotic bsp cost ctw ctw lg ln ln ln ln ln ln chapter 
evaluation conservative protocols tw small lookahead bsp tw achieve similar supersteps asynchronous oracle 
roll backs increase number event re simulations 
assume event re simulated average oe gamma times oe 
protocols assume load balance optimal ae 
assume state saving increases cost event gamma units 
asymptotic bsp cost tw tw oe oe gamma ln ln parameters oe provide information trade optimistic simulation 
validation shows experimental validation number supersteps sync async protocols respectively 
curves show values obtained sync oracle divided function defined curves show values obtained async oracle 
experiments total events scheduled initially lp high load 
shows data experiments kept fixed varied 
axis experimental values divided curves oracle data top bottom 
number processors 
shows constant large presents inverse case kept fixed varied 
axis experimental values divided case curves data top bottom 

shows decrease summary cases formulae sections table 
note tb included assumed 
yawns uses non scalable min reduction 
third section table show cost algorithms accordance trend observed empirically constant number supersteps unit simulation time 
formulae table show yawns requires slackness higher communication synchronisation costs 
results toroidal network sparse topology defines constant number chapter 
evaluation conservative protocols theta theta theta theta theta theta theta theta theta theta theta theta sync async supersteps toroidal topology 
input links lp 
fully connected topology feasible protocols yawns tw 
case shown fourth section table 
results confirm claims section 
performance conservative protocols improves noticeably amount lookahead available model number messages load 
performance optimistic protocol improved factors 
cmb outperform tw cases large lookahead high load 
tw able remain efficient small lookahead low load 
observed software overheads tw slightly larger overheads conservative simulation 
addition protocol lowest requirements synchronisation enables simulation events superstep 
improves load balance 
anti message traffic increase noticeably cost communication 
communication requirements tw lower cmb null messages 
large lookahead synchronous asynchronous conservative protocols achieve similar performance 
case total number supersteps tends similar protocol 
small lookahead asynchronous protocols outperform synchronous protocols 
cases synchronous protocols require larger number supersteps complete simulation 
result strongly impacted moderately high cost barrier synchronisation processor 
protocols suitable communication topologies large fan fan 
need performing periodical min reductions detrimental performance synchronous protocols systems sparse communication topology 
formulae table confirm 
features conservative synchronisation protocols studied chapter chapter 
evaluation conservative protocols protocol comp 
comm 
sync 
yawns lg lg lg yawns cmb ln ln ln ln ln ln ctw lg ln ln ln ln ln ln tw oe oe gamma ln ln cmb ctw lg tw oe oe gamma yawns lg lg lg yawns tw oe oe gamma ln ln table cost computation communication synchronisation 
section table presents formulae yawns lg min reductions respectively toroidal topology 
second section presents results cmb ctw tw assumption phold values chapter adapted queuing network model toroidal topology 
third section presents similar results considering trend observed 
fourth section presents results queuing network fully connected topology phold values 
ffl tb uses conservative global time window 
protocol simple efficient loads large lookahead 
protocol independent communication topology lps 
ffl cmb nm uses local time windows achieves efficient performance communication topologies small fan fan 
ffl ctw sp similar features cmb nm periodical execution shortest paths algorithm increase overheads 
ffl bl requires periodical examination lps located pre defined neighbourhood 
exacerbates dependency communication topology increases overheads 
ffl yawns independent communication topology achieve efficient performance loads moderate lookahead 
chapter experience special purpose protocols chapter propose efficient special purpose protocols class complex systems 
main application simulations computational physics simulation entities represent atoms particles interact large scale system 
examples systems colliding hard spheres ising spin models analyse performance terms bsp cost model 
parallel discrete event simulation colliding spheres related systems considered problem deserved attention literature 
currently important class applications simulations theoretical physics hard particle fluids ising spin models disk packing problems 
kinds systems viewed general setting moving objects real life transport problems navigation systems combat models 
hand systems considered sufficiently general computationally intensive sort benchmark time warp simulation special purpose protocols devised large scale systems shared memory multi processors 
chapter synchronous asynchronous protocols simulation systems evaluate performance examples ising spin model hard particle fluid 
potentially large scale systems property events take place randomly evenly distributed spatial region 
chapter 
experience special purpose protocols believe examples exhibit sufficient generality complexity representative wide class related dynamic systems 
note systems class simulated efficiently general purpose conservative optimistic bsp protocols previous chapters 
ising spin models simulated conservative protocols efficiently 
fluids simulated protocols base lookahead zero scheduled events cancelled unpredictable manner 
optimistic protocols case 
researchers shown time warp protocol able simulate similar systems reasonable efficiency called colliding pucks 
experiments conducted small scale systems 
aim achieve simulation millions particles atoms case amount memory simulator crucial metric optimise 
optimistic simulators traditional local rollback mechanism require memory conservative ones necessary keep old states processed events fossil collection 
respect global rollback mechanism simulation re started previous check point passed error offers viable solution problem global rollback achieve twice memory hypothetical conservative protocol 
necessary take consideration processing global rollback occurrence significantly expensive running time local rollbacks involving components system 
solution devise special purpose synchronisation protocols able keep rate global rollbacks low level 
chapter follow approach focusing simulation occurrence particular events located borders spatial regions assigned processors 
empirical results show rate rollbacks low obtain speedups highly optimised sequential simulators 
bsp time warp modified perform global rollbacks remains seen oracle simulation method able reduce rate global rollbacks reasonable level interesting topic research area 
basic bsp simulation algorithms kind systems relevant chapter statistically homogeneous steady state systems event occurrences randomly evenly distributed space simulated bsp computer phase algorithms follows 
processors bsp computer system divided equal sized regions owned unique processor 
events involving elements located boundaries called border zone events bz events synchronise parallel operation chapter 
experience special purpose protocols processor owns region border zone event take place 
event scheduled occur time bz prefix operation calculates broadcasts minimum local time values distributed processors 
parallel simulation initialization parallel prefix bz condition superstep simulate events time bz processor reads state neighbouring regions superstep processor simulate occurrence parallel prefix bz endwhile synchronous algorithm executed processor 
processors 
synchronous version algorithm works doing iterations composed phases parallel phase processor simultaneously allowed simulate sequentially asynchronously region ii synchronisation phase occurrence border zone event simulated processor whilst ones remain idle state 
improve efficiency algorithm simulating border zone events parallel synchronisation phase 
synchronisation phase cause synchronisation processors simulation time exchange state information neighbouring regions 
system examples studied state information refers state particular atoms particles located neighbouring regions 
parallel phase processor simulates events times current global bz event bz event time local bz events held region processor 
global processor synchronisation issued periodically variable time intervals driven chronological occurrence bz events 
see pseudo code 
assume elements evenly distributed system regions theta elements 
goal simulate occurrence events average assumed occur randomly evenly distributed chapter 
experience special purpose protocols elements element 
goal achieved bsp algorithm iterations iteration simulates total pe events parallel phase plus event synchronisation phase pe define bz fraction bz events occur simulation 
show kind systems interested bz leading pe bz gamma shows choosing regions sufficiently large possible achieve reasonable degree parallelism strategy 
actual gain running time due parallel phase processor simulates events sequentially depends crucially cost communication synchronisation processors incurred synchronisation phase 
efficiency algorithm improved attempting simulate parallel border zone events iteration 
explain procedure example 
assume situation bz events regions respectively 
notation fa bg identifier element region scheduled bz event occur time addition define time element region scheduled bz event 
assume elements related due topology system simulated neighbouring atoms ising spin model described 
note necessarily time bz event region simulation restricted order relation respective scheduled times simulate simulate simulate parallel bz events process sequentially bz events region lesser condition reached 
new bz event processed region non bz events time interval consecutive bz events simulated 
described pseudo code region shown 
operation bsp fetch reads value element stored region ising spin systems ising spin system modelled theta toroidal network 
node network atom magnetic spin value gamma 
atom attempts change spin value discrete times time atom currently simulated random variable negative exponential distribution 
new spin value decided considering current spin values neighbours 
goal simulation process occurrence spin changes events 
chapter 
experience special purpose protocols parallel simulation region initialization bz event condition superstep bsp fetch superstep superstep simulate events simulate bz event bz event endif superstep endwhile asynchronous algorithm executed processor sequential simulation system trivial necessary deal type event efficient event list administer times cost processing event takes place sequential algorithm lg calendar queue conjectured calendar queue cost load similar produced ising spin system 
cost sequential simulation system atoms case parallel simulation theta toroidal network divided theta regions theta atoms 
region total gamma atoms border zone bz gamma 
region sequential event list algorithm applied parallel phase executed smaller number atoms 
cost processing event parallel phase gamma lg lg event list 
iteration cost parallel phase determined maximum number events simulated processor period 
number hard determine 
assume average similar number events simulated processor note improve load balance impose upper limits number events processor superstep 
going assume total gamma bz events simulated parallel phases executed simulation total gamma bz simulated processor 
assume analysis bz bz events take place simulated sequentially chapter 
experience special purpose protocols synchronous algorithm 
cost parallel simulation gamma bz bz tcs tcs cost communication synchronisation 
predict performance bsp algorithm need compare fastest sequential algorithm problem 
define speedup case ising spin model gamma bz bz bz tcs replace obtain upper bound tcs required achieve expressed gamma bz bz bz tcs shows effect cost tcs essentially absorbed bz particular machine characterised parameters achieve speedup sufficiently large problem characterised parameters bz 
example extreme situation system low simulated inefficient machine high way achieve requires increasing parallel slackness increasing reducing reduce effect tcs 
synchronous algorithm cost tcs dominated parallel prefix operation tcs log 
efficient algorithm shown cost depends number different processors processor communicate order decide simulate bz event tcs ising spin model estimate bounds tcs ensure 
bz lg gamma bz obtain tcs lg synchronous algorithm 
hand asynchronous algorithm assume bz events processed iteration gamma bz bz tcs bz tcs lg obtain better bound tcs lg chapter 
experience special purpose protocols ising spin system exp bz theo bz table empirical results processor ibm sp 
note restricted case leads bounds respectively 
bounds shown table chapter see restriction upper bound tcs possible satisfy practice 
example running synchronous algorithm array computer require adjust 
table show empirical results obtained running time lg sequential algorithm asynchronous algorithm 
column show ratio total number bz events simulated processor total number iterations performed parallel algorithm 
column shows average processors 
columns show observed predicted fraction bz events respectively 
hard disk fluids second example complex consists dimensional box size lb theta lb contains hard disks evenly distributed 
random assignment velocities problem consists simulating total elastic disk disk collisions ddc events running time small possible 
section show similar bounds tcs required simulate systems bsp computer efficiently 
achieve efficient sequential running time box divided theta cells size oe theta oe oe lb diameter disk 
box periodical sense time disk runs box boundary wall re enters box opposite point 
neighbourhood disk center located cell composed cell cells immediately periodical adjacent define average number disks cell 
oe disk collide gamma disks located neighbourhood reduces lg cost associated simulation ddc event takes place regarded constant lg event list administer pending events 
disks move freely ddc events eventually cross neighbouring chapter 
experience special purpose protocols cells 
regard instant disk crosses cell neighbouring cell virtual wall collision event 
time event takes place necessary consider possible collisions disks located new cells part neighbourhood cells immediately adjacent adjacent average disks considered 
consider effect events define average number events take place consecutive ddc events 
goal simulating ddc events involves processing occurrence events 
note represents probability event take place instant simulation time ddc event probability event event 
perform simulation necessary maintain disk updated information time possible collisions disks located neighbourhood necessary periodically update time crosses neighbouring cell virtual wall computations effected pair wise manner considering positions velocities objects involved event calculated 
outcome dynamic set event tuples represents disk virtual wall indicates ddc event 
initialisation events event tuples predicted disks system new events successively calculated simulation advances time disk suffers ddc event 
note subset set events calculated disk events occur simulation obvious identify events advance 
different methods cope problem proposed literature 
common principle efficient data structure maintain event list events stored removed take place invalidated earlier events ddc event stored event list invalidated ddc event takes place simulation 
assume event maintained disk time event list event invalidated new event calculated considering complete neighbourhood words ddc event invalid event retrieved event list new collisions calculated considering gamma disks located neighbourhood implies fairly slower sequential simulation simplifies implementation 
note fraction invalid events retrieved event neglect effect analysis 
initialisation simulation enters basic cycle essentially composed operations picking chronological event event list ii updating state disk involved current event iii calculating new events disk event ddc events iv inserting event event list chapter 
experience special purpose protocols disk involved current event 
operations cyclically performed condition reached occurrence border zone event case parallel simulation 
running time sequential algorithm estimated follows 
constant factors neglected considering operations updating position velocity disk calculating ddc event single operations cost 
disk necessary consider gamma disks located neighbourhood whilst calculating new ddc events calculating event takes time 
cost associated event list lg event insertion retrieving event negligible 
selecting event time disk negligible effected new events calculated 
gives costs gamma lg gamma lg simulation ddc event takes place respectively 
cost simulation ddc event takes place lg note includes cost events take place consecutive ddc events 
total running sequential algorithm theory hard disk fluids expression ae gamma ae gamma ae ae ae disk area density system 
calculating obtained expression ae ae lg extreme conditions ae implies opt 
hand restriction oe imposes lower bound opt replacing ae oe obtain ae opt practice choosing leads efficient simulation terms total running time space cells 
parallel phase processor simulates evolution disks located region 
total processors average disks region logarithmic property gamma lg chapter 
experience special purpose protocols average running time spent processor computing occurrence consecutive ddc events region 
emphasise hard disk systems far difficult simulate parallel ising spin models 
particular necessary cope problem event scheduled particular disk may occur predicted time disk hit neighbouring disk earlier simulated time 
necessarily leads deal possibility rollbacks simulation re started check point passed error specific details implementation simulations 
regions simulated processor thetan cells define bz cells gamma cells located boundaries region 
studying probabilities cases bz event takes place calculate bz function parameters hard disk system 
general expression bz bz probabilities ddc event place border zone respectively 
probabilities calculated considering disk probability arbitrary cell direction uniform probability 
calculations somewhat involved cases considered 
briefly expressions obtained studying types bz events ddc positions disk involved 
probability bz gamma disk located bz cell probability gamma bz gamma gamma disk located cell neighbouring bz cell 
event disk crosses cell probability ddc event disk collides disk located neighbouring cell probability 
disk located cell neighbouring bz cell probability gamma disk located corner box 
case probability bz event ddc event event 
disk located corner probabilities respectively 
similar considerations disk located inside bz cell 
ddc event probability bz event just bz doing weighted sum cases obtained gamma gamma pm gamma gamma pm pm represents probability ddc event disks located cell 
probability depends size cells oe purpose analysis suffices say bz chapter 
experience special purpose protocols running time parallel algorithm pp sp bz pp sp bz pp sp pp time spent simulating pe events ddc parallel phase sp time spent synchronisation phase simulating event plus cost tcs associated communication synchronisation processors 
note pe events total pe ddc events events evenly distributed processors processors simultaneously simulate pe ddc events 
pp pp pe bz gamma sp sp lg lg tcs sp tcs gamma bz bz bz tcs expression tcs assuming lg obtain gamma bz bz bz tcs lg shows practical simulation bz bound tcs similar ising spin system 
hand assume border zone events simulated iteration asynchronous algorithm gamma bz bz tcs bz tcs lg leads bound similar ising spin model 
important note calculations involved derivation speedup conservative sense mixing bsp cost units ones defined 
basic unit cost updating disk state calculating new event disk higher cost time step assumed bsp model 
table show empirical results hard disk fluid simulated asynchronous algorithm running ibm sp parallel computer 
chapter 
experience special purpose protocols hard disk fluid exp bz table empirical results processor ibm sp 
chapter derived upper bounds cost communication synchronisation processors order perform efficient simulation large scale systems 
conclude possible satisfy bounds current parallel computers 
empirical results confirm 
bounds valid load perfectly balanced parallel phase processor simulates similar number events border zone events 
systems examples chapter property 
example simple system links neighbouring regions processors maintained fixed simulation 
cost event processed system extremely low 
imposes harder requirements cost communication synchronisation upper bounds lower constant factors 
second example noticeably complex dynamic nature system 
links regions change randomly simulation 
synchronous algorithm necessary cope problem rollbacks scheduled events associated disk necessarily occur predicted time 
simulation time progresses statistically rate region upper bounds communication synchronisation similar simpler example note constant factors higher second system example relaxes requirements bounds 
empirical results obtained asynchronous algorithm shown running ibm sp 
obtain speedup synchronous algorithm similar conditions 
provides evidence synchronous protocols significantly efficient asynchronous ones bsp setting 
chapter thesis studied realisation parallel discrete event simulation pdes bulk synchronous parallel bsp model computing 
focused analysis design implementation comparative evaluation synchronisation protocols performing efficient parallel event processing 
optimistic conservative protocols investigated synchronous asynchronous realisations 
effort dedicated development general purpose methods details operation protocol transparent user 
concentrated optimistic protocols established comparisons conservative ones 
explored cases necessary resort special purpose protocols investigated efficient implementation pending event set optimistic simulation 
summary results concluding remarks main result automatic adaptive optimistic synchronisation protocol general purpose pdes bsp call bsp time warp 
design protocol relevant results thesis efficient realisation pending event set event list maintained processor able efficiently speculative events scheduled logical processes supersteps ii determination means analysis pdes bsp fundamental level efficient scalable performance achieved logical processes allowed advance asynchronously simulation time superstep 
importantly analysis provided algorithmic representation asynchronous time advance async oracle controller optimistic execution actual bsp time warp protocol 
way scheme unique feature results simulation ideal bsp asynchronous protocol oracle simulation automatically adaptively tune chapter 
operation bsp time warp 
integrated unique feature protocol new method preventing rollback thrashing slower logical processes higher event processing priority maintaining event list processor ii storing rolled back newly generated events event lists iii setting upper limits number simulated events superstep iv keeping values fixed independently current rate rollbacks 
event lists enable chronological event processing supersteps parallel simulation tends focus processing events timestamps system avoids rollback thrashing 
oracle simulation give suitable adaptive values limits observed scheme able achieve near optimal gvt advance superstep low rate rollbacks 
addition experimental study thesis shows proposed method preventing rollback thrashing outperforms alternative methods workloads high rate rollback occurrences ii oracle simulation method sufficiently general allow transformation known asynchronous synchronous optimistic protocols automatic adaptive ones iii overheads associated practical implementation bsp time warp similar highly optimised bsp implementations conservative protocols iv bsp time warp outperform conservative protocols certain demanding loads achieve competitive performance 
remainder section emphasise aspects thesis section suggest topics research pdes bsp 
event lists currently widely accepted pending event set implemented efficiently general purpose priority queues pqs tree structure special purpose event queues eqs multiple lists structure 
observed pqs eqs serious limitations pqs suitable dealing speculative events arising optimistic parallel simulation eqs lose efficiency dramatically certain loads 
thesis proposed hybrid pqs eqs overcomes limitations approach 
hybrid queue hq general purpose particularly suitable servicing load generated bsp time warp 
hq data structure composed tournament tree collection lists kept unsorted provide low cost buffering areas speculative events 
efficient performance achieved dynamically keeping lists small sizes ii distributing events uniformly random lists iii reducing number accesses tournament tree 
investigated feasibility tournament tree implementing parallel chapter 
pqs 
showed tree reduce significantly requirements communication synchronisation processors 
appendix discuss parallel pqs optimistic simulation bsp operating automatic mode 
theoretical analysis focused crucial performance metrics total number supersteps required complete simulation balance parallel event processing process 
balance communication comes result balance computation event processing base quantitative analysis demanding load event occurrence generates sending new event message processor high probability 
load feature perfectly balanced global level considering mapping event occurrences processors extremely unbalanced superstep level 
case cumulative effect imbalance superstep lead simulation sequential computation 
results indicate approaches time advance achieve load balance slackness large large number lps processor large number events lp 
importantly results indicate asynchronous time advance achieves optimal number supersteps simulation model synchronous time advance force execution excessively large number event processing supersteps 
apart obvious gain performance coming reduction total number barrier synchronisations crucial point set events simulated system total number supersteps defines average number events simulated superstep 
events simulated superstep balance event processing process degrade significantly 
analysis reveals bsp setting synchronous protocols outperform asynchronous protocols cases practice 
claim validated performing experiments actual implementations synchronous asynchronous protocols 
comparative evaluation protocols evaluation optimistic protocols observed small number processors low rate rollbacks protocols achieve similar performance 
high rate rollbacks bsp time warp efficient protocols 
addition number processors scale whilst slackness kept fixed results show bsp time warp outperforms wider margin 
synchronous event horizon sync protocol btb inefficient cases 
chapter 
proposed efficient bulk synchronous implementations asynchronous synchronous conservative protocols 
results show asynchronous protocols cmb variations outperform synchronous ones cases 
conservative asynchronous protocols restricted communication topologies small fan fan 
established comparisons bsp time warp 
cases large lookahead low cost communication synchronisation processors small number processors conservative protocols outperform substantially proposed bsp time warp protocol 
see example 
achieve optimal performance user required introduce specific knowledge operation simulation model conservative protocols order increase lookahead 
bsp time warp able remain reasonably efficient situations conservative protocols fail dramatically little lookahead ii moderately high cost barrier synchronisation processors large fan fan communication topology lps 
results show overheads associated practical implementation bsp time warp similar conservative protocols 
provides evidence cumulative cost overheads introduced hybrid priority queue ii grouped rollback processing iii oracle simulation low practice 
special purpose protocols example protocols tailored applications hard particle fluids 
showed theoretically empirically potentially large scale systems efficiently simulated practice 
focused event processing task particular border zone events 
enabled global rollback mechanism low cost reduce significantly memory requirements associated optimistic simulation fluids conservative simulation case 
aim simulate large systems local rollback mechanisms implemented bsp time warp attractive principle necessary save old states processed events spatial region 
global rollback crude mechanism events states recalculated single causality error 
observed simulations driven border zone events able keep rate global rollbacks low level particular systems 
chapter 
colliding spheres research simulation large scale systems hard particle fluids determine oracle simulation method proposed thesis able achieve similar performance special purpose protocols 
case bsp time warp realisation global rollbacks form incremental state saving application 
surprising bsp time warp efficient special purpose protocols 
cmb protocol null messages yawns lookahead considered example kind protocol tailored particular application toroidal queuing network non preemptive servers 
queuing networks reasonable expect bsp time warp achieve competitive performance colliding spheres systems 
oracle simulations models computing interesting topic investigated feasibility oracle simulation method traditional models parallel computing 
shared memory multi processors facilities performing barrier synchronisation processors direct extension bsp time warp automatic mode appendix 
asynchronous message passing systems gvt calculation mechanism extended obtain maximum superstep counters maintained lps 
time warp systems interval gvt calculations associated interval real time 
lp receives new gvt value oracle superstep count information determine rate gvt advance virtual superstep 
case oracle superstep count measure real time 
able establish proper relation quantities length real time virtual superstep determine rate gvt advance real time 
respective lps locally define suitable moving simulation time window certain amount real time moved forward emulating virtual supersteps 
load balancing methods believe additional research general purpose pdes bsp focus efficient realisation mechanisms effecting automatic load balancing optimistic conservative bsp synchronisation protocols 
chapter 
development optimal strategies performing proper load balance pdes known computationally intractable 
heuristics proposed achieve reasonable load balance irregular systems 
tailored specific applications 
techniques balancing load general purpose simulators mainly number simulated events processor metric optimise 
case practical rule place lp current largest number simulated events processor cumulative number simulated events 
addition schemes attempt place pairs heavily communicating lps processors 
bsp significant impact total number supersteps required complete simulation 
load balancing schemes suitable bsp operating direct mode 
bsp automatic mode proper load balance comes result global priority queue administer pending events 
appendix investigate preliminary level implementation schemes bsp time warp direct automatic modes 
study enumerate topics research area details appendix consideration average timestamp increment events highly communicating lps probability resident lps ii combination load balancing methods 
chapter 
initial number jobs server toroidal queuing network small base lookahead cmb nm yawns bsp tw cmb yw theta theta theta theta theta initial number jobs server toroidal queuing network large base lookahead cmb nm yawns bsp tw cmb yw theta theta theta theta theta results bsplib implementation protocols processors sgi computer 
running time seconds 
shows values 
note results figures considered validation performance predicted chapter 
figures cmb nm cmb null messages base lookahead cmb yw cmb nm extended yawns lookahead 
appendix benchmark methodology important advantage bsp model cost model enables predict performance programs actual implementation 
parallel computer characterised bsp parameters implied performance prediction methodology simple application able estimate cost computation communication synchronisation bsp parameters enable predict running time application different parallel computers 
appendix apply idea pdes setting 
bsp cost model obtain information relevant factors determining efficiency parallel simulations 
compute speedup considering demanding case underlying parallel algorithm 
term parallel algorithm generic sense specific synchronisation protocol assumed 
consider idealised situation overheads associated synchronisation protocol relevant computation believe serious obstacle predicting actual performance overheads small designing efficient algorithms 
note conservative assumptions cost model 
assume cost processing event parallel algorithm identical sequential algorithm 
consider cost event lowest feasible possible 
assumptions pessimistic efficiency parallel algorithm advantage taken regarding partitioning system processors granularity events extremely small 
addition charge high cost administration messages processors 
extent assumptions account synchronisation protocol overheads 
parameters representing classes simulation models specific models 
expression represent simulation model mainly parameters 
parameters determine classes systems reasonable appendix benchmark methodology speedup achieved parallel computer 
practical realisation ideas leads benchmark program pdes bsp 
feasible speedups assume simulation goal process occurrence events system 
cost processing event sequential algorithm total cost sequential simulation hand total cost parallel simulation sp sp total number supersteps required simulate events average cost superstep 
average total nep events simulated superstep nep sp situation perfect load balance processor simulates occurrence nep events superstep 
cost processing event synchronisation protocol overheads considered 
value average maximum amount performed processor superstep 
introduce imbalance factor pb pb nep pb remaining nep gamma pb events assumed uniformly distributed remaining gamma processors 
addition assume fraction pm events simulated processor superstep causes message transmissions 
nep pb pm size message 
define sp nep speedup pb pb pm harder requirement parallel algorithm assume addition include computational overheads associated processing messages superstep sending reception messages 
assume overhead pm units running time processed event granularity events 
define restrict lowest feasible cost processing event particular machine 
obtain pb pm pb pm appendix benchmark methodology pb pm 
parameter measure slackness nep parameter pm accounts locality pb load balance 
way simulation models represented instance tuple pm 
final expression speedup useful sense describes methodology performance prediction different parallel computers represented enhanced values 
example particular computer interesting know range values pm possible achieve 
define systems feasible efficient simulation parallel computer 
user need determine lower bound cost processing event estimation number words typical messages 
values parallel computer evaluate different range values pm 
empirical lower bound determined simulating load system low cost event 
consider load sequential hold model 
model sequential simulation organised pending event set implementation called event list 
sequential program works follows inserting events event list hold model performs sequence hold operations ae 
hold operation retrieves event list event simulation time ii increases time units random variable iii re insert event event list 
accurate value cost processing event obtained measuring total running time spent processing sequence hold operations dividing cost achieved implement event list calendar queue exponential distribution values random variable note general case log means heap priority queues calendar queue easily degenerate cost processed event systems chapter 
example example practical speedup follows 
implemented sequential hold model executed processors ibm sp average performance mflops bsp parameters bit word 
obtained error varied language compiler optimisation 
extrapolated cray appendix benchmark methodology ibm sp theta theta theta theta theta theta theta theta theta theta cray theta theta theta theta theta theta theta theta theta theta performance prediction ibm sp cray 
pb 
curve data pm pm pm pm theta pm 
mflops bsp parameters bits word 
estimate cray 
values expression evaluated pb pm nep words bits assume single event message composed doubles send receive timestamps integers event lps identification plus data 
results shown 
clearly large systems nep ae simulated efficiently machines smaller systems best suited cray machine lower values 
particular cost barrier synchronisations significant impact efficiency small systems 
fixed specially smaller ones observe computational overheads represented term pm communication cost responsible important part performance degradation pm approaches 
obviously event granularity approaches infinity indicates optimal speedup combination parameters pm example observed improves noticeably 
representative values typical single message sizes suggest high performance parallel computers effect message transmissions important cost computational overheads associated underlying synchronisation protocol ibm sp 
design implementation efficient sequential algorithms computational part superstep plays crucial role speedup achieved parallel simulation 
effect large imbalance pb shown 
data show appendix benchmark methodology ibm sp theta theta theta theta theta theta theta theta theta theta cray theta theta theta theta theta theta theta theta theta theta performance prediction ibm sp cray 
pb 
curve data pm pm pm pm theta pm 
highly sensitive load balance software overheads 
parallel simulation achieve large imbalance similar distributed memory architectures proper load balance simulation crucial effect performance 
validation bsp benchmark program implemented validate performance predictions showed figures 
design follows 
processor hold model executed 
hold model parametrized number hold operations performed superstep input parameter program 
parameter enables control slackness 
goal perform total hold operation system 
measures sequential running time required achieve goal sequential program estimate superstep nep pb pm nep gammap gamma pm processors respectively new messages inserted calendar queue message delete arbitrary item queue insert new event ii nep pb nep gammap gamma respectively hold operations performed processor iii superstep nep pb pm nep gammap gamma pm respectively messages sent processors communication performed 
size system set means processor calendar queues maintains total events 
ibm sp observed similar results figures 
differences cases considered 
appendix load balancing strategies chapters assumed user responsible allocation logical processes lps processors 
initial configuration kept fixed simulation 
techniques performing automated dynamic load balancing improve inefficiencies introduced unbalanced mapping lps processors 
appendix evaluate effects performance practical load balancing schemes intended general purpose 
explore bsp automatic mode solution balancing processors load highly irregular applications 
evaluation practical methods load balance measured counting number events processed lp interval simulation time 
elaborate load balancing scheme amount computation involved processing event considered 
simplicity count events assume processing costs identical 
cumulative sum counters resident lps provides measure load balance processor 
addition number messages sent pairs lps second load balance measure 
observed bsp setting cost increased communication significant impact performance cost associated increase supersteps 
analysis chapter difficult see random allocation lps processor suffice wide range simulation models globally large communication fan fan 
loads resemble hold model fully connected toroidal topology random allocation lps sensible strategy apply 
cases causality threads comparatively smaller timestamp increments significantly determine performance simulation number supersteps events superstep appendix load balancing strategies load balance 
appendix define demanding loads step aside homogeneous symmetric phold loads 
define clusters highly communicating lps differing event time increments 
define clusters significant fraction messages routed 
differing time increments hot spot lps introduce high imbalance load 
cases events scheduled exponential distribution mean 
loads loads identified composed phold lps organisation define total nh clusters called clusters cluster contains random number lps 
number uniformly distributed average number lps cluster 
nh clusters contain lps considered hot spots receive great amount messages 
remainder lps organised normal clusters called clusters cluster contains random number lps 
number uniformly distributed nv nv nv nv average number lps cluster 
type cluster lps selected uniformly random message sending 
lp located cluster sends message cluster probability 
lp sends message lp located cluster probability 
message sent probability message sent cluster probability 
rules messages sent lps located clusters follows 
message sent cluster probability cluster probability probability lp located cluster probability 
aim load create sets lps perform causes imbalance ii increase locality communication lps cluster placed different processors net effect increase supersteps imbalance 
appendix load balancing strategies load contains set clusters cluster random number lps 
number uniformly distributed nv nv nv nv average number lps cluster 
types events called internal external events 
internal events take place respective clusters external events scheduled clusters take place clusters 
addition increments timestamps internal events smaller time increments external events 
cluster lps time increments fraction increments external events mean value exponential distribution 
clusters large number lps tend process large number internal events introduces imbalance 
routing probabilities external event messages sending message cluster sending lp lps cluster 
internal messages sent lps selected uniformly random 
load similar difference time increments internal events fraction gamma external events size number lps largest cluster number lps cluster events scheduled 
load balancing methods assume simulation executed determined interval simulation time total number simulated events counted interval lp 
schemes consider counts allocate lps processors schemes consider 
mapping schemes 
lps distributed processors order implied identifiers lps processor second processor forth 

lps distributed uniformly random processors 

lp largest number simulated events placed processor cumulative load 

considering clusters lps single lps 
cluster largest cumulative simulated events count placed processor cumulative load 
appendix load balancing strategies schemes figures shown numbers enumerated 
scheme specific knowledge structure simulation model 
general purpose system effect automatically accomplished considering counts messages pairs communicating lps space requirement 
proposed lps arranged linear chain partitioned 
lps put chain accordance linear ordering lps considers messages sent pairs 
heavily communicating lps put close chain increase probability placed subchain processor 
experiments empirical results shown obtained load instances 
total number lps kept fixed number processors increased 
load define nh nv 
loads define nv 
experiment collect information load balancing scheme apply respective load balancing scheme information determine mapping lps second run program 
results bsp time warp load balancing schemes implemented bsp time warp system described chapter 
figures show results event efficiency defined chapter supersteps unit simulation time figures show results load figures load figures load 
load timestamp increments events mean value scheme achieves best event efficiency values moderate increase supersteps scheme 
loads mean value timestamp increment events small scheme allocates clusters processors achieves best event efficiencies supersteps 
case total number supersteps substantially smaller supersteps achieved schemes 
results show selection load balancing method depends particular load 
sensible heuristic follow costly method observe appendix load balancing strategies measure load balance achieved 
sequence methods 
results moving time window obtained results moving time window protocol described chapter mtw 
results shown 
qualitative events efficiencies smaller achieved bsp time warp 
practical realisation simulation study normally require executions simulation program 
case load statistics collected regular intervals simulation time stored secondary memory 
subsequent runs program statistics load balance simulation different methods 
similar approach applied simulation run implementing dynamic load balancing strategy described 
dynamic load balancing effected moving lps heavily loaded processors lightly loaded processors execution actual simulation 
bsp time warp protocol lps moved groups barrier synchronising simulation gvt ii performing fossil collection iii moving respective lps new processors 
involves sending local state variables pending events send times equal gvt 
statistics collected fossil events determine mapping lps interval 
actual number lps moved reduced defining types lps accordance load requirements 
mapping algorithm determines number lps type placed processors 
lps required complete number type moved heavily loaded processor respective processor 
length interval adjusted cost performing load balancing kept total running time interval 
mapping algorithm executed sequentially processor 
similar procedure utilised conservative protocols chapter 
automatic mode bsp operating automatic mode programmer provided shared memory space 
memory implemented hash function distributes evenly uniformly random blocks shared memory processors 
appendix load balancing strategies theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta results bsp time warp protocol 
appendix load balancing strategies practical aspects shared memory bsp discussed memory block assigned integer valued address linear hash function defined significant bits specify processor block mapped remainder bits specify location block processor 
concurrent read concurrent write shared memory implemented bsp follows superstep ffl locally sort memory requests processor linear time integer sorting algorithm 
ffl multiple requests memory location select representative requests address 
ffl send representatives processor determined hash function 
superstep ffl processor process requests received 
writes involves merely updating value local memory reads sending back locally held value requesting processor 
superstep ffl process responses duplicating values multiple read requests location 
realisation pdes pram model computing discussed 
practical realisation ideas 
algorithm global event list proposed shared memory multi processors 
global event list implemented calendar queue allows concurrent read write pending events means locks kind simulation originally studied 
simulation algorithm organised cycles cycle processor simulates occurrence event 
cycle ended barrier synchronisation processors 
section investigate similar approach bsp context 
note scheme proposed implemented shared memory multi processor supporting barrier synchronisation processors avoids bsp implementation shared memory 
advantage method allows simulation events processor cycle 
parallel priority queue ppq maintain pending events 
memory processed events states associated lps maintained shared memory 
routines cause occurrence events maintained duplicated processor appendix load balancing strategies spmd 
discussed chapter ppq implemented bsp operating direct automatic mode pram emulation 
cycle algorithm extract min operation retrieves ppq events time system 
events distributed uniformly random processors processor simulates occurrence events 
events associated lp routed processor sequential nondecreasing timestamp processing current cycle 
described chapter events considered part events simulated processor 
limit achieved remaining events newly generated events inserted event queue 
roll backs processed direct cancellation 
number events processed cycle determined automatically adaptively oracle simulation chapter 
case asynchronous superstep counters incremented message sent logical process 
sequential simulator bsp protocols perform experiments previous section 
expected results similar load balancing scheme distribute lps uniformly random number 
advantage case simulation load may change dynamically combinations loads affecting performance protocol significantly 
qualitative simulations automatic mode may feasible alternative highly irregular loads instance clustering lps timestamp increments events changes dynamically simulation 
research bsp direct mode experimental results section obtained sequential simulator bsp synchronisation protocols section chapter 
results show clustered loads convenient consider average timestamp increment events scheduled clusters 
topics suggested investigation ffl inclusion metric average timestamp increment events load balancing scheme 
case pairs lps high communication messages small timestamp increments high probability allocated processor 
ffl design bsp algorithms execute resulting load balancing algorithm parallel 
particular collection processing data effected distributed appendix load balancing strategies memory bsp computer 
systems fully connected communication topology necessary maintain space data 
ffl implementation hybrid load balancing schemes scheme requiring greatest amount statistical data expensive schemes able balance load reasonably 
relevant problem solved prediction load balance method advance performing simulation allocation lps dictated selected load balancing method 
bsp automatic mode ffl implementation bsp time warp automatic mode 
ffl comparative study different realisations parallel priority queues administer pending events 
particular randomised deterministic queues implemented direct automatic bsp mode 
ffl investigate methods exploiting locality automatic mode 
appendix load balancing strategies theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta theta results moving time window protocol 
appendix regression analysis appendix provide details regression analysis effected obtain formulae supersteps event efficiencies chapter sections 
supersteps sync simulation results obtained algorithm chapter show distributions bimodal uniform produces similar different constant factors 
assuming asymptotic form fi ff shows values points scaled lg lg fi ff lg table shows ff fi values obtained performing squares regression points 
values show general trend curve 
secondly transformed experimental data points ff ff values shown table performed linear regression points regression line form fi ff fl obtained 
values fi fl probability distributions shown table appendix regression analysis theta theta theta theta theta theta theta theta supersteps unit simulation time sync 
curve data bimodal exponential uniform triangular theta distributions 
async investigate actual behaviour performing simulations algorithm shown chapter 
figures show simulation results different probability distributions 
fixed shows sync ff behaviour 
values smaller shown 
particular values factor predicted ff squares regression points pseudo line produces ff fi values shown table compared ff fi values shown table particular ratio fi async fi sync column 
shows behaviour fixed quite similar ln ln data suggest ln ln large 
type curves obtained 
note points obtained directly evaluating fi ff fl ff fi fl values shown table sync 
points shown slightly smaller conjecture special case discussed chapter section treat transition point special case relevant experiments 
values consistently factor larger 
note shows just instance scalability data 
shown probability distribution set curves appendix regression analysis dist ff fi bim exp uni tri dist ff fi fl bim exp uni tri asymptotic trend fi ff regression line fi ff fl table lines slopes increasing function say fi ff fl ff exponential uniform bimodal distributions ff triangular distribution 
fi ff ln ln fi observed similar trend fl fl ff ln ln fi squares regression curves lines returns points fi fl 
regression transformed points ln ln fi ln ln fl produces ff fi ff fi values shown table direct evaluation formulae predicts simulation results wide range experiments produce different data perform regression 
function ln ln grows slowly comparison example ln ln ff fi values shown table practical systems reasonable expect exponential uniform bimodal distributions 
shown axis shows values ranging 
curves 
curves finish small values 
curves data suggest slightly higher prediction small empirical data matches conjecture quite 
show scalability ratio ff ln ln 
results clearly show large scale systems expect async outperform sync wider margin terms total number supersteps 
shown commonly exponential uniform distributions produce largest ratio appendix regression analysis consider effect aggregation lps processors 
discussed section scalability depends number lps time advances gamma small accommodate threads large find lps small time advance processors probability gamma consecutive events thread scheduled different processor 
increase shows results experiments total number lps delta kept constant whilst values changed accordingly pairs delta 
emphasise case minimal superstep counter algorithm depicted increased event scheduled occur lp located processor simulating bsp computer delta processors 
shows remains fairly constant wide range pairs ae decreases slightly 
shows increase lps processor able compensate reduction processors 
large value tends value simulation delta processors lp processor 
ln ln ff verify claim results figures shows function different values maintaining constant exponential distribution 
shows values resulting product delta takes values values identical figures shows practical increases ln ln 
non zero probability scheduling consecutive events processor effect reducing small seen figures point slightly smaller sibling 
explain non constant trend curves practical point view decomposition large system set lps ae positive effects running time reduces ways associated reduction dominant term 

previous expressions number threads dd conclude fi ff values comparatively small trend ratio seen curve shows data different accordance notation 
values taken experiments 
appendix regression analysis dist ff fi fi fi bim exp uni tri dist ff fi ff fi bim exp uni tri table regression constants probability distributions 
note decomposition lps effects sync global horizon taken events sent processors lps 
expressions learn ratio practice constant 
shows ratio dd constant different values 
trend clearly observed 
event efficiency sync derive regression formula deterministic distribution 
shows fairly logarithmic trend asymptotic section suggests trend ln ln ln constant 
available simulation data performed multiple linear regressions points ln ln ln ef time different case fixed regression line calculated specific measure error line calculated standard actual values predicted regression line 
produced table tuples error value produced regression lines smallest error basic regression formula ff fr fi fr ln ln ln squares regression pseudo line properly scaled fr function shows ff goes zero asymptotically expected increases relative weight ln ln ln factor ratio see means practice slackness requirement sync higher predicted appendix regression analysis bim exp uni tri theta theta theta theta theta theta theta theta theta theta theta theta ln ln bim exp uni tri theta theta theta theta theta theta theta theta theta theta exp exp theta theta theta theta theta theta theta theta bim exp uni tri theta theta theta theta theta theta theta theta theta theta bim exp uni tri theta theta theta theta theta theta theta theta supersteps async 
appendix regression analysis exp theta theta theta theta theta theta theta theta theta exp theta theta theta theta theta theta theta theta theta exp dp dp theta theta theta theta theta theta theta theta exp theta theta theta theta theta theta theta theta supersteps async aggregation lps 
appendix regression analysis asymptotic formulae 
regression curve produces ff gamma hand regression data suggests parameter fi goes faster gamma consider fi introduces small error 
regression formula gamma fr gamma note effect ln ln negligible range interest say similar regression procedure fr ln produces formula gamma ln gamma differences values formulae formulae verified effective exponential distribution results simulation data distribution 
efficiency values obtained quite similar chapter 
particular obtained approximations error fi gamma formula ln second formula additive constant improve approximation small approximation actual average number events processed superstep processor small small order terms significant 
constant corrective factor 
similar results obtained linear interpolation values chapter input parameter 
effective exponential distribution considering dd obtained formula gamma ln gamma async similar sync scalability ln seen shows remains fairly bimodal exponential uniform distributions 
appendix regression analysis det theta theta theta theta theta theta theta theta ff results efficiency shows ratio different values 
actual simulation data values calculated evaluating regression formula constant factors included effective async 
case effective calculated respective experimental shows ratio grows logarithmically curve ff ln fi ff fi increasing functions squares regression pseudo line produces ff fi values plotted suggests ff fi ln ff fi fi ln ff squares regression curves produces values ff fi ff fi 
omitting constants obtain ln ln ln ln ln shows sync degrades ln system scales 
suggests regression formula ff ln fixed squares regression curve suggests ff ff see regression curves ff suggests ff ln see estimation exponential distribution ln ln ln approximates experimental data error 
appendix regression analysis tri uni exp theta theta theta theta theta theta theta theta bim ln theta theta theta theta theta theta theta theta theta theta theta theta 
ln ln ln ff ln fi exp theta theta theta theta theta ff theta theta theta theta theta ff ln efficiency async regression 
bibliography 
parallel simulation scheme distance objects 
scs multiconference distributed simulation pages march 

parallel simulation conservative windows 
winter simulation conference pages 
ball 
adaptive time warp concurrency control algorithm 
scs multiconference distributed simulation pages jan 
dittrich meyer auf der heide 
realistic parallel algorithms priority queue operations selection bsp model 
euro par 
lncs 
beckman van warren blume jefferson 
distributed simulation time warp part design colliding pucks 
scs multiconference distributed simulation feb 
bentley 
heaps 
comm 
acm 
biswas browne 
simultaneous update priority structures 
int 
conf 
parallel processing pages 
hogg phillips 
list synchronization procedure discrete event simulation 
comm 
acm dec 
lake turner 
cooperative acceleration robust conservative distributed discrete event simulation 
th workshop parallel distributed simulation pads pages 
das 
dynamic load balancing strategies conservative parallel simulation 
th workshop parallel distributed simulation pads pages 

semi global time event algorithm 
th workshop parallel distributed simulation pads pages 
bibliography brown 
implementation analysis binomial queue algorithms 
siam comput 
brown 
calendar queues fast priority queue implementation simulation event set problem 
comm 
acm oct 
bryant 
simulation packet communications architecture computer systems 
technical report mit lcs tr massachusetts institute technology 
cai turner 
dag consistent parallel simulation predictable robust conservative algorithm 
th workshop parallel distributed simulation pads pages 

conservative discrete event simulations bulk synchronous parallel architectures 
technical report prg tr computing laboratory oxford university 

bulk synchronous parallel algorithms conservative discrete event simulation 
parallel algorithms applications 

bulk synchronous parallel algorithms optimistic discrete event simulation 
technical report prg tr computing laboratory oxford university 
chandy misra 
distributed simulation case study design verification distributed programs 
ieee trans 
softw 
eng 
se sept 
chang jones 
message oriented discrete event simulation 
simulation aug 
chung sang rego 
performance comparison event calendar algorithms empirical approach 
software practice experience oct 
mar 
efficient simulations fluids algorithm experiments 
chaos fractals 

discrete event simulation object movement interactions 
simulation 
das 
estimating cost throttled execution time warp 
th workshop parallel distributed simulation pads pages 
das fujimoto 
adaptive memory management optimism control time warp 
acm trans 
modeling computer simulation april 
bibliography davey 
self optimizing partitioned sequencing sets discrete event simulation 
infor feb 

expert system prototype assisting statistical validation simulation models 
simulation feb 
nicol reynolds 
analysis bounded time warp comparison yawns 
acm trans 
modeling computer simulation oct 
driscoll gabow tarjan 
relaxed heaps alternative fibonacci heaps applications parallel computation 
comm 
acm nov 
mcgregor summers 
applying object oriented paradigm discrete event simulations language 
simulation feb 
kleinrock 
upper bound improvement asynchronous versus synchronous distributed processing 
scs multiconference distributed simulation pages jan 
kleinrock 
processor conservative simulation analysis 
th workshop parallel distributed simulation pads pages 
ferscha 
estimating rollback overhead optimism control time warp 
th annual simulation symposium pages 

efficient data structure simulation event set 
comm 
acm aug 

comparison heaps tl structure simulation event set 
comm 
acm oct 
fredman sedgewick sleator tarjan 
pairing heap new form self adjusting heap 
algorithmica mar 
fredman tarjan 
fibonacci heaps uses improved network optimization algorithms 
journal acm july 
fujimoto 
time warp shared memory multiprocessor 
trans 
soc 
computer simulation july 
fujimoto 
parallel discrete event simulation 
comm 
acm oct 
fujimoto 
performance time warp synthetic loads 
scs multiconference distributed simulation pages jan 
bibliography gafni 
rollback mechanisms optimistic distributed simulation systems 
scs multiconference distributed simulation pages 

pram programming theory vs practice 
th euromicro workshop parallel distributed processing madrid spain jan 
technical report prg tr computing laboratory oxford university 

selection bulk synchronous parallel model applications priority queues 
int 
conf 
parallel distributed processing techniques applications 

parallel priority queue list contraction bsp approach 
euro par passau germany aug 
lncs 
gonnet 
heaps applied event driven mechanisms 
comm 
acm july 
gonnet baeza yates 
handbook algorithms data structures nd edition 
addison wesley 
chapter 
gupta fujimoto 
performance analysis time warp multiple homogeneous processors 
ieee trans 
softw 
eng oct 
tripathi 
investigations adaptive distributed simulation 
th workshop parallel distributed simulation pads pages 

improved event list algorithm 
winter simulation conference pages 
ieee piscataway 
beckman blume reiher van warren wieland jefferson 
performance colliding pucks simulation time warp operating system part asynchronous behavior 
scs multiconference distributed simulation march 
aj 
parallel algorithms 
addison wesley reading mass 
jefferson 
virtual time 
acm trans 
prog 
lang 
syst july 
jefferson 
virtual time ii protocol storage management distributed simulation 
th annual acm symposium principles distributed computation pages aug 
johnson 
priority queues update finding minimum spanning trees 
inf 
proc 
letters dec 
bibliography dahl 
analysis algorithm priority queue administration 
bit 
jones 
empirical comparison priority queue event set implementations 
comm 
acm 
jones 
concurrent simulation alternative distributed simulation 
winter simulation conference pages washington dec 
jones 
concurrent operations priority queues 
comm 
acm 
karp zhang 
parallel algorithms backtrack search branch bound 
journal acm 
kingston 
analysis tree algorithms simulation event list 
acta informatica apr 
knuth 
art computer programming vol 
fundamental algorithms 
addison wesley reading mass 
knuth 
art computer programming vol 
sorting searching 
addison wesley reading mass 

efficient algorithm hard sphere problem 
phd thesis departament computer science university colorado boulder colorado 
hill 
architecture independent locality analysis efficient pram simulations 
high perfomance computing networking vienna austria april 
lncs 

pram programming theory practice 
concurrency practice experience appear 

library generation pseudorandom numbers 
random mat ac 
liao 
priority queue applications revisited 
algorithmica 

lin lazowska 
selecting checkpoint interval time warp simulation 
th workshop parallel distributed simulation pads pages may 

lin 
optimal memory management time warp parallel simulation 
acm trans 
modeling computer simulation oct 
lipton 
time warp vs chandy misra worst case comparison 
scs multiconference distributed simulation pages jan 
bibliography 
role knowledge distributed simulation 
scs multiconference distributed simulation pages 

efficient parallel simulations dynamic ising spin systems 
journal computational physics 

efficient distributed event driven simulations multiple loop networks 
comm 
acm jan 

simulate systems 
journal computational physics 

simulating serially parallel 
international journal computer simulations pages 
weiss 
analysis rollback simulation 
acm trans 
modeling computer simulation april 

comments building heaps parallel 
inf 
proc 
letters 
mar 
related systems bulk synchronous parallel model 
th workshop parallel distributed simulation pads pages june 
mar 
direct bsp algorithms parallel discrete event simulation 
technical report prg tr computing laboratory oxford university 
mar 
event driven hard particle molecular dynamics bulk synchronous parallelism 
computer physics communications 
mar 
priority queue operations erew pram 
euro par workshop parallel discrete algorithms 
lncs 
mar 
empirical assessment optimistic pdes bsp 
th european simulation symposium oct 
mar 
asynchronous time warp versus synchronous event horizon simulation time advance bsp 
euro par workshop theory algorithms parallel computation pages sept 
lncs 
mar 
pending event set binary tournaments 
th european simulation symposium oct 
mar 
time warp bsp computers 
th european simulation multiconference june 
bibliography mar 
efficient algorithms body hard particle molecular dynamics 
journal computational physics 
mar 
empirical assessment priority queues event driven molecular dynamics simulation 
computer physics communications dec 
mar 
object oriented approach discrete event simulation complex large systems moving objects 
th annual simulation symposium pages april 

simulating computer systems techniques tools 
mit press series computer systems 
fujimoto 
operating system parallel simulation supercomputing 
journal parallel distributed computing aug 
mccoll 
general purpose parallel computing 
gibbons spirakis editors lectures parallel computation pages 
cambridge university press 
mccoll 
special purpose parallel computing 
gibbons spirakis editors lectures parallel computation pages 
cambridge university press 
mccoll 
architecture independent programming model scalable parallel computing 
ferrante hey editors portability performance parallel processors 
john wiley sons 
mccoll 
bsp programming 
blelloch chandy jagannathan editors workshop specification parallel algorithms volume pages 
dimacs series discrete mathematics theoretical computer science 
mccoll 
scalable parallel computing grand unified theory practical development 
simon editors th ifip world computer congress volume pages 
elsevier aug 
mccoll 
scalable computing 
van leeuwen editor computer science today trends developments pages 
lncs springer verlag 
sargent 
analysis event set algorithms discrete event simulation 
comm 
acm 
mckenzie 
parallel simulation billiard balls shared variables 
th workshop parallel distributed simulation pads philadelphia pa may 
bibliography miller kochut potter 
query driven simulation functional object oriented database system 
international journal computer simulation 
misra 
distributed discrete event simulation 
computing surveys march 

object oriented design output tools simulation languages 
simulation jan 
moret shapiro 
empirical assessment algorithms constructing minimum spanning tree 
dimacs series discrete mathematics computer science june 
nicol 
high performance parallelized discrete event simulation stochastic queueing networks 
winter simulation conference pages 
nicol 
global synchronization optimistic parallel discrete event simulation 
th workshop parallel distributed simulation pads pages 
nicol 
cost conservative synchronization parallel discrete event simulations 
journal acm april 
nicol fujimoto 
parallel simulation today 
annals operations research 
nicol johnson 
performance modeling ides framework 
th workshop parallel distributed simulation pads pages 
nicol johnson 
ides java distributed simulation engine 
workshop modeling analysis simulation computer telecommunication systems mascots 
wen 
optimal parallel initialization algorithms class priority queues 
ieee trans 
parallel distrib 
systems 

graphical programming simulation models object oriented environment 
simulation feb 
fujimoto 
adaptive flow control time warp 
th workshop parallel distributed simulation pads pages 

entity connection approach simulation 
simulation pages oct 

parallel priority queues 
inf 
proc 
letters pages 
bibliography 
parallel algorithms priority queue operations 
swat lncs pages 
prasad 
efficient scalable pram algorithms discrete event simulation bounded degree networks 
journal parallel distributed computing 
prasad 
effectiveness global event queues rollback reduction load balancing 
th workshop parallel distributed simulation pads pages 

distributed discrete event simulation specification language execution environments 
scs multiconference distributed simulation pages march 

memory management techniques time warp distributed memory machine 
th workshop parallel distributed simulation pads pages 
macintyre 
trade time space optimistic parallel discrete event simulation 
th workshop parallel distributed simulation pads pages 
cheng jones shih 
parallelism locality priority queues 
th ieee symposium parallel distributed processing pages 
rao zhang 
building heaps parallel 
inf 
proc 
letters 
rao kumar 
concurrent access priority queues 
ieee trans 
comput 
rapaport 
event scheduling problem molecular dynamics simulation 
journal computational physics 
reddy fox 
knowledge simulation system 
ieee software march 
reed 
parallel discrete event simulation shared memory 
ieee trans 
soft 
engineering april 

comparative study parallel sequential priority queue algorithms 
acm transactions modeling computer simulation april 
fujimoto das 
efficient implementation event sets time warp 
th workshop parallel distributed simulation pads may 
bibliography 
lazy queue new approach implementing pending event set 
international journal computer simulation 
sanders 
fast priority queues parallel branch bound 
second int 
workshop irregular lncs pages 
anzai 
reduction event list molecular dynamic simulation 
computer physics communications 
skillicorn hill mccoll 
questions answers bsp 
technical report prg tr computing laboratory oxford university 
journal scientific programming 
sleator tarjan 
self adjusting heaps 
siam comput feb 
briscoe wieland 
mtw strategy scheduling discrete simulation events concurrent execution 
scs multiconference distributed simulation pages july 
srinivasan reynolds 
adaptive synchronization algorithms pdes 
winter simulation conference pages dec 
stasko vitter 
pairing heaps experiments analysis 
comm 
acm 

multiple synchronization environment parallel discrete event simulation 
international journal computer simulation 

breathing time warp 
th workshop parallel distributed simulation pads pages may 

discrete event simulation event horizon 
th workshop parallel distributed simulation pads pages 
tarjan sleator 
self adjusting binary search trees 
journal acm july 
tay teo kong 
speculative parallel simulation adaptive throttle scheme 
th workshop parallel distributed simulation pads pages 

bulk synchronous parallel random access machine 
euro par lyon france aug 
lncs 
turner xu 
performance evaluation bounded time warp algorithm 
th workshop parallel distributed simulation pads pages 
bibliography ulrich 
event manipulation discrete simulations requiring large numbers events 
comm 
acm sept 

discrete event simulation package pascal 
simulation 
valiant 
bulk synchronous parallel computers 
reeve zenith editors parallel processing artificial intelligence pages wiley chichester 
valiant 
bridging model parallel computation 
comm 
acm aug 
valiant 
general purpose parallel architectures 
van leeuwen editor handbook theoretical computer science 
north holland 

distribution event times notices simulation event list 
infor may 
duval 
comparison simulation event list algorithms 
comm 
acm april 
vuillemin 
data structure manipulating priority queues 
comm 
acm apr 
wieland hawley blume reiher beckman jefferson 
distributed combat simulation time warp model performance 
scs multiconference distributed simulation march 
wieland 
implementing distributed combat simulation time warp operating system 
acm third conference hypercube concurrent computers applications feb 
wieland jefferson 
case studies serial parallel simulation 
international conference parallel processing pages pp 
iii 
williams 
algorithm heapsort 
comm 
acm june 
wilson nicol 
experiments automated load balancing 
th workshop parallel distributed simulation pads pages 
zhang korf 
parallel heap operations erew pram 
th int 
parallel processing symposium pages 
