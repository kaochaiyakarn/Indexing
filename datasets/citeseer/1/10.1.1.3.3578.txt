novelty detection review part statistical approaches sameer singh research department computer science university exeter exeter ex pt uk singh ex ac uk novelty detection identification new unknown data signal machine learning system aware training 
novelty detection fundamental requirements classification identification system test data contains information objects known time training model 
provide stateof art review area novelty detection statistical approaches 
second part details novelty detection neural networks 
discussed multitude applications novelty detection extremely important including signal processing computer vision pattern recognition data mining robotics 

detecting novel events important ability signal classification scheme 
fact train machine learning system possible object classes data system encounter important able differentiate known unknown object information testing 
realised practice studies novelty detection extremely challenging task 
reason exist models novelty detection shown perform different data 
clearly evident single best model novelty detection success depends type method statistical properties data handled 
applications require classifier act detector classifier requirement detect input part data classifier trained fact unknown 
technique useful applications fault detection tarassenko dasgupta forrest dasgupta king radar target detection carpenter detection masses mammograms tarassenko hand written digit recognition tax duin internet commerce statistical process control 
increased interest novelty detection number research articles appeared autonomous systems adaptive machine learning 
surveys appeared addison 
earlier interest novelty detection study control systems 
high integrity systems traditional classification method number reasons abnormalities rare may data describes fault conditions 
novelty detection offered solution problem modelling normal data distance measure threshold determining abnormality 
years novelty detection number applications especially signal processing image analysis biometrics 
applications problem complicated multiple classes high dimensionality noisy features quite samples 
novelty detection methods tried keep problems offer solutions real world 
review currently methods novelty detection statistical approaches 
important issues related novelty detection 
summarise terms principles 
principle robustness trade novelty detection method capable robust performance test data maximises exclusion novel samples minimising exclusion known samples 
trade limited extent predictable experimental control 
principle uniform data scaling order assist novelty detection possible test data training data normalisation lie range singh 
principle parameter minimisation novelty detection method aim minimise number parameters user set 
principle generalisation system able generalise confusing generalised information novel tax duin 
principle independence novelty detection method independent number features classes available show reasonable performance context imbalanced dataset low number samples noise 
principle adaptability system recognises novel samples test able information retraining saunders gero 
principle computational complexity number novelty detection applications online computational complexity novelty detection mechanism possible 
survey study number approaches novelty detection studies address principles 
approach number different methods detail important studies areas 

statistical approaches statistical approaches modelling data statistical properties information estimate test samples comes distribution 
techniques vary terms complexity addison 
simplest approach constructing density function data known class assuming data normal computing probability test sample belonging class 
probability estimate thresholded signal novelty 
simple model simply find distance sample class mean threshold basis standard deviations away sample 
distance measure mahalanobis probabilistic distance webb 

discuss choice features ability novelty detection 
scheme novelty index rank features ability detecting novelty 
simple statistical scheme outlier rejection box plots 
box plot known display number summary lower extreme lower quartile median upper quartile upper extreme 
box plots suitable exploring symmetric skewed quantitative univariate data identify infrequent values categorical data 
data univariate sorted ascending order outliers ranked frequencies univariate outlier values 
samples highest frequencies discarded 
predetermined percentage worst examples discarded 
knorr 
suggest object dataset distance db outlier fraction objects lie distance greater specifically standard multidimensional indexing structure execute range search radius object neighbours neighbourhood search declare non outlier rejected outlier 
technique words nearest neighbour scheme hellman 

main contribution study authors solution fast indexing search large multidimensional databases 
advanced statistical modelling techniques exist novelty detection 
example mixture models modelling complex data distributions hidden markov model novelty detection discussed 
main approaches exist estimation probability density function parametric non parametric methods 
parametric approach assumes data comes family known distributions normal distribution certain parameters calculated fit distribution 
real world situations underlying distribution data known techniques little practical importance 
non parametric methods form density function derived data parameters model 
result non parametric methods give greater flexibility general systems 
intuitive widely non parametric technique histogram analysis 
shape density estimate vary significantly depending choice origin purely arbitrary 
things get worse density estimation multivariate data required 
better way estimating density functions kernel methods 
similar histograms built number individual kernels centred sampled data points 
parameter determines width kernel smooth estimation 
kernel function usually symmetric probability density function non negative domain integrate unity defined range 
value density arbitrary value dependent distance observed data shape kernel 
clearly smoothing parameter plays central role estimation density 
choosing global value result density function adequately describe data particularly regions low data density various techniques may employed locally adjust 
parametric methods estimating probability density function limited require extensive priori knowledge problem 
non parametric statistical approaches assumption form data distribution flexible computationally expensive 
density estimation cases performed nearest neighbour methods parzen window method 
probability estimate test sample belonging distribution obtained thresholded 
approaches limitations regards choice parameters neighbours smoothing parameters difficulty tackling noise data 
discuss parametric non parametric approaches detail sections respectively 
parametric approaches parametric approaches assumption data distributions gaussian nature modelled statistically data means covariance 
number studies theoretically investigated novelty detection data 
particular importance trade recognition rate proportion data rejected hansen 
error rate reject rate commonly describe performance level pattern recognition system 
uncertainty noise inherent pattern recognition task errors generally unavoidable 
option reject introduced safeguard excessive misclassification 
trade errors rejects seldom 
reject option exercised outliers known classes rejected 
chow studied trade detail find optimal threshold rejection 
obvious recognition rule optimum error rate error probability minimizes reject rate reject probability 
author showed optimum rule reject pattern maximum posteriori probabilities threshold 
error reject trade derived bayes optimum recognition system option reject 
hansen 
extended chow introducing role classifier confidence decisions 
intuitively rejection rule amount confidence classifier classification 
novelty rejection scheme study ensemble neural network classifiers employing consensus scheme 
pattern classified category majority votes 
number votes winning class receives threshold placed number classifiers 
threshold pattern rejected 
recognition tasks underlying probability distributions patterns completely known 
optimal threshold chow longer useful 

tackle problem 
method provides works posteriori probabilities affected errors 
authors suggest multiple thresholds class 
threshold placed maximum posteriori probability just chow case class different threshold 
results nearest neighbour neural network classifiers show scheme outperforms parametric assumption 
improvement chow original study 

pattern recognition problems idea combining various experts aim compensating weakness single expert widely investigated 
main problem combination rule able solve conflicts experts disagree 
cases experts final decision may unreliable desirable reject patterns sophisticated processing 
extend de stefano applying technique multi expert systems 
technique similar hansen 
reject option mes architecture defined drops assumption knowing exact values posteriori probabilities 
reject option defined mes architecture bayesian combining bc rule 
bc rule estimates posteriori probability input sample belongs class selects class highest probability 
value calculated reasons values near characterizing reliable classification values near indicating unreliable classifications 
parameters combined ways thresholded rejection 
threshold computed maximizing function measures mes classification effectiveness considered application domain 
approaches suggested artificially generated anomalies improve novelty detection performance system 
wei 
suggest artificial anomalies novelties injected training data help learner discover boundary original data 
generate artificial anomalies close known data useful heuristic randomly change value feature existing example leaving features unaltered 
sparse regions characterized infrequent values individual features 
amplify sparse regions proportionally create artificial anomalies 
technique works novel class anomalies overlap known classes 
random anomalies generated classification takes place random anomalies misclassified known removed data 
process repeated satisfactory size stable random anomalies data created 
system tested network intrusion detection task 
better performance obtained training data augmented data anomalous classes 
number random anomalies generated critical system performance 
discuss advanced methods parametric statistical novelty detection including probabilistic gmm approaches section hidden markov models section hypothesis testing section 
approaches complex linear schemes novelty detection elad primarily aimed data density estimation robust statistics 
probabilistic gmm approaches gaussian mixture modelling gmm models general distributions estimating density fewer kernels number patterns training set addison 
parameters model chosen maximizing log likelihood training data respect model 
done optimisation algorithms conjugate gradients reestimation techniques em algorithm 
gmm suffer curse dimensionality sense dimensionality data high large number samples needed train model 
number studies gmm novelty detection described 
roberts tarassenko developed robust method novelty detection aims minimize number heuristically chosen thresholds novelty decision process 
novelty detection method similar barnett lewis bishop tarassenko parra 
tax duin 
brotherton 
tarassenko 
yeung chow density function training data estimated gmm 
parameters gmm estimated em algorithm 
major contribution algorithm decides add gaussian unit automatic criterion determines number gaussians 
growth decision monitoring smallest mahalanobis distance training vector gaussian network 
growth threshold initially set progressively increased 
algorithm ensures gaussian seen sample training data 
maximum growth threshold algorithm novelty threshold 
maximum posterior probability test vector threshold rejected novelty 
technique tested medical signal processing task detect epileptic seizures 
total gaussian kernels grown system exhibiting high performance rates 
tarassenko applies novelty detection technique detection masses mammograms 
mammography suited problem novelty detection question mass exists mammogram examples abnormal tissue scarce compared examples normal tissue 
idea build model normality training data normal examples compare test patterns model 
assumption abnormalities uniformly distributed outside boundaries normality 
description normality unconditional probability density estimation training data 
test vector falls region input space density pre determined threshold test vector considered novel 
technique similar bishop tackles regions training space low density legitimate training objects 
regions exist setting global novelty threshold fail reject novel cases reject lot normal cases 
solution implementation local novelty threshold depends density data region input space 
space partitioned means algorithm parts input space density function calculated independently partition 
precise number partitions critical 
authors considered ways density estimation gaussian mixture models parzen windows parzen windows better due unavailability large number training samples 
technique tested images database 
cases mass structures correctly identified novel cases 
unfortunately large number false positives discovered 
similar approach taken 
jet engine fault detection 
input data initially pre processed simpler model distribution input space chosen transformed space 
transform euclidean distance transformed space equal mahalanobis distance original space 
transformation done different methods component wise normalisation whitening transform 
distribution normal vectors transformed space approximated small number spherical clusters selected means clustering algorithm 
cluster radius calculated average distance feature vectors belonging cluster cluster centre 
novelty test thresholding shortest normalised distance test vector cluster centre 
distance nearest cluster mean normalised radius cluster order account varying data densities different regions input space 
test vector sufficiently far cluster centres region space known training samples deemed novel 
novelty threshold set accept training samples 
method tested jet engine fault detection compared parzen windows method previous study tarassenko 
method described slightly outperforms parzen windows component wise normalisation transformation 
parra 
new scheme density estimation 
novelty detection performed finding underlying density training data novel technique 
hyper sphere drawn separate known regions unknown regions 
novel objects ideally fall outside hyper sphere 
appropriate threshold separates known new test objects 
strength study density estimation technique non linear distributions distributions priori information available 
factorization joint probability distribution formulated minimal mutual information criterion constraint volume conservation 
volume conservation implemented symplectic maps 
gaussian upper bound leads computationally efficient optimisation technique turn facilitates density estimation 
method tested motor fault detection 
data high dimensional combination linear pca symplectic maps reduce dimensionality 
novelty detection method gave slightly better results compared various methods including mlp rbf nearest neighbour 

method novelty detection probabilistic framework applied tasks limited amount training data available 
important dimensionality data kept relatively small order probability model estimated number inputs significantly larger number dimensions 
small number samples training set gmm 
normalising transformation applied training data small number spherical basis functions fitted transformed data 
authors normalising methods component wise normalisation whitening transformation 
placement basis functions done means algorithm euclidean distance transformed space 
novelty detection average distance data vectors corresponding basis function training data computed 
novelty test vector assessed computing shortest normalised distance kernel centre 
locally defined measure novelty distance nearest kernel normalised average distance data kernel 
validation set set novelty threshold set novel point training set 
method tested fault detection task jet engine 
component wise normalisation gives better results recognising previously unseen normal engine data whitening transform slightly better recognising abnormal data 
authors suggest monte carlo simulation generate synthetic data facilitate estimating data density training data samples 
tax duin describe methods rejecting outliers data density distribution 
data objects low probability areas rejected methods barnett louis bishop tarassenko 
techniques different methods computing data density mixtures gaussians parzen windows nearest neighbour estimator 
methods novelty detection compared method classifier instability introduced study 
mixtures gaussians method parzen windows density distribution training data 
difference new object mean training objects larger standard deviations training distribution new object rejected 
nearest neighbour method slightly different approach followed find probability density 
distance new object nearest neighbour training set distance nearest neighbour nearest neighbour training set 
quotient second distance taken indication novelty object 
new method novelty detection introduced classifier instability 
linear classifier maximizing fisher criterion extending class classifier multiple classes 
take bootstrap samples size original training set train classifiers 
outputs classifiers differ 
variation outputs indicates diversity different training sets 
large variation indicates object hard classify 
variation thresholded 
results show new method outperforms distribution probability methods small training set available 
cases especially abundance training data parzen windows method best 
drawback parzen windows large number samples required proper estimation width parameter needs user set 
gaussian case problem selecting correct number kernels required intuitive 
system tested hand written digits success 
roberts proposes extreme value theory evt novelty detection concerns abnormally low high values tails data distributions 
data observed value extreme data changes 
knowledge statistics useful tasks novelty detection outlier removal rejecting classification regression patterns lie away expected statistics training data set 
lot done previously area datasets known pure datasets contain patterns class 
bishop tarassenko parra tarassenko brotherton 
methods cases data normal case abundant easily obtainable examples abnormal case rare expensive obtain medical fault detection domains 
methods sensitive cases normal case contains examples abnormal class 
examples classification influence density distribution estimation normal class fitting abnormal data making detection abnormal cases problematic 
evt forms representations tails distributions 
fisher showed distribution function data point stable number samples tends infinity weakly converge positive affine transform 
second key theorem fisher states distribution non degenerate limit distribution normalised maxima take forms 
forms referred gumbel distribution roberts 
research ultimately concerned samples drawn distribution maxima distribution converges gumbel form 
distribution gives probability observing extreme value parameters determined monte carlo simulation 
gaussian mixture model gmm estimate distribution data evt probability directly evt distribution derived range data gmm fitted 
component closest data point concerned mahalanobis sense calculate evt probability dominates evt statistics 
em algorithm estimate parameters gmm minimum length coding penalize models higher complexity 
technique tested epilepsy dataset objective discriminating normal abnormal behaviour noise removal task image salt pepper noise 
technique exhibited performance tasks need setting novelty thresholds plague techniques statistical novelty detection 
yamanishi 
ss outlier detection system viewpoint statistical learning theory works data mining detect fraud network intrusion network monitoring 
focused outlier detection unsupervised learning information source 
time datum input required evaluate large datum deviated compared normal pattern 
ss uses probabilistic model representation underlying mechanism data generation 
probability density domain categorical variables histogram finite mixture model employed histogram cell represent probability density domain continues variables 
time datum input line learning algorithm employed update model 
authors developed sequentially discounting laplace estimation learning histogram density categorical domain sequentially discounting expectation maximising learning finite mixture continues domain 
ss gives score datum basis learned model indicating model changed learning 
high score means datum outlier 
authors novel features ss include fact ss adaptive non stationary data 
useful cases drifting sources time series data tackled 
added score calculated ss clear statistical information theoretic meaning 
works heuristics cost distances mahalanobis describe outliers ss defines score datum model shifted learning 
ss computationally inexpensive deal categorical continues variables 
system successfully tested network intrusion database kdd cup 
spence 
independently developed class models probability distributions images called hierarchical image probability hip models 
hip constructs tree structured graph dependencies hidden variables different scales uses mixtures multivariate gaussians model local distributions vectors features 
hidden variables similar markov random fields mrf 
method applied mammographic images reject contain regions set normal images training data 
due tree structure belief network hidden variables relatively straightforward train em algorithm 
expectation step performed directly 
expectation weighted probability label parent child pair labels image 
expectations computed normal distribution step tractable 
detecting novel examples useful cad system generating confidence measures cad output identifying data useful training model 
hip model generative structure enables novel examples identified thresholding log likelihood models 
system tested mammography images extensive results shown comparison competing systems 
addition authors explain novelty threshold selected critical system performance 
statistical approaches dealing novelty detection modelling density training data rejecting test patterns fall regions low density 
order techniques training data needs free outliers outliers known 
common data descriptor gaussian mixture model gmm 
lauer detail method works training data corrupted unknown number outliers 
approach robust outliers tolerate small number training data 
calibrate algorithm classified validation patterns needed rough estimate proportion outliers training data 
start presumption training data contains small number outliers 
model pattern distribution composition big percentage normal patterns small proportion corrupted patterns 
proportion anomalous patterns distribution normal patterns po distribution anomalous patterns distribution training set pn po value interpreted prior probability outlying patterns modelling called mixture alternative 
learning task decomposed steps estimate training data decompose decide outlier probabilities prior 
second step difficult knowledge anomalous patterns number 
addition distribution po estimated reliably due small number outliers training data 
second step performed directly assumption distribution proportion estimated basis 
estimation pn equivalent determination distribution parameters 
usage gmm considered em algorithm employed estimate parameters 
approach run different values 
parameter optimised resample expected proportion outliers 
respect interpreted parameter algorithm controls sensitivity anomalous patterns 
system tested artificial datasets various complexities real database medical data patients carrying rare diseases 
results compared traditional approach novelty detection data densities providing outliers training set 
approach outperforms traditional approach 
austin describe novelty detection method gaussian mixture models gmm sensor fault detection 
structural health monitored analysing frequency occurrence matrix foom produced flight 
unfortunately get corrupted time corrupted need filtered 
classes sensor fault 
random addition counts second shift response sensor load monitors 
noise distortion independent nature flight 
search noise mean variance cell 
setting threshold possible count number cells value gaussian measure probability 
suitable threshold set experimentally 
second problem necessary reduce dimensionality input data 
authors eigenface algorithm achieve reduction 
dimensionality training data reduced authors model distribution foom data gaussian basis function neural network 
em algorithm estimate parameters gmm 
gmm provides probability density function forms basis novelty measure useful scale value lies 
threshold placed reject patterns low probability belonging mixture model 
experimental results showed performance rejecting faulty large number healthy rejected 
authors state probably due high variability strain events flights 
anticipated addition data correct problem 
novelty detection textual data applications generated considerable interested past baker 
topic detection tracking tdt novelty detection variant traditional classification problem allow classification new classes 
tdt new topics emerge means classifier expand classes continuously 
authors cluster unlabelled documents multinomial na bayes classifier estimating parameters em algorithm 
estimated probabilities classify unlabelled documents known classes novel class 
novelty detection task parameter estimation newly identified classes unreliable due complete lack data 
authors propose agglomeration classes hierarchy node formed recursively pooling data children 
shrinkage improve estimates 
shrinkage linearly interpolates parameter estimates leaf hierarchy parameter estimates leaf ancestors 
alternative em algorithm authors deterministic annealing da clustering 
da probabilistic informationtheoretic principles build hierarchy avoids poor locally optimal solutions trap em algorithm 
constraining entropy implicitly smooth surface em hill climbing reducing number local optima em get trapped 
build hierarchy algorithm starts infinite temperature matter classes em assume parameter estimates converge value 
effectively class root hierarchy 
temperature lowered system undergoes phase transitions effective number clusters grows splitting node hierarchy children 
approach extended line novelty detection assuming hierarchy obtained existing data priori knowledge determining subsequent document report topic 
document new nodes document labelled new 
similarly hansen 
discuss role gaussian mixture modelling textual data novelty detection 
main purpose study demonstrate known techniques signal data analysis textual information 
hidden markov models hmm hmms stochastic models sequential data duda 
hmm contains finite number unobservable hidden states 
state transitions governed stochastic process form markov chains 
state state dependent events observed 
emission probabilities observable events determined probability distribution state 
estimate parameters hmm modelling normal system behaviour sequences normal events collected normal system operation training data 
expectationmaximization em algorithm estimate parameters 
hmm trained confronted test data probability measures thresholded novelty detection 
yeung 
describe hmms novelty detection application intrusion detection profiling system call sequences shell command sequences computer security 
main approaches 
hidden markov models hmm 
trained hmm sample likelihood observed sequence respect model computed forward backward algorithm 
threshold probability discriminate normal abnormal behaviour 
second technique simpler 
probability distribution normal system behaviour observed time modelled 
simple occurrence frequency distribution purpose 
behaviour system monitored modelled way 
information theoretic measure known measure dissimilar distributions 
threshold determine observed behaviour abnormal 
validation set determine threshold 
case hmm threshold chosen minimum likelihood training sequences 
second model cross entropy value computed entire training set trace training set 
threshold chosen maximum cross entropy 
information theoretic technique outperformed hmm approach experiments 
hmm model better suited intrusion detection system calls 
hypothesis testing simple statistical technique novelty detection determining test sample comes distribution training data 
approach test find damaged beams 
approach described starts measurements nf natural vibration frequencies structure virgin stage soon structure built 
periodically take measurements natural frequencies test compare 
test shows significant difference sets measurements damage 
approach tested case study involving continuous beam 
experimental data damaged beam obtained running finite element program cracks simulated 
test performed significance levels showed promising results 
non parametric approaches non parametric approaches assumption statistical properties data 
consider approaches nearest neighbour density estimation parzen density estimation string matching approaches 
knn approaches nearest neighbour algorithm technique estimating density function data addison 
technique overcomes problems parzen window require smoothing parameter 
width parameter set result position data point relation data points considering nearest patterns training data test pattern 
problem technique large sized datasets large number computations performed 
novelty detection distribution normal vectors described small number spherical clusters placed nearest neighbour technique 
novelty assessed measuring normalised distance test sample cluster centres 
number studies approach novelty detection detailed 
hellman nearest neighbour nn classifier rejecting patterns higher risk misclassified 
spirit chow threshold posteriori probabilities bayes optimum recognition system rejecting patterns low probability 
chow assumed data priori probabilities conditional probability density known 
practical applications statistics unknown inferred set labelled examples 
advantage approach assumptions concerning underlying statistics 
cover hart shown number training samples tends infinity nearest neighbour risk greater twice bayes risk regardless underlying statistics 
hellman explained single nn information reject samples 
information necessary considering nns 
come class pattern classified rejected 
hellman showed going single nn new rule increase reject rate twice decrease probability error 
errors twice costly rejects new rule lower total cost single nn rule 
rule extended examine nns classify neighbours agree 
approach conservative author proposed alternative examine nns neighbours agree classify test pattern reject 
said author claim novelty detection approach merely method rejecting patterns high misclassification risk 
novelty detection novel classes induce high confusion classifier novel classes erroneously classified training classes 

novelty detection method applied rotor fault detection 
training data subjected simple outlier removal ensure 
pattern lies standard deviations average removed set 
novelty detection surface imposed set healthy signals 
new signal falls outside surface deemed novel 
surfaces placed healthy points include spherical boundary elliptical boundary rectangular boundary formed extrema data min max surface nearest neighbour boundaries 
methods new pattern compared centre hyper sphere euclidean distance ellipse mahalanobis distance 
min max technique smallest possible box containing healthy data 
dimensions box determined minima maxima signature signals 
nearest neighbour novelty detector allows general data topology 
minimum euclidean distances point closest neighbour 
distance proportional maximum distances decision parameter 
incoming point compared point healthy set 
new point greater distance healthy points decision parameter novelty declared 
radius hyper sphere ellipse controls trade novelty detection false alarms 
similarly ball drawn training point nearest neighbour method minmax parameters hyper box methods increase method sensitivity novelty 
experimental results showed elliptical surface suitable novelty detection 
number techniques model density training data novelty detection 
barnett louis bishop tarassenko parra tax duin brotherton tarassenko yeung chow 
requires large number samples overcome curse dimensionality 
fact novelty detection techniques require large amount data form normal class especially high dimensions 
simplest model just little amount data available unimodal normal distribution 
tax duin suggest modelling probability density data unimodal normal distribution threshold probability density accepting data placing threshold mahalanobis distance 
modelling complete probability density indication obtained comparing distances 
method local density test object nearest neighbour training set 
distance test pattern nearest neighbour training data distance neighbour nearest neighbour 
quotient distances indication novelty 
euclidian distance purpose 
method useful distributions relatively fast decaying probabilities 
techniques tested real artificial data useful little amount training data exist samples feature 
jiang 
propose phase clustering algorithm outlier detection modified means algorithm minimum spanning tree mst 
means algorithm modified calculate minimum distance pair cluster centres 
distance pattern closest cluster larger distance pattern assigned new cluster 
extreme case pattern form cluster upper limit kmax defined 
kmax reached nearest clusters merged 
cluster centres defined modified means algorithm regarded nodes form mst distance nodes 
mst constructed longest edge tree removed forest replaced newly obtained sub trees 
small clusters tree number nodes selected regarded outliers 
different datasets compare technique traditional means clustering algorithm 
experiments new technique outperformed baseline techniques tested 
datasets include iris data sugar cane breeding data mail log data 
yang liu describe approaches novelty detection document classification linear squares fit llsf nearest neighbour nn classifier approach 
nn algorithm simple 
nearest neighbours test pattern training set 
categories nearest neighbours weight category candidates 
similarity score neighbour weight 
neighbours share category neighbour weights category added resulting weighted sum likelihood score category respect test pattern 
threshold set cross validation applied determine test pattern sufficiently novel rejected 
llsf multivariate regression model automatically learnt training data categories 
solving linear squares fit training pairs input output vectors obtain matrix regression coefficients 
solution matrix defines mapping arbitrary pattern vector weighted categories 
sorting category weights ranked list categories obtained pattern 
thresholding category weights category assignments obtained 
category specific threshold determined crossvalidation 
minimum threshold imposed novelty detection pattern rejection 
yang 
describe simple novelty detection method applied document classification 
training data old events learn useful statistics prediction new novel events 
approach consists steps classifying documents broad topics consists multiple events identifying named entities optimising weight relative normal words topic computing word list topic 
measure novelty new document conditioned system predicted topic document 
algorithm simple 
new document arrives compared documents available 
nearest neighbour past cosine similarity score threshold document labelled novel meaning story novel event labelled old added history 
threshold set cross validation 
algorithm works levels 
level classifier determines broad topic arrived document second level novelty detector decides document describes new event old event 
method applied benchmark document database showed performance 
technique simplistic probably fail domains exhibit high complexity various objects 
interesting approach novelty detection 
parzen density estimation parzen windows method duda non parametric data density estimation 
yeung chow follow established novelty detection approach estimating density training data rejecting patterns similar bishop tarassenko parra tax duin brotherton tarassenko 
authors apply technique intrusion detection problem 
authors chosen gaussian kernel functions reasons 
gaussian function smooth density estimation varies smoothly second radially symmetrical gaussian assumed function completely specified variance parameter 
novelty threshold set separate training set called threshold determination set applied unconditional probability test pattern modelled distribution 
technique tested dataset kdd cup 
string matching approaches string matching approaches treating training data templates represented string vector features computing measure dissimilarity training test data 
forrest 
method solving problem distinguishing self nonself change detection algorithm way natural immune system achieves task 
self data converted binary format forming collection large number random strings generated forming set 
strings matched strings match eliminated 
perfect matching extremely rare matching criterion relaxed consider contiguous matches strings 
created new patterns converted binary matched 
match new pattern belongs non self rejected 
number experiments performed designed test various aspects detection system 
system tested network intrusion tasks perform extremely 
extension provided dasgupta forrest dasgupta biologically inspired computing concepts 
bodies novelty detection carried cells receptors surface detect foreign proteins 
body releases large number cells allows match body cells circulate 
cell matches cell body cell deemed foreign dealt 
novelty detection technique works similar way 
sufficient subset training data taken analogue values discrete sampling 
point assigned integer value converted binary form 
large set strings called detectors generated match strings obtained training data 
new data point encoded matches detectors deviation normal system behaviour evaluated treated novel data 
matching performed matching threshold sets number bits match strings deemed similar 
major concern identified authors system matching threshold 
data specific correct setting essential satisfactory system performance 
larger detectors sensitive novelty data small result reasonable size detector set 
technique tested tool breakage detection results average runs showed performance detecting abnormal behaviour 
area extends previous studies dasgupta gonzalez 
extends idea previous dasgupta forrest dasgupta multi class approach 
specifically non self unknown space classified multiple subclasses determine level abnormality 
technique implemented computer intrusion task 
anomaly detection system acceptable assumption normal operation system characterized series observations time 
normal system behaviour generally exhibits stable patterns observed period time 
common ground fault detection systems including proposed tarassenko japkowicz dasgupta forrest tarassenko campbell bennett 
dasgupta gonzalez na approach task determine minimum maximum values monitored parameters measure abnormality deviation values 
approach consider fact normality dependent time values acceptable time acceptable different time 
added notion normality depends correlation interaction various parameters features 
sliding window pattern characterization normal behaviour system represented subspace called self compliment non self 
approaches described fault detection positive characterization negative characterization 
positive characterization nearest neighbour technique records euclidean distance test vector nearest neighbour self subspace 
user set value determines allowable variability self subspace 
distance exceeds value vector deemed abnormal 
technique implemented kd tree faster querying 
negative characterization approach tune dasgupta forrest dasgupta implemented genetic algorithms gas build representation non self subspace self subspace input 
gas evolve rules cover non self subspace shape self non self subspaces known priori patterns belong self approximate subspaces 
genetic algorithm attempts evolve rules cover non self space 
goodness rule determined various factors number normal samples cover space area overlap rules 
multi objective multi modal optimisation problem 
objective find single solution number solutions cooperatively solve problem 
covering non self space accomplished set rules necessary evolve multiple rules 
sequential niching algorithm employed evolve different rules 
system operation test vector falls non self space deemed abnormal 
techniques tested compared computer intrusion detection system 
data obtained mit lincoln lab 
attack free data training system tested systems 
negative characterization approach clearly efficient time space compared positive characterization positive characterization exhibited precise results 
dasgupta majumdar extend studies multi dimensional data 
technique proposed identical described previous papers multidimensional data passed pca dimensionality reduction discarding features accounted variability selecting dimensions 
dimensions binary encoded studied binary strings gray coded 
system tested network anomaly detection task results obtained anomalies went undetected 
clustering approaches clustering approaches aimed partitioning data number clusters data point assigned degree membership clusters 
degree membership thresholded suggest data point belongs cluster novelty detected sample belongs available classes 

describe evident data analysis software quickly detecting investigating visualizing novel events set images evolve time frequency 
follows earlier research 

instance magnetic resonance novelty may manifest neural activations time course 
conventional data analysis methods assume model requisite function available example brain response designed cognitive motor stimulus validity model tested statistical methods inference 
case neuroscience researchers probing brain function increasingly complex cognitive experiments 
complexity demands model validation approach versatile adaptive data driven model free 
novelty detection prime candidate solving problem 
evident clusters time courses volumetric data enhanced variant bezdek fuzzy means algorithm bezdek 
time courses separated way intra cluster distance minimized simultaneously maximizing inter cluster distances 
fuzzy index controls fuzziness cluster portions approaches fuzzy means algorithm converges classical hard means algorithm 
approaches cluster centroids tend centroid time courses 
fuzzy means opposed classical means algorithm dictated ability avoid getting stuck local minima objective function tries optimise 
fuzzy cluster analysis produces cluster membership map anatomical slice volumetric data 
membership map image representing degree membership active voxel cluster 
thresholding membership map voxels belong cluster userspecified level membership identified 
yang 
attempt automatically detect novel events temporally ordered stream news stories retrospectively stories arrive 
objective identify stories continuous news streams belong previously unidentified events 
done line fashion events occur accumulated collection 
retrospective event detection stories grouped cluster uniquely identifies event 
line event detection document labelled arrives sequence new old flag indicating document story discussing novel event 
clustering approaches investigated agglomerative hierarchical algorithm group average clustering gac single pass algorithm incr generates non hierarchical partition input collection 
appropriate retrospective event detection 
story represented vector weighted terms 
normalised vector sum documents cluster represent cluster called prototype centroid 
standard cosine similarity measure describe similarity cluster centroid document 
gac agglomerative algorithm maximizes average similarity document pairs resulting clusters 
iteration divides current set clusters buckets local clustering bucket 
process repeated generates clusters higher higher levels predefined number clusters obtained 
input algorithm set documents output forest cluster trees number trees specified user 
clusters produced growing binary tree bottom approach 
novelty detection case single pass clustering 
algorithm sequentially processes input documents time grows clusters incrementally 
new document classified similar cluster similarity exceeds predefined threshold seed new cluster 
adjusting threshold obtain clusters different levels granularity 

survey novelty detection statistical approaches 
research driven modelling data distributions estimating probability test data belong distributions 
model approaches need specify assumptions nature training data 
addition amount quality training data important robust determination training data distribution parameters 
statistical approaches cheap compute straight forward explanation techniques 
main competition novelty detection task comes variety neural networks discuss successive 

baker hofmann mccallum yang hierarchical probabilistic model novelty detection text technical report 

barnett lewis outliers statistical data john wiley 

bezdek ehrlich full fcm fuzzy means clustering algorithm computers geosciences vol 
pp 


bishop novelty detection neural network validation proc 
iee conference vision image signal processing pp 


brotherton johnson classification novelty detection linear models class dependent elliptical basis function neural network proc 
ijcnn conference anchorage may 

campbell bennett linear programming approach novelty detection advances nips vol 
mit press cambridge ma 

carpenter rubin artmap fd familiarity discrimination applied radar target recognition proc 
international conference neural networks vol 
iii pp 


chow optimum recognition error reject tradeoff ieee transactions information theory vol 
pp 
january 

de stefano method improving classification reliability multilayer perceptrons ieee transactions neural networks vol 
pp 


cover hart nearest neighbor pattern classification ieee transactions information theory vol pp 


jacob cooper applications probability density estimation detection abnormal conditions engineering proc 
institute mechanical engineers vol 
pp 


dasgupta gonzalez approach intrusion detection division computer science university memphis tech 
report cs 

dasgupta forrest novelty detection time series data ideas immunology proc 
international conference intelligent systems reno nevada 

dasgupta comparison negative positive selection algorithms novel pattern detection proc 
ieee international conference systems man cybernetics vol 
pp 


dasgupta majumdar anomaly detection multidimensional data negative selection algorithm proc 
ieee conference evolutionary computation pp 
hawaii may 

duda hart stork pattern classification wiley 

elad hel keshet rejection classifier face detection pattern recognition letters vol 
pp 


fisher limiting forms frequency distribution largest smallest member sample proc 
camb 
phil 
soc 


reject criteria bayesian combiner pattern recognition vol 
pp 


forrest perelson allen self non self discrimination computer proc 
ieee symposium research security privacy pp 
oakland ca may 

roli reject option multiple thresholds pattern recognition vol 
pp 


line control chart pattern detection discrimination neural network approach artificial intelligence engineering vol 
pp 


marks ii el elliptical novelty grouping online short turn detection excited running ieee transactions energy conversion vol 
march 

hansen salamon error reject tradeoff open systems information dynamics vol 
pp 


hansen nielsen larsen modeling text generalizable gaussian mixtures proc 
ieee icassp vol 
pp 


hellman nearest neighbour classification reject option ieee transactions systems science cybernetics vol 
pp 
july 

austin neural networks novelty detection airframe strain data proc 
ieee ijcnn 

japkowicz myers gluck novelty detection approach classification proc 
th ijcai conference montreal pp 


jiang tseng su phase clustering algorithm outliers detection pattern recognition letters vol 
pp 


king king tarassenko hayton novelty detection techniques monitoring high integrity plant proc 
international conference control applications vol 
pp 


knorr ng distance outliers algorithms applications vldb journal pp 


lauer mixture approach novelty detection training data outliers luc de raedt peter flach eds proc 
th european conference machine learning pp 
springer 

informal identification outliers medical data intelligent data analysis medicine pharmacology berlin august 

network intrusion fault detection statistical anomaly approach accepted publication ieee communications magazine october 

pierce worden guy atherton long term stability normal condition data novelty detection proc 
th international symposium smart structures materials california 

pierce worden long term stability normal condition damage detection composite panel proc 
th international conference damage assessment structures cardiff uk june 

identifying damage sensitive environment insensitive features damage detection proc 
ies conference swansea uk 

corbett clark ripley townsend tarassenko choosing appropriate model novelty detection proc 
th iee international conference artificial neural networks cambridge pp 


townsend carr king cowley tarassenko system analysis jet engine vibration data integrated computer aided engineering vol 
pp 


addison novelty detection neural network technology proc 
conference 

parra deco statistical independence novelty detection information preserving non linear maps neural computation vol 
pp 


evident functional magnetic resonance image analysis system artificial intelligence medicine vol 
pp 


roberts tarassenko probabilistic resource allocating network novelty detection neural computation vol 
pp 


roberts novelty detection extreme value statistics iee proc 
vision image signal processing vol 
issue pp 


roberts extreme value statistics novelty detection biomedical signal processing proc 
st international conference advances medical signal information processing pp 


statistical approach damage detection vibration monitoring proc th pan american congress applied mechanics puerto rico 

saunders gero importance emergent proc 
artificial intelligence design 

detection novelty functional images fuzzy clustering proc 
rd meeting nice france 

singh approach novelty detection applied classification image regions ieee transactions knowledge data engineering press 

spence parra detection synthesis compression mammographic image analysis hierarchical image probability model ieee workshop mathematical methods biomedical image analysis pp 


stefano reject reject question answer case neural classifiers ieee transactions systems man cybernetics part ieee comp 
press new york vol 
pp 


pattern recognition proc 
congress evolutionary computation cec vol 
pp 


tarassenko novelty detection identification masses mammograms proc 
th iee international conference artificial neural networks vol 
pp 


tarassenko townsend cowley novelty detection jet engines iee colloquium condition monitoring imagery external structures health pp 


tax duin outlier detection classifier instability advances pattern recognition joint iapr international workshops pp 


tax duin data description subspaces international conference pattern recognition vol 
barcelona 

webb statistical pattern recognition arnold 

wei miller stolfo wenke chan artificial anomalies detect unknown known network intrusions proc 
ieee international conference data mining icdm pp 


yamanishi takeuchi williams 
line unsupervised outlier detection finite mixtures discounting learning algorithms proc 
th acm sigkdd international conference knowledge discovery data mining pp 
boston ma usa august 

yang pierce carbonell study retrospective line event detection proc 
acm sigir conference research development information retrieval pp 


yang liu re examination text categorization methods proc 
acm sigir conference research development information retrieval pp 


yang zhang carbonell jin topic conditioned novelty detection international conference knowledge discovery data mining july 

yeung ding host intrusion detection dynamic static behavioral models pattern recognition vol 
pp 


yeung chow parzen window network intrusion detectors proc 
international conference pattern recognition 

