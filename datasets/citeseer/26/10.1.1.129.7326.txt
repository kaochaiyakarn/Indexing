general framework mining concept drifting data streams skewed distributions jing gao wei fan jiawei han philip yu university illinois urbana champaign ibm watson research center uiuc edu cs uiuc edu ibm com years interesting studies predictive modeling data streams 
studies assume relatively balanced stable data streams handle skewed positives lots negatives stochastic distributions typical data stream applications 
propose new approach mine data streams estimating reliable posterior probabilities ensemble models match distribution samples negatives repeated samples positives 
formally show interesting important properties proposed framework reliability estimated probabilities skewed positive class accuracy estimated probabilities efficiency scalability 
experiments performed synthetic real world datasets skewed distributions demonstrate framework substantial advantages existing approaches estimation reliability predication accuracy 
real applications network traffic monitoring credit card fraud detection web click stream generate continuously arriving data known data streams 
classification help decision making predicting class labels data past records classification stream data extensively studied years interesting algorithms developed :10.1.1.14.4071
open problems stream classification illustrated 
descriptive non parametric generative parametric methods major categories stream classification algorithms 
existing algorithms simply choose explained supported part national science foundation nsf iis nsf bdi 
descriptive model chosen vice versa 
second stream classification algorithms focus mining concept drifting data streams recognize concept drift change conditional probability class feature vector reality observe changes joint probability hard tell changes caused changes 
third algorithms predict class label test example 
may deterministic problems reasonable stochastic application previously deterministic problem evolving stochastic 
compared deterministic problems example strictly belongs class stochastic processes assign labels test examples probability distribution 
scenario model generate accurate probability estimates preferred 
important issue existing stream classification algorithms typically evaluate performances data streams balanced class distribution 
known inductive learning methods performances balanced data perform poorly skewed data sets 
fact skewed distribution seen data stream applications 
cases positive instances popular negative instances 
example online credit card fraud rate just 
hand loss functions associated classes unbalanced 
cost misclassifying credit card fraud normal impose thousands dollars loss bank 
deficiency inductive learning methods skewed data addressed people :10.1.1.58.7757:10.1.1.28.9570
inductive learner goal minimize classification error rate completely ignores small number positive examples predicts example negative 
definitely undesirable 
light challenges provide sys analysis stream classification problems general 
formally define kinds concept changes stream data show effective method equally cases 
argue descriptive model approximate posterior probability desirable real stream classification problems 
observations applicable different scenarios particularly interested skewed stream mining problem important problem existing methods handle 
main contributions follows 
concept drift data streams formally defined analyzed 
show expected error rate directly related concept drift reduced training model date data 

analyze important stream classification problems systematically 
comparing descriptive models generative models label prediction probability estimation draw concept drifting stream mining descriptive model generate high quality probability estimates best choice 

propose effective efficient algorithm classify data streams skewed class distribution 
employ sampling ensemble techniques algorithm show strengths theoretically experimentally 
results clearly indicate proposed method generates reliable probability estimates significantly reduces classification error minority class 
rest organized follows 
section analyzes different kinds concept drifts discusses important problems stream classification 
section introduce ensemble approach mining skewed data streams demonstrate advantages theoretical analysis 
experimental results ensemble approach section 
related section followed section 
inductive learning concept drifting data streams section point unattended problems stream classification provide thorough analysis problems possible concept changes model inductive learning posterior probability estimation 
concept drifting data streams section describe different kinds concept changes discuss error rate changes result 
assuming true probability distribution expected error model err yp dx yp predicted class label chosen equal loss 
note refers estimated probability model different true conditional probability 
ym examples yp ym rooms improvement 
concept drift best described changes 
composed feature probability class label conditional probability change joint probability better understood changes components 
possibilities discussed 
case demonstrate building new model data help reduce err 
define data data held memory current time continuously arriving stream data 
optimal update model data matter concepts evolve 
change case remain 
definition expected error change 
useful train model data old model may achieved minimum examples yp ym due reasons original training data sufficient incurs variance model prediction 
feature change feature change happens changes remains 
words previously infrequent feature vectors frequent vice versa 
changes expected error may move move stay depends specific combination corresponding values 
model reconstruction improve estimated probability examples yp ym past due small number training examples 
conditional change remains changes 
condition minimum expected error rate integrated instances go way 
reason error individual feature vector dependent increase decrease remain 
expected error indicator conditional change 
evolves normally necessary reconstruct model 
consider problem rebuild model match new conditional probability 
size new data large train accurate new model old examples expected help due concept evolution 
new data trivial size error model trained new data mainly comes variance training data help reduce variance 
existing approaches solve problem weighted combination old examples selection consistent old examples 
dual change change 
depending combination expected error increase decrease remain unchanged indicate dual change 
similar conditional change evolved normally necessary train new model 
summary main observations hypothetical analysis 
isn general correlation expected error previous model types concept drifts data stream 
observing changes expected error reliable indicator concept drift 
hand expected error previous model change usually room improvement proper model reconstruction 
effective stream mining algorithm shall assume particular type concept drift ought assimilate new data soon possible consistently produce highly accurate models 
stream data skewed distribution hard handle may examples minority class new data 
discuss problem section 
descriptive model vs generative model stream classification methods generally fall categories generative descriptive 
generative methods naive bayes logistic regression assume follows certain form distributions parameters estimated training set 
hand descriptive methods decision tree little assumptions true form 
structure parameters hypothesis learnt training set 
applying real data descriptive models expected accurate generative models 
stream applications little prior knowledge data distribution hard predefine true form 
form distribution may evolve data continuously arrives 
example underlying distribution may change gaussian beta 
reality know underlying form changes 
risky assume certain kind distribution data 
usually wrong assumption distribution form lead poor performances generative models 
second training data may balanced 
real applications class distribution highly skewed insufficient examples minority class 
typically non parametric models require larger amount data parametric models 
hard learn parameters accurately limited examples 
training examples far sufficient parametric model overfit data low generalization accuracy 
descriptive methods provide favorable solution stream classification problems 
building descriptive model require prior knowledge form data distribution 
data speaks 
matter underlying distribution changes descriptive model easily adapted new distribution 
probability estimation vs label prediction ways classify test examples 
directly classify categories predict class labels 
approach estimate choose best threshold optimize criteria 
favor second approach reasons 
typically known advance problem deterministic stochastic domain knowledge previously deterministic problem may evolve stochastic 
labels observe stochastic problems deterministic follow certain distribution 
specific feature vector may appear training data class label imply belongs class example assigned classes different probabilities 
example chance precipitation probability rain falls 
case estimation reasonable predicting class labels 
second predicted labels may accurate 
categorizing example wrong class invoke huge amount loss cases 
probability estimates hand provide information uncertainties classification 
ensure accuracy probability estimates calibration smoothing methods 
high confidence prediction example posterior probability sure prediction example estimated posterior probability 
uncertainty information useful decision making 
estimation posterior probability provides flexible analysis scheme 
subjective objective criteria applied probability estimates find optimal decision threshold 
example threshold chosen resulting precision recall balanced 
summary argue real world stream classification problems descriptive model output accurate probability estimates preferred 
main reason covers situations data streams methods aware 
desiderata argued concept drift happen sub component joint probability distribution data stream expected error reliable indicator mining new data chunk expected improve accuracy situations descriptive model preferred generative model general purpose stream mining wide variety problems estimating probability suitable strong assumption unknown true probability distribution 
observations applicable situations predictive mining data streams rest extend ideas design evaluate general framework mine skewed concept drifting data streams 
mining skewed data stream section propose simple strategy effectively mine data streams skewed distribution 
choice methods incorporates analysis section 
provide formal analysis aspects proposed framework 
stream ensemble framework skewed distribution seen data stream applications 
cases positive examples popular negative ones 
misclassifying positive example usually invokes higher loss compared misclassifying negative example 
traditional inductive learner tends ignore positive examples predict example negative undesirable skewed stream mining 
handle skewed class distribution propose simple systematic method applies deterministic stochastic data streams 
start problem definition algorithm 
applications credit card application flow incoming data stream arrives sequential chunks sm size sm date chunk 
data chunk arrives sm simplicity denote aim stream classification train classifier data arrived far estimate posterior probabilities examples assume data comes classes positive negative classes number examples negative class greater number positive examples 
words 
class problem posterior probability positive class computed negative class simply 
accurate probability estimation propose utilize sampling ensemble techniques framework 
sampling 
split chunk parts contains positive examples contains negative examples size smaller example network intrusion detection data normal examples attacks 
noted stochastic problems appear times 
count class contribute calculation posterior probability 
stream mining data chunks training data 
stream data huge amount usually impossible store 
second stream mining requires fast processing huge training set classification process extremely slow unsatisfactory 
section show model reconstruction new data reduces expected error 
words best way construct model build data chunk 
works examples negative class examples dominate data chunk sufficient training accurate model 
positive examples far sufficient 
inductive learner built chunk perform poorly positive class 
enhance set positive examples propose collect positive examples keep training set 
specifically positive examples training set 
pm 
hand randomly sample negative examples data chunk qm class distribution balanced 
strategy quite simple effective skewed classification shown section 
ensemble 
training single model training set propose generate multiple samples training set compute multiple models samples 
advantage ensemble accuracy multiple model usually higher single model trained entire dataset 
error inductive learner comes bias variance 
shown section variance reduced training multiple models 
samples uncorrelated possible base classifiers uncorrelated errors ensemble algorithm input current data chunk test data number ensembles distribution ratio set positive examples ap output updated set positive examples ap posterior probability estimates examples algorithm 
split definitions 

update ap ap 
calculate number negative examples sample nq values np 

draw sample size nq replacement 
train classifier ci ap 
compute posterior probability estimates ci 
compute posterior probability estimates combining ensemble outputs eq 

ensemble algorithm framework eliminated averaging 
get uncorrelated samples negative example training set randomly propagated exactly sample negative examples samples completely disjoint 
positive examples propagated sample 
take parameter input ratio positive examples negative examples sample 
typically distribution balanced 
np number positive examples training set number negative examples sample nq np 
suppose samples generated series classifiers 
ck trained samples 
classifier ci outputs estimated posterior probability fi example simple averaging combine probability outputs models worth noting differs bagging bagging bootstrap samples training sets bagging uses simple voting framework generates averaged probability test example 
outline algorithm 
assume data chunk fit main memory 
analysis ensemble framework explain sampling ensemble techniques contributes error reduction 
analyze complexity algorithm 
error decomposition expect trained classifier approximate posterior class distribution 
estimate posterior probability necessarily true probability 
classification bayes error remaining errors decomposed bias variance 
bias measures difference expected probability true probability variance measures changes estimated probabilities varied training sets 
stated output classifier expressed fc posterior probability class input bias introduced classifier variance classifier input class problem assigned positive class :10.1.1.14.4071
bayes optimal boundary represented set points satisfy 
fc different estimate bayes boundary incorrect boundary error xb xb estimated boundary points xb xb 
shows classification error rate linearly proportional boundary error 
focus analysis boundary error 
analogy bias variance decomposition described eq 
boundary error expressed terms boundary bias boundary variance xb xb independent trained model independent gaussian distribution zero mean variance normally distributed mean variance error reduction sampling show sampling techniques proposed framework reduces variance skewed data classification 
sampling approach reduce expense increase current data chunk train model positive examples limited error classifier mainly come variance 
proposed framework positive examples previous time shots incorporated training set 
adding positive examples reduce high variance caused insufficient data 
concept changes bias may affected adding old examples may increase slightly 
reason negative examples training set current data chunk assumed sufficient reflecting current concept 
boundary classes biased including old positive examples training set 
bias increasing reduction variance dominant generalization accuracy improved 
error reduction ensemble ensemble reduce variance single classifiers 
eqs 
formula holds average bias variance respectively 
noise error ensemble independent variance eq 
derived boundary variance reduced factor bi proposed framework greatly reduce variance employing sampling ensemble techniques skewed stream classification 
shown experiments improvements gained accuracy significant 
efficiency analysis addition error reduction benefits ensemble single classification model involve efficiency improvements 
suppose base learner decision tree dimension data denoted number positive examples sample np number negative examples nq 
training size sample np nq time complexity decision tree learner np nq log np nq 
ensembles executed sequentially training time multiple model dk np nq log np nq 
train single model data set training size np time complexity np log np 
class distribution sample balanced assume np nq ne 
time complexity single model ensemble represented ne log ne log ne respectively 
number models ensemble typically greater 
log log conclude ensemble efficient single model ensemble executed sequence 
reality classifier ensemble independent computed parallel 
gain efficiency significant parallel ensembles 
experiments conducted thorough experiments synthetic real data sets 
analyze proposed stream ensemble method perspectives proposed method performances matter concept changes series real data sets forms distributions concept changes unknown stream ensemble method propose able provide accurate probability estimates reliable estimation posterior probability method gain great improvements prediction accuracy gains accuracy efficiency improved ensemble framework 
experiment setup synthetic data generation generate synthetic data streams different kinds concept changes 
data form multi dimensional feature vector label example 
describe simulate changes 
form 
follows gaussian distribution mean vector covariance matrix 
feature change simulated change mean vector 
suppose mean th dimension changed isi data chunk 
specifically representing magnitude changes si specifies direction changes reversed probability 
form deterministic problems 
probability having label case 
xi value th dimension ai weight assigned corresponding dimension 
hyperplane characterize boundary classes defined function xi ai 
experiment complicated boundary generate datasets difficult learn 
boundary defined function 
examples satisfying labeled positive examples labeled negative 
weights ai initialized random values range 
set value number positive examples smaller table description data sets data sets classes inst feature rare class inst chunk thyroid class vs class thyroid class vs class opt class vs rest letter class vs rest covtype class vs class negative examples 
skewness ratio control degree skewness 
concept change represented change weight ai 
ai changed data chunk parameters si defined way feature change described 
form stochastic problems 
label stochastically generated sigmoid function model posterior distribution positive class exp skewness controlled deterministic problems 
fact posterior probability belonging positive class 
small examples posterior probability account 
concept changes realized changes weights illustrated deterministic scenario 
generate data chunks size stated section kinds changes feature change conditional change dual change 
changes simulated adjusting parameters described 
distribution data chunk unchanged 
data chunks changes occurs 
real data sets synthetic data series real data sets uci machine learning repository 
data sets directly correspond skewed data mining problems converted rare class problems small class rare class remaining records biggest remaining class second class 
simulate data stream data randomly partitioned chunks skewed distribution maintained chunk 
data sets summarized table 
measures evaluate proposed method perspectives probability estimates accurate 
classification accurate 
standard measures evaluating quality probability estimation 
popular mean squared error defined xi xi xi output ensemble estimated posterior probability xi xi true posterior probability xi 
skewed mining problems rare class interesting usually associated higher classification cost low examples rare class 
skewed mining problems classification error measure examples majority class dominate result hard tell rare examples classified correctly 
kind problems evaluation metrics typically precision detection rate recall false alarm rate 
show metrics correlated roc curve plot demonstrate experimental results 
roc curve represents trade detection rate false alarm rate plots graph axis false alarm rate axis detection rate 
ideal roc curve false alarm rate detection rate 
words area roc curve ideal case 
algorithm produce roc curve close left top corner possible 
area roc curve auc evaluation metric better algorithm auc value closer 
method evaluate results plot correlation recall precision 
recall precision plot precision axis recall axis 
baseline methods section show sampling ensemble techniques help reduce classification error 
baseline methods comparing sampling single model ns 
current data chunk training highly skewed 
single model trained training set 
sampling single model ss 
training set proposed ensemble table mean squared error deterministic stream data changes decision trees se ns ss se naive bayes ns ss logistic regression se ns ss feature conditional dual table mean squared error stochastic stream data changes decision trees se ns ss se naive bayes ns ss logistic regression se ns ss feature conditional dual methods 
obtained keeping positive examples seen far sampling negative examples current data chunk 
difference lies classification model single model method multiple model proposed method 
accordingly denote method sampling ensemble se adopts sampling ensemble techniques 
comparing baseline methods strengths sampling ensemble illustrated 
experiments base learners include parametric non parametric classifiers decision tree naive bayes logistic regression 
implementation weka package 
parameters single ensemble models set default values weka 
empirical results part report experimental results regarding effectiveness efficiency proposed method 
results demonstrate ensemble method improve quality probability estimates positive class classification accuracy terms roc curve recall precision plot efficient training time comparison 
test concept drift streams generate synthetic data streams different kinds concept drifts 
kinds stream data sets generated deterministic stochastic feature conditional dual concept changes 
data set dimensions chunks chunk size 
percentage rare examples data chunk dimensions chosen randomly change 
chunk data set recognized test data data chunks training 
interested probability estimates positive class mean square error positive class reported kind stream data 
results obtained calculating errors randomly generated data sets 
naive bayes logistic regression base learners 
results shown table deterministic table stochastic respectively 
clearly seen matter concept changes proposed method se greatly improves mean square error positive class deterministic stochastic data streams 
decrease error rate significant deterministic data stochastic data average 
ns performs badly current data chunk training highly skewed 
training skewed data set inductive learner build model tends ignore positive examples simply classify example negative 
ns generates error close regarding mean square error positive class 
performances ss mean square error positive class reduced positive examples sample negative examples 
reason class distribution balanced incorporation positive examples 
helps improve performances positive class 
single model high error rate caused classification variance 
se utilizes exactly training sets ss performances se better ensemble reduce variance classifier averaging outputs 
seen tables proposed method mean square error positive class usually 
significant reduction error rate se vs ss se vs ns 
average error decreases sampling reduces sampling ensemble 
observed naive bayes best table mean squared error real data data set decision trees se ns ss se naive bayes ns ss logistic regression se ns ss thyroid thyroid opt letter covtype performance synthetic data set 
due fact synthetic data generated gaussian distribution diagonal covariance matrix guarantees independence features 
conclude proposed method consistently improves posterior probability estimates minority class feature conditional dual concept drifts deterministic stochastic applications 
test real data part conduct experiments real life data sets 
thyroid data set select class class rare class class majority class 
similarly covtype data set biggest class class identified majority class smallest class class corresponds rare class 
data sets letter opt recognition letters digits respectively 
data sets simply choose class represent rare class collapse remaining classes majority class 
way original data sets skewed data sets generated results averaged generated data sets 
table observed proposed method se consistently outperforms ns ss real life data sets 
improvements significant compared synthetic data sets 
probably due learning complexity data sets 
concepts synthetic data sets changed data chunk harder learn 
ns ss unable handle fast changing highly skewed data sets 
balancing training data multiple models improvements se synthetic data apparent 
real data sets concept changes intense error rates ns ss typically respectively 
leaves small space se improve 
se successfully achieves error tenth error generated ns time 
ns ss high error rates se reduce error 
interesting observation base learner globally optimal 
table decision tree base learner se ns ss synthetic synthetic thyroid thyroid opt letter covtype table naive bayes base learner se ns ss synthetic synthetic thyroid thyroid opt letter covtype table logistic regression base learner se ns ss synthetic synthetic thyroid thyroid opt letter covtype decision trees performance thyroid letter naive bayes suitable covtype opt best classified logistic regression 
demonstrates real data sets different characteristics different sizes skewness degrees distributions 
diverse testbed shows wide capabilities proposed method 
model accuracy analysis purpose experiment compare model accuracy terms detection recall false alarm rates 
tables show results applying proposed method baseline methods series synthetic detection rate precision se ns ss false alarm rate roc curve se ns ss recall recall precision plot plots synthetic real data sets 
measure area roc curve auc 
data sets synthetic synthetic refer deterministic stochastic data sets dual concept change generated described 
greatest enhancements achieved synthetic data sets 
base learner decision tree se increases auc auc ns ss 
real data sets ns gained auc 
proposed method consistently better competitors 
show roc curves plots data sets synthetic opt figures 
parameter setting described base learner 
clearly synthetic real applications proposed method consistently improves precision 
synthetic data set hard learn due highly skewed distribution concept changes precision obtained single model extremely low recall range 
method achieved nearly times precision single model roc curve area near 
justifies sampling ensemble techniques method effectively improve probability estimates lead detection rate precision se ns ss false alarm rate roc curve se ns ss recall recall precision plot plots opt better classification model 
improvements opt data set significant 
reason data set sharply skewed nearly positive examples single model obtained high precision nearly 
proposed method succeeds improving roc graphs increase precision classification variance reduced 
effect data size skewness study impact chunk size reliability probability estimates 
data sets synthetic skewness degree base learner 
vary chunk size 
results shown table 
general classification errors methods decrease respect mse auc chunk size increases training examples lead reduction classification errors 
real applications chunk size usually fixed number examples held memory 
noted se outperforms ns ss chunk size varies 
example chunk size increases mse se decreases table effect chunk size se mse ns ss se auc ns ss table effect skewness skewness se mse ns ss se auc ns ss mse ns higher changing 
show effects skewness classification error 
data set synthetic chunk size base decision tree 
table classification errors ns decrease percentage positive examples increases 
example auc ss increases 
reason ns training size change positive examples help reduce classification error 
trend observed ss se auc increases respectively 
training sets ss se balanced sampling skewness degree original data set impacts training size 
percentage positive examples low need greatly sample negative examples distribution balanced 
percentage positive examples high incorporate negative examples training set 
larger training set accurate classification model expected 
training efficiency study time complexity ensemble approach compared single model 
synthetic data stream chunks generated 
chunk size varied number ensembles 
training times parallel serial ensembles reported 
expected ensemble outperforms corresponding single model significantly especially chunk size large 
chunk size serial ensemble reduces training time half 
reduction significant chunk size increases 
chunk size training time single model times training time seconds single model serial ensemble parallel ensemble chunk size training time training time serial ensemble 
training set high cardinality training single model huge data set cost large amount time 
ensemble method hand divides large training set small sets saves lots time training classifiers trained sequentially 
gain efficiency significant classification processes executed parallel 
results verify proposed method improves classification accuracy efficiency scalability 
related class imbalance important research problem years people realized imbalance class distribution causes suboptimal classification performance 
workshops aaai icml journal special issue sigkdd exploration dedicated class imbalance problem 
solutions proposed handle problem preprocessing data transforming algorithms post processing models 
balancing training set distribution popular approach 
specifically sampling algorithms developed sample majority examples minority examples 
methods may improve prediction accuracy minority class greatly challenged stream applications infinite data flow continuous concept drifts 
general framework dealing skewed data stream great demand 
skewed stream problems studied context summarization modeling 
evaluation existing stream classification methods done balanced data streams :10.1.1.14.4071
reality concepts data streams usually evolve time 
stream classification models designed mine concept drifting data streams regard concept drifts changes conditional probability 
shown concept changes may occur feature conditional probability 
application examples skewed data mining studied 
provide general framework building accurate classification models skewed data streams 
important related parts 
part analyze requirements choices techniques general predictive modeling data streams clearly understood previously 
comprehensive understanding requirements helps design better algorithms evaluate performance algorithms environment close reality 
specific argue concept drifts data streams involve changes 
show concept evolves form expected error decrease increase stay 
date data help reduce classification error 
second explain descriptive models preferred generative models stream mining 
descriptive models represent true concept accurately especially data streams applications skewed distribution underlying true distributions concept evolution patterns remain unknown mining 
discuss benefits posterior probability estimation compared direct class label prediction data stream classification 
probability estimates provide refined information users better decision making 
stochastic problems estimation meaningful 
analyses helpful inductive learning stream mining problems particularly interested applying mine skewed data streams 
design effective framework sampling ensemble techniques 
algorithm generates balanced training set keeping positive examples sampling negative examples 
training set divided samples multiple models trained samples 
final outputs averaged probability estimates test data multiple models 
show sampling ensemble techniques contribute classification variance reduction 
error reduction significant experimental results concept drifting streams mean square error decreases 
demonstrated formal analysis experiments synthetic real world datasets proposed method effective error reduction efficient scalable respect training time 
method introduced mainly focuses class problems easily extended multi class problems 
directions include applying framework multi class data skewed class distributions analyzing strengths ensemble methods stream environments various kinds concept changes 
abe 
sampling approaches learning imbalanced datasets active learning cost sensitive learning 
proc 
icml kdd workshop learning imbalanced data sets 
aggarwal han wang yu 
demand classification data streams 
proc 
kdd 
babcock babu datar motwani widom 
models issues data stream systems 
proc 
pods 

study behavior methods balancing machine learning training data 
sigkdd 

chawla japkowicz 
editorial special issue learning imbalanced data sets 
sigkdd 

cormode muthukrishnan 
summarizing mining skewed data streams 
proc 
sdm 
fan 
systematic data selection mine data streams 
proc 
kdd 
fan yu wang 
mining extremely skewed trading anomalies 
proc 
edbt 
hastie tibshirani friedman 
elements statistical learning 
springer verlag 
hulten spencer domingos 
mining data streams 
proc 
kdd 
korn muthukrishnan wu 
modeling skew data streams 
proc 
sigmod 
tumer ghosh 
analysis decision boundaries linearly combined neural classifiers 
pattern recognition 
witten frank 
data mining practical machine learning tools techniques 
morgan kaufmann 
wang fan yu han 
mining concept drifting data streams ensemble classifiers 
proc 
kdd 
weiss provost 
effect class distribution classifier learning 
technical report ml tr rutgers university 
zhang yang 
probabilistic score estimation piecewise logistic regression 
prof icml 
zhang fan yuan davidson li 
forecasting skewed biased stochastic ozone days 
proc 
icdm 
