practical skew handling parallel joins david dewitt je rey naughton donovan schneider seshadri july approach dealing skew parallel joins database systems 
approach easily implementable current parallel dbms performs skewed data degrading performance system non skewed data 
main idea multiple algorithms specialized di erent degree skew small sample relations joined determine algorithm appropriate 
developed implemented experimented new skew handling parallel join algorithms virtual processor range partitioning clear winner high skew cases traditional hybrid hash join clear winner lower skew skew cases 
experimental results implementation algorithms gamma parallel database machine 
knowledge rst reported skew handling numbers actual implementation 
multiprocessor database system technology progressed point number companies shipping products parallelism provide dramatic speedup scaleup performance 
clear success systems parallelism ective means meeting performance requirements large database applications 
basic technique systems exploiting intra query parallelism hash redistribution relations joining attribute dg vulnerable presence skew underlying data 
simply put underlying data su ciently skewed load imbalances resulting parallel join execution swamp gains due parallelism unacceptable performance result 
response problem large growing number skew handling algorithms proposed 
general terms algorithms signi cant amount preprocessing order compute execution plan designed minimize load imbalances 
algorithms may succeed minimizing skew invariably perform worse basic parallel hash join algorithm data skewed 
example previously proposed skew handling algorithms require relations joined completely department computer sciences university wisconsin madison 
hp labs palo alto 
scanned join begins hl ko 
time perform parallel hash join small multiple time required scan relations joined represent substantial overhead unacceptable extremely skewed data 
little empirical evidence extreme degrees skew occur commonly practice sub optimal penalize normal case order bene extreme case 
reason sought approach join processing normal case approaches performance fastest known parallel join algorithms non skewed data avoids disastrous performance degradation standard hash join processing su ers skewed data 
basic idea algorithms optimized di er ing degrees skew 
experiments algorithms su cient usual parallel hybrid hash join algorithm sd new algorithm call virtual processor range partitioning performs moderately skewed data cost slightly higher parallel hybrid hash join 
settling algorithms implemented new skew handling algorithms range partitioning weighted range partitioning scheduling version virtual processor range partitioning performed tests imple mentation 
detailed data performance implementation 
best knowledge skew handling algorithms rst ones implemented research prototype commercial parallel database system product 
fundamental step underlying approach initial pass sampling relations joined 
resulting set samples ways predict level skew data select appropriate join algorithm employ skew handling algorithms determine proper mapping processors 
initial sampling implementation extremely fast approximately percent time take hybrid hash perform join relations assuming non skewed data 
desirable property approach easily implemented framework existing parallel database systems 
modi cations required existing system minimal took person month add skew handling scheme gamma prototype 
remainder organized follows 
section describes algorithms techniques avoid skew 
section describes implementation algorithms gamma parallel database machine 
section results series experiments implementation algorithms 
section describes related handling skew parallel join operations including comparison earlier techniques 
section 
algorithms section composed parts description basic parallel hash join vulnerable skew basic techniques employ handle skew resulting new algorithms built basic techniques 
techniques described context parallel hash joins applicable wide range parallel database algorithms 
fact fundamental problem skew joins 
skew occur hashing parallelize task 
example techniques describe section just applied traditional join algorithm sort merge processor 
review basic parallel hash join highest level working parallel hash join algorithms shared multiprocessor database system simple 
concreteness suppose joining join condition initially relations distributed system processors sizes tuples jrj jsj approximately jrj tuples reside disk processor 
similarly processor jsj tuples disk 
perform join processor executes steps 
processor parallel reads partition relation disk applying hash function join attribute tuple turn 
hash function range numbers tuple hashes value processor number set tuples sent processor step denoted 
processor parallel builds memory resident hash table tuples sent step 
hash table uses di erent hash function repartition tuples step 

processor parallel reads partition disk applying hash function step tuple turn 
step hash function map tuples processors 
set tuples sent step denoted 
processor receives incoming tuple processor probes hash table built step see joins tuple answer tuple generated 
mentioned simpli ed description 
example tuples received step memory ow handling scheme employed 
commonly ow processing handled partitioning smaller subparts called buckets bucket small entirely memory 
critical factor determining performance algorithm number buckets needed larger number buckets necessary tuples ow buckets disk re read perform join 
preceding description clear parallelization number tuples mapped processor approximately equal load imbalances result form imbalance walton terms redistribution skew 
load imbalances result poorly designed hash function 
load imbalance due poor hash function removed choosing better hash function theoretical literature hashing gives number techniques designed nd hash function high probability performs cw 
fundamental problem arises repeated values join attribute 
de nition hash function map tuples equal join attribute values processor way hash function avoid load imbalances result repeated values 
subtle cause load imbalance occurs number matching tuples varies processor processor 
form load imbalance results join selectivity di ers join selectivity forr type load imbalance called join product skew walton 
skew avoidance fundamentals subsections describe techniques apply resolving types skew 
range partitioning basic approach redistribution skew replace hash partitioning range partitioning 
idea allocating processor bin hash function processor allocated subrange join attribute value 
values delineate boundaries ranges need equally spaced join attribute domain allows values chosen equalize number tuples mapped subrange 
example join attribute values appearing relation processors choose splitting value sending tuples values processor zero tuples join attribute values processor 
general processors splitting values delineating boundaries contiguous ranges 
call splitting values partitioning vector 
partitioning vector exact partitions tuples relation exactly equal sized pieces 
computing exact partitioning vector di cult attractive aspect range partitioning relatively easy determine approximate partitioning vector sampling examining entire relation 
technique sampling approximate splitting vectors previously dbms algorithms evaluating dns parallel external sorting dns 
theoretical investigation table example relations performance sampling range splitting appears sn 
relation join say question arises algorithm attempt balance number tuples node number tuples node sum tuples node 
answer clear useful general observation imbalance number building tuples worse imbalance number probing tuples imbalance number building tuples site gives rise extra buckets local driving number os signi cantly 
observation validated results reported sd experimental results section 
subset replicate complication arises join processing range partitioning presence highly skewed data equal sized partitions necessary map single data value multiple partitions 
example join attribute values equal sized partitioning map processor zero processor 
range partitioning assigns single values partition take care ensure possible answer tuples produced 
simple solution send tuples repeated join attribute value processors value mapped results multiple processors doing exactly producing answer tuples multiple sites 
su cient send tuples repeated attribute value relation sites value mapped send tuple repeated attribute value relation exactly sites repeated values 
call technique subset replicate 
subset replicate similar fragment replicate technique proposed distributed relational query processing epstein 
example suppose joining join predicate furthermore suppose relations contain tuples shown table 
suppose wish join processors 
splitting single value processors value subset replicate partitioning processors send tuples processor tuples processor 
subset part partitioning 
tuples correctness tuples join attribute value replicated processors 
means tuples sent top tuples sent top 
question arises replicate building inner relation subset probing outer relation vice versa 
clearly situations perform reasonable heuristic subset building relation replicate probing relation 
motivation heuristic critical portion building relation mapped processor small possible minimize number buckets join 
weighting complication arises range partitioning case join attribute value appears di erent number times di erent partitions 
example suppose join attribute values tuple relation wish partition processors andp 
partitioning vector meaning tuples join attribute value mapped processors 
total tuples join attribute value balance load evenly processors tuples join attribute directed processor join attribute values processor processor join attribute value 
refer technique distributing replicated values relation weighted range partitioning 
virtual processor partitioning subsection deal problem join product skew 
concreteness suppose joining tuple relations relation join attribute value appears times join attribute value appears 
assume processors 
equal sized range partitioning tuples join attribute value relations mapped processor zero meaning processor zero asked generate result tuples 
way remedy problem choosing set splitting values mapped processor case 
solution problem choose partitions processors 
idea appeared times skew join literature respect hash bucket partitioning rst technique probably 
refer technique multiple range partitions node virtual processor partitioning 
previous example chose buckets processor total buckets ne granularity resolve problem 
particular spread buckets subranges mapped di erent processor 
course leaves open question virtual processor partitions mapped actual processors 
considered techniques described subsection 
load scheduling consider basic techniques mapping virtual processor partitions actual processors 
round robin 
simplest scheme processors ith virtual processor partition mapped actual processor mod 
processor scheduling 
scheme virtual processor partition compute estimate cost joining tuples formula estimating cost join chose simple technique estimating jr ij est js ij est jr ij est jr ij est estimate number tuples mapped partition js ij est estimate number tuples mapped partition jr ij est estimate number tuples computed estimate size assuming join attribute values ofr uniformly distributed endpoints range virtual processor partition estimate cost joining virtual processor partitions computed task scheduling algorithm try equalize times required virtual processor partitions allocated physical processors 
heuristic scheduling algorithm known lpt gra 
approach similar wolf hash par statistics schedule partitions gained complete scan relations sampling hash partitioning range partitioning 
algorithm description algorithms implemented described terms skew handling techniques de ned 
rst need discuss approximate splitting vectors computed 
algorithm hybrid hash rst sampling compute statistical pro le join attribute values relations joined 
obtained sample strati ed sampling coc stratum consisting set tuples initially residing processor 
processor sampling performed page level extent map sampling 
extent map sampling described section 
issues involving strati ed sampling page level sampling discussed sn 
describe skew handling algorithms 

hybrid hash 
just basic parallel hybrid hash algorithm modi cations skew handling 
description algorithm alternatives appears sd 

simple range partitioning 
top level algorithm works follows sample building inner relation 
samples compute approximate partitioning vector 
number partitions de ned partitioning vector equal number processors 
redistribute building relation approximate partitioning vector de termine processor tuples go 
build memory hash table containing building relation tuples possi ble 
ow tuples partitioned buckets sized bucket main memory sd 
redistribute probing outer relation approximate partitioning vector step 
tuple probing relation probe memory hash table outputting join result tuple match 
ow occurred step probing tuples corresponding ow buckets building relation written directly disk 
probing tuples received building probing relations processed 

weighted range partitioning 
algorithm range partitioning simple range partitioning tuples redistributed weighted range partitioning 

virtual processor partitioning round robin 
algorithm range partitioning having number partitions equal number processors number partitions multiple number processors 
exact number partitions parameter algorithm 
partitions allocated processors round robin allocation 

virtual processor partitioning processor scheduling 
algorithm virtual processor partitioning round robin round robin allocation partitions processors processor scheduling lpt 
implementation details section describe details implementation skew handling algorithms gamma 
explaining sampled relations consider modi cations gamma necessary remainder algorithms 
sampling implementation mentioned section strati ed sampling obtain sample relations distributed multiprocessor 
strati ed sampling node multiprocessor needs take samples processor takes samples local partition database 
simple random sample entire relation strati ed sample su cient purposes 
strati ed sampling requires processor take speci ed number samples partition database 
number techniques proposed problem notably sampling trees sampling hash tables dense index primary key dns 
section describe new technique call extent map sampling 
extent sampling requires index dense primary key index attribute 
scheme hinges fact systems allocate pages contiguous units called extents record information pages le stored linking extents pages le 
information maintained small memory resident data structure 
address page extent adding set address rst page extent 
information select random page tuple follows generate random number number pages le relation 
find address rth page le chaining linked list extents 
random page desired page brought random tuple desired follow randomly choosing tuples page 
correctly chooses random page pages relation number tuples 
need acceptance rejection sampling accept reject randomly chosen page inclusion probabilities tuple relation identical 
pages number tuples require exactly fetch random tuple 
average number required fetching random tuple inverse ll factor 
ll factor need average fetch random tuple 
better previous index methods assuming previous methods due acceptance sampling 
reason adopted extent map sampling implementation 
page level sampling implementation 
means random page selected read memory extent map sampling add tuple page sample 
ect boosts number samples factor equal average number tuples page 
technique cient correlation join attribute page low 
implementation gamma order investigate performance skew handling algorithms implemented algorithms gamma dgs experimental vehicle 
gamma falls class shared sto architectures 
hardware consists processor intel ipsc hypercube 
processor con gured cpu megabytes memory megabyte maxtor 
disk drive 
disk drive embedded scsi controller provides kbyte ram bu er acts disk cache sequential read operations 
nodes hypercube interconnected form hypercube custom vlsi routing modules 
module supports full duplex serial reliable communication channels operating megabytes sec 
gamma built top operating system designed speci cally supporting database management systems 
nose provides multiple lightweight processes shared memory 
non preemptive scheduling policy help prevent occurring 
nose provides communications nose processes reliable message passing hardware intel ipsc hypercube 
file services nose wisconsin storage system wiss 
services provided wiss include sequential les byte stream les unix tree indices long data items external sort utility scan mechanism 
sequential le sequence records may vary length page may inserted deleted arbitrary locations le 
optionally le may associated indices map key values record identi ers records le contain matching value 
indexed attribute may designated clustering attribute le 
gamma contained code needed perform parallel hybrid hash join 
critical code needed added system order incorporate new skew handling join algorithms 
code parallel strati ed page level extent map sampling 
code sort resulting samples build required approximate splitting vectors 
code redistributes tuples new distribution types subset replicate re quired algorithms 
items straightforward 
discuss changes redistribution code detail 
basic parallel hybrid hashing gamma data structure called split ta ble dgs dg 
data structure contains entries hash bucket processor number pairs 
processors execute relational operation split tables entries 
semantics tuple hashes hash bucket sent processor number split table entry hash bucket 
processor executing operation copy split table 
processor associated split table outgoing bu er pages processor 
tuple maps hash bucket added corresponding bu er page page lls message containing page sent target processor 
add basic range partitioning added new type split table called range split table 
simple modi cation change entries split table correspond ranges join attribute values corresponding hash buckets 
deciding send tuple hashing join attribute value nd corresponding entry range split table searched nd range containing join attribute value 
tuple maps range repeated values split table redistribution building inner relation duplicate ranges selected random sent corresponding processor 
redistribution probing outer relation sent processors corresponding containing subranges 
add weighted range partitioning augmented basic range split table contain weights upper lower boundary values range table 
weights computed sorted set samples time partitioning values computed 
redistribution building relation sending tuple randomly selected subrange subrange selected probability re ects weights weighted range split table 
obvious way add virtual processor range partitioning expand basic range splitting tables add entries processors 
di culty doing lower level gamma code assumes exactly outgoing bu er page entry split table 
large numbers virtual processors space required scheme prohibitive 
example processors virtual processor ranges processor require output bu ers megabytes byte network packets node 
total amount memory node sytem 
solve problem level split table 
upper level table contains number virtual processor partitions 
lower level table contains entry processor 
entry upper table consists range lower split table entry number pair 
tuple processed decide processor sent rst lookup performed upper table determine set virtual processor ranges join attribute value tuple appears 
entries ranges examined determine lower level entries tuple belongs 
set entries lower level table system determine processors tuple sent 
bu er page destination processor 
experiments results test data purposes experiment set test data simple intuitively easy understand stress skew handling algorithms 
option generate relations attributes drawn standard statistical distributions zipf normal 
decided relations attributes experiments harder understand control 
exam ple suppose wish perform set joins pair relations varying level skew relations keeping answer size approximately constant 
di cult sets zip distributions 
remedy problem generated relations number integer attributes various amounts scalar skew tuple relation attribute constant appears xed number tuples remaining tuples contain values uniformly distributed distribution major bene ts 
easy understand exactly experiment performed 
second easy keep answer size constant varying amounts skew 
captures essence zip distribution small number highly skewed values bulk values appearing infrequently su ering drawbacks 
term scalar skew due walton 
model skew omiecinski 
exact description attributes follows 
case assuming relation tuples 
attributes relevant experiments 
number case number tuples value appears join attribute tuples chosen random 
remainder tuples join attribute value chosen randomly number tuples relation 
example attribute semantics value appears exactly randomly chosen tuples 
remaining tuples contain values uniformly chosen random rationale choosing attributes apparent set experiments 
addition attributes listed tuple contained string attribute pad length tuple bytes 
experiments relations tuples 
relation occupies approximately megabytes disk space 
experiments conducted processors disks 
speedup scaleup exper iments performed interested focusing relative performance di erent algorithms 
furthermore previous join dgg dgs dgs dns sd sorting dns tests demonstrated gamma provides linear speedup scaleup wide range di erent hardware software con gurations 
single skew experiments rst set experiments ran building relation skewed probing relation uniform 
models common sort join practice joins key relation corresponding foreign key 
data point average experiments 
range weighted range virtual processor range partition round robin number samples building relation xed probing relation sampled algorithms 
virtual range partition processor scheduling algorithm took samples building probing relations 
virtual processor range partitioning algorithms virtual processors processor 
results experiment appear table 
alg 
hh dnf dnf dnf range dnf dnf dnf range vp rr vp ps table ect skewed building relation 
table entries marked dnf means algorithm nish 
reason tests nish cases marked dnf algorithms mapped tuples join attribute single processor simultaneously memory processor 
current gamma implementation node hybrid hash code handle extreme case 
see hybrid hash hh clearly algorithm choice zero skew case 
compared skew handling algorithms hybrid hash incur overhead collecting samples sorting samples computing approximate splitting vector hybrid hash determine destination processor redistribution need compute hash function algorithms necessary search sorted list appropriate range entry 
di erence performance range partitioning range weighted range par range zero skew artifact implementation weighted range partitioning implemented second uses cient table search repartition ing 
expect range partitioning reimplemented new code slightly faster zero skew doesn need check weights choosing destination subset phase 
range partitioning weighted range partitioning ect partitioning sending tuples join attribute tuples processor zero 
range partitioning sends tuples processor zero weighted range partitioning sends tuples processor zero tuples plus tuples processor 
weighted range partitioning performs worse number tuples distributed processor cases case join hash table processor zero contains bucket tuples bucket mapped 
situation worse bucket ones case 
virtual processor range partitioning round robin allocation vp rr starts zero skew slightly higher overhead weighted range redistribution determine destination processor search bigger range table bigger factor 
virtual processor range partitioning processor scheduling vp ps overhead sample sort probing relation run lpt scheduling algorithm 
skewed cases algorithms outperform range range map tuples processors avoiding large hash table entry ect 
wanted test ect skewed probing relation gorithms 
note rst algorithms sample probing relation algorithms splitting vector independent skew probing relation 
reason performance deteriorates rapidly sowe go 
note hybrid hash relatively 
vp ps samples probing relation estimates virtual processor execution times inaccurate provide performance 
algorithm hh range range vp rr vp ps table ect skewed probing relation 
alternative approach handling single relation skew sample probing relation samples compute splitting vector building probing relations 
pursue approach reason probing relation highly skewed distribute building relation splitting vector evenly distributes probing relation greatly varying numbers building tuples sent processor 
turn causes processor buckets necessary building relation evenly distributed cause performance su er 
join product skew subsection experiments relations participate join skewed 
general sort skew harder deal skew single relation 
intuitively problem join product skew relatively small number repeats cause tremendous blowup number tuples generated join 
example join relations join clause result tuples generated due matches tuples ones join attributes 
result bytes 
addition exceeding capacity disk drives don think queries sense 
accordingly decided experiment modest skews 
rst set experiments shows performance algorithms con guration number virtual processors node table 
algorithm hh range vp rr vp ps table performance data join product skew 
joins table designed result size roughly comparable tables 
case result contains tuples due joining tuples contain ones join attribute 
clear virtual processor algorithms signi cant success dealing sort skew 
intuitively reason range weighted range algorithms skew relation cause tuples join attribute sent processor 
exception join virtual processor algorithms virtual buckets mapped processors distribute 
join round robin algorithm fails distribute building relation 
virtual processor range partitioning processor scheduling algorithm fails distribute multiple buckets estimates required virtual processor inaccurate 
clear performance virtual processor range partition algorithms critically dependent number virtual processors processor 
table explores performance round robin variant join various numbers pro cessor node 
experiments processor scheduling variant uniformly worse round robin variant omit data points algorithm 
table shows clear trend virtual processors better performance 
reason tuples distributed actual processors achieving better load balancing 
virt 
procs 
exec 
sec 
table dependence number virtual processors virtual processor range partitioning 
illustrate dependence virtual processor range partitioning number samples 
table lists average time function number samples virtual processor range partition round robin algorithm function number samples join 
virtual processor range partitioning round robin allocation uniformly best skew handling algorithm data 
note performance relatively stable independent number samples 
general trend samples results poor load balancing samples results overhead due sampling notice table running times dip samples rise 
number samples execution time sec table dependence number samples virtual processor range partitioning 
wewould emphasize virtual processor range partition round robin exceedingly successful balancing load processors execution 
table gives maximum minimum times processors complete building phase redistributing building relation building memory hash table entire join 
samples virtual processors processor 
note total time seconds di ers time reported join table 
times table averages runs times table single run 
di erence maximum minimum times building phase di erence total execution time 
phase min seconds max seconds building complete join table maximum minimum times processors virtual processor range partitioning 
related wealth research area parallel join algorithms 
originally join attribute values assumed uniformly distributed skew problem see example bra dg dgs 
parallel join algorithms matured uniformity assumption challenged see ly sd 
section examine number previously proposed algorithms dealing data skew compare algorithms 
walton dale walton parallel databases 
distinguish attribute value skew avs inherent dataset partition skew occurs parallel machines load balanced nodes 
avs typically leads partition skew factors involved 
include 
tuple placement skew tps initial distribution tuples may vary nodes 

selectivity skew ss selectivity selection predicates may vary nodes example case range selection range partitioned attribute 

redistribution skew rs nodes may receive di erent numbers tuples redistributed preparation actual join 

join product skew join selectivity individual nodes may di er leading imbalance number output tuples produced 
walton analytical model order compare scheduling hash join algorithm hybrid hash join algorithm gamma sd dgs 
main result scheduling hash ectively handles rs hybrid hash degrades eventually worse scheduling hash rs increases 
join signi cantly skewed absolute performance hybrid hash signi cantly better scheduling hash 
schneider dewitt sd explored ect skewed data distributions parallel join algorithms processor version gamma database machine 
experiments designed tps ss absent 
tested avs normally distributed values hash function redistribution phase quite ective balancing load rs low 
likewise low 
results parallel hash join algorithms hybrid grace simple sensitive rs resulting avs building relation due hash table ow relatively insensitive rs probing relation 
experiments double skew lead run extrapolated problems worse case superset rs building relation 
kitsuregawa kitsuregawa ogawa ko describe algorithms bucket converging parallel hash join bucket spreading parallel hash join 
bucket converging hash join basic tion grace join algorithm 
relation read disk parallel partitioned buckets larger number nodes 
bucket statically assigned particular node redistributed phase algorithm 
size bucket examined necessary buckets redistributed sum sizes buckets processor balanced 
relation processed similarly 
phase respective buckets node joined locally 
point rst phase algorithm initial repartitioning sus rs 
alternative propose bucket spreading hash join algorithm 
algorithm relations partitioned buckets bucket horizontally partitioned available processors initial repartitioning phase 
second phase algorithm sophisticated network omega network redistribute buckets nodes local join operation 
omega network contains logic balance load bucket redistribution 
simulation results algorithms avs modeled zip distribution 
data uniformly distributed algorithms identical 
bucket spreading algorithm shown ectively reduce rs presence increasing avs bucket converging algorithm su ers 
compared weighted range virtual processor algorithms algorithms higher response times 
particular algorithms redistribute joining relations exactly 
bucket spreading algorithm redistributes relations twice 
addition relations memory extra write read relations disk required repartitioning phases 
bucket converging algorithm hand incurs extra redistribution costs buckets redistributed order balance load processors 
point algorithm susceptible rs 
hua lee hua lee hl proposed algorithms processing parallel joins presence avs 
rst algorithm tuple interleaving parallel hash join bucket spreading hash join algorithm kitsuregawa ogawa ko 
major di erence relying specially designed intelligent network mapping buckets nodes decision handled software coordinator node 
second algorithm adaptive load balancing parallel hash join tries avoid massive data redistribution incurred tuple interleaving algorithm 
case mild skew redistribution perform better 
algorithm relations partitioned buckets bucket statically assigned single node 
immediately performing local joins partition tuning phase executed best decreasing heuristic determine buckets retain locally versus ones redistribute 
algorithm basically identical kitsuregawa ogawa bucket converging algorithm nal algorithm extended adaptive load balancing parallel hash join designed case severe skew 
relations partitioned buckets bucket stored locally 
nodes report size local bucket coordinator decides allocation buckets nodes 
allocation decision broadcast nodes buckets redistributed network 
local joins respective buckets performed node 
basic form algorithm identical wolf 
algorithms di er computation allocation strategy 
algorithms compared analytical model 
basic results tuple interleaved extended adaptive load balancing algorithm una ected skew size partitions performance adaptive load balancing algorithm bucket converging algorithm eventually cross worse skew increases 
rst algorithms basically identical kitsuregawa relative performance algorithms 
algorithms extended adaptive load balancing parallel hash join algorithm relation exactly 
relations memory extra read write relations occurs initial bucket forming phase 
cost step certainly higher cost incur sampling relations second implementation 
wolf dias yu wolf propose algorithm parallelizing hash joins presence severe data skew 
scheduling hash algorithm follows 
relations read local selections projections applied results written back locally set coarse hash buckets 
additionally statistics ner hash function maintained bucket 
scheduling phase occurs coordinator collects ne coarse bucket statistics computes allocation buckets nodes 
allocation strategy broadcast nodes relations redistributed network accordingly 
hash joins performed locally bucket 
heuristics proposed computing allocation strategy scheduling phase including longest processing time rst rst decreasing skew 
analytical model brie compare strategies 
avs modeled zip distribution 
tps ss skew occurs 
double skew skew join relations style join speci cally modeled 
load balancing heuristics shown highly ective balancing load especially number processors large 
comparison performance join algorithms skew handling non skew handling 
hua extended adaptive load balancing parallel hash join algorithm algorithm incurs extra read write relations initial bucket forming phase 
cost step certainly higher cost sampling relations 
may case increased accuracy skew information obtained looking tuple su ciently improve variance response time processors cost extra read write pass worthwhile 
implementing algorithms hardware software base probably impossible determine precisely algorithm provides best performance 
omiecinski omiecinski proposed load balancing hash join algorithm shared memory mul 
algorithm bucket spreading algorithm kitsuregawa ogawa ko 
di ers doesn rely special purpose hardware assigns buck ets processor rst decreasing heuristic optimizations shared memory environment 
analytical limited experimental results processor sequent machine show algorithm ective limiting ects avs double skew joins 
avs modeled having single value account relation values uniformly distributed 
algorithms skew handling proposed represent simple way augment existing parallel database systems performance robust presence skewed joins 
modi cations needed install changes existing system simple needed add extent map sampling equivalent support subset replicate virtual processor split tables nally small amount code analyze samples build necessary split tables 
experiments performed suggest approach joins 
take pilot sample relations involved join 

inspect resulting set samples determine relation highly skewed counting number repeated samples 

relations appears skewed revert simple hybrid hash 

relations appears skewed virtual processor range partition round robin join algorithm 
skewed relation building relation 
scheme incorporates number heuristics optimizer heuristics choosing sub optimal plan situations 
simple implementable general runs non skewed joins time comparable standard hybrid hash overhead outlined takes just seconds implementation runs skewed joins su ering terrible worst case performance result running hybrid hash highly skewed data 
open questions remain addressed 
experiments illustrate virtual processor range partitioning algorithm depends critically number virtual processors chosen 
optimal number parameter depends system con guration importantly number processors little skew willing tolerate 
values experiments virtual processors processor reasonable performed test data claim globally optimal 
second address question handle joins operands greatly di erent size 
experience experiments suggest critical point number buckets building relation minimum 
ways large number buckets result large building relation skewed building relation 
reasonable heuristic relations roughly comparable size skewed relation building relation di erent size smaller relation building relation skew handled building split table samples probing relation 
intend experiment heuristic 
number processors system grows thousands overhead sorting analyzing samples grow cost obtaining samples constant number samples processor system scales 
clear overhead grow fast cost performing join processors join presumably big join room reducing overhead doing processing parallel doing central coordinating processor 
example rst step processor sort local set samples sending coordinator simple merge sort 
acknowledgments supported donations dec ibm ibm research initiation ncr tandem 
generous support research possible 
baru frieder kandlur segal 
join cube analysis simu lation implementation 
kitsuregawa tanaka editors database machines knowledge base machines 
kluwer academic publishers 
gray price 
convoy phenomenon 
operating system review 
bra 
algebra operations parallel computer performance evaluation 
kitsuregawa tanaka editors database machines knowledge base machines 
kluwer academic publishers 

chou david dewitt randy katz anthony klug 
design implementation wisconsin storage system 
software practice experi ence october 
coc william cochran 
sampling techniques 
john wiley sons new york new york edition 
cw lawrence carter mark wegman 
universal classes hash functions 
journal computer system sciences 
dg david dewitt robert gerber 
multiprocessor hash join algorithms 
proceedings twelfth international conference onvery large databases pages stockholm sweden 
dg dewitt gray 
parallel database systems high performance database processing 
communications acm appear 
dgg david dewitt robert gerber goetz graefe michael krishna kumar 
gamma high performance data ow database machine 
proceedings twelfth international conference onvery large databases pages kyoto japan august 
dgs david dewitt ghandeharizadeh donovan schneider 
perfor mance analysis gamma database machine 
proceedings sigmod international conference management data pages chicago illinois may 
dgs dewitt ghandeharizadeh schneider hsiao ras 
gamma database machine project 
ieee transactions knowledge data engineering march 
dns david dewitt je rey naughton donovan schneider 
comparison non equijoin algorithms 
proceedings eighteenth international conference large databases barcelona spain august 
dns david dewitt je rey naughton donovan schneider 
parallel external sorting probabilistic splitting 
pdis miami beach florida december 
robert epstein michael stonebraker eugene wong 
distributed query pro cessing relational database system 
proceedings acm sigmod ternational conference management data 
gra graham 
bounds multiprocessing timing anomalies 
siam journal com puting 
hl hua chiang lee 
handling data skew multiprocessor database computers partition tuning 
proceedings th international conference large databases pages barcelona spain august 
ko masaru kitsuregawa yasushi ogawa 
bucket spreading parallel hash new robust parallel hash join method data skew super database computer sdc 
proceedings sixteenth international conference onvery large data bases brisbane england august 
kitsuregawa tanaka oka 
application hash data base machine architecture 
new generation computing 
ly philip yu 
ectiveness parallel joins 
ieee trans actions knowledge data engineering december 
edward omiecinski 
performance analysis load balancing hash join algorithm shared memory multiprocessor 
proceedings seventeenth international conference onvery large data bases barcelona spain september 
frank olken doron rotem 
random sampling trees 
proceedings fifteenth international conference onvery large databases pages amsterdam netherlands august 
frank olken doron rotem ping xu 
random sampling hash les 
proceedings acm sigmod conference management data pages atlantic city new jersey may 
sd donovan schneider david dewitt 
performance evaluation parallel join algorithms shared multiprocessor environment 
proceedings acm sigmod international conference management data pages portland oregon june 
sn seshadri je rey naughton 
sampling issues parallel database systems 
proceedings edbt conference vienna austria march 
sto stonebraker 
case shared 
database engineering 
christopher walton alfred dale roy 
taxonomy performance model data skew ects parallel joins 
proceedings seventeenth international large data bases barcelona spain september 
joel wolf daniel dias philip yu john turek 
ective algo rithm parallelizing hash joins presence data skew 
ibm watson research center tech report rc 

