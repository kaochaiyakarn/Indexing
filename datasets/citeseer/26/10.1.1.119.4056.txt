threads input output synthesis kernel henry massalin calton pu department computer science columbia university new york ny calton cs columbia edu november synthesis operating system kernel combines techniques provide high performance including kernel code synthesis ne grain scheduling optimistic synchronization 
kernel code synthesis reduces execution path frequently kernel calls 
optimistic synchronization increases concurrency kernel 
combination results signi cant performance improvement traditional operating system implementations 
hardware software emulating sun running sunos synthesis achieves times dozen times speedup unix kernel calls context switch times microseconds faster 
synthesis operating system kernel parallel distributed computational environment 
major goals design implementation synthesis 
high performance 
self tuning capability dynamic load con guration changes 
simple uniform intuitive model computation high level interface 
focus aspects synthesis kernel implementation supports threads input output 
achieve high performance combine kernel code synthesis decreases kernel call overhead specialization reduced synchronization decreases kernel thread synchronization overhead 
introduced principles code synthesis synthesis kernel fast reasons 
frequently executed synthesis kernel calls compiled optimized run time ideas similar currying constant folding 
example open le input custom short fast read routine returned read calls 
second frequently traversed data structures sprinkled machine instructions self traversing 
example cpu dispatching including context switches done ready queue way details see 
describe synergy combining code synthesis kernel implementation techniques 
self contained summarize kernel code synthesis aspects background information section 
traditional os kernel call dispatching scheduling overhead kernel synchronization cost 
see traditional kernels powerful mutual exclusion mechanisms semaphores 
synthesis kernel code synthesis trim kernel calls context switches 
bottleneck turned kernel internal synchronization cost synthesis kernel highly parallel 
answer problem consists methods reduce synchronization synthesis kernel described section 
illustrate new possibilities performance improvements introduced techniques describe kinds objects supported synthesis kernel threads discussions threads section section relevant uniprocessor multiprocessor systems 
distribution aspects synthesis scope 
performance improvement techniques follow software engineering principle called principle powerful solution problem 
carefully separate kernel implementation interface speci cation principle applied system 
kernel code synthesis reduced synchronization examples 
section measurement data show ectiveness techniques 
synthesis background synthesis model computation synthesis model computation conceptually von neumann machine threads execution memory protection boundaries devices 
support parallel distributed computing threads execution form directed graph nodes threads arcs data ow channels 
graph model support parallel distributed computation described detail 
synthesis threads threads execution unix processes 
threads execute user level code run entirely kernel provide additional concurrency kernel operations 
threads execute programs quasi address space store data 
devices move threads including les messages 
physical node synthesis subspaces single address space de ned cpu architecture bit microprocessor bit address space 
kernel blanks part address space supposed see 
parts address space easy share memory setting address mappings 
current implementation kernel support virtual memory 
kernel code synthesis idea kernel code synthesis introduced previous 
synthesis code synthesizer kernel generate specialized short fast kernel routines speci situations 
wehave methods synthesize code 
factoring invariants method bypasses redundant computations constant folding 
collapsing layers method eliminates unnecessary procedure calls context switches vertically layered modules horizontally pipelined threads 
executable data structures method shortens data structure traversal time data structure traversed way 
basic kernel components describe synthesis kernel implementation concrete terms rst summarize basic components 
synthesis kernel divided anumber collections procedures data 
call collections procedures encapsulate hardware resources hydra objects 
important threads device servers 
threads abstraction cpu 
device servers abstractions devices 
threads consist procedures data 
events start threads animate 
support inheritance language features 
implemented combining small number building blocks 
building blocks known monitors queues schedulers 
simple somewhat unusual switches pumps gauges 
shall see section synthesis implemented building blocks 
see uses optimization techniques collapsing layers combine building blocks kernel 
unusual building blocks require explanation 
switch equivalent switch statement 
example switches direct interrupts appropriate service routines 
pump contains thread actively copies input output 
pumps connect passive producers passive consumers 
gauge counts events procedure calls data arrival interrupts 
schedulers gauges collect data scheduling decisions 
building block mayhave implementations 
applying principle economical implementation depending usage 
example kinds queues synthesis kernel 
semantically wehave usual kinds queues synchronous queue blocks queue full queue empty asynchronous queue signals conditions 
kind implementations dedicated queues optimistic queues 
dedicated queues knowledge producer consumer queue omit synchronization code 
optimistic queues accept queue insert queue delete operations multiple producers multiple consumers 
optimistic queue described detail section 
threads created creator contains stages allocation factorization optimization 
allocation stage allocates memory associated synthesized procedures 
factorization stage uses factoring invariants substitute constants code templates 
optimization stage improves nal code specialized peephole optimizations 
starts execution existing installing invoking thread 
stages combination factorization optimization dynamic link 
combination stage nds appropriate connecting mechanism queue monitor pump simple procedure call 
factorization optimization creator clean connecting code 
dynamic link stage stores synthesized code entry points 
reduced synchronization overview methods reduce synchronization cost code isolation procedure chaining optimistic synchronization 
method shortens execution path somewhat di erent way 
informally speaking code isolation procedure chaining thought avoidance techniques 
absolutely unavoidable optimistic synchronization 
code isolation uses kernel code synthesis separate isolate fragments data structure manipulation programs 
separation eliminates unnecessary synchronization fragment operates piece data 
example thread thread table entry tte equivalent unix 
naive procedures traverse thread table modify tte table 
synthesis thread updates tte exclusively 
synthesize short code manipulate tte synchronization 
procedure chaining avoids synchronization serializing execution con icting threads 
allowing concurrent execution complicated synchronization problems chain new procedure executed currently running procedure 
example currently executing thread handles interrupts synthesis 
signal arriving middle interrupt handling potentially dangerous kill signal may terminate interrupt handling prematurely 
chain procedure invoked signal interrupt handler 
procedure chaining implemented ciently simply changing return addresses stack 
optimistic synchronization assumes interference threads rare shorten normal non interfering case 
idea optimistic validation go ahead changes locking 
check update tests assumption noninterference remains true 
test fails rollback retry 
optimistic synchronization implemented optimistic queue describe 
optimistic queues queue manipulation example optimistic synchronization important synthesis kernel data structures queues 
control structures interrupt signal handlers implemented queues pointers routines 
words synchronize queue operations locking synthesis kernel run locking 
queues usual put item put get item get operations classify operations environment 
wehave kinds queues single producer single consumer sp sc single consumer mp sc single producer multiple consumer sp mc multiple producer multiple consumer mp mc 
simplest case sp sc gure gives basic idea queues queue bu er full empty consumer producer operate di erent parts bu er 
synchronization necessary bu er empty full 
synchronization primitives usual primitives say busy wait blocking wait 
argue queues queues lose items put generate items taken 
avoid lost updates sp sc queue code isolation 
variables written head updated size return return get data put data tail head head tail wait wait data buf buf data tail head sp sc queue producer tail consumer 
avoid item repeatedly update head instruction put 
consumer detect item producer nished 
di erence sp sc queue mp sc queue reduces single compare swap instruction plus retry loop ensure synchronization multiple producers 
larger critical sections may require sophisticated synchronization 
interesting queue shown implements atomic inserts items size queue 
problems consider multiple producer synchronization solved compare swap atomic insert multiple items explain 
minimize synchronization producers increments atomically head pointer thenumber items inserted claim space queue 
producer proceeds ll space time producers lling theirs 
consumer may trust head reliable indication data queue 
separate array ag bits queue element 
producers ll queue element set ag associated array indicating consumer data item valid 
consumer clears item ag taken queue 
give idea relative costs current implementation mp sc normal execution path length instructions mc processor put 
case threads trying write item su ciently empty queue succeed attempt increment di erent times succeed fails 
thread succeeds consumes instructions 
failing thread goes retry loop total instructions 
return tail return size return put data head cas head fail buf data flag note cas old new compare swap performs operation atomically old new return ok return fail threads synthesis threads mp sc queue multiple insert synthesis threads light weight processes 
synthesis thread called simply thread executes context de ned tte 
thread state completely described tte see gure containing register save area vector table points kinds procedures thread speci system calls interrupt handlers error traps signal vectors address map tables context switch context switch procedures 
kernel code generated thread goes protected area avoid user tampering 
kernel procedure bodies part thread signal start step destroy thread calls customized system calls synthesized open see section synthesized interrupt handlers queue bu ering see section specialized error trap handlers signal procedures see section 
thread context synthesis thread kernel call say thread executing kernel mode contrast having kernel server process run kernel call behalf client thread 
trap instruction switches thread supervisor state kernel accessible addition user 
consequently call may move data user kernel 
outside kernel thread attempt access illegal address thread take bus fault exception kernel mode 
thread running waiting 
waiting thread blocked event resource 
resource waiting queue 
example thread waiting cpu sitting ready queue thread blocks characters tty driver chained tty driver queue 
spreading waiting threads blocking unblocking faster 
eliminated general blocked queue traverse insertion blocking search deletion unblocking 
waiting thread unblocking procedure chained interrupt handling waiting queue reduced synchronization due code isolation 
context switches context switches expensive traditional systems unix complete switch save registers system area setup run time stack nd current proc table copy registers proc table start process complications summarized source code 
synthesis context switch shorter reasons 
switch part context 
second executable data structures minimize critical path 
instances optimize context switch data 
rst handling oating point registers second mmu address space switch 
synthesis threads oating point processor 
save oating point processor information context switch plus bytes information takes microseconds save memory comparable microseconds needed entire context switch oating point see section data 
threads oating point processor generate default context switch code 
thread executes rst oating point instruction illegal instruction trap happens 
synthesis kernel context switch procedures include oating point processor 
way users oating point processor pay added overhead 
dispatcher procedure synthesis 
shows ready run threads waiting cpu chained executable circular queue 
jmp instruction context switch procedure ing thread points context switch procedure thread 
assume thread currently running 
time quantum expires interrupt vectored thread context switch procedure sw 
procedure saves cpu registers thread register save area tt reg 
jmp instruction directs control ow entry points thread thread context switch procedure sw sw mmu 
control ows sw mmu change address space required control ows sw 
context switch procedure loads cpu vector base register address thread vector table restores cpu general registers resumes execution thread 
context switch takes microseconds see table 
striking example achieved optimization synthesized code 
thread operations thread supports operations 
operations invoked hardware error trap handlers interrupt handlers fall category 
operations invoked threads signal start 
introduce brie operations describe interrupt handling section 
synthesis systems signal asynchronous software interrupt sent thread interrupt handler thread 
synthesized signal system call signal procedure receiving thread calls signal handler procedure 
run signal handler user mode user signal system call alters general registers area receiving thread tte receiving thread call signal handler activated 
thread control debugger support implemented synthesized system calls start step 
system call suspends execution thread removing thread tte ready queue 
start system call puts tte back 
step system call causes stopped thread execute single machine instruction 
debugger runs asynchronous thread shares debugged 
error trap synchronous hardware interrupt generated illegal operations referencing non existent memory dividing zero 
hardware interrupts error trap handlers run kernel mode 
hardware interrupts error traps synchronous occur immediately illegal operation 
error trap handlers 
allow arbitrarily complex error handling user mode send error signal interrupted thread 
error signal handler runs user mode described 
send error signal error trap handler copies kernel stack frame user stack modi es return address kernel stack user error signal procedure executes return exception takes thread user error signal procedure 
synthesized thread creation time error trap handlers consume machine instructions supporting cient emulation unimplemented kernel calls machine instructions 
unix emulator performance measurement implemented traps 
scheduling currently scheduling policy round robin adaptively adjusted cpu quantum thread 
priorities synthesis uses scheduling assigns larger smaller quanta threads need execute criterion 
detailed explanation ne grain scheduling scope idea implementation synthesis described detail 
give brief informal summary 
directed graph model computation section thread need execute determined rate data ows 
cpu time consumed thread increasing function data ow faster rate faster thread needs run 
scheduling algorithm assigns larger cpu quantum thread 
kind scheduling ne granularity cpu requirements rate rate may change quickly requiring scheduling policy adapt changes 
ective cpu time received thread determined quantum assigned thread divided sum quanta assigned threads 
priorities simulated preferential treatment certain threads ways may raise thread cpu quantum may reorder ready queue threads block 
event unblocks thread tte placed front ready queue giving immediate access cpu 
way minimize response time events 
minimize time spent context switching cpu quanta adjusted large possible maintaining ne granularity 
atypical microseconds 
input output synthesis means device drivers 
includes data ow hardware devices 
data move logical channels call streams connect source destination data ow 
details stream model described separate 
describe streams implemented building blocks described section 
device servers physical devices encapsulated called device servers 
typically device server interface supports usual operations write 
general write denotes data ow direction control ow caller callee read denotes data ow opposite direction control ow callee back caller 
device server may threads 
polling server run continuously thread 
interrupt driven server block initialization 
server threads wakes physical device generates interrupt 
high level servers may composed basic servers 
boot time kernel creates servers raw physical devices 
simple example pipelines output raw server lter 
concretely synthesis equivalent tty driver lter processes output raw tty server interprets erase kill control characters 
lter reads characters raw keyboard server dedicated queue 
send characters screen lter writes optimistic queue output come user program echoing input characters 
default le system server composed lter stages 
connected disk hardware disk device server 
stage pipeline disk scheduler disk request queue followed default le system cache manager contains queue data transfer bu ers 
directly connected cache manager synthesized code read currently open les 
le systems share physical disk unit connect disk scheduler monitor switch 
disk scheduler redirect data ow appropriate stream 
synthesized code pipeline low overhead shown measurements section 
producer consumer implementation stream model synthesis summarized known producer consumer paradigm 
stream control ow directs data ow 
cases producer consumer relationships shall consider turn 
simplest case active producer passive consumer vice versa 
case called active passive simple implementations 
producer consumer single single procedure call job 
multiple producers consumers multiple single attach monitor multiple participants serialize access 
normal producer consumer problem active producer active consumer 
case called active active requires queue mediate 
single single case sp sc queue su ces 
multiple single case may attach monitor multiple resulting mp sc mp mc queues 
queue may synchronous blocking asynchronous signals depending situation 
case passive producer passive consumer 
example program clock producer ready provide reading time display consumer accepts new pixels painted screen 
cases pump reads clock time producer writes information new pixels consumer 
works multiple passive producers consumers 
summary wehave cient implementation case producer consumer problem 
stream model easily described composition producers consumers building blocks switches monitors queues shown generality implementation 
practice composing new device server building blocks straightforward 
interrupt handling heart device server interrupt handler 
interrupt processing combines elements procedure calls context switches 
procedure call interrupt pushes currently executing stack return address 
interrupt handling nishes execution resumes interrupted instruction current thread 
context switch interrupt unexpected unrelated current thread 
furthermore interrupt handler temporarily changes program counter general registers current thread receiving arguments returning results current thread 
synthesis interrupt handling di ers traditional os unix thread synthesis synthesizes interrupt handling routine system calls 
customized interrupt handlers system calls faster general purpose equivalents 
examples synthesized interrupt handlers timer interrupt context switch current thread section analog digital bu ered queue section 
way increase concurrency kernel push bulk interrupt processing character arrives dev tty queue separate thread created interrupt handler 
cases separate thread normal interrupts require little processing 
simple cases interrupt handler run currently executing thread avoid context switch 
take restore registers interrupt handler 
short interrupt processing higher level interrupts may happen long interrupt handling simple scenario repeats eventually highest level interrupt processing completes returns level 
ultimately entire stack handled 
thread running simple interrupt handler take care recursive interrupts signals may cause synchronization problems 
choices handle signal middle interrupt create new thread nish interrupt delay processing signal 
delaying signal costs bypasses creation new thread degrade system performance signi cantly current interrupt handling quick 
procedure chaining delay signal linking signal processing routine interrupt handler 
synthesis thread vector table points routines servicing hardware interrupts error traps system calls 
principle thread may completely di erent set interrupt handlers currently majority shared threads 
system calls frequently customized thread 
particular operations write synthesized open operation 
new opened les devices threads thread system call vectors changed point synthesized procedures 
creation thread vector table lled default set system calls error vectors help debugging 
optimizations boot time kernel uses collapsing layers optimize device servers 
example communicating raw tty pipe conceptual model tty procedure call raw tty get character 
transforms combination active passive producer consumer pair procedure call 
pipeline tty actively reads tty device actively writes forming pair connected sp sc optimistic queue 
optimization bu ered queue 
usually queue operations cheap dozen instructions compared processing time element queue 
cases data movement little queue operation queue operations main overhead 
bu ered queues kernel code synthesis generate specialized queue insert operations couple instructions moves chunk data di erent area queue element 
way overhead queue insert amortized blocking factor 
example device server handles single word interrupts second packing queue element hardware described section 
raw sun data sun synthesis synthesis descr 
user sys tot watch emulator ratio compute pipe 
kb pipe mb sec pipe mb sec file mb sec open null close 
open tty close 
table measured unix system calls seconds measurements environment current implementation synthesis runs experimental machine called similar sun motorola cpu mb wait state main memory mb hard disk inch 
addition unusual devices channel bit analog output channel bit analog input compact disc player interface kx kx bit er graphics processor 
designed instrumented aid systems research 
measurement facilities include instruction counter memory counter hardware program tracing microsecond resolution interval timer 
cpu operate mhz mhz 
normally run mhz 
setting cpu speed mhz introducing wait state memory access closely emulate performance sun 
written unix emulator running top synthesis kernel capable servicing sunos kernel calls 
simplest case emulator translates unix kernel call equivalent synthesis kernel call 
multiple synthesis primitives unix call 
hardware software emulation run object code equivalent fair comparison synthesis sunos 
benchmark programs compiled sun cc sunos release 
executable timed sun brought executed unix emulator 
validate emulation rst benchmark program compute bound test machines 
test program implements function producing chaotic sequence 
touches large array non contiguous points ensures just measuring cache perfor mance 
comparing synthesis sunos purpose making synthesis hardware software emulate sun compare synthesis sunos kernel calls 
executables comparison direct 
table summarize compare results measurements 
columns raw sun data obtained time command stopwatch 
sun unloaded measurements time reported cpu available 
synthesis emulator data obtained microsecond resolution real time clock rounded second 
times veri ed stopwatch running test times obtain easily measured time interval 
source code programs numbered included appendix program computation intensive calibration function validate hardware emulation 
calibration program shows synthesis emulator roughly slower sun 
learned sun runs mhz faster mhz 
programs write read back data pipe chunks bytes 
show remarkable speed advantage times single byte read write operations 
due combination synthesized kernel calls short ne grain scheduling reduces average queue operation costs 
chunk grows page size di erence signi cant times 
generated code loads long words registers stores back 
unrolled loops achieves data transfer rate mb second 
program reads writes le cached main memory chunks bytes 
program earlier measurement shows improvement current implementation synthesis 
include programs open close dev null dev tty show synthesis kernel code generation cient 
open close operations synthesize code read write times faster unix open code generation 
synthesis le system entirely memory resident loops kept data pages sunos memory bu ers minimizing di erence 
table contains details le system operations discussed section 
synthesis kernel calls obtain direct timings synthesis kernel call times microseconds synthesis kernel monitor execution trace records memory instructions executed current thread 
trace calculate native unix operation time usec emulation usec emulation trap overhead open dev null open dev tty open file close read char file read chars file read dev null data kernel queues bu er cache 
table file device microseconds operation time usec create destroy start step signal thread thread table thread operations microseconds exact kernel call times counting memory instruction execution time 
tables show timings calculated sun emulation mode 
running full speed mhz actual performance times faster 
table le device operations 
operations native synthesis le device calls 
comparison native mode emulator mode shows cost unix emulation synthesis 
worth noting table cost open 
simplest case open dev null takes microseconds nd le hashed string names stored backwards code synthesis read write null 
additional microseconds opening dev tty come generating real code read write 
opening le implies synthesizing sophisticated code bu er allocations additional microseconds 
table see synthesis threads light weight microsecond creation time 
needed ll approximately kbytes tte rest 
short time start step thread possible trace debug threads highly interactive way 
operation time usec full context switch full context switch fp registers partial context switch block thread unblock thread thread floating point processor 
table dispatcher scheduler microseconds operation time usec service raw tty interrupt service raw interrupt set alarm alarm interrupt chain procedure re try chain procedure re try chain signal thread delayed interrupt table interrupt handling microseconds table see context switch times consumed dispatcher 
note timings achieved generated code executable data structures case 
separation oating point processor shorten main critical path explained section 
table shows timings interrupt handling alarm setting handling signaling 
example raw tty interrupt handling simply picks character 
attentive readers noticed measurement gures faster traditional run time library routines 
example naive implementations memory allocation block copy string comparison slowed system considerably 
synthesis memory allocation routine executable data structure implementing fast heap randomized traversal added 
block copy read outlined section 
string comparison mentioned part open earlier section 
kernel size synthesis kernel written assembly language fast prototyping language 
may sound peculiar usually people high level programming languages fast prototyping 
lack support cient dynamic code synthesis particular cient static code generation general unable nd suitable compiler 
actively pursuing design implementation high level programming language development generation synthesis 
rough breakdown kernel shows lines code raw device drivers tty disk graphics lines creator lines templates code synthesis queues threads les lines utilities shared library printf lines kernel monitor high level debugging programming tools 
kernel assembles kbytes kernel monitor 
concern kernel size code generation little functions add lot memory 
space advantages code generation 
true synthesis kernel running threads having open les memory unix system running similar load heavily loaded systems normally seen 
lightly loaded system static kernel size dominates space allocated dynamically 
synthesis excels 
processes running synthesis kernel occupies 
threads created les opened space requirements go 
small static space required kernel means run synthesis small pc computers embedded industrial controllers application areas tens threads running simultaneously 
hand run jobs concurrently probably extra memory space run 
expect techniques described useful operating system implementors 
speci cally wehave kernel code synthesis optimistic synchronization ne grain scheduling increase os kernel concurrency ciency implementation synthesis kernel support threads input output 
toachieve high performance synthesis repeatedly apply principle simplest abstraction cheapest implementation case 
level abstraction synthesis kernel interface kernel data structures algorithms eliminated sophisticated algorithms implement 
di erent tricks speed synthesis kernel common theme simpli cation normal case dictated principle 
kernel code synthesis shortens normal execution path binding system state early subsequent kernel calls simply jump generated rou avoiding system state traversal repetition 
code generation time apply known compiler optimization techniques constant folding common sub expression elimination 
applied synthesis including threads input output 
reduced synchronization shortens critical path careful set exception handling 
example implemented queue operations optimistic synchronization 
synthesis kernel data structures queues kernel basically runs inter locking 
expect especially important synthesis multi processor designed 
combining kernel code synthesis optimistic synchronization achieved high performance compared mature commercial systems 
example unix emulator running hardware emulator sun run binary executable synthesis performance threads times dozen times better sunos 
optimistic synchronization best suited multi processor ne grain scheduling distributed system expect performance gains run synthesis environments 
acknowledgments partially funded new york state center advanced technology computer information systems cu foundation special purpose national science foundation cda 
acknowledge hardware parts contributed hitachi ibm motorola 
special go john ousterhout shepherd sosp program committee member helped shape style content 
anonymous sunos release source code 
sun microsystems source license 
douglas hofstadter 
godel escher bach eternal golden braid 
basic books 
massalin pu 
fine grain scheduling 
proceedings workshop experience building distributed systems asilomar october 
pu massalin 
model computation synthesis 
technical report cucs department computer science columbia university preparation 
pu massalin ioannidis 
synthesis kernel 
computing systems winter 
stephenson 
fast ts 
proceedings ninth acm symposium operating systems principles pages october 
wulf cohen jones levin pierson pollack 
hydra kernel multiprocessing operating system 
communications acm june 
measurement programs 
