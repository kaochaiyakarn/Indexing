better best parsing liang huang dept computer information science university pennsylvania walnut street philadelphia pa cis upenn edu discuss relevance best parsing applications natural language processing develop efficient algorithms best trees framework hypergraph parsing 
demonstrate efficiency scalability accuracy algorithms experiments bikel implementation collins lexicalized pcfg model chiang cfg decoder hierarchical phrase translation 
show particular improved output algorithms potential improve results parse reranking systems applications 
problems natural language processing nlp involve optimizing objective function set possible analyses input string 
set exponential sized compactly represented merging equivalent 
objective function compatible packed representation optimized efficiently dynamic programming 
example distribution parse trees sentence pcfg represented packed forest highest probability tree easily extracted 
objective function compatible packed representation exact inference intractable 
alleviate problem common approach machine learning loopy belief propagation pearl 
solution popular nlp split computation phases phase compatible objective function produce best list top candidates serves approximation full set 
second phase optimize analyses best list 
typical example discriminative reranking best lists generative module collins parsing shen david chiang inst 
advanced computer studies university maryland av williams college park md umiacs umd edu translation reranking model nonlocal features computed parsing proper 
example minimum bayes risk decoding kumar byrne goodman assuming defines probability distribution candidates seeks candidate highest expected score arbitrary metric parseval bleu general metric compatible parsing algorithm best lists approximate full distribution similar situation occurs parser produce multiple derivations regarded equivalent multiple lexicalized parse trees corresponding parse tree want maximum posteriori parse sum equivalent derivations 
equivalence relation general compatible parsing algorithm best lists approximate data oriented parsing bod speech recognition mohri riley 
instance best approach cascaded optimization 
nlp systems cascades modules want optimize modules objective functions jointly 
module incompatible packed representation previous module due factors non local dependencies 
want postpone disambiguation propagating best lists subsequent phases joint parsing semantic role labeling gildea jurafsky sutton mccallum information extraction coreference resolution wellner formal semantics tag joshi vijay shanker 
discriminative training uses best lists approximate normalization constant partition function intractable train model optimizing metric incompatible packed representation 
example och shows train log linear translation model maximizing likelihood training data maximizing bleu score metrics model data 
similarly chiang uses best parsing algorithm described cfg log linear translation model order learn feature weights maximize bleu 
algorithms packed representations graphs hidden markov models finitestate methods ratnaparkhi parser ratnaparkhi stack machine translation decoders brown och ney best paths problem studied pure algorithmic context see eppstein sinclair surveys nlp speech community mohri mohri riley 
aims best tree algorithms packed representations hypergraphs gallo klein manning equivalently graphs packed forests includes parsers parsing mt decoders 
algorithm expressible weighted deductive system shieber goodman nederhof falls class 
experiments apply algorithms lexicalized pcfg parser bikel similar collins model collins synchronous cfg machine translation system chiang 
previous pointed charniak johnson major difficulty best parsing dynamic programming 
simplest method abandon dynamic programming rely aggressive pruning maintain tractability collins bikel 
approach prohibitively slow produces best lists see sec 

gildea jurafsky described overhead extension cky algorithm reimplemented collins model obtain best parses average parses sentence 
algorithm turns special case algorithm sec 
reported prohibitively slow 
original design algorithm described aware efforts closely related jim nez done parallel charniak johnson 
jim nez algorithm similar algorithm sec 
charniak johnson propose algorithm similar algorithm multiple passes improve efficiency 
apply method charniak parser get best lists reranking yielding improvement parsing accuracy 
differs jim nez respects 
formulate parsing problem general framework hypergraphs klein manning making applica ble wide variety parsing algorithms jim nez define algorithm extension cky cfgs chomsky normal form cnf 
generalization theoretical importance critical application state theart parsers collins charniak 
collins parsing model instance rules dynamically generated include unary productions making hard convert cnf preprocessing algorithms applied directly parsers 
second algorithm improvement jim nez leads slight theoretical empirical speedup 
third implemented algorithms top state art large scale statistical parser decoders report extensive experimental results jim nez tested relatively small grammars 
hand algorithms scalable general coarse fine approach charniak johnson 
experiments obtain best lists nearly fast best parsing modest memory 
charniak adopted algorithm parser implementation confirmed findings 
literature shortest path problems minieka generalized floyd algorithm way similar algorithm lawler improved idea similar little slower binary branching case algorithm 
hypergraphs gallo 
study shortest hyperpath problem nielsen 
extend shortest hyperpath 
nielsen aspects 
solve problem best derivations trees best hyperpaths cases coincide see sec 
discussions 
second assumes non negative costs probabilities apply dijkstra algorithms 
generative models suffer problem general models log linear models may require negative edge costs mcdonald taskar 
viterbi algorithm applicable long hypergraph acyclic mcdonald 
get best parses 
formulation klein manning weighted directed hypergraphs gallo abstraction probabilistic parsing problem 
definition 
ordered hypergraph henceforth hypergraph tuple finite set vertices finite set hyperarcs set weights 
hyperarc triple head vector tail nodes 
weight function distinguished vertex called target vertex 
note definition different previous sense tails vectors sets allow multiple occurrences vertex tail ordering components tail 
definition 
hypergraph said monotonic total ordering weight function monotonic arguments rm ai ai am am 
define comparison function min output 
assume monotonicity corresponds optimal substructure property dynamic programming cormen 
definition 
denote arity hyperarc 
constant call source vertex 
define arity hypergraph maximum arity hyperarcs 
definition 
backward star bs vertex set incoming hyperarcs 
degree bs 
definition 
derivation vertex hypergraph size weight recursively defined follows bs derivation size weight 
bs di derivation ti derivation size di weight 

ordering weights induces ordering derivations iff 
definition 
define di th best derivation think 
dk components vector shall denote 
best derivations problem hypergraphs find hypergraph derivations ranked introduce nonrecursive representation derivations analogous back pointers parser implementation 
definition 
derivation back pointers dbp tuple bs 
correspondence derivations accordingly extend weight function turn induces ordering iff 
di denote th best dbp confusion arise terms derivation dbp interchangeably 
computationally best problem stated follows hypergraph arity compute 
dk 
shown klein manning hypergraphs represent search space parsers just graphs known lattices represent search space finite state automata hmms 
generally hypergraphs represent search space weighted deductive system nederhof 
example weighted cky algorithm context free grammar chomsky normal form cnf input string represented hypergraph arity follows 
item represented vertex corresponding recognition nonterminal spanning positions production rule yz free indices hyperarc corresponding instantiation inference rule complete deductive system shieber weight function defined ab pr yz nederhof 
sense hypergraphs thought compiled instantiated versions weighted deductive systems 
parser traverse hypergraph 
order derivation values computed correctly need traverse hypergraph particular order definition 
graph projection hypergraph directed graph bs 
hypergraph said acyclic graph projection directed acyclic graph topological ordering ordering topological ordering sources target 
assume input hypergraph acyclic topological ordering traverse 
practice hypergraph typically known advance note defined weight derivation function derivations practice store derivation weight inside dbp avoid recomputing 
examples hypergraph hyperpath derivation hypergraph target vertex source vertices hyperpath derivation vertex appears twice different sub derivations 
impossible hyperpath 
topological ordering dynamic hypergraph generated order 
example cky sufficient generate items items arbitrary nonterminals 
derivations hyperpaths klein manning introduces correspondence hyperpaths derivations 
extended best case correspondence longer holds 
definition 
nielsen hypergraph hyperpath destination acyclic minimal hypergraph 


source vertex connected source vertex 
illustrated derivations trees different hyperpaths minimal hypergraphs sense derivation vertex appear possibly different sub derivations represented hyperpath 
derivations problem solve different nature shortest hyperpaths problem nielsen 
problems coincide sub derivations optimal reason best hyperpath algorithm klein manning similar best tree algorithm knuth 
best case coincide hypergraph isomorphic case factor diagram cfd mcallester proof omitted 
derivation forest cfg parsing cky algorithm instance represented cfd forest earley algorithm 
earley derivation 
note item appears twice predict complete 
procedure viterbi topological order bs incoming hyperarcs min update generic best viterbi algorithm item equivalently vertex hypergraph appear twice earley derivation prediction rule see example 
best derivations problem potentially applications tree generation knight modeled hyperpaths 
detailed discussions line scope 
algorithms traditional best viterbi algorithm traverses hypergraph topological order vertex calculates best derivation incoming hyperarcs bs see 
take arity hypergraph constant time complexity algorithm 
algorithm na goodman mohri isolate basic operations line best algorithm generalized order extend algorithm formation derivation best subderivations generalization binary operator semiring second min chooses better derivations operator idempotent semiring mohri 
generalize operations operate best lists 

new multiplication operation mult performed steps 
enumerate derivations jr ji 
time 

sort derivations weight 
time log rk log 

select elements sorted list elements 
time 
time complexity mult rk log 
extend min merge takes vectors length fewer input outputs top sorted order elements 
similar merge sort cormen done linear time 
need rewrite line viterbi algorithm extend best case merge mult time complexity line log making complexity log consider arity hypergraph constant 
space complexity vertex need store vector length context cky parsing cfg best viterbi algorithm complexity version log slower factor log 
algorithm speed mult seek exploit fact input vectors sorted function monotonic interested top elements possibilities 
define vector elements de fine vector elements bi 
compute pe mult maintain candidate set derivations potential best derivation list 
picture input dimensional space contains derivations need sort elements order extract top efficient algorithm cormen select kth best element elements time 
improve overhead 
included pe boundary 
initialized 
step extract best derivation call append pe 
replaced neighbors see illustration 
implement priority queue cormen extraction best derivation efficient 
iteration extract min insert operations 
binary heap implementation priority queues get log time complexity iteration 
interested top elements iterations time complexity single mult log yielding time complexity log reducing multiplicative overhead factor assuming constant 
context cky parsing reduces overhead log 
shows additional pseudocode needed algorithm 
integrated viterbi algorithm simply rewriting line invoke function mult merge mult algorithm combine merge mult speed merge mult similar idea 
letting mult generate full derivations hyperarc applying merge results combine candidate sets hyperarcs single candidate set 
initialize bs set top parses incoming hyperarc cf 
algorithm 
suffices keep top bs candidates lead significant speedup case bs top derivation top derivation remove element replace elements algorithm 
full pseudocode algorithm shown 
algorithm compute mult lazily algorithm exploited idea lazy computation performing mult times necessary 
algorithm calculates full best list vertex hypergraph interested maintain min heap min heap reduce iteration cost log fibonacci heap improve log 
techniques change complexity constant see 
implemented linear time algorithm quick select cormen 
illustration algorithm dimensions 
numerical monotonic function defined italic numbers axes ai respectively 
want compute top results ai 
iteration current frontier shown oval boxes bold face denoting best element 
element extracted replaced neighbors iteration 
function mult cand initialize heap empty list result mult cand cand return procedure cand extract min cand append 
add neighbors ti cand insert cand add heap part algorithm 
procedure topological order procedure initialize heap cand cand procedure temp bs cand top elements temp prune away useless candidates cand algorithm procedure global kth derivation computed 
return cand defined visit vertex 
append extract min cand cand cand initialize heap best derivation append extract min cand update heap adding successors derivation get best derivation delete heap procedure cand 
add neighbors bi ti recursively solve sub problem ti cand insert cand exists heap add heap algorithm algorithm time complexity best viterbi algorithm ek log algorithm ek log algorithm vk log algorithm dmax log generalized dmax log table summary algorithms 
best derivations target vertex goal item 
take laziness extreme delaying best calculation parsing 
algorithm assumes initial parsing phase generates hypergraph finds best derivation item second phase proceeds algorithm starts goal item calls recursively necessary 
pseudocode algorithm shown 
side note second phase applicable cyclic hypergraph long derivation weights bounded 
algorithm complexity log algorithm dmax log dmax size longest top derivations cfg cnf dmax 
significant improvements algorithms turns multiplicative overhead additive overhead 
practice usually dominates cky parsing cfg 
theoretically running times grow slowly increases exactly demonstrated experiments 
summary discussion algorithms algorithms best viterbi algorithm generalized jim nez algorithm compared table 
key difference algorithm jim nez algorithm restriction top candidates making heaps line see sec 

line algorithm considered generalization jim nez algorithm case acyclic monotonic hypergraphs 
line responsible improving time complexity dmax log generalized jim nez algorithm dmax log maxv bs maximum degree vertices 
case algorithm outperforms jim nez experiments report results sets experiments 
probabilistic parsing implemented algorithms top widely parser bikel conducted experiments parsing efficiency qual ity best lists 
implemented algorithms parsing mt decoder chiang report results decoding speed 
experiment bikel parser bikel parser state art multilingual parser lexicalized context free models collins eisner 
support best parsing collins parse reranking collins see section accomplishes simply abandoning dynamic programming items considered equivalent charniak johnson 
theoretically time complexity exponential input sentence length constant merging equivalent items limit number items chart 
practice beam search reduce observed time 
standard beam width method prohibitively expensive bikel parser 
collins narrower beam applied cell limit show detrimental effect quality output 
omit method speed comparisons implementation algorithm na baseline 
implemented best algorithms top bikel parser conducted experiments ghz bit amd opteron gb memory 
program written java running sun jvm server mode maximum heap size gb 
experiment sections penn treebank ptb marcus training data section sentences evaluation standard 
ran bikel parser settings emulate model collins 
efficiency tested algorithms various conditions 
comparison average parsing time sentence algorithms section standard beam width shows parsing speed algorithm improved dramatically algorithms nearly constant exactly matches complexity analysis 
algorithm log significantly outperforms baseline na algorithm log 
comparison algorithm jim nez algorithm terms average beam search threshold pruning cell chart typically containing items corresponding span reduced discarding items worse times score best item cell 
known beam width 
type pruning known histogram pruning best items kept cell 
called cell limit 
average parsing time seconds algorithm algorithm algorithm average parsing speed 
vs vs log log average heap size jm algorithm beam algorithm beam jm algorithm beam algorithm beam average heap size alg 
vs jim nez efficiency results best algorithms compared jim nez algorithm heap size 
shows larger algorithms average heap size smaller algorithm considerably smaller average heap size 
difference useful applications short best lists needed 
example mcdonald 
find gives optimal parsing accuracy 
accuracy efficient best algorithms enable search larger portion search space aggressive pruning producing best lists better quality previous methods 
demonstrate comparing best lists ratnaparkhi collins parallel charniak johnson ways including oracle reranking average number parses 
ratnaparkhi introduced idea oracle reranking suppose exists perfect reranking scheme magically picks best parse highest score top parses sentence 
performance oracle reranking scheme upper bound actual reranking system collins increases score nondecreasing large score converges 
ratnaparkhi reports experiments oracle reranking statistical parser compute best parses experiments 
collins parse reranking experiments model parser collins beam width cell limit obtain best lists average number parses obtained sentence maximum 
charniak johnson coarse fine parsing top charniak parser get best lists section 
compares results oracle reranking 
collins curve converges continues increase 
beam width parser plus oracle reaches score compared collins 
charniak johnson completely different parser best score points higher collins making difficult compare absolute numbers 
compared relative improvement best 
shows largest percentage improvement terms score 
explore impact collins cell limit quality best lists plotted average number parses sentence length 
generally speaking input sentences get longer number parses grows exponentially 
see curve collins best list goes large 
suspect due cell limit pruning away potentially parses early chart 
sentences get longer lower probability parse contribute eventually best parses 
infer collins best lists limited quality large demonstrated early convergence oracle reranking score 
comparison curves beam widths continue grow 
experiments suggest best parses better quality previous best parsers reason maximum collins merged best list beam best list beam collins 
oracle score charniak johnson beam width collins ratnaparkhi oracle reranking percentage improvement best charniak johnson beam width collins ratnaparkhi relative improvement relative scores oracle reranking top parses section compared charniak johnson collins ratnaparkhi 
average number parses sentence length beam width beam width collins beam width average number parses sentence length section beam width compared collins 
seconds algorithm algorithm algorithm compared algorithm offline mt decoding task 
average time excluding initial best phase vs log log 
similar quality charniak johnson far highest score reranking lead better results real parse reranking 
experiment mt decoder second experiment cky decoder machine translation system chiang implemented python accelerated 
implemented algorithms compute best english translations mandarin sentences 
cfg system large millions rules effectively intersected finite state machine english side language model grammar constant system quite large 
decoder uses relatively narrow beam search efficiency 
ran decoder ghz xeon gb memory sentences nist test set 
tested algorithm algorithm offline algorithm 
sentence measured time calculate best list including initial best parsing phase 
averaged times test set produce graph shows algorithm runs average times faster algorithm 
furthermore able test algorithm reasonable amount time 
curvature plot algorithm may due lack resolution timing function short times 
problem best parsing effect best list size quality applications subjects increasing interest nlp research 
general purpose algorithm best parsing applied state art large scale nlp systems bikel implementation collins lexicalized pcfg model bikel collins chiang synchronous cfg decoder chiang machine translation 
hope encourage investigation larger better best lists improve performance nlp applications questions intend pursue 
anonymous reviewers previous version pointing jim nez eugene charniak mark johnson providing early draft useful comments 
extremely grateful dan bikel help experiments michael collins providing data 
go dan gildea jonathan julia aravind joshi kevin knight daniel marcu mitch marcus ryan mcdonald fernando pereira giorgio satta shen hao zhang 
bikel 

intricacies collins parsing model 
computational linguistics 
bod 

parsing shortest derivation 
proc 
eighteenth international conference computational linguistics coling pages 
sinclair 

comparative study shortest path algorithms 
proc 
th uk performance engineering workshop computer telecommunications systems 
brown cocke della pietra della pietra jelinek lai mercer 

method system natural language translation 
patent 
charniak 

maximum entropy inspired parser 
proc 
meeting north american chapter association computational linguistics naacl pages 
charniak johnson 

coarse finegrained best parsing discriminative reranking 
proc 
acl 
chiang 

hierarchical phrase model statistical machine translation 
proc 
acl 
collins 

discriminative reranking natural language parsing 
proc 
seventeenth international conference machine learning icml pages 
morgan kaufmann 
collins 

head driven statistical models natural language parsing 
computational linguistics 
cormen leiserson rivest stein 

algorithms 
mit press second edition 
eisner 

bilexical grammars parsing algorithms 
bunt nijholt editors advances probabilistic parsing technologies pages 
kluwer academic publishers 
eppstein 

bibliography shortest paths best solutions problems 
www ics uci edu eppstein bib 
gallo longo pallottino 

directed hypergraphs applications 
discrete applied mathematics 
gildea jurafsky 

automatic labeling semantic roles 
computational linguistics 
goodman 

parsing inside 
ph thesis harvard university 
goodman 

semiring parsing 
computational linguistics 
jim nez 

computation best parse trees weighted stochastic context free grammars 
proc 
joint iapr international workshops advances pattern recognition 
joshi vijay shanker 

compositional semantics lexicalized tree adjoining grammar ltag underspecification necessary 
bunt editors proc 
pages 
klein manning 

parsing hypergraphs 
proceedings seventh international workshop parsing technologies iwpt october beijing china 
tsinghua university press 
knight 

overview probabilistic tree transducers natural language processing 
proc 
sixth international conference intelligent text processing computational linguistics lncs 
knuth 

generalization dijkstra algorithm 
information processing letters 
kumar byrne 

minimum bayes risk decoding statistical machine translation 
hlt naacl 
lawler 

comment computing shortest paths graph 
comm 
acm 
marcus santorini marcinkiewicz 

building large annotated corpus english penn treebank 
computational linguistics 
mcallester collins pereira 

diagrams structured probabilistic modeling 
proc 
uai 
mcdonald crammer pereira 

online large margin training dependency parsers 
proc 
acl 
minieka 

computing sets shortest paths graph 
comm 
acm 
mohri 

semiring frameworks algorithms shortest distance problems 
journal automata languages combinatorics 
mohri riley 

efficient algorithm best strings problem 
proceedings international conference spoken language processing icslp denver colorado 
nederhof 

weighted deductive parsing knuth algorithm 
computational linguistics pages 
nielsen andersen 

finding shortest hyperpaths 
computers operations research 
och 

minimum error rate training statistical machine translation 
proc 
acl pages 
och ney 

alignment template approach statistical machine translation 
computational linguistics 
pearl 

probabilistic reasoning intelligent systems networks plausible inference 
morgan kaufmann 
ratnaparkhi 

linear observed time statistical parser maximum entropy models 
proc 
emnlp pages 


representation just time specialization prototype python 
heintze sestoft editors proceedings acm sigplan workshop partial evaluation semantics program manipulation pages 
shen sarkar och 

discriminative reranking machine translation 
proc 
hlt naacl 
shieber schabes pereira 

principles implementation deductive parsing 
journal logic programming 
sutton mccallum 

joint parsing semantic role labeling 
proc 
conll 
taskar klein collins koller manning 

max margin parsing 
proc 
emnlp 
wellner mccallum peng hay 

integrated conditional model information extraction coreference application citation matching 
proc 
uai 
