appears aamas workshop agent tracking modeling agents observations utility approach intention recognition mao university southern california institute creative technologies way marina del rey ca mao ict usc edu assumption rational agent adopt plan maximizes expected utility utility approach plan recognition problem 
approach explicitly takes observed agent preferences consideration computes estimated expected utilities plans disambiguate competing hypotheses 
online plan recognition realized incrementally plan knowledge observations change state probabilities 
discuss compare probabilistic models 

overview schmidt identified plan recognition problem right plan recognition applied widely variety domains including natural language understanding generation allen perrault carberry story understanding wilensky charniak goldman multi agent coordination huber dynamic traffic monitoring pynadath wellman collaborative systems ferguson adventure game albrecht network intrusion detection geib goldman multiagent team monitoring kaminka 
plan recognition approaches proposed 
kautz allen formal theory plan recognition mccarthy circumscription 
define plan recognition problem identifying minimal set top level actions sufficient explain observed actions minimal covering set principle disambiguation 
deal uncertainty inherently plan inference charniak goldman jonathan gratch university southern california institute creative technologies way marina del rey ca gratch ict usc edu built probabilistic model plan recognition bayesian reasoning 
system supports automatically generation belief network bn observed actions network construction rules 
constructed belief network understanding character actions story 
huber durfee wellman prs general language plan specification 
gave dynamic mapping prs specification belief networks applied approach coordinate multi agent team 
pynadath wellman proposed probabilistic method parsing 
approach employs probabilistic state dependent grammars represent agent plan generation process 
psdg representation inference algorithms supports efficient answering restricted plan recognition queries 
bui proposed online probabilistic policy recognition method hidden markov model ahmm extension ahmm allowing policies memories ahmem 
frameworks scalability policy recognition models achieved approximate inference scheme rao blackwellised particle filter 
bayesian models probabilistic approaches dempster shafer theory carberry bauer 
approaches differ plan recognition systems infer hypothesized plan observed actions 
world states particular state desirability typically represented utilities states rarely considered recognition 
hand real world applications utilities different outcomes known blythe 
planning agent usually takes account actions may different outcomes outcomes desirable 
agent decisions acts world agent needs balance different possible outcomes order maximize expected utility goal attainment 
plan render assistance troop aa child aa troop stay troop helping treat child child cured 
competing plans troop mother perspective utility rationality issues explored earlier ai rational assumptions doyle 
plan recognition viewed inferring decision making strategy observed agent 
natural assume rational agent adopt plan maximizes expected utility 
current probabilistic approaches capture fact observed actions support hypothesized plan missing part utility computation 
take decision theoretic view explicitly consider outcome utilities plan recognition 
different ways address utility issue plan recognition believe different approaches appropriate different problem domains 
mao gratch proposed possible ways refine problem 
extensions probabilistic reasoning framework incorporating utility nodes belief networks adjust prior conditional probabilities conditional probability tables cpts 
third proposal takes viewpoint 
computes expected utilities plans chooses plan candidate maximal expected utility evidence far 
focuses third solution 
remainder organized follows 
motivate section illustrate example leadership training environment 
section introduces plan representation adopt 
section approach intention recognition computing expected utility possible plans 
illustrate approach motivating example 
section discusses related plan support inspection troop aa child aa troop leave compares approach bayesian probabilistic models 
section summarize raise 

motivating example troop transit support supported consider example context mission rehearsal exercise mre leadership trainer developing rickel 
human trainee command troop operation support unit eagle 
route troop vehicles severely injured civilian child 
trainee balance continue mission render aid 
decisions outcomes possible 
scenario injured boy mother virtual agent observed troop actions trying infer troop plan predict subsequent actions 
mother simple task model troop 
kept possible plans troop mind see 
plan render assistance composed troop stay treat child 
plan support inspection consists troop leave support eagle 
simplification troop stay troop leave treat child support eagle primitive actions 
action nondeterministic effects shown 
troop transit child cured eagle supported action effects 
outcomes child cured eagle supported goals render assistance support inspection utility values respectively example simplified plan may outcome 
typically belief networks bayesian reasoning step create random variable belief network representing top level plan 
rest variables dependency arcs probability values provide evidence proposition top plan pursued observed agent 
step create random variable action plan 
adoption top plan causes execution actions dependency arc top plan action node belief network 
step add evidence variables belief network represent dependencies actions observed evidence context 
suppose example initially plans support inspection prior probability cpts node belief network plan identical corresponding nodes plan 
plans different outcome utilities different probabilities achieve outcomes shown 
scenario proceeded assume trainee decided send moving forward support eagle 
mother observed half troop staying half leaving 
observed action equally support plans bayesian reasoning infer plans identical posterior probability see results mao gratch 
example outcome desirable troop achieved 
intuitively troop actively pursue plan 
current probabilistic models distinction outcome utility outcome probability explicitly plan inference 
address problem introduce plan representation approach 

plan representation adopt probabilistic plan representation approach 
action consists set preconditions effects 
actions non deterministic effects denoted effect prob action effect conditional effects 
represent success failure action execution actions execution probability denoted execute prob action 
likelihood preconditions effects represented probability values 
desirability action effects represented utility values 
hierarchical plan representation action primitive action directly executed agent 
action may decomposed multiple ways decomposition consists sequence primitive sub actions 
node plan structure action decomposed way 
decision node hand decomposed multiple ways agent decide options 
outcome primitive action effect group primitive action effects action effects single utility value non zero utility value 
plan represented action sequence 
plan associated intended goal positive utility value 
plan contains actions denotes set primitive plans result decomposing actions primitive ones 
side effects goal attainment plan may desirable undesirable outcome including goal 
decision theoretic point view expected utility plan represents benefit disadvantage plan 
shall discuss compute plan utility section 

intention recognition intention recognition infer agent goal plan perceiving agent observations 
plan inference perceiving agent perspective knowledge information perceiver observed agent 
model perceiver inference process computing estimated expected utilities observed agent possible plans perceiver plan knowledge observations observed agent 
computing plan utility computation plan utility similar decision theoretic planning drips haddawy abstraction hierarchy operators 
plan recipes known compute exact utility value range utility values searching plan space decisiontheoretic planning 
action theory actions preconditions effects known information utilized recognizer 
approach take observations actions state information consideration evidence incrementally update state probabilities 
updated state probabilities change probabilities action preconditions turn change probabilities action execution effect occurrences 
expected utilities associated plans updated incrementally changes observations 
evidence 
action observed execution probability 
probability precondition excluding deleted delete effects probability effect equal effect probability 
conditional effects probability consequent conditional effect equal probability antecedent conditional effect 
precondition del effect add effect effect prob del effect effect prob consequent cond effect antecedent cond effect action effect observed 
action observed probability successful execution computed precondition execute prob oi set outcomes primitive plan pi outcome oj oi 
ak action sequence pi leads oj 
probability oj computed oj ai effect prob ak oj estimated expected utility primitive plan pi computed eu pi oj utility oj oj oi hierarchical plan representation action non decision node expected utility action sum utilities sub actions 
action decision node expected utility action maximum utilities sub actions assume agent tries maximize expected utility 
utility root node plan hierarchy estimated expected utility plan 
computation plan highest estimated expected utility chosen hypothesized plan evidence far 
illustration return example introduced section 
initially troop accident area troop aa child accident area child aa 
mother perspective assume execution probability action 
prior probabilities states execution probabilities actions follows 
troop aa child aa troop helping troop transit child cured supported execute prob troop stay execute prob troop leave execute prob treat child execute prob support know effect prob troop stay troop helping effect prob troop leave troop transit effect prob treat child child cured effect prob support supported observation troop action equally supports troop stay troop leave troop stay troop leave troop helping troop transit compute probabilities executing treat child support evidence treat child support compute outcome probabilities child cured supported compute estimated expected utilities plan plan current observations eu plan eu plan mother recognized troop pursuing plan support eagle 
oversimplified example complex cases including multiple outcomes conditional probabilities actions algorithm applied way 

discussions probabilistic approaches considered influence world states plan recognition goldman pynadath wellman bui 
goldman argued state world influence agent decision pursue plans 
proposed plan execution model probabilistic horn abduction 
traffic monitoring pynadath wellman actions unobservable 
recognizer infers driver plan observable action effects 
bui hidden markov model online policy recognition 
framework stochastic model exploit special properties ahmm structure lead efficient plan recognition algorithms 
adopt markov model considerations 
markov approach requires relatively large state space assumes fixed goals 
core technologies application system center common representation plan knowledge shared reused different system components 
modeling realistic virtual agents give agents flexibility strategically varying interpretations outcome desirability result coping specific situations marsella gratch 
pynadath wellman bui agent utility functions implicitly taken account approaches capture likelihood agent expand plan particular way expansion probabilities pynadath wellman 
main difference approach probabilistic approaches explicitly take agent preferences consideration 
doing claiming recognizer know exact utility functions observed agent think recognizer know partially know information utilized evidence impact recognition process 
real world applications utilities states blythe 
bayesian probabilistic models view plan recognition abduction bayesian rules compute best candidate plan 
probabilistic reasoning advantageous accounting observed actions support hypothesized plan inference requires large numbers prior conditional probabilities 
situations probabilities hard obtain 
answer numbers come 
view plan recognition recognizing decisionmaking strategy observed agent maximizing expected utilities plans criterion disambiguation 
approach needs prior probabilities prior probabilities states action success failure probabilities action effects 
probabilities non deterministic conditional action effects available systems planning component 
state probabilities probabilities action execution relatively easier obtain comparing cpts required belief networks 
partly eases burden defining large numbers prior conditional probabilities probabilistic models trade approach approximate consider state dependencies 
knowledge actions preconditions effects typically available plan system 
approach knowledge observations actions effects change probabilities states 
strong assumption observability actions effects approach sequence observations processed incrementally way 
approach compatible idea decision theoretic planning 
helps computer systems share representation intermediate results underlying techniques planning recognition allows systems interleave planning inferring plans depending tasks hand 

summary assumption rational agent adopt plan maximizes expected utility view plan recognition inferring decision making strategy observed agent 
approach plan recognition problem 
approach explicitly takes observed agent preferences consideration computes estimated expected utilities plans disambiguate competing hypotheses 
consider actions state information recognition process 
online plan recognition realized incrementally plan knowledge observations change state probabilities 
discuss compare probabilistic models 
point limitations bayesian inference show approach help 
approach sufficient practical application compatible existing system representation heuristic narrowing hypotheses space rational assumption evaluated 
need collect experimental data run experiments realistic scenarios test effectiveness approach 
virtual environment supports face face interactions humans virtual agents provides ideal testbed evaluating 
developed funds department army contract number daad 
colleagues mre project collaboration 
opinions findings recommendations authors necessarily reflect views department army 
albrecht zukerman nicholson 
bayesian models keyhole plan recognition adventure game 
user modeling adapted interaction 
allen perrault 
analyzing intention utterances 
artificial intelligence 
bauer 
dempster shafer approach modeling agent preferences plan recognition 
user modeling user adapted interaction 
bauer 
acquisition user preferences plan recognition 
proceedings fifth international conference user modeling 
blythe 
decision theoretic planning 
ai magazine 
bui venkatesh west 
policy recognition hidden markov model 
journal artificial intelligence research 
bui 
general model online probabilistic plan recognition 
proceedings eighteenth international joint conference artificial intelligence 
carberry plan recognition natural language dialogue 
mit press 
charniak goldman 
semantics probabilistic quantifier free order languages particular application story understanding 
proceedings eleventh international joint conference artificial intelligence 

charniak goldman 
bayesian model plan recognition 
artificial intelligence 
doyle 
rationality roles reasoning 
computational intelligence 
ferguson allen 
trains mixed initiative planning assistant 
proceedings third conference artificial intelligence planning systems 
ferguson allen 
trips intelligent integrated problem solving assistant 
proceedings fifteenth national conference artificial intelligence 
geib goldman 
plan recognition intrusion detection systems 
proceedings second darpa information survivability conference exposition 
goldman geib miller 
new model plan recognition 
proceedings fifteenth conference uncertainty artificial intelligence 
haddawy 
decision theoretic refinement planning inheritance abstraction 
proceedings second international conference artificial intelligence planning 
huber durfee wellman 
automated mapping plans plan recognition 
proceedings tenth international conference uncertainty artificial intelligence 
kaminka pynadath tambe 
monitoring teams overhearing multiagent plan recognition approach 
journal artificial intelligence research 
kautz allen 
generalized plan recognition 
proceedings fifth national conference artificial intelligence 
mao gratch 
decision theoretic approaches plan recognition 
ict technical report www ict 
usc edu publications ict tr pdf 
marsella gratch 
modeling coping behavior virtual humans don worry happy 
proceedings second international joint conference autonomous agents multiagent systems 
pynadath wellman 
accounting context plan recognition application traffic monitoring 
proceedings eleventh international conference uncertainty artificial intelligence 
pynadath wellman 
probabilistic state dependent grammars plan recognitions 
proceedings sixteenth conference uncertainty artificial intelligence 
rickel marsella gratch hill traum swartout 
new generation virtual humans interactive experiences 
ieee intelligent systems 
schmidt sridharan goodson 
plan recognition problem intersection psychology artificial intelligence 
artificial intelligence 
wilensky 
understanding stories involving recurring goals 
cognitive science 
