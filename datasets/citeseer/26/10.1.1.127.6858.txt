multimodal person recognition unconstrained audio video choudhury brian clarkson tony jebara alex pentland perceptual computing group mit media laboratory cambridge ma clarkson jebara media mit edu propose person identi cation technique recognize verify people unconstrained video audio 
expect fully frontal face image clean speech input 
recognition algorithm detect compensate pose variation changes auditory background select reliable video frame audio clip recognition 
depth information human head detect presence opposed image person 
system achieves recognition veri cation rates natural real time input registered clients 
automatic identi cation people applications di erent areas 
recognition performed unobtrusive manner useful secured access sites automatic banking password free computer login analysis person dependent behaviors preferences 
relatively high accuracy rates obtained face recognition computer vision techniques fusing modalities speaker veri cation di erent bio metric measurements 
done person identi cation little restriction person movement speech 
researchers proposed di erent techniques handle varying pose template techniques modeling pose variations manifolds subspaces high dimensional image space 
main goal recognize person unconstrained audio video information 
derive con dence scoring allows identify reliable video frames audio clips recognition 
propose robust method depth information rejecting try fool face recognition system photographs 
face recognition realistic environment face image query background pose expression 
need system detect face reliably kind background recognize person despite wide variations pose facial expression 
system able pick reliable images video sequence recognition task 
propose technique uses real time face tracking depth information detect recognize face varying pose 
face detection tracking rst step recognition process accurately robustly detect face 
order 
detect face skin color information 

detect approximate feature location symmetry transforms image intensity gradient 

compute feature trajectories correlation tracking 

process trajectories stably recover structure facial pose 

head model warp normalize face frontal position model skin color rgb values mixture gaussians 
train model take samples people varying skin tone di erent lighting conditions 
model detect regions image contain skin color blobs 
largest blob processed look facial features eyes nose mouth 
method require face frontal detection stage 
loci features give estimate pose 
pose estimate head model warp detected face frontal view 
frontal face undergoes histogram tting normalize illumination 
detailed description face detection tracking please refer 
eigenspace modeling face detected features identi ed image region containing face sent recognition 
face nding stage gives approximation feature locations 
re ne estimates re searching eyes mouth coefficients coefficients small area previous estimate 
overcomes time consuming stage face facial feature detection image recognition process suitable real time application 
feature locations accurately detected face normalized eyes mouth xed locations 
eigenspace built training images provided real time face tracker 
eigenvectors largest eigenvalues project images 
having model pose normalization allows single eigenspace range poses 
eliminates requirement storing selecting multiple eigenspaces 
face detection algorithm constrain user maintain frontal pose 
capture facial variations person gaussian cients 
de ne probability match person test image probability test image cients person model 
unimodal case person maximum test image claimed identity 
see distribution eigen coe cients people demonstrates di erences mean coe cients people 
person person mean coefficients standard deviation mean coefficients standard deviation eigenvector distribution rst eigen coe cients person depth estimate face recognition security purpose important system fooled image person 
structure motion estimate tracking stage yields depth estimates features 
information di erentiate actual head image 
picture held front camera motion gives structure 
shows depth values extracted test trials 
photograph yielded depth value feature points depth values varied greatly actual faces 
looking reliably recovering structure individuals recognition purposes 
depth values tracked feature points depth values tracked objects object features depth photograph rest faces 
speaker identi cation past shown text independent speaker identi cation si relies characterization spectral distributions speakers 
convolutional additive noise audio signal cause mismatch model test distributions resulting poor recognition performance audio channel kept consistent minimize convolutional noise problem additive noise natural scenarios 
techniques rasta substantial success matching spectral response di erent auditory channels 
severe drops performance evident small amounts additive noise 
done suggested presence noise doesn necessarily degrade recognition 
compared system error rates clean database realistic database 
training testing done database error rates comparable 
building idea speaker identi cation system simple set linear spectral features characterized hmms 
simple combination suited adapting speaker models various types background noise 
event detection rst state audio pipeline coarse segmentation incoming audio 
purpose segmentation identify segments audio contain speech 
route statistical modeling easier faster 
integrating possible segmentations built segmentation prior knowledge 
simple cient event detector constructed thresholding total energy incorporating constraints event length surrounding pauses 
constraints encoded machine 
resulting segmentation yields series audio clips analyzed speaker identi cation 
method aw possibility arbitrarily long events 
example jack hammer nearby level sound exceed threshold 
simple solution adapt threshold equivalently scale energy 
system keeps running estimate energy statistics continually normalizes energy zero mean unit variance similar brown onset detector 
ect period silence system period loud sound system grows 
feature extraction segmentation khz sampled audio ltered weak high pass lter order remove dc set boost higher frequencies 
calculate mel scaled frequency coe cients mfcs frames audio spaced ms apart ms long 
frame size sets lower limit frequency measurement hz 
mel scaling increases resolution lower frequencies speech typically occurs 
mfc linear operation audio signal additive noise cause nonlinear distortion features 
useful allows detect additive noise model noise isolation 
modeling system uses hmms capture spectral signature speaker 
hmm estimated examples speech 
estimation achieved rst segmental means initialize hmm parameters expectation maximization em maximize locally model likelihood 
examples speech common temporal structure training examples 
situation requires fully connected ergodic hmms 
order nd optimal model complexity task varied number states number gaussians state recognition rate optimized 
tested hmms states gaussians 
best performance achieved state hmm gaussians state equivalently mixture gaussians 
surprising lack temporal structure text independent training testing examples 
arguably hmms unnecessary 
hmms justi ed background noise adaptation 
background adaptation statistical models trained clean speech speech speci environment perform badly speech di erent environment 
changing environment causes distortions speech features create test speech model distribution 
convolutional noise caused primarily di ering microphone sound card types microphone sound source location 
additive noise caused presence sound sources 
assume microphone type location constant concentrate additive noise 
goal able adapt models clean speech noisy environments 
adaptation require samples speech noisy environment usually available 
clean speech models recordings background noise adaptation technique estimate appropriate noisy speech models 
model adaptation procedure related parallel model combination algorithm estimating hmms noisy speech hmms separately trained speech noise 
background noise structure repetitive noises motor noise randomly occurring changes rain storm appropriate hmm model 
feature extraction hmm training 
background noise speech assumed independent features extracted linear operators distributions easily estimated 
background noise hmm states clean speech hmm states noisy speech hmm 
combination hmms hmm states state space constructed outer product state spaces 
probability distributions state convolution distributions distributions adaptation evaluated speech people collection described auditory background scene street storm 
noise scene contains frequent passing cars constant background rain 
created sets audio data speech set uncorrupted speech speech noise set constructed adding background recordings audio clips speech set 
mixed signal noise ratio snr db 
sets divided training test sets 
single state hmm si trained speech individual speech set 
state hmm trained background sounds 
hmm adapt si hmms creating new set hmms match speech noise set 
option real time adaptation trained hmms call ci speech noise training set evaluate ectiveness adaptation 
test hmms speech speech noise test sets 
table contains recognition rates sets audio clips 
shown extremely poor performance hmms speech noise test set background scene clearly caused mismatch speech models audio 
adaptation able regain performance assume hmms exactly matched speech noise set 
hmm models speech speech noise speech adapted corrupted recognition rates clean speech corrupted speech adapted speech models 
classi er fusion goal classi er fusion complement modality 
classi er performing poorly important suggestions skew nal decision 
careful considerations ensure appropriate weighting classi er 
derivation weighting relies having measurement classi er reliability 
xi probability classi er assigns person probabilities calculated model likelihoods xi xi xi xi normalization necessary comparing classi er scores removes measure test case modelled classi er models 
con dence scores tried numerous measures estimating classi er con dence 
face classi er tested con dences measures test image distance face space dffs dffs kx aggregate model likelihood aml aml log xjm maximum probability average probability distance speech classi er evaluated aml measures 
measures arbitrary ranges distributions converted probabilities transformation measures 
pdf con dence 

estimate 
set images audio clips parzen windows gaussian kernels 
shows mapping dffs measure 
confidence distance face space distance face space mapping dffs probability top dffs pdf set images bottom derived cdf mapping 
table shows con dence measure performs predictor recognition 
percentages correlation con dence scores correctly incorrectly recognized test cases 
score chance means score uncorrelated recognition 
measure clearly outperforms rest measures adopted con dence measure system 
bayes net fusion classi ers knowledge source may dependent sources 
full bayesian approach assumes assuming knowledge source dependent sources 
requires estimation conditional distributions turn requires large amounts training data 
dependencies unnecessary assumptions explicit net 
knowledge sources classi er 
classi er probability foreach person con dence score speech face dffs aml comparison con dence scores prediction rates correct recognition left wrong recognition right 
bayes net combining knowledge sources classi er produce nal decision 
con dence classi er ci xi client 
displays bayes net knowledge sources 
audio video channels assumed conditionally independent depicted lack direct links cs cf xf assuming con dence scores independent equivalent assuming distributions con dence scores classi ers 
xjxs cs xf cf prior con dence score ci simply recognition rate classi er 
prior estimated separately individual lack training data forced prior 
experiments recognition veri cation experiments performed 
describe data collection process discuss results various methods evaluation 
data collection collected data training testing automated teller machine atm scenario 
setup included single camera microphone placed average head height 
speech synthesis system communicate subjects displaying text screen 
reasons fold 
subjects won constrained face screen times 
second natural answer speech question spoken 
subjects instructed behave actual atm 
constraints placed movement speech 
session begins subject enters camera eld view system detects face 
system person begins banking transaction 
series questions asked question system waited speech event proceeding 
typical session follows 
wait face enter scene 
system welcome 
please state name 
user joe 

system deposit withdrawal 

user withdrawal 

system amount please 
user dollars 

system transaction complete 
banking 

wait face leave scene 
go back step transaction process system saves pixel images centered face audio khz 
collected data people 
evaluation methods evaluated system recognition veri cation rates 
procedures include criteria rejecting clients entirely probability output bayes net 
rejection means system get suitable image clip audio clip recognizing verifying client 
usually application ask client repeat session 
recognition procedure follows 
client gives information 

recognized identity 
reject recognized identity rejection threshold 
veri cation procedure follows 
client gives claimed identity 

recognized identity 
reject recognized identity rejection threshold 

verify recognized identity claimed identity reject 
results experiment analyzed hit rate correct rejection rate entire range rejection thresholds 
optimal operating threshold theoretically sum hit correct rejection rates maximized 
assuming equal cost weights hit rate correction rejection rate 
experiment success rate zero threshold rejections optimal operating threshold 
modality image clip session audio video audio video recognition rates zero rejection threshold rejections modality image clip audio video audio video recognition rates optimal rejection threshold rejection rates 
results results recognition veri cation processes calculated audio information video information combining outputs bayes net described 
calculate rates images clips best clip session 
best de ned image clip highest con dence score 
session applications meaningful identi es session accuracy accuracy video frame audio clip 
table gives overview system recognition performance thresholding 
recognition perfect done session basis reliable image clip pair 
table shows optimal operating point image clip recognition 
high rejection rates quite reasonable image clips person 
veri cation rates table 
veri cation near perfect false acceptance rate image clip basis 
session performance perfect 
expected prune away reliable images audio clips performance increases appreciably 
con dent images clips recognition veri cation rates rise false acceptances 
implemented evaluated system combines face recognition speaker identi cation modules high accuracy person recognition 
furthermore modules designed take large variety natural real time input 
face recognition module achieves high recognition accuracies combining face detection head tracking eigenface recognition 
text independent speaker identi cation module robust changes back modality image clip session audio video audio video veri cation rates optimal rejection threshold false acceptance rates 
ground noise incorporating adaptation event detection modeling stages 
simple bayes net combine outputs face speech modules 
method quite ective deriving including con dence scores predict module reliability 
fact shown system select con dence scores reliable images audio clips session case perform perfect recognition veri cation rates 
ali azarbayejani alex pentland 
recursive estimation motion structure focal length 
ieee pattern analysis machine intelligence 
david beymer 
face recognition varying pose 
memo 
bimbot hutter lindberg 
speaker veri cation telephone network research activities cave project 
technical report ptt telecom enst idiap kth kun 
brown 
computational auditory scene analysis representational approach 
phd thesis university eld 
frey antonio thomas huang 
mixture local linear subspaces face recognition 
international conference computer vision pattern recognition 
gales young 
robust continuous speech recognition parallel model combination 
technical report university 
daniel graham nigel 
face recognition unfamiliar views subspace methods pose dependency 
third international conference face gesture recognition 
hermansky nelson morgan phil kohn 
rasta plp speech analysis 
icsi technical report tr 
tony jebara alex pentland 
parameterized structure motion adaptive feedback tracking faces 
ieee conference computer vision pattern recognition 
ma wen gao 
text independent speaker identi cation spectral weighting functions 
proceedings 
lu stan li 
generalizing capacity face database face recognition 
third international conference automatic face gesture recognition 
