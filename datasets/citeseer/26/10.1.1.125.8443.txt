ieee transactions pattern analysis machine intelligence vol 
december real time american sign language recognition desk wearable computer video thad starner student member ieee joshua weaver alex pentland member ieee computer society real time hidden markov model systems recognizing sentence level continuous american sign language asl single camera track user hands 
system observes user desk mounted camera achieves percent word accuracy 
second system mounts camera cap worn user achieves percent accuracy percent unrestricted grammar 
experiments word lexicon 
index terms gesture recognition hidden markov models wearable computers sign language motion pattern analysis 
different types gestures structured sets belong sign languages 
sign language gesture assigned meaning strong rules context grammar may applied recognition tractable 
american sign language asl language choice deaf united states 
asl uses approximately gestures common words finger spelling communicating obscure words proper nouns 
majority signing full words allowing signed conversations proceed pace spoken conversation 
asl grammar allows flexibility word order english uses redundancy emphasis 
variant signed exact english see common spoken english widespread america 
conversants asl may describe person place thing point place space store object temporarily 
purposes experiment aspect asl ignored 
furthermore asl eyebrows raised question relaxed statement directive 
built systems track facial features source information aid recognition task addressed 
related similar path early speech recognition previous attempts machine sign language recognition concentrate isolated signs fingerspelling 
space permit thorough review general attempts relied instrumented gloves desktop camera system form template matching neural nets recognition :10.1.1.125.8443
current extensible systems employ hidden markov models hmms 
hidden markov models prominently successfully speech recognition handwriting authors massachusetts institute technology media laboratory room ames street cambridge ma 
mail thad sandy media mit edu 
manuscript received apr revised sept 
recommended acceptance boyer 
information obtaining reprints article please send mail tpami computer org ieeecs log number 
ieee recognition 
consequently ideal visual recognition complex structured hand gestures sign languages 
explicit segmentation word level necessary training recognition 
language context models applied different levels related development technology done speech recognition community 
authors reported project uses hmms computer vision literature :10.1.1.51.6538:10.1.1.125.8443
time continuous density hmms appear speech community continuous gesture recognition scarce gesture lexicons small automatic training baum welch re estimation uncommon 
results reported standard accuracy measures accepted speech handwriting recognition communities training testing databases identical dependent manner 
time hmm gesture recognizers tasks appeared literature year hmm continuous sign language systems demonstrated 
submission uist liang sign language shows encouraging results glove recognizer 
hmm system recognizes postures orientations motion primitives 
combined constituents form lexicon words continuously recognized realtime percent accuracy 
iccv vogler metaxas described desk camera system achieves percent word accuracy word lexicon 
vision process computationally expensive implementation electromagnetic tracker interchangeably mutually orthogonal calibrated cameras collecting experimental data 
task describe extensible systems color camera track hands real time interpret american sign language hidden markov models 
tracking stage system attempt fine description hand shape concentrating evolution gesture time 
studies human sign readers suggest surprisingly little hand detail necessary humans interpret sign language 
fact movies shot waist isolated signs show movies retain percent full resolution intelligibility subsampled pixels 
experiment tracking process produces coarse description hand shape orientation trajectory 
resulting information input hmm recognition signed words 
scope create user independent full lexicon system recognizing asl system extensible goal 
continuous sign language recognition full sentences demonstrates feasibility recognizing complicated series gestures 
addition real time recognition techniques described allow easier experimentation demonstrate possibility commercial product simplify archival test data 
recognition system sentences form personal pronoun verb noun adjective personal pronoun recognized 
structure allows large variety meaningful sentences generated randomly chosen words class shown table 
personal pronouns verbs nouns adjectives included total lexicon words 
words chosen paging humphries selecting words generate coherent sentences grammar constraint 
words chosen distinctiveness ieee transactions pattern analysis machine intelligence vol 
december table asl test lexicon part speech vocabulary pronoun pl verb want lose love pack hit loan noun box car book table pants bicycle bottle wristwatch umbrella coat pencil shoes food magazine fish mouse bowl adjective red brown black gray yellow fig 

state hmm recognition 
lack detail finger positioning 
note finger position plays important role signs pack vs car food vs red vs mouse hidden markov modeling due space limitations reader encouraged refer existing literature hmm evaluation estimation decoding 
tutorial relating hmms sign language recognition provided author master thesis :10.1.1.51.6538
initial topology hmm determined estimating different states involved specifying sign 
fine tuning topology performed empirically 
case initial topology states considered sufficient complex sign 
handle complicated signs skip transitions specified allowed topology emulate strictly state hmm 
different topologies specified sign explicitly method allows training adapt hmm automatically human intervention 
testing different topologies state hmm skip transition determined appropriate task fig 

feature extraction hand ambiguity previous systems shown strong constraints viewing relatively detailed models hands recovered video images 
constraints conflict recognizing asl natural context require simple unchanging backgrounds clothing allow occlusion require carefully labelled gloves difficult run real time 
project track hands single camera realtime aid gloves markings 
natural color hands needed 
vision sign recognition possible mounting locations camera position observer signer point view signer 
views thought second person person viewpoints respectively 
training second person viewpoint appropriate rare instance translation system worn hearing person translate signs mute deaf individual 
system appropriate signer wishes control dictate desktop computer case fig 

view desk tracking camera 
images analyzed resolution 
fig 

hat mounted camera pointed downward hands corresponding view 
experiment 
fig 
demonstrates viewpoint desk experiment 
person system observes signer hands viewpoint signer 
fig 
shows placement camera cap second experiment demonstrates resulting viewpoint 
camera attached sgi development current hardware allows entire system unobtrusively embedded cap wearable computer 
sized camera qn embedded front seam 
relatively quality speaker lining transducer thin consumer grade stereo speakers 
pc cpu digitizer batteries placed back head 
see starner mit wearable computing site wearables www media mit edu projects wearables detailed information wearable computing related technologies 
wearable computer system provides greatest utility asl spoken english translator 
worn signer communication necessary business vacation 
providing signer self contained unobtrusive person view translation system feasible trying provide second person translation systems signer encounter day 
systems color ntsc composite video captured analyzed pixel resolution 
lower resolution avoids video effects 
silicon graphics mhz indy workstation maintains hand tracking frames second frame rate sufficient human recognition 
segment hand initially algorithm scans ieee transactions pattern analysis machine intelligence vol 
december image finds pixel appropriate color determined priori model skin color 
pixel seed region grown checking nearest neighbors appropriate color 
pixel checked considered part hand 
effect performs simple morphological dilation resultant image helps prevent edge lighting 
centroid calculated product growing step stored seed frame 
hands skin tone labels left hand right hand simply assigned whichever blob leftmost rightmost 
note priori model skin color may appropriate situations 
example mobile system lighting change appearance hands drastically 
image fig 
provides clue addressing problem person view 
bottom image signer nose 
camera mounted cap nose stays place relative image 
signer nose calibration object generating model hands skin color tracking 
calibration system prototyped experiments 
extracting hand blobs scene second moment analysis performed blob 
sixteen element feature vector constructed hand position change frames area pixels angle axis inertia eigenvector blob length eigenvector eccentricity bounding ellipse 
tracking skin tones analysis helps model situations hand ambiguity implicitly 
hand occludes hand face nose case wearable version color tracking resolve ambiguity 
face remains area frame position determined discounted 
hands move rapidly occlude 
occlusion occurs hands appear system single blob larger normal area significantly different moments hands previous frame 
implementation hands assigned features single blob occlusion occurs 
informative tracking hand separately method retains surprising amount discriminating information 
occlusion event implicitly modeled combined position moment information retained 
method combined time context provided hidden markov models sufficient distinguish different signs hand occlusion occurs 
second person view desk recognizer experimental situation explored second person view desk recognizer 
experiment sentences obtained sentences eliminated due subject error outlier signs 
general sign seconds long 
intentional pauses exist signs sentence sentences distinct 
testing purposes sentences training reserved testing 
test sentences portion training process 
training sentences divided automatically equal portions provide initial component signs 
initial estimates means variances output probabilities provided iteratively viterbi alignment training data recomputing means variances pooling vectors segment 
entropic hidden markov model toolkit htk basis step hmm modeling training tasks 
results table word accuracy desk system experiment training set independent test set features percent percent relative features percent percent features unrestricted grammar percent percent percent percent word accuracies percent correct parentheses different 
test uses strong part speech grammar feature elements 
second test removes absolute position feature vector 
test uses features requires hypothesized output composed words lexicon 
word occur time number times 
initial alignment program fed baum welch estimates turn refined embedded training ignores initial segmentation 
recognition htk viterbi recognizer partof speech grammar known form sentences 
contexts require significantly data train 
similar effect achieved strong grammar data set 
recognition occurs times faster real time 
word recognition accuracy results shown table different percentage words correctly recognized shown parentheses accuracy rates 
accuracy calculated acc total number words test set number deletions number substitutions number insertions 
note errors accounted accuracy rate possible get large negative accuracies corresponding error rates percent 
part speech grammar pronoun verb noun adjective pronoun insertion deletion errors possible number class words allowed known 
errors vocabulary substitutions grammar accuracy equivalent percent correct 
assuming independence random chance result percent correct percent calculated averaging likelihood part speech correct 
grammar recognizer allowed match observation vectors number vocabulary words order 
fact number words produced recognizer number samples sentence 
deletion insertion substitution errors possible unrestricted grammar tests comparison random chance irrelevant 
absolute number errors type listed table 
insertion errors correspond signs repetitive motion 
additional relative features test provided results 
test absolute position removed feature vector 
provides sense recognizer performs relative features available 
may case daily signer may place location time system 
percent percent accuracies part ofspeech grammar show hmm topologies sound models generalize 
subject variability body rotation position known problem data set 
signs distinguished hands positions relation body confused absolute positions hands screen coordinates measured 
relative ieee transactions pattern analysis machine intelligence vol 
december table word accuracy wearable computer system grammar training set independent test set part speech percent percent word sentence percent percent percent unrestricted percent percent percent percent word accuracies percent correct parentheses different 
word grammar limits recognizer output words selected vocabulary 
grammars 
feature set absolute positions hands removed feature vector 
change causes error rate increase slightly demonstrates feasibility allowing subject vary location room signing possibly removing constraint system 
error rates unrestricted experiment better indicate problems may occur extending system 
grammar signs repetitive long gestures inserted twice actual occurrence 
fact insertions caused errors substitutions 
sign shoes recognized shoes shoes viable hypothesis language model 
practical solution problem context training statistical grammar 
person view wearable recognizer second experiment sentences collected different subject 
sentences mistake 
full sentence database available anonymous ftp media mit edu pub asl 
subject took care look forward signing confound tracking head rotation variations seen 
frames sentence data contain hands resting position 
take account token silence speech convention added lexicon 
sign trained rest included calculating accuracy measurement 
resulting word accuracies experiment listed table 
experiment sentences training independent sentences testing 
new grammar added experiment 
grammar simply restricts recognizer word sentences regard part speech 
percent correct words expected chance word grammar percent 
deletions insertions possible grammar repeated word thought deletion insertion substitutions 
interestingly part speech word unrestricted tests accuracies essentially suggesting signs lexicon distinguished feature set method 
previous experiment repeated words represent percent errors 
fact simple repeated word filter applied post process recognition unrestricted grammar test accuracy percent exactly restrictive grammar 
looking carefully details partof speech word grammar tests indicate pronoun restriction may hurt performance part speech grammar 
strong grammars superfluous task 
addition close accuracies fair test test training cases indicate hmms training converged generalized extremely task 
main result high accuracies indicate harder tasks attempted 
wearable system accurate desk system 
possible factors 
wearable system occlusion problems face hands 
second wearable data set problem body rotation data set experienced 
third data set created verified separate subjects successively better data recording methods 
controlling various factors requires new experiment described section 
discussion shown high accuracy computer vision method recognizing sentence level american sign language selected word lexicon 
experiment shows system communicate desk computer 
second experiment demonstrates wearable computer method part asl english translator 
experiments argue hmms powerful method sign language recognition speech handwriting recognition 
addition experiments suggest person view provides valid perspective creating wearable asl translator 
argued sign evolved maximum intelligibility frontal view thought reveals sign may distinguishable signer learning provide control feedback 
determine view superior recognition begun new experiment 
native signers task complete 
task designed encourage small vocabulary words encourage natural sign 
views signers recorded stereo pair front view side wearable computer view 
tracking various views compared directly 
head motion facial gestures roles sign wearable system trouble addressing 
fact head rotation significantly impair current system 
shown effects experiment body head rotation issue viewpoint 
simple fiducials belt shirt may compensate tracking provide additional features 
option wearable system add inertial sensors compensate head motion 
addition emg may placed cap head band forehead analyze eyebrow motion discussed picard 
way facial gesture information may recovered 
system grows lexicon size finger palm tracking information may added 
may simple counting fingers visible contour hand palm facing 
addition tri sign context models statistical grammars may added may reduce error factor speech handwriting trends hold true sign 
improvements address user independence 
just speech making system understand different subjects variations language involves collecting data subjects 
system tried hard estimate number subjects amount data comprise suitable training database 
independent recognition places new requirements feature set 
modifications mentioned may initially sufficient development process highly empirical 
ieee transactions pattern analysis machine intelligence vol 
december similarly addressed problem finger spelling 
changes feature vector address finger information vital adjusting context modeling importance 
finger spelling closer parallel speech recognition 
tri sign context occurs subword level grammar modeling occurs word level 
odds context word signs 
tri sign context finger spelling signing 
beneficial switch separate mode finger spelling recognition 
natural language techniques applied address spatial positioning issues asl 
answers questions may key creating unconstrained sign language recognition system 
acknowledgments authors hall help editing document 
supported bt things think consortium mit media laboratory 
baum inequality associated maximization technique statistical estimation probabilistic functions markov processes inequalities vol 
pp 

campbell becker azarbayejani bobick pentland invariant features gesture recognition second int conf 
face gesture recognition pp 

hand shape identification tracking sign language interpretation ijcai workshop looking people 
essa darrell pentland tracking facial motion proc 
workshop motion non rigid articulated objects austin tex nov 
horn robot vision 
cambridge mass mit press 
huang jack hidden markov models speech recognition 
edinburgh univ press 
humphries rourke basic course american sign language 
silver spring md publ 
liang real time continuous gesture interface sign language submitted uist 
picard agents recognize emotion 
driscoll perception american sign language dynamic point light displays exp human perform vol 
pp 

rabiner juang hidden markov models ieee assp magazine pp 
jan 
rehg kanade digiteyes vision human hand tracking school computer science technical report cmu cs carnegie mellon univ dec 
hunter jain recursive identification gesture inputs hidden markov models proc 
second ann 
conf 
applications computer vision pp 
dec 
landy cohen pavel intelligible encoding asl image sequences extremely low information rates comp 
vision graphics image processing vol 
pp 

starner visual recognition american sign language hidden markov models master thesis mit media laboratory feb :10.1.1.51.6538
starner makhoul schwartz chou line cursive handwriting recognition speech recognition methods icassp pp 

starner mann rhodes levine healey kirsch picard pentland augmented reality wearable computing presence vol 
pp 

starner pentland real time american sign language recognition video hidden markov models technical report mit media lab perceptual computing group :10.1.1.125.8443
earlier version appeared 
starner weaver pentland real time american sign language recognition desktop wearable computer video technical report perceptual computing mit media laboratory july :10.1.1.125.8443
vogler metaxas asl recognition coupling hmms motion analysis iccv bombay 
wilson bobick learning visual behavior gesture analysis proc 
ieee int symp 
computer vision coral fla nov 
yamato ohya ishii recognizing human action time sequential images hidden markov models proc 
computer vision pattern recognition pp 

young htk hidden markov model toolkit cambridge univ eng 
dept speech group entropic research lab washington 
