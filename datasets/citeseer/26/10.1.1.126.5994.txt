fast monte carlo algorithms finding low rank approximations alan frieze carnegie mellon university ravi kannan yale university santosh vempala consider problem approximating matrix matrix specified rank smaller singular value decomposition svd find best approximation 
takes time polynomial prohibitive modern applications 
develop algorithm qualitatively faster provided may sample entries matrix natural probability distribution 
applications sampling done efficiently 
main result randomized algorithm find description matrix rank min rank holds probability ffi frobenius norm 
algorithm takes time polynomial log ffi independent particular implies constant time determined matrix arbitrary size low rank approximation 
categories subject descriptors theory computation analysis algorithms problem complexity information systems information storage retrieval mathematics computing numerical linear algebra general terms algorithms theory additional key words phrases matrix algorithms sampling low rank approximation author addresses frieze dept mathematical sciences carnegie mellon university pittsburgh pa 
af andrew cmu edu kannan computer science dept yale university new haven ct 
kannan cs yale edu santosh vempala mathematics dept cambridge ma 
vempala math mit edu alan frieze supported part nsf ccr 
ravi kannan supported part nsf ccr 
santosh vempala supported nsf ccr sloan foundation fellowship 
permission digital hard copy part material fee personal classroom provided copies distributed profit commercial advantage acm copyright server notice title publication date appear notice copying permission acm copy republish post servers redistribute lists requires prior specific permission fee 
cfl yy acm yy journal acm vol 

month yy pages 
alan frieze 
real world data large number attributes features dimensions 
question fact generated small model smaller number parameters number attributes 
way question problem finding low rank approximation matrix find matrix rank isas small possible matrix frobenius norm defined pi ij 
alternatively view rows points rn problem finding dimensional linear subspace minimizes squared distances points 
problem arises contexts partly matrix algorithms efficient low rank matrices 
consider norms norm see section focus frobenius norm traditional singular value decomposition svd solve problem time min mn nm 
applications motivated infor mation retrieval web slow needs linear sublinear algorithm 
speed svd low rank approximation papadimitriou suggested random projection pre processing step project rows log dimensional subspace find svd subspace reduces worst case complexity mn log small loss approxi mation quality 
high 
fast problem solved 
sight omega mn bound single non zero entry examine entries find approximation 
suppose sample entries proportional magnitudes 
constant sized sample suffice case show rank approximation time poly nomial error parameter provided sample natural probability distribution 
sampling assumptions explicit shortly discussed context applications main result 
theorem 
matrix ffi randomized algo rithm finds description matrix rank min rank holds probability ffi 
algorithm takes time polynomial log ffi independent complex computational find singular values randomly chosen submatrix max 
matrix explicitly constructed kmn time 
consequence poly time determine high probability ifa rank approximation error error probability boosted standard techniques prove theorem fixed error probability central idea approach described follows pick rows journal acm vol 

month yy 
fast low rank approximation independently random probability distribution see section 
suppose rows form matrix 
scaled form matrix step algorithm section 
relatively easy lemma show approximately equals intuition th entry dot product jth columns random sample rows estimates scaling done estimate unbiased 
standard linear algebra get svd sd approximately sd st repeating sd st read svd obtained sd sst sst just matrix reduced computing svd constant sized matrix 
leaves computation sst apply sampling trick second time sample columns form matrix step algorithm ww approximates sst sd needed svd suffices 
central computational task 
algorithm section 
lemma key step analysis showing go approximate left singular vectors approximate right singular vectors small loss key insight basis algorithm existence low rank approximation subspace spanned small sample rows 
state formally 
constant defined 
theorem 
matrix sample rows distribution satisfying assumption 
vector space spanned probability exist orthonormal set vectors 
kx min rank cs 
useful note restriction linear transformation subspace spanned ax kx orthogonal subspace kx 
elementary linear algebra matrix rows span vectors 
rank describe right singular vectors precisely eigenvectors journal acm vol 

month yy 
alan frieze approximation suffices give vectors 

algorithm vectors computed multiplying submatrix aset vectors rp 
matrix recovered set dimensional vectors set numbers indicating submatrix corresponding rows 
follows singular values canbe computed cumulative additive error section give proof existence theorem 
theorem directly gives mnk poly algorithm suggests algorithm linear small polynomial 
algorithm drineas 
subsequent developments discussed section 
denotes ith row matrix denotes jth column column vector mi ith row jth column 
positive integer denotes set 

sampling assumptions describe sampling assumptions detail 
assumption 
sample rows row chosen prob ability pi satisfying pi constant independent 
denotes euclidean length pi known don need know pi 
assumption 
row sample entry probability qj qj pi jp pi qj known don need know values 
matrix known sparsity structure able set sampling little preprocessing 
particular matrix dense ij mn constant take pi qj general matrix making pass entire matrix set data structures sample entries fast onwards time sample satisfy assumptions 
pass things 
suppose ij aij journal acm vol 

month yy 
fast low rank approximation create log bins pass put lth bin entries aij keep track number entries bin 
treat entries bin value 
sample pick bin probability proportional total sum squares bin 
pick entry uniformly set entries bin 
pass set similar data structures row 
applications section discuss algorithm context applications low rank approximation 
show situations satisfy sampling assumptions algorithm obtain svd efficiently 
applications discuss include face recognition picture compression 
latent semantic indexing 
general technique processing documents 
give cursory description broad area discuss relation main problem see berry dumais dumais details empirical results 
suppose documents terms occur documents terms may words occur documents key words occur 
model hypothesizes small number unknown topics documents 
topic modelled probability distribution terms vector non negative reals summing 
model hand shown additional assumptions subspace spanned best topics close span top called document term matrix papadimitriou 
matrix aij frequency jth term ith document 
alternatively define aij depending jth term occurs ith document 
argue practice assumptions algorithm place full svd algorithm 
easy see allowed pass document set data structures ideally creator document supply vector squared term frequencies 
frequency large unreasonable occur called buzz words removed analysis need precompute length li pj aij document 
thisis typically available say file size pick document probability proportional length 
easily seen satisfy assumption squares sample ith entry probability li pj lj 
assump tion squares satisfied frequencies small 
assumption similarly implemented document pick word uniformly qj aij li 
web search model 
kleinberg kleinberg proposed algorithm forthe problem finding important documents set documents returned web search works analyzing hyperlink matrix matrix entries ij equal depending th journal acm vol 

month yy 
alan frieze document points th 
algorithm sets find unit length vectors xt ay maximized 
course problem singular vectors keyword multiple meanings top singular vectors large singular values interesting 
interest find largest singular vectors small worthwhile consider assumptions case 
assumption sufficient sample documents roughly number 
assumption sufficient able follow random link document 
low rank approximations regularity lemma 
lemma szemer edi graph theory gives partition vertex set graph pairs parts nearly regular give details 
lemma host applications see koml os simonovits graph theory 
lemma non constructive asserted existence partition give algorithm find 
alon duke odl yuster able give algorithm partition polynomial time alon 
frieze kannan frieze kannan low rank approximations adjacency matrix related regular partitions 
szemer edi lemma algorithm constructing partition derived connection 
isnot directly relevant results point case low rank approximations useful 
direct application szemer edi partition frieze kannan 

singular value decomposition matrix expressed rx oe oe 
form orthonormal set 
oe tv av oe tu called singular value decomposition rank theorem eckart young golub van loan matrix minimizes matrices rank dk kx av implies dk kx oe dk rx oe notation 
journal acm vol 

month yy 
fast low rank approximation 
small sample induces approximation goal section prove theorem subspace spanned rows chosen assumption contains approximation nearly best possible 
chance 
belong subspace done pkt av provide required approximation show vectors defined shortly approximate scaled versions respective random sample rows chosen distribution 

define vector valued random variable pi 
note general multiset rows picked multiple times vectors clearly subspace generated compute expectation wt 
view average 
xs xj distribution xj pi probability pi 
expectations xj mx pi pi pi mx pi oe sc 
exactly equal just expectation kx kx oe sufficient prove theorem 
wish carry 
define oet 
span 
expectation variance vector valued random variable taken separately component 
journal acm vol 

month yy 
alan frieze 
orthonormal basis rn span 
dimension 
lx ay kx av matrix candidate approximation span bound error note 
nx nx ay nx 
nx kx nx oe expectations get nx oe 
rank dk best rank approximation dk nx oe dk non negative random variable implies pr dk follows pr dk required 
observe low rank approximation respect frobenius norm implies low rank approximation respect norm journal acm vol 

month yy 
fast low rank approximation max mx 
better approximations obtained norm 
theorem 
kx dk kx proof 
pkt suppose unit eigenvector eigenvalue see nx oe 
rank matrix pkt kx dk nx oe dk oe contradicts 

sampling algorithm section main constant time algorithm produce ap proximation theorem 
pick set rows distribution satisfying assumption 
form matrix rows scaling 
pick columns probability assumption scale columns get matrix singular vectors matrix show get low rank approximation reader want consult discussion theorems intuitive idea algorithm works 
description parameter 
journal acm vol 

month yy 
alan frieze algorithm input matrix integer error parameter 
set max 
sample rows independently choose rows 
ip 
pm satisfies assumption pi matrix rows 
scaling amounts normalizing rows thesame length 
sample columns independently choose columns 
jp distribution 
satisfies 
show assumption 
matrix columns jt jt 

compute svd compute top singular vectors 
inthe column space 
filter wt fl fl wt output low rank approximation pt 
discuss implementation algorithm 
particular carry step 
pick row row probability suppose chosen row ith row pick 
qj assumption 
defines probabilities 
row qj xi cpi ppi xi ca ppi xi ppi journal acm vol 

month yy 
fast low rank approximation step implied lemma 
lemma 
chosen algorithm probability proof 
routine calculation observe row cp random variable sum independent random variables 
var pvar pe part lemma follows chebychev inequality 
second part similar 

analysis lemma asserts sample rows matrix provides sense nt close mt analysis 
lemma 
matrix 
qa 
qi ff 
ff 
oe 
ip sequence independent chosen distribution matrix 
pr mt nt ffp journal acm vol 

month yy 
alan frieze proof 
mt nt bx nt nt px px ax qi mi rmi mt nt mt px px ax qi rm ffp px ax rm ffp ax rm mt nt bx mt ffp ax bx rmi ffp ax bx ffp result follows markov inequality 
introduce notation rest analysis 
matrix define delta orthogonal unit vectors represents norm subspace spanned 
case delta mt mx 
journal acm vol 

month yy 
fast low rank approximation top singular vectors delta kx oe lemma 
matrices number columns st 
pair unit vectors row space zt az zt st sz 
set unit vectors 
row space delta delta proof 
part lemma easy 
second fact tr matrix see delta equals tr az tr az az az az az az 
exactly similar reasoning delta st sz st sz 
part lemma second part follows 
ready prove main theorem 
proof theorem 
prove theorem probability 
apply lemma twice row induced column sample 
follows lemma probability events hold st sst cp min 
assume events occur 
proof ap proximate constants arise somewhat crudely convenient rationals 
follows theorem probability row space delta dk dk 
journal acm vol 

month yy 
alan frieze applying second part lemma vectors see delta delta dk 
st singular values exist column space delta st dk applying theorem st wt see probability unit vectors column space delta st delta st dk applying second part lemma st wt vectors see delta wt delta st dk vectors computed algorithm satisfy delta wt dk note highest possible value delta dk show fact delta large implies delta large 
construct suitable set vectors algorithm orthonormal singular vectors delta wt delta wt dk applying lemma time st wt vectors delta st delta wt dk crucial step switch column space inthe row space achieved claims proof section 
claim 
delta delta st claim 
follows lemma delta delta dk assuming 
dk rearranging terms get theorem dk journal acm vol 

month yy 
fast low rank approximation proof claims observe sst sst sst sst sst 
consider st sv sst sst sst wt wt 
furthermore sst sst 
similarly sst sst 
bounds st sv fl fl bounds lemma 
vector matrix sst st st st sv sst sst wt st wt observe part lemma implies st wt st wt fl 
claim follows immediately 
st sv sst delta 
journal acm vol 

month yy 
alan frieze delta delta st fl completes proof claim fl 
value satisfy 

developments problem low rank preliminary version frieze appeared 
drineas drineas give algorithm running time 
theoretically slower due depen dence practice better dependence 
alternative sampling algorithm achlioptas mcsherry comparable bounds frobenius norm bounds norm 
main idea matrix randomly sampling entries compute svd faster 
bar yossef lower bound low rank approximation essentially matches bound drineas 
shown algorithm complexity possible just uniform sampling 
drineas current implicitly defined low rank approximation explicit drineas kannan shows matrix columns picked sampling matrix rows random ss cur matrix computed explicit approximation preserving sparsity structure drineas kannan applied sampling idea multiplying matrices showed sample columns probability distributions similar corresponding rows product approximates product ab improvement analysis terms number rows need sampled obtained drineas 
achlioptas mcsherry fast computation low rank approximations proceedings rd annual symposium theory computing 
alon duke odl yuster algorithmic aspects regularity lemma journal algorithms 
bar yossef sampling lower bounds information theory proceedings th annual symposium theory computing 
berry dumais brien 
linear algebra intelligent information retrieval siam review 
deerwester dumais landauer furnas harshman 
indexing latent semantic analysis journal society information science 
drineas kannan fast monte carlo algorithms approximate matrix multiplication proceedings nd ieee annual symposium foundations computer science 
drineas kannan pass efficient algorithms approximating large matrices proceedings symposium discrete 
journal acm vol 

month yy 
fast low rank approximation drineas frieze kannan vempala vinay clustering large graphs singular value decomposition machine learning 
drineas mahoney kannan fast monte carlo algorithms matrices ii computing low rank approximations matrix technical report yale university yaleu dcs tr 
dumais furnas landauer deerwester latent semantic analysis improve information retrieval proceedings chi conference human factors computing new york acm 
dumais improving retrieval information external sources behavior research methods instruments computers 
frieze kannan regularity lemma approximation schemes dense problems proceedings th annual ieee symposium foundations computing 
frieze kannan quick approximations matrices applications combinatorica 
frieze kannan simple algorithm constructing regularity partition electronic journal combinatorics 
frieze kannan vempala fast monte carlo algorithms finding low rank approximations proceedings th symposium foundations computer science 
golub van loan matrix computations johns hopkins university press london 
kleinberg authoritative sources hyperlinked environment jacm 
koml os simonovits szemer edi regularity lemma applications graph theory combinatorics paul erdos eds bolyai society mathematical studies 
papadimitriou raghavan tamaki vempala latent semantic indexing probabilistic analysis jcss 
regular partitions graphs proceedings colloque inter 
cnrs 
fournier las eds 
received october may accepted june 
journal acm vol 

month yy 
