merl mitsubishi electric research laboratory www merl com style machines matthew brand aaron hertzmann merl nyu media research laboratory broadway broadway cambridge ma new york ny brand merl com mrl nyu edu tr april approach problem stylistic motion synthesis learning motion patterns highly varied set motion capture sequences 
sequence may distinct choreography performed distinct style 
learning identifies common elements sequences different styles element performed small number stylistic degrees freedom span variations dataset 
learned model synthesize novel motion data interpolation extrapolation styles 
example convert novice ballet motions graceful modern dance expert 
model driven video scripts noise generate new choreography synthesize virtual motion capture styles 
proceedings siggraph july 
new orleans louisiana usa 
may copied reproduced part commercial purpose 
permission copy part payment fee granted nonprofit educational research purposes provided partial copies include notice copying permission mitsubishi electric information technology center america acknowledgment authors individual contributions applicable portions copyright notice 
copying reproduction republishing purpose shall require license payment fee mitsubishi electric information technology center america 
rights reserved 
copyright mitsubishi electric information technology center america broadway cambridge massachusetts submitted december revised release april 
merl tr conference proceedings siggraph 
matthew brand mitsubishi electric research laboratory style machines aaron hertzmann nyu media research laboratory synthetic styles drawn space contains ballet modern dance different body types 
choreography synthetic 
show trajectory left hand foot 
approach problem stylistic motion synthesis learning motion patterns highly varied set motion capture sequences 
sequence may distinct choreography performed distinct style 
learning identifies common elements sequences different styles element performed small number stylistic degrees freedom span variations dataset 
learned model synthesize novel motion data interpolation extrapolation styles 
example convert novice ballet motions graceful modern dance expert 
model driven video scripts noise generate new choreography synthesize virtual motion capture styles 
cr categories computer graphics dimensional graphics realism animation artificial intelligence robotics kinematics dynamics mathematics computing probability statistics time series analysis data coding information theory data compaction compression computer applications arts humanities performing arts keywords animation behavior simulation character behavior 
natural think walking running stylistic variations basic motor theme 
point view style motion conveys meaning underlying motion 
existing animation tools provide little high level control style animation 
introduce style machine statistical model generate new motion sequences broad range styles just adjusting small number stylistic knobs parameters 
style machines support synthesis resynthesis new styles style identification existing data 
driven kinds inputs including computer vision scripts noise 
key result method learning style machine including number nature stylistic knobs data 
style machines model highly nonlinear nontrivial behaviors ballet modern dance working long unsegmented motion capture sequences learned model generate new choreography improve novice dancing 
style machines easy generate long motion sequences containing different actions transitions 
offer broad range stylistic degrees freedom show early results manipulating gender weight distribution grace energy formal dance styles 
style machines learned relatively modest collections existing highly generative flexible alternative motion libraries 
potential uses include generation modest amount motion capture animator train resulting style machine generate large amounts motion data new orderings actions 
casts thousands random walks machine produce thousands unique plausible motion synthesized motion data unique style 
improvement motion capture unskilled performers resynthesized style expert athlete dancer 
motion capture data resynthesized new mood gender energy level body type acquisition style machines driven computer vision data gloves impoverished sensors computer mouse offer low cost low expertise alternative motion capture 
related effort addressed problem editing reuse existing animation 
common approach provide interactive animation tools motion editing goal capturing style existing motion editing content 
gleicher provides low level interactive motion editing tool searches new motion meets new constraints minimizing distance old motion 
related optimization method method adapt motion new characters 
lee provide interactive multiresolution motion editor fast fine scale control motion 
editing merl tr conference proceedings siggraph 
schematic illustrating effects cross entropy minimization 

simple walk cycles projected space 
data point represents body pose observed time 

conventional learning fits single model data ellipses indicate state specific contours arcs indicate allowable transitions 
learning overwhelmed variation sequences fails discover essential structure walk cycle 

individually estimated models hopelessly overfit individual sequences generalize new data 
addition divide cycle differently blended compared 

cross entropy minimized models constrained similar qualitative structure identify similar phases cycle 

generic model abstracts information style specific models various settings style variable recover specific models plus interpolation extrapolation 
systems produce results may violate laws mechanics popovi witkin describe method editing motion reduced dimensionality space order edit motions maintaining physical validity 
method useful complement techniques 
alternative approach provide global animation controls 
signal processing systems described bruderlin williams provide frequency domain controls editing style motion 
witkin popovi blend existing motions provide combination motion styles 
rose radial basis functions interpolate extrapolate set aligned labeled example motions happy sad young old walk cycles kinematic solvers smoothly string motions 
similar functionality falls framework 
interactive systems provide fine control rely skilled animators produce compelling convincing results 
furthermore generally difficult produce new motion substantially different existing motions style content convert hand walk dance signal processing methods require example motions time warped words sequential correspondences component motion 
unfortunately rarely case set complex motions property 
style machines automatically compute flexible correspondences sequences fast dynamic programming algorithms 
unites themes separate research histories motion analysis estimation dynamical sense models examples style content separation 
howe analyze motion video mixture gaussians model 
grzeszczuk learn control physical systems physical simulation 
authors hidden markov models analyze synthesize motion 
bregler brand hmms recognize analyze motion video sequences 
brand analyzes animation human speech example audio video 
regard styles wilson bobick parametric hmms motion recognition models learned user labeled styles 
tenenbaum freeman separate style content general domains bilinear model modeling factors individually linear cooperatively multiplicative effects output effects lighting pose images faces 
style content models depend large sets hand labeled hand aligned samples exponential number stylistic degrees freedom dofs plus explicit statement stylistic dofs 
introduce methods extracting information directly automatically modest amounts data 
learning stylistic state space models seek model human motion generate novel choreography variety styles 
attempt engineer model attempt learn extract data function approximates data generating mechanism 
cast unsupervised learning problem goal acquire generative model captures data essential structure traces data generating mechanism discards accidental properties particulars specific sample 
accidental properties include noise bias sample 
essential structure divided components call structure style 
example walking running stylistic variations locomotion dynamical system particularly simple temporal structure deterministic loop 
modeler structure style distinction 
state space representations useful take structure locomotion small set qualitative states rules govern changes state 
take style variations mapping qualitative states quantitative observations 
example shifting weight load right leg dynamically significant state common forms locomotion look quite different running appropriate state space model time series data hidden markov model hmm 
hmm probabilistic finite state machine consisting set discrete states state state transition probabilities state signal emission probabilities state gaussian distribution small space full body poses motions 
see concise hmm tutorial see detailed tutorial :10.1.1.131.2084:10.1.1.131.2084
add hmm multidimensional style variable vary parameters call result stylistic hmm time series style machine 
see formal definitions 
defines space hmms fixing parameter yields unique hmm 
show separate structure style accidental properties dataset minimizing entropies 
main advantages separating style structure wind simpler generative models significantly data required general learning setting 
framework fully unsupervised automatically identifies number nature stylistic degrees freedom fewer number variations dataset 
merl tr conference proceedings siggraph 
discovered degrees freedom lend intuitive operations useful synthesis style mixtures extrapolations analogies 
generic style specific models family training samples 
family mean samples generic data generating mechanism common motor program dancing 
sample may instantiate different variation 
samples need aligned ordering timing appearance actions may vary sample sample 
modeling goal extract single parameterized model covers generic behavior entire family training samples easily model individual style combination styles extrapolation styles just choosing appropriate setting style variable learning involves simultaneous estimation generic model set style specific models objectives model fit sample specific model close generic model generic model simple possible maximizing probability correct generalization new data 
constraints information theoretic expression eqn 

section explain constraints interact produce third desirable property style specific models expressed small variations generic model space variations captured just parameters 
describe style machines applied pure signal data 
details specific working motion capture data described 
estimation entropy minimization learning minimize sum entropies measure ambiguity probability distribution cross entropies measure divergence distributions 
principle minimum entropy advocated various forms seeks simplest model explains data equivalently complex model parameter estimates fully supported data :10.1.1.18.5785:10.1.1.134.6624
maximizes information extracted training data boosts odds generalizing correctly 
learning objective components corresponding constraints listed 
cross entropy model distribution statistics extracted data measures model misfit data 

cross entropy generic specific model measures inconsistencies analysis data 

entropy generic model measures ambiguity lack structure analysis data 
minimizing model faithful data 
minimizing essentially maximizes overlap generic specific models congruence similarity support hidden states 
means models behave similarly hidden states similar meanings example dataset motion sequences style specific hmms converge similar finite state machine models locomotion cycle corresponding states hmm refer qualitatively similar poses motions locomotion cycle 
nth state model tuned poses body weight shifts right leg regardless style motion see 
minimizing optimizes model making sure gives clearest concise picture data hidden state explaining clearly delineated phenomenon data 
flattening alignment gaussians minimization entropy cross entropy respectively 
gaussian distributions visualized ellipsoid iso probability contours 
putting gives learning objective function log posterior log likelihood log prior arg min data entropy misfit model entropy 
vector model parameters vector expected sufficient statistics describing data parameterizes model generic entropy measure cross entropy measure 
eqn 
formulated bayesian posterior likelihood function prior data entropy term mentioned arises normalization likelihood function measures ambiguity statistics calculated vis vis model 
effects prior worth examining prior give final model special style spanning generative properties 
prior term expresses belief parsimony principle model give maximally concise minimally uncertain explanation structure training set 
optimal bias extracting information possible data 
apply prior generic model 
prior interesting effect emission distributions pose velocity gradually removes dimensions variation flattening distribution effective way reduce volume entropy see 
prior term keeps style models close congruent generic model corresponding hidden states models similar behavior 
practice assess prior emission distributions specific models effect keeping variation dependent emission distributions clustered tightly generic emission distribution 
consequently minimizes distance corresponding states models entire models 
add term allows vary strength prior course optimization 
constraining generic style specific gaussians overlap constraining narrow cause distribution state specific gaussians styles small number degrees freedom 
intuitively gaussians narrow overlap aligned directions overlapping disks space planar 
illustrates 
dimensions overlapping gaussians flat fewer degrees freedom relative 
consequently style specific models drawn generic model training models settle parameter subspace see 
subspace variation style specific models described just parameters 
identify degrees freedom solving smooth low dimensional manifold contains parameterizations style specific models 
merl tr conference proceedings siggraph 
schematic style dof discovery 
left constraints style specific models drawn data clouds typically span dimensions parameter space 
right drawn generic model settle parameter subspace indicated dashed plane 
experiments showed linear subspace usually provides low dimensional parameterization dataset stylistic degrees freedom 
subspace easily obtained principal components analysis pca set vectors representing model parameters 
useful extend prior additional functions 
example adding varying gives deterministic annealing optimization strategy forces system explore error surface scales converging nearest local optimum see equations 
optimization learning hope simultaneously segment data motion primitives match similar primitives executed different styles estimate structure parameters minimally ambiguous maximally generative models 
entropic estimation gives framework solving partially discrete optimization problem embedding high dimensional continuous space entropies :10.1.1.134.6624
gives numerical methods form maximum posteriori map entropy optimizing parameter estimators 
attempt find best data generating model gradually excess model parameters supported data 
solves discrete optimization problem causing diffuse distribution possible segmentations collapse single segmentation 
optimization proceeds expectation maximization em fast powerful fixpoint algorithm guarantees convergence local likelihood optimum initialization :10.1.1.131.2084
estimators give modify em cross entropy optimization annealing 
annealing strengthens em guarantee quasi global optimality global map optimality probability approaching annealing necessary assurance due number combinatorial optimization problems solved simultaneously segmentation labeling alignment model selection parameter estimation 
full algorithm 
initialize generic model style specific model motion sequence 

em loop convergence step compute expected sufficient statistics motion sequence relative model 
step generic calculate maximum posteriori parameter values minimum entropy prior step statistics entire training set 
step specific calculate maximum posteriori parameter values minimum cross entropy prior step statistics current sequence 
adjust temperature see schedules 

find subspace spans parameter variations models 
calculate pca differences generic style specific model 
initialization random full annealing initial conditions 
encode useful hints initial model em loop partial annealing starting lower temperature 
hmms useful property saves trouble labelling training data actions particular training sequence may squashed stretched time oddly ordered repeated course learning basic hmm dynamic programming algorithms find optimal segmentation labelling sequence 
cross entropy prior simply adds constraint similarly labeled frames exhibit similar behavior necessarily appearance sequences 
illustrates induced state machine labelling similar incongruent sequences induced state machine captures elements transitions 
working motion capture machine learning application problem harder easier depending data represented algorithm 
learning algorithms look statistically salient patterns variation data 
motion capture may patterns humans find perceptually expressively salient 
want preprocess data highlight sources variation tell story dance leg motions compensatory body motions suppress irrelevant sources variation inconsistent marker placements world coordinates sequences modeled stylistic variations 
sources variation inter sequence variations body shapes need scaled dominate style space 
describe methods converting raw marker data suitable representation learning motion 
data gathering preprocessing gathered human motion capture data variety sources see 
data consists positions physical markers placed human actors acquired short intervals motion capture studios 
data source provided data different arrangement markers body 
defined reduced marker arrangement markers input sequences converted combining deleting extra markers 
note missing markers recovered synthesized data remapping style machines original input marker data 
doubled size data set mirroring resampled sequences hz 
captured synthetic motion capture data figures animations show motions markers connected fake skeleton 
bones skeleton algorithmic value added illustration purposes markers easier follow 
step convert marker data joint angles plus limb lengths global position global orientation 
near base back root kinematic tree 
joint angles training 
joint angles nature periodic example ranging training assumes input signal lies infinite domain took pain choose joint angle parameterization merl tr conference proceedings siggraph 
discontinuities jump training data 
able fully eliminate discontinuities 
partially due input data inverted knee bends 
conversion joint angles removes information articulations cause greatest changes body pose 
restore information scale joint angle variables statistically salient articulations vary pose measured data set procedure similar described gleicher 
reduce dependence individual body shape mean pose subtracted sequence noise dimensionality reduced pca typically fewer significant dimensions data variation training 
training models initialized state transition matrix pj probabilities declining exponentially diagonal gaussians initialized randomly centered nth frame sequence 
initial conditions save learning algorithm gratuitous trouble selecting factorial number equivalent models differing ordering states 
train annealing setting temperature high making decay exponentially zero 
forces estimators explore error surface scales committing particular region parameter space 
high temperature phase set cross entropy temperature zero force variation models stay near generic model 
high temperatures accidental commitments initialization largely 
generic temperature declines briefly heat cross entropy temperature allowing style specific models venture find datapoints explained generic model 
drive temperatures zero estimators converge entropy minimum 
temperature schedules hints guide optimization find global structure offload local variation specific models simplify compress models possible 
result training collection models model distribution hidden states state explains frame information sequence 
typically distribution zero near zero entropy meaning collapsed single state sequence explains data 
sequence probable states encodes content data show applying different style specific model causes content resynthesized different style 
remap model emission distributions joint angles angular velocities scaled importance joint 
information needed synthesis 
remapping means re estimating emission parameters observe time series synchronous training data 
making new styles encode style specific hmm vector state means square root covariances kij kij state dwell times average long model stays state transitioning 
new styles created interpolation extrapolation space 
dimensionality space reduced pca treating hmm single observation generic hmm origin 
pca gives cyclic domains ideally von mises distribution essentially gaussian wrapped circle analytic variance estimator known 
subspace models axes intrinsic degrees variation styles training set 
typically stylistic dofs needed span variations training set dimensions style variable interpolates styles training set varying coordinates models style subspace style specific hmm resulting parameter vector 
course interesting extrapolate going outside convex hull training styles theme explored 
analyzing new data obtain style coordinates novel motion sequence copy generic model style specific model assigns high likelihood retrain model cross entropy constraints respect original generic model 
projection resulting parameters style manifold gives style coordinates 
obtain sample state occupancy matrix 
mentioned summarizes content motion sequence key synthesis described 
synthesizing virtual motion data new value style variable state sequence encoding content may new style calculating maximum likelihood path arg maxy 
brand describes method calculating maximum likelihood sample time timesteps 
generalizes improves result information 
resulting path inherently smooth curve varies system dwells hidden state frames velocity constraints frame 
motion discontinuities synthesized samples possible difference velocities successive states large relative frame sampling rate 
preprocessing steps reversed produce virtual motion capture data final output 
actions take longer different styles move style style accommodated scaling dwell times state sequence match new style 
ways making time flexible incorporate dwell times directly emission distributions synthesize list varying sized time steps clock frames 
addition existing motion capture new styles possible generate entirely new motion data directly model 
learning automatically extracts motion primitives motion cycles data see take form state sub sequences 
cutting pasting state sequences sequence new choreography 
model state machine arc states consecutively scheduled motion primitives model automatically modify primitives transition smoothly 
find path state machine primitives insert states path 
interesting effect achieved doing random walk state machine generates random plausible choreography 
examples collected set locomotion time series variety sources 
motion capture sequences feature variety different kinds motion body types postures marker placements 
converted motion data common set markers prototypical body 
normalize body walk kick spin windmill states 
merl tr conference proceedings siggraph 
walk kick spin windmill male ballet states 
female expert ballet female modern dance states 

time 

time 

time 

time 
states 
female lazy ballet top state machine learned dance sequences totalling frames 
low probability arcs removed clarity 
motion cycles labeled primitives contained linear sequences 
bottom occupancy matrices constructed learning indicate sequence segmented labeled 
note variations timing ordering cycles sequences 
completion analogy walking running synthesis stylistic motion 
stick figures show frames show trajectories extremities 
energetic arm swing power stride running 
motion sequences synthesized choreography different styles row 
actions aligned vertically turning kicking spinning 
odd body geometry reflects marker placements training motion capture 
merl tr conference proceedings siggraph 
algorithm typically identifies variations body geometry principal stylistic dofs 
hint algorithm trained hmm lowdimensional representation data 
entropic estimation yielded model essentially phase diagram locomotive cycle 
initialization full training 
lightly annealed constrained hint final generic model retain information initialization 
pca resulting style specific models revealed stylistic degrees freedom explained variation models 
significant stylistic dof appears global pose tilts forward running back 
contains information speed motion 
style dof controls balance gender varying modifies hips distance midline compensating swing arms 
style dof characterized amount energy motion increasing yields sequences look high 
extrapolating hull specific models yields behaved motion expected properties 
double amount tilt walk forward 
demonstrate analogies 
analogies particularly interesting form extrapolation 
problem walking running solve terms style coordinates running walking equivalent completing parallelogram having style coordinates walking running corners 
run walk resulting synthesized sequence looks form high energy pop dance style 
similarly analogy walking running cat walking gives looks model skip run fashion show 
turn examples handled existing time warping signal processing methods 
complicated example system trained performances classically trained man woman modern dance woman lazy ballet seconds duration roughly different moves 
performances similar vary timing ordering style moves 
state model took roughly minutes train frames interpreted matlab code single cpu mhz alphaserver 
parameter extinction left state roughly parameters 
shows system discovered roughly equivalent qualitative structure 
shows flowchart choreography discovered learning 
took frame sequence novice dancer attempting similar choreography little success getting moves wrong wrongly ordered losing beat occasionally stumbling 
resynthesized masculine modern style obtaining notable improvements grace recognizability dance 
shown accompanying video 
generated new choreography doing random walk state machine 
resulting state sequence synthesize new motion capture variety styles ballet modern male shown video 
illustrates different results showing poses aligned time slices different synthesized performances 
demonstrate driving style machines video 
essence technique generation var ied motion capture hmm state sequences distributions states 
examples obtained state sequences existing motion capture random walks hmm state machine 
fact state sequences calculated arbitrary signals brand shadow technique infer state sequences body pose velocity video image sequences 
means create animations acting motion front camera style machines map expert style choreography 
accompanying video show vision driven motion capture stylistic variations thereon 
discussion unsupervised framework automates tasks motion capture editing analysis data needn segmented annotated aligned contain explicit statement theme stylistic degrees freedom dofs 
things discovered learning 
addition algorithms automatically segment data identify primitive motion cycles learn transitions primitives identify stylistic dofs primitives look quite different different motion capture sequences 
approach treats animation pure data modeling inference task prior kinematic dynamic model representation bones masses gravity prior annotation segmentation motion capture data primitives styles 
needed generating animation learned directly data 
user isn forced stay data pure expect methods easily coupled constraints quadratic synthesis objective function linear gradient eqn 
penalty terms larger optimizations incorporate user specified constraints kinematics dynamics foot placement done video clear potential raw inference 
method generalizes reasonably small training set data driven approaches fail gracefully problems look training set 
currently exploring variety strategies incrementally learning new motions data comes 
important open question choice temperature schedules see trade learning time quality model 
results sensitive time courses theoretical results choose optimal schedules 
concentrated motion capture time series style machine framework quite general applied variety data types underlying models 
example model variety textures mixture models learn stylistic dofs synthesize extrapolated textures 
summary style machines generative probabilistic models synthesize data broad variety styles interpolating extrapolating stylistic variations learned training set 
introduced cross entropy optimization framework possible learn style machines sparse sampling unlabeled style examples 
showed apply style machines full body data demonstrated kinds applications existing motion capture new styles synthesizing new stylized motion data synthesizing stylized motion video 
showed style machines doing dance student wished posing motor skills expert dancer choreography novice 
acknowledgments merl tr conference proceedings siggraph 
datasets train models available bill freeman michael gleicher zoran popovic adaptive optics anonymous sources 
special bill freeman collected dance sequences especially purpose style content analysis 
egon pasztor assisted converting motion capture file formats jonathan yedidia helped define joint angle parameterization 
baum 
inequality associated maximization technique statistical estimation probabilistic functions markov processes 
inequalities 
brand :10.1.1.134.6624
pattern discovery entropy minimization 
heckerman whittaker editors artificial intelligence statistics 
morgan kaufmann january 
brand 
exploring variational structure cross entropy optimization 
langley editor proceedings international conference machine learning 
brand 
voice 
proceedings siggraph pages august 
brand 
shadow 
proceedings iccv september 
bregler 
learning recognizing human dynamics video sequences 
proceedings cvpr 
bruderlin williams 
motion signal processing 
proceedings sig graph pages august 
buhmann 
empirical risk approximation induction principle unsupervised learning 
technical report iai tr institut informatik iii universit bonn 

gonnet hare jeffrey knuth 
lambert function 
advances computational mathematics 
freeman tenenbaum 
learning bilinear models factor problems vision 
proceedings conf 
computer vision pattern recognition pages san juan pr 
gleicher 
motion editing spacetime constraints 
symposium interactive graphics pages april 
gleicher 
retargeting motion new characters 
proceedings siggraph pages july 
grzeszczuk terzopoulos hinton 
fast neural network emulation control physics models 
proceedings sig graph pages july 
howe leventon freeman 
bayesian reconstruction human motion single camera video 
solla muller editors advances neural information processing systems volume 
mit press 
lee shin 
hierarchical approach interactive motion editing human figures 
proceedings siggraph pages august 
popovi witkin 
physically motion transformation 
proceedings siggraph pages august 
rabiner :10.1.1.131.2084
tutorial hidden markov models selected applications speech recognition 
proceedings ieee feb 
rose cohen 
verbs adverbs multidimensional motion interpolation 
ieee computer graphics applications september october 
tenenbaum freeman 
separating style content 
mozer jordan petsche editors advances neural information processing systems volume pages 
mit press 
takeuchi 
fourier principles emotion human animation 
proceedings siggraph pages august 
wilson bobick 
parametric hidden markov models gesture recognition 
ieee trans 
pattern analysis machine intelligence 
witkin popovi 
motion warping 
proceedings siggraph pages august 
zhu wu mumford 
minimax entropy principle applications texture modeling 
neural computation 
time 
graphical models hmm top middle path map bottom 
observed signal xt explained discrete valued hidden state variable changes time case vector valued style variable hidden inferred probabilistically 
arcs indicate conditional dependencies variables take form parameterized compatibility functions 
give rules learning inferring parameters associated arcs analysis inferring synthesis novel consistent behaviors inferring arbitrary settings 
hidden markov models hmm probability distribution time series 
dependency structure diagrammed 
specified pi pj pi sn set discrete states stochastic matrix pj gives probability transitioning state state stochastic vector pi probability sequence state emission probability pi probability observing state typically gaussian pi ki ki mean covariance ki 
cover hmm essentials see detailed tutorial :10.1.1.131.2084:10.1.1.131.2084
useful think continuous valued time series path configuration space 
hmm state space merl tr conference proceedings siggraph 
model meaning divides configuration space regions owned particular hidden state emission probability distribution 
likelihood path 
xt respect particular sequence hidden states 
probability point path respect current hidden state ps xt times probability state sequence product state transitions ps 
summed possible ps hidden state sequences obtains likelihood path respect entire hmm ps ps ps ps xt maximum likelihood hmm may estimated data alternating steps expectation computing distribution hidden states maximization computing locally optimal parameter values respect distribution 
step contains dynamic programming recursion eqn 
saves trouble summing exponential number state sequences pi xt jpj pi pi called forward variable similar recursion gives backward variable jpj xt pi step variables calculate expected sufficient statistics form basis new parameter estimates 
statistics tally expected number times hmm transitioned state cj jpj ipi xt probability hmm hidden state si observing datapoint xt 
statistics optimal respect information entire sequence model due forward backward recursions 
step calculates maximum likelihood parameter estimates simply normalizations pi ci ki ci xt xt training eqns 
remap model synchronized time series 
replace powerful entropy optimizing estimates 
stylistic hidden markov models stylistic hidden markov model hmm parameters functionally dependent style variable see 
simplicity exposition develop case emission probability functions pi xt gaussians means covariances varied case specified pi pj ki mean vector covariance matrix ki variation matrices style vector parameterize multivariate gaussian probability pi xt observing datapoint xt state xt si xt iv ki iv 
stylized covariance matrix ki iv kept positive definite mapping eigenvalues absolute values 
parameters pi pj ki obtained data entropic estimation dominant eigenvectors obtained post training pca style specific models estimated data varied user 
fix value model standard discrete state gaussian output hmm 
call case generic hmm 
simpler version model treated supervised context means vary specify hand structure model transition function pj number dimensions stylistic variation dim value training sequence 
framework learns automatically supervision generalizes wide variety graphical models 
entropies cross entropies terms objective function eqn 
essentially likelihood function measures fit model data log remaining terms measure fit model beliefs 
precise forms derived likelihood function 
multinomials parameters log log 
dimensional gaussians mean covariance log log log log ij ij ij 
likelihood function composed multinomials gaussians multiplication particular setting hidden states 
working composite distributions optimize sum components entropies gives measure model coding length typically bounds usually entropy composite model 
entropy declines bounds tight 
log posterior exp temperature merl tr conference proceedings siggraph 
optimization continuation parameterization top expectation maximization finds local optimum repeatedly constructing convex bound touches objective function current parameter estimate step blue calculating optimal parameter settings bound step red 
objective function shown energy log posterior probability optimum lowest point curve 
bot tom annealing adds probabilistic guarantee finding global optimum defining smooth blend model fitting hard optimization problem symbolized foremost curve maximizing entropy easy problem represented curve tracking optimum blend 
estimators optimal gaussian parameter settings minimizing vis vis datapoints xi gaussian parame mean covariance xi xi xi optimal multinomial parameter settings vis vis event counts multinomial distribution parameterized probabilities fixpoint pj exp ze log pj pj defined 
factors vary strength entropy cross entropy priors annealing 
derivations appear technical report available www merl com 
estimators comprise maximization step illustrated 
path maps path map statistical model supports predictions time series behavior target system observations cue system 
path map essentially hmms share backbone hidden states transition function derived target system see 
output hmm characterized state gaussian emission distributions target configurations velocities 
path cue configuration space calculates distribution hidden states eqn 

distribution calculates optimal path target configuration space equations synthesis improve brand solution motion sequence matrix state occupancy probabilities 
entropy declines distribution possible motion sequences lim vector yt yt target position velocity time minus mean state constant 
means covariances ki synthesizing model set gaussian emission probabilities ps ks 
break ing inverse covariance submatrices aj obtain maximum likelihood trajectory motion sequence solving weighted system linear equa tions bj dj yt aj bj cj dj idi yt ci di yt jfj iei ej cj dj fj aj bj ej endpoints obtained dropping appropriate terms equation dj cj dj ej bj dj aj bj cj dj yt yt fj generalizes brand geodesic information occupancy matrix just state sequence 
squares solution ly system calculated time block tridiagonal 
introduce improvement synthesis set training data eqn 
solve set gaussian means 
minimizes weighted reconstructing data state sequence 
factor eqn 
ly gm indicator matrix built sequence probable states 
solution calculation ly tends enormous dimension ill conditioned precondition problem behaved lg caution tension perfectly fitting training data generalizing new problems large amount data minimum entropy setting means better minimum squared error setting 
