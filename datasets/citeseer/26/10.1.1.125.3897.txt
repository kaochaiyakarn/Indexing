usenix association proceedings hotos ix th workshop hot topics operating systems hawaii usa may advanced computing systems association usenix association rights reserved information usenix association phone fax email office usenix org www www usenix org rights individual papers remain author author employer 
permission granted noncommercial reproduction educational research purposes 
copyright notice included reproduced 
usenix acknowledges trademarks 
events bad idea high concurrency servers rob von behren jeremy condit eric brewer computer science division university california berkeley brewer cs berkeley edu capriccio cs berkeley edu event programming highly touted years best way write highly concurrent applications 
having worked systems believe approach mistake 
specifically believe threads achieve strengths events including support high concurrency low overhead simple concurrency model 
argue threads allow simpler natural programming style 
examine claimed strengths events threads show weaknesses threads artifacts specific threading implementations inherent threading paradigm 
evidence user level thread package scales threads achieves excellent performance web server 
refine duality argument lauer needham implies implementations thread systems event systems similar performance 
argue compiler support thread systems fruitful area research 
mistake attempt high concurrency help compiler discuss enhancements enabled relatively simple compiler changes 
highly concurrent applications internet servers transaction processing databases number challenges application designers 
handling large numbers concurrent tasks requires scalable data structures 
second systems typically operate near maximum capacity creates resource contention high sensitivity scheduling decisions overload handled care avoid thrashing 
race conditions subtle corner cases common debugging code maintenance difficult 
threaded servers historically failed meet challenges leading researchers conclude event programming best way achieve high performance highly concurrent applications 
literature gives primary arguments events inexpensive synchronization due cooperative multitasking lower overhead managing state stacks better scheduling locality application level information flexible control flow just call return 
extensive events high concurrency environments including ninja seda inktomi traffic server :10.1.1.130.8002:10.1.1.130.8002
working systems realized properties restricted event systems implemented threads rest possible 
ultimately experience led conclude event programming wrong choice highly concurrent systems 
believe threads provide natural abstraction high concurrency servers small improvements compilers thread runtime systems eliminate historical reasons events 
additionally threads amenable compiler enhancements believe right paradigm highly concurrent applications thread package better compiler support 
section compares events threads common arguments threads 
section explains threads particularly natural writing high concurrency servers 
section explores value compiler support threads 
section validate approach simple web server 
section covers related section concludes 
threads vs events debate threads events old 
lauer needham attempted discussion showing message passing systems process systems duals terms program structure performance characteristics 
years authors declared need event driven programming highly concurrent systems :10.1.1.23.5560:10.1.1.130.8002
usenix association hotos ix th workshop hot topics operating systems events threads event handlers monitors events accepted handler functions exported module sendmessage procedure call fork join return procedure waiting messages waiting condition variables selection dual notions thread event systems paraphrased lauer needham 
converted terminology contemporary terms eventdriven systems 
duality revisited understand threads events debate useful reexamine duality arguments lauer needham 
lauer needham describe canonical threaded message passing event systems 
provide mapping concepts regimes paraphrased case proper implementations approaches yield equivalent performance 
argue decision comes paradigm natural target application 
case high concurrency servers believe thread approach preferable 
message passing systems described lauer needham correspond precisely modern event systems full generality 
lauer needham ignore cooperative scheduling events synchronization 
second event systems shared memory global data structures described atypical lauer needham messagepassing systems 
fact event system really matches canonical message passing system seda stages queues map exactly processes message ports :10.1.1.130.8002:10.1.1.130.8002
performance equivalence claimed lauer needham requires equally implementations don believe suitable threads implementation high concurrency 
demonstrate section discuss enhancements section 
arguing performance equivalent lauer needham implicitly graph call blocking graph 
graph describes flow control application respect blocking yielding points 
node graph represents blocking yielding point edge represents code executed points 
lauer needham duality argument essentially says duals graph 
duality argument suggests criticisms thread performance usability years arguably seda contributions return event driven systems practices lauer needham 
requests second threaded server event server concurrent tasks repeat threaded server benchmark seda :10.1.1.130.8002
threaded server uses preallocated thread pool process requests event server uses single thread pull items queue 
requests internally generated avoid network effects 
request consists read cached disk file 
motivated problems specific threading packages threads general 
examine common criticisms 
problems threads performance 
criticism attempts threads high concurrency performed 
don dispute criticism believe artifact poor thread implementations respect high concurrency 
currently available thread packages designed high concurrency blocking operations surprising perform poorly 
major source overhead presence operations number threads 
common problem thread packages relatively high context switch overhead compared events 
overhead due preemption requires saving registers state context switches additional kernel crossings case kernel threads 
shortcomings intrinsic properties threads 
illustrate fact repeated seda threaded server benchmark modified version gnu pth user level threading package optimized remove operations scheduler :10.1.1.130.8002
results shown 
optimized version pth scales quite threads easily matching performance event server 
control flow 
criticism threads restrictive control flow 
argument threaded programming encourages programmer think linearly control flow potentially precluding efficient control flow patterns 
hotos ix th workshop hot topics operating systems usenix association complicated control flow patterns rare practice 
examined code structure flash web server applications ninja seda tinyos :10.1.1.117.697:10.1.1.23.5560
cases control flow patterns applications fell simple categories call return parallel calls pipelines 
patterns expressed naturally threads 
believe complex patterns difficult 
accidental nonlinearities occur event systems hard understand leading subtle races errors 
intentionally complicated control flow equally error prone 
coincidence common event patterns map cleanly call return mechanism threads 
robust systems need error handling storage deallocation cleanup need return event model 
patterns considered graceful threads dynamic fan fan patterns occur multicast publish subscribe applications 
cases events probably natural 
high concurrency servers studied patterns 
synchronization 
criticism thread synchronization mechanisms heavyweight 
event systems claim advantage cooperative multitasking gives synchronization free runtime system need provide mutexes handle wait queues 
adya show advantage really due cooperative multitasking preemption events cooperative thread systems reap benefits :10.1.1.20.464:10.1.1.20.464
important note regime cooperative multitasking provides free synchronization uniprocessors high concurrency servers run multiprocessors 
discuss compiler techniques supporting multiprocessors section 
state management 
criticism thread stacks ineffective way manage live state 
threaded systems typically face tradeoff risking stack overflow wasting virtual address space large stacks 
event systems typically threads unwind thread stack event handler avoid problem 
solve problem threaded servers propose mechanism enable dynamic stack growth discuss solution section 
additionally event systems encourage programmers minimize live state blocking points require programmer manage state hand 
contrast thread systems provide automatic state management call stack mechanism allow programmers wasteful 
section details solution problem 
scheduling 
criticism virtual processor model provided threads forces runtime system generic prevents making optimal scheduling decisions 
event systems capable scheduling event deliveries application level 
application perform shortest remaining completion time scheduling favor certain request streams perform optimizations 
evidence events allow better code locality running kind event row :10.1.1.14.141
lauer needham duality indicates apply scheduling tricks cooperatively scheduled threads 
summary arguments show threads perform events high concurrency substantial qualitative advantages events 
absence scalable user level threads provided largest push event style shown deficiency artifact available implementations fundamental property thread abstraction 
case threads point largely argued threads events equivalent power threads fact perform high concurrency 
section argue threads appropriate abstraction high concurrency servers 
observations modern servers 
concurrency modern servers results concurrent requests largely independent 
second code handles request usually sequential 
believe threads provide better programming abstraction servers properties 
control flow 
high concurrency systems event programming tends obfuscate control flow application 
instance event systems call method module sending event expect return method similar event mechanism 
order understand application programmer mentally match call return pairs different parts code 
furthermore call return pairs require programmer manually save restore live state 
process referred stack adya major burden programmers wish event systems :10.1.1.20.464:10.1.1.20.464:10.1.1.20.464
obfuscation program control flow lead subtle race conditions logic errors due unexpected message arrivals 
thread systems allow programmers express control flow encapsulate state natural manner 
syntactically thread systems group calls returns usenix association hotos ix th workshop hot topics operating systems making easier understand cause effect relationships ensuring relationship 
similarly run time call stack encapsulates live state task making existing debugging tools quite effective 
exception handling state lifetime 
cleaning task state exceptions normal termination simpler threaded system thread stack naturally tracks live state task 
event systems task state typically heap allocated 
freeing state correct time extremely difficult branches application control flow especially case error conditions cause deallocation steps missed 
event systems ninja seda garbage collection solve problem 
previous java general purpose garbage collection mechanism inappropriate highperformance systems :10.1.1.130.8002
inktomi traffic server counting manage state maintaining correct counts difficult particularly error handling 
existing systems 
preference threads subtly visible existing event driven systems 
example ninja system ended threads complex parts recovery simply nearly impossible get correct behavior events tried 
addition applications didn need high concurrency written threads just simpler 
similarly ftp server harvest uses threads :10.1.1.21.1584
just fix events 
argue switching thread systems build tools languages address problems event systems reply matching live state management shared state management 
tools effectively duplicate syntax run time behavior threads 
case point cooperative task management technique described adya allows users event system write thread code gets transformed continuations blocking calls :10.1.1.20.464:10.1.1.20.464
cases fixing problems events tantamount switching threads 
compiler support threads tighter integration compilers runtime systems extremely powerful concept systems design 
threaded systems achieve improved safety performance minor modifications existing compilers runtime systems 
describe synergy overcome limitations current threads packages improve safety programmer productivity performance 
nearly release slow memory leaks due kind counting leaks limiting factor mtbf server 
dynamic stack growth developing mechanism allows size stack adjusted run time 
approach avoids tradeoff potential overflow wasted space associated fixed size stacks 
compiler analysis provide upper bound amount stack space needed calling function furthermore determine call sites may require stack growth 
recursive functions function pointers produce additional challenges problems addressed analyses 
live state management compilers easily purge unnecessary state stack making function calls 
example temporary variables popped subroutines called entire frame popped case tail call 
variables overlapping lifetimes automatically reordered moved stack order prevent live variables unnecessarily pinning dead ones memory 
compiler warn programmer cases large amounts state held blocking call allowing programmer modify algorithms space issue 
synchronization compile time analysis reduce occurrence bugs warning programmer data races 
static detection race conditions challenging progress due compiler improvements tractable program analyses 
nesc language networked sensors tinyos architecture support atomic sections compiler understands concurrency model :10.1.1.117.697:10.1.1.127.9488
tinyos uses mixture events run threads compiler uses variation call graph similar blocking graph 
compiler ensures atomic sections reside edge graph particular calls atomic section yield block indirectly 
compiler analysis help determine atomic sections safe run concurrently 
information runtime system allow safe execution multiprocessors automating hand coded graph coloring technique libasync 
evaluation evaluate ability threads support high concurrency designed implemented simple line user level cooperative threading package linux 
thread package uses coroutine library minimalist context switching translates blocking requests asynchronous requests internally 
asynchronous socket hotos ix th workshop hot topics operating systems usenix association mbits second knot favor connections knot favor accept haboob concurrent clients web server bandwidth versus number simultaneous clients 
unable run benchmark haboob clients haboob ran memory 
unix poll system call asynchronous disk provided thread pool performs blocking operations 
library overrides blocking system calls provides simple emulation pthreads allows applications written library compile unmodified standard pthreads 
thread package wrote line test web server knot 
knot accepts static data requests allows persistent connections includes basic page cache 
code written clear straightforward threaded style required little performance tuning 
compared performance knot seda event driven web server haboob test suite evaluate seda :10.1.1.130.8002
dev poll patch original haboob tests deprecated tests haboob standard unix poll knot 
test machine mhz xeon smp gb ram running linux 
test uses small workload little disk activity 
ran haboob jvm ibm jit enabled 
presents results 
tested different scheduling policies knot favors processing active connections accepting new ones knot reverse knot 
policy provides natural throttling mechanism limiting number new connections server saturated requests 
second policy designed create higher internal concurrency closely matches policy haboob 
shows knot haboob general performance pattern 
initially linear increase bandwidth number simultaneous connections increases server saturated bandwidth levels 
performance degradation knot haboob due poor scalability poll 
newer sys system call knot avoids problem achieves excellent scalability 
poll result comparison incompatible haboob socket library 
result shows thread package achieve scaling behavior designed event system 
steady state bandwidth achieved knot nearly mbit rate server apparently limited interrupt processing overhead kernel 
believe performance spike clients due lower interrupt overhead fewer connections server created 
haboob maximum bandwidth mbit significantly lower knot haboob cpu limited clients 
possible reasons result 
haboob thread handler model requires context switches events pass handler 
requirement causes haboob context switch times second fully loaded times frequently knot 
second proliferation small modules haboob seda natural outgrowth event programming model creates large number module crossings queuing operations 
third haboob creates temporary objects relies heavily garbage collection 
challenges deeply tied event model simpler threaded style knot avoids problems allows efficient execution 
event systems require various forms run time dispatch event handler execute known statically 
problem related problem ambiguous control flow affects performance reducing opportunities compiler optimizations increasing cpu pipeline stalls 
related ousterhout known case favor events arguments conflict 
argues programming concurrency fundamentally difficult concludes cooperatively scheduled events preferable purposes allow programmers avoid concurrent code cases 
explicitly supports threads true concurrency case target space 
agree cooperative scheduling helps simplify concurrency argue tool better context simpler programming model threads 
adya cover subset issues better :10.1.1.20.464:10.1.1.20.464
identify value cooperative scheduling threads define term stack management live state 
expands usenix association hotos ix th workshop hot topics operating systems ideas exploring thread performance issues compiler support techniques 
seda hybrid approach events threads events stages threads :10.1.1.130.8002
approach quite similar messagepassing model discussed lauer needham lauer needham advocate single thread stage order avoid synchronization stage 
seda showed value keeping server operating range explicit queues agree various queues threads visible enable better debugging scheduling 
addition stage boundaries seda provide form modularity simplifies composition case pipelines 
call return patterns boundaries require stack better implemented threads blocking calls 
techniques advocate improving threads introduced previous 
filaments nt fibers examples cooperative user level threads packages targeted large numbers blocking threads 
languages erlang concurrent ml include direct support concurrency lightweight threading :10.1.1.45.3454:10.1.1.21.1584
bruggeman employ dynamically linked stacks implement shot continuations turn build user level thread packages 
contribution bring techniques single package accessible broader community programmers 
event systems obtain performance high concurrency systems shown similar higher performance achieved threads 
simpler programming model wealth compiler analyses threaded systems afford gives threads important advantage events writing highly concurrent servers 
advocate tight integration compiler thread system result programming model offers clean simple interface programmer achieving superior performance 
george necula matt welsh feng zhou russ cox helpful contributions 
berkeley millennium group hardware benchmarks 
material supported national science foundation graduate research fellowship nsf millennium eia 
adya howell theimer bolosky douceur :10.1.1.20.464
cooperative task management manual stack management 
proceedings usenix atc june 
armstrong virding williams :10.1.1.21.1584
concurrent programming erlang 
prentice hall second edition 
bruggeman waddell dybvig 
representing control presence shot continuations 
acm sigplan conference programming language design implementation june 
chankhunthod danzig neerdaels schwartz worrell :10.1.1.21.1584
hierarchical internet object cache 
proceedings usenix annual technical conference january 
dabek kaashoek mazieres morris 
event driven programming robust software 
proceedings th acm sigops european workshop september 
engler andrews 
filaments efficient support fine grain parallelism 
technical report massachusetts institute technology 
gay levis von behren welsh brewer culler :10.1.1.127.9488
nesc language holistic approach networked embedded systems 
acm sigplan conference programming language design implementation 
hill szewczyk woo hollar culler pister :10.1.1.117.697
system architecture directions networked sensors 
architectural support programming languages operating systems pages 
tinyos available webs cs berkeley edu 
larus parkes :10.1.1.14.141
cohort scheduling enhance server performance 
technical report msr tr microsoft research march 
lauer needham 
duality operating system structures 
second international symposium operating systems ir october 
ousterhout 
threads bad idea purposes 
presentation usenix annual technical conference january 
pai druschel zwaenepoel 
flash efficient portable web server 
proceedings annual usenix technical conference june 
reppy :10.1.1.45.3454
higher order concurrency 
technical report cornell university june 
shah madden franklin hellerstein :10.1.1.130.8002
java support data intensive systems experiences building telegraph dataflow system 
sigmod record 

coroutine library source 
www de 
von behren brewer chen welsh macdonald lau gribble culler 
ninja framework network services 
proceedings usenix annual technical conference june 
welsh culler brewer :10.1.1.130.8002
seda architecture conditioned scalable internet services 
symposium operating systems principles pages 
hotos ix th workshop hot topics operating systems usenix association 
