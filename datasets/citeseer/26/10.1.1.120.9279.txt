journal computational biology volume numbers mary ann pp 
probabilistic statistical properties words overview reinert sophie michael waterman overview statistical probabilistic properties words occurring analysis biological sequences 
counts occurrence counts clumps renewal counts distinguished exact distributions normal approximations poisson process approximations compound poisson approximations derived 
sequence modelled stationary ergodic markov chain test determining appropriate order markov chain described 
convergence results take error estimating markovian transition probabilities account 
main tools involved moment generating functions martingales stein method chen stein method 
similar results occurrences multiple patterns example problem unique recoverability sequence chip data discussed 
special emphasis lies complicated dependence structure word occurrences due self overlap due overlap words 
results derive approximate conservative con dence intervals tests 
key words word counts renewal counts markov model exact distribution normal approximation poisson process approximation compound poisson approximation occurrences multiple words sequencing hybridization martingales moment generating functions stein method chen stein method 

statistical probabilistic properties words considerable interest elds reliability theory analysis biological sequences 
provide overview state research 
main aspects word occurrences biological sequences occur times occur 
important problem instance determine statistical signi cance word frequency dna sequence 
naive idea word may signi cantly rare dna sequence disrupts replication gene expression counter selection factor signi cantly frequent word may fundamental activity regard genome stability 
known examples words exceptional frequencies dna sequences certain biological palindromes corresponding restriction sites avoided instance coli karlin cross hotspot instigator sites bacteria see king college statistical laboratory cambridge cb st uk 
unit de en france 
department mathematics department biological sciences department computer science usc los angeles ca 
reinert 
papers aim identifying represented words particular genome instance leung speed rocha 
statistical methods study distribution word locations sequence word frequencies active eld research 
dna sequences long asymptotic distributions proposed rst 
exact distributions exist motivated analysis genes protein sequences 
unfortunately exact results adapted practice long sequences heavy numerical calculation allow validation quality stochastic approximations approximation error provided 
example blast probably best known algorithm dna matching relies poisson approximation 
approximate values applicability poisson approximation needs justi ed 
statistical properties words sense respect underlying probability model 
dna sequences commonly modeled stationary random sequences 
typical models homogeneous markov chains model mm probability occurrence letter position depends previous letters sequence position independent case particular case 
hidden markov models hmms reveal composition dna sequence may vary sequence churchill muri durbin studied hmms 
statistical properties words derived heterogeneous models 
dna sequences code amino acid sequences proteins nonoverlapping triplets called codons 
positions codons distinct statistical properties coding dna naturally think sequences successive letters come codon positions respectively 
chains transition matrices denoted mm 
focus homogeneous models mm give existing results mm 
probabilistic models tted observed biological sequence pay attention uence model parameter estimation statistical results 
asymptotic results take care problem exact results require true model driving observed sequence known 
choice markov model order depends sequence length data requirements estimation 
able test hierarchical models chi square tests assign type markovian dependence appropriate underlying sequence 
practical point view depends composition biological sequence wants take account 
sequence generated order markov chain model mm predict letter words 
concerned rstly occurrences single pattern sequence 
discuss underlying probabilistic models section 
main complication word occurrences arises overlaps words 
interested overlapping occurrences particular nonoverlapping ones section 
presenting results statistical distribution word locations sequence section focus distribution number overlapping occurrences section number section 
section study occurrences multiple patterns 
section gives example probabilistic statistical considerations come play dna sequence analysis 
analyze called chips fast effective method determining dna sequence 
chips provide tuple contents dna sequence typically 
nontrivial combinatorial problem arises determining probability randomly chosen dna sequence uniquely reconstructed tuple contents 
section meant appendix gives compilation general techniques applied 
consider nite words 
necessarily due abundance literature existing probabilistic statistical aspects words omitted 
intended serve complete literature survey just list take space volume introduce reader major aspects eld provide techniques warn major pitfalls associated analysis words 
reason completely omit algorithmic aspect excellent starting point waterman gus eld particular example see apostolico 


probabilistic models biological sequences biological sequence dna sequence protein sequence nite sequence letters letter dna alphabet fa tg letter amino acid alphabet 
probabilistic statistical properties words model biological sequence consider models random sequences letters 
observed nite biological sequence sn consider convenience nite random sequence nite alphabet set integers 
classes markov models widely analyze biological sequences discuss estimate parameters observed sequence 
give classical chi square test choose appropriate order markov model sequence 

models random sequences letters simplest model assumes letters independent take value probability jaj jaj denotes size alphabet 
re ne model simply assume independent letters value probability 
called model 
practice particular dna sequences model typically accurate 
consider general homogeneous model model mm ergodic stationary order markov chain nite alphabet transition matrix am am am am am am 

general stationary distribution ergodic stationary markov chain transition matrix de ned solution 
implies markov chain unique stationary distribution de ned am ba am am ba am am 
model letters fx chosen independently probabilities 
corresponds transition matrix identical rows stationary distribution 
jaj 
coding dna sequence naturally read successive nonoverlapping letter words called codons 
codons translated amino acids genetic code produce protein sequence 
different codons code amino acid rst letters codon suf ce determine corresponding amino acid 
letters may different importance depending position respect codon partition 
distinguish letter probabilities position modulo coding dna sequence consider stationary markov chain distinct transition matrices 
am pk am am am am 

model mm 
index called phase represents position letter inside codon 
convention phase word phase letter sequence codons letter words phase 
stationary distribution am ba am am pk ba am am 

estimation model parameters modeling biological sequence consists choosing probabilistic model see previous paragraph estimating model parameters unique realization biological sequence 
case model mm means estimate transition probabilities am am estimators classically denoted bp am am 
derive estimators maximize likelihood model observed sequence give maximum likelihood estimators models mm mm 
reinert assume stationary markov chain transition matrix stationary distribution 
likelihood model ab ab denotes number occurrences letter word ab random sequence nd transition probabilities maximize likelihood maximizes log likelihood log log ab log 
separately maximize ab log keeping mind 
choose ab log ab log ac log ab log partial derivatives equal zero means implies particular follows ab ab ad bp ac ab ac ad ab note second partial derivatives likelihood function negative assuring determined maximum 

convenience notation estimators remainder chapter bp ab letter sequence counts differ 
important note estimators bp random variables 
assuming biological sequence realization random sequence calculate numerical value estimator bp obs obs ab obs obs denotes observed count biological sequence 
see results obtained assuming true parameters known equal practice obs ab obs take care estimation 
common practice substitute estimator corresponding parameter distributional results changes distribution studied illustrated waterman 
probabilistic statistical properties words model mm maximum likelihood estimator am am 
am bp am am am model mm 
am am am amb 
test appropriate order markov model test markov model appropriate sequence length straightforward test chi square test viewed generalized likelihood ratio test 
known chi square test independence see rice 
general suppose sample size cross classi ed table rows columns 
instance rows labeled columns labeled count letter row followed letter column sequence 
test may assume sequence consist independent letters 
purpose recall ab denotes count cell ath row count bth column count 
ab counts letter followed letter sequence 
probability cell ath row marginal probability bth column marginal probability 
test null hypothesis independence alternative free 
maximum likelihood estimate alternative maximum likelihood estimate sequence simply consecutive pairs ab pearson chi square statistic sum squared differences observed expected count divided expected counts ux vx ab think letters alphabet enumerated 
null hypothesis follows asymptotically chi square distribution degrees freedom 
reject null hypothesis large compared corresponding chi square distribution 
rule thumb test applicable expected frequency row column 
applying test dna counts compare chi square distribution degrees freedom 
typical cutoff level likes conservative 
corresponding critical values 
reject null hypothesis independence level meaning repeated experiment times cases reject null hypothesis true 
reject null hypothesis level trials reject null hypothesis true 
reject null hypothesis 
null hypothesis independence rejected appropriate level say independent model 
null hypothesis get rejected test higher order dependence 
step test rst order markov chain 
reinert proceed regarding transition followed transition dna sequence fa tg rows record letter words ab columns transitions ab count cell ab number transitions ab number times letter word ab followed sequence 
previously denoted abc separation ab refer cell sizes 
ab probability cell ab quantities 
test null hypothesis rst order markov chain ab alternative ab free 
maximum likelihood estimate ab ab ab bc alternative maximum likelihood estimate ab ab ab enumerating letters fa tg pearson chi square statistic ab 
quantity compared chi square statistic degrees freedom 
hypothesis rejected test higher order markov chain analogous way 

overlapping nonoverlapping occurrences statistical inference independence assumptions 
sequence letters independent identically distributed different random indicators word occurrences independent due overlaps 
example occurs position sequence occurrence occur position occur position occurrence position possible 
arguments needed probabilistic statistical analysis word occurrences deal overlapping structure 
word length nite alphabet occurrences may overlap sequence periodic meaning exists 
wi wi 
word may periods 
set periods de ned fp 
wi wi 
pg 
word periodic empty 
instance periodic admits periods 
occurrences sequence starting respectively positions 
rst occurrences overlap form clump 
clump sequence maximal set overlapping occurrences sequence 
de nition clumps sequence overlap 
clump composed exactly overlapping occurrences called clump clumps previous sequence rst clump starting positions second clump starting position 
set concatenated words composed exactly overlapping occurrences example type nonoverlapping occurrences interest require scanning sequence rst occurrence sequence renewal occurrence renewal overlap previous renewal 
overlap sequence 
example starting positions 
probabilistic statistical properties words depending problem interested studying overlapping occurrences sequence restricting attention nonoverlapping occurrences beginnings clumps beginnings clumps 
introduce notation related occurrences word clump clump renewal sequence corresponding counts 

occurrence number overlapping occurrence occurrence starts position sequence 
yi associated random indicator yi ifw starts position 
convenience sections yi random indicator occurrence ends position precise case 
stationary order markovian model expectation yi represents probability occurrence occurs position sequence denoted wm wm wm 
ambiguity index referring order model omitted 
number overlapping occurrences sequence simply called count de ned nn pn yi pn yi yi associated occurrence position 

clump counts clump starts position nite sequence occurrence starting position overlap previous occurrence follows eyi ifa clump starts position yi yi yi 
eyi zero depending overlapping structure de ne set principal periods periods strictly multiples minimal period turns eyi yi yi denotes pre length concatenated word pw 
called root called principal root equation obtained steps note occurrence starting position overlaps previous occurrence directly preceded occurrence principal root meaning principal root occurs position ii note events disjoint 
prove ii assume different principal roots occur simultaneously position minimal root decomposed xy yx nonempty words 
proposition says words commute powers word 
obtain contradiction minimal root minimal see details 
follows equation probability em clump starts position em 
number en clumps nite sequence count may different sum en inf pn eyi possible clump start reinert position position 
difference en en inf equal equal 
fact shown en en inf em see reinert 

clump number clumps clump starts position occurrence concatenated word starting position overlap occurrence sequence proceeded clump occurrence occurrence clump directly preceded principal root directly followed suf 
straightforward calculation yields expression eyi ifa clump starts position yi yi yi cw yi cw follows probability clump start position em 
formula improved 
note fw denoting follows em 
count number clumps nite sequence may different sum en inf pn eyi possible effects 
difference controlled probability 
possible effects may lead difference count en inf controlled reinert 

renewal renewal count renewal starts position occurrence starting position rst overlap previous renewal ii associated random indicator ii ifa renewal starts position yi convention 
renewal occurrence position exactly clump occurrence nite sequence 
renewal count extensive linear ordering sequence de ned ii 
probabilistic statistical properties words 
word locations sequence concerned length gaps word occurrences 
describe get exact distribution give asymptotic results 

exact length word occurrences word length nite alphabet assume stationary rst order markov chain transition matrix stationary distribution 
interested statistical distribution distance successive occurrences precisely probabilities occurs occurrence occurs 
section say word occurs position occurrence ends position happens probability 
probability obtained recursive formula robin rst proposed independent uniformly distributed letters blom 
clear 
decompose event disjoint events fw occurs fw occurs occurrence fw occurs occurrences 
fe probability 
decomposed occurrence occurs disjoint events 

occurrences positions occurrences necessarily overlap possible case 

occurrence positions distinguish cases depending possible overlap occurrences overlap previous calculation overlap 
xd get proof theorem see robin 
reinert theorem 
distribution distance successive occurrences word markov chain recursive formula 
distance successive occurrences note null 
instance aaa aaa aaa aa 
note recurrence formula nite recurrence calculating requires calculation 
requiring substantial numerical calculations large approach computation problem generating function de ned key argument expression rational function theorem see robin form coef cient expressed recurrence formula order degree polynomial see section 
theorem 
generating function 
transition matrix exists ai bi jaj jaj ai implying expression rational function pole equal 

td general properties var 
successive derivations obtained decomposition stated previous 
proof theorem 
proof theorem complicated just develop sum theorem technical 
give main lines calculation 
replacing theorem td obtain sum terms probabilistic statistical properties words td td th td td zx hx hx tz tu reinert grouping leads establishes theorem 
distance successive occurrences seen distance th th occurrence sequence homogeneous model 
may useful study distance th th occurrence called scan karlin colleagues dembo karlin 
distance sum independent identically distributed random variables distribution get exact distribution taylor expansion probability coef cient series 

asymptotic scans preceding paragraph get exact distribution scan distance word occurrence th stationary markov chain 
analyzing biological sequence assume observe occurrences motif observe distances 
dh occurrences motif 
observe called scans pi detect poor rich regions motif interested studying signi cance smallest largest scans generally kth smallest scan denoted mk kth largest scan denoted mk 
section poisson approximation statistical distribution extreme value mk obtained dembo karlin chen stein method 
similar result exists mk identical setup explained detail 
start de ning bernoulli variables chen stein method see section denote ifd 
xr number scans equal note duality principle fw kg fmk 
theorem get poisson approximation distribution 
apply theorem rst need choose neighborhood dependence indicator variable ideally indicator variables index neighborhood dependence independent indicator variable 
secondly quantities bound called 
piecing gives bound total variation distance distributions 
proceed follows 
probabilistic statistical properties words 
choose neighborhood bi fj ji jj poisson variable expectation theorem gives dtv xr ew ew 
ew ew xr nfi dtv denotes total variation distance see section 
neighborhood bi chosen independent bi leading 
xr bi nfi shown nally get 
duality principle dtv rx rx 
xr da 
xr jp mk xr approximation useful comparison expected distribution scans observed biological sequence 
applied karlin coli genome approximating scan distribution section sum independent exponential random variables 
reinert 
word count distribution word length nite alphabet random sequence section devoted statistical distribution count sequence state compute exact distribution model recursion techniques 
long sequences asymptotic results obtainable general easier handle 
appropriate asymptotic regime depends crucially length target word relative sequence length short words law large numbers applied approximate word count expected word count 
crude estimate easily improve employing central limit theorem states word count distribution asymptotically normal 
approximation satisfactory words long 
rare words rule thumb words length log compound poisson approximation give better results 
error approximation bounded terms sequence length word length word probabilities possible assess compound poisson approximation choice 
error bound incorporated give conservative con dence intervals explained 

exact stationary rst order markov chain exact distribution count easily obtained distribution successive positions th occurrence duality principle fn ft ng 
exact distribution obtained section deriving taylor expansion generating function generating function obtained see theorem 
just state result robin sum independent identically distributed random variables distribution coef cient taylor expansion equal 
duality principle get nx 
generalizes exact result gentleman mullin obtained case sequence composed letters letter occurs equal probability 
case gentleman gives algorithm calculating word frequency distribution 
markov case exact distribution count obtained techniques automaton built pattern structure matrix language decomposition approach combinatorial methods 

weak law large numbers crude rst approximation weak law large numbers states observed counts converge expected counts 
may chebyshev inequality bound expected deviation observed counts expected number occurrences 
approximation valid probabilistic statistical properties words relatively short words case normal approximation gives information 
approximation derived subsection 

asymptotic distribution gaussian regime assume stationary order markov chain transition probabilities am am stationary distribution am 
am subsection yi yi yi ifw ends position model known asymptotic normality en directly follows central limit theorem markov chains variance 
expectation variance en varn en en eq 

problem nding exceptional words biological sequences model unknown parameters estimated observed sequence 
expected mean available approximated estimator 
paragraph get asymptotic normality asymptotic variance 
trivial problem estimation changes fundamentally variance expression 
expected mean en probability occurrence ends position sequence see eq 

estimating parameter maximum likelihood estimator gives estimator bn en wm 
wm rst consider maximal model mainly nd exceptional words leung speed rocha 
introduce notation pre length suf length 
maximal model estimator bn asymptotic normality bn asymptotic variance obtained elegant way martingale techniques 
martingales see chung 
bn natural estimator approximately martingale shown 
introduce martingale mn yi yi fi fi 
easy verify mn fn mn 
yi fi ifw ends occurs fi ends gp reinert nx yi fi mn ifw ifw ends ng ends 

note ifw ends tends zero 
proposition establishes asymptotic normality mn proposition 

mn 
proof 
application theorem dimensional random variable jn yi yi fi 
conditions satis ed 
condition holds jn fi 
check var jn fi converges 
yi random variable obtain var yi fi yi fi nx var jn fi ifw yi fi ends gp nx var yi fi ifw ends gp convergence follows law large numbers 
establishing condition iii 
theorem proves proposition 
proposition equation yield initially wanted prove convergence tn 
bp bp probabilistic statistical properties words purpose decompose tn follows tn bp mn martingale pn yi yi fi theorem gives lim 
mn nx yi yi fi yi yi fi lim nx var yi fi 
technique derivation yi yi yi get 
note law large numbers guarantees surely 
able deduce tn converges distribution just proved theorem 
theorem 
bn reinert bn nbs nbs plug estimator ns nbs bn models straightforward extend previous martingale approach prove asymptotic normality derive asymptotic variance 
value difference bn decomposed linear combination martingales exactly done tn 
instance abcde abcde bn abcde abcde abcde abcd de ab bc cd de de cd abcd abc de cd abc ab bc approach consists method proposed 
idea consider bn count vector wm 
wm 
see equation 
exists covariance matrix en 
see waterman exposition 
step method theorem transfer convergence nally get en en partial derivative vector en 
method easily provide explicit formula asymptotic variance function derivative depends conditional approach 
provides alternative problem 
initially model method generalized general model mm 
principle conditionally suf cient statistic sm model mm collection counts fn am 
am ag rst letters sequence 
technique developed cowan derive conditional expectation sm conditional variance 
key arguments rst conditional expectation probabilistic statistical properties words asymptotically equivalent leading asymptotic normality sm second var sm limiting value am am am am am am wm wm denotes number occurrences inside am stands conditional moment order bounded follows 
amb 
overlapping structure clearly appears limiting variance 
exercise verify limiting variances theorem equation identical 
martingale conditional approaches extended mm model see de nition notation 
wants distinguish occurrences coding dna sequence particular phase represents position word respect codons interested count phase recall word phase phase letter 
state result maximal model see general case 
theorem 
assume stationary order markov chain transition probabilities pk stationary distribution 

pk pk pk 
approach stein method normal approximations theorem 
moment assume independent model 
put varn nx nx yi nx yi nx ix yi reinert note de ne put yi 
nx fn choose fi ji jj fi ji jj 
neighborhood structure theorem set indicators half lines 
provides explicit bound kolmogorov smirnov distance normal distribution 
note due independence quantities vanish 
theorem 
assume independent model 
constants word length jp result generalized model mm neighborhood size proportional log theorem need modifying quantities bound terms conditional expectations respect sigma elds respect sums proceed result multivariate generalization 

asymptotic distribution poisson regime previous section showed count word random sequence length approximated gaussian distribution large gaussian approximation fact expected count small meaning rare word 
poisson approximations appropriate counts rare events 
illustration known sum independent bernoulli variables approximated gaussian distribution poisson distribution depending asymptotic behavior expected value 
sequence letters independent poisson compound poisson approximations widely studied literature aki fu 
markovian models different conditions considered aki works concern general periodic words provide explicit parameters limiting distribution 
see poisson distribution satisfactory periodic words possible overlaps compound poisson distribution proposed 
classes tools generating functions provide approximation error chen stein method gives bound total variation distance distributions see section details 
section chose chen stein approach rst order markovian model known parameters generalizations higher order estimated parameters section 
assumption overlapping structure word basic 
case sequence composed letters see apostolico 

assume stationary rst order markov chain transition probabilities stationary distribution word length yi yi ifw starts position eyi 
applying theorem bernoulli variables yi obtain bound total variation distance distribution poisson distribution mean probabilistic statistical properties words mean converge rare word assumption nm 
note nm means log 
main dif culty applying theorem comes term possible overlaps periodic words 
periodic word set period empty 
take bi fi 
neighborhood 
guarantees tend 
get nfi eyi quantity order small periods poisson approximation valid count words set periods empty 
periodic words crucial argument consider clumps de nition overlap 
rst prove count en approximated poisson distribution mean em see eq 
applying theorem bernoulli variables eyi de ned 
prove compound poisson approximation applying theorem bernoulli variables eyi de ned asymptotically equivalent probability 
simplicity variables eyi eyi denoted eyi eyi poisson approximation count 
aim approximate vector ey eyi bernoulli variables vector independent poisson coordinates mean ez em em de ned 
apply theorem choose neighborhood bi fj ij 
neighborhood bi letters common eyi ey de ning eyi de ning ey separated positions 
important consider lag converging nity leads exponential decay term theorem see 
deriving bound total variation distance ey consists bounding quantities 
bounding presents dif culty em log clumps overlap sequence eyi ey ij 
get symmetry bi nfi ey ey ey em em log bounding little involved give steps technique compound poisson approximation count described detail 
de nition eje eyi ey bi reinert ey bi 

properties conditional expectation markov property give eje eyi je eyi 
evaluate right hand term introduce set possible words length preceding clump fg 
clump starts position words gw starts position 
write gives eyi yi gw 
je yi gw eyi gw jp yi gw gw gw gw diagonalize transition matrix 
jaj eigenvalues ja ja ja 
perron frobenius theorem see karlin taylor ensures ja abbreviate 
right eigenvector eigenvalue vector stationary distribution left eigenvector eigenvalue 
diag 
decompose rst column 
rst row vector stationary distribution 

denotes jaj jaj matrix entries equal de ne jaj jaj gw jaj gw jaj jaj gw jaj probabilistic statistical properties words max note 
gw em proved theorem 
em jaj jaj 
jaj theorem 
em 
independent poisson variables expectation ez ey em em jaj dtv em 
count en approximated en inf eyi dtv en en inf en en inf em see section 
triangle inequality leads corollary corollary 
poisson variable expectation ez em 
en em em jaj dtv em em 
compound poisson approximation count 
approximate distribution count rst asymptotically equivalent inf pn probability reinert dtv inf inf em 
goal approximate vector eyi 
bernoulli variables vector independent poisson coordinates expectation ez em em equation 
neighborhood bi bi letters de ning eyi de ning ey separated positions 
eyi described 
consider bi bound successively quantities 
de nition em em em em 
reinert obtain em em kem em em term involves products eyi ey bi clump position overlap clump products zero 
identify need describe detail compound words may occur positions purpose introduce set words length follow clump write fd dp eyi yi gcd 
convenience simply write gcd sum sum 
gives nf ey gcd eyi gcd 
jc jcj yi gcd clumps overlap 
distinguish cases position overlaps gcd position possible letters fi jc 
jc jg fi jcj 
jcj denote associated term 
position overlap gcd position fi 
jc fi jcj 
denote associated term 
symmetry summing gives gcd gcd jcj jcj eyi gcd 
jcj eyi gcd ey jcj probabilistic statistical properties words summing ey leads gc jcj jcj eyi gc 
occurrence gc position overlap occurrence position jcj follows eyi gc gc jcj note gc leads term easier bound get gc em gc 
gc em em em min min smallest value fm ag 
em min log log em bounding consists different steps previously described count decomposition 
interest repeating technical part just give bound state theorem max em jaj theorem 
independent poisson variables expectation ez em 
previous notation dtv eyi em em em jaj em em min reinert total variation distance properties dtv kz aa dtv eyi independent poisson variables kz distributed kz independent poisson variables expectation em 
note compound poisson distribution 
triangle inequality leads corollary corollary 
independent poisson variables expectation ez em cp denotes compound poisson distribution kz previous notation dtv cp em em em jaj log em em em min chen stein method obtained different type bound markov chain coupling local approach 
related results poisson approximations markov chain coupling announced roos stark 
special case runs random sequence letters binary alphabet extensively studied erd gave asymptotic behavior longest run sequence bernoulli trials length longest segment contains proportion greater level result re ned devroye lynch 
compound poisson approximation counts runs case sequence letters independent considered roos employing chen stein method results limiting distribution reduced special case 
xia obtained accurate limiting approximation case runs length approximation perturbation poisson distribution 
bound total variation distance instance word count distribution associated compound poisson distribution great advantage providing con dence intervals see section 
notation corollary kz ta dtv kz aa estimation parameters 
transition probabilities unknown estimated observed sequence need evaluate total variation distance word count distribution distribution kz independent poisson variables expectation bem bem observed value plug maximum likelihood estimator em 
similarly want know total variation distance count en poisson variable expectation bem 
triangle inequality fact total variation distance poisson variables expectation jl dtv en po bem dtv en po em em probabilistic statistical properties words law iterated logarithm markov chains equation show bm 
log log surely 
see 
rare word condition nm get equation obtain nm log log log log quantity converges zero rare word condition implies log 
dtv en po bem dtv en po em log log approximation follows corollary 
note explicit bound additional error term 
long sequences error term due maximum likelihood estimation small compared bound compound poisson approximation error 
similarly total variation distance compound poisson distributions bounded dtv kz kz aa equation quantity tends zero nm see 
generalization mm 
assume sequence order markov chain alphabet transition probabilities am am am basic idea rewrite sequence alphabet de ning xi sequence xi rst order markov chain transition probabilities am bm am bm am bm 
denote word 
written alphabet 

results valid number overlapping occurrences number en clumps xn 
occurrence position corresponds occurrence position xn simply 
contrast clumps xn different clumps periodic leading en en 
take simple example ata 
put ta ab 
sequence reinert contains unique clump associated sequence contains clumps ab 
ab period ata period 
fact periods periods strictly 
poisson approximation count order markov chain follow immediately case rigorous proof require applying chen stein theorem adapted neighborhood bounding new quantities mm carried 
corollary ensures approximated sum kz poisson variable expectation times probability clump starts position xn 
equation obtain ez mg important consequence mm compound poisson approximation words overlap letters comes single poisson approximation 

large deviation approach long sequences probability word occurs certain number times approximated gaussian compound poisson distribution sections 
aim section show large deviation techniques approximate probability word frequency deviates expected value 
word length recall denotes probability occurs position aim provide approximations 
assume stationary rst order markov chain nite alphabet transition probabilities 
generalizing mm follows setup section theorem need consider irreducible markov chain xn xi transition matrix count written 
ifx xi ifu 
function sup hx log largest eigenvalue matrix de ned 
applying theorem closed subset open subset get lim log probabilistic statistical properties words similarly lim log 
denoting observed count biological sequence obs get large obs 
obs obs exp obs obs obs obs obs exp note approximation obtained assuming transition probabilities known 
eigenvalue jaj jaj matrix word length limiting factor numerical calculation jaj 
renewal count distribution particular case nonoverlapping occurrence counts section count word 
random sequence de ned section 
consider renewal count pn ii ii random indicator renewal starts position see 
exact results particular combinatorial approach language decompositions derive moment generating function renewal count 
tools different ones asymptotic results 

gaussian approximation letters 
independent identically distributed asymptotic distribution renewal count studied breen 
proved central limit theorem markovian case 
main technique generating functions bound rate convergence obtained 
result 
note asymptotic mean variance established normal approximation follows markov renewal central limit theorem 
derive expected renewal count 
ii expectation say er 
commonly expectation see breen instance ignores effect 
ii effectively identically distributed stationarity markov process case 
start calculation 
recall set periods denotes word composed rst letters consider overlap matching polynomial associated see guibas odlyzko li de ned markov process stationarity renewal theory 
understand formula note decompose event occurrence starting position disjoint union renewal starting position reinert renewal starting position directly followed letters period fi 

written follows yi ix expectations sides gives ifi gg ii yi 
gives result 
previously noted rst variables 
identically distributed boundary effects 
asymptotic results interest section effect may ignored 
note provides exact renewal count expectation er calculating asymptotic variance little involved relying overlap matching polynomial 
purpose similarly de ne jaj jaj matrix row vector stationary distribution 
denoting markovian transition matrix put put 
proved theorem generating functions 
special case theorem fact proves multivariate approximation 
theorem 
nm 
theorem easier prove case carried waterman 
fact needed establish variance expression follows renewal central limit theorem 

poisson approximation similarly count derive poisson approximation renewal count rare word condition nm 
simple 
recall yi ifw starts position probabilistic statistical properties words write ii yi yi yi eyi yi ii yi 
note renewal occurrence rst positions clump occurrence observed nite sequence conversely 
en ii yi derived poisson approximation number clumps en see section 
consider difference en yi summand nonzero rstly need yi 
note renewal implies occurrence 
product products different qi qi 
implies renewal positions occurrence position position 
occurrence renewal part larger clump repeating argument see occurrence part clump started position 
implies occurrence occurrence clump occurrence en eyi 
quantity small asymptotic framework nm 
may poisson bound number clumps derived just add error term order log idea proof 

prove result words having principal period 
related results obtained 
reinert 
occurrences multiple patterns characterizing protein families short motifs instance interested distribution joint occurrences multiple patterns single patterns 
interest determine statistical signi cance count degenerated words 
asymptotic results similar approximations available distribution joint occurrences joint counts multiple patterns section 
see main new feature consider possible overlaps different words target family 
interested family words fw 
wr words describe possible overlaps de ning fp 

means occurrence overlap occurrence right means overlap left 
note lack symmetry example 
avoid assumption 
substring model sequence fx stationary ergodic markov chain 
gaussian approximation joint distribution multiple word counts 
assume general model mm minf 
state asymptotic normality vector 
prove result multivariate martingale central limit theorem 
estimated count 
novelty consists deriving asymptotic covariance matrix suppose words length maximal model martingale technique see section leads ifw 
note formula reduces asymptotic variance section 
generally conditional approach see section leads am am am am am am am am ifw wr probabilistic statistical properties words denotes number occurrences inside denotes number occurrences inside 
formula reduces 
note wants study total number occurrences word family fw 
qx qx poisson compound poisson approximations joint distribution counts multiple word counts 
assume model generalization mm follows single pattern case 
give bound error poisson process approximation overlapping counts reinert de ne quantities 
em em em em em min em em min em em max max choose index set sq ir ir jaj 
pq 
written disjoint union 
rx 
reinert de ne ir 
apply theorem bernoulli process ey eyi poisson process eyi ey po em choose neighborhood bi fj 
maxf 
denote maximal length words min denote minimal length words 
reinert prove results 
theorem 
assumption notation dtv ey min jaj qx em qx em 
corollary 
independent poisson variables ez em 
previous notation assumption dt en qx min em jaj qx em qx em proof direct application theorem similar section 
similar way compound poisson approximation numbers occurrences obtained 
choose index set 
qx apply theorem bernoulli process ey eyi poisson process de ned eyi ey po em ir ir 
neighborhood bi probabilistic statistical properties words weak assumption overlap structure 
substring composed word 
theorem 
assumptions notation dtv ey jaj qx em 
corollary easily obtained 
corollary 
independent poisson variables expectation ez pq em cp denotes compound poisson distribution kz assumptions notation dtv qx 
cp jaj qx em qx em derived compound poisson approximation special case counting total number overlapping occurrences words word family 
uses markov chain coupling local approach bound error slightly different avor 
poisson approximation renewal count distribution 
related results renewal counts available 
poisson approximation problem reduced counts case single word 
consider nonoverlapping occurrences competition 
example sequence set words tat tta aa renewal occurrences tat position tta position aa positions 
occurrences tat position tta position aa positions counted overlap counted words 
ifa competing renewal starts position number competing sequence poisson process approximation poisson approximation counts want assess ic eyi 
consider ic eyi 
note ic eyi occurrence position occurrence start clump overlapping occurrence position 

occurrence competing renewal word wr overlapping occurrence 
may bound eyi qx 
reinert bound valid probability smaller space clumps occur 
secondly consider ic wr eyi 
ic eyi occur occurrence position overlapped occurrence different word wr may bound eyi qx bound remains valid 
ey ey qx obtain corollary theorem 
qx qx corollary 
assumption notation dtv min jaj qx em qx em qx qx note order approximation theorem additional error terms comparable respectively 
poisson approximation competing renewal counts follows immediately 
gaussian approximation joint distribution competing renewal counts 
multivariate normal approximation obtained 
main problem specify covariance structure 
state result quite bit notation needed 
matrix denote transposed matrix square matrix represents vector diagonal elements de ne probabilities word pr collect nal letters start correct initial letters probabilistic statistical properties words overlap matching polynomials de ned de ne matrix furthermore denote vector denote 

ek pr ek ek 
ek ek diagonal matrix components ek diagonal elements 
put ek ek 
put pr de ne vector put de ne vector matrix 
dz 

qk ez identity matrix de ned matrix matrix matrix entry element row corresponding letter word columns corresponding rst letter de ne variance covariance matrix ez ek ek ez diag 
reinert de ne mean wr 
ingredients state normal approximation obtained 
theorem 
assumption nm 
case single pattern theorem reduces theorem 
sequencing hybridization slightly involved example statistics probability words applied dna sequence analysis describe problem related sequencing hybridization see 
details 
sequencing hybridization tool determine dna sequence unordered list tuples contained sequence typical numbers 
fact dna nucleotides bind 
example sequence 
sequencing chip possible probes length attached surface substrate fragment distinct location 
chip single stranded target dna ampli ed labeled exposed sequencing chip 
probes chip copy single stranded target dna substring complementary probe exists target 
probes detected detector 
example sequence probes 
chips washed due automatization method fast inexpensive 
method originally developed sequence dna date major compare different dna strings order detect mutations 
particular chips employed analysis hiv blood samples decide virus sample known form hiv new mutation 
arrays gene expression studies 
technical dif culties producing error free chip image may dif cult read 
sources errors eliminated main drawback procedure sequence may produce data 
example sequence probes sequence 
control error resulting nonunique recoverability interested estimate probability sequence uniquely recoverable sequence unambiguous 
probability depend probe length length target sequence frequencies different nucleotides sequence 
furthermore need bound error estimating probability unique recoverability order assertions reliability chip 
simpli cation assume know set tuples sequence multiplicity order occur 
multiset called spectrum sequence 
sequel unique recoverability understood mean unique recoverability sequence spectrum 
pevzner characterizes unique recoverability spectrum de bruijn graph see van lint wilson vertices tuples sequence 
vertices joined directed edge spectrum contains tuple rst nucleotides coincide nucleotides coincide pevzner showed sequence uniquely recoverable spectrum unique eulerian path connecting vertices 
ukkonen conjectured pevzner proved exactly structures prevent unique recoverability probabilistic statistical properties words 
rotation 
sequence starts ends tuple 
case de bruijn graph cycle vertex chosen starting point 

transposition way repeat 
tuple occurs times sequence de bruijn graph loops vertex order loops passed xed 

transposition interleaved pairs repeats 
interleaved pairs tuple repeats de bruijn graph vertices connected path form 



described path connecting vertices listing vertices order path 
implies ways going graph 
example 
sequence possesses spectrum multiset 
competing sequence spectrum 
de sequence vertices aca cac act ctc tca 
directed edges aca cac directed edge cac aca cac act act ctc ctc tca tca cac 
competing sequence de bruijn graph 
sequence path connecting vertices alternate path aca cac aca cac act ctc tca cac 
aca cac act ctc tca cac aca cac connecting vertices corresponds sequence spectrum 
unique recoverability described terms possibly overlapping repeats tuples single sequence 
model dna random sequence 

independent identically distributed alphabet fa sequence uniquely recoverable event tuple repeat rare 
implies consider occurrence tuples poisson regime 
note interested con guration repeats occur need poisson process approximation process repeats poisson approximation number repeats 
repeats rare way repeats negligible probability sequence starts ends tuple 
bounding probabilities restrict attention interleaved pairs repeats 
poisson regime pairs repeats occurrences repeats discrete uniform 
additional randomization position repeats continuously uniform orderings pairs approximately equally 
allows application combinatorial argument catalan numbers obtain number interleaved pairs repeats repeats approximately 
expected number repeats tuples single sequence get probability 
uniquely recoverable spectrum 
chen stein method poisson approximation theorem provides explicit bounds error terms approximation follows 
sequence 
independent identically distributed letters probability random letters match 
write interested repeats 
de ne yi yi ifx ifx ifx 
yi leftmost repeat starting put 
careful analysis see yields process ya suf cient decide sequence uniquely recoverable spectrum contains strictly information process indicators occurrences 
reinert poisson process approximation rst identify expected number leftmost repeats 
self overlap ya 
expected number repeats self overlap self overlap order leftmost repeat indices overlapping set matches required indices nonoverlapping set match required 
ya depends decomposition quotient remainder qd pq probability random letters match ya pr pd pq pq pd 
bounded away nity corresponds having log constant seen pt regime bounded away nity short version general result 

maxa probability letter 
theorem 
process independent poisson distributed coordinates ya ez dtv uniform case nonuniform case 

general result derived general alphabets explicit bounds obtained 
bounds approximate probability unique recoverability 

obtained results number possible reconstructions sequence reconstruction unique 

chen stein method 
probabilistic statistical tools chen stein method powerful tool deriving poisson approximations compound poisson approximations terms bounds total variation distance 
random processes values space total variation distance probability distributions de ned dtv sup measurable jp sup measurable jeh eh published chen poisson analog stein method normal approximations stein widespread application word counts just 
friendly exposition 
description examples 


key theorem word counts stationary markov chains theorem probabilistic statistical properties words 
improved bound 
theorem theorem giving theorem 
theorem 
index set 
ya bernoulli random variable pa ya 
suppose chosen ba 
independent poisson variables mean pa total variation distance dependent bernoulli process ya poisson process satis es dtv ba pa pb ya pa ya yb ba 
dtv po min 
le note ya independent yb ba think ba neighborhood strong dependence ya 
consequence theorem indicator event measurable functional error bound form jeh eh dtv 
test statistic jp construct con dence intervals nd values tests statistic 
note method prove compound poisson approximations 
multivariate compound poisson approximations convenient 
univariate compound poisson approximations better bounds hand see roos 


stein method normal approximations stein method normal approximation rst published stein 
applied obtain multivariate normal approximations bound error distance suprema convex sets 
denote class indicator functions convex sets random vectors values vector sums 
assume constant jy di jy theorem 
si subsets 
ng si 
assume exist constants sets denotes cardinality 

ng ij 
ng reinert exists universal constant sup jeh hj ew exists constant depending dimension sup jeh hj nad log log nx eje yk log log sj nx eje yk yk yl ji 
moment generating function sj nx yk sj short outline moment generating functions see rice 
moment generating function random variable de ned discrete distribution tx 
sj tx 
moment generating function exists open interval containing zero uniquely determines probability distribution 
particular regularity conditions moments random variable obtained moment generating function differentiation 
nite dt etx tx 
ex sides equation exist 
similarly differentiating times obtain 
special case moment generating function rational written 
prt 
coef cients 
pr 
qs 
normalization may assume 

prt 

probabilistic statistical properties words identi cation coef cients sides yields pi ix qi ix qi gives recurrence formula coef cients pd 
method pd min qi general method propagation error linear approximation taylor expansion nonlinear function random variables 
particularly interested validity normal approximation functions random vectors see rice 
theorem waterman 
theorem 

nk sequence random vectors satisfying bn bn 
vector valued function 
real valued gi nonzero differential gi gx gi 
gx gi de ne di di 
large deviation principle gi 
gx bn 
assume irreducible markov chain nite alphabet transition probabilities theorem markov chains 
theorem miller 
function mapping pn obeys large deviation principle rate function de ned closed subset open subset lim sup log lim inf log nx nx inf inf 
rate function positive convex uniquely equal zero ef sup hx log largest eigenvalue matrix hf reinert 
clt martingales theorem du 
theorem 
jn triangular array dimensional random vectors ijj positive matrix 
put fn jn 
jn jn fn denotes conditional expectation vector jn cov jn fn denotes conditional covariance matrix jn ii nx jn fn nx cov jn fn iii jn nx ij fn 
acknowledgments simon helpful comments 
supported part sandia national laboratories operated lockheed martin department energy contract 
de ac mathematics information computational science program ce science department energy 
apostolico bock 
annotated statistical indices sequence analysis proceedings compression complexity sequences 
ieee computer society press 
bollobas coppersmith sorkin 
euler circuits dna sequencing hybridization preprint 
goldstein gordon 
moments suf ce poisson approximations chen stein method ann 
prob 
goldstein gordon 
poisson approximation chen stein method statistical science 
martin reinert waterman 
poisson approximation long repeats random sequence application sequencing hybridization comp biol 
xia 
poisson perturbations preprint 
holst janson 
poisson approximation 
oxford university press 
chen loh 

compound poisson approximation nonnegative random variables stein method ann 
prob 

solving stein equation compound poisson approximation adv 
appl 
prob 
el 
codon usage explain gt rich islands surrounding chi sites escherichia coli genome mol 


markov renewal processes counters repeated sequences markov chains ann 
appl 
prob 
blom 
random digits required sequences obtained appl 
prob 
breen waterman zhang 
renewal theory patterns appl 
prob 
beckmann trifonov 
linguistics nucleotide sequences morphology comparison vocabularies 
struct 
dynamics 

large deviation techniques decision simulation estimation 
wiley 
ehrlich 
nucleotide sequence protects dna degradation analogue mol 

probabilistic statistical properties words chen 
poisson approximation dependent trials ann 
prob 

limit theorem number non overlapping occurrences pattern sequence independent trials appl 
prob 

limit theorem number overlapping appearances pattern sequence independent trials prob 
theory rel 
fields 
chung 
course probability theory nd ed 
academic press 
churchill 
stochastic models heterogeneous dna sequences bull 
math 
biol 
cowan 
expected frequencies dna patterns whittle formula appl 
prob 
du 
probabilit 
probl mes temps mobile 
masson 
devroye 
exact convergence rate limit theorems erd nyi shepp ann 
prob 
dembo karlin 
poisson approximations scan processes ann 
appl 
prob 
durbin eddy krogh mitchison 
biological sequence analysis 
cambridge university press 
roos 
compound poisson approximation random variables stein method appear combinatorics probability computing 
erd nyi 
new law large numbers analyse math 

compound poisson approximation markov chains 
ph thesis royal institute technology stockholm 
fu 
poisson convergence reliability large linearly connected system related coin tossing statistica sinica 
gentleman 
distribution frequency subsequences alphabetic sequences exempli ed acid appl 
statist 
gentleman mullin 
distribution frequency occurrence nucleotide subsequences overlap capability biometrics 
skolnick 
compound poisson approximations word patterns markovian hypotheses appl 
prob 

poisson approximations runs patterns rare events adv 
appl 
prob 

improved poisson approximations word patterns adv 
appl 
prob 
guibas odlyzko 
long repetitive patterns random sequences 
gus eld 
algorithm strings trees sequences 
cambridge university press 
aki 
number occurrences success runs speci ed length state markov chain statistica sinica 
karlin burge campbell 
statistical analyses counts distributions restriction sites dna sequences nucl 
acids res 
karlin 
assessment inhomogeneities coli physical map nucl 
acids res 
karlin taylor 
course stochastic processes nd ed 
academic press 

second moment counts words random texts generated markov chains comp 
applic 
biosci 

exact computation pattern probabilities random sequences generated markov chains comp 
applic 
biosci 
leung marsh speed 
short dna words genomes comp 
biol 
li 

martingale approach study occurrence sequence patterns repeated experiments ann 
prob 

combinatorics words 
addison wesley 

stochastic models statistical methods dna sequence data 
ph thesis university utah 
muri 
modelling bacterial genomes hidden markov models proceedings computational statistics eds 
payne green 
physica verlag heidelberg 
pevzner 
tuple dna sequencing computer analysis 
struct 
dynamics 
pevzner 
dna physical mapping alternating eulerian cycles colored graphs algorithmica 
de 
finding words unexpected frequencies dna sequences statist 
soc 


success runs state markov chain appl 
prob 

uni ed approach word statistics proceedings second annual international conference computational molecular biology recomb 

uni ed approach word occurrence probabilities appear discrete applied mathematics special issue computational biology 
reinert reinert 
compound poisson poisson process approximations occurrences multiple words markov chains comp 
biol 
rice 
mathematical statistics data analysis 
duxbury press 

coupling constructions rates clt dependent summands applications model weighted statistics multivariate analysis 
robin 

exact distribution word occurrences random sequence letters appl 
prob 
rocha 
oligonucleotide bias general trends taxonomic comparisons nucl 
acids res 
roos 
stein chen method compound poisson approximation 
ph thesis university zurich 
roos stark 
poisson approximation mixing sequences coupling preprint 

compound poisson approximation word counts dna sequences probability statistics 

tude du nombre occurrences un mot dans une cha ne de markov application la de mots de fr quence dans les quences adn 
ph thesis universit ren descartes paris 
statistique re de mod les ann 
inst 
henri poincar 
el ehrlich 
identi cation chi site sequences related escherichia coli chi site mol 

stein 
bound error normal approximation distribution sum dependent random variables proc 
sixth berkeley symp 
math 
statist 
probab vol 

univ california press berkeley 

central limit theorem patterns markov chain sequence letters preprint 
ukkonen 
approximate string matching grams maximal matches theoret 
comp 
science 
van lint wilson 
course combinatorics 
cambridge university press 
waterman 
computational biology 
chapman hall 
address correspondence reinert king college statistical laboratory king parade cambridge cb st united kingdom 
