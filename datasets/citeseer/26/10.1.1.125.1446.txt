evaluation frequently audio features classification music perceptual categories tim elias pampalk gerhard widmer austrian research institute artificial intelligence vienna department computational perception johannes kepler university linz tim elias gerhard growing amount available music induces increasing demand music information retrieval mir applications music recommendation applications automatic classification algorithms 
audio crucial part systems audio feature extraction routines 
evaluate variety combinations feature extraction machine learning algorithms suited classify music perceptual categories 
examined categorizations perceived tempo mood happy neutral sad emotion soft neutral aggressive complexity vocal content 
aim contribute investigation aspects music captured common audio descriptors experiments conclude examined categorizations captured 
indicates research needed alternative possibly extra musical sources information useful music classification 

music information retrieval mir deals automatic extraction useful information music audio data 
outcome mir research useful variety applications notably ongoing change music distribution gradually shifts sales online music stores reliable automatic music recommendation classification systems desirable 
mir algorithms help radio dj playlist generation organization personal public music collections 
research done field audio music similarity measures automatic classification music audio 
algorithms evaluated relative task genre classification publications categories considered pieces album artist 
interestingly publications evaluated different aspects music captured applied feature extraction algorithms 
evaluate combinations known feature extraction machine learning algorithms suited capturing aspects mood emotion vocal content perceived tempo complexity 
enhanced knowledge topic support development improved feature extraction algorithms able describe facets music captured existing ones 

related substantial research carried problem automatic genre classification name :10.1.1.121.9421:10.1.1.5.7586
systematic genre classification contest international conference music information retrieval ismir far spent classifying music genre isolated attempts applying labellings categorizations intrinsic music 
algorithm automatically detect mood classical music acoustic data 
apply attribute set support vector machine classification music emotion classes system low performance example micro averaging category weighted averaging recall precision 
system automatically learns relations adjectives audio features 
adjectives gained crawling web 
web data artist audio features tracks artist combined associations adjectives audio features artist level 
system learns labels related mood genre gives probabilities occurrence label unseen instances 
system eval ismir ismir net genre contest index htm different descriptive labels pieces belonging major classes rock 
labellings obtained web artist level 
perceived complexity multiple dimensions research ongoing develop feature extraction algorithm takes account 
interesting approach automatic development new features describe arbitrary aspects music 
publication systematically evaluate features frequently literature labels song level 

experimental setup estimate examined categorizations music amenable automatic classification features extracted audio useful task approach calculate wide range features commonly literature genre classification songs music collection labeled desired categories 
features converted attributes suited fed standard machine learning algorithms 
different attribute sets evaluated combination twelve different machine learning algorithms 
experiments confusion matrices classification accuracies assessed 
steps described detail sections 

song collection target categorizations experiments house database consisting pieces mp format 
pieces hand labeled categories table male subject 
table cardinalities class fact unequally distributed consequence real world song collection 
genre focus categories common sense understanding example complexity affected kind rhythm melody line number different instruments appear 
aware categorizations including genre means granted human categorize songs way clear individual choose categories labeling repeated 
asking humans way get labellings 
taken music guide www com genre descriptors id tagging system www id org categorizations chosen reflect important dimensions music necessarily correlated example depend genre piece contains 
mir system music recommendation system valuable able distinguish categories important part humans refer music band plays fast complex instrumental music 
categorization classes songs class mood happy neutral sad perceived tempo slow slow medium fast fast varying complexity low medium high emotion soft neutral aggressive focus instruments genre blues classical folk jazz new age noise rock world tab 

categorizations song collection 

feature extraction extract features music piece converted wav format downsampled khz mono seconds exactly middle taken compute features 
features audio excerpt divided frames samples length overlapped half 
tested feature sets described sections 

set set vector containing components song implemented information definitions 
timbral texture features 
audio frame values extracted spectral centroid center magnitude distribution spectrum 
spectral frequency power distribution concentrated 
spectral flux measure short time changes spectrum 
zero crossing rate number times time domain signal passes zero level 
mfccs 
mfccs give description envelope frame spectrum 
timbral texture features mean variance values frames low energy rate 
altogether results values value low energy rate values mean variance spectral centroid spectral spectral flux zero crossing rates values mfccs 
beat histogram describes periodicity audio excerpt different tempo levels cases prominent peak corresponds main tempo excerpt 
rhythmic content features properties beat histogram audio excerpt motivated detail relative amplitude highest peaks divided sum histogram ra relative ratio height second highest peak highest peak bpm values highest peaks sum sum histogram bins indication beat strength 
analogous manner pitch histogram describes pitch height audio excerpt unfolded pitch histogram gives values pitch range folded pitch histogram values lie octaves apart summed resulting histogram bins 
pitch content features properties folded unfolded pitch histograms amplitude highest peak folded histogram higher songs harmonic changes 
pitches highest peaks folded unfolded histograms 
unfolded histogram indicates octave range dominant pitch piece folded histogram indicates main pitch class 
interval highest peaks folded histogram related main interval region piece 
sum histogram bins 
value higher pitch detected accurately 
results features directly comparable results procedure selecting representative excerpts pieces precisely specified 

set mpeg mpeg standard designed offer comprehensive framework describing content multimedia files 
offers techniques metadata handling extracting features different types multimedia files 
part features describe basic properties audio called low level descriptors 
mpeg selected subset suitable specific type experiments 
example audio waveform descriptor main purpose support display audio envelope 
timbre descriptors best fitted monophonic audio segments 
mpeg setup audio power measure power contained time domain signal 
audio spectrum centroid analogue spectral centroid defined logarithmic frequency scale 
audio spectrum spread audio spectrum flatness bands measures far spectrum deviates flat curve respective frequency band 
audio harmonicity consisting values frame fundamental frequency approximation main pitch 
harmonicity ratio measure harmonic current frame sounds 
upper limit harmonicity frequency sound harmonic anymore 
analogous set attribute values song means variances values time series band respectively gives total attributes song 

large set third set consisted attributes sets additional attributes derived features features reported various authors context music classification measure signal bandwidth current frame spectral power alternative measure signal energy statistical moments frequency power distribution spectral centroid beat tracking beat onset features summarized inter onset interval histograms feature estimates percussive piece value piece monophonic melody estimation average pitch height standard deviation pitch height average note duration relation upward downward pitch changes calculated attributes 
types beat histogram folded unfolded pitch histograms mean maximum standard deviation values appearing quantiles chosen attributes 
bandwidth spectral power statistical moments mean variance taken attributes 
altogether resulted attributes calculated large feature set 

proposed algorithm additionally algorithm described parameter set proposed 
algorithm similarity function result distance measure set attributes nearest neighbors classification categorizations 
calculation algorithm done ma toolbox 

machine learning algorithms evaluate amount information captured features feature data features train respectively apply machine learning algorithms 
machine learning algorithms built discover underlying structure feature data extract information useful classification task hand rate success indicator quality features 
rate success drawn average classification accuracy clearly higher baseline classification accuracy obtained frequent class assigned 
different machine learning algorithms different approaches equally kinds data reason twelve variations machine learning algorithms machine learning toolbox weka nearest neighbors na bayes additional kernel estimation algorithm algorithm decision tree learner support vector machine svm adaboost decision stump classification regression applying linear regression 
evaluation done fold cross validation machine learning algorithm trained known class membership pieces collection trained algorithm classify remaining procedure repeated times piece classified 

results altogether combinations attribute set learning algorithm categorization evaluated 
get picture results categorization average classification accuracy best performing learning algorithm respective table interesting confusion matrices depicted 

focus focus categorization experiments accuracy baseline table shows best classification accuracies indicate tested descriptor sets suited detection 
focus classification results baseline set mpeg large set best tab 

best classification accuracies focus categories instruments 
experiments confusion matrices indicated ability distinguish vocal pieces pieces focus depicted 
interestingly descriptor set represented cases cases learning algorithm naive bayes produced classification accuracies baseline cases 
focus nb set mpeg focus nb descriptors voc bth nst voc bth nst voc bth nst voc bth nst voc bth nst focus nn ap fig 

confusion matrices focus classes voc vocal bth nst instrumental row gives percentages pieces belonging true category classified predicted categories 
true categories denoted left predicted categories bottom 
left naive bayes classification set mpeg set consisting implemented descriptors comparison right shows confusion matrix best method achieved highest accuracy 
outcome explained fact dedicated vocal feature presumably dedicated vocal detection algorithm proposed yield better results especially discrimination instrumental pieces pieces contain instruments 

complexity complexity classification results similar focus categorization experiments baseline reached highest accuracies summarized table somewhat baseline 
complexity classification results baseline set mpeg large set best tab 

best classification accuracies complexity categories low medium high 
confusion matrices confirm impression poor performance pieces belonged frequent complexity class medium correctly classified high accuracy easily achieved guessing frequent class 
experiments pieces voc bth nst low high complexity misclassified correctly classified indications class separability abilities 
notion complexity probably ill defined acquired machine learning algorithm 

perceived tempo tempo classification accuracies picture appears table cases baseline reached best accuracies higher baseline 
perceived tempo classification results baseline set mpeg large set best tab 

best classification accuracies perceived tempo categories slow slow medium fast fast varying 
confusion matrices indicate frequent class clearly discriminated classes respective attribute set learning algorithm combination 
confusion matrices show dark row position frequent class depicted 
set containing implemented descriptors naive bayes able classify pieces slow fast varying perceived tempo accurately learning algorithms 
pieces slow medium fast confused varying perceived tempo 
vsl sl med fst vfs var vsl tempo nb descriptors sl med fst vfs var vsl sl med fst vfs var vsl tempo nb set tc fig 

confusion matrices naive bayes classification tempo classes vsl slow sl slow med medium fst fast vfs fast var varying set consisting descriptors set 
descriptors contained set confusion matrix confusions appearing sl med fst vfs var frequently neighboring classes varying class 
perceived tempo depends complicated combination aspects ground beat slow perceived tempo high instrument plays quick melody depend groove 

emotion table seen best accuracies emotion categorization achieved method 
descriptor set learning algorithm combinations accuracies baseline cases highest accuracies achieved clearly accuracies method 
emotion classification results baseline set mpeg large set best tab 

best classification accuracies emotion categories soft neutral aggressive 
main difference method algorithms method primarily aims modeling timbral similarity methods incorporate concepts meant describe aspects music melodic harmonic content 
results suggest high correlation emotion categories soft neutral aggressive timbre 
addition low correlation aspects music harmony melody rhythm categories supposed different interpretations piece soft aggressive 

mood table seen examined descriptor sets suited distinguishing happy neutral sad songs 
confusion matrices show black row indicating lack class separation ability deviate appearance confusion matrices naive bayes classifications 
indicate possible distinguish sad happy songs extent 
set set mpeg feature selection interesting case 
mood classification results baseline set mpeg large set best tab 

best classification accuracies mood categories happy neutral sad 
hap neu sad mood nb set tc hap neu sad hap neu sad mood nb set mpeg fig 

confusion matrices naive bayes classification mood classes hap happy neu neutral sad sad set mpeg set 
presumably categorization happy neutral sad pieces subtle recognized algorithm 

genre best genre classification accuracies descriptor set table 
results difficult compare literature databases different consideration unequally distributed classes high baseline reasonable 
hap genre classification results baseline set mpeg large set best tab 

best classification accuracies genre categories 
neu sad 
important observations results hardly baseline feature set learning algorithm combinations examined categorizations 
cases best accuracy values obtained proposed algorithm better best accuracy values obtained feature sets 
examined categorizations algorithms generally best genre categorization categorization frequently literature 
exception proposed algorithm worked comparably emotion categorization 
detail individual categorizations got results indication commonly audio features useful classification pieces complexity classes 
focus perceived tempo mood categorizations classification accuracies baseline 
confusion matrices indicate examined features capture aspects categorizations 
preliminary experiments point emotion class soft neutral aggressive predominantly correlated timbre suggesting improvement timbre similarity measures improve classification accuracies categorization 
number possible explanations results 
mentioned training data inconsistently labeled categorizations ill defined depend current mood listener 
features capture temporal aspects pieces features describe short time properties music 
change time important music time independence features play role 
generally acoustic aspect side music 
important acoustical events combined meaning semantic part music 
part socio cultural aspects important inferred audio signal 
results confirm negative results mention probable existence glass ceiling upper bound performance audio similarity classification algorithms 
development dedicated features attributes categories discussed contribute research improved music audio features enable get closer upper bound 
generally results give indication holistic algorithm view music necessary acquire information pieces sources audio description techniques extra musical information may important includes cultural aspects usage patterns listening habits course lyrics musical pieces 
quite research currently going automatic extraction cultural meta data music web combining information audio features effective way challenge 

acknowledgments research funded eu fp project semantic interaction music audio contents austrian fonds zur der wissenschaftlichen forschung 
start 
austrian research institute artificial intelligence acknowledges financial support austrian federal education science culture transport innovation technology 

iso iec information technology mpeg multimedia content description interface part audio 

aucouturier pachet 
music similarity measures 
editor proceedings rd international symposium music information retrieval paris france october 

aucouturier pachet 
improving timbre similarity high sky 
journal negative results speech audio sciences 
baumann shankar 
socio cultural compatibility mir systems 
proceedings international symposium music information retrieval ismir barcelona spain october 
ellis lawrence 
voice segments improve artist classification music 
aes nd international conference espoo finland june 


phd thesis university british columbia february 
richard david 
efficient musical instrument recognition solo performance music basic features 
proceedings aes th international conference london uk june 
gouyon dixon pampalk widmer 
evaluating rhythmic descriptors musical genre classification 
proceedings aes th international conference london uk june 
gouyon herrera cano 
pulse dependent percussive music 
proceedings aes nd international conference virtual synthetic entertainment audio st petersburg russia june 
lefebvre 
music genre estimation low level audio features 
proceedings aes th international conference london uk june 
kim whitman 
singer identification popular music recordings voice coding features 
proceedings international symposium music information retrieval ismir paris france october 
knees pampalk widmer 
artist classification web data 
proceedings international symposium music information retrieval ismir barcelona spain october 
li sethi mcgee 
classification general audio data content retrieval 
pattern recogn 
lett 
li ogihara 
detecting emotion music 
proceedings international symposium music information retrieval ismir baltimore md usa october 
liu lu 
zhang 
automatic mood detection acoustic music data 
proceedings international symposium music information retrieval ismir baltimore md usa october 

ong herrera 
computing structural descriptions music identification representative excerpts audio files 
proceedings aes th international conference london uk june 
pachet 
automatic extraction music descriptors acoustic signals 
proceedings international symposium music information retrieval ismir 
pampalk 
matlab toolbox compute music similarity audio 
proceedings fifth international conference music information retrieval ismir barcelona spain october 

explorative hierarchical user interface structured music repositories 
master thesis vienna university technology institut kybernetik und artificial intelligence der universit wien 
herrera 
describing perceived complexity songs computational methods implementation 
proceedings aes th international conference london uk june 
tzanetakis cook 
musical genre classification audio signals 
ieee transactions speech audio processing 
whitman lawrence 
inferring descriptions similarity music community metadata 
proc intl computer music conf 
whitman roy 
learning word meanings descriptive parameter spaces music 
proceedings hlt naacl workshop learning word meaning non linguistic data pages edmonton canada 
whitman 
combining musical cultural features intelligent style detection 
proc ismir 
witten frank 
data mining practical machine learning tools java implementations 
morgan kaufmann san francisco 
xu shao tian 
musical genre classification support vector machines 
proceedings ieee icassp hong kong china april 
