appear proceedings tenth acm sigkdd international conference knowledge discovery data mining kdd seattle wa august 
probabilistic framework semi supervised clustering basu dept computer sciences university texas austin austin tx cs utexas edu unsupervised clustering significantly improved supervision form pairwise constraints pairs instances labeled belonging different clusters 
years number algorithms proposed enhancing clustering quality employing supervision 
methods constraints modify objective function learn distance measure 
propose probabilistic model semisupervised clustering hidden markov random fields provides principled framework incorporating supervision prototype clustering 
model generalizes previous approach combines constraints euclidean distance learning allows broad range clustering distortion measures including bregman divergences euclidean distance divergence directional similarity measures cosine similarity 
algorithm performs partitional semi supervised clustering data minimizing objective function derived posterior energy hmrf model 
experimental results text data sets demonstrate advantages proposed framework 

large amounts unlabeled data available real life data mining tasks messages automatic email classification system genes unknown functions doing gene function prediction labeled data limited expensive generate labeling typically requires human expertise 
consequently semi supervised learning uses labeled unlabeled data topic significant interest 
focus semi supervised clustering performance unsupervised clustering algorithms improved limited amounts supervision form labels data constraints :10.1.1.11.5360:10.1.1.20.7363
existing methods semi supervised clustering fall general categories call constraint 
constraint methods rely user provided labels constraints guide algorithm appropriate data partitioning 
done modifying objective function permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
copyright acm xxxxx xx xx xx 
mikhail bilenko dept computer sciences university texas austin austin tx cs utexas edu raymond mooney dept computer sciences university texas austin austin tx mooney cs utexas edu evaluating clusterings includes satisfying constraints enforcing constraints clustering process initializing constraining clustering labeled examples :10.1.1.20.7363
distance approaches existing clustering algorithm uses particular clustering distortion measure employed trained satisfy labels constraints supervised data 
adaptive distance measures semisupervised clustering including string edit distance trained expectation maximization em kl divergence trained gradient descent euclidean distance modified shortestpath algorithm mahalanobis distances trained convex optimization :10.1.1.11.5360:10.1.1.58.3667
propose principled probabilistic framework hidden markov random fields semi supervised clustering combines constraint distance approaches unified model 
motivate objective function semi supervised clustering derived posterior energy hmrf framework propose em partitional clustering algorithm hmrf kmeans find local minimum objective function 
previously proposed unified approach semi supervised clustering experimentally shown produce accurate clusters methods data sets :10.1.1.138.1114
approach restricted euclidean distance clustering distortion measure 
show generalize model handle non euclidean measures 
generalization utilize bregman divergence includes wide variety useful distances kl divergence 
number applications text clustering vector space model directional similarity measure angle vectors appropriate 
consequently clustering algorithms utilize distortion measures appropriate directional data developed :10.1.1.140.2184:10.1.1.38.4937
unified semi supervised clustering framework applicable directional similarity measures 
summarize proposed approach aids unsupervised clustering incorporating labeled data ways improved initialization initial cluster centroids estimated neighborhoods induced constraints constraint sensitive assignment instances clusters points assigned clusters distortion points cluster centroids minimized minimum number link link constraints violated iterative distance learning distortion measure re estimated clustering warp space respect user specified constraints incorporate data variance 
experimental results clustering text documents demonstrate advantages approach 

background motivation framework focus partitional prototype clustering underlying unsupervised clustering model set data points partitioned pre specified number clusters cluster having representative prototype defined cost function involving distortion measure points cluster representatives minimized 
popular clustering algorithm category means 
earlier research semi supervised clustering considered supervision form labeled points constraints :10.1.1.7.8086
considering model supervision provided form link link constraints indicating respectively pair points put cluster 
pairwise constraint model assigns associated cost violating constraint 
considering supervision form constraints realistic requiring class labels unsupervised learning applications clustering speaker identification conversation clustering gps data lane finding class labels may unknown user specify pairs points belong different clusters :10.1.1.7.8086:10.1.1.20.7363
constraint supervision general class labels set classified points implies equivalent set pairwise constraints vice versa 
semi supervised clustering model considers set data points specified distortion measure points 
supervision provided set link constraints set associated violation costs set link constraints associated violation costs 
task partition data clusters total distortion points corresponding cluster representatives measure minimized minimum number constraints violated 
restrict attention hard clustering point assigned single cluster model 
word notation terminology boldface variables represent vectors calligraphic upper case refer sets representatives enumerated xi denotes objective function xim represents mth component dimensional vector xi 
term distance measure synonymously distortion measure 
hidden markov random field incorporate pairwise constraints underlying distortion measure points unified probabilistic model consider hidden markov random fields 
hmrf components hidden field li random variables values unobservable 
clustering framework set hidden variables unobserved cluster labels points indicating cluster assignments 
hidden variable li takes values set indices clusters 
observable set xi random variables random variable xi generated conditional probability distribution pr xi li determined corresponding hidden variable li 
random variables conditionally independent hidden variables pr xi pr xi li 
framework set observable variables hmrf corresponds data points 
observed data hidden mrf hidden markov random field fig 
shows simple example hmrf 
observed dataset consists points 
corresponding cluster labels 

link constraints provided link constraint provided 
task partition points clusters 
clustering configuration shown fig 

linked points put cluster point linked assigned cluster involved constraints put clusters respectively 
hidden random variable li associated set neighbors link constraints link constraints define neighborhood hidden labels neighbors point xi points linked 
random field defined hidden variables markov random field probability distribution hidden variables obeys markov property pr li li pr li probability distribution value li data point xi depends cluster labels points linked linked xi 
consider particular cluster label configuration joint event li hammersley clifford theorem probability label configuration expressed gibbs distribution pr exp exp vn set neighborhoods normalizing constant label configuration potential function decomposed functions vn denoting potential neighborhood label configuration provided pairwise constraints class labels restrict mrfs hidden variable pairwise potentials 
prior probability configuration cluster labels pr exp fm xi xj xi xj fc xi xj xi xj fm xi xj non negative function penalizes violation link constraint fc xi xj corresponding penalty function links 
note third condition definition necessary points involved constraints 
intuitively form pr gives higher probabilities label configurations satisfy link constraints link constraints discouraging violation user specified constraints 
map estimation particular configuration hidden variables unknown cluster labels variables observable field hmrf data points generated specified conditional probability distributions 
conditional probability observation set xi configuration li pr clustering framework form pr probability density function parameterized cluster representatives function related clustering distortion measure show section 
posterior probability cluster label configuration pr pr pr considering pr constant finding maximum posteriori map configuration hmrf equivalent maximizing posterior probability pr exp cz 
negative logarithm pr known posterior energy 
note map estimation reduce maximum likelihood ml estimation pr pr constant 
model accounts dependencies cluster labels pr constant full map estimation pr required 
cluster representatives cluster labels points unknown clustering setting maximizing eqn incomplete data problem popular solution method expectation maximization em 
known means equivalent em algorithm hard clustering assignments :10.1.1.48.3989
section describes means type hard partitional clustering algorithm hmrf kmeans finds local maximum function 
posterior probability pr eqn components factor evaluates label configuration corresponding cluster assignments point gives higher probability configuration satisfies link link constraints 
particular label configuration determines cluster assignments cluster representatives 
second factor estimates probability generating observed data points conditional distributions parameterized cluster representatives depend distortion measure 
posterior probability cluster label configuration points takes account cluster distortion measure constraints principled unified framework 
clustering objective function eqn suggests general framework incorporating constraints clustering 
particular choices constraint penalty functions fm fc conditional probabilities motivated distortion measure appropriate clustering task 
considering second term eqn restrict attention probability densities exponential form exp xi li xi xi li distortion xi li normalization constant 
different clustering models fall exponential form xi li vectors square norm cluster conditional probability unit variance gaussian xi li probability distributions kl divergence cluster conditional probability multinomial distribution xi li vectors unit length norm minus dot product cluster conditional probability von mises fisher vmf distribution unit concentration parameter essentially spherical analog unit variance gaussian :10.1.1.140.2184:10.1.1.48.3989
discuss connection specific distortion measures study corresponding cluster conditional probabilities detail section 
examine potential function term eqn 
previous linked points considered neighborhood markov random field generalized potts potential function 
potential func tion link penalty fm xi xj wi li wi cost violating link constraint indicator function true false 
function specifies cost violating link constraint xi xj wi irrespective distance xi semi supervised clustering framework want constraint violations learn underlying distance measure penalty violating link constraint distant points higher nearby points 
reflect fact linked points far apart current distortion measure put different clusters measure inadequate needs modified bring points closer 
link penalty function chosen fm xi xj wi xi xj li penalty scaling function choose monotonically increasing function distance xi current distortion measure 
specific penalty functions different distortion measures described section 
analogously penalty violating link constraint points nearby current distance measure higher distant points 
encourage distance learning step put linked points farther apart 
link penalty function accordingly chosen fc xi xj wi dmax xi xj li dmax maximum value scaling function dataset 
form fc ensures penalty violating link constraint remains non negative second term greater 
note fm fc penalty functions mrf hidden variables non isotropic values potential pairs random variables field non uniform model valid hmrf 
putting eqn logarithms gives cluster objective function minimizing equivalent maximizing map probability eqn equivalently minimizing posterior energy hmrf xi xi li xi wi xi xj li xi wi dmax xi xj li logz 
task minimize parameterized 

algorithm adaptive distortion measures choice distortion measure particular clustering problem depends properties domain consideration 
number popular distortion measures including euclidean distance kullback leibler divergence belong general family functions known bregman divergences 
popular class distortion measures includes directional similarity functions normalized dot product cosine similarity pearson correlation 
selection appropriate distortion measure clustering task take account intrinsic properties dataset 
example euclidean distance appropriate low dimensional data distribution close normal distribution normalized dot product best captures similarity directional data differences angles vectors important vector lengths 
bregman divergences directional similarity measures cosine similarity shown exist efficient means type iterative relocation algorithms minimize corresponding clustering cost functions 
realistic datasets shelf distortion measures may fail capture correct notion similarity clustering setting 
unsupervised measures mahalanobis distance pearson correlation attempt correct similarity estimates global mean variance dataset 
measures may fail estimate distances accurately attributes true contribution similarity correlated variance 
semi supervised clustering approaches proposed incorporate adaptive similarity functions including parameterization jensen shannon divergence euclidean distance :10.1.1.7.8086
initial shown euclidean distance parameterized learned principled manner semi supervised clustering setting :10.1.1.138.1114
turn popular distortion measures cosine similarity kullback leibler divergence describe adaptive versions distortion measures hmrf framework 
parameterized cosine similarity cosine similarity parameterized symmetric matrix leads distortion measure xi xj xt ax xi weighted norm ax 
parameterization equivalent projecting instance space spanned cosine similarity natural measure prototype clustering assumption data generated mixture von mises fisher vmf distributions xi xj thought distortion measure data generated mixture vmf distributions projected space :10.1.1.140.2184
realistic high dimensional domains computing full matrix extremely expensive computationally focus attention diagonal equivalent vector weights diag 
referring cosine measure eqn xi xj 
xi xj distortion measure clustering framework described section penalty scaling function xi xj xi xj leads objective function xi li xi wi xi xi xj li wi max xi xi xj li logz max 
parameterized divergence certain domains data described probability distributions text documents represented probability distributions words generated multinomial model 
kl divergence widely distance measure data dkl xi xj xim log xim jm xi probability distributions events xim jm 
previous cohn parameterized kl divergence multiplying th component weight kl xi xj log xim shown jm parameterization kl longer bregman divergence probability distributions undesirable convergence longer guaranteed algorithm described 
kl divergence employ related measure divergence belongs class bregman divergences 
divergence form di xi xj xim log xim jm xim jm xi longer need probability distributions non negative vectors 
probability distributions divergence kl divergence equivalent 
parameterize divergence vector non negative weights dia xi xj log xim am xim jm jm parameterization thought scaling attribute original space weight contained corresponding component divergence transformed space 
implies dia bregman divergence respect transformed space 
clustering framework described section requires define appropriate penalty scaling function xi xj hmrf potential functions described eqns 
consider unordered constraint pairs xi xj symmetric penalize constraints appropriately 
meet requirement sum weighted divergences xi mean vector xi divergence mean dima analogous jensen shannon divergence symmetric kl divergence mean defined follows xi xj dima xi xj xim jm am xim log jm log xim jm xim jm formulation leads objective function wi xi xj li xi wi dima max dima xi xi xj li logz jia dia xi xi li parameterized distortion measures dima underlying generative models weighted cosine corresponds von mises fisher vmf distribution projected space divergence corresponds multinomial distributions rescaled probabilities 
pr eqn defined underlying hmrf model cases minimizing objective functions jia leads maximizing pr corresponding underlying models 
em framework discussed section minimized means type iterative algorithm hmrf kmeans 
outline algorithm fig 

basic idea hmrf kmeans follows step current cluster representatives data point re assigned cluster minimizes contribution 
step cluster representatives re estimated cluster assignments minimize current assignment 
clustering distortion measure updated step reduce objective function simultaneously transforming space data lies 
note corresponds generalized em algorithm objective function reduced necessarily minimized step 
effectively step minimizes cluster assignments step minimizes cluster representatives step minimizes parameters distortion measure step repeated till specified convergence criterion reached 
specific details step step discussed sections 
algorithm hmrf kmeans input set data points xi number clusters set link constraints xi xj set link constraints xi xj distance measure constraint violation costs output disjoint partitioning xh objective function eqn locally minimized 
method 
initialize clusters centroids set 
repeat convergence 
step re assign cluster labels points xi minimize 

step cluster labels re calculate cluster centroids minimize 

step re estimate distance measure reduce 

hmrf kmeans algorithm note calculating normalizing constant eqn computationally intensive distortion measures cosine similarity corresponds computing bessel function :10.1.1.140.2184
approximation considering logz constant clustering iterations drop term eqn 
initialization initial centroids essential success partitional clustering algorithms means 
previous shown limited supervision form labeled points results initial centroids partitional clustering 
case supervision provided pairwise constraints labeled points 
follow motivation inferring initial centroids constraints 
try utilize constraints unlabeled data initialization 
follow stage initialization process 
neighborhood inference transitive closure link constraints get connected components consisting points connected links 
connected components create neighborhoods define link neighborhoods mrf hidden cluster variables 
assuming consistency constraints infer additional constraints neighborhoods 
augment set link constraints inferred transitive closure initial set 
pair neighborhoods link add link constraints pair points augment link set entailed constraints 
step corresponds inferring information possible neighborhood structure hidden mrf assumption consistency constraints 
point onwards overload notation refer augmented link link sets respectively 
note know set constraints noisy implying constraints consistent add additional inferred constraints constraints provided initially 
cluster selection stage produces neighborhood sets neighborhoods initial clusters hmrf means algorithm 
cluster centers initialized centroids neighborhood sets 
clusters initialized neighborhoods remaining clusters initialized points obtained random perturbations global centroid neighborhoods selected initial clusters clustering distortion measure 
farthest traversal heuristic initialization prototype partitional clustering algorithms 
goal farthest traversal find points maximally separated terms distance function 
case apply weighted variant farthest traversal centroids neighborhoods weight centroid proportional size corresponding neighborhood 
consider weighted distance centroids distance distortion measure multiplied weights centroids 
weighted farthest biased select centroids relatively far apart large size 
weighted farthest selection algorithm maintains set centroids visited far 
centroid largest neighborhood selected starting point added visited set 
point algorithm unvisited centroid farthest weighted distance smallest weighted similarity visited set chosen 
tie resolved selecting centroid farthest global centroid data 
point added visited set process continued till centroids visited 
neighborhood centroids chosen weighted farthest traversal set initial cluster centroids hmrf kmeans 
stage initialization procedure able take account unlabeled labeled data obtain cluster representatives provide initial partitioning dataset 
step step assignments data points clusters updated current estimates cluster representatives 
simple means interaction cluster labels step simple assignment point cluster representative nearest clustering distortion measure 
contrast hmrf model incorporates interaction cluster labels defined random field hidden variables 
result computing assignment data points cluster representatives minimize objective function computationally intractable non trivial hmrf model 
exist techniques computing cluster assignments approximate optimal solution framework iterated conditional modes icm belief propagation linear programming relaxation 
follow icm approach greedy strategy sequentially update cluster assignment point keeping assignments points fixed 
algorithm performs cluster assignments random order points 
point xi assigned cluster representative minimizes point contribution objective function job xi xi xi wi xi xj xi xi wi dmax xi xj optimal assignment point minimizes distortion point cluster representative term incurring minimal penalty constraint violations caused assignment second third terms 
points assigned randomly re ordered assignment process repeated 
process proceeds point changes cluster assignment successive iterations 
icm guaranteed reduce keep unchanged local minimum step 
assignment points clusters incorporates pairwise supervision discouraging constraint violations proportionally severity guides algorithm desirable partitioning data 
step step algorithm consists parts 
cluster representatives re estimated points currently assigned decrease objective function eqn 
shown bregman divergences cluster representative calculated step em algorithm equivalent expectation value points cluster essentially arithmetic mean 
additionally experimentally demonstrated distribution clustering smoothing cluster representatives prior deterministic annealing schedule leads considerable improvements 
smoothing controlled parameter cluster representative estimated follows dia distortion measure ia xi xh xi xh directional measures cluster representative arithmetic mean projected unit sphere :10.1.1.140.2184
weighting account centroids estimated follows distortion measure cosa xi xh xi xi xh xi constraints take part cluster representative reestimation step remains means bregman divergences spkmeans weighted cosine similarity 
second parameterized variant distortion measure dia shown distortion measure parameters updated decrease objective function 
certain distance measure parameterizations minimization partial derivatives solving parameter values may feasible euclidean distance :10.1.1.138.1114
general closed form solution may unattainable 
cases gradient descent provides alternative avenue learning distortion measure weights 
distortion measures described dia weight am updated update rule am am am xi li am xi am xi wi xi wi xi xj li am dmax am xi xj am li particular distortion measures considering dia gradients xi am xi xj am jm xi xt ax im jm xi xi xi dia xi xj xim log am xim xim jm jm intuitively distance learning step results modifying distortion measure similar data points brought closer dissimilar points pulled apart 
process leads transformed data space facilitates partitioning unlabeled data respects supervised constraints provided user reflects natural variance data 

experiments datasets clustering sparse high dimensional data text documents represented vector space model particularly mutual information kmeans kmeans kmeans kmeans number constraints clustering results news different dataset difficult cluster small datasets 
due fact clustering algorithms easily get stuck local optima datasets leads poor clustering quality 
previous studies sp kmeans algorithm applied document collections size small compared dimensionality word space observed little relocation documents clusters initializations leads poor clustering quality convergence algorithm 
scenario realistic applications 
example clustering search results web search engine viv simo typically number webpages clustered order hundreds 
dimensionality feature space corresponding number unique words webpages order thousands 
webpage sparse contains small number possible words 
supervision form pairwise constraints beneficial cases may significantly improve clustering quality 
demonstrate effectiveness semi supervised clustering framework consider data sets characteristics sparse high dimensional having small number points compared dimensionality space 
derived datasets newsgroups collection 
collection messages harvested different usenet newsgroups messages newsgroup 
original dataset reduced dataset created random subsample documents newsgroups 
datasets created selecting categories reduced collection 
news similar consists newsgroups similar topics comp graphics comp os ms windows comp windows significant overlap clusters due cross posting 
news related consists newsgroups related topics talk politics misc talk politics guns politics mideast 
news different consists articles posted newsgroups cover different topics alt atheism rec sport baseball sci 
space separated clusters 
vector space model news similar points dimensions news related points dimensions news different points dimensions 
overlap topics news similar news related significant challenging datasets news different 
datasets pre processed word removal tf www vivisimo com www ai mit edu people newsgroups mutual information kmeans kmeans kmeans kmeans number constraints clustering results dia news different dataset idf weighting removal high frequency low frequency words methodology dhillon 
clustering evaluation normalized mutual information nmi clustering evaluation measure 
nmi external clustering validation metric estimates quality clustering respect underlying class labeling data measures closely clustering algorithm reconstruct underlying label distribution data 
random variable denoting cluster assignments points random variable denoting underlying class labels points nmi measure defined nmi mutual information random variables shannon entropy conditional entropy :10.1.1.140.2184
nmi effectively measures amount statistical information shared random variables representing cluster assignments user labeled class assignments data points 
methodology generated learning curves runs fold cross validation dataset 
studying effect constraints clustering dataset set aside test set particular fold 
different points learning curve correspond constraints input semi supervised clustering algorithm 
constraints obtained training set corresponding remaining data randomly selecting pairs points training set creating link link constraints depending underlying classes points different 
unit constraint costs constraints original inferred datasets provide individual weights constraints 
pilot studies gradient step size chosen values clustering clustering dia weights restricted non negative 
realistic setting parameters tuned cross validation hold set 
clustering algorithm run dataset nmi calculated test set 
learning curve results averaged runs 
mutual information kmeans kmeans kmeans kmeans number constraints clustering results news related dataset mutual information kmeans kmeans kmeans kmeans number constraints clustering results news similar dataset results discussion compared proposed hmrf kmeans algorithm unsupervised means clustering 
variants compared distortion measures dia representatives bregman divergences directional measures respectively kmeans complete hmrf kmeans algorithm includes supervised data initialization described section incorporates constraints cluster assignments described section performs distance learning described section kmeans ablation hmrf kmeans uses pairwise supervision initialization cluster assignments perform distance learning kmeans ablation uses constraints initialize cluster representatives kmeans unsupervised means algorithm 
figs 
demonstrate results experiments weighted cosine similarity distortion measure figs 
summarize experiments weighted divergence dia 
mutual information kmeans kmeans kmeans kmeans number constraints clustering results dia news related dataset mutual information kmeans kmeans kmeans kmeans number constraints clustering results dia news similar dataset results demonstrate full hmrf kmeans algorithm outperforms unsupervised means baseline versions hmrf kmeans dia relative performance kmeans kmeans indicates supervision initializing cluster representatives highly beneficial constraint sensitive cluster assignment step lead significant additional improvements dia kmeans outperforms kmeans news different fig 
news similar fig 
indicates incorporating constraints cluster assignment process useful datasets 
result reversed news related fig 
implying cases constraints step may unnecessary agrees previous results domains 
incorporating supervised data stages algorithm kmeans initialization cluster assignment distance update leads substantial performance improvement 
seen results pairwise constraints figs 
distance learning beneficial absence pairwise constraints able capture relative importance different attributes unsupervised data 
absence supervised data constraints violated distance learning attempts minimize objective function adjusting weights distortion unsupervised datapoints corresponding cluster representatives 
realistic application domains supervision form const cases provided human experts case important semi supervised clustering algorithm performs small number constrains 
kmeans starts outperforming variants unsupervised clustering baseline early learning curve appropriate algorithm actual semi supervised data clustering systems 
results show hmrf kmeans algorithm effectively incorporates labeled unlabeled data stages improves clustering quality 

related related unified model semi supervised clustering constraints proposed segal 
model unified markov network combines binary markov network derived pairwise protein interaction data naive bayes markov network modeling gene expression data 
proposed hmrf framework general formulation works broad class clustering distortion measures including bregman divergences directional similarity measures 
contrast formulation segal considers gaussian cluster conditional probability distribution corresponds having mahalanobis distance underlying clustering distance measure 
additionally hmrf kmeans algorithm performs distance learning unified framework done markov network model 
hmrf kmeans algorithm proposed related em algorithm hmrf model fitting proposed zhang 
hmrf kmeans performs additional step distance learning step considered hmrf em algorithm 
discussion hmrf em algorithm restricted gaussian conditional distributions generalized formulation 
research semi supervised clustering focusing individually constraint distance semisupervised clustering 
cop kmeans constraint clustering algorithm heuristically motivated objective function :10.1.1.20.7363
method hand underlying probabilistic model hidden markov random fields 
bansal proposed framework pairwise constrained clustering model performs clustering constraints formulation uses constraints underlying distortion measure points 
distance semi supervised clustering pairwise constraints cohn gradient descent weighted jensen shannon divergence context em clustering 
xing utilized combination gradient descent iterative projections learn mahalanobis distance means clustering :10.1.1.58.3667
redundant component analysis rca algorithm link constraints learn mahalanobis distance convex optimization :10.1.1.7.8086
spectral learning method utilizes supervision transform clustering distance measure spectral methods 
distance learning techniques clustering train distance measure supervised data perform clustering unsupervised data 
contrast method integrates distance learning clustering process utilizes supervised unsupervised data learn distortion measure 

general probabilistic framework incorporating pairwise supervision prototype clustering gorithm instantiations framework particular distortion measures 
open issues interesting explore 
investigating alternative approaches training distortion measures step algorithm may lead improved performance algorithm 
initial results distance learning clustering suggest transforming data space highly beneficial clustering quality 
conjecture developing alternative feature selection feature extraction approaches perform types data space transformation supervised data promising direction 
weighted farthest algorithm cluster initialization described section proven useful 
intend explore theoretical implications initialization algorithm hmrf model develop alternative techniques utilize labeled unlabeled data initializing cluster representatives 
icm algorithm constraint sensitive cluster assignment hmrf model methods proposed task loopy belief propagation 
extensive experimental comparison strategies informative iterative reassignment algorithms hmrf kmeans hmrf framework 
want run experiments study sensitivity hmrf kmeans algorithm constraint violation parameters done segal 
want apply algorithm application domains 
interesting problem bioinformatics improve quality clustering genes unknown functions utilizing constraints genes derived domain knowledge 
segal constraints derived protein protein interactions clustering gene expression data mahalanobis distance underlying distortion measure 
want apply hmrf kmeans algorithm different kinds gene representations different clustering distance measures appropriate pearson correlation appropriate distortion measure gene microarray data divergence useful phylogenetic profile representation genes plan run experiments clustering datasets hmrf kmeans algorithm constraints inferred protein interaction databases function pathway labels known subset genes 

introduced theoretically motivated framework semisupervised clustering employs hidden random markov fields utilize labeled unlabeled data clustering process 
framework number distortion measures including bregman divergences directional measures accommodates trainable measures adapted specific datasets 
introduced hmrf kmeans algorithm performs clustering framework incorporates supervision form pairwise constraints stages clustering algorithm initialization cluster assignment parameter estimation 
instantiations algorithm particular distortion measures popular high dimensional data kl divergence cosine similarity 
experimental evaluation shown algorithm derived hmrf framework leads improved cluster quality realistic textual datasets unsupervised clustering proposed approach 

acknowledgments insightful comments 
research supported national science foundation iis itr iis faculty fellowship ibm 

baeza yates ribeiro neto 
modern information retrieval 
acm press new york 
banerjee dhillon ghosh sra :10.1.1.140.2184
generative model clustering directional data 
proceedings ninth acm sigkdd international conference knowledge discovery data mining kdd pages 
banerjee dhillon ghosh 
clustering bregman divergences 
proceedings siam international conference data mining sdm 
bansal blum chawla 
correlation clustering 
proceedings rd ieee symposium foundations computer science focs pages 
bar hillel hertz weinshall :10.1.1.7.8086
learning distance functions equivalence relations 
proceedings th international conference machine learning icml pages 
basu banerjee mooney 
semi supervised clustering seeding 
proceedings th international conference machine learning icml pages 
basu banerjee mooney 
active semi supervision pairwise constrained clustering 
proceedings siam international conference data mining sdm 
basu bilenko mooney :10.1.1.138.1114
comparing unifying search similarity approaches semi supervised clustering 
proceedings icml workshop continuum labeled unlabeled data machine learning data mining pages 
besag 
statistical analysis dirty pictures 
journal royal statistical society series methodological 
bilenko mooney 
adaptive duplicate detection learnable string similarity measures 
proceedings ninth acm sigkdd international conference knowledge discovery data mining kdd pages 
blum mitchell 
combining labeled unlabeled data training 
proceedings th annual conference computational learning theory pages 
boykov veksler zabih 
markov random fields efficient approximations 
proceedings ieee computer vision pattern recognition conference cvpr pages 
cohn caruana mccallum 
semi supervised clustering user feedback 
technical report tr cornell university 
cover thomas 
elements information theory 
wiley interscience 
demiriz bennett embrechts 
semi supervised clustering genetic algorithms 
artificial neural networks engineering annie pages 
dempster laird rubin 
maximum likelihood incomplete data em algorithm 
journal royal statistical society 
dhillon guan 
information theoretic clustering sparse occurrence data 
proceedings third ieee international conference data mining icdm pages 
dhillon modha 
concept decompositions large sparse text data clustering 
machine learning 
dom 
information theoretic external cluster validity measure 
research report rj ibm 
eisen spellman brown botstein 
cluster analysis display genome wide expression patterns 
proceedings national academy sciences usa 
geman geman 
stochastic relaxation gibbs distributions bayesian restoration images 
ieee transactions pattern analysis machine intelligence 
hammersley clifford 
markov fields finite graphs lattices 
unpublished manuscript 
hochbaum shmoys 
best possible heuristic center problem 
mathematics operations research 
joachims 
transductive inference text classification support vector machines 
proceedings sixteenth international conference machine learning icml pages 
kamvar klein manning 
spectral learning 
proceedings seventeenth international joint conference artificial intelligence ijcai pages 
kearns mansour ng :10.1.1.48.3989
information theoretic analysis hard soft assignment methods clustering 
proceedings th conference uncertainty artificial intelligence uai pages 
klein kamvar manning :10.1.1.11.5360
instance level constraints space level constraints making prior knowledge data clustering 
proceedings nineteenth international conference machine learning icml pages 
kleinberg tardos 
approximation algorithms classification problems pairwise relationships metric labeling markov random fields 
proceedings th ieee symposium foundations computer science focs pages 
macqueen 
methods classification analysis multivariate observations 
proceedings th berkeley symposium mathematical statistics probability pages 
marcotte van der eisenberg 
localizing proteins cell phylogenetic profiles 
proceedings national academy science 
mardia 
directional statistics 
john wiley sons nd edition 
neal hinton 
view em algorithm justifies incremental sparse variants 
jordan editor learning graphical models pages 
mit press 
nigam mccallum thrun mitchell 
text classification labeled unlabeled documents em 
machine learning 
pearl 
probabilistic reasoning intelligent systems networks plausible inference 
morgan kaufmann san mateo ca 
pereira tishby lee 
distributional clustering english words 
proceedings st annual meeting association computational linguistics acl pages 
segal wang koller 
discovering molecular pathways protein interaction gene expression data 
bioinformatics july 
strehl ghosh mooney 
impact similarity measures web page clustering 
workshop artificial intelligence web search aaai pages july 
wagstaff cardie rogers :10.1.1.20.7363
constrained means clustering background knowledge 
proceedings th international conference machine learning icml pages 
xing ng jordan russell :10.1.1.58.3667
distance metric learning application clustering side information 
advances neural information processing systems pages cambridge ma 
mit press 
zhang brady smith 
hidden markov random field model segmentation brain images 
ieee transactions medical imaging 
