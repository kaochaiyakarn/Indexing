context threading flexible efficient dispatch technique virtual machine interpreters marc benjamin vitale angela brown university toronto systems research lab bv cs toronto edu direct threaded interpreters indirect branches dispatch bytecodes deeply pipelined architectures rely branch prediction performance 
due poor correlation virtual program control flow hardware program counter call context problem direct threading indirect branches poorly predicted hardware limiting performance 
dispatch technique context threading improves branch prediction performance aligning hardware virtual machine state 
linear virtual instructions dispatched native calls returns aligning hardware virtual pc 
sequential control flow predicted hardware return stack 
convert virtual branching instructions native branches hardware branch prediction resources 
evaluate impact context threading branch prediction performance interpreters java ocaml pentium powerpc architectures 
pentium iv technique reduces mean mispredicted branches 
powerpc reduces mean branch stall cycles ocaml java 
due reduced branch hazards context threading reduces mean execution time java ocaml ppc respectively 
combine context threading conservative inlining technique find performance comparable selective inlining 
interpretation powerful tool implementing programming language systems 
facilitates interactive program development debugging compact portable deployment simple language prototyping 
combination features interpreted languages attractive settings applicability constrained research supported nserc ibm cas 
poor performance compared native code 
consequently important systems sun hotspot ibm production java virtual machine run mixed mode compiling executing parts program interpreting 
baseline interpreter performance continues relevant 
ertl gregg observed performance efficient direct threaded interpretation limited pipeline stalls flushes due extremely poor indirect branch prediction 
modern pipelined architectures pentium iv powerpc ppc keep pipelines full perform 
hardware branch predictors native pc exploit branches typical native code cpu workloads 
direct threaded virtual machine vm interpreters typical workloads 
branches targets unbiased unpredictable 
interpreted program virtual program counter vpc correlated control flow 
propose organize interpreter native pc correlates vpc exposing virtual control flow hardware 
introduce technique subroutine threading popular early interpreters languages forth 
leverage return address stack prediction 
implement virtual instruction subroutine ends native return instruction 
note subroutines full fledged functions sense higherlevel programming language register save restore stack frame creation 
instructions virtual program loaded interpreter translate sequence call instructions virtual instruction targets subroutines 
virtual instructions dispatched simply natively executing sequence calls 
key effectiveness simple approach dispatch time native pc perfectly correlated virtual pc 
bytecodes return address stack modern processors reliably predicts address bytecode execute 
dynamic instruction generally static instruction virtual program branches pose greater challenge virtual instructions provide limited form specialized inlining replacing indirect relative branches exposing virtual branches hardware branch predictors 
review techniques virtual instruction dispatch interpreters describe performance problems define context problem section 
discuss improving dispatch performance section 
provide relevant details implementations java virtual machine sablevm ocaml interpreter pentium iv power pc architectures section 
extensive suite benchmarks java ocaml evaluate context threading section 
contributions introduce new dispatch technique virtual machine interpreters dramatically improves branch prediction demonstrate technique depend specific language cpu architecture 
show context threading effective 
ppc eliminates mean elapsed time java benchmarks individual benchmarks running twice fast direct threading 
ocaml achieve reduction mean execution time reduction ppc benchmarks achieving respectively 
show context threading compatible inlining simple heuristic call tiny inlining 
ocaml achieve speedups relative direct threading context threading 
java perform better sablevm implementation selective inlining 
context problem interpreter executes virtual program dispatching virtual instructions sequence 
current instruction indicated virtual program counter 
virtual program consists list virtual instructions consisting opcode zero operands 
exact representation virtual program depends dispatch technique 
typical switch dispatched interpreter implemented loop fetches opcode executes switch statement opcode implemented separate case block opcode body body 
switch dispatch considerably slower start art direct threaded dispatch 
shown direct threaded interpreter represents virtual program instructions list addresses 
program bytecode created compiler push push loader mul print done direct threading table dtt inst push inst push inst mul inst print inst done vpc virtual program stack opcode implementation bodies inst goto arg vpc vpc arg goto vpc 
inst print goto vpc inst done exit 
inst mul goto vpc program inst push start goto vpc 
direct threaded vm interpreter mov eax addl jmp eax addi pentium iv assembly power pc assembly 
direct threaded dispatch address points opcode body 
refer list direct threading table dtt 
operands stored list immediately corresponding opcode address 
vpc points dtt indicate instruction executed 
note body potentially virtual instructions body 
example inst push instructions point single body 
actual dispatch instruction accomplished vpc opcode body supported gnu labels values extensions 
show assembly code corresponding dispatch statement pentium iv powerpc architectures 
executing indirect branch pentium iv speculatively dispatch instructions predicted target address 
powerpc uses different strategy indirect branches shown 
target address loaded register branch executed register address 
speculate powerpc stalls target address known instructions may scheduled load branch reduce eliminate stalls 
stalling incorrect speculation serious pipeline hazards 
perform full speed modern cpu need keep pipelines full correctly predicting branch targets 
indirect branch predictors assume destination indirect branch highly correlated address branch instruction 
observed ertl assumption usually wrong direct threaded interpreter workloads :10.1.1.134.3903
direct threaded implementation jump instruction virtual opcode imple mented 
example instances inst push 
context vpc dispatch push body results native indirect branch back start push body virtual instruction vpc inst push 
target native indirect branch context vpc determined address stored example mul opcode 
target indirect branch depends virtual context hardware pc branch causing hardware speculate incorrectly 
refer lack correlation native pc context problem 
related interpreters focused dispatch problem 
remains definitive description threaded code dispatch techniques 
divided broad classes refine dispatch alter bodies efficient simply fewer dispatches 
switch direct threading belong class subroutine threading discussed 
discuss superinstructions replication second class 
particularly interested subroutine threading replication provide context branch prediction hardware 
forth interpreters subroutine threaded dispatch 
program represented list body addresses sequence native calls bodies constructed native returns 
describes subroutine threaded forth cpu 
improves resulting code inlining small opcode bodies converts virtual branch opcodes single native branch instructions 
credits charles moore inventor forth discovering ideas earlier 
outside forth little thorough literature subroutine threading 
particular authors address problem store virtual instruction operands 
section document operands handled implementation subroutine threading 
choice optimal dispatch technique depends hardware platform dispatch highly dependent micro architectural features 
earlier hardware call return expensive subroutine threading required costly branches versus case direct threading 
rodriguez presents tradeoffs various dispatch types bit cpus 
example finds direct threading faster subroutine threading cpu jsr ret instruction require extra cycles push pop return address stack 
hand subroutine threading faster 
modern hardware cost call return lower due return branch prediction hardware cost direct threading increased due misprediction 
section demonstrate effect modern cpus 
superinstructions reduce number dispatches 
consider code add constant integer variable 
may require loading variable stack loading constant adding storing back variable 
vm designers extend virtual instruction set single superinstruction performs instructions 
technique limited virtual instruction encoding byte opcode may allow limited number instructions number desirable superinstructions grows exponentially number subsumed atomic instructions 
furthermore optimal superinstruction set may change workload 
approach uses profile feedback select create superinstructions statically interpreter compiled 
presents selective inlining 
constructs superinstructions virtual program loaded 
created relatively portable way ing native code bodies gnu labels 
technique documented earlier independent discovery inspired projects exploit selective inlining 
applied optimization ocaml reports significant speedup microbenchmarks 
discuss section technique separate supports facilitates inlining optimizations 
certain classes opcode bodies relocated body contain pc relative instructions typically excludes function calls 
selective inlining requires superinstruction starts virtual basic block ends block 
ertl dynamic superinstructions memcpy applied effect simple native compilation inlining bodies nearly virtual instruction 
ertl shows avoid virtual basic block constraints dispatch interpreter code required virtual branches un relocatable bodies 
catenation patches sparc native code implementations moved specializes operands converts virtual branches native eliminating virtual program counter 
replication creating multiple copies opcode body decreases number contexts executed increases chances successfully predicting successor 
replication implemented inlining opcode bodies reduces number dispatches average dispatch overhead 
extreme create copy instruction elimi misprediction entirely 
technique results significant code growth may may cause cache misses 
summary misprediction indirect branches direct threaded interpreter dispatch virtual instructions limits performance modern cpus context problem 
described dispatch optimization techniques 
techniques improve performance dispatch reducing number contexts body executed 
reduce number dispatches possibly zero 
dynamo system trace runtime optimization arbitrary programs 
optimizations include replacing indirect branches guarded linear control flow 
expect highly applicable threaded interpreters 
sullivan applied dynamo java vm poorly 
due context problem distinguish different runtime contexts bytecode body 
solution detect traces pc vpc tuple pc 
technique simpler accomplishes thing 
section describe address context problem directly interpreter control flow exposing virtual execution native branch prediction resources 
design implementation direct threaded interpreters known poor branch prediction properties known small cache footprint small medium sized opcode bodies 
branches cache misses major pipeline hazards retain cache behavior direct threaded interpreters improving branch behavior 
preceding section describes various techniques improving branch prediction replicating entire bodies 
effect techniques trade instruction cache size better branch prediction 
ertl claims forth small opcode bodies code growth occurs cause cache related stalls 
vitale find larger opcode bodies code growth replication induce cache misses 
believe best avoid growing code possible 
introduce new technique minimally affects code size produces dramatically fewer branch mispredictions direct threading direct threading inlining 
section motivate design terms aligning virtual machine context physical machine context outline implementation 
direct threading table opcode implementation bodies dtt ctt inst goto arg vpc vpc arg context threading table program bytecode goto vpc ctt created compiler ctt 
call inst push push ctt call inst push inst print push loader ctt call inst mul mul ctt call inst print ret print call inst done done inst done vpc exit virtual program stack inst mul 
ret 
inst push 
subroutine threaded vm interpreter understanding branches motivate design note virtual program may contain usual types control flow conditional unconditional branches indirect branches calls returns 
consider dispatch straight line virtual instructions 
direct threaded interpreters sequential virtual execution just expensive handling control transfers virtual instructions dispatched indirect branch 
second note dynamic execution path virtual program contain patterns loops example similar nature patterns executing native code 
control flow patterns originate algorithm virtual program implements interpreted compiled 
note modern microprocessors considerable resources devoted identifying patterns native code exploiting predict branches 
fact hardware provides different types predictors support different types native branches 
unfortunately direct threading uses indirect branches due context problem patterns exist virtual program effectively hidden microprocessor 
fundamental goal approach expose virtual control flow patterns hardware physical execution path matches virtual execution path 
achieve goal exploit different types hardware prediction resources handle different types virtual control flow transfers 
section show replace straight line dispatch subroutine threading 
section show inline conditional indirect jumps section discuss handling virtual calls returns native calls returns 
strive maintain property virtual program counter precisely correlated physical program counter fact technique mapping control flow points 
ret handling linear dispatch dispatch straight line virtual instructions largest single source branches executing interpreter 
technique hopes improve branch prediction accuracy address dispatch 
obvious solution inlining eliminates dispatch entirely straight line sequences virtual instructions 
inlining benefits enabling optimizations implementations multiple virtual instructions 
increase code size caused aggressive inlining potential overwhelm benefits cost increased instruction cache misses 
eliminate dispatch propose alternative organization interpreter native call return instructions 
conceptually approach elegant subroutines natural unit abstraction express implementations virtual instructions 
illustrates implementation subroutine threading example program 
case show state virtual machine virtual instruction executed note virtual program stack contains value 
add new structure interpreter architecture called context threading table ctt contains sequence native call instructions 
native call dispatches body virtual instruction 
term context threading hardware address call instruction ctt provides execution context hardware importantly branch predictors 
opcode body ends native return instruction opcodes modify virtual control flow indirect jump direct threading 
direct threading table dtt necessary store immediate virtual operands correctly resolve virtual control transfer instructions 
direct threading entries dtt point opcode bodies subroutine threading refer call sites ctt 
counterintuitive improve dispatch performance calling body 
obvious call constant target expensive execute indirect jump issue 
modern microprocessors contain specialized hardware improve performance call return specifically return address stack predicts destination return instruction corresponding call 
cost subroutine threading control transfers versus direct threading cost outweighed benefit eliminating large source unpredictable branches 
handling virtual branches subroutine threading handles branches induced dispatch straight line virtual instructions actual control flow virtual program hidden hardware 
bodies opcodes affect virtual control flow context 
problems relating shared indirect branch prediction resources relating lack history context conditional branch prediction resources 
consider implementation inst goto 
simple unconditional virtual branch prediction problematic goto instructions virtual program share single indirect branch instruction single prediction context 
conditional virtual branches problem 
simple solution generate replicas indirect branch instruction ctt immediately call branching opcode body 
branching opcode bodies native return transfers control replicated indirect branch ctt 
consequence virtual branch instruction hardware context 
refer technique branch replication 
branch replication attractive simple produces desired context minimum replicated instructions 
number drawbacks 
branching opcodes execute hardware control transfers call body return actual branch unnecessary overhead 
second overly general indirect branch instruction cases inst goto prefer simpler direct native branch 
third replicating dispatch part virtual instruction take full advantage conditional branch predictor resources provided hardware 
due limitations branch replication indirect virtual branches exceptions 
branches fully inline bodies virtual branch instructions ctt 
refer branch inlining 
process inlining convert indirect branches direct branches possible 
reduce pressure btb exploit conditional branch predictors 
particular virtual conditional branches appear real conditional branches hardware 
primary cost branch inlining increased code size modest virtual branch instructions simple small bodies 
instance pentium iv branch instructions inlined words additional space 
shows example inlining inst goto branch instruction 
illustrates handle virtual call return control flow described 
context threading table ctt vpc vpc jmp destination 
call inst call call indirect callee 
opcode call callee opcodes callee opcodes callee opcodes callee opcodes callee jmp inst return opcode implementation bodies inst goto opcode body inst call manipulate vpc ret inst return manipulate vpc ret 
context threaded vm interpreter branch return inlining handling virtual call return significant source control transfers remain virtual program virtual calls returns 
successful branch prediction real problem virtual call virtual return virtual return may go back multiple call sites 
noted previously hardware elegant solution problem native code form return address stack 
need deploy resource predict virtual returns 
describe solution 
virtual call body effect transfer control start callee 
virtual call instruction see arrow labeled 
virtual call body simply sets vpc refer virtual callee executes native return ctt location 
similar branch replication insert new native call indirect instruction point ctt transfer control start callee arrow 
call indirect causes location ctt pushed hardware return address stack 
instruction callee dispatched arrow 
callee modify virtual return instruction follows 
ctt emit native direct branch dispatch body virtual return arrow 
native call dispatch direct branch avoids perturbing return address stack 
modify body virtual return native return instruction transfers control way back instruction original virtual call arrow 
refer technique apply return inlining final step complete technique aligns virtual program control flow corresponding native flow 
practical chal apply name generalized function call opcode ocaml implementing design apply return inlining 
take care match hardware stack virtual program stack 
instance ocaml exceptions unwind virtual machine stack hardware stack unwound corresponding manner 
second run time environments extremely sensitive hardware stack manipulations modify machine stack pointer purposes handling signals 
cases possible create separate stack structure swap virtual call return points 
approach introduce significant overhead justified apply return inlining provides substantial performance benefit 
having described design general implementation evaluate effectiveness real interpreters 
experimental evaluation section evaluate performance context threading compare direct threading selective inlining 
context threading combines subroutine threading branch inlining apply return inlining 
evaluate contribution techniques impact context threading virtual machines microprocessor architectures 
describing experimental setup section 
investigate effectively techniques address pipeline branch hazards section effect execution time section 
section demonstrates context threading complementary inlining resulting portable relatively simple technique provides performance comparable better sablevm implementation selective inlining 
virtual machines benchmarks platforms ocaml chose ocaml representative class efficient stack interpreters direct threaded dispatch 
bytecode bodies interpreter efficient hand tuned including register allocation 
implementation ocaml interpreter clean easy modify 
sablevm sablevm java virtual machine built quick interpretation implementing lazy method loading novel bi directional virtual function lookup table 
hardware signals handle exceptions 
importantly purposes sablevm implements multiple dispatch mechanisms including switch direct threading selective inlining sablevm calls inline threading 
support multiple dispatch mechanisms easy add context threading allows table 
description ocaml benchmarks pentium iv powerpc ppc lines branch branch elapsed time time stalls time source benchmark description tsc mpt cycles cycles sec code boyer boyer theorem prover fft fast fourier transform fib fibonacci recursion lexer generator kb knowledge base program nucleic nucleic acid structure quicksort quicksort sieve sieve eratosthenes classic peg game takeuchi function curried taku takeuchi function table 
description specjvm benchmarks pentium iv powerpc ppc branch branch elapsed time time stalls time benchmark description tsc mpt cycles cycles sec compress modified lempel ziv compression db performs multiple database functions jack java parser generator javac java compiler jdk jess java expert shell system mpegaudio decompresses mpeg layer audio files mtrt thread variant raytrace raytrace raytracer rendering performs fft sor lu large soot java bytecode bytecode optimizer compare selective inlining implementation believe complicated technique 
ocaml benchmarks benchmarks table constitute complete standard ocaml benchmark suite boyer kb quicksort sieve integer processing nucleic fft floating point benchmarks 
exhaustive search algorithm solves solitaire peg game 
fib taku tiny programs calculate integer values 
benchmarks unusual contain distinct virtual instructions contain instance 
features important consequences 
indirect branch direct threaded dispatch relatively predictable 
second minor changes dramatic effects positive negative ftp ftp inria fr inria projects xavier leroy benchmarks tar gz cause instructions contribute behavior 
sablevm benchmarks sablevm experiments run complete specjvm suite compress db mpegaudio raytrace mtrt jack jess javac large object oriented application soot scientific application 
table summarizes key characteristics benchmarks 
pentium iv measurements pentium iv processor aggressively dispatches instructions branch predictions 
discussed section taken indirect branches direct threaded dispatch mispredicted due lack context 
ideally measure mispredict penalty branches see effect execution time counter purpose 
count number mispredicted taken branches mpt show effectively mpt relative direct boyer fft fib kb nucleic quicksort ocaml benchmark sieve sub branch context tiny taku geomean lr ctr stall cycles relative direct boyer fft fib kb nucleic quicksort ocaml benchmark pentium iv mpt ppc lr ctr stalls 
ocaml pipeline hazards relative direct threading context threading improves branch prediction 
measure time cycle accurate time stamp counter tsc register 
count mpt tsc events linux kernel module collects complete data multithreaded java benchmarks powerpc measurements need characterize cost branches differently powerpc processors typically speculate indirect branches split branches shown ppc stalls branch unit branch destination known 
count number cycles stalled due link count register dependencies 
fortunately older ppc cpu counter counter stall lr ctr dependency provides exactly information 
ppc hardware counters obtain execution times terms clock cycles 
expect branch stall penalty larger cpus ppc directly count stall cycles processor 
report elapsed execution time ppc 
interpreting data presenting results normalize experiments direct threading case baseline state art dispatch technique 
give absolute execution times branching characteristics benchmark platform direct threading tables 
bar graphs sections show contributions component technique subroutine threading subroutine threading mpt events counted performance counter setting value xc hint bit encourage speculation models ppc default 
sieve sub branch context tiny plus branch inlining branch replication exceptions indirect branches complete context threading implementation includes apply return inlining labeled context 
include bars selective inlining sablevm simple inlining technique facilitate comparisons inlining results discussed section 
show bar direct threading height definition 
effect pipeline branch hazards context threading designed align virtual program state physical machine state improve branch prediction reduce pipeline branch hazards 
evaluation examining met goal 
reports extent context threading reduces pipeline branch hazards ocaml benchmarks reports results java benchmarks sablevm 
left graphs labeled results count mispredicted taken branches mpt 
right graphs labeled effect lr ctr stall cycles ppc 
cluster bar graph reports geometric mean benchmarks 
context threading eliminates mispredicted taken branches mpt pentium iv lr ctr stall cycles ppc similar effects interpreters 
examining figures reveals subroutine threading single greatest impact reducing mpt average ocaml sablevm reducing lr ctr stalls average ppc 
result matches expectations subroutine threading addresses largest single source unpredictable branches dispatch taku geomean mpt relative direct compress db jack javac jess mpeg mtrt java benchmark ray select sub branch context tiny soot geomean lr ctr stall cycles relative direct compress db jack javac jess mpeg mtrt java benchmark pentium iv mpt ppc lr ctr stalls 
sablevm pipeline hazards relative direct threading straight line bytecodes 
branch inlining largest effect expected conditional branches significant remaining pipeline hazard applying subroutine threading 
branch inlining cuts remaining 
ppc branch inlining smaller important effect eliminating remaining lr ctr stall cycles 
notable exception mpt trend occurs ocaml benchmarks fib taku 
tiny recursive benchmarks de virtualizing conditional branches hurts prediction small amount 
noted previously minor changes behavior single instruction noticeable impact benchmarks 
interestingly ocaml benchmarks challenge branch inlining reap greatest benefit apply return inlining shown 
due recursive nature benchmarks performance dominated behavior virtual calls returns 
mapping operations native calls returns enormous impact 
sieve result apply return inlining increase mpt non recursive ocaml benchmarks effect platforms small improvement 
sablevm apply return inlining restricted fact sablevm uses processor esp register 
implement complicated stack switching technique discussed section allow virtual machine stacks mis aligned sablevm manipulates directly 
increases overhead apply return inlining implementation reduces effectiveness return address stack predictor seen bar labeled context 
ppc effect apply return inlining lr ctr stalls small sablevm 
having shown techniques significantly re raytrace select sub branch context tiny duce pipeline branch hazards examine impact reductions execution time 
performance context threading improves branch prediction resulting increased pipeline usage ppc 
native call return pair dispatch increases instruction overhead 
section examine net result effects execution time 
data reported relative direct threading 
figures show results ocaml sablevm benchmarks respectively 
organized way previous section results left labeled ppc results right labeled 
reports performance ocaml sablevm ppc cpu 
geometric means rightmost cluster figures show context threading significantly outperforms direct threading virtual machines architectures 
geometric mean execution time ocaml vm lower context threading direct threading lower ppc lower ppc 
sablevm context threading compared direct threading runs faster ppc faster ppc 
measure cost lr ctr stalls ppc greater reductions execution time consistent design stages vs ppc 
interpreters architectures effect techniques clear 
subroutine threading single largest impact elapsed time 
branch inlining largest impact eliminating additional elapsed time 
general reductions execution time track reductions branch hazards seen figures soot geomean 
ppc elapsed time relative direct threading ocaml ppc elapsed real sec sablevm ppc elapsed real sec ocaml benchmark java benchmark boyer fft fib kb nucleic quicksort sieve taku geomean compress db jack javac jess mpeg mtrt ray soot geomean elapsed time relative direct elapsed time relative direct sub branch context tiny select sub branch context tiny 
sablevm elapsed time relative direct threading pentium iv tsc ppc cycles java benchmark java benchmark compress db jack javac jess mpeg mtrt ray soot geomean compress db jack javac jess mpeg mtrt raytrace soot geomean tsc relative direct cycles relative direct select sub branch context tiny select sub branch context tiny 
ocaml elapsed time relative direct threading pentium iv tsc ppc cycles ocaml benchmark ocaml benchmark boyer fft fib kb nucleic quicksort sieve taku geomean boyer fft fib kb nucleic quicksort sieve taku geomean tsc relative direct cycles relative direct sub branch context tiny sub branch context tiny 
instruction overheads dispatch technique evident ocaml benchmarks fib benefits improved branch prediction relative direct threading minor 
cases opcode bodies small extra instructions executed dispatch dominant factor 
effect apply return inlining execution time minimal changing geometric mean discernible pattern 
limited performance benefit added complexity general implementation apply return inlining worthwhile 
ideally detect heavy recursion automatically perform apply return inlining needed 
conclude general usage subroutine threading plus branch inlining provides best trade 
demonstrate context threaded dispatch complementary inlining techniques 
inlining inlining techniques address context problem replicating bytecode bodies removing dispatch code 
reduces instructions executed pipeline hazards 
section show selective inlining context threading technique reduce pipeline hazards context threading slower instruction overhead 
address issue comparing tiny inlining technique selective inlining 
figures bar shows measurements gagnon selective inlining implementation sablevm 
figures see selective inlining reduces mpt lr ctr stalls significantly compared direct threading effective regard subroutine threading 
larger reductions pipeline hazards context threading necessarily translate better performance selective inlining 
illustrates sablevm selective inlining beats context threading roughly ppc ppc techniques roughly effect execution time shown respectively 
results show reducing pipeline hazards caused dispatch sufficient match performance selective inlining 
eliminating dispatch code selective inlining real fewer instructions context threading 
context threading dispatch technique easily combined inlining strategies 
investigate impact dispatch instruction overhead demonstrate context threading complementary inlining implemented tiny inlining simple heuristic inlines bodies length times length dispatch code 
eliminates dispatch table 
selective inlining vs context tiny sablevm context selective tiny arch ppc ppc head surrounding smallest bodies calls ctt replaced comparably sized bodies tiny inlining ensures total code growth minimal 
fact smallest inlined ocaml bodies smaller length relative call instruction 
table summarizes effect tiny inlining 
come sablevm sophisticated selective inlining implementation 
powerpc outperform sablevm ppc ppc 
primary costs direct threaded interpretation pipeline branch hazards caused context problem 
context threading solves problem correctly deploying branch prediction resources result outperforms direct threading wide margin 
pipelines full secondary cost executing dispatch instructions significant 
suitable technique addressing overhead inlining shown context threading compatible inlining tiny heuristic 
simple approach context threading achieves performance equivalent better selective inlining 
current time writing extended context threading technique general purpose framework allows safe execution arbitrary instrumentation code bytecodes 
framework implemented bytecode logging assist debugging frequency branch bias profilers 
developed lazy linking technique allows dynamically add generated code segments 
tools currently identify hot basic blocks regenerate link program fly 
intend capabilities dynamically generate code interesting compilation units including loop bodies traces methods 
modern cpus deep pipelines kept full perform 
filling pipelines requires processor speculate instructions executing predicting direction target branching instructions 
direct threaded interpreters indirect branches dispatch bytecode bodies 
older processors efficient modern processors branches pipeline hazards causing stalls flushes due mispredictions hurting performance 
context threading improves performance exposing virtual program control flow hardware reducing pipeline hazards 
sequential bytecodes subroutine threading dispatching bytecode relative call predicting successor return stack 
inline bodies virtual conditional instructions exposing virtual execution context hardware conditional branch predictors 
demonstrate technique improving prediction virtual returns 
shown techniques eliminate significant number pipeline branch hazards 
reduce mean branch mispredictions reduce mean lr ctr branch unit stall cycles powerpc 
relative direct threading context threading reduces mean elapsed time pentium iv powerpc powerpc 
context threading performs better direct threading worse direct threaded inlining 
implemented simple inlining scheme inline small bytecodes 
come sablevm sophisticated selective inlining implementation 
ppc outperform sablevm implementation selective inlining 
context threading easy implement provides significant performance advantage direct threading 
addresses main obstacle high performance virtual instruction dispatch exposing virtual program control flow hardware control flow predictors 
furthermore context threading technique simple code remains flexible supports optimizations inlining code specialization 
conclude context threading better technique baseline interpretation may attractive environment dynamic optimization 
java hotspot virtual machine technical white 

bala duesterwald banerjia 
dynamo transparent dynamic optimization system 
sigplan conference programming language design implementation pages 

life lane 
forth dimensions january february 

optimizing bsr jsr threaded forth 
forth dimensions march april 
ertl gregg 
behavior efficient virtual machine interpreters modern architectures 
lecture notes computer science 
ertl gregg 
optimizing indirect branch prediction accuracy virtual machine interpreters 
proc 
acm sigplan pldi 
ertl gregg 
structure performance efficient interpreters 
journal instruction level parallelism 
ertl gregg krall 
vmgen generator efficient virtual machine interpreters 
software practice experience 
gagnon hendren 
proc 
th intl 
conference compiler construction volume lecture notes computer science pages 
springer 
hinton boggs 
microarchitecture pentium processor 
intel technology journal 
intel 
ia intel architecture software developer manual volume system programming guide 


architectural trail threaded code systems 
ieee computer march 
motorola 
mpc risc microprocessor programmer manual 

motorola 
mpc mpc risc microprocessor user manual rev 

riccardi 
optimizing direct threaded code selective inlining 
sigplan proc 
pldi pages 
miller 
numerical benchmark java 
rodriguez 
benchmarks case studies forth kernels 
computer journal 
romer lee voelker wolman wong 
baer bershad levy 
structure performance interpreters 
proc 
asplos pages october 
rossi 
survey instruction dispatch techniques byte code interpreters 
technical report tko helsinki university faculty information technology may 
spec jvm benchmarks 
takeuchi komatsu nakatani 
overview ibm java just time compiler 
ibm systems journals java performance issue february 
sullivan baron amarasinghe 
dynamic native optimization interpreters 
proc 
workshop interpreters virtual machines emulators 
vall rai gagnon hendren lam sundaresan 
soot java bytecode optimization framework 
proceedings conference centre advanced studies collaborative research page 
ibm press 
vitale 
catenation operand specialization tcl vm performance 
proc 
nd pages 
