maximum margin algorithms boolean kernels roni khardon rocco department computer science tufts university ma usa roni cs tufts edu department computer science columbia university new york ny usa rocco cs columbia edu 
introduced boolean kernels learn feature space containing conjunctions length original boolean features input space 
motivates question maximum margin algorithms support vector machines learn disjunctive normal form expressions pac learning model kernel 
study question variant structural risk minimization srm performed class hierarchy taken length conjunctions 
show maximum margin algorithms pac learn term dnf srm scheme 
consider pac learning uniform distribution show kernel uses conjunctions length maximum margin hypothesis fail uniform distribution 
results concretely illustrate margin algorithms may overfit learning simple target functions natural kernels 
keywords kernel methods pac learning background maximum margin algorithms notably support vector machines svm received considerable attention years see 
basic form svm learn linear threshold hypotheses combine powerful ideas 
idea learn linear separator achieves maximum margin training data arbitrary consistent hypothesis 
second idea implicit feature expansion kernel function 
kernel original space examples computes inner product expanded feature space 
kernel corresponds expanded feature space svm hypothesis implicit representation maximum margin linear threshold hypothesis expanded feature space original feature space 
svm theory implies kernel efficiently computable possible efficiently construct maximum margin hypothesis efficiently computable 
line algorithms proposed iteratively construct large margin hypotheses feature space see 
major focus research learning theory question various classes boolean functions learned computationally efficient algorithms 
canonical open question area exist efficient algorithms valiant pac learning model learning boolean formulas disjunctive normal form dnf 
question open pac model nearly years ago intensively studied researchers see 
svms learn dnf 
analyze performance maximum margin algorithms boolean kernels learn dnf formulas 
authors proposed family kernel functions kk kk computes number monotone unrestricted conjunctions length exactly true equivalent expanding original feature space boolean features include conjunctions 
linear threshold elements represent disjunctions naturally view dnf formula linear threshold function expanded feature space 
natural ask kk kernel maximum margin learning algorithms algorithms learning dnf 
additional motivation studying dnf learnability kk kernels comes progress dnf learning problem 
fastest known algorithm pac learning dnf due works explicitly expanding example feature space monotone conjunctions explicitly learning consistent linear threshold function expanded feature space 
kk kernel enables expansions implicitly computationally efficient way natural investigate maximum margin algorithm yields computationally efficient algorithm pac learning dnf 
note easily seen standard convergence bounds large margin classifiers imply kk kernel maximum margin algorithm efficient algorithm pac learning dnf 
bound theorem implies nontrivial generalization error kk boolean kernel similar known polynomial kernel monomials length represented 
main difference polynomial kernel assigns weights monomials depend certain binomial coefficients weights different monomials differ exponential factor 
boolean kernel monomials weight 
kernel algorithm sample size large sample computational advantage kk kernel lost 
upper bounds imply kk kernel maximum margin algorithm poor generalization error run smaller sample 
situation analogous generalization error perceptron winnow algorithms studied 
perceptron winnow standard bounds gave exponential upper bound number examples required learn various classes detailed algorithm specific analysis gave positive pac learning results perceptron negative pac results winnow problems considered 
analogously perform detailed analyses kk kernel maximum margin algorithms 
previous khardon constructed simple boolean function example sequence showed sequence causes kn kernel perceptron algorithm perceptron algorithm run feature space monotone conjunctions exponentially mistakes 
current differs ways earlier study maximum margin algorithm perceptron consider pac learning random sample online learning analyze kk kernels results study kernels corresponding monotone monomials length denote kk 
addition maximum margin algorithms consider natural scheme structural risk minimization srm family boolean kernels 
srm hierarchy classes learns class separately uses cost function combining complexity class observed accuracy choose final hypothesis 
cost function typically balances various criteria observed error bound generalization error 
natural scheme srm classes formed kk 
prove negative results establish strong limitations ability maximum margin algorithms pac learn dnf formulas simple boolean classes monomial kernels 
result says essentially 
kk kernel maximum margin algorithm pac learn term dnf 
precisely prove result term monotone dnf relevant variables distribution 
kk maximum margin hypothesis error larger standard practice experimental polynomial kernel typically small values tried best chosen 
overwhelmingly high probability choice polynomial size random sample 
note result implies kk maximum margin algorithms fail combined srm regardless cost function 
simply maximum margin hypothesis error final srm hypothesis error 
accuracy bound result small simple variant construction result proves result target function 
distribution kk maximum margin hypothesis error overwhelmingly high probability choice polynomial size random sample 
attempt learn monomials non constant size provably lead overfitting 
note standard bounds maximum margin algorithms show kk kernel algorithm learn polynomial size sample 
strong negative results pac learning arbitrary distributions consider problem pac learning monotone dnf uniform distribution 
frameworks positive results obtained learning dnf random examples see 
scenario simple variant construction result shows learning fail small result term monotone dnf relevant variables kk maximum margin hypothesis error probability choice random sample uniform distribution 
hand show kk algorithm fails uniform distribution large result target function 
kk maximum margin hypothesis error probability choice polynomial size random sample uniform distribution 
note substantial gap low values learning guaranteed fail high values show learning fails constant probability 
feel significant interest characterize performance kk maximum margin algorithm uniform distribution intermediate values discussion point section 
note results adapted give similar negative results standard polynomial kernel 
preliminaries consider learning boolean functions boolean cube 
convenient consider range mapped mapped 
easily achieved transformation deal linear function representations done affecting results 
rest assume representation 
arguments refer norms vectors 
notation xl definition 
linear threshold function sign margin mh note mh euclidean distance hyperplane 
definition 
bi set labeled examples bi 
sign linear threshold function 
margin mh min mh 
maximum margin classifier linear threshold function sign mh max min quantity called margin denoted ms 
note ms iff consistent linear threshold function 
ms maximum margin classifier unique 
transformation maps corresponding kernel function 
set labeled examples bi belongs write denote set transformed examples bi refer learning algorithm maximum margin learner algorithm draws sample poly labeled examples fixed probability distribution unknown function learned 
algorithm hypothesis sign sign maximum margin classifier 
loss generality assume normalized 
assume contains positive negative examples maximum margin classifier defined 
svm theory tells computed poly time maximum margin learning algorithm runs poly time output hypothesis evaluated poly time 
goal analyze pac learning ability various kernel maximum margin learning algorithms 
recall see pac learning algorithm class functions algorithm runs time polynomial confidence parameter accuracy parameter 
assume case function description size poly 
access random labelled examples distribution probability pac learning algorithm output efficiently computable hypothesis prx 
algorithm satisfies criterion particular distribution uniform distribution say uniform distribution pac learning algorithm 
note number nonempty monotone conjunctions monomials size variables 
write denote dimensional vector xt xt xi components monotone conjunctions desired size 
note example norm expanded example 
write denote number bits definition 
write kk denote 
refer kk monomials kernel 
theorem shows monomial kernels easy compute theorem 
kk frequently observation direct consequence cauchy schwarz inequality observation 
ui 
consequence observation number features expanded feature space 
distribution free non learnability give dnf distribution monomials kernel fails learn dnf consider read monotone dnf variables log 
fact results hold concreteness log running example 
log number terms log 
rest section refer function defined equation size parameter 
polynomial threshold function defined multivariate polynomial 
xn real coefficients 
output function 
xn 
degree function simply degree polynomial note hypothesis output kk kernel maximum margin algorithm polynomial threshold function degree minsky papert see gave lower bound polynomial threshold function degree dnf theorem 
polynomial threshold function equation degree 
distribution consider probability distribution outputs probability distribution outputs string drawn product distribution bits drawn uniformly bits drawn product distribution assigns bit probability small values result representation depend sample drawn lemma 
maximum margin algorithm uses kernel kk learning hypothesis error greater proof 
hypothesis error clearly error kernel kk hypothesis polynomial threshold function degree error setting variables causes error uniform distribution bits 
setting variables hypothesis degree polynomial threshold function variables 
minsky papert theorem polynomial threshold function compute target function exactly wrong setting variables 
uniform distribution setting variables probability contradicts larger values fact show maximum margin hypothesis high probability overfit sample 
definition captures typical properties sample distribution definition 
sample typical sample sample includes example nonzero example sample pair positive negative examples satisfies interested cases polynomial size sample algorithm 
lemmas hold standard chernoff bound arguments lemma 
poly probability random sample draws typical sample 
definition 
sample 
set includes positive examples positive example satisfies lemma 
typical sample size poly examples 
prd show typical sample achieve large margin lemma 
typical sample 
maximal margin ms satisfies ms mh proof 
exhibit explicit linear threshold function margin mh data set 
sign defined follows active positive example active positive example 
value gives maximum margin average smallest value xi largest value xj 
positive example ones 
positive example ones positive example sample contributes ones 
negative example sample positive example sample share ones sample 
putting conditions get margin sample desired 
lemma 
typical sample threshold maximum margin classifier mh 
proof 
sign maximum margin hypothesis 
mh mh mh second equality holds inequality lemma 
lemma 
maximum margin algorithm uses kernel kk learning probability hypothesis error greater proof 
sample learning sign maximum margin hypothesis 
known see proposition maximum margin weight vector linear combination support vectors certain examples sample 
coordinates wt nonzero corresponding features conjunctions xt example lemma probability sample 
consider 
follows observations sum nonzero numbers sum squares numbers 
observation 
positive example erroneously classified negative lemma inequality holds 
prove appendix holds 
observe positive examples probability argument shows misclassified lemma guarantees relative weight positive examples error rate claimed 
lemma lemma imply result theorem 
value maximum margin algorithm uses kernel kk learning probability hypothesis error greater small modification obtain result 
particular need deal small simple function modify slightly probability 
argument lemma yields theorem 
maximum margin algorithm uses kernel kk learning probability hypothesis error uniform distribution theorem tells kk maximum margin learner pac learning algorithm monotone dnf distribution free pac model rule possibility kk maximum margin learner succeed particular probability distributions uniform distribution section investigate uniform distribution 
section took advantage fact occurred high weight distribution give lower bound value negative example sample argue value maximum margin classifier large ms uniform distribution lower bound longer holds subtle analysis 
turning main result easy observe proof lemma goes uniform distribution gain factor 
proves result algorithm uses low degree hypothesis possibly sufficiently accurate target 
contrast result show large algorithm overfit 
result consider target function 
data set drawn uniform distribution labelled function positive examples negative examples 
ui denote weight th positive example positive examples ordered 
similarly vj denote weight th negative example 
definition 
sample typical sample example satisfies 
pair positive negative examples satisfy 
straightforward application chernoff bounds yields lemmas lemma 
poly probability random sample draws typical sample 
definition 
sample 
set includes positive examples positive example satisfies 
lemma 
typical sample size poly examples 
lemma analogous lemma lemma 
typical sample size maximal margin ms satisfies ms proof 
exhibit explicit linear threshold function margin 
sign defined follows positive example pick set features monomials take value done positive example xi bits 
feature sets assign 

remaining features set set value gives maximum margin average smallest value xi largest value xj 
note positive example contributes nonzero coefficients number 
construction positive example xi satisfies xi 
typical sample negative example xj shares ones positive example value xj sum numbers squares sum 
observation xj 
lemma follows combining bounds xi xj 
turns relative sizes weights lightest positive negative examples play important role 
definition 
sample size positive skewed lightest positive example weighs lightest negative example log lemma prove appendix shows random sample positive skewed constant probability lemma 
sample size poly drawn uniform distribution 
positive skewed probability 
give lower bound threshold maximum margin classifier 
lemma 
labeled sample size typical positive skewed sign maximum margin hypothesis 
proof 
positive skewed know sum weights wt normalized sum squares weights 
observation 
ms lemma proves lemma 
putting pieces theorem 
maximum margin algorithm uses kernel kk log learning uniform distribution probability hypothesis error proof 
lemmas sample learning typical positive skewed probability 
consider 
reasoning lemma sum numbers squares sum 
example erroneously classified negative 
suffices show 
appendix show holds log required 
argument shows misclassified lemma guarantees relative weight positive examples prx probability hypothesis error rate theorem proved 
boolean kernels offer interesting new algorithmic approach major open problems computational learning theory learnability dnf expressions 
studied performance maximum margin algorithm boolean kernels giving negative results settings problem 
results indicate maximum margin algorithm overfit learning simple target functions natural expressive kernels functions combined structural risk minimization 
hope negative results tool explore alternate approaches may succeed discuss briefly 
direction modify basic learning algorithm 
interesting variants basic maximum margin algorithm years soft margin criteria kernel regularization 
may possible prove positive results dnf learning problems approaches 
starting point test performance counterexamples functions distributions constructed 
immediate goal close gap small large results uniform distribution 
known learning polynomial size dnf uniform conjunctions length log ignored little effect 
interesting setting uniform distribution learning problem log 
learning uniform log kernel qualitatively quite different learning large values able analyze 
example log sufficiently large polynomial size sample taken high probability features monomials size active sample 
concrete problem scenario consider question log kernel maximum margin algorithm efficiently pac learn target function uniform 
problem easy show naive hypothesis constructed proofs achieves large margin high accuracy 
possible show high probability maximum margin hypothesis margin multiplicative factor margin achieved preliminary results answer question suggest answer may positive 
positive answer view strong motivation analyze general case 
blum furst jackson kearns mansour rudich 
weakly learning dnf characterizing statistical query learning fourier analysis 
proceedings sixth annual symposium theory computing pages 
blum rudich 
fast learning term dnf formulas queries 
journal computer system sciences 
boser guyon vapnik 
training algorithm optimal margin classifiers 
proceedings fifth annual workshop computational learning theory pages 

subexponential exact learning algorithm dnf equivalence queries 
information processing letters 

fourier spectrum monotone functions 
journal acm 
gentile 
new approximate maximal margin classification algorithm 
journal machine learning research 
hancock mansour 
learning monotone dnf formulas product distributions 
proceedings fourth annual conference computational learning theory pages 
jackson 
efficient membership query algorithm learning dnf respect uniform distribution 
journal computer system sciences 
kearns vazirani 
computational learning theory 
mit press cambridge ma 
khardon 
fourier transform learn disjoint dnf 
information processing letters 
khardon roth 
efficiency versus convergence boolean kernels line learning algorithms 
dietterich becker ghahramani editors advances neural information processing systems cambridge ma 
mit press 

learning dnf time proceedings third annual symposium theory computing pages 
kowalczyk smola williamson 
kernel machines boolean functions 
dietterich becker ghahramani editors advances neural information processing systems cambridge ma 
mit press 
kucera marchetti spaccamela 
learning monotone dnf formulae uniform distributions 
information computation 
kushilevitz roth 
learning visual concepts dnf formulae 
proceedings sixth annual conference computational learning theory pages 
minsky papert 
perceptrons computational geometry 
mit press cambridge ma 

learning boolean functions support vector machines 
proc 
th international conference algorithmic learning theory pages 
springer 
lnai 
sakai 
learning monotone log term dnf formulas uniform distribution 
theory computing systems 

pac learning winnow perceptron perceptron algorithm 
proceedings twelfth annual conference computational learning theory pages 

learning monotone dnf product distributions 
proceedings fourteenth annual conference computational learning theory pages 
shawe taylor cristianini 
support vector machines 
cambridge university press 

learning dnf approximating inclusion exclusion formulae 
proceedings fourteenth conference computational complexity pages 
valiant 
theory learnable 
communications acm 

learning dnf uniform distribution quasi polynomial time 
proceedings third annual workshop computational learning theory pages 

learning sub classes monotone dnf uniform distribution 
proceedings ninth conference algorithmic learning theory pages 
watkins 
kernels matching operations 
technical report csd tr computer science department royal holloway university london 
appendix proof equation show suffices show 
proof uses cases depending value relative case suffices show mk equivalent clearing denominators binomial coefficients mk 
fact ab provided ab easy see condition holds suffices show mk turn implied mn fact obtain right hand side 
holds true poly 
long log mn log case case bounds third occurrences equation second occurrence 
suffices show suffices show holds th roots rearranging upper bound left side previous inequality holds left side greater right side poly case proved 
case bound proved holds log log binary entropy function 
applying bound left side 
suffices show easily seen hold poly 
prove bound stirling approximation fact weaker form upper bound 



qh equation follows 
case case suffices show easily seen hold poly 
equation holds 
proof lemma recall lemma lemma sample size poly drawn uniform distribution 
positive skewed probability 
step reduce situation positive examples negative examples independent 
positive integers 
consider new probabilistic experiment call em draws binomial distribution obtain sorted values vm draws obtain sorted values um 
values 
vm distributed identically weights negative examples lemma scenario conditioned likewise 
um positive examples 
define event event am succinctness write am event original scenario size sample drawn positive skewed 
pr am pr pr pr am min pr am min pr am 
suffices show values pr am 
fix range henceforth consider experiment em event involving ui independent event involving vi denote 
idea part proof show probability falls relatively small left tail distribution bounded away tail 
gives gap desired 
consider 
denote note precisely weight left tail distribution 
event 
order draws land left tail weight union bound probability occurs note case total number examples example condition lightest positive example weighing biases number positive examples biases biases weight lightest negative example 
pr 
probability easily seen pr 
consider 
denote captures weight left tail similar 
event event fails occur draws misses left tail weight need slightly careful note takes discrete values tail may weigh conceivably take care show tail weigh denote largest integer cm claim 
constant cm proof 
suppose cm cm implies particular implies implies 
chernoff bound implies values contradicts inequality cm constant polynomial claim implies left tail weight weight probability draws misses left tail pr 
claim 
events occur event am occurs 
proof 
suppose sake contradiction events occur 
occurs hand occurs 
inequalities clearly imply 
fact imply recalling sum terms 
largest terms equation 
lemma proved lemma 
lemma equation implies contradicts claim proved 
events independent pr am pr pr lemma proved 
proof lemma clearly suffices prove standard chernoff bound tells event know log log observe provided 
log may assume log easily verified satisfied log lemma proved 
proof equation show assuming sample typical 
suffices show 
case 
suffices show inequality true recall log fact suffices show log log fact ex see inequality holds log ln 
poly case log 
case 
suffices show suffices show standard properties binomial coefficients imply left side greater right 
poly log side 
case 
case suffices show previous case holds values 
