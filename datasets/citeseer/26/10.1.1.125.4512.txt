rapid cache reliable inexpensive write cache high performance storage systems yiming hu qing yang modern high performance disk systems extensive non volatile ram nvram write caches 
single copy nvram cache creates single point failure dual copy nvram cache expensive high cost nvram 
presents new cache architecture called rapid cache redundant asymmetrically parallel inexpensive disk cache 
typical rapid cache consists redundant write buffers top disk system 
buffers primary cache ram nvram backup cache containing level hierarchy small nvram buffer top log disk 
small nvram buffer combines small write data writes log disk large sizes 
exploiting locality property accesses advantage known logstructured file systems backup cache nearly equivalent write performance primary ram cache 
read performance backup cache critical normal read operations performed primary ram cache reads backup cache happen error recovery periods 
rapid cache presents asymmetric architecture fast write fast read ram primary cache fast write slow read nvram disk hierarchy backup cache 
asymmetrically parallel architecture algorithm separates actively accessed data inactive data cache virtually eliminate garbage collection overhead major problems associated previous solutions log structured file systems disk caching disk 
asymmetric cache allows cost effective designs large write caches high parallel disk systems dual copy costly nvram caches 
possible implement reliable write caching low disk systems rapid cache inexpensive disks perform reliable caching 
analysis trace driven simulation results show rapid cache significant reliability cost advantages conventional single nvram write caches preliminary research th international symposium high performance computer architecture hpca january orlando florida :10.1.1.125.4512:10.1.1.125.4512
yiming hu department electrical computer engineering computer science university cincinnati cincinnati oh 
mail uc edu 
sun microsystems san antonio road palo alto ca 
mail sun com 
qing yang department electrical computer engineering university rhode island kingston ri 
mail ele uri edu 
great cost advantages dual copy nvram caches 
rapid cache architecture opens new dimension disk system designers exercise trade offs performance reliability cost 
keywords disks storage systems performance reliability fault tolerance modern disk systems extensive nonvolatile ram nvram write caches asynchronous write write request acknowledged write goes disk 
write caches significantly reduce response times disk systems seen users particularly raid systems 
large write caches improve system throughput advantage temporal spatial localities data may overwritten times combined written disk 
io requests bursty requests come long intervals relative inactive periods 
large write caches benefit burstiness write workloads data coming bursts quickly stored cache written back disk system busy 
treiber menon reported write caches reduce disk utilization writes order magnitude compared basic raid systems 
write caches introduces problems poor reliability high cost 
disks impressively reliable today mean time failure mttf hours 
low failure rate coupled possible redundancy raid gives mean time data loss hundreds millions hours typical raid system :10.1.1.17.2863
adding single cache front disk system creates single point failure vulnerable data loss 
savage wilkes pointed typical nvram technology battery backed ram quite low mttf hours single copy nvram cache suffers significantly higher risk data loss results disk failures :10.1.1.17.2863
overcome reliability problem high raid systems dual copy caches failure cache leaves cache intact 
write request comes controller writes copies data independently caches primary cache backup cache 
reliability problem nvram known costly size nvram cache limited 
example major nvram manufacturer quoted price nvram embedded lithium cell batteries mb quantity december 
cost disks hand cents mb difference orders magnitude 
cost difference widening difference orders magnitudes years ago prices disks falling rapidly 
disk system reasonably sized write cache nvram may dominate cost entire system 
example system disks gb disk nvram write cache mb mb nvram costs total cost disks assuming gb disk costs 
dual copy caches ease reliability problem single copy cache cost prohibitively high particularly large caches 
result suitable upper echelon market 
standard dual copy write cache system symmetric structure primary write cache backup write cache size access characteristics fast read speed fast write speed 
backup cache provide performance benefit system normal operations 
wasteful backup cache identical primary cache 
needed backup cache written quickly read operations critical reads backup cache occur error recovering periods 
observations propose new disk cache architecture called redundant asymmetrically parallel inexpensive disk cache cache short provide fault tolerant caching disk systems inexpensively 
main idea rapid cache conventional fast write fast read primary cache non volatile fast write slow read backup cache 
primary cache normal nvram dram backup cache consists small nvram cache log disk cache disk 
backup cache small random writes buffered small nvram buffer form large logs written cache disk large transfers similar log structured file systems :10.1.1.26.8749:10.1.1.117.5365
large writes eliminate expensive small writes buffer quickly available additional requests level cache appears host large nvram 
result backup cache achieve write speed primary cache 
slow read performance backup cache affect system performance data block backup cache copy primary cache read speed ram 
dual cache system asymmetric primary cache backup cache different sizes structures 
reliability rapid cache expected high disk reliable 
system inexpensive nvram backup cache small ranging hundreds kb mb cost disk space significantly large nvram 
show rapid caches provide higher reliability compared single copy nvram caches lower cost compared dual copy nvram caches sacrificing performance 
hand low cost budget rapid caches significantly higher performance compared conventional nvram cache architectures affording larger primary cache sizes maintaining reliability 
idea rapid cache system particularly suitable parallel disk systems raid raid systems environments require high performance high reliability 
concentrate study rapid caches top raid systems 
carried trace driven simulation experiments analytical studies evaluate performance reliability rapid cache 
real world traces synthetic traces generated realistic workloads analyze performance rapid cache architecture compare existing disk cache architectures 
numerical results show rapid cache significant performance cost reliability advantages existing architectures 
organized follows 
section presents detailed architecture operations rapid cache 
section presents experimental methodology 
simulation results section followed approximate reliability cost analysis section 
discuss related section conclude section 
architecture operations shows basic structure rapid cache 
consists conventional primary ram cache backup cache 
backup cache level hierarchy small nvram top cache disk similar dcd :10.1.1.119.6793
rapid cache write operation sent primary cache backup cache read operations performed primary cache 
dram read cache incoming requests nvram primary disks disk controller dram write cache backup cache small nvram cache disk rapid cache top disk system high reliability primary cache nvram provide redundant protection power failure 
hand low cost systems primary cache dram 
normal operations dram primary cache backup cache contain redundant data 
caches fails data reconstructed 
power failure data retained backup nvram cache disk 
read cache primary write cache dram unified read write cache structure shown better cache utilization 
rapid cache large unified dram primary cache higher throughput lower cost better reliability single copy conventional nvram cache 
applications require redundant protection power failure triple rapid cache shown build highly reliable large cache system 
idea low cost backup caches support large primary dram cache 
normal operations primary cache backup caches provide triple redundancy protection 
backup caches provide dual redundancy protection power failure 
triple rapid caches especially suitable high systems need large reliable write caches 
large cache sizes triple rapid cache lower cost better reliability rapid cache large nvram primary cache conventional dual copy nvram cache 
dram primary read write cache incoming requests raid controller nvram backup write cache raid cache disk rapid cache unified read write cache dram unified primary cache incoming requests raid controller nvram backup write cache nvram backup write cache raid cache disk cache disk triple rapid cache cache disks unified rapid cache triple rapid cache structures backup cache shows detailed structures backup nvram cache cache disk 
nvram cache consists lru cache segment buffers hash table 
related data structure called disk segment table located dram buffer 
cache disk space disk segment incoming write data lru cache nvram disk segment data disk hash table segment buffer segment buffer disk segment dram disk segment table disk segment disk segm detailed structure backup cache cache disk actively accessed data backup cache reside lru cache 
actively accessed data kept cache disk 
data cache disk organized format similar log structured file system sprite lfs bsd lfs :10.1.1.117.5365:10.1.1.117.5365
segment contains number slots hold data block 
data blocks stored segments addressed segment ids slot ids 
data blocks stored lru cache addressed logical block addresses 
hash table contains location information valid data blocks backup cache 
describes block nvram lru cache cache disk data address lru cache cache disk 
current design size hash entry bytes 
data backup cache exact image data primary write cache total number valid data blocks backup cache primary write cache regardless sizes backup nvram cache disk 
data block size kb mb write cache blocks total 
valid block corresponding hash entry bytes total hash table size kb compact placed nvram 
purpose speeding garbage collection keep track data structure called disk segment table 
table contains redundant information quickly completely reconstructed hash table case crash stored dram 
discuss structure disk segment table detail section 
dram read cache incoming requests raid controller dram nvram primary write cache raid nvram backup write cache cache disk rapid cache dedicated physical cache disk dram read cache incoming requests raid controller nvram dram backup nvram write cache primary write cache raid cache partitions rapid cache distributed logical cache disk physical rapid cache logical rapid cache cache disk backup cache dedicated physical disk shown 
distributed data disks raid system data disk having small partition acting part large distributed logical cache disk shown 
modern raid systems physical implemented extra cost modern raid systems include spare disks put service active disk fails :10.1.1.119.6793
pointed wilkes normal operations spare disks systems contribute performance system :10.1.1.119.6793
hard tell spare disks working 
spare disk physical cache disk rapid cache 
secondary benefit aware spare disk working condition able replace failed late 
spare disk active disk replace failed rapid cache degraded logical cache disk mode partition residing spare disk failed disk replaced new spare disk put system 
case logical cache disk system distributed spare disk utilized normal operation 
data written logical cache partitions raid disks involve parity operations 
words logical cache partitions act just bunch logical disks 
backup cache provides reliable non volatile backup cached data 
write write request comes controller invalidates data copy read cache 
sends data simultaneously primary cache lru cache backup cache 
space available caches data copied caches immediately 
hash entry backup cache created indicate data block located backup lru cache 
data written primary cache nvram buffer backup cache controller sends acknowledgment host signaling request complete 
space left primary cache controller tries discard clean block cache room new request 
find clean block controller chooses lru data block writes raid 
lru block safely written raid space primary cache freed incoming request 
copy replaced data secondary cache lru cache cache disk invalidated 
lru cache backup cache full rapid controller picks empty segment buffer sets current segment buffer 
lru data block copied segment buffer corresponding entries hash table disk segment table modified reflect fact data block current segment buffer lru cache 
segment buffer nvram cache space lru data block safely freed accept incoming request 
write requests may continue evict lru blocks segment buffer segment buffer full 
controller writes contents segment buffer cache disk segment large write 
point controller switches empty segment buffer current segment buffer continues operation 
entire segment buffer written large write small writes segment buffer quickly available write finishes 
small nvram cache large cache disk appear controller large nvram write cache 
dedicated segment buffers allow data transferred cache disk single large continuous transfer 
systems support scatter gather transferring hardware technique assemble data non contiguous memory locations dedicated segment buffers needed 
segment buffer size directly affects write efficiency 
rapid cache dedicated larger segment size smaller write overheads caused disk seeking rotational latencies 
hand larger segment size results smaller lru cache size nvram size 
trade large segment sizes large backup lru cache sizes 
simulation experiments workload kb segment buffers give best performance 
rapid cache logical cache disk segment size large segment writes compete normal raid reads data disks 
large segment sizes may result lower read performance 
kb segment buffers achieve performance case 
read reading straightforward rapid cache 
request comes read cache primary write cache searched 
cache hit data returned immediately 
case cache lru block read cache discarded buffer space freed 
requested data read raid system freed lru block data returned 
backup cache involved read operations 
traditional raid system nvram write cache dirty data write cache written raid system process called normally happens background 
raid system rapid cache requires 
current design threads initiated controller detects idle period number dirty blocks primary write cache exceeds high water mark say cache capacity 
threads find dirty lru block primary cache read old data parity block disks read cache compute new parity write new data parity disks 
new data parity written dirty block primary cache marked clean data block backup cache nvram lru cache cache disk invalidated 
invalidation backup cache block involves releasing lru buffer block nvram lru cache marking corresponding segment slot invalid data disk segment segment buffer deleting hash entry hash table 
threads run continuously idle period dirty block count primary cache falls low water mark say cache capacity 
notice data backup cache read written process 
slow speed cache disk affect performance 
garbage collection shown rapid cache data cache disk organized segments similar lfs system 
lfs system system running disk segments partially full data overwrites invalidations 
result lfs frequently call garbage collector reads partially full disk segments ram compacts data writes data back disk new segment 
mentioned previously garbage collection cause great performance loss cases 
rapid cache system segments cache disk may fragmented require garbage collection 
asymmetrically parallel architecture rapid cache data cache disk primary write cache read quickly 
need read data cache disk 
garbage collection rapid controller simply searches disk segment table find fragmented segments 
copies corresponding data primary cache segment buffer ram 
controller writes contents segment buffer new disk segment invalidates old segments 
garbage collection overhead rapid cache small fraction lfs 
perform garbage collection controller able quickly identify disk segments contain valid data blocks 
able quickly find logical block address lba data block cached disk segment slot segment id slot id disk segment table entry segment cache disk 
entry contains counter valid blocks cached segment flag indicating segment cached segment buffer lock concurrency control slot mapping table describes slots segment contain valid data 
slot mapping table array integers 
slot segment entry integer table 
slot contain valid data block entry slot mapping table set 
entry set lba cached data block 
slot cache disk entry slot mapping table total size disk segment table mainly determined number slots cache disk 
cache disk size mb cache block size kb slots requiring integers kb disk segment table 
information disk segment table quickly completely reconstructed hash table case crash 
garbage collection needed number available empty disk segments falls threshold garbage collector activated 
collector searches disk segment table set disk segments smallest valid block counters maximum amount garbage 
collector reads segments ram large requests finds remaining valid blocks slot mapping table merges form new segment 
new segment written back disk 
old disk segments marked blank 
addition low cost garbage collection algorithm simulation experiments workload rapid controller call garbage collector meaning garbage collection overhead virtually impact system performance 
due reasons 
disk spaces inexpensive cents mb writing normally choose cache space times larger primary write cache size 
example primary cache size mb disk space mb cache space costs 
mb data spread space mb disk space empty 
second lfs system writes actively accessed data inactive data segment rapid cache system active data inactive data separated 
active data kept lru cache data disk segments cache disk relatively inactive 
entire segments invalidated background threads constantly inactive data disk arrays 
result time controller find empty disk segment need garbage collection 
modern disks minimal capacity gb writing 
physical cache disk may able quite large cache space 
addressed physical cache disk may introduce extra cost system 
logical cache disk may want smaller cache space size disk space data disks 
error handling availability rapid cache system excellent reliability data redundancy provided primary cache backup cache 
data caches lost reason cache read rebuild data 
system crash power failure data retained nvram cache disk backup cache 
primary cache nvram provide additional protection 
takes seconds tens seconds recover data backup cache reading cache disk done large segment size efficient 
fact power failure period data cached cache disk safer nvram 
disks retain data long period time doing 
hand data stored active devices nvram ups uninterrupted power supply backed dram safe data disks nvram batteries may leak ups may run power fail 
compared single nvram write cache rapid cache system excellent availability 
cache partition logical cache disk crashes system operate continuously spare disk swap replace failed disk controller simply skip failed disk affecting system performance significantly 
dedicated cache disk crashed system borrow small partition data disk operate logical cache disk mode 
nvram backup cache fails small portion primary cache borrowed system continue operations failed nvram replaced 
primary write cache fails read cache switched unified read write cache mode accept write data 
case rapid cache system uses unified read write primary cache entire unified primary cache fails system may operate degraded mode lower performance slow read speed backup cache 
simulation models trace driven simulations evaluate effectiveness rapid cache 
section describe details simulation workload models 
simulators rapid cache simulator built top general cached raid simulator developed 
raid mapping function borrowed berkeley simulator 
disk model simulator developed kotz models hp disk drive described 
hp inch gb disk average access time ms kb data block 
disk simulator provides detailed simulation including scsi bus contention built cache read ahead write head skewing simulator quite accurate large scale simulation systems stanford simos dartmouth 
hp slightly dated 
changes closer performance ranges current disks increasing rotation speed rpm rpm increasing capacity increasing average linear density sectors track sectors track increasing interface bus speed mb sec mb sec decreasing platter number 
assume raid controller high speed mb sec fibre channel bus connected host 
requests reserve bus starting data transfer 
bus speed limit response time nvram ram cache hits data hit ram cache need read bus 
controller handle pending requests 
additional requests wait fifo queue 
requests processed come serve basis may complete order 
cache block size kb 
cache fully associative uses lru algorithm easy efficient software relatively small cache 
raid simulator number raid columns set disks number raid rows 
stripe unit kb data layout left symmetric 
results obtained garbage collector running 
workload models purpose performance evaluation show rapid cache deliver performance expensive nvram caches various workload environments 
order provide fair unbiased evaluation paid special attention selecting workload drives simulators plays critical role performance evaluation 
main objective choosing workload models close realistic workloads possible cover wide range parameters possible 
objective mind sets trace files selected discussed 
real world traces set traces real world traces obtained emc hp laboratories 
emc trace referred emc tel trace collected emc disk array system installed telecommunication customer site 
trace file contains requests fixed request size kb 
trace write dominated write ratio 
average request rate requests second 
hp traces collected hp ux systems month period described detail 
trace called cello news 
single disk holding usenet news database 
news database updated constantly day 
trace savage wilkes evaluate afraid raid system :10.1.1.17.2863
chosen days traces starting may 
day hundreds requests 
careful examination hp trace files reveals requests bursty 
request rate request burst high usually exists long idle period seconds consecutive bursts requests 
result average request rate low requests second 
low request rate highly bursty request pattern rapid cache obviously perform time move data nvram buffer collected burst cache disk garbage collection idle period 
order conservative evaluation rapid cache artificially reduce idle period increase average request rate 
searched traces shortened idle period longer milliseconds milliseconds average request rate requests second 
increase rate overlaid days cello news traces single trace 
approach varma days cello traces overlaid study performance raid caches 
study overlaid days traces giving rise request rate requests second 
numbers requests resulting traces vary requests 
request size kb 
synthetic traces real world traces give realistic evaluation performance systems limited view system performance considering fast changing computer world :10.1.1.111.8732
order observe rapid cache performs variety workloads generated set synthetic traces 
synthetic traces generated access characteristics cello news traces traces smith 
carefully fine tuned trace generation parameters request interval times data access patterns working set sizes read write ratios way characteristics generated traces similar real world traces 
furthermore order provide fair comprehensive evaluation vary workloads wide spectrum cover possible possible workload situations 
request interval time traces modeled exponentially distributed random variables 
chose exponential distribution function analyses cello news traces hp laboratories 
request may come burst called bursty request outside burst called background request 
generator repeatedly inserts clusters bursty requests background requests 
mean request rate burst times larger mean request rate background requests exponentially distributed interval times 
burst length interval length consecutive bursts terms number requests exponentially distributed analysis real world traces mean respectively 
data access pattern modeled approach similar varma 
separate history tables maintained writes reads 
request may selected history table selected uniformly possible disk addresses 
request selected history table entry table selected random variable representing distance entry top table 
analysis real world traces shows distance approximated exponential distribution time intentionally chose different distribution functions exponential distribution normal distribution uniform distribution generate traces different access patterns 
history tables form lru stacks simulate temporal locality accesses 
entry selected table removed stack pushed back top stack 
working set size mainly controlled sizes history tables 
larger history tables result larger working sets 
smith performed extensive research disk caching large databases timesharing systems 
traces different systems show significantly different characteristics 
working set sizes synthetic traces modeled cello news traces traces studied smith 
shows cache ratios function cache sizes cello news synthetic traces lru cache kb block size 
synthetic trace modeled cello news slightly higher initial ratio smaller working set mb 
synthetic ratio emc tel cello news synthetic synthetic synthetic cache size mb ratios traces various cache sizes trace read access working burstiness note name ratio pattern set mb synthetic traces emc tel write dominated cello news write dominated bursty synthetic normal write dominated moderate working set synthetic uniform write dominated small working set synthetic exponential read dominated large working set table characteristics traces 
access pattern refers random function controls distance top history table selected entry table 
mean burst length mean interval length terms number requests 
modeled telecom trace low initial ratio small working set 
ratio decreases slowly cache size increases 
emc tel low initial ratio 
synthetic modeled bank trace moderate initial ratio large working set mb 
table lists characteristics traces study 
request sizes traces kb emc tel request size kb 
generated different trace files mean request rates ranging requests second 
trace file contains requests 
verify requests sufficient generate reasonably accurate results simulation run selected trace files increased request numbers 
ran simulations different configurations long traces 
results trace requests trace requests 
result cold start effect average response times requests biased slower requests 
relative performance different configurations trace length change 
example rapid cache standard dual copy cache identical performance traces requests 
identical performance traces requests average response times slightly faster longer trace 
time limit ran simulations requests 
simulation results objective show rapid cache similar performance conventional cache lower cost higher reliability 
hand budget rapid cache architecture allows larger primary cache low cost obtain higher performance compared conventional cache 
purpose define baseline system conventional read write cache system optional backup nvram cache size primary write cache 
backup nvram size rapid caches chosen mb 
experiments size larger mb result significant performance improvement size smaller mb may cause performance degradation traces 
section discusses impact backup cache size detail 
size cache disks rapid caches set mb simulation runs 
number chosen large avoid garbage collection time 
performance subsection compare performance rapid caches conventional caches terms throughput response time simulation results 
emphasized primary cache size rapid cache system perform better conventional cache system performance mainly limited primary cache size 
show rapid cache similar performance conventional cache lower cost higher reliability 
hand budget rapid cache architecture allows larger primary cache low cost obtain higher performance compared conventional cache 
performance real world traces real world traces emc tel cello news moderate load relatively small system simulation 
number disks raid system set 
read cache size mb emc tel trace mb cello news trace 
varied primary write cache sizes mb emc tel trace mb cello news trace 
table lists read write response time baseline systems rapid caches workload 
immediate report low cache ratio trace average response times quite low especially write requests 
table shows baseline system rapid caches similar identical performance 
compares performance rapid caches conventional caches trace 
average response times read write requests plotted functions numbers overlaid traces 
large read caches fast write technique average response times systems low low throughput 
average response times steadily increase cache sizes response time ms read write split cache unified cache baseline rapid rapid baseline rapid rapid mb read write read write read write read write read write read write table performance trace emc tel 
size nvram buffer rapid cache mb 
rapid means logical rapid cache rapid means physical rapid cache 
response time ms read cache mb write cache mb logical rapid physical rapid baseline baseline physical rapid logical rapid number trace overlays response time ms read cache mb write cache mb baseline physical rapid logical rapid baseline physical rapid logical rapid number trace overlays response time ms read cache write cache mb baseline physical rapid logical rapid logical rapid physical rapid baseline number trace overlays performance trace cello news 
note single trace request rate requests sec 
overlaying traces results request rate requests sec 
number overlaid traces request rate goes high increased disk traffic 
eventually request rate increases point system saturated response times increase sharply 
point system handle higher workload 
define throughput point maximum system throughput 
clear results performance rapid caches close baseline systems terms maximum system throughput response time time 
confirms backup cache rapid caches performs 
small nvram cache disk achieve similar write performance large primary write cache 
logical rapid cache log writes disks compete normal data reads may cause performance degradation 
interesting note logical rapid cache performs quite time 
reason logical cache disk space distributed data disks traffic caused log writing seen individual data disk relatively low 
addition large read caches systems dram inexpensive 
large read caches significantly reduce disk read traffic seen data disks reducing possibility bandwidth conflicts 
emc tel physical rapid cache performs better logical rapid cache 
physical rapid cache performs better logical rapid cache high workload near saturation point 
particular trace physical rapid cache shows slightly higher response times logical rapid cache baseline system low workloads 
attributed extreme burstiness cello news traces artificially reduced inter burst periods 
artificially reduced length long inter burst idle periods ms stress rapid cache system large bursts arrive closely overflowing small mb backup nvram rapid cache 
result contents backup nvram rapid cache log written cache disk times large burst 
may create waiting queue front physical cache disk resulting slightly increased write response time slightly increased average response time 
logical rapid caches log write traffic distributed multiple disks queuing effect log writing negligible workload low 
believe slightly increased write response time physical rapid caches highly bursty workload major performance concern 
main performance metric throughput 
long cache disk sufficient bandwidth keep write traffic long run discuss performance cache disk section throughput entire system equilibrium state limited primary cache backup cache 
low cost budget rapid cache larger primary cache achieve higher throughput lower response time baseline system 
example shown backup cache configuration increasing size primary write cache rapid cache mb mb doubles throughput reduces response time 
performance synthetic traces synthetic traces higher rates scaled systems increasing number disks raid systems read cache size mb mb 
figures compare performance rapid caches conventional caches 
figures top sub plots show average response times plotted functions request rates throughput 
clear simulation results maximum throughputs physical rapid caches identical baseline systems 
logical rapid caches perform 
performance similar close baseline systems 
response time vs throughput curves rapid caches baseline systems completely overlapped time 
easier compare sub plots figures show relative differences response times vs throughput saturation points data saturation points meaningless systems workable state 
sub plots show response times physical rapid caches similar baseline system time 
worst case occurs synthetic trace high load physical rapid caches response times higher baseline systems 
logical rapid caches slightly response time ms read cache mb write cache mb baseline physical rapid logical rapid throughput requests second relative response time differences read cache mb write cache mb logical rapid vs baseline physical rapid vs baseline throughput requests sec response time ms read cache mb write cache mb baseline physical rapid logical rapid baseline physical rapid throughput requests second relative response time differences read cache mb write cache mb logical rapid vs baseline physical rapid vs baseline throughput requests sec response time ms read cache mb write cache mb baseline physical rapid logical rapid baseline physical rapid throughput requests second relative response time differences read cache mb write cache mb logical rapid vs baseline physical rapid vs baseline throughput requests sec performance relative response time difference trace synthetic higher response time higher baseline systems 
discussed subsection increased response times major concern important performance metrics throughput 
interesting note read dominated traces synthetic performance degrades gracefully workload increases write dominated traces synthetic synthetic figures performance changes relatively abruptly 
workload increases read response times increase rapidly increased disk traffic write response times increase gradually fast write technique 
write dominated traces average response time largely determined write response time average response times increase gradually system write cache saturates 
point average response times increase abruptly 
performance impacts backup cache obtain better picture backup cache affects system performance subsection study effects backup nvram size maximum throughput backup caches 
response time ms read cache mb write cache mb baseline physical rapid logical rapid baseline physical rapid logical rapid throughput requests second relative response time differences read cache mb write cache mb logical rapid vs baseline physical rapid vs baseline throughput requests sec response time ms read cache mb write cache mb baseline physical rapid logical rapid baseline physical rapid logical rapid throughput requests second relative response time differences read cache mb write cache mb logical rapid vs baseline physical rapid vs baseline throughput requests sec response time ms read cache mb write cache mb baseline physical rapid logical rapid baseline physical rapid throughput requests second relative response time differences read cache mb write cache mb logical rapid vs baseline physical rapid vs baseline throughput requests sec performance relative response time difference trace synthetic effects backup nvram size study effect backup nvram size system performance varied backup nvram size re ran simulation experiments 
shows performance physical rapid caches different backup nvram sizes mb mb mb compares baseline system 
see request rates low sizes perform equally 
performance mb case degrades high workloads 
limited backup nvram size case system may run segment buffers previous log writes pending 
result write request evict block backup lru cache segment buffer wait log write finishes segment buffer freed 
causes high response times low throughput 
increase backup cache size mb system runs segment buffers 
able obtain nearly equivalent write performance baseline system 
demonstrated fact response time vs curve physical rapid cache baseline system completely overlapped difficult tell line corresponds system 
similar results observed traces configurations 
response time ms read cache mb write cache mb baseline physical rapid logical rapid throughput requests second relative response time differences read cache mb write cache mb logical rapid vs baseline physical rapid vs baseline throughput requests sec response time ms read cache mb write cache mb baseline physical rapid logical rapid throughput requests second relative response time differences read cache mb write cache mb logical rapid vs baseline physical rapid vs baseline throughput requests sec response time ms read cache mb write cache mb baseline physical rapid logical rapid throughput requests second relative response time differences read cache mb write cache mb logical rapid vs baseline physical rapid vs baseline throughput requests sec performance relative response time difference trace synthetic maximum throughput backup cache rapid cache primary cache backup cache may affect performance 
goal rapid cache provide low cost backup cache matches write performance primary cache want backup cache potential performance bottleneck 
subsection try isolate backup cache rest system study performance limitations 
basically assume near perfect primary cache larger working set workload 
system performance limited backup cache 
note study case dedicated cache disk 
logical cache disk difficult isolate interaction log writes normal data reads writes currently studying ways evaluate performance limits logical cache disks 
constructed new trace called synthetic purpose 
trace contains write requests interested performance backup cache write 
shown trace working set mb 
cache larger mb absorb requests eliminating traffic data disks 
chose primary cache consisting mb read cache mb write cache larger working set trace 
nvram backup cache mb 
addition default segment size kb larger segment size kb study effect larger segments 
shows simulation results 
case kb segment size maximum throughput response time ms read cache mb write cache mb baseline physical rapid mb physical rapid mb physical rapid mb baseline physical rapid mb physical rapid mb throughput requests second effects backup nvram sizes trace synthetic backup cache write requests second 
pure write trace backup cache kb segment size higher throughput write requests second larger segments utilizes disk bandwidth efficiently 
read dominated traces noticeable performance difference cases kb kb segment sizes 
notice maximum throughput requests second pure write trace 
hand transaction processing workloads read dominated 
workload contains reads writes write throughput requests second translate read write throughput requests second read traffic consume backup cache bandwidth 
possible ways improve performance physical rapid cache high workloads 
faster disk higher read channel bandwidth 
new disk drives offer higher bandwidth simulations 

multiple physical cache disks obtain higher aggregated bandwidth 
example simulation physical cache disk data disks 
easily double cache disk bandwidth physical cache disks 
raid products contain spare disks multiple spare disks multiple cache disks free 
disk costs hundreds dollars 
compared expensive nvram rapid cache physical low cost solution extra dedicated cache disk free spare disk 
ratio cache size mb ratios vs cache sizes trace synthetic 
low cost solution combines physical cache disk logical cache disk 
scheme logs normally written dedicated cache disk log writes affect read performance 
load high dedicated cache disk saturates controller distributes part log write traffic logical cache distributed data disks resulting higher combined log writing bandwidth 
reliability costs reliability model subsection analyze reliability cache system exponentially distributed failures repairs ram disks 
consider different cache configurations rapid cache nvram primary cache rapid cache dram primary cache single nvram cache dual nvram caches 
consider rapid cache nvram primary cache 
assume primary cache consists number nvram memory modules 
represent mean time failure nvram module mean time failure disk respectively 
case failure repair process start replacing failed memory module failed disk 
reasonable assume mean repair time ram disk denoted 
recall write operation rapid cache performed primary cache backup cache 
memory module primary cache fails response time ms read cache mb write cache mb kb segment size kb segment size throughput requests second maximum throughput backup cache trace synthetic data lost component containing data copy backup cache fails repair failed module done 
similarly component backup cache fails data lost copy primary cache fails repair 
size terms memory modules primary cache size nvram backup cache respectively 
mean failure rate caused primary cache failure failure nvram backup cache mean failure rate caused primary cache failure disk failure probability mirror copy primary cache data resides nvram backup cache probability mirror copy resides disk backup cache mean failure rate entire cache system 
reduces mean time data loss rapid cache system nvram primary cache mentioned previously nvram orders magnitude expensive regular dram 
new rapid cache architecture possible implement primary cache dram nvram 
dram primary write cache hand may compromise reliability cache 
addition ram failures data may get lost due reasons power failure hardware failures cpu failures environment failures cope frequent power failures systems ups prevent data loss sudden power failures 
case data loss occurs dram power fails ups fails 
hardware failure cpu failure occurs replacing failed hardware usually requires system shutdown 
result data dram lost recovered backup cache 
data failure rate backup cache 
mean time power failure mean time failure ups mean time hardware failure respectively 
assume mean time repair types failures 
mean failure rate mean time data loss rapid cache dram primary cache reliability analysis cache architectures straightforward 
single nvram cache case mean time data loss simply 
mean time data loss dual nvram case reliability costs comparison important factor determines reliability write cache mean time failure nvram 
unfortunately remarkably little data available literature data sheets various ram products 
savage wilkes cited hours data retention lifetimes integral lithium cell backed static ram extremely expensive hours predicted mttf popular card :10.1.1.17.2863
lack published data mttf assume optimistically mttf ram hours favors conventional nvram cache architectures represents conservative evaluation rapid cache 
analysis assumes nvram cache consists number mb modules 
existing disk systems raids storage computer independent modules constitute write cache 
power failures ups failure source possible data loss dram 
assume systems considered backed ups systems 
chose mean time power failure hours mttf ups hours analysis :10.1.1.17.2863
mean time hardware failures environment failures assumed month hours 
mttf disks assumed hours 
mean time repair types failures assumed hours 
cost figures semiconductor devices disks change rapidly 
difficult give accurate date cost evaluation 
order give general idea cost different cache architectures cache sizes reliability hours cost dollars read write single dual copy rapid rapid single dual copy rapid rapid mb mb nvram nvram cache dp cache np nvram nvram cache dp cache np table reliability costs comparison different write cache architectures 
size nvram buffer rapid cache mb 
note rapid cache dp refers rapid cache dram primary write cache 
rapid cache np refers rapid cache nvram primary write cache 
cache sizes logical rapid cache baseline physical rapid cache read write max 
throughput req sec 
max 
throughput req sec 
mb synthetic synthetic synthetic synthetic synthetic synthetic table performance different cache architectures synthetic traces assumptions 
cost dram mb cost nvram mb quoted major nvram manufacturer december 
cost disk space cents mb 
logical cache disk quite reasonable cost number cache space logical located partitions data disks 
case physical cache disk cache space located partition hot standby disk explained previously 
reasonable mb cost additional disk drive needed 
spare disk available raid dedicated cache disk required add cost additional minimum size disk drive available market 
table lists reliability cost comparison baseline cache rapid cache typical configurations 
easy comparison summarize performance different cache architectures different traces table 
clear table difference baseline cache rapid cache terms reliability cost significant 
compared single copy nvram write cache reliability rapid cache nvram write cache orders magnitudes higher baseline cache system additional cost introduced rapid cache 
compared dual copy nvram caches rapid caches nvram primary cache higher reliability baseline cache system disks reliable nvram approximately half cost 
rapid cache dram write primary cache reliability orders magnitude better single copy nvram cache 
importantly cost rapid cache dramatically lower single copy nvram caches dual copy nvram caches 
cases cost rapid cache single copy nvram caches dual copy nvram caches 
words rapid cache comes free provide similar reliability baseline cache costing dollars provide 
rapid cache larger primary cache improve performance maintaining low cost 
example rapid cache mb dram read cache mb dram write cache costs 
provides times higher throughput orders magnitude better reliability single copy nvram write cache mb costs 
pointed cost figures semiconductor devices disks change rapidly 
past years costs dram disk dropped times 
cost nvram contrary dropped 
trend continue 
result cost difference schemes traditional nvram cache systems increase 
systems larger larger write caches accommodate increasing demands 
larger caches bigger savings scheme provide 
related ng chen proposed rio ram io implement reliable ram 
rio software system ram survive operating system crashes 
goals rapid caches rios different 
rapid caches hardware tolerate hardware failures power outages software crashes 
rio focus surviving software crashes 
idea disk log improve system performance improve reliability ram file systems database systems long time 
example log structured file system lfs journal file system jfs similar systems disk data metadata logging improve file system performance speed crash recovery :10.1.1.26.8749:10.1.1.117.5365
database systems long elaborate logging techniques improve reliability ram buffer implement transaction semantics 
nvram database systems reduce overhead logging 
raid systems implemented lfs algorithm raid controller level :10.1.1.119.6793
lfs collects writes ram buffer form large logs writes large logs data disks 
lfs demonstrated superior performance workloads studies shown garbage collection overhead lfs major performance bottleneck transaction processing environments decreasing system performance :10.1.1.1.8150:10.1.1.1.8150
garbage collection overhead high disk utilization reaches total disk capacity 
disk caching disks dcd proposed shows possible implement large non volatile write cache inexpensively :10.1.1.119.6793
dcd uses small nvram cache small cache disk form level cache 
write data assembled small nvram cache logged cache disk 
data cache disk data disk idle periods 
level hierarchical structure acts large non volatile cache cost lower large nvram cache 
dcd excellent performance low medium traffic workloads directly applying dcd high workloads may face problems 
dcd requires involves reading dirty data cache disk writing data disk 
process may performance bottleneck high loads reads log writes compete cache disk bandwidth 
read speed dcd slow data may read cache disk 
envy large nonvolatile main memory storage system flash :10.1.1.17.2863
flash disk characteristics data erased blocks write speed slow 
envy solved write problem battery backed sram front flash 
data written sram transferred flash large blocks 
system appears users large high speed nvram 
idea rapid cache inspired previous research especially lfs dcd important differences highlighted 
lfs dcd address reliability problem single copy caches 
lfs dcd data collected ram buffer logged disks buffer full 
backup cache rapid cache data written lru cache nvram 
active data may overwritten lru cache frequently 
inactive data evicted lru cache collected segment buffer logged cache disk 
separation active data inactive data significantly reduces cache disk traffic garbage collection cost 
dcd data cache disk data disk may performance bottleneck high workloads 
rapid cache need read cache disk dirty data accessed primary cache 
overhead rapid cache conventional system single copy dual copy nvram write cache 
lfs needs garbage collection significantly limits system performance cases 
asymmetrically parallel architecture rapid cache separation active data inactive data backup cache enable design garbage collection algorithm efficient lfs 
rapid cache seldom requires garbage collection 
fact garbage collection overhead rapid cache low virtually impact system performance 
nvram caches significantly improve write performance disk systems 
high cost nvram disk systems cost nvram caches higher disks dominates system cost 
addition single copy nvram cache creates single point failure highly reliable disk system dual copy nvram cache expensive 
new disk cache architecture called rapid cache 
rapid caches systems particularly useful improving performance reliability large parallel disk systems raids 
main feature rapid cache asymmetrically parallel architecture consists fast write fast read primary cache inexpensive fast write slow read hierarchical backup cache 
trade read performance backup cache economy reliability 
fortunately compromise read performance backup cache affect system performance way read operations backup cache necessary error recovery periods 
hand economy reliability performance gained shown dramatic 
win win trading possible exploiting locality disk accesses efficiency large disk transfers 
shown simulation experiments analysis possible configure rapid cache number ways optimize throughput reliability system cost compared single copy nvram cache rapid cache dram primary cache higher reliability similar performance fraction cost 
compared single copy nvram cache rapid cache nvram primary cache better reliability similar performance slightly higher cost 
compared dual copy nvram cache rapid cache nvram primary cache similar better reliability similar performance half cost 
low cost budget rapid caches significantly higher performance compared conventional nvram cache architectures affording larger primary cache size maintaining reliability 
asymmetrically parallel architecture rapid caches algorithm separates active data inactive data virtually eliminate garbage collection overhead major problems associated previous solutions lfs dcd 
furthermore dram primary cache economically feasible combine read cache write cache resulting unified cache significant performance advantages 
unified cache expensive implement existing dual copy cache architectures requirement large read cache nvram combined write cache 
results unified rapid cache space limitation simulation results show unified rapid cache achieve times higher throughput split cache total cache size 
low cost feature rapid cache possible large primary cache achieve high performance high systems 
wide range disk systems benefit rapid cache architecture 
acknowledgments research supported part national science foundation mip mip national science foundation career award ccr ohio board computer science collaboration 
dr david kotz dartmouth college letting disk simulator 
hp laboratories emc providing disk traces 
benefited discussions dr chung lo university rhode island reliability issues nvram 
algorithms synthetic trace generator initially designed qi zhang 
hu yang rapid cache reliable inexpensive write cache disk systems proceedings th international symposium high performance computer architecture hpca orlando florida jan :10.1.1.125.4512
menon architecture fault tolerant cached raid controller proceedings th annual international symposium computer architecture san diego california pp 
may 
treiber menon simulation study cached raid designs proceedings int symposium high performance computer architectures raleigh north carolina pp 
jan 
chen lee gibson katz patterson raid high performance reliable secondary storage acm computing surveys vol 
pp 
june 
varma jacobson algorithms disk arrays non volatile caches proceedings nd annual international symposium computer architecture santa margherita ligure italy pp 
june 
ruemmler wilkes unix disk access patterns proceedings winter usenix san diego ca pp 
jan 
savage wilkes afraid frequently redundant array independent disks proceedings usenix technical conference san diego ca jan :10.1.1.17.2863
wu zwaenepoel envy non volatile main memory storage system proceedings th symposium architectural support programming languages operating systems pp :10.1.1.17.2863
oct 
salem management partially safe buffers ieee transactions computers vol 
pp 
mar 
coombs drawing new raid roadmap data storage vol 
pp 
dec 
ousterhout douglis beating bottleneck case log structured file systems tech 
rep computer science division electrical engineering computer sciences university california berkeley oct 
rosenblum ousterhout design implementation log structured file system acm transactions computer systems pp 
feb 
seltzer bostic mckusick staelin implementation log structured file system unix proceedings winter usenix san diego ca pp 
jan 
holland ii gibson parity logging disk arrays acm transactions computer systems pp 
aug 
smith disk caching large databases systems tech 
rep csd computer science division university california berkeley sept 
hu yang dcd disk caching disk new approach boosting performance proceedings rd international symposium computer architecture isca philadelphia pennsylvania pp :10.1.1.119.6793
may 
wilkes golding staelin sullivan hp autoraid hierarchical storage system acm transactions computer systems vol :10.1.1.119.6793
pp 
feb 
kotz toh radhakrishnan detailed simulation model hp disk drive tech 
rep pcs tr department computer science dartmouth college july 
ruemmler wilkes disk drive modeling ieee computer pp 
mar 
ganger generating representative synthetic workloads unsolved problem proceedings computer measurement group cmg conference pp :10.1.1.111.8732
dec 
dallas semiconductor ds ab nonvolatile sram data sheet gibson patterson designing disk arrays high data reliability journal parallel distributed computing vol 
pp 
jan feb 
ng chen design verification rio file cache ieee transactions computers vol 
pp 
apr 
ng chen integrating reliable memory databases proceedings international conference large data bases vldb pp 
aug 
menon performance comparison raid log structured arrays proceedings fourth ieee international symposium high performance distributed computing pp 
aug 
seltzer smith balakrishnan chang padmanabhan file system logging versus clustering performance comparison proceedings usenix new orleans la pp 
jan 

