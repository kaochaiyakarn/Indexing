minimum cut model spoken lecture segmentation igor regina barzilay computer science artificial intelligence laboratory massachusetts institute technology regina csail mit edu consider task unsupervised lecture segmentation 
formalize segmentation graph partitioning task optimizes normalized cut criterion 
approach moves localized comparisons takes account longrange cohesion dependencies 
results demonstrate global analysis improves segmentation accuracy robust presence speech recognition errors 
development computational models text structure central concern natural language processing 
text segmentation important instance 
task partition text linear sequence topically coherent segments induce content structure text 
applications derived representation broad encompassing information retrieval question answering summarization 
surprisingly text segmentation extensively investigated decade 
unsupervised segmentation approach hearst algorithms assume variations lexical distribution indicate topic changes 
documents exhibit sharp variations lexical distribution algorithms detect segment boundaries accurately 
example algorithms achieve high performance synthetic collections generated concatenation random text blocks choi 
difficulty arises transitions topics smooth distributional variations subtle 
evident performance existing unsupervised algorithms structured datasets spoken meeting transcripts galley 
refined analysis lexical distribution needed 
addresses challenge casting text segmentation graph theoretic framework 
text weighted undirected graph nodes graph correspond sentences edge weights represent pairwise sentence similarity 
framework text segmentation corresponds graph partitioning optimizes normalized cut criterion shi malik 
criterion measures similarity partition dissimilarity different partitions 
approach moves localized comparisons takes account long range changes lexical distribution 
key hypothesis global analysis yields accurate segmentation results local models 
tested algorithm corpus spoken lectures 
segmentation domain challenging respects 
structured written text lecture material exhibits disfluencies artifacts spontaneous communication 
addition output speech recognizers fraught high word error rates due specialized technical vocabulary lack domain spoken data training 
pedagogical considerations call fluent transitions different topics lecture complicating segmentation task 
experimental results confirm hypothesis considering long distance lexical dependencies yields substantial gains segmentation performance 
graph theoretic approach compares favorably state art segmentation algorithms attains results close range human agreement scores 
attractive prop proceedings st international conference computational linguistics th annual meeting acl pages sydney july 
association computational linguistics erty algorithm robustness noise accuracy algorithm deteriorate significantly applied speech recognition output 
previous unsupervised algorithms assume fragments text homogeneous lexical distribution correspond topically coherent segments 
previous research analyzed various facets lexical distribution including lexical weighting similarity computation smoothing hearst choi reynar kehagias ji zha 
focus orthogonal fundamental aspect analysis impact long range cohesion dependencies segmentation performance 
contrast previous approaches homogeneity segment determined similarity words relation words segments text 
show optimizing global objective enables detect subtle topical changes 
graph theoretic approaches vision segmentation inspired minimum segmentation algorithms developed image analysis 
shi malik introduced normalized cut criterion demonstrated practical benefits segmenting static images 
method simple application existing approach new task 
order new linguistic framework redefine underlying representation introduce variety smoothing lexical weighting techniques 
second computational techniques finding optimal partitioning quite different 
minimization normalized cut np complete general case researchers vision approximate computation 
fortunately find exact solution due linearity constraint text segmentation 
minimum cut framework linguistic research shown word repetition particular section text device creating thematic cohesion halliday hasan changes lexical distributions usually signal topic transitions 
sentence similarity plot physics lecture vertical lines indicating true segment boundaries 
illustrates properties lecture transcript undergraduate physics class 
text representation church plot cosine similarity scores pair sentences text 
intensity point plot indicates degree th sentence text similar th sentence 
true segment boundaries denoted vertical lines 
similarity plot reveals block structure true boundaries delimit blocks text high inter sentential similarity 
sentences different blocks hand tend exhibit low similarity 
graph representation text formalizing objective previous unsupervised approaches segmentation intuitive notions similarity density formalize objective text segmentation cuts graphs 
aim jointly maximize intra segmental similarity minimize similarity different segments 
words want find segmentation maximally homogeneous set segments maxi mally different 
undirected weighted graph set nodes corresponding sentences text set weighted edges see 
edge weights define measure similarity pairs nodes higher scores indicate higher similarity 
section provides details graph construction 
consider problem partitioning graph disjoint sets nodes aim minimize cut defined sum crossing edges sets nodes 
words want split sentences maximally dissimilar classes choosing minimize cut need ensure partitions maximally different homogeneous accounting intra partition node similarity 
formulate requirement framework normalized cuts shi malik cut value normalized volume corresponding partitions 
volume partition sum edges graph vol normalized cut criterion ncut defined follows ncut cut vol cut vol minimizing objective simultaneously minimize similarity partitions maximize similarity partitions 
formulation allows decompose objective sum individual terms formulate dynamic programming solution multiway cut problem 
criterion naturally extended way normalized cut cut vol 
cut ak ak vol ak 
ak form partition graph ak set difference entire graph partition decoding papadimitriou proved problem minimizing normalized cuts graphs np complete shi malik 
case multi way cut constrained preserve linearity segmentation 
segmentation linearity mean nodes leftmost rightmost nodes particular partition belong partition 
constraint formulate dynamic programming algorithm exactly finding minimum normalized multiway cut polynomial time min argmin cut aj aj vol aj cut aj aj vol aj normalized cut value optimal segmentation sentences segments 
th segment aj begins node uj ends node uk 
back pointer table recover optimal sequence segment boundaries 
equations capture respectively condition normalized cut value trivial segmentation empty text segment zero constraint segment starts node 
time complexity dynamic programming algorithm kn number partitions number nodes graph sentences transcript 
building graph clearly performance model depends underlying representation definition pairwise similarity function various model parameters 
section provide details graph construction process 
preprocessing building graph apply standard text preprocessing techniques text 
stem words porter stemmer porter alleviate sparsity word counts stem equivalence classes 
remove words matching prespecified list words 
graph topology noted previous section normalized cut criterion considers long term similarity relationships nodes 
effect achieved constructing graph 
considering pairwise relations long text may detrimental segmentation accuracy 
discard edges sentences exceeding certain threshold distance 
reduction graph size provides computational savings 
similarity computation computing pairwise sentence similarities sentences represented vectors word counts 
cosine similarity commonly text segmentation hearst 
avoid numerical precision issues summing series small scores compute exponentiated cosine similarity scores pairs sentence vectors si sj si sj si sj refine analysis smoothing similarity metric 
comparing sentences take account similarity immediate neighborhoods 
smoothing achieved adding counts words occur adjoining sentences current sentence feature vector 
counts weighted accordance distance current sentence si sj si vectors word counts parameter controls degree smoothing 
formulation sentences nodes 
represent graph nodes non overlapping blocks words fixed length 
desirable lecture transcripts lack sentence boundary markers short utterances skew cosine similarity scores 
optimal length block tuned heldout development set 
lexical weighting previous research shown weighting schemes play important role segmentation performance ji zha choi 
particular concern words may common general english discourse occur text particular lecture subject 
example lecture support vector machines occurrence term svm going convey lot information distribution segments total word asr wer corpus lectures lecture tokens accuracy physics ai table lecture corpus statistics sub topics fairly rare term general english bears semantic content 
words convey varying degrees information different lectures term weighting specific individual lectures important similarity computation 
order address issue introduce variation tf idf scoring scheme information retrieval literature salton buckley 
transcript split uniformly chunks chunk serves equivalent documents tf idf computation 
weights computed separately transcript topic word distributions vary lectures 
evaluation set section different corpora evaluate model provide brief overview evaluation metrics 
describe human segmentation study corpus spoken lecture data 
parameter estimation heldout development set lectures estimating optimal word block length representing nodes threshold distances discarding node edges number uniform chunks estimating tf idf lexical weights alpha parameter smoothing length smoothing window 
simple greedy search procedure optimizing parameters 
corpora evaluate segmentation algorithm sets data 
datasets new segmentation collections compiled study remaining set includes standard collection previously evaluation segmentation algorithms 
various corpus statistics new datasets table 
briefly describe corpus 
physics lectures corpus consists spoken lecture transcripts undergraduate materials publicly available www 
csail mit edu acl html physics class 
contrast segmentation datasets corpus contains longer texts 
typical lecture minutes sentences words corresponds pages raw text 
access manual transcriptions lectures output automatic speech recognition system 
word error rate representative state art performance lecture material 
physics lecture transcript segmentations produced teaching staff introductory physics course massachusetts institute technology 
objective facilitate access lecture recordings available class website 
segmentation conveys high level topical structure lectures 
average lecture annotated segments typical segment corresponds pages transcript 
artificial intelligence lectures second lecture corpus differs subject matter style segmentation granularity 
graduate artificial intelligence class average twelve segments lecture typical segment half page 
segment roughly corresponds content slide 
time segmentation obtained lecturer 
lecturer went transcripts lecture recordings segmented lectures objective making segments correspond presentation slides lectures 
due low recording quality unable obtain asr transcripts class 
manual transcriptions lectures 
synthetic corpus part analysis synthetic corpus created choi commonly evaluation segmentation algorithms 
corpus consists set concatenated segments randomly sampled brown corpus 
length segments corpus ranges eleven sentences 
important note lexical transitions concatenated texts sharp segments come texts written widely varying language styles completely different topics 
speaker dependent model lecturer trained hours lectures courses sum mit segment speech recognizer glass 
evaluation metric pk measures evaluate system beeferman pevzner hearst 
pk measure estimates probability randomly chosen pair words window length words inconsistently classified 
metric variant pk measure penalizes false positives equal basis near misses 
metrics defined respect average segment length texts exhibit high variability real data 
follow choi compute mean segment length determining parameter text separately 
plot receiver operating characteristic roc curve gauge performance finer level discrimination swets 
roc plot plot true positive rate false positive rate various settings decision criterion 
case true positive rate fraction boundaries correctly classified false positive rate fraction non boundary positions incorrectly classified boundaries 
computing true false positive rates vary threshold distance true boundary hypothesized boundary considered correct 
larger areas roc curve classifier indicate better discriminative performance 
human segmentation study spoken lectures different style corpora human segmentation studies hearst galley 
interested analyzing human performance corpus lecture transcripts longer texts clear cut concept sub topic 
define segment sub topic signals prominent shift subject matter 
disregarding sub topic change impair high level understanding structure content lecture 
part human segmentation analysis asked annotators segment physics lecture corpus 
annotators taken class past familiar subject matter consideration 
wrote detailed instruction manual task annotation guidelines part model 

annotators instructed segment level granularity mean seg 
count mean seg 
length seg 
length dev 
table annotator segmentation statistics physics lectures 
ref hyp table pk annotation agreement different pairs annotators 
identify prominent topical transitions necessary summary lecture 
annotators annotation software toolkit developed meeting segmentation 
provided recorded audio lectures corresponding text transcriptions 
intentionally provide subjects target number boundaries wanted see annotators converge common segmentation granularity 
table presents annotator segmentation statistics 
see classes segmentation granularities 
original annotator segmented coarse level average segments lecture respectively 
annotators operated finer levels discrimination segments lecture average 
conclude multiple levels granularity acceptable spoken lecture segmentation 
expected length lectures varying human judgments selecting relevant topical content 
previous studies quantify level annotator agreement pk measure 
table shows annotator agreement scores different pairs annotators 
pk measures ranged 
observe greater consistency similar levels granularity kappa measure appropriate measure case sensitive near misses required independence assumption placement boundaries 
edge cutoff physics manual pk wd physics asr pk wd ai pk wd choi pk wd table edges nodes separated certain threshold distance removed 
classes 
note annotator operated level granularity consistent original segmentation 
pk measure score serves benchmark compare results attained segmentation algorithms physics lecture data 
additional point note uniform random baseline segmentations attain pk measure respectively physics lecture set 
experimental results true positive rate cutoff cutoff false positive rate roc plot minimum cut segmenter physics lectures edge cutoffs set sentences 
benefits global analysis determine impact long range pairwise similarity dependencies segmentation performance 
choi ui mincut physics manual pk wd physics asr transcripts pk wd ai pk wd choi pk wd table performance analysis different algorithms pk measures lectures heldout development 
key hypothesis considering long distance lexical relations contributes effectiveness algorithm 
test hypothesis discard edges nodes certain number sentences apart 
test system range data sets including physics ai lectures synthetic corpus created choi 
include segmentation results physics asr transcripts 
results table confirm hypothesis account non local lexical dependencies helps different domains 
manually transcribed physics lecture data example algorithm yields pk measure account edges separated sentences 
dependencies sentences considered algorithm yields reduction pk measure 
shows roc plot segmentation physics lecture data different cutoff parameters demonstrating clear gains attained employing longrange dependencies 
table shows improvement consistent lecture datasets 
note point increasing threshold degrades performance introduces spurious dependencies see column table 
speaker occasionally return topic described lecture bias algorithm put segment boundary closer lecture 
long range dependencies improve performance synthetic dataset 
expected segments synthetic dataset randomly selected widely varying documents brown corpus spanning different genres written language 
effectively genuine long range dependencies exploited algorithm 
comparison local dependency models compare system state art similarity segmentation system developed choi 
publicly available implementation system optimize system range mask sizes different parameter settings described choi heldout development set lectures 
control segmentation granularity specify number segments segmentation system baseline 
table shows minimum cut algorithm consistently outperforms similarity baseline lecture datasets 
attribute gain presence attenuated topic transitions spoken language 
spoken language spontaneous structured written language speaker needs keep listener changes topic content introducing subtle cues prior topics course topical transitions 
non local dependencies help elucidate shifts focus strength particular transition measured respect local long distance contextual discourse relationships 
system outperform choi algorithm synthetic data 
attributed discrepancy distributional properties synthetic corpus lacks coherence thematic shifts lecture corpus spontaneous speech smooth distributional variations 
note try adjust model optimize performance synthetic data 
smoothing method developed lecture segmentation may appropriate short segments ranging eleven sentences constitute synthetic set 
compared method state art algorithm explicitly rely pairwise similarity analysis 
algorithm ui computes optimal segmentation estimating changes language model predictions different partitions 
publicly available implemen tation system require parameter tuning heldout development set 
method achieves favorable performance range lecture data sets see table algorithms attain results close range human agreement scores 
attractive feature algorithm robustness recognition errors testing asr transcripts caused relative increase pk measure compared relative increase ui system 
attribute feature fact model dependent individual recognition errors detrimental effect local segment language modeling probability estimates ui system 
block level similarity function sensitive individual word errors partition volume normalization factor effect derived models 
studied impact long range dependencies accuracy text segmentation 
modeled text segmentation task aiming simultaneously optimize total similarity segment dissimilarity various segments 
showed global analysis lexical distribution improves segmentation accuracy robust presence recognition errors 
combining global analysis advanced methods smoothing ji zha weighting boost segmentation performance 
current implementation automatically determine granularity resulting segmentation 
issue explored past ji zha explore existing strategies framework 
believe algorithm produce segmentations various levels granularity depending needs application employs 
ultimate goal automatically generate tables content lectures 
plan investigate strategies generating titles succinctly describe content segment 
explore interaction generation segmentation components improve performance system 
authors acknowledge support national science foundation career iis iis nsf graduate fellowship 
opinions findings recommendations expressed publication author necessarily reflect views national science foundation 
providing implementation segmentation system alex assisting toolkit 
grateful david karger illuminating discussion minimum cut algorithm 
acknowledge mit nlp speech groups annotators anonymous reviewers valuable comments suggestions help 
beeferman berger lafferty 

statistical models text segmentation 
machine learning 
choi wiemer hastings moore 

latent semantic analysis text segmentation 
proceedings emnlp 
choi 

advances domain independent linear text segmentation 
proceedings naacl 
church 

char align program aligning parallel texts character level 
proceedings acl 
galley mckeown jing 

discourse segmentation multi party conversation 
proceedings acl 
glass 

probabilistic framework speech recognition 
computer speech language 


meeting structure annotation data tools 
proceedings workshop discourse dialogue 
halliday hasan 

cohesion english 
longman london 
hearst 

multi paragraph segmentation expository text 
proceedings acl 
ji zha 

domain independent text segmentation anisotropic diffusion dynamic programming 
proceedings sigir 
kehagias petridis 

linear text segmentation dynamic programming algorithm 
proceedings eacl 
federico 

language modeling transcription ted corpus lectures 
proceedings icassp 
pevzner hearst 

critique improvement evaluation metric text segmentation 
computational linguistics pp 

porter 

algorithm suffix stripping 
program 
reynar 

topic segmentation algorithms applications 
ph thesis university pennsylvania 
salton buckley 

term weighting approaches automatic text retrieval 
information processing management 
shi malik 

normalized cuts image segmentation 
ieee transactions pattern analysis machine intelligence 
swets 

measuring accuracy diagnostic systems 
science 


statistical model domain independent text segmentation 
proceedings acl 
