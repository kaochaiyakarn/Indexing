mapping loops recon gurable architectures viktor prasanna department electrical engineering systems university southern california los angeles ca usa usc edu usc edu 
recon gurable circuits systems evolved application speci accelerators general purpose computing paradigm 
algorithmic techniques software tools heavily hardware paradigm evolved 
loop statements traditional programs consist regular repetitive computations candidates performance enhancement con gurable hardware 
develops formal methodology mapping loops recon gurable architectures 
develop parameterized model recon gurable architectures general capture wide range con gurable systems 
model de ne solve problem mapping loop statements recon gurable architectures 
show polynomial time algorithm compute optimal sequence con gurations important variant problem 
illustrate approach showing mapping example loop statement 
con gurable systems evolving systems designed accelerate speci application systems achieve high performance general purpose computing 
various recon gurable architectures explored research groups develop general purpose con gurable system 
recon gurable architectures vary systems fpgas glue logic attached host computer systems include con gurable logic die microprocessor 
application development con gurable hardware necessitates expertise low level hardware details 
developer aware intricacies speci recon gurable architecture achieve high performance 
automatic mapping tools evolved high level synthesis tools 
tools try generate hardware con gurations user provided descriptions circuits various input formats vhdl occam variants 
supported darpa adaptive computing systems program contract dabt monitored fort 
automatic compilation applications involves con guration generation con guration management 
code environment aims provide operating system applications paradigm 
general techniques developed exploit characteristics devices partial dynamic recon guration concepts dynamic circuit switching virtual pipelines framework abstracts characteristics con gurable hardware uni ed methodology mapping applications con gurable hardware 
address issues development automatic compilation applications 
develop algorithmic techniques mapping applications platform independent fashion 
develop model recon gurable architectures 
parameterized model general capture wide range con gurable systems 
include board level systems fpgas con gurable computing logic systems chip con gurable logic arrays die microprocessor 
con gurable logic ective speeding regular repetitive computations 
loop constructs general purpose programs class computations 
address problem mapping loop construct con gurable architectures 
de ne problems model address issue minimizing recon guration overheads scheduling con gurations 
polynomial time solution generating optimal con guration sequence important variant mapping problem 
mapping techniques utilized analyze application tasks develop choice con gurations schedule recon gurations 
parameters architecture applications tasks techniques statically compile time determine optimal mapping 
techniques utilized runtime mapping making static compile time analysis 
analysis runtime decision parameters known runtime 
section describes hybrid system architecture model detail 
loop mapping problems de ned optimal solution important variant section 
show example mapping section discuss section 
related question mapping structured computation recon gurable architectures addressed researchers 
brie describe related research di erent 
previous addresses related issues pipeline generation loops code framework dynamic circuit simulation virtual pipelines 
projects address similar issues framework developing model solving general mapping problems fully addressed speci 
model parameterized model con gurable computing system consists con gurable logic attached traditional microprocessor 
model utilized analyzing application tasks regards suitability execution con gurable logic developing actual mapping scheduling tasks con gurable system 
rst describe model con gurable architectures discuss components model actual features architectures 
hybrid system architecture model data buffers risc memory configurable logic unit interconnection network configuration cache risc memory data buffers configurable logic unit bus configuration cache fig 

hybrid system architecture example architecture hybrid system architecture general architecture consisting traditional risc microprocessor additional con gurable logic unit clu 
shows architecture model example actual architecture 
architecture consists traditional risc microprocessor standard memory con gurable logic con guration memory data bu ers communicating interconnection network 
outline parameters hybrid system architecture model 
set functions fn performed con gurable logic 
set possible con gurations cm con gurable logic unit 
tij execution time function fi con guration cj 
rij recon guration cost changing con guration ci cj 
nc number con guration contexts stored con guration cache 
recon guration time spent con guring cache external memory respectively 
width depth con gurable logic describe amount con gurable logic available 
granularity con gurable logic width individual functional unit 
schedule con gurations execute input tasks 
execution time sequence tasks sum execution time tasks various con gurations recon guration time 
parameterized outlined model wide range systems board level architectures systems chip 
systems include splash dec perle oxford harp berkeley garp nsc napa 
values parameters establish architecture dictate class applications ectively mapped architecture 
example system chip smaller size con gurable logic lower board level architecture potentially faster recon guration times lower 
model encompass memory access component computation terms memory access delays communication bandwidth supported 
currently assumed interconnection network bandwidth support required data con guration access 
detailed description model parameters see 
loop synthesis known rule thumb execution time program spent code 
code usually consists repeated executions set instructions 
typical constructs specifying iterative computations various programming languages 
generally classi ed loop constructs 
computations operate large set data set operations bene con gurable computing 
loop structures candidates performance improvement con gurable logic 
con gurations execute task generated operations loop 
operation executed dedicated hardware con guration execution time task expected lower software 
operations loop statement bea simple operation addition integers complex operation square root oating point number 
problems solutions independent complexity operation 
linear loop synthesis problem mapping operations tasks loop con gurable system involves generating con gurations operations reducing overheads incurred 
sequence tasks executed mapped sequence con gurations execute tasks 
objective reduce total execution time 
scheduling general sequence tasks set dependencies minimize total execution time known np complete problem 
consider problem generating sequence con gurations loop constructs sequence statements executed linear order 
linear data control dependency tasks 
loop constructs including mapped high performance pipelined con gurations fall class 
total execution time includes time taken execute tasks chosen con gurations time spent recon guring logic successive con gurations 
choose con gurations execute tasks fast reduce recon guration time 
possible choose possible con gurations task execution 
recon guration time depends choice con gurations 
recon guration times signi cant compared task execution times goal minimize overhead 
problem sequence tasks loop tp executed linear order tp ti number iterations nd optimal sequence con gurations cq si fc cmg minimizes execution time cost de ned qx tsi ii tsi execution time con guration si ii recon guration cost rii 
optimal solution loop synthesis input consists sequence statements tp ti number iterations compute execution times tij executing tasks ti con guration cj 
recon guration costs rij pre computed con gurations known 
addition loop setup cost cost loading initial con guration memory access costs accessing required data costs system initiate computation con gurable logic unit 
memory access costs modeled possible statically determine loop setup cost 
simple greedy best con guration task recon guration costs tasks ected choice con guration current task 
search solution space considering possible con gurations task executed 
optimal solution executing task ti computed cost executing task ti incrementally computed 
lemma 
sequence tasks gurations executing tasks computed ino rm time 
optimal sequence proof execution cost de nition de ne optimal cost executing task con guration cj eij 
initialize values possible con gurations execute compute optimal sequence con gurations con guration 
compute recursive equation ei ti mink eik possible ways execute task nished executing values eik optimal value ei op 
compute optimal sequence con gurations comput ing eij values 
complete task sequence 
corresponding optimal con guration sequence computed matrix 
dynamic programming compute eij values 
computation value takes time con gurations 
rm values computed total time complexity iso rm 
lemma provides solution optimal sequence con gurations compute iteration loop statement 
repeating sequence con gurations guaranteed give optimal execution iterations 
shows con guration space tasks possible con gurations 
executed task executed 
edges labeled recon guration costs cost edges con gurations shown high 
see optimal sequence execution iterations sequence repeated times 
repeated sequence optimal solution iteration give optimal solution iterations 
fig 

example recon guration cost graph optimal con guration sequence simple solution fully unroll loop compute optimal sequence con gurations tasks 
complexity algorithm npm number iterations 
typically value high desirable higher value gives higher speedup compared software execution 
assume show optimal con guration sequence computed pm time 
lemma 
optimal con guration sequence computed unrolling loop times 
proof denote optimal sequence con gurations fully unrolled loop cx 
tasks iterations con guration executes executes 
iteration execution con guration cp executes task 
task executed con gurations cp cx 
con gurations task number con gurations cp cx con guration repeat 
cy 
occurrence con guration task cy cz 
subsequence cy identical cy cy cz 
replace subsequence higher iteration cost subsequence lower iteration cost yielding better solution 
contradicts initial assumption con guration sequence optimal 
subsequences identical 
violate correctness execution subsequences executing xed number iterations sequence input tasks 
applying argument complete sequence cx proved subsequences identical 
longest possible length subsequence possible tasks possible con gurations 
subsequence con gurations repeated give optimal con guration sequence tasks 
need unroll loop times 
theorem 
optimal sequence gurations iterations loop statement tasks task executed possible con gurations computed ino pm time 
proof lemma know need unroll loop times compute required sequence con gurations 
solution unrolled sequence tasks computed pm lemma 
sequence repeated give required sequence con gurations iterations 
total complexity iso pm 
complexity algorithm pm better fully unrolling npm factor 
solution number iterations known compile time determined runtime 
decision sequence con gurations execute loop taken runtime statically known loop setup single iteration execution costs runtime determined illustrative example techniques developed evaluated model 
evaluation take input model parameter values applications tasks solve mapping problem output sequence con gurations 
currently building tool show results obtained manual evaluation section 
discrete fourier transform dft important component signal processing systems 
typical implementations fast fourier transform fft compute dft log time 
basic computation unit butter unit inputs outputs 
involves complex multiplication complex addition complex subtraction 
implementations fft fpgas 
computation optimized various ways suit technology achieve high performance 
describe analysis implementation highlight key features mapping technique model 
aim highlight technique mapping sequence operations sequence con gurations 
technique utilized map con gurable architecture 
timing area information garp architecture representative values 
architecture rst determine model parameters 
calculated model parameters published values tabulated table 
set functions con gurations outlined table 
values respectively 
con guration time column gives recon guration values assume recon guration values target con guration irrespective initial con guration 
execution time column gives tij values model 
function operation con guration con guration execution time time multiplication fast ns multiplication slow ns addition ns subtraction ns shift ns table 
representative model parameters garp recon gurable architecture input sequence tasks executed fft butter operation 
butter operation consists complex multiply complex addition complex subtraction 
loop statements decomposed functions executed clu list functions table 
complex multiplication consists multiplications addition subtraction 
complex addition subtraction consist additions subtractions respectively 
statements loop mapped multiplications additions subtractions resulted task sequence tm tm tm tm ta ts ta ta ts ts 
tm multiplication task mapped function ta addition task mapped function ts subtraction task mapped function 
optimal sequence con gurations task sequence algorithm repeated iterations 
important aspect solution multiplier con guration solution slower con guration 
recon guration overhead lower higher execution cost amortized iterations loop 
total execution time number iterations 
mapping applications architecture independent fashion provide framework automatic compilation applications 
loop structures regular repetitive computations speeded con gurable hardware 
developed techniques map loops application programs con gurable hardware 
developed general hybrid system architecture model 
parameterized model captures wide range con gurable systems 
model facilitates formulation mapping problems de ned important problems mapping traditional loop structures con gurable hardware 
demonstrated polynomial time solution important variant problem 
showed example mapping fft loop techniques 
model extended solve general mapping problems 
application development phase enhanced model develop solutions algorithm synthesis logic synthesis 
reported part usc project 
project developing algorithmic techniques realizing scalable portable applications con gurable computing devices architectures 
developing computational models algorithmic techniques models exploit dynamic recon guration 
addition partitioning mapping issues compiling recon gurable hardware addressed 
related results 

prasanna 
recon gurable meshes theory practice 
recon gurable architectures workshop raw apr 

viktor prasanna 
hybrid system architecture model recon gurable architectures 
technical report department electrical engineering systems university southern california 

buell arnold 
splash fpgas custom computing machine 
ieee computer society press 

choi prasanna 
con gurable hardware symbolic search operations 
international conference parallel distributed systems dec 

chung prasanna 
parallel object recognition fpga con gurable computing platform 
international workshop computer architectures machine perception oct 

prasanna 
fast parallel implementation dft devices 
th international workshop field programmable logic applications sept 

hauser wawrzynek 
garp mips processor recon gurable coprocessor 
ieee symposium fpgas custom computing machines pages april 

kress hartenstein 
operating system custom computing machines paradigm 
th international workshop field programmable logic applications pages sept 

lawrence kay luk page 
recon gurable hardware speed product development performance 
th international workshop field programmable logic applications 

luk shirazi guo cheung 
pipeline morphing virtual pipelines 
th international workshop field programmable logic applications sept 


simulation tool dynamically recon gurable fpgas 
ieee transactions vlsi systems sept 

xilinx dsp application notes 
fastest fft west www xilinx com apps htm 

petersen hutchings 
assessment suitability fpga systems digital signal processing 
th international workshop field programmable logic applications 

carberry johnson wong 
time multiplexed fpga 
ieee symposium fpgas custom computing machines pages april 

nsc napa url 
www national com napa 

vuillemin bertin shand touati 
programmable active memories recon gurable systems come age 
ieee transactions vlsi systems march 


compilation pipeline synthesis recon gurable architectures 
recon gurable architectures workshop raw 
verlag apr 
article processed latex macro package llncs style 
