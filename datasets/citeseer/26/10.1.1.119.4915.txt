arxiv cond mat dec attractor neural networks giorgio parisi dipartimento di universit di roma la sapienza february lecture models neural networks developed years 
aim construct neural networks associative memories 
different attractors network identified different internal representations different objects 
lecture comparison theoretical results experiments done real mammal brains 
field neural networks intensively studied people coming quite different disciplines mathematics computer sciences physics biology psychology 
carries training methodology discipline taste believes important interesting 
goals people quite different 
roughly speaking divided want understand real mammal brain works want information gather study brain order build new brands computers 
new computers behave intelligent way sense compared existing ones 
interested understanding complex collective behaviour emerges interaction simpler elementary objects 
quite issue 
biology observed assembly objects behaves quite differently isolated objects crucial phenomenon 
examples emergent collective behaviour macromolecules atoms cells macromolecules animals single cells species evolution ecosystems animals 
task deducing laws higher levels lower level simple 
physicists particular question past successfully answered similar questions albeit simpler context 
emergence collective behaviour quite familiar name phase transition 
examples assembly spins decreasing temperature increasing follow original notation celsius system electrons behaves 
collective phenomena understood appropriate tools statistical mechanics 
systems especially understanding behaviour system microscopic components construction corresponding theoretical framework easy job 
elaborate constructions needed order understand peculiar behaviour disordered systems spin glasses different equivalent equilibrium states 
nowadays physicists succeeded reaching control observed collective phenomena physical systems believe task deriving macroscopic laws form microscopic ones biological setting duty 
techniques statistical mechanics order reach understanding dynamics mutual interaction dna thousands different enzymes escherichia coli 
times ripe task years started understand behaviour physical complex systems mainly disordered systems spin glasses display different equilibrium states 
toolbox statistical mechanics contains sharp sophisticated instruments 
approach biology physicists 
believe physicists standards biologists reasons 
important reasons modern physics start galileo times unnatural choice neglecting friction 
day life friction dominates force proportional speed old approach aristotle acceleration 
friction unable walk verified find ice road 
world friction look real world 
physics started extrapolating experiments properties frictionless world constructing theoretical framework able describe artificial world culminated mechanics 
friction included theory stage 
times history physics progress achieved selecting features supposed simpler analyse neglecting rest time moment theory able cope new features nowadays approach automatic reflex physicists 
great simplifications see introduced hopfield study attractor neural networks step backward tradition physics 
technical reason discovered study second order phase transitions wilson 
carries name universality 
basic idea simple 
number qualitatively different collective behaviours system macroscopic level high definitively number different microscopic systems 
thousands millions different materials ising type exist specific heat diverges phase transition point tc value systems 
qualitative quantitative properties quote book freely translated modern language book study objects move constant speed horizontal direction constant acceleration vertical direction 
real cannon balls follow law worse speak 
collective behaviour depend kind collective behaviour observed microscopic details system 
course quite different system may qualitative different phase transitions glasses 
phase transitions may divided universality classes homogeneous systems qualitative behaviour quantitative features near phase transition point constant inside universality class change small change systems 
words collective behaviour understood self consistent way making microscopic dynamics 
program reached higher success dimensional systems possible collective behaviour systems belonging quite large class classified simple consistency requirements collective behaviour 
understanding collective behaviour obtained studying universality classes particular system quite different systems supposed belong universality class equivalent far collective behaviour concerned 
reaction theoretical physicist new problem search simplest system belong universality class 
universality suggests unwanted complications neglected need reintroduce stage change main results 
course large amount experience serendipity needed discriminated unwanted complications essential properties 
lecture describe developments done years construction network neurons behave associative memory 
associative memory memory usual human sense remember names faces notions recognise known objects able recall receive partial information lecture comparison predictions models experiments real mammal brains 
spirit thom classification catastrophes world associative distinguish kind memory computer memory addressable memory address identifies content address 
schematic description neurons entering details model may convenient schematic description neurons mutual interactions 
mainly consider electric activity neuron easiest measure 
consider difference voltage neuron surrounding liquid observe fast spikes mv amplitude time duration millisecond 
number spikes second may range hundreds normal physiological conditions greater tens 
activity neuron depends signal receives neurons 
different neurons connected synapses unidirectional devices needed transmit information 
neuron synapse active neurotransmitters released absorbed release neurotransmitters increases activity neuron increases 
synapses may excitatory inhibitory 
neurotransmitters increases activity synapse excitatory decreases activity synapse inhibitory 
neuron may receive signals neurons number neurons average range goes 
activity neuron high excitatory signals overcame inhibitory ones low 
different synapses different effects 
efficacy synapse depends time usually believed physiological mechanism strengthen synapses neurons simultaneously active hebb rule 
details mechanism vertebrates unclear moment large amount information collected 
synapses allow neuron send message specifically neuron may quite far away 
neurons send non specific messages nearby neurons producing neurotransmitters diffuse intercellular liquid 
going consider activity 
try construct model set interconnected neurons neural network parametrize activity neurons functions synaptic strength functions ji 
stimulus network neuron assumed si ji total stimulus simply sum stimulus coming form neuron assume equal product synaptic strength activity neuron producing stimulus dynamic equations neuron supposed simplest case dt si non linear function arguments 
order fully describe network learning stage give equations control time evolution synaptic strengths reasons time discuss point interesting unfortunately understood 
assume dynamics produce synaptic couplings kind postulate 
associative memory believed internal representation pattern neuron activities associated object category able recognise remember 
believed object memorised changing synaptic strengths appropriate way 
order associative memory dynamics neurons neurons set equal time correspond learned pattern neuron activities remain times far 
words learned pattern correspond stable attractor points statistical sense small fluctuations fixed points allowed 
apply external stimulus push neurons direction equal partially correspond learned patterns neurons evolve 
property implies memory able retrieve information object knowledge part presence partially wrong information 
external stimulus different stored pattern system recognised absence match 
goal may obtained case fixed point reached chaotic behaviour observed 
case memory called cognitive knows writing eq 
neglected propagation time stimulus 
adding variability propagation times leads appearance new phenomena 
correct result obtained reaching attractor fixed point meaning recalling information stable point implies absence recognition 
clear physiological constraint implies different patterns activities may stored neural network 
model network different attractors 
point view memory similar spin glass different equilibrium states possible 
hopfield model hopfield model simplest version model different attractors exist 
model neuron activities conventionally taken time integer valued quantity 
choice unnatural choice sound better crucial qualitatively difference cases shall see 
step increase unity dynamics neuron activities obtained applying rule sign si si ji 
matrix symmetric ji jk dynamics corresponds sequential algorithm looking minimum hamiltonian ji 
main advantage hopfield model stage model similar zero temperature dynamics statistical mechanics model 
analogy strong introduce possibility errors write sign si probability tanh si sign si probability tanh si 
case obtain dynamics statistical mechanics system temperature random hamiltonian successfully studied techniques developed spin glasses 
limit recover original error free dynamics eq 

possible prove original zero temperature dynamics fixed point reached large time time independent 
hamiltonian decreases times changes value 
absence limiting cycles strong simplification main reason considering model aim store network different patterns denoted index runs index runs matrix assumed symmetric form ji strong hebbian flavour 
correspond say matrix changes quantity time network learns new pattern pi 
symmetry matrix physiologically realist necessary statistical mechanics techniques able consider evolution network process energy minimisation 
ask question configurations fixed point dynamics satisfy equations sign ji far value requirement may stated precise way 
define distance configuration configuration 
words percentage neurons different configurations 
configurations uncorrelated distance 
look existence configurations satisfy eq 
small distance problem carefully studied limit goes infinity 
simplest case assume different allow possibility having periodic behaviour period time independent separately odd times 
case update neurons sequential way setting sign si 
properties model similar described text possible fixed points limiting cycles period may 
uncorrelated average number 
situation finds existence regimes find configuration near configurations precisely find distance dmax dmax increasing function reaches maximum interval number solutions increasing slowly exp small value 
solutions exist small distance find solution distances order 
regime network works associative memory loading greater ac memory stops goes state total confusion 
order transition feature model disappear changing characteristics model 
models exist critical value system memory refined models hopfield model contains unrealistic features 
refined models proposed 
restriction neuron activity easily removed dramatic consequences 
different choices probability distribution patterns learning procedure studied 
features added dilution network consists assuming neurons connected strictly zero 
mention interesting results lack time 
recall interesting result obtained late elisabeth gardner 
commit learning algorithm ask find matrix patterns fixed point dynamics 
interesting computation show patterns uncorrelated limit possible possible 
interest kind results tell network independently learning algorithm dynamics js 
symmetric form matrix remain framework equilibrium statistical mechanics 
new qualitative features appear asymmetric 
hopfield model evolution fixed point reached fixed point stored patterns 
introduce asymmetries matrix shown evolution leads fixed point spurious fixed points correlated stored patterns disappear 
network reach fixed point near stored pattern time evolution network chaotic variables change value apparent random way 
results interesting obtains effort feature possibility chaotic states removing artificial characteristic model symmetry 
simple model effect studied asymmetrically diluted model ji ai eq ai asymmetric matrix elements probability probability limit small model easily studied analytically simple computations finds storage capacity equal large time behaviour network fully chaotic near attractors 
large amount done years problems learning rules example cases extension techniques developed statistical mechanical systems fruitful 
real experiments seen construct model different features associative memories 
quite results eventually important projects new generations computers 
moment interesting practical application neural networks fast triggers order high energy experiments 
super 
case decide event interesting short time order nanoseconds 
neural network may able perform complex task short time massive parallelism neurons physically implemented 
biological point view interested known attractors really exist mammal brains brain perform complex task example able recognise different image correspond physical object 
order address problem identified experimentally memory cell information stored 
past neurons respond switch low firing rate higher selective way external stimulus example visual 
stimulus highly complex face simple horizontal line 
unfortunately time activity neurons disappeared stimulus removed 
neurons remain active selective way removal stimulus period larger seconds 
experiments monkeys species trained learn fractal patterns order 
learning patterns monkeys pairs time distance seconds 
supposed act differently pattern equal fruit juice performed correctly 
small area mm neurons respond selective way visual presentation patterns 
reasonable suppose recorded activities come cells belong attractor cells excited attractor 
hypothesis correct possible start experimental study property attractor 
interesting features experiment compared theoretical predications 
interesting unexpected feature experiment existence correlations neural activities different patterns 
patterns fixed randomly chosen order 
patterns uncorrelated probability neuron active presentation th pattern higher average neuron active presentation th pattern large smaller 
neural activities corresponding patterns learned nearby times correlated 
shown correlations arise naturally relative simple model neural network experimental features correlations agreement theoretical predictions 
quite experiments theory evolve convergent way possible obtain detailed confirmation refutation theoretical approach 
hope audience flavour large amount done field neural network years 
said time 
parisi physics word 
parisi spin glass theory world scientific singapore 
parisi field theory disorder simulations world scientific singapore 
braitenberg anatomy cortex springer verlag berlin 
hopfield proc 
natl 
acad 
sci 
usa 
amit modeling brain functions cambridge cambridge press 
gardner phys 

parisi phys 

gardner europhys 
lett 

denker schwartz solla jackel hopfield complex systems 
tishby phys rev letters 
parisi network 

see example opper preprint 
neural networks biology high energy physics del eds pisa ets miyashita chang nature 
miyashita nature 
amit brunel tsodyks correlations cortical hebbian experiment theory rome preprint 

