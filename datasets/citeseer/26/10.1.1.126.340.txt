proceedings aaai fall symposium uncertainty computation pp 
cape cod ma 
methods sampling pages uniformly world wide web david pennock steve lawrence lee giles department management science engineering stanford university nec research institute independence way princeton nj school information sciences technology pennsylvania state university university park pa lawrence stanford edu research nj nec com giles ist psu edu new algorithms generating uniformly random samples pages world wide web building henzinger 
henzinger bar yossef 
bar yossef 
algorithms weighted random walk methodology 
algorithm directed sample operates arbitrary directed graphs naturally applicable web 
show limit algorithm generates samples uniformly random 
second algorithm undirected sample operates undirected graphs requiring mechanism obtaining inbound links web pages access search engine 
additional knowledge inbound links algorithm arrive uniform distribution faster directed sample derive explicit bounds time convergence 
addition evaluate algorithms simulated web data showing yield reliably uniform samples pages 
compare results previous algorithms discuss theoretical relationships various proposed methods 
world wide web massive network information reflecting ideas trends society 
accurate characterizations web content structure provide window interests millions individuals organizations globe 
obtaining estimates quantities difficult due web sheer size pages inktomi nec january lawrence giles growing distributed dynamic nature 
exhaustive enumeration web pages technically challenging costly task results rapidly outdated brin page kahle 
reasonable approach infer statistics random sample web pages 
generating uniform sample web pages nontrivial problem 
methods proposed standard methodology emerged 
lawrence giles lawrence giles queried major search part conducted visiting nec re search institute 
engines estimate overlap databases 
infer bound size indexable web estimate search engines relative coverages 
authors lawrence giles employ sampling approach random testing ip addresses determine characteristics hosts pages web update size estimate web 
bharat broder bharat broder propose methodology generating random queries 
methods explicit hyperlink structure web 
view web directed graph nodes correspond web pages edges correspond hyperlinks 
sample web pages generated crawling web graph specified policy 
henzinger 
henzinger crawling policy reweighting results random crawl order approximate uniform sample 
algorithm refer pagerank sample pagerank web page 
pagerank measure popularity web page part google www google com rank search results brin page 
authors explain method ideally yield nearly uniform sample point practical theoretical barriers discussed comparative experiments section 
experimental results generated sample appears biased web pages large numbers inbound links 
bar yossef 
bar yossef propose alternative random walk method sampling web pages uniformly 
method regular sample assumes web undirected graph hyperlinks followed backward forward 
web truly undirected practice algorithm query search engine inbound links page 
experiments indicate applied actual web type approximation results biased sample 
develop new algorithm generating uniform samples web built methodology 
approach directed sample works arbitrary directed graphs directly appli cable web 
prove asymptotic limit algorithm generates uniform sample web pages expected number occurrences sample pages web 
knowledge algorithm provable asymptotic convergence real web 
algorithm undirected sample analysis section modify algorithm operate undirected graph undirected sample assume knowledge inbound links page 
setting show problem analysis considerably simplified 
addition guaranteeing convergence derive formal bounds time convergence 
empirical results comparisons section test directed sample algorithm simulated directed web graph showing generates samples independent number links page 
directly compare undirected sample algorithm pagerank sample regular sample algorithms simulated web data undirected modeling assumptions 
experiments undirected sample regular sample outperform pagerank sample 
isolate key approximation pagerank sample believe leads biased samples show modified pagerank sample thought special case directed sample 
conclude summary discussion research directions 
setup notation broder 
broder find web divided main components central strongly connected core set pages reached core connect back set pages connect core reached set pages disconnected core 
seek generate uniform sample pages core pages reachable core 
sampling method random walk hope sample pages reachable starting page 
believe purposes statistical testing subset web sufficiently representative publicly accessible web pages interest 
view web directed graph web pages nodes hyperlinks edges 
denote set web pages assume loss generality page strongly connected core www yahoo com 
matrix defined matrix thought connection matrix non zero elements denote connections var ious pages web 
note assume node connected diagonal elements equal dead pages hyperlinks connect back page 
assumption assumption exists words page reached page traversing edges 
assumption holds pages strongly connected core pages reachable core 
denote matrix obtained normalizing row sums think transition probability matrix associated random walk hyperlink chosen uniformly random 
assumption implies associated random walk irreducible diagonal elements positive aperiodic 
follows standard result stochastic processes exists stationary distribution associated algorithm directed sample analysis stationary distribution represents asymptotic frequency visiting page random walk transition probability sufficiently long walk expect frequency web page vis web page include sample probability expected number occurrences web page sample yielding uniformly random sample 
unfortunately know true value estimate 
web page collected initial crawl compute estimate stationary probability performing random walk recording walk visits page formal definition algorithm follows 
note design parameters algorithm directed sample 
start web page crawl web transition probability time periods 

time periods continue crawl web denote web pages visited crawl denote additional time periods 
collection distinct web pages collected crawl 
note web pages repeated 

page compute estimated station ary follows 
crawl web accord ing time periods starting page probability denote sequence web pages visited crawl indicator random variable equal 

include page final sample set probability positive number proposition establishes algorithm soundness sufficiently large returned sample set uniform sample 
specifically asymptotic limit expected number occurrences page pages proposition web page final set web pages returned step algorithm 
proof 
recall variables denote collection web pages gathered step algo rithm 
random variable defined represents event included corresponds set web pages final sample sample 
collection random variables denotes starting page crawl step follows equality follows fact corresponds state time random walk standard result stochastic processes implies bound time convergence 
large values may required produce near uniform sample potentially affecting practicality running directed sample entire web 
note parameter burn time 
phase need perform memoryless crawl need record information way 
purpose burn eliminate dependence induce near stationary distribution random vari ables instantiated step 
pa rameter number pages traversed order estimate stationary distribution web pages high number inbound links www yahoo com visited algorithm produces accurate estimates stationary probabilities relatively small web pages small numbers inbound links vast majority pages occur infrequently crawl may need large obtain estimates pages 
section see eliminate estimation phase step altogether assume access inbound links page 
currently pursuing techniques reduce bound time convergence directed sample 
examining potential algorithm conjunction focused crawler chakrabarti van den berg dom diligenti order generate uniform samples topic specific subsets web traversing entire web 
algorithm undirected sample analysis directed sample algorithm page collected step included final sample probability inversely proportional estimated stationary probability quality resulting sample depends signifi cantly accurately able estimate true stationary probability section show assume web undirected graph algorithm greatly simplified expedited 
assumption equivalent requiring knowledge pages point web page 
assumption partially justified fact search engines allow queries inbound links web pages 
note search engines databases complete fully date performing queries time consuming costly 
undirected setting defined matrix means hyperlink matrix denotes connection matrix various web pages web ignoring directionality 
case assumption holds pages strongly connected core pages reachable core pages connect core 
consider transition probability matrix defined matrix corresponds transition probability web page hyperlink chosen uniformly random follow including point page 
web page denote degree sum number links page number links degree total number connections associated page application directed sample algorithm case undirected graph relies lemma 
lemma irreducible associated stationary distribution denotes total number edges graph 
proof 
irreducible aperiodic 
follows stationary distribution exists unique 
suffices show note follows desired follows 
lemma provides explicit formula stationary distribution basic algorithm section step need estimate stationary probability 
eliminates potentially long crawl steps required directed case 
formal definition algorithm follows 
algorithm undirected sample 
start web page crawl web transition probability time periods 

time periods continue crawl web denote web pages visited crawl 
additional time periods 

page included sample probability positive number proof proposition immediately extends current case 
assuming web modeled undirected graph able put bound deviation sample truly random sample 
denote undirected graph web denotes set web pages denotes collection hyperlinks assuming denote maximum de 
gree denote diameter web 
denote collection shortest paths points web graph denotes maximum number paths single edge common 
measures bottleneck web graph 
proposition proposition implies sufficiently large value expected number occurrences web page shows rate convergence exponential parameter sample approaches maximum degree diameter bottleneck 
plan compute estimates quantities real web 
proof proposition relies results diaconis diaconis geometric bounds eigenvalues markov chains 
depends graphical properties web lemma transition probability reversible markov chain state space sta tionary distribution assume irreducible eigenvalues proof 
see proposition diaconis 
lemma connected graph 
denotes random walk graph denotes second largest eigenvalue maximum degree diameter graph denotes collection shortest paths points graph 
proof 
see corollary diaconis 
lemma connected graph bipartite 
path odd length collection paths denotes random walk graph denotes smallest eigenvalue maximum degree maximum number edges proof 
see corollary diaconis 
node web graph self loop choose lemma collection self loops bound proof proposition follows 
proof 
recall denote collection web pages collected step 
random variable defined represents event included corresponds set web pages final sample 
sample 
collection random variables implies equality follows lemma 
starting web page corresponds web page visited time crawl follows lemma denotes second largest eigenvalue transition probability denotes smallest eigenvalue equality follows expression stationary probability lemma 
follows lemmas desired result follows 
empirical results comparisons section experimental evaluations directed sample undirected sample algorithms including comparisons previous algorithms 
describe modified pagerank sample algorithm viewed special case directed sample isolate key approximation step pagerank sample believe leads biased samples 
directed sample test directed sample algorithm simulated web graph nodes belong primary strongly connected component 
graph generated pennock pennock extension barab si albert barab si albert model web growth 
model generates undirected graphs edge distributions identical real web 
converted resulting undirected graph directed graph assigning directionality edges random 
ran directed sample algorithm parameters resulting sample size method random walk expect numbers inbound outbound links source sample bias 
compares distribution inbound links sample set true distribution entire graph 
displays comparison outbound links 
likelihood particular page occurs sample appears independent number links page 
true inlink distribution sampled inlink distribution ratio generated sample truly random sample number inlinks distribution inbound links simulated web graph 
distribution inbound links pages returned directed sample algorithm 
ratio sampled distribution true distribution directed sample truly random sampling algorithm 
shows histogram node id numbers sample 
nodes graph grouped equally spaced buckets 
shows proportion sampled nodes chosen bucket 
sample uniform proportion bucket 
plots ratio proportion bucket true expected value uniform sampling 
figures appear systematic bias sampling 
true outlink distribution sampled outlink distribution ratio generated sample truly random sample number outlinks comparison sampled actual outbound link distributions directed sample algorithm 
node numbers directed sample ratio generated sample truly random sample bin number distribution node numbers samples generated directed sample algorithm 
undirected sample section empirical results undirected sample algorithm 
experiments performed undirected graph nodes main connected component generated pennock pennock model web growth 
burn time set starting node set node number generated sample size nodes 
choice web pages visited accepted sample 
shows distribution number edges graph versus sample 
bottom portion shows ratio proportion nodes sample having certain number edges versus true proportion 
systematic bias nodes small large degrees 
shows histogram node numbers generated algorithm 
true edge distribution edge distribution undirected sample truly random sample undirected sample ratio number edges distribution number edges samples generated undirected sample algorithm 
node numbers undirected sample random sample undirected sample ratio bin number distribution node numbers samples generated undirected sample algorithm 
comparative experiments section compare results undirected sample pagerank sample henzinger regular sample bar yossef 
denote total number nodes graph 
pagerank sample algorithm conducts random walk graph node probability neighbor chosen random probability node graph chosen random 
choosing node random nodes feasible henzinger 
henzinger approximate step choosing nodes visited far 
final sample generated choosing visited nodes probability inversely proportional pagerank 
regular sample algorithm conducts random walk dynamically built graph constructed node degree graph regular 
construction performed assuming degree node original graph bounded constant new graph built adding appropriate number self loops node node degree 
node graph degree associated stationary distribution random walk graph uniform 
true edge distribution total nodes edge distribution pagerank sample edge distribution regular sample edge distribution undirected sample ratio pagerank regular undirected number edges distribution edges simulated undirected graph 
distribution edges pages returned pagerank sample algorithm 
distribution edges pages returned regular sample algorithm 
distribution edges pages returned undirected sample algorithm 
ratio sampled distribution true distribution algorithms 
burn time undirected sample regular sample initial seed set size pagerank sample 
ran undirected sample pagerank sample gorithms samples size collected 
regular sample algorithm generated sample nodes unique vast majority nodes repeats due self loops 
assumed knowledge true regular sample algorithm 
shows true edge distribution simulated web graph sampled distributions algorithms 
see undirected sample regular sample produce appear uniform samples noticeable bias number edges incident node 
hand pagerank sample appear exhibit consistent bias pages large numbers edges 
note original idea underlying pagerank sample algorithm seen sense special case directed sample algorithm 
idealized crawling policy pagerank sample corresponds transition probability denotes number outlinks web page random walk performed page visited included sample probability inversely proportional pagerank denoted turns stationary probability page transition probability idea underlying pagerank sample similar directed sample employing alternative crawling policy associated stationary distribution 
believe source bias pagerank sample stems approximation step required 
henzinger 
henzinger note conduct random walk web graph transition probability matrix recall probability web page chosen random pages 
feasible 
choose web page random need algorithm place 
authors approximate step randomly choosing pages visited far 
conjecture primary source error contributing bias resulting sample 
new algorithms directed sample undirected sample uniform random sampling world wide web pages 
algorithms generate samples provably uniform limit 
tradeoffs algorithms 
directed sample algorithm naturally suited web assumptions works directed graph may take long time converge 
undirected sample algorithm converges faster formally bound convergence time algorithm requires assumption hyperlinks followed backward forward 
empirical tests verify algorithms appear produce unbiased uniform samples 
simulated web data undirected sample algorithm performs regular sample algorithm better pagerank sample algorithm methods proposed literature 
discuss theoretical connections directed sample pagerank sample highlighting believe key approximation step pagerank sample leads biased samples 
bar yossef berg chien 
approximating aggregate queries web pages random walks 
proceedings th international conference large data bases 
barab si albert 
emergence scaling random networks 
science 
bharat broder 
technique measuring relative size overlap public web search engines 
proceedings th international world wide web conference 
brin page 
anatomy large scale hypertextual web search engine 
seventh international world wide web conference 
broder kumar maghoul raghavan rajagopalan stata tomkins 
graph structure web 
proceedings th international world wide web conference 
chakrabarti van den berg dom 
focused crawling new approach topic specific web resource discovery 
proceedings th international world wide web conference 
diaconis 
geometric bounds eigenvalues markov chains 
annals applied probability 
diligenti coetzee lawrence giles gori 
focused crawling context graphs 
th international conference large databases vldb 
henzinger heydon mitzenmacher najork 
near uniform url sampling 
proceedings th international world wide web conference 
inktomi nec 
january 
web surpasses documents 
inktomi nec press release www inktomi com 
kahle 
preserving internet 
scientific american 
lawrence giles 
searching world wide web 
science 
lawrence giles 
accessibility information web 
nature 
pennock flake lawrence giles glover winners don take model web link accumulation 
preparation 
