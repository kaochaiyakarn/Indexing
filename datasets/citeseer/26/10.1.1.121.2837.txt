operating system support planetary scale network services andy mic bowman brent chun david culler scott karlin steve muir larry peterson timothy roscoe mike department computer science intel research computer science division princeton university university california berkeley planetlab geographically distributed overlay network designed support deployment evaluation planetary scale network services 
high level goals shape design 
enable large research community share infrastructure planetlab provides distributed virtualization service runs isolated slice planetlab global resources 
second support competition multiple network services planetlab decouples operating system running node services define planetlab principle referred management 
describes planet lab realizes goals distributed virtualization management focus os running node 
planetlab geographically distributed overlay platform designed support deployment evaluation planetary scale network services :10.1.1.109.4681
currently includes machines spanning sites countries 
supports research projects focused wide range services including file sharing network embedded storage content distribution networks routing multicast overlays qos overlays scalable object location services anomaly detection mechanisms network measurement tools :10.1.1.1.2787:10.1.1.1.2787:10.1.1.110.5867:10.1.1.159.9358:10.1.1.115.4299:10.1.1.28.5987:10.1.1.28.5987:10.1.1.161.2760
distributed system planetlab characterized unique set relationships principals users administrators researchers service providers design requirements operating system different traditional hosting services timesharing systems 
relationship planetlab organization institutions host planetlab nodes administrative control nodes local sites need enforce policies nodes kinds quantity network traffic nodes generate 
implies need share control planetlab nodes 
second relationship planetlab users currently researchers evaluating deploying planetary scale services 
researchers access platform implies distributed set machines shared way find useful 
planetlab account associated resources span multiple machines 
call abstraction slice implement technique called distributed virtualization 
third relationship exists planetlab researchers contributing system designing building infrastructure services services contribute running platform opposed merely applications 
services run slice planetlab support multiple parallel services similar functions developed different groups 
call principle management imposes requirements system 
planetlab exists relation rest internet 
experience shows experimental networking performed planetlab easily impact external sites intrusion detection vulnerability scanners 
leads requirements policies limiting traffic planetlab users send rest internet way concerned outside individuals find exactly seeing unusual traffic planetlab 
rest internet needs feel safe planetlab 
contribution describe detail requirements result relationships planetlab fulfills synthesis operating systems techniques 
contribution partly design planetlab progress time tell infrastructure services evolve give fuller definition 
time design largely product experience having hundreds users stressing planetlab platform operational july 
requirements section defines distributed virtualization management identifies requirements places planetlab design 
distributed virtualization planetlab services applications run slice platform set nodes service receives fraction node resources form virtual machine vm 
virtualization virtual machines course established concepts 
new planetlab distributed virtualization acquisition distributed set vms treated single compound entity system 
support concept planetlab provide facilities create slice initialize sufficient persistent state boot service application question bind slice set resources constituent node 
slice behavior left unspecified architecture 
includes exactly slice created discuss context management programming environment planetlab provides 
giving slices latitude possible defining suitable environment means example planetlab os provide tunnels connect constituent vms particular overlay configuration provides interface allows service define topology top fully connected internet 
similarly planetlab prescribe single language runtime system allows slices load environments software packages need 
isolating slices planetlab isolate slices maintaining illusion slice spans distributed set private machines 
requirement seen traditional operating systems planetlab slice distributed set vms single process image 
node resource guarantees required example slices run time sensitive applications network measurement services soft real time constraints reminiscent provided multimedia operating systems 
means things respect planetlab os allocate schedule node resources cycles bandwidth memory storage runtime behavior slice node adversely affect strictly true planetlab currently provides unix api lowest level 
long term goal decouple aspects api unique planetlab underlying programming environment 
performance node 
certain slices able request minimal resource level return receive soft real time performance guarantees 
partition available name spaces network addresses file names prevent slice interfering gaining access information slice 
cases partitioning contextualizing coordinated set nodes system 
provide stable programming base manipulated code running slice way negatively affects slice 
context unix windows operating system means slice root system privilege 
resource scheduling vm isolation recognized important issues start expectation best effort solution sufficient time 
experience excessive loads especially near conference deadlines volatile performance behavior due insufficient isolation dominant problems early versions system 
lack isolation led significant management overhead human intervention required deal run away processes unbounded log files 
isolating planetlab planetlab os protect outside world slices 
planetlab nodes simply machines connected internet consequence buggy malicious services running slices potential affect global communications infrastructure 
due planetlab widespread nature goal supporting novel network services impact goes far reach application running single computer 
places requirements planetlab os 
thoroughly account resource usage possible place limits resource consumption mitigate damage service inflict internet 
proper accounting required isolate slices 
concerned node impact hosting site network bandwidth consumes remote sites completely planetlab sites probed planetlab node 
furthermore local administrators planetlab site planetlab organization need collectively set policies node 
easy audit resource usage actions just resources accounted slices fact 
concern users services affect outside world novel requirement planetlab traditional timesharing systems interactions users unsuspecting outside entities inherently rare 
security recognized start critical issue design planetlab 
effectively limiting auditing legitimate users turned just significant issue securing os prevent malicious users hijacking machines 
example single planetlab user running tcp throughput experiments berkeley nodes managed consume half available bandwidth campus gateway span days 
experiments internet mapping triggered ids mechanisms resulting complaints caused local administrators pull plug nodes 
internet turned unexpectedly sensitive kinds traffic experimental planetary scale services tend generate 
management planetary scale services relatively ongoing subject research particular includes services required manage global platform planetlab 
explicit goal planetlab allow independent organizations case research groups deploy alternative services parallel allowing users pick ones 
applies application level services targeted users infrastructure services manage control planetlab slice creation resource topology discovery performance monitoring software distribution 
key management allow parallel infrastructure services run slices planetlab evolve time 
new twist traditional problem evolve system generally wants try new version service parallel existing version roll back forth versions 
case multiple competing services simultaneously evolving 
desire support management leads requirements planetlab os 
minimize functionality subsumed planet lab os maximize functionality running services top os local node abstractions directly supported os allowing global network wide abstractions implemented infrastructure services 
maximize opportunity services compete level playing field interface os infrastructure services sharable special privilege 
words single privileged application controlling particular aspect os planetlab os potentially supports management services 
implication interface sharable defined explicitly exposing state underlying os 
contrast interface os privileged control program running user space ad hoc control program effect extension os happens run user space 
particular note slice creation implemented service running slice leads additional requirement planetlab os provide low level interface creating vm shared multiple slice creation services 
host bootstrapping slice creation service create initial slices including slices slice creation services run 
important technical issue influence slice abstraction evolves quickly network wide slice instantiated 
applications ones listed relatively long lived possibly modified restarted frequently process creating slice run heavy weight operation 
hand facility rapidly establishing tearing slice analogous creating destroying network connection lead slices relatively short lived example slice corresponds communication session known set participants 
evaluate performance current slice creation mechanism section 
clear slice creation services user community provide utilize capability create destroy slices 
bottom line os design faces tension implementing functionality kernel running user space objective minimize kernel code 
vmm architectures planetlab os faces additional analogous tension run slice vm functionality slice user authentication requires extra privilege access part kernel 
addition third aspect problem peculiar planetlab functionality implemented parallel competing subsystems versus mechanisms nature implemented bootstrapping slice creation 
planetlab os strives minimize remains core non kernel functionality unique node 
evolving architecture management addresses challenge evolving planetlab remains practi slices vms vmm linux node manager resource allocation sensors auditing slice bootstrapping local admin resource limits kill process planetlab node architecture cal issue evolving underlying os supports management 
simply stated research community ready planetlab moment machines deployed 
waiting new os tailored broad coverage services option case gaining experience fully understand system look 
experience previous testbeds strongly suggested biases application writers seldom willing port applications new api expect full featured system minimalist api tuned os research agenda 
suggested strategy starting full featured os elected linux due widespread research community incrementally transforming experience 
evolution guided meta architecture depicted 
lowest level planetlab node runs virtual machine monitor vmm implements isolates vms 
vmm defines api services implemented 
planetlab currently implements vmm combination linux kernel set kernel extensions outlined section 
privileged root vm running top vmm called node manager monitors manages vms node 
generally speaking node manager enforces policies creating vms allocating resources services interacting node manager create new vms directly calling vmm 
interactions node manager local services running vm node allowed call node manager meaning remote access specific node manager indirect services running node 
today policy hard coded node manager expect local administrators eventually able configure policies nodes 
purpose local administrator vm shown 
subset services slices running top vmm characterized privileged way allowed privileged calls node manager allocate local resources vm 
expect slices provide service users unprivileged infrastructure services may need run privileged slice 
date types infrastructure services emerging brokerage services acquire resources create slices bound environment services initialize maintain slice code base monitoring services discover available resources monitor health running services 
expect new facilities incorporated architecture time key question new functionality implemented unprivileged slice privileged slice node manager vmm 
decisions guided principles function implemented highest level possible running service slice limited privileged capabilities preferred slice widespread privileges turn preferred augmenting node manager preferable adding function vmm 
privileged slices granted minimal privileges necessary support desired behavior 
granted blanket superuser privileges 
design alternatives planetlab os synthesis existing operating systems abstractions techniques applied new context distributed platform motivated requirements discussed previous section 
section discusses planetlab requirements recommend certain approaches process discusses related 
node virtualization challenge planetlab os provide virtual machine abstraction slices question level 
spectrum full vmware completely virtualize physical hardware support multiple unmodified operating system binaries 
planet lab supply low level virtualization slice run copy os access devices resources available hypervisor 
allow planetlab support os kernel research provide stronger isolation removing contention os resources 
cost approach performance vmware support number simultaneous slices required planetlab due large amount memory consumed machine image 
far planetlab community required ability run multiple operating systems planetlab able take advantage efficiency supporting single os api 
slightly higher level approach proposed called isolation kernels xen denali 
short full virtualization hardware subset processor instruction set specialized virtual devices form virtual machine exported users 
virtual machine longer replica physical machine operating systems ported new architecture architecture support virtualization far efficiently 
systems mature shown scale represent promising technology planetlab 
approach adopted virtualize level similar commercial offerings projects user mode linux bsd jail linux vservers 
high level virtualization adequately supports planetlab goals supporting large numbers overlay services providing reasonable assurances isolation 
isolation resource allocation second orthogonal challenge isolate virtual machines 
operating systems explicit goal isolating application performance go back far keykos system provided strict resource accounting mutually antagonistic users 
isolation mechanisms explored multimedia support applications require soft real time guarantees 
central problem crosstalk contention shared resource server process prevents os correctly scheduling tasks 
variously addressed sophisticated accounting control transfers processor capacity reserves scheduling data paths scout entirely restructuring os eliminate server processes data path nemesis :10.1.1.28.6923
planetlab os borrows isolation mechanisms scout key difference mechanisms controlled node runs multiple competing tasks belong global slice purely local set cooperating tasks 
problem distributed coordination resources turn explored context condor open grid services architecture :10.1.1.114.2815
systems aimed execution batch computations support long running network services 
seek define complete architectures computations run 
planetlab requirements different platform support multiple approaches creating binding resources slices 
illustrate distinction point globus grid toolkit account management system emulab testbed implemented planetlab service oriented frameworks sharp :10.1.1.11.3768
network virtualization having settled node virtualization system call level third challenge virtualize network 
vertically structured operating systems exokernel nemesis explored allowing access raw network devices filters send receive 
planet lab os uses similar approach providing shared network access safe version raw socket interface 
traditionally provided raw physical device single library os manage controlled sharing raw device library oses connections 
planetlab kernel take responsibility sharing raw access reception transmission potentially arbitrary packets multiple competing services controlled manner administrative policy 
additionally protect surrounding network buggy malicious services issue typically ignored existing systems 
alternative sharing partitioning single network address space virtual machines vm local version space moving demultiplexing level 
instance assign different ip address vm allow entire port space manage routing table 
problem simply ipv addresses available assign order node 
monitoring final somewhat new challenge support monitoring management large distributed infrastructure 
network side commercial management systems hp provide simplified interfaces routing functionality service provisioning equipment status checks 
host management side systems ibm tivoli computer associates address corresponding problems managing large numbers desktop server machines enterprise 
kinds systems aimed single organizations defined applications goals seeking manage control equipment 
managing wide area evolving federated system planetlab internet poses different challenges 
pretty 
planetlab os section defines planetlab os node software global slice abstraction built 
planet lab os consists linux series kernel patches vservers hierarchical token bucket packet scheduling silk scout linux kernel module provides cpu scheduling network accounting safe raw sockets node manager trusted domain contains slice bootstrapping machinery node monitoring management facilities 
describe functionality provided components discuss implement slices focusing main areas vm abstraction resource allocation controlled access network system monitoring 
node virtualization slice corresponds distributed set virtual machines 
vm turn implemented vserver 
vserver mechanism patch linux kernel provides multiple independently managed virtual servers running single machine 
vservers principal mechanism planetlab providing virtualization single node contextualization name spaces user identifiers files 
providing security slices sharing node vservers provide limited root privilege allows slice customize vm dedicated machine 
vservers correspond resource containers isolation discuss section 
interface vservers provide virtualization system call level extending non reversible isolation provided filesystems operating system resources processes ipc 
processes vserver full access files processes ipc network interfaces accounts named containing vserver denied access system wide operating system resources 
vserver uid gid namespace weaker form root provides local superuser compromising security underlying machine 
despite having subset true superuser capabilities useful practice 
modify vserver root filesystem allowing users customize installed software packages vserver 
combined vserver uid gid namespaces allows vservers implement account management schemes maintaining vserver passwd running different tcp port providing basis integration wide area testbeds netbed ron :10.1.1.11.3768:10.1.1.161.2760
vserver initialized pieces persistent state set ssh keys vserver file 
allow owners slice ssh vserver serves boot script gets executed time vserver starts running 
vservers communicate ip local sockets ipc functions 
strong separation slices simplifies resource management isolation vservers interaction vservers independent locations 
namespace network addresses ip address port numbers contextualized imply ip address vserver hiding vserver node nat 
rejected options favor slices sharing port numbers addresses single node 
implementation vserver machine assigned unique security context process associated specific vserver security context 
process security context assigned new system call inherited process descendants 
isolation vservers enforced system call interface combination security context uid gid check access control privileges decide information exposed process 
mechanisms implemented baseline vserver patch kernel 
implemented utilities simplify creating destroying vservers transparently redirect user vserver specific slice ssh 
planetlab utilities initialize vserver creating mirror root filesystem inside vserver hard links immutable immutable invert filesystem bits 
create linux accounts login name equal slice name node primary vserver vserver just created sharing single uid 
default shell account main vserver set bin shell performs actions login switching slice vserver security context vserver root filesystem relinquishing subset true superuser capabilities redirecting account inside vserver 
result account arrangement users accessing virtual machines remotely ssh scp transparently redirected appropriate vserver need modify existing service management scripts 
virtualizing standard linux kernel vservers achieve substantial sharing physical memory disk space active state needed idle vservers 
physical memory savings accrued having single copies kernel daemons shared read copy write memory segments unrelated vservers 
disk space sharing achieved filesystem immutable invert bit allows primitive form copy write cow 
cow vserver root filesystems vserver disk footprints just required full copies section 
comparable sharing virtual machine monitor isolation kernel strictly harder different isolation guarantees 
planetlab application vservers extensive linux capability mechanism 
capabilities determine privileged operations pinning physical memory rebooting allowed 
general vserver root account denied capabilities undermine security machine accessing raw devices granted capabilities 
discussed section planetlab node supports special contexts additional capabilities node manager admin slice 
node manager context runs capabilities includes machinery create slice initialize state assign resources sensors export information node traffic auditing service 
admin slice provides weaker privileges site administrators giving set tools manage nodes providing access 
admin context complete view machine example cap node total outgoing bandwidth rate kill arbitrary processes run tcpdump monitor traffic local network 
discussion virtualizing kernel cost weaker guarantees isolation challenges eliminating qos crosstalk 
virtual machine monitors isolation kernels provide isolation low level vservers implement isolation system call interface 
malicious vserver exploits linux kernel vulnerability gain control operating system compromise security machine 
observed incident subset planetlab nodes compromised way 
lower level vm monitor 
potential cost incurred virtualizing kernel qos crosstalk 
eliminating qos crosstalk interactions buffer cache strictly harder vservers 
described section fairly deep isolation achieved 
combination vservers capabilities provides flexibility access control currently planetlab 
example sensor slices see section granted access information sources easily shared clients 
gain experience privileges services require extending set linux capabilities natural path exposing privileged operations controlled way 
isolation resource allocation key feature slices isolation provide services 
early experience planetlab illustrates need slice isolation 
example seen slices acquire available file descriptors nodes preventing slices disk network routinely fill available disk capacity unbounded event logging consume cpu nodes running infinite loop 
isolating slices necessary platform useful 
node manager provides low level interface obtaining resources node binding local vm belongs slice 
node manager policy decisions regarding resources allocated remotely accessible 
bootstrap brokerage service running privileged slice implements resource allocation policy 
policy includes resources allocate slices run brokerage services services free redistribute resources slices 
note resource allocation largely controlled central policy current system expect eventually defined node owner local administrator 
today resource related policy set local node administrator upper bound total outgoing bandwidth may consumed node 
interface node manager denotes right set node resources resource capability rcap bit opaque value knowledge provides access associated resources 
node manager provides privileged slices operation create resource capability rcap acquire operation takes resource specification argument returns rcap sufficient resources node satisfy 
node manager tracks set resources available node mapping committed resources corresponding rcap serves index table 
describes slice privileges resource reservations time 
consists list reservations physical resources cpu cycles link bandwidth disk capacity limits logical resource usage file descriptors assignments shared name spaces tcp udp port numbers slice privileges right create virtual machine node 
specifies start times interval values apply 
acquired passed service 
resources associated rcap bound virtual machine vserver slice creation time operation bind slice name rcap operation takes slice identifier rcap arguments assuming associated rcap includes right create virtual machine creates vserver binds resources described rcap 
note node manager supports operations manipulate described fully 
implementation non renewable resources memory pages disk space file descriptors isolated slice reservations limits 
implemented wrapping appropriate system calls kernel functions intercept allocation requests 
request accepted denied slice current usage accepted slice counter incremented appropriate amount 
renewable resources cpu cycles link bandwidth os supports approaches providing isolation fairness guarantees 
fairness ensures slices running node receives available resources periods contention guarantees provide slice reserved amount resource mbps link bandwidth 
planetlab provides cpu bandwidth guarantees slices request fair best effort service rest 
addition isolating slices resource limits outgoing traffic cpu usage protect rest world planet lab 
hierarchical token bucket htb queuing discipline linux traffic control facility tc cap total outgoing bandwidth node cap vserver output provide bandwidth guarantees fair service vservers 
node administrator configures root token bucket maximum rate site willing allow traffic leave node 
vserver startup token bucket created child root token bucket service requests guaranteed bandwidth rate token bucket configured rate minimal rate kbps fair best effort service 
packets sent vserver tagged kernel subsequently classified vserver token bucket 
htb queuing discipline provides child token bucket configured rate fairly distributes excess capacity root children proportion rates 
bandwidth cap placed vserver limiting amount excess capacity able 
default rate root token bucket set mbps vserver capped mbps rate kbps fair best effort service 
addition general rate limiting facility htb limit outgoing rate certain classes packets may raise alarms network 
instance able limit rate outgoing pings packets containing ip options small number second simply involves creating additional child token buckets classifying outgoing packets correct bucket 
identifying potentially troublesome packets determining reasonable output rates subject ongoing 
cpu scheduling implemented silk kernel module leverages scout provide vservers cpu guarantees fairness 
replacing linux cpu scheduler necessary linux provides approximate fairness individual processes enforce fairness vservers provide guarantees 
planetlab cpu scheduler uses proportional sharing ps scheduling policy fairly share cpu 
incorporates resource container abstraction maps vserver resource container possesses number shares :10.1.1.41.1733
individual processes spawned vserver placed vserver resource container 
result vserver set processes receives cpu rate proportional vserver shares divided sum shares active vservers 
example vserver assigned shares sum shares active vservers vservers contain runnable process vserver shares gets cpu 
ps scheduling policy provide minimum cycle guarantees capping number shares admission controller ensure cap exceeded 
current policy limits number outstanding cpu shares meaning share guarantee cpu 
additionally planetlab cpu scheduler provides switch allow vserver proportionally share excess capacity limit guaranteed rate similar nemesis scheduler :10.1.1.28.6923
previous example vserver shares received cpu allowed proportionally share excess bit turned rate capped cpu 
discussion implemented centrally controlled brokerage service called planetlab central plc responsible globally creating slices 
plc maintains database principals slices resource allocations policies central server 
exports interface includes operations create delete slices specify boot script set user keys resources associated slice instantiate slice set nodes 
node component plc called resource manager runs privileged slice allowed call acquire operation node 
resource manager node periodically communicates central plc server obtain policy slices created resources bound 
plc allocates resources participating institutions projects allocates resources brokerage services redistribution 
way plc serves bootstrap brokerage service expect sophisticated decentralized services evolve time 
envision evolution proceeding dimensions 
plc currently allows resources bound slice specified simple share duration pair exposing detailed accepted node manager 
share specifies relative share node cpu link capacity slice may consume duration indicates period time allocation valid 
plc policy specifies translate share value user valid node manager 
time expect plc expose structure directly users imposing policy resource allocation decisions 
decided initially hide node manager interface semantics defined point divide resources units open problem compensate difficulty fields meaningful individual schedulers node 
second significant interest developing brokerage services establish resource value demand site purchasing capacity resources contributes 
plc currently simple model site receives equal number shares redistributes projects site 
plc allocates shares directly certain infrastructure services including experimental brokerage services allowed redistribute services 
long term envision site administrator deciding employ different possibly multiple brokerage services giving fraction total capacity 
effect site administrators currently allocate resources plc default 
date plc supports additional brokerage services emulab sharp 
emulab supports short lasting network experiments pooling set planetlab resources establishing batch queue slices able serialize access 
useful times heavy demand conference deadlines 
sharp secure distributed resource management framework allows agents acting behalf sites exchange computational resources secure fully decentralized fashion 
sharp agents peer trade resources peering partners cryptographically signed statements resources 
network virtualization planetlab os supports network virtualization providing safe version linux raw sockets services send receive ip packets root privileges 
sockets safe respects 
raw socket bound particular tcp udp port receives traffic port conflicts avoided ensuring socket type standard tcp udp raw sending particular port 
second outgoing packets filtered sure local addresses headers match binding socket 
safe raw sockets support network measurement experiments protocol development planetlab 
safe raw sockets monitor traffic slice 
sniffer socket bound port opened vm socket receives copies packet headers sent received port 
additionally sufficiently privileged slices open special administrative sniffer socket receives copies outgoing packets machine tagged context id sending vserver administrative socket implement traffic monitoring facility described section 
interface standard linux raw socket captures incoming ip packets allows writing arbitrary packets network 
contrast safe raw socket bound specific udp tcp port receives packets matching protocol port bound 
outgoing packets filtered ensure formed source ip udp tcp port numbers spoofed 
safe raw sockets standard linux socket api minor semantic differences 
just standard linux raw socket created socket system call difference necessary specify tcp udp protocol field 
bound particular local port specified protocol system call 
point socket send receive data usual sendto sendmsg recvfrom calls 
data received includes ip tcp udp headers link layer header 
data sent default need include ip header slice wants include ip header sets socket option socket 
icmp packets sent received safe raw sockets 
safe raw icmp socket bound local tcp udp port icmp identifier depending type icmp messages socket receive send 
get icmp packets associated specific local tcp udp port destination unreachable source quench redirect time exceeded parameter problem icmp socket needs bound specific port 
exchange icmp messages associated specific tcp udp port echo echo reply timestamp timestamp reply information request information reply socket bound specific icmp identifier bit field icmp header 
messages containing bound identifier received sent safe raw icmp socket 
planetlab users debug protocol implementations applications sniffer raw sockets 
slices lack necessary capability put network card promiscuous mode standard way 
sniffer raw socket bound tcp udp port previously opened vserver socket receives copies packets sent received port send packets 
utility called opens sniffer socket pipes packets tcpdump parsing user get full tcpdump style output connections 
implementation safe raw sockets implemented silk kernel module intercepts incoming ip packets linux interface linux socket safe raw socket 
packets demultiplex linux socket returned linux protocol stack processing demultiplex safe raw socket placed directly socket queue maintained silk 
packet sent safe raw socket silk intercepts wrapping socket sendmsg function kernel verifies addresses protocol port numbers packet headers correct 
packet passes checks handed linux protocol stack standard raw routine 
silk port manager maintains mapping port assignments vservers serves purposes 
ensures port opened simultaneously tcp udp socket safe raw socket sniffer sockets excluded 
implement silk wrap bind connect sendmsg functions standard tcp udp sockets kernel error returned attempt bind local tcp udp port safe raw socket 
words silk port manager approve deny requests bind port just safe raw sockets 
second bind called sniffer socket port manager verify port free opened vserver attempting bind 
port free sniffer socket bound port owned vserver vserver open socket port 
third silk allows node manager described section reserve specific ports particular vserver 
port manager stores mapping reserved port considered owned vserver attempts vservers bind port fail 
discussion driving application safe raw sockets network measurement service 
provides users ability execute measurement scripts send arbitrary ip packets originally written privileged raw sockets 
example implements versions ping traceroute needs send icmp packets udp packets ip ttl field set 
requires ability generate tcp syn packets containing data bottleneck bandwidth estimation 
safe raw sockets allowed quickly ported planetlab simply adding calls 
users safe raw sockets modified versions traceroute ping run vserver linux utilities typically run root privileges order open raw socket 
safe raw sockets implement user level protocol stacks variants tcp tuned high bandwidth pipes packet re ordering striping multiple overlay paths 
bsd tcp library currently runs planetlab 
safe raw sockets just example planetlab services need able share certain address spaces 
emerging example slices want customize routing table control ip tunneling packets 
example need share access known ports multiple services want run dns servers 
case adopting approach similar raw sockets partition address space doing early demultiplexing low level kernel 
second case plan implement user level 
case single service granted privileged exclusive access address space 
monitoring monitoring tools clearly required support distributed infrastructure planetlab runs hundreds machines worldwide hosts dozens network services interact internet complex unpredictable ways 
managing infrastructure collecting storing propagating aggregating discovering reacting observations system current conditions difficult challenges facing planetlab 
consistent principle management defined low level sensor interface uniformly exporting data underlying os network individual services 
data exported sensor simple process load average node complex peering map autonomous systems obtained local bgp tables 
sensors encapsulate raw observations exist different forms pro vide shared interface alternative monitoring services 
interface sensor provides pieces information available derived local node 
sensor server aggregates sensors single access point providing controlled sharing sensors clients monitoring services 
obtain sensor reading client request sensor server 
sensor outputs tuples untyped data values 
tuple sensor conforms schema 
sensor thought providing access potentially infinite database table 
sensor semantics divided types snapshot streaming 
snapshot sensors maintain finite size table tuples immediately return table subset queried 
range single tuple rarely varies number processors machine circular buffer constantly updated snapshot available clients instance times connect system calls associated slices 
streaming sensors follow event model deliver data asynchronously tuple time available 
client connects streaming sensor receives tuples sensor server closes connection 
precisely sensor server compliant server implementing subset specification get head methods listening requests particular port 
requests come form uniform resource identifiers uris get methods 
example uri localhost nodes ip name request sensor named nodes sensor server listening port 
portion uri sensor name ip name interpreted sensor 
case nodes sensor returns comma separated lines containing ip address dns name registered planetlab node 
selected sensor server protocol straightforward supported protocol 
primary format data returned sensor text file containing easy parse comma separated values 
implementation assortment sensor servers implemented date consist stripped server encapsulating existing source information 
example sensor server reports various information kernel activities 
sensors exported server essentially wrappers proc file system 
example sensors include returns information current memory usage load returns minute load average load returns minute load average uptime returns uptime node seconds bandwidth slice returns bandwidth consumed slice id 
examples simple respects 
require virtually processing simply parse filter values available proc 
second stream information maintain history 
easily imagine variant example streams bandwidth consumed slice minute period updated minutes returns table readings 
contrast complex sensor server shortly available reports information local host connected internet including path information returned peering relationships determined local bgp feed latency information returned ping 
sensor server illustrates sensors may expensive invoke possibly sending receiving messages internet respond result may cache results earlier invocations 
discussion sensor abstraction emerging collection sensor implementations assortment monitoring services deployed 
services modeled distributed query processors including pier sophia irisnet 
long term goal monitoring services detect reason react anomalous behavior disruptive 
planetlab immediate need responding disruptions fact 
frequently past year traffic generated planetlab researchers caught attention isps academic institutions web sites home users 
nearly cases problems stemmed na service design analysis programmer errors hyper sensitive intrusion detection systems 
examples include network mapping experiments probe large numbers random ip addresses looks scanning worm services aggressively traceroute ing certain target sites different ports looks services performing distributed measurement target site looks ddos attack services sending large numbers icmp packets bandwidth problem renders low routers unusable 
addressing complaints requires auditing tool map incident responsible party 
specifically traffic auditing service runs planet lab node snooping outgoing traffic administrative raw sniffer socket provided silk module tags packet id sending vserver 
packet auditing service logs time sent ip source destination protocol port numbers tcp flags applicable 
generates web pages node summarize traffic sent hour ip destination slice name 
hope administrator site receives questionable packets planetlab machine type machine name ip address browser find audit generated pages contact experimenters traffic 
example admin clicks ip address destination summary page shown planetlab accounts sent packet address hour provided links send email researchers associated accounts 
link directs admin network traffic database www planet lab org back logs archived queries origin traffic sent earlier hour ago 
experience traffic auditing service mixed 
hand planetlab support team useful responding traffic queries receiving complaint web interface identify responsible party forward complaint 
result reduction incident response time time invested support staff incident 
hand external site administrators find web page choose 
example receiving strange packet planetlab cs princeton edu sites respond sending email abuse princeton edu time support team receives complaint bounced levels university administration 
may able avoid indirection providing reverse dns mappings nodes planet lab org requires effort site sponsors planetlab nodes 
finding mechanisms decentralize process ongoing 
experience date involved implementing querying read sensors safely accessed untrusted monitoring services easily imagine planetlab supporting set actuators trusted management services control planetlab 
example actuator terminates slice sophia expression written kill slice violated global bandwidth consumption limits 
today slice termination exposed actuator implemented node manager invoked trusted plc service authenticated network operator remotely logs node manager 
evaluation section evaluates aspects slice creation initialization 
vserver scalability scalability vservers primarily determined disk space vserver root filesystems service specific storage 
planetlab vserver created root filesystem points back trimmed root filesystem comprises directories files covering mb disk 
vserver primitive cow files excluding var vserver root filesystem mirrors root filesystem requiring mb disk space original root filesystem size 
mb consists mb copy var mb copy mb create directories kb directory 
reduction vserver disk footprints afforded cow able create vservers single planetlab node 
push disk space sharing true filesystem cow applying techniques systems windows single instance store 
kernel resource limits secondary factor scalability vservers 
vserver provided illusion virtual execution environment remains single copy underlying operating system associated kernel resources 
heavy degrees concurrent vserver activity possible limits kernel resources may exposed consequently limit system scalability 
observed file descriptors 
nature limits different large degrees concurrency resource usage single vserver unmodified linux kernel 
cases solution simply extend kernel resource limits recompiling kernel 
course simple scaling kernel resources may insufficient inefficient algorithms employed kernel searches linked lists 
far run types algorithmic bottlenecks 
slice creation section reports long takes node manager create vserver single node 
current implementation plc node poll slice creation instructions minutes artifact piggybacking slice creation mechanism existing software update machinery 
remains seen rapidly slice deployed large number nodes 
create new slice specific node slice creation service complete steps node 
slice creation service contacts port mapping service find port node manager xml rpc server listening requests 
slice creation service performs node manager acquire rpc obtain rcap immediate rights vserver best effort resource usage 
slice creation service performs node manager bind rpc bind ticket new slice name 
node manager completing rpcs creates new vserver notifies necessary resource schedulers effect newly added resource bindings new slice 
node manager calls instantiate vserver calls vserver init start execution software new vserver 
running ghz pentium steps complete seconds average 
long fourth fifth steps takes depends user wants initialize slice 
minimum vserver creation initialization takes additional seconds average 
include time load initialize service software packages 
assumes hit warm cache vservers 
creating new vserver scratch takes minute 
service initialization section uses example service sophia demonstrate long takes initialize service slice exists 
sophia slice managed combination rpm apt get custom slice tools 
sophia slice created loaded appropriate environment 
accomplished executing boot script inside vserver 
script downloads installs apt get tools root sophia slice rpm starts update process 
apt get update process periodically downloads tree current packages specific sophia slice 
newer package rpm hierarchy dependencies download installed 
mechanism new versions packages directly pushed nodes published sophia packages tree 
slice update mechanism polls potentially followed action request push package tree performs upgrade actions 
current setting takes average seconds perform empty update node download package tree find new upgrade 
new sophia core package needs upgraded time increases seconds node 
operations occur parallel slice upgrade time bound sum node update times 
slice considered upgraded active nodes finished upgrading 
run nodes average update time corresponding slowest node seconds 
performance improved example better distribution mechanism 
faster alternative rpm package dependencies system improve locally performed dependency checks 
experience providing network research community platform planetary scale services planet lab os evolved set mechanisms support distributed virtualization management 
design allows network services run slice planetlab global resources planetlab os providing local node abstractions global network wide functionality possible pushed infrastructure services running slices 
slice creation coupled resource allocation slice termination run global privileged service long term expect set alternative infrastructure services emerge supplant bootstrap services 
andersen balakrishnan kaashoek morris :10.1.1.161.2760
resilient overlay networks 
proc 
th sosp pages banff alberta canada oct 
balazinska balakrishnan karger 
ins twine scalable peer peer architecture intentional resource discovery 
proc 
pervasive pages zurich switzerland aug 
banga druschel mogul :10.1.1.41.1733
resource containers new facility resource management server systems 
proc 
rd osdi pages new orleans la feb 
barham fraser hand harris ho neugebauer pratt warfield 
xen art virtualization 
proc 
th sosp lake george ny oct 
voigt peterson 
silk scout paths linux kernel 
technical report department information technology uppsala university uppsala sweden feb 
black barham donnelly 
protocol implementation vertically structured operating system 
proc 
ieee conf 
comp 
networks nov 
bolosky goebel douceur 
single instance storage windows 
proc 
th usenix windows sys 
symp pages seattle wa aug 
chu rao zhang 
case system multicast 
proc 
sigmetrics pages santa clara ca jun 
chun lee weatherspoon 
distributed worm detection service 

planet lab org 
chun 
slice creation management jun 
www planet lab org 
dabek kaashoek karger morris stoica 
wide area cooperative storage cfs 
proc 
th sosp pages banff alberta canada oct 
dike 
user mode linux 
proceedings th annual linux showcase conference oakland ca nov 
engler kaashoek 
dpf fast flexible message demultiplexing dynamic code generation 
proc 
sigcomm pages stanford ca aug 
virtual private server 
www com products materials datasheet vps pdf 
fielding gettys mogul frystyk masinter leach berners lee 
hypertext transfer protocol rfc 
internet req 
jun 
foster kesselman nick tuecke :10.1.1.114.2815
physiology grid open grid services architecture distributed systems integration 
www org wg drafts ogsa draft pdf jun 
fu chase chun schwab vahdat 
sharp architecture secure resource peering 
proc 
th sosp lake george ny oct 
hardy 
keykos architecture 
operating systems review oct 
harren hellerstein huebsch loo shenker stoica 
complex queries dht peer peer networks 
proc 
st int 
workshop peer peer systems iptps cambridge ma mar 
jin wei low choe cottrell doyle feng martin newman singh 
fast tcp theory experiments apr 
submitted publication 

kamp watson 
confining omnipotent root 
proc 
nd int 
sane conf maastricht netherlands may 
kubiatowicz bindel chen czerwinski eaton geels gummadi rhea weatherspoon weimer wells zhao 
oceanstore architecture global scale persistent storage 
proc 
th asp los pages cambridge ma nov 
leslie mcauley black roscoe barham :10.1.1.28.6923
design implementation operating system support distributed multimedia applications 
ieee sel 
areas comm 
linux advanced routing traffic control 
org 
linux vservers project 
linux vserver 
org 
litzkow livny mutka 
condor hunter idle workstations 
proc 
th icdcs pages san jose ca jun 
mercer savage tokuda 
processor capacity reserves operating system support multimedia applications 
int 
conf 
multimedia computing systems pages boston ma may 
mosberger peterson 
making paths explicit scout operating system 
proc 
nd osdi pages seattle wa oct 
nath ke gibbons karp seshan 
irisnet architecture enabling sensor enriched internet service 
technical report irp tr intel research pittsburgh jun 
peterson anderson culler roscoe :10.1.1.109.4681
blueprint introducing disruptive technology internet 
proc 
hotnets princeton nj oct 
peterson hartman muir roscoe bowman 
evolving slice abstraction jan 
www 
planet lab org 
silk planetlab 
www cs 
princeton edu acb 
ratnasamy handley karp shenker 
topologically aware overlay construction server selection 
proc 
infocom pages new york city jun 
rowstron druschel 
pastry scalable distributed object location routing large scale peer peer systems 
proc 
th middleware pages heidelberg germany nov 
rowstron druschel 
storage management caching past large scale persistent peer peer storage utility 
proc 
th sosp pages banff alberta canada oct 
spring wetherall anderson 
facility distributed internet measurement 
proc 
th usits seattle wa mar 
stoica morris karger kaashoek balakrishnan 
chord peer peer lookup service internet applications 
proc 
sigcomm pages san diego ca aug 
subramanian stoica balakrishnan katz 
overqos offering internet qos overlays 
proc 
hotnets princeton nj oct 
wang pai peterson 
effectiveness request redirection cdn robustness 
proc 
th osdi pages boston ma dec 
peterson roscoe 
sophia information plane networked systems 
proc 
hotnets ii cambridge ma nov 
whitaker shaw gribble 
scale performance denali isolation kernel 
proc 
th osdi pages boston ma december 
white lepreau stoller ricci hibler barb :10.1.1.11.3768
integrated experimental environment distributed systems networks 
proc 
th osdi pages boston ma dec 
zhang karp floyd peterson 
rr tcp reordering robust tcp dsack 
proc 
th icnp atlanta ga nov 
