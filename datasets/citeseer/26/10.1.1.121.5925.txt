workload specific file system benchmarks thesis keith arnold smith division engineering applied sciences partial fulfillment requirements degree doctor philosophy subject computer science harvard university cambridge massachusetts january copyright keith arnold smith rights reserved didn understand daddy late fundamental problem current generation file system benchmarks fail take account fact file system performance vary depending workload running 
benchmarks attempt reduce file system perfor mance single number producing simplistic dimensional ordering sys tems tested 
may useful marketing literature performance file systems real world complicated 
different workloads place different demands file system result different behavior underlying sys tem 
file system provides superior performance web server may inferior performance running software development workload 
dissertation demonstrate size fits approach current file system benchmarks accurately predict performance different workloads different file systems 
new benchmarking methodology predicts file system performance context specified workload allows researchers developers isolate areas file system performance greatest bottlenecks particular workloads 
time harvard fortunate enjoy advice support encouragement friends colleagues 
dissertation completed 
foremost advisor margo seltzer provided invaluable assistance guidance stage graduate career 
margo available willing help problem facing large small completely unrelated graduate studies 
guided project showed conduct computer systems research 
imagine coming far margo guidance counsel imagine working project referring back lessons learned 
thesis committee margo brad chen ugo barbara grosz provided essential guidance especially finishing dissertation 
patient seemingly endless delays completing comments suggestions improved understanding research 
am grateful graduate student colleagues brainstorming sessions lunch dates endless conversation topics ranging compiler optimization chinese culture 
chris small past office mate provided help step way configuring new machines re learning drive car 
catherine zhang patiently listened details job search 
endo taught value power drill 
cliff young ideal lunch companion 
baker provided tea cookies friendship year courses distributed algorithms computer graphics 
david holland sharp eyes quick mind helped find innumerable bugs software 
experiences enlightening lecture alan perlis introductory computer science course yale 
moment intention computer science viewed learning program 
imagine studying 
enthusiasm subject probably electrical engineer 
wish parents 
dad explained rockets televisions airplanes 
taught worth doing worth doing right 
mom gave lessons computers programming born 
encouraged pursue interests satisfy 
love support encouragement set trajectory brought graduate school 
extend deepest love gratitude wife horne 
encouraged return school pursue masters doctorate consequences advice 
patient supportive including final 
having center life helped keep trials graduate study perspective 
completed love 
table contents dissertation overview contributions background file system architecture general file system architecture unix file system architecture berkeley fast file system fast file system architecture fast file system evolution clustered soft updates file system workloads methodology workload differences differences workloads differences time differences operating systems netnews workloads file system benchmarks file system microbenchmarks file system macrobenchmarks file system aging motivation empty file systems life time evolution file system aging generating workload replaying workload workload verification applications aging indirect block allocation fragment allocation ffs workload specific performance analysis motivation existing benchmarking techniques goals application specific benchmarking general approach limiting assumptions file system characterization microbenchmark goals microbenchmark selection pathname resolution request size cache state access pattern file truncation file attributes asynchronous overhead microbenchmarks microbenchmark design implementation workload characterization workload specific performance analysis preprocessing cache simulator pattern analyzer performance analyzer postprocessing understanding results validation test environment methodology workloads kernel build sdet postmark evaluation kernel build results script sdet results multiple script sdet results postmark results summary results related file system aging workload specific benchmarks application benchmarks trace driven simulations file system simulations machine performance characterization hbench hbench os hbench java hbench hbench web modeling lessons learned development process benefits hbench fs architecture hbench fs details simulating partial block writes simulating sparse files additional sources background pathname lookup read request sizes truncate size argument lookup failures appendix hbench fs input formats trace format trace library snapshot format system profile format list figures 
sample ffs block layout 
effect utilization file system performance 
effect aging file system behavior 
real vs simulated file system 
fragmentation function file size 
performance baseline 
performance improved indirect block allocation 
file layout smart fragment allocation 
performance smart fragment allocation 
file system comparison 
hbench fs high level architecture 
example asynchronous overhead 
hbench fs tool chain 
processing sample trace 
sample hbench fs output 
measured predicted kernel build performance 
kernel build performance breakdown 
kernel build latency distribution 
slow ffs kernel build distribution latencies 
fast ffs kernel build distribution latencies 
script sdet performance 
slow ffs latency distributions script sdet workload 
slow ffs su latency distributions script sdet workload 
fast ffs latency distributions script sdet workload 
fast ffs su latency distributions script sdet workload 
multiple script sdet performance 
postmark performance 
slow ffs latency distributions postmark workload 
hbench fs accuracy 
trace data structures 
sample trace processing program 
sample snapshot list tables table 
benchmark configuration table 
number split files noswitch file systems table 
performance modified files noswitch file system table 
sample microbenchmark results table 
file system interface table 
characteristics file system calls table 
hbench fs microbenchmarks table 
test hardware configuration table 
test configurations table 
hbench fs error summary table 
hbench fs prediction errors test configuration table 
hbench fs prediction errors workload table 
operation types table 
flag values table 
operation class definitions table 
request vector components table 
relationship values table 
string order chapter keynote address symposium operating systems design imple mentation david patterson observed better worse benchmarks shape field patterson benchmark gains wide spread acceptance vendors researchers benchmark yardstick measuring improvements sys tems 
important focus improving system performance improve sys tem benchmark results 
narrow focus benchmark results bad depending quality benchmark 
benchmark accurately reflects usage patterns important class applications provides results predict performance applications 
benchmark targeting system improvements increase benchmark performance results better performance users 
contrast poor benchmark leads researchers developers tune systems ways improve benchmark results provide little benefit user 
field computer file systems find worse spectrum 
standard benchmarks exist significant flaws 
survey research papers published showed file system researchers seldom standard benchmarks small 
commonly benchmark study andrew benchmark howard frequently mis 
fundamental problem current generation file system benchmarks fail take account fact file system performance vary depending workload running 
benchmarks attempt reduce file system performance single number producing simplistic dimensional ordering systems tested 
may useful marketing literature performance file systems real world complicated 
different workloads place different demands file system result different behavior underlying system 
file system provides superior performance web server may inferior performance running software development workload 
dissertation demonstrate size fits approach current file system benchmarks accurately predict performance different workloads different file systems 
new benchmarking methodology predicts file system performance context specified workload allows researchers developers isolate areas file system performance greatest bottlenecks particular workloads 
dissertation overview different types file system workloads widely different characteristics benchmark take account target workload file system may poor predictor particular workload perform file system 
chap ter survey range common workloads file system may encounter exam ine important differences 
discuss existing benchmarks 
chapter provides background information architecture implementa tion file systems dissertation 
major problems existing file system benchmarks 
problem typically conducted file systems empty state rarely seen real users 
second problem file system benchmarks answer question users ask workload perform file system chapter address problem presenting technique called file system aging 
benchmarking file system artificial workload generated real file system usage patterns age file system 
aging workload reproduce effect months years file system activity 
applying aging workload file system prior running benchmarks creates benchmarking environment representative file system state typically seen real world 
fixed aging workload researcher age file systems reproducible manner 
similarly applying workload different file systems see differences file system architecture affect long term file system behavior 
aging workload generated traces snapshots real file system aging workloads representative different types file system activity created data collected different file system 
address second problem predicting performance particular workload particular file system developed benchmarking framework called hbench fs separates evaluation test file system evaluation workload 
chapter describe scheme vendor run series microbenchmarks file system 
resulting microbenchmark vector system vector provides quantitative measurements wide range simple file system operations creating reading file 
potential customers characterize workload tracing 
hbench fs takes file system trace system vector inputs combine predict latency operation trace 
summing predicted latencies operations trace accurately predict relative performance workload different file systems 
separating workload file system evaluation provides important benefits 
allows researchers developers explore scenarios 
attempting optimize piece file system researcher easily determine application benefit contemplated improvement modifying system vector new vector analyze workload 
separating file system evaluation workload analysis possible users evaluate products different vendors having access hardware question 
current situation users able perform comparison context workload comparing single benchmark number provided different vendors 
having performance predictions operation basis allows useful types performance analysis 
user may example know certain operations critical occur user waiting response look performance operations 
similarly researcher analyze performance workload terms time going determining types operations longest latencies consume file system time 
chapter provides survey related areas computer science 
chapter describe existing techniques file system benchmarking tools analyzing system behavior context particular application workload application specific benchmarking tools techniques areas computer science 
summarize results chapter 
contributions dissertation contributions demonstrate benchmarking empty file systems best inaccurate worst misleading 
show simple technique artificially aging file systems provides accurate meaningful results traditional approach benchmarking empty file systems 
show different workloads place different demands file systems simple dimensional performance evaluation inadequate predict particular application perform specific file system architecture 
suite file system benchmarking tools hbench fs analyze performance file system context specific workload interest 
hbench fs provides accurate predictions relative performance different file systems executing workload 
provides fine grained performance information file system application architects locate eliminate performance bottlenecks 
chapter background chapter provide background information architecture implemen tation file systems dissertation 
discuss techniques collecting data file system workloads survey range common loads file system may encounter examining important differences 
provide brief overview traditional file system benchmarks 
file system architecture section provides overview file system design implementation focusing aspects file system architecture largest impact performance 
discussion focuses berkeley fast file system ffs native file system various bsd implementations unix operating system 
mature optimized file system influenced design commonly file system architectures including linux ext fs beck 
file system examples demonstrations dis 
general file system architecture computer systems typically provide storage form files 
file system imple ments storage abstraction top storage peripherals attached host com puter typically hard disks 
file system exports interface allowing clients read write manipulate files 
traditional desktop system file system clients user applications executing machine 
network file systems nfs sandberg allow clients remote machines share access files server machine 
file system consists persistent disk data software provides access data 
disk representation file system essentially large data structure 
file system software implements various algorithms manipulating disk data 
possible completely different software implementations disk file system 
allows developers add new features performance enhancements existing file systems requiring users re initialize disk file systems 
allows completely different implementations disk file systems 
unix systems example provide support ms dos file systems may resident local disk forin 
addition file data file system stores variety internal data structures disk 
meta data provides information file system needs access manipulate file data 
meta data includes global file system information disk blocks allocated file information location file data disk file name 
modern file systems directories provide hierarchical namespace 
directory object contains names files directories internal pointers file system find named objects 
providing flat namespace containing names files system directories allow file systems organize files tree hierarchy 
directories implemented special 
file systems provide support links known shortcuts aliases allow multiple names point file 
systems namespace forms directed graph simple tree 
type file supports special operations manipulated operating system 
unix file system architecture unix systems implement files ordered stream bytes 
basic unit data transfer application file single byte 
efficiency applications usually read write larger units data file system imposes requirement 
applications may read data location file 
default behavior file system keep track offset byte transferred file 
successive requests start subsequent byte file 
writing data application may overwrite existing data file append file 
file system provide mechanism inserting deleting data middle file 
way accomplish actions rewrite file contents point insertion deletion 
unix systems allow support multiple file system implementations system 
allows single system access files native file systems ffs dos windows partitions machine remote file systems machines 
unix provides support multiple file system implementations virtual file system vfs interface kleiman 
vfs provides uniform interface file systems supported unix kernel 
conforming interface developers create new file systems easily integrate kernel 
essence object oriented approach implementing files file systems unix kernel 
kernel dispatches file system operations appropriate file system implementation pointers stored file file system data structures 
unix systems provide number services file system implementations 
disk media file systems reside typically 
contrast record oriented file systems require file performed records 
record oriented file systems may support single record size file may allow variable sized records 
record oriented file systems allow insertion deletion records arbitrary points file 
orders magnitude slower main memory kernel attempts cache frequently data memory 
allows system avoid repeated requests disk receives multiple requests data 
primary cache file data called buffer cache contains copies accessed data blocks 
operating system typically replaces cache blocks lru manner 
optimize performance avoid making applications block disk unnecessarily file systems attempt overlap requests application computation 
prefetching blocks disk applications request system tries avoid forcing applications stall waiting data disk 
similarly operating system may write dirty data buffer cache disk asynchronously write requests return application blocking disk 
systems size buffer cache fixed boot time 
systems solaris sprite netbsd allow amount memory caching file data grow shrink relative demands file system virtual memory activity nelson cranor 
raw data blocks containing file system meta data usually stored buffer cache regular file data blocks kernel provides separate caches frequently accessed types meta data 
name cache called directory name lookaside cache stores results name lookup operations attribute cache vnode cache stores attributes meta data accessed files 
caches avoid overhead repeatedly translating raw meta data provide fast access contents corresponding meta data blocks evicted buffer cache 
file system satisfy requests data various caches 
reads writes data underlying disk system 
operating system provides simple block oriented interface disk devices 
file system performs operations multiples fixed block size 
minimum block size determined disk sector size smallest possible size typically bytes file systems larger block sizes performance benefits come issuing large sequential requests disk 
older file systems designed exploit geometry underlying disk allocated space files 
current trends disk storage technology impossible current file systems 
contrast older disk drives divided tracks constant number sectors modern disks maximize usable storage space increasing number sectors track distance track disk spindle 
constant angular velocity disks difficult file system determine exploit disk geometry real problem comes large scale storage systems hewlett packard autoraid presents standard scsi disk interface host system stores data different formats multiple internal disks wilkes 
reliable knowledge geometry performance characteristics underlying storage media behavior contemporary file systems rely sequentially numbered disk blocks organized way optimize sequential blocks 
single disk sequentially numbered blocks typically correspond adjacent blocks track 
general means optimal file layout allocate logically sequential file blocks physically sequential disk blocks 
berkeley fast file system early kirk mckusick colleagues computer systems research group berkeley developed berkeley fast file system ffs mckusick 
released part berkeley software distribution unix bsd 
de facto standard file system bsd derived unix implementations including freebsd bsd os solaris digital unix 
ffs file system research dissertation section provides overview design implementation 
section discusses evolution ffs architecture initial 
complete description ffs available design implementation bsd operating system mckusick 
fast file system architecture ffs places superblock fixed location disk partition 
block summarizes state file system includes global file system information file system block size number blocks disk partition various parame ters governing file layout policy pointers disk locations meta data structures 
file ffs described disk data structure called inode index node 
data structure contains information file attributes pointers blocks containing file data 
attribute information includes file owner group access permissions size bytes times file accessed modified 
inode fixed size data structure bytes limited amount space list disk blocks allocated file 
allow arbitrarily large files ffs uses indirect addressing scheme illustrated similar original unix file system ritchie 
inode contains pointers fifteen disk blocks 
twelve pointers contain addresses twelve blocks file 
larger files ffs uses remaining block pointers inode point indirect blocks 
points singly indirect block containing pointers additional file data blocks 
points doubly indirect block contains pointers additional singly indirect blocks turn hold pointers file data blocks 
inode pointer indirect block containing pointers additional double indirect blocks 
file system default block size kilobytes scheme allows file sizes terabytes 
ffs allocates indirect blocks demand file grows large require 
ffs stores directories manner files 
ffs sets flag bit inode indicate file interpreted directory regular file 
file directory disk directory file contains file name inode number file 
ffs stores inode root directory fixed location inode number 
ffs divides underlying disk partition allocation pools called cylinder groups 
original ffs implementation cylinder group corresponded number consecutive cylinders physical disk 
difficult determine cylinder size modern disks current ffs implementations simply allocate fixed number blocks cylinder group 
blocks cylinder group data blocks 
ffs allocate file data blocks indirect blocks 
fixed set blocks cylinder group hold inodes multiple inodes stored block 
number cylinder groups number inodes cylinder group fixed file system initialized total number inodes file attributes 
block pointers 
inode file data blocks 
triple indirect block 
double indirect blocks indirect blocks 
sample ffs block layout 
depicts file bottom inode top indirect blocks inode uses list file data blocks 
inode contains twelve direct block pointers point twelve data blocks file 
inode contains indirect block pointers point single double triple indirect block 
addition block pointers inode contains file attributes 
file represents maximum number files directories created file system 
cylinder group contains bookkeeping information including bitmaps indicating blocks inodes allocated redundant copy superblock disaster recovery 
ffs uses cylinder groups allocation pools attempts exploit expected patterns locality related items cylinder group 
example ffs tries allocate files cylinder group directory cylinder group files directory 
important issue file systems maintaining file system integrity face possible system failure 
especially important file system operations modify piece data meta data file creation deletion 
ffs creates new file writes pieces meta data initializes file inode writes new file name appropriate directory pointer inode 
naive implementation variety states possible system crashed just creating file depending modifications reached disk 
scenario new directory entry written disk system failure newly initialized inode 
rebooting file system directory entry referenced invalid inode 
situation result variety unexpected behaviors 
traditionally ffs taken steps avoid sort problem 
ffs requires file system operation modifies piece meta data meta data modifications written disk predefined order 
allows consistency checking program fsck scan file system crash detect correct problems described 
ffs meets requirement synchronously writing piece meta data 
sufficient ensure file system integrity introduces large performance penalty 
file system operation requires synchronous meta data updates complete disk speeds 
ffs attempts guarantee integrity file system meta data system failure 
user file data may corrupted 
cpu memory speeds 
problem addressed ffs soft updates see section 
fast file system evolution years fast file system benefited variety optimizations improvements 
sections summarize important improvements focusing included main stream ffs implementations provided various bsd unix kernels 
interesting potentially useful optimizations proposed research literature 
clustered original implementation fast file system performed block time 
application requested kilobyte read file system kilobyte block size generate separate disk requests individual block 
event blocks contiguous disk system incur overhead seek latencies rotational delays disk head moved block 
mcvoy kleiman addressed problem implementing clustered sunos version ffs mcvoy 
margo seltzer colleagues added clustered bsd unix version ffs seltzer 
modified ffs allow issue disk requests multiples block size maximum cluster size 
value typically configured kilobytes maximum scsi request size 
clustered allowed ffs issue disk requests spanning multiple blocks ffs offer guarantees size clusters allocates disk 
attempts allocate maximally sized clusters actual cluster sizes may smaller depending availability contiguous free space 

prior clustered ffs typically tuned attempt allocate block disk file disk interleave 
best case throughput single file typically half raw throughput available underlying disk mcvoy 
clustered enhancement ffs usually reads block requested application rest cluster containing final block application request 
eliminates need additional disk request case application continues reading file sequentially 
similarly ffs queue writes disk application written data fill cluster 
subsequent examination disk file layout showed ffs frequently allocated small clusters new files large extents contiguous free space available disk seltzer 
response problem kirk mckusick implemented sophisticated disk allocation algorithm dynamically reallocated data new locations disk order achieve larger cluster sizes 
reallocation occurs relevant data dirty buffer cache algorithm introduce additional disk evaluating benefits new algorithm led develop file system aging techniques discussed chapter smith 
demos operating system early example clustered demos ran cray computer los alamos scientific laboratory needed provide high file throughput powell 
kent peacock introduced file clustering unix adding system file system peacock 
soft updates noteworthy enhancements ffs soft updates technique avoid synchronous meta data update problem described section 
soft updates meets ffs requirement meta data updates writ disk fixed order maintaining detailed information relationships cached items meta data 
soft updates uses dependency information guar individual pieces meta data written correct order 
allows ffs perform meta data updates asynchronously relying soft updates 
circumstances ffs may prefetch additional cluster data cluster user currently reading 
ensure ordering requirements met 
soft updates eliminates disk bottleneck meta data intensive workloads run times faster ffs soft updates ganger 
soft updates alternative common approach journaling file system eliminate synchronous meta data updates chang seltzer file system workloads primary goals file system design hide slow speed disk techniques caching prefetching delayed write back 
file sys tem issue synchronous requests disk file system designers attempt mini latency related data region disk 
optimizations incorporate assumptions behavior file access patterns user level applications 
common prefetching policies example assume files read sequentially 
order better understand file systems researchers studied file access patterns different workload different com puting environments 
john ousterhout colleagues university california berkeley published landmark study file system usage patterns bsd unix fast file system ousterhout 
study conducted server berkeley computer science department results document usage patterns seen environment 
years seen publication variety similar studies 
studies examined file system usage changed initial bsd study 
researchers data file system usage different computing environments vax vms windows nt different types workloads scientific computing web servers 
section provide overview file system usage studies emphasis file system usage varies different workloads 
methodology major techniques researchers collect data file sys tem usage patterns snapshots traces 
snapshot static description file system state single instant time 
snapshot typically collected program scans file system corresponding disk collects desired information 
con trast file system trace describes file system usage file system state 
trace dynamically collected record operations issued file system period time 
data collection techniques offers advantages disadvantages 
snapshots suffer fact provide information manner file system accessed 
looking snapshots collected file system different times possible infer file system activity occurred snapshots impossible infer 
example file access time changed snapshots infer file accessed specified time 
impossible know times file accessed 
file system traces provide complete information types accesses file system provide information state files don appear trace 
example file system trace tell percentage files file system accessed trace 
complete technique understanding file system usage combine file system trace snapshot collected trace period 
snapshot allows trace interpreted context file system state time trace collected 
example trace record numerical identifier file accessed snapshot provide information needed map identifiers names corresponding files 
snapshot trace 
researchers emphasized difference static dynamic data collection snapshots traces respectively bennet 
accurate distinction believe important focus fact snapshots traces contain fundamentally different types data 
researchers example conducted studies series snapshots taken minutes file system bennet chiang 
dynamic data conveys different information trace 
possible model state changes trace operation causes providing accurate view file system state point trace 
choice data include file system snapshot trace researcher collecting data 
contemporary systems provide utilities collect snapshots traces 
tools listing files performing backups generate snapshots 
various system monitoring profiling tools generate traces bsd unix systems linux trace toolkit 
studies researchers built tools instrumented systems hand needed customize type data collected 
case researcher typically constrained types data available amount time space available collect store data 
common concern collecting file system traces operations performed tracing tools may interfere workload traced 
tracing system performs file system operations resulting trace dominated tracing system 
similarly tracing infrastructure uses system resources system performance may degrade point system longer useful 
minimize interference researchers restrict types amount data collect 
time faster computers larger storage systems allowed researchers collect increasingly detailed file system data 
types data included snapshots traces increased durations traces 
example study bsd fast file system ousterhout colleagues examined traces recorded types file system operation approximately days ousterhout 
contrast study roselli anderson collected traces different types file system operation time periods months roselli 
complete discussion numerous studies file system usage patterns scope thesis 
satyanarayanan provide thorough brief survey file system usage studies 
important studies include snapshot trace studies windows nt file system usage douceur vogels douceur vogels drew roselli examination long term file access patterns hp ux windows nt roselli roselli 
workload differences studies file system usage patterns tried generalizations access patterns examining differences different types loads 
fact studies examined single type workload 
studies collected data different types workloads 
addition studies examined differences file system workloads different ing system environments windows nt unix 
studies reported changes workload patterns time 
differences file system access patterns motivate need application specific benchmarking techniques 
benchmarking technology allow users evaluate system performance context workload adapt differences access patterns come changes operating system changes time 
words application specific benchmarking framework accurate predictions performance application workloads today continue able accurate predictions 
likewise allow researchers users evaluate performance impact switching operating system platform 
wide range differences file access patterns seen studies indicates need workload specific benchmarking techniques 
seemingly small differences access patterns substantial impact file system performance file system design 
similar workloads example different working set sizes see considerably different performance system workload working set fits buffer cache 
section survey studies file system usage patterns shed light differences 
differences workloads variety file system usage studies collected data different load environments studies provided substantive information file system access patterns differed environments studied 
ramakrishnan colleagues collected file system usage data different production environments vax vms computer systems ramakrishnan 
sites included traditional software development office management transaction processing batch processing workloads 
authors primarily interested finding common features different workloads examined 
common features vax vms environment unix environments examined ousterhout baker files open short time files small files read written sequentially 
authors observed significant differences file access patterns different workloads 
median file sizes similar workloads average file sizes transaction processing batch processing workloads times larger workloads indicating large files workloads larger workloads 
transaction processing batch processing workloads fewer total files file systems workloads study 
workloads accessed total data bytes day activity 
transaction processing workloads accessed larger portion file system data 
batch processing workload highest ratio data bytes read data bytes written followed transaction processing workloads 
workloads accessed small percentage total files file systems workload order entry database accessed files twelve hour period 
general ramakrishnan colleagues traces displayed similar probability density functions access characteristics number files accessed day effect outliers significant transaction pro cessing workloads 
example program development trace active files account file opens compared airline reservation database active files account file opens 
different study smith seltzer reported snapshot study nearly file systems servers harvard division applied science 
servers running sunos 
authors collected snapshots file systems nightly basis approximately months 
snapshots included extensive information physical layout files disk allowing authors examine variations file fragmentation file systems file fragmentation changed time 
smith seltzer wide variation amount file fragmentation different file systems 
reflected usage patterns file systems 
news spool file system stored usenet news articles experienced frequent creation deletion small files highly fragmented 
contrast file system containing system binaries fragmentation reflecting fact little turn file system 
smith seltzer location free space varied file systems study 
new files allocated existing pool free space location fragmentation free space file system restricts layout performance newly created files 
geoffrey kuenning colleagues ucla published trace study file access patterns commercial environment running dos kuenning 
goal evaluate algorithms predicting files mobile computer need disconnected network files prefetched mobile computer disk 
authors divided traces broad categories personal productivity mail project planning calendar applications programming commercial commercial accounting package 
kuenning associates commercial environment accessed data day 
total sizes files accessed single day megabytes commercial environment compared megabyte environments 
authors examined different sets traces conflicts events users write file short time span potential problem users disconnected file server 
commercial environment higher conflict rate user day environments user day 
drew roselli colleagues collected long term file system traces computing environments late roselli roselli 
environments included unix clusters supporting instructional research activities university california berkeley web server serving images large database library 
traced desktop workstations running office productivity applications windows nt 
roselli colleagues research instructional workloads similar respects 
surprising users environments performing similar tasks programming text editing 
despite similarities authors differences workloads demonstrate need workload specific benchmarking tools 
particular locality working set sizes significantly different environments 
cache simulations showed comparable cache sizes instructional workload generated times read traffic times write traffic disk 
important evaluating performance system workloads 
hardware configuration provided sufficient disk bandwidth demanding research workload collapse heavier demands instructional workload 
roselli colleagues observed significant differences web server workload conventional research instructional workloads 
instructional research workloads showed steady improvement cache hit rate cache size increased web server workload showed little improvement cache hit rate cache size exceeded megabytes 
point hit rate improved dramatically 
suggests web server workload defined working set little locality subsets working set 
workloads read traffic write traffic 
instructional research workloads large caches megabytes absorb read traffic writes dominate disk requests 
contrast megabyte cache web workload generate twice read traffic write traffic 
suggests web workload benefit file system optimized reads instructional research workloads gain benefit write optimized file system 
instructional research workloads files accessed frequently written read rarely 
phenomenon occur web workload little write traffic 
studies examined file access patterns scientific computing applica tions parallel super computing environments 
studies variety significant differences scientific workloads traditional time sharing workloads 
miller katz traced application file system accesses vector processing supercomputer cray mp nasa ames miller 
super computing applications studied performed repeated sequential accesses large files 
files typically large cached memory key characteristic determining file system behavior ability system stream large sequential files memory 
colleagues collected file access traces parallel supercomputer node cm national center super computing applications 
miller katz file sizes larger traditional time sharing workloads third files accessed larger megabytes accesses files larger gigabytes 
vector computer workloads colleagues requests small kilobyte 
furthermore requests sequential consecutive blocks files 
reflects partitioning data sets multiple processors cm 
kotz performed similar study node ipsc nasa ames saw similar results kotz 
differences time ousterhout study file access patterns bsd unix fast file system touchstone subsequent file system studies referred 
par ticular subsequent studies explicitly compared results ousterhout examine changes file access patterns time 
studies examined traditional academic workloads similar operating system envi ronments authors attributed differences changes brought faster computers larger disks new applications 
mary baker colleagues performed trace study file access patterns sprite distributed operating system baker 
explicitly compared results earlier bsd unix study aspects file system usage remained file throughput increased factor 
primary cause change sizes largest files accessed traces increased order magnitude 
baker colleagues file lifetimes decreased 
werner vogels drew roselli performed trace studies file access patterns windows nt hp ux vogels roselli 
authors explicitly compared results earlier sprite bsd studies 
studies showed continued increase file throughput burstiness commensurate increases large file sizes 
studies sequential access dominant access pattern significant increase random accesses 
differences operating systems publication trace study file accesses bsd unix fast file system ousterhout researchers performed similar studies operating envi ronments 
studies vax vms vm cms showed file access patterns environments similar ousterhout colleagues observed bsd unix biswas 
studies compared windows nt loads unix workloads significant differences 
study hp ux windows nt workloads discussed roselli examined block lifetimes different workloads roselli 
measure time data block written deleted block file truncated deleted block overwritten new data 
systems significant fraction newly written data short lifetime 
approximately files mary baker sprite study deleted seconds created baker 

systems sprite nelson exploit characteristic holding dirty data buffer cache short interval writing disk 
allows short lived data die cache reduces disk traffic 
hp ux workloads studied earlier sprite workload roselli block lifetimes windows nt bimodal distribution 
newly written blocks died second died newly written blocks died day 
hp ux workloads contrast showed sharper increase blocks deleted time 
instructional workload example 
baker original study showed higher fraction files lived seconds 
conservative comes roselli study uses different method compute file block lifetimes roselli 
new data blocks lived second newly written blocks lived day 
douceur bolosky published study files commercial environment running windows douceur 
collected snapshot data file systems machines microsoft main campus 
study file systems operating system environment interesting compare results studies 
earlier studies anecdotal evidence showed file systems little free space bennet smith 
contrast douceur bolosky average file systems half full 
difference may due inherent differences windows unix environments including fact douceur bolosky studying desktop workstations contrast earlier studies examined centralized servers explanation rapid increase disk capacities years 
netnews workloads usenet news servers source unique file system workload 
workload stresses conventional file system architectures severely proposals file system optimizations zadok completely new file system architectures specifically targeted supporting usenet news 
advent world wide web may netnews obsolete technology anecdotal evidence suggests news bandwidth continues increase currently reaching volumes gigabytes day traffic 
demand news isps provide news service file server vendors offer news specific optimizations manley 
scott provides excellent overview problems traditional file systems ffs face supporting usenet news server 
news server software inn spencer henry spencer david lawrence 
managing usenet 
reilly associates cambridge ma 
organizes file system separate directory newsgroup individual files directories article 
high volume newsgroups directory sizes reach tens thousands files 
file systems ffs simple linear scan directory looking name pay large overhead lookups 
articles tend arrive servers random order respect news groups 
diminishes effectiveness buffer cache cached contents directories replace reused 
random newsgroup distribution works cross purposes common file system assumption files directory accessed collocated disk 
behavior news clients tends display locality little news server 
clients humans 
time read article newsgroup disk heads server long relocated different location 
news article stored separate file processing requires creation small files 
unix style file systems traditionally performed file creates synchronously see section perform poorly type workload 
file system benchmarks systems benchmarks traditional file system benchmarks broadly classified different categories 
microbenchmarks measure specific characteristic file system behavior time create delete file 
macrobenchmarks contrast measure performance file system pre determined workload 
may real application generate workload ing linking large piece software may custom application drives file system synthetic workload 
isolation type benchmark fully illuminates behavior file system 
macrobenchmarks determine sys tem particular workload perform best provide little information underlying causes performance differences 
microbenchmarks con trast useful understanding detailed performance differences sys tems system may provide higher throughput 
microbenchmarks may show file system performs areas 
commonly different file systems offer different advantages 
cases microbenchmark results provide insight systems best suited particular workloads 
file system microbenchmarks quantities common targets file system microbenchmarks time create file time delete file throughput reading files throughput writing files 
occasionally researchers microbenchmarks measure quantities time create symbolic link read directory 
quantities measured corresponding file system operations perceived occur real file system workloads 
quantities offers range parameters researchers vary writing microbenchmark 
example file read throughput usually depends important parameters file data buffer cache test pro gram reads files sequentially randomly 
researchers usually report behavior microbenchmark programs regard variety parameters affect benchmark results 
file read throughput depend size number files read location files directory hierarchy 
minor detail files read order created affect benchmark results 
researchers seldom provide full details microbenchmark programs 
knowing studies similar parameters microbenchmark programs impossible compare microbenchmark results different researchers 
chris small colleagues reported problem just file system benchmarks areas systems research argued need standardized benchmark programs small 
addition ad hoc microbenchmark programs explicitly designed measure aspect file system performance researchers standard utility programs microbenchmarks 
researchers choose program exercises small part file system functionality file copies recursive directory listings 
file system macrobenchmarks goal programs understand real workloads perform file system 
macrobenchmarks consist executing application carefully specified parameters 
program exercises file system may suitable common program compiler 
compiler read write files tool researchers fre quently 
typical compilation consists building link ing operating system kernel system benchmarked 
andrew benchmark howard commonly file system macrobenchmarks small 
uses time build piece software metric file system performance 
andrew includes phases intended mimic behavior software developers 
phases consist creating directory hierarchy source files copying source files hierarchy examining new copy stat system call reading new copy grep utility 
researchers modified andrew run multiple concurrent andrew workloads system attempting mimic effect timesharing seltzer 
ironically light wide spread andrew originally intended measuring scalability file servers distributed file systems evaluating performance file system 
addition application macrobenchmarks variety programs synthetic workloads 
widely known spec sfs benchmark earlier laddis benchmark measuring nfs server performance 
benchmark creates initial file hierarchy nfs server 
multiple client machines issue random nfs requests server 
clients select operations pre defined distribution generated traces actual system behavior 
sfs reports results nfs operations second 
commonly synthetic macrobenchmarks include postmark katcher iostone park 
benchmarks similar sfs perform random operations selected pre determined distribution 
diane tang provides overview critique file system benchmarks including iostone laddis tang 
sfs programs report single result elapsed time execute benchmark file system throughput achieved benchmark 
providing single number evaluation file system performance benchmarks essentially claiming able provide dimensional ordering different file systems 
see chapter claim doesn hold examine different file systems perform different workloads 
fact benchmark predict performance file system workload similar benchmark workload 
highlights central deficiency existing benchmarking methodology 
users turn benchmarks benchmark results order answer question workload perform system microbenchmarks provide detailed information file system performance isolation seldom sufficient answer question 
absence detailed understanding interactions workload file system microbenchmarks provide little insight workload performance target file system 
macrobenchmarks contrast designed answer question user left difficult task determining publicly available macrobenchmarks similar workloads 
chapters discuss technique researchers 
andrew benchmark unusual regard reports time phases complete 
different phases exercise different parts file system provides additional information differences file system architecture map differences workload performance 
environment execute benchmarks realistic new benchmarking strategies possible users determine workload perform file system interest 
chapter file system aging increasing prevalence intensive applications multi media applica tions large databases placed growing pressure computer storage systems 
response pressures researchers investigated variety new technologies improving file system performance functionality 
rosenblum ousterhout proposed log structured file system lfs way address increasing fraction disk traffic due writes rosenblum 
ganger kaashoek proposed tech niques reorganizing small files meta data objects improve disk locality ganger 
researchers explored variety strategies application assisted prefetching caching exploiting application specific knowledge patterns better utilize systems patterson mowry cao 
order accurately assess utility technologies researchers need tools allow understand behavior file systems realistic conditions 
laboratory settings realistic conditions usually simulated benchmark programs 
section described range benchmarking techniques benchmarks currently file system researchers 
selecting proper benchmark half problem 
accurately characterize performance file system benchmark executed environment similar conditions system real world 
unfortunately requirement widely ignored file system researchers 
standard practice file system research perform benchmarking empty file systems state rarely seen real world environments 
chapter propose methodology artificially aging file system simulating long term workload 
aging file system prior running benchmarks resulting benchmark performance resembles real file system workload generated 
just researchers different benchmarking programs simulate different application workloads different aging workloads simulate different execution environments 
section motivate describing inaccuracies arise traditional approach executing benchmarks empty file systems 
section describes file system aging technology demonstrates produces realistically aged file systems 
section aging methodology evaluate new file layout policies unix fast file system 
section 
motivation executing benchmark empty file system fails capture important character file system behavior substantial effect file system performance 
real file systems empty 
fact pro effect performance file system 
file systems optimize throughput allocating physically contiguous disk blocks logically sequential data allowing data read written near optimal speeds 
empty disks type alloca tion simple 
real file systems typically highly utilized contiguous alloca tion may difficult impossible achieve due fragmentation available free space 
result new files may fragmented highly utilized system result ing lower file system throughput 
second problem benchmarking empty file system impossible study evolution file system time 
passage time state file system may change 
files created deleted patterns file fragmentation may change relative locations logically related objects disk file data meta data 
variety file system policies may effect short term empty file system noticeable impact file system performance long run 
decisions file system today blocks allocate new file may affect file system months years 
section example problems demonstrating benchmarks conducted empty file system provide misleading results fail measure effects significant changes underlying file system 
empty file systems common problem benchmarking empty file systems stems fact difficult measure effects file fragmentation empty disk 
fragmentation fact life file system designs foolish bench mark file systems empty file fragmentation 
demon strate effect ran simple file system benchmark empty full unix file systems 
measure performance full file system copied active file system departmental file servers test machine benchmarking file system built empty file system parameters disk measured performance 
benchmark program chapter measures file system throughput reading writing files variety different sizes 
shows read throughput files kb mb 
throughput real file system lower throughput comparable empty file system 

copying entire file system copied file system meta data 
result test file system exactly free blocks allocated blocks original file system copied actual data 
life time evolution file systems attempt optimize performance clustering logically related data underlying disk 
effectiveness different clustering strategies may apparent observing short term behavior file system 
time free allocated space disk may fragmented affecting ability file system perform clustering 
note fragmentation affects sequential layout file data proximity related files disk relative locations file meta data describes 
cases way evaluate competing designs comparing file systems long period activity 
previous smith studied effect design parameter file system performance 
bsd fast file system mckusick optimizes sequential performance allocating physically contiguous clusters blocks logically sequential file data 
life file system free space fragmented increasingly difficult find contiguous free space new clusters 
read throughput mb sec file size kb 
effect utilization file system performance 
graph shows read throughput range file sizes unix file systems 
difference file systems amount free space available 
file system empty benchmark performed 
file system duplicate month old file system full 
sharp performance drop kilobytes occurs test files large require indirect block 
characteristic ffs file systems explained detail seltzer 
empty full comparing different algorithms finding allocating free space new files discovered provided nearly identical performance empty disk see 
applying simulated month workload file systems apparent substantial performance difference file systems different disk allocation policies see 
file system aging previous section demonstrates benchmarking empty file systems provide accurate assessment real world behavior file system architecture 
order get realistic picture file system behavior file system analyzed realistic conditions 
means file system empty state developed months years operation 
order analyze file system performance manner need apply methodol ogy allows researchers fill file system realistic manner resulting file sys tem similar active real world conditions extended period time 
analyzing file system performance manner presents variety problems arise benchmarking empty file system empty file system performance aged file system performance read throughput mb sec new file system old file system file size kb read throughput mb sec new file system old file system file size kb 
effect aging file system behavior 
graphs plots read throughput range file sizes file systems different block allocation strategies 
graph performance measured empty file systems 
graph performance measured aging file systems simulated month workload 
empty file system new allocation algorithm performed slightly better performance systems nearly identical aged file systems file systems perform worse empty case new allocation algorithm provides large improvement read throughput 
complete discussion study smith 
different applications apply different workloads file system possible simulate effects different file system workloads 
file system traditional engineering environment year may behave differently news server similar period time underlying file system architectures identical 
technique fill file system reproducible allowing scientific comparisons laboratory setting 
manner file systems filled independent architecture underlying file system allowing different file system implementations compared 
order study file system performance realistic manner address con listed developed technique call file system aging 
precompute artificial workload intended simulate pattern file operations applied file system extended period time 
aging workload consists sequence records describes creation deletion modification file directory applying workload different file systems researcher see differences file system architecture affect long term behavior file system 
aging workload generated snapshots traces real file system 
aging workloads representative different types file system activity created data collected appropriate file systems 
despite desire architecture neutral file system aging technique tools chapter minor dependencies underlying file system ffs case 
dependencies discussed section 
section technique generate aging workloads describe program applies workload test file system evaluate 
real file system workload file creation consists multiple events create file write data new file 
aging workloads coalesce separate events single record specifying name size new file 
reasonable simplification light fact files written entirety immediately created ousterhout baker 
accuracy aging workload comparing artificially aged file systems original file systems aging workloads generated 
generating workload central problem aging file system generating realistic workload 
test system start empty disk workload start empty file system simulate load new file system months years result ing file system full 
possible method generating workload collect extended file system traces age test file system replaying exact set file operations seen trace 
unfortunately time storage space required collect trace usually strategy impractical generated aging workloads sets file system data available 
result sacrifice realism workload exchange greater flexibility tuning workload needs 
aging workload sequence records describes single file system operation 
glance file system trace 
difference file system trace includes operations performed file system aging workload needs include operations effect long term state file system 
particular operations interested allocate deallocate file data file system meta data 
common operations file directory creates deletes 
interested write operations represent primary mechanism file data space allocated 
files written entirety immediately created ousterhout baker don need explicitly include individual write operations workload 
sufficient file create records include size target file generate aging workload set file system snapshots collected file system local file server 
snapshots originally gathered different 
drew roselli colleagues berkeley released set file system traces collected period year roselli 
traces know potentially age file system 
research project seltzer collected nightly approximately file systems different file servers periods time ranging years 
snapshot describes files file system time snapshot 
file snapshot includes file inode number inode change time inode generation number file type file size list disk blocks allocated file 
sequence snapshots file system generate aging workload modeled actual activity file system period time covered snapshots 
snapshots variety different file systems generate aging workloads representative different file system uses 
extended period time covered file system snapshots possible build aging workload simulates months file system activity 
generating workload sequence traces step process 
generate operations initialize target file system state similar snapshot original file system 
create skeleton workload comparing successive pairs snapshots generating workload account changes original file system pair snapshots 
flesh workload adding create delete events variety short lived files 
step creating aging workload generate sequence file system operations bring test file system state similar represented snapshot original file system 
state am trying reproduce set files exist file system simple matter creating file initial snapshot 
sort actual create operations inode change times files snapshot expectation reasonable approximation order files created original file system 

conventional file system architectures file directory create delete operations records need include aging workload order reproduce long term evolution file system state 
experimental file system architectures include types operations aging workload 
carl staelin smart file system example migrates file data blocks central cylinders disk frequently accessed staelin 
properly age file system aging workload include file read operations 
generate skeleton aging workload 
comparing inodes listed successive pairs snapshots generate list files created deleted modified replaced times snapshots 
major difficulty stage determining sequence actions occurred snapshots provide sufficient information determine exact time operations took place 
heuristics assign times create delete operations generated comparing successive snapshots 
inode change time recorded file snapshot indicates time file meta data modified 
modifications include original creation file allocation new disk blocks file 
previous studies shown files typically written burst seldom modified written ousterhout baker inode change time newly created file approximate time file created 
file deleted snapshots information providing hints time deleted 
randomly assign times file deletions occurred snapshots 
ad hoc decision expedite development file system aging workloads 
careful analysis file deletion times real file system traces provide accurate solution improve realism aging workloads 
inode listed successive snapshots different file attributes things may happened original file system file modified replaced 
inode generation number provides information required determine actions occurred 
generation number snapshots file modified 
case place file modification operation aging workload assign time corresponding inode change time snapshot 
generation number different snapshots original file deleted new file assigned inode number 
case place operations workload delete subsequent create 
determine time create described place delete immediately prior 
processing snapshots manner workload missing important component real file system activity 
file created deleted successive snapshots appear snapshot 
trace file system studies shown files live hours successive snapshots ousterhout baker 
files may significant effect state longer lived files file system 
approximate effect short lived files add additional file operations workload generated snapshots 
order add additional workload answer questions operations add physically temporally add 
determine file operations add aging workload examined patterns activity displayed short lived files day trace nfs requests network appliance file server hitz 
day trace list active directories created profile short lived file activity directories 
result different profiles containing list create delete operations short lived files occurred day directory 
day aging workload select profiles random added aging workload day activity aging workload set short lived file profiles integrate finding active directories day aging workload randomly distributing profiles 
time shift profile coincides peak activity directory added 
nfs trace generate profiles short lived file activity originally collected study cleaning algorithms log structured file systems 
scaled number short lived file profiles size file system generated aging workload adding profile mb original file system 

file system snapshots preserve names files active cylinder groups active directories 
reasonable approximation ffs allocates files directory cylinder group 
blackwell generated server typical academic workload consisting text editing compilation executing simulations trace generate aging workloads file systems similar environments 
order generate aging workloads types file system activity database news servers need different traces approximate activity short lived files 
replaying workload age file system apply aging workload generated described empty file system 
measurements target file system size file system aging workload generated aging load larger file systems 
aging program reads records workload file performing specified file operations 
aging workload includes timestamps file operation simply execute requests rapidly possible 
replaying workload real time unnecessary purposes ffs file systems order requests received file system relative times requests determines behavior file system 
task replaying aging workload complicated fact file system snapshots provide pathnames files 
ffs exploits expected patterns locality allocating files directory cylinder group disk algorithm aging program assign files directories major impact accuracy aging simulation 
due absence original pathnames file system snapshots decided sufficient create files correct cylinder groups 
creating files cylinder group simulated file system original file system ensured cylinder group simulated file system received set allocation deallocation requests corresponding cylinder group original file system snapshots generated 
files inode number compute cylinder group allocated original file system 
force files cylinder groups aged file system exploited details ffs implementation 
start aging process empty file system 
step create directory cylinder group file system 
algorithm ffs assign directories cylinder groups ensures directory placed different cylinder group 
file aging workload inode number compute cylinder group allocated original file system place file corresponding directory aged file system 
ffs places files cylinder group directory guarantees files cylinder group original file system cylinder group aged file system 
drawbacks approach 
creating extra directory cylinder group am introducing file cylinder group exist data sets generate aging workload directory 
effect directories negligible space occupy files manipulated aging simulation 
second drawback exploiting details ffs implementation am limiting applicability file system aging tools file systems physical partitioning improve clustering logically related data 
workload verification order evaluate realism simulation compared test file system aged techniques real file system generated aging load 
test file system necessarily starts empty state generated aging workload file system snapshots starting day created 
file system contains home directories graduate students study ing parallel computing file systems deriving aging methodology 
aging workload generated file system simulates days approximately months activity gigabyte file system 
workload disk controller ncr size mb cpu parameters disk parameters file system parameters cpu intel pentium clock speed pro mhz disk type fujitsu es fragment size kb memory mb ram total disk space mb block size kb bus type pci rotational speed contains approximately file operations write gigabytes data disk takes hours replay generic ffs implementation 
workload file system full 
ran aging workload test file system configured file system parameters original system compared resulting state test file system state original file system sequence snapshots 
discussion refer original file system aging workload generated real file system refer test file system aged artificial workload simulated file system 
table describes hardware configuration age simulated file system benchmarks described section 
primary changes observed file system architectures system ages increased file fragmentation disk 
started comparing 
measured hour replay time aging workload file system mounted bsd async option 
option forces file system writes occur asynchronously including synchronous metadata updates described section 
impractical option file system holding live data useful running aging workload 
system failure executing aging workload danger losing valuable data simply re run workload 
running workload file system mounted async option takes hours 
rpm max 
cluster size kb cylinders rotational gap heads cylinder groups avg 
sectors track heads track buffer kb sectors track average seek ms table benchmark configuration 
table describes hardware configuration benchmarking verifying file system aging workload 
file system parameters shown italics set match file system generated aging workload despite fact match underlying hardware 
aspects fragmentation real simulated file systems 
define layout score quantify amount file fragmentation file file system 
layout score individual file fraction file blocks optimally allocated 
optimally allocated block contiguous preceding block file 
block file included calculation impossible previous block similarly layout score defined block files fragmented 
file layout score perfectly allocated blocks contiguously allocated disk 
file layout score contiguously allocated blocks 
evaluate fragmentation set files entire file system compute aggregate layout score files 
metric fraction blocks files optimally allocated ignoring block file block files 
simulation period aggregate layout score real file system compared simulated file system 
aging workload cause fragmentation file system generate fragmentation occurred real file system 
presents time series aggregate layout scores file systems days simulation indicates aggregate layout score simulated file system tracked real file system closely half simulation second half simulation aging workload failed replicate large changes file fragmentation real file system 
gain better understanding fragmentation differences real simulated file systems sorted files file systems size computed aggregate layout scores files variety sizes 
shows results 
file systems similar layout scores small files kb larger files simulated file system higher layout scores indicating failed 
note seemingly high layout scores blocks real simulated file systems optimally allocated typical ffs 
file systems snapshot library seldom aggregate layout score news servers subject extreme file fragmentation 
capture fragmentation occurred real system 
large files cause aged file system higher aggregate layout score real 
difference layout scores noteworthy files mb caused discrepancy 
files sizes original file system unusually fragmented layout scores 
file systems examined large files exhibit degree fragmentation 
owners files outputs large simulation programs 
speculated file activity concurrent creation large files place cylinder groups may caused fragmentation data necessary confirm hypothesis 
summarize simulated aging workload mimics real file system derived steady increase fragmentation time 
total amount fragmentation simulated system real file system largely simulated file system failed replicate large changes fragmentation seen real file system 
fundamental cause inaccuracy aging workload sufficient information perfectly aggregate layout score simulated real time days 
real vs simulated file system 
chart plots aggregate layout score day month simulation period 
simulated line shows fragmentation artificially aged file system 
real line shows fragmentation original file system aging workload generated 
file systems behave similarly half simulation aging workload fails capture large changes original file system workload half simulation period 
aggregate layout score simulated real file size kb 
fragmentation function file size 
file sizes rounded number file blocks aggregate layout score computed files various sizes real simulated file systems 
results graphed 
file systems suffer extreme fragmentation small files kb 
real file system file layout drops noticeably large files mb 
similar decline simulated system 
reconstruct workload real file system randomized decisions 
important areas occurred assigning times file delete operations simulating activity short lived files file system 
real file system workloads dependencies operations activity occurring file system 
accurate model interdependencies allow realistic decisions regarding file delete times short lived file activity 
absence model decreases aging 
tools superior traditional approach benchmarking empty file systems effective evaluating impact design decisions long term behavior file system 
applications aging earlier study smith file system aging analyze effectiveness improved block allocation scheme ffs 
empty file system original improved schemes virtually indistinguishable aged file system improved scheme resulted performance improvements percent 
aging enables researcher explore long term effects number policy decisions file system features 
section aging methodology answer fol lowing questions ffs layout 
indirect blocks blocks contain pointers data blocks usually allocated separate cylinder group containing previous part file 
imposes sharp performance penalty files kb kb 
allocate indirect block file cylinder group start file affect performance 
undesirable side effects 
fragments partial blocks rarely allocated adjacent preceding block file 
placing fragments adjacent preceding blocks may improve performance may lead internal fragmentation 
changing fragment allocation beneficial 
basic technique exploring issues propose implement modification ffs 
aged file systems differed modification ran variety benchmarks aged file system evaluate effect pro posed change long term behavior file system 
order compare performance file systems simple benchmark programs 
measures file system throughput sequentially reading writing files variety sizes 
run benchmark measures read write performance file size 
benchmark operates mb data decomposed appropriate number files file size measured 
ffs allocates files single directory cylinder group data divided subdirectories containing files 
increases number cylinder groups exercised benchmark 
benchmark executes phases 
create write files created 
file sizes mb entire file created write operation 
large files created mb writes necessary 
phase measures write throughput including time required create new files allocate disk space 

read test file system flush file cache 
files read order created 
create phase performed mb units 
file size tests executed benchmark times averaging resulting throughput measurements 
test cases standard deviation average throughput 
benchmark unrealistic important sense 
real file system workloads seldom create large batches files size 
actual usage patterns typically interleave creation deletion files variety sizes possibly resulting file fragmentation see sequential benchmark described 
second benchmark attempts address problem exploiting realistically created files left test file system aging workload 
previous research shown older files seldom accessed satyanarayanan active files file system tend relatively young 
approximated set hot files simulated file system files modified days aging workload 
files represent files aged file system files megabytes storage allocated disk space 
second benchmark measures file system throughput reading writing complete set hot files 
limit amount time spent seeking file sorted files directory multiple files read cylinder group moving 
preserve file layouts overwrite files write phase test 
ffs enhanced improved block clustering algorithm smith mentioned section baseline system 
performance file system aging shown 
read write throughput throughput mb sec read write file size kb 
time performed experiments allocation algorithm considered experimental 
standard part ffs bsd systems 
file fragmentation layout score file size kb 
performance baseline 
charts show performance baseline file system file throughput benchmark 
benchmark executed file system aged workload described section 
graph plots read write throughput function file size 
graph plots layout scores test files created benchmark 
sharp drops graphs file size passed kb corresponds point ffs allocates indirect block file see section 
indirect block allocation time indirect block allocated file ffs file system assigns block data blocks different cylinder group previous part file 
new cylinder group chosen selecting cylinder group disk average number free blocks relative rest file system 
scheme undesirable forces long seeks periodic locations large files 
large files extra seeks typically amortized transfer entire file negligible effect throughput 
typical file system block size kb policy force change cylinder groups mb file 
switching cylinder groups may useful practice prevents single large file consuming free space cylinder group 
unfortunately glaring problem policy switching cylinder groups allocation indirect block file ffs indirect block allocated twelfth data block file 
kb file system means ffs imposes extra seek kb file 
medium size files kilobytes extra seek noticeable impact performance 
effect extra seek apparent performance baseline file system 
layout score test files drops indirect block allocated kb kb read write performance decline point 
larger drop read performance write performance indirect block causes seek read interferes file prefetching blocks referenced indirect block prefetched indirect block read disk 
address problem modified ffs switch cylinder groups allocates second indirect block file 
test file systems occurs file size reaches approximately mb 
call implementation ffs includes enhancement noswitch 
expected minor enhancement effect improving file throughput files kilobytes 
larger files see improvement savings eliminating seek amortized time takes read write entire file 
throughput benchmark compare performance noswitch file system baseline file system empty aged partitions 
shows results 
expected read write throughput files kilobytes improves noswitch file system 
note slight performance drop file size passes kb indirect block 
occurs addition transferring file data file system transfer indirect block 
comparing performance empty aged file systems see noswitch system outperforms baseline cases 
magnitude performance improvement shown area pairs curves file systems smaller aged file system 
best case kb files noswitch file system improves performance empty file system aged file system 
concern noswitch file system improve performance needed run benchmarks aged file system 
aged file system accurately assess magnitude performance improvement 
aged file system allows assess empty file system performance aged file system performance file system throughput mb sec noswitch read baseline read noswitch write baseline write file size kb file system throughput mb sec noswitch read baseline read noswitch write baseline write file size kb 
performance improved indirect block allocation 
charts compare read write throughput baseline file system file system switch cylinder groups allocating indirect block noswitch 
graph shows comparison empty file system graph shows comparison aged file systems 
noswitch file system offers higher throughput cases magnitude improvement indicated area noswitch baseline lines graphs significantly smaller aged file systems 
adverse side effect enhancement 
described earlier ffs attempts exploit locality locating files directory cylinder group directory 
directory files large original scheme switching cylinder groups twelve blocks large file may ensured single large file consume free space cylinder group forcing subsequently allocated files placed cylinder groups destroying desired locality 
study effect examined state baseline noswitch file systems aged 
noswitch file system caused increase number files displaced cylinder group directory expect see larger number files data block file different cylinder group file inode 
ffs tries locate file inode cylinder group directory 
counted number split files file systems file determined cylinder groups separated file inode data block 
intervening cylinder groups longer seek required read file data reading inode 
results summarized table 
baseline noswitch number split files files split cyl 
group splits cyl 
group splits table number split files noswitch file systems 
table compares number split files files inode data block different cylinder groups baseline file system aged file system noswitch enhancement 
rows table respectively total number split files file system percentage files file system split percentage split files data block cylinder group away inode percentage split files data block cylinder groups away inode 
file systems cylinder groups 
noswitch file system twice split files baseline file system indicating switching cylinder groups indirect block allocated fact cause highly utilized cylinder group run free space 
baseline file system split files require relatively short seeks half cases file data cylinder group away cases data cylinder groups file inode 
contrast third split files noswitch file system involve seeks cylinder groups 
attempt balance performance gain large files allocated cylinder group potential performance loss longer seeks required read extra split files generated noswitch file system turn results hot file benchmark 
results benchmark summarized table show noswitch file system offers modest improvement read throughput virtually change write throughput 
performance improvement suggests throughput gained better layout larger files outweighs throughput lost increasing number split files 
improvement performance small may artifact particular workload file system modification may universally applicable 
important note means evaluate trade benchmarked noswitch empty file system 
baseline noswitch aggregate layout score split files read bandwidth mb sec write bandwidth mb sec table performance modified files noswitch file system 
table presents read write throughput files modified days aging workload baseline noswitch file systems 
aggregate layout scores files test number files data block located different cylinder group file inode split files 
throughput measurements averages test runs 
standard deviations reported means 
fragment allocation ffs limit amount internal fragmentation caused small files ffs allows single file system block subdivided fragments 
minimum fragment size deter mined time file system created blocks may divided pieces integral multiples fragment size 
files twelve data blocks files indirect blocks partial block containing integral number fragments may data block full sized file system block 
test file system example block size kb frag ment size kb 
kb file allocated file blocks followed partial block containing fragments 
scheme efficient reducing amount disk space wasted internal fragmentation algorithm ffs uses allocate fragments files results suboptimal file layout 
allocating fragment ffs attempts find free fragment appropriate size cylinder group file 
fragment available ffs divide larger free fragment 
fragment appropriate size available ffs allocate entire file system block divide fragments 
primary goal fragment allocation algorithm limit amount free space exists fragments 
downside approach fragment file seldom allocated near preceding block file 
example see layout scores small files lower files indicating small files fragmented 
fragmentation entirely due fragment allocation policy 
baseline file system example block files allocated blocks contiguous disk 
block files second block full block fragment allocated contiguously 
ideally fragment file contiguous preceding block file 
modified ffs fragment allocation algorithm 
new algorithm attempts allocate block immediately adjacent previous file block 
block available broken fragments unused portion marked free 
desired block available fall back ffs original fragment allocation policy 
small files data block fragment original ffs policy hoping fill free fragments created full blocks broken provide contiguous fragments larger files 
refer version ffs uses new fragment allocation policy 
sequential benchmark compare performance file system baseline system 
interested behavior files fragments focused small files running benchmark 
shows layout score small files created running benchmark aged file systems 
presents measured performance versions ffs empty aged file systems 
shows scheme dramatically decreases file fragmentation files fragments 
baseline file systems achieve nearly perfect layout file sizes integral multiple kilobyte disk block size 
intermediate sizes eliminates fragmentation seen baseline system 
difference file layout translates performance differences seen 
saw tooth effect read performance tested systems caused changes performance characteristics file systems fragments 
file sizes multiples file system block size require fragments 
note file sizes performance baseline file system file system file layout algorithm 
file sizes integral multiples file system block size outperforms baseline system due improved allocation fragments layout score file size kb baseline 
file layout smart fragment allocation 
graph shows amount file fragmentation small file sizes baseline file systems 
layout score plotted files created throughput test 
files 
baseline systems decreased throughput files fragments ffs issues separate request disk driver fragment regardless fragment contiguous previous file block 
differences write throughput smaller test creates writes test files test time dominated create operation requires synchronous disk writes seltzer 
cost creating file baseline file systems 
write performance tested systems shows unexpected jump file size reaches kb 
result performance bug fixed version ffs tests 
full cluster kb data written file ffs clustered writes 
result smaller file sizes ffs issued write request file block regardless layout disk 
file sizes overhead performing individual operations completely masked performance differences caused fragment allocation policy 
files larger kb see file system provided improved throughput file sizes required fragment 
empty file system performance aged file system performance file system throughput mb sec read baseline read write baseline write file size kb file system throughput mb sec read baseline read write baseline write file size kb 
performance smart fragment allocation 
charts compare read write throughput baseline file system file system uses improved fragment allocation algorithm 
graph shows comparison empty file systems graph shows comparison aged file systems 
saw tooth effect shows impact changing fragment size file system performance 
peaks represent file sizes integral number blocks 
file sizes require fragment perform reading writing fragment requires extra operation 
step writer performance kb files result performance bug ffs described body chapter 
performance curves drop kb ffs switches cylinder groups point 
potential downside strategy amount fragmentation free space causes 
data file system allocated full sized file system blocks 
file system free space fragments full sized blocks file system may run free blocks sizeable amount free space fragments 
seltzer colleagues described particularly spectacular instance problem seltzer news servers reported free space despite fact file system megabytes percent disk free fragments 
evaluate file system increases fragmentation free space compared number free blocks free fragments baseline file systems 
expected file systems amount free space 
file system twice space fragments vs free space 
total amount fragmented free space relatively small file systems side effect allocation scheme tolerable applications cause problems file system close maximum capacity 
behavior file system change dramatically passage time 
file system filled successive generations files created modified deleted performance characteristics system change 
ignoring changes file system behavior researchers fail accurately assess file system designs respond real world conditions 
active file systems behave differently empty ones variety file system design decisions full effects apparent long period 
order accurately evaluate long term behavior competing file system architectures developed process artificially aging file system replaying long term workload test file system 
demonstrated evaluation new file layout policies unix fast file system technology allows scientific evaluation design decisions may discernible effect short term characteristics file system behavior 
chapter workload specific performance analysis fundamental questions benchmarking tries answer workload perform system previous chapter demonstrated file system aging helps answer question producing benchmark results accurate realistic traditional approach benchmarking empty file sys tems 
results achieved measuring performance aged file system benchmark generate results 
regardless test file system read intensive benchmark probably poor predictor performance write intensive workload 
unfortunately current file system benchmarks suffer type mismatch user workloads 
typical benchmarks sfs andrew iostone assign single score system measure 
tacit assumption benchmarks single dimensional ranking systems test 
real world seldom case 
file system performs best workload may best workload 
shown repeatedly variety research papers comparing different file system architectures seltzer patterson tomkins seltzer 
ideal benchmark allow user evaluate system context workload 
workload specific performance evaluation increasingly important today computing environment 
tasks handled single central server run dedicated hardware 
example large computing installations separate systems acting file servers mail servers web servers news servers name servers ideally administrators sites tools determine competing hardware operating system configurations provide best performance services 
tools evaluate benefits hardware upgrades installing memory faster disks determine optimal configuration parameters applications operating systems 
traditionally user wanted evaluate performance workload variety file systems execute workload various systems interest 
possible users financial get access evaluation systems practical users 
facilitate common situation class users designed benchmarking methodology allows user evaluate performance workload file system having access actual machine file system 
key benchmarking methodology separating measurement file system analysis user workload 
scheme file system vendor provides profile file system results suite microbenchmarks evaluate different aspects system performance 
user analyzes application collecting trace calls file system api 
combining profiles predict performance workload file system identify types operations file system consumes time 
information useful application developers wish tune software avoid file system bottlenecks file system architects wish eliminate bottlenecks 
section motivate demonstrating different file system architectures provide better performance different workloads 
section discuss traditional approaches analyzing file system performance 
section describes goals workload specific performance analysis tools 
section explain architecture implementation tools section validate comparing performance predictions actual behavior workloads variety file system architectures 
section describes possible avenues 
section 
motivation existing macrobenchmarks attempt reduce file system performance single number 
benchmarks assume file system best benchmark result best performing 
unfortunately real world file systems seldom lend selves simple analysis 
file system best workload may best different workload 
similar benchmark programs intended repre sent type workload may rank files systems differently 
problem observed shows data collected earlier study comparing log structured file system lfs versions ffs seltzer 
ffs old version fast file system include support clustered see section efs version ffs includes clustered graph shows time run concurrent instances andrew benchmark howard 
set benchmark results clearly shows single file system consistently performs 
instance andrew benchmark run lfs outperformed file systems 
instances andrew benchmark run efs showed best performance lfs worst performance 
research studies comparing multiple file system architectures shown phenomenon ranking file systems performance depends benchmark howard patterson tomkins seltzer 
existing benchmarking techniques traditional techniques analyzing understanding file system performance relied mix microbenchmarks macrobenchmarks 
researchers typically microbenchmark results explain predict performance marks 
best approach allows researcher understand file system operations perform poorly particular system examine microbenchmark results influence performance large scale workloads highlight ing workloads suited architecture 
type measurement provide excellent insight behavior systems study painstaking carry 
seldom practical studies focus handful workloads results may little benefit users workloads differ macrobenchmarks study 
recourse user perform analysis system question execution time seconds number concurrent andrew jobs 
file system comparison 
graph compares performance file systems logstructured file system lfs old version berkeley fast file system ffs version fast file system supports clustered efs 
graph shows file system performance application run time execute concurrent instances andrew benchmark 
file system offering best performance varies depending degree 
data copied earlier publication permission author seltzer 
lfs efs ffs performing measurements system trying infer performance workload previously published results 
approach requires access file system interest potential problem users limited financial resources 
approach requires detailed understanding interaction workload file system 
inferring performance workload microbenchmark results problematic workload stresses parts system 
benchmarking methodology attempt automate general approach microbenchmarks understand workload performance 
provide extensive suite microbenchmarks evaluate performance aspects standard file system functionality set tools analyze performance workload results microbenchmarks 
output analysis provides types information researchers traditionally generated hand analyzing file system performance 
goals goal develop benchmarking methodology explicitly acknowledges workload dependent nature file system performance 
benchmark allow users understand workload behave different file system architec tures 
highlight performance trade offs different file systems impact trade offs performance 
chapter set tools called hbench fs allow researcher perform important types perfor mance analysis 
hbench fs predicts performance workload target file system 
allows easy comparisons competing file system benchmark result ms architectures context workload interest 
lookup comparisons useful lookup hbench fs hit provide accurate performance file create 
researchers harvard investigating workload specific benchmarks different types computer systems 
name hbench fs part naming scheme benchmark suites 
hbench os brown measures operating system performance hbench web manley measures web server performance predictions 
importantly hbench fs able correctly rank different file systems terms performance provide workload interest 
hbench fs provides analysis underlying causes performance differences different systems 
addition predicting performance workload target file system hbench fs breaks performance terms file system functionality showing request types consume time 
ultimate goal provide complete accuracy performance breakdown data useful researchers developers information types file system operations consume time particular workload file system combination 
developers researchers results hbench fs optimize application file system performance response specific bottlenecks workload encounters file system 
developers researchers contemplating changes file system entirely new file system architecture hbench fs conduct experiments 
user provide hypothetical performance characterization proposed file system hbench fs predict performance various workloads 
output hbench fs provides variety information helps perform different types performance analysis described 
hbench fs provides access raw prediction data customized performance analysis 
individual tasks described performed existing techniques approach usually requires tremendous amount expertise access applications file systems question 
hbench fs separates file system analysis workload analysis allowing user study performance workload file system architecture may access may exist 
hbench fs automates tasks traditionally associated performance analysis including selection microbenchmarks determining aspects file system performance greatest impact workload 
application specific benchmarking shows high level architecture hbench fs 
set analysis tools combine data profiles file system workload interest predict workload perform file system 
file system profile consists results large suite file system microbenchmarks intended fully characterize aspects traditional file system functionality 
workload profile includes system call trace desired workload collected operating system environment snapshot file system trace 
file system workload pro files generated separately researcher need access file system implementation application analyze perform 
ideal world system vendors publish file system profiles systems sell 
application vendors publish profiles applications 
simplest case user select application file system profiles interest ana combined performance 
sophisticated users generate application profiles 
sections provide details hbench fs including file system profiles workload profiles techniques uses file system profile analysis tools performance predictions workload profile 
hbench fs high level architecture 
hbench fs consists set tools analyze performance specific workload target file system combining data file system workload 
addition analysis tools hbench fs includes tools generating performance profile target file system 
performance predictions profiles 
hbench fs research prototype intended demonstrate validity approach commercial quality product limitations describe sections 
general approach margo seltzer colleagues proposed different methods performing application specific benchmarks vector trace driven hybrid seltzer 
hbench fs falls category combining aspects vector trace driven approaches 
vector benchmark uses system vector characterize performance system application vector characterize behavior application 
element system vector gives performance aspect target system 
corresponding element application vector measure application uses piece system functionality 
dot product vectors provides prediction application performance system provided system vector 
aaron brown technique analyze effect operating systems apache web server performance brown 
zhang vector techniques perform application specific benchmarking java vir tual machines zhang 
workload profile consists stream file system requests issued application interest goal hbench fs predict latency operation trace 
hbench fs individual performance predictions vector methodology described 
case system vector consists microbenchmark results file system profile 
hbench fs generates application vector called request vector context file system request produces performance prediction request dot product vectors 
performance file system heavily dependent order receives requests 
read requests sequential ranges file typically outperform random requests file 
similarly series requests exhibit strong locality outperform request stream locality 
hbench fs captures aspects file system performance system request vectors including separate performance elements sequential random access patterns cached uncached file accesses 
order generate request vectors hbench fs needs know access pattern cache behavior request 
information depends relationships requests workload obtained looking individual file system requests isolation 
hbench fs uses seltzer trace driven methodology 
generating request vectors hbench fs preprocesses workload trace cache simulator tools annotate trace indicate cache behavior access patterns request 
better understand hbench fs generates performance predictions consider example single request create file named usr home keith test file 
hbench fs subdivide request discrete file system operations name lookup operations component pathname single file create operation 
hbench fs analyzes cache behavior request processes 
conclude lookups hit name attribute caches final lookups caches 
request vector form lookup misses lookup hits file creates eq application vector 
table provides sample mark measurements values taken ffs performance fast test config described section 
values get system vector predict latency file creation request dot product vectors ms eq see generating request vector file system request com described 
addition differentiating lookups hit name attribute caches hbench fs considers request pat tern stream lookups treating successive lookups directory differently lookups different directories 
analysis assumes create request succeed 
practice fail variety reasons target file exist component pathname invalid 
analyzing file system requests context snapshot included workload profile hbench fs determine request fail generate appro priate request vector 
limiting assumptions designed hbench fs evaluate limited class file system storage system archi locally attached single disk file systems 
means hbench fs evaluate variety interesting architectures class file systems provides sufficient range architectural variation provide interesting set test cases validating experimenting benchmarking methodology 
current form hbench fs model important aspects networked file systems 
performance predictions systems hbench fs need account effects network topology congestion file system performance 
similarly large scale direct attached storage devices typically contain multiple disks additional cache memory require extensions hbench fs performance model account additional level caching ability concurrently serve multiple requests parallel disks 
general hbench fs approach preclude analyzing complex file system architectures section discuss ways supported 
microbenchmark result ms lookup lookup hit file create table sample microbenchmark results 
table contains microbenchmark results example section 
results taken fast ffs configuration described section 
hbench fs checks common error conditions invalid pathnames 
types errors invalid permissions common typically represent exceptional case expected case behavior applications 
current version hbench fs limited operating system environments provide posix posix interface file system basic operating system services 
file system characterization hbench fs uses extensive set microbenchmarks characterize performance file system 
programs attempt measure performance aspects file system functionality 
assumptions underlying file sys tem architecture take advantage file system operating system spe cific knowledge obtain measurement data 
hbench fs uses collective microbenchmark results create system vector combines stream request vectors generate performance predictions workload 
microbenchmark goals designing suite microbenchmarks hbench fs uses generating system vec tor goals constraints 
benchmarks sive 
words measure aspects file system functionality 
functionality defined set system calls manipulate file system files 
table lists important calls posix file system interface provides brief description functionality 
goal hbench fs microbenchmarks quantify performance different aspects file system functionality expressed system call interface 
possible benchmarks orthogonal avoid redundancy 
ideally benchmark measure exactly piece file system functionality piece functionality measured exactly microbenchmark 
practical reality areas impossible divide file system functionality fine granularity desired 
writing file example typically requires allocating space data transferring data file 
file system interfaces way separate measure actions 
system call arguments functionality open pathname target file 
access mode 
creat pathname new file 
file permissions 
access mode 
open file returning file descriptor 
certain file operations read write performed file descriptor 
create new file returning file descriptor new file 
unlink pathname target file 
remove specified file 
read file descriptor 
transfer size 
buffer 
write file descriptor 
transfer size 
buffer 
read data current file offset application buffer 
write data application buffer file current offset 
close file descriptor 
close file 
calling process longer file descriptor file descriptor 
new offset 
set file offset pointer truncate pathname target file 
truncate file freeing storage space file descriptor 
allocated file removing inode directory entry mkdir pathname new directory 
access mode 
create new directory rmdir pathname target directory 
remove directory file descriptor 
transfer size 
buffer 
read directory entries directory 
stat pathname target file 
return attributes file directory fstat file descriptor access pathname target file 
determine specified type access desired access mode 
allowed target file 
rename pathname existing file 
new pathname file 
change name file 
chmod chown pathname target file 
change access mode owner group new file attributes access times target file 
file descriptor new file attributes table file system interface 
table lists important calls posix file system interface lists primary arguments provides brief description functionality 
calls truncate stat chmod chown versions takes file pathname argument takes descriptor open file argument 
listed separate call creat usually implemented passing special file creation flag open 
descriptions calls ignore complex aspects behavior 
portability important goal microbenchmark suite 
achieve microbenchmarks access file system standard public interfaces 
mentioned section benchmarks assume run file system supports posix interface 
benchmarks exploit knowledge designer may file system internals system specific interfaces 
example systems provide system call provides access values various system parameters size buffer cache call bsd unix 
call standard rely determine size target system buffer cache 
hbench fs includes microbenchmark measures buffer cache size empirically 
microbenchmark selection simplest approach building microbenchmark suite provide microbenchmark measuring call file system interface 
approach pre sents number problems 
system calls perform differently depending arguments state system 
read system call prime example 
amount time takes complete read vary considerably depend ing target data buffer cache 
data buffer cache latency read call vary size read request takes longer transfer megabyte data buffer cache transfer kilobyte 
requests data buffer cache see perfor mance varies 
case performance depends request size access pattern 
file systems optimize file layout sequential access 
series reads request sequential ranges data file perform better series reads request data random locations file 
factors mean comprehensive suite microbenchmarks requires multiple measurements system calls 
drawback benchmark system call approach redundancy 
file system calls overlapping functionality 
truncate call frees storage allocated file 
removing file frees file storage addition freeing inode clearing directory entry 
effort avoid redundancy important overlaps various calls file system interface 
scenarios system calls need measured variety arguments system different states 
table lists system calls identifying share functionality require similar measurement techniques 
pathname resolution shown table calls file system interface take pathname arguments 
processing calls file system parse specified pathname determine target file operation 
benchmarking system calls independently redundantly measure overhead pathname parsing require benchmark account performance target system call varies length pathname argument 
hbench fs includes separate microbenchmark measuring time file system takes resolve single pathname component 
hbench fs uses program measure time perform single lookup variety circumstances name name cache attributes target file attribute cache series lookups occur directory occur dif ferent directories 
hbench fs benchmarks file system calls take pathname argument controlled circumstances order minimize eliminate overhead pathname processing 
hbench fs measures performance calls short component pathnames 
tests ensure 
measure latency single pathname lookup microbenchmark performs series access calls 
call accesses directory test file system 
bring data needed resolve pathname cache 
second call measures time access directory names directory attributes caches 
third call measures time access file directory 
call accessing directory plus additional resolving pathname 
difference measurements represents time resolve pathname component 
pathname data loaded name attribute caches measure operation test 
predict latency pathname parsing system calls hbench fs combines results name lookup benchmark result relevant system call benchmark demonstrated example section 
system call pathname resolution request size access pattern open creat unlink read write close truncate mkdir rmdir stat fstat access rename chmod chown table characteristics file system calls 
table summarizes common characteristics frequently file system calls 
column corresponds piece functionality aspect behavior shared calls 
pathname resolution column indicates calls translate pathname arguments determine file operate 
request size column indicates calls performance depends request size argument provided caller 
usually size request 
truncate calls specify request size implicitly size file truncated 
access pattern column indicates calls performance depends caller pattern access sequential vs random multiple requests 
performance calls designated cache state column depends target data buffer cache 
truncate column indicates calls truncate target file explicitly implicitly 
get attr set attr columns indicate calls read modify respectively target file attributes 
calls listed async column generate file system activity asynchronous system call 
cache state truncate get attr set attr async request size cache state access pattern performance file system calls depends request size passed 
read write calls transfer variable amount data file system user 
time transfer data user buffer cache proportional request size vary just byte gigabytes bit architectures 
file system architectures performance file system varies depending size file 
saw chapter overhead reading indirect block ffs substantial impact file throughput 
hbench fs accounts relationship request size latency ways 
cached reads writes hbench fs assumes written disk asynchronously hbench fs assumes performance expressed equation requires benchmark measurements measure basic overhead read write system calls measure rate system transfers data application buffer cache 
hbench fs measures quantities twice read calls write calls 
latency syscall overhead request size data transfer rate eq read requests satisfied buffer cache system call latency includes time fetch desired data buffer cache disk 
time depends variety factors including file system layout clustering pol parameters underlying disk difficult reduce uncached read performance simple formula 
hbench fs measures uncached read perfor mance variety file sizes similar file throughput benchmark chapter section 
performance uncached reads depend requesting application access pattern 
account hbench fs benchmarks uncached reads sequential random access patterns 
read request size 
traditionally non sequential file access patterns referred random truly random 
hbench fs benchmarks measures latency sequential random accesses 
theory system call treated way read write calls separate measurements system call overhead transfer rate uncached throughput variety request sizes access patterns 
hbench fs approximates performance microbenchmark results read system call 
file truncation truncate calls cases performance may function request size 
case request size passed file system argument implicit size file truncated 
performance calls depends size target file 
benchmarks uncached reads hbench fs measures time truncate files variety sizes 
truncate performance depends size target file state buffer cache 
file systems form indirection indirect blocks ffs store pointers data blocks large files 
order truncate file file system determine blocks allocated file freed 
file indirect blocks cache truncate call synchronously read disk significantly increasing call latency 
accurately capture behavior hbench fs measures truncate performance files cached uncached 
unlink system call implicitly truncates target file freeing file blocks part removing file 
separately benchmarking unlink call variety file sizes cache states truncate hbench fs uses truncate benchmark results predict latency unlink calls 
hbench fs determines cost remove file time deallocate storage measuring time remove zero length file 
predict latency particular unlink call hbench fs adds time truncate file appropriate size cache state basic unlink overhead 
unlink call takes pathname argument hbench fs adds time resolve pathname 
hbench fs handles rmdir call removes directory file way 
place truncate operation occur open call 
optional argument open system call allows caller specify operating system truncate target file opening 
case hbench fs adds truncation time prediction latency open call 
file attributes table shows number file system calls manipulate file attribute data 
calls divided groups return file attribute data caller stat fstat access change value file attributes chown chmod 
benchmarking calls individually hbench fs measures performance call group stat chmod uses results calls group 
asynchronous overhead far discussion assumed performance impact file system request limited synchronous execution time operation 
request types true 
requests impose additional asynchronous performance costs file system 
file systems example optimize write performance implementing write cache 
application issues write request system file system copies target data application buffer cache control returns application continues executing 
file system marks data blocks buffer cache dirty indicating flushed disk time 
time file system needs reclaim buffer space dirty data part regularly scheduled task file sys tem writes dirty data disk 
application perspective latency write request time transfer data buffer cache corresponding disk writes occur asynchronously 
disk writes effect latency original write request affect performance subsequent file system operations may find disk requests queued nous writes 
hbench fs includes microbenchmark quantify asynchronous cost 
benchmark executes workload known performance characteristics concurrently task issues write requests fixed rate 
hbench fs varies rate generates write traffic measures corresponding slowdown known workload 
provides measure asynchronous overhead write operations 
known workload hbench fs uses benchmark hot cache file truncation test contains mix file read write create truncate delete operations 
example shows slowdown ffs performance function write load 
theory type file system operation generate asynchronous overhead hbench fs measure potential asynchronous overhead type file system operation 
practice write operations percent slowdown write load kb sec 
example asynchronous overhead 
graph shows slowdown mixed workload file system operations function write load generated concurrent process 
data collected ffs running slow hardware platform described section 
common source asynchronous activity type operation hbench fs currently measures overhead 
microbenchmarks addition various performance measurements described point hbench fs includes handful measurements determine values various file system parameters block size sizes buffer cache name cache attribute cache 
hbench fs microbenchmarks values 
measuring uncached read times example hbench fs uses measured buffer cache size determine garbage data needs read file system order flush data cache 
hbench fs uses values file system parameters analyzes workload profile see section 
system vector 
table provides complete list benchmarks included hbench fs microbenchmark design implementation complete description implementation microbenchmark scope chapter 
benchmark stand program 
various programs share library provides functionality performing common tasks ing test files initializing various caches desired state 
benchmarks results benchmarks dependencies 
depen managed oram control benchmark execution 
benchmarks designed try determine average latency performance characteristic 
attempt vary conditions affect performance 
different areas disk drives different performance characteristics benchmarks operate large number files deliberately spread different directories attempt guarantee files distributed disk 
hbench fs explicitly require benchmarks run aged file system ensure results reflect performance name description units bc buffer cache size kilobytes name cache size name entries mdc meta data cache size files bs file system block size bytes fs file system fragment size bytes lus bc sequential lookup time name attributes cached milliseconds lus nc sequential lookup time name attributes cached milliseconds lus ac sequential lookup time attributes cached name uncached milliseconds bc random lookup time name attributes cached 
milliseconds nc random lookup time name attributes cached milliseconds ac random lookup time attributes cached name uncached 
milliseconds rdc cached read throughput kilobytes sec rd rd sequential read throughput different size requests kb kilobytes sec rd kb kb rrd rrd random read throughput different size requests kb kilobytes sec rrd kb kb write throughput kilobytes sec wr wr execution time fixed workload different amounts seconds wr concurrent write load kb kb kb rdo system call overhead read call milliseconds system call overhead write call milliseconds open open system call time milliseconds cr create system call time milliseconds rm unlink system call time milliseconds stat stat system call time 
milliseconds mkdir mkdir system call time milliseconds rmdir rmdir system call time milliseconds rename rename system call time milliseconds chmod chmod system call time milliseconds tr tr tr cached truncate time different size files kb kb kb milliseconds trc trc uncached truncate time different size files kb kb milliseconds trc kb table hbench fs microbenchmarks 
table lists microbenchmarks hbench fs characterize performance file system 
name column indicates keyword associated result microbenchmark result file 
hbench fs runs benchmarks repeatedly varying file size background workload 
rd throughput reading kilobytes files 
benchmarks measure latency corresponding file system functionality 
read write benchmarks measure file system throughput 
hbench fs converts throughput measurements latencies predicting execution time read write system calls 
target file system real world conditions 
results section aged file systems 
workload characterization workload characterization components trace file system operations generated workload runs snapshot target file system time trace started 
snapshot provides recursive listing names files directories target file system 
snapshot specifies parent directory inode number file test file system 
workload profiles collected snapshots unix file listing command ls 
information collected variety ways converted input format hbench fs requires 
file system request trace includes variety information 
importantly requests include inode number target file 
depending trace collected information may included raw trace may derived post processing trace convert pathnames file descriptors inodes numbers 
hbench fs needs original arguments passed file system requests 
read write calls requires request sizes file offset 
trace includes pathname arguments 
pathnames may specified relative calling process current directory inode number directory needed 
variety ways collecting required trace information 
collected traces study instrumenting bsd os kernel 
application call file system kernel writes relevant trace information internal buffer 
user level daemon process periodically copies 
chapter term inode refer unique identifier file 
traces fact inode number ffs 
hbench fs requires numbers unique file consistently file system trace snapshot 

posix definition read write file offset explicitly provided system call argument 
maintained internally file system 
offsets available raw trace computed post processing trace 
data kernel remote file 
technique similar linux trace toolkit actual trace points data collected different 
tracing techniques provide necessary data 
operating systems provide tools tracing system calls bsd systems 
traces seldom provide data hbench fs needs usually possible post process traces generate missing data 
system calls example specify target file small integer called file descriptor 
taken file descriptor insufficient identify target file 
trace includes file system operation usually open creat call returned file descriptor determine corresponding file 
appendix describes trace format hbench fs uses input output 
workload specific performance analysis section described hbench fs divides file system performance various microbenchmark results comprise system vector 
order analyze workload profile hbench fs needs generate request vector operation workload combine vectors system vector predict performance opera tion summarize performance predictions way useful user hbench fs 
section examine steps 
operations easy generate appropriate request vector 
recall synchronous cost write request expressed equation 
request vector write request write system call overhead write data transfers number kilobytes data transferred write request 
elements request vector zero 
operations request vectors difficult generate 
unlink operation example consists unlink appropriate size truncate lookups 
truncate lookup operations need know hit cache go disk 
addition need know lookup requests sequential directory random different directories 
order determine necessary information hbench fs includes tools analyze trace cache locality access pattern 
hbench fs generates performance predictions chain analysis tools 
tool pass workload trace adding additional information 
cache simulator example annotates operation indicate hits cache 
tool chain implemented unix pipeline tool reads writes trace fixed format 
tools share library functions manipulating traces 
easy add additional tools needed 
example custom preprocessing tool added chain convert trace formats format expected hbench fs 
similarly additional tools added chain perform custom analysis performance predictions 
inputs tools outputs workload trace workload snapshot system vector preprocessor cache simulator pattern analyzer performance analyzer postprocessing 
pathname multiple components lookup requests usually random 
sequential lookups occur pathname includes component successive file system requests pathnames directory 
request vectors request latencies performance predictions 
hbench fs tool chain 
diagram shows interactions various hbench fs analysis tools 
boxes left column represent inputs tools 
center column contains tools 
right column shows various outputs produced tools 
outputs tools inputs tools 
shows full tool chain shows tools modifies sample trace 
sections discuss tools detail 
preprocessing thing hbench fs workload profile preprocess format rest analysis tool chain 
primary goal step sure information workload snapshot propagated appropriate operations workload trace 
preprocessor reads workload snapshot builds memory graph representing file system hierarchy described snapshot 
preprocessor iterates requests workload trace 
encounters operation pathname argument uses memory image file system hierarchy resolve pathname adds inode number resulting file directory request record 
preprocessor updates memory model file system hierarchy encounters request creates deletes file directory 
typical trace commands fail due incorrect pathnames 
traversing memory image file system hierarchy preprocessor detects failures annotates corresponding file system requests indicate failure occurred 
information hbench fs generate request vector includes parts operation occur file system detects failure 
example open request component pathname third component invalid hbench fs generates request vector contains lookup requests 
lookup open occur file system continue processing request failed lookup 

code building manipulating memory copy file system hierarchy similar tool written diane tang senior thesis tang 
input trace open tmp file read file id offset count read file id offset count close file id preprocessor output open tmp file file id operations lookups open read tmp file file id offset count operations block read read tmp file file id offset count operations block read close tmp file file id operations close cache simulator output open tmp file file id operations cached lookup uncached lookup open read tmp file file id offset count operations uncached block read read tmp file file id offset count operations uncached block read close tmp file file id operations close pattern analyzer output open tmp file file id operations cached lookup uncached random lookup open read tmp file file id offset count operations uncached random block read read tmp file file id offset count operations uncached sequential block read close tmp file file id operations close performance analyzer output open tmp file file id operations cached lookup uncached random lookup open latency ms read tmp file file id offset count operations uncached random block read latency ms read tmp file file id offset count operations uncached sequential block read latency ms close tmp file file id operations close latency ms 
processing sample trace 
shows sample trace consisting opening file tmp file reading kilobytes read requests closing file 
data trace shown tool hbench fs tool chain processes 
new data added tool shown bold face 
latency numbers performance analyzer output computed microbenchmark results slow ffs configuration described section 
cache simulator cache simulator determines file system operations hit buffer cache name cache attribute cache 
simulator uses parameters system vector determine sizes caches file system fragment size uses unit granularity buffer cache 
simulator assumes caches empty trace keeps track caches contents trace updating processes request 
cache simulator assumes caches lru replacement scheme 
assumes dirty buffers flushed disk ready re time reach head lru list 
buffer cache simulation tracks file data blocks ignoring meta data inode blocks indirect blocks typically stored buffer cache actual file system 
simulator may optimistic predicting requests hit buffer cache 
meta data typically small portion total data file system minimal impact predicted hit rate 
read request simulator processes determines requested blocks buffer cache annotates request indicate number blocks hit buffer cache 
encounters request pathname argument simulator indicates name lookups hit name attribute caches 
truncate unlink requests cache simulator indicate target file indirect blocks buffer cache cache state data significant effect performance 
see section cache simulator keep track information hbench fs approximates cache state indirect blocks assuming file inode data blocks cached indirect blocks cached 
heuristic may accurate practice works 
tool buffer cache simulator written mary baker analyze benefits adding non volatile ram nvram computer systems baker 
modified code eliminate nvram simulation add support name attribute caches 
pattern analyzer described section hbench fs system vector differentiates sequential random access patterns 
analyzing workload trace pattern analyzer annotates individual file system operations indicate access pattern follow 
performance usually depends access pattern requests cache go disk tool ignores requests satisfied cache 
talk request sequential mean tial relative previous request generated disk request types analyze access patterns file reads comparable operation directories lookup operations associated requests include pathname argument 
analyzing reads simple 
disk bound read requests successive ranges file second request considered sequential 
read requests random 
successive lookup requests considered sequential looking files directory 
performance analyzer final component tool chain performance analyzer 
tools computes predicted latency operation workload trace 
aggregates data asynchronous costs write requests trace 
operation workload trace performance analyzer computes dot product operation request vector target file system system vector 
result hbench fs prediction operation latency target file system 
performance analyzer output fully annotated workload trace including request vector predicted latency operation 
analyzer computes total write throughput workload file system utilization 
throughput computation uses total run time workload timestamp operation timestamp operation divisor 
file system utilization represents fraction workload runtime file system active 
computed dividing total latency file system operations total run time workload 
computed file system utilization greater happen target file system slower system trace collected performance analyzer uses value 
performance analyzer uses values predict asynchronous overhead write requests workload 
performance analyzer interpolates write overhead data included system vector determine amount slowdown associated expected throughput level 
predicts asynchronous overhead equation 
asynchronous overhead slowdown total latency utilization eq intuition equation estimated slowdown factor multiplied total latency file system operations predicts cost asynchronous activity associated workload 
overhead effect operations workload 
file system disk idle half time expect roughly half asynchronous operations occur disk idle 
scale total overhead utilization 
ideally able assign asynchronous overhead individual operations workload trace suffer additional latency 
practice impossible empirically determining system write disk scheduling policies 
add considerable amount additional complexity performance analyzer simply reports write meta data update overheads addition producing trace annotated predicted latencies operation 
example consider hypothetical workload analyzed test platform write overhead shown 
assume workload total latency seconds spread run time seconds kilobytes second write traffic 
write overhead data pattern analyzer estimate write load result slowdown 
multiplying slowdown factor total predicted latency analyzer predict total overhead asynchronous write traffic seconds 
utilization system seconds predicted latency divided second runtime performance analyzer scale total asynchronous overhead amount predict additional latency asynchronous write traffic seconds 
postprocessing output performance analyzer described section official hbench fs output 
providing complete annotated workload trace hbench fs allows user perform additional analysis summarization results wishes 
user example sum latencies individual opera tions trace get prediction total amount time file system add workload latency 
useful type analysis sum latencies request type 
provides information types operations consume time identifying bottlenecks application file system 
trace processing library easy generate custom post processing tools 
took approximately minutes build tool compute predicted hit rate buffer cache 
shows sample output postprocessing tool analyze hbench fs predictions rest chapter 
tool computes total latency trace including asynchronous overheads writes meta data updates latencies operation type 
reports totals absolute time percentages 
understanding results important understand exactly hbench fs predicting 
operation workload trace hbench fs predicts amount latency file system contribute workload 
subtly different predicting actual latency operation 
key difference hbench fs account time disk bound request may spend waiting disk queue unrelated requests complete 
anytime file system issues request disk request may queued pending operations 
operations come sources concurrent file system operations write operations triggered earlier file system operations 
case hbench fs attempt predict amount time request spends blocked disk queue 
prevents hbench fs double billing time different file system requests 
validation order evaluate predictions hbench fs produces analyze perfor mance workloads variety file systems hardware platforms 
workload test platform combination compared actual measurements operation count time sec percent open read write create remove mkdir rmdir trunc getattr setattr readdir total predicted write overhead sec 

sample hbench fs output 
table shows output hbench fs processing sample trace 
raw output simple tool computes total latency collects statistics latencies number operations type operation trace 
latency operation type listed seconds percentage total latency workload 
load performance predictions generated hbench fs 
selecting workloads place different demands underlying file system show hbench fs accurate predictions variety conditions help isolate formance critical operations case 
test environment evaluated hbench fs different hardware platforms running differ ent file systems 
machines mhz pentium iii mhz pentium 
refer fast slow machines 
table provides full description hardware configurations 
machines ran bsd os release 
operating system derived bsd unix mckusick uses ffs native file system 
slow machine fast machine cpu pentium pentium iii clock speed mhz mhz memory mb mb disk controller ncr sym aha uw scsi bandwidth mb sec mb sec disk type seagate st seagate st lw total disk space gb gb rotational speed rpm rpm average access ms ms ms ms table test hardware configuration 
table describes hardware configurations test machines 
configuration hardware operating system file system slow ffs slow machine bsd os ffs slow ffs su slow machine bsd os ffs soft updates fast ffs fast machine bsd os ffs fast ffs su fast machine bsd os ffs soft updates table test configurations 
table lists hardware platform operating system file system test configurations 
bsd os includes support soft updates see section 
enabling disabling soft updates support provides different file systems evaluate 
table summarizes resulting test configurations 
test machines extra disk exclusively test file systems 
eliminated contention disk head test workloads generated loading executables swapping 
test file systems located gigabyte partition test disks 
running hbench fs test programs aged test file systems aging workload described section 
partition size slightly larger file system aging workload generated allow room create various files needed test workloads 
methodology evaluation select workloads stresses different parts underlying file system execute multiple file system platforms ing actual performance 
trace workload platforms 
trace file system profiles platform hbench fs predict performance workload platforms 
compare predictions measured performance platform 
predicting performance workload total latency computed hbench fs 
workloads spend time interacting file system sufficient compare hbench fs prediction total run time workload 
workloads spend significant amounts time outside file system 
hbench fs predicts latency generated file system compare total execution time workloads hbench fs predictions 
trace workload platform interest 
addition data required hbench fs traces include measured latency operation 
information determine time workload spends file system compare predictions hbench fs 
described section postprocessing tools hbench fs provide breakdown total time spent type operation 
compare predictions measurements running workloads target systems 
traces workloads running platform determine actual performance system time dividing timing information trace operation type 
workloads evaluating hbench fs results different workloads executing range different file system platforms 
varying applications examine hbench fs responds workloads place different demands underlying file system 
varying file system show hbench fs accurately predict system offer best performance different applications 
section describe workloads evaluate hbench fs 
need compare measured predicted performance workload multiple platforms need accurately reproduce workloads test platform 
macrobenchmarks test workloads 
kernel build workload traditional compiler workload complete build generic bsd os kernel 
workload consists primarily file read write operations compiler reads source file requisite headers writes resulting object files 
linker reads object files writes kernel binary 
approximately file reads write 
workload forms small number file create delete operations 
sdet spec benchmark designed emulate typical time sharing workload 
deprecated computing environments shifted time shared central com networked client server machines gaede 
interestingly advent thin client computing relocates computations central server machine suggests type workload may relevant evaluating system perfor mance schmidt wong 
basic sdet benchmark script user commands designed emulate typical software development environment 
script includes commands editing compiling searching comparing copying spell checking variety files 
sdet executes copies script concurrently reporting system performance scripts hour function degree concurrency 
evaluation hbench fs consider workloads different levels concurrency varying scripts 
postmark postmark designed jeffrey katcher reproduce file system activity generated mail usenet news commerce applications internet ser vice providers katcher 
workloads typically involve large number small kilobytes files constant flux 
model workload postmark creates large set files random sizes uniformly distributed preset range 
postmark performs fixed number operations files 
operations alternate creating deleting random file reading appending data random file 
create operation postmark selects size new file random range sizes initial file set 
reads file postmark reads file entirety 
append operation postmark opens file seeks writes random amount data file exceeding maximum file size 
postmark workload uses initial files ranging size bytes kilobytes 
files distributed directories test file system 
workload consists file operations described 
evaluation kernel build results shows measured total latency system latency predictions generated slow ffs trace workload profile 
graph shows hbench fs accurately ranks performance systems captures large scale performance differences 
workload switching slow machine fast machine provides larger performance gain adding soft updates ffs 
addition predicting total latency kernel build workload test configurations hbench fs provides breakdown latency generated different types system calls 
shows results breakdown actual breakdowns determined traces 
data see kernel build workload spends time performing file total file system latency seconds measured predicted 
measured predicted kernel build performance 
graph shows measured predicted performance kernel build workload bsd os test configurations 
performance metric total latency generated file system 
predictions generated slow ffs trace workload profile 
slow ffs slow ffs su fast ffs fast ffs su reads 
accounts large performance improvement switching slow fast platform relatively modest improvement offered soft updates 
fast platform offers higher throughput cached uncached reads 
contrast soft updates improves performance meta data updates occur read requests 
kernel build workload impact soft updates apparent total elimination time spent performing create operations slow ffs su fast ffs su configurations 
shows error hbench fs predictions workload attributed read predictions 
hbench fs overestimates read time configurations slow machine underestimates read time total file system latency seconds async get attribute create slow ffs slow ffs su fast ffs fast ffs su file system configuration write read open 
kernel build performance breakdown 
chart compares measured predicted performance kernel build workload bsd os test configurations 
bars subdivided show amount time consumed type operations 
performance predictions show predicted amount asynchronous overhead write requests 
overhead impossible isolate measured systems additional latencies caused asynchronous disk writes included operations experience 
configurations fast machine 
slow machine hbench fs slightly predicts time consumed get attribute stat fstat access open operations 
fast machine hbench fs slightly predicts time spent write requests 
addition predicting latencies individual requests hbench fs predicts total additional overhead caused asynchronous file system activity 
quantity show separately operation type costs predicted results 
impossible isolate cost activity measured data overhead necessarily included individual requests incur added latency 
impact asynchronous overhead write requests difficult results evaluate hbench fs predictions 
impossible gauge overhead affects measured performance operations trace easy measurement compare hbench fs prediction 
examine predictions asynchronous overhead affect accuracy hbench fs results 
shows asynchronous overhead predictions increase errors slow configurations increasing predicted total latency past measured latency 
fast platform opposite happens asynchronous overhead brings hbench fs predictions closer measured performance configurations 
way examine accuracy hbench fs predictions compare distribution predicted measured latencies individual requests workload 
shows data test configurations 
ease readability data displayed logarithmic scale latency axis 
systems show large discrepancies measured predicted distributions short latency millisecond events smaller differences longer latency events 
file system performance dominated longer latency disk bound requests hbench fs produces accurate performance predictions despite mispredictions faster events 
better understand errors hbench fs predictions examine distributions latencies different types file system requests 
shows distribution measured predicted latencies read open get attribute requests slow ffs configuration 
distributions slow ffs su configuration nearly identical 
graphs see different causes hbench fs mispredictions 
get attribute open requests hbench fs consistently predicts higher latencies measured actual system 
indicates microbenchmark results operations overly pessimistic 
note graphs general shape predicted distribution curve closely matches real distribution indicating hbench fs tool chain accurately predicting information cache hits access patterns 
average read requests platform slow ffs platform exhibit error different problem 
predicted data sharp slow ffs jump approximately milliseconds 
corresponds slow ffs su large number kilobyte uncached random read requests trace 
fast ffs slow ffs fast ffs su slow ffs su cumulative distribution cumulative distribution measured predicted request latency ms fast ffs measured predicted request latency ms cumulative distribution cumulative distribution measured predicted request latency ms fast ffs su measured predicted request latency ms 
kernel build latency distribution 
graph shows cumulative distribution measured predicted request latencies kernel build workload bsd os configurations 
axis graphs uses log scale 
cumulative distribution cumulative distribution cumulative distribution get attribute requests open latency ms read requests open requests measured predicted measured predicted read latency ms measured predicted open latency ms 
slow ffs kernel build distribution latencies 
graphs show cumulative distribution predicted measured latencies get attribute read open requests kernel build workload running slow ffs configuration 
distributions include get attribute requests read requests open requests 
hbench fs microbenchmarks provide single measurement value requests predicted latency 
real system requests experience range latencies indicated gradual slope measured read distribution 
case turns sum measured latencies slightly sum predicted latencies resulting hbench fs prediction read latency slow ffs configuration 
shows distribution measured predicted latencies read write requests fast ffs configuration 
fast ffs su configuration distributes nearly identical 
reads slow ffs noticeable cumulative distribution cumulative distribution read latency ms read requests write requests write latency ms measured predicted measured predicted 
fast ffs kernel build distribution latencies 
graphs show cumulative distributions predicted measured latencies read write requests kernel build workload running fast ffs configuration 
distributions include read requests write requests 
jump predicted latencies hbench fs predicts latency kilobyte uncached random read requests 
case actual distribution includes longer latencies uncached reads hbench fs predicts 
write requests fast ffs configuration hbench fs predicts relatively fast service times 
longer predicted latencies correspond larger request sizes system spends time transferring data application buffer cache 
measured latencies include number longer latencies 
magnitude latencies greater millisecond indicates requests blocking disk 
writes occur assembler writing object files 
assembler writes output non sequential order 
result periodically writes data block file system flushed disk 
disk pending file system locks corresponding cache buffer forcing subsequent write call block disk request completes 
phenomenon occurs fast machine slow machine greater difference cpu speed disk speed platform 
slow machine file system flushes buffers disk exactly point sequence writes slower cpu disk complete assembler writes additional data corresponding file block 
hbench fs attempts account delays aggregate prediction asynchronous overhead 
fast configuration predicted asynchronous overhead plus predicted time write operations measured time write operations see indicating hbench fs predicting asynchronous overhead associated type background write activity 
script sdet results turn examine results sdet workload starting results workload consists running just sdet script 
kernel build load trace collected slow ffs configuration workload profile hbench fs generate performance predictions test platforms 
fig ure shows measured predicted total latency workload 
graph shows different types file system operations contribute latencies 
kernel build workload discussed section 
hbench fs captures large scale performance differences various platforms 
kernel build workload adding soft updates ffs larger impact performance switch ing slow fast hardware platform 
reason readily apparent performance breakdown 
vanilla ffs configurations workload spends time performing create remove operations 
soft updates operations require synchronous disk accesses 
soft updates meta data updates occur asynchronously allowing create remove requests execute total file system latency seconds 
script sdet performance 
chart shows measured predicted performance script sdet workload 
bars subdivided show amount time consumed type operation 
performance predictions show predicted amount asynchronous overhead write requests 
overhead impossible isolate measured systems additional latencies caused asynchronous disk writes included operations experience 
async rmdir mkdir remove create read slow ffs slow ffs su fast ffs fast ffs su file system configuration memory speeds disk speeds 
fast ffs platform improves perfor mance create remove requests providing faster disk subsystem large improvement offered soft updates 
figures show distribution predicted measured latencies individual requests script sdet workload 
shows latencies requests platforms provides additional graphs show operations hbench fs greatest errors 
kernel build workload configurations show hbench fs consistently predicts duration short latency events millisecond 
requests get attribute open requests required pathname attribute data cached 
additional discrepancy different configurations show different amounts error longer latency events 
differences greatest effect total latency predictions 
cumulative distribution cumulative distribution measured predicted create latency ms create requests slow ffs measured predicted request latency ms cumulative distribution read requests measured predicted read latency ms 
slow ffs latency distributions script sdet workload 
top graph shows cumulative distribution predicted measured latencies requests script sdet workload 
bottom graphs show distribution latencies creates reads operations contributed hbench fs mispredictions 
note readability axis top graph uses logarithmic scale 
different sources errors observed data 
operations read requests configurations create requests slow ffs configuration hbench fs predicts single average performance metric class operations 
cases introduce errors actual average performance different hbench fs prediction 
phenomenon best illustrated create performance slow ffs configuration 
hbench fs predicts create requests latency approximately milliseconds operations longer due uncached pathname components 
distribution measured latencies shows broader range times tightly clustered milliseconds 
workload contains create operations 
average error milliseconds create get total error full second closely matches error seen 
cumulative distribution cumulative distribution read requests measured predicted read latency ms slow ffs su measured predicted request latency ms cumulative distribution remove requests measured predicted remove latency ms 
slow ffs su latency distributions script sdet workload 
top graph shows cumulative distribution predicted measured latencies requests script sdet workload 
graphs show distribution latencies read remove rmdir calls operations contributed hbench fs mispredictions 
note readability axis top graph uses logarithmic scale 
cumulative distribution cumulative distribution cumulative distribution read latency ms read requests fast ffs su fast ffs measured predicted request latency ms measured predicted measured predicted request latency ms cumulative distribution remove requests measured predicted remove latency ms 
fast ffs latency distributions script sdet workload 
top graph shows cumulative distribution predicted measured latencies requests script sdet workload 
bottom charts show distribution latencies reads removes operations contributed hbench fs mispredictions 
note readability axis top graph uses logarithmic scale 
cumulative distribution read requests measured predicted read latency ms 
fast ffs su latency distributions script sdet workload 
left graph shows cumulative distribution predicted measured latencies requests script sdet workload 
right graph shows distribution latencies read requests operations contributed hbench fs mispredictions 
note readability axis left graph uses logarithmic scale 
slow ffs su fast ffs configurations hbench fs noticeable errors predictions file remove operations 
latency distributions shown respectively 
slow ffs su configuration average remove latency predicted hbench fs considerably higher seen measured data 
predicted measured latencies quite small difference minor impact milliseconds performance prediction 
hbench fs incurs larger errors remove requests fast ffs configuration 
file remove operations execute disk speeds errors significant impact accuracy hbench fs performance predictions 
multiple script sdet results described section sdet benchmark allows user vary number scripts executes concurrently 
generated additional workloads concurrent sdet scripts 
shows measured predicted total latencies workloads 
general performance similar script load hbench fs predicts important performance differences 
script workloads hbench fs incorrectly predicts fast ffs configura tion outperform slow ffs su configuration 
sdet workloads hbench fs slightly predicts latency fast ffs configuration slightly predicts latency slow ffs su configuration 
number concur rent scripts increases measured performance platforms converges 
script workloads hbench fs errors large change ordering systems 
postmark results final workload examine postmark benchmark 
shows measured predicted latency workload contributions differ ent request types latency 
kernel build sdet workloads hbench fs consistently predicts performance postmark test plat forms 
largely due substantial errors predictions amount time spent processing read write requests 
shows distribution request latencies entire workload reads writes slow ffs configuration 
distributions similar total file system latency seconds total file system latency seconds total file system latency seconds sdet script measured predicted sdet scripts measured predicted sdet scripts measured predicted total file system latency seconds total file system latency seconds total file system latency seconds sdet scripts measured predicted sdet scripts measured predicted sdet scripts measured predicted slow ffs slow ffs su fast ffs fast ffs su 
multiple script sdet performance 
graphs show measured predicted performance sdet workloads different levels concurrency 
test platforms 
hbench fs predicts approximate shape latency distribution consistently predicts latency disk bound requests requests latencies millisecond 
errors occur read write requests measured latencies milliseconds longer hbench fs predictions clearly seen latency distributions request types 
causes discrepancies 
primary cause hbench fs underestimates asynchronous overhead caused write traffic 
workload writes megabytes data test file system compared megabytes kernel build workload megabytes script sdet workload 
furthermore data written small files large amount internal total file system latency seconds async remove create write read open slow ffs slow ffs su fast ffs fast ffs su file system configuration 
postmark performance 
chart shows measured predicted performance script sdet workload 
bars subdivided show amount time consumed type operation 
performance predictions show predicted amount asynchronous overhead write requests 
overhead impossible isolated measured systems additional latencies caused asynchronous disk writes included operations experience 
fragmentation file system writes far data disk 
fact disk writes outnumber disk reads postmark workload ratio approximately 
workloads disk reads outnumber disk writes 
net result write traffic impose significant latency disk bound requests 
shows hbench fs predict asynchronous overhead postmark workload nearly account large differences measured predicted time spent performing read write operations 
phenomenon accounts differences write latencies postmark workload partial block writes 
application appends data file block file may completely full 
case file system need add new data existing file block 
block memory file system synchronously read disk 
unfortunately phenomenon occurs postmark workload hbench fs cache simulator cumulative distribution cumulative distribution measured predicted read latency ms read requests slow ffs measured predicted request latency ms cumulative distribution write requests measured predicted write latency ms 
slow ffs latency distributions postmark workload 
top graph shows cumulative distribution predicted measured latencies requests postmark workload 
bottom graphs show latency distributions read write requests operations contributed hbench fs error 
distributions postmark workload test platforms similar seen 
charge corresponding write requests cost reading partial block 
accounts fact hbench fs predicts writes workload execute memory speeds 
real latencies show approximately percent write requests go disk 
extremely long latencies seen write requests due additional overhead write back traffic 
summary results previous sections described hbench fs predictions case case basis 
examine results attempt understand hbench fs predicts file system performance 
primary goals hbench fs allow users researchers compare workload perform different file systems 
predictions useful important hbench fs properly rank performance test systems 
ideal benchmark file systems workload correctly predict file system perform best workload cause latency 
combining data workloads test platforms studied comparisons 
cases hbench fs correctly predicts faster file system 
exceptions comparisons slow ffs su fast ffs configurations script sdet workloads 
see section gives hbench fs accuracy rate 
worth noting mispredictions occurred cases relative performance difference systems small script sdet workload script workload 
cases real performance difference systems small hardest predict correctly negative consequences performance ordering smallest 
performance difference systems small factors price reliability usability far important comparing systems 
best hope system hbench fs predicted latency precise match corresponding measured latency 
get understanding closely hbench fs approaches ideal plots measured predicted latency test workload file system pair 
correlation coefficient performance measurements predictions indicates strong linear relationship 
table shows raw data listing measured predicted latency test 
table shows error hbench fs prediction absolute terms percentage measured performance 
errors range script sdet workload running slow ffs configuration script sdet workload running fast ffs su configuration 
average error median 
root mean square rms error 
table shows average absolute error tests file system configurations 
slow ffs platform provided error test configurations 
platforms higher error rates 
surprising predicted file system latency sec measured file system latency sec 
hbench fs accuracy 
scatter plot shows predicted measured latency validation test 
data shows strong linear relationship measured performance workload hbench fs predictions 
correlation coefficient note axes logarithmic scales 
workload file system measured latency sec predicted latency sec prediction error sec prediction error kernel build slow ffs slow ffs su fast ffs fast ffs su sdet slow ffs script slow ffs su fast ffs fast ffs su sdet slow ffs scripts slow ffs su fast ffs fast ffs su sdet slow ffs scripts slow ffs su fast ffs fast ffs su sdet slow ffs scripts slow ffs su fast ffs fast ffs su sdet slow ffs scripts slow ffs su fast ffs fast ffs su sdet slow ffs scripts slow ffs su fast ffs fast ffs su postmark slow ffs slow ffs su fast ffs fast ffs su table hbench fs error summary 
table lists predicted measured total latency prediction errors test workloads configurations 
predicted measured latencies listed seconds 
errors listed absolute terms difference predicted measured latency seconds percentage measured latency 
largest sources error hbench fs predictions overhead cache write back traffic faster configurations workloads write data file system faster generating overhead 
table shows absolute error workloads averaged test configurations 
asynchronous write back traffic primary cause error workloads write traffic kernel build script sdet 
smallest errors workload greatest amount write traffic postmark largest error 
test configuration average error slow ffs slow ffs su fast ffs fast ffs su table hbench fs prediction errors test configuration 
table lists average absolute prediction error test configurations 
row average error workloads tested corresponding file system configuration 
workload average error kernel build sdet script sdet scripts sdet scripts sdet scripts sdet scripts sdet scripts sdet postmark table hbench fs prediction errors workload 
table lists average absolute prediction error test workloads 
row average errors file system configurations ran corresponding workload 
addition listing error different sdet workload sdet row lists average error different sdet workloads 
major weakness current version hbench fs way predicts overhead asynchronous file system activity 
developing hbench fs tried develop simple model provide single estimate aggregate cost back ground activity generated write requests 
resulting model provides useful esti mates workloads moderate amounts write activity kernel build sdet workloads substantially underestimates impact asynchronous workloads postmark large numbers small write requests 
current implementation hbench fs computes workload write throughput number bytes written write requests workload 
assumes overhead generated kilobytes write traffic regardless workload writes kilobytes single file kilobyte dif ferent files 
reality case generates times disk writes 
accurate compute asynchronous overhead number blocks written number bytes written 
possible approach develop sophisticated model delayed write interact subsequent requests 
standard write back policy file system buffer caches update hbench fs cache simulator mimic 
unfortunately range write back strategies employed different file systems need develop technique empirically determine algorithm target file system 
area hbench fs consistently errors handling remove requests 
intuitively approach computing latency unlink request time truncate file plus time remove zero length file sense 
results accurate handle removes truncates separately 
need run series remove microbenchmarks different file sizes update analysis tools compute remove latencies results 
add extensions handle wider range architectures 
interested multiple disk systems raid vanilla striping 
support need develop method modeling parallelism workload microbenchmarks measuring parallelism available system 
large class architectures useful support networked file systems 
non trivial challenges predicting performance systems 
hbench fs need model network latencies depend amount file system traffic possible presence large amounts non file system traffic 
second challenge face supporting client server file systems fact workload may spread number client systems 
variety minor improvements added hbench fs 
important add support memory mapped files 
principle simple extension hbench fs current functionality 
mapping file memory similar opening file 
page requests correspond file reads writes dirty pages provide metric amount asynchronous disk generated application 
need find way capture paging activity input traces 
wouldn problem current tracing tools sources things trace information derived standard tracing tools existing file system traces 
variety minor details corner cases hbench fs currently handle hard symbolic links 
know workloads functionality significant visible effect performance completeness included hbench fs 
file system performance heavily dependent workload runs file sys tem 
different workloads issue different mixes requests placing different demands underlying file system 
hbench fs provides automated tools allow user researcher predict particular file system architecture perform particular workload 
separating file system analysis workload analysis hbench fs allows user predictions having physical access target system 
hbench fs automates parts performance analysis researchers traditionally perform hand including target platform determining different parts file system interface contribute performance workload 
hbench fs produces predictions contribution file system total latency workload predicts time type file system operation contributes latency 
providing fine grained predictions operation workload hbench fs allows researchers perform customized analysis workloads 
predictions produced hbench fs typically accurate compared measured performance system workloads file systems 
predictions total latency average error correctly predict file system provide best performance particular workload test cases 
major sources error arose workloads generated large amounts write traffic 
chapter related chapter survey research related file system aging workload specific benchmarking 
describe techniques researchers artificially fill age file systems 
examine variety techniques evaluate system performance context specific workloads 
describe aimed developing analytic models file system performance 
file system aging chapter described file system aging accurately reproduce real world state file system 
date file system studies explicitly evalu ated performance file systems empty 
existing studies mea sure non empty file system performance variety ad hoc techniques fill test file system 
simplest way fill test file system create files consume desired amount space 
margo seltzer colleagues approach evaluating performance transaction processing workloads log structured file system lfs showing lfs performance declined free space file system decreased seltzer 
measurements seltzer filled test file system creating single large file appropriate size seltzer 
researchers stochastic methods age file system 
finkel tested file system aging technique created deleted files random selecting file sizes hyper exponential distribution 
ganger kaashoek similar technique evaluate clustering ffs distribution file sizes seen servers hyper exponential distribution ganger 
cases authors interested understanding fragmentation affected file system optimizations 
type aging useful fragmenting file system aging workload real file access patterns impossible determine amount fragmentation performance degradation seen studies matches users see real world 
karl swartz technique similar file system aging study usenet news performance swartz 
swartz benchmark repeatedly executed time consuming tasks news server perform batching expiring news articles 
separately aging test file systems running benchmark swartz benchmark aging workload repeatedly running benchmark observing decrease server performance file system increasingly fragmented 
workload specific benchmarks hbench fs evaluates file system performance context workload interest 
addition providing prediction performance hbench fs provides analy sis aspects file system performance critical applica tion 
hbench fs allows users perform analysis access target file system 
researchers variety techniques provide similar information ranging executing desired workload target platform performing detailed simulation target file system underlying hardware 
section discuss spectrum options available citing prominent examples research literature 
application benchmarks simplest approach determining particular workload perform tar get file system platform execute workload system question 
ad hoc approach numerous researchers benefit providing accurate results minimal effort 
approach assumes researcher ready access target file system little case hard ware software unavailable 
depending availability tracing profiling tools target platform technique may may provide kind detailed performance analysis available hbench fs 
customized nature technique difficult compare results multiple sources loads seldom identical 
effort standardize comparison workloads different platforms number researchers industry groups proposed standardized benchmarks common workloads 
jeffrey katcher postmark benchmark katcher described section example type benchmark 
postmark intended model file system activity generated internet server applications mail commerce usenet news 
benchmark issues requests directly file system api applications generate workload 
provides direct understanding file system contributes performance 
executing target applications assurance postmark workload representative file system requests generated applications 
documentation postmark unfortunately provides argument evidence benchmark accurately captures file system requests generated target internet applications accurately predicts performance leaving users rely intelligence faith author 
application benchmarks include execution actual software generates file system traffic 
typically benchmarks intended measurements performance application including performance file system network memory system parts system workload exercises 
transaction processing performance council tpc example standardized family benchmarks different types database workloads including line transaction processing decision support web commerce 
tests measure performance complete database solution including database software operating system underlying hardware 
carefully specifying measurement reporting processes tpc benchmarks attempt provide cross platform performance comparisons important class applications minimizing opportunities vendors manipulate results advantage burgess 
similar benchmarks include storage performance evaluation council spec measuring performance web servers mail servers java virtual machines spec usenet news benchmarks created yasushi saito colleagues saito 
standardized benchmarks tpc benchmarks easier compare results achieved different researchers vendors provide generalized way understand performance demands workload bottlenecks underlying file system 
trace driven simulations researchers wanted understand behavior file system implementations necessarily building buying desired file system usually simula tions place actual implementation 
common simulation studies trace driven cache simulations 
studies similar cache simula tion performed hbench fs results simulation pre dict performance workload simply report performance cache typically terms cache events misses write backs 
early trace cache simulations studied effects increasing size file system buffer cache changing write back policy ousterhout 
studies exam ined variety aspects cache design including name attribute caching shirriff cache consistency distributed file systems baker nvram caches baker variety cooperative caching strategies dahlin dahlin sarkar 
researchers trace driven simulations study aspects file system performance 
general simulations difficult develop cache simulations described need simulate file system cache pieces file system functionality 
log structured file system lfs architecture rosenblum topic simulation studies 
design cleaner original sprite implementation lfs informed results simulation studies random file system workloads rosenblum 
subsequent studies trace simulations study alternative cleaning algorithms blackwell matthews 
file system simulations contrast time performance predictions provided hbench fs simu lations described far provided metrics performance cache hit rates case lfs write costs 
understand absolute performance simulated file system architecture researchers need include underlying disk system simulation 
accurate disk simulators available individual disks ruemmler kotz disk arrays wilkes studies approach predict performance various file system architectures 
researcher includes disk simulator file system performance study faces problem translating file level activity disk requests fed simulator 
trace cache study example cache simulator decide requests cache typically provides information corresponding file blocks may allocated disk 
different researchers variety approaches solve problem 
simplest approaches include disk location files traces drive cache simulation random mapping files disk locations 
colleagues strategies trace study file prefetching caching policies 
complicated approaches incorporate file system code simulation increasing detail simulation required build simulator 
researchers built trace simulation environments provide scaffolding required run entire file system top disk simulator thekkath bosch 
randolph wang colleagues different approach 
simulating file system top disk simulator incorporated disk simulator running operating system 
test file system issued requests sent disk simulator determined appropriate delay servicing requests suspended requesting process appropriate amount time wang 
approach allowed researchers evaluate performance file system relied disk features available contemporary disks 
hbench fs offers middle ground detailed simulations described cache simulations described section 
simulator includes full file system source systems study researchers collect arbitrarily detailed performance data instrumenting simulator 
requires access file system source code detailed understanding file system implementation available users 
hbench fs contrast automatically provides detailed performance data needed users researchers 
machine performance characterization researchers techniques similar hbench fs analyzing pre processor performance 
example built instruction tim ing model predicting performance high performance circa processors ibm amdahl 
model instruction level traces predict performance application programs 
authors timing formulas derived manufacturers specifications predict latency instruction instruction set architecture 
simulated performance critical subsystems caches memory interlocks instruction prefetch account time add instruction latencies 
hbench fs motivated desire compare performance different systems similar interfaces file system interfaces case hbench fs instruction set architectures case instruction timing model 
resulting system accurately predicted processor perfor mance provided useful analysis execution time spent 
ret observed results analysis lasting unexpected benefits 
results included infor mation branch distances directions common instruction pairs operand lap lasting unexpected benefits 
design instruction timing model similar hbench fs 
systems combination trace analysis fine grained performance data predict performance workload individual operations comprise workload 
hbench fs instruction timing model provide cross platform performance comparisons platforms support instruction set architecture 
instruction timing model relies manufacturer specifications derive performance models individual instructions 
accuracy model depends accuracy availability information processor performance 
contrast hbench fs determines system performance suite microbenchmark programs allowing treat target file system black box 
saavedra smith machine model uses similar approach predict performance fortran programs saavedra 
view execution fortran program terms fortran operations called 
saavedra smith summarize behavior program program characterization generate profiling program execution determine times executes 
generate machine characterization suite microbenchmarks determine performance 
contrast instruction timing model described saavedra smith include trace driven simulation memory hierarchy relying published cache tlb data account impact memory system performance saavedra 
characterizing application behavior programming language level machine model allows performance comparisons systems different processor architectures 
suite microbenchmarks characterize system performance vector technique predicting application performance similar hbench fs 
analyze performance widely studied benchmark programs saavedra smith able previously published cache data workloads need develop trace analysis tools hbench fs instruction timing model 
hbench projects harvard university developing workload specific bench marks variety computer systems 
projects goal pro vide framework analyzing performance specific workload interest 
hbench fs benchmarks hbench os see section allow workload test system measured separately 
members hbench fam ily hbench web see section provide techniques distilling complex workloads benchmarks run target systems 
projects rely vector trace methodologies described seltzer colleagues seltzer 
hbench fs currently hbench benchmark hybrid approach combining vector trace benchmarking 
hbench os aaron brown initially developed hbench os measure performance netbsd operating system primitives variety hardware platforms brown 
results benchmarking suite vector methodology analyze apache web server performance operating system hardware platforms brown 
brown microbenchmark results produced hbench os sys tem vector system call tracing facilities characterize apache ing system functionality 
components vectors match exactly brown applied change basis application vector mapping compo nent corresponding microbenchmark result approximating related 
seltzer colleagues extended technique collection standard unix utilities ls tar seltzer 
able predict correct rank ing systems tested achieved reasonable predictions performance ratios different systems 
hbench java zhang vector benchmarking develop workload specific bench marks predicting performance java virtual machines jvms zhang 
zhang identifies high level components jvm represented system vector system classes memory management including allocation garbage collection costs execution engine including costs bytecode interpretation context switching just time compilation 
current version hbench java measures small subset java core api 
sufficient accurately predict performance variety large scale java applications 
zhang demonstrates value workload specific benchmarking com predictions hbench java results spec jvm standard ized workload independent benchmark 
spec jvm predictions accurate cases fail correctly rank performance different jvms 
hbench zhang vector benchmarking evaluate application spe cific performance jvm garbage collectors zhang 
benchmark character aspects garbage collector performance system vector fixed cost running garbage collector object cost collecting dead objects object cost examining live objects 
fixed cost parameterized heap size object costs live dead objects parameterized object size similar way hbench fs parameter read write performance request size 
zhang uses profiling data generate application vector 
hbench web contrast hbench benchmarks described section manley col leagues trace techniques workload specific web server benchmark manley 
hbench web analyzes web server logs generate site specific stochastic workloads measure web server performance 
hbench web collects types data processes server logs logical documents collections web documents requested typically appear web page user session profiles characterize pattern requests different users different ip addresses inter arrival time new user sessions 
data hbench web generates stochastic workload mimicking tics original workload seen server logs 
adjusting interarrival times users easily scale resulting benchmark model anticipated traffic increases 
fundamental goals hbench web hbench fs similar workload specific performance analysis hbench web similarities hbench fs 
incorporate vector benchmarking hbench web provides way characterize performance web server 
hbench fs hand benefit extensions allowed development parameterized stochastic workloads file system traces 
modeling probabilistic modeling techniques markov chains queuing networks widely predict performance computer systems notably field capacity planning 
hbench fs models typically combine workload characterization system characterization provide performance predictions 
strategy capacity planning build validate model existing system model study performance impact increased workload changes system configuration lazowska 
models complex software systems typically reduce behavior probabilistic model demands place underlying hardware 
modeling web server workload example researcher determine distribution request types requested files cgi script executions researcher measure average cpu time memory requirements operations type request 
validating initial model performance actual system researcher estimate performance alternate hardware configurations estimating effect proposed changes resource demands type request 
complex process requiring detailed familiarity operating characteristics system 
adding memory system example decrease rate file system buffer cache 
accurately model effect researcher estimate resulting change number operations request type workload 
hbench fs contrast analyzes file system performance terms standard api 
hbench fs evaluate performance workload file system combination requiring types detailed information underlying system components may required analytic models 
hbench fs provides detailed performance estimates probabilistic modeling techniques 
formal models typically represent workload probability distribution different request types hbench fs explicitly models exact sequence requests comprise workload 
allows hbench fs performance estimates sequence requests types requests 
actual workload traces hbench fs may allow detailed performance estimates drawback making difficult model hypothetical changes workload 
probabilistic model usually simple matter increase request rate change request mix workload 
efforts model behavior file systems relied techniques described reduce file system probabilistic model resource demands places underlying hardware system 
shriver colleagues group attempted model internal behavior file system 
developed simple model performance streams file read requests ffs shriver 
model explicitly incorporates details ffs disk layout prefetching strategy limiting ffs 
unclear easily model extended include full range file system activity significantly possible build model file system performance independent internal details target file system architecture 
researchers focused effort developing models disk performance 
disks better suited performance modeling 
file systems disks share similar designs performance characteristics making possible develop models support wide range disks 
sophisticated models disk performance developed past years researchers shriver 
colleagues queuing networks model performance hierarchical storage systems built network attached devices 
shriver colleagues composite device models model complex aspects modern disk behavior including read ahead caches request reordering shriver 
associates extended models multiple disks sharing common bus 
chapter lessons learned developing hbench fs iterative process involving repeated tests improve ments design 
design improvements driven errors performance predictions increased understanding performance critical aspects file sys tem design 
section describe practical lessons learned development experience 
development process hbench fs developed intermittently period years 
time high level architecture combining vector trace benchmarking remained largely unchanged 
details system changed sub including quantities measured microbenchmark suite meth ods combining fine grained measurements workload trace produce large scale performance predictions 
initial design hbench fs identified different types data file system call manipulate file data naming data file attributes 
type data read written cached accessed sequentially randomly 
simple taxonomy file system functionality provided different operations hbench fs needed microbenchmark cached sequential reads naming data 
design set tools similar cache simulator pattern analyzer final hbench fs design divided operation workload profile basic file system micro operations 
current implementation hbench fs strategy evident way predicts performance read write system calls 
simplicity approach appealing practice ran number difficulties 
micro operations benchmarked independently 
problematic operations read write name attribute data 
file system operations operate naming data read write attributes named file making impossible separately measure cost naming attribute micro operations 
cost performing certain micro operations varies depending higher level file system operation 
ffs example takes considerably longer write file attribute data create file change ownership file create operation synchronous change ownership call 
initial model account asynchronous overhead associated write operations 
successive designs eliminated quantities measured replaced microbenchmarks measured larger pieces file system functionality 
point idea modeling time perform file system opera tion time parse target file name plus time perform operation emerged 
subsequent improvements involved refinements set microbenchmarks processing algorithms 
discovered need treat cached uncached truncate operations importantly remove operations differently 
added separate benchmarks creating removing directories approximating time operations results file create remove microbenchmarks 
development hbench fs followed strategy incremental implementation 
initial implementation hbench fs measured predicted performance lookup read operations 
initial validation workload running depend kernel source tree heavy operations 
time added support file system operations hbench fs tested increasingly complex workloads 
reached point testing hbench fs complex workloads continued incremental improvements predictions attained sufficient level accuracy 
knew early stage hbench fs needed address problem account overhead write back activity pieces development 
essence waited see rest system produce reasonable results tackled harder outstanding problems 
benefits hbench fs architecture aspects hbench fs architecture development strategy facilitated evolution analysis tuning hbench fs 
benefits sur retrospect came 
software engineering aspects development methodology particular incremental approach adding functionality fully planned 
file systems complex software systems 
include different components caches prefetching write back algorithms disk layout policies components interactions components substantial impact performance 
surprisingly complexity greatest obstacle developing flexible benchmarking tool hbench fs 
considering multitude factors affect file system performance accurate performance predictions require measurements simulation analysis aspect file system 
hbench fs provides accurate performance predictions despite fact considerably complex file systems analyzes 
practice turns relatively small fraction file system functionality critical file system performance 
frequently executed read write system calls magnitude performance impact various caches 
phenomenon greatly simplified development hbench fs 
accurately characterizing behavior performance critical aspects file system architecture able quickly develop hbench fs point results promising warrant investigation 
iterative development strategy provided natural way exploit fact different aspects file system architecture different importance determining performance 
allowed focus initial efforts measuring simulating performance important parts file system adding additional detail needed hbench fs provided accurate predictions wide range file system functionality 
postponing minor details file system performance late development process ultimately able eliminate altogether turned effect performance small worth effort modeling 
amount accuracy desired results determined amount detail captured hbench fs 
commercial quality system research prototype effort undoubtedly required 
underlying strategy vector benchmarking determine performance individual file system operations proved flexible greatly facilitated incremental development hbench fs 
vector analysis encouraged dividing file system performance independent components expanding hbench fs changing way handled individual operations seldom required substantial changes bulk tool chain 
expanding system request vectors common changes development typically required development new microbenchmark addition simple functions pre processing post processing tools 
final benefit architecture hbench fs amount data provides 
wealth data facilitates analysis file system performance proved invaluable tuning debugging hbench fs 
development validation described section workload profiles included measured latency request trace 
comparing predictions measurements individual operations different classes operations usually able quickly identify causes prediction errors 
intermediate traces output program analysis tool chain provided invaluable source debugging information 
tools structured pipeline single monolithic program trivial look output quickly ascertain tool source problem 
wealth data hbench fs provides predictions computes seldom needed add instrumentation analysis tools better understand behavior 
hbench fs details course developing hbench fs uncovered peculiarities file system behavior usage affect development workload specific benchmarking tool 
section briefly discuss issues 
simulating partial block writes section describe partial block writes account tion error postmark workload 
file sizes seldom exact multiple file system block size final block file seldom full 
partially empty block buffer cache write operation appends data file synchro nous read required load disk 
causes corresponding write request execute disk speed memory speed 
phenomenon occurs overwriting existing data file 
write request block aligned data request added existing data blocks triggering disk reads blocks buffer cache 
preliminary versions hbench fs captured behavior cache simulator adding uncached read request vector cache simulator detected partial block write uncached data block 
unfortunately sparse files difficult cache simulator accurately predict partial block writes occur 
sparse file holes extents data written 
common way produce sparse file create new file seek offset past file start writing data 
resulting file extent file target seek contain data ffs file system architectures disk blocks associated 
difficulty arises application performs partial block write hole sparse file 
disk block allocated offset write file system simply copies data empty cache buffer allows buffer written asynchronously disk 
glance may unusual scenario practice occurs regularly common applications write output non sequential order assembler linker kernel build workload described section 
order know handle unaligned write cache simulator able determine corresponding block target file allocated 
current implementation hbench fs cache simulator model sparse files 
faced choice simulating reads triggered partial block writes predicting write times workloads contain writes sparse files simulating reads predicting write times workloads contain non aligned appends overwrites 
chose option 
examined data suspect appends common cause partial block writes 
balanced approach include overhead reads triggered appending data file ignore generated types partial block writes 
best solution course 
posix semantics dictate operating system return zeros application reads location file written 
applies holes sparse files reads occur past file 
modify cache simulator accurately model sparse files 
require substantial modifications simulator presents difficulty determining files workload snapshot sparse 
simulating sparse files sparse files cause inaccuracies hbench fs 
reading hole sparse file generate disk reads file system simply provides zero data offsets corresponding hole 
cache simulator model sparse files charges application uncached read target data buffer cache 
workloads examined seldom issue reads sparse files 
workloads transaction processing may heavier sparse files 
accurately predict performance workloads may necessary add support sparse files cache simulator 
additional sources background measuring overhead background operations hbench fs con write back activity generated write system calls 
preliminary versions hbench fs included similar benchmark measure background overhead gener ated file create remove operations 
studies soft updates shown meta data updates generate substantial asynchronous disk traffic seltzer 
workloads studied inaccuracies measuring effect greater small amounts background load caused create remove calls 
include benchmark final version hbench fs 
theory file system request generate background disk traffic 
ideally hbench fs model running tests similar existing write back overhead benchmark type file system call 
pathname lookup described section microbenchmark pathname lookup time varies state attribute name caches 
provides measurements cases name attributes target file cached cached attributes cached name 
fourth possible scenario cached name data uncached attribute data measurement unable generate sequence operations reliably cause file name cached attributes 
case rarely occurred traces examined approxi mated performance time lookup name attribute data cached 
practice lookup request misses name attribute cache may pay cost going disk fetch required data 
data may buffer cache 
simulate case lookup misses name attribute cache cache simulator determines data block target directory buffer cache 
cost lookup assumed lookup hits caches 
satisfied memory speeds disk speeds 
probably possible devise microbenchmark scenario practice necessary 
read request sizes request size arguments read calls value reflect amount data transferred user 
request size larger amount data current file offset file file system transfers existing data 
generating request vector read call hbench fs uses mimics behavior determines number blocks trans user 

benchmarking scenario hard links allow creation multiple directory entries refer file attributes 
allows warm attribute cache accessing file link 
measurement phase benchmark measure time access file different uncached link 
truncate size argument argument truncate system calls specifies size tar get file truncated 
truncating file non zero size application eliminate part data file grow file truncating larger size essen tially creating hole file 
require multitude additional cate benchmarks accurately simulate behavior hbench fs 
examining variety workload traces shows practice system calls rarely truncate file size zero ignored uncommon case truncating files non zero sizes 
traces examined showed file truncation occurs result open calls specify trunc flag directs operating system truncate target file opening 
lookup failures developing hbench fs noticed traces contain large number lookup operations fail usually open stat system calls 
typically occurs program searches different directories find desired file shell looking executable directory listed user compiler looking header files directories 
behavior occurs notice able effect workload performance needed modeled hbench fs 
new generation computer hardware provides performance improve ments 
processor speeds network bandwidths memory sizes continue grow rap 
disk performance improved slower rate 
increased disk capacities network bandwidths sparked similar increases data set sizes 
result trends storage systems increasing bottleneck contemporary applications 
techniques proposed implemented sold solutions bottleneck including file system optimizations soft updates ganger hardware solutions striping data multiple disks achieve higher bandwidths patterson integrated solutions combining new file systems disk array techniques hitz 
technology evaluating file system performance kept pace rapid evolution storage system design 
research papers continue evaluate new architectures simple benchmarking techniques changed little past years 
realistic techniques evaluating performance file system allow users answer question workload perform file system current benchmarks suffer variety shortcomings prevent effectively answering question 
benchmarks evaluate empty near empty file systems condition real users rarely encounter 
shortcoming bench marks operate executing fixed workload target file system 
provides little information workloads different mixes opera tions perform 
dissertation techniques addressing problems 
file system aging provides deterministic technique evaluating file system realistic state 
aging generates state replaying sequence operations mimicking long term workload file system accurately reproduces visible file system utilization invisible file fragmentation aspects file system state including types state may unique underlying file system architecture clustering fragmentation related inodes ffs 
file system aging provides technique evaluate design decisions affect performance life file system 
workload benchmarking addresses second problem 
hbench fs provides framework allows users predict specific workload perform different file systems 
addition allowing workload specific benchmarking hbench fs offers number advantages potential users 
separating evaluation file system evaluation workload allows user predict performance file system workload published data file system performance 
possible evaluate file system physically available testing due cost factors 
similarly hbench fs evaluate file systems exist allowing users conduct studies providing hypothetical system vectors 
addition providing simple predictions workload perform specific file system platform hbench fs provides wealth data researchers developers better understand application behavior file system performance 
appendix hbench fs input formats described chapter hbench fs takes inputs workload profile consisting file system trace file system snapshot system profile containing results suite microbenchmarks 
appendix document formats inputs briefly describe library functions hbench fs tools manipulate 
trace format hbench fs trace consists multiple records describes part single file system operation 
records written binary format 
allows processing tools manipulate traces extensive parsing means traces portable big little endian machines 
trace record consists file system operation structure followed strings 
file system operations described multiple trace records 
structure related substructures shown 
structure may contain pointers strings associated file system operation name target file directory 
pointers invalid raw traces trace processing library fills reads records trace 
multiple structures may chained specify single file system operation 
open system call example component target file pathname open request 
multiple operations chained manner flag chain flag set op flags field structure 
operation chain flag chain flag set 
operations take pathname argument broken chains input hbench fs tools 
hbench fs preprocessing tool adds truncate operations chains file directory remove operations open requests specify trunc flag 
tool substitutes create operation open operations creat flag set 
final output hbench fs collapses chain single record 
op type op flags op time sec op time nsec structure contains fields 
field specifies type operation described record 
table lists valid operation types 
note operations types sup ported current version hbench fs 
field contains flags 
valid flag values described table 
fields provide time stamp seconds nanoseconds respectively current operation 
indicates time operation issued original trace 
hbench fs uses timestamps determine elapsed time operations total time trace 
operations chained timestamp 
value timestamp operation trace matter long sub sequent timestamps increase indicate passage time 

maximum usability hbench fs include preprocessing tool divides individual operations chains 
current version functionality combined tool parses trace data produced instrumented kernel 
descriptor file typedef struct ino int char filename ino int char file parameters operation typedef struct file size offset offset start int count size bytes io settable attributes typedef struct int mode long uid long gid long size time atime time attr structure defines internal format hbench fs tools 
typedef struct int op type operation type int op flags flags time op time sec time operation int op time nsec pid op pid process id calling process long op client client id int op size nfs packet int op open flags flags open sys call int op class general class operation 
specifies structures valid 
file op target target file union io op un io operation attr op un attr 
second file needed file op un file rename link 
op un int op symlink data char op int sub operations int relation relation prev 
op double op latency predicted latency op 
msec double op latency real measured latency op 
msec double op measured time process de scheduled runnable running double op sleep time measured time process sleeping blocked 
trace data structures 
shows structures define trace format hbench fs tools 
structures operation trace 
operation name operation number description op null null operation 
op getattr get attributes 
stat fstat system calls 
op setattr set attributes 
chmod chown op lookup lookup 
resolve name specified directory op read file read operation op write file write operation op op create file create operation 
op remove file remove operation 
op rename file rename operation 
op link create link existing file 
supported 
op readlink read symbolic link 
supported 
op symlink create symbolic link 
supported 
op mkdir directory create operation 
op rmdir directory remove operation op readdir directory read operation op return file system attributes 
supported op root return handle root file system 
supported op open file open operation 
op directory open operation 
op close file close operation 
op directory close operation 
op access access system call 
op truncate file truncate operation 
op chdir change directory call 
table operation types 
table lists operation types supported hbench fs trace format 
note types supported op op root nfs operations system calls 
flag name flag value description flag target operation file 
flag target operation directory 
flag target operation symbolic link 
flag fail operation fails 
flag chain operation part chain operations 
flag chain operation chain flag ignore operation ignored 
table flag values 
table list legal flag values op flags field structure 
hbench fs sets flag fail flag operations expect fail example attempts open nonexistent files 
hbench fs sets flag ignore flag operations process 
typically occurs operation middle chain fails 
subsequent operations chain ignored 
op pid op client op op op flags op class op target field provides identifier process issued current operation 
current versions hbench fs field 
field provides identifier client issued current operation 
combined op pid field provide unique identifier job running distributed system 
current version hbench fs supports workloads running single machine field 
field 
originally intended store size nfs request traces generated nfs traffic 
open requests op open op type field field indicates flags passed open request 
hbench fs uses fields determine proper behavior simulate open request 
create truncate target file 
field indicates class operation 
hbench fs divides file system operations different classes 
class indicates optional fields esp op un field valid 
table shows possible values field mapping operation types classes 
mapping fixed class field redundant 
earlier versions hbench fs 
sub structure describes target file directory operation 
file structure defined 
structure contains inode number name target file directory parent directory 
op un op op relation union structures 
table shows sub structures valid class operation 
operation type op symlink corresponding symlink system call field contain length symbolic link 
operation type op symlink corresponding symlink system call field pointer link data 
pathname contained thy symbolic link 
represents partial request vector 
contains elements described table 
note array contain complete request vector 
full request vector currently stored place 
data request vector stored relation op type fields 
field indicates relationship current operation previous disk bound operation 
valid values field listed table 
class name class value operations valid fields class simple operations listed classes class io op read op write op readdir op truncate op un op un io class attr op setattr op un op un attr class file op rename op link op un op un file class symlink op symlink op op class ignore op null op op op root table operation class definitions 
table lists legal values op class field structure 
class table lists operations belong class fields structure valid operations class 
brevity complete list operations class simple included 
operations don appear table class simple 
truncate operations field io substructure op latency op latency real field contains predicted latency operation milliseconds 
optional field contains measured latency current operation mil 
component name component index description total number blocks written total number fragments written includes fragments contained partial block file total number blocks read total number fragments read includes fragments contained partial block file number blocks read buffer cache number fragments read buffer cache number lookups hitting name attribute caches number lookups missing name attribute caches number lookups missing name attribute caches name buffer cache number lookups hitting attribute cache missing name cache number lookups hitting name cache missing attribute cache number truncate operations cached meta data number truncate operations uncached meta data number file remove operations number directory remove operations number file create operations number directory create operations table request vector components 
table lists components request vector stored array structure 
note values 
op op sleep time optional field contains measured amount time milliseconds current operation running 
includes time spent run state process blocked ready run waiting processor 
optional field contains measured amount time milliseconds current operation spent blocked state 
difference op op sleep time fields amount time calling process spent runnable waiting processor 
relation name relation value description rel invalid relation field uninitialized 
rel targets current previous operations 
rel child target previous operation child target current operation 
rel parent target previous operation parent directory target current operation 
rel targets current previous operations directory 
rel unknown relationship targets current previous operations 
rel cached current operation satisfied cache 
table relationship values 
table lists valid values relation field structure 
string description op target filename name target file 
op target name target directory 
op un op un file filename name second file 
op un op un file name second file directory op contents symbolic link 
table string order 
table shows order strings trace file 
directory names may absolute relative pathnames 
note second file directory name appear trace record symbolic link 
record trace file may followed strings 
different strings may associated trace record file directory names target file file directory names second file stored op un op un file case link rename operations contents symbolic link 
strings structure contains char pointer unsigned integer field contain ing length string 
string trace file corresponding length field non zero 
strings record stored fixed order shown table 
trace library practice seldom need directly manipulate trace files 
hbench fs tools share library common functions reading writing trace records 
library write filters pre process post process workload profiles 
primary functions trace library described para graphs 
new op void function allocates memory trace record initializes new record contain null data returns pointer new record 
read op int fd function reads trace record file descriptor specified fd 
reads record associated strings current offset target file allo memory needed 
returns pointer new record null reaches input file 
void write op int fd record function writes trace record specified record file descriptor spec ified fd 
writes trace record strings contains 
include stdio include sys types include trace main argc argv int argc char argv rec int read blocks int read blocks rec read op null rec op flags flag ignore delete op rec continue read blocks rec read blocks rec delete op rec printf rate double read blocks double read blocks 
sample trace processing program 
sample program demonstrates trace library functions 
program iterates records trace file reading standard input 
sums total number blocks read operations total number reads buffer cache 
finishes processing trace file program prints predicted cache rate workload 
void delete op record function deletes trace record specified record 
frees storage allo cated record strings contains 
void print op file output record function prints human readable summary contents trace record 
standard paradigm functions iterate trace reading record read op processing possibly writing write op deleting delete op 
shows simple program post processes trace determine predicted cache rate 
snapshot format addition file system trace hbench fs requires snapshot file system trace collected 
trace format snapshot uses simple text format typically generated post processing output unix ls command 
snapshot contains listing files directory target file system 
listing starts pathname directory relative root file system single line 
line describes entry directory 
lines format type size name link field contains inode number file 
type field specifies type file regular files directories symbolic links 
size field contains file size bytes 
name field name file 
optional link field contains link data file symbolic link 

line directory listing line containing tilde characters directories typically listed depth order order appear output ls command 
order acceptable long directory listed parent directory listed 
line snapshot file necessarily contains name root directory 
addition name line contains inode number size directory 
contains small sample snapshot 
src lib include bin src trim total time summary print trace include include rcs makefile src rcs trim summary print trace makefile lib include trace bin trim total time timing summary simulator print trace 
sample snapshot 
shows small sample snapshot format expected hbench fs 
target file system contains top level directories src lib include bin contains variety files 
system profile format system profile text file containing results running hbench fs microbenchmark suite file system 
line file contains results single microbenchmark 
lines format benchmark result benchmark field contains name benchmark listed column table 
result field contains benchmark result units listed third column table 
system profile may contain comment lines starting character 
file generated automatically makefile controls running hbench fs microbenchmarks 
baker mary baker john hartman michael kupfer ken shirriff john ousterhout 
measurements distributed file system 
proceedings th symposium operating systems principles sosp pp 

monterey ca 
october 
baker mary baker satoshi etienne john ousterhout margo seltzer 
non volatile memory fast reliable file systems 
proceedings th international conference architectural support programming languages operating systems asplos pp 

boston ma 
october 
rakesh elizabeth shriver phillip gibbons bruce yossi matias jeffrey scott vitter 
modeling optimizing throughput multiple disks bus 
proceedings sigmetrics pp 

atlanta ga may 
beck michael beck harald hme ulrich robert magnus dirk 
linux kernel internals second edition 
addison wesley longman limited 
harlow england 

bennet michael bennett michael bauer david 
characteristics files nfs environments 
proceedings acm symposium small systems pp 


biswas biswas ramakrishnan 
file access characterization vax vms environments 
proceedings th international conference distributed computing systems pp 

paris france 
may 
blackwell trevor blackwell jeffrey harris margo seltzer 
heuristic cleaning algorithms log structured file systems 
proceedings usenix technical conference pp 

new orleans la january 
bosch peter bosch mullender cut paste file systems integrating simulators file systems 
proceedings usenix technical conference pp 

san diego ca 
january 
weinberger 
trace driven study cms file 
ibm journal research development vol 
num 
pp 

september november 
brown aaron brown 
decompositional approach performance evaluation 
harvard university computer science technical report tr 
april 
brown aaron brown 
operating system benchmarking wake lmbench case study performance netbsd intel architecture 
proceedings sigmetrics pp 

seattle wa 
june 
burgess gary burgess 
tpc 
top reasons favor tpc benchmarks 
transaction processing performance council 
www tpc org articles html 
cao pei cao edward kai li 
implementation performance application controlled file caching 
proceedings st symposium operating systems design implementation osdi pp 

monterey ca 
november 
cao pei cao edward anna karlin kai li 
implementation performance integrated application controlled file caching prefetching disk scheduling 
acm transactions computer systems vol 
num 
pp 

november 
chang chang mergen roberts porter 
evolution storage facilities aix version risc system processors 
ibm journal research development vol 
pp 

january 
chang chang gibson 
automatic hint generation speculative execution 
proceedings rd symposium operating systems design implementation osdi pp 

new orleans la february 
chiang chi ming chiang matt mutka characteristics user file usage patterns 
systems software vol 
num 
pp 

december 
nick david trent baker 
scalable news architecture single spool 
login vol 
num 
pp 

june 
russell 
bonnie experimental 
www com au bonnie site checked september 
cranor charles cranor 
uvm virtual memory system 
proceedings usenix technical conference pp 

monterey ca 
june 
dahlin dahlin clifford randolph wang thomas anderson david patterson 
quantitative analysis cache policies scalable network file systems 
proceedings sigmetrics pp 

nashville tn 
may 
dahlin michael dahlin randolph wang thomas anderson david patterson 
cooperative caching remote client memory improve file system performance 
proceedings st symposium operating systems design implementation osdi pp 

monterey ca 
november 
douceur john douceur william bolosky 
large scale study file system contents 
proceedings sigmetrics pp 

atlanta ga may 
duncan ray duncan 
advanced programming second edition 
microsoft press 
redmond wa 

forin alessandro forin gerald malan 
ms dos file system unix 
proceedings winter usenix technical conference pp 

san francisco ca 
january 
scott 
cyclic news filesystem getting inn 
proceedings th systems administration conference lisa pp 

san diego ca 
october 
gaede steven gaede 
perspectives spec sdet benchmark 
january 
available www spec org osg sdm sdet 
ganger gregory ganger frans kaashoek 
embedded inodes explicit grouping exploiting disk bandwidth small files 
proceedings usenix technical conference pp 

anaheim ca 
january 
ganger gregory ganger kirk mckusick craig soules yale patt 
soft updates solution metadata update problem file systems 
acm transactions computer systems vol 
num 
pp 

may 
robert joseph moran william shannon 
virtual memory architecture sunos 
proceedings summer usenix technical conference pp 

phoenix az 
june 
eric ii raphael finkel 
file system 
university kentucky department computer science technical report number 

hitz hitz lau malcolm 
file system design nfs file server appliance 
proceedings winter usenix technical conference pp 

san francisco ca 
january 
howard john howard michael kazar menees david nichols satyanarayanan robert sidebotham michael west 
scale performance distributed file system 
acm transactions computing systems vol 
pp 

february 
katcher jeffrey katcher 
postmark new file system benchmark 
technical report tr 
network appliance october 
tracy andrew tomkins hugo patterson brian bershad pei cao edward garth gibson anna karlin kai li 
trace driven comparison algorithms parallel prefetching caching 
proceedings nd symposium operating systems design implementation osdi pp 

seattle wa 
october 
kleiman kleiman 
vnodes architecture multiple file system types sun unix 
proceedings summer usenix technical conference pp 

atlanta ga june 
kotz david kotz song bac toh sriram radhakrishnan 
detailed simulation model hp disk drive 
dartmouth college department computer science technical pcs tr 
july 
kotz david kotz nils 
dynamic file access characteristics production parallel scientific workload 
proceedings supercomputing pp 

washington dc 
november 
kuenning geoffrey kuenning gerald popek peter reiher 
analysis trace data predictive file caching mobile computing 
proceedings summer usenix technical conference pp 

boston ma 
june 
lazowska edward lazowska john zahorjan scott graham kenneth sevcik 
quantitative system performance 
prentice hall englewood cliffs nj 

manley stephen manley michael courage margo seltzer 
self scaling self configuring benchmark web servers 
harvard university computer science technical report tr 
manley stephen manley margo seltzer michael courage 
self scaling self configuring benchmark web servers 
proceedings sigmetrics pp 

madison wi 
june 
manley stephen manley network appliance personal communication 
september 
matthews neefe matthews drew roselli adam costello randolph wang thomas anderson 
improving performance log structured file systems adaptive methods 
th symposium operating systems principles sosp pp 

saint malo france 
october 
mckusick kirk mckusick william joy leffler fabry 
fast file system unix 
acm transactions computing systems vol 
num 
pp 

august 
mckusick kirk mckusick keith bostic michael karels john quarterman 
design implementation bsd operating system 
addison wesley 
reading ma 

mcvoy mcvoy kleiman 
extent performance unix file system 
proceedings winter usenix technical conference pp 

dallas tx 
january 
daniel yesha 
analytic model hierarchical mass storage systems network attached storage devices 
proceedings sigmetrics pp 

philadelphia pa june 
daniel almeida 
evaluating web server capacity 
web techniques 
april 
www com archives 
miller ethan miller randy katz 
input output behavior supercomputing applications 
proceedings conference supercomputing pp 

albuquerque nm 
november 
mowry automatic compiler inserted prefetching core applications 
proceedings nd symposium operating systems design implementation osdi pp 

seattle wa 
october 
satyanarayanan 
long term distributed file tracing implementation experience 
software practice experience vol 
num 
pp 

june 
nelson michael nelson brent welch john ousterhout 
caching sprite network file system 
acm transactions computer systems vol 
num 
pp 

february 
oram andrew oram steve 
managing projects 
reilly associates sebastopol ca 

ousterhout ousterhout costa harrison kunze kupfer thompson 
trace driven analysis unix bsd file system 
proceedings th symposium operating systems principles sosp pp 

orcas island wa 
december 
park park becker 
iostone synthetic file system benchmark 
computer architecture news vol 
num 
pp 

june 
patterson david patterson garth gibson randy katz 
case redundant arrays inexpensive disks raid 
proceedings sigmod conference management data pp 

chicago il 
june 
patterson david patterson 
bad career research academia 
keynote address st symposium operating systems design implementation osdi 
monterey ca 
november 
slides audio available www cs utah edu lepreau osdi keynote html 
patterson hugo patterson garth gibson daniel jim zelenka 
informed prefetching caching 
proceedings th symposium operating systems principles sosp pp 

copper mountain december 
peacock kent peacock 
counterpoint fast file system 
proceedings winter usenix technical conference pp 

dallas tx 
february 
bernard leonard 
instruction timing model cpu performance 
proceedings th annual symposium computer architecture pp 

march 

file migration distributed computer systems 
ph dissertation university california berkeley 
july 
powell michael powell 
demos file system 
proceedings th symposium operating systems principles sosp pp 

west lafayette 
november 
carla ellis david kotz michael best 
characterizing parallel file access patterns large scale multiprocessor 
proceedings th international parallel processing symposium pp 

ieee computer society press 
april 
ramakrishnan ramakrishnan biswas ramakrishna 
analysis file traces commercial computing environments 
proceedings sigmetrics pp 

newport ri 
june 
ritchie dennis ritchie ken thompson 
unix time sharing system 
communications acm vol 
num 
pp 

july 
rosenblum mendel rosenblum john ousterhout 
design implementation log structured file system 
acm transactions computing systems vol 
pp 

february 
roselli drew roselli thomas anderson 
characteristics file system workloads 
university california berkeley technical report csd 
december 
roselli drew roselli jacob lorch thomas anderson 
comparison file system workloads 
proceedings usenix technical conference pp 

san diego ca 
june 
ruemmler chris ruemmler john wilkes 
disk drive modeling 
ieee computer vol num 
pp 

march 
saavedra rafael saavedra alan jay smith 
measuring cache tlb performance effect benchmark runtimes 
ieee transactions computers vol 
num 
pp 

october 
saavedra rafael saavedra alan smith 
analysis benchmark characteristics benchmark performance prediction 
acm transactions computer systems vol num 
pp 

november 
saito yasushi saito jeffrey mogul ben verghese 
usenet performance study 
unpublished manuscript 
www research compaq com wrl projects usenet ps 
november 
sandberg russell sandberg david goldberg steve kleiman dan walsh bob lyon 
design implementation sun network filesystem 
proceedings summer usenix technical conference pp 

portland 
june 
sarkar sarkar john hartman 
efficient cooperative caching hints 
proceedings nd symposium operating systems design implementation osdi pp 

seattle wa 
october 
satyanarayanan satyanarayanan 
study file sizes functional lifetimes 
proceedings th symposium operating systems principles sosp pp 

pacific grove ca 
december 
schmidt brian schmidt monica lam duane 
interactive performance slim stateless thin client architecture 
proceedings th symposium operating systems principles sosp pp 

kiawah island resort sc 
december 
seltzer margo seltzer keith bostic kirk mckusick carl staelin 
implementation log structured file system unix 
proceedings winter usenix technical conference pp 

san diego ca 
january 
seltzer margo seltzer keith smith hari balakrishnan jacqueline chang sara venkata padmanabhan 
file system logging versus clustering performance comparison 
proceedings usenix technical conference pp 

new orleans la january 
seltzer margo seltzer david keith smith zhang 
case application specific benchmarking 
proceedings th workshop hot topics operating systems hotos vii pp 

rico rio az 
march 
seltzer margo seltzer gregory ganger kirk mckusick keith smith craig soules christopher stein 
journaling versus soft updates asynchronous meta data protection file systems 
proceedings usenix technical conference pp 

san diego ca 
june 
seltzer margo seltzer harvard university 
personal communication 
november 
shirriff ken shirriff john ousterhout 
trace driven analysis name attribute caching distributed system 
proceedings winter usenix technical conference pp 

san francisco ca 
january 
shriver elizabeth shriver merchant john wilkes 
analytic behavior model disk drives readahead caches request reordering 
proceedings sigmetrics pp 

madison wi 
june 
shriver elizabeth shriver small keith smith 
file system prefetching 
proceedings usenix technical conference pp 

monterey ca 
june 
leonard bernard 
retrospective instruction timing model cpu performance 
years international symposia computer architecture pp 

sohi ed 
acm press 
new york ny 

small christopher small narendra ghosh margo seltzer keith smith 
systems research measure 
harvard university computer science technical report tr 
november 
smith smith 
analysis long term file patterns application file migration algorithms 
ieee transactions software engineering 
vol 
se pp 

july 
smith keith smith margo seltzer 
file layout file system performance 
harvard university computer science technical report tr 
december 
smith keith smith margo seltzer 
comparison ffs disk allocation policies 
proceedings usenix technical conference pp 

san diego ca 
january 
spec standard performance council 
specweb release 
line whitepaper 
www spec org osg web docs whitepaper html 
storage performance evaluation council 
spec jvm web site 
www spec org osg jvm 
storage performance evaluation council 
spec mail web site 
www spec org osg mail 
spencer henry spencer david lawrence 
managing usenet 
reilly associates cambridge ma 

staelin carl staelin hector garcia molina 
smart filesystems 
proceedings winter usenix technical conference pp 

dallas tx 
january 
swartz karl swartz 
brave little toaster meets usenet 
proceedings tenth systems administration conference lisa pp 

chicago il 
october 
tang diane tang 
benchmarking filesystems 
senior thesis 
harvard university 
cambridge ma 
april 
thekkath thekkath john wilkes edward lazowska 
techniques file system simulation 
software practice experience vol 
num 
pp 

november 
tomkins andrew tomkins hugo patterson garth gibson 
informed multi process prefetching caching 
proceedings sigmetrics pp 

seattle wa 
june 
tpc transaction processing performance council 
tpc benchmark standard specification 
associates 
ca 
august 
rodney van meter 
observing effects multi zone disks 
proceedings usenix technical conference pp 

anaheim ca 
january 
vogels werner vogels 
file system usage windows nt 
proceedings th symposium operating systems principles sosp pp 

charleston sc 
december 
wang randolph wang thomas anderson david patterson virtual log file systems programmable disk 
proceedings nd symposium operating systems principles osdi pp 

new orleans la february 
wilkes john wilkes richard golding carl staelin sullivan 
hp autoraid hierarchical storage system 
proceedings th symposium operating systems principles sosp pp 

copper mountain december 
wilkes john wilkes 
pantheon storage system simulator 
hewlett packard laboratories technical report hpl ssp revision 
may 
available www hpl hp com research itc csl ssp pantheon 
keith 
laddis generation nfs file server benchmarking 
proceedings summer usenix technical conference pp 

cincinnati oh 
june 
wong alexander ya li wong margo seltzer 
operating system support multi user remove graphical interaction 
proceedings usenix technical conference pp 

san diego ca 
june 
michel 
measuring characterizing system behavior kernel level event logging 
proceedings usenix technical conference pp 

san diego ca 
june 

ssh secure login connections internet 
proceedings th usenix security symposium pp 

san jose ca 
july 
zadok erez zadok ion alex 
extending file systems stackable templates 
proceedings usenix technical conference pp 

monterey ca 
june 
zhang zhang margo seltzer 
hbench java application specific benchmarking framework java virtual machines 
proceedings acm java grande conference pp 

san francisco ca 
june 
zhang zhang margo seltzer 
hbench application specific benchmark suite evaluating jvm garbage collector performance 
appear proceedings th usenix conference object oriented technologies systems coots 
san antonio tx 
january 

