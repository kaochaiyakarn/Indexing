media laboratory perceptual computing section technical report submitted ieee cvpr action recognition probabilistic parsing new approach recognition temporal behaviors activities 
fundamental idea inspired speech recognition divide inference problem levels 
lower level performed standard independent probabilistic temporal event detectors hidden markov models hmms propose candidate detections low level temporal features 
outputs detectors provide input stream stochastic contextfree grammar parsing mechanism 
grammar parser provide longer range temporal constraints disambiguate uncertain low level detections allow inclusion priori knowledge structure temporal events domain 
achieve system provide techniques generating discrete symbol stream continuous low level detectors enforcing temporal exclusion constraints parsing generating control method low level feature application current parsing state 
demonstrate approach experiments visual sensing data 
stochastic action recognition years tremendous growth amount computer vision research aimed understanding action 
noted bobick efforts ranged interpretation basic movements recognizing walking sitting task providing newtonian physics description motion objects 
particular emphasis activities behaviors entity recognized may considered stochastically predictable sequence states 
greatest number examples come form gesture recognition analogies speech handwriting recognition inspired researchers devise hidden markov model methods ivanov room media laboratory massachusetts institute technology ames st cambridge ma classification gestures :10.1.1.51.6538
basic premise approach visual phenomena observed considered markovian feature space sufficient training data exists automatically learn suitable model characterize data 
research interests lie area vision observations span extended periods time 
find situations purely statistical approaches recognition ideal 
situations characterized properties complete data sets available smaller examples easily semantically equivalent processes possess radically different statistical properties competing hypotheses absorb different lengths input stream raising need naturally supported temporal segmentation structure process difficult learn explicit priori known 
consider simple example draw square hand air clockwise counterclockwise direction 
case square model indicate square drawn 
seemingly simple task requires significant effort statistical pattern recognition techniques 
human observer hand provide set useful heuristics system model human higher level perception 
recognize need characterize signal heuristics turn attention syntactic pattern recognition combined statistical syntactic approaches allow address problems listed 
take advantage techniques divide activity recognition problem components 
lower level performed standard independent probabilistic temporal event detectors hmms propose candidate detections low level temporal features 
outputs detectors provide input stream stochastic contextfree grammar parsing mechanism 
grammar parser enforce longer range temporal constraints disambiguate correct uncertain mislabeled low level detections allow inclusion priori knowledge structure temporal events domain 
domains division clear 
example consider dancing 
small number primitives right leg back structured higher level units box step quarter turn 
typically examples right leg back drawn relatively examples higher level behaviors 
example recognizing car executing parallel parking maneuver 
higher level activity described car executes pull side primitive followed arbitrary number cycles pattern turn wheels left back turn wheels right pull forward 
instances natural division atomic statistically abundant primitives higher level coordinated behavior 
related vast amount syntactic pattern recognition devoted areas image speech recognition 
review syntactic pattern recognition related methods 
examples attempts enforce semantic constraints recognition visual data 
instance courtney uses structural approach interpreting action surveillance setting 
grammatical approach visual data recognition brand uses simple non stochastic grammar recognize sequences discrete events 
authors formulate fairly universal events common monitoring applications blob interaction primitives 
combined probabilistic syntactic approaches problems vision shown 
examples probabilistic parsing speech processing literature 

particular developing probabilistic extensions earley context free parser interest :10.1.1.113.983
probabilistic input formation recognize components model vocabulary train hmm atomic gesture 
run time hmms performs viterbi parse incoming signal computes likelihood gesture primitive 
run time algorithm output probability sequence length hmm output plot 
point probability plot normalized maximum likelihood hmm current sample input signal 
value result backwards search fifo queue corresponds sequence certain length 
plot shows lengths horizontal lines corresponding sample probability plot 
hmms recognize words gesture vocabulary version performs backward match signal window reasonable size 
time step algorithm outputs estimated likelihood sequence ends current sample length sequence 
exploit property enforce temporal consistency low level temporal feature happening time 
hmms run parallel providing parser maximum normalized probability corresponding sequence length time step 
shows output single hmm bank illustrating relation output probabilities sequence lengths 
event generation continuous vector output hmm bank represented series events want consider probabilistic parsing 
events terms express action grammar 
step need strong decisions discarding events just need generate sufficient stream probabilistic parser perform structural rectification suggestions find interpretation structurally consistent grammatical temporally consistent uses non overlapping sequence primitives maximum likelihood alternatively search position trellis product probability sequence length maximal 
result finding weighted maximum corresponds maximum probability sequence maximum length 
example output hmm bank 
top plot shows input sequence 
plots show output hmm bank superimposed result discretization 
corresponding discretized compressed sequence 
input vectors probabilistic parser formed samples sequences time step 
outputs low level feature detectors hmms 
tasks discussed simple discretization procedure provides results 
hmm bank select small threshold cut noise output search areas non zero probabilities maximum 
shows example output hmm bank superimposed results discretization 
discretization replace continuous time vector output hmm bank discrete symbol stream generated discarding interval discretized signal values zero 
displays example resulting event sequence generated 
probabilistic parsing goal parsing sequence find path input consistent expected structure forms temporally consistent sequence maximum probability 
perform probabilistic parsing sequence efficient earley context free parsing algorithm extended probabilistic input :10.1.1.113.983
structure sequence described stochastic context free grammar scfg formed associating probability production 
analogously hmms forward backward inner probabilities introduced 
forward probability instance computed sum probabilities derivations form prefix wt string wt probability path computed process iterates basic steps scanning completion prediction 
initialization scanning reads symbol input stream matches initial set rules 
rules satisfy symbol read stream corresponding pending derivations get pruned parse tree 
completion step set productions just confirmed scanning updates positions pending derivations way derivation tree 
prediction traverses grammar tree way leaf nodes finds set production rules currently possible position input parse tree 
scanning applied 
combined bottom bottom approach provides effective means propagating probabilities parsing process 
viterbi path traced parsing single derivation path maximum path probability 
notation algorithms notion state important part earley parsing algorithm 
state denoted xk marker current position corresponding production position input stream starting index substring production applied 
nonterminal said dominate substring wk wi wl case state wl terminal substring 
parser generates state set position input 
means notation states index belong th state set corresponding th position input stream 
state explains string dominates giving possible interpretation symbols wk wi 
discussion expressions context state generation read generates 
scanning scanning step simply reads input symbol matches pending states iteration xk xk forward inner probabilities 
note increase index 
signifies fact scanning step inserts states new state set iteration algorithm 
completion completion uses results scanning advance positions parse tree 
simplified probabilistic form completion step generates states xk yj 
xk prediction xk yj 
xk yj 
prediction step hypothesize possible continuation input current position parse tree xk xk prediction step introduces rule probabilities associated productions parsing process due recursion instances recursive correction needs applied probability computations 
complete details refer :10.1.1.113.983
recursive correction needs applied 
example lattice parse input 
dashed line shows possible parse 
rectangles drawn samples show spurious symbols parse need ignored derivation contiguous 
see spurious symbols simply removed stream alternative derivation sequence shown dotted line interrupted 
sample contains concurrent symbols handled lattice parsing 
extensions uncertain terminals likelihoods incoming symbols string available incorporated parsing algorithm multiplying forward inner probabilities likelihoods symbols scanning step 
essentially possible consider multiple instances input symbol time step performing parse input lattice 
input parser form vector consisting non zero likelihoods input symbols discrete instance time 
parsing performed parallel manner suggested terminals 
earley framework done efficiently additional terminal computational complexity increases linearly 
spurious symbol deletion 
parsing needs performed lattice symbols need consider inclusion string come random times 
results appearance spurious ungrammatical symbols input stream 
need able consider inputs separately different time steps disregard appearance input stream derivation ungrammatical 
time need preserve symbol stream considering possible derivations completely different string 
problem illustrated 
simple approach convert grammar introducing skip non terminal allowed match input sym bol making modifications 
terminal productions replaced apre bc bc 
pre terminal skip rule formed skip skip process performed automatically pre processing step grammar read parser modifications grammar explicitly written 
constraining terminal length consistency 
consider event terminal occurrence regard detected length terminal find grammatical sentences overlapping terminals 
order avoid need implement algorithm ensures timing consistency input symbols 
earley framework implement incremental fashion filter completion step keeping track terminal lengths scanning prediction 
order accomplish task need introduce state variables high mark low mark 
parsing steps modified follows scanning scanning step reads appropriate values available incoming terminal samples terminal 
updates propagated scanning follows xk xk index current sample 
addition set time stamp new th state set st prediction step 
completion similarly scanning completion step advances high mark state completing state extending range completed non terminal 
xk yj 
including xk completion performed states yj 
subject filtering constraints skip 
prediction prediction step responsible updating low mark state reflect timing input stream 
xk st st st time stamp state set updated scanning step 
essence filtering paths consistent timing terminal symbols considered 
exception skip states 
designed remove symbols stream temporally structurally inconsistent allowed temporally inconsistent 
interrupt parses sequence subsequences form parse remain connected skip states 
experimental results parser system augmented annotation module lets associate production rule annotation 
time production expand non terminal annotation attached annotation emitted rule resulting starting sample indexes optionally segmenting input signal semantically significant blocks 
results semantic recognition semantic segmentation gestures 
recognition disambiguation example simple gesture recognition semantic disambiguation show recognition short hand gesture take possible forms 
define square gesture counterclockwise right handed clockwise gesture consists parts top bottom left side right side 
formulation top bottom example ambiguous formed gesture 
note happen context 
right handed square top left right movement bottom right left 
case left handed square definitions reversed 
attempt semantically disambiguate definitions recognize square regardless fact segmentation dat label segment logp right hand square top bottom viterbi probability segmentation dat label segment logp left hand square bottom top viterbi probability square sequence segmentation 
right handed square left handed square 
right handed left handed square 
describe structure simple grammar reflects ambiguity terminal meaning skip rules omitted simplicity square rh lh rh top ud bot du lh bot du top ud top lr rl bot rl lr lr left right ud rl right left du receive input data vision system shown :10.1.1.47.9503:10.1.1.47.9503
system uses stereo algorithms determine position person hands head 
frame rate approximately frames second square data set consists samples experiment 
terminal recognition trained state hmms velocities examples primitive hand movements 
achieving reasonable recognition rate performed square gestures determining candidate events described 
results passed parser yielding results 
shows semantic structure recovered right hand square sequence labeled square 
recognition results left stereo interactive virtual environment computer vision system collect data 
handed square sequence shown 
note left right gesture interpreted top global context case bot tom second 
figures show timing constraints propagated parse formed continuous coverage input signal 
recognition semantic segmentation complex test approach chose domain musical conducting 
easy think conducting gestures complex gestures consisting combination simpler parts write grammar coincidentally book describing baton techniques written famous conductor max rudolf called grammar conducting 
capture data person trained conductor uses natural conducting gestures 
task attempting solve 
piece music includes part complex music beat pattern 
complex conducting pattern conductors gestures merging beats groups 
experiment collect data conductor conducting bars score arbitrarily choosing gestures attempt find bar segmentation simultaneously identifying beat pattern 
experimental setup essentially previous example 
jean second symphony opus major segmentation bar start sample conducted quarter beat pattern 
bar start sample conducted quarter beat pattern 
bar start sample conducted quarter beat pattern 
bar start sample conducted quarter beat pattern 
viterbi probability results segmentation long conducting gesture bar sequence 
trained hmms primitive components pattern components pattern 
primitives set similar corresponding hmms show high likelihood time results noisy lattice 
parse lattice grammar gc simplicity omitting skip productions gc piece bar piece bar bar right results run lower level part algorithm conducting sequence positional component 
demonstrates output probabilistic parsing algorithm form semantic labels corresponding sample index ranges 
figures see segmentation labeling performed correctly showing great deal semantic filtering skip states account large portion input samples 
formal grammars syntactic pattern recognition reasonable decomposition entity consideration set primitives lend automatic recognition possible 
method combining probabilistic model simple vocabulary gestures higher level structural knowledge tasks recognition temporal behaviors activities 
method semantic segmentation disambiguation labeling complex behaviors feature decompositional properties 
advantages method problems addressed instance grammar inference hard framework stochastic parsing 
researched opportunities fully utilizing production probabilities 
experiments determined heuristically simple reasoning understanding process 
rule probabilities reflect typicality string derivation play significantly important role recognizing interpretation activities higher complexity 
plan exploring added advantages learned probabilities research 
bobick 
movement activity action role knowledge perception motion 
philosophical transactions royal society london 
bobick wilson 
state technique summarization recognition gesture 
proc int conf comp vis 
brand 
understanding manipulation video 
pages 

courtney 
automatic video indexing object motion analysis 
pr 
pentland space 
proc 
comp 
vis 
pattern rec pages 
charniak 
statistical language learning 
mi press cambridge massachusetts london england 
fu 
step unification syntactic statistical pattern recognition 
ieee transactions pattern analysis machine intelligence pami 
ivanov bobick 
probabilistic parsing action recognition 
technical report tr mit media lab vision modeling group 
jelinek lafferty mercer 
basic methods probabilistic context free grammars 
pietro mori renato di editors speech recognition understanding 
advances trends applications volume nato advanced study institute pages 
springer verlag berlin 
rabiner juang 
fundamentals speech recognition 
prentice hall englewood cliffs 
max rudolf 
grammar conducting 
comprehensive guide baton techniques interpretation 
books new york 

pattern recognition statistical structural neural approaches 
wiley new york 
hunter jain 
recursive identification gesture inputs hidden markov models 
proc 
second annual conference applications computer vision pages 
starner pentland 
visual recognition american sign language hidden markov models 
proc 
intl 
workshop automatic gesture recognition 
zurich 
stolcke :10.1.1.113.983
bayesian learning probabilistic language models 
ph university california berkeley 
tsai fu 
attributed grammars tool combining statistical approaches pattern recognition 
ieee transactions systems man cybernetics volume smc number pages 

wren azarbayejani darrell pentland :10.1.1.47.9503
pfinder real time tracking human body 
ieee trans 
pattern analysis machine intelligence july 

