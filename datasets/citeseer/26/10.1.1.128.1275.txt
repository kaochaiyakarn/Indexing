factored partially observable markov decision processes dialogue management jason williams pascal poupart steve young engineering department school computer science engineering department cambridge university university waterloo cambridge university cambridge uk ontario canada cambridge uk cam ac uk cs uwaterloo ca eng cam ac uk shows dialogue model represented factored partially observable markov decision process pomdp 
factored representation benefits enabling nuanced reward functions specified 
dialogue model significantly larger past pomdps experiments small testbed problem demonstrate optimisation techniques scale produce policies outperform traditional fully observable markov decision process 
shows dialogue manager produced pomdp optimisation technique may directly compared handcrafted dialogue manager 
experiments testbed problem show automatically generated dialogue managers outperform handcrafted dialogue managers automatically generated dialogue managers testbed problem successfully adapt changes speech recognition accuracy 
creating improving dialogue manager hand typically expensive time consuming undertaking 
expressing actions machine take dialogue situation ideally dialogue designer simply express desired outcomes dialogue 
specification combined user model planning optimisation algorithm produce dialogue manager 
markov decision processes mdps provide principled framework type approach 
application mdps dialogue management problem explored levin pieraccini 
levin provide formal treatment mdp may applied dialogue management singh show application real systems 
mdps assume current state environment conversation known exactly naturally precisely model noisy evidence speech recogniser 
limitation prompted dialogue management researchers explore pomdps naturally express uncertainty current state 
roy compare mdp pomdp version spoken dialogue system find pomdp version gains reward unit time mdp version 
authors show trend speech recognition accuracy degrades margin pomdp outperforms mdp increases 
zhang extend ways 
authors add hidden system states account various types dialogue trouble different sources speech recognition errors 
second authors bayesian networks combine observations variety sources parse score acoustic confidence score looking outside po mdp framework paek horvitz suggest dynamic influence diagram model user dialogue state selecting actions maximum expected immediate utility proposal viewed pomdp greedily selects actions selects actions immediate reward 
choosing appropriate utilities authors show local grounding actions automatically selected principled manner 
interested pomdps enable planning horizon 
previous applied pomdps dialogue management important issues addressed 
unclear models estimate system dynamics practice 
example zhang indicate system dynamics handcrafted depending lot experience developer second model includes notion dialogue state result reward functions models capture notion appropriateness action example relative appropriateness confirming vs querying slot value 
handcrafted dialogue managers baseline comparison dialogue system literature authors attempt comparison handcrafted dialogue manager 
contributions 
propose factored architecture describing pomdp dialogue manager 
past applying pomdps express formally pomdp discount see section background pomdps 
zhang included unobservable states possible causes dialog trouble example channel errors contrast re interested conventional sense dialogue state viewed user example items confirmed 
mdps dialogue management factored representation adds component state dialogue perspective user enabling dialogue designers add reward measures appropriateness system actions 
factored representation creates separate distributions user model speech recognition model facilitates estimating adapting system dynamics dialogue data 
scope model results larger model past pomdp dialogue management problem show simple testbed problem developed perseus algorithm spaan vlassis scales sufficiently optimize model finds policy outperforms mdp baseline 
second show direct comparisons hand crafted automatically generated policy 
demonstrate technique introducing hand crafted dialogue managers testbed problem find dialogue manager created automated technique outperforms 
organised follows 
section briefly reviews background pomdps 
section presents factored architecture 
section shows example testbed system architecture 
section compares testbed system mdp baseline assesses robustness face changing speech recognition accuracy 
section shows handcrafted policy compared automatically generated policy comparison testbed problem 
section concludes 
overview pomdps formally pomdp defined tuple am set states am set actions agent may take defines transition probability am defines expected immediate realvalued reward am set observations defines observation probability am pomdp operates follows 
time step machine unobserved state machine selects action receives reward transitions unobserved state depends am machine receives observation dependant am observation gives system evidence current state known exactly maintain distribution states called belief state write indi cate distribution states time indicate probability particular state time immediate reward computed expected reward belief states 
mt goal machine maximise cumulative infinite horizon discounted reward called return literature system action set written un subscripted model machine user actions chosen write machine action set clarity 
mt bt am mt 
geometric discount factor time step belief state computed exactly shown eq 

belief space real valued optimal policy may consist arbitrary partitioning dimensional space 
fact size policy space grows exponentially size observation set doubly exponentially distance time steps horizon kaelbling 
real world problems possess small policies high quality 
approximate method called perseus 
perseus spaan vlassis capable rapidly finding compact policies exist 
perseus heuristically selects small set representative belief points iteratively applies value updates just points belief space achieving significant speedup 
perseus tested range problems outperform variety methods including grid methods spaan vlassis 
factored architecture proposal formulate dialogue manager spoken dialogue system factored pomdp follows 
pomdp state variable separated components user goal su su user action au au state dialogue sd sd pomdp state tuple su au sd note machine perspective components unobservable 
user goal gives current goal intention user 
examples complete user goal include travel itinerary request information calendar product user purchase 
user action gives user user actual action 
examples user actions include specifying place user travel responding question null response indicating user took action 
state dialogue sd indicates relevant dialogue state information perspective user 
example sd indicate particular slot stated stated grounded grounded 
sd enables policy decisions appropriateness behaviours dialogue example ungrounded items dialogue designer wish penalise asking open question vs grounding item 
note include state component confidence associated particular user goal 
concept confidence naturally captured distribution probability mass assigned particular user goal belief state 
explore speech recognition confidence score incorporated principled way 
pomdp action am am action machine takes dialogue 
example machine actions include greeting user asking user want go confirming user wants leave specific place 
pomdp observation drawn set au au note time step pomdp receives single observation maintains distribution possible user actions 
factor model decompose pomdp transition function follows su sd au su sd au am su su sd au am au su su sd au am 
assume conditional independence follows 
term call user goal model indicates user goal changes change time step 
assume user goal time step depends previous goal machine action su su sd au am su su am 
second term call user action model indicates actions user take time step 
assume user action depends current goal preceding machine action au su su sd au am au su am 
third term call dialogue model indicates user machine actions affect state conversation 
assume current state dialogue depends previous state dialogue user action machine action sd au su su sd au am sd au sd am 
sum transition function su su am au su am 
factored representation reduces number parameters required transition function allows groups parameters estimated separately 
example estimate user action model corpus counting user dialogue acts machine dialogue act user goal generic distribution adapt particular problem data available 
separately specify dialogue model handcrafted function information state update rules example larsson traum 
observation function am su sd au am 
appropriately cover conditions corpus need include variability strategy employed machine example wizard oz framework simulated asr channel 
observation function accounts corruption introduced speech recognition engine assume observation depends action taken user su sd au am au au 
observation function estimated corpus derived analytically phonetic confusion matrix language model observation discrete recognition hypothesis mixture discrete continuous recognition hypothesis confidence score 
shows influence diagram proposal 
reward function specified explicitly proposal depends design objectives target system 
note reward measure contain incentives dialogue speed turn penalty appropriateness rewards conditioned dialogue state successful task completion rewards conditioned user goal 
weights incentives estimated formalisms paradise walker adapted needs particular domain example accuracy performing financial transaction arguably important accuracy obtaining weather information 
update belief state time step am numerator consists observation function transition matrix current belief state 
denominator independent regarded normalisation factor 
substituting equation simplifying write implicitly assumes recognition grammar 
model readily extended enable system action activates particular grammar 
au au su su su timestep timestep influence diagram factored model 
dotted box indicates composite state comprised components su sd au 
shading indicates component unobservable 
arcs circular chance nodes diamond shaped utility nodes show influence arcs square decision nodes informational see jensen 
testbed spoken dialogue system test ideas proposal created simulated dialogue management problem travel domain user trying buy ticket travel city city 
machine asks user series questions submits ticket purchase request dialogue 
machine may choose fail 
testbed problem cities 
machine actions available including greet ask ask conf conf submit fail state space tuple su au sd user goal su su specifies user desired itinerary 
total user goals su dialogue state sd contains components 
indicate user perspective place place specified unconfirmed confirmed 
third component specifies current turn turn 
total dialogue states xd yd xd user action au au observation au drawn set null state components yield total states add additional absorbing state 
machine takes fail action submit action control transitions state dialogue ends 
initial prior probability user goal distributed uniformly user goals 
testbed problem user fixed goal duration dialogue define user goal model accordingly 
define user action model include variable set responses example user may respond ask ask user may respond greet toy user may respond confirm confirm point user respond respond null 
probabilities user action model chosen user usually provides cooperative varied responses doesn respond 
probabilities handcrafted selected authors experience performing usability testing slot filling dialogue systems 
intend estimate user model dialogue data 
define dialogue model deterministically implement notions dialogue state field referenced user takes value field referenced user exactly takes value field referenced user takes value define observation function encode probability making speech recognition error perr define observation function perr au au perr au vary perr explore effects speech recognition errors 
reward measure includes components task completion dialogue appropriateness including reward confirming field referenced user reward fail action reward submit action user goal respectively reward 
reward measure reflects intuition behaving inappropriately abandoning hopeless conversation early severe getting user goal wrong 
turn penalty expresses intuition equal short dialogues better long dialogues 
reward measure assigned greet action turn dialogue 
portion reward function effectively expresses design decision greet action may taken turn 
discount 
experiments 
perseus algorithm requires parameters number belief points number iterations 
experimentation belief points iterations attained asymptotic performance values perr space limitations detail distribution isn shown 
testbed evaluation comparison mdp baseline test automated solution pomdp feasible worthwhile created mdp dialogue manager baseline patterned systems literature 
mdp trained evaluated interaction model environment formed pomdp transition observation reward functions 
model environment takes action mdp input emits observation reward mdp output 
mdp state contains components field reflect standpoint machine value observed value observed confirmed value confirmed 
additional states dialogue start dialogue pomdp state space included mdp state space total mdp states 
mdp state estimator maps pomdp observation mdp state mdp action pomdp action 
example current mdp state mdp policy selects mdp action mdp state estimator maps mdp action back pomdp action updates environment model 
mdp state estimator tracks value observed slot enabling map mdp action confirm pomdp action confirm mdp action submit submit 
behaviour mdp state estimator identical mdp spoken dialogue system literature levin 
mdp learns experience simulated environment selected line learning technique watkins learning train mdp baseline 
variety learning parameters explored best performing parameter set selected initial values set exploration parameter 
learning rate set number visits updated 
evaluate resulting mdp policy dialogs simulated learned policy 
shows expected return pomdp solution average return mdp solutions vs perr ranging 
negligible error bars show confidence interval return assuming normal distribution 
note return decreases consistently perr increases solution methods pomdp solution attains largest return solutions values perr performance gain pomdp solution solutions increases perr increases 
result conclude pomdp solution copes higher speech recognition error rates better mdp approach consistent roy 
expected average return perr pomdp mdp expected average return pomdp policies mdp baseline 
error bars show confidence interval 
average return err evaluation performance pomdp policies vs perr 
white bars show policy trained perr checked bars perr shaded bars perr 
error bars show confidence interval 
robustness changes error rate practice error rate spoken dialogue system varies user user 
interested see pomdp solution adapts value perr designed 
shows average return dialogue managers executed different value perr error bars show confidence interval true average return sampled dialogues 
see pomdp solutions brittle fail perr deviates training 
comparison handcrafted policy method evaluate handcrafted policy intuitively policy specifies action take situation 
previous section relied representation pomdp policy produced value iteration value function represented set vectors dimensionality 
write indicate sth component nth vector 
vector represents value points belief space executing policy tree starts action associated vector 
write indicate action associated nth vector 
assume policy trees infinite horizon express optimal policy timesteps arg max value function method provides partitioning belief space regions corresponding optimal actions expected return action 
second way representing pomdp policy policy graph finite state controller consisting nodes number directed arcs 
controller node assigned pomdp action write indicate action associated nth node 
arc labelled pomdp observation controller nodes exactly outward arc observation 
denotes successor node node observation policy graph general common way representing handcrafted dialogue management policies 
complex handcrafted policies example created rules usually compiled possibly large policy graph 
policy graph expected return associated controller node explicit 
pointed hansen find expected return associated controller node solving system linear equations solving set linear equations yields set vectors vector controller node 
find expected value starting controller node belief state compute example handcrafted policies results handcrafted policies created called hc hc hc 
handcrafted policies take action greet 
hc takes ask ask actions fill fields performing confirmation 
user respond re tries action 
receives observation inconsistent nonsensical re tries action 
fills fields takes corresponding submit action 
logical diagram showing hc shown 
hc identical hc machine receives observation inconsistent nonsensical immediately takes fail action 
fills fields takes corresponding submit action 
hc employs similar strategy hc extends hc confirming field collected 
user logical diagram shown clarity actual controller uses real values variables resulting controller states 
responds confirmation re asks field 
user provides inconsistent information treats new information correct confirms new information 
user respond machine receives nonsensical input re tries action 
successfully filled confirmed fields takes corresponding submit action 
shows expected return handcrafted policies optimised pomdp solution 
pomdp solution outperforms handcrafted policies values perr inspected pomdp solution order characterise differs handcrafted solutions 
conceptually pomdp policy differs handcrafted policies tracks conflicting evidence discarding 
example pomdp policy interpret best observations slot handcrafted policies maintain hypothesis slot 
illustration consider environment uncertainty speech recognition errors 
environment benefit maintaining multiple hypotheses user goal expect pomdp perform identically policy track multiple hypotheses user goal 
demonstrates point perr hc hc form identically pomdp policy 
interesting note hc confirms inputs performs values perr reward function provided testbed system requiring consistent recognition results response ask response confirm gives rise longer dialogs outweigh benefit increase certainty greet ask ask guess hc handcrafted controller ask hc performs worse confirms element lengthening dialogue reducing return 
expected return err pomdp hc hc hc expected return vs perr pomdp policy handcrafted policies 
proposed factored architecture describing pomdps applied spoken dialogue management 
factored representation useful reasons facilitates estimating specifying system dynamics reducing number parameters enabling different aspects system dynamics specified independently 
second enables incorporation explicit dialogue model user standpoint allows dialogue designer add rewards appropriate dialogue behaviour 
shown convert handcrafted policy represented finite state controller value function providing principled way handcrafted policies compared directly policies produced automated solutions 
model larger past pomdp dialogue managers testbed problem shown pomdp optimisation technique finds policies outperform mdp baseline handcrafted controllers operating conditions 
pomdp solution appears adapt changes speech recognition error rate 
crucial theoretical issue scale model handle larger problems state action observation sets grow exponentially number concepts problem 
factored representation assist optimisation process may possible exploit factoring optimisation algorithms efficient 
reported supported eu fp talk project 
hansen eric hansen 
solving pomdps searching policy space 
uncertainty artificial intelligence madison wisconsin 

jensen 
finn jensen 
bayesian networks decision graphs 
new york springer 
kaelbling leslie pack kaelbling michael littman anthony cassandra 
planning acting partially observable stochastic domains 
artificial intelligence vol 

larsson traum larsson david traum 
information state dialogue management dialogue move engine toolkit 
natural language engineering 
levin esther levin roberto pieraccini wieland eckert 
stochastic model human machine interaction learning dialogue strategies 
ieee transactions speech audio processing volume 
levin pieraccini esther levin roberto pieraccini 
stochastic model computer human interaction learning dialogue strategies 
eurospeech rhodes greece 
paek horvitz tim paek eric horvitz 
conversation action uncertainty 
proc 
uncertainty artificial intelligence uai stanford ca june 
olivier 
framework unsupervised learning dialogue strategies 
ph thesis faculty engineering belgium 
roy nicholas roy pineau sebastian thrun 
spoken dialogue management probabilistic reasoning 
annual meeting association computational linguistics acl 
singh satinder singh diane litman michael kearns marilyn walker 
optimizing dialogue management reinforcement leaning experiments njfun system 
journal artificial intelligence vol 

spaan vlassis spaan nikos vlassis 
perseus randomized point value iteration pomdps 
technical report ias uva informatics institute university amsterdam 
matthew jason williams steve young 
framework wizard oz experiments simulated asr channel 
international conferences spoken language processing icslp south korea 
walker marilyn walker candace kamm diane litman 
developing general models usability paradise 
natural language engineering vol 

zhang zhang bo cai mao guo 
planning acting uncertainty new model spoken dialogue system 
proceedings th annual conference uncertainty artificial intelligence uai 
san francisco usa 
