value locality load value prediction lipasti christopher wilkerson john paul shen department electrical computer engineering carnegie mellon university pittsburgh pa shen ece cmu edu virtual memory demand paging cache memories computer systems exploiting spatial temporal locality reduce average latency memory 
introduce notion value locality third facet locality frequently real world programs describe effectively capture exploit order perform load value prediction 
temporal spatial locality attributes storage locations describe likelihood locations close neighbors 
similar vein value locality describes likelihood recurrence previously seen value storage location 
modern processors exploit value locality restricted sense control speculation branch prediction seeks predict value single condition bit previously seen values 
extends predict entire bit register values previously seen values 
find just condition bits fairly predictable static branch basis full register values loaded memory frequently predictable 
furthermore show simple microarchitectural enhancements modern microprocessor implementations powerpc alpha enable load value prediction effectively exploit value locality collapse true dependencies reduce average memory latency bandwidth requirements provide measurable performance gains 

related gap main memory processor clock speeds growing alarming rate rd 
result computer system performance increasingly dominated latency servicing memory accesses particularly accesses easily predicted temporal spatial locality captured conventional cache memory organizations smi 
conventional cache memories rely program temporal spatial locality reduce average memory access latency 
temporal locality describes likelihood referenced address referenced soon spatial locality describes likelihood close neighbor referenced address referenced soon 
designing physical attributes size line size associativity cache memory best match temporal spatial locality programs ongoing challenge researchers designers alike 
proposed adding 
currently intel portland oregon 
preprint appear asplos vii october additional features non blocking fetches kro victim caches jou sophisticated hardware prefetching cb alleviate access penalties locality characteristics captured conventional designs 
proposed altering behavior programs improve data locality programs better matches capabilities cache hardware 
improvements primarily limited scientific code predictable control flow regular memory access patterns due ease rudimentary loop transformations dramatically improve temporal spatial locality cmt 
explicit prefetching advance memory poor locality examined extensively context cb additional hardware support 
dynamic hardware techniques controlling cache memory allocation significantly reduce memory bandwidth requirements proposed 
addition alternative pipeline configurations reduce average memory access latency early execution loads examined jou 
relevant prior related tree machine har har uses value cache store look results recurring arithmetic expressions eliminate redundant computation value cache effect performs common subexpression elimination asu hardware 
richardson follows concept ric introducing concepts trivial computation defined operations occurrence simple operands redundant computation operation repeatedly performs computation sees operands 
proposes hardware mechanism result cache reduces latency trivial redundant complex arithmetic operations storing looking results result cache 
introduce value locality concept related redundant computation demonstrate technique load value prediction lvp predicting results load instructions dispatch exploiting affinity load instruction addresses values loads produce 
lvp differs harbison value cache richardson result cache important ways lvp table indexed instruction address value lookups occur early pipeline second speculative nature relies verification mechanism guarantee correctness 
contrast harbison richardson table indices available pipeline harbison uses data addresses richardson uses actual operand values require predictions correct requiring mechanisms keeping tables coherent computation 

value locality introduce concept value locality define likelihood previously seen value recurring repeatedly storage location 
concept general applied storage location computer system limited current study examine value locality general purpose floating point registers immediately memory loads target registers 
plethora previous dynamic branch prediction smi yp focused restricted application value locality prediction single condition bit past behavior 
viewed logical continuation body extending prediction single bit prediction entire bit register 
intuitively difficult task discover useful amount value locality register 
bit register contain values possibly predict somewhat occur 
turns narrow scope prediction mechanism considering static load individually task easier able accurately predict significant fraction register values loaded memory 
values predictable 
examining number real world programs assert value locality exists primarily reason partial evaluation sig effective compile time optimization real world programs run time environments operating systems incur severe performance penalties general design 
implemented handle contingencies exceptional conditions erroneous inputs occur relatively rarely real life designed expansion code reuse mind 
code aggressively optimized modern state art compilers exhibits tendencies 
empirical observations programs examined study feel helpful understanding value locality exists data redundancy frequently input sets real world programs contain data little variation 
examples sparse matrices text files white space empty cells spreadsheets 
error checking checks infrequently occurring conditions compile loads effectively run time constants 
program constants efficient generate code load program constants memory code construct immediate operands 
computed branches compute branch destination switch statement compiler generate code load register base address branch run time constant 
virtual function calls call virtual function compiler generate code load function pointer runtime constant 
glue code due concerns linkage conventions compiler generate glue code calling compilation unit 
code frequently contains loads instruction data addresses remain constant execution program 
gain non automatic storage compiler load pointers table initialized program loaded remains constant 
call subgraph identities functions procedures tend called fixed small set functions likewise tend call fixed small set functions 
result loads restore link register callee saved registers high value locality 
memory alias resolution compiler conservative stores aliasing loads frequently generate appear redundant loads resolve aliases 
register spill code compiler runs registers variables may remain constant spilled memory reloaded repeatedly 
naturally subject particulars instruction set compiler run time environment employed argued eliminated changes isa compiler run time environment applying link time run time code optimizations sw 
changes improvements slow appear aggregate effect factors value locality measurable significant today modern risc isas examined provide state art compilers run time systems 
worth pointing value locality particular static loads program significantly affected compiler optimizations loop unrolling loop peeling tail replication types transformations tend create multiple instances load may exclusively target memory locations high low value locality 
similar effect load latencies static load cache rates reported abraham 
rks table 
benchmark descriptions cc gcc spec flags cc gcc spec description input set spec insn recog spec cjpeg jpeg encoder bw image compress spec file compression eqntott spec eqn truth table gawk gnu awk result parser gnu hash fn generator grep gnu grep st mo mpeg berkeley mpeg decoder perl spec anagram search iter 
spec mod 
input spec simulator output file dict compress frames fast dithering find admits input quick quick sort random elements 
sc spreadsheet spec xlisp spec lisp interpreter doduc nuclear reactor simulator hydro computation galactic jets swm shallow water model tomcatv mesh generation program short input spec instr 
count ppc alpha queens tiny input spec short input spec iterations vs iterations vs total value locality value locality alpha axp cc cjpeg compress doduc eqntott gawk grep hydro powerpc mpeg perl quick sc swm tomcatv xlisp cc cc cjpeg compress doduc eqntott gawk grep hydro mpeg perl quick sc swm tomcatv xlisp 
load value locality light bars show value locality history depth dark bars show history depth sixteen 
benchmark set explore value locality quantify performance impact summarized table chosen thirteen integer benchmarks spec spec image processing applications cjpeg mpeg commonly unix utilities gawk grep gnu perfect hash function generator version gcc cc recursive quicksort 
addition chosen spec floating point benchmarks 
benchmarks compiled full optimization manufacturer compilers exception token benchmark compiled ibm cset compiler aix gnu osf 
benchmarks run completion input sets described include instructions tracing tools unable capture 
shows value locality load instructions benchmarks 
value locality benchmark measured counting number times static load instruction retrieves value memory matches previously seen value static load dividing total number dynamic loads benchmark 
sets numbers shown light bars history depth check matches retrieved value second set dark bars history depth sixteen check sixteen unique values see history depth integer programs exhibit load value locality range extending history depth sixteen hypothetical perfect mechanism choosing right sixteen values improve better 
means vast majority static loads exhibit little variation values load course program execution 
unfortunately benchmarks cjpeg swm tomcatv demonstrate poor load value locality 

history values stored direct mapped table entries indexed tagged instruction address values sixteen stored entry replaced lru policy 
constructive destructive interference occur instructions map entry 
value locality value locality value locality value locality cc cc cjpeg integer data fp data data addresses instruction addresses compress doduc eqntott gawk grep hydro mpeg perl quick sc swm tomcatv xlisp 
powerpc value locality data type light bars show value locality history depth dark bars show history depth sixteen 
explore notion value locality collected data classifies loads type data loaded floatingpoint data non floating point data instruction addresses data addresses pointers 
results summarized results shown powerpc architecture 
sets numbers shown benchmark history depth light bars depth sixteen dark bars 
general see address loads tend better locality data loads instruction addresses holding slight edge data addresses integer data loads holding edge floating point loads 

exploiting value locality fact memory loads programs demonstrate significant degree value locality opens exciting new possibilities 
describe evaluate load value prediction unit hardware mechanism addresses memory latency memory bandwidth problems novel fashion 
exploiting affinity load instruction addresses values loaded able reduce load latency cycles 
second reduce memory bandwidth requirements identifying highly predictable loads completely bypassing conventional memory hierarchy table 
lvp unit configurations 
history depth greater hypothetical perfect selection mechanism assumed 
lvp unit configuration lvp table cvu entries history depth entries bits entry bits entry simple constant limit perf perfect perf perfect loads 
lvp unit consists load value prediction table section generating value predictions load classification table section 
section deciding predictions correct constant verification unit cvu section replaces accessing conventional memory hierarchy verifying highly predictable loads 

load value prediction table predict value loaded memory associating load instruction value previously loaded instruction 
indexed load instruction address tagged constructive destructive interference occur loads map entry direct mapped 
table shows number entries column history depth entry column configurations study 
configurations history depth greater assume hypothetical perfect mechanism selecting correct value predict included explore limits history load value prediction 

dynamic load classification 
load value prediction useful done accurately incorrect predictions lead increased structural hazards table 
hit rates 
percentages shown fractions unpredictable predictable loads identified 
benchmark powerpc alpha axp simple limit simple limit pred pred pred pred cc cjpeg compress doduc eqntott gawk grep hydro mpeg perl quick sc swm tomcatv xlisp gm longer load latency misprediction penalty discussed section 
experimental framework classify static loads categories dynamic behavior 
loads values unpredictable predictable predictable 
classifying separately able take full advantage case 
avoid cost misprediction identifying unpredictable loads avoid cost memory access identify verify loads highly predictable 
order determine predictability static load instruction associated set history bits 
previous predictions load instruction correct able classify loads general groups unpredictable predictable constant loads 
load classification table consists direct mapped table bit saturating counters indexed low order bits instruction address 
table shows number entries column size saturating counter column configurations study 
bit saturating counter assigns available states don predict don predict predict constant bit counter assigns states don predict constant counter incremented predicted value correct decremented 
table show percentage unpredictable loads able classify unpredictable columns percentage predictable loads able correctly classify predictable columns simple limit configurations 

constant verification unit mechanism accurately identify loads retrieve predictable values verify correctness predictions 
predictable loads simply retrieve value conventional memory hierarchy compare predicted value actual value see 
highly predictable constant loads constant verification unit cvu allows avoid accessing conventional memory system completely forcing entries correspond constant loads remain coherent main memory 
table 
successful constant identification rates 
percentages shown ratio constant loads dynamic loads 
benchmark powerpc alpha axp simple limit simple limit cc cjpeg compress doduc eqntott gawk grep hydro mpeg perl quick sc swm tomcatv xlisp gm entries classified constants data address index placed separate fully associative table inside cvu 
table kept coherent main memory invalidating entries data address matches subsequent store instruction 
constant load executes data address concatenated index lower bits instruction address cvu content addressable memory cam searched matching entry 
matching entry exists guaranteed value entry coherent main memory updates stores retrieval invalidated cvu entry 
exist constant load demoted constant just predictable status predicted value verified retrieving actual value conventional memory hierarchy 
table shows percentage dynamic loads successfully identified treated constants 
thought percentage decrease required bandwidth data cache 
second order effect observe decrease cache bandwidth machine model see section 
disappointed unable obtain significant reduction pleased note load value prediction speculative techniques prefetching branch prediction reduces increases memory bandwidth requirements 

load value prediction unit interactions cvu described loads stores 
load instruction fetched low order bits load instruction address index parallel 
analogous branch history table determines prediction analogous branch target buffer forwards value load dependent instructions 
address generated stage ex sample pipeline cache access cvu access progress parallel 
actual value returns data cache compared predicted data dependent speculative instructions consequently written back reissued 
search cvu performed time prevent initiating memory access time cvu able prevent memory access bank conflict cache occurs 
case cvu match cancel subsequent retry cache execution store fully associative lookup performed store address matching entries removed cvu 

lvp unit implementation notes exhaustive investigation lvp unit design parameters implementation details scope 
demonstrate validity concept analyzed sensitivity key parameters selected design points microarchitectural studies section 
realize designs selected means optimal minimal efficient improved significantly 
example reserve full bits value entry lvp table instructions generate fewer bits space table certainly shared entries clever engineering 
intent details design intent explore larger issue impact load value prediction microarchitecture instruction level parallelism leave details 
note lvp unit characteristics attractive cpu designer 
lookup index available early instruction fetch stage access tables stages 
necessary chip space relatively large tables built impacting cycle fetch disp ex ex comp sample load execution 
block diagram lvp mechanism 
load pc index find value predict determine prediction 
constant loads find match cvu needn access cache stores cancel matching cvu entries 
load completes predicted actual values compared updated dependent instructions reissued necessary 
time 
second design adds little complexity critical delay paths microarchitecture 
table lookups verifications done parallel existing activities serialized separate pipeline stage value comparison 
reiterate lvp unit speculative nature reduces memory bandwidth requirements 

microarchitectural models order validate quantify performance impact load value prediction constant identification implemented timing models significantly different modern microprocessor implementations powerpc dns ltt alpha axp bk aggressively order clean order 
chose different architectures order alleviate concern value locality behavior observed artifact certain idioms instruction set compiler run time environment operating system running universal attribute general purpose programs 
chose powerpc axp represent extremes microarchitectural spectrum complex cpus aggressively dynamically reorder instructions achieve high ipc metric clean straightforward deeply pipelined speed demon cpus instruction class predict 
cvu load pc address address index verify 
predicted value cache actual value address table 
instruction latencies sample store execution powerpc alpha axp issue result issue result simple integer complex integer load store simple fp complex fp branch pred comp unit rs fetch dispatch unit rs gpr rename rs rs fpu fpr rename lvp unit rs bru cr rename rs lsu lsu 
powerpc block diagram 
buffer sizes shown 
rely primarily clock rate high performance 
issue result latencies common instruction types machines summarized table 
powerpc machine model microarchitecture powerpc summarized 
model published reports powerpc dns ltt accurately models aspects microarchitecture including branch prediction fetching dispatching register renaming order issue execution result forwarding non blocking cache hierarchy store load alias detection instruction order completion 
alleviate bottlenecks design model aggressive generation version term 
differs doubling number reservation stations fpr gpr rename buffers completion buffer entries adding additional load store unit lsu additional cache port base data cache relaxing dispatching requirements allow loads stores dispatch issue cycle 
addition add lvp unit predicts load values keeping value history indexed load instruction addresses 
lvp unit predicts values dispatch forwards speculatively subsequent operations rename busses 
dependent instructions able issue execute immediately prevented completing architecturally forced retain possession reservation stations 
speculatively forwarded values tagged uncommitted loads depend tags propagated results subsequent dependent instructions 
uncommitted loads execute load store pipe predicted values verified cvu address match comparison actual values retrieved loads 
load verified dependent operations ready order completion release reservation stations case correct prediction restart execution correct load values prediction incorrect 
load store unit supports multiple non blocking loads cache misses verifying predicted value take dozens cycles allowing processor speculate levels dependency chain load executing instructions resolving branches blocked true dependencies 
worst case penalty incorrect load value prediction scheme compared predicting value question additional cycle latency structural hazards reissue buffer multiplier int pipe fetch decode slot dispatch int pipe compare writeback fp multiply pipe 
alpha axp block diagram 
fp add pipe writeback divider occurred 
penalty occurs dependent instruction executed speculatively waiting reservation station load value committed corrected 
load value comparison takes extra cycle standard cycle load latency dependent instruction reissue execute correct load value cycle prediction 
addition earlier incorrect speculative issue may cause structural hazard prevents useful instructions dispatching executing 
cases dependent instruction executed due structural unresolved data dependencies penalty dependent instruction issue soon loaded value available parallel value comparison load store pipeline 
case due accurately prevents incorrect predictions misprediction penalty significantly affect performance 
structural hazard penalty case correct prediction 
speculative values verified cycle actual values available dependent instructions may occupying reservation stations cycle longer prediction 
alpha axp machine model order processor model summarized differs actual axp bk ways 
fully model maf address file enables nonblocking cache misses 
assume pipelined memory subsystem allows number nonblocking misses aggressive actual tend results lvp 
second order allow speculation occur lvp configurations compare actual data returned data cache predicted data 
distance data cache writeback critical path hardware comparison requires extra stage writeback 
third modification addition reissue buffer allows buffer instruction dispatch groups contain predicted loads 
feature able instructions misprediction occurs single cycle penalty 
modifications apply lvp configurations baseline model 
order keep axp model simple possible dispatched loads mispredicted possible instructions flight squashed reissued reissue buffer regardless dependent predicted data 
unable stall past dispatch stage unable predict loads data cache 
occurs able return non speculative state serviced 
penalty doing prediction 
inability lvp unit speculate cache cases means lvp unit primary benefit provision zero cycle load 
typically envision cvu mechanism reducing bandwidth cache hierarchy evidence discussed section section 
equipped true dual ported cache load store units largely unaffected reduction bandwidth requirement cache 
addition reducing bandwidth primary benefit cvu model enables predictions identified constants proceed regardless data cache 
lvp predictions proceed spite cache verified cvu 

experimental framework experimental framework consists main phases trace generation lvp unit simulation microarchitectural simulation 
phases performed operating environments ibm aix dec osf 
powerpc traces collected generated trip instruction tracing tool 
trip early version software tool developed ibm rs captures instruction value address cpu user state 
supervisor state initiating system call corresponding return user state lost 
alpha axp traces generated atom tool se captures user state instruction value address 
instruction address value traces fed model lvp unit described earlier annotates load trace value prediction states prediction incorrect prediction correct prediction constant load 
annotated trace fed cycle accurate microarchitectural simulator correctly accounts behavior type load 
microarchitectural models implemented framework ds enables significant productivity gains allowing reuse retarget existing models 
lvp unit model separated microarchitectural models reasons shift complexity microarchitectural models better distribute simulations multiple cpus conserve trace bandwidth passing bits state load microarchitectural simulator full bit values loaded 

experimental results collected types results microarchitectural models cycle accurate performance results various combinations lvp unit configurations microarchitectural models distribution load latencies average data dependency resolution latencies reductions bank conflicts 

base machine model speedups realistic lvp show speedup numbers relative baseline speedup speedup cc gm simple gm limit gm perfect cc cjpeg compress doduc eqntott gawk gm simple gm constant gm limit gm perfect alpha axp powerpc cc cjpeg compress doduc eqntott gawk grep hydro mpeg perl quick 
base machine model speedups 
grep hydro mpeg perl quick sc swm tomcatv xlisp sc swm tomcatv xlisp lvp unit configuration consider realistic processor generations idealized lvp unit configurations 
realistic configurations simple constant described table 
explore limits load value prediction include results limit perfect lvp unit configurations described table 
similar simple configuration larger realistic assumes hypothetical perfect mechanism selecting sixteen values associated load instruction address correct predict 
configuration perfect able correctly predict load values classify constants 
configurations configurations interesting give sense additional performance expect aggressive accurate lvp implementations 
shows lvp configurations alpha axp 
omit constant configuration simulations differ significantly simple configuration limited access native alpha cpu cycles collecting traces 
general derives roughly twice performance benefit lvp 
attribute factors small level data cache direct mapped vs way associative cache benefits cvu inorder issuing policy sensitive load latency forced depend solely compiler try overlap useful computation 
hand able find useful computation dynamically due order core 
benchmarks grep gawk stand dramatic performance increases achieve models 
gain results fact benchmarks data dependence bound important relatively short dependency chains load latencies significant share critical path 
amdahl law collapsing load latencies results significant speedups 
conversely benchmarks expect perform better high load value locality hydro mpeg models fail load latencies lesser share critical dependency paths 
bandwidth reducing effects cvu manifest lower level data cache rates benchmarks running 
example rate compress drops instruction reduction 
likewise eqntott experience reductions rates translate significant speedups shown 
cjpeg mpeg gain lvp eke measurable gains due reduction primary data cache rate brought cvu 

enhanced machine lvp model speedups explore interaction load value prediction powerpc microarchitecture collected results enhanced machine model described earlier conjunction lvp configurations 
results simulations summarized table third column shows average speedup base lvp columns show average additional speedups simple constant limit perfect lvp configurations respectively 
general see increased machine parallelism closely matches parallelism exposed load value prediction relative gains realistic lvp configurations nearly higher baseline 
dramatic examples trend grep gawk show little speedup increased machine parallelism lvp nearly double relative speedups lvp simple lvp configuration grep increases gawk increases 
table 
powerpc speedups 
column shows speedup relative lvp columns show additional lvp speedups relative baseline lvp 
bench base cyc simple constant limit perfect cc cc cjpeg compress doduc eqntott gawk grep hydro mpeg perl quick sc swm tomcatv xlisp gm 
distribution load verification latencies show distribution load verification latencies loads verified ppc load verification latency ppc simple constant limit perfect load verification latency 
load verification latency distribution 
numbers shown percentage correctly predicted loads verified number cycles dispatched 
lvp configurations simple constant limit perfect machine models 
show percentage correctly predicted loads verified number cycles dispatched 
numbers shown sum benchmarks 
results provide intuitive feel number cycles load latency eliminated load value prediction 
clearly larger percentage loads longer latency lvp prove beneficial 
interestingly distributions lvp configurations look virtually identical indicates aggressive lvp implementations limit perfect uniformly effective regardless load latency 
expect wider microarchitecture reduce average load latency structural dependencies eliminated 
results counter expectation clear shift right distribution shown 
shift caused time dilation brought improved performance turn caused microarchitectural improvements relative improvement lvp performance noted section 

data dependency resolution latencies intent load value prediction collapse true dependencies reducing memory latency zero cycles 
confirm happening quantify dependencies collapsed measured average amount time instruction spends reservation station waiting true dependencies resolved 
results summarized categorizes waiting time reductions functional unit type 
numbers shown average benchmarks normalized waiting times lvp 
see instructions branch bru multi cycle integer units experience reductions true dependency resolution time 
sense branches move special purpose register instructions waiting operand types link register count register condition code registers lvp mechanism predict 
conversely dramatic reductions seen floating point fpu single cycle fixed point load store lsu instructions correspond fact operands predicted 
furthermore relatively higher value locality address loads shown corresponds dramatic reductions shown load store instructions 
just simple constant lvp configurations average dependency resolution latency load store instructions reduced 
relative resolution latency ppc bru fpu lsu fu type ppc simple constant limit perfect bru fpu lsu fu type 
data dependency resolution latencies 
cycles spent waiting operands normalized baseline models 

bank conflicts purpose cvu reduce memory bandwidth eliminating need constant loads access conventional memory hierarchy 
models benefit manifests reduction number bank conflicts banks level data cache 
cycle load store attempt access data cache port 
accesses bank conflict occurs store wait try cycle 
model problem aggravated loads store attempt access available banks cycle 
show fraction cycles bank conflict occurs benchmarks running models 
bank conflicts occur simulation cycles benchmark set cycles 
simple lvp unit configuration able reduce numbers respectively constant configuration manages reduce pleased note reductions relatively higher shown table means cvu tends target loads average cause bank conflicts 
interestingly handful benchmarks gawk grep hydro experience slight increase relative number cycles bank conflicts shown 
brought time dilation caused increased performance lvp configurations increase absolute number bank conflicts 
benchmark tomcatv experience slight increase absolute number bank conflicts model 
view second order effect perturbations instruction level parallelism caused lvp relieved note overshadowed factors result slight net performance gain tomcatv see table 

major contributions 
introduce concept value locality computer system storage locations 
second demonstrate load instructions examined instruction address basis exhibit significant amounts value locality 
third describe load value prediction microarchitectural technique capturing exploiting load value locality reduce effective memory latency bandwidth requirements 
encouraged results 
bank conflict bank conflict cc cc cjpeg compress doduc eqntott gawk powerpc lvp simple constant grep powerpc hydro mpeg perl quick sc swm tomcatv xlisp cc cc cjpeg compress doduc eqntott gawk grep hydro mpeg perl quick sc swm tomcatv xlisp 
percentage cycles bank conflicts 
shown measurable average average cases dramatic performance gains achievable simple microarchitectural extensions current microprocessor implementations represent extremes superscalar design philosophy 
envision proceeding different fronts 
believe relatively simple techniques employed capturing value locality refined extended effectively predict larger share load values 
refinements extensions include allowing multiple values static load prediction table including branch history bits readily available processor state lookup index moving history prediction computed predictions techniques value stride detection 
second load classification mechanism refined correctly classify loads extended control pollution value table removing loads latency critical table 
third microarchitectural design space explored extensively load value prediction dramatically alter available program parallelism ways may match current levels machine parallelism 
fourth feedback directed compiler support rescheduling loads different memory latencies value locality may prove beneficial 
aggressive approaches value prediction investigated 
include speculating multiple paths value space speculating values generated instructions loads 
acknowledgments supported part onr 

gratefully acknowledge generosity intel donating numerous fast pentium pro workstations 
systems reduced simulation turnaround time order magnitude 
wish ibm letting trip instruction tracing tool 
todd austin sohi 
zero cycle loads microarchitecture support reducing load latency 
proceedings th annual acm ieee international symposium microarchitecture pages december 
walid abu david kuck duncan lawrie 
performance enhancement paging systems program analysis transformations 
ieee transactions computers may 
asu aho sethi ullman 
compilers principles techniques tools 
addison wesley reading ma 
abraham rau gupta 
predictability load store instruction latencies 
proceedings th annual acm ieee international symposium microarchitecture december 
bk peter bannon jim keller 
internal architecture alpha microprocessor 
compcon 
cb tien fu chen jean baer 
performance study software hardware data prefetching schemes 
st annual international symposium computer architecture pages 
david callahan ken kennedy allan porterfield 
software prefetching 
fourth international conference architectural support programming languages operating systems pages santa clara april 
chen mahlke chang 
hwu 
data access microarchitecture superscalar processors compiler assisted data prefetching 
proceedings th international symposium microarchitecture 
cmt steve carr kathryn mckinley chau wen tseng 
compiler optimizations improving data locality 
sixth international conference architectural support programming languages operating systems pages san jose october 
dns christopher nelson john shen 
performance evaluation powerpc microarchitecture 
proceedings nd international symposium computer architecture santa margherita ligure italy june 
ds john paul shen 
visualization microarchitecture workbench 
ieee computer 

comparing risc microprocessors 
proceedings microprocessor forum october 
har samuel harbison 
computer architecture dynamic optimization high level language programs 
phd thesis carnegie mellon university september 
har samuel harbison 
architectural alternative optimizing compilers 
proceedings international conference architectural support programming languages operating systems asplos pages march 
jou jouppi 
architectural organizational tradeoffs design cpu 
technical report tn dec wrl december 
jou norman jouppi 
improving direct mapped cache performance addition small fully associative cache prefetch buffers 
th annual international symposium computer architecture pages seattle may 
david keppel susan eggers robert henry 
evaluating runtime compiled value specific optimizations 
technical report university washington 
kro david 
lockup free instruction fetch prefetch cache organization 
th annual international symposium computer architecture pages 
ieee computer society press 
ltt david thomas thomas paul tu 
powerpc microprocessor high performance superscalar risc processor 
compcon 
todd mowry monica lam anoop gupta 
design evaluation compiler algorithm prefetching 
fifth international conference architectural support programming languages operating systems pages 
rd roland 
predicting precluding problems memory latency 
ieee micro 
ric stephen richardson 
caching function results faster arithmetic avoiding unnecessary computation 
technical report sun microsystems laboratories 
se amitabh srivastava alan eustace 
atom system building customized program analysis tools 
proceedings acm sigplan conference programming language design implementation pages 
sig sigplan 
proceedings symposium partial evaluation semantics program manipulation volume cambridge ma september 
sigplan notices 
smi smith 
study branch prediction techniques 
proceedings th annual symposium computer architecture pages june 
smi alan jay smith 
cache memories 
computing surveys 
sw amitabh srivastava david wall 
link time optimization address calculation bit architecture 
sigplan notices june 
proceedings acm sigplan conference programming language design implementation 
gary tyson matthew john matthews andrew 
modified approach data cache management 
proceedings th annual acm ieee international symposium microarchitecture pages december 
yp yeh patt 
level adaptive training branch prediction 
proceedings th annual international symposium microarchitecture pages november 
