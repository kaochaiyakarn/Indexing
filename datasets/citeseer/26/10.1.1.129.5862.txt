lifetime maintenance case base indexes continual case reasoning zhong zhang qiang yang department computer science rensselaer polytechnic institute troy ny usa cs rpi 
edu school computing science simon fraser university burnaby canada cs sfu 
ca cs 
sfu 
tel fax 
key areas case reasoning main tain domain knowledge face changing environment 
case retrieval key process cbr feature value pairs attached cases rank cases user 
different feature value pairs may different importance measures process represented feature weights attached cases 
maintain weights date current key factors deter mining success cbr 
focus lifetime maintenance feature weights case base 
task de sign cbr maintenance system learns user preference selection cases tracks user evolving preferences cases 
approach maintain feature weighting dy namic context integration learning system inspired back propagation neural network 
explain new system architecture reasoning algorithms contrasting approach previous ones 
effectiveness system demonstrated experiments real world application domain 
case reasoning cbr enjoyed tremendous success technique solving problems related knowledge reuse maintenance issue case bases remained open problem 
fact defining case knowledge just step long life cycle knowledge base application 
today industrial environment new cases entered fast rate 
relative importance cases changing partly due uneven changing distribution inherent problem space partly due changing table 
small case base loan cases unit case case case case loan status bad bad problem desc 
solution monthly bank income tus decision units units extend loan units units 
units units 
units units interest users 
evolve case base continually automated manner urgent task knowledge base industry 
research directly motivated cable tv ing domain 
domain typical equipment troubleshooting procedures captured cases stored case base 
authoring initial case base new equipment services arrive rapid rate case base manager cable tv constantly adjust case base 
adjustment processes new cases arrive order account new equipment services time weighting values attached case features adjusted conform changing trend customer service 
consider elements case base 
retrieve knowledge cases depends case features selected weighted 
feature indexing involves determining features case facilitate re trieval 
features associated case combinations important descriptors distinguish case 
practice ing column names designate features see table features values user form questions answers 
receiving input problem weights attached features values compute distance measure cases 
popular methods nearest neighbor algorithm 
method involves computation similarity input case previous cases weighted sum features similarity 
case query formula compute distance wa 
distance ff wi weight assigned feature fi difference similarity function different values feature fc ffl values feature fi case query respectively 
similarity input problem cases assessed expression basis 
previous nutshell problem attack maintain features weights case base multi user changing complex environment 
assume desired case base maintenance system set features feature set potential values 
subset features values may relevant particular problem case hand time prior knowledge ones useful reasoner currently 
set weights attached feature value case combinations users system provide feedback outcome solutions provided feedback process 
tasks acquire feature weights user system certain period time adapt feature weights user preferences time allow different users different weights continuously track user changing preferences cases case base update weights correspondingly reflect change allow influence feature value selection case dependent values features case base words feature weights context dependent 
past focused various aspects problem 
aha aha introduces series case learning cbl algorithms 
aimed situations feature weights vary greatly predictor features instance irrelevant features exist 
feature weights ad prediction attempt training process comparing current training case similar stored cases 
cbl initially signs equal weight feature 
increases weights features values similar correct predictions 
decreases feature weights 
adjustment delta determined difference tween feature values cases similarity assessed 
pointed cbl lacks ability address context sensitive case information 
limited application goal feature prediction sets features values 
feature weight update procedures point system similar neural network type computation author pursue direction 
closely related approach introspective learning monitoring run time process reasoner fl ros abs 
abs demonstrates system combines introspective learning cbr 
pose problem experiences constructing cbr system air traffic control 
problem difficult determine important features adjust relative importance 
situation complicated fact features highly context sensitive 
method uses called pulling pushing operations adjust feature weights 
target cases judged correct solution learning method push away pull closer authors reported result empirical tests 
claimed failure oriented success oriented learning contributes result 
state learning method pivotal cases redundancy case base essential learning process 
pivotal case provides coverage provided cases case base sk 
papers inspired look deeper issue case base main 
systems allow system acquire new feature weights feedback cbr result 
wish move direction step fur ther providing general architecture founded algorithms address lifetime maintenance problems 
maintenance system layer architecture structure case base conceptualized layer structure feature values form layer cases 
feature value layer connected case layer set weights maintained 
solution layer fig 

new structure case base second set weights problem layer th filt ye extend original layer structure case base layer structure layer architecture special case 
case layer extract solutions case put third layer 
possible different problems share solution prob lem access alternative solutions 
important motivation separation structure case reduce redundancy case base 
problems solutions case base size reduced size approach eases scale problem helps case base maintenance problem easier need arises problem solution need revised 
order change possible introduce second set weights attached connections cases possible 
second set weights represents important solution particular case solution potential candidate case 
addi tion distinguishes solution cases solution belongs cases time 
initially weighted connection feature value pair problem problem layer problem solution third layer 
addition scaling redundancy added advantage struc ture represent context sensitive case base layer structure 
method second layer consists problem descriptions represent problem context layer representing different contexts problems occur 
user enter problem descriptions form feature value pairs select desired context solve problem 
second set weights turn help rank right case cases dealing problems 
set features simultaneously influence contexts problems time 
architecture learning algorithms follow seen balance neural bayesian models rn nea 
cbr consider user behavior encoded weights assigned feature value pairs cases case base find behavior variable user user time time user 
difficult find prior probabilistic model describe 
difficult predict user behavior changes time 
addition cases form problem descriptions contexts solutions represent experiential knowledge encoded probability variables 
weight maintenance introduce notations different entities 
sets weights similar weights layer back propagation neural network 
suppose features 
feature fi mi values case base contains problems solutions 
structure shown total mi feature value pairs nodes feature value pair layer 
label feature value pairs fvi problem layer pj represent problem solution layer sk represent solution set weights attached connection problem pj feature value pair fvi association 
second set weights wkj attached connection solution problem pj sk potential solution pj 
computation problem score input feature value pairs corresponding layer nodes considered turned 
problem score computed feature value pairs follows 
problem pj score computed formula vs sp score problem pj xi connection problem pj feature value pair fvi fvi selected 
xi 
formula property higher ixi higher spj property demonstrated nn algorithm case retrieval process discussed section 
problem scores computed problems associated scores user selection confirmation 
con problem user may select corresponding solutions associated current selected confirmed problem 
com putation solution score similar computation output back propagation neural network 
soon score solution computed user fo judgment 
user thinks solution right appropriate score confirm claiming success 
failure registered system 
situations user option specify desired score solution information captured learning algorithm computation errors 
considered situation user specify desired score just confirmation disapproval solution 
case default adjustment value added deducted computed solution score automatically get desired score 
instance solution gets actual computed score desired score solution current default adjustment 
user specify desired score values long specified value 
computation learning delta value done solution layer 
delta values update weights layer 
computation solution scores compute learning delta values solutions associated current selected confirmed problem 
formula employed 
dsk ss learning delta value solution sk dsk desired score sk 
learning delta values propagated back problem layer 
computation learning delta value layer similar formula 
dez learning delta value problem pj 
con solution sk problem pj include deltas wkj 
adjust weights attached solutions associated current selected confirmed problem 
weights attached connections problems solutions adjusted learning delta values computed formula problem scores computed formula 
formula adjustment spj new weight computed old weight attached connection solution problem pj learning rate 
weights attached problem layer computed similar manner 
system gives user opportunity judge problem desired score computed problem scores 
situation system uses formula compute new weights 
ne void sp symbol represents 
xi connection feature value pair fvi problem pj fvi selected adjustments local selected problem 
simple example consider small case base shown table adapted wat 
row table represents loan information person 
select columns table features form indices problem 
relevant feature value pairs weights initialized 
assume target described feature value pairs monthly income units job status monthly 
formula score case score case score case score case 
cases ranked suppose user satisfied score case 
user sets score 
receiving response system compute necessary adjustment feature value pairs associated case 
example assume adjustments 
weights adjusted system compute problem scores see case desired score 
process needs repeat times cases reflect user preferences case ranking 
learning process contrasting case base maintenance algorithm back propagation neural network see traditional neural network processes sample datum process weights connecting adjacent layers adjusted 
process repeat times order get final satisfactory goal 
case base maintenance framework assume explicit training set 
user just tell system retrieved problem solution desired undesired 
system capture responses feed back neural network learning compo nent 
long run expected converge user preferences 
interactions feature value pairs impossible pre model user preference pass 
adjustment user preferences requires iterative process 
empirical tests section wish demonstrate proposed system conforms expectations 
particular wish confirm hypotheses 
feature weight maintenance system learn user preferences sufficient interaction user system 
feature weight maintenance system affected interactions different input vectors 
particular fewer interactions shorter take system converge user behavior 
real world applications frequently occurring problems con system converge quickly desired feature weight sets provided domain experts 
case base local cable tv created cbr system integrates feature weight maintenance functions problem resolution components 
case base representatives solve customers problems help desk 
case base collected cases features questions 
questions total question answer pairs 
label question answer pair qa 
weights assigned initially individual question answer pairs domain experts 
table shows case case base 
domain customer call technical representatives help desk 
describe current problem tech nical representative input description problem resolution module 
select questions ask customer 
answers questions problem resolution module retrieve set relevant cases scores 
table 
example case representation cable tv domain question subscriber pay status 
question type problem experienced 
picture problem description problem solution reception low band 
check splitter cable fine tune tv channels 

problem continues tv seconds 

problem continues generate trouble ticket 
experiment apply dynamic learning method case base 
order experiment set copies case base different sets weights 
copy case base uses weights specified domain experts 
second copy weights initialized 
think weights copy represent user preference learn weights second copy dynamic learning method 
select cases problems case base 
cases frequently 
accordingly select valid sets question answer pairs case base feature value pairs mutually exclusive domain knowledge 
copy case base case retrieval results produced valid sets cover cases 
occupies highest positions case retrieval results 
think valid sets represent user preference 
order test effectiveness learning ability feature weight maintenance system execute copies case base reasoning system side side separate problem resolution modules 
copy input valid sets question answer pairs 
module produces set cases scores 
second copy input valid set 
set cases scores produced 
comparing sets cases scores find differences provide feedback weight learning modules 
comparison specification learning process applied valid sets turn case retrieval results produced second copy approximate ones produced copy 
experiment learning process took rounds composed query query 
scores cases produced second copy converge desired scores produced copy 
define error case produced valid set question answer pairs learning process absolute difference computed score desired score 
test desired score case produced copy case base computed score produced second copy 
query take look case having highest score 
get total cases 
check cases errors comparing 
error convergence highest queries nn fig 

error convergence chart highest cases cable tv domain computed scores produced second copy desired scores produced copy training process 
error convergence chart cases graphed 
axis represents time line training process queries entered 
axis represents errors case score error defined absolute difference obtained desired case scores 
experiment find errors converge means case scores converge desired scores 
attribute result observation state experiment setup see section 
small number training rounds provide evidence claim 
mso indicate method brought cases desired scores guarantee training rounds learning process cases scores converge desired ones 
user change input distribution 
different user come 
destroy previous convergence state trigger learning process 
mms achieve lifetime maintenance feature weights case process cbr 
need applications cbr sys tems motivated explore dynamic nature 
research motivated desire cbr system responsive system 
behavior needs simulate user behavior incorporating preferences 
user behavior changing requiring cbr system keep pace changes 
integration back propagation neural network maintenance possible exhibits important scaling characteristics 
separation problems solutions problem solution need represented making maintenance issues easier deal 
addition middle layer effectively represent contextual information solving long standing problem cbr 
note system limitations 
exper tests nearly cases converge desired scores encountered divergence times due interactions different cases different feature sets 
effect interaction reduced introducing stronger bias factors system 
addition sumptions learning model user system person 
different user comes system satisfy previous optimal case retrieval result 
hope address problems introducing effective learning feedback control algorithms architectures 
acknowledgment authors supported natural sciences engineering research council canada nserc epic nserc industrial chair fund bc advanced systems institute canadian cable labs fund 
abs aha fl nea rn ros cunningham smyth 
introspective learning improve retrieval cbr case study air traffic control 
proceedings second international conference case reasoning iccbr pages providence ri usa 
aha 
case learning algorithms 
proceedings darpa case reasoning workshop pages washington 
morgan kaufmann 
leake wilson 
learning improve case adaptation introspective reasoning cbr 
proceedings international conference case reasoning pages portugal 
springer verlag 
fox leake 
learning refine indexing introspective reason ing 
proceedings th international joint conference artificial intelligence montreal canada august 
neal 
bayesian learning neural networks 
springer verlag 
russell norvig 
artificial intelligence modern approach 
prentice hall 
edwards sleeman 
changing viewpoint re indexing introspective question 
proceedings th annual con ference cognitive science society pages 
lawrence erlbaum associates 
sk smyth keane 
remembering forget 
proceedings th international joint con erence artificial intelligence pages montreal canada august 
wa wettschereck aha 
weighting features 
proceedings international conference case reasoning iccbr pages lisbon portugal 
springer verlag 
wat ian watson 
applying case reasoning techniques enterprise sys tems 
morgan kaufmann publishers 
