application controlled physical memory external page cache management generation computer systems gigabytes physical memory processors mips range higher 
trend suggests memory management programs concern memory bound applications scienti simulations database management systems require sophisticated memory management support especially multiprogramming environment 
furthermore new architectures introducing new complexities processor memory requiring techniques page coloring variable page sizes physical placement control 
describe design implementation evaluation virtual memory system provides application control physical memory external page cache management 
approach sophisticated application able monitor control amount memory available execution exact contents memory scheduling nature page page abstraction page frame cache provided kernel 
able handle multiple page sizes control speci physical pages uses 
claim approach signi cantly improve performance memory bound applications reducing kernel complexity complicate applications reduce performance 
david cheriton computer science department stanford university ca generation computer systems measure physical memory gigabytes just current systems rated megabytes previous generation systems rated kilobytes 
trend prompted demise operating system virtual memory systems secondary storage 
secondary storage networking growth places ective external data capacities terabyte range maintaining rough ratio main secondary storage held decades 
real ect arrival gigabyte memories clearly delineate applications modest memory requirements requirements unbounded large scale simulation requirements grow proportional external data capacities data base systems 
increasing speed processors lack comparable improvement performance memory system performance key limiting factor demanding applications 
page fault secondary storage costing close instruction times instruction budget exists take intelligent approach page management virtual memory systems 
major problems current virtual memory systems 
firstly application know amount memory available informed signi cant changes amount available memory control speci physical pages allocated 
secondly program control contents physical memory allocated 
program easily control read ahead writeback discarding pages physical memory 
addressing problems signi cant performance bene ts applications argued 
knowledge amount available physical memory application may space time tradeo di erent algorithms modes execution achieve desired computation 
example mp large scale parallel particle simulation monte carlo method generates nal result averaging number simulation runs 
simulation run shorter amount time uses particles 
application automatically adjust uses run amount memory requires availability memory 
similarly parallel database query processing program adapt degree parallelism uses memory usage memory availability 
run time memory management library garbage collection adapt frequency collections available physical memory information available 
control speci physical page frames uses virtual memory mapping application optimize cient access system memory organization application access patterns 
example dash machine physical memory distributed machine provides consistent shared memory abstraction cache consistency protocol 
type machine large scale application allocate page frames speci portions program page frame physical location machine expected access portion memory 
similarly application allocate physical pages virtual pages minimize mapping collisions physically addressed caches tlbs implementing page coloring application speci basis account expected data access patterns run time 
control portion virtual address space mapped physical memory application operate far ciently virtual address space exceeds size physical memory 
example database management system ensure critical pages containing central indices directories physical memory 
query optimizer transaction scheduler bene knowing pages memory cost page fault signi cantly increase cost query 
latency page fault dramatically extends lock hold time times locks held fault 
multiprocessor machines unfortunate page fault cost just elapsed time fault cost multiplied number processes blocked hit page lock held blocked process 
control read ahead writeback page discarding application minimize bandwidth requirements ect latencies execution 
scienti computations large data sets predict data access patterns advance allows disk access latency overlapped current computation cient application directed readahead writeback supported operating system requisite bandwidth available 
example large scale particle simulation cited takes approximately seconds scan memory data megabytes simulated time interval machine mips processors 
ample time overlap prefetching writeback data entirely memory 
extensions virtual memory systems page pinning external pagers application program advisory system calls unix attempt address issues incompletely signi cant increase kernel complexity 
exploring signi cantly di erent modularization silicon graphics unix trademark memory system implementation provides application control reduces kernel complexity 
describe design implementation evaluation virtual memory system provides application control physical memory call external page cache management 
external page cache management virtual memory system ectively provides application physical page caches application manage external kernel 
particular know exact size cache page frames 
control exactly page selected replacement page fault control completely data transferred page including selecting read ahead writeback 
information physical addresses implement schemes page coloring physical placement control 
essence kernel virtual memory system provides page frame cache application manage conventional transparent virtual address space main memory versus secondary storage division transparent performance 
default process level manager provides page cache management applications want manage virtual memory section describes design implemented kernel 
section evaluates external page cache management drawing measurements implementation simulated database transaction processing system 
section describes related 
close discussion directions 
external page cache management inv external page cache management requires new kernel operations process level modules allow process level management page frames 
rst describe kernel support followed discussion application speci managers 
discuss default manager 
describe module responsible global memory allocation 
section focuses design implementation external page cache management new generation distributed system basic approach applicable systems unix 
kernel page cache management support kernel page cache management support provided operations segments 
segment address range zero pages similar conventional virtual memory notion segment 
pages added removed mapped unmapped read written segment operations 
parameter segment creation call optionally speci es page size support machines alpha microprocessor support multiple page sizes 
segments cached mapped les portions program address spaces code segment data segment program address spaces illustrated 
referring program virtual address space segment composed binding regions segments 
gure illustrates virtual address segment code data stack segments bound code data stack regions address space respectively 
bound region virtual address space segment page frames code region data region stack region va segment bound region code segment uio bound region data uio segment bound region stack uio segment kernel implementation virtual address space associates range addresses page aligned multiple pages segment equal sized range blocks segment memory address covered bound region rst segment ectively corresponding address associated bound segment 
binding facilities support copy write binding pages ectively bound source segment modi ed 
segment structure similar virtual memory designs novelty lies associated page cache management support 
external page cache management supported signi cant additions conventional virtual memory management operations regards segment roughly analogous unix open les mach memory objects 
firstly explicit manager module associated segment kernel operation seg manager secondly kernel operation pages moves pages page frames source segment starting destination segment starting setting page ags speci ed clearing page ags speci ed migrated page frame 
similar kernel operation seg page pages modi es page ags migrating page frames 
operations allow manager modify page state ags asthe dirty ag addition protection ags accessible conventional unix mprotect 
operation seg page pages returns returns page ags physical address speci ed set page frames 
operations conjunction modest extensions conventional virtual memory facilities ability catch page faults user level implement external page cache management 
segment manager module responsible managing pages associated segment 
particular missing protected page frame segment event communicated manager 
manager handles fault sequence illustrated 
referring gure file server segment manager kernel application kernel interface 
page fault 
request server 
reply server 
migrate page 
resume page fault handling external page cache management application page frame address space traps kernel forwards page fault indication manager step 
manager allocates page frame segment free page segment requests data page frame le server holding data step waits reply 
server replies data step data copied previously allocated page frame kernel invoked step move page frame faulting page address application segment 
manager responds application allowing resume step 
gure assumes page data retrieved le server 
manager page data available locally steps replaced procedure manager data available page frame allocated application 
copy write fault kernel performs copy manager allocated page 
filling page frame tends dominate costs page fault handling usually requires accessing backing store copying page 
note kernel manages hardware supported vm translation tables page tables tlbs map pages protections speci ed segment bound region data structures 
page fault trap occurs memory satis ed information kernel data structures 
particular simple tlb misses handled 
operation operates page frames bound regions operating associated segments 
example migrating page frame address range corresponding data region virtual address segment ectively migrates page frame segment labeled data segment 
migrating page frame segment treated write operation purposes segment protection copy write behavior 
operation reclaim pages frames segments part page reclamation strategy 
cached les implemented segments accessed kernel provided le block read write interface speci cally uniform input output object uio protocol 
le read segment page associated page frame causes page fault event manager segment regular page fault 
file write operations requiring page allocation handled similarly 
file access performance comparable system kernel resident le system le cached access single kernel operation le cached access time dominated secondary storage access costs 
manager module executed process separate application faulting process 
rst case kernel suspends faulting process communicates manager process interprocess communication facility 
second case kernel transfers control procedure executed page faulting process similar conventional signal interrupt 
method generally cient rst method context switch required 
hardware mips machines resumption application page faulting handling performed directly manager going kernel improving ciency 
systems mc processors require return kernel restore privileged pipeline state 
potential variety high performance uses application page cache management hope architectures allow direct application resumption fault 
faulting process executes segment manager care required handling page faults process stack toavoid nitely recursive page faulting 
approach separate fault handling signal stack memory page fault page fault handling occur 
separate signal stack segment multi threaded program thread separate signal stack stack segment 
initialization kernel creates segment awell known segment identi er includes page frames memory system order physical address access limited system processes speci cally system page cache manager see section 
system page cache manager uses operation allocate page frames various segment managers demand 
minimal con guration system real time application demand paging application processes allocate pages directly initial segment obviating need process level server mechanism 
scenario illustrates kernel virtual memory support contains little extra mechanism required support embedded applications con gured process level servers implement full demand paging system sophisticated application paging control 
summary primary kernel extensions ability designate explicit manager segment kernel operations modify segments page frame ags kernel operation determine page attributes range pages frames 
information control exported kernel cient communication segment managers page fault block interface le mapped address space reading process page protection fault events process level module readily implement avariety sophisticated schemes including replicated writeback page compression logging coordinate writeback application required clean database transaction commit 
comparison external pager approach supported mach kernel kernel page reclamation page writeback 
application speci segment managers sophisticated large scale application application speci segment manager manages application memory segments 
management actions include handling page faults reclaiming pages segments interacting system segment manager allocate additional pages return pages appropriate 
handle page faults quickly segment manager typically maintains free page segment just normally done virtual memory system conventional design 
free page segment mapped manager address space manager directly copy data page frames part allocation reclamation 
example part conventional page fault may read page data backing storage page address space corresponds page free page segment allocated page fault 
migrates page frame faulting segment allows faulting process continue 
complex schemes appropriate applications 
example segment manager database management system dbms may temporary index segments free page segments simply steal scratch areas maintain explicit free areas 
dbms segment manager may di erent free page segment indices views relations making easier track memory allocation di erent types data 
single application may di erent segment manager modules di erent segments types segments uses 
example may maintain di erent free page segments handle distributed physical memory machines page coloring schemes 
techniques rely able request page frames system page cache manager speci physical addresses particular physical address ranges 
manager implement standard page frame reclamation strategies various clock algorithms 
particular periodically migrate page frames segments manages back free page segment keeping track segment page number page frame migrates writing back dirty page data 
page frame referenced original segment page frame reused manager simply migrates back original segment 
manager informed segment manages closed deleted reclaim segment page frames time 
manager application speci strategies deleting segments temporary data knows longer needed better discard regenerate entirety paged back regenerated page time 
similarly large scale matrix computation manager may able prefetch pages matrices minimize ect disk latency computation recognizing simply discard dirty pages intermediate matrix writing back conserving bandwidth 
initialization segment manager requests creation free page segments initial page frame allocations system page cache manager 
creates segments possibly demand application handle application data specifying manager segments 
issue page faults segment manager code data handled ways 
code data reside segments managed manager default segment manager described section 
case rst manager incurring page fault code data segment second fault handled segment manager rst manager continues page fault handling 
approach simple implement provide predictable performance application segment manager 
alternative approach application manager manage segments containing code data ensure segments paged program active ectively locking portion memory 
approach application starts execution segments control default segment manager 
application manager accesses pages point force memory assumes management segments segments ensuring memory 
page fault assuming ownership causes initialization sequence retried succeeds manager completed initialization excludes page frames candidates replacement 
approach avoid page faults page fault handling code segments signal stack ectively pinned data just stack segments described earlier 
approach application swapped secondary storage 
particular application segment manager swaps application segments code data segments 
returns ownership segments default segment manager indicates ready swapped 
application manager suspended segment swapped 
resumption application manager gains control repeats initialization sequence described 
application segment manager specialized generic standard segment manager inheritance object oriented implementation 
generic implementation provides data structures managing free page segment basic page faulting handling 
page replacement selection routines page ll routines easily specialized particular application requirements 
application programmer ort pro scheme assumes amount memory required manager small compared amount memory 
assume large system memory con guration suitable running class memory bound techniques assumption invariably true 
clear approach general system memory resources meager relative working set size servers real time interactive modules 
vide page cache management minimized focused application speci policies techniques task developing segment manager scratch 
default segment manager default segment manager implements cache management conventional programs making oblivious external page management 
manager executes server outside kernel 
default segment manager currently created part rst team memory resident set systems servers started immediately kernel initialization 
default manager page fault 
implementation uio cache directory server extended act default segment manager 
server manages virtual memory system ectively le page cache 
address spaces realized bindings open les sunos original role handle le opens closes add les cache demand remove appropriate 
original form page faults handled mappings established 
modi cations external page cache management required extensions server manage free page segment handle page fault requests page reclamation writeback 
maintaining information cached les le basis extensions data structures functionality relatively modest 
determine memory requirements applications default segment manager default manager implements clock algorithm allocates page frames requester number page frames referenced interval 
implementation algorithm requires passing fault manager process rst page page protection bits set disallow 
handling fault requires changing protection referenced page 
reduce overhead handling faults default manager changes protection number contiguous pages single page fault occurs 
general default manager implement algorithms corresponding kernel module conventionally structured system including page coloring appropriate 
performance default segment manager competitive systems indicated measurements section 
system page cache manager system page cache manager module manages allocation global memory pool segment managers 
manager requests number page frames order satisfy memory requirements 
defer refuse request competing demands memory memory allocation policy 
returns page frames local free page segment returned segment manager segment manager terminates 
support segment manager requests particular page frames physical address physical sunos trademark sun microsystems address range required physical placement control page coloring 
satisfy allocation request physical address constraints handled conventional unconstrained page frame request size memory requested larger available 
allocates provides page frames willing 
extensions easily provided architectures modifying complicating destabilizing kernel 
memory market model system memory allocation developed explored depth separate report 
brief imposes charge process memory uses period time arti cial monetary unit 
process holding megabytes memory seconds charged drams charging rate drams megabyte second 
process provided income drams second existence value depending number competing processes administration policy allocating system 
segment manager part application process manage dram supply balance cost memory application versus income 
particular return memory longer ord pay memory 
ability force return memory processes exhausted dram supply treating process behavior faulty 
batch programs application segment manager suspends swaps program saved drams ord memory reasonable time slice execution 
queries determine demand memory possibly identify trade running small amount memory soon versus waiting longer get larger amount memory 
process drams ord memory memory runs soon memory request granted 
time slice dram savings running low pages data returns quiescent state low memory requirement 
re nement allow process continue memory charge outstanding memory requests 
savings tax imposed avoid demand dramatically exceeding supply basically xed price xed supply market 
charge trade memory example scan structured programs prevents programs avoiding memory charge excessive monetary model allows allocate memory resources programs income supplied program re ecting policy 
particular claim user account receives equal income programs receive equal share machine time active users 
claim assumes machine primary limiting resources memory monetary model allows applications decide best structure computation relative system resources choosing instance computing large amount short versus computing longer time slices memory 
model allows segment managers predict long execute amount memory available time 
conventional approaches global page management developed application lose pages swapped 
implementing conventional working set algorithms appear require trusting application segment managers information largely duplicating monitoring page access behavior 
results date suggest approach results stable cient global memory allocation mechanism large scale computations provides applications considerable exibility making application speci tradeo memory matching application control provided mechanisms described 
system page cache manager default segment manager basic kernel virtual memory management provide equivalent functionality ofa conventional virtual memory system modular form 
particular page replacement policies allocation strategies moved outside kernel 
line objective minimal sized kernel suitable embedded realtime applications conventional timesharing interactive workstation 
small number kernel extensions required external page cache management added conventional unix system example provide bene ts application controlled paging major surgery required revise system design match modularity 
particular kernel extensions required designate mapped le le meaning page frames le reclaimed su cient notice just segments 
kernel operation ioctl system call required set managing process associated le allocate pages 
kernel default manager ectively 
ptrace signal wait mechanism communicate page faults process level segment manager 
simplest solution protecting manager page faults code private data simply lock pages memory facility available unix may require manager run privileged process 
evaluation taken pronged approach external page cache management 
firstly implemented external page cache management kernel systems servers details design evaluate complexity performance 
secondly evaluated bene ts external page cache management simulation database management system uses large amount memory 
measurements system primitives external page cache management implemented system modi cation kernel virtual memory manager extensions 
kernel uses external page cache management machine independent virtual memory module approximately lines code compared approximately lines previous version 
excised code migrated page cache managers real saving total amount code required functionality 
signi cant reducing size kernel providing greater external functionality 
performance implementation evaluated decstation 
processor mhz clock kilobyte page size 
table summarizes performance relative ultrix 
measurement ultrix equivalent faulting process minimal fault default segment manager minimal fault read kb write kb table system primitive times times microseconds minimal cost page fault measured table occurs manager just migrate page frame free page segment faulting process segment 
case occurs frequently rst access heap page copy write faults write appending new page segment 
table measurements suggest handling minimal page fault faster faulting process ultrix kernel 
di erence cost microseconds cost page zeroing ultrix kernel performs page allocation 
ultrix zeroing required security page may applications case page user 
referring second row table cost fault handling default manager higher ultrix signi cantly ect performance applications measurements subsection show 
low overhead page fault handling allows cient implementation user level algorithms page protection hardware described 
examples algorithms include mechanisms concurrent garbage collection concurrent checkpointing 
ultrix decstation cost user level fault handler protected page simply changes protection page microseconds 
higher cost handling full fault external page cache management 
ultrix competitive user level fault handling systems mach sunos 
example appel li measurements decstation overhead mach fault handling operations twice overhead ultrix similar operations 
nal measurements table costs reading writing kb block le 
case accesses block read write interface ultrix user level fault handler signal handler mprotect system call changes protections application program memory 
discussed section 
ultrix measured cost read write system calls 
write cost ultrix 
read cost higher ultrix reads 
numbers show providing external page cache management large negative ect performance common operations accesses cached les 
default segment manager ran number standard unix applications default segment manager instrumentation measure overhead executing real application programs default segment manager 
comparison compiled source code di erent operating system dependent libraries ultrix 
applications 
di compare kb les generating di erences le kb 

uncompress uncompress kb le generating le mb 

latex format input document generating page document 
cases hardware decstation megabytes memory 
page size machine kb 
di erences hardware con gurations 
ultrix machine local disk 
machine diskless le storage provided running decstation running ultrix 
applications run les read cached memory eliminate di erences performance irrelevant virtual memory system design factors measuring 
scenarios worst case approach network le access latency hide cost going process level manager 
notable di erences ultrix 
unit transfer ultrix kb 
unit transfer kb 
means twice read write operations kernel ultrix 
ultrix allocates pages units 
default manager allocates pages units appends le case allocates pages units 
unit page allocation signi cant allocation requires going segment manager 
low levels virtual memory system ultrix uses page tables describe address spaces 
augments segment bound region data structures global entry direct mapped hash table entry area 
table shows mean elapsed time executing programs ultrix 
measurements show performance applications comparable performance applications ultrix 
attempt account speci cally di erences performance measured virtual memory system activity ofeach shown table 
program ultrix di uncompress latex table application elapsed time seconds program manager migrate manager calls pages overhead di ms uncompress ms latex ms table vm system activity costs column shows number times execution program manager invoked including requests forwarded operations closing le requests page frame 
column shows number times manager invoked 
column basically shows manager calls handle page faults segment releases management operations 
column shows cost milliseconds manager calculated di erence cost minimal page fault default segment manager corresponding cost ultrix table multiplied number manager calls 
cost process level handling page faults small percentage program execution time measured case disk network access di uncompress latex 
di erences application performance ultrix table accounted table attribute di erences run time library implementations ultrix 
applications measured latex signi cantly slower continuing investigate reason 
measurements table indicate external page cache management responsible milliseconds di erence execution times 
assuming applications measured representative run default segment manager conclude minimizing kernel external page cache management introduce signi cant overhead normal programs 
fact expect overhead suggested measurements somewhat system normal conditions signi cant number page faults include disk network eliminated costs measurements provide worst case avoid spurious di erences arising device behavior 
application speci page cache management explore performance bene ts page cache management program simulates database transaction processing system exploits space time tradeo indices cient join processing 
memory plentiful cient perform large joins generating indices relations advance 
creation indices result additional paging better discard indices space regenerate memory needed 
program run processors silicon graphics megabyte database 
transaction arrival rate transactions second transaction mix small type transactions remaining joins relations update third 
hierarchical locking scheme concurrency control 
program mixture implementation simulation 
locks implemented parallelism real 
execution transaction simulated looping number instructions page fault simulated equivalent time required handle page fault sgi 
measurements table show performance di erences con gurations database program 
con guration average worst case response response index index memory index paging index regeneration table ect memory usage transaction response ms rst con guration shows response time index joins 
second con guration shows reduction response time achieved index accessing relations performing join case indices memory 
case con guration labeled index paging megabyte index paged transactions average seconds size virtual memory program exceeds memory allocated program megabyte 
measurements show indices significant bene response time physical memory available limited bene size database system virtual memory exceeds available physical memory modest amount paging 
database system informed virtual memory size exceeds physical memory allocated discard indices regenerate necessary 
index regeneration entry shows performance bene ts approach physical memory allocated database system reduced megabyte 
case average response time order magnitude paging case worse index memory case 
example demonstrates case page cache management having signi cant bene ts application virtual memory slightly exceeded available physical memory 
expect similar bene ts memory intensive applications 
related inadequacy conventional transparent virtual memory model apparent developments papers areas 
example hagmann proposed operating system wrong place making decisions memory management 
discussed problems current vm systems design addresses problems 
conventional approach pinning pages memory provide application complete information pages memory application typically pin pages memory 
operating system allow signi cant percentage page frame pool pinned compromising ability share resource applications 
amount pinning feasible dependent memory 
complications led systems particularly di erent versions unix restrict memory pinning privileged systems processes impose severe limits number pages pinned process 
extension pinning noti cation locks process noti able pinned page reclaimed allow pinning give application control page frames reclaimed 
external page cache management system page cache manager reclaim page frames applications application segment manager complete control page frames 
expect appropriate generic segment manager software developing application speci segment manager harder developing pin manager module 
experience required area drawn 
external pagers mach provide ability implement application speci read ahead writeback backing servers external pages 
extensions address application control page cache primarily focused handling backing storage 
extensions mach address shortcomings mach noted young thesis 
supports user level page replacement policies 
implementation involves adding mechanism mach kernel deal aspect page cache management problem page replacement complicating simplifying kernel done 
export information application level memory allocated particular program 
subramanian describes mach external pager takes account dirty pages need written back 
shows signi cant performance improvements number ml programs exploiting fact garbage pages discarded writeback 
proposes adding support kernel discardable pages remedy problems associated supporting discardable pages outside mach kernel 
external pager knowledge physical memory availability 
second unnecessary zero lls security page reallocated application 
problems addressed external management adding special mechanism kernel 
database management systems demanded operating systems provided facilities pinning pages unix calls limited advisory capability berkeley unix call 
approaches provide simple ways prevent page uence paging behavior real measure control page cache program proposed 
support application designated page replacement page basis noti cation changes available physical memory scope design implementation current facilities 
current virtual memory system functionality evident database literature complaints virtual memory system compromising database performance calls extended virtual memory facilities elimination virtual memory system altogether 
see approach database management systems information control page management demanded literature 
achieve compromising integrity operating system general purpose functionality 
analogy proposed operating system support parallel application management processors 
example tucker gupta show signi cant improvements simultaneous parallel application execution applications informed changes numbers available processors allowed adapt compared conventional transparent oblivious approach 
anderson black proposed kernel mechanisms exporting control processor management applications 
just processor focused targeted demanding applications requirements exceed normal standards plentiful hardware resources 
processor focused targeted improving performance conventional applications software development tools utilities 
complements focusing application control physical memory control processor allocation 
concluding remarks external page cache management promising approach address demands memory bound applications providing control portion system memory resources signi cantly complicating system facilities particularly kernel 
argued cost page fault high hidden application ect performance 
parallel database transaction processing application support view showing small amount paging eliminate performance bene algorithms virtual address space just slightly excessive amount physical memory available compared economical space 
behavior consistent memory thrashing behavior observed memory bound applications general 
strange spacetime tradeo recognized algorithms community algorithms exists problems er precisely tradeo virtual memory systems previously exported information control applications allow choice algorithm intelligently 
cost page fault disk hundreds thousands instructions foreseeable application expect trade space time space real virtual 
external page cache management implemented system requires relatively simple extensions kernel provides performance user page fault handling times microseconds current conventional hardware 
approach subsumes external pager mechanism mach external page cache management obviates need provide kernel support various application speci advisory monitoring modules required causing signi cant increase kernel code complexity 
argue complexity code size bene ts best appreciated considering size complexity unix module deal memory management problems raised 
vein expect considerations page coloring physical placement control cache line software control paradigm place demands memory management software 
wehave exploited new external page cache management kernel operations reduce size kernel implementing system page cache management default segment manager outside kernel 
changes lead signi cantly simpli ed kernel page reclamation copy write support distributed consistency removed process level managers 
primary focus going development application speci segment managers generic manager object oriented techniques specialize infrastructure particular application requirements 
goal minimize burden application programs providing bene ts application control 
investigating market model systemwide memory management performance sharing system memory resources competing applications 
primary focus batch processing results date promising 
external page cache management approach develops principle operating system design call cient completeness described previously context supporting emulation 
operating system kernel providing abstraction hardware resources provide cient complete access functionality performance hardware 
context memory management complete cient abstraction hardware resource page cache 
fair multiplexing memory multiple competing applications achieved managing page frame allocation page caches 
generally leads relatively low level service interface concert goals minimalist kernel design wehave shown external page cache management 
summary believe external page cache management technique structuring generation kernel virtual memory systems addressing growing complexity memory system organizations growing demands applications reducing size kernel virtual memory support conventionally structured systems 
facility commonly available commercial systems expect exciting memory management improvements may come developers database management systems large scale computations demanding applications performance currently badly hindered haphazard behavior conventional virtual memory management 
supported defense advanced research projects agency contract 
comments asplos referees quality 
anita borg mendel rosenblum john chapin hendrik comments criticisms 
extremely grateful jonathan stone hours spent helping perform measurements 
thomas anderson brian bershad edward lazowska henry levy scheduler activations ective kernel support user level management parallelism acm transactions computer systems february 
andrew appel kai li virtual memory primitives user programs proceedings th symposium architectural support programming languages operating systems santa clara california april 
daley multics virtual memory proceedings nd acm symposium operating systems principles princeton new jersey october 
david black scheduler support concurrency parallelism system ieee computer magazine may 
david cheriton distributed system communications acm march 
david cheriton gregory whitehead edward binary emulation unix kernel usenix summer conference june 
david cheriton hendrik philip restructuring parallel simulation improve shared memory multiprocessor cache behavior experience shared memory multiprocessor symposium tokyo japan april 
david cheriton hendrik patrick boyle paradigm highly scalable shared memory multi computer architecture ieee computer february 
david cheriton market approach operating system memory allocation working march 
daniel mhz dual issue cmos microprocessor th international solid state circuits conference pages february 
robert hagmann comments workstation operating systems virtual memory proceedings nd ieee workshop workstation operating systems paci grove california september 
samuel le er design implementation bsd unix operating system addison wesley november 
dan lenoski dash prototype implementation performance proceedings th symposium computer architecture pages may dylan mcnamee katherine armstrong extending mach external pager interface user level page replacement policies technical report university september 
brian bray william lynch flynn page allocation reduce access time physical caches technical report csl tr computer systems laboratory stanford university 
michael stonebraker operating system support database management communications acm july 
michael stonebraker design xprs memorandum 
ucb erl university california berkeley march 
subramanian managing discardable pages external pager proceedings second usenix mach symposium monterey california november 
irving traiger virtual memory management database systems operating systems review april 
andrew tucker anoop gupta process control scheduling issues multiprogrammed shared memory multiprocessors proceedings th acm symposium operating systems principles eld park arizona december 
michael young duality memory communication implementation multiprocessor operating system proceedings th acm symposium operating systems principles austin texas november 
michael young exporting user interface memory management communication oriented operating system phd thesis department computer science carnegie mellon university november 
available technical report cmu cs 
