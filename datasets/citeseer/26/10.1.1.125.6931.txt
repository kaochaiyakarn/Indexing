part overview probably approximately correct pac learning framework david haussler haussler cse ucsc edu center computer engineering information sciences summary part university california santa cruz ca survey theoretical results ciency machine learning algorithms 
main tool described notion probably approximately correct pac learning intro duced valiant 
de ne learning model look results obtained 
consider criticisms pac model extensions proposed address criticisms 
look brie models proposed computational learning theory 
dangerous thing try formalize enterprise complex varied machine learning subjected rigorous mathematical analysis 
tractable formal model simple 
inevitably people feel important aspects activity left theory 
course right 
advisable theory machine learning having reduced entire eld bare essentials 
hoped aspects phenomenon brought clearly focus tools mathematical analysis new insights gained 
support onr gratefully acknowledged 
preliminary version part chapter appeared 
light wish discuss results obtained years called pac probably approximately correct learning theory 
valiant introduced theory get computer scientists study compu tational ciency algorithms look learning algorithms 
simpli ed notions statistical pattern recognition decision theory approaches computational complexity theory came notion learning problems feasible sense polynomial time algorithm solves analogy class feasible problems standard complexity theory 
valiant successful orts 
theoretical computer scientists ai researchers obtained results theory complained proposed modi ed theories 
eld research includes pac theory relatives called computational learning theory 
far monolithic mathematical edi ce sits base machine learning unclear possible desirable 
argue insights gained varied computational learning theory 
purpose short monograph survey reveal insights 
de nition pac learning intent pac model successful learning unknown target concept entail obtaining high probability approximation 
name probably approximately correct 
basic model instance space assumed set possible assignments boolean variables attributes concepts hypotheses subsets notion approximation de ned assuming probability distribution de ned instance space giving probability instance 
error hypothesis xed target concept denoted error clear context de ned error denotes symmetric di erence 
error probability disagree instance drawn randomly hypothesis approximation target concept error small 
obtain hypothesis 
simplest case looking independent random examples target concept example consisting instance selected randomly label instance target concept positive example negative example 
training testing distribution noise phase 
learning algorithm computational procedure takes sample target concept consisting sequence independent random examples returns hypothesis 
cn set target concepts instance space 
hn de ned similarly 
de ne pac learnability follows concept class pac learnable hypothesis space exists polynomial time learning algorithm polynomial target concepts cn probability distributions instance space algorithm independent random examples drawn probability returns hypothesis hn error smallest polynomial called sample complexity learning algorithm intent de nition learning algorithm process examples poly nomial time computationally cient able produce approximation target concept high probability reasonable number random training examples 
model worst case requires number training examples needed bounded single xed polynomial target concepts distributions instance space 
follows number variables instance space con dence parameter sample complexity function plot error function training sample size get usually thought learning curve xed con dence upper envelope learning curves xed con dence obtained varying target concept distribution instance space 
needless say curve observed experimentally 
usually plotted experimentally error versus training sample size particular target concepts instances chosen randomly single xed distribution instance space 
curve curve obtained inverting sample complexity 
return point 
thing notice de nition target concepts concept class may learned hypotheses di erent class gives exibility 
cases interest 
rst target class hypothesis space 
case say properly pac learnable 
imposing requirement hypothesis class may necessary included speci knowledge base speci inference engine 
see learning di cult 
case don care hypothesis space evaluated ciently 
occurs goal accurate computationally cient prediction examples 
able freely choose hypothesis space may learning easier 
concept class exists hypothesis space evaluated instances polynomial time pac learnable simply pac learnable 
variants basic de nition pac learnability 
important variant de nes notion syntactic complexity target concepts classi es concept cn syntactic complexity 
usually syntactic complexity concept taken length number symbols bits shortest representation xed concept representation language 
variant pac learnability number training examples allowed grow polynomially syntactic complexity target concept 
variant concept class speci ed concept representation language represent boolean function example discussing learnability dnf disjunctive normal form formulae decision trees 
variants model algorithm request examples separate distributions drawing positive negative examples randomized coin ipping algorithms 
shown variants equivalent model described modulo minor technicalities concept classes pac learnable model pac learnable 
model easily extended non boolean attribute instance spaces instance spaces structural domains blocks world 
instances de ned strings nite alphabet learnability nite automata context free grammars investigated 
outline results basic pac model anumber fairly sharp results notion proper pac learnability 
summarizes results 
precise de nitions concept classes involved reader referred literature cited 
negative results complexity theoretic assumption rp np 

conjunctive concepts properly pac learnable class concepts form disjunction conjunctions properly pac learnable class existential conjunctive concepts structural instance spaces objects 

linear threshold concepts perceptrons properly pac learnable boolean real valued instance spaces class concepts form conjunction linear threshold concepts properly pac learnable 
holds disjunctions linear thresholds linear thresholds multilayer perceptrons hidden units 
addition weights restricted threshold arbitrary linear threshold concepts boolean instances spaces properly pac learnable 

classes dnf cnf decision lists properly pac learnable xed unknown classes dnf functions cnf functions decision trees properly pac learnable 
di culties proper pac learning due computational di culty nding hypothesis particular form speci ed target class 
example boolean threshold functions weights properly pac learnable boolean instance spaces rp np pac learnable general boolean threshold functions 
concrete case enlarging hypothesis space computational problem nding hypothesis easier 
class boolean threshold functions simply easier space search class boolean threshold functions weights 
similar extended hypothesis spaces classes mentioned properly pac learnable 
turns classes pac learnable 
known classes dnf functions cnf functions decision trees multilayer perceptrons hidden units pac learnable 
stronger result show concept class pac learnable show properly pac learnable result implies concept class pac learnable reasonable hypothesis space 
methods determining pac concept classes developed pitt warmuth 
methods involve reductions learning problem notions learning completeness learning problems analogous corresponding notions theory complexity classes general computational problems 
framework pitt warmuth conjunction results goldreich gold micali shown certain learning problems learning complete see concept classes associated problems pac learnable extremely weak sense assuming existence cryptographically secure pseudo random bit generator existence certain type way function 
assumption stronger assumption rp np convincing evidence validity 
simpler problems shown pac learnable stronger cryptographic assumptions 
particular kearns valiant show polynomial time learning algorithm deterministic finite automata dfas invert certain cryptographic functions 
done rst showing inverting cryptographic functions reduces learning arbitrary boolean formulas boolean expressions operators 
shown learning boolean formulas reduces learning dfas follows dfas polynomially learnable assumption cryptographic functions ciently invertible 
kearns valiant obtain strong negative results multilayer perceptrons 
particular methods show exists constant polynomial class concepts represented feedforward neural networks boolean inputs hidden layers hidden units hidden unit computes linear threshold function polynomially learnable cryptographic assumptions theorem 
smallest value depth result holds determined 
mentioned possible strong result holds multilayer perceptrons just hidden units 
methods proving pac learnability formalization bias positive learnability results obtained 
showing cient algorithm nds hypothesis particular hypothesis space consistent sample concept target class 
sample complexity algorithm polynomial 
consistent mean hypothesis agrees example training sample 
algorithm nds hypothesis exists called consistent algorithm 
noted pac usage term consistent relation notion consistency methods parameter estimation statistics 
size hypothesis space increases may easier nd consistent hypoth require random training examples insure hypothesis accurate high probability 
limit subset instance space allowed hypothesis trivial nd consistent hypothesis sample size proportional size entire instance space required insure accurate 
fundamental tradeo computational complexity sample complexity learning 
restriction particular hypothesis spaces limited size form bias explored facilitate learning 
addition cardinality hypothesis space param eter known vapnik chervonenkis vc dimension hypothesis space shown useful quantifying bias inherent restricted hypothesis space 
vc dimension hypothesis space denoted de ned maximum number instances labeled positive negative examples possible ways labeling consistent hypothesis 
hypothesis space target class cn hn 
shown consistent algorithm learning sample complexity atmost hn ln ln improves earlier bounds may considerable overestimate 
terms cardinality denoted shown sample complexity ln hypothesis spaces boolean domains second bound gives better bound 
contrast hypothesis spaces real valued attributes nite rst bound applicable 
neural networks particular linear threshold functions notable exception 
vc dimension class linear threshold functions boolean inputs logarithm cardinality class quadratic better rst bound case hypothesis space nite 
general vc dimension class functions represented multilayer perceptrons xed architecture variable weights upper bounded quantity close slightly higher number variable weights inputs real valued boolean 
weights represented high nite precision may better estimates vc dimension conjunction rst bound 
concepts represented neural networks xed size bits precision weight hypothesis space nite real valued inputs second bound applicable better 
unfortunately case bounds overly pessimistic practice 
extensions results case noisy training data complex learning prob lems described second part chapter chapter vapnik 
criticisms pac model criticisms leveled pac ai researchers interested empirical machine learning 
worst case emphasis model unusable practice 
notions target concepts noise free training data unrealistic practice 
take turn 
aspects worst case nature pac model issue 
worst case model measure computational complexity learning algorithm de nition sample complexity worst case number random examples needed target concepts target class distributions instance space 
little done issue notable exception address issue 
pointed section de nition pac learning worst case de nition sample complexity means calculate sample complexity algorithm exactly expect overestimate typical error hypothesis produced function training set size particular target concept particular distribution instance space 
compounded fact usually calculate sample complexity algorithm exactly relatively simple consistent algorithm 
forced fall back upper bounds sample complexity hold consistent algorithm previous section may contain constants 
upshot basic pac theory predicting learning curves 
variants pac model come closer 
simple variant distribu tion speci de ne analyze sample complexity learning algorithm speci distribution instance space uniform distribution boolean space 
potential problems 
rst nding distributions analyzable indicative ofthe distributions arise practice 
second bounds obtained may sensitive particular distribution analyzed reliable actual distribution slightly di erent 
re ned bayesian extension pac model explored 
bayesian approach involves assuming prior distribution possible target concepts training instances 
distributions average error hypothesis function training sample size function particular training sample de ned 
con dence intervals pac model de ned 
experiments model small learning problems encouraging needs done sensitivity analysis simplifying calculations larger problems analysed 
success tackling di cult computations involved certain bayesian approaches learning theory obtained tools statistical physics 
distribution speci learning provides increasingly important counterpart pac theory variant pac model designed address issues probability take model explored 
model designed speci cally help understand issues incremental learning 
looking sample complexity de ned measure performance probability learning algorithm incorrectly guesses label th training example sequence random examples 
course algorithm allowed update hypothesis new training example processed grows expect probability mistake example decrease 
xed target concept xed distribution instance space easy see probability mistake example average error hypothesis produced algorithm random training examples 
probability mistake example exactly plotted empirical learning curves plot error versus sample size average runs learning algorithm sample size 
focus worst case probability mistake th example possible target concepts distributions training examples 
probability mistake th example examined target concept selected random prior distribution target class examples drawn random certain xed distribution 
bayesian approach 
call worst case probability mistake call average case probability mistake 
results summarized follows 
concept class dn cn 
concept class consistent algorithm hypothesis space worst case probability mistake example dn ln dn dn 
furthermore particular consistent algorithms concept classes worst case probability mistake example dn ln dn best said general arbitrary consistent algorithms 
second concept class exists universal learning algorithm neces consistent computationally cient worst case probability mistake example dn hand learning algorithm worst case probability mistake example dn universal algorithm essentially optimal 
surge interest bayesian approaches neural network learning see :10.1.1.31.4284
third focus average case behavior di erent universal learning algorithm called bayes optimal learning algorithm weighted majority algorithm closely related cient algorithm called gibbs randomized weighted majority algorithm average case probability mistake example dn dn respectively 
furthermore particular concept classes particular prior probability distributions concepts classes particular distributions instance spaces classes average case probability mistake example dn learning algorithm constant 
indicates general bounds tight small constant 
better forms upper lower bounds speci distributions examples speci target concepts speci sequences examples 
results show interesting things 
certain learning algorithms perform better arbitrary consistent learning algorithms worst case average case restricted setting de nitely learning just nding consistent hypothesis appropriately biased hypothesis space 
second worst case worse average case 
experiments learning perceptrons multilayer perceptrons shown cases dn predictor actual average case learning curves backpropagation synthetic random data 
overestimate natural data domains learning conjunctive concepts uniform distribution 
distribution algorithm speci aspects learning situation taken account 
general concur extensions pac model required explain learning curves occur practice 
amount experimentation distribution speci theory replace security provided distribution independent bound 
second criticism pac model assumptions de ned target concepts noise free training data unrealistic practice 
certainly true 
pointed computational hardness results learning described having established simple noise free case hold general case 
pac model advantage allowing state negative results simply strongest form 
positive learnability results strengthened applicable practice extensions pac model needed purpose 
proposed see 
de nitions target concepts random examples hypothesis error pac model just simpli ed versions standard de nitions statistical pattern recognition decision theory reasonable thing go back established elds general de nitions developed 
probability misclassi cation measure error general loss function de ned pair consisting guessed value actual value classi cation gives non negative real number indicating cost charged particular guess particular actual value 
error hypothesis replaced average loss hypothesis random example 
loss guess wrong right discrete loss get pac notion error special case 
general loss function choose false positives expensive false negatives vice versa useful 
loss function allows handle cases possible values classi cation 
includes problem learning real valued functions choose guess actual loss functions 
second assuming examples generated selecting target concept generating random instances labels agreeing target concept assume random instance randomness label 
instance particular probability drawn instance possible classi cation value particular probability occurring 
random process described making independent random draws single joint probability distribution set possible labeled instances 
target concepts attribute noise classi cation noise kinds noise modeled way 
target concept noise distribution instance space bundled joint probability measure labeled examples 
goal learning nd hypothesis minimizes average loss examples drawn random joint distribution 
pac model disregarding computational complexity considerations viewed special case set discrete loss function added twist learning performance measured respect worst case joint distributions entire probability measure concentrated set examples consistent single target concept particular type 
pac case possible get arbitrarily close zero loss nding closer closer approximations underlying target concept 
possible general case ask produced learning algorithm comes performance best possible hypothesis hypothesis space 
unbiased hypothesis space known bayes optimal classi er 
pac research general framework 
quadratic loss function mentioned place discrete loss kearns shapire investigate problem ciently learning real valued regression function gives probability classi cation instance 
general approach links learning model minimum description length framework rissanen yamanishi 
second part chapter show vc dimension related tools originally developed vapnik chervonenkis type analysis applied general study learning neural networks 
restrictions whatsoever placed joint probability distribution governing generation examples notion target concept target class eliminated entirely 
method speci sample complexity bounds obtained learning feedforward neural networks various loss functions 
results related lines chapters vapnik white 
viewed larger context statistics basic pac model really toy model useful important ideas machine learning clean framework questions computational complexity addressed answered negatively strongest form nearly rich capture range machine learning practice 
sophisticated union statistics computer science possibly disciplines required task 
comprehensive model type suggested computational learning theory literature number aspects approaches machine learning explored 
discussed section 
theoretical learning models anumber theoretical approaches machine learning compu tational learning theory 
total mistake bound model :10.1.1.130.9013
arbitrary sequence examples unknown target concept fed learning algorithm seeing instance algorithm predict label instance 
incremental learning model probability mistake model described assumed instances drawn random measure learning performance total number mistakes prediction worst case sequences training examples arbitrarily long target concepts target class 
call quantity worst case mistake bound learning algorithm 
interest case exists polynomial time learning algorithm concept class worst case mistake bound target concepts cn polynomial pac model mistake bounds allowed depend syntactic complexity target concept 
perceptron algorithm learning linear threshold functions boolean domain example learning algorithm worst case mistake bound 
bound comes directly bound number updates perceptron convergence theorem see 
worst case mistake bound perceptron algorithm polynomial linear number boolean attributes target concepts conjunctions disjunctions concept expressible weights arbitrary threshold 
variant perceptron learning algorithm multiplicative additive weight updates developed signi cantly improved mistake bound target concepts small syntactic complexity :10.1.1.130.9013
performance algorithm extensively analysed case examples may mislabeled 
shown polynomial time learning algorithm target class polynomial worst case mistake bound pac learnable 
general methods converting learning algorithm worst case mistake bound pac learning algorithm low sample complexity 
total mistake bound model unrelated pac model 
fascinating transformation learning algorithms weighted majority method 
see general methods 
method combining learning algorithms single incremental learning algorithm powerful robust component algorithms 
method extends bayesian style weighted majority algorithm mentioned previous section 
idea simple 
com ponent learning algorithms run parallel sequence training examples 
example algorithm prediction predictions combined voting scheme determine prediction master algorithm 
receiving feed back prediction master algorithm adjusts voting weights component algorithms increasing weights correct prediction decreasing weights guessed wrong case factor 
shown method combining learning algorithms robust regard mislabeled examples 
importantly method produces master algorithm worst case mistake bound approaches worst case mistake bound best component learning algorithm 
performance master algorithm best component algo rithm 
particularly useful learning algorithm known parameter algorithm tuned particular application 
case weighted majority method applied pool component algorithms version original learning algorithm di erent setting parameter 
master algorithm performance approaches performance component algorithm best setting parameter 
weighted majority method adapted case predictions component algorithms continuous 
leads method designing master algorithm worst case loss approaches worst case loss best linear combination component learning algorithms 
total number mistakes loss total squared prediction error 
version weighted majority method obtain mistake bounds case best component algorithm changes various sections trial sequence 
general learning problems drifting target concepts investigated 
represents interesting new direction computational learning theory research 
pac total mistake bound models extended signi cantly learning algorithms perform experiments queries teacher learning 
simplest type query membership query learning algorithm proposes instance instance space told instance member target concept 
ability membership queries greatly enhance ability algorithm ciently learn target concept mistake bound pac models 
shown polynomial time algorithms polynomially membership queries polynomial worst case mistake bounds learning 
monotone dnf concepts disjunctive normal form negated variables 
formulae boolean formulae appears 
deterministic nite automata 
horn sentences propositional prolog programs 
addition general method converting cient learning algorithm membership queries polynomial worst case mistake bound pac learning algorithm long pac algorithm allowed membership queries 
concept classes listed pac learnable membership queries allowed 
contrasts evidence cryptographic assumptions classes pac learnable random examples 
surprisingly cryptographic assumptions slightly richer classes listed list pac learnable membership queries 
include 
non deterministic nite automata 
intersections deterministic nite automata 
shown generalizing notion polynomial time learning preserving reduction case membership queries allowed reducing known cryptographically secure problems learning problems 
brief survey able cover small fraction results obtained computational learning theory 
glimpse results refer reader 
hope wehave convinced reader insights provided line investigation di culty searching hypothesis spaces notion bias ect required training size ectiveness majority voting methods usefulness actively making queries learning ort worthwhile 
part decision theoretic generalizations pac model neural net applications summary part describe generalization pac learning model statistical decision theory 
model learner receives randomly drawn examples example consisting instance outcome tries nd decision rule speci es appropriate action take instance order minimize expectation loss 
arbitrary sets real valued function examples generated arbitrary joint distribution special cases include problem learning function problem learning conditional probability distribution regression problem learning distribution density estimation 
give theorems uniform convergence empirical loss estimates true expected loss rates certain decision rule spaces show implies learnability bounded sample size disregarding computational complexity 
application give distribution independent upper bounds sample size needed learning feedforward neural networks 
theorems generalized notion vc dimension applies classes real valued functions adapted vapnik pollard notion capacity metric dimension classes functions map bounded metric space 
fuller version part chapter appears 
probably approximately correct pac model learning examples done job drawing practitioners machine learning theoretically oriented computer scientists pursuit solid useful mathematical dation applied machine learning 
practitioners include mainstream arti cial intelligence neural net research 
attempting address issues relevant applied machine learning number shortcomings model cropped repeatedly 

model de ned valued functions 
practitioners learn func tions instance space take values arbitrary set multi valued discrete functions real valued functions vector valued functions 

practitioners wary assumption examples generated underlying target function satis ed noise models proposed weaken assumption 
see general regression models investigated component training example randomly speci ed conditional distribution general goal approximate conditional distribution instance computational learning theory literature model type investigated general case 

learning problems unsupervised learner access randomly drawn unlabeled examples instance space learning viewed form approximation distribution generating examples 
usually called density estimation instance space continuous speci parametric form underlying distribution assumed 
called parameter estimation speci parametric probability models 
example computational learning theory literature investigation abe warmuth complexity learning parameters hidden markov model 
purpose twofold 
propose extension pac model vapnik chervonenkis pollard addresses issues 
second extension obtain distribution independent upper bounds size training set needed learning various kinds feedforward neural networks 
overview proposed framework extend pac model propose general framework statistical decision theory see ferguson kiefer berger 
general framework assume learner receives randomly drawn training examples example consisting instance outcome arbitrary sets called instance outcome spaces respectively 
examples generated joint distribution unknown learner 
distribution comes known class joint distributions representing possible states nature 
training learner receive random examples drawn joint distribution 
example learner shown instance asked choose action set possible actions called decision space 
outcome revealed learner 
case examine outcome depends instance action chosen learner 
action outcome learner su er loss measured xed real valued loss function assume loss function known learner 
learner tries choose actions minimize loss 
look case training examples learner develops deterministic strategy speci es believes appropriate action instance uses strategy examples 
look batch learning incremental line learning :10.1.1.130.9013
learner strategy function instance space decision space called decision rule 
assume decision rule chosen xed decision rule space functions example instances may encoded inputs neural network outputs network may interpreted actions case network represents decision rule decision rule space may functions represented networks obtained varying parameters xed underlying network 
goal learning nd decision rule minimizes expected loss examples drawn random unknown joint distribution learning framework applied variety situations 
illustra tions 
discussion refer reader excellent surveys white barron devroye vapnik greatly indebted 
discussion appears chapters vapnik white 
recommend text kiefer general statistical inference decision theory 
betting example rst example consider problem learning maximize pro minimize loss 
horse races 
instance race action consists placing placing certain bet outcome determined winner second third place 
loss amount money lost bet placed outcome race negative loss interpreted gain 
joint distribution represents probability various races outcomes 
joint distribution unknown learner random examples xm ym consisting race outcome pair generated distribution 
examples learner develops deterministic betting strategy decision rule 
best decision rule speci es bet race minimizes expectation loss chosen randomly unknown conditional distribution determined underlying joint distribution necessarily unique best decision rule minimizes expected loss random example 
known bayes optimal decision rule 
learner tries approximate bayes optimal decision rule best decision rules decision rule space decision rules represented particular kind neural network 
classi cation second example consider problem medical diagnosis 
instance vector measurements medical tests conducted patient action diagnosis patient disease state outcome may de ned actual disease state patient 
possible diagnoses possible disease states 
specify loss function wemay stipulate zero loss correct diagnosis pair diagnosis di ering disease state positive real loss depending severity consequences particular 
decision rule diagnostic method bayes optimal decision rule minimizes expected loss examples test results associated disease states occur randomly unknown natural joint distribution 
medical diagnosis situation typical example classi cation learning problem eld pattern recognition see 
problem learning boolean function noise free examples investigated pac model special case classi cation learning 
outcome space instance example drawn random 
outcome unknown boolean target function determined stochastically 
decision space outcome space action interpreted prediction outcome decision rule maps instance space outcome space just target function 
ai pac learning particular common refer hypothesis case hypothesis space 
setup outcome function instance applied function learning problem letting arbitrary sets 
general function learning problem loss function usually measures distance prediction actual value metric 
pac model discrete metric 
expected loss decision rule hypothesis just probability predicts incorrectly usual pac notion error hypothesis 
general may set strings graphs real vectors case distance metrics general kinds loss functions may appropriate 
regression general problem regression di erent character classi cation learning addressed decision theoretic learning framework 
illustrate third example consider variant medical diagnosis situation doctor provides estimate probability patient diseases predicting speci disease asserting healthy 
assume actual disease state includes disease 
example doctor may say test results say disease probability disease probability disease probability 
doctor trying estimate conditional distribution disease states test results action entails providing vector parameters determine estimated distribution 

decision space set parameter vectors 
arbitrary discrete outcome space 
keeping instance xed parameter vector outcome denote probability outcome respect distribution de ned parameter vector take action instance asserting instance estimate conditional probability outcome outcome denote actual conditional probability instance respect unknown joint distribution 
distributions replaced densities continuous 
de ne loss function setting log 
called negative log likelihood loss function 
de ne loss way expected loss resulting action natural information theoretic interpretation kullback leibler divergence assume bp kullback leibler divergence bp denoted de ned log countable bp information gain actual conditional probability distribution estimated conditional distribution plus entropy ofp entropy true conditional distribution constant independent action choosing action instance minimizes expected log likelihood loss equivalent action gives closest estimate true conditional distribution possible outcomes measured kullback leibler divergence instance known kullback leibler divergence minimized bayes optimal decision rule regression 
regression version medical diagnosis situation de nition log likelihood loss function depends interpretation components parameter vector possible diseases patient possible mutually exclusive disease states yk yk means healthy 
fy yk 
specify action takes form ak ai yi estimated probability disease state yi 
components vector positive sum 
case log likelihood loss yi log yi 
constraints components nuisance interpretations ai log yi log yk 
case ak arbitrary real numbers ak ignored 
yi ai log likelihood loss yi ai log ai log aj 
known logistic loss 
third interpretation allow possibility patient may disease assume purposes estimation diseases occur independently 
disease state de ned binary vector length th bit yi ith disease 
similarly vector independent probabilities ak ai estimated probability entropy ofp denoted logp 
expectation negative log likelihood loss 
analogous results hold densities relevant quantities nite see chapter white 
patient having ith disease 
case log loss bp kx call cross entropy loss 
ky yi yi ai yi log ai medical diagnosis example outcome space discrete 
uses regression real valued outcome measurement real valued quantity instance represents experimental conditions quantity measured 
case regression usually de ned estimating conditional expectation instance action instance consists estimate mean various outcomes typically observed instance easy show quadratic loss function expected loss minimized true mean version regression ts naturally decision theoretic framework 
alternate approach loss function ja yj case expected loss minimized median conditional distribution instance 
see chapters white vapnik discussion 
density parameter estimation problems parameter estimation density estimation viewed special cases decision theoretic framework 
parameter estimation note instance fact standard version regression de ned estimating conditional mean instance quadratic loss function special case general version regression de ned continuous outcome spaces object estimate parameters specifying conditional density ofy instance log likelihood loss function 
see assume represent conditional density gaussian density mean variance 
variance xed independent ofx estimate conditional density completely determined mean decision space action interpreted specifying mean gaussian density 
substituting evaluating log log likelihood loss seen log 
xed variance equivalent learning quadratic loss additive multiplicative constants de nition rescale changing value minimizes expectation 
general treatment ideas appears chapter white 
discusses estimated conditionally gaussian density members exponential family densities 
space element particular instance ignored entirely 
regression problem reduces problem estimating parameters single distribution outcome space sample random outcomes simpler problem parameter estimation 
decision rule function merely single vector parameters decision rule space decision space density estimation consider dual case space element ignored 
examples unlabeled instances drawn randomly density 
decision set positive decision rule density information theoretic considerations suggest loss function loga 
expected loss minimized true density member best decision rule terms minimizing expected loss smallest kullback leibler divergence true density 
chapter white section unsupervised networks detailed exposition approach indication neural networks represent densities 
simplest example representation mixture gaussian densities neural network hidden layer described 
methods density estimation discussed vapnik 
instance space discrete estimating density probability distribution 
ideas carry decision space decision rule represent probability distribution loss function properties 
examples illustrate diversity learning problems cast proposed decision theoretic framework restrictive assumptions outcome depend action learner observes outcome loss 
weakening assumptions model types learning including associative reinforcement learning theory learning automata static environment 
pursue 
summary discussion results major practical issues decision theoretic view learning 
rst number random examples needed order able produce decision rule decision rule space decision rule expected loss near minimum decision rules examples problem tting decision rule produced performs training data random examples drawn joint distribution generated training data 
second adequacy decision rule space contain decision rule expected loss close bayes optimal decision rule particular joint distribution dealing hope achieve near optimal performance decision rule space 
choosing right decision rule space requires considerable insight particular problem domain 
third practical problem computational complexity method produce decision rule training examples 
issue addressed extensively pac literature addressed 
important issues examine rst 
issue referred problem estimating sample complexity learning problem pac literature 
number random training examples needed avoid tting depends critically nature decision rule space 
di erent kinds decision rule spaces di erent areas learning research partly di erent kinds instance outcome spaces 
pattern recognition statistics instance space usually nite dimensional real vector space instance consists vector real valued measurements attributes 
density estimation decision rule represents density choices possible 
common choice mixture gaussian densities 
standard regression outcome decision spaces identical real valued linear functions decision rules 
complex outcome spaces medical diagnosis example decision rule space regression usually de ned generalized linear model 
similarly binary classi cation possible outcomes pac model linear threshold functions decision rules straightforward generalizations case ary classi cation see 
linear bias pattern recognition statistics contrast pac model ai areas including neural networks rich variety decision rule spaces see 
main goal develop analytic tools help understand problem tting complex decision rule spaces 
order focus problem tting take simpli ed view learning learner chooses decision rule space tries nd decision rule near minimal expected loss 
learner looks decision rule minimizes observed average loss training examples called empirical loss empirical risk see chapter vapnik 
example standard linear regression learning algorithm method squares nd linear function minimizes average examples training set 
known training examples tend function nd come close minimizing actual expected quadratic loss obtained integrating possible unseen examples respect unknown joint distribution 
situation occurs nontrivial decision rule spaces including nonlinear regression models de ned feedforward neural nets 
certain measures dimension capacity decision rule space classes derived see obtain general upper bounds number random training examples needed high probability decision rule small empirical loss training examples small actual expected loss get uniform convergence results empirical estimates 
show give upper bounds su cient training sample size derived notion vc dimension generalize results 
application give speci bounds number training examples needed avoid tting learning decision rule space feedforward neural nets extending previous see related 
nets widely current neural net learning research 
model feedforward neural nets quite general allows types units nets including quasi linear units radial basis units product units 
general setting successful learning means nding decision rule average loss close minimal decision rules decision rule space loss close zero pac model 
addition additive model de ne close measure relative di erence metric similar standard multiplicative measure approximation combinatorial optimization 
allows state relevant uniform convergence bounds generalized cherno style bounds chapter general regression negative loglikelihood loss function principle minimizing empirical loss principle maximum likelihood 
hoe ding style bounds pollard results giving better bounds su cient training sample size important cases 
types bounds analogous types bounds vapnik gives uses measure absolute di erence measure relative di erence 
bounds sided bound deviations mean 
give upper bounds required sample size give indication order magnitude dependence sample size certain critical parameters learning problem illustrate theory 
crude directly practice explicit formulae choosing appropriate sample size 
cross validation techniques training examples held reserve test performance decision rules produced learning algorithm perform better task practice see cross validation means estimating amount tting learning method particular cases engineering trick provides scienti explanation phenomenon 
goal understand explain tting general decision rule spaces scienti engineering viewpoint 
note practice learning algorithms just search decision rule xed decision rule space minimizes empirical loss 
example common decision rule space depend number training examples available richer richer decision rule spaces examples available see 
allow learning algorithm produce sequence decision rules expected losses approach loss bayes optimal decision rule limit nite training sample size large class possible joint distributions 
results estimate appropriate rate decision rule space grow relative sample size avoid tting 
approaches method structural risk minimization introduced vapnik bayesian minimum description length mdl approaches try nd decision rule minimizes function empirical loss decision rule complexity :10.1.1.31.4284
achieve expected loss approaching bayes optimal decision rule limit may ective practice 
uniform convergence results develop analysis methods analysis vapnik argues reducing constants bounds criteria obtained provide useful guidance practitioner choosing sample network size place conjunction cross validation 
empirical studies group bell labs support claim 
types bounds may nd direct practice 
cross validation methods full treatment approaches scope chapter 
issues dealt fully vapnik chapter 
noted bayesian methods structural risk minimization applied decision rule space includes neural networks xed size 
example weight penalty functions neural net training 
approaches may signi cantly reduce training sample size needed avoid tting practice 
overview methods brie discuss methodology previous obtaining results 
builds directly vapnik chervonenkis pollard dudley uniform convergence empirical estimates application pattern recognition 
builds itai pac learnability respect speci probability distributions related natarajan tadepalli extensions vc dimension multi valued functions pac learnability respect classes probability distributions 
addition kulkarni independently generalized pac model related manner 
key ideas notion cover metric space associated idea metric dimension called fractal dimension 
notion dimension played important role active study fractals nature especially connection chaos dynamical systems 
build beautiful results vapnik chervonenkis dudley pollard relate type generalized vc dimension decision rule space number balls radius required cover space respect certain metrics 
sizes smallest covers determine metric dimension space 
treatment closely parallels approach 
interesting note related results connecting covers vc dimension independently developed computational geometry lead potentially rich area investigation combines elements combinatorics topology geometry probability measure novel framework 
feel area fascinating purely mathematical standpoint potentially useful speci cally lemma nearly equivalent lemma primal space dual 
result gives stronger version theorem part 
stronger version result theorem 
machine learning applied elds 
organization results remainder chapter organized follows 
learning framework described section de ned formally section 
look question evaluating performance learning algorithms terms number training examples 
question formalized decision theory perspective 
lemma lemma evaluate performance learning algorithms minimizing empirical loss 
lemma need bounds rate uniform convergence empirical loss estimates true expected losses 
section 
key bound theorem section general version theorem 
bound theorem need bounds random covering numbers associated decision rule space loss function distribution related idea cover described 
tools bounding random covering numbers worst case distributions developed section 
introduce notion capacity decision rule space particular loss function related notion metric dimension section notions pollard generalization vc dimension pseudo dimension described section appendix obtain bounds performance terms number training examples learning algorithms multilayer feedforward neural networks minimizing empirical loss corollary 
discussion results section 
technical proofs de nitions omitted simplify presentation 

notational conventions denote real numbers non negative real numbers log ln denote logarithm base natural logarithm respectively 
denote expectation random variable var denote variance 
probability space de ned implicitly context pr denote probability set 
usually measure underlying probability space de ned explicitly symbol usually denote probability measure appropriate algebra set instance space outcome space 
denote fold product measure functions subsets mentioned follows assumed measurable explicit 
alternately view random variables unspeci ed probability space viewed real valued measurements 
case viewed joint distribution case probability set de ned dp expectation function denoted dp countable abuse notation probability mass func tion denotes fzg 
pz case 
continuous density associated exists denoted countable yjx denote probability viewing random variables similarly xjy 
jx denotes conditional distribution marginal distribution de ned 
abbreviate 
list notation places text indicating section de ned 
countable assume algebra contains subsets assume complete separable metric space see section algebra smallest algebra contains open sets algebra borel sets 
uncountable marginal conditional distributions de ned bounded measurable function dp dp yjx sections section rh rh true risk section optimal risk section empirical risk section br optimal empirical risk section section regret functions section big risk section sample complexity section covering number sections packing number section dim metric dimension section pseudo dimension section capacity section lh jz section section section empirical expectation section distance vectors section distance functions section distance functions section learning optimization formalize basic problem learning introduced section 
introduce formal notion learning algorithm higher level loss function call regret function measures learning algorithm performs 
regret function de ned terms low level loss function discussed previous section 
show algorithm solve learning problem solving related optimization problem 
basic components rst review formalize components basic learning problem introduced previous section rst components instance outcome decision decision rule spaces respectively 
rst arbitrary sets fourth family functions discussed extensively previous section 
fth component family joint probability distributions represent possible states nature governing generation examples 
set called sample space 
assume examples drawn independently random probability distribution pon sample space sequence examples called sample 
follows usually assume includes probability distributions results distribution independent 
component loss function mapping 
assume bounded nonnegative real possible enforce condition simply adding constant tol doesn change learning problem essential way 
nite learning problem needs restricted meet condition 
example regression restrict possible parameter vectors possible outcomes constant take logb 
density estimation thing accomplished restricting instance space bounded subset densities values uniformly greater constants add logb loss function positive 
method works estimating distributions discrete spaces restrict nite instance space demand probability distributions see 
restrictions reasonable practice possible fact common assume speci class probability distributions example doing classi cation learning discrete selected arbitrary distribution xjy variate gaussian distribution 
hand doing linear regression real valued selected arbitrary distribution linear function additive gaussian noise 
pac learning theory discrete analog case 
usually boolean function particular type de ned small disjunctive normal form formula possibly plus random noise 
note get bounded loss linear regression bounded subset bound bounding coe cients functions bounded 
measurements naturally bounded ranges annoying see alternative approaches unbounded loss functions 
measuring distance optimality metric decision rule hand distribution sample space loss average value example drawn random de ned rh rh dp subscript omitted loss function clear context 
bounded expectation nite distribution decision theory expected loss rh called risk true underlying distribution 
quantity generalizes notion error computational learning theory 
section stated goal learning quite informally examples chosen indepen dently random unknown probability distribution nd decision rule comes close minimizing risk rh clear context denote mum rh decision rule space formalize notion basic learning problem rst need say mean close 

natural interpretation demand jr sj small 
section better relative measure distance 
real function de ned jr sj non negative reals straightforward tedious verify metric metric similar standard function jr sj measure di erence quality solution quality optimal solution combinatorial optimization 
measure modi ed behaved arguments zero symmetric arguments metric 
properties useful 

non negative reals 
non negative andd 

jr sj jr sj refer second property compatible ordering reals 
regret function big risk speci ed measure closeness optimality need specify criteria successful learning algorithm 
risk decision rule close optimum high probability average distance small 
measure success terms performance algorithm worst case distribution average case analysis distributions 
questions lead right back decision theory time higher level analysis learning 
see consider structure learning algorithm sample size algorithm sample xm ym drawn random unknown product distribution 
choose decision rule 
abstractly algorithm de nes function set samples zm requiring computability call learning method 
pis actual state nature governing generation examples algorithm produces decision rule say su er nonnegative real valued regret 
formally treatment regret function derived loss function measure extent failed produce near optimal decision rule assuming true state nature amount regret feel having produced optimal decision rule 
possible state nature average regret su ered algorithm possible training samples risk algorithm sample size big risk de ned formally rl goal learning minimize big risk 
dp illustrate de nitions examples 
suppose want capture notion successful learning pac model 
possibility isto introduce accuracy parameter de ne regret function letting rh 
su er regret decision rule produced learning algorithm risk optimal measured absolute di erence metric 
de nition regret big risk rl measures probability decision rule produced risk optimal random training examples drawn demand big risk small smaller con dence parameter 
pac model commonly assumed examples algorithm noise free examples underlying target function 
case risk optimal decision rule zero rh demanding big risk gives usual pac criterion risk decision rule hypothesis produced greater probability atmost regret function de ned similarly metric measure distance optimality absolute di erence 
speci cally de ne regret function letting rh 
case big risk rl measures probability risk decision rule produced algorithm distance optimal metric algorithm random training examples drawn see sections gives useful exible de nition regret 
fact main results terms family fl regret functions show corresponding results may derived corollaries family fl regret functions 
regret functions possible lead di erent learning criteria 
example simpler way de ne regret rh 
standard noise free pac model de nition regret equal risk rl expectation underlying loss case big risk rl measures expectation loss incurred learning algorithm random training examples drawn forms decision rule uses determine action independent random example drawn gives generalization learning criterion studied 
big risk gives expectation amount loss expected loss su ered optimal decision rule 
particular density estimation densities instance space de ning regret rh equal kullback leibler divergence big risk expected kullback leibler divergence decision rule returned algorithm true density see sections 
possible de ne regret function directly underlying loss function example density estimation possible measures distance densities hellinger distance total variational distance 
criterion inferring model probability de ned appropriate regret function de ning underlying loss full formalization basic learning problem having de ned regret function big risk function face issue want minimize big risk possible states nature want assume prior distribution possible distributions de ne notion average case big risk minimized 
goal know minimax optimality pac model 
bayesian notion optimality approaches learning neural nets statistical mechanics 
unfortunately question clear cut answer leads directly longstanding unresolved debate statistics see discussion 
set generalize pac model results best illustrated minimax setting formalize notion basic learning problem minimax criterion 
subsequent hope explore bayesian setting 
bayesian approaches neural network learning see bayesian versions pac model see :10.1.1.31.4284
de ne exactly mean basic learning problem means learning method solve problem minimax setting 
de nition learning problem de ned andl rst components de ned insection component family regret functions de ned section fl fl loss function 
learning method de ned section 
say solves basic learning problem land exists nite sample size rl sample complexity learning method smallest integer valued function 
fl denote fl denote 
discussed de nition generalizes pac criterion 
fact de nition quite generous sample size needed get big risk required nite 
particular property metric section underlying loss function bounded assume algorithm solves basic learning problem class regret functions solves class 
doesn matter classes regret functions 
practice sample complexity ofl critical depend class regret functions 
nature dependence seen clearly expand condition rl condition means random training examples drawn probability decision rule produced algorithm satis es risk greater optimal decision rule condition require case sample complexity de ned terms small additive deviations optimality allow additive multiplicative deviations 
deviations controlled parameters example standard pac model setting conditions equivalent reduces pac condition condition approximates condition small particular assuming underlying loss function bounded property metric shows condition implies condition 
shows parameter condition generally exible single parameter condition 
relation learning optimization assume underlying loss function xed regret functions derived order solve basic learning problem nd high probability decision rule risk close optimal 
true distribution unknown rely estimates rh various derived random training sample 
training sample zm zi xi yi denote empirical risk pmi yi xi br hg de ne natural optimization problem associated basic learning problem training sample nd decision rule br close br decision rule empirical risk training sample close minimal 
solving optimization problem automatically solve learning problem 
need empirical risk estimates 
bounded sample size rh probability 
say empirical risk estimates decision rules converge uniformly true risk exists sample size zi drawn independently random distribution probability rh 
metric absolute di erence metric 
result shows uniform convergence empirical risk estimates learning method gives randomized solution optimization problem estimates gives solution basic learning problem 
state metric argument works absolute di erence metric 
lemma 
suppose sample size probability distributions pr rh independently random distribution suppose algorithm pr br br drawn randomly 
pr solves basic learning problem family regret functions sample complexity 
proof 
triangle inequality 
br 
br br 
br second assumption lemma states holds probability atleast 
rst assumption implies hold probability 
fails nd decision rule rh 
compatibility ordering reals 
probability atleast hold 
result follows 
statistics type result called consistency theorem statistic decision rule computed learning method term consistency di ers sharply common pac learning research 
uniformly empirical estimates means section concentrate problem bounding number random examples needed get empirical estimates risk decision rules decision rule space decision rule example lh 
previous section assume non negative bounded loss function values interval decision rule lh de nes random variable values 
value lh example loss determine action take instance outcome risk just expectation lh rh lh lh dp furthermore zm sequence examples empirical risk empirical estimate mean lh sample denote ez lh ez lh mx lh zi lh hg 
need draw random examples get uniformly empirical estimate expectation random variable lh 
general problem obtaining uniformly estimate expectation function class real valued functions widely studied see 
assumptions functions immediately run problem functions take arbitrarily large values arbitrarily small probabilities making impossible obtain uniformly empirical estimates expectations nite sample size 
problem avoided making assumptions moments functions assuming exists single non negative function nite expectation called envelope lies absolute value function see vapnik chapter 
case loss takes values constant function serves envelope 
case especially nice envelope works distributions domain functions usual measure deviation empirical estimates true means simply absolute value di erence 
say empirical estimates expectations functions converge uniformly true expectations size random sample grows pr jb ez goes zero 
called uniform convergence probability see 
vapnik dudley pollard obtained general bounds sample size needed pr jb ez 
vapnik obtains better bounds important cases consid ering relative deviation empirical estimates true expectations 
looks bounds sample size needed pr ez bounds sample size needed pr ez anthony shawe taylor obtain bounds form 
note sided bounds bound probability empirical mean signi cantly smaller true mean 
extremely useful mentioned previous section measures deviation su er discontinuity ate metric properties 
give bounds sample size needed pr ez pr jb ez ez deviation measured metric setting appropriately obtain results similar special cases main theorem 
results pollard gives results bound sample size needed jb ez pr analogy second type bound vapnik bounds sided 
pursue 
restricted case functions positive uniformly bounded 
case nite considering general case useful see bounds get case nite set functions 
easily prove 
theorem nite set functions zm sequence examples drawn independently distribution 
sample size pr jb ez ln probability sample size probability pr ez ln proof 
second part theorem bernstein inequality see easy show single function pr ez details lemma part appendix 
follows probability ez setting bound solving gives result sample size 
proof rst part lemma similar hoe ding inequality see implies single pr jb ez letting lh theorem conjunction lemma previous section obtain bounds sample complexity learning algorithms minimize empirical risk 
family regret functions 
case get sample complexity case get sample complexity log log shown previous section generalization pac learning model obtained regret functions case setting note plugging setting gives sample complexity log signi cant improvement quadratic generalization pac model metric measure distance optimality resulting family regret functions ers new insight regard 
vapnik relative di erence empirical estimates true expectations advantage see appendix vapnik chapter 
general case main task section generalize theorem nite collections uniformly bounded functions 
basic idea simple replace nite class functions nite class approximates sense function close function argue type uniform convergence empirical estimates implies uniform convergence simplest version technique choice depends distribution direct method discussed section ii see section chapter white chapter 
general results apart certain measurability constraints obtained allowing depend particular random sample chapter 
called random cover size called random covering number 
type result derive 
need preliminary de nitions introduce notion covers metric di 
general treatment ideas appendix section 
general treatment section de nitions su ce section 
real vectors xm andy ym mi jxi yij 
distance metric 
set points lie bounded region cover nite set necessarily contained function denotes size smallest cover refer number 
de ne upper metric dimension set points logn dim log lower metric dimension denoted dim de ned similarly 
dim dim quantity denoted dim referred simply metric dimension note polylogarithmic dim metric dimension essentially picks exponent rate growth covering number function assume functions map 
sample zm zi jz zm fg call jz restriction note jz set points cube consider size covering number jz giving indication richness scale class functions restricted domain zm 
metric dimension jz gives indication number essential degrees freedom restriction zm drawn independently random random covering number jz gives indication richness typical set points domain note nite jz jfj samples random covering number jz jfj sample sizes distributions main result uniform empirical estimates nite classes functions similar theorem random covering numbers place jfj 
theorem permissible set functions zm sequence examples drawn independently distribution pr ez jz corollary assumptions pr jb ez proof corollary 
follows directly result setting 
see note property metric section implies jr sj setting 
constants results crude estimates 
serious attempt minimize 
see results talagrand better constants corollary 
bound result depends critically relative magnitudes negative exponent ine exponent expectation covering number jz re ects extent jz lls cube example jz metric dimension constant jz suitably small case negative exponential term eventually dominates expected covering number critical sample size nm log bound goes zero exponentially fast 
see examples section give bounds metric dimension jz terms combinatorial parameter called pseudo dimension theorem shows exponential drop occurs metric dimension bound holds measurability condition de ned need concern practice 
detailed discussion 
hand high probability jz lls cube extent jz large possible covering number dominates bound trivial 
results theorem page indicate uniform convergence take place case 
similar remarks apply bound theorem uses metric 
proof theorem follows proof pollard theorem general outline 
metric necessitates number substantial modi cations 
approach taken di erent taken independently prior pollard 
di erent involved techniques general theory weighted empirical processes developed alexander 
prove stronger result theorem see theorem 
result obtained bounding probability uniform convergence sample length terms expected covering numbers associated sample length expanding expectation include negative exponential term truncation 
turns saves factor negative exponential term 
theorem permissible set functions assume 
suppose generated independent random draws probability measure pr ez min jz expectation drawn randomly addition jz nite min jf theorem obtained corollary result substituting minimum left hand side rst bound 
theorem obtain slightly better constants results sequel 
capacity metric dimension function classes section develop way obtaining distribution independent bounds random covering numbers needed theorems 
key idea introduce pseudo metric see section decision space distance actions maximum di erence loss actions possible outcomes 
de nition loss function denote pseudo metric de ned sup jl note bounded pseudo metric space actions apart 
notions cover metric dimension previous section generalized arbitrary pseudo metric spaces 
generalization section appendix 
remainder concepts notation special 
decision rules map instance space pseudo metric induce pseudo metric decision rules di er extent actions di er respect ways 
easiest function distance de ning distance decision rules supremum works useful method obtaining uniform convergence learning results see related techniques white chapter 
see crucial issue size smallest cover resulting pseudo metric space cases get smaller covers better results function distance 
distance distance results worse 
powerful method 
de nition family functions set bounded pseudo metric space 
probability measure pseudo metric de ned 
dp probability measures nite measure set supremum unbounded 
call capacity analogy de nition metric dimension de ne upper metric dimension dim log lower metric dimension denoted dim de ned similarly 
dim dim quantity denoted dim referred simply metric dimension dim 
show bounds capacity lead distribution independent bounds rate uniform convergence empirical risk estimates functions respect loss function probability distribution lh family functions de ned lh hg lh 
jx marginal joint distribution see section 
lemma lh proof 
lh 
maps lh 
su ces show contraction functions jl dp dp jx term metric entropy quantities logn dl 
analogous fundamentally distinct concept dynamical systems literature 
term capacity related meanings 
usage taken 
gives theorem distribution independent uniform convergence risk estimates learning 
theorem assume decision rule space loss function lh permissible 
probability distribution assume 
generated independent draws pr rh proof 
lh 
sequence points trivial isometry jz pz pz empirical measure induced set measure equal fraction points contains 
lemma jz pz setting probability theorem 
order apply theorem need tools bounding capacity decision rule spaces 
lines close section stating basic lemmas capacity free product set function classes capacity compositions functions classes 
proofs 
de nition ak bounded metric spaces 
ak metric de ned kx uj vj uk vk hj family functions aj 
free product hk class functions fk fj hj kg fk function de ned fk fk lemma hk de ned 
probability measure ky hj ky hj 
dim dim hj similarly dim dim de ned 
de nition probability measure measurable function pf denotes probability measure induced pf measurable de nition function metric space metric space 
lipschitz bound real number 
lipschitz bound smallest class functions uniform lipschitz bound lipschitz bound 
lemma xk metric spaces xj bounded hj class functions xj xj hj bj uniform lipschitz bound hj denote class functions xk de ned compositions functions hj 
ffk fk fj hj kg kx ky bla ky hj 
dim dim hj similarly dim dim de ned 
sample size bounds learning multi layer neural nets applications results previous section learning feedforward neural nets see 
decision rule space represented feedforward neural net consists family functions instance space decision space 
apply theorem previous section need obtain upper bound capacity decision rule spaces various loss functions loss functions metric bounded terms metric nd constant cl ak andb bk ina cl pki jai bij 
case clear cl dl 
problem reduced obtaining upper bound capacity cl 
give examples illustrate reduction 
consider common case outcome space contained receive explicit feedback coordinate action occurs coordinate ai action prediction corresponding coordinate outcome loss function may metric measures distance predicted vector actual outcome vector 
metric forany actions triangle inequality metric bounded respect metric cld cld 
example metrics 
ki yi ai may take cl similarly note trick doesnot apply mean squared loss ki yi ai loss satisfy triangle inequality 
case easy show direct calculation outcome space bounded md may take cl 
loss nal example consider case cross entropy kx yi ln ai discussed section log likelihood loss regression problem action represents vector probabilities independent bernoulli variables outcome gives observed values variables 
loss bounded restrict probabilities 
case kx kx bi ai kx bi ai kx jai bij bi yi ln ai bi ai inequality follows fact min case cl max min jx yj min turn task obtaining upper bound capacity decision rules map decision space particular decision rules represented neural networks 
neural net output decision rule space family real valued functions ja bj case apply methods vapnik chervonenkis pollard get bounds capacity 
vapnik method doing described chapter 
way pollard notion pseudo dimension denoted developed section appendix 
methods extensions basic method vapnik chervonenkis method valued functions notion vc dimension seen applications machine learning 
results pseudo dimension derived appendix get result 
denotes pseudo dimension 
theorem family functions 
assume 

dim dl em em ln proof 
probability measure theorems sections appendix em em ln theorem applied 
gives follows easily 
general case apply methods previous section addition pseudo dimension methods section obtain bounds 
illustrate case class decision rules represented feedforward neural network 
feedforward neural network de ned directed acyclic graph incoming edges node unit ordered incoming edge carry real number representing activation edge 
assume activations restricted interval constants 
units divided input units incoming edges units serve input ports network activations determined external inputs computation units incoming edges units compute activation activations incoming edges 
activation determined activation placed outgoing edges unit 
computation units outgoing edges called output units serve output ports network 
computation units output units called hidden units 
network computes function maps vectors activation values input units vectors activation values output units composing functions computed computation units obvious way 
action computation unit incoming edges speci ed function resulting activation unit activations incoming edges vector nets consider function de ned kx wj wj adjustable real weights adjustable real bias xed real valued functions call input transformers xed function call global modi er xed non increasing non decreasing function function 
di erent units di erent modi ers transformers squashing functions 
say function computed computation unit incoming edges lipschitz bound jf bd 
give examples illustrate exibility ofthis model level individual computation unit 
assume number input transformers number inputs input transformer simply extracts component input xj case isthe standard case neural net research input transformation just identity map ignored 
standard case global modi er get known quasi linear unit standard case kx get unit computes function form nx xj aj aj wj pn similar called radial basis unit neural net literature 
assume input transformers take logs components inputs 
assume 
change squashing function 
nx giving commonly known product unit 
de ne feedforward architecture feedforward net unspeci ed weights biases ny wj computation unit xed global modi er xed squashing function xed input transformers variable weights variable bias 
say unit depth architecture longest directed path input unit unit edges 
input units depth computation units incoming edges input units depth computation units incoming edges input units computation units depth depth depth architecture depth deepest unit 
bound capacity decision rule space represented feedforward architecture follows 
theorem feedforward architecture input units output units depth 
total number adjustable weights biases assume bj functions representable setting adjustable weights biases lipschitz bounds functions computed computation units depth bj 
bl proof 
nj number units depth architecture lj nj ld nd xj lj de ne family hj functions xj xj manner 
assume enumeration computation units depth functions fi represented ui nj average lipschitz bound fis bj 
hj free product lj copies identity function 
hj xj xj 
function hj represents mapping sequence activations units depth sequence activations units depth activations depth unaltered new activations depth calculated family hj consists functions hj obtained manner varying weights biases units depth manner lipschitz constraint satis ed 
subsequent calculations performed longer need preserve activations shallower units 
omit identity function components hd hd 
de nition hd hj clear class statement theorem represented class compositions functions classes hd 
identity function bound bj lipschitz bound components function hj hj bj 
easily veri ed free product function lipschitz bounded lipschitz bounds component functions 
assumption bj uniform lipschitz bound hj aj bl aj 
metric xj 
lemma part dy hj hj contained free product lj function classes 
class product trivial class containing identity function nite dimensional vector space real valued functions summed xed modi er composed non increasing non decreasing squashing function 
case dimension vector space number free parameters associated corresponding computation unit number weights plus adjustable bias 
theorems section appendix pseudo dimension theorem ln xand 
capacity class function follows lemma part hj wj total number weights biases computation nodes depth multiplying bounds follows dy wj wj dy wj bl bl corollary bd theorem 
instance space space andy outcome space 
loss function cl cld probability distribution generated independent random draws 
pr rf cl bl 
assume computation unit depth number weights wmax weight allowed absolute value greater input transformers identity functions global modi er lipschitz bound squashing function lipschitz bound wmax 
probability sample size dlog wmax log proof 

veri ed lh permissible decision rule space theorem theorem pr rf cl cl bl second bound readily veri ed lipschitz bound linear function de ned wmax weights bias wmax times largest absolute value weight 
furthermore lipschitz bound sum functions sum lipschitz bounds individual functions lipschitz bound composition functions product lipschitz bounds individual functions 
input transformers identity functions global modi er squashing function lipschitz bounds respectively weight allowed absolute value greater lipschitz bound computation unit wmax 
holds units depth may take bj wmax rst bound 
solving order magnitude estimate second bound 
give constants upper bound part theorem show large 
mean suggest bound tight 
verify asymptotic bound part tight 
particular show dependence lipschitz bounds necessary 
evidence may necessary comes analysis case squashing function sharp threshold function 
sign 
corollary apply case jump prevents obtaining lipschitz bound computation units 
smooth approach sign function slope increases limit bound corollary degenerates 
techniques shown results similar corollary hold case lipschitz bounds required bound sample size log log total number computation units net 
details 
despite uncertainty need lipschitz bounds result give indication maximum training sample size needed popular network con gurations 
example squashing function chosen temperature shown lipschitz bound modi er 
case term dlog wmax bound corollary dlog wmax 
maximum weight temperature depth constants asymptotic bound theorem log similar bound obtained 
noted corollary feature lipschitz bounds required computation units depth 
computation units depth hidden units lipschitz units required 
architecture layer hidden units depth single output unit depth quite common lipschitz bounds required output unit 
means weights biases associated hidden units need bounded order get rates uniform convergence corollary example methods white chapter obtain result type 
example consider networks implement generalized radial basis func tions described 
networks layer hidden units depth output unit depth 
structure hidden units described example input transformers identity functions modi er squashing function usually smooth decreasing function 
output unit simply computes weighted sum unit modi er function squashing function identity 
unit depth require lipschitz bound unit 
bound maximum weight coming output unit wmax number units hidden layer term dlog wmax bound log wmax 
xing gives sample size bound similar obtained 
log appears dominant factor bounds apart accuracy parameters bounds support conventional wisdom training set size primarily related number adjustable parameters net 
support notion relationship appropriate training size number parameters nearly linear worst case 
needed sharpen relationships see lower computation units network radial basis functions described quite primitive adjustable multiplicative parameter included basic radial distance calculation 
parameters needed reasonable type kernel density estimation see 
parameters simulated inserting layer computation units inputs layer described 
alternately analysis done directly adjustable kernel units 
cleaner approach detailed 
bounds obtained 
extended pac learning model general decision theoretic framework addresses concerns raised machine learning practitioners introduced number new theoretical tools 
concentrate applications extended model problem obtaining upper bounds su cient training sample size 
required obtain lower bounds sample size needed determine computational complexity nding decision rules near minimal empirical risk 
promising results lines 
granting results obtained extended model number shortcomings form 
easily remedied may problematic 
de ne model xed decision rule space model extended learning problems sequence decision rule spaces fhn decision rule space attribute domain xn families decision rule spaces di erent complexities xed domain tradeo decision rule complexity empirical risk addressed 
extension easy involved 
approach problem vapnik principle structural risk minimization see 
approaches include mdl see regularization see general bayesian methods see 
second constants upper bounds large give sample size estimates useful practice 
may di cult improve point results directly usable applied 
matching asymptotic lower bounds practitioners may need rely part empirically derived sample size bounds 
possible bayesian viewpoint may yield better tools calculating sample complexities 
support belief 
necessary sample size estimates decision rule spaces general studied minimax perspective uniform convergence tackled bayesian perspective 
vapnik gives alternative related approach chapter 
issues need considered complete treatment problem tting including distribution speci bounds sample complexity theorem distribution speci random covering numbers distribution speci apply distribution independent setting decision rule spaces nite pseudo metric dimensions include various classes smooth functions relatives see chapter non sources examples see white chapter 
despite shortcomings feel theory give provides useful insights nature problem tting learning generality useful starting point research 
iwould dana angluin david pollard phil long careful criticisms earlier draft numerous suggestions improvements 
naoki abe blumer richard dudley michael kearns helpful comments earlier drafts 
iwould ron rivest david rumelhart andrzej ehrenfeucht nick littlestone stimulating discussions topics 
appendix metric spaces covering numbers metric dimension pseudo metric set function symmetry triangle inequality 
addition metric 
pseudo metric space 
complete cauchy sequence points converges point separable contains countable dense subset countable subset exists called discrete metric 
diameter supf tg 
diameter nite say bounded 
cover nite set necessarily contained nite cover totally bounded 
note implies separable bounded 
case function denotes size smallest cover space pseudo metric 
refer number 
set separated distinct denote size largest separated subset refer number 
third argument ton omitted metric clear context 
inequalities easily veri ed see theorem totally bounded subset pseudo metric space measures boundedness covering number packing number equivalent factor de ne upper metric dimension pseudo metric space dim logn log lower metric dimension denoted dim pseudo metric space de ned similarly 
dim dim quantity denoted dim referred simply metric dimension 
quantity called fractal dimension capacity dimension 
avery lucid intuitive treatment isgiven 
pseudo dimension classes real valued functions section look way bounds covering numbers appearing theorem obtained 
technique due pollard extended methods certain intuitions combinatorial geometry 
generalizes techniques vapnik chervonenkis dimension apply valued functions 
establishing basic notation 
de nition sign sign 
xd sign sign sign xd sign tg 
boolean vector bd fx sign bg called orthant somewhat arbitrarily included points value zero particular coordinate associated lower orthant 
sign denotes set intersected lett fy tg translation obtained adding vector say full exists sign exists translation intersects result known proved variety ways 
example follows easily known bounds number cells arrangements hyperplanes see 
give elementary proof technique 
lemma hyperplane intersects proof 
hyperplane choose vector follows 
includes origin vector orthogonal strictly negative coordinate 
nonzero orthogonal vector doesn negative coordinate 
nonzero vector line perpendicular passes origin 
complete proof show sign sign denotes vector 
suppose contrary sign sign implies inner product non positive fact strictly negative contain strictly negative coordinate 
choice orthogonal contains strictly negative coordinate giving immediate contradiction non zero orthogonal case dx contradiction left side non positive right side strictly positive 
follows lemma contained hyperplane full 
de nition family functions set 
sequence zd points jz zd fg 
jz full say shattered pseudo dimension denoted largest exists sequence points shattered arbitrarily long nite sequences shattered nite 
clear set valued functions sequence points jz full jz case length longest dx sequence points thatf jz de nition vapnik chervonenkis di class valued functions 
pseudo dimension generalizes vapnik chervonenkis dimension arbitrary classes real valued functions 
pseudo dimension generalizes algebraic notion dimension vector space real valued functions 
theorem dudley dimensional vector space functions set 
proof 
fix sequence zd points zd 
linear mapping image jz vector space dimension implies jz subspace dimension lemma jz full 
implies hand dimensional vector space real valued functions exists sequence points jz shattered implying ways vc dimension generalized real valued functions see vapnik chapter 
dudley compares tions albeit di erent context 
generalization wehave proposed pseudo dimension minor variant notion pollard de ne classes real valued functions polynomial discrimination called vc subgraph classes 
pseudo dimension form de ned new book 
pseudo dimension invariance properties useful see results type 
theorem family functions 
fix function fg fg 
real interval possibly function takes values fix nondecreasing resp 
nonincreasing function fh fg indicates function composition 


continuous strictly increasing resp 
continuous strictly decreasing 
proof 
part follows directly fact notion set points full invariant translation 
part su ces prove results nondecreasing continuous strictly increasing 
zd jz full jz intersects vector xd boolean vector exists function zi xi th bit 
ui minff zi th bit bis li zi th bit bis nondecreasing wehave ui li ri ui li foreach rd 
ff clearly intersects orthant full 
implies jz full 
equality follows continuous strictly increasing obtain class composing putting probability measure view class real valued functions pseudo metric space 
distance functions integral absolute value di erence distance relative measure 
need assumptions integrability functions measure 
concerned families functions values bounded range cause problems 
convenience choose range 
general treatment see 
de nition class functions andp measure pseudo metric de ned jf gj jf techniques go back dudley pollard obtained beautiful theorem bounding metric dimension probability measure result stronger gives explicit bounds packing numbers balls radius packing numbers closely related covering numbers theorem section bounds theorem obtain uniform convergence results empirical estimates functions state result lemma special case class functions values interval somewhat better bounds packing numbers 
theorem pollard family functions set 
measure em em ln proof uses essentially techniques pollard 
results uniform convergence section 
theorem family functions set 
assume 
generated independent draws distribution pr ez em em ln em ln probability proof 

sequence points trivial isometry jz pz pz empirical measure induced set measure equal fraction points contains 
theorem section theorem dl dl em em ln probability theorem 
em em ln em em ln second result setting bound equal solving gives em ln em ln better bounds logarithmic factor theorem quoted 
easily veri ed ln ln bound second result follows 
corollary assumptions pr jb ez em em ln em ln probability proof 
follows directly result setting property metric proof corollary section 
abe warmuth 
computational complexity distributions probabilistic automata 
proceedings nd workshop computational learning theory pages 
published morgan kaufmann 
alexander 
rates growth weighted empirical processes 
proc 
berkeley con ference honor jerzy neyman jack kiefer volume pages 
alexander 
rates growth sample moduli weighted empirical processes indexed sets 
probability theory related fields 
amsterdam 
valiant learning model extensions assessment 
master thesis mit department electrical engineering computer science jan 
angluin 
learning regular sets queries counterexamples 
information com putation nov 
angluin 
queries concept learning 
machine learning 
angluin frazier pitt 
learning conjunctions horn clauses 
th annual ieee symposium foundations computer science pages 
angluin hellerstein karpinski 
learning read formulas queries 
acm 
angluin 
won membership queries help 
proceedings rd annual acm symposium theory computing pages new orleans may 
acm 
angluin laird 
learning noisy examples 
machine learning 
angluin valiant 
fast probabilistic algorithms hamiltonian circuits matchings 
journal computer system sciences apr 
anthony biggs 
computational learning theory 
cambridge tracts theoretical computer science 
cambridge university press 
barron 
statistical properties arti cial neural networks 
th conference control pages 
barron cover 
minimum complexity density estimation 
ieee transactions information theory 
barto anandan 
pattern recognizing stochastic learning automata 
ieee trans 
systems man cybernetics 
baum 
nearest neighbor back propogation accurate feasible sized sets examples 
snowbird conference neural networks computing 
unpublished manuscript 
baum haussler 
size net gives valid generalization 
neural computation 
itai 
learnability xed distributions 
proc 
workshop comp 
learning theory pages san mateo ca 
morgan kaufmann 
bergadano saitta 
error boolean concept descriptions 
proceedings european working session learning pages 
berger 
statistical decision theory bayesian analysis 
springer verlag new york 
billingsley 
probability measure 
wiley newyork 
blum rivest 
training neuron neural net np complete 
proceedings workshop computational learning theory pages san mateo ca 
published morgan kaufmann 
blumer ehrenfeucht haussler warmuth 
occam razor 
information processing letters 
blumer ehrenfeucht haussler warmuth 
learnability vapnik chervonenkis dimension 
journal association computing machinery 
breiman friedman olshen stone 
classi cation regression trees 
wadsworth international group 
buntine 
learning classi cation rules 
phd thesis sydney 
buntine weigend 
bayesian back propagation 
complex systems 
clarke barron 
entropy risk bayesian central limit theorem 
manuscript 
clarke barron 
information theoretic asymptotics bayes methods 
ieee trans actions information theory 
cover 
geometrical statistical properties systems linear inequalities applications pattern recognition 
ieee trans 
electronic computers ec 
cover 
capacity problems linear machines 
kanal editor pattern recognition pages 
thompson books 
denker schwartz solla howard jackel hop eld 
automatic learning rule extraction generalization 
complex syst 
devroye 
automatic pattern recognition study probability error 
ieee trans 
pattern anal 
mach 
intelligence 
duda hart 
pattern classi cation scene analysis 
wiley 
dudley 
central limit theorems empirical measures 
ann 
prob 
dudley 
course empirical processes 
lecture notes mathematics 
dudley 
universal classes metric entropy 
ann 
prob 
durbin rumelhart 
product units powerful biologically plausible extension networks 
neural computation 
edelsbrunner 
algorithms combinatorial geometry 
springer verlag 
ehrenfeucht haussler kearns valiant 
general lower bound number examples needed learning 
information computation 
farmer 
information dimension probabilistic structure chaos 


farmer ott 
dimension chaotic attractors 
physica 
ferguson 
mathematical statistics theoretic approach 
academic press 
case editors 
proceedings workshop computational learning theory 
morgan kaufmann san mateo ca 
goldreich goldwasser micali 
construct random functions 
acm 
gullapalli 
stochastic reinforcement learning real valued functions 
neural networks 
tishby 
statistical theory learning rule 
editors neural networks spin glasses 
world scienti 

linear function neurons structure training 
biol 
cybern 
haussler 
quantifying ai learning algorithms valiant learning frame 
arti cial intelligence 
haussler 
learning conjunctive concepts structural domains 
machine learning 
haussler 
decision theoretic generalizations pac learning model 
proc 
workshop algorithmic learning theory pages japan 
haussler 
probably approximately correct learning 
proc 
th national conference arti cial intelligence pages 
morgan kaufmann 
haussler 
sphere packing numbers subsets boolean cube bounded vapnik chervonenkis dimension 
technical report ucsc crl university calif computer research laboratory santa cruz ca 
appear journal combinatorial theory haussler 
decision theoretic generalizations pac model neural net learning applications 
information computation september 
haussler kearns littlestone warmuth 
equivalence models polynomial learnability 
information computation 
haussler kearns schapire 
bounds sample complexity bayesian learning information theory vc dimension 
machine learning 
haussler littlestone warmuth 
predicting functions randomly drawn points 
technical report ucsc crl university california santa cruz computer research laboratory dec 
appear information computation 
haussler pitt editors 
proceedings workshop computational learn ing theory 
morgan kaufmann san mateo ca 
haussler welzl 
epsilon nets simplex range queries 
disc 
comp 
geometry 
helmbold long 
tracking drifting concepts random examples 
proceedings workshop computational learning theory pages san mateo ca august 
morgan kaufmann 
helmbold sloan warmuth 
learning nested di erences intersection closed concept classes 
machine learning 
kearns li 
learning presence malicious errors 
th acm symposium theory computing pages chicago 
kearns li pitt valiant 
learnability formulae 
th acm symposium theory computing pages new york 
kearns li pitt valiant 
learnability boolean formulae 
proceedings nineteenth annual acm symposium pages new york new york may 
kearns valiant 
cryptographic limitations learning boolean formulae nite automata 
st acm symposium theory computing pages seattle wa 
kearns schapire 
cient distribution free learning probabilistic concepts 
st annual symposium foundations computer science pages 
kiefer 
statistical inference 
springer verlag 
kolmogorov 
entropy capacity sets functional spaces 
amer 
math 
soc 
translations ser 

kuh petsche rivest 
mistake bounds incremental learners concepts drift applications feedforward networks 
nips 
morgan kaufmann 
kulkarni 
metric vapnik chervonenkis dimension learnability class distributions 
technical report lids center intelligent control systems mit 
kullback 
information theory statistics 
wiley newyork 
lecun denker solla 
optimal brain damage 
editor advances neural information processing systems volume page 
morgan kaufmann 
levin 
way functions pseudorandom generators 
combinatorica 
lindley 
position bayesian statistics 
statistical science 
mansour rivest 
results learnability vapnik chervonenkis dimension 
proceedings workshop computational learning theory pages san mateo ca 
published morgan kaufmann 
littlestone :10.1.1.130.9013
learning quickly irrelevant attributes abound new linear threshold algorithm 
machine learning 
littlestone 
line batch learning 
proceedings second annual workshop computational learning theory pages 
morgan kaufmann 
littlestone 
mistake bounds logarithmic linear threshold learning algorithms 
phd thesis university california santa cruz 
littlestone long warmuth 
line learning linear functions 
technical report ucsc crl uc santa cruz october 
extended see pro ceedings third annual acm symposium theory computing new louisiana may pages 
littlestone warmuth 
weighted majority algorithm 
information computation 
long warmuth 
composite geometric concepts polynomial learnability 
information computation 
appear 
mackay 
bayesian methods adaptive models 
phd thesis california institute technology 
mandelbrot 
fractal geometry nature 
freeman 
mccullagh nelder 
generalized linear models 
chapman hall london 
mitchell 
need biases learning generalizations 
technical report cbm tr rutgers university new brunswick nj 
moody darken 
fast learning networks locally tuned processing units 
neural computation 
narendra 
learning automata 
prentice hall 
natarajan 
learning classes distributions 
proceedings workshop computational learning theory pages san mateo ca 
published morgan kaufmann 
natarajan 
learning sets functions 
machine learning 
natarajan 
probably approximate learning classes distributions 
technical report hpl sal hewlett packard labs palo alto ca 
natarajan 
results learning 
technical report cmu ri tr carnegie mellon 
natarajan tadepalli 
new frameworks learning 
proceedings th international conference machine learning pages san mateo ca 
published morgan kaufmann 
nobel dembo 
uniform convergence dependent processes 
technical re port stanford university dept statistics stanford ca 
nolan pollard 
processes rates convergence 
annals statistics 
nowlan 
maximum likelihood competitive learning 
editor advances neural information processing systems volume pages 
morgan kaufmann 
nowlan hinton 
soft weight sharing 
technical report dept comp 
sci toronto 
opper haussler 
calculation learning curve optimal classi cation algorithm learning perceptron noise 
computational learning theory proceed ings fourth annual workshop pages 
morgan kaufmann 
opper haussler 
generalization performance bayes optimal classi cation algo rithm learning perceptron 
physical review letters may 
pearl 
connection complexity credibility inferred models 
journal general systems 
pitt 
inductive inference dfas computational 
inproceedings aii workshop analogical infer ence lecture notes arti cial intelligence pages heidelberg october 
springer verlag 
pitt valiant 
computational limitations learning examples 
acm 
warmuth 
prediction preserving reducibility 
comp 
sys 
sci december 
special issue third annual conference structure complexity theory washington dc june 
poggio girosi 
theory networks approximation learning 
technical report memo massachusetts institute technology cambridge ma 
pollard 
convergence stochastic processes 
springer verlag 
pollard 
rates uniform sure convergence empirical processes indexed unbounded classes functions 
manuscript 
pollard 
empirical processes theory applications volume nsf cbms regional conference series probability statistics 
institute math 
stat 
am 
stat 
assoc 

metric entropy learnability 
unpublished manuscript universidad simon 
renyi 
probability theory 
north holland amsterdam 
rissanen 
stochastic complexity modeling 
annals statistics 
rivest haussler warmuth editors 
proceedings workshop computational learning theory 
morgan kaufmann san mateo ca 
rivest 
learning decision lists 
machine learning 
rumelhart 
personal communication 
rumelhart mcclelland 
parallel distributed processing explorations microstructure cognition 
volume foundations 
mit press cambridge mass 
pazzani 
average case analysis empirical explanation learning algorithms 
machine learning 

learning dnf noise attributes 
proceedings workshop computational learning theory pages san mateo ca 
published morgan kaufmann 
sloan 
types noise data concept learning 
proc 
workshop comp 
learning theory pages san mateo ca 
morgan kaufmann 
sompolinsky tishby seung 
learning examples large neural networks 
physical review letters 
cormen rivest 
algorithms 
mit press 
talagrand 
sharper bounds gaussian empirical processes 
annals probability 
tesauro cohn 
neural networks better vapnik chervonenkis bounds 
lippmann moody touretzky editors advances neural infor mation processing vol 
pages 
morgan kaufmann 
tishby levin solla 
consistent inference probabilities layered networks predictions generalizations 
ijcnn international joint conference neural net works volume ii pages 
ieee 

advances neural information processing systems volume 
morgan mann 

advances neural information processing systems volume 
morgan mann 
valiant 
theory learnable 
communications acm nov 
valiant 
learning disjunctions conjunctions 
proc 
th ijcai volume pages los angeles august 
valiant warmuth editors 
proceedings workshop computational learning theory 
morgan kaufmann san mateo ca 
vapnik chervonenkis 
uniform convergence relative frequencies events probabilities 
theory probability applications xvi 
vapnik 
estimation dependences empirical data 
springer verlag 
vapnik 
inductive principles search empirical dependences methods weak convergence probability measures 
proceedings nd workshop com putational learning theory san mateo ca 
published morgan kaufmann 
vapnik chervonenkis 
uniform convergence relative frequencies events probabilities 
theory probability applications 
venkatesh 
learning binary weights majority functions 
computational learning theory proceedings fourth annual workshop pages 
morgan kaufmann 
vovk 
aggregating strategies 
proceedings nd workshop computational learning theory pages 
published morgan kaufmann 
weigend huberman rumelhart 
predicting connectionist ap proach 
international journal neural systems 
weiss kulikowski 
computer systems learn 
morgan kaufmann san mateo ca 
welzl 
partition trees triangle counting range search problems 
th acm symp 
comp 
geometry pages urbana il 
dudley 
special vapnik chervonenkis classes 
discrete mathematics 
white 
connectionist nonparametric regression multilayer feedforward networks learn arbitrary mappings 
neural networks 
white 
learning arti cial neural networks statistical perspective 
neural computa tion 
yamanishi 
learning criterion stochastic rules 
proceedings nd workshop computational learning theory pages 
published morgan kaufmann 
yamanishi 
learning criterion stochastic rules 
machine learning 
special issue proceedings nd workshop computational learning theory appear 

