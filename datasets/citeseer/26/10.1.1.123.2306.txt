time lined tcp tcp friendly delivery streaming media mukherjee tim department computer science university waterloo waterloo ontario canada 
uwaterloo ca cs uwaterloo ca introduces time lined tcp tltcp 
tltcp protocol designed provide tcp friendly delivery data applications loss tolerant streaming media players 
previous unicast delivery streaming media internet proposes udp performs congestion control user level regulating application sending rate attempting mimic behavior tcp order tcp friendly 
tltcp hand intended implemented transport level tcp modifications support time lines 
treating data byte stream tltcp allows application associate data deadlines 
tltcp sends data similar fashion tcp deadline section data elapsed point obsolete data discarded favor new data 
result tltcp supports tcp friendly delivery streaming media retaining tcp congestion control functionality 
describe api tltcp involves augmenting socket calls 
describe streaming media applications various encoding schemes mpeg associate data deadlines tltcp api 
simulations examine behavior tltcp wide range networks workloads 
find performs data delivery circumstances bandwidth shared equally competing tltcp tcp flows 
scenarios tltcp unfriendly tcp flows competing tcp flows share bandwidth 

widely believed congestion control mechanisms critical stable functioning internet 
presently vast majority internet traffic uses appears proceedings international conference network protocols icnp osaka japan pp 
november tcp protocol incorporates congestion control 
due growing popularity streaming media applications tcp suitable delivery data growing number applications implemented udp 
udp implement congestion control protocols applications implemented udp detect react congestion network 
ideally fashion ensures fairness competing existing internet traffic tcp friendly 
applications may obtain larger portions available bandwidth tcp applications 
wide spread protocols implement congestion control avoidance mechanisms result congestive collapse internet similar collapse occurred october 
described motivated concerns 
perspective application need protocol designed transporting data deadlines network provides quality service qos guarantees 
perspective network need protocol generates streams compete fairly existing traffic performs congestion control robust mechanisms 
created new protocol called time lined tcp tltcp designed support tcp friendly delivery time sensitive data internet 
contributions created new transport protocol called time lined tcp tltcp delivering time sensitive data internet 
devised way tltcp robust window congestion control tcp requiring data delivered reliably 
result tltcp competes fairly tcp flows tcp friendly wide range network conditions 
tltcp associates section data deadline uses novel time lined data delivery mechanism tltcp uses deadlines keep track sections data obsolete ensures obsolete data sent 
tltcp provides interface suited continuous media applications simple byte stream 
propose augmenting socket api allows sending application specify deadline handing section data tltcp 
api allows tltcp inform receiving application gaps data delivered 
proposed changes alter extend semantics socket api 
performed extensive simulation experiments evaluate tltcp 
experiments show tltcp performs data delivery time lined fashion 
furthermore data simulations quantified effect tltcp flows competing tcp flows 
simulation results show tltcp tcp friendly wide range network conditions 
addition circumstances tltcp tcp unfriendly tcp unable share bandwidth 
remainder organized follows 
section describe related section explain approach problem 
section describes protocol conjunction streaming media applications 
tltcp protocol operates described section 
report results simulation experiments ns network simulator section 
followed section 
related previous examined rate algorithms implementing tcp friendly congestion control 
case sender rate injects packets network order perform congestion control 
compete fairly tcp sending rate regulated attempting achieve throughput tcp stream operating conditions 
approaches models attempt characterize tcp congestion control mechanisms 
data sent application measures estimates values parameters model packet loss rates round trip times timeout values 
parameters model application periodically recomputes appropriate sending rate 
proposed schemes differ primarily complexity accuracy model 
rap employs relatively simple additive increase multiplicative decrease aimd model tcp congestion control mechanisms able obtain relatively tcp friendly behavior competing bandwidth tcp sack flows 
targeted internet scenarios tcp sack red widely deployed able share bandwidth fairly common implementations tcp tcp tahoe tcp reno 
significant advantage tltcp tcp friendly tcp reno implementations widely tcp implementation internet today 
propose rate equation designed rtp rtcp 
scheme dynamically computes additive increase rate performs backoff 
experiments conducted red gateways reported show scheme share bandwidth equally situations low loss rates 
expect tltcp stable share bandwidth equally conditions low loss rates 
padhye describe evaluate rate control proto col detailed model tcp throughput 
able show protocol tcp friendly variety network configurations conditions recomputation interval time rate adjustments chosen carefully 
seen simulation results best recomputation interval may vary different network conditions making difficult recomputation strategy variety circumstances 
point share bandwidth fairly tcp streams bottleneck link delays small large difficult obtain accurate estimates loss rates 
ramesh describe number potential drawbacks model approaches 
particular point factors result inaccurate packet loss estimates model developed padhye 
inaccurate estimates lead allocation bandwidth non tcp flows 
tltcp model ack clocked impacted drawbacks 
cen describe streaming control protocol scp uses congestion window policy congestion avoidance 
approach similar tcp perform retransmission faithful tcp order improve smoothness streaming 
experimental results reported implementation scp top udp show packet rates competing scp tcp sessions differ significantly variety network configurations 
scheme reported jacobs attempts mimic tcp congestion window user space :10.1.1.31.4078
window size estimate bandwidth drive media pump sender uses udp send data receiver 
attempting mimic congestion window tcp user level inaccurate 
fact message written udp socket mean packet released network 
mechanism user space means knowing message waiting kernel buffers traversing link 
tltcp media pump regulate data sends uses sliding window protocol tcp 
tltcp udp meant implemented kernel making changes tcp stack 
furthermore schemes proposed past tltcp uses time lined nature continuous media drive data sends 
details scheme proposed jacobs provided unclear tcp friendly approach :10.1.1.31.4078

proposed approach previous approach models tcp 
propose new protocol called time lined tcp tltcp intended implemented transport level tcp modifications support time lines 
time lines delivery time sensitive data applications streaming media players 
applications time sensitive data arrives deadline meant played useful simply ignored 
tcp ensure application tcp friendly tcp unsuitable data transfer potentially send obsolete data longer useful receiving application 
tltcp addition specifying data size application includes deadline transport protocol trying send data 
tltcp attempts send data deadline expired point presumed data obsolete time reach receiver 
deadline expired tltcp abandons obsolete data favor new data associated deadlines 
note deadlines defined relative sender 
best effort service scheme easily extended deadlines relative receiver factoring rtt estimates deadlines 
tltcp intended implemented transport level kernel 
tltcp ack clocked able mimic behavior tcp wide range conditions 
tcp continues evolve believe relatively easy implement version protocol 
expect relatively difficult produce accurate models develop protocols variation modification tcp 

applications continuous media application uses tltcp expected handle encoding scheme specific functions relying tltcp perform congestion control best effort data delivery 
sending application typically calculate schedule transmission data 
section data sent sequence video frames layers video audio samples assigned deadline determined schedule account buffering delay characteristics encoding decoding schemes 
receiver application playback receiving buffering portion data 
playback portions data decoded user 
sender able send portions section deadline associated section expires receiver may able continue lower quality playback depending application ability tolerate lost data 
example mpeg video frames varying degrees importance playback application respectively 
roughly speaking frames displayed independently frames displayed previous frames arrived 
frames bidirectionally encoded displayed previous encoded frame encoded frame delivered 
bidirectional dependencies display order frames differs order stored file transported 
instance display order mpeg video may der sequence stored mpeg file tltcp sections created mpeg file order stored deadlines assigned order display 
deadline assigned frame frames directly dependent frame frames dependent frames depend frame 
frames assigned deadlines earlier frames depend sent frames depend 
example deadline assign ments follows 
sending ap plication start writing encoded frames socket described tltcp try deliver sections order written 
available bandwidth insufficient deliver section tltcp may discard expiry start sending important frame associated deadline words bandwidth insufficient tltcp discard important data attempt deliver important data chance reaching receiver time playback 
note available bandwidth decreases due congestion sending application receiving feedback playback application may decide change transmission schedule just send frames just frames important frames time get delivered 
reusing example data sections handed tltcp reduced bandwidth cases described look respectively 
mpeg receiver hand able continue playback quality playback worsen frames skipped 
api api tltcp main functions 
sending application needs able specify tltcp segments data associated deadlines 
second receiving needs able deliver client application received data information gaps located 
propose augmenting unix socket calls sendmsg purpose 
see api consider example 
server process creates sock stream socket connects receiver establish data connection 
various fields msg header structure filled calling sendmsg msg tl flag indicate time lined data 
pointers data sections sent tltcp stored array msg structures 
pointer data base size data len 
size msg array equal number sections written stored msg field header 
deadlines corresponding data sections provided ancillary data message 
value deadlines stored control field header message type type specified tl deadline 
len equal number data sections 
receiver called tl flag indicates data received time lined 
receiver read ancillary data pointed control order distinguish data gaps 
field ancillary data data corresponding field msg structure points valid data application store pointer order retrieve data 
hand ancillary data contains tl gap application needs note size location gap take account playback 

functioning tltcp discussed previously additional mechanisms support time lines functionality data sending characteristics tltcp similar tcp 
description tltcp tcp reno 
assume reader familiar tcp reno tcp refer tcp reno 
sender tltcp sender accepts time sensitive data application tltcp api 
section data associated deadline sent 
sender maintains linked list called time line list stores deadlines time lined data 
node list stores deadline starting sequence number associated section data 
note data stored kernel buffers tcp lowest seqno field list node points data byte section buffer 
sender performs data sends normal tcp sender expiry lifetime timer indicates deadline current section data expired 
selects section data sent list sets lifetime timer deadline section 
data lowest sequence number new section data discarded 
lifetime timer addition tcp timers tltcp timer called lifetime timer 
new timer keeps track deadlines associated oldest data sending window minimum receiver advertised window congestion window 
lifetime timer counts fashion tcp timers 
lifetime timer expires data associated deadline sent considered obsolete discarded sending window 
words response deadline expiry sending window moved forward sequence numbers obsolete 
tltcp attempts send data associated deadline lifetime timer set deadline 
furthermore expiry lifetime timer time line list updated contain entries data sections obsolete 
shows sequence actions taken expiry lifetime timer 
due expiry deadlines data sections may delivered completely leaving gaps sequence bytes delivered receiver 
consider example illustrates tltcp sender transports continuous media data receiver 
suppose sender send window size bytes 
simplicity assume single byte payload packets 
sender send lifetime tmr expired rem expired data timeline list buf timeline list empty cur node get cur node timeline list store seq move window cur node lowest seq set lifetime tmr cur node deadline 
pseudo code actions taken expiry lifetime timer 
consecutive packets 
assume application specified deadlines sequence numbers respectively deadline packets expire deadline packets 
tltcp sets lifetime timer deadline commences sending 
suppose deadline expires packets sent 
point tltcp abandon sending sequences packet send 
set lifetime timer continue keep track unacknowledged packets obsolete data 
done order preserve semantics congestion window mechanism detailed explanation see section 
receiver expiration lifetime timer sender discards data associated current deadline sent 
receiver informed consider discarded data lost reject packets new section receive window 
receiver continue acknowledge received sequence number obsolete 
hand sender discarded obsolete data continue send current data deadlock result 
order prevent deadlock data discarded tltcp sender explicitly notifies receiver change expected sequence number 
expected sequence number update notifications allow receiver keep track gaps stream 
information gaps located data eventually passed application attempts read data 
expected sequence number notifications included packet bits available tcp options 
call bit field seq update 
receiver knows needs skip sequence numbers receives packet containing seq update value greater expected sequence number adjusts expected sequence number sequence number contained update 
acks obsolete data sender needs keep track acknowledgments obsolete data order ensure send window correctly sized permitted advance acks arrive obsolete data 
reconsider example described section deadline expires packets sent 
point tltcp keeps track fact receive acks packets removes packets buffer 
sender continues sending data associated deadline packets sent send window full 
window full data sent outstanding acks arrive 
way logically view current situation imagine obsolete data occupying slots current send window 
send window thought acks obsolete data arrive sender window moved amount data acked allowing new sends 
example ack received sequence number window move ahead sequence numbers acks cumulative sender may send new packets 
keeping track acks obsolete data necessary acks allow window move forward 
example logical window moves forward receipt ack sequence number 
order recognize acks obsolete data tltcp uses vector store highest ack received obsolete section unacknowledged data 
size vector bounded window size 
acks obsolete data arrive entries vector freed obsolete new entries added 
note tltcp keeps track sequence numbers unacknowledged data obsolete sends data new sections retransmitting obsolete data 
handling lost packets lost packet detected prior deadline expiry data tltcp retransmit lost packet 
tltcp attempts reliably deliver data prior expiry deadline associated data 
hand lost packet obsolete tltcp sends lowest unacknowledged packet current 
similar actions taken tcp tltcp transmit current data retransmit possibly obsolete data case tcp 
clarify works reconsider example suppose window size 
assume packets sent due deadline expiry packets deemed obsolete 
imagine packet lost detected sender duplicate acks retransmit timeout 
tltcp sender send unacknowledged packet case 
may result behavior close identical tcp 
order illustrate scenario compare actions tltcp take tcp conditions 
scenario depicted 
time packet sent tltcp behaves tcp 
say tltcp behaves tcp mean sends packet tcp 
sequence number data sent may different case 
case tltcp packet sent ack sequence number lost case tcp packet tcp resends ack lost tltcp ack arrive time tcp ack 
acks clock subsequent sends time tcp tltcp sender tcp sender tltcp obsolete data ack ack deadline expiry loss detected current data transmitted ack ack 
example loss obsolete data 
shown packet sent window size greater ack received tltcp sends 
refer pseudo retransmission tltcp retransmitting data may require retransmission order ensure packet sent tcp send packet 
ack original send packet arrives prior ack ack clock tltcp subsequent send sooner clocked tcp 
sender tcp sender tltcp ack ack ack loss detected send tcps send pseudo retransmit ack ack ack 
example 
deviation behavior tcp may occur pseudo retransmissions update message 
loss obsolete packet triggering pseudo retransmission cause subsequent losses obsolete packets ignored shown 
suppose original example section packet lost addition packet 
scenario tcp retransmit lost packet reduce rate sending result duplicate acks reducing congestion window due timeout 
tltcp pseudo retransmission include sender tcp sender tltcp resend lost packet ack resend lost packet detected tcp detects loss tltcp misses current data ack normal sends continue 
example tltcp missing packet loss obsolete data 
seq update cause receiver move receive window packets request packets missing fact packet lost 
general packet loss detected update received receiver receiver ignore missing data request update onwards 
consequence shown example tltcp unable detect loss packets subsequent pseudo retransmission experience second slowdown 

simulations section evaluate behavior tltcp simulations 
reasons simulation experiments suitable live internet experiments purposes 
order quantify tltcp tcp friendliness need measure effect tltcp traffic tcp streams discounting impact factors background traffic 
live internet scenario factors control cases add significant noise experimental results simulations impact due factors eliminated factored results 
furthermore measurements obtained baseline case control experiment meaningful experiments run conditions original experiment 
conditions simulation reproducible baseline experiments run valid measurements comparison easily obtained 
tltcp new protocol order test thoroughly need vary network parameters controlled fashion 
simulations able study effect varying parameters wide range time order quantify effect 
live internet experiment network parameters number flows competing bottleneck control link delays bottleneck bandwidth difficult vary 
implemented tltcp ns simulator conducted experiments study tltcp time lined data transport behavior quantify tcp friendliness 
time lined data transfer simulated network shown simultaneous data transfer sessions tcp sender receiver tltcp sender receiver 
keep track packet arrivals streams order compare data sending characteristics 
sake clarity constant sized data sections bytes associated constant deadlines second ensure section delivered deadline 
parameters simulation shown table justification values provided section 
sequence number sequence number plots tltcp tcp time seconds 
data sending characteristics tltcp compared tcp 
shown plot sequence number verses time sequence number represents byte data packet 
seen case tltcp flow data sent sequentially duration second deadline set sections data 
deadline visible jump sequence number multiple sequential sending resumes second 
note slopes continuous sections tltcp plot tcp plot 
fact lines coincident discontinuities tltcp trace masked 
observed discontinuities sequence number tltcp stream stems fact expiry deadlines tltcp stops sending data expired section starts sending new section data 
new sections data experiment sequence numbers multiples indicating tltcp starting send new section 
experiments pattern data sending observed tltcp 
inferred tltcp performs data transfer time lined manner 
fact slopes continuous sections tltcp packet trace tcp implies consume equal bandwidth 
seen graphs streams consume approximately half mbps bandwidth approximately packets bytes delivered seconds stream 
tcp friendliness studies tcp friendliness interpreted measured ability non tcp flows equally share bandwidth tcp flows 
typically measured observing throughput obtained flows tcp non tcp simultaneously operating bottleneck link determining bandwidth shares flow 
consider main metrics examining extent flows share bandwidth equally 
friendliness ratio ratio mean throughput observed non tcp flows tltcp flows case mean throughput obtained tcp flows friendliness ratio expose variations observed bandwidth individual flows consider ratio maximum observed bandwidth minimum observed bandwidth 
call separation index examine separation index flows experiment 
experiments tcp non tcp flows call measure experiments tcp flows call experiments total flows equal number competing tltcp tcp flows 
baseline comparison run experiments conditions flows tcp flows 
order produce metric similar tcp flows considered compute ratio mean throughput half tcp flows mean throughput half 
value vary depending flows chosen half 
compute consider extremes computes worst possible value ratio mean bandwidth bandwidth flows highest mean bandwidth lowest bandwidth flows hand computes best possible done sorting flows bandwidth dividing flows groups odd ranked ranked flows 
compute ratio maximum mean odd flows minimum mean odd flows tcp flows share bandwidth equally round trip times equal consider sources configured symmetrically shown delays streams equal 
experiments sender continuously sending data corresponding receiver 
choose initial set simulation parameters shown table representative internet traffic 
experiments consider impact changes parameters tcp friendliness tltcp 
bottleneck link bandwidth mbps representative link 
byte packet size common size packets seen internet 
maximum receiver window packets bytes near higher default values typical tcp implementations 
assume data transfers unidirectional set ack size bytes size tcp ack payload 
source destination hosts connect bottleneck link mbps link represents local area network 
previous simulation results suggest tcp share bandwidth evenly large number flows bottleneck router queue needs provisioned hold times packets number flows 
order ensure tcp shares bandwidth equally provision queue bottleneck router hold packets 
experiments run simulated time seconds data collection begins seconds avoid transient effects startup 
tltcp flows sections bytes deadlines sections set seconds 
corresponds maximum data rate mbps 
intentionally chosen high order thoroughly exercise time line specific mechanisms tltcp 
parameter value packet size bytes ack size bytes bottleneck link bw mbps bottleneck link delay ms router buffer size pkts source dest link bw mbps source dest link delay ms receiver max window size pkts simulated time sec size tltcp sections bytes deadlines tltcp sections sec total number flows table 
default simulation parameters 
senders receivers bottleneck link 
topology simulations 
varying number flows set experiments increase contention bottleneck increasing number competing flows order study resource sharing behavior tltcp flows 
seen figures range flows experiments tltcp obtains friendliness ratios separation indices total flows reached 
tltcp share bandwidth fairly point important notice baseline case tcp flows competing conditions share bandwidth fairly 
seen values close 
situation number tcp streams compete single bottleneck router studied previously morris 
observed large number competing flows tcp congestion control mechanisms fail ensure fair friendliness ratio best worst number flows 
varying flows friendliness ratios separation index mix tcp number flows 
varying flows separation indices sharing bottleneck bandwidth 
result high packet loss rates occur situation subsequent timeouts bandwidth obtained competing flows highly variable 
morris suggests number flows exceeds times queue size bottleneck router tcp share bandwidth equally 
experiments bottleneck buffer queue size fairness ratios separation indices close ideal value tcp tltcp flows 
total flows queue size packets flow flows tltcp tcp share bandwidth 
larger number flows tcp fairness notion tcp friendliness looses meaning 
consider larger number flows 
tltcp congestion control mechanisms tcp 
expected sharing behavior tltcp better tcp 
seen figures experiments mix tcp tltcp flows higher values friendliness ratio separation index observed compared baseline experiment just tcp flows 
experiments tltcp flows reduce data rates competing tcp flows congestion 
described section tltcp performs response loss obsolete data keep track subsequent losses obsolete data 
case competing flows due heavy contention bottleneck packet loss rates high data rates low result greater likelihood multiple losses obsolete data tltcp flows 
tltcp flows unable detect losses reduce sending rates congestion competing tcp flows obtaining larger share bandwidth 
examining individual flows observe simulation run fewer retransmissions tltcp flows competing tcp flows confirming tltcp flows packet losses reduce data rate competing tcp streams 
stated total flows remaining experiments 
ensures bottleneck router sufficient buffer space decreases likelihood tcp flows share bandwidth equally 
varying maximum window size section consider impact increasing maximum receiver window sizes tcp friendliness tltcp 
noted section scenarios cause behavior tltcp deviate tcp occur multiple packet losses obsolete data 
greater likelihood occurring larger window sizes possibility unacknowledged obsolete data case 
tcp tltcp large receiver windows increase possibility greater variations send window sizes competing flows 
figures show friendliness ratios separation indices respectively window sizes bytes respectively 
sizes chosen loosely correspond default window sizes commonly tcp implementations 
remaining values chosen significantly exceed commonly sizes 
results experiments demonstrate conditions simulations tltcp tcp share bandwidth fairly receiver window size ranges typically defaults current tcp implementations 
friendliness ratio best worst window size packets 
window tcp friendliness ratios maximum window size packets unequal sharing bandwidth 
experiment tcp flows window size friendliness ratio seen close separation index close 
instance separation index valuable metric uncovering 
seen friendliness ratios cases just tcp flows mix tltcp tcp flows improve considerably receiver window size increased 
friendliness ratios tcp cases separation index mix tcp window size packets 
window separation indices maximum window sizes close separation indices indicate disparities throughput individual streams 
observed results window size fairly similar 
unclear flows fair window size larger window size 
speculate increase window size larger window size may cause bandwidth sharing unequal sender congestion window flows varies minimum segment maximum receiver advertised window 
ideally flows equilibrium equal window sizes achieve throughput 
equilibrium reached congestion control mechanisms tcp tltcp keep changing size congestion window additively incrementing losses multiplicatively decrementing loss inferred 
additionally packets forwarded routers fifo discipline flow forwarding flows may experience bursty losses may experience losses 
flows experience losses reduce congestion window keep incrementing resulting disparity observed throughput 
large receiver window ones experiments increases disparity flows allows flows losses increase window size larger extent large receiver window limit 
believe reason results window sizes similar indicate increased friendliness trend unfairness self limiting 
point increasing receiver window size result appreciable difference friendliness metrics observed tcp tltcp 
reason cases flow able increase window limited size experiencing packet loss consequently reducing 
result flows able significantly increase sending windows sizes larger average experience packet losses reaching limit 
examining traces experiments find spite doubling maximum possible window size step average acquired window sizes flows experiments similar 
experiments mix tltcp tcp flows examining traces observe tltcp flows ones obtain greater bandwidths 
fact tltcp infer multiple packet losses obsolete data 
tltcp flow large window size experiment obsolete data sending window 
turn means larger likelihood multiple packet losses obsolete data 
larger receiver window tltcp stream increment window tcp stream continue loss detected 
average tltcp streams obtain greater throughput large maximum receiver window sizes 
note extent disparities throughput expected get worse larger windows self limiting nature unfairness described 
varying propagation delay known flows different pairs hosts internet encounter wide variety round trip delays 
important transport protocol able function properly wide range round trip delays 
dealing large range round trip delays reported problem existing rate streaming media protocols 
rate protocol report small round trip delays behaves aggressively compared tcp obtaining larger share bottleneck bandwidth competing tcp flows 
point large round trip delays comparatively small rate recomputation intervals unable accurately estimate loss rates result performance highly variable 
advantage tltcp compared rate protocols ack clocked uses ack roundtrip timing mechanisms tcp 
expect tltcp able react quickly traffic fluctuations provide stable behavior wider range operating conditions rate protocols 
set experiments study tltcp behavior large range bottleneck delays 
friendliness ratio best worst delay milliseconds 
varying delay friendliness ratios seen figures friendliness ratios separation indices obtained tltcp close obtained tcp 
observation tltcp tcp flows able share bandwidth wide range bottleneck delays indicates lifetime timer expiry events tltcp flows significantly affect accuracy round trip timing mechanisms 
addition examining traces experiments saw average round trip estimates tltcp flows close tcp flows 
separation index mix tcp delay milliseconds 
varying delay separation indices varying deadlines way large window sizes increase likelihood behavior tltcp deviates tcp time line chosen impact tltcp 
clearly large deadlines possible send packets section prior deadline tltcp operate manner identical tcp 
deadlines smaller likelihood having deal losses obsolete data increases set experiments examine impact range deadlines friendliness tltcp 
shows fairness ratios separation indices variety deadline intervals seconds corresponds resolution timers common implementations tcp seconds 
notion time lines tcp compare results experiment tltcp flows tcp flows experiment flows tcp 
results show tltcp operates fairly large range friendliness ratio separation index mix deadlines seconds 
varying data deadlines 
deadlines 
short deadlines tltcp able share bandwidth 
case deadline interval seconds 
corresponds data rate mbps stream streams mbps link size section remains bytes 
interesting note instance tltcp streams obtain lower throughput competing tcp streams experiments tltcp streams obtain higher throughput 
reason twofold impact short deadlines tltcp data sends 
packets sent sequence deadline expires data section needs sent 
second seq update messages sent frequently deadlines expire frequently 
note update messages part new data packets sent 
small deadlines seconds observe experiments tltcp sender able send packets jump data sequence indicated update message 
just packets sent section loss occurs high likelihood subsequent packets received receiver update message reach receiver 
packets reach receiver loss update fast recovery mechanisms triggered 
due small number packets section reach receiver tltcp streams able reduce sending rate fast recovery 
confirmed examining trace files far fewer instances fast retransmit fast recovery observed experiment deadlines seconds deadlines seconds 
reducing congestion window half fast recovery tltcp flows experience timeouts abruptly reduce sending window segment 
small deadlines tltcp streams obtain smaller portion available bandwidth 
note scenario described deadline seconds small number packets sent packets discarded sender expiry corresponding deadline 
clearly undesirable real application indicates deadlines set properly 
application tltcp attempt maximize amount data reaches receiver reduce dropping packets 
situation lot data dropped application expected set larger deadlines reduce size section 
unfairness observed experiment deadlines seconds occur tltcp real application 
conclude section noting tltcp transports data time lined fashion tcp friendly manner wide range window sizes deadlines round trip times competing traffic 
furthermore conditions tltcp flows appear unfair tcp flows conditions tcp unable share bandwidth 

proposes new protocol time lined tcp delivery time sensitive data internet 
remaining confines tcps window congestion control designed reliable data transfer tltcp attempts deliver noncontiguous time sensitive data suitable continuous media players applications send time sensitive data 
designed compete fairly existing traffic internet 
augmentations socket calls proposed allow tltcp accept data deadlines sending application deliver data received indicate gaps receiving application 
results simulations show tltcp compete fairly existing traffic internet 
intend integrate tltcp kernel test internet 
order facilitate deployment intend modify tltcp sender tltcp sender interoperate tcp acting receiver 
allow leverage installed base tcp streaming media servers tltcp intend explore possibility backing strict friendliness requirements order provide better performance applications 

braden clark crowcroft davie deering estrin floyd jacobson partridge peterson ramakrishnan shenker wroclawski zhang 
request comments april 
brakmo peterson 
tcp vegas congestion avoidance global internet 
ieee journal selected areas communications october 
caida 
traffic workload overview www caida org learn flow html 
cen pu walpole 
flow congestion control internet streaming applications 
multimedia computing networking 
claffy 
internet measurement data analysis topology workload performance routing statistics 
nae workshop 
www caida org papers nae 
fall floyd 
simulation comparisons tahoe reno sack tcp 
computer communication review july 
floyd 
connections multiple congested gateways packet switched networks part way traffic 
acm computer communications review 
floyd fall 
promoting congestion control internet 
ieee acm transactions networking appear 
floyd jacobson 
random early detection gateways congestion avoidance 
ieee acm transactions networking august 
jacobs eleftheriadis :10.1.1.31.4078
streaming video dynamic rate shaping tcp congestion control 
journal visual communication image representation september 
van jacobson 
congestion avoidance control 
acm sigcomm pages 
acm press august 
mahdavi floyd 
tcp friendly unicast rate flow control january 
www psc edu network ing papers tcp friendly html 

random drop congestion control 
acm sigcomm pages 
semke mahdavi ott 
macroscopic behavior tcp congestion avoidance algorithm 
computer communication review july 
mena heidemann 
empirical study real audio traffic 
proceedings ieee infocom tel aviv israel appear 
ieee 
morris 
tcp behavior flows 
ieee international conference network protocols icnp october 
padhye firoiu towsley kurose 
modeling tcp throughput simple model 
acm sigcomm 
padhye kurose towsley 
model tcp friendly rate control protocol 
ieee nossdav june 
paxson 
automated packet trace analysis tcp 
proceedings sigcomm 
paxson 
internet packet dynamics 
proceedings sigcomm 
sridhar ramesh rhee 
issues tcp model flow control 
technical report tr north carolina state university 
rejaie handley estrin 
rap rate congestion control mechanism real time streams internet 
technical report university southern california 
rejaie handley estrin 
rap rate congestion control mechanism real time streams internet 
ieee infocomm march 
rowe patel smith liu 
mpeg video software representation transmission playback 
proceedings ist spie international symposium electrical imaging science technology san jose ca february 
schulzrinne 
loss delay adjustment algorithm tcp friendly adaptation scheme 
international workshop network operating system support digital audio video nossdav july 
stevens 
request comments january 
stevens 
tcp ip illustrated volume 
addison wesley 
stevens 
unix network programming volume 
prentice hall nd edition 
ucb lbnl vint 
network simulator ns version www mash cs berkeley edu ns 
