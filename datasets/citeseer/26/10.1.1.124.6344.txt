trec sdr track amit singhal john choi donald hindle julia hirschberg fernando pereira steve whittaker labs research choi hindle julia pereira research att com participated spoken document retrieval sdr track trec 
speech retrieval system uses modern information retrieval ir methods conjunction house automatic speech recognition 
novel feature trec document expansion reduce performance loss due asr errors 
results show retrieval automatic transcriptions speech quite competitive doing retrieval human transcriptions 
experiments indicate document expansion improve retrieval automatic transcripts 
presents analysis document expansion context trec sdr track task 

text retrieval conference trec short annual series evaluation workshops organized nist darpa evaluate modern text retrieval related technologies large scale datasets 
seventh text retrieval conference trec held nist november 
trec included track spoken document retrieval sdr track evaluate modern ir technology conjunction modern speech recognition technology search spoken content 
teams participated full sdr recognition retrieval category track 
participated full sdr category 
internal speech recognition system weighted finite state transducers :10.1.1.30.7559

ir system internally modified version cornell known smart retrieval system 
speech retrieval believe parallel text corpora example printed news time period successfully exploited improve retrieval effectiveness system 
especially true news material currently sdr track 
ideas sdr track participation 
initial results parallel corpus quite encouraging 

speech recognizer speech recognition process involves steps 
prior recognition speech story segmented approximately minute long formed segments cart classifier 
resulting segments submitted wideband narrowband classifier selection acoustic model recognition segment 
recognizer standard time synchronous beam quasi sdr category allowed teams recognition output cmu sphinx iii system recognition teams participated category 
search algorithm 
probabilities defining transduction text dependent phone sequences word sequences estimated word level grapheme phone mappings implemented general framework weighted finite state transducers 
transducer composition generate word lattice output 
continuous density state left right contextdependent hidden markov phone models 
models trained dimensional feature vectors consisting mel frequency cepstral coefficients second time derivatives 
training iterations included eigenvector rotations kmeans clustering maximum likelihood normalization means variances viterbi alignment 
output probability distributions consist weighted mixture gaussians diagonal covariance mixture containing components 
training data divided wideband narrowband partitions resulting acoustic models 

language models pass recognition process 
pass built word lattices speech minimal trigram language model beam determined heuristically provide manageable word lattices 
word lattices removing trigram grammar weights retaining acoustic weights intersecting lattices gram language model 
best path extracted lattices 
pass trigram language model rescoring gram model standard katz backoff models word vocabulary 
choosing vocabulary words sdr training transcript 
base vocabulary supplemented words frequency greater appearing new york times la times segments ldc north american news corpus ldc catalog number ldc ldc upenn edu period june january 
vocabulary includes common acronyms training texts preprocessed include acronyms 
language model training transcription sources sdr training transcripts hub transcripts transcripts nbc nightly news print source ldc na news corpus newspaper text 
pass trigram model built constructing backoff language model words training text yielding grams grams 
model reduced size approach seymore rosenfeld grams grams 
composed lexicon smaller trigram model yielded manageable sized network 
second pass ln ln tf log df tf factor idf factor pivoted byte length normalization factor tf term frequency text nis total number documents df documents containing term weighting factor factor dtb weighting factor factor factor dtn weighting factor factor table term weighting schemes model grams grams grams 
model transcription sources sdr hub nbc effect interpolated text source na news give weight 
word error rate recognizer sdr track data 
transcriptions labeled att 

retrieval system sdr track na news corpus language model training described parallel corpus query document expansion described 
test data dated june january news dated may february month na news corpus 

task sdr track participants search collection hours speech recordings documents different user queries 
example user query query government officials crime 
speech recordings manually segmented different stories story judged user relevant irrelevant query 
aim user query rank stories ir system relevant stories ranked nonrelevant stories 
task called ad hoc searching task trec community 
difference standard text retrieval task erroneous automatic speech transcriptions stories place perfect text 
participants create word level transcriptions stories recognizer ad hoc searching algorithm retrieval erroneous transcriptions 
effectiveness ranking measured non interpolated average precision standard metric ir measure retrieval effectiveness 
details ad hoc task evaluation 
base query expansion human att table average precision results 

retrieval algorithm slightly different algorithm official trec participation algorithm main trec ad hoc task yields consistently better results 
main steps algorithm 
pass dtn queries weighted documents see table pass retrieval done 
expansion top documents retrieved pass assumed relevant query documents ranked assumed non relevant 
rocchio method parameters expand query adding new words new phrases highest rocchio weights 
include idf factor expansion process documents dtb weighted 
pass expanded query documents generate final ranking documents 
table shows retrieval automatic transcriptions wer worse retrieval perfect transcriptions 
see query expansion step improves retrieval effectiveness noticeably 
results important show viability doing effective speech retrieval modern speech recognition ir technologies 

document expansion best transcript recognizer misses content words adds spurious words spoken document 
misses reduce word recall proportion spoken words recognized spurious words reduce word precision proportion recognized words spoken 
believe information retrieval algorithms benefit higher word recall robust poor word precision 
approach enhance word recall add new words words probably spoken weren top choice speech recognizer automatic transcriptions spoken document 
techniques plausible bringing new words document 
obvious ir perspective similar documents find documents related document add new words related documents document hand 
speech recognition perspective obvious choice word lattices contain multiple recognition hypotheses utterance 
word lattice contains words acoustically similar recognized words said words recognized best transcription 
official trec participation constrained document expansion expansion words code provided wer human nist cambridge university dragon dragon systems att labs nist carnegie cmu shef sheffield university nist carnegie mellon cmu dera dera table different automatic transcriptions 
proposed similar documents appear word lattice 
official conference rigorous study document expansion discovered constraining document expansion allow terms word lattices generated recognizer held additional benefit doing 
document expansion na news results equally better 
allows test document expansion retrieval automatic transcriptions provided sdr track participants don word lattices 
dnew dold di test document expansion different automatic transcriptions provided nist various track participants 
table lists transcriptions word error rates 
steps involved document expansion 
find documents related speech document 
running automatic transcription speech document query raw tf idf weighted na news corpus retrieving similar documents 
words nearest neighbors speech document process 
documents weighted raw tf idf query nearest neighbors raw tf idf weighted documents yield best expansion results 

speech transcriptions modified rocchio formula 
initial document vector vector th related document modified document vector 
documents weighted see table 
new words added document 
term selection rocchio weights new words multiplied idf terms selected idf stripped selected term final weight 
furthermore ensure document expansion process doesn change effective length document vectors change results due document length normalization effects force total weight terms new vector total weight terms initial document vector :10.1.1.50.9950
expand documents original length original document indexed terms add new terms document 
results unexpanded expanded documents unexpanded docs expanded docs transcript base qry expn base qry expn human dragon att nist shef nist table cross recognizer analysis 
listed table 
main highlights results document expansion yields large improvements board importantly document expansion reduces performance gap retrieval perfect automatic transcriptions 
points highlighted 
left plot shows average precision axis wer axis 
number plotted unexpanded queries columns marked base table 
prevents effects query expansion affecting graphs allows study effects document expansion isolation 
horizontal lines human transcriptions lines different automatic transcriptions 
see left graph document expansion solid lines yields large improvements board task doing document expansion dashed lines 
indicated noticeably higher average precision solid lines compared corresponding dashed lines 
right graph plots loss human transcriptions axis unexpanded expanded documents 
baseline expanded documents higher expanded human transcriptions solid horizontal line left graph 
observe poorest transcriptions document expansion yields improvement impressive reduces performance gap human transcription original despite higher baseline 
results similar transcriptions 
case test collection document expansion beneficial general doesn hold special advantage automatic speech transcripts 
right graph shows case document expansion useful text erroneous 
dashed line right graph shows loss average precision retrieval done unexpanded automatic transcriptions unexpanded human transcriptions 
line shape dashed line left graph essentially curve different scale loss human transcriptions mark 
notice loss leftmost point close rightmost point 
solid line right plot shows losses various transcripts expanded documents 
baseline curve higher corresponds solid horizontal line average precision dragon att nist initial queries shef original documents expanded documents word error rate nist loss human transcriptions dragon att nist initial queries shef original documents expanded documents word error rate raw average precision loss human transcriptions initial user queries 
left graph 
see document expansion benefits poor transcriptions benefits human better automatic transcriptions 
poor transcriptions gap retrieval effectiveness reduces nist 
loss reductions quite significant 
summary document expansion useful automatic speech transcripts human transcriptions 
automatic recognitions relatively poor need help retrieval 
document expansion helping exactly transcriptions quite noticeably 
encouraging word error rates high retrieval effectiveness drops just post document expansion 
drop expansion 

results establish facts 
reasonable speech recognition retrieval effectiveness automatic transcription comparable perfect transcriptions speech 
transcriptions poor get large drop retrieval effectiveness 

document expansion helps speech retrieval importantly helps retrieval noticeably help badly needed poor automatic speech transcriptions 
second result quite encouraging study effect 

acknowledgments grateful sdr track participants provided transcriptions nist 
thankful nist making transcriptions available 
wouldn possible support andrej michael riley 

chris buckley 
implementation smart information retrieval system 
technical report tr department computer science cornell university ithaca ny may 

julia hirschberg christine nakatani 
machine learning identify intonational segments 
proceedings aaai spring symposium applying machine learning discourse processing palo alto ca march 

katz 
estimation probabilities sparse data language model component speech recognizer 
ieee transactions acoustics speech signal processing pages 

fernando pereira michael riley 
speech recognition composition weighted finite automata 
emmanuel roche yves schabes editors finite state language processing pages 
mit press cambridge massachusetts 

rocchio 
relevance feedback information retrieval 
smart retrieval system experiments automatic document processing pages englewood cliffs nj 
prentice hall 
gerard salton editor 
smart retrieval system experiments automatic document retrieval 
prentice hall englewood cliffs nj 

seymore ronald rosenfeld 
scalable backoff language models 
icslp volume 

amit singhal chris buckley mandar mitra 
pivoted document length normalization 
proceedings nineteenth annual international acm sigir conference research development information retrieval pages 
association computing machinery new york august 

amit singhal john choi donald hindle david lewis fernando pereira 
trec 
voorhees harman editors proceedings seventh text retrieval conference trec appear 

voorhees harman 
overview seventh text retrieval conference trec 
voorhees harman editors proceedings seventh text retrieval conference trec appear 
nist 
