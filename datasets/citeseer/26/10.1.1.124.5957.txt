src technical note july modified september supersedes src technical note continuous profiling cycles gone 
jennifer anderson lance jeffrey dean sanjay ghemawat monika henzinger shun tak leung richard sites mark vandevoorde carl waldspurger william weihl systems research center lytton avenue palo alto california www research digital com src appear acm transactions computer systems 
slightly revised version appear th acm symposium operating systems principles october st malo 
france 
copyright acm rights reserved 
republished permission describes digital continuous profiling infrastructure sampling profiling system designed run continuously production systems 
system supports multiprocessors works unmodified executables collects profiles entire systems including user programs shared libraries operating system kernel 
samples collected high rate samples sec mhz processor low overhead slowdown workloads 
analysis tools supplied profiling system sample data produce precise accurate accounting level pipeline stalls incurred individual instructions time spent 
instructions incur stalls tools identify possible reasons cache misses branch mispredictions functional unit contention 
fine grained instruction level analysis guides users automated optimizers causes performance problems provides important insights fixing 
performance programs running modern highperformance computer systems hard understand 
processor pipelines complex memory system effects significant impact performance 
single program entire system perform desired expected difficult pinpoint reasons 
digital continuous profiling infrastructure provides efficient accurate way answering questions 
system consists parts novel features data collection subsystem samples program counters records disk database suite analysis tools analyze stored profile information levels fraction cpu time consumed program number stall cycles individual instruction 
information produced analysis tools guides users done digital systems research center src western research laboratory wrl 
anderson dean wrl sites adobe remaining authors src 
sites may reached adobe com authors may reached sanjay monika mtv pa dec com 
inquiries system described sent dcpi pa dec com information including profiling system software web www research digital com src dcpi 
time critical sections code explains detail static dynamic delays incurred instruction 
faced major challenges designing implementing profiling system efficient data collection high sampling rate identification classification processor stalls samples 
data collection system uses periodic interrupts generated performance counters available digital alpha processors sample program counter values 
processors intel pentium pro sgi similar hardware support 
profiles collected unmodified executables code profiled including applications shared libraries device drivers kernel 
thousands samples gathered second allowing useful profiles gathered relatively short time 
profiling efficient overhead processor time depending workload 
permits profiling system run continuously production systems improves quality profiles minimizing perturbation system induced profiling 
collected profiles contain time biased samples program counter values number samples associated particular program counter value proportional total time spent executing instruction 
samples show relative number cache misses branch mispredictions incurred individual instructions may collected processor performance counters support events 
analysis tools collected samples generate usual histograms time spent image procedure source line instruction 
analysis tools detailed machine model heuristics described section convert time biased samples average number cycles spent executing instruction number times instruction executed possible explanations static dynamic stalls 
techniques deduce information entirely time biased program counter profiles binary executable types samples available may improve accuracy results 
section contains examples output tools 
discussed combination fine grained instruction level analysis detailed profiling long running workloads produced insights performance difficult achieve tools 
insights improve performance major commercial applications 
output analysis tools directly programmers fed compilers linkers post linkers run time optimization tools 
profiling system freely available web running digital alpha processors digital unix september ports progress alpha nt 
underway feed output tools digital optimizing backend spike om post linker optimization framework 
studying new kinds profile driven optimizations possible fine grained instruction level profile information provided system 
section discusses profiling systems 
section illustrates system 
sections describe design performance data collection system techniques achieve low overhead high sampling rate 
section describes subtle interesting techniques analysis tools explaining derive instruction cpi execution frequency explanations stalls raw sample counts 
section discusses section summarizes results 
related profiling systems monitor complete system activity high frequency sampling low overhead morph designed run continuously long periods production systems essential obtaining useful profiles large complex applications databases 
addition know system analyze time biased samples produce accurate fine grained information number cycles taken instruction reasons stalls tools produce similar information simulators higher cost 
table compares profiling systems 
overhead column describes profiling slows target program low overhead defined arbitrarily 
scope column shows profiling system restricted single application app measure full system activity sys 
grain column indicates range individual measurement applies 
example gprof counts procedure executions pixie count executions instruction 
prof goes reports time spent executing instruction wide variations latencies different instructions useful just execution count 
stalls column indicates system subdivide time spent instruction components cache latency branch misprediction delays system overhead scope grain stalls pixie high app inst count gprof high app proc count high app proc count quartz high app proc count high app inst count time inaccurate simos high sys inst time accurate pixie high app inst count dynamic high app inst time accurate prof low app inst time high sys inst time inaccurate morph low sys inst time sampler low sys inst time inaccurate timer low sys inst time inaccurate counters dcpi low sys inst time accurate table profiling systems systems fall groups 
includes pixie gprof quartz simos part sgi speed shop intel dynamic analyzer 
systems binary modification compiler support direct simulation programs gather measurements 
high overhead usually require significant user intervention 
slowdown large continuous measurements production despite techniques reduce instrumentation overhead substantially 
addition simulation systems provide accurate information locations causes stalls 
systems second group statistical sampling collect fine grained information program system behavior 
sampling systems including morph prof part rely existing source interrupts timer interrupts generate program counter samples 
prevents sampling interrupt routines result correlations sampling system activity 
hardware performance counters randomizing interval samples able sample activity essentially entire system interrupt handler avoid correlations activity 
issue discussed section 
systems performance counters including sampler part share characteristics system 
continuous profiling need lot memory sample data 
addition sampler unable map sample data accurately back individual instructions 
contrast tools produce accurate accounting stall cycles incurred instruction potential reason stalls 
data analysis examples illustrate range information system provide section provides examples 
system analyze improve performance wide range complex commercial applications including graphics systems databases industry benchmark suites compilers 
example tools performance problem commercial database system fixing problem reduced response time particular sql query hours 
example tools fine grained instruction level analyses identified opportunities improve optimized code produced digital compiler speeding mgrid specfp benchmark 
system includes large suite tools analyze profiles different levels detail 
section examples tools display number samples procedure image 
calculate cycles instruction basic block execution frequencies procedure show possible causes stalls see section 
analyze variations profile data runs 
tools annotate source assembly code sample counts highlight differences separate profiles program summarize time spent entire program percentage cycles spent waiting data cache misses see example kind summary single procedure translate profile data pixie format produce formatted postscript output annotated control flow graphs 
procedure level bottlenecks provides high level view performance workload 
reads profile data gathered system displays listing number samples procedure sorted decreasing number samples 
list samples image procedure 
shows lines output run perf drawing benchmark 
example ffb routine accounts cycles workload 
notice profile includes code kernel code shared libraries 
columns cumulative percent cycle samples consumed procedure preceding listing information total number fraction instruction cache samples occurred procedure 
instruction level bottlenecks provides detailed view time spent instruction procedure 
illustrates output key basic block copy benchmark running alphastation 
copy benchmark runs loop array elements bit integers compiler unrolled loop times resulting loads stores iteration 
generated code shown drives memory system full speed 
basic block shows summary information block 
lines display best case actual cycles instruction cpi block 
best case scenario includes stalls statically predictable instruction stream assumes dynamic stalls load instructions hit cache 
copy benchmark see actual cpi quite high best theoretical cpi dynamic stalls occurred 
shows dynamic stalls significant performance problem basic block 
lists instructions basic block annotated information stall cycles total samples event type cycles counts number samples listed event type 
cycles cum procedure image ffb usr lib dec ffb ev usr usr usr bcopy dispatch usr ffb usr lib dec ffb ev checksum usr mix usr program source code image contains line number information 
assembly instruction stalls inserts bubbles show duration possible cause stall 
line assembly code shows left right instruction address instruction number pc samples instruction average number cycles instruction spent head issue queue stalled addresses instructions may caused instruction stall 
note alpha load instructions write operand register operators write third operand 
line listing represents half cycle easy see instructions dual issued 
see large stalls cycles instruction cycles instruction 
letters stalled stq instruction indicate possible reasons cache incurred ldq provides data needed stq write buffer overflow data tlb dtb stq instruction stalled possible reasons 
lines labeled indicate static stalls due hazards case caused able dual issue adjacent stq instructions 
identifies reasons analyzing instructions time biased program counter samples monitoring events cache misses 
expected listing shows copy loop streams data performance bottleneck due memory latency 
entry write buffer able retire writes fast keep computation 
dtb real problem loop walks key procedures perf run 
page may incur dtb misses crossing page boundary 
ruled samples dtb events collected 
particular experiment collected default lists dtb possibility designed assume worst data indicate 
section discusses 
analyzing variance program executions benchmarks analyze performance data collection system showed best case cpi actual cpi addr instruction samples cpi culprit pd branch mispredict pd dtb ldq cy addq dual issue ldq cy ldq cy ldq cy lda dual issue cache 
cy write buffer overflow stq cy dual issue stq cy hazard 
cy stq cy stq cy lda dual issue bne cy analysis copy loop 
number samples type cycles set set set set total set set set set statistics calculated sample counts procedure different sample set range sum sum mean std dev min max procedure smooth statistics runs specfp benchmark wave 
variance running times different runs 
tools examine benchmarks wave sequential specfp workload detail 
ran wave alphastation observed running times varied 
best case cpi actual cpi cache cache cache dtb write buffer synchronization branch mispredict busy busy unexplained stall unexplained gain dynamic ra dependency rb dependency rc dependency fu dependency static total stall execution net sampling error total tallied samples summary cycles spent procedure smooth fast run specfp benchmark wave 
ran sets sample files isolate procedures greatest variance reads multiple sets sample files computes statistics comparing profile data different sets 
output wave shown 
shows procedures wave program sorted normalized range difference maximum minimum sample counts procedure divided sum samples 
see procedure smooth larger range procedures 
ran smooth profile obtaining summary fraction cycles consumed type dynamic static stall procedure 
summary fastest run profile fewest samples shown 
summary slowest run shown shows percentages stall cycles attributed cache dtb write buffer overflow increase dramatically respectively 
increase probably part due differences virtual physical page mapping different runs different data items located pages map location board cache cache number conflict misses increase 
data collection system analysis tools described previous section rely profiles gathered workload executes 
gather profiles digital continuous profiling infrastructure periodically samples program counter pc processor associates sample corresponding executable image saves samples disk compact profiles 
key system ability support high frequency continuous profiling efficiency uses cpu modest amounts memory disk 
direct result careful design 
sampling relies alpha processor performance counter hardware count various events cycles cache misses instructions executed processor 
processor generates high priority interrupt specified number events occurred allowing interrupted instruction context captured 
time system gathers samples provide accurate statistical picture total number events associated instruction executable image run system 
blind spots code code profiled systems rely real time clock interrupt existing system functions obtain samples 
accumulated samples analyzed discussed section reveal useful performance metrics various levels abstraction including execution counts average number stall cycles instruction shown section 
shows overview data collection system 
level system consists interacting components kernel device driver services performance counter interrupts daemon process extracts samples driver associates executable images merges nonvolatile profile database modified system loader mechanisms identifying executable images loaded running process 
rest section describes pieces detail hardware performance counters 
alpha performance counters alpha processors provide small set hardware performance counters configured count specified event 
precise number counters set supported events interface details vary alpha processor implementations 
existing alpha processors count wide range interesting events including processor clock cycles cycles instruction cache misses data cache misses branch mispredictions 
loader modified user space kernel log image exec info device driver daemon info buffered samples hash table cpu cpu cpu overflow buffers cpu data disk profile database data collection system overview performance counter overflows generates high priority interrupt delivers pc instruction executed identity overflowing counter 
device driver handles interrupt records process identifier pid interrupted process pc delivered interrupt event type caused interrupt 
system default configuration monitors cycles events 
monitoring cycles results periodic samples program counter showing total time spent instruction 
monitoring events reveals number times instruction misses instruction cache 
system configured monitor events giving detailed information causes dynamic stalls 
limited number events monitored simultaneously system supports time multiplexing different events fine grain 
sgi provides similar multiplexing capability 
sampling period performance counters configured overflow different values legal settings vary different alpha processors 
monitoring cycles alpha interrupts generated events events 
bit performance counter register writable allowing period maximum events monitor cycles obtain information needed estimate instruction frequency cpi see section details 
monitor samples usually accurate provide important additional information understanding causes stalls see discussion section 
chosen 
minimize systematic correlation timing interrupts code run randomize length sampling period writing pseudo random value performance counter interrupt 
default sampling period distributed uniformly monitoring cycles 
attributing events pcs accurately interpret samples important understand pc delivered interrupt handler 
performance counter interrupt delivered processor exactly cycles counter overflows 
interrupt delivered handler invoked pc oldest instruction issue queue time interrupt delivery 
delayed delivery skew distribution cycle counter overflows just shifts sampling period cycles 
number cycle counter samples associated instruction statistically proportional total time spent instruction head issue queue 
instructions stall head issue queue accounts occurrences stalls 
events incur cycles latency mask interrupt latency 
example misses usually take long interrupt delivered processor instruction incurred issued 
sampled pc event usually correctly attributed instruction caused events cycle interrupt latency cause significant problems 
samples associated events caused instruction show instructions cycles instruction stream depending latency specific event type 
dynamically varying number instructions including branches occur interval useful information may lost 
general samples events cycles helpful tracking performance problems useful detailed analysis 
blind spots deferred interrupts performance counter interrupts execute highest kernel priority level deferred running non interruptible system code highest priority level 
events profiling performance counter interrupt handler difficult 
implemented meta method obtain high priority interrupt code counted samples events associated instruction runs finishes interrupt level drops 
synchronous pal calls samples attributed instruction call provide useful information time spent call 
primary asynchronous pal call deliver interrupt dispatches particular kernel entry point samples deliver interrupt accumulate entry point 
samples high priority asynchronous pal calls interrupts relatively infrequent usually spread running workload simply add small amount noise statistical sampling 
device driver device driver efficiently handles interrupts generated alpha performance counter overflows provides ioctl interface allows user mode programs flush samples kernel buffers user space 
interrupt rate high approximately interrupts second processor monitoring cycles alpha running mhz higher simultaneous monitoring additional events 
raises problems 
interrupt handler fast example interrupt handler takes cycles consume cpu 
note cache way memory costs order cycles afford execute lots instructions take cache misses 
second samples generate significant memory traffic 
simply storing raw data bit pid bit pc bit event interrupt buffer generate kb processor second 
data copied user level process processing merging disk profiles imposing unacceptable overhead 
reduce problems resorting lower frequency event sampling increase amount time required collect useful profiles 
engineered data collection system reduce overhead associated processing sample 
reduce number samples copied user space processed ing samples interrupt handler space limitations preclude detailed discussion 
daemon counting device driver number times particular sample occurred 
typically reduces data rate sample data moving device driver user level daemon factor 
second organize data structures minimize cache misses 
third allocate processor data structures reduce writes shared cache lines synchronization required correct operation multiprocessor 
fourth switch dynamically specialized versions interrupt handler reduce time spent checking various flags run time constants 
rest section describes optimizations detail 
data structures processor maintains private set data structures 
processor data structures primarily modified interrupt routine running processor 
read modified flush routines copy data user space 
synchronization details interactions discussed section 
processor maintains hash table aggregate samples counting number times pid pc event triple seen 
reduces amount data passed device driver user level daemon factor workloads resulting memory traffic lower processing overhead aggregated sample 
hash table implemented array fixed size buckets bucket store entries entry consists pid pc event plus count 
pair overflow buffers stores entries evicted hash table 
buffers kept entries appended copied user space 
overflow buffer full driver notifies daemon copies buffer user space 
interrupt handler hashes pid pc event obtain bucket index checks entries index matches sample count incremented 
entry evicted overflow buffer replaced new sample count 
evicted entry chosen mod counter incremented eviction 
entry occupies bytes bucket occupies cache line bytes alpha incur data cache search entire bucket 
way associativity hash table helps prevent thrashing entries due hashing collisions 
section discuss experiments conducted evaluate greater associativity help 
reducing cache misses cache way memory costs order cycles 
turns cache misses instructions data dominant sources overhead interrupt handler execute instructions significant impact overhead long result cache misses 
reduce overhead designed system minimize number cache misses 
common case hash table hit interrupt handler accesses bucket hash table various private processor state variables pointer local hash table seed period randomization global state variables size hash table set monitored events sampling period 
hash table search generates cache additionally pack private state variables read copies global variables byte processor data structure cache needed 
making copies shared state avoid interprocessor cache line thrashing invalidations 
uncommon case hash table evict old entry hash table 
eviction accesses extra cache line empty overflow buffer entry evicted entry written 
global variables accessed packed byte processor structure described 
accesses generate cache misses 
reducing synchronization synchronization eliminated interrupt handlers different processors multiprocessor minimized handlers driver routines 
synchronization operations particular memory barriers expensive costing order cycles small number interrupt handler result unacceptable overhead 
data structures driver techniques synchronize access designed eliminate expensive synchronization operations interrupt handler 
separate hash table pair overflow buffers processor handlers running different processors need synchronize 
synchronization required handler routines copy contents hash table overflow buffers handler user space 
processor hash table protected flag set processor 
flush routine copies hash table processor performs inter processor interrupt ipi processor set flag indicating hash table flushed 
ipi handler raises priority level ensure executes atomically respect interrupts 
hash table flushed performance counter interrupt handler writes sample directly overflow buffer 
overflow buffers synchronized similarly 
expensive allow remove memory barriers interrupt handler exchange increasing cost flush routines 
interrupt handler runs frequently flush routines tradeoff 
user mode daemon user mode daemon extracts samples driver associates corresponding images 
users may request separate process profiles specified images 
data image periodically merged compact profiles stored separate files disk 
sample processing main daemon loop waits driver signals full overflow buffer copies buffer user space processes entry 
daemon maintains image maps active process uses pid pc entry find image loaded pc process 
pc converted image offset result merged hash table associated relevant image event 
daemon obtains information image mappings variety sources described section 
periodically daemon extracts samples driver data structures updates disk profiles discards data structures associated terminated processes 
time intervals associated periodic processing user specified parameters default daemon drains driver minutes inmemory profile data merged disk minutes 
simple timeout approach cause undesirable bursts intense daemon activity version system avoid updating disk profiles incrementally 
complete flush initiated user level command 
obtaining image mappings sources information determine images loaded process 
modified version dynamic system loader loader notifies system daemon image loaded process 
notification contains pid unique identifier loaded image address loaded filesystem pathname 
mechanism captures dynamically loaded images 
second kernel exec path invokes chain recognizer routines determine load image 
register special routine head chain captures information static images 
recognizer stores data kernel buffer flushed daemon seconds 
obtain image maps processes active daemon starts start daemon scans active processes mapped regions mach system calls available digital unix 
mechanisms able successfully classify virtually samples collected driver 
remaining unknown samples aggregated special profile 
experience number unknown samples considerably smaller typical fraction week long run 
profile database daemon stores samples disk profile database 
database resides user specified directory may shared multiple machines network 
samples organized non overlapping epochs contains samples collected time interval 
new epoch initiated user level command 
epoch occupies separate sub directory database 
separate file store profile image event combination 
profile files written compact binary format 
significant fractions executable images consist symbol tables instructions executed profiles typically smaller associated executables order magnitude days continuous profiling 
disk space usage problem designed improved format compress existing profiles approximately factor 
workload mean base platform description runtime secs uniprocessor workloads specint mhz alphastation spec benchmark suite compiled base specfp mhz alphastation peak compilation flags run driver 
perf mhz alphastation tests perf server performance testing program 
tests chosen representative cpu bound tests 
mhz alphastation consisting loops measure memory system bandwidth 
multiprocessor workloads altavista mhz cpu alphaserver trace queries gb altavista news index 
system driven maintain outstanding queries 
dss mhz cpu alphaserver parallel specfp mhz cpu alphaserver timesharing days mhz cpu alphaserver profiling performance performance critical success profiling system intended run continuously production systems 
system collect thousands samples second incur sufficiently low overhead benefits outweigh costs 
section summarize results experiments designed measure performance system explore tradeoffs design 
evaluated profiling system performance different configurations cycles system monitors cycles default system monitors cycles instruction cache misses mux system monitors cycles performance counter uses multiplexing monitor instruction cache misses data cache misses branch mispredictions counter 
table shows workloads average running times minimum runs shown confidence intervals base configuration system machines ran 
aggregate time overhead measure overhead ran workload minimum times configuration ran workloads times 
table shows percentage overhead confidence intervals imposed different configurations system compared base configuration 
timesharing workload included table table description workloads decision support system dss query tpc specification 
specfp programs parallelized stanford suif compiler 
server office technical applications running default configuration system 
workload gather statistics long running profile session 
workload cycles default mux uniprocessor workloads specint specfp perf noop circle ellipse poly assign saxpy scale sum multiprocessor workloads altavista dss parallel specfp table slowdown percent measured live system run configuration determine slowdown 
perf report results rates mb sec operations sec perf table shows degradation rates 
workloads table shows increase running time 
numbers table show overhead imposed system quite low usually 
variation performance run run workload typically greater system overhead 
shows data detail programs altavista gcc portion specint workload peak version wave portion specfp workload peak version 
graph gives scatter plot running times seconds configurations 
range axis mean value axis intersecting mean value 
confidence intervals shown 
altavista representative majority workloads studied profiling overhead small little variance different runs 
contrast system incurs relatively high overhead gcc 
benchmark compiles pre processed source files assembly files file requires separate invocation program distinct pid 
samples distinct pid match hash table eviction rate high resulting higher overhead see section 
wave data shows apparent speedup running dcpi experiments 
similar cases running time variance exceeded profiling overhead 
overheads measured slightly higher experienced practice discussed section measurements done instrumented version system logged additional statistics imposing overhead normally incurred 
components time overhead main components system overhead 
time service performance counter interrupts 
second time read samples device driver daemon merge samples disk profiles appropriate images 
investigate cost components performed experiments system instrumented collect statistics number cycles spent interrupt handler collected separately cases samples hit hash table eviction rate hash table total number samples observed 
real workloads able directly measure time spent interrupt handler include time deliver interrupt time return interrupt handler 
experimentation tight spin loop revealed best case interrupt setup teardown time cycles including interrupt handler 
real workloads value increase due additional instruction cache misses 
altavista secs gcc secs wave secs base cycles default mux distribution running times evaluate daemon sample cost processing experiments configured gather samples daemon showed cycles spent daemon kernel behalf daemon 
dividing total number samples processed driver gives sample processing time daemon 
statistics summarized workload table configurations 
separately measured statistics gcc program specint workload show effects high eviction rate 
table shows workloads low eviction rates specfp altavista spend time processing interrupt hit hash table faster spend time processing sample daemon samples aggregated single entry evicted hash table 
workloads high eviction rate average interrupt cost higher addition higher eviction rate leads sample metric allow comparison sample time interrupt handler different time spent processing entry overflow buffer multiple samples processed entries counts higher 
cycles default mux sample cost cycles sample cost cycles sample cost cycles workload intr cost daemon intr cost daemon intr cost daemon rate avg hit cost rate avg hit cost rate avg hit cost specint gcc specfp perf altavista dss parallel specfp timesharing measured measured table time overhead components overflow entries higher sample cost daemon 
aggregate space overhead section evaluates memory disk overheads system 
memory consumed device driver daemon disk space store nonvolatile profile data 
described section device driver maintains hash table pair overflow buffers processor non kernel memory 
experiments overflow buffer held samples hash table held samples total kb kernel memory processor 
daemon consumes ordinary memory 
allocates buffer large flush overflow buffer hash table processor data structures active process image 
memory usage grows number active processes depends workload locality 
process data structures infrequently default minutes samples image buffered saved disk default minutes result daemon worst case memory consumption occurs profiled workload consists short lived processes processes poor locality 
table presents average peak resident memory text data daemon workload 
shows length time daemon running workload configuration 
workloads memory usage modest 
week long timesharing workload running processor compute server hundreds active processes required memory mb 
multiprocessor gb physical memory fraction memory devoted profiling system 
workstations smaller configurations mb mb memory overhead ranges 
current daemon implementation carefully tuned expect substantial memory savings techniques reductions storage costs hash tables aggressive inactive structures 
shown table disk space consumed profile databases small 
sets profiles required megabytes storage 
week long timesharing workload stored cycles profiles distinct executable images just mb disk space 
potential performance improvements driver carefully engineered performance room improvement 
addition performance daemon probably improved substantially 
shown section performance system heavily dependent effectiveness hash table aggregating samples 
explore alternative designs constructed trace driven simulator models driver hash table structures 
sample traces logged special version driver examined varying associativity replacement policy table size hash function 
experiments indicate increasing associativity way way packing entries processor cache line increase total number entries hash table swap front hash table hits inserting new entries line roundrobin policy currently reduce system cost 
intend incorporate changes version system 
driver user mode daemon heavily optimized 
key changes re cycles default mux space kbytes space kbytes space kbytes workload uptime memory disk uptime memory disk uptime memory disk avg peak usage avg peak usage avg peak usage specint gcc specfp perf altavista dss parallel specfp timesharing measured measured table daemon space overhead duce time process raw driver sample significantly 
costly activity daemon involves associating sample corresponding image currently requires hash lookups 
sorting buffer raw samples pid pc amortize lookups large number samples 
memory copy costs reduced mapping kernel sample buffers directly daemon address space 
estimate changes cut overhead due daemon factor 
data analysis overview cycles samples recorded data collection subsystem tell approximately total time spent instruction head issue queue 
see large sample count instruction know immediately sample counts instruction simply executed times stalled times executed 
addition instruction stall know 
data analysis subsystem fills missing pieces information 
note analysis done offline samples collected 
profile data analysis subsystem produces instruction frequency proportional number times instruction executed profiled period cpi estimate average number cycles spent instruction head issue queue execution profiled period set culprits possible explanations wasted issue slots due static dynamic stalls 
analysis done phases phase estimates frequency cpi instruction second phase identifies culprits stall 
analysis designed processors execute instructions order working extending outof order processors 
programs executions deterministic possible measure execution counts instrumenting code directly pixie 
case phase analysis estimates frequency necessary 
large systems databases deterministic deterministic programs ability derive frequency estimates sample counts eliminates need create run instrumented version program simplifying job collecting profile information 
estimating frequency cpi crux problem estimating instruction frequency cpi sample data provides information total time spent instruction head issue queue proportional product frequency cpi need factor product 
example instruction sample count frequency cpi frequency cpi tell sample count 
combining information instructions excellent job factoring total time spent instruction component factors 
bulk estimation process focused estimating frequency fi instruction fi simply number times instruction executed divided average sampling period gather samples 
sample count si approximately ci average number cycles instruction spends head issue queue 
analysis finds fi ci easily obtained division 
analysis estimates fi values examining procedure time 
steps performed procedure 
build control flow graph cfg procedure 

group basic blocks edges cfg equivalence classes frequency execution 

estimate frequency equivalence class contains instructions suitable sample counts 

linear time local propagation method flow constraints procedure cfg propagate frequency estimates cfg 

heuristic predict accuracy estimates 
details 
building cfg cfg built extracting code procedure executable image 
basic block boundaries identified instructions change control flow branches jumps 
indirect jumps analyze preceding instructions try determine possible targets jump 
analysis fails case cfg noted missing edges 
current analysis identify interprocedural edges calls longjmp note absence 
determining frequency equivalence cfg noted missing edges block edge assigned equivalence class 
extended version cycle equivalence algorithm identify sets blocks edges guaranteed executed number times 
set constitutes equivalence class 
extension algorithm handling cfg infinite loops idle loop operating system 
estimating frequency sample counts heuristic estimating frequency equivalence class instructions works class time 
instructions class frequency henceforth called addr instruction ldq addq ldq ldq ldq lda stq stq stq stq lda bne estimating frequency copy loop 
heuristic assumptions instructions class encounter dynamic stalls second statically compute instructions minimum number cycles mi instruction spends head issue queue absence dynamic stalls 
mi obtained scheduling basic block model processor run 
mi may 
practice mi group multi issued instructions 
issue point instruction mi 
issue point dynamic stalls frequency modulo sampling error si mi 
issue point incurs dynamic stalls si increase 
estimate averaging smaller ratios si mi issue points class 
example illustrates analysis copy loop shown previously 
column shows output instruction scheduler si mi column shows ratio issue point 
heuristic various rules choose ratios marked averaged computing frequency 
close true frequency example 
challenges making accurate estimates 
equivalence class issue points 
general smaller number issue points greater chance encounter dynamic stall 
case heuristic overestimate extreme class issue points contains basic blocks 
case best exploit flow constraints cfg compute frequency propagation phase 
second equivalence class small number samples 
case estimate si mi ranges instructions class 
increases number samples heuristic generally improves estimate 
third mi may statically determinable 
example number cycles instruction spends head issue queue may general depend code executed basic block 
block multiple predecessors static code schedule computing mi 
case currently ignore preceding blocks 
block listed limitation leads error mi ldq instruction processor issue ldq cycles stq previous iteration 
static stall misclassified dynamic stall issue point ignored 
fourth dynamic stalls mi values inaccurate 
suppose issue point instruction depends preceding instruction uses result needs hardware resource mi function latency instruction incurs dynamic stall cause spend fewer mi cycles head issue queue latency overlaps dynamic stall 
address problem ratio pi sk pi mk issue point instructions estimate reliable si mi dependence ensures statically determined latency decreased dynamic stalls intervening instructions 
select ratios include average 
rough terms examine clusters issue points relatively small ratios cluster set issue points similar ratios maximum ratio cluster minimum ratio cluster 
reduce chance underestimating cluster discarded issue points appear anomalous values si mi cluster contains minimum fraction issue points class estimate imply unreasonably large stall instruction class 
local propagation local propagation exploits flow constraints cfg additional estimates 
boundary case block predecessors successors frequency block equal sum frequencies incoming outgoing edges 
flow constraints form dataflow equations analysis variant standard iterative algorithm compilers 
variations new estimate block edge estimate immediately propagated members block edge equivalence class negative estimates allowed 
flow equations produce negative values frequency values estimates 
nature flow constraints time required local propagation linear size cfg 
currently experimenting global constraint solver adjust frequency estimates violate flow constraints 
predicting accuracy estimates analysis uses second heuristic predict accuracy frequency estimate low medium high confidence 
confidence estimate function number issue points compute estimate tightly ratios issue points clustered estimate propagation magnitude estimate 
evaluating frequency estimation process natural question point frequency estimates produced tools match actual frequencies 
evaluate accuracy estimates ran suite programs twice profiling tools pixie tool instruments basic blocks edges branch points obtain execution counts 
compared estimated execution counts fp frequency estimate sampling period measured execution counts values approximately equal modulo sampling error programs execution deterministic 
experiment subset spec suite 
subset contains base versions floating point benchmarks peak versions integer benchmarks ijpeg 
executables lacked relocation symbols required instrumented version ijpeg 
profiles generated running program spec workload times 
histogram showing results instruction frequencies 
axis series sample percent samples percent error low conf 
medium conf 
high conf 
distribution errors instruction frequencies weighted cycles samples buckets 
bucket covers range errors estimate bucket contains samples instructions fp times execution count 
axis percentage cycles samples 
shows samples estimates actual execution counts samples 
furthermore nearly samples estimates marked low confidence 
measure accuracy frequency estimates edges 
edges get samples axis percentage edge executions measured 
expect edge frequency estimates indirectly flow constraints accurate block frequency estimates 
edge executions estimates 
gauge accuracy estimates affected number cycles samples gathered compared estimates obtained profile single run integer workloads obtained runs 
integer workloads results cases similar estimates runs somewhat tightly clustered near bucket 
single run samples estimates actual execution counts runs increases 
individual programs gcc analysis data small number runs estimates runs significantly better 
single run gcc workload percent edge executions percent error low conf 
medium conf 
high conf 
distribution errors edge frequencies weighted edge executions samples runs increases 
data runs bucket get smaller gcc decreases 
suspect samples bucket come frequency equivalence classes issue points dynamic stalls occur regularly 
case gathering cycles samples improve analysis 
analysis estimating frequencies identifying culprits relatively quick 
takes approximately minutes analyze suite programs total roughly mb executables 
roughly time spent blocked identifying culprits identifying instructions stalled long reveals performance bottlenecks users eventually automatic optimizers know stalls occurred order solve problems 
section outline information tools offer compute accurate analysis tools provide information levels instruction procedure 
instruction level annotate stall culprits possible explanations applicable previous instructions may caused stall 
culprits displayed labeled bubbles instructions previously shown 
example analysis may indicate instruction stalled cache point load instruction fetching operand stalled instruction needs 
procedure level summarize cycles spent procedure showing gone cache misses cache misses aggregating instruction level data 
sample summary shown earlier 
summaries users quickly identify focus effort important performance issues procedure 
stall list possible reasons single culprit reporting culprit misleading 
stall shown analysis output average numerous stalls occurred profiling 
instruction may stall different reasons different occasions multiple reasons occasion 
example instruction basic block may stall branch misprediction time cache cache misses write buffer overflow may contribute stall instruction stores register previously loaded memory 
identify culprits stalls variety information 
specifically need binary executable sample counts cycles events 
sample counts types events taken consideration available optional 
source code required 
symbol table information availability procedure names easier users correlate results source code 
analysis considers static dynamic causes stalls 
static causes schedule instructions basic block accurate model processor issue logic assuming dynamic stalls 
detailed record keeping provides long instruction stalls due static constraints stalls previously issued instructions may cause stall 
explain static stalls 
additional stall cycles observed profile data treated dynamic stalls 
explain dynamic stall instruction follow guilty proven innocent approach 
specifically start list possible reasons dynamic stalls general try rule impossible extremely specific case question 
candidate eliminated estimate upper bound contribute stall 
uncertain assume candidate culprit 
cases candidates remain elimination 
ruled stall marked unexplained typically accounts samples procedure entire spec suite 
candidates currently consider cache misses cache misses instruction data tlb misses branch mispredictions overflows competition function units including integer multiplier floating point divider 
ruled different technique 
illustrate cache misses 
key ruling cache misses observation instruction extremely stall due cache cache line instruction execute immediately specifically examine control flow graph addresses instructions 
stalled instruction head basic block stall cache lies cache line 
head basic block determine control flow graph basic blocks may execute immediately 
instructions cache line stalled instruction cache ruled 
analysis ignore basic blocks control flow edges executed frequently stalled instruction 
event samples collected place upper bound stall cycles attributed cache misses 
count instruction sampling period estimate cache misses occurred instruction 
estimate execution frequency instruction compute upper bound stall cycles assuming pessimistically cache incurred cache fill way memory 
accurate analysis 
nontrivial program way short detailed simulation ascertain individual instructions stalled validate analysis directly comparing results correct answer 
evaluate indirectly comparing number stall cycles attributes cause corresponding sample count event sampling serves cache possible scenarios stalled instruction executed immediately interrupt software exception returns preceding instruction loads data happen displace cache line containing stalled instruction unified cache 
scenarios usually rare 
cache stall cycles billions top range bottom range events billions correlation numbers cache stall cycles events procedures spec benchmark suite alternative measure performance impact cause 
direct quantitative metric accuracy strong correlation suggest usefully identifying culprits 
events vastly different costs exact event counts may produce numbers stall cycles accurate direct comparison 
example cache cost cycles depending level memory hierarchy instruction 
illustrate validation approach cache misses 
plots cache stall cycles events procedures accounting execution time benchmark spec suite part main graph magnified clarity 
procedures corresponds vertical bar 
axis projected number icache misses procedure calculated scaling counts sampling period 
axis number stall cycles attributed cache misses tools report range stall cycles may caused part cache misses shows stall cycles generally increase counts set endpoints clustering straight line outlier pairs 
quantitative terms correlation isolate effect culprit analysis frequency estimation experiment analysis execution counts measured instrumented executables described section 
count procedure top bottom midpoint corresponding range stall cycles respectively suggesting strong linear correlation 
expect points deviate substantially majority cost cache vary widely analysis heuristic 
example conspicuous outliers near 
case number stall cycles unusually large overly pessimistic assumption concerning single stall compress benchmark specint 
second case number smaller expected procedure fpppp specfp contains long basic blocks instruction prefetching especially effective reducing penalty incurred relatively large number cache misses 
directions number interesting opportunities research 
plan focus primarily new profile driven optimizations exploit finegrained information supplied analysis tools 
underway drive existing compiletime link time binary rewriting optimizations profile data integrate optimizers profiling system single continuous optimization system runs background improving performance key programs 
plan optimize extend existing infrastructure 
currently investigating hardware software mechanisms capture information sample referenced memory addresses register values branch directions 
prototyped general software extensions instruction interpretation double sampling 
interpretation involves decoding instruction associated sampled pc determining useful information extracted recorded 
example conditional branch interpreted determine branch taken yielding edge samples prove valuable analysis optimization 
double sampling alternate technique obtain edge samples 
selected performance counter interrupts second interrupt setup occur immediately returning providing pc values execution path 
careful coding ensure second pc executed directly providing edge samples samples form longer execution path profiles 
developing graphical user interface improve usability tools interactively visualizing exploring profile data 
working hardware designers develop sampling support generation alpha processors uses order execution model presents number challenges 
digital continuous profiling infrastructure transparently collects complete detailed profiles entire systems 
low overhead typically practical continuous profiling production systems 
suite powerful profile analysis tools reveals useful performance metrics various levels abstraction identifies possible reasons processor stalls 
system demonstrates possible collect profile samples high rate low overhead 
high rate sampling reduces amount time user gather profiles analysis tools 
especially important tools require samples granularity individual instructions just basic blocks procedures 
low overhead important reduces amount time required gather samples improves accuracy samples minimizing perturbation profiled code 
collect data high rate low overhead performance counter interrupt handling carefully designed minimize cache misses avoid costly synchronization 
processor maintains hash table aggregates samples associated pid pc event 
workload locality aggregation typically reduces cost storing processing sample order magnitude 
samples associated executable images stored disk profiles 
describe performance instruction level analysis tools introduce novel algorithms address issues long instruction stalls reasons stall 
determine stall latencies average cpi computed instruction estimated execution frequencies 
accurate frequency estimates recovered profile data set heuristics detailed model processor pipeline constraints imposed program control flow graphs correlate sample counts different instructions 
processor pipeline model explains static stalls dynamic stalls explained guilty proven innocent approach reports possible cause eliminated careful analysis 
profiling system freely available web 
dozens users successfully system optimize wide range production software including databases compilers graphics accelerators operating systems 
cases detailed instruction level information essential pinpointing fixing performance problems continuous profiling long periods necessary obtaining representative profile 
mike burrows allan heydon hal murray sharon perl sharon smith helpful comments greatly improved content presentation anonymous referees sosp tocs provided numerous helpful comments 
dawson engler initially suggesting inter processor interrupts avoid expensive synchronization operations interrupt handler mitch alpha nt version system general help suggestions project developers supplying source code helped get ground building early versions data collection system 
gary carleton bob davies intel answering questions marty sgi answering questions 
anderson lazowska 
quartz tool tuning parallel program performance 
proceedings acm sigmetrics conference measurement modeling computer systems pages boulder colorado may 
ball larus 
optimally profiling tracing programs 
acm transactions programming languages systems july 
gem optimizing compiler system 
digital technical journal 

fast implementations minimal standard random number generator 
communications association computing machinery january 
cohn goodwin lowney rubin 
spike optimizer alpha nt executables 
usenix windows nt workshop seattle washington aug 
cohn lowney 
hot cold optimization large windows nt applications 
th annual international symposium microarchitecture micro paris france december 
digital continuous profiling infrastructure project 
www research digital com src dcpi 
digital equipment 
alpha microprocessor hardware manual 
maynard ma 
order number ec te 
digital equipment 
alpha axp microprocessors hardware manual 
maynard ma 
order number ec te 
aaron goldberg john hennessy 
integrated system performance debugging shared memory multiprocessor applications 
ieee trans 
parallel distributed systems pages january 
graham kessler mckusick 
gprof call graph execution profiler 
sigplan notices june 
hall maximizing multiprocessor performance suif compiler 
ieee computer december 

digital internal tool 
johnson pearson pingali 
program structure tree computing control regions linear time 
proceedings acm sigplan conference programming language design implementation pages orlando florida 

memory bandwidth machine balance high performance computers 
ieee technical committee computer architecture newsletter december 
www cs virginia edu stream 
kent 
perf 
www org gpc xpc static index html 
mips computer systems 
manual pixie 
sunnyvale ca 
prof digital unix man page 
reiser 
program profiling problems solution machine language rewriting 
sigplan notices january 
rosenblum herrod witchel gupta 
complete computer simulation simos approach 
ieee parallel distributed technology fall 
sites 
alpha axp architecture manual 
digital press newton ma 
standard performance evaluation 
www org osg spec 
transaction processing performance council 
www tpc org bench descrip html 
intel visual tuning environment 
developer intel com design 
zagha performance analysis mips performance counters 
proceedings supercomputing pittsburgh pennsylvania november 
zhang operating system support automated profiling optimization 
proceedings th acm symposium operating systems principles st malo france oct 
