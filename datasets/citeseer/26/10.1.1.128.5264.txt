case intelligent ram iram appear ieee micro april case intelligent ram iram david patterson thomas anderson neal cardwell richard kimberly keeton randi thomas katherine yelick computer science division eecs department university california berkeley ca email patterson cs berkeley edu trends call question current practice microprocessors drams fabricated different chips different fab lines gap processor dram speed growing year size organization memory single dram chip awkward system size growing year 
intelligent ram iram merges processing memory single chip lower memory latency increase memory bandwidth improve energy efficiency allow flexible selection memory size organization 
addition iram promises savings power board area 
reviews state microprocessors drams today explores opportunities challenges estimates performance energy efficiency iram designs 

problem division semiconductor industry microprocessor memory camps provides advantages 
foremost fabrication line tailored needs device 
microprocessor fab lines offer fast transistors fast logic metal layers accelerate communication simplify power distribution dram fabs offer polysilicon layers achieve small dram cells low leakage current reduce dram refresh rate 
separate chips mean separate packages allowing microprocessors expensive packages dissipate high power watts provide hundreds pins wide connections external memory allowing drams inexpensive packages dissipate low power watt dozen pins 
separate packages turn mean computer designers scale number memory chips independent number processors desktop systems processor dram chips server systems processors drams 
memory systems standardized single line memory module simm dual line memory module allows user scale amount memory system 
quantitative evidence success industry size drams industry microprocessors industry 
addition financial success technologies industries improved rates 
dram capacity average years microprocessor speed done 

problem 
processor memory performance gap hen processor memory performance gap dram split camps disadvantages 
shows microprocessor performance improving rate year access time dram improving year 
computer designers faced increasing processor memory performance gap primary obstacle improved computer system performance 
system architects attempted bridge processor memory performance gap introducing deeper deeper cache memory hierarchies unfortunately memory latency longer worst case 
example table shows cpu memory performance high performance computer system 
note main memory latency system factor larger raw dram access time difference due time drive address microprocessor time multiplex addresses dram time turn bidirectional data bus overhead memory controller latency simm connectors time drive dram pins address return data 
cpu case intelligent ram iram appear ieee micro april table latency bandwidth memory system high performance computer 
processor alpha machine alphaserver clock rate mhz memory performance latency bandwidth cache kb chip ns clocks mb sec cache kb chip ns clocks mb sec cache kb chip ns clocks mb sec cache mb chip ns clocks mb sec main memory subsystem ns clocks mb sec single dram component ns clocks mb sec table cpi cache misses time spent alpha programs category specint specfp database sparse clocks instruction cpi cache misses instructions cache misses instructions cache misses instructions cache misses instructions fraction time processor fraction time cache misses fraction time cache misses fraction time cache misses fraction time cache misses despite huge chip caches sophisticated processors order 
problem dynamically scheduled superscalar pipelines capable executing multiple instructions clock cycle long latency limited bandwidth main memory dominates performance applications 
example table shows clock cycles instruction cpi cache misses fraction time spent component alpha spec integer cpu benchmarks spec floating point cpu benchmarks data base program running debit credit benchmark sparse matrix calculation called sparse linpack cve 
database matrix computations spend time memory hierarchy 
capable executing instructions clock cycle peak cpi average cpi applications 
digital started shipping mhz version processor external memory system faster clock larger fraction application time spent waiting main memory 
extraordinary delays memory hierarchy occur despite tremendous resources spent trying bridge processor memory performance gap 
call percent die area transistors dedicated caches memory latency hiding hardware memory gap penalty 
table quantifies penalty grown area transistors microprocessors pat 
fact pentium pro offers package dies larger die kb second level cache 
processor memory performance gap widened point dominating performance applications cumulative effect decades year improvement dram capacity resulted huge individual dram chips 
put dram industry bind 
shows time number dram chips required reasonably configured pc shrinking 
required minimum memory size reflecting application operating system memory usage growing half quarters rate dram chip capacity 
example consider word processor requires mb memory needs increased rate dram chip capacity growth word processor fit kb bytes 
result prolonged rapid improvement dram capacity fewer dram chips needed pc point soon pc customers may require single dram chip 
minimum system drams collective width matches width dram bus microprocessor 
width bits pentium bits risc machines 
shows fourfold increase capacity traditional difference dram generations accompanied fourfold increase width keep minimum memory size 
case intelligent ram iram appear ieee micro april year processor digital alpha digital strong arm sa intel pentium intel pentium pro table memory gap penalty microprocessors 
chip cache size kb kb kb kb kb kb kb kb kb kb memory gap penalty die area counting pad ring memory gap penalty transistors die area mm total transistors total total minimum memory increment simply number dram chips times capacity chip 
plots memory increment dram generation dram width 
difficulty narrower drams provided lowest cost bit bit wide part say cheaper bit wide part 
reasons difference include cheaper package testing time testing time function chip width chip capacity smaller die size wider drams wider busses chip require power ground pins accommodate signal pins cost savings containing narrower parts attractive 
wide drams awkward systems provide error correction data busses 
bit data bus example typically check bits meaning width memory longer necessarily power 
simm module new wide part data older narrow part check bits 
problem new high bandwidth dram interfaces synchronous dram interleaves memory banks internally older drams 
minimum memory size 
problem mb mb mb mb mb mb mb dram generation mb mb mb mb mb gb 
number drams minimum memory size pc time 
desirable minimum memory size increasing capacity dram chip increasing quickly 
world bit wide drams efficient bit wide drams unused memory bits increases effective cost 
figures suggest customers may longer automatically switch larger capacity dram soon generation matches cost bit organization minimum memory increment may larger needed larger capacity dram need wider configuration expensive bit narrow version smaller dram wider capacity match width needed error checking results higher costs 
simm packaging isolates customer drams simm customers prefer cheapest simm smaller narrower drams fewer larger wider drams 
expect mbit dram gbit dram see critical reception 
case intelligent ram iram appear ieee micro april small narrow drams large narrow drams large wide drams dram bus interface dram bus interface dram bus interface 
relationship dram bus width microprocessor versus data width dram chip minimum number dram chips minimum memory capacity 
rectangle represents dram chip area rectangle indicating capacity width indicating number data pins 
example bit wide version mb dram requires chips bit bus mbytes 
bit wide version mb dram bus chips yielding mbytes 
bit wide version mb dram minimum memory increment returns mbytes need just chips bus 

iram potential solution growing processor memory performance gap awkwardness high capacity dram chips believe time consider unifying logic dram 
call chip iram standing intelligent ram transistors merged chip devoted memory 
reason put processor dram increasing processor sram dram practice approximately times denser sram prz ratio larger transistor ratio drams structures shrink cell size 
iram enables larger amount chip memory possible conventional 
dram generation data width 
iram potential solution mb mb mb mb mb mb mb mb mb mb mb bit dram bus bit dram bus mb mb mb mb mb minimum memory increment mb 
minimum memory size dram bus widths dram capacity changes 
bar shows size bit interface intel pentium bit interface risc chips 
examined issue past iram attractive today reasons 
gap performance processors drams widening year years despite efforts architects compiler writers applications developers applications limited memory speed today past 
second actual processor occupies die table upcoming gigabit dram capacity programs data sets fit single chip 
past little memory fit onchip cpu mainly considered building blocks multiprocessors bar noa 
third dram dies grown generation drams metal layers accelerate longer lines larger chips 
high speed interface synchronous dram require fast transistors dram chip 
dram trends logic dram closer speed logic logic fabs past 
potential advantages iram higher bandwidth 
dram naturally extraordinary internal bandwidth essentially fetching square root capacity dram clock cycle chip proces case intelligent ram iram appear ieee micro april sor tap bandwidth potential bandwidth gigabit dram greater indicated logical organization 
important keep storage cell small normal solution limit length bit lines typically bits sense amp 
quadruples number sense amplifiers 
save die area block small number lines reduces internal bandwidth factor meets external demand 
iram goal capture larger fraction potential chip bandwidth 
example prototype gigabit drams 
men tioned cope long wires inherent mm dies gigabit drams vendors metal layers mitsubishi samsung 
total number memory modules chip mbit modules mbit modules respectively 
gigabit iram memory modules bits wide 
tremendous bandwidth sense amps block extra metal layers enable cross chip bandwidth 
assuming kbit metal bus needs just mm mm iram busses running mhz 
internal iram bandwidth high gbytes sec 
comparison sustained memory bandwidth alphaserver includes mhz bit memory bus gbytes sec 
computer architecture researchers case memory bandwidth increasingly limit performance bur 
lower latency 
reduce latency wire length kept short possible 
suggests fewer bits block better 
addition dram cells furthest away processor slower closest ones 
restricting access timing accommodate worst case processor designed aware accessing slow fast memory 
additional reduction latency obtained simply multiplexing address reason iram 
chip dram processor avoids driving wires potentially turning data bus accessing external memory controller 
summary access latency iram processor need limited constraints standard dram part 
lower latency may obtained intelligent utilizing faster circuit topologies redesigning address data schemes 

iram potential solution potential memory latency random addresses ns possible latency oriented dram design chip processor fast second level caches 
recall memory latency alphaserver ns 
points suggest iram offers performance opportunities types applications 
applications predictable memory accesses matrix manipulations may take advantage potential increase iram bandwidth 
applications unpredictable memory accesses large memory footprints data bases may take advantage potential decrease iram latency 
energy efficiency 
integrating microprocessor dram memory die offers potential improving energy consumption memory system 
dram denser sram traditionally chip memory 
iram fewer external memory accesses consume great deal energy drive high capacitance chip buses 
chip accesses energy efficient dram consumes energy sram 
iram potential higher performance conventional approach 
higher performance fixed energy consumption translated equal performance lower amount energy performance advantages iram translated lower energy consumption fro 
memory size width 
advantage iram conventional designs ability adjust size width chip dram 
limited powers length width conventional dram iram designers specify exactly number words width 
flexibility improve cost iram solutions versus memories conventional drams 
board space 
iram may attractive applications board area precious cellular phones portable computers integrates chips 
potential disadvantages iram addition potential advantages questions answered iram succeed case intelligent ram iram appear ieee micro april area speed logic dram process discussions experts circuit design process suggested area cost speed cost today 
area power impact increasing bandwidth dram core standard dram cores designed highly multiplexed lines reduce area power 
effective dram core internal bandwidth need add lines 
area increase affect cost bit iram 
retention time dram core operating high temperatures gia gave rule thumb halving retention rate increase degrees refresh rates rise dramatically iram run temperature microprocessors 
scaling system single iram gigabit dram contains mbytes certainly systems needing memory 
major architecture challenge quantifying pros cons potential solutions 
matching iram commodity focus dram industry today drams second sourced commodities interchangeable allows manufactured high volumes 
single processor architecture adopted adding processor stratify effectively reduce interchangeability 
testing iram cost testing manufacturing significant drams 
adding processor significantly increase test time conventional dram testers 

quantifying potential advantages iram section looks early attempts quantify done iram technology pat fro 
estimating performance iram alpha fastest current microprocessor alpha described sufficient detail cve allow estimate performance iram similar organization 
alpha caches chip kb instruction cache kb data cache kb level cache 
system measured included third level mb cache chip 
table page describes chip system 
designing iram scratch surely different decisions memory hierarchy 
quantifying potential advantages iram performance estimate conventional design suggests potential iram 
estimate time spent table page step estimate performance piece microprocessor implemented iram 
table shows performance factor multiply alpha performance parameters estimate speed iram pat pick single number category pick optimistic pessimistic factors piece 
table performance factors estimating iram performance 
portion microprocessor optimistic time factor pessimistic time factor logic sram dram mentioned guesses slowdown logic dram process range 
optimistic pessimistic factors logic portion processor table 
common mistake assume microprocessor slowdown factor 
shown table vast majority transistors microprocessors sram 
separate factor speed sram dram process times slower 
time main memory times faster iram ns alpha system table 
multiply times 
argue values purpose suggest approach estimating performance supply values 
seen discussions sram performance separately logic performance combined performance estimate may lead inaccurate predictions 
iram different memory hierarchy purposes estimating performance organization adjust performance 
multiply processor time full logic slowdown despite possibility clock rate limited speed hits caches 
misses caches go slower cache multiply misses sram factor 
misses cache iram go chip dram 
wider interface chip believe latency oriented dram lower latency assume misses cache speed 
believe misses faster ns case intelligent ram iram appear ieee micro april alpha multiply dram factor 
table shows optimistic pessimistic performance factors iram organized alpha 
expected spec benchmarks poorest performers iram spend little time memory hierarchy times slower depending iram time factors 
note database varies little slower little faster sparse linpack varies times faster 
table optimistic pessimistic parameters table estimate iram performance programs 
category specint specfp database sparse opt 
pes 
opt 
pes 
opt 
pes 
opt 
pes 
fraction time processor fraction time cache misses fraction time cache misses fraction time cache misses fraction time cache misses total ratio time vs alpha means iram slower study part benchmarks rarely caches 
spec programs original alpha study cve infamous light memory hierarchy reason retired replaced spec benchmarks 
real programs don behave spec 
computer designer wants fastest hardware design microprocessors range performance acceptable result 
iram alpha falls range acceptable performance highest performance microprocessors 
memory gap continues grow expect expect better performance relative conventional designs 
performance potential advantage iram results sufficient justify bold step producing microprocessors dram fab 
reasons iram include cost savings amortizing fab cost dram chips lower power board space lower cost due getting exact 
quantifying potential advantages iram amount memory chip 
keep mind performance estimate case study conventional microprocessor organization iram best way exploit new technology 
section explores alternative model better utilizes potential iram 
estimating performance iram vector processor high speed microprocessors rely instruction level parallelism ilp programs means hardware potential short instruction sequences execute parallel 
mentioned high speed microprocessors rely getting hits cache supply instructions operands sufficient rate keep processors busy 
alternative model exploiting ilp rely caches vector processing 
established architecture compiler model popularized supercomputers considerably older superscalar 
vector processors high level operations linear arrays numbers 
advantages vector computers vectorized programs run include 
result independent previous results enables deep pipelines high clock rates 

single vector instruction great deal means fewer instruction fetches general fewer branch instructions fewer mispredicted branches 

vector instructions access memory block time allows memory latency amortized say elements 

vector instructions access memory regular constant stride patterns allows multiple memory banks simultaneously supply operands 
advantages mean vector processors rely data caches high performance 
rely low latency main memory sram memory banks get high memory bandwidth 
addition interleaved low latency main memory vector computers large register sets typically vector registers bit elements 
bits bits high speed registers vector processors depend multiple pipelined functional units high speed microprocessors 
match high speed functional units high bandwidth memory case intelligent ram iram appear ieee micro april vector processors multiple ports processor memory 
iram memory low latency highly interleaved iram naturally matches needs vector processor 
head hundreds millions transistors chip large register set multiple pipelined functional units quite plausible 
vectors appear promising way exploit iram 
vectors easily allow trade hardware slower clock rate sacrificing peak performance 
example vector processor clock rate operates elements clock cycle peak performance vector processor clock rate operates element clock cycle 
allowing multiple instructions cycle vector machine multiple pipes example cray uses pipes fujitsu vp uses pipes 
iram logic slower factor iram vector processor peak performance consuming twice elements clock cycle trading transistors clock rate 
observed performance depend application 
shown iram vector microprocessor include sixteen bit wide memory ports iram offering collective gb sec memory bandwidth 
sixteen element vector registers 
pipelined vector units floating point add multiply divide integer operations multimedia operations operate element time pipe vector processor operate elements clock cycle cost multiple vector units 
iram spectacular vector performance 
micron dram process mm chip high performance vector accelerator add multiply units running mhz kbit busses running mhz 
combination offers gflops gbytes sec balanced vector system 
putting performance perspective fastest vector uniprocessor cray achieves speed gflops linpack 
historically cray research vector processors doubled performance months gflops iram gbit generation faster vector processor era 
challenge vector processing fraction computation accelerated vector processing 
classically scientific programs deal matrices 
quantifying potential advantages iram benefited vector processing 
new multimedia dsp applications computers may lend vector processors 
new mmx extension instruction set thought modest vector extension 
vector terminology mmx vector registers bit elements functional units pipes 
study nott intended suggest fate iram depends popularity vector processing 
intended show iram performance features may lead trade offs different conventional microprocessor design initial investigations show promise 
estimating energy efficiency iram increasing prevalence portable computing promoted energy efficiency concern primarily circuit designers issue general interest computer architecture community 
examined efficiency processor goal net int scalar processor cache cache 
organization iram design 
memory interface unit queue load store vector registers case intelligent ram iram appear ieee micro april examine energy consumed memory system 
power deceiving metric directly relate battery life 
extreme case putting processor sleep mode wins power metric solution allows accomplished 
energy efficiency expressed joules instruction mips watt better measures machine best utilizes limited battery life 
compare energy efficiency digital strongarm memory system including kb instruction cache kb data cache chip iram memory system fro 
looking number bits unit area strongarm caches versus dram similar technology see difference considerably larger conventional wisdom sram dram cell 
conservative tack compare strongarm iram memory ratios table shows energy efficiency advantage iram 
depending benchmark iram advantage roughly factor 
benchmark perl li gcc compress iram memory iram memory 
related iram may timely new idea 
categories useful classifying related accelerators 
category includes logic chip dram run restricted application 
efforts targeted graphics logic included memory frame buffer 
best known example video dram 
examples mitsubishi dram includes portion logic mbits dram speedup graphics dee graphics accelerator portable pcs 
non graphics examples include cache uses dram increase size gia 
uniprocessors 
category combines processor chip dram 
part attractive high performance power performance system cost performance system combinations shi 

related multiprocessors 
category includes chips intended exclusively building block multiprocessor include mimd multiple instruction streams multiple data streams multiprocessor single chip fil mur include simd single instruction stream multiple data streams multiprocessor array processor single chip aim ell 
category popular research area 
places uniprocessor multiprocessor chips chart showing amount hardware memory axis versus amount hardware processing axis 
units axis bits storage 
axis harder choose compare bit simple processors bit alu bit processors bit alu bit superscalar processor bit alus bit floating point units 
solution sum products arithmetic unit operate parallel multiplied width yielding number bits parallel arithmetic units 
examples number bits parallel arithmetic units types machines listed legend 
simd research machines processor bits chip 
note substantial increase memory mitsubishi uniprocessor single die uses dram 
suggests directions iram 
path right mimd simd chip modest amount memory arithmetic unit 
gradually rising right going larger ratio memory arithmetic units 
lower path follows amdahl rule thumb suggests memory capacity increases linearly speed processor balanced system 
shown graph technology advance increases memory density logic faster 
view early iram researchers promise scalable multiprocessing due part lack sufficient chip memory distracted making uniprocessors bar 
efforts targeted multiple processors chip get high peak performance neglected difficulty programming machines especially memory limited 
gigabit dram sufficient chip memory allow balanced systems fast uniprocessors surely easier program widely applicable 
case intelligent ram iram appear ieee micro april bits arithmetic units simd chip dram uniprocessor sram mimd chip dram uniprocessor dram mimd component sram machine transputer mosaic computational ram pip ram alpha pentium pro mbits memory 
ordering dimensional space bits arithmetic units versus mbits memory 

merging microprocessor dram chip presents opportunities performance energy efficiency cost factor reduction latency factor increase bandwidth factor advantage energy efficiency unquantified cost savings removing superfluous memory reducing board area 
surprising claims exotic unproven technology tapping potential technology years 
believe popularity iram limited amount memory chip expand year 
best case scenario iram expand graphics requires mbits game embedded personal digital assistant markets require mbits storage 
high volume applications turn justify creation process friendly iram dram cells little bigger dram fab amenable logic sram 
iram grows mbits storage iram 
adopted network computer portable pc markets 
success turn microprocessor manufacturers include substantial dram chip dram manufacturers include processors chip 
iram presents opportunity change nature semiconductor industry 
current division logic memory camps homogeneous industry emerge historical microprocessor manufacturers shipping substantial amounts dram just ship substantial amounts sram today historical dram manufacturers shipping substantial numbers microprocessors 
scenarios occur set manufacturers oriented high performance low cost 
revolution occur field needs accurate answers questions speed area power yield logic dram process 
speed area power yield cache memory dram process 
dram change targeted low latency 
dram change targeted large internal bandwidth 
balance desire dram low power keep refresh rates low desire microprocessors high power high performance 
microprocessor portion iram redundant components achieve yields dram achieves redundancy 
built self test bring potentially higher costs iram testing 
right way connect memory modules single cpu single chip iram 
computer architectures compiler optimizations turn high bandwidth iram high performance 
right memory hierarchy iram hierarchy managed 
architectural operating system solution iram applications need memory chip iram 
changes technology applications early risc research developed time investigate new instruction set architectures 
case intelligent ram iram appear ieee micro april list combined potential impact industry iram exciting research area 
answers questions help determine laboratory novelties major trend industry decade 

acknowledgments research supported darpa dabt california state micro program research intel sun microsystems 
people giving feedback earlier versions steven 

aim kimura 
gb parallel image processing ram integrating mb dram processors 
digest technical papers ieee international solid state circuits conference san francisco ca usa feb 
bar barron transputer microprocessor application 
edited aspinall london uk cambridge 

bur burger goodman memory bandwidth limitations microprocessors isca rd annual international conference computer architecture philadelphia pa usa may 
cve performance characterization alpha microprocessor tp spec workloads proceedings 
second international symposium high performance computer architecture san jose ca usa feb 

dal dally fine grain message passing concurrent computers third conference hypercube concurrent computers applications 
pasadena ca usa jan 
edited fox dee deering new form memory optimized graphics siggraph conference proceedings 
orlando fl usa july 

ell elliott stumm computational ram memory simd hybrid application dsp custom integrated circuits conference boston ma may pages 
fil dally carter 
machine multicomputer 
proceedings micro th annual ieee acm international symposium microarchitecture ann arbor mi usa nov dec 

fro cardwell patterson energy efficiency iram architectures submitted isca th annual international conference computer architecture boulder usa june 
gia mb mhz integrated cache memory interface ecc protection proceedings san francisco ca usa feb 
hen hennessy patterson computer organization design nd ed 
san francisco morgan kaufmann publishers 
kitamura 
combined dram logic chip massively parallel systems proceedings 
sixteenth conference advanced research vlsi chapel hill nc usa march 
mur murakami parallel processing ram chip mb dram quad processor 
digest technical papers ieee international solid state circuits conference san francisco ca usa feb 
noa wallach dally machine multicomputer architectural evaluation th annual international symposium computer architecture san diego ca usa may 
pat patterson cardwell anderson cardwell keeton thomas yelick intelligent ram iram chips remember compute 
digest technical papers ieee international solid state circuits conference san francisco ca usa feb 
perl sites studies windows nt performance dynamic execution traces second symposium operating systems design implementation seattle wa usa oct nov 
prz steven new dram technologies comprehensive analysis new architectures resources sebastopol california 
ashley fong pong andreas missing memory wall case processor memory integration international symposium computer architecture philadelphia pa usa may 
case intelligent ram iram appear ieee micro april shi shimizu kondo 
multimedia risc microprocessor mb dram digest technical papers ieee international solid state circuits conference san francisco ca usa feb 
wulf mckee hitting memory wall implications obvious computer architecture news march vol 
