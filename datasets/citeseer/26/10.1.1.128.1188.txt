heterogeneous distributed computing maheswaran tracy braun howard jay siegel parallel processing laboratory school electrical computer engineering purdue university west lafayette usa pre copy edited version chapter appearing encyclopedia electrical electronics engineering webster editor john wiley sons new york ny vol 
pp 

biggest challenges high performance computing machine architectures advanced obtain increased peak performance small fraction performance achieved real application sets 
typical application may various subtasks different architectural requirements 
application executed machine machine spends time executing subtasks unsuited 
advances high speed digital communications possible collections different high performance machines concert solve computationally intensive application tasks 
article describes issues involved heterogeneous computing hc suite machines solve application tasks 
hypothetical example application various subtasks best suited different machine architectures shown frs 
example application executes time units baseline serial machine 
application consists subtasks best suited execute simd synchronous parallel machine second best suited distributed memory mimd asynchronous parallel machine third best suited shared memory mimd machine fourth best suited execute vector pipelined machine 
executing application simd machine may improve execution time simd subtask time units subtasks varying extents 
execution time improvement may factor subtasks may suited simd machine 
different machines match computational requirements individual subtasks result execution time 
hypothetical example advantage heterogeneous suite machines heterogeneous suite time includes inter machine communication overhead frs 
drawn scale 
better baseline serial execution time factor 
subtasks dependent shared data inter machine data transfers need performed multiple machines 
data transfer overhead considered part execution time hc suite 
example time executing vector machine include time needed get data machines 
types hc systems 
article focuses mixed machine hc systems sia heterogeneous suite independent machines interconnected high speed links function 
mixed mode hc refers single parallel processing system processors capable executing synchronous simd asynchronous mimd mode parallelism switch modes instruction level negligible overhead sim 
trac examples mixed mode hc systems prototyped sim 
way exploit mixed machine hc environment decompose application task subtasks subtask computationally suited single machine architecture different subtasks may different computational needs 
subtasks may data dependencies 
subtasks obtained subtask assigned machine matching 
subtasks inter machine data transfers ordered scheduling 
known finding matching scheduling mapping minimize completion time application general np complete fer 
currently programmers manually specify task decomposition assignment subtasks machines 
long term pursuit field heterogeneous computing automate process 
cases application collection independent tasks precedence constrained set subtasks considered previous discussion 
cases matching scheduling problem considers minimization completion time meta task consisting tasks application 
article includes information summarized various projects cover different aspects hc research 
exhaustive survey literature 
section article illustrates concepts involved describing representative techniques systems 
section hc application case studies described 
section example hc environments tools discusses various software systems available manage hc suite machines 
different ways categorizing hc systems taxonomies section 
conceptual model section provides block diagram illustrates involved automatically mapping application hc system 
techniques characterizing applications representing machine performance briefly examined section task profiling analytical benchmarking 
methods characterizations obtaining assignment subtasks machines ordering subtasks assigned machine explored section matching scheduling 
example hc application studies simulation mixing turbulent convection hc system minnesota supercomputer center demonstrated usefulness hc application involving dimensional simulation mixing turbulent convection klm 
system developed hc application consists tmc simd cm mimd cm vector cray silicon graphics workstation communicating high speed high performance parallel interface network 
necessary simulation calculations divided phases calculation velocity temperature fields calculation particle traces calculation particle distribution statistics refinement temperature field 
calculation velocity temperature fields associated phase governed second order partial differential equations 
approximate field components equations dimensional cubic splines grid size 
result linear system equations representing unknown spline coefficients 
system equations spline coefficients solved applying conjugate gradient method 
conjugate gradient computations performed cm 
time interval grid spline coefficients sent cray phase performed 
calculation particle traces phase involved solving set ordinary differential equations velocity field solution phase 
calculation performed vectorized lagrangian approach cray 
computed coordinates particles spline coefficients temperature field transferred cray cm 
phase cm calculate statistics particle distribution assemble dimensional temperature field spline coefficients received phase 
grid splines generate file containing point temperature field representing volume voxels voxel dimensional element 
voxels coordinates particles particles sent sgi workstation 
sgi workstation visualized results interactive volume renderer 
simulation successful demonstration benefits hc authors klm noted required improve environment developing hc applications 
collision galaxies way consisting tmc mimd cm cray mimd ibm mimd sp sgi power challenge carry large simulation colliding galaxies 
objective grand challenge project harness power collection parallel machines address questions origin large scale structure universe galaxies form 
simulation performed solving body dynamics problem gas dynamics problem 
body problem solved self consistent field scf method 
gas dynamics problem solved piecewise parabolic method ppm 
scf code parallelized entire calculation contains particles computer processors processor evolves particles 
processor computes contribution particles global gravitational field 
partial results summed parallel reduction operation 
summing expansion coefficients computed broadcast processors 
processors information reconstruct global gravitational field evaluate gravitational acceleration particles 
computation time step scf requires flop particle 
particles distributed computation time time step approximately equivalent machines 
example particles processor cm particles processor yielded balanced load 
speed obtained cm suite particles machines executing concurrently 
results obtained distributed simulation viewed distributed visualization system 
sgi power challenge solving body problem scf code 
ppm code executed parallel ibm sp machine spmd mode 
ppm algorithm computationally intensive high computation communication ratio 
code obtains nearly mflop node ibm sp 
example hc environments tools section overviews examples software environments tools exist developed hc systems 
examples implemented different levels high level management framework smartnet low level globus toolkit 
functionalities described tend evolve change rapidly descriptions 
tools include legion grn linda cag mentat ninf ses 
smartnet smartnet mapping framework employed managing jobs resources heterogeneous computational environment frg 
smartnet enables users execute jobs network different machines network single machine 
smartnet supports resource management system rms accepts requests mapping job sequence jobs 
jobs assigned machines suite mapping algorithms built smartnet 
traditionally rmss opportunistic load balancing schemes job assigned machine available 
smartnet uses multitude sophisticated algorithms assign jobs machines 
smartnet goal optimize mapping criteria hc environment criteria flexible allowing smartnet adapt different situations environments 
smartnet exploits variety information resources map manage applications heterogeneous environment 
considers computational capabilities machine match computational needs application machine loading availability time needed inter machine data transfers 
smartnet considers current state resources inter machine communication network mapping algorithms assign jobs machines account shared usage resources 
smartnet variety optimization criteria perform mapping 
currently implemented optimization criteria maximizing throughput minimizing expected completion time job minimizing average expected run time job 
mapping engine built smartnet uses set different heuristics search space possible maps find best defined optimization criteria 
heuristics implemented 
include algorithms greedy strategies varying execution time complexities algorithms evolutionary programming strategies 
mapper modular designed implement algorithm satisfies relatively simple interfacing requirements 
smartnet mapping engine considers heterogeneity network machines user tasks 
advantages smartnet constrain user particular programming language require special wrapper code legacy programs 
smartnet requires user provide description time complexity program 
smartnet demonstrates performance enhanced considering machine loading heterogeneity coordinating execution user programs 
smartnet provides global general purpose scalable tunable resource management framework hc systems 
smartnet designed developed naval laboratory operational research laboratories 
ideas lessons learned smartnet designing implementing darpa ito quorum program project called mshn management system heterogeneous networks 
mshn collaborative research effort nps naval postgraduate school naval laboratory purdue university usc university southern california 
technical objective mshn project design prototype refine distributed resource management system leverages heterogeneity resources tasks deliver requested qualities service 
netsolve netsolve client server application designed provide network access remote computational resources solving computationally intense scientific problems cad 
machines participating netsolve system local geographically distributed hc network 
problem netsolve client application task sends request netsolve agent residing different machine 
netsolve agent selects resource problem size nature problem 
instantiations netsolve agents clients 
machine netsolve system runs netsolve computational server access machine scientific packages 
netsolve system accessed variety interfaces including matlab shell scripts fortran 
netsolve called blocking nonblocking fashion computations performed concurrently client system improving performance 
netsolve uses load balancing improve system performance 
machine netsolve system execution time problem estimated 
estimate determine hypothetical best machine execute problem 
execution time estimate factors including size data size problem complexity algorithm network parameters machine characteristics 
maintain accurate system performance information instance agent maintains value workload server 
new workload value conditionally broadcast regular intervals value outside defined range server broadcasts value 
allows accurate system information maintained needlessly burdening network workload value 
netsolve capabilities handling fault tolerance different levels 
servers generally handle failure detection 
clients minimize side effects service failures maintaining lists computational servers 
includes increasing number interfaces improved load balancing allowing user defined functions 
pvm parallel virtual machine pvm software environment enables hc system utilized single connected flexible concurrent computational resource bed sun 
pvm software package consists system level daemons called reside machine hc system library pvm interface routines 
responsible providing services local processes remote processes executing machines hc system 
considering entire set collectively virtual machine formed 
virtual machine allows hc system viewed single 
provide major services process virtual machine management communication synchronization 
process virtual machine management issues include computational unit scheduling placement configuration inclusion remote computers virtual machine naming addressing resources 
communication performed asynchronous message passing allowing sending process continue execution having wait receive acknowledgment 
synchronization processes provided accomplished barriers techniques 
multiple processes synchronized including synchronization processes executing local machine processes executing remotely 
pvm system provides library interface routines 
applications access platforms hc system library calls embedded imperative procedural languages fortran 
library routines resident machine interact provide communication synchronization process management services 
single may provide requested service service provided group hc system working concert 
heterogeneous network computing environment tool aids users pvm decomposing application subtasks deciding distribute subtasks machines currently available hc system bed 
allows programmer explicitly specify parallelism application creating directed graph nodes represent subtasks written fortran arcs represent precedence constraints flow dependencies 
types control constructs conditional looping fan pipelining 
cost executing subtask machine hc system represented user specified cost matrix 
meaning parameters cost matrix defined user estimated execution times utilization costs terms dollars 
execution time uses cost matrix estimate cost effective machine execute subtask 
directed graph cost matrix specified uses pvm constructs configure subset machines defined cost matrix virtual machine 
initiates execution program 
subtask graph realized distinct process machine hc system 
subtasks communicate sending parameter values necessary execution subtask 
parameter values specified user subtask 
parameter values needed execution subtask obtained predecessor subtasks 
set immediate predecessor subtasks required parameters subtask execution earlier predecessor subtasks checked required parameters located 
parameters subtask executed appropriate parameters passed descendant subtasks 
trace execution application display real time replay 
globus metacomputing infrastructure toolkit globus project fok fok defines set low level mechanisms provide basic hc infrastructure requirements communication resource allocation data access 
low level mechanisms part globus metacomputing infrastructure toolkit implement higher level hc services mappers parallel programming tools 
component toolkit defines interface implementation hc environment 
interfaces allow higher level services invoke component mechanisms 
implementation uses low level instructions realize mechanisms different systems occurring hc environments 
presently globus toolkit consists components 
communication component provides wide range communication methods including message passing remote procedure call distributed shared memory multicast 
resource location allocation module provides mechanisms expressing application resource requirements identifying resources suitable requirements scheduling resources located 
unified resource information service component mechanism provided posting receiving real time information hc environment 
data access module responsible providing high speed access remote data files 
resource allocated process creation component initiate computation 
includes initialization executables starting executable passing arguments integrating new process rest computation process termination 
authentication interface module provides basic authentication mechanisms validating identity users resources 
modules globus toolkit considered define hc system 
definition hc system simplifies development higher level applications allowing hc programmers think geographically distributed heterogeneous collections resources unified entities 
allows range alternative infrastructures services applications developed 
stated long term goal globus project address problems configuration performance optimization hc environments 
accomplish goal globus project designing constructing set higher level services layered globus toolkit 
higher level services form adaptive wide area resource environment aware 
taxonomies heterogeneous computing classifications hc systems provided divides systems mixed machine hc systems mixed mode hc systems 
categories defined earlier article 
mixed machine hc systems denote spatial heterogeneity mixed mode hc systems denote temporal heterogeneity 
researchers refined classification obtain different schemes 
taxonomy called em execution mode machine model hc systems 
scheme hc systems categorized orthogonal directions 
direction execution mode machine defined type parallelism supported machine 
example high performance computing architectures specialized support mimd simd vector execution modes 
heterogeneity criterion temporal spatial 
second categorization machine model defined machine architecture machine performance 
example sun sparc cy intel considered different architectures 
addition cpus type driven different speed clocks provide different machine performance considered different machine models 
heterogeneity criterion spatial nature 
hc systems classified counting number execution modes em number machine models mm 
categories proposed single execution mode single machine model single execution mode multiple machine model multiple execution mode single machine model memm multiple execution mode multiple machine model 
fully homogeneous systems class 
hc systems composed different architectures clock speeds execution mode class 
memm classes mixed machine systems memm class include different execution models mixed mode machines 
corresponds mixed mode systems temporal heterogeneity 
hc systems composed different architectures machines different execution models fall memm class 
classification provided hc systems grouped system heterogeneous computing shc network heterogeneous computing nhc 
shc divided shc mixed mode shc 
shc systems perform computations simd mimd modes simultaneously exhibit spatial heterogeneity single machine 
mixed mode shc systems switch execution simd mimd modes parallelism exhibit temporal single machine 
nhc systems divided nhc mixed machine nhc 
nhc denotes homogeneous distributed computing systems mixed machine nhc indicates heterogeneous distributed computing systems 
conceptual model heterogeneous computing examples featured application studies section programmer specified machine assignment program segment initial data item 
long term goals hc research develop software environments automatically find near optimal mapping hc program expressed machine independent high level language 
performing mapping automatically benefits increase portability programmer need concerned composition hc suite easier hc system possibility deriving better mappings user ad hoc methods 
environment exists today researchers working developing environment automatically efficiently perform mapping subtasks machines hc suite 
conceptual model environment dedicated hc suite machines described sid mab 
stage information type application task machine hc suite generate set parameters relevant computational characteristics applications machine architecture features hc system 
set parameters categories computational requirements categories machine capabilities derived 
stage consists components task profiling analytical benchmarking 
task profiling decomposes application task subtasks subtask computationally homogeneous 
usually different subtasks different computational needs 
computational requirements subtask quantified profiling code data 
analytical benchmarking quantifies effectively machines available suite 
model integrating software support needed automating heterogeneous computing systems sid mab 
performs types computations required 
components stage discussed section 
stage requires information available stage derive estimated execution time subtask machine hc suite associated inter machine communication overheads 
statically derived results incorporated initial values machine loading inter machine network loading status parameters machine network faults perform matching scheduling subtasks machines 
result assignment subtasks machines execution execution schedule certain cost metrics minimizing execution time tasks 
matching scheduling hc systems examined detail article 
stage execution application 
dynamic matching scheduling system employed subtask completion times loading status machines network monitored 
monitoring process necessary actual computation times data transfer times may input data dependent deviate static estimates 
information may re invoke matching scheduling stage improve machine assignment execution schedule 
automatic hc relatively new field 
preliminary frameworks task profiling analytical benchmarking mapping proposed research needed conceptual model reality sia sid 
task profiling analytical benchmarking task profiling specifies types computations application program decomposing source program homogeneous code blocks computational requirements fre 
set code types defined features machine architectures available processing requirements applications considered execution hc system phase conceptual mode described previous section 
set code types function application task code types sizes data sets process 
task profiling performed stage conceptual model previous section 
analytical benchmarking provides measure available machines heterogeneous suite performs code types fre 
combination task profiling analytical benchmarking provide necessary information matching scheduling step discussed section 
performance particular code type specific kind machine multi variable function 
variables performance function include requirements application data precision size data set processed algorithm applied programmer compiler efforts optimize program operating system architecture machine execute specific code type 
selection theory collection mathematical formulations proposed selecting appropriate machine code block 
formulations che define analytical benchmarking method measuring optimal speedup particular machine type executing best matched code type baseline system 
ratio actual speedup optimal speedup defines code block matched machine type 
generally actual speedup optimal speedup 
parallel assessment window system paws distributed heterogeneous supercomputing management system briefly examined 
represent example preliminary frameworks implementing task profiling analytical benchmarking 
paws prototype consists tools application characterization tool architecture characterization tool performance assessment tool interactive graphical display tool peg 
application characterization tool transforms program written specific subset ada acyclic graphical language illustrates program data dependencies 
tool groups sets nodes edges functions procedures allowing execution behavior program described various levels 
tool perform task decomposition computational requirements machine capabilities 
benchmark machines architecture characterization tool divides architecture specific type machine categories computation data movement communication control 
category repeatedly partitioned subsystems lowest level subsystems described raw timing information 
performance assessment tool uses information architecture characterization tool generate timing information operations machine 
sets performance parameters application parallelism profiles execution profiles generated performance assessment tool 
parallelism profiles describe applications theoretical upper bounds performance maximal number operations parallelized 
execution profiles represent estimated performance applications partitioned mapped particular machine 
parallelism execution profiles produced traversing applications task flow graph computing recording node performance statistically execution time estimates 
interactive graphical display tool user interface accessing tools paws 
classifies task profiling analytical benchmarking results systematic framework 
generates universal set codes usc task profiling 
usc considered standardized set benchmarking programs analytical benchmarking 
similar hardware organizational information maintained architectural characterization tool paws usc constructed hierarchical structure machines hc suite 
highest level hierarchical structure modes parallelism selected specify machine architectures 
second level finer architectural characteristics organization memory system chosen 
hierarchical structure organized architectural characteristics level choices category type interconnection network 
assigns code type computational characteristic path root hierarchical structure leaf node 
path represents specific set architectural features defined nodes path 
approach extended include generation representative set templates rst characterize execution behavior programs various levels detail 
hc methodologies include mathematical formulation task profiling analytical benchmarking similar concept che fre 
overview matching scheduling matching scheduling important component conceptual model automatic hc earlier 
finding optimal solution matching scheduling problem np complete fer 
example consider matching scheduling subtasks machines 
means possible mappings 
assuming takes evaluate quality mapping exhaustive comparison possible mappings require nanoseconds seconds years 
necessary heuristics find best mappings evaluate possible mapping combinations 
mapping schemes static mapping decisions line execution subtask sil dynamic mapping decisions line execution subtasks frc hal mas 
mathematical formulation matching scheduling hc optimal selection theory ost fre provides known mathematical formulation selecting optimal heterogeneous configuration machines set problems fixed cost constraint hc systems 
ost assumed application consists non overlapping code segments totally ordered time 
execution time application equals sum execution times code segments 
code segment defined decomposable partitioned code blocks executed multiple copies best matched machine type 
sufficient number machines best matched machine type assumed available 
simplicity linear speedup assumed decomposable code segment 
application code segments different types machines execute code segments 
vj number machines type cost machine type cj 
estimated execution time code segment machine type ti optimization problem involves minimizing total execution time application defined subject constraint total cost machines cost incurred type machines 
assume code segment best suited machine type vj number type machines execution time code segment type machine vj 
goal minimize total execution time application minimize total cost constraint augmented optimal selection theory extension ost 
considers performance code segments available machine type choices just best matched machine type fixed number machines type 
practice extension useful best matched machine may available limited number machines type may available 
extension ost provided heterogeneous optimal selection theory host che 
host extends allowing concurrent execution mutually independent code segments different types machine incorporating effects different possible local mappings 
consider example code block multiplication matrices distributed memory parallel machine 
implementations varying execution characteristics derived code block 
host assumes best mapping choice minimum execution time known code block 
generalized optimal selection theory refines ost handle communication delays 
basic code element called process 
application represented directed acyclic graph dag node denotes process arc denotes dependency processes 
node number weights attached corresponding execution times process machine type known mapping machine 
edge number weights communication path possible pair host machines 
matching scheduling problem formulated objective assigning node machine type finding start time node completion time application minimized 
polynomial time algorithms provided certain types dags 
static matching scheduling heuristics heuristics summarized assumptions noted 
application task represented dag nodes subtasks need executed perform application arcs data dependencies subtasks 
edge labeled global data item transferred subtasks connected edge 
matching scheduling algorithm controls hc machine suite hardware platform 
subtask execution non preemptive 
estimated expected execution time subtask machine known 
pair machines hc suite equation estimating time send data machines function data set size known 
cluster mapping heuristic hc matching scheduling process thought mapping graph represents set subtasks task graph graph represents set machines hc suite system graph 
cluster mapping performed stages 
stage task graph system graph clustered 
task graph clustering combines communication intensive subtasks cluster 
similarly system graph clustering combines machines tightly coupled small inter machine communication times cluster 
clustering task graph depend clustering system graph vice versa 
task system graph needs clustered 
second phase clustered task graph mapped clustered system graph 
clustering reduces complexity mapping problem improves quality resulting mapping 
min time heuristic min time lmt heuristic static matching scheduling algorithm subtasks hc system 
list scheduling class algorithms 
lmt algorithm uses phase approach 
phase uses technique called level sorting order subtasks precedence constraints 
level sorting defined follows 
level contains subtasks incident arcs 
predecessors arcs level subtask levels 
subtask level exists incident arc data dependency source subtask level 
level sorting technique clusters subtasks able execute parallel 
second phase lmt algorithm uses min time algorithm assign subtasks level level 
min time algorithm greedy method attempts assign subtask best machine 
number subtasks number machines smallest subtasks merged number subtasks equal number machines 
subtasks ordered descending order average computation time 
subtask assigned machine minimum completion time 
sorting subtasks average computation time increases likelihood larger subtasks getting faster machines 
optimization lmt algorithm discussed involves information amount communication subtasks different levels 
enables scheduler map subtasks share large amounts data machine 
genetic matching scheduling heuristic genetic algorithms gas possible solutions encoded chromosomes set called population 
population iteratively operated steps stopping criterion met 
step selection step chromosomes removed duplicated fitness value measure quality solution represented chromosome 
followed crossover step chromosomes paired corresponding components paired chromosomes exchanged 
chromosomes randomly mutated constraint resulting chromosomes represent valid solutions physical problem 
apply gas subtask matching scheduling problem hc systems approach chromosomes encoded parts matching string mat scheduling string ss 
mat subtask si assigned machine mj 
scheduling string topological sort dag representing task valid total ordering partially ordered dag 
ss subtask si th subtask total ordering 
chromosome associated fitness value completion time solution represented chromosome expected execution time application task mapping specified chromosome 
small scale tests subtasks machines population size ga approach solution mapping expected completion time optimal solution exhaustive search 
large scale tests subtasks machines population size ga approach produced solutions mappings average better produced faster non evolutionary basic min time lmt heuristic proposed 
dynamic matching scheduling heuristics static mapping heuristics assume accurate estimates available parameters subtask completion times data transfer times 
general estimates degree uncertainty subtask computation times data transfer times may dependent input data 
dynamic mapping heuristics handle uncertainty may needed 
researchers proposed different dynamic heuristics varying hc models bur frc hal 
furthermore dynamic mapping heuristics machines come line go line run time 
hybrid hybrid heuristic described dynamic algorithm matching scheduling subtask dags hc systems mas 
initial statically obtained matching scheduling provided input hybrid 
hybrid executes phases 
phase hybrid performed prior application execution subtasks partitioned levels lmt heuristic 
subtask assigned rank examining subtasks level level 
rank subtask th level set expected computation time machine assigned initial matching 
rank subtask si level determined computing length critical path si subtask execution terminates 
second phase hybrid occurs application execution 
hybrid changes matching scheduling subtasks level subtasks level running 
subtasks level examined descending order static rank subtask assigned machine earliest completion time particular subtask 
hybrid starts scheduling level subtasks level subtask begins execution finish level remapping level subtask input data machine available needs execute 
level scheduled highly actual execution time information subtasks levels 
may subtasks levels running waiting execution subtasks level considered remapping 
subtasks expected execution times 
simulation results indicate hybrid improve performance statically obtained initial matching scheduling cases 
initial mappings simulation generated baseline heuristic 
timings indicate remapping time needed level subtasks order hundreds milliseconds machines subtasks 
worst case situation obtain complete overlap execution subtasks operation hybrid computation time shortest running subtask greater level scheduling time 
ongoing research examine ways increase performance gain obtained hybrid 
generational scheduling generational scheduling gs heuristic dynamic mapping heuristic subtasks hc systems frc 
cyclic heuristic stages 
gs forms partial scheduling problem pruning subtasks unsatisfied precedence constraints initial dag represents application 
initial partial scheduling problem consists subtasks independent incident edges dag 
subtasks initial partial scheduling problem mapped machine auxiliary scheduler 
auxiliary scheduler considers subtasks assignment come serve order 
subtask assigned machine minimizes completion time particular subtask 
subtask initial partial scheduling problem completes execution gs heuristic performs remapping 
remapping gs revises partial scheduling problem adding removing subtasks 
completion subtask triggered remapping event may satisfied precedence constraints subtasks 
subtasks added initial partial scheduling problem 
subtasks started execution removed initial partial scheduling problem 
revised partial scheduling problem obtained subtasks mapped hc machine suite auxiliary scheduler 
procedure cyclically performed completion subtasks 
self adjusting scheduling heterogeneous systems self adjusting scheduling heterogeneous systems sash heuristic dynamic scheduling algorithm mapping set independent tasks meta task hc suite machines hal 
processor dedicated compute schedule scheduling overlapped execution tasks 
scheduling phase scheduling processor loads tasks phase working processors local queues 
dedicated processor schedules subset tasks previously scheduled tasks executed working processors 
duration scheduling phase determined lower bound estimate load working processors 
working processor complete executing tasks local queue signals scheduling processor scheduling processor assigns tasks processors partial schedule just computed 
sash heuristic computes schedules variation branch bound algorithm 
variation tree represent space possible schedules 
node tree represents partial schedule consisting set tasks assigned corresponding set processors 
edge node represents augmentation schedule task processor assignment 
scheduling phase consists sash iterations 
iteration node lowest cost expanded augmenting partial schedule task processor assignment 
node expansions terminate tasks scheduled time scheduling phase expires 
matching scheduling meta tasks defined earlier article meta task collection independent tasks need mapped hc suite 
tasks may subtasks data dependencies 
heuristics environments considered previous sections article suitable mapping tasks decomposed subtasks data dependencies 
exceptions include environments smartnet netsolve manage meta tasks decomposed tasks mapping heuristic sash meta tasks 
typically independent tasks involved tasks arrive hc suite random fashion service 
machines suite may go line new machines may come line 
dynamic mapping heuristics usually employed assign tasks machines 
furthermore tasks deadlines priorities associated 
types dynamic approaches line interval 
line approach assigns task machine submitted 
interval approach waits set new tasks arrive map tasks remap earlier tasks started execution 
developing heuristics matching scheduling meta tasks hc systems active research area 
summary directions article illustrates concepts involved heterogeneous distributed computing sampling various research development activities area 
means exhaustive survey hc literature 
practical importance hc revealed application studies summarized article 
conceptual model provided envisions automatic hc programming environment 
components model require research devising practical theoretically sound methodologies sia sid 
flavor performed matching scheduling provided article 
important question particularly relevant stages conceptual model information obtained automatically information provided programmer areas researched realize automatic hc environment envisioned developing machine independent programming languages designing high speed networking systems studying communication protocols reliable low overhead data transmission quality service requirements devising debugging tools formulating algorithms task migration fault tolerance load balancing designing user interfaces user friendly programming environments developing algorithms applications heterogeneous computing requirements 
issues pertain meta tasks application decomposed subtasks 
machine independent programming languages allow user augment code compiler directives necessary program hc system 
aspects considered designing language directives compilation program efficient code machines suite decomposition tasks subtasks determination computational requirements subtask machine dependent subroutine libraries 
need debugging performance tuning tools hc suite machines 
involves research areas distributed programming environments visualization techniques 
area research dynamic task migration different parallel machines execution time 
current research area involves determining move executing task different machines ars ars dynamic task migration load rebalancing fault tolerance 
ideally information current loading status machines hc suite network incorporated mapping decisions 
methods developed measuring current loading determining status faulty faulty estimating subtask completion times 
uncertainty estimated parameter values subtask completion times taken consideration determining machine assignment execution schedule 
summary currently available hc systems demonstrate significant benefits require programmer intimate knowledge involved mapping application task suite machines 
widespread hc system hindered 
research areas briefly explained article improve situation allow hc realize full potential 
acknowledgment development article supported part darpa ito quorum program nps subcontract numbers 
authors noah beck kwok mitch comments 
bibliography ars armstrong siegel cohen tan dietz fortes dynamic task migration spmd simd virtual machines 
int 
conf 
parallel processing icpp vol ii aug pp 

ars armstrong siegel dynamic task migration simd spmd virtual machines 
st ieee int 
conf 
engineering complex computer systems nov pp 

bed beguelin dongarra geist manchek sunderam visualization debugging heterogeneous environment 
computer 
bur ramanujan siegel method line line derived iterative automatic target recognition tasks particular class heterogeneous parallel platforms 
supercomputing journal appear preliminary version th heterogeneous computing workshop hcw apr pp 

butler lusk monitors messages clusters parallel programming system 
parallel computing 
cag carriero gelernter mattson linda heterogeneous computing environments 
st workshop heterogeneous processing whp mar pp 

cad casanova dongarra netsolve network enabled server solving computational science problems 
int 
supercomputer applications high performance computing 
che chen selection theory methodology heterogeneous supercomputing 
nd workshop heterogeneous processing whp apr pp 

survey heterogeneous computing concepts systems 
proc 
ieee 
ed heterogeneous computing 
norwood ma artech house 

wu portable programming model network heterogeneous computing 
ed heterogeneous computing norwood ma artech house pp 

fer fernandez allocating modules processors distributed system 
ieee trans 
softw 
eng se 
fok foster kesselman globus metacomputing infrastructure toolkit 
int 
supercomputer applications high performance computing 
fok foster kesselman globus project status report 
th heterogeneous computing workshop hcw mar pp 

fox web high performance computing communications 
th ieee symp 
high performance distributed computing aug 
fre freund optimal selection theory 
supercomputing nov pp 

frc freund carter watson keith generational scheduling heterogeneous computing systems 
int 
conf 
parallel distributed processing techniques applications pdpta aug pp 

frg freund campbell hensgen keith kidd lima moore rust siegel scheduling resources multi user heterogeneous computing environments smartnet 
th heterogeneous computing workshop hcw mar pp 

freund kidd hensgen moore smartnet scheduling framework meta computing 
nd int 
symp 
parallel architectures algorithms networks june pp 

frs freund siegel heterogeneous processing 
computer 
yang distributed heterogeneous supercomputing management system 
computer 
grn grimshaw nguyen lewis campus wide computing early results legion university virginia 
int 
supercomputer applications high performance computing 
grimshaw weissman west meta systems approach combining parallel processing heterogeneous distributed computing systems 
parallel distributed computing 
hal lilja dynamic scheduling techniques heterogeneous computing systems 
concurrency practice experience 
iverson parallelizing existing applications distributed heterogeneous environment 
th heterogeneous computing workshop hcw apr pp 

ahmad optimal task assignment heterogeneous computing systems 
th heterogeneous computing workshop hcw apr pp 

prasanna wang heterogeneous computing challenges opportunities 
computer 
klm chin purcell case study metacomputing distributed simulations mixing turbulent convection 
nd workshop heterogeneous processing whp apr pp 

potter scott dynamic task mapping algorithms distributed heterogeneous computing environment 
th heterogeneous computing workshop hcw apr pp 

mab maheswaran braun siegel high performance mixed machine heterogeneous computing th euromicro workshop parallel distributed processing jan pp 

mas maheswaran siegel dynamic matching scheduling algorithm heterogeneous computing systems 
th heterogeneous computing workshop hcw mar pp 

youssef choi matching scheduling generalized optimal selection theory 
rd heterogeneous computing workshop hcw apr pp 

norman beckman bryan gannon keahey welling yang galaxies collide way example heterogeneous wide area collaborative supercomputing 
int 
supercomputer applications high performance computing 
peg pease ahmad andrews bey karpinski paws performance evaluation tool parallel computing systems 
computer 
ses sato matsuoka ninf network information library globally high performance computing 
parallel object oriented methods applications 
watson flann freund genetic simulated annealing scheduling data dependent tasks heterogeneous environments 
th heterogeneous computing workshop hcw apr 
sia siegel antonio metzger tan li heterogeneous computing 
ed parallel distributed computing handbook new york ny mcgraw hill pp 

sid siegel dietz antonio software support heterogeneous computing 
tucker jr 
ed computer science engineering handbook boca raton fl crc press pp 

sim siegel maheswaran watson antonio atallah mixed mode system heterogeneous computing 
ed heterogeneous computing norwood ma artech house pp 

sil lee compile time scheduling heuristic interconnection constrained heterogeneous processor architectures 
ieee trans 
parallel distrib 
syst 
singh youssef mapping scheduling heterogeneous task graphs genetic algorithms 
th heterogeneous computing workshop hcw apr pp 

sun sunderam pvm framework parallel distributed computing 
concurrency practice experience 
wang 
kim nichols freund siegel nation augmenting optimal selection theory 
st workshop heterogeneous processing whp mar pp 

wang siegel roychowdhury 
task matching scheduling heterogeneous computing environments genetic algorithm approach 
parallel distributed computing 
watson siegel antonio nichols atallah framework compile time selection parallel modes simd spmd heterogeneous environment 
nd workshop heterogeneous processing whp apr pp 

weaver linguistic support heterogeneous parallel processing survey approach 
rd heterogeneous computing workshop hcw apr pp 

yang ahmad estimation execution times heterogeneous supercomputer architecture 
int 
conf 
parallel processing icpp vol aug pp 


