unsupervised word sense disambiguation rivaling supervised methods david yarowsky department computer information science university philadelphia pa usa yarowsky cis upenn edu presents unsupervised learning algorithm sense disambiguation trained unannotated english text rivals performance supervised techniques require time consuming hand annotations 
algorithm powerful constraints words tend sense discourse sense collocation exploited iterative bootstrapping procedure 
tested accuracy exceeds 
presents unsupervised algorithm accurately disambiguate word senses large completely untagged corpus 
algorithm avoids need costly hand tagged training data exploiting powerful properties human language 
sense collocation nearby words provide strong consistent clues sense target word conditional relative distance order syntactic relationship 

sense discourse sense target word highly consistent document 
language highly redundant sense word ectively overdetermined 
algorithm uses properties incrementally identify collocations target senses word collocations note problem sense disambiguation assigning instance word established sense de nitions dictionary 
di ers sense induction distributional similarity partition word instances clusters may standard sense partitions 
traditional dictionary de nition collocation appearing location juxtaposition words 
idiomatic non compositional interpretation implied 
sense 
procedure robust exhibits strengths supervised approaches including order information lost earlier unsupervised algorithms 
sense discourse observation words strongly tend exhibit sense discourse document stated quanti ed gale church yarowsky 
date full power property exploited sense disambiguation 
reported rst take advantage regularity conjunction separate models local context word 
importantly sense discourse hard constraint ects classi cation probabilistically overridden local evidence strong 
current sense discourse hypothesis tested set examples hand tagged period years data studied disambiguation experiments 
words table measures claim accuracy word occurs discourse takes discourse applicability word occur discourse 
sense discourse hypothesis word senses accuracy plant living factory tank vehicle steal boil palm tree hand axes grid tools sake bene drink bass sh music space volume outer motion legal physical crane bird machine average clearly claim holds high reliability words may con dently exploited source evidence sense tagging 
sense collocation strong tendency words exhibit sense collocation observed quanti ed yarowsky 
ect varies depending type collocation 
strongest immediately adjacent collocations weakens distance 
stronger words predicate argument relationship arbitrary associations equivalent distance 
stronger collocations content words function words 
general high reliability behavior excess adjacent content words example extremely useful property sense disambiguation 
supervised algorithm property yarowsky 
decision list control structure rivest algorithm integrates wide diversity potential evidence sources lemmas ected forms parts speech arbitrary word classes wide diversity positional relationships including local distant collocations trigram sequences predicate argument association 
training procedure computes word sense probability distributions collocations orders log likelihood ratio log pr pr optional steps interpolation pruning 
new data classi ed single predictive piece disambiguating evidence appears target context 
combining probabilities decision list approach avoids problematic complex modeling statistical dependencies interesting speculate reasons phenomenon 
tendency statistical distinct arbitrary terms moderate corpus frequency quite occur discourse homographs 
particularly true content words exhibit bursty distribution 
appears human writers active tendency avoid mixing senses discourse 
small study homograph pairs observed occur roughly times arbitrary word pairs comparable frequency 
regardless origin phenomenon strong signi cant practical additional probabilistic disambiguation constraint 
ect continuous function conditional burstiness word tendency deviate constant poisson distribution corpus 
ratios involve observed value smoothing crucial 
process employed sensitive including type collocation adjacent bigrams wider context collocational distance type word content word vs function word expected amount noise training data 
details provided yarowsky appear 
encountered frameworks 
algorithm especially suited utilizing large set highly non independent evidence 
general decision list algorithm suited task sense disambiguation component unsupervised algorithm 
unsupervised learning algorithm words tend occur collocations reliably indicate sense tend occur multiple collocations 
provides mechanism bootstrapping sense tagger 
begins small set seed examples representative senses word incrementally augment seed examples additional examples sense combination collocation sense discourse tendencies 
algorithms accomplish similar ends approach advantages simplicity ability build existing supervised classi cation algorithm modi cation 
shown empirically exhibits considerable ectiveness 
algorithm illustrated disambiguation instances polysemous word plant previously untagged corpus 
step large corpus identify examples polysemous word storing contexts lines initially untagged training set 
example sense training examples keyword context plant operating thousands plant animal species zonal distribution plant life 
strain microscopic plant life 
monomer plant 
apparatus plant animal cells computer disk drive plant located 
divide life plant animal kingdom close studies plant life natural 
car truck plant japan 
keep manufacturing plant pro table molecules plant animal tissue union responses plant closures 
animal plant tissues dangers plant animal life manufacturing plant orlando 
growth aquatic plant life water 
automated manufacturing plant 
animal plant life discovered st louis plant manufacturing computer manufacturing plant adjacent 
proliferation plant animal life 
including variants em algorithm baum dempster especially applied gale church yarowsky 
supervised classi cation algorithm returns probabilities classi cations may potentially 
include bayesian classi ers mosteller wallace implementations neural nets brill rules brill 
step possible sense word identify relatively small number training examples representative sense 
accomplished hand tagging subset training sentences 
laborious procedure identifying small number seed collocations representative sense tagging training examples containing seed collocates seed sense label 
remainder examples typically constitute untagged residual 
strategies identifying seeds require minimal human participation discussed section 
example words life manufacturing seed collocations senses plant labeled respectively 
partitions training set examples living plants examples manufacturing plants residual examples 
sense training examples keyword context strain microscopic plant life 
zonal distribution plant life 
close studies plant life natural 
rapid growth aquatic plant life water 
proliferation plant animal life 
establishment phase plant virus life cycle 
divide life plant animal kingdom dangers plant animal life 
mammals animal plant life beds support plant life river 
heavy seas damage plant life growing 

monomer plant 
molecules plant animal tissue 
car truck plant japan 
apparatus plant animal cells 
union responses plant closures 
cell types plant kingdom 
said plant operating 
thousands plant animal species animal plant tissues 
computer disk drive plant located 

automated manufacturing plant 
vast manufacturing plant distribution 
chemical manufacturing plant producing keep manufacturing plant pro table computer manufacturing plant adjacent 
discovered st louis plant manufacturing copper manufacturing plant copper wire manufacturing plant example 
cement manufacturing plant 
manufacturing plant dow 
manufacturing plant orlando 
useful visualize process seed development graphically 
gure illustrates sample initial state 
circled regions training examples contain seed collocate 
bulk sample points constitute untagged residual 
purposes exposition assume binary sense partition 
straightforward extend senses sets seeds 

aa life 

bbb manufacturing sample initial state sense training example sense training example currently unclassi ed training example life set training examples containing collocation life 
step train supervised classi cation algorithm sense sense seed sets 
decision list algorithm yarowsky identi es collocations reliably partition seed training data ranked purity distribution 
abbreviated example decision list trained plant seed data 
initial decision list plant abbreviated collocation sense plant life manufacturing plant life words manufacturing words animal words equipment words employee words assembly plant plant closure plant species automate words microscopic plant 
note collocate may appear multiple times list di erent collocational relationships including left adjacent right adjacent cooccurrence positions word window various syntactic associations 
di erent positions yield substantially di erent likelihood ratios cases plant vs plant indicate entirely di erent classi cations 
step apply resulting classi er entire sample set 
take members residual tagged sense sense probability certain threshold add examples growing seed sets 
decision list algorithm additions contain newly learned collocations reliably indicative previously trained seed sets 
acquisition additional partitioning collocations cooccurrence previously identi ed ones illustrated lower portion 
step optionally sense discourse constraint lter augment addition 
details process discussed section 
brief instances polysemous word discourse assigned sense sense tag may extended examples discourse conditional relative numbers probabilities associated tagged examples 
labeling previously untagged contexts sense discourse property change disc 
tag numb 
training examples discourse existence plant animal life 
classi ed plant animal 
bacterial plant cells enclosed life plant producing stem aspect plant life example 
tissues plant egg cells 
plant growth attuned augmentation training data form bridge new collocations may occur nearby context previously identi ed collocations 
bridge sense collocate cell illustrated graphically upper half 
similarly sense discourse constraint may correct erroneously labeled examples 
example error correction sense discourse property change disc 
tag numb 
training examples discourse contains varied plant animal life common plant life 
slight arctic plant species 
protected plant parts remaining step repeat step iteratively 
training sets sense seeds plus newly added examples tend grow residual tend shrink 
additional details aimed correcting avoiding misclassi cations discussed section 
aa aa aa aa aaa aa aa aa life microscopic species animal cell 
bbb 
manufacturing bb bb bbb bb bb bb bb bbb bbb equipment bb bb employee automate sample intermediate state steps step 
training parameters held constant algorithm converge stable residual set 
note training examples exhibit multiple collocations indicative sense illustrated 
decision list algorithm resolves con icts single reliable piece evidence matching collocations 
circumvents problems associated non independent evidence sources 
bb bb bb bb bb aa aa aaa bb aa aa aa aa aa aa aa aa aa aa aa aa aa aa aa aa aa aa aa bb bb bb bb bb bbb bb sample final state step classi cation procedure learned nal supervised training step may applied new data annotate original untagged corpus sense tags probabilities 
abbreviated sample nal decision list plant 
note original seed words longer top list 
displaced broadly applicable collocations better partition newly learned classes 
cases multiple seeds possible original seed sense indicator sense collocate compatible second class 
noise introduced irrelevant misleading seed words fatal 
may corrected majority seeds forms coherent collocation space 
final decision list plant abbreviated collocation sense plant growth car words plant height union words equipment words assembly plant nuclear plant ower words job words fruit words plant species 
decision list applied new test sentence loss animal plant species extinction 
highest ranking collocation target context species classify example sense living plant 
available information occurrences plant discourse may override classi cation described section 
options training seeds algorithm seed words accurately productively distinguish possible senses 
seed words selected strategies words dictionary de nitions extract seed words dictionary entry target sense 
done automatically words occur signi cantly greater frequency entry relative entire dictionary 
words entry appearing reliable collocational relationships target word weight criteria yarowsky 
single de ning collocate class remarkably performance identifying single de ning collocate class bird machine word crane seeds contexts containing words 
wordnet miller automatic source de ning terms 
label salient corpus collocates words occur target word unusually great frequency especially certain collocational relationships tend reliable indicators target word senses crane 
human judge decide done quickly typically minutes full list words 
occurrence analysis selects collocates span space minimal overlap optimizing orts human assistant 
fully automatic approach yields rich highly reliable seed sets minimal 
escaping initial misclassi cations previous bootstrapping approaches algorithm escape initial 
examples added growing seed sets remain long probability classi cation stays threshold 
classi cation begins new examples crucial collocate returned residual may classi ed differently 
contexts added wrong seed set misleading word dictionary de nition may typically correctly ed iterative training proceeds 
redundancy language respect collocation process primarily self correcting 
certain strong collocates may entrenched indicators wrong class 
discourage behavior training algorithm techniques incrementally increasing width context window intermediate convergence periodically adds new feature randomly perturbing class inclusion threshold similar simulated annealing 
sense discourse property algorithm performs local collocational information treating token target word independently 
accuracy improved exploiting fact occurrences word discourse exhibit sense 
property places step seed training options samp 
major dict 
top schutze word senses size sense words defn 

iter 
plant living factory space volume outer tank vehicle container motion legal physical bass sh music palm tree hand steal boil axes grid tools duty tax obligation drug medicine sake bene drink crane bird machine avg algorithm converged step iteration 
step property error correction 
polysemous word plant occurs multiple times discourse tokens tagged algorithm low local collocation information may overridden dominant tag discourse 
probability di necessary cation determined empirically early pilot study 
decision total number occurrences plant discourse number occurrences assigned majority minor senses discourse cumulative scores sum log likelihood ratios 
cumulative evidence exceeds minority threshold conditional minority cases relabeled 
case admit cation unclear sense dominant 
con dent local classi cations tend overridden dominant tag overwhelming strength sense tendency 
property iteration similar nal post hoc application helps prevent initially collocates gaining 
major di erence discourses substantial disagreement concerning dominant sense instances discourse returned residual merely leaving current tags unchanged 
helps improve purity training data 
fundamental limitation property coverage 
noted section half examples occur discourse instances word provide evidence sense protect misclassi cation 
additional hope cases isolated tokens tend strongly favor particular sense bursty 
additional information 
evaluation words evaluation randomly selected previously studied literature 
include words sense di erences realized di erences french translation drug duty words schutze disambiguation experiments tank space motion plant 
data extracted word corpus containing news articles scienti abstracts spoken transcripts novels certainly constitute largest training testing sets sense disambiguation literature 
columns illustrate di erences seed training options 
words seeds surprisingly 
approach successful senses complex concept space adequately represented 
salient words dictionary de nition seeds increases coverage concept space improving accuracy 
spurious words example sentences source noise 
quick hand tagging list algorithmically identi ed salient collocates appears worth ort due increased accuracy minimal cost 
columns illustrate ect adding probabilistic sense discourse constraint collocation models dictionary entries training seeds 
column shows ectiveness number words studied limited highly time consuming constraint full hand tagging necessary direct comparison supervised training 
post hoc constraint 
apparently small absolute terms average represents reduction error rate 
applied iteration process reduces training noise yielding optimal observed accuracy column 
comparative performance column shows relative performance supervised training decision list algorithm applied data discourse information 
unsupervised training additional sense discourse constraint frequently exceeds value 
column shows performance schutze unsupervised algorithm applied words trained new york times news service corpus 
algorithm exceeds accuracy word average relative performance vs 
comparison previous algorithm exhibits fundamental advantage supervised learning algorithms including black hearst gale 
yarowsky leacock 
bruce wiebe lehman require costly hand tagged training sets 
raw unannotated monolingual corpora 
hope aligned bilingual corpora training data supervised algorithms brown approach su ers limited availability corpora frequent failure bilingual translation di erences model monolingual sense di erences 
dictionary de nitions optional seed unsupervised algorithm stems long history dictionary approaches including lesk guthrie 
ide slator 
earlier approaches sophisticated measures overlap dictionary de nitions realized potential combining relatively limited seed information de nitions nearly unlimited occurrence information extractable text corpora 
unsupervised methods shown great promise 
dagan itai method occurrence statistics independent monolingual corpora languages guide lexical choice machine translation 
translation hebrew verb object pair lah tom sign seal contract treaty determined probable combination words english monolingual corpus 
shows leveraging bilingual lexicons monolingual di erence striking schutze data exhibit higher baseline probability vs words constitute easier task 
language models overcome need aligned bilingual corpora 
hearst proposed early application bootstrapping augment training sets supervised sense tagger 
trained fully supervised algorithm hand labelled sentences applied result new data added tagged examples training set 
regrettably algorithm described sentences developed 
current di ers eliminating need training data entirely collocation discourse constraints accomplish 
schutze pioneered hierarchical clustering word senses 
disambiguation experiments schutze post hoc alignment clusters word senses 
toplevel cluster partitions purely distributional information necessarily align standard sense distinctions generated sense clusters manually assigned hand inspection sentences cluster 
contrast algorithm uses automatically acquired seeds tie sense partitions desired standard useful anchor guide 
addition schutze performs classi cations treating documents large unordered bag words 
doing loses important distinctions collocational distance word sequence existence predicate words 
contrast algorithm models properties carefully adding considerable discriminating power lost relatively impoverished models language 
essence algorithm works harnessing powerful empirically observed properties language strong tendency words exhibit sense collocation discourse 
attempts derive maximal leverage properties modeling rich diversity collocational relationships 
uses discriminating information available algorithms treating documents bags words ignoring relative position sequence 
strengths sensitive wider range language detail typically captured statistical sense disambiguation algorithms 
unsupervised algorithm works surprisingly directly outperforming schutze unsupervised algorithm test words 
impressively nearly performance supervised algorithm identical training contexts vs cases achieves superior performance sense constraint vs 
indicate cost large sense tagged training corpus may necessary achieve accurate word sense disambiguation 
partially supported fellowship arpa aro daal pri 
author information principles research center bell laboratories greatly resources support 
jason eisner mitch marcus mark liberman alison mackey dan melamed lyle ungar valuable comments 
baum inequality associated maximization technique statistical estimation probabilistic functions markov process inequalities pp 
black experiment computational discrimination english word senses ibm journal research development pp 
brill eric corpus approach language learning ph thesis university 
brown peter stephen della pietra vincent della pietra robert mercer word sense disambiguation statistical methods proceedings th annual meeting association computational linguistics pp 
bruce rebecca janyce wiebe word sense disambiguation decomposable models proceedings nd annual meeting association computational linguistics las cruces nm 
church stochastic parts program noun phrase parser unrestricted text proceeding ieee international conference speech signal processing glasgow 
dagan ido alon itai word sense disambiguation second language monolingual corpus computational linguistics pp 
dempster laird rubin maximum likelihood incomplete data em algorithm journal royal statistical society pp 
gale church yarowsky method disambiguating word senses large corpus computers humanities pp 
gale church yarowsky 
discrimination decisions dimensional spaces 
palmer eds current issues computational linguistics honour don walker kluwer academic publishers pp 

guthrie guthrie wilks subject dependent occurrence word sense disambiguation proceedings th annual meeting association computational linguistics pp 
hearst marti noun homograph disambiguation local context large text corpora corpora university waterloo ontario 
leacock claudia geo rey towell ellen voorhees corpus statistical sense resolution proceedings arpa human language technology workshop 
lehman jill essential nature statistical knowledge sense resolution proceedings twelfth national conference onarti cial intelligence pp 
lesk michael automatic sense disambiguation tell pine cone ice cream cone proceeding conference association computing machinery newyork 
miller george wordnet line lexical database international journal lexicography 
mosteller frederick david wallace inference federalist addison wesley reading massachusetts 
rivest learning decision lists machine learning pp 
schutze hinrich dimensions meaning proceedings supercomputing 
slator brian context sense preference text intelligent systems current research text analysis information extraction retrieval jacobs ed ge research development center newyork 
jean nancy ide word sense disambiguation large neural networks extracted machine readable dictionaries proceedings coling pp 
yarowsky david word sense disambiguation statistical models roget categories trained large corpora proceedings coling nantes france 
yarowsky david sense collocation proceedings arpa human language technology workshop princeton 
yarowsky david decision lists lexical ambiguity resolution application accent restoration spanish french proceedings nd annual meeting association computational linguistics las cruces nm 
yarowsky david 
homograph disambiguation speech synthesis 
hirschberg sproat van santen eds progress speech synthesis springer verlag appear 
