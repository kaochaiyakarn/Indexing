support vector machines classifying large sets multi represented objects hans peter kriegel peer kr ger matthias schubert institute computer science university munich 
munich germany kriegel schubert dbs informatik uni muenchen de databases key technology molecular biology data intensive discipline 
molecular biological databases heterogeneous unification data integration mandatory huge amount available information 
currently promising approach integration ontologies 
mapping biological entities ontologies usually achieved manually semiautomatically system automatic classification biological entities ontologies saves time effort 
support vector machine approach automatically classifies biological entities ontology 
solve difficult task method copes aspects 
biological entities belong class may placed classes varying abstraction levels 
object may described representations 
classifier enabled draw information consider possibility objects described incompletely 
method introduces technique weighting regulates impact representation dynamically object 
significantly improve time performance classifier exploit inheritance relations ontology 
experimental evaluation protein data parts established molecular biological ontology shows prototype offers impressive accuracy efficient cope large number classes encountered real world problems 
supported german education science research technology bmbf bioinformatics functional analysis mammalian genomes project part german genome analysis network 
keywords support vector machines multi represented objects combined classifiers hierarchical classification multiclass svms 
years amount publicly available biological information increased dramatically 
consequence databases emerged offering diverse information kinds biological entities proteins nucleotides pathways information sources accessible web information strongly limited due heterogeneity data formats data models access facilities sources 
currently promising approach overcoming problems ontologies taxonomies data integration 
ontologies developed molecular biology small fraction widely accepted 
popular ontologies molecular biology gene ontology go models function genes gene products proteins 
major protein databases swiss prot provide mapping entries go 
entries mapped biologists world produce new entries day 
obtain mapping far unlinked protein database entity go usually information biological function protein representing entry explored 
usually done manually series biological experiments tests time consuming costly task 
great benefit mapping done automatically computer supported prediction biological function raw data stored major protein databases amino acid sequence protein obtained easily laborious experiments 
generally framework automatic prediction function biological entities proteins needed classifies entities ontologies go 
introduce classification system provides mapping far unlinked biological entities gives prediction biological function entities 
fact objects linked classes entities restricts general relationships modelled ontology 
system exploits class inheritance ontology classification taxonomic part 
due nature biological entities system copes demands instances may belong class taxonomy 
different instances placed varying abstraction levels 
biological ontologies may employ multiple inheritance order model classes 
aspect representations biological entities usually derived multiple sources proteins amino acid sequence data textual descriptions experimental results available databases swiss prot 
smaller number proteins additional data available dimensional 
usually data derived public databases protein data bank pdb 
different sources different views entities depending research scope 
desirable classification system uses available information possible able exploit multiple representations data object improve accuracy 
quality type representation may vary different entries types representations classifier automatically weight influence representation 
example textual annotations proteins existing usually useful classification sequence data proteins 
framework flexible handle missing representations case representations instance missing classifier able 
biological ontologies built large numbers classes biological entities occur large cardinalities efficiency mandatory handle large problems applicable time 
take challenges novel approach hierarchical classification support vector machines 
main contributions efficient accurate method handling multi classified instances employing support vector machines 
method classifying objects built multiple representations able cope missing representations 
discussion methods hierarchical classification aspect large classification problems taxonomic directed acyclic graphs strict taxonomy trees 
thorough experimental evaluation demonstrating effectiveness efficiency prototype subsections go 
prototype designed automatically map proteins swiss prot entries go 
sequence data text annotations different representations proteins 
note data sources secondary tertiary structures easily incorporated prototype 
rest organized follows 
section briefly review related 
section major concepts approach cope challenges mentioned 
proposed prototype evaluated realistic experimental setting section 
section offers summary gives perspectives 
related support vector machines 
years support vector machines svms received attention offering superior performance various applications 
basic svms distinguish classes calculating maximum margin hyperplane training examples classes 
soft margins kernel functions enables classify kind data 
employ svms distinguishing classes approaches introduced 
biological sequence classification 
classifying biological sequences nucleotide protein sequences active area research 
common approaches nearest neighbor classifiers knn kinds markov models mm including simple mm selective mm higher order mm 
examples knn mm approaches 
knn methods biological sequence classification usually edit distance similarity functions 
simple comprehensible biologists approaches suffer expensive computation 
mm widely biological sequence classification inherent ability model sequential constraints data 
svms applied sequence classification demonstrated excellent accuracy suitable feature extraction method employed 
suitable sequence classification extraction method model sequential nature data 
finding adequate extraction trivial task research addresses challenge 
text classification 
classification text documents investigated research community areas information retrieval machine learning data mining 
process text document algorithms rely projecting documents feature space relevant terms 
documents described vector term frequencies tf vector term frequencies weighted inverse document frequency tfidf 
classify gained vectors established classification methods applicable long handle large number features common text applications 
dimensions uncommon text applications sparseness feature vectors represent documents dimensions show zero count documents approaches classify text introduced 
svms demonstrated high value making accurate predictions field text classification 
hierarchical multi classification 
employing class hierarchies improve large scale classification problems predominantly text classification 
taxonomies taken directory services html documents structural class systems patent codes constructed proper test bed 
idea hierarchical classification solving set small problems classes achieved faster effective solving large scale classification problem distinguishing large amount classes 
approaches introduced :10.1.1.21.988
achieved big performance improvement gain classification accuracy 
approaches examined arbitrary shaped class system functional data types employing multiple inheritance far 
furthermore examines combination support vector machines class hierarchies far evaluation strict level taxonomy tree 
approaches employ general ontologies classification relational learning 
approaches rely general relations problem try solve dissimilar challenge want take 
classifier fusion 
task learning objects multiple representations drawn attention pattern recognition community 
author describes method classifier fusion combine results multiple classifiers object 
furthermore surveys basic combination methods introduces combined learner achieve combination rules offering better accuracy 
introduced method discussed data mining point view 
described method treat major demands system scalability handling incomplete objects 
classification biological objects address problem classifying biological objects genes proteins large class system gene ontology 
goal classification learn function maps objects correct class possible 
training set tuples objects correct classes classifier called training set 
variant simple classification multi classification maps object subset application multi classification mandatory large parts objects associated class 
application domains objects represented possibly complex data type 
established way process objects extract set meaningful features object representation 
kinds data representations text exist approaches feature extraction 
derived features span called feature space 
dimension feature space represents feature 
object represented feature vector 
classifier trained set feature vectors derived training set 
stated biological entities built multiple data types representations sequence data text input space classifier analogously structured structure determined set different representations object 
building joined feature space different representations texts sequences principally applicable corresponding feature vectors mirror properties data object poorly 
argue classification benefits incorporating knowledge structure input space knowledge representation feature extracted classifier 
words features representation treated similar way different representations 
second property biological entities utilized enhance performance prototype 
input space output space analogously structured 
fact classes usually organized sophisticated class system taxonomy ontology case go 
solve classification problem necessary consider relations classes ci fact classes structured exploited dealing large cardinalities efficiently 
introduce approach multi classification support vector machines 
integrate knowledge varying object representations structure input space enable accurate incorporation information objects possible classification process 
discuss hierarchical classification utilizing structure output space order enhance performance framework 
classes class attain maximum votes 
single class decision accomplished returning class having maximum number votes vector 
note maximum vote necessarily 
third described approach uses decision directed acyclic graphs reduce number binary svms considered classification support vector machines making set valued predictions support vector machines svms capable providing superior accuracy compared classification methods representations biological objects 
standard svms binary svms objects classes finding hyperplane separates training set classes best possible way 
svms capable making binary decisions necessary enhance distinguish classes set valued predictions 
methods implementing svms compared distinguish classes 
called approach employs binary svm class decide object belongs class 
approach capable predict class combinations possible 
example object mapped classes binary svms decide class distinguish rest classes 
second approach called versus approach uses binary svms distinguishing pair classes 
classifying object results aggregated called voting vector 
vector provides dimension class components correspond number binary svms predicted class 
trained svms 
approach trains number svms employ fraction classification 
choose versus approach system voting vectors provide meaningful intermediate result 
enable approach predict set class combinations exploit characteristic application 
class combinations sense limit set valid class combinations 
example object predicted dog cat time 
collect set combinations occur training data 
classification extend set original classes class combinations 
valid combinations predictable 
note versus rest approach solves problem set valued predictions offered inferior results due prediction invalid class combinations see section experimental results 
drawback mentioned approaches multi class svms extra effort introducing class leads additional binary svms distinguishing new class 
avoid additional overhead extend class set 
refine post processing voting vectors gained versus approach 
classification function form set objects set classes votes 
binary svms distinguishing class extended class set including valid class combinations dim vector space voting vectors classifier form cl cl classifiers 
prototype employs versus multi class support vector machine 
vector space voting vectors suited describing results classifier 
multi class svm partitions feature space binary svms 
voting vector corresponds partition feature space 
note partitions continuous placed certain set classes 
partitions binary svms distinguish classes partition corresponding voting vector 
note voting vector describes partition majority objects belongs classes separate objects respect class majority objects belonging partition belong class combination 
reason classifier offers better efficiency just function usually cardinality output space smaller number features describing object employ additional svms cases method offers performance benefit due simpler input space structuring input space important aspect system propose classification biological object available information 
classifier able different representations possible object described form available representations 
proteins common representations describing text sequence data secondary structure 
prototype uses text sequence data extended easily additional representations 
extract features representation standard techniques kind representation see section 
step extract features objects training set representation 
mentioned simple solution building feature space incorporating features drawn representations reasons sophisticated approach offers better results 
number features best suitable representation yields unbalanced weighting impact representation 
example number features suitable text representation orders magnitude higher 
classifiers favor representation providing features representation carrying information 
furthermore techniques proposed handle different representations vary parametrization classifiers svm text sequence may different kernel functions distinguish objects 
combined feature space forced find compromise tuning decisions offer optimal results 
handling missing representations data object difficult classifier expects values missing dimensions input space 
consequence classification system considers varying representations separately 
idea data source handled specialized classifier 
results combined build prediction object 
classifier form 
rn set objects 
rn represented tuple feature vectors 
rn drawn single representations 
rn set classes extended class set including valid class combinations dim vector space voting vectors classifier form cl cl rn comb rn rj comb feature vectors rj classified specialized classifier voting vector 
function comb combines voting vectors available representation common voting vector mapped expanded class space 
due design representation classified best possible way specially tuned svm 
initial weighting number features representation 
missing representations handled properly designed combination function 
combination function designed handle input voting vectors generates output vector independent missing representations process able 
note missing representations processed quality prediction suffer depending significance remaining descriptions 
general combination function form comb comb 
fn rn 
rn feature space voting vectors base classes normalized function combine components input vectors number representations 
common choices minimum product sum maximum sum product normalized offers survey strategies suited best kind object 
furthermore introduces idea employing additional learner improve predictions 
idea kept second classifier long collide requirement handling objects missing representations 
result loose possibility consider correlations votes different classes drawn different representations 
results achieved employing methods described capable improve accuracy introduce weighted strategy achieve better results 
main problem basic strategies data source impact result 
model influence different data sources introduce weight factors representation object weight factors reflect aspect confident specialized classifier voting vector produced special feature vector rj 
rule calculating components general voting vector fi ri 
ri rj weight describing confidence prediction derived rj rj th component voting vector derived th data source 
note choose base combination strategy data sources contribute result 
derive meaningful weights established method deriving confidence values binary svms 
method calculates distance feature vector separating hyperplane 
idea closer feature vector confident prediction 
characteristic svms objects difficult decide placed surrounding hyperplane 
derive confidence values model certain distance separating hyperplane decision considered secure sigmoid function usually applied distance 
furthermore closer surrounding hyperplane treated sensitive way 
confidence conf svm svm object distance separating hyperplane svm parameter regulating sensitivity 
systems employ multi class svms usually employ just binary svm process deriving proper weight consider distances 
determine class having maximum vote voting vector derived data source 
class determine minimum confidence value belonging svms characterize predicted class cf 

multi class svm treating representation built matrix binary svms svm 
svm svm svm 

note matrix svms symmetric classifier distinguishing distinguishing determine weight way min vj vj rj vj voting vector derived rj vj class vj having maximum number votes 
idea class having maximum count part prediction 
feature vector predicted high confidence value needs sufficient distance classes 
weights normalized comb described 
classifiers offering highly reliable results significantly impact resulting voting vector 
weights calculated single instance classified combination function adjusts current object illustration class confidence estimation see text details 
complete representations 
object predicted representation significant current task 
call new method object adjusted weighting 
structuring output space classification large class sets providing classes time consuming task 
remember versus multi class svm needs binary svms classes 
system scalable necessary find efficient way classification large class problems 
way speed classification employ additional knowledge class set 
considering class system ontology taxonomy just set classes opens possibility split large classification problem smaller ones faster process 
note accuracy achieved smaller systems tends significantly higher due easier problem 
ontologies common approach model class information molecular biology 
ontology usually models kinds relations useable classification system 
problem objects want classify link object 
exploiting general relations determine class object difficult application 
hand inheritance relations ontology knowing object part super type opens possibility part sub type 
taxonomy part ontology 
taxonomy varies majority class hierarchies projects regarding aspects instances placed varying abstraction levels 
common biological ontologies collect entities specified non leaf nodes ontology sample 
refinements class 
possible database entries may link varying classes class system 
treat multi classified objects belonging classes 
class hierarchy ontology multiple inheritance classes 
characteristic leaves taxonomy tree demands taxonomic graph 
characteristics restrict ontology taxonomic directed acyclic graph 
directed acyclic graph dag connected directed graph contain cycles 
entry node dag node incoming edge 
entry point node called root rooted dag 
taxonomic directed acyclic graph rooted dag node connected class objects 
class predecessor node super type classes nodes predecessor node edges 
furthermore require entries belonging super type exactly union entries belonging sub types 
requirement fulfilled place easily fix introducing additional leaf nodes super types having instances belong sub types 
get choice class system providing general setting 
sample depicted 
find method hierarchical classification best suited exploiting discuss basic approaches ability support setting 
basic approach hierarchical classification decompose flat class problem smaller problems sizes ni common hierarchical classifiers class hierarchies super type provides classifier predicts subtypes object belongs 
idea smaller problems easier faster decide big problem 
differences majority introduced methods hierarchical classification part class system traversed classification 
principally strategies tackle problem probabilities combination classifier outputs considered leaf class hierarchy 
class hierarchy visited leaves getting smaller confidence values top level classifiers considered classifiers confident rest decision paths 
step step level sub classes considered pruned 
small portion classifiers system employed classification 
approach tries achieve best possible accuracy second approach offers better efficiency loose accuracy due restrictiveness 
second approach favorable target employ large providing classes accuracy suffer 
reasons employing second approach achieve classification large occurrence multiple inheritance leaves varying abstraction levels computationally demanding calculate comparable probabilities leaves 
achieve calculation implies knowledge leading leaf 
furthermore fact leaves placed different abstraction levels requires proper normalization probabilities 
employing classifiers consider possibility object belongs classes generate confidence values reflect realistic estimation 
shows example hierarchical classifier svms employing distance hyperplane confidence value 
described case object misclassified due high second level confidence value 
possibility multiple leading class able compensate wrong decision second approach 
path reach class pruned reachable path 
example wrong decision due high nd level confidence value 
choose second approach building classifier employs class system 
system consists organizing classes want predict 
node classifier designed described previous subsection trained decide correct sub types precondition object belongs class node attached 
hierarchical classification achieved giving object classifier root node predicted paths branch process reaches leaf 
set reached leaf nodes prediction class set system 
experimental evaluation test bed order demonstrate advantages system carried versatile experimental evaluation 
experiments performed different classification problems 
test beds consist gene ontology classes relationships 
corresponding objects taken swiss prot protein database consist describing text amino acid sequence described protein 
properties test bed shown table 
order obtain sufficient training objects class original environment pruned 
result pruning fulfills conditions 
leaf class refers minsupport proteins 

inner node min direct son classes 

pruning process contains training set set set set set name response ex protein binding receptor bind stimulus activity ing activity number classes goal proteins multi class pro objects possible 
condition fulfilled moving proteins pruned classes direct parent 
details classification problems listed table 
algorithms implemented java tested station equipped ghz pentium iv processor gb main memory 
measure accuracy multi classified objects definition classification accuracy accuracy table details test environments test object set test objects correct class set object predicted class set object order avoid overfitting evaluation fold cross validation 
classify protein sequences employed approach described 
basic idea local amino acids global exchange groups characteristics protein sequence 
construct meaningful feature space formed possible grams kind characteristic provided dimensions sequence feature space 
text descriptions employed tfidf vector description built extracted terms 
representations classified employing degree polynomial kernel 
due superior results described hierarchical approach experiments structured output space exception flat classifier approach 
feature selections applied node separately described 
experimental results show versus rest approach suitable application compared accuracy text descriptions versus approach 
offered significantly inferior results settings employing extended class set classification accuracy method compared versus rest approach 
versus approach accuracy follow approach cf 

example classification accuracy achieved set test bed versus strategy versus rest approach reached 
second experiment demonstrates classifier offers better results compared single classifier direct extension class set cf 
section 
step approach achieved comparable accuracy superior efficiency test sets cf 

particular approach showed set goal classes classification accuracy took average seconds classification time object 
competing method classifier direct extension class set achieved ca 
classification accuracy evidently slower seconds average classification time object 
results step approach improved efficiency effectiveness classifier 
order show advantages hierarchical approach unstructured class system compared approaches introduced classifier accuracy runtime hierarchical classification employing versus svm extended class set direct extension subsequent versus svms approach 
additionally compare approach flat classifier 
representations 
observed better accuracy cases enormous improvement classification time especially working large class systems cf 

case set providing target classes flat classifier achieved accuracy took average seconds classification object 
hierarchical approach achieved data significantly higher accuracy needed seconds object 
hierarchical classification processed times faster flat classification 
note considerable speed achieved especially large performance critical smaller problems 
furthermore classification accuracy surpassed accuracy observed approaches majority test sets 
experiment compares structured input space classification 
compared accuracy achieved employing text part sequence part combined feature space incorporates features representations combined classifier 
combined classifier evaluated object adjusted weights cf 
table 
cases classification text accurate sequence data 
furthermore combination object adjusted weights variant employing combined feature space capable improve accuracy text description cases 
promising restrict classifier employ text descriptions 
variant employs object adjusted weighting hand increases accuracy test beds 
examined method able dynamically decide representation suited best draw advantages representations 
experiment examines capability system cope incomplete data objects 
trained classifiers data sources tested classifying sequence part test instances 
majority test beds turned accuracy approximately reached level achieved classifying sequence data see line table 
case set classification accuracy exceeded values observed sequences 
system able handle incomplete data 
note capability gets important increasing number representations getting demanding train classifiers handle remaining representations best possible increasing numbers representations 
furthermore incorporating representations remaining representations compensate missing information 
proposed prototype classifying data objects taxonomic directed acyclic graphs applied biological entities molecular biological ontologies 
method addresses problems biological instances consist multiple representations sequence text classifi method set set set set set classification text classification sequence modelling multi represented objects combined feature space seperate feature spaces combined average function object adjusted weighting combination training text sequence classification sequence table classification accuracy text descriptions sequence data varying combination methods 
cation process prototype able integrate possible representations instance handle frequently occurring case representations missing 
second prototype handles multi classified objects occurrence multiple inheritance leaf nodes different abstraction levels 
thorough experimental evaluation prototype versatile test bed classifying proteins swiss prot gene ontology 
test bed demonstrated method capable classify new entries high accuracy efficiency adequate real world applications 
plan extend system new data sources ontologies employing various different representations 
new data sources provide linked instances plan extend system exploit general relationships supported ontologies 
furthermore plan develop method interleaved calculation general voting vector 
example voting vector data source calculated binary svms data sources chance change result 
efficiency improved 
berman westbrook feng bhat protein data bank 
nucleic acid research 
bairoch 
martin donovan phan schneider 
swiss prot protein knowledgebase supplement trembl 
nucleic acid research 
bry kr ger 
computational biology database digest data data analysis data management 
distributed parallel databases 
consortium 
gene ontology tool unification biology 
nature genetics 
cortes vapnik 
support vector networks 
machine learning 
craven dipasquo freitag mccallum mitchell nigam slattery 
learning construct knowledge bases world wide web 
artificial intelligence 
murray 
effect hierarchical classifiers text categorization 
proc 
rd conf 
empirical methods natural language processing emnlp 
deshpande karypis 
evaluation techniques classifying biological sequences 
proc 
pacific asia conf 
knowledge discovery data mining pakdd pages 
duin 
combining classifier train train 
proc 
th int 
conf 
pattern recognition icpr quebec city canada pages 
dumais chen 
hierarchical classification web content 
proc 
rd int 
conf 
research development information retrieval sigir pages 
durbin eddy krogh 
biological sequence analysis 
cambridge university press 

han karypis 
centroid document classification analysis experimental results 
proc 
th european conf 
principles data mining knowledge discovery pkdd lyon france volume lecture notes computer science pages 
springer 
joachims 
text categorization vector machines learning relevant features 
proc 
th european conference machine learning ecml chemnitz germany volume lecture notes computer science pages 
springer 
kittler duin matas 
combining classifiers 
ieee transactions pattern analysis machine intelligence 
koller sahami 
hierarchically classifying documents words 
proc 
th int 
conf 
machine learning icml nashville tn pages 
kudenko hirsh 
feature generation sequence categorization 
proc 
th nat 
conf 
artificial intelligence aaai pages 
kuncheva bezdek duin 
decision templates multiple classifier fusion experimental comparison 
pattern recognition 
larkey 
issues automatic classification patents 
learning text categorization 
papers workshop pages 
aaai press 
lesh zaki ogihara 
mining features sequence classification 
proc 
th int 
conf 
knowledge discovery data mining sigkdd 
mccallum rosenfeld mitchell ng 
improving text classification shrinkage hierarchy classes 
proc 
th int 
conf 
machine learning icml madison wi pages 
mount 
bioinformatics sequence genome analysis 
press 
platt cristianini shawe taylor 
large margin dags multiclass classification 
advances neural information processing systems nips conference denver pages 
mit press 
rocchio 
relevance feedback information retrieval 
salton editor smart retrieval system experiments automatic document processing pages 
prentice hall 
salton 
automatic text processing transformation analysis retrieval information computer 
addison wesley 
vaithyanathan mao dom 
hierarchical bayes text classification 
proc 
int 
workshop text web mining pricai melbourne australia pages 
wang ma shasha wu 
new techniques extracting features protein sequences 
ibm systems journal 
wang zhou 
building hierarchical classifiers class proximity 
proc 
th int 
conf 
large databases vldb edinburgh scotland pages 
yang 
evaluation statistical approaches text categorization 
technical report cmu cs carnegie mellon university april 
