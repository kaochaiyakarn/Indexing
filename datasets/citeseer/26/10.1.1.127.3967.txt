proc 
ieee th symposium field programmable custom computing machines fccm napa valley california april session tools 
kenneth pocek jeffrey arnold editors ieee computer society press los alamitos ca usa pp 

macro hardware compilation java bytecodes dynamic reconfigurable computing system jo cardoso inesc university presents new approach synthesize reconfigurable hardware hw user specified regions program assumption virtual hw support 
automation approach supported compiler front hw compiler development 
front starts java bytecodes supports language compiled jvm java virtual machine model 
extracts bytecodes dependencies inside basic blocks 
information stored representation graphs suitable efficiently exploit existent parallelism program typically high level synthesis 
intermediate representations hw compiler exploits temporal partitions behavior level resolves memory access conflicts generates vhdl descriptions register transfer level mapped reconfigurable hw devices 

consensus research community reconfigurable computing rc concept needs best hw compiler tools manage hw complexity nowadays possible integrate reconfigurable processing unit 
rc systems integrate best research efforts hw sw codesign sw compilation high level synthesis hls areas 
rc architectures provide capability spatial parallel computation achieve better speed ups program execution 
compilers able exploit full potential available massive parallelism needed 
proof concept research efforts consequently advances architectural compilation targeting 
hw synthesis spatial scheduling partitioning integrated compilation programs multi fpga devices 
scheduling approach suitable dynamic reconfiguration starts data flow graph representations 
authors adapted traditional hls frameworks architectural synthesis rc systems 
hor cio neto inesc ist inesc rua alves rd 
floor lisboa portugal phone fax joao cardoso hcn inesc pt research efforts tailored architectures processing elements implemented currently available physical coarse grain architectures new 
efforts try avoid known problems fine grain approaches steps area delay prediction 
typical hls techniques exploit efficiently sharing resources supported layout flexibility asics 
face problems pre defined architectures case 
sharing registers functional units produce poor results majority hw size mux area adder register 
re register variables lifetime needs control overhead complicates routing step 
including registers interconnections scheduled steps degrade critical path 
majority available architectures rc systems hw compilation consider local memory attached 
front exploit distribution data lifetime locality specific characteristics target architecture 
synergies efficiently exploited new hls framework described order produce adequate hw solution executed 
concept virtual hw vw possible architectures short reconfigurable times partial reconfiguration support 
hw compilation integrate temporal partitioning schemes automatically exploit new capability 
temporal partitioning resolves implementation hw region fit time sharing device way partition fits hw resources 
new algorithms integrate temporal partitioning schemes hw compilation steps behavioral level order efficiently exploit vw concept 
efforts hls sw programming languages majority tailored 
low level language manipulate memory contents pointers fine grain physical loca tions hinder static resolution significant number optimizations 
exploitation data storage higher levels abstraction possible java programming language strongly typed uses atomicity objects arrays 
describes front compiler starts java bytecodes obtained java program source 
selection bytecodes advantages model platform independent executable available tools free objectoriented retains source information semantic uses atomicity object supports multi sw languages 
integration hw compilation rc systems explained 
hw compilation starts intermediate graph models front integrates temporal partitioning schedule memory accesses communication temporal partitions 
uses graph models permit exploitation inter block parallelism execution independent blocks graph time exploitation intra block inter operation parallelism simultaneous execution multiple operations 
graphs permit fully exploitation freedom reorder basic blocks bbs due lack data dependencies permit scheduling phase defines new order bbs case resource sharing conditional paths 
section explains approach hw compilation java bytecodes 
describes representation graphs obtained front correspondent level complete flow stretched graphs hw compilation phase second level 
section presents mapping scheduling schemes proposed permit component 
section explains integration temporal partitioning developed algorithms 
section proof concept examples shown 
identified 

hardware compilation flow previously existent hls tool compiler generates vhdl behavioral processes 
approach suitable rc decided develop new tool called achieved results specially suited support rc concept 
computes temporal partitioning graphs generated produces vhdl descriptions rtl register transfer level temporal partition 
shows compilation flow bytecodes application sw hw 
bounding boxes table summarize subset java language correspondent bytecodes currently sup ported 
supported types supported operations 
table java subset correspondent bytecodes currently supported shown inside boxes unidimensional arrays 
types operations control mechanisms boolean byte short int long float double char arrays objects exception handling method invocation creation objects creation arrays break continue switch casting conversion inputs control dependencies graph cdg data dependencies graph ddg data flow graph dfg bb 
graphs extracted java bytecodes application front compiler 
cdg ddg previously sw compilation hw sw partition proved efficient 
level level sw synthesis java classfiles communication host java classfiles cdg control dependencies graph target architecture description macro cells library front compiler cfg control flow graph ddg data dependencies graph hw compilation back rtl vhdl description bitstreams data flow graphs 
compilation flow java classfiles reconfigurable computing systems 
moment scheduling scheme consider sharing resources implementing arithmetic logic operation sharing need control unit 
arithmetic logic operation dfg mapped macro cell library implements equivalent functionality 
mapping mobilities nodes dfg explained 
scheduling task resolves memory accesses conflicts may occur bus sharing architectures communication tween temporal partitions 
compiler generates description control unit runtime scheduler reconfigurations moment implemented sw 
structural vhdl generated represents interconnection units contained library relatively placed macros 
library contains minimal set macro cells support subset jvm instructions 
vhdl representation macro cells includes specific attributes specify relative locations shapes corresponding hw taken account tool 
back shown 
moment back xc xilinx series 
fpga library logic synthesis fpga place route rtl vhdl description bitstreams vhdl netlist series 
synopsys design compiler 

back synthesis flow 
graph intermediate representations generated front step disassemble jvm instructions bytecodes classfile 
control flow graph cfg selected method generated 
cfg directed graph node representing jvm instruction edges representing execution dependency instructions 
cfg includes start node vertices included path vertices 
edge nodes instruction executed immediately instruction 
traditional cfgs model cfg includes switch type vertices support jvm redirect control flow multiple outgoing edges value variable evaluated switch captures exception handling routines 
analyze data control dependencies method bb level cfg transformed new vertices bbs jvm instructions 
bb integrates sequence consecutive jvm instructions cfg flow control enters leaves possibility branching throwing exception possibility start instruction 
dominators tree dt constructed existent natural loops identified extracted conventional compiler techniques described 
identification related loops information bounded unbounded counter variable incremental value initial value final condition natural loop grouped special node 
presence nested loops set bbs outer loop contains equivalent set inner loop 
tree pdt constructed algorithm dt reverse traversing order 
cdg obtained pdt 
node control dependent node determines executed 
cdg direct graph node representing bb edges representing control dependencies bbs 
cdg includes start node outermost conditional bb edge incoming start node 
innermost conditional bb incoming edge outermost hierarchy control dependencies 
cdg ddg fundamental evaluate implementation massive parallelism true concurrent model hw 
construction ddg considers utilization local variables operand stack memory alias accesses array elements semantic dependencies dependencies creation object call constructor 
data dependencies produced utilization local variables fields determined solving reaching definitions data flow problem general iterative algorithm 
definition variable occurs exists jvm instruction assigns may assign value variable istore astore variable occurs jvm instruction uses value variable iload aload definition chains local variable field computed reaching definitions 
indicates definitions local variables fields reach 
data dependent true dependency uses local variable field time defined 
types encapsulated ddg form distinct edges 
true dependencies edges encapsulate local variable number field number identification number bits variable field 
output anti dependencies modeled edges labels types constrain ordering bbs executed communication costs 
stack dependencies determined traversing forward jvm instructions cfg program storing information stack contents operands types instruction pushed oper 
possible stack model jvm invariant stack contains number type operands execution flow instruction cfg 
bb algorithm examines stack state instruction bb determine dependencies 
stack states enter bb exit bb depend bb instruction uses stack operands popping dup instruction involved 
case algorithm examines states involved 
algorithm considers propagation constants examining states stack 
alias problem requires similar analysis available expressions problem 
named available object array assignment aoa 
object array assignment available point program path cfg start assignment definition variable assigned assignment aoa variables assignment expression treated unique variable lifetime assignment 
sequence accesses excluding stores object array address message sends manipulation fields array elements maintained original cfg 
extraction type possible parallelism requires deeper inter procedural analysis 
analysis currently distinguish elements array object uses atomicity object array 
creating program dependence graph pdg combines control data dependencies single representation union ddg cdg hardware compiler maintains graphs order permit efficient exploitation pre computation conditional branches 
dfg created bb contained region migrate hw 
dfg nodes representing operations variables constants load store operations conditional nodes method invocations edges representing flow data nodes 
nodes representing variables serve fork nodes multiple operations value variable 
nodes local variables dfg mapped nets wires registers memory locations scheduling phases 
computation dfg done stack contents computed stack dependencies algorithm cited 
dfg compiler computes bitwidth operation variable see example 
jvm instruction type conversion byte int sequence jvm instructions bb sets variable width result propagates backwards chains operations dfg forward sink node 
arguments java method explicitly represented bytecodes algorithm tries propagate forwards 
advanced bit width extraction needs done improve hw results permit possible extract boolean type encapsulated bytecodes byte 
moment user identify code regions degrade performance application help profiler tool 
library inserting tags java source code developed includes tag interface methods specify code segments start classes implement order specify timing constraints maxtime mintime 
compiler uses calls methods identify user defined code segments constraints specified 
library permits analysis performance code tags host machine execution program 
identifies region eliminates library bytecodes method cfg construction performed 
mapped hw user specify single entry single exit region input java program 
byte byte iload iload istore converts signed integer bits signed byte bits 
computation bit widths dfg 
representation models hw compilation types models impact scheduling hls research community data flow control flow 
common representations cfg fork join nodes model control dfg bb 
authors dfg region representation suited parallelism level information low fact mixes control data dependencies limits flexibility compilation 
scheduling algorithms proposed try best models switching 
representation model proposed maintains control dependencies separated data dependencies uses full reordering bbs input cfg data dependencies 
better suited performance driven implementations 
permits explore control flow data flow techniques efficiently permits exploit massive parallelism input program provides efficient schedule merge points stage 
start define merge point different way standard compiler theory merge point serves join multiple control flow edges cfg 
context merge dependencies points selection inserted form muxes example execution depends branch taken control point bb outgoing edges prior considered merge point 
bb control point bb branches control structure conditional node root 
node edge data flow dependencies correspondent variable location merge dependent closest conditional node root sources nodes edge 
conditional paths side effects instance store memory merge dependent points currently inserted nodes produce side effects 
insertion merge dependent points exploited considering sharing resource units conditional paths 
example shows representation graphs impact compilation hw 
example shows sharing resources mutually exclusive execution paths consequent insertion new merge points 
described control dependencies merge dependencies data dependencies maintained disjoint graphs see example true concurrent environment mixture limit optimizations 
cdg important determine operations distinct conditional paths shared way represent control node control dependent paths 
case resource sharing mutually exclusive paths conditional nodes produce merge dependent points successor nodes cdg share resources see example 
example 
representation graphs correspondent bb number identified source 
local jvm variable corresponds method 
graphs obtained cfg seen 
static int ex int int int bb bb bb bb bb return bb 
example correspondent cfg 
cfg input hw mapping worst execution time wet graph estimated cfg start ta max ti wet ddg mdg exploration maximum parallelism region permit wet tb max considering delay multiplier ns adder ns comparison ns ta ns tb ns 
examples bbs conditional branches conditional nodes large improvements may obtained 
cdg start ddg start mdg 
graph transformations exploit hardware technology 
mux start mux 
graph obtained ddg mdg mapped hardware 
example 
sharing resources mutually exclusive execution paths 
example hw graph shown 
mux 
hw graphs obtained mdg ddg obtained sharing multiplier mutually exclusive execution paths 
mux mux mutually exclusive paths spatial sharing operation exploited 
multipliers implementation need registers consequently need fsm start control seen 
resource sharing mutually exclusive execution paths reduce area graph implementation may introduce delay overhead needs know result comparison earlier 
scheduling mapping techniques efficiently generate hw selected region necessary map node dfg macro cell input description library 
operation node dfg mapped correspondent macro cell hw library minimum delay 
node operations dfg scheduled fine grained asap soon possible late possible schemes obtaining node resource constraints 
scheduling delay macro cell fractions clock period previously selected user control steps coarse grain scheduling schemes 
time interval operation node affecting delay critical path calculated 
time interval calculated equation represents sum mobility delay operation 
tii asap ti operation dfg algorithm selects functionally equivalent macro cells library lower area perturb critical path delay algorithm sketched 
intra mapping intra scheduling level operations dfg hw compiler compute scheduling bb level 
traverses nodes graph obtained union ddg mdg applies pre processing steps assign level node dependencies nodes 
node inputs primary inputs level 
node inputs created nodes level equal maximum level correspondent levels source nodes plus 
determine node dependencies nodes 
node inputs primary inputs 
node inputs created nodes equal maximum source nodes equal 
assign level node dependencies nodes 
node outputs primary outputs level maxlevel determined 
node outputs nodes level equal minimum levels sink node minus 
determine node dependencies nodes 
node outputs primary outputs maxtime calculated 
node outputs created nodes equal minimum source nodes equal 
sort nodes increasing order levels 
determine fine grain mobilities bb 
mobility node difference 
level sort nodes increasing order mobilities 
region fit temporal partitioning performed described section temporal partition memory accesses scheduled 
mapping ld foreach dfg set migrate hw map operation dfg functional equivalent macro cell ld minimum delay compute fine grain asap compute fine grain compute ti asap refine mapping ti dfg refine mapping ti dfg foreach operation dfg ti search ld set functional equivalent macro cells operation search lower area ti compute new fine grain asap path contains compute new fine grain path contains compute new tis path contains 
algorithm schedule map nodes dfg 
dealing arrays implementation consider access local memory 
binding memory addresses store array elements done statically array dimension intra procedural analysis designer help tool 
dfg obtained bytecodes uses variable node represents array address memory see 
hw region nodes variables replaced real addresses start memory location statically allocated array 
load store nodes cor respond clock cycle doing scheduling time interval number clock cycles needed macro cell access memory clock cycle load register added 
scheduler scheme static list scheduling priority function mobilities avoid conflicts ram macro cell concurrent accesses temporal partition furnish control steps needed interface synchronous component 
description control unit tabular format translated vhdl entity synthesized logic synthesis tool 
real address array memory aload start variable node memory load node reg start sram macro 
transformations java program hw graph presence arrays 
control unit selects addresses data sources case load operations controls storing output sram macro cell specific register 
control unit load store data temporal partitions 

temporal partitioning development algorithms enable automation process compute partitions graph executed time sharing formulated 
described problem similarities scheduling problem hls 
nodes graph scheduled time slots executed partition 
temporal partitioning preserve dependencies nodes temporal dependencies node dependent node mapped partition executed partition node mapped 
similarities problems allow common hls scheduling schemes temporal partitioning integration algorithm 
temporal partitioning problem modeled specified non linear programming nlp model 
formulation spatial partitioning integrated hls system 
small input graphs formulation solved reasonable execution time 
algorithms np complete heuristic methods developed permit feasible execution large input examples 
partitioning algorithm levels nodes obtained asap scheduling algorithm 
algorithm fills available area increasing order asap levels 
selection nodes level arbitrary 
approach integrates temporal partitioning schemes permit exploration results user select 
example orientation partitioning algorithm levels produces best results asap levels temporal proximity dependencies nodes levels 
example 
temporal partitioning asap levels 
suppose edges communication cost node unit area maximum area hw device units 
temporal partitioning results applying version algorithm asap levels respectively shown 
example levels produce better results 
partitions obtained levels fewer communication edges 

schemes temporal partitioning asap levels levels 
temporal partitioning algorithms implemented 
algorithm extends algorithm selection node asap levels scheduling local priority function 
function applied nodes current level permits orient selection increasing order mobilities 
critical path graph high priority mapping nodes current partition 
algorithms switch partition node fit current partition trying map remaining unscheduled nodes level 
algorithm shown tries resolve issue recursively searching list mobilities node mapped current partition nodes considered 
algorithm asap levels priority function algorithm 
address different architectures technology schemes communication mechanisms temporal partitions considered registers sw control task load store communication partitions 
scheme suited boards processor micro controller control hw reconfiguration partitions communications boards local memory store data 
advent integration processor cores decreased communication overhead types systems 
set registers device partially reconfigured 
registers configured region shared temporal partitions include advent new tailored time sharing 
macro cell access memory locations controlled hw control unit 
suited types processor local memory communication host time consuming 
schedul sl sl null new stack push nodes current level stack foreach unscheduled node sorted mobility peek area sched area amax put current schedule update sched area pop empty null schedul sl 
algorithm temporal partitioning oriented mobility nodes search level asap 

experimental proof concept moment framework lines code java programming language 
generates vhdl hierarchical rtl descriptions 
top level entity related temporal partition defined 
temporal partition entity level describing bb dfg terms interconnections tween macro cells hw library 
hierarchical description direct correspondence hierarchic graph representation hw compilation user guide manual refinement tasks permit back annotation realistic area time entity 
dotty tool visualize graph representations labels graphs vhdl signals instances important help mechanism phases 
library macro cells circuit generators implemented permits target xilinx xc series fpgas 
library includes integer operators arithmetic logical comparison constants barrel macro cell memory access muxes component declared characterized shown specific file 
supports parsing file loading components intermediate format suitable processed mapping phase 
component mult op area number bits operand 
latency ns delay macro cell function operation type function integer multiplier 
description macro cell library 
test cases explored 
validate complete hw sw approaches boards connected pci 
hamming decoder binary pattern image coding hal example considered 
hamming example jvm instructions grouped bbs compare approach logic synthesis traditional hls hls 
applied directly behavioral vhdl automatically obtained bytecodes example 
table ii shows obtained results 
table iii shows macro cells 
specialized macro cells operations constants gives area cells delay critical path decreases near ns 
logic synthesis synopsys design compiler results area cells delay ns see ls table ii due bit optimizations performed tool 
logic synthesis applied example larger examples inefficient generate flatten structure 
behavior includes memory accesses loops true logic synthesis approach suitable feasible 
academic hls tool results estimated hw area cells cells obtained 
result explained utilization numerous registers muxes 
timeconsuming considered 
results consider logic optimizations rtl structure obtained hls tools 
table ii 
hw results hamming decoder 
routing overhead measured tool rec reconfiguration time 
approach area delay ns address rec cells data pairs cells ls hls table iii 
macro cells hamming decoder bit data types 
macro cell description quantity op logical const op constant op logical xor op logical xor shr op logical shift right constant shl op logical shift left constant mux multiplexer entries eq op comparision equal example sw execution time jdk interpreter jit respectively executed pc mb ram pentium mhz 
results show speed ups hw solution obtained interpreter jit respectively 
hw sw version improve performance sw version due communication costs host board attached pci 
algorithm decomposes image blocks pixels encodes single word 
consider part algorithm computes encoding luminance mean luminance pixels block 
shows part algorithm considered code segment innermost loop unrolled identified tags compiled hw 
segment jvm instructions grouped bbs 
assumes mapping array lum local memory board generates control unit schedule memory accesses 
table iv shows results obtained step hw graph generated 
maximum clock frequency example limited impossibility centralized control unit furnishes control signals drive extremities fpga long wires degrades delays 
table iv 
hw results example 
area cycles delay ns address rec cells mhz data pairs lum array ints int bitstring byte xp xp xp maxtime new maxtime start bitstring lum xp mean lum bitstring bitstring lum xp mean lum bitstring bitstring lum xp mean lum bitstring bitstring lum xp mean lum bitstring 
part algorithm 
third example hal bit operands 
loop body considered implemented hw 
segment fits xc consider xc dfg partitioned time partitions executed time sharing fpga see results table 
time sharing implementation uses sw schedule reconfigurations load store data 
specify maximum area fpga cells fpga area sure routing feasible 
results obtained algorithm oriented asap levels 
better performance achieved local memory board store data 
reconfiguration times consider partial reconfiguration capability fpga 
fpga area cells table results hal example 
delay ns pairs cells rec stores loads xc xc 
presents new approach hardware compilation software programming language suitable fully exploit special characteristics reconfigurable computing architectures 
intermediate representations performance driven hardware synthesis large examples explained 
representations adequate traditionally high level synthesis algorithms 
permit exploit ordering basic blocks mutually exclusive execution paths storing control merge dependencies distinct graphs 
describes intermediate representation graphs java bytecodes extracted 
approach includes temporal partitioning technique order exploit virtual hardware concept 
presents extended heuristics integration temporal partitioning hardware compilation behavior level 
selection node scheduled current partition complex cost functions 
efforts integrate communication cost node produce best results consider schemes communication temporal partitions identified 
focus support methods invocation programmer guide temporal partitioning development scheduling temporal partitioning schemes able support cyclic regions 
possibility share large hardware resources considered alleviate execution overheads merging operations temporal partition 
acknowledgments authors acknowledge support praxis xxi program scope project praxis tit portuguese phd program action 
mangione smith seeking solutions configurable computing ieee computer december pp 

becker hartenstein herz parallelization compilation configurable accelerators proc 
asia south pacific design automation conference yokohama japan february 
de micheli gupta hardware software design proc 
ieee vol 
march pp 
muchnick 
advanced compiler design implementation 
morgan kaufmann publishers san francisco california usa 
de micheli synthesis optimization digital circuits mcgraw hill 
athanas silverman processor reconfiguration instruction set metamorphosis architecture compiler ieee computer vol 
march pp 

peterson connor athanas scheduling partitioning ansi programs multi fpga ccm architectures proc 
th ieee symposium field programmable custom computing machines napa valley california usa april pp 

ait architectural synthesis techniques dynamically reconfigurable logic proc 
th int 
workshop field programmable logic applications darmstadt germany sept lncs vol 
springer verlag pp 

integrated synthesis system dynamically reconfigurable multi fpga architectures proc 
reconfigurable architectures workshop orlando florida usa march 
survey reconfigurable computing architectures tutorial th int 
workshop field programmable logic applications estonia august september 
long data driven computer virtual hardware proc 
st ieee workshop field programmable custom computing machines napa valley california usa april pp 

designs hardware ansi rtl verilog design test bench compiler march 
see www com pubs htm 
de micheli synthesis pointers application pointer analysis behavioral synthesis proc 
iccad november 
cardoso neto automatic path java bytecodes hardware high level synthesis proc 
th ieee international conference electronics circuits systems lisbon portugal september pp 

lindholm yellin 
java virtual machine specification 
addison wesley reading massachusetts 
ieee standard vhdl language manual ieee std 
ferrante ottenstein warren program dependency graph uses optimization acm transactions programming languages systems june 
hw sw design methodology custom computing machines partitioning implicit parallelism ph thesis portuguese ist lisbon january 
xilinx xc field programmable gate arrays version april 
see www xilinx com 
aho sethi ullman compilers principles techniques tools addison wesley reading massachusetts 
steensgaard mutations microsoft research october 
gajski dutt 
wu 
lin high level synthesis chip system design kluwer academic publishers 
bergamaschi control flow versus data flow scheduling combining approaches adaptive scheduling system ieee transactions large scale integration vlsi systems vol 
march pp 

cardoso neto library macro cells circuit generators xilinx xc fpga series inesc technical report december 
vemuri optimal temporal partitioning synthesis reconfigurable architectures proc 
design automation test europe paris france feb 
bhatia temporal partitioning scheduling reconfigurable computing proc 
th ieee symposium field programmable custom computing machines napa valley california usa april 
dotty graphviz version 
see www research att com sw tools graphviz 
synopsys design compiler april 
xilinx series user guide 
