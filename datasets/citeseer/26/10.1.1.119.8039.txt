machine learning automated text categorization fabrizio sebastiani consiglio nazionale delle ricerche italy automated categorization classification texts predefined categories witnessed interest years due increased availability documents digital form ensuing need organize 
research community dominant approach problem machine learning techniques general inductive process automatically builds classifier learning set preclassified documents characteristics categories 
advantages approach knowledge engineering approach consisting manual definition classifier domain experts effectiveness considerable savings terms expert manpower straightforward portability different domains 
survey discusses main approaches text categorization fall machine learning paradigm 
discuss detail issues pertaining different problems document representation classifier construction classifier evaluation 
categories subject descriptors information storage retrieval content analysis indexing indexing methods information storage retrieval information search retrieval information filtering information storage retrieval systems software performance evaluation efficiency effectiveness artificial intelligence learning induction general terms algorithms experimentation theory additional key words phrases machine learning text categorization text classification 
years content document management tasks collectively known information retrieval ir gained prominent status information systems field due increased availability documents digital form ensuing need access flexible ways 
text categorization tc aka text classification spotting activity labelling natural language texts thematic categories predefined set task 
tc dates back early early major subfield information systems discipline increased applicative interest availability powerful hardware 
tc applied contexts ranging document indexing controlled vocabulary document filtering automated metadata generation word sense disambiguation population hierarchical catalogues web resources general application requiring document organization selective adaptive document dispatching 
late popular approach tc operational real world applications community knowledge engineering ke consisting manually defining set rules encoding expert knowledge address istituto di dell informazione consiglio nazionale delle ricerche pisa italy 
mail fabrizio iei pi cnr sebastiani classify documents categories 
approach increasingly lost popularity especially research community favour machine learning ml paradigm general inductive process automatically builds automatic text classifier learning set preclassified documents characteristics categories interest 
advantages approach accuracy comparable achieved human experts considerable savings terms expert manpower intervention knowledge engineers domain experts needed construction classifier porting different set categories 
ml approach tc concentrates 
current day tc discipline crossroads ml ir shares number characteristics tasks information knowledge extraction texts text mining knight pazienza 
considerable debate exact border disciplines lies terminology evolving 
text mining increasingly denote tasks analyzing large quantities text detecting usage patterns try extract probably useful probably correct information 
view tc instance text mining 
tc enjoys quite rich literature fairly scattered international journals devoted special issues topic joachims sebastiani lewis hayes systematic treatments subject textbooks journals entirely devoted tc manning sch tze chapter chapter length treatment subject 
note warn reader term automatic text classification literature mean things quite different ones discussed 
aside automatic assignment documents predefined set categories main topic term mean ii automatic identification set categories borko iii automatic identification set categories grouping documents merkl task usually called text clustering iv activity placing text items groups task tc text clustering particular instances manning sch tze 
organized follows 
section formally define tc various subcases section review important applications 
section describes main ideas underlying ml approach classification 
discussion text classification starts section introducing text indexing transformation textual documents form interpreted classifier building algorithm classifier eventually built 
section tackles inductive construction text classifier training set preclassified documents 
section discusses evaluation text classifiers 
section concludes discussing open issues possible avenues research tc 
fully searchable bibliography tc created maintained author available ira uka de bibliography ai automated text categorization html machine learning automated text categorization 
text categorization definition text categorization text categorization task assigning boolean value pair dj ci domain documents set predefined categories 
value assigned dj ci indicates decision file dj ci value indicates decision file dj ci 
formally task approximate unknown target function describes documents ought classified means function called classifier aka rule coincide possible 
precisely define measure coincidence called effectiveness discussed section 
assume categories just symbolic labels additional knowledge procedural declarative nature meaning available 
exogenous knowledge data provided classification purposes external source available classification accomplished basis endogenous knowledge knowledge extracted documents 
particular means metadata publication date document type publication source assumed available 
tc methods discuss completely general depend availability special purpose resources unavailable costly develop 
course assumptions need verified operational settings legitimate source information available deemed worth developing az junker abecker 
relying endogenous knowledge means classifying document solely semantics semantics document subjective notion follows membership document category pretty relevance document information need ir saracevic decided deterministically 
exemplified phenomenon inter indexer inconsistency cleverdon human experts decide classify document dj category ci may disagree fact happens relatively high frequency 
news article clinton attending filed politics jazz depending subjective judgment expert 
single label vs multi label text categorization different constraints may enforced tc task depending application 
instance need integer exactly elements assigned dj case exactly category assigned dj dis called single label aka non overlapping categories case case number categories may assigned dj dis dubbed multi label aka overlapping categories case 
special case single label tc binary tc dj assigned category ci complement ci 
theoretical point view binary case single label case general multi label algorithm binary classification sebastiani multi label classification needs transform problem multi label classification independent problems binary classification ci ci 
requires categories stochastically independent value dj depend value dj viceversa usually assumed case applications case discussed section 
converse true algorithm multi label classification binary single label classification 
fact document dj classify classifier attribute categories dj obvious choose appropriate category ii classifier attribute dj category obvious choose inappropriate category rest explicitly mentioned deal binary case 
various reasons binary case important important tc applications including filtering see section consist binary classification problems deciding dj jazz 
tc binary classification problems feature unevenly populated categories fewer documents jazz unevenly characterized categories jazz characterized better 
solving binary case means solving multi label case representative important tc applications including automated indexing boolean systems see section 
tc literature couched terms binary case 
techniques binary classification just special cases existing techniques single label case simpler illustrate 
ultimately means view classification consisting independent problems classifying documents category ci 
ci function approximates unknown target function 
category pivoted vs document pivoted text categorization different ways text classifier 
dj want find ci filed document pivoted categorization dpc alternatively ci want find dj filed category pivoted categorization cpc 
distinction pragmatic conceptual important sets available entirety right start 
relevant choice classifier building method methods see section allow construction classifiers definite slant style 
dpc suitable documents available different moments time filtering mail 
cpc suitable new category may added existing set number documents classified ii documents need reconsidered classification larkey 
dpc cpc situation common 
machine learning automated text categorization specific techniques apply style proportional thresholding method discussed section applies cpc exception rule techniques discuss allow construction classifiers capable working mode 
hard categorization vs ranking categorization complete automation tc task requires decision pair dj ci partial automation process different requirements 
instance dj da system simply rank categories estimated appropriateness dj hard decision 
ranked list great help human expert charge final categorization decision restrict choice category categories top list having examine entire set 
alternatively ci ca system simply rank documents estimated appropriateness ci symmetrically classification ci human expert just examine top ranked documents entire document set 
modalities called category ranking tc document ranking tc yang respectively obvious counterparts dpc cpc :10.1.1.109.2516:10.1.1.109.2516
semi automated interactive classification systems larkey croft useful especially critical applications effectiveness fully automated system may expected significantly lower human expert :10.1.1.47.8517:10.1.1.47.8517
may case quality training data see section low training documents trusted representative sample unseen documents come results completely automatic classifier trusted completely 
rest explicitly mentioned deal hard classification algorithms discuss naturally lend ranking tc details section 

applications text categorization tc goes back maron seminal probabilistic text classification 
number different applications briefly review important ones 
note borders different classes applications listed fuzzy artificial may considered special cases 
applications explicitly discuss speech categorization means combination speech recognition tc myers schapire singer multimedia document categorization analysis textual captions sable hatzivassiloglou author identification literary texts unknown disputed authorship forsyth language identification texts unknown language automated identification text genre kessler automated essay grading larkey :10.1.1.42.8449:10.1.1.134.3024
automatic indexing boolean information retrieval systems application spawned early research field borko field gray harley heaps maron sebastiani automatic document indexing ir systems relying controlled dictionary prominent example boolean systems 
document assigned keywords keyphrases describing content keywords keyphrases belong finite set called controlled dictionary consisting thematic hierarchical thesaurus nasa thesaurus aerospace discipline mesh thesaurus medicine 
usually assignment done trained human indexers costly activity 
entries controlled vocabulary viewed categories text indexing instance tc may addressed automatic techniques described 
recalling section note application may typically require keywords assigned document 
document pivoted tc probably best option new documents may classified available 
various text classifiers explicitly conceived document indexing described literature see fuhr robertson harding tzeras hartmann 
automatic indexing controlled dictionaries closely related automated metadata generation 
digital libraries usually interested tagging documents metadata describe variety aspects creation date document type format availability 
metadata thematic role describe semantics document means bibliographic codes keywords keyphrases 
generation metadata may viewed problem document indexing controlled dictionary tackled means tc techniques 
document organization indexing controlled vocabulary instance general problem document base organization 
general issues pertaining document organization filing purposes personal organization structuring corporate document base may addressed tc techniques 
instance offices newspaper incoming classified ads prior publication categorized categories cars sale real estate newspapers dealing high volume classified ads benefit automatic system chooses suitable category ad 
possible applications organization patents categories making search easier larkey automatic filing newspaper articles appropriate sections politics home news automatic grouping conference papers sessions 
text filtering text filtering activity classifying stream incoming documents dispatched asynchronous way information producer information consumer belkin croft 
typical case producer news agency consumer newspaper hayes 
case filtering system block delivery documents consumer interested news concerning sports case sports newspaper 
filtering seen case single label tc classification incoming documents disjoint categories relevant machine learning automated text categorization irrelevant 
additionally filtering system may classify documents deemed relevant consumer thematic categories example articles sports classified sport deal allow journalists specialized individual sports access documents prospective interest 
similarly mail filter trained discard junk mail androutsopoulos drucker classify non junk mail topical categories interest user 
filtering system may installed producer case route documents interested consumers consumer case block delivery documents deemed uninteresting consumer 
case system builds updates profile consumer liddy case common refer rest section single profile needed 
profile may initially specified user resembling standing ir query updated system feedback information provided implicitly explicitly user relevance non relevance delivered messages 
trec community lewis called adaptive filtering case user specified profile available called routing batch filtering depending documents ranked decreasing order estimated relevance just accepted rejected :10.1.1.16.3103
batch filtering coincides single label tc categories completely general tc task authors hull hull schapire sch tze somewhat confusingly term filtering place appropriate term categorization :10.1.1.104.8304
information science document filtering tradition dating back addressed systems various degrees automation dealing multi consumer case discussed called selective dissemination information current awareness see korfhage chapter 
explosion availability digital information boosted importance systems nowadays contexts creation personalized web newspapers junk mail blocking usenet news selection 
information filtering ml techniques widely discussed literature see crestani iyer kim yu lam 
word sense disambiguation word sense disambiguation wsd activity finding occurrence text ambiguous polysemous word sense particular word occurrence 
instance bank may different senses english bank england financial institution bank river hydraulic engineering artifact 
wsd task decide senses occurrence bank week borrowed money bank 
wsd important applications including natural language processing indexing documents word senses words ir purposes 
wsd may seen tc task see gale view word occurrence contexts documents word senses categories 
quite obviously single label tc sebastiani case document pivoted tc usually right choice 
wsd just example general issue resolving natural language ambiguities important problems computational linguistics 
examples may tackled means tc techniques lines discussed wsd context sensitive spelling correction prepositional phrase attachment part speech tagging word choice selection machine translation see roth 
hierarchical categorization web pages tc aroused lot interest possible application automatically classifying web pages sites hierarchical catalogues hosted popular internet portals 
web documents catalogued way issuing query general purpose web search engine searcher may find easier navigate hierarchy categories restrict search particular category interest 
classifying web pages automatically obvious advantages manual categorization large subset web infeasible 
previous applications typically case category populated set documents 
cpc chosen allow new categories added obsolete ones deleted 
respect previously discussed tc applications automatic web page categorization essential peculiarities hypertextual nature documents links rich source information may understood stating relevance linked page linking page 
techniques exploiting intuition tc context attardi chakrabarti rnkranz vert oh experimentally compared yang 
hierarchical structure category set may decomposing classification problem number smaller classification problems corresponding branching decision internal node 
techniques exploiting intuition tc context dumais chen chakrabarti koller sahami mccallum ruiz srinivasan weigend :10.1.1.14.5443:10.1.1.14.5443:10.1.1.14.5443:10.1.1.21.988:10.1.1.21.988:10.1.1.21.988

machine learning approach text categorization popular approach operational settings creation automatic document classifiers consisted manually building means knowledge engineering ke techniques expert system capable tc decisions 
expert system typically consist set manually defined logical rules category type dnf formula category dnf disjunctive normal form formula disjunction conjunctive clauses document classified category iff satisfies formula iff satisfies clauses 
famous example approach machine learning automated text categorization wheat farm wheat commodity export wheat wheat winter soft wheat wheat fig 

rule classifier wheat category keywords indicated italic categories indicated small caps apt 
construe system hayes built carnegie group reuters news agency 
sample rule type construe illustrated 
drawback approach knowledge acquisition bottleneck known expert systems literature 
rules manually defined knowledge engineer aid domain expert case expert membership documents chosen set categories set categories updated professionals intervene classifier ported completely different domain set categories different domain expert needs intervene repeated scratch 
hand originally suggested approach give effectiveness results hayes reported breakeven result see section subset reuters test collection outperforms best classifiers built late state art ml techniques 
classifier tested dataset construe clear randomly chosen favourable subset entire reuters collection 
argued yang results allow state effectiveness results may obtained general :10.1.1.109.2516
early ml approach tc gained popularity eventually dominant research community see mitchell comprehensive ml 
approach general inductive process called learner automatically builds classifier category ci observing characteristics set documents manually classified ci ci domain expert characteristics inductive process characteristics new unseen document order classified ci 
ml terminology classification problem activity supervised learning learning process supervised knowledge categories training instances belong advantages ml approach ke approach evident 
engineering effort goes construction classifier automatic builder classifiers learner 
means learner available shelf needed inductive automatic construction classifier set manually classified documents 
happens classifier exists original set categories updated classifier ported completely different domain 
area content document management tasks example unsupervised learning activity document clustering see section 
sebastiani ml approach preclassified documents key resource 
favourable case available happens organizations previously carried categorization activity manually decide automate process 
favourable case manually classified documents available happens organizations start categorization activity opt automated modality 
ml approach convenient ke approach case 
fact easier manually classify set documents build tune set rules easier characterize concept extensionally select instances intensionally describe concept words describe procedure recognizing instances 
classifiers built means ml techniques nowadays achieve impressive levels effectiveness see section making automatic classification qualitatively economically viable alternative manual classification 
training set test set validation set ml approach relies availability initial corpus documents preclassified 
values total function known pair dj ci document dj positive example ci dj ci example ci dj ci research settings operational settings classifier built desirable evaluate effectiveness 
case prior classifier construction initial corpus split sets necessarily equal size training validation set tv tv 
classifier categories inductively built observing characteristics documents test set te tv testing effectiveness classifiers 
dj te fed classifier classifier decisions dj ci compared expert decisions dj ci 
measure classification effectiveness dj ci values match dj ci values 
documents participate way inductive construction classifiers condition satisfied experimental results obtained unrealistically evaluation scientific character mitchell page 
operational setting evaluation performed typically re train classifier entire initial corpus order boost effectiveness 
case results previous evaluation pessimistic estimate real performance final classifier trained data classifier evaluated 
called train test approach 
alternative fold crossvalidation approach see mitchell page different classifiers built partitioning initial corpus disjoint sets te tek iteratively applying train test approach pairs tvi tei tei final effectiveness obtained individually computing effectiveness averaging individual re machine learning automated text categorization sults way 
approaches case internal parameters classifiers tuned testing values parameters yield best effectiveness 
order optimization possible train test approach set tv split training set tr tr classifier built validation set va tr tv called hold set repeated tests classifier aimed parameter optimization performed obvious variant may fold cross validation case 
note reason test classifier documents trained test documents optimized test set validation set kept separate corpus may define generality ci category ci percentage documents belong ci ci dj dj ci training set generality gtr ci validation set generality gva ci test set generality gte ci may defined obvious way 
information retrieval techniques text categorization text categorization heavily relies basic machinery ir 
reason tc content document management task shares characteristics ir tasks text search 
ir techniques phases text classifier life cycle ir style indexing performed documents initial corpus classified operational phase ir style techniques document request matching query reformulation 
inductive construction classifiers ir style evaluation effectiveness classifiers performed 
various approaches classification differ tackle cases non standard approaches 
indexing induction evaluation themes sections respectively 

document indexing dimensionality reduction document indexing texts directly interpreted classifier classifier building algorithm 
indexing procedure maps text dj compact representation content needs uniformly applied training validation test documents 
choice representation text depends regards meaningful units text problem lexical semantics meaningful natural language rules combination units problem take freedom expression test document denote document training set validation set 
includes document submitted classifier operational phase 
sebastiani compositional semantics 
similarly happens ir tc problem usually disregarded text dj usually represented vector term weights dj set terms called features occur document tr wkj represents loosely speaking term tk contributes semantics document dj 
differences approaches accounted different ways understand term different ways compute term weights 
typical choice identify terms words 
called set words bag words approach document representation depending weights binary 
number experiments apt dumais lewis representations sophisticated yield significantly better effectiveness confirming similar results ir salton buckley :10.1.1.161.6020:10.1.1.161.6020:10.1.1.161.6020
particular authors phrases individual words indexing terms fuhr sch tze tzeras hartmann experimental results date uniformly encouraging irrespectively notion phrase motivated syntactically phrase grammar language see lewis statistically phrase grammatically composed set sequence words patterns contiguous occurrence collection statistically significant see :10.1.1.32.2489
lewis argues reason discouraging results indexing languages phrases superior semantic qualities inferior statistical qualities respect word indexing languages phrase indexing language terms synonymous nearly synonymous terms lower consistency assignment synonymous terms assigned documents lower document frequency terms lewis page 
remarks syntactically motivated phrases apply statistically motivated ones smaller degree 
combination approaches probably best way go tzeras hartmann obtained significant improvements noun phrases obtained combination syntactic statistical criteria crude syntactic method complemented statistical filter syntactic phrases occurred times positive examples category ci retained 
final word usefulness phrase indexing tc told investigations direction actively pursued mladeni grobelnik :10.1.1.32.2489:10.1.1.32.2489
issue weights usually range exception lewis ease exposition assume 
special case binary weights may denoting presence absence term exception represented learning approaches hidden markov models frasconi 
machine learning automated text categorization document binary non binary weights depends classifier learning algorithm 
case non binary indexing determining weight wkj term tk document dj ir style indexing technique represents document vector weighted terms may 
times standard tfidf function see salton buckley defined tr tfidf tk dj tk dj log tr tk tk dj denotes number times tk occurs dj tr tk denotes document frequency term tk number documents tr tk occurs 
function embodies intuitions term occurs document representative content ii documents term occurs discriminating note formula indexing formulae weights importance term document terms occurrence considerations null importance order terms occur document syntactic role play 
words semantics document reduced collective lexical semantics terms occur disregarding issue compositional semantics exception representation techniques foil cohen sleeping experts cohen singer :10.1.1.14.6535
order weights fall interval documents represented vectors equal length weights resulting tfidf normalized cosine normalization wkj tfidf tk dj tfidf ts dj normalized tfidf popular indexing functions including probabilistic techniques vert techniques indexing structured documents larkey croft :10.1.1.47.8517
functions different tfidf especially needed tr available entirety start tr tk computed adaptive filtering case approximations tfidf usually employed dagan section 
indexing removal function words topic neutral words articles prepositions conjunctions performed exceptions include lewis nigam riloff concerning stemming grouping words share morphological root suitability tc controversial :10.1.1.1.5684:10.1.1.1.5684
similarly unsupervised term clustering see section instance stemming reported hurt effectiveness baker mccallum tendency adopt exist variants tfidf differ terms logarithms normalization correction factors :10.1.1.42.7488:10.1.1.42.7488:10.1.1.42.7488
formula just possible instances class see salton buckley singhal variations theme 
application tc inappropriate remove function words author identification documents disputed 
fact noted manning sch tze page little words give author away example relative frequencies words 
sebastiani reduces dimensionality term space see section stochastic dependence terms see section 
depending application full text document selected parts indexed 
option rule exceptions exist 
instance patent categorization application larkey indexes title lines summary section containing claims novelty described invention 
approach possible fact documents describing patents structured 
similarly document title available pay extra importance words contains apt cohen singer weiss :10.1.1.14.6535:10.1.1.14.6535
documents flat identifying relevant part document non obvious task 
darmstadt indexing approach air system fuhr occupies special place literature indexing tc 
system final result air project important efforts history tc spanning duration years tzeras hartmann produced system employed classification corpora scientific literature documents categories important theoretical spin offs field probabilistic indexing fuhr fuhr buckley approach indexing taken air known darmstadt indexing approach dia fuhr 
indexing sense section terms controlled vocabulary synonym tc dia extended indexing free terms fuhr buckley 
idea underlies dia wider set features described section 
approaches mentioned view terms dimensions learning space terms may single words stems phrases see sections combinations 
contrast dia considers properties terms documents categories pairwise relationships basic dimensions learning space 
examples properties term tk idf tk properties relationship term tk document dj tf tk dj location title tk dj properties document dj length dj properties category ci training set generality ci 
possible document category pair values features collected called relevance description vector rd dj ci 
size vector determined number properties considered independent specific terms categories documents multivalued features appropriate aggregation air system applications including air phys system application air indexing physics literature experiments richly documented series papers doctoral theses written german 
interested reader may consult fuhr detailed bibliography 
machine learning automated text categorization functions applied order yield single value included rd dj ci way abstraction specific terms categories documents achieved 
main advantage approach possibility consider additional features hardly accounted usual term approaches location term document certainty phrase identified document 
term category relationship described estimates derived training set probability ci tk document belongs category ci contains term tk dia association factor relevance description vectors rd dj ci final representations classification document dj category ci 
essential ideas dia transforming classification space means abstraction detailed text representation standard bag words approach taken researchers far 
new tc applications dealing structured documents categorization web pages ideas may increasing importance 
dimensionality reduction text retrieval tc high dimensionality term space large value may problematic 
fact typical algorithms text retrieval cosine matching scale high values hold sophisticated learning algorithms classifier induction llsf algorithm yang chute 
classifier induction applies pass dimensionality reduction dr effect reduce size vector space set called reduced term set 
dr beneficial tends reduce overfitting phenomenon classifier tuned contingent characteristics training data just constitutive characteristics categories 
classifiers overfit training data re classifying data trained worse classifying previously unseen data 
experiments shown order avoid overfitting number training examples roughly proportional number terms needed fuhr buckley page suggested training examples term may needed tc tasks 
means dr performed overfitting may avoided smaller amount training examples 
removing terms risk remove potentially useful information meaning documents 
clear order obtain optimal cost effectiveness reduction process performed care 
various dr methods proposed information theory linear algebra literature relative merits tested experimentally evaluating variation effectiveness classifier undergoes application function term space 
distinct ways viewing dr depending task performed locally individual category globally association factors called adhesion coefficients early papers tc see field robertson harding 
sebastiani local dr category ci set terms chosen classification ci see apt lewis ringuette li jain ng sable hatzivassiloglou sch tze wiener :10.1.1.54.6608:10.1.1.54.6608
means different subsets dj working different categories 
typical values 
global dr set terms chosen classification categories see mladeni yang yang pedersen :10.1.1.32.9956:10.1.1.109.2516:10.1.1.109.2516:10.1.1.32.2489:10.1.1.32.2489:10.1.1.32.2489
distinction usually impact choice dr technique techniques local global dr alike supervised dr techniques see section exceptions rule 
rest section assume global approach say applies local approach 
second orthogonal distinction may drawn terms nature resulting terms dr term selection subset dr term extraction terms type terms terms words terms may words obtained combinations transformations original ones 
previous distinction ways doing dr tackled different techniques address separately sections 
dimensionality reduction term selection predetermined integer techniques term selection called term space reduction tsr attempt select original set set terms document indexing yields highest effectiveness 
yang pedersen shown tsr may result moderate increase effectiveness depending classifier reduction tsr technique 
moulinier called wrapper approach identified means learning method building classifier john 
starting initial term set new term set generated adding removing term 
new term set generated classifier built tested validation set 
term set results best effectiveness chosen 
approach advantage tuned learning algorithm local dr performed different numbers terms different categories may chosen depending category easily separable 
sheer size space different term sets cost prohibitive standard tc applications 
computationally easier alternative filtering approach john keeping terms receive highest score function measures importance term tc task 
explore solution rest section 
machine learning automated text categorization document frequency 
simple effective global tsr function document frequency tr tk term tk terms occur highest number documents retained 
series experiments yang pedersen shown tr tk possible reduce dimensionality factor loss effectiveness reduction factor bringing just small loss 
indicate terms occurring frequently collection valuable tc 
contradict known law ir terms low medium document frequency informative ones salton buckley 
results contradict known see salton large majority words occurring corpus low document frequency means reducing term set factor document frequency words removed words low medium high document frequency preserved 
course words need removed advance lest topic neutral words retained mladeni 
note slightly empirical form tsr document frequency adopted authors remove terms occurring training documents popular values range form dr maron ittner applying sophisticated form dumais li jain :10.1.1.161.6020:10.1.1.161.6020
variant policy removing terms occur times training set dagan joachims popular values ranging baker mccallum apt cohen :10.1.1.42.7488:10.1.1.42.7488:10.1.1.42.7488:10.1.1.21.7950
information theoretic term selection functions 
sophisticated information theoretic functions literature dia association factor fuhr chi square sch tze sebastiani yang pedersen yang liu coefficient ng ruiz srinivasan information gain larkey lewis lewis ringuette mladeni moulinier ganascia yang pedersen yang liu mutual information dumais lam larkey croft lewis ringuette li jain moulinier ruiz srinivasan taira yang pedersen odds ratio mladeni ruiz srinivasan relevancy score wiener gss coefficient :10.1.1.11.9519:10.1.1.11.9519:10.1.1.47.8517:10.1.1.47.8517:10.1.1.47.8517:10.1.1.54.6608:10.1.1.42.8449:10.1.1.42.8449:10.1.1.32.9956:10.1.1.161.6020:10.1.1.161.6020:10.1.1.32.2489:10.1.1.32.2489
mathematical definitions measures summarized convenience table probabilities interpreted event space documents tk ci denotes probability random document term tk occur belongs category ci estimated better uniformity table views tsr functions terms subjective probability 
cases tk ci tk ci slightly artificial functions usually viewed probabilistic terms 
formulae refer local category specific forms functions slightly artificial cases tk ci 
note gss coefficients named authors originally names generate confusion 
sebastiani function denoted mathematical form document frequency tk ci tk ci dia association factor tk ci ci tk information gain ig tk ci ci ci tk tk log mutual information mi tk ci log tk ci tk ci chi square tk ci coefficient tk ci tr tk ci tk ci tk ci tk ci tk tk ci ci tr tk ci tk ci tk ci tk ci tk tk ci ci relevancy score rs tk ci log tk ci tk ci odds ratio tk ci tk ci tk ci tk ci tk ci gss coefficient gss tk ci tk ci tk ci tk ci tk ci table 
main functions term space reduction purposes 
information gain known expected mutual information name lewis page larkey 
rs tk ci formula constant damping factor 
counting occurrences training set 
functions specified locally specific category ci order assess value term tk global sense sum tk tk ci weighted average tk ci tk ci maximum fmax tk max tk ci category specific values tk ci usually computed 
functions try capture intuition best terms ci ones distributed differently sets positive negative examples ci 
interpretations principle vary different functions 
instance experimental sciences measure results observation differ independent results expected initial hypothesis lower values indicate lower dependence 
dr measure independent tk ci 
terms tk lowest value tk ci independent ci interested terms select terms tk ci highest 
tsr function rationale ultimate word value effectiveness brings 
various experimental comparisons tsr functions carried mladeni yang pedersen :10.1.1.32.9956:10.1.1.32.2489:10.1.1.32.2489
experiments functions listed table possible exception mi improved results document frequency 
instance yang pedersen shown various classifiers various initial corpora sophisticated techniques machine learning automated text categorization tk ci max tk ci reduce dimensionality term space factor loss small increase effectiveness 
collectively experiments reported mentioned papers indicate max means performs better 
noted results just indicative general statements relative merits functions result comparative experiments performed thoroughly controlled conditions variety different situations different classifiers different initial corpora 
dimensionality reduction term extraction predetermined term extraction attempts generate original set set synthetic terms maximize effectiveness 
rationale synthetic naturally occurring terms due pervasive problems polysemy homonymy synonymy original terms may optimal dimensions document content representation 
methods term extraction try solve problems creating artificial terms suffer 
term extraction method consists method extracting new terms old ones ii method converting original document representations new representations newly synthesized dimensions 
term extraction methods experimented tc term clustering latent semantic indexing 
term clustering 
term clustering tries group words high degree pairwise semantic relatedness groups centroids representative may terms dimensions vector space 
term clustering different term selection tends address terms synonymous near synonymous terms targets non informative terms lewis investigate term clustering tc 
method employed called reciprocal nearest neighbour clustering consists creating clusters terms similar measure similarity 
results inferior obtained single word indexing possibly due disappointing performance clustering method lewis page says relationships captured clusters accidental systematic relationships hoped li jain view semantic relatedness words terms occurrence absence training documents 
technique context hierarchical clustering algorithm witnessed marginal effectiveness improvement small size experiment see section hardly allows definitive reached 
lewis li jain examples unsupervised clustering clustering affected category labels attached documents 
baker mccallum provide example supervised clustering term selection methods wrapper methods address problem redundancy 
sebastiani distributional clustering method employ clusters terms tend indicate presence category group categories 
experiments carried context na bayes classifier see section showed effectiveness loss showed effectiveness improvement aggressive levels reduction 
experiments slonim tishby confirmed potential supervised clustering methods term extraction 
latent semantic indexing 
latent semantic indexing lsi deerwester dr technique developed ir order address problems deriving synonymous near synonymous polysemous words dimensions document representations 
technique compresses document vectors vectors lower dimensional space dimensions obtained combinations original dimensions looking patterns cooccurrence 
practice lsi infers dependence original terms corpus wires dependence newly obtained independent dimensions 
function mapping original vectors new vectors obtained applying singular value decomposition matrix formed original document vectors 
tc technique applied deriving mapping function training set applying training test documents alike 
characteristic lsi newly obtained dimensions term selection term clustering intuitively interpretable 
bringing latent semantic structure vocabulary corpus 
instance sch tze page discuss classification category demographic shifts economic impact document positive test instance category contained quite revealing sentence nation grew people americans left industrial agricultural south west 
classifier decision incorrect local dr performed term selection retaining top original terms correct task tackled means lsi 
exemplifies lsi works sentence contain terms relevant category selected quite possibly words contained produce lsi higher order terms generate document space category 
sch tze page put great number terms contribute small amount critical information combination evidence major problem term classifier 
drawback lsi original term particularly discriminating category discrimination power may lost new vector space 
wiener lsi alternative ways local dr creating category specific lsi representations ii global dr creating single lsi representation entire category set 
experiments showed approach perform better approaches perform better simple tsr relevancy score see table 
sch tze experimentally compared lsi term extraction tsr different classifier learning techniques linear machine learning automated text categorization discriminant analysis logistic regression neural networks 
experiments showed lsi far effective techniques methods performed equally neural network classifier 
tc works lsi similar term extraction techniques see hull li jain sch tze weigend yang 

inductive construction text classifiers inductive construction text classifiers tackled variety ways 
deal methods popular tc briefly mention existence alternative standard approaches 
start discussing general form text classifier 
recall section alternative ways viewing classification hard fully automated classification ranking semi automated classification 
inductive construction ranking classifier category ci consists definition function csvi document dj returns categorization status value number roughly speaking represents evidence fact dj ci 
documents ranked csvi value 
works document ranking tc category ranking tc usually tackled ranking document dj csvi scores different categories 
csvi function takes different meanings learning method instance na bayes approach section csvi dj defined terms probability rocchio approach discussed section csvi dj measure vector closeness dimensional space 
construction hard classifier may follow alternative paths 
consists definition function csvi 
consists definition function csvi analogous ranking classification followed definition threshold csvi dj interpreted csvi dj interpreted definition thresholds topic section 
sections concentrate definition csvi discussing number approaches applied tc literature 
general assume dealing hard classification evident context approaches adapted ranking classification 
presentation algorithms qualitative quantitative focus methods classifier learning effectiveness efficiency classifiers built means focus section 
determining thresholds various policies determining threshold depending constraints imposed application 
important distinction threshold derived analytically experimentally 
method possible presence theoretical result indicates compute threshold maximizes expected value alternative methods possible training classifier standard predefined value threshold 
ease exposition discuss 
sebastiani effectiveness function lewis :10.1.1.16.3103
typical classifiers output probability estimates membership dj ci see section effectiveness computed decision theoretic measures utility see section defer discussion policy called probability thresholding lewis section :10.1.1.16.3103
theoretical result available revert method consists testing different values validation set choosing value maximizes effectiveness 
call policy csv thresholding cohen singer schapire wiener called scut yang :10.1.1.54.6608:10.1.1.54.6608:10.1.1.109.2516:10.1.1.104.8304:10.1.1.14.6535:10.1.1.14.6535
different typically chosen different ci second popular experimental policy proportional thresholding iwayama tokunaga larkey lewis lewis ringuette wiener called pcut yang :10.1.1.54.6608:10.1.1.54.6608:10.1.1.42.8449:10.1.1.42.8449:10.1.1.109.2516
policy consists choosing value gva ci closest gtr ci embodies principle percentage documents training test set classified ci 
obvious reasons policy lend document pivoted tc 
depending application fixed thresholding policy aka doc thresholding lewis rcut yang applied stipulated fixed number categories equal dj assigned document dj :10.1.1.109.2516
instance applications tc automated document indexing field lam 
strictly speaking thresholding policy sense defined section happen classified ci csvi csvi 
quite clearly policy home document pivoted tc 
suffers certain coarseness fact equal documents allows fine tuning 
experiments lewis proportional policy superior probability thresholding microaveraged effectiveness tested slightly inferior macroaveraging see section 
yang csv thresholding superior proportional thresholding possibly due category specific optimization validation set fixed thresholding consistently inferior policies 
fact results obtained different classifiers doubt reinforce 
general aside considerations choice thresholding policy may influenced application instance applying text classifier document indexing boolean systems fixed thresholding policy chosen proportional csv thresholding method chosen web page classification hierarchical catalogues 
probabilistic classifiers probabilistic classifiers see lewis thorough discussion view csvi dj terms ci dj probability document represented vector dj binary weighted terms belongs ci compute probability application bayes theorem ci dj ci dj ci dj machine learning automated text categorization event space space documents dj probability randomly picked document vector dj representation ci probability randomly picked document belongs ci :10.1.1.11.8264:10.1.1.11.8264
estimation dj ci problematic number possible vectors dj high holds dj reasons clear shortly concern 
order alleviate problem common assumption coordinates document vector viewed random variables statistically independent independence assumption encoded equation dj ci wkj ci probabilistic classifiers assumption called na bayes classifiers account probabilistic approaches tc literature see joachims koller sahami larkey croft lewis lewis gale li jain robertson harding :10.1.1.47.8517:10.1.1.47.8517:10.1.1.47.8517:10.1.1.11.6124:10.1.1.11.6124:10.1.1.21.988:10.1.1.21.988:10.1.1.21.988:10.1.1.21.988
na character classifier due fact usually assumption quite obviously verified practice 
best known na bayes approaches binary independence classifier robertson sparck jones results binary valued vector representations documents 
case write pki short ci wkj ci factors may written wkj ci wkj ki pki wkj pki pki wkj pki may observe tc document space partitioned categories ci complement ci ci dj ci dj 
plug take logs obtain log ci dj log ci pki wkj log log pki log pki dj log ci dj log ci ki wkj log log pki log ki dj write pki short ci 
may convert single equation subtracting componentwise obtaining log ci dj ci dj ci log ci wkj log pki pki pki pki log pki pki cooper pointed case full independence assumption na bayes classifier assumption needed weaker linked dependence assumption may written dj ci dj ci wkj ci wkj ci sebastiani note ci dj ci dj increasing monotonic function ci dj may directly csvi dj 
note log ci ci pki log con ki stant documents may disregarded defining classifier category ci basically requires estimating parameters training data may done obvious way 
note general classification document require compute sum fac tors presence wkj log pki ki pki imply fact factors ki wkj may disregarded accounts vast majority document vectors usually sparse 
method illustrated just variants na bayes approach common denominator 
lewis excellent roadmap various directions research na bayes classifiers taken ones aiming relax constraint document vectors binary valued 
looks natural weighted indexing techniques see fuhr salton buckley accounting importance tk dj play key role ir 
introduce document length normalization 
value log ci dj ci tends dj extreme high low long documents documents wkj values irrespectively semantic relatedness ci calling length normalization 
length account easy non probabilistic approaches classification see section problematic probabilistic ones see lewis section :10.1.1.11.8264
possible answer switch interpretation na bayes documents events terms events baker mccallum mccallum chakrabarti guthrie :10.1.1.14.5443:10.1.1.14.5443:10.1.1.14.5443:10.1.1.42.7488:10.1.1.42.7488
accounts document length naturally noted lewis drawback different occurrences word document viewed independent assumption implausible :10.1.1.11.8264
relax independence assumption 
may hardest route follow produces classifiers higher computational cost characterized harder parameter estimation problems koller sahami :10.1.1.21.988
earlier efforts direction probabilistic text search van rijsbergen shown performance improvements hoped 
fact binary independence assumption seldom harms effectiveness theoretical justification domingos pazzani 
quotation text search paragraph casual 
types classifiers literature probabilistic classifiers inextricably intertwined probabilistic search systems see crestani review attempt determine probability document falls true fixed thresholding method section adopted 
fact fixed document dj third factor formula different different categories may influence choice categories file dj 
machine learning automated text categorization fig 

decision tree equivalent dnf rule 
edges labelled terms leaves labelled categories underlining denotes negation 
category denoted query search systems take relevance feedback notion essentially involving supervised learning central 
decision tree classifiers probabilistic methods quantitative numeric nature criticized effective may easily interpretable humans 
class algorithms suffer problem symbolic non numeric algorithms inductive rule learners discuss section decision tree learners important examples 
decision tree dt text classifier see mitchell chapter tree internal nodes labelled terms branches departing labelled tests weight term test document leafs labelled categories 
classifier categorizes test document dj recursively testing weights terms labeling internal nodes vector dj leaf node reached label node assigned dj 
classifiers binary document representations consist binary trees 
example dt illustrated 
number standard packages dt learning dt approaches tc package 
popular ones id fuhr cohen hirsh cohen singer joachims lewis catlett li jain :10.1.1.11.6124:10.1.1.52.2415:10.1.1.33.4944:10.1.1.14.6535
tc efforts experimental dt packages include dumais lewis ringuette weiss :10.1.1.161.6020:10.1.1.161.6020:10.1.1.161.6020
possible method learning dt category ci consists divide conquer strategy checking training examples sebastiani label ci ci ii selecting term tk partitioning tr classes documents value tk placing class separate subtree 
process recursively repeated subtrees leaf tree generated contains training examples assigned category ci chosen label leaf 
key step choice term tk operate partition choice generally information gain entropy criterion 
fully grown tree may prone overfitting branches may specific training data 
dt learning methods include method growing tree pruning removing overly specific branches 
variations basic schema dt learning abound mitchell section 
dt text classifiers main classification tool fuhr lewis catlett lewis ringuette baseline classifiers cohen singer joachims members classifier committees li jain schapire singer weiss :10.1.1.11.6124:10.1.1.11.6124:10.1.1.52.2415:10.1.1.134.3024:10.1.1.134.3024:10.1.1.14.6535:10.1.1.14.6535
decision rule classifiers classifier category ci built inductive rule learning method consists dnf rule conditional rule premise disjunctive normal form dnf type illustrated literals possibly negated keywords premise denote presence non negated keyword absence negated keyword keyword test document dj clause head denotes decision classify dj ci 
dnf rules similar dts encode boolean function 
advantage dnf rule learners tend generate compact classifiers dt learners 
rule learning methods usually attempt select possible covering rules rules correctly classify training examples best minimality criterion 
dts typically built topdown divide conquer strategy dnf rules built bottom fashion 
initially training example dj viewed clause terms contained dj equals ci ci dj positive negative example ci 
set clauses dnf classifier ci obviously scores high terms overfitting 
learner applies process generalization rule simplified series modifications removing premises clauses merging clauses maximize compactness time affecting covering property classifier 
process pruning phase similar spirit employed dts applied ability correctly classify training examples traded generality 
dnf rule learners vary widely terms methods heuristics criteria employed generalization pruning 
dnf rule learners applied tc charade moulinier ganascia dl esc li yamanishi ripper cohen cohen hirsh cohen singer inductive rule learning algorithms build decision lists arbitrarily clauses dnf rules may rewritten disregard issue :10.1.1.33.4944
machine learning automated text categorization moulinier swap apt 
methods rules propositional logic pl research carried rules order logic fol obtainable inductive logic programming methods 
cohen extensively compared pl fol learning tc instance comparing pl learner ripper fol version additional representational power fol brings modest benefits 
regression methods various tc efforts regression models see fuhr pfeifer ittner lewis gale sch tze 
regression denotes approximation real valued binary case classification function means function fits training data mitchell page 
describe model linear squares fit llsf applied tc yang chute 
llsf document dj vectors associated input vector dj weighted terms output vector dj weights representing categories weights vector binary training documents non binary csv test documents 
classification may seen task determining output vector dj test document dj input vector dj building classifier boils computing matrix mi dj dj 
llsf computes matrix training data computing linear leastsquares fit minimizes error training set formula arg mi arg stands usual def minimum ij represents called frobenius norm matrix tr matrix columns input vectors training documents tr matrix columns output vectors training documents 
matrix usually computed performing singular value decomposition training set generic entry mik represents degree association category ci term tk 
experiments yang chute yang liu indicate llsf effective text classifiers known date :10.1.1.11.9519:10.1.1.11.9519
disadvantages cost computing matrix higher competitors tc arena 
line methods linear classifier category ci vector ci belonging dimensional space documents represented csvi dj corresponds dot product dj ci 
note classifier document weights cosine normalized see dot product vectors corresponds cosine similarity ci dj cos kj ki represents cosine angle separates vectors 
sebastiani similarity measure query document computed standard vectorspace ir engines means turn linear classifier built classification performed invoking engine 
practically search engines dot product flavour adapted doing tc linear classifier 
methods learning linear classifiers partitioned broad classes batch methods line methods 
batch methods build classifier analysing training set 
tc literature example batch method linear discriminant analysis model stochastic dependence terms relies covariance matrices categories hull sch tze 
foremost example batch method rocchio method importance tc literature discussed separately section 
section concentrate line classifiers 
line aka incremental methods build classifier soon examining training document incrementally refine examine new ones 
may advantage applications tr available entirety start meaning category may change time adaptive filtering 
apt applications semi automated classification adaptive filtering may expect user classifier provide feedback test documents classified case training may performed operating phase exploiting user feedback 
simple line method perceptron algorithm applied tc sch tze wiener subsequently dagan ng :10.1.1.54.6608:10.1.1.54.6608
algorithm classifier ci initialized setting weights positive value 
training example dj represented vector dj binary weights examined classifier built far classifies 
result classification correct done wrong weights classifier modified dj positive example ci weights active terms terms tk wkj promoted increasing fixed quantity called learning rate dj negative example ci weights demoted decreasing 
note classifier reached reasonable level effectiveness fact weight low means tk negatively contributed classification process far may discarded representation 
may see perceptron algorithm incremental learning methods allowing sort fly term space reduction dagan section 
perceptron classifier shown effectiveness experiments quoted 
perceptron additive weight updating algorithm 
multiplicative winnow dagan differs perceptron different constants promoting weights respectively promotion demotion achieved multiplying adding 
balanced winnow dagan variant positive winnow classifier consists weights ki ki term tk final weight computing dot product difference ki ki machine learning automated text categorization tion positive instance active terms ki weight promoted ki weight demoted case negative instance ki gets promoted ki gets demoted rest promotions positive winnow 
balanced winnow allows negative weights perceptron positive winnow weights positive 
experiments conducted dagan positive winnow showed better effectiveness perceptron turn outperformed dagan version balanced winnow 
line methods building text classifiers widrow hoff refinement called exponentiated gradient applied time tc lewis sleeping experts cohen singer version balanced winnow :10.1.1.14.6535
additive weight updating algorithm second third multiplicative 
key differences previously described algorithms algorithms update classifier misclassifying training example classifying correctly ii update weights corresponding terms just active ones 
linear classifiers lend category pivoted document pivoted tc 
classifier ci standard search engine query set test documents vector dj representing test document query set classifiers 
rocchio method linear classifiers consist explicit profile prototypical document category 
obvious advantages terms interpretability profile readily understandable human say neural network classifier 
learning linear classifier preceded local tsr case profile ci weighted list terms presence absence useful discriminating ci 
rocchio method inducing linear profile style classifiers 
relies adaptation tc known rocchio formula relevance feedback vector space model tc method rooted ir tradition ml 
adaptation proposed hull authors object research right ittner joachims sable hatzivassiloglou schapire singhal baseline classifier cohen singer joachims lewis schapire singer sch tze member classifier committee larkey croft see section :10.1.1.47.8517:10.1.1.11.6124:10.1.1.134.3024:10.1.1.134.3024:10.1.1.21.7950:10.1.1.21.7950:10.1.1.104.8304:10.1.1.14.6535:10.1.1.14.6535
rocchio method computes classifier ci category ci means formula dj posi wkj posi dj wkj wkj weight tk document dj posi dj tr dj ci dj tr dj ci 
formula control parameters allow setting relative importance positive negative examples 
instance set dumais hull sebastiani fig :10.1.1.161.6020:10.1.1.161.6020

comparison tc behaviour rocchio classifier nn classifier 
small crosses circles denote positive negative training instances respectively 
big circles denote influence area classifier 
note ease illustration document similarities viewed terms euclidean distance common terms dot product cosine 
joachims sch tze profile ci centroid positive training examples :10.1.1.11.6124
classifier built means rocchio method rewards closeness test document centroid positive training examples distance centroid negative training examples 
role negative examples usually de emphasized setting high value low cohen singer ittner joachims 
method quite easy implement quite efficient learning classifier basically comes averaging weights 
terms effectiveness drawback documents category tend occur disjoint clusters set newspaper articles sports category dealing boxing rock climbing classifier may centroid documents may fall outside clusters see 
generally classifier built rocchio method linear classifiers disadvantage divides space documents linearly 
situation graphically depicted documents classified ci fall circle 
note positive training examples classified correctly classifier 
enhancements basic rocchio framework 
issue application rocchio formula profile extraction set considered entirety chosen sample set near positives defined positive negative training examples selected yielding dj posi wkj posi dj wkj dj wkj machine learning automated text categorization factor significant dj wkj near positives difficult documents tell apart positives 
near positives corresponds query zoning method proposed ir singhal 
method originates observation original rocchio formula relevance feedback ir near positives tend generic negatives documents user judgments available ones scored highest previous ranking 
early applications rocchio formula tc hull ittner generally distinction near positives generic negatives 
order select near positives schapire issue query consisting centroid positive training examples document base consisting negative training examples top ranked ones similar centroid near positives 
wiener equate near positives ci positive examples sibling categories ci asin application tc hierarchical category sets notion sibling category ci defined 
similar policy adopted ng ruiz srinivasan weigend 
query zoning plus enhancements tsr statistical phrases method called dynamic feedback optimization schapire rocchio classifier achieve effectiveness comparable stateof art ml method boosting see section times quicker train 
results doubt bring renewed interest rocchio classifier previously considered cohen singer joachims lewis sch tze yang :10.1.1.11.6124:10.1.1.109.2516:10.1.1.109.2516:10.1.1.14.6535:10.1.1.14.6535
neural networks neural network nn text classifier network units input units represent terms output unit represent category categories interest weights edges connecting units represent dependence relations 
classifying test document dj term weights wkj loaded input units activation units propagated forward network value output unit determines categorization decision 
typical way training nns backpropagation term weights training document loaded input units misclassification occurs error backpropagated change parameters network eliminate minimize error 
simplest type nn classifier perceptron dagan ng linear classifier extensively discussed section 
types linear nn classifiers implementing form logistic regression proposed tested sch tze wiener yielding effectiveness 
non linear nn lam lee ruiz srinivasan sch tze weigend wiener yang liu network additional layers units tc usually represent higher order interactions terms network able learn :10.1.1.11.9519:10.1.1.11.9519:10.1.1.11.9519:10.1.1.54.6608:10.1.1.54.6608
comparative experiments relating non linear nns linear counterparts performed yielded improvement sch tze sebastiani small improvements wiener :10.1.1.54.6608
example classifiers example classifiers build explicit declarative representation category ci rely category labels attached training documents similar test document 
methods called lazy learners defer decision generalize training data new query instance encountered mitchell pag 
application example methods aka memory reasoning methods tc due masand colleagues masand examples include joachims lam larkey larkey li jain yang pedersen yang liu :10.1.1.11.9519:10.1.1.11.9519:10.1.1.11.6124:10.1.1.42.8449:10.1.1.42.8449:10.1.1.32.9956
presentation example approach nn nearest neighbours algorithm yang 
deciding dj ci nn looks training documents similar dj ci answer positive large proportion positive decision taken negative decision taken 
yang distance weighted version nn see mitchell section fact similar document ci weighted similarity test document 
classifying dj means nn comes computing csvi dj rsv dj dz dz ci dz trk dj trk dj set documents dz maximize rsv dj dz thresholding methods section convert real valued csvi binary categorization decisions 
rsv dj dz represents measure semantic relatedness test document dj training document dz matching function probabilistic larkey croft vector yang ranked ir system may purpose :10.1.1.47.8517
construction nn classifier involves determining experimentally validation set threshold indicates training documents considered computing csvi dj 
larkey croft yang yield best effectiveness 
various experiments shown increasing value significantly degrade performance 
note nn linear classifiers divide document space linearly suffer problem discussed section 
graphically depicted local character nn respect rocchio appreciated 
method naturally geared document pivoted tc ranking training documents similarity test document done categories 
category pivoted tc need store document ranks test document obviously clumsy dpc de facto reasonable way nn 
machine learning automated text categorization number different experiments see section shown nn quite effective 
important drawback inefficiency classification time linear classifier dot product needs computed classify test document nn requires entire training set ranked similarity test document expensive 
drawback lazy learning methods true training phase defer computation classification time 
example techniques 
various example techniques tc literature 
example cohen hirsh implement example classifier extending standard relational dbms technology similarity soft joins 
whirl system scoring function csvi dj rsv dj dz dz ci dz trk dj alternative obtaining small statistically significant improvement version whirl 
experiments technique outperformed number classifiers decision tree classifier ripper cnf rule classifier 
variant basic nn approach proposed reinterpret redefining difference original nn approach training document dz similar test document dj belong ci information discarded weights negatively decision classify dj ci 
combination profile example methods lam ho 
nn system fed generalized instances gis place training documents 
approach may seen result clustering training set obtaining set clusters ki ki ki ki building profile generalized instance documents belonging cluster means algorithm learning linear classifiers rocchio widrow hoff applying nn profiles place training documents computing csvi dj def ki ki dj dj ci dj instance ci dj tr rsv dj dj dj ci dj rsv dj dj dj ci tr dj tr represents degree positive represents weight entire process 
exploits superior effectiveness see nn linear classifiers time avoiding sensitivity nn presence outliers sebastiani fig 

learning support vector classifiers 
small crosses circles represent positive negative training examples respectively lines represent decision surfaces 
decision surface indicated thicker line shown best possible middle element widest set parallel decision surfaces minimum distance training example maximum 
small boxes indicate support vectors 
positive instances ci lie region positive instances ci located training set 
building classifiers support vector machines support vector machine svm method introduced tc joachims subsequently drucker dumais dumais chen klinkenberg joachims taira yang liu :10.1.1.11.9519:10.1.1.11.9519:10.1.1.161.6020:10.1.1.161.6020
geometrical terms may seen attempt find surfaces dimensional space separate positive negative training examples decision surfaces separates positives negatives widest possible margin separation property invariant respect widest possible idea best understood case positives negatives linearly separable case decision surfaces hyperplanes 
dimensional case various lines may chosen decision surfaces 
svm method chooses middle element widest set parallel lines set maximum distance elements set highest 
noteworthy best decision surface determined small set training examples called support vectors 
method described applicable case positives negatives linearly separable 
yang liu experimentally compared linear case assumption categories linearly separable non linear case standard benchmark obtained slightly better results case 
argued joachims svms offer important advantages tc machine learning automated text categorization term selection needed svms tend fairly robust overfitting scale considerable dimensionalities human machine effort parameter tuning validation set needed theoretically motivated default choice parameter settings shown provide best effectiveness 
dumais applied novel algorithm training svms brings training speeds comparable computationally easy learners rocchio 
classifier committees classifier committees aka ensembles idea task requires expert knowledge perform experts may better individual judgments appropriately combined 
tc idea apply different classifiers task deciding dj ci combine outcome appropriately 
classifier committee characterized choice classifiers ii choice combination function 
concerning issue known ml literature order guarantee effectiveness classifiers forming committee independent possible tumer ghosh 
classifiers may differ indexing approach inductive method 
tc avenue explored knowledge example scott matwin 
concerning issue ii various rules tested 
simplest majority voting mv binary outputs classifiers pooled classification decision reaches majority votes taken obviously needs odd number li jain liere tadepalli 
method particularly suited case committee includes classifiers characterized binary decision function csvi 
second rule weighted linear combination weighted sum csvi produced classifiers yields final csvi 
weights wj reflect expected relative effectiveness classifiers usually optimized validation set larkey croft :10.1.1.47.8517
policy dynamic classifier selection dcs committee classifier effective validation examples similar dj selected judgment adopted committee li jain 
different policy intermediate dcs adaptive classifier combination acc judgments classifiers committee summed individual contribution weighted effectiveness validation examples similar dj li jain 
classifier committees mixed results tc far 
larkey croft combinations rocchio na bayes nn pairwise combinations rule 
experiments combination classifiers outperformed best individual classifier nn combination classifiers improved pairwise combinations 
results give strong support idea classifier committees profit complementary strengths individual members 
small size test set documents suggests sebastiani experimentation needed drawn 
li jain tested committee formed various combinations ana bayes classifier example classifier decision tree classifier classifier built means subspace method combination rules worked mv dcs acc 
case committee formed na bayes subspace classifier combined means acc committee outperformed narrow margin best individual classifier attempted classifier combination acc gave better results mv dcs 
discouraging especially light fact committee approach computationally expensive cost trivially amounts sum costs individual classifiers plus cost incurred computation combination rule 
remarked small size experiment test sets documents allow draw definitive approaches adopted 
boosting 
boosting method schapire schapire singer occupies special place classifier committees literature classifiers forming committee obtained learning method called weak learner :10.1.1.134.3024:10.1.1.104.8304
key intuition boosting classifiers trained conceptually parallel independent way committees described sequentially 
way training classifier may take account classifiers perform training examples concentrate getting right examples performed worst 
specifically learning classifier dj ci pair importance weight ij ij set equal dj ci pairs represents hard get correct decision pair classifiers 
weights exploited learning specially tuned correctly solve pairs higher weight 
classifier applied training documents result weights ij updated ht ij update operation pairs correctly classified weight decreased pairs misclassified weight increased 
classifiers built weighted linear combination rule applied yield final committee 
boostexter system schapire singer different boosting algorithms tested level decision tree weak learner :10.1.1.134.3024
algorithm adaboost mh simply called adaboost schapire explicitly geared maximization microaveraged effectiveness adaboost aimed minimizing ranking loss getting correct category ranking individual document :10.1.1.104.8304
experiments conducted different test collections schapire shown adaboost outperform sleeping experts classifier proven quite effective experiments cohen singer :10.1.1.14.6535
experiments schapire singer showed adaboost outperform aside sleeping experts na bayes classifier standard non enhanced rocchio classifier joachims schapire show simple modification policy allows optimization classifier utility see section 
machine learning automated text categorization prtfidf classifier 
boosting algorithm committee classifier sub committees improves effectiveness especially efficiency adaboost mh sebastiani 
approach similar boosting employed weiss experiment committees decision trees having average leaves complex simple leaves trees schapire singer eventually combined simple mv rule combination rule similarly boosting mechanism emphasising documents misclassified previous decision trees :10.1.1.134.3024
boosting approaches employed iyer kim li jain myers 
methods previous sections tried give overview complete possible learning approaches proposed tc literature hardly possible exhaustive 
learning approaches adopted fall squarely class algorithms remained isolated attempts 
noteworthy ones bayesian inference networks dumais lam tzeras hartmann genetic algorithms clack masand maximum entropy modelling manning sch tze :10.1.1.161.6020:10.1.1.161.6020

evaluation text classifiers text search systems evaluation document classifiers typically conducted experimentally analytically 
reason order evaluate system analytically proving system correct complete need formal specification problem system trying solve respect correctness completeness defined central notion tc membership document category due subjective character inherently non 
experimental evaluation classifier usually measures effectiveness efficiency ability take right classification decisions 
measures text categorization effectiveness precision recall 
classification effectiveness usually measured terms classic ir notions precision recall adapted case tc 
precision wrt ci defined conditional probability dx ci dx ci probability random document dx classified ci decision correct 
analogously recall wrt ci defined dx ci dx ci probability random document dx ought classified ci decision taken 
category relative values may averaged way discussed shortly obtain values global entire category set 
borrowing terminology logic may viewed degree soundness classifier wrt may viewed degree completeness wrt defined understood subjective probabilities measuring expectation user system behave correctly classifying unseen document sebastiani category expert judgments ci classifier tpi fpi judgments fni tni table 
contingency table category ci 
category set expert judgments classifier tp tpi judgments fn fni table 
global contingency table 
fp fpi tn tni ci 
probabilities may estimated terms contingency table ci test set see table 
fpi false positives wrt ci commission number test documents incorrectly classified ci tni true negatives wrt ci tpi true positives wrt ci fni false negatives wrt ci aka errors omission defined accordingly 
estimates indicated precision wrt ci recall wrt ci may obtained tpi tpi tpi fpi tpi fni obtaining estimates different methods may adopted microaveraging obtained summing individual decisions tp tp fp tpi tpi fpi tp tp fn tpi tpi fni indicates microaveraging 
global contingency table table obtained summing category specific contingency tables 
macroaveraging precision recall evaluated locally category globally averaging results different categories indicates macroaveraging 
methods may give quite different results especially different categories different generality 
instance ability classifier behave categories low generality categories positive training instances emphasized macroaveraging machine learning automated text categorization microaveraging 
obviously depends application requirements 
assume microaveraging say rest section may adapted case macroaveraging obvious way 
measures effectiveness 
measures alternative com tp tn ml literature accuracy estimated tp tn fp fn fp fn error estimated tp tn fp fn widely tc 
reason yang points large value denominator typically tc insensitive variations number correct decisions tp tn 
adopted evaluation measure frequent case low average generality trivial classifier dj ci dj ci tends outperform non trivial classifiers see cohen section 
adopted parameter tuning validation set may result parameter choices classifier behave trivial 
non standard effectiveness measure proposed sable hatzivassiloglou section suggest base absolute values success failure dj ci dj ci dj ci dj ci values relative success csvi dj dj ci csvi dj dj ci 
means correct resp 
wrong decision classifier rewarded resp 
penalized proportionally confidence decision 
proposed measure reward choice thresholding policy unfit autonomous hard classification systems 
appropriate interactive ranking classifiers type larkey confidence classifier decision influences category ranking consequence usefulness system 
measures alternative effectiveness 
general criteria different effectiveness seldom classifier evaluation 
instance efficiency important applicative purposes seldom sole yardstick due volatility parameters evaluation rests 
efficiency may useful choosing classifiers similar effectiveness 
interesting evaluation carried dumais compared different learning methods different dimensions effectiveness training efficiency average time takes build classifier category ci training set tr classification efficiency average time takes classify new document dj category ci 
important alternative effectiveness utility class measures decision theory extend effectiveness economic criteria gain loss 
utility utility matrix table numeric values ufp represent gain brought true positive false positive false negative true negative respectively greater ufp 
standard effectiveness special case utility ufp 
trivial cases ufp case spam filtering failing discard piece junk mail fp serious mistake discarding sebastiani category set expert judgments classifier ufp judgments table 
utility matrix 
legitimate message fn androutsopoulos 
classifier outputs probability estimates membership dj ci decision theory provides analytical methods determine thresholds avoiding need determine experimentally discussed section 
specifically lewis reminds expected value utility maximized ufp ufp case standard effectiveness equal utility tc discussed detail lewis 
works utility employed crestani cohen singer hull lewis catlett schapire :10.1.1.52.2415:10.1.1.52.2415:10.1.1.104.8304:10.1.1.14.6535:10.1.1.14.6535
utility popular text filtering community trec filtering track evaluations long lewis :10.1.1.16.3103
values utility matrix extremely application dependent 
means utility pure effectiveness element difficulty cross comparison classification systems see section classifiers experimentally comparable utility matrices 
effectiveness measures different ones discussed occasionally literature include adjacent score larkey coverage schapire singer error schapire singer pearson product moment correlation larkey recall larkey croft top candidate larkey croft top larkey croft :10.1.1.47.8517:10.1.1.42.8449:10.1.1.134.3024
attempt discuss detail 
shows tc community making consistent efforts experimentation protocols far universal agreement evaluation issues consequence understanding precisely relative merits various methods 
combined effectiveness measures 
precision recall sense isolation 
fact classifier dj ci dj ci trivial acceptor 
csvi function values needs set threshold obtain trivial acceptor 
case usually low precisely equal average test set generality gte ci conversely known everyday ir practice higher levels may obtained price low values 
tempted infer symmetry trivial 
false undefined denominator zero trivial see table 
fact clear definition tp depends positives tp fp tp fp split true positives tp false positives fp depend machine learning automated text categorization precision recall precision recall tp tp fp trivial tp fp undefined trivial acceptor fn tn trivial collection fp tn trivial collection tp fn tp tp fp tp tp fp tp tp fn fn tp tp tp tp fn undefined table 
trivial cases tc 
tn fp tn tn tn fp undefined tn fp tn tn tn fn tn tn fn undefined fn tn tn practice tuning function csvi tuned words riloff lehnert liberal improving detriment conservative improving detriment classifier evaluated means measure combines various measures proposed frequent point average precision threshold repeatedly tuned allow take values 
computed different values averaged resulting values 
analogous standard evaluation methodology ranked ir systems may categories place ir queries 
frequently document ranking classifiers see sch tze yang yang yang pedersen test documents place ir queries categories place documents :10.1.1.32.9956:10.1.1.109.2516:10.1.1.109.2516
frequently category ranking classifiers see lam larkey croft schapire singer wiener :10.1.1.47.8517:10.1.1.47.8517:10.1.1.47.8517:10.1.1.54.6608:10.1.1.54.6608:10.1.1.134.3024:10.1.1.134.3024
case macroaveraging needs redefined document category basis 
measure sense binary valued csvi functions case may varied 
cardinality positives 
breakup symmetry point view classifier judgment positives vs negatives tp dichotomy interest trivial acceptor vs trivial symmetric tp fn tp tp fp precision tn contrapositive 
fact fp tn trivial acceptor trivial 
increased lowering usually cost decreasing usually increased raising cost decreasing kind tuning possible csvi functions values binary valued csvi functions tuning possible anyway difficult see weiss page 
exception single label tc independent document dj classified wrong category cs decreasing means classified right category ct decreasing 
case measure effectiveness 
sebastiani breakeven point value equals apt cohen singer dagan joachims joachims lewis lewis ringuette moulinier ganascia ng yang :10.1.1.11.6124:10.1.1.20.9305:10.1.1.109.2516:10.1.1.109.2516:10.1.1.14.6535:10.1.1.14.6535
obtained process analogous point average precision plot function computed repeatedly varying thresholds breakeven value plot intersects line 
idea relies fact decreasing increases monotonically usually decreases monotonically value near gte ci 
values exactly equal set value closest interpolated breakeven computed average values 
function van rijsbergen chapter cohen cohen singer lewis gale lewis moulinier ruiz srinivasan may seen relative degree importance attributed :10.1.1.16.3103:10.1.1.14.6535
coincides coincides 
usually value attributes equal importance 
shown moulinier yang breakeven classifier equal value :10.1.1.109.2516:10.1.1.109.2516
effectiveness measure chosen classifier tuned thresholds parameters set resulting effectiveness best achievable classifier 
tuning parameter threshold normally done experimentally 
means performing repeated experiments validation set values parameters pk fixed default value case tuned parameter pk chosen value parameter pk tuned different values parameter value yielded best effectiveness chosen benchmarks text categorization standard benchmark collections initial corpora tc publically available experimental purposes 
widely reuters collection consisting set newswire stories classified categories related economics 
reuters collection accounts experimental tc far 
unfortunately translate reliable comparative breakeven proposed lewis criticized 
lewis see message sep text categorization mailing list quoted permission author points breakeven effectiveness measure may parameter setting yields breakeven case final breakeven value obtained interpolation artificial ii equal necessarily desirable clear system achieves high breakeven tuned score high effectiveness measures 
yang notes value parameters close interpolated breakeven may reliable indicator effectiveness 
machine learning automated text categorization results sense experiments carried subtly different conditions 
general different sets experiments may cross classifier comparison experiments performed exactly collection documents categories split training set test set evaluation measure measure depends parameters utility matrix chosen parameter values 
unfortunately lot experimentation reuters collections performed caveat mind testing different classifiers popular versions reuters yang shown lack compliance conditions may experimental results hardly comparable 
table lists results experiments known performed major versions reuters benchmark reuters column reuters column reuters column reuters column reuters column experiments computed breakeven listed popular effectiveness measures readily compare 
note results belonging column directly comparable 
particular yang showed experiments carried reuters column directly comparable versions strangely includes significant percentage unlabelled test documents negative examples categories tend effectiveness 
experiments performed reuters column comparable collection restriction reuters categories highest generality obviously easier collection 
test collections frequently ohsumed collection set hersh joachims lam ho lam lewis ruiz srinivasan yang pedersen documents titles title medical journals ohsumed subset medline document base categories terms mesh thesaurus :10.1.1.11.6124:10.1.1.32.9956
newsgroups collection set lang baker mccallum joachims mccallum nigam mccallum nigam schapire singer :10.1.1.14.5443:10.1.1.14.5443:10.1.1.14.5443:10.1.1.42.7488:10.1.1.42.7488:10.1.1.134.3024:10.1.1.21.7950:10.1.1.21.7950:10.1.1.13.8629:10.1.1.1.5684:10.1.1.1.5684
documents messages posted usenet newsgroups categories newsgroups 
reuters collection may freely downloaded experimentation purposes www research att com lewis reuters html considered standard variant reuters 
cover experiments performed variants reuters different listed small number authors variant reported results difficult interpret 
includes experiments performed original reuters hayes reuters cohen singer :10.1.1.14.6535
ohsumed collection may freely downloaded experimentation purposes ftp edu pub ohsumed sebastiani system type results reported documents training documents test documents categories word non learning yang probabilistic dumais etal :10.1.1.109.2516
probabilistic joachims probabilistic lam etal :10.1.1.11.6124:10.1.1.11.6124
mf probabilistic lewis bim probabilistic li yamanishi probabilistic li yamanishi nb probabilistic yang liu decision trees dumais etal :10.1.1.11.9519
decision trees joachims ind decision trees lewis ringuette swap decision rules apt etal :10.1.1.11.6124:10.1.1.11.6124
ripper decision rules cohen singer decision rules cohen singer dl esc decision rules li yamanishi charade decision rules moulinier ganascia charade decision rules moulinier etal :10.1.1.14.6535
llsf regression yang llsf regression yang liu line linear dagan etal :10.1.1.11.9519:10.1.1.109.2516
widrow hoff line linear lam ho rocchio batch linear cohen singer batch linear dumais etal :10.1.1.14.6535
rocchio batch linear joachims rocchio batch linear lam ho rocchio batch linear li yamanishi classi neural network ng etal :10.1.1.11.6124:10.1.1.11.6124
nnet neural network yang liu neural network wiener etal :10.1.1.11.9519
gis example lam ho nn example joachims nn example lam ho nn example yang nn example yang liu svm dumais etal :10.1.1.11.9519:10.1.1.11.6124:10.1.1.11.6124:10.1.1.109.2516
svmlight svm joachims svmlight svm li yamanishi svmlight svm yang liu adaboost mh committee schapire singer committee weiss etal :10.1.1.11.9519:10.1.1.11.6124:10.1.1.11.6124:10.1.1.134.3024
bayesian net dumais etal 
bayesian net lam etal 
mf table 
comparative results different classifiers obtained different version reuters 
noted entries indicate microaveraged breakeven point parentheses indicates macroaveraging indicates measure 
boldface indicates best performer collection 
ap collection cohen cohen cohen singer lewis catlett lewis gale lewis schapire singer schapire :10.1.1.52.2415:10.1.1.134.3024:10.1.1.134.3024:10.1.1.104.8304:10.1.1.14.6535
cover experiments performed collections reasons illustrated footnote case significant number authors collection experimental conditions making comparisons difficult 
text classifier best 
published experimental results especially listed table allow attempt considerations comparative performance tc methods discussed 
bear mind comparisons reliable experiments performed author carefully controlled conditions 
problematic involve different experiments performed different authors 
case various background con machine learning automated text categorization ditions extraneous learning algorithm may influence results 
may include different choices pre processing stemming indexing dimensionality reduction classifier parameter values different standards compliance safe scientific practice tuning parameters test set separate validation set discussed published papers 
different methods may applied comparing classifiers yang direct comparison classifiers may compared tested collection usually researchers background conditions :10.1.1.109.2516
reliable method 
indirect comparison classifiers may compared tested collections respectively typically different researchers possibly different background conditions baseline classifiers tested direct comparison method 
test gives indication relative hardness results test may obtain indication relative effectiveness reasons discussed method reliable 
number interesting drawn table methods 
concerning relative hardness collections indicate harder collection evidence reuters reuters reuters reuters reuters 
facts unsurprising particular inequalities direct consequence peculiar characteristics reuters reuters discussed section 
concerning relative performance classifiers remembering considerations may attempt boosting classifier committees support vector machines example methods regression methods deliver top notch performance 
sufficient evidence decidedly opt method efficiency considerations application dependent issues play role breaking tie 
neural networks line linear classifiers slightly worse previously mentioned methods 
batch linear classifiers rocchio probabilistic na bayes classifiers look worst learning classifiers 
rocchio results confirm earlier results sch tze classifiers linear discriminant analysis linear regression neural networks perform better rocchio 
results schapire rank rocchio best performers near positives training 
data table hardly sufficient say decision trees 
dumais decision tree classifier shown perform nearly top performing system svm classifier probably renew interest decision trees interest sebastiani results reported earlier literature cohen singer joachims lewis catlett lewis ringuette :10.1.1.11.6124:10.1.1.52.2415:10.1.1.14.6535:10.1.1.14.6535
far lowest performance displayed word classifier implemented yang including learning component concerning word learning classifiers completeness recall highest effectiveness values reported literature reuters collection breakeven belongs construe manually constructed classifier 
classifier tested standard variants reuters mentioned table clear yang small test set reuters breakeven value obtained chosen randomly safe scientific practice demand :10.1.1.109.2516
fact indicative performance construe manual approach represents convincingly questioned yang :10.1.1.109.2516
important bear mind considerations absolute statements may comparative effectiveness tc methods 
reasons particular applicative context may exhibit different characteristics ones reuters different classifiers may respond differently characteristics 
experimental study joachims involving support vector machines nn decision trees rocchio na bayes showed classifiers similar effectiveness categories positive training examples 
fact experiment involved methods scored best support vector machines nn worst rocchio na bayes table shows applicative contexts different reuters may invalidate drawn 
note worth statistical significance testing 
authors gone trouble validating results means tests 
tests useful verifying strongly experimental results support claim system better system verifying difference experimental setup affects measured effectiveness system 
hull sch tze direction validating results means anova test friedman test aimed determining significance difference effectiveness methods terms ratio difference effectiveness variability categories conducts similar test rank positions method category 
yang liu define full suite significance tests apply microaveraged macroaveraged effectiveness 
apply systematically comparison different classifiers able infer fine grained relative effectiveness 
examples significance testing tc see cohen cohen cohen hirsh joachims koller sahami lewis wiener :10.1.1.54.6608:10.1.1.54.6608:10.1.1.21.7950:10.1.1.21.7950:10.1.1.21.988:10.1.1.21.988:10.1.1.21.988:10.1.1.33.4944
word comparison documents category names treated vector weighted terms vector space model 
word implemented yang purpose determining difference effectiveness adding learning component classifier brings 
word called str yang yang chute 
learning classifier proposed wong 
machine learning automated text categorization 
automated tc major research area information systems discipline number factors domains application numerous important proliferation documents digital form bound increase dramatically number importance 
indispensable applications sheer number documents classified short response time required application manual alternative implausible 
improve productivity human classifiers applications classification decision taken final human judgment larkey croft providing tools quickly suggest plausible decisions :10.1.1.47.8517
reached effectiveness levels comparable trained professionals 
effectiveness manual tc anyway cleverdon importantly improved substantially progress research 
levels effectiveness automated tc growing steady pace reach plateau level plateau probably higher effectiveness levels manual tc 
reasons early effectiveness text classifiers dramatically improved arrival tc arena ml methods backed strong theoretical motivations 
examples multiplicative weight updating winnow family widrow hoff adaptive resampling boosting support vector machines provide sharp contrast relatively unsophisticated weak methods rocchio 
tc ml researchers challenging application datasets consisting hundreds thousands documents characterized tens thousands terms widely available 
means tc benchmark checking learning technique scale substantial sizes 
turn probably means active involvement ml community tc bound grow 
success story automated tc going encourage extension methods techniques neighbouring fields application 
techniques typical automated tc extended successfully categorization documents expressed slightly different media instance noisy text resulting optical character recognition ittner junker hoch 
experiments ittner employing noisy texts training phase texts affected source noise test documents effectiveness levels comparable obtainable case standard text achieved 
speech transcripts myers schapire singer :10.1.1.134.3024
instance schapire singer classify answers phone operator request may help able route call specialized operator call type 
concerning radically different media situation bright see lim interesting attempt image categorization sebastiani textual metaphor 
reason capturing real semantic content non textual media automatic indexing open problem 
systems attempt detect content images recognising shapes colour distributions texture general problem image semantics unsolved 
main reason natural language language text medium admits far fewer variations languages employed media 
instance concept house triggered relatively natural language expressions house houses home housing inhabiting triggered far images images different houses exist possible colours shapes viewed possible perspectives possible distances solved multimedia indexing problem satisfactory way general methodology discussed text apply automated multimedia categorization reasons believe effectiveness levels high 
adds common sentiment research automated content indexing multimedia documents needed 
owes lot suggestions constructive criticism norbert fuhr david lewis 
comments earlier draft alessandro sperduti fruitful discussions 
crestani 
probabilistic learning selective dissemination information 
information processing management 
androutsopoulos spyropoulos 
experimental comparison naive bayesian keyword anti spam filtering personal mail messages 
proceedings sigir rd acminternational conference research development information retrieval athens gr pp 

apt damerau weiss 
automated learning decision rules text categorization 
information systems 
attardi di marco 
categorization context 
journal universal computer science 
baker mccallum 
distributional clustering words text classification 
proceedings sigir st acminternational conference research development information retrieval melbourne au pp 

belkin croft 
information filtering information retrieval sides coin 
communications acm 
fuhr lustig 
automatic indexing system air phys 
research application 
proceedings sigir th acminternational conference research development information retrieval grenoble fr pp 

reprinted sparck jones willett pp 

borko 
automatic document classification 
journal association computing machinery 
matwin sebastiani 
learner independent evaluation usefulness statistical phrases automated text categorization 
chin ed text databases document management theory practice 
hershey idea group publishing 
forthcoming 
machine learning automated text categorization 
gram text categorization 
proceedings sdair rd annual symposium document analysis information retrieval las vegas pp 

chakrabarti dom agrawal raghavan 
scalable feature selection classification signature generation organizing large text databases hierarchical topic taxonomies 
journal large data bases 
chakrabarti dom indyk 
enhanced hypertext categorization hyperlinks 
proceedings sigmod acm international conference management data seattle pp 

clack yu 
autonomous document classification business 
proceedings st international conference autonomous agents marina del rey pp 

cleverdon 
optimizing convenient online access bibliographic databases 
information services 
reprinted willett pp 

cohen 
learning classify english text ilp methods 
de raedt ed advances inductive logic programming pp 

amsterdam nl ios press 
cohen 
text categorization relational learning 
proceedings icml th international conference machine learning lake tahoe pp 

cohen hirsh 
joins generalize text classification whirl 
proceedings kdd th international conference knowledge discovery data mining new york pp 

cohen singer 
context sensitive learning methods text categorization 
information systems 
cooper 
inconsistencies probabilistic information retrieval 
information systems 
masand smith waltz 
trading mips memory knowledge engineering classifying census returns connection machine 
communications acm 
crestani lalmas van rijsbergen campbell 
document relevant 
probably 
survey probabilistic models information retrieval 
surveys 
dagan karov roth 
mistake driven learning text categorization 
proceedings emnlp nd conference empirical methods natural language processing providence pp 

deerwester dumais furnas landauer harshman 
indexing latent semantic indexing 
journal american society information science 
zaragoza gallinari 
hmm passage models document classification ranking 
proceedings ecir rd european colloquium information retrieval research darmstadt de 
az de rodr guez ure pez garc vega 
integrating linguistic resources uniform way text classification tasks 
proceedings lrec st international conference language resources evaluation es pp 

domingos pazzani 
optimality simple bayesian classifier zero loss 
machine learning 
drucker vapnik wu 
automatic text categorization applications text retrieval 
ieee transactions neural networks 
dumais chen 
hierarchical classification web content 
proceedings sigir rd acminternational conference research development information retrieval athens gr pp 

dumais platt heckerman sahami 
inductive learning algorithms representations text categorization 
proceedings cikm th sebastiani acminternational conference information knowledge management bethesda pp 

rigau 
boosting applied word sense disambiguation 
proceedings ecml th european conference machine learning barcelona es pp 

field 
automatic indexing automatic assignment controlled language indexing classification free indexing 
journal documentation 
forsyth 
new directions text categorization 
gammerman ed causal models intelligent data management pp 

heidelberg de springer 
frasconi soda 
text categorization multi page documents hybrid naive bayes hmm approach 
journal intelligent information systems 
forthcoming 
fuhr 
probabilistic model dictionary automatic indexing 
proceedings riao st international conference recherche information par ordinateur grenoble fr pp 

fuhr 
models retrieval probabilistic indexing 
information processing management 
fuhr buckley 
probabilistic learning approach document indexing 
information systems 
fuhr hartmann lustig tzeras 
air rule multistage indexing system large subject fields 
proceedings riao rd international conference recherche information par ordinateur barcelona es pp 

fuhr 
retrieval test evaluation rule automated indexing air phys 
proceedings sigir th acminternational conference research development information retrieval cambridge uk pp 

fuhr pfeifer 
probabilistic information retrieval combination abstraction inductive learning probabilistic assumptions 
information systems 
rnkranz 
exploiting structural information text classification www 
proceedings ida rd symposium intelligent data analysis amsterdam nl pp 

sebastiani simi 
experiments feature selection negative evidence automated text categorization 
proceedings ecdl th european conference research advanced technology digital libraries lisbon pt pp 

gale church yarowsky 
method disambiguating word senses large corpus 
computers humanities 
vert lalmas fuhr 
probabilistic description oriented approach categorising web documents 
proceedings cikm th acm international conference information knowledge management kansas city pp 

gray harley 
computer assisted indexing 
information storage retrieval 
guthrie walker guthrie 
document classification machine theory practice 
proceedings coling th international conference computational linguistics kyoto jp pp 

hayes andersen nirenburg schmandt 
tcs shell content text categorization 
proceedings th ieee conference artificial intelligence applications santa barbara pp 

heaps 
theory relevance automatic document classification 
information control 
hersh buckley leone 
ohsumed interactive retrieval evaluation new large text collection research 
proceedings sigir machine learning automated text categorization th acminternational conference research development information retrieval dublin pp 

hull 
improving text retrieval routing problem latent semantic indexing 
proceedings sigir th acminternational conference research development information retrieval dublin pp 

hull pedersen sch tze 
method combination document filtering 
proceedings sigir th acminternational conference research development information retrieval rich ch pp 

ittner lewis ahn 
text categorization low quality images 
proceedings sdair th annual symposium document analysis information retrieval las vegas pp 

iwayama tokunaga 
cluster text categorization comparison category search strategies 
proceedings sigir th acminternational conference research development information retrieval seattle pp 

iyer lewis schapire singer singhal 
boosting document routing 
proceedings cikm th acm international conference information knowledge management mclean pp 

joachims 
probabilistic analysis rocchio algorithm tfidf text categorization 
proceedings icml th international conference machine learning nashville pp 

joachims 
text categorization support vector machines learning relevant features 
proceedings ecml th european conference machine learning chemnitz de pp 

joachims 
transductive inference text classification support vector machines 
proceedings icml th international conference machine learning bled sl pp 

joachims sebastiani 
guest editors special issue automated text categorization 
journal intelligent information systems 
forthcoming 
john kohavi pfleger 
irrelevant features subset selection problem 
proceedings icml th international conference machine learning new brunswick pp 

junker abecker 
exploiting thesaurus knowledge rule induction text classification 
proceedings nd international conference advances natural language processing bl pp 

junker hoch 
experimental evaluation ocr text representations learning document classifiers 
international journal document analysis recognition 
kessler nunberg sch tze 
automatic detection text genre 
proceedings acl th annual meeting association computational linguistics madrid es pp 

kim hahn zhang 

text filtering boosting naive bayes classifiers 
proceedings sigir rd acminternational conference research development information retrieval athens gr pp 

klinkenberg joachims 
detecting concept drift support vector machines 
proceedings icml th international conference machine learning stanford pp 

knight 
mining online text 
communications acm 

decision theory approach optimal automated indexing 
proceedings sigir th acminternational conference research development information retrieval berlin de pp 

koller sahami 
hierarchically classifying documents words 
proceedings icml th international conference machine learning nashville pp 

sebastiani korfhage 
information storage retrieval 
wiley computer publishing new york 
lam lee 
feature reduction neural network text categorization 
proceedings dasfaa th ieee international conference database advanced systems advanced application tw pp 

lam ho 
generalized instance set automatic text categorization 
proceedings sigir st acminternational conference research development information retrieval melbourne au pp 

lam low ho 
bayesian network induction approach text categorization 
proceedings ijcai th international joint conference artificial intelligence nagoya jp pp 

lam ruiz srinivasan 
automatic text categorization applications text retrieval 
ieee transactions knowledge data engineering 
lang 
newsweeder learning filter netnews 
proceedings icml th international conference machine learning lake tahoe pp 

larkey 
automatic essay grading text categorization techniques 
proceedings sigir st acminternational conference research development information retrieval melbourne au pp 

larkey 
patent search classification system 
proceedings dl th digital libraries berkeley pp 

larkey croft 
combining classifiers text categorization 
proceedings sigir th acminternational conference research development information retrieval rich ch pp 

lewis 
evaluation phrasal clustered representations text categorization task 
proceedings sigir th acminternational conference research development information retrieval dk pp 

lewis 
representation learning information retrieval 
ph 
thesis department computer science university massachusetts amherst 
lewis 
evaluating autonomous text classification systems 
proceedings sigir th acminternational conference research development information retrieval seattle pp 

lewis 
sequential algorithm training text classifiers corrigendum additional data 
sigir forum 
lewis 
trec filtering track description analysis 
proceedings trec th text retrieval conference gaithersburg pp 

lewis 
naive bayes independence assumption information retrieval 
proceedings ecml th european conference machine learning chemnitz de pp 

lewis catlett 
heterogeneous uncertainty sampling supervised learning 
proceedings icml th international conference machine learning new brunswick pp 

lewis gale 
sequential algorithm training text classifiers 
proceedings sigir th acminternational conference research development information retrieval dublin pp 

see lewis :10.1.1.16.3103
lewis hayes 
guest editorial special issue text categorization 
information systems 
lewis ringuette 
comparison learning algorithms text categorization 
proceedings sdair rd annual symposium document analysis information retrieval las vegas pp 

lewis schapire callan papka 
training algorithms linear text classifiers 
proceedings sigir th acminternational conference research development information retrieval rich ch pp 

machine learning automated text categorization li yamanishi 
text classification esc stochastic decision lists 
proceedings cikm th acm international conference information knowledge management kansas city pp 

li jain 
classification text documents 
computer journal 
liddy paik yu 
text categorization multiple users semantic features machine readable dictionary 
information systems 
liere tadepalli 
active learning committees text categorization 
proceedings aaai th conference american association artificial intelligence providence pp 

lim 
learnable visual keywords image classification 
proceedings dl th digital libraries berkeley pp 

manning sch tze 
foundations statistical natural language processing 
mit press cambridge 
maron 
automatic indexing experimental inquiry 
journal association computing machinery 
masand 
optimising confidence text classification evolution symbolic expressions 
kinnear ed advances genetic programming chapter pp 

cambridge mit press 
masand waltz 
classifying news stories memorybased reasoning 
proceedings sigir th acminternational conference research development information retrieval dk pp 

mccallum nigam 
employing em pool active learning text classification 
proceedings icml th international conference machine learning madison pp 

mccallum rosenfeld mitchell ng 
improving text classification shrinkage hierarchy classes 
proceedings icml th international conference machine learning madison pp 

merkl 
text classification self organizing maps lessons learned 
neurocomputing 
mitchell 
machine learning 
mcgraw hill new york 
mladeni 
feature subset selection text learning 
proceedings ecml th european conference machine learning chemnitz de pp 

mladeni grobelnik 
word sequences features text learning 
proceedings erk seventh electrotechnical computer science conference ljubljana sl pp 

moulinier ganascia 

applying existing machine learning algorithm text categorization 
wermter riloff eds connectionist statistical symbolic approaches learning natural language processing heidelberg de pp 

springer verlag 
moulinier ra ganascia 

text categorization symbolic approach 
proceedings sdair th annual symposium document analysis information retrieval las vegas pp 

myers kearns singh walker 
boosting approach topic spotting subdialogues 
proceedings icml th international conference machine learning stanford 
ng goh low 
feature selection perceptron learning usability case study text categorization 
proceedings sigir th acminternational conference research development information retrieval philadelphia pp 

nigam mccallum thrun mitchell 
text classification labeled unlabeled documents em 
machine learning 
sebastiani oh myaeng lee 

practical hypertext categorization method links incrementally available class information 
proceedings sigir rd acminternational conference research development information retrieval athens gr pp 

pazienza ed 

information extraction 
number lecture notes computer science 
springer heidelberg de 
riloff 
little words big difference text classification 
proceedings sigir th acminternational conference research development information retrieval seattle pp 

riloff lehnert 
information extraction basis high precision text classification 
information systems 
robertson harding 
probabilistic automatic indexing learning human indexers 
journal documentation 
robertson sparck jones 
relevance weighting search terms 
journal american society information science 
reprinted willett pp 

roth 
learning resolve natural language ambiguities unified approach 
proceedings aaai th conference american association artificial intelligence madison pp 

ruiz srinivasan 
hierarchical neural networks text categorization 
proceedings sigir nd acminternational conference research development information retrieval berkeley pp 

sable hatzivassiloglou 
text approaches non topical image categorization 
international journal digital libraries 
salton buckley 
term weighting approaches automatic text retrieval 
information processing management 
reprinted sparck jones willett pp 

salton wong yang 
vector space model automatic indexing 
communications acm 
reprinted sparck jones willett pp 

saracevic 
relevance review framework thinking notion information science 
journal american society information science 
reprinted sparck jones willett pp 

schapire singer 
boostexter boosting system text categorization 
machine learning 
schapire singer singhal 
boosting rocchio applied text filtering 
proceedings sigir st acminternational conference research development information retrieval melbourne au pp 

sch tze 
automatic word sense discrimination 
computational linguistics 
sch tze hull pedersen 
comparison classifiers document representations routing problem 
proceedings sigir th acm international conference research development information retrieval seattle pp 

scott matwin 
feature engineering text classification 
proceedings icml th international conference machine learning bled sl pp 

sebastiani sperduti 
improved boosting algorithm application automated text categorization 
proceedings cikm th acminternational conference information knowledge management mclean pp 

singhal mitra buckley 
learning routing queries query zone 
proceedings sigir th acminternational conference research development information retrieval philadelphia pp 

machine learning automated text categorization singhal salton mitra buckley 
document length normalization 
information processing management 
slonim tishby 
power word clusters text classification 
proceedings ecir rd european colloquium information retrieval research darmstadt de 
sparck jones willett eds 

readings information retrieval 
morgan kaufmann san mateo 
taira 
feature selection svm text categorization 
proceedings aaai th conference american association artificial intelligence orlando pp 

kok 
adaptive information filtering evolutionary computation 
information sciences 
tumer ghosh 
error correlation error reduction ensemble classifiers 
connection science 
tzeras hartmann 
automatic indexing bayesian inference networks 
proceedings sigir th acminternational conference research development information retrieval pittsburgh pp 

van rijsbergen 
theoretical basis occurrence data information retrieval 
journal documentation 
van rijsbergen 
information retrieval second ed 
butterworths london uk 
available www dcs gla ac uk keith 
weigend wiener pedersen 
exploiting hierarchy text categorization 
information retrieval 
weiss apt damerau johnson oles goetz 
maximizing text mining performance 
ieee intelligent systems 
wiener pedersen weigend 
neural network approach topic spotting 
proceedings sdair th annual symposium document analysis information retrieval las vegas pp 

willett ed 

document retrieval systems 
taylor graham london uk 
wong kan young 
action automatic classification full text documents 
sigir forum 
yang 
expert network effective efficient learning human decisions text categorisation retrieval 
proceedings sigir th acminternational conference research development information retrieval dublin pp 

yang 
noise reduction statistical approach text categorization 
proceedings sigir th acminternational conference research development information retrieval seattle pp 

yang 
evaluation statistical approaches text categorization 
information retrieval 
yang chute 
example mapping method text categorization retrieval 
information systems 
yang liu 
re examination text categorization methods 
proceedings sigir nd acminternational conference research development information retrieval berkeley pp 

yang pedersen 
comparative study feature selection text categorization 
proceedings icml th international conference machine learning nashville pp 

yang slattery ghani 
study approaches hypertext categorization 
journal intelligent information systems 
forthcoming 
yu lam 
new line learning algorithm adaptive text filtering 
proceedings cikm th acm international conference information knowledge management bethesda pp 

