compiler runtime analysis efficient communication data intensive applications processing analyzing large volumes data plays increasingly important role domains scientific research 
developing compiler processes data intensive applications written dialect java compiles efficient execution distributed memory parallel machines 
focus problem generating correct efficient communication data intensive applications 
static analysis techniques extracting global reduction function data parallel loop determining subscript function monotonic 
runtime technique reducing volume communication global reduction phase 
experimented data intensive applications evaluate efficacy techniques 
results show techniques extracting global reduction functions establishing monotonicity subscript functions successfully handle applications significant reduction communication volume execution times achieved runtime analysis technique runtime communication analysis critical achieving speedups parallel configurations 
analysis processing large multidimensional scientific datasets data items associated points multidimensional attribute space important component science engineering 
examples datasets include raw processed sensor data satellites output hydrodynamics chemical transport simulations archives medical images 
supported nsf acr nsf career award aci nsf ccr 
renato ferreira agrawal joel saltz department computer science university maryland college park md cs umd edu department computer information sciences university delaware newark de agrawal cis udel edu datasets large example medical imaging size single digitized composite slide image high power light microscope gb uncompressed single large hospital process thousands slides day 
processing typically carried multidimensional datasets related scientific domains share important common characteristics 
access data items described range query multidimensional bounding box underlying multidimensional space dataset 
basic computation consists mapping coordinates retrieved input items corresponding output items aggregating way retrieved input items mapped output data items 
computation particular output element reduction operation 
developing compiler support allowing high level efficient programming data intensive computations multidimensional datasets 
dialect java expressing class computations includes data parallel extensions specifying collection objects parallel loop reduction interface 
compiler extensively uses existing runtime system active data repository adr optimizing resource usage execution data intensive applications 
adr integrates storage retrieval processing multidimensional datasets distributed memory parallel machine 
runtime system language design compilation techniques particularly exploit commonalities data processing applications stated earlier 
target distributed memory parallel configuration cluster workstations execution data intensive computations 
compiling class applications distributed memory parallel configuration communication generation optimization important challenge 
focus compiler runtime analysis required correct efficient interprocessor communication class data intensive applications targeting 
problem different certain ways general communication analysis problem handled data parallel compilers 
applications targeting communication restricted global reduction processors 
processor accesses large disk resident datasets volume communication large 
object oriented data parallel language communication analysis harder 
compiler runtime analysis techniques 
static compiler analysis technique extracting global reduction function original loop 
second technique determining monotonicity subscript functions 
runtime analysis technique reducing communication volume global reduction 
evaluate technique developed prototype compiler titanium infrastructure berkeley 
experiences compiling applications experimental results shown compiler techniques successfully handle example applications despite limitations 
shown substantial reduction communication volume achieved runtime analysis technique resulting significant reduction execution times 
rest organized follows 
section give overview applications target language features high level abstractions compiler supports satellite data processing example give overview compilation techniques 
static analysis techniques extracting global reduction functions determining monotonicity subscript functions section 
runtime analysis technique reducing volume communication section 
experimental results section 
compare related research efforts section conclude section 
overview section details class applications targeting 
describe briefly compiler front execution strategy handle applications 
data intensive applications applications target arise domains science engineering 
satellite data processing earth scientists study earth processing remotely sensed data continuously acquired satellite sensors significant amount earth science research devoted developing correlations sensor various properties surface earth 
typical analysis processes satellite data days year generates composite images area study 
generating composite image requires projection globe dimensional grid pixel composite image computed selecting best sensor value maps associated grid point 
analysis microscopy data virtual microscope application support need interactively view process digitized data arising tissue specimens 
raw data system captured digitally scanning collections full microscope slides high power 
virtual microscope application emulates usual behavior physical microscope including continuously moving stage changing magnification focus 
data intensive applications related scientific areas share common characteristics 
basic computation consists mapping coordinates retrieved input items corresponding output items aggregating way retrieved input items mapped output data items 
computation particular output element reduction operation correctness output usually depend order input data items aggregated 
language features example application subsection high level abstractions facilitating rapid development applications process disk resident datasets 
satellite data processing application example 
describe nature datasets captured satellites orbiting earth describe typical processing explain high level abstractions data parallel language constructs support performing processing 
satellite orbiting earth collects data sequence blocks 
satellites contain sensors different bands 
measurements produced satellite short values bits band 
satellite orbits earth sensors sweep surface building scan lines measurements 
block consists half scan lines array short integers element 
latitude longitude time stored block measure 
typical computation satellite data follows 
rectangular portion earth specified latitudes points 
time range specified 
point earth specified area available pixels time period scanned output value computed produce composite image planet 
image re interface object class implementing interface reduction variable public class pixel short bands short geo class block short time pixel bands pixel getdata point search lat long geo data return pixel exists return null low level data layout class block data void data new block pixel getdata point point time get point get get return data time getdata public class implements int value void accumulate pixel input aggregate value input pixel output searchers study number properties deforestation time pollution different areas 
sources sparsity irregularity dataset computation 
pixels captured satellite viewed comprising sparse dimensional array time latitude longitude dimensions 
pixels time values available latitude longitude 
second source irregularity dataset comes earth spherical satellite sees area earth rectangular grid 
translation rectangular area satellite captured band latitudes straight forward 
show essential structure associated satellite data processing application 
class block represents data captured time unit satellite 
class function getdata takes latitude longitude pair sees pixel block location 

satellite data processing code high level data layout public class data void data new pixel getdata point return data getdata public class point 
point 
new public static void main int args point args args point args args point low args args args point high args args args low high image new foreach point point get get pixel val getdata accumulate val returns pixel 
class stores data dimensional array blocks 
classes block visible programmer writing processing code 
goal provide simplified view dataset application programmers easing development correct necessarily efficient data processing application 
compiler translating code obviously access source code classes enables generate efficient low level code 
interface input dataset visible programmer writing main execution code 
access class gives view dimensional grid pixels available 
main processing function takes command line arguments input 
specify time range processing performed 
latitudes points rectangular output desired 
need iterate blocks time range examine pixels fall output region perform reduction operation 
specify computation data parallel language follows 
consider dimensional rectangular grid time latitude longitude axes 
grid pixels exist small fraction points grid 
high level code just iterates grid foreach loop 
point grid time lat long tuple examine block time pixel 
pixel exists performing reduction operation object output lat long 
rely types data parallel constructs 
collection objects type object collection coordinate associated coordinate belongs prespecified rectilinear section 
foreach loop iterates objects property order iterations influence result associated computations 
java interface called 
object class implementing interface acts reduction variable 
reduction variable property updated inside foreach loop series operations associative commutative 
furthermore intermediate value reduction variable may loop self updates 
execution strategy overview experiences data intensive applications developing runtime support basic code execution scheme follows 
output data structure divided tiles tile fits main memory 
avoid causing page faults loop execution severely degrade performance 
input dataset read disk block time 
disks provide highest bandwidth incur lowest overhead accessing data single disk block 
input disk block brought main memory iterations loop read disk block update element current tile performed 
tile output data structure allocated particular disk block may read contribute multiple output tiles 
foreach sl sl sr srn om sl fm om sl sr srn 
canonical form loop loop preprocessing facilitate execution loops fashion compiler performs initial preprocessing loop 
process may replace initial loop sequence loops conforms canonical form 
consider data intensive parallel loop dialect java described earlier 
purpose discussion collections objects elements modified loop referred left hand side lhs collections collections elements read loop considered right hand side rhs collections 
canonical form support shown 
domain loop iterates denoted rhs collection objects read loop denoted 
similarly lhs collections written loop denoted om 
lhs collections accessed single subscript function sl 
iteration loop value output element oi sl updated function fi 
specifically function form oi sl oi sl op sr op sr op op gn srn op associative commutative operator function gi uses ii sri scalar values program 
loop planning executing data intensive loops number decisions need execution iterations loop 
decisions loop planning phase described 
decisions chosen simple strategy sophisticated treatment topic research 
issues executing loop parallel iteration partitioning deciding iterations performed processor 
approach execute iteration owner element read iteration 
result communication required rhs elements 
motivation input collections usually larger output collections class applications 
lhs strip sl execute processor pj allocate initialize strip sl om rhs collection ii disk block element block iters sl sl update values sl om sl perform global reduction finalize values sl 
basic loop execution strategy issue choice tiling strategy lhs collections 
approach far query runtime system determine available memory allocated processor 
mentioned earlier lhs divided tiles strips fs srg fit available memory 
determine set disk blocks need read performing updates tile 
lhs tile allocated 
elements particular disk block required updating multiple tiles disk block read 
compiler uses static declarations program extract expression applied meta data associated disk block 
purpose describing execution strategy assume rhs collection ii processor lhs strip set disk blocks need read denoted 
loop execution strategy basic loop execution strategy shown 
separate describe variations strategy match characteristics certain applications 
details compiler support operations performed locally processor separate 
focus statement strategy global reduction stage 
compiler analysis techniques section static analysis techniques 
extracting global reduction function original data parallel loop 
function required correct processing loop distributed memory machine 
second technique determining subscript functions accessing input output collections monotonic 
information exploited runtime technique described section reduce volume communication 
extracting global reduction function describe technique extracting global reduction function 
problem statement shown output collection oi updated loop follows oi sl fi oi sl sr srn want synthesize function fi form oi sl fi oi sl sl perform global reduction collections oi computed individual processors local reduction phase 
solution approach approach classifying data dependencies control dependencies updates data members lhs objects 
consider statement local reduction function updates data member lhs object oi sl 
statement includes temporary variables defined local reduction function perform forward substitution replace temporary variables 
forward substitution update data member classified types 
assignment loop constant expression expression value constant invocation data intensive loop local reduction function extracted 

assignment value data member lhs object expression involving data members loop constants 

update commutative associative function op data member oi sl updated oi sl oi sl op function involve members lhs object oi sl 

update classified previous groups 
compiler compile data intensive loops update data member lhs object local reduction function classified second third group 
restriction create problems applications looked far 
set statements local reduction function update data members lhs object denoted 
accumulate pixel val int val bands int val bands int value max value accumulate old value max value old value 
local reduction function global reduction function satellite application general statements set control dependent predicates function 
currently handle local reduction functions statements set control dependent loop constant expressions 
restriction create problems set applications examined 
code generation synthesizing function fi start statements set statements fall groups left unchanged 
statements fall group replaced statement form oi sl oi sl op sl code generation notion program slicing :10.1.1.20.9646
original local reduction function statements set slicing criteria apply technique construct function produce results modified statements group statements 
slicing code generation naturally handles possibility statement set may control dependent loop constant expression 
simple example application technique shown 
example satellite application described section 
statement local reduction function statement updates value data member reduction object 
statement type analysis 
replacing statement data member object old computed processor construct program slice 
slice include statement function resulting global reduction function single statement 
monotonicity analysis subsection static analysis technique determining function monotonic 
specifically interested determining subscript functions accessing lhs rhs collections monotonic 
approach combining control flow analysis integer programming techniques 
initially analysis assumptions 
assume loops subscript inverted subscript function 
second simplicity presentation basic ideas consider foreach loops input output collections single dimension 
denote function consideration assumed foreach loop collections single dimension function takes integer input returns integer output 
consider control flow graph cfg representing function function contains calls functions inline functions code function represented single cfg 
enumerate acyclic paths cfg denote pn 
focus code acyclic path 
performing forward substitution temporary value create expression relating output function input function values program 
input output function path pj taken denoted sj 
function monotonic path pj hold sj sj sj sj suppose function invoked particular parameter 
particular acyclic path taken depend value parameter 
establishing monotonicity function need hold sj sl sj sl expressions functions sj computed forward substitution check conditions integer set manipulation ability omega calculator 
calculator obviously answer queries type turned sufficient set applications 
usually improve accuracy technique presence control flow establishing certain conditionals independent input parameter function 
consider conditional predicate predicate shown independent input parameter invocation function parameter take successor cfg 
allows partition paths disjoint groups pk 
groups paths property invocation function parameter results execution path belonging group pj invocation function parameter result execution paths belonging group pj 
analysis possible paths execution condition monotonicity restated jp pk lp sj sl jp pk lp sj sl dealing loops discuss perform monotonicity analysis subscript functions contain loops 
set applications subscript functions loops technique deal loops limited form 
process loops properties loop single entry point single exit point loop contain conditionals loop countable number times loop iterates depend value computed loop array accessed loop accessed affine subscripts assigned affine values scalar updated loop updated affine values 
cases updates performed loop array elements scalars summarized loop count constant values 
loop replaced single basic block 
treatment loops analysis previously applied 
multidimensional spaces data parallel dialect java allows foreach loops collections multidimensional spaces 
subscript function takes multidimensional point input outputs multidimensional point 
cases runtime analysis section requires subscript functions properties value dimension output point dependent exactly dimension input point loop constant 
value dimension input point influences value dimension output point 
dimension output point value dependent dimension input point function relating input value output value monotonic 
properties ascertained simple dependence analysis subscript function 
establishing third property analysis single dimensional cases applied dimension 
runtime communication analysis number nodes system naive approach divide output tile sections 
node responsible collecting aggregating elements section tile 
node needs communicate nodes section tile 
total output size total communication volume volume communication increases linearly number nodes rapidly bottleneck 
section approach exploits fact node system may data entire output tile processed 
conceptually tile partitioned sections node responsible collecting aggregating elements section tile 
communicating entire sections tile owner node node sends set elements section updated 
best case processors may update disjoint set output elements 
total communication volume factor increases asymptotically main challenges supporting optimized communication strategy 
determining efficiently set elements tile updated node 
communicate element nodes incurring high data overhead 
challenge addressed meta data associated disk block monotonicity analysis described section 
mentioned section system determines list rhs disk blocks need brought memory processing tile 
part meta data bounding box stored disk block containing range elements block 
monotonicity subscript function sl inverse subscript function established input bounding box mapped output rectangle simply applying subscript function corners 
constructing list rectangles blocks available locally particular tile know elements updated node 
rectangles create blocks elements need communicated nodes 
avoid communicating element want eliminate intersections list rectangles 
algorithm purpose subsection 
dequeue event list events switch type case split list switch intersection range range case entirely outside case entirely inside box ends box insert split box box default output rect range started coord remove list grow range incorporate range insert split longest rect shortest ends insert range list inside range rectangle list case range list output rect range started coord 
sweeping line algorithm remove intersections rectangular regions eliminating intersections algorithm receives input collection intersecting rectangles 
produces output set rectangles comprise set elements intersect 
algorithm notion sweeping line 
implemented dimensional version algorithm turned sufficient set applications 
algorithm extended dimensional space sweeping plane line 
algorithm 
vertical sweeping line parallel axis algorithm 
main data structures algorithm 
event list 
initially stores coordinates rectangle 
rectangle split new values may inserted event list 
event explicitly marked event event split event 
vertical sweeping line refer range rectangle mean range coordinates 
second data structure list 
point execution algorithm stores rectangles intersect current location sweeping line 
initially list empty 
algorithm 
consists retrieving event event list performing actions triggered event 
goes events 
illustrate algorithm example 
intersecting rectangles picture 
initialization sweeping line leftmost position shown 
event handled rectangle list currently empty processing just inserts rectangle list 
event list shown ii rectangle comparing ranges notice intersects range rectangle actions taken outputting rectangle fraction traversed removing rectangle list updating range include range inserting list rectangle inserting rectangle list 
shown iii rectangle located sweeping line 
lies entirely active range ends rectangle action taken 
event shown iv active range ends split event inserted coordinate event range list action taken 
line reaches rectangle shown 
range rectangle list algorithm outputs rectangle 
recall range updated earlier include range event splits inserted earlier execution 
events system just inserts ranges list changes intersect active ranges 
rectangles reached algorithm outputs remaining portions separate rectangles 
rectangle event shown vi 
algorithm guarantee optimality terms returning minimal number rectangles 
show section runtime overhead algorithm extremely low 
loop execution mentioned section communication takes place global reduction phase 
node responsible sending set non overlapping rectangles intersect section tile owner section tile 
node sends message node 
message includes integer containing total number rectangles message integers rectangle describing coordinates rectangle data elements rectangles 
components message referred ii iv iii 
example execution intersection removal algorithm meta data associated message 
total overhead depends number dimensions output collection number rectangles processed 
message containing dimensional rectangles bytes 
reducing number rectangles returned intersection elimination algorithm help reducing overhead 
discuss section overhead extremely low test cases 
messages exchanged node processes message received traversing rectangles contained meta data attached message update associated elements 
nodes update section tile global reduction function constructed described section 
experimental results prototype compiler generate code applications 
run test programs cluster mhz pentium ii nodes connected gigabit ethernet 
node mb main memory gb local disk 
ran experiments nodes cluster 
runs node configuration 
application virtual microscope 
implemented multi grid version application processes images captured different generates high resolution output image 
refer application 
second application experimented satellite image processing application similar described section 
refer section 
applications substantially different terms nature datasets handle computations perform mg accesses dense dataset retrieve data corresponding portion vi mg satellite orig node node orig node node medium large table 
number input rectangles eliminating intersections slide order generate output image 
regularity dataset exploited partition disk blocks nodes fashion node data portion entire output region 
application benefit runtime communication optimization developed 
second application satellite accesses sparse dataset retrieve data corresponding region planet aggregates period time 
aggregation performed large time period expect nodes data points elements output 
runtime communication optimization profitable application 
implemented separate versions applications 
implements naive approach described section high communication overhead 
refer version full 
second version incorporates runtime communication optimization referred 
base line best case implemented version performs communication 
version referred 
applications experimented different query sizes referred medium large queries 
query size mean size input dataset application processes execution 
mg application dataset contains gb data 
query size corresponds reading mb generating output mb 
query application requires reading nearly gb generating output nearly gb 
entire dataset satellite application contains gb 
medium query reads mb generate output mb 
large query reads nearly gb generating mb output 
consider intersection elimination algorithm 
number rectangles applying algorithm test case shown table 
numbers reported application query pair total number rectangles applying algorithm orig number rectangles applying algorithm node case node aggregate number rectangles nodes applying algorithm node 
important observations table 
total number rectangles med large mb kb mb kb mb kb mb kb mb kb mb kb sat med sat large mb kb mb kb mb kb mb kb mb kb mb kb table 
communication meta data sizes opt versions med large sat med sat large mb mb mb mb mb mb mb mb mb mb mb mb table 
total communication volume full versions need processed algorithm quite large cases efficiency algorithm important keeping overhead analysis low 
second substantial reduction number rectangles achieved means significant overlap rectangles corresponding different disk blocks 
focus runtime cost executing intersection elimination algorithm 
test cases execution nodes time taken algorithm total execution time 
cases ratio decreases number nodes increases 
focus overhead meta data needs sent optimized messages comprised disjoint rectangular sections 
table presents total communication volume mega bytes sum sizes messages sent application execution versions 
parenthesis table shows sum sizes meta data sent messages 
size meta data total communication volume cases 
data table clearly establishes overhead sending meta data optimized messages negligible 
table shows total communication volume full versions 
numbers compared total communication volume shown opt versions table see reduction communication volume achieved runtime technique 
medium query size reduction communication volume processors respectively 
large query size reduction communication volume time number processors full opt 
application medium query time number processors full opt 
application large query processors respectively 
satellite medium query size reduction communication volume configurations 
large query size application reduction nodes respectively 
shows execution times application running medium query 
improvements produced optimization nodes respectively 
speedups opt version processors respectively 
presents execution times executing query 
opt version performs better full version nodes respectively 
speedups query nodes respectively 
performance gains nodes medium large queries proportional reduction communication volume reported earlier 
number nodes increases amount overlap portions written different nodes decreases 
higher performance gains obtained commu time full opt number processors 
satellite application running medium query time full opt number processors 
satellite application large query portions written node 
execution times application 
expected runtime communication analysis effective application included node execution 
results query shown 
improvements nodes respectively 
speedups opt versions nodes respectively 
results application query shown 
performance improvement observed nodes respectively 
speedups time nodes respectively 
performance gains nodes query sizes proportional reduction communication volume reported earlier 
related communication analysis optimization problem addressed harder challenging ways general ways general communication analysis problem handled distributed memory compilers 
communication restricted global reduction stage target applications 
processor accesses large datasets volume communication large 
object oriented data parallel language communication analysis harder 
kandemir focused analysis optimizations core programs including inter processor communication 
considering different set applications different language runtime support infrastructure communication analysis project focused near neighbor communication 
applications hand require global reduction 
runtime analysis communication optimization extensively part inspector executor framework parallelizing sparse computations distributed memory details runtime analysis section different considering different application class 
analysis optimization reduction operations studied topic compiler literature 
object oriented language reduction operations performed complex objects compiler analysis significantly different previous 
monotonicity analysis significantly different existing similar problems handling complex control flow 
integer set manipulation previously specific optimization code generation problems parallel compilation 
developing compiler data parallel dialect java targeting data intensive applications 
focused compiler runtime techniques enabling correct efficient communication class applications 
static analysis techniques extracting global reduction function data parallel loop determining monotonicity subscript function 
runtime technique reducing volume communication global reduction phase 
experimented data intensive applications evaluate efficacy techniques 
results show techniques extracting global reduction functions establishing monotonicity subscript functions successfully handle applications significant reduction communication volume execution times achieved runtime analysis technique runtime communication analysis critical achieving speedups parallel configurations 
vikram adve john mellor crummey 
integer sets data parallel program analysis optimization 
proceedings acm sigplan conference programming language design implementation pages 
acm press june 
acm sigplan notices vol 

agrawal renato ferreira joel saltz jin 
high level programming methodologies data intensive computing 
proceedings fifth workshop languages compilers run time systems scalable computers may 
choudhary fox haupt ranka 
wu 
compiling fortran hpf distributed memory mimd computers 
journal parallel distributed computing april 
chang acharya sussman saltz 
customizable parallel database multi dimensional data 
acm sigmod record march 
chang renato ferreira alan sussman joel saltz 
infrastructure building parallel database systems multi dimensional data 
proceedings second merged ipps spdp th international parallel processing symposium th symposium parallel distributed processing 
ieee computer society press april 
chang moon anurag acharya carter shock alan sussman joel saltz 
titan high performance remote sensing database 
proceedings international conference data engineering pages 
ieee computer society press april 
siddhartha chatterjee john gilbert fred long robert schreiber shang hua teng 
generating local addresses communication sets data parallel programs 
proceedings fourth acm sigplan symposium principles practice parallel programming ppopp pages may 
acm sigplan notices vol 

ferreira moon humphries sussman saltz miller 
virtual microscope 
proceedings amia annual fall symposium pages 
american medical informatics association hanley belfus october 
available university maryland technical report cs tr umiacs tr 
renato ferreira agrawal joel saltz 
compiling object oriented data intensive computations 
proceedings international conference supercomputing may 
renato ferreira agrawal joel saltz 
compiler supported high level abstractions sparse datasets 
submitted publication available www udel edu ics renato ps 
han chau wen tseng 
improving compiler runtime support irregular reductions 
proceedings th workshop languages compilers parallel computing august 
high performance fortran forum 
hpf language specification version 
available www rice edu versions hpf files ps gz january 
kandemir banerjee choudhary ramanujan shenoy 
global communication optimization technique data flow analysis linear algebra 
acm transactions programming languages systems toplas november 
kandemir choudhary ramanujam 

unified framework optimizing locality parallelism core computations 
ieee transactions parallel distributed systems 
wayne kelly maslov william pugh evan rosser dave wonnacott 
omega calculator library version 
november 
yuan lin david padua 
analysis irregular array accesses applications compiler optimizations 
proceedings conference compiler construction cc pages march 
bo lu john mellor crummey 
compiler optimization implicit reductions distributed memory multiprocessors 
proceedings th international parallel processing symposium ipps april 
nasa goddard distributed active archive center 
advanced high resolution radiometer global area coverage avhrr gac data 
gsfc nasa gov campaign docs land bio origins html 
rajiv gupta 
loop monotonic statements 
ieee transactions software engineering june 
tip :10.1.1.20.9646
survey program slicing techniques 
journal programming languages september 
yelick pike miyamoto krishnamurthy hilfinger graham gay colella aiken 
titanium high performance java dialect 
concurrency practice experience november 
hao yu lawrence rauchwerger 
adaptive reduction parallelization techniques 
proceedings international conference supercomputing pages 
acm press may 
hans zima barbara mary chapman 
compiling distributed memory systems 
proceedings ieee february 
special section languages compilers parallel machines 
