journal arti cial intelligence research submitted published technical recommendation study combining multiple information sources basu cs rutgers edu department computer science rutgers university road piscataway nj telcordia technologies south street morristown nj haym hirsh hirsh cs rutgers edu department computer science rutgers university road piscataway nj william cohen whizbang com whizbang 
labs whizbang labs east henry street pittsburgh pa craig nevill manning nevill cs rutgers edu department computer science rutgers university road piscataway nj growing need manage exploit proliferation online data sources opening new opportunities bringing people closer resources need 
instance consider recommendation service researchers receive daily pointers journal papers elds interest 
survey known approaches problem technical recommendation ask extended deal multiple information sources 
speci cally focus variant problem recommending conference submissions reviewing committee members ers testbed try di erent approaches 
whirl information integration system able implement di erent recommendation algorithms derived information retrieval principles 
novel autonomous procedure gathering reviewer interest information web 
evaluate approach compare methods preference data provided members aaai conference reviewing committee data actual submissions 

de ne recommendation problem follows representation interests nd relevant papers 
fact replace papers de nition name artifact choice instantiation recommendation problem 
recommendation interesting 
basu hirsh cohen nevill manning ability automatically lter large set papers nd aligned research interests advantages 
growing number publications online di cult keep latest research eld 
timeliness information critical desirable reach target audience minimal latency 
straightforward approach nding relevant papers may look close matches person interests content clear represent interests researchers contents papers 
feature sets recommendation apart variant problem dealt regular basis numerous conference chairs 
conferences er venue large number fairly speci papers distributed smaller number reviewers tight 
scope problem constrained degree topic conference organizers reviewers expend great deal time ort reviewing process 
suggest real value nding ways automating ltering process burdensome potential consumers 
consider algorithms recommending focused sets technical papers 
conference reviewing platform explore series questions relating recommendation process 
new interest ai community problem proposed challenge task ijcai 
focus conference reviewing turns natural choice obtain data set papers conference submissions obtain information preferences set reviewers submissions 
section discuss related addresses conference reviewing problem 
consider area recommender systems recommending articles newsgroup readers recommending web pages web site visitors contribute task 
focus varying sources information data representations allowing formulate di erent recommendation algorithms recombine sources computing similarity 
show di erence performance vary amount source data compared baseline single source information data representations 
compare recommendation algorithms collaborative ltering random assignment papers reviewers 
apply methods experimental data involving reviewer preferences conference abstracts aaai conference 

know recommendation know recommending papers reviewers generally arbitrary researcher trying selective papers ultimately reach consumer relevance interests expertise 
nding papers conference reviewers necessarily complex task papers may assigned reviewers criteria 
instance reviewer load balancing con ict resolution reviewer author may criteria 
addition 
data obtained permission aaai aaai reviewers appropriate authors submitted papers 
technical recommendation study combining multiple information sources reviewer reviewing preferences may uenced considerations readability novelty 
example preference novelty may lead reviewer choose simply relevant interests 
methods suited address issues number reasons 
con dentiality purposes lack information related author identity liation submitted conference papers 
secondly constraint satisfaction main concern primarily interested nding best papers person regard multiple people receive incorporate criteria selection procedure 
away represent novelty respect consumer means recognizing 
methods distinguish notion interest expertise respect reviewers 
general recommendation problem researcher may want retrieve papers areas outside expertise case separate representation needed 
previous area assigning conference papers reviewers approached problem content information retrieval 
dumais nielsen data provided members reviewing committee hypertext conference 
reviewers submitted abstracts papers interests provided complete relevance assessments papers submitted conference 
information retrieval method known latent semantic indexing lsi compared reviewer abstracts submissions ranking submissions similar reviewer 
results noticed performance metric evaluates number relevant articles returned top achieve improvement automated methods compared random assignment articles reviewers 
results encouraging believe widespread availability online resources introduces opportunities exploring new issues 
reviewers weren asked supply interest information 
process reviewer interest data automated simple methods 
retrieving relevant papers approximation reviewer interests 
automatic collection reviewer interest information web ectively removes reviewer loop novel aspect research 
yarowsky florian attempted similar task acl conference 
primary focus classi cation assignment exactly conference committees 
papers submitted acl conference electronic form requested committee members provide representative papers 
number papers returned members insu cient augmented collection papers downloaded online sources 
content retrieval context vector space model salton routing strategies 
main algorithm rst computed centroid reviewer representative papers computed centroid committee sum reviewer centroids 
classi ed assigned committee computing cosine similarity committee centroids choosing highest rank 
approaches experimented naive bayes classi er assessment similarity reviewing committee members authors cited basu hirsh cohen nevill manning papers 
system performance relative judges task evaluated actual assignments provided program chair conference extrapolated automated methods ective judges especially cases judges may experienced 
dealing large conferences papers covering variety areas information load greater conference organizers reviewers alike 
cases getting evaluative relevance judgments submitted accepted papers reviewers feasible 
example aaai conference reviewers state preferences papers potentially review 
scanning list soon lled quota bids papers expressed interest reviewing 
focus building extensible framework recommendation de ning process systematically incorporate information formulating recommendation algorithms purpose generating better recommendations 
content information retrieval known content ltering popular recommendation method consider systems recommend web pages syskill webert pazzani billsus 
number systems fab content ltering mainly part hybrid approach involves collaborative ltering 
content ltering looks contents artifact words web page collaborative ltering consider opinions minded people respect artifacts 
collaborative ltering recommend netnews articles konstan miller maltz herlocker gordon riedl movies hill stead rosenstein furnas basu hirsh cohen music cohen fan shardanand maes jokes gupta goldberg 
content collaborative methods data orthogonal opportunities come hybrid approaches combinations data 
movie recommendation provides example design hybrid system 
hybrid systems exploit data multiple sources expectation better compensating limiting factor data sparseness associated single source 
current study wewould identify di erent sources information describe papers reviewers expectation individual pieces knowledge di erence recommendations 
share common goal combining data multiple sources hybrid recommendation approaches algorithms develop strictly contentbased 
evaluative purposes compare algorithms results applying collaborative ltering methods set reviewer preferences 

representing papers reviewers approach recommendation represent entity variety information sources enumerate di erent combinations sources evaluate ectiveness combinations ranked retrieval methods 
recommendation problem entities papers consumers reviewers case 
entity represent salient features entity sequence technical recommendation study combining multiple information sources information sources 
addition need type information source relates reviewer reviewers actual preferences papers 
discussion choice information sources choices data typically assign papers reviewers usually provided explicitly papers authors choices rely implicit knowledge mined semi structured data available web 
information sources experiments compilation submitted abstracts obtained aaai aaai conference 
papers submitted conference 
aaai gave collection papers experiments abstracts accepted papers abstracts papers rejected authors granted aaai permission provide 
excluded papers authored authors 
submission obtained title set user assigned keywords prespeci ed list 
associated set information sources provided papers authors 
may consider body source information available reviewers source 
reviewer information sources far seen example entity represented multiple information sources mainly composed distinct units title case represent entity 
consider trying automatically compose representation reviewer interests 
may try rst go reviewer home page 
may decide look reviewer papers 
sources er di erent point view reviewer interests considered separate unit 
focus sources reviewer entry level home page papers referenced home page substitute asking reviewer provide interest information 
believe home pages online papers credible information sources fair number conference reviewers stated research interests sources 
information sources decided represent reviewer interests 
case home pages entire text reviewers entry level home page taken reviewer interests 
case postscript les de ne rst words extracted 
extracted information web pre existing utilities 
nd reviewers home pages fed names members review committee ahoy home page nding engine shakes langheinrich etzioni 
ahoy returned match supplied url starting point mir service retrieves les contents web sites 

ahoy cs washington edu 

www math uio mir 
basu hirsh cohen nevill manning mir download html les postscript les accessible entry level home page residing site 
person papers may directly available site additionally retrieved cross sites contained postscript les mir 
postscript les converted ascii nevill manning reed witten 
postscript les retrieved reviewer treated uniformly 
desirable attempt attempt determine timeliness especially respect reviewer current interests 
distinguish journal papers conference papers lecture notes 
reason attempt detailed analysis contents les automatically extract titles abstracts 
rely heuristics looking rst words approximate 
detailed analysis valuable recommendation process immediate goal obtain gross sense usability sources semi structured information 
reviewer preferences evaluate queries need ground truth set data specifying papers reviewer selected suitable review 
information evaluate di erent approaches perform making choices 
note approximation full set abstracts reviewer liked reviewing process requires reviewer nd minimum quota papers quota reached reviewer need look papers nd 
view optimistically yielding close approximation reviewer full set preferences reviewers able abstracts keywords attempt inspect subset papers labeled keywords areas knowledgeable 
experiments ground truth comes actual preferences stated aaai reviewers gave aaai permission release preference information papers considered 
point data re ects reviewers initial preferences reviewing 
data papers reviewers received aaai reviewer assignment process 
course potential limitation data portion data may representative entire data conference 
example preference data approximately half reviewers predicting preferences collection papers distribution skewed accepted papers 
issue aaai researchers representative larger community researchers large 
ask similar question user populations conferences 
consider acceptable limitations resulting conference reviewing platform recommendation 

moment focus postscript convenience reason limit just le format main constraint able extract words document 
technical recommendation study combining multiple information sources 
recommendation methodology section examine collaborative content methods recommendation 
methods allow explore di erent subsets data described previous section 
recommending reviewer information sources sections outline content recommendation framework uses data describing papers data describing reviewers recommendations 
reviewer preference data evaluation purposes input recommendation process 
order locate papers closely match reviewer interest data rely ad hoc similarity metrics commonly information retrieval community 
describe methods section whirl 
brief reviewer compare reviewer representation appropriate information source 
comparisons implemented query returns rank ordered list papers 
consequently compute precision top proportion papers returned preferred reviewer query 
nal score query average value computed subset reviewers larger set reviewers gave permission 
recommendation algorithms take di erent reviewer information sources inputs 
data plotted dimensions reviewer set information sources describing reviewers set information sources describing papers 
construct reviewer matrix entry matrix score measuring ectiveness respective sources reviewer compute similarity reviewers papers performing ranked retrieval 
instance reviewer representations described construct matrix gives possible evaluations scores 
refer matrix recommendation sources matrix 
conceptually extend recommendation sources matrix dimension considering combinations rows columns 
refer augmented matrix source combinations matrix 
de ne recommendation algorithm combination method procedure applied rows columns source combinations matrix 
introduces dimension comparison combination method consider looking replicates source combinations matrix 
pose questions experimental analysis recommendation algorithms incorporate information lead better performance 
method combining data algorithm di erence 
whirl queries whirl system speci cally designed tasks cohen cohen hirsh 
tasks necessary manipulate general way information obtained heterogeneous online basu hirsh cohen nevill manning sources potentially having data organization terminology 
particular whirl possible integrate information decomposed represented clean modular way 
example tohave information home pages postscript papers represented separately information integration tool resolve sources information 
whirl conventional dbms extended ad hoc similarity metrics developed information retrieval community 
metrics reason pieces text culled heterogeneous sources similarity values strict equality 
whirl computes similarity vector space representation model text salton 
text object represented term weights terms stemmed porter algorithm porter tfidf weighting scheme 
similarity vectors computed cosine similarity metric 
answers query rank ordering generated tuples tuples having similar pairs attribute elds appearing rst 
example whirl pose query select reviewer name id reviewer reviewer descriptor sim query return list reviewer names ids papers abstracts similar reviewer interest descriptor 
returning tuples descriptor elds identical performed traditional database join query returns name id pairs tuples elds contain similar terms ordered decreasing value similarity 
advantage doing ad hoc joins requiring textual elds identical important text comes multiple sources may di erent terminology 
itis important perspective comparing relative importance di erent elds cient way 
whirl data stored form whirl relations 
data constructed relations representing di erent information sources 
conference submission form relation containing id keywords title 
reviewer form reviewer relation contains single tuple attributes representing reviewer name representation reviewer interests example reviewer home page 
far discussed whirl formulate queries involving single information source reviewers papers 
advantage whirl approach lies simplicity extend queries incorporate multiple sources 
primary advantage whirl ease measure impact conjunctive queries incorporating data multiple sources 
form conjunctive queries adding multiple conditions clause select reviewer name id reviewer reviewer descriptor sim reviewer descriptor sim keywords technical recommendation study combining multiple information sources whirl clause contains multiple conditions similarity scores individual conjuncts combined product independent probabilities 
similarity scores independent probabilities convenient way combine scores albeit ers straightforward approach combination previously studied cohen 
query whirl assign score re ects similarity submitted reviewer descriptor similarity submitted keywords reviewer descriptor 
combining information sources query expansion mean recommendation algorithm combine data multiple information sources 
means enumerating information sources possible inputs algorithm de ning way sources compute similarity 
instance suppose look reviewer source sources collection reviewers papers 
decide interest reviewer compute similarity reviewer source sources combine similarity scores 
alternatively compute single similarity score rst combining sources single representation computing similarity respect reviewer source 
idea combining sources single representation appending terms sources 
information retrieval terms relevant sources appended baseline representation query process query reformulation 
usually referred query expansion 
methods bear resemblance query expansion analogy 
expansion methods described sections 
course prior knowledge relevance sources sense di er information retrieval implementation query expansion 
compare relative performance recommendation algorithms multiple dimensions compare results 
di erentiate results methods combine data compute similarity di erentiate results information sources comparison 
words set inputs method query expansion perform better 
want compare merit single source consider groups algorithms include source input algorithm exclude source 
simply count number times algorithms include source outperform algorithms exclude determine relative merit source 
concatenation method way add information new data source append terms appearing source original whirl query 
type query single whirl conjunct textual elds appearing conjunct grow addition new terms 
call method 
basu hirsh cohen nevill manning suppose example start base query previous section compares reviewer descriptors abstracts 
suppose wewant compare reviewer descriptors abstracts keywords 
way method 
form new eld representing union words appearing keywords elds substitute original query 
descriptor keywords 
new query select reviewer name id reviewer reviewer descriptor sim descriptor similarly replace descriptor clause represent di erent combinations elds keywords title union operator 
conjunction method previously stated important motivation whirl ability execute conjunctive queries combine information sources recommendation process 
type query adding terms particular text eld add conjuncts original 
refer method reformulating queries 
enumerate query combinations considered follows 
sources queries select reviewer name id reviewer replacing body clause reviewer descriptor sim reviewer descriptor sim keywords reviewer descriptor sim title ak reviewer descriptor sim reviewer descriptor sim keywords reviewer descriptor sim reviewer descriptor sim title kt reviewer descriptor sim keywords reviewer descriptor sim title akt reviewer descriptor sim reviewer descriptor sim keywords reviewer descriptor sim title assign labels keywords title queries identify sources 
labels comparable fashion method representing information sources concatenated 
technical recommendation study combining multiple information sources queries vary source data represent reviewers 
rst variant accounts case reviewer descriptor contains words reviewer home page second accounts case descriptor contains union rst words extracted postscript le obtained reviewer web pages 
decided try combination see representations reviewers improve performance 
simplicity test hypothesis expanded conjunctive query involving single extra conjunct 
constructed reviewer table contains attributes papers consisting abstracts reviewer postscript papers homepage consisting reviewer home page 
ran queries additional conjunct appearing clause reviewer homepage sim keywords keywords descriptor intuitions keywords reviewer homepage greater number words common 
recommending reviewer preferences reviewers common set papers approach recommending papers take information collaborative ltering 
note actual conference reviewing problem collaborative ltering method assigning papers may practical 
bene preferences set reviewers study information generally available reviewers making selections making di cult base predictions preferences 
worthwhile measure impact reviewer preferences purpose recommending papers 
recommendation methodology collaborative ltering approaches implemented follows reviewer recommended online manner 
reviewer tells system relevant 
assigned rating said rated positively 
relevant assigned rating said rated negatively 
rating represent rating assigned reviewer relevant reviewer provides single relevant positive example order condition recommendations 
know papers liked reviewers simulate process data 
experiment collaborative ltering algorithms knn hill cohen fan extended direct bayes cohen fan 
represent papers previously rated reviewer trials 
knn algorithm uses distance metric locate reviewers closest current reviewer respect papers rated dist rating rating compute score arbitrary respect ratings closest reviewers follows basu hirsh cohen nevill manning score rating rating methodology highest scoring reviewer recommendation 
extended direct bayes viewed ad hoc extension direct bayesian approach recommendation 
de ne represent laplace corrected estimate prior probability reviewer give positive rating 
thought measuring relatedness papers 
consider arbitrary trial represent papers rated positively reviewer previous trials consider arbitrary trial scoring function rank score expression represents probability related assuming independent 
evaluation methodology sections evaluate performance recommendation algorithms 
collaborative ltering compute recommendations reviewer run positive examples feedback 
reviewer list recommendations measure precision top gives proportion items returned top reviewer preferred reviewer 
possible evaluation metrics compute precision di erent levels papers returned suited conference reviewing task 
reviewer may get list papers review simulate recommending top papers returned methods 
computing precision measure percentage papers list matched reviewer preferences 
metric commonly literature 
instance dumais nielsen measure number relevant articles top reporting results constituted reasonable reviewer load 
additionally report results precision top 
knn algorithm set experiments 
recommendation algorithms seen choice query expansion method crossed choice input data sources 
methods ran queries detailed previous section 
resulted runs reviewer method 
run returned ordered list ids 
run measure precision top 
discussion refer run abstracts reviewer papers run 
similarly runs reviewer home page 
ph runs combine sources information extra conjunct 
results report represent precision values averaged reviewers 
order compare performance di erent information sources need evaluation population reviewers 
reviewers provided preference data home pages papers available online 
performed set runs reviewers randomly chosen set technical recommendation study combining multiple information sources source ak kt akt top top ph top top top ph top table average precision scores top top papers returned 
reviewers home pages papers available online report results averaged reviewers 
mentioned earlier reviewer choices may uenced avariety factors ranging person curiosity readability 
factors di cult model 
furthermore human judges may assign papers reviewers criteria relevance contents reviewer interests individual opinions may vary 
highly proposed methods achieve precision 
unfortunately nature problem able get assessment judges done task 
evaluate recommendation framework built content information retrieval principles compare relative performance reasonable baseline approaches 

results number questions mind analyze results 
course experiments vary amount information input algorithms method query expansion algorithms 
questions answer algorithm set algorithms suited task hand 
ask choice inputs results measurable di erences performance 
tabulation results provides basis analyzing contentbased algorithms table table 
baseline method compare algorithms random assignment 
method assigns reviewer random collection papers 
method expect precision 
words means select papers randomly reviewer fewer papers selected 
table table replicates source combinations matrix discussed earlier 
ran trials top papers returned table concatenated representation matrices top top experiments 
rst rows table table report precision gures top papers returned method method respectively 
method basu hirsh cohen nevill manning precision top top compare dat method comparison query methods similarly show results top papers returned bottom rows tables 
view rows representing reviewer sources query columns representing sources measure impact adding data ways 
reading row groups columns representing information sources gauge results vary data included queries 
similarly reading column gauge di erences results reviewer data included queries 
information say performance recommendation algorithms di erent methods query expansion 
compare relative performance methods values listed table table 
note cases performance methods exceeds random selection accuracies factor times better 
record information data point query uses sources information methods di er combine data sources meaningless plot points refer queries single source 
gure axis represents queries expanded method axis represents queries expanded method 
point falls line methods yielded performance query information sources 
points fall area line mark queries higher precision 
data reveal cases higher precision making dominant query expansion methods preferred method task hand 
expectation increase source data notice increase precision 
speci cally note query uses information submission majority cases performs statistically signi cantly technical recommendation study combining multiple information sources source ak kt akt top top ph top top top ph top table average precision scores top top papers returned 
better queries information case performs statistically signi cantly worse 
note adding information lead monotonically better results 
notice case top papers returned indistinguishable 
note pht performs better statistically signi cantly better 
similar cases 
explain gaps 
gaps true statistical di erences may consider explanation adding information may increasing amount noise representations 
consider example keywords xed list poor match real subject matter 
special cases keywords source lead degradation retrieval performance 
analogous analysis sources examine column table table measure ect adding information reviewer representation 
majority time nd queries incorporating information ph entries perform statistically signi cantly better single source queries entries 
far illustrated move groups columns blocks rows source combinations matrix adding sources queries improvement 
signi cant gains realize 
focusing reviewer source consider queries contained data single source lowest precision 
pair queries corresponding query row matrix sources report resulting improvement precision table 
top results note best case gain improvement precision going single source multi source query top results gain improvement 
comparisons queries qi qj tailed sign test 
speci cally consider set rij reviewers precision qi precision qj estimate probability pij prob precision qi precision qj rij consider di erence statistically signi cant reject con dence null hypothesis pij generated rij independent ips fair coin 
basu hirsh cohen nevill manning single source queries improvement adding sources pt top ha top top pt top ha top top table comparision single source vs multi source queries 
methods top top knn table average precision scores top top papers returned collaborative filtering methods 

results support intuitions incorporating information queries quality retrieval results improves 
di erent source single source queries note impact source dependent reviewer representation 
come assessment sources signi cant conference reviewing task 
series gures illustrate impact source plotting precision values queries exclude source axis precision values queries include source axis 
point falls line queries exactly performance choice source irrelevant 
points fall area line mark queries higher precision compared query counterparts contain source 
simply counting number times queries include source outperform queries include source way ranking sources decreasing order importance 
case queries include source papers home page source reviewers highest rates success compared information sources papers reviewers respectively 
natural question ask trends noticed hold 
answer means give de nitive answer question information really better 
just noticed query performance linked reviewer sources nd linked query expansion method 
technical recommendation study combining multiple information sources queries precision top top dat queries role information source queries keywords precision top top dat queries keywords role keywords information source queries titles basu hirsh cohen nevill manning precision top top dat queries titles role title information source queries reviewer papers precision top top dat queries reviewer papers role papers information source technical recommendation study combining multiple information sources queries reviewer homepages precision top top dat queries reviewer homepages role homepage information source table show results collaborative ltering runs 
report averages precision values computed top papers returned reviewer recommendation lists 
recommending exhausted set positive examples reviewer reviewer recommendation lists varying lengths 
cases size list compute precision top assuming remaining items incorrect predictions 
methods collaborative ltering exceed random selection signi cant margin 
top papers returned collaborative recommendation methods competitive best performance 
interesting observation methods di er method di erent data recommendations 
state information sources recommend papers average papers coincide reviewer preferences 
compared random selection collaborative ltering method yields papers interest reviewers 
summary learned experiments 
context peer reviewing papers recommendation process people intensive 
recommendation systems require users provide samples preferences extrapolate behaviors 
collaborative methods go preference information multiple users predict preferences single user 
automatically collecting reviewer interest information web sources precomputing similarities pro les content require input reviewers 
furthermore content retrieval methods exceed performance collaborative methods task 
believe recommendation framework provides extensible way formulating queries provides control information content queries 
control information include queries incorporate information 
new data available evaluate data basu hirsh cohen nevill manning sources combinations ective ne tuning query formulation process 

related query reformulation expanding queries whirl viewed type query reformulation review related information retrieval community topic 
salton describes process query reformulation moving query relevant items away nonrelevant ones 
context vector space model retrieval means query expression form salton number representing weight assigned term wewant arrive new query expression weights adjusted new terms introduced vector representation terms ectively removed reducing respective weights 
harman describes operational procedure underlying process merging document query vectors 
speci cally means query terms original query appearing relevant documents added initial query expression 
expansion occurs positive negative weights depending terms appears relevant non relevant document 
description assumes relevance judgments documents system return 
practically speaking type information hard come 
people seeking compensate lack information expanding queries variety techniques thesauri relevance feedback 
case query reformulation part iterative interactive process users results retrieval asked supply feedback regarding relative importance results 
comparing approach methods query reformulation couple observations 
query reformulation driven knowledge precomputed data 
entities papers abstracts keywords titles sense vary amount information queries 
equivalent collection table lookup run time determine formulations promising 
note way construct queries method combines aspects boolean vector space models query formulation approach 
case boolean queries relevance feedback lead new query expressions consisting term conjuncts salton term term term notice replace term vector expression query expression formulated method 
technical recommendation study combining multiple information sources 
shown collect information reviewers automatically web part recommendation framework route papers reviewers 
treat problem decomposing reviewer interest contents information sources combining information sources di erent query formulations 
experiments compared ways formulating queries content information retrieval collaborative approach 
recommendation algorithm conjunctive queries outperforms approaches 
looked di erent subsets information sources algorithms case optimal algorithm information generally lead better performance 
practical setting recommendation method choice depend number factors ranging availability information ease 
hand framework provides exible alternative simple keyword searches intrusive alternative collaborative methods 
hand methods assume obtain data reliable accurate timely 
results optimistic web provide credible information sources successfully recommendation process 

acknowledgments extend aaai aaai reviewers aaai authors members rutgers machine learning research group reviewers inputs 
note property respective companies listed whirl labs research lsi telcordia technologies 
basu hirsh cohen 

recommendation classi cation social content information recommendation 
proceedings aaai 
cohen 

integration heterogeneous databases common domains queries textual similarity 
inproceedings acm sigmod 
cohen 

whirl approach information integration 
ieee intelligent systems 
ieee press 
cohen fan 

web collaborative ltering recommending music crawling web 
proceedings www 
cohen hirsh 

joins generalize text classi cation whirl 
proceedings kdd 
dillon 

automatic relevance feedback boolean retrieval systems 
journal documentation 
basu hirsh cohen nevill manning dumais nielsen 

automating assignment submitted manuscripts reviewers 
proceedings acm sigir 


challenge ijcai prove value ai ai 
proceedings ijcai 
gupta goldberg 

jester new lineartime collaborative ltering algorithm applied jokes 
workshop recommender systems acm sigir 
harman 

relevance feedback revisited 
proceedings acm sigir 
hill stead rosenstein furnas 

recommending evaluating choices virtual community 
proceedings chi 
konstan miller maltz herlocker gordon riedl 

grouplens applying collaborative ltering usenet news 
vol 

nevill manning reed witten 

extracting text postscript 
software practice experience 
pazzani billsus 

learning revising user pro les identi cation interesting web sites 
machine learning 
porter 

algorithm su stripping 
program 
salton 

automatic text processing 
addison wesley 
salton 

improving retrieval performance relevance feedback 
readings information retrieval 
shakes langheinrich etzioni 

dynamic sifting case study homepage domain 
proceedings www 
shardanand maes 

social information ltering algorithms automating word mouth 
proceedings chi 
yarowsky florian 

load conference chairs digital routing assistant 
proceedings joint sigdat conference empirical methods nlp large corpora 

