learning semantic grammars constructive inductive logic programming john zelle raymond mooney department computer sciences university texas austin tx zelle cs utexas edu mooney cs utexas edu automating construction semantic grammars difficult interesting problem machine learning 
shows semantic grammar acquisition problem viewed learning search control heuristics logic program 
appropriate control rules learned new order induction algorithm automatically invents useful syntactic semantic categories 
empirical results show learned parsers generalize novel sentences perform previous approaches connectionist techniques 
designing computer systems understand natural language input difficult task 
laboriously hand crafted computational grammars supporting natural language applications inefficient incomplete ambiguous 
difficulty constructing adequate grammars example knowledge acquisition bottleneck motivated research machine learning 
numerous researchers studied computer acquisition natural languages research concentrated learning syntax language example sentences wirth berwick wolff practice natural language systems typically concerned extracting meaning sentences usually expressed sort case role structure 
semantic grammars uniformly incorporate syntactic semantic constraints parse sentences produce semantic analyses proven extremely useful constructing natural language interfaces limited domains allen unfortunately new grammars written semantic domain size grammar required research supported national science foundation iri texas advanced research program 
general applications manual construction infeasible 
interesting question machine learning grammars automatically constructed analysis examples domain 
semantic grammar acquisition problem presents number difficult issues 
little agreement constitutes adequate set cases sentence analysis different tasks may require differing semantic representations 
learning architecture general allow mapping arbitrary meaning representations 
second domain specific semantic constraints automatically recognized incorporated grammar 
necessitates form constructive induction identify useful semantic word phrase classes 
learning system crucial resulting grammar generalize unseen inputs 
generativity natural languages unreasonable assume system trained small fraction possible inputs 
show problem semantic grammar acquisition considered learning control rules logic program 
framework acquisition problem attacked techniques inductive logic programming 
introduce new induction algorithm incorporates constructive induction learn word classes semantic relations necessary support parsing process 
empirical results show promising approach language acquisition problem 
learning case role mapping mapping problem traditional case theory decomposes sentence proposition represented main verb various arguments agent patient instrument represented noun phrases 
basic mapping problem decide sentence constituents fill roles 
case analysis part task sentence interpretation problem nontrivial simple sentences 
consider sentences mcclelland kawamoto 
boy hit window 

hammer hit window 

hammer moved 

boy ate pasta cheese 

boy ate pasta fork 
sentence subject boy agent 
second subject hammer instrument 
role played subject determined grounds boys animate 
third sentence subject hammer interpreted patient illustrating importance relationship surface subject verb 
sentences prepositional phrase attached verb making fork instrument ate object cheese accompaniment pasta 
domain specific semantic knowledge required correct assignment 
previous approaches research learning case role assignment task taken place connectionist paradigm miikkulainen dyer mcclelland kawamoto argue proper assignment difficult task requiring independent sources knowledge syntactic semantic suited connectionist techniques 
connectionist models face number difficulties handling natural language 
output structures flat nonrecursive unclear embedded propositions sophisticated analyses handled 
models limited producing single output structure input 
input sentence truly ambiguous system produces single output appears weighted average possible analyses enumerating consistent interpretations 
believe symbolic techniques appropriate approach suffer deficiencies 
addition empirical results demonstrate system trains faster generalizes novel inputs better neural counterparts 
shift reduce case role parsing variations shift reduce parsing proven practical symbolic natural language applications tomita system adopts simple framework case role mapping simmons yu process best illustrated way example 
consider sentence man ate pasta 
parsing begins empty stack input buffer containing entire sentence 
step parse word shifted front input buffer stack top elements action stack contents shift shift man det man det shift ate man det agt ate agt man det shift ate agt man det shift pasta ate agt man det det pasta det ate agt man det pat ate pat pasta det agt man det parsing man ate pasta stack popped combined form new element pushed back stack 
sequence actions stack states simple example shown 
action notation label indicates stack items combined role label item stack position head 
advantage assuming constrained parsing mechanism form structure building actions limited 
operations required construct case representation directly inferable representation 
general structure building action required unique case role appears analysis 
set actions required produce set analyses union actions required individual analysis 
overview chill system chill constructive heuristics induction language learning general approach semantic grammar acquisition 
input system set training instances consisting sentences paired desired case representations 
output shift reduce parser prolog maps sentences case representations 
parser may produce multiple analyses backtracking single input sentence allowing true ambiguity training set 
chill algorithm consists distinct tasks 
training instances formulate overly general parser capable producing case structures sentences 
initial parser overly general produces spurious analyses input sentence 
parser specialized introducing search control heuristics 
control heuristics limit contexts certain program clauses eliminating spurious analyses 
section details processes 
chill algorithm constructing overly general parser shift reduce parser easily represented logic program 
state parse reflected con tents stack input buffer 
distinct parsing action operator clause takes current stack input produces new ones 
overly general parser built translating action inferable training problems clause implements action 
example clause implementing agt action op inp snew inp combine agt snew 
building program parse set training examples accomplished adding clauses op predicate 
clause direct translation required parsing action 
mentioned identification necessary actions straight forward 
particularly simple approach include actions agt agt role training examples unnecessary operator clauses removed program subsequent specialization process 
parser specialization general framework overly general parser produces great spurious analyses training sentences conditions specifying appropriate various operators 
program specialized including control heuristics guide application operator clauses 
section outlines basic approach chill 
detail incorporating clause selection information prolog programs zelle mooney program specialization occurs phases 
training examples analyzed construct positive negative control examples operator clause 
examples correct operator applications generated finding correct parsing training pair overly general parser subgoal operator applied successful parse positive control example operator 
positive control example operator considered negative example operators positive example 
second phase general order induction algorithm employed learn control rule operator 
control rule comprises horn clause definition covers positive control examples operator negative 
induction algorithm chill discussed subsection 
final step fold control information back overly general parser 
control rule easily incorporated overly general program unifying head operator clause head control rule clause adding induced conditions clause body 
definitions invented predicates simply appended program 
example agt clause op typically modified op det animate combine agt 
animate boy 
animate girl 
new predicate invented representing concept animate 
rule may roughly interpreted stating stack contains items second completed noun phrase head animate attach phrase agent top stack 
inducing control rules induction task generate horn clause definition covers positive control examples operator cover negative 
growing body research inductive logic programming addresses problem 
algorithm implements novel combination bottom techniques systems cigol muggleton buntine golem muggleton feng top methods systems foil quinlan pos positive examples neg negative examples def positive examples unit clauses 
repeat def sampling pairs clauses pair clauses 
find generalization pos neg reduce definition pos def compaction achieved return def chill induction algorithm space permit complete explanation induction mechanism general idea simple 
intuition want find small general definition discriminates positive negative examples 
start specific definition set positive examples introduce generalizations definition compact measured cigol size metric 
search general definitions carried hill climbing fashion 
step number possible generalizations considered producing greatest compaction theory implemented process repeats 
basic algorithm outlined 
heart algorithm find generalization procedure 
takes clauses current definition constructs new clause empirically subsumes cover invented predicates system generated names 
renamed clarity 
negative examples 
reduce definition proves positive examples current definition augmented new generalized clause 
preferential treatment new clause placed top prolog definition clauses longer proving positive examples deleted produce reduced definition 
find generalization employs levels effort produce generalization 
construction general generalization lgg plotkin input clauses 
lgg covers negative examples refinement unnecessary 
clause general attempt refine foil mechanism adds literals derivable background previously invented predicates 
resulting clause general passed invent predicate invents new predicate discriminate positive examples negatives covered 
predicate invention carried manner analogous 
step find projection clause variables set ground tuples generated projection clause prove positive examples disjoint ground tuples generated proving negative examples 
ground tuples form positive negative example sets new predicate top level induction algorithm recursively invoked create definition predicate 
experimental results crucial test learning system learned concept generalizes new input 
chill tested number case role assignment tasks 
comparison connectionism experiment chill tried baseline task reported miikkulainen dyer sentence case structure examples mcclelland kawamoto referred corpus 
corpus produced set sentence templates generating sentences pairs sentences illustrated 
sample comprises unique sentences allow multiple analyses 
parser capable backtracking generating legal parses input training done considering unique sentence single example 
particular sentence chosen inclusion training testing set pairs representing correct analyses sentence included set 
training testing followed standard paradigm choosing random set test examples case creating parsers increasingly larger subsets remaining examples 
reported results reflect averages trials 
testing parser enumerate analyses test sentence 
parsing sentence fail ways incorrect analysis may generated correct analysis may generated 
order account types inaccuracy metric introduced calculate average correctness test sentence follows accuracy number distinct analyses produced number produced analyses correct number correct analyses possible sentence 
chill performs learning task demonstrated learning curve shown 
system achieves accuracy novel sentences seeing training sentences 
training sentences produces accuracy 
accuracy training examples corpus accuracy direct comparison previous results difficult connectionist learning curves tend expressed terms low level measures number correct output bits 
closest comparison results miikkulainen dyer accuracy achieved word level training pairs corpus 
output contains slots assuming independence errors gives estimate completely correct parses 
interestingly types inaccuracies differ substantially systems 
neural networks produce output contain minor errors chill tends produce correct output 
engineering standpoint advantageous system knows fails connectionists interested failing reasonably 
respect training time induction algorithm employed chill prototype implemented prolog 
running sparcstation creation parsers examples required minutes half hour cpu time 
compares favorably backpropagation training times usually measured hours days 
noteworthy chill consistently invented interpretable word classes 
example invention animate 
concept implicit analyses system animate objects assigned agent role 
invented classes clearly picked distribution words input sentences 
system regularly invented semantic classes human food possession noun generation corpus 
phrase classes useful making parsing distinctions invented 
example structure instrumental phrase invented 
instrument 
instrument fork 
instrument bat 
necessary parsing corpus distinguish instruments different verbs instruments various verbs hitting eating grouped 
semantic relationship words required parsing distinctions relationships learned 
chill created relation possess human possession reflects distributional relationship humans possessions corpus 
notice invented rule contains invented word categories 
priori reason suppose chill invent interpretable categories naturalness invented concepts supports empirical results indicating chill making right generalizations 
realistic domain corpus designed specifically illustrate case mapping problem 
necessarily reflect true difficulty semantic grammar acquisition natural language applications 
experiment designed test chill realistic task 
portion semantic grammar lifted extant prototype natural language database designed support queries concerning tourist information ng portion grammar recognized distinct sentences 
simple case grammar produced labellings deemed useful database query task devised generate sample sentence analyses 
example pair shown illustrates type sentences analyses 
average learning curve domain shown 
curve shows generalization results show star hotels downtown la double rates dollars 
show theme hotels det type star mod loc la mod downtown attr rates mod double nbr unit dollars dative example tourist domain sentences differed training 
results encouraging 
training examples resulting parser achieved accuracy novel sentences 
training examples accuracy 
accuracy training examples tourist domain accuracy related noted ai research language acquisition focused case role mapping problem 
number language acquisition systems may viewed learning search control heuristics 
langley anderson langley anderson independently posited acquisition mechanisms learning search control production systems 
systems cognitively motivated addressed task language generation case role analysis task examined 
berwick berwick acquired syntactic parsing rules type shift reduce parser 
system linguistically motivated incorporated constraints specific theory lan guage assumed 
contrast chill uses induction techniques avoid commitment specific model grammar 
exemplar acquisition system style case grammar chill described simmons yu chill system depends analyst provide appropriate word classifications requires detailed interaction guide parsing training examples 
corpus natural language research addressed issues automated dictionary construction lehnert brent berwick systems manually constructed parsers bootstrap new patterns analyzable text 
employ machine learning techniques generalize acquired templates construct new features support parsing decisions 
contrast chill attempt applying modern machine learning methods fundamental task constructing efficient parsers 
research generalization results experiments far undertaken quite encouraging testing larger realistic corpora required determine practicality techniques 
avenue research deepening analyses produced system 
applying techniques construct natural language systems require modifying parser produce final representations database queries adding additional learning components map intermediate case structures final representations 
methods learning semantic grammars hold potential substantially automating development natural language interfaces 
system employs inductive logic programming techniques learn shift reduce parser integrates syntactic semantic constraints produce representations 
system produces overly general parser constrains inductively learning search control heuristics eliminate spurious parses 
learning heuristics constructive induction automatically generate useful semantic syntactic classes words phrases 
experiments reasonably large corpora sentence case role pairs demonstrate system learns accurate parsers generalize novel sentences 
experiments demonstrate system trains faster produces accurate results previous connectionist approaches creates interesting recognizable syntactic semantic concepts 
allen james 
natural language understanding 
benjamin cummings menlo park ca 
anderson john 
architecture cognition 
harvard university press cambridge ma 
berwick 
acquisition syntactic knowledge 
mit press cambridge ma 
brent berwick robert 
automatic acquisition subcategorization frames tagged text 
speech language proceedings darpa workshop 
morgan kaufmann 


discrimination constructive induction logic programs 
proceedings tenth national conference artificial intelligence san jose ca 

langley 
language acquisition error recovery 
cognition brain theory 
lehnert cardie fisher mccarthy soderland 
university massachusetts muc test results analysis 
proceedings fourth darpa message understanding evaluation conference 
morgan kaufmann 

mcclelland kawamoto 
sentence processing assigning roles constituents sentences 
rumelhart mcclelland editors parallel distributed processing vol 
ii 
mit press cambridge ma 

miikkulainen dyer 
natural language processing modular pdp networks distributed lexicon 
cognitive science 
muggleton buntine 
machine invention order predicates inverting resolution 
proceedings fifth international conference machine learning ann arbor mi 

muggleton feng 
efficient induction logic programs 
muggleton editor inductive logic programming 
academic press new york 

ng 
computerized prototype natural language tour guide 
technical report ai artificial intelligence laboratory university texas austin tx 
plotkin 
note inductive generalization 
meltzer michie editors machine intelligence vol 

elsevier north holland new york 
quinlan 
learning logical definitions relations 
machine learning 
simmons yu 
acquisition context dependent grammars english 
computational linguistics 
tomita 
efficient parsing natural language 
kluwer academic publishers boston 
wirth 
completing logic programs inverse resolution 
proceedings european working session learning france 
pitman 

wolff 
language acquisition data compression generalization 
language communication 
zelle mooney 
combining foil ebg speed logic programs 
proceedings thirteenth international joint conference artificial intelligence chambery france 
