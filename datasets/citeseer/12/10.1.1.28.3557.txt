learning hierarchical partially observable markov decision process models robot navigation georgios theocharous sridhar mahadevan cse msu edu cse msu edu cse msu edu department computer science engineering michigan state university east lansing mi propose investigate general framework hierarchical modeling partially observable environments oce buildings hierarchical hidden markov models hhmms 
main goal explore hierarchical modeling basis designing ecient methods model construction 
case study focus indoor robot navigation show framework learn hierarchy models environment di erent levels spatial abstraction 
introduce idea model reuse combine learned models larger model 
describe extension hhmm model includes actions call hierarchical pomdps describe modi ed hierarchical baum welch algorithm learn models 
train di erent families hierarchical models simulated real world corridor environment compare standard representation environment 
show hierarchical pomdp approach combined model reuse allows learning hierarchical models data better train faster models 
arti cial intelligence ai sequential decision making uncertainty adopted framework partially observable markov decision processes pomdp 
framework allows modeling environments underlying states hidden partially observable noisy sensory observations actions 
pomdps extend known hidden markov model hmm include actions rewards 
developed algorithms building pomdp models baum welch procedure dynamic programming 
past pomdps restricted uniform scale models model learning planning algorithms scale poorly size model 
studies shown hmm pomdp framework program autonomous mobile robots navigate real ce environments systems models 
size environment grows increasingly dicult learn models desirable natural way reusing previously learned sub models 
address limitations earlier standard hmm pomdp systems hierarchical hidden markov model hhmm framework 
hhmm approach robot learns uses hierarchy homogeneous representations environment layer hierarchy maintains probabilistic model environment de ned resolution 
tree structure hhmm models provides natural approach rapid model learning reusing previously learned sub models 
extend hhmm models include primitive actions show procedure converting hierarchical models pomdps 
intuitively hierarchical modeling allow learn environment modular fashion able learn faster able discover relationships levels trivial representations 
fortunately natural environments viewed di erent levels spatial abstraction 
example oce environment modeled coarse level consist nodes corridors intersections dead ends ner level model element represent region corridor 
demonstrate experiments hhmm framework extended hierarchical pomdp case appears compelling advantages basis designing scalable spatial learning algorithms 
provide empirical results learning realworld simulated robot navigation illustrate potential hierarchical pomdp framework 
ii 
hierarchical hidden markov models hierarchical hidden markov model hhmm generalizes standard hidden markov model hmm allowing hidden states represent stochastic processes 
hhmm visualized tree structure types states production states leaves tree emit observations internal states unobservable hidden states represent entire stochastic processes 
production state associated observation vector maintains distribution functions observation de ned model 
internal state associated horizontal transition matrix vertical transition vector 
horizontal transition matrix internal state de nes transition probabilities children 
vertical transition vectors de ne probability internal state activate children 
internal state associated child called state returns control parent 
states produce observations activated vertical transition parent 
hhmm formally de ned tuple hs oi denotes set states 
functions denotes parent state function returns th child state state child state denoted set children state denoted number children jc types states 
production states states states 
denotes horizontal transition functions de ned separately state 
horizontal transition function maps child state probability distribution children states write denote horizontal transition probability th th child state example 
fc 
denotes vertical transition function state function de nes initial distribution children states state state child example 
denotes set observations 
product 
denotes function maps product state distribution observation set 
write probability observing state shows graphical representation example hhmm 
hhmm produces observations follows 
current node root chooses activate children vertical transition vector root children 

child activated product state produces observation observation probability output vector 
transitions state level 
state reached transition control returned parent 

child state chooses activate children 
state waits control returned child state 
transitions state level 
resulting transition state control returned parent state 
fine describe hierarchical baum welch algorithm able re estimate model parameters including transitions matrices vertical vectors observation vectors hhmm observation sequences extended algorithm able learn parameters hhmm includes actions describe 
fig 

example hierarchical hmm 
leaf production states associated observations 
iii 
hierarchical partially observable markov decision process models model de nition robot navigation example planning problem requires extending hhmm model include primitive actions reward functions specifying goals 
call extended model hierarchical pomdp formally de ne follows denotes set states exactly hhmm 
denotes set primitive actions 
primitive actions initiate terminate product states 
product states represent lowest resolution physical environment action start product state product state 
example indoor robot navigation environment states corridors product states meter locations corridors primitive action go forward take robot product state product state 
transition probability product state product state simply lookup operation global transition matrix pomdps 
hierarchical pomdp model may look single horizontal transition matrix multiple vertical vectors 
example calculation shown 

denotes horizontal transition functions de ned separately state action horizontal transition function maps child state action pair probability distribution children states fc 
denotes vertical transition function state function de nes initial distribution children states state denote set observations 
product 
function maps product state distribution observation set 
product denotes immediate reward function de ned product states 
shows example hierarchical pomdp 
hierarchical baum welch algorithm hierarchical pomdp de ned extending hierarchical baum welch algorithm hhmms 
de ne variable shown equation fig 

example hierarchical pomdp primitive actions 
calculate transition state state action consider non zero probability paths 
path path 
probability transitioning action 
finished ja started variables gives probability observation sequence state nished time actions taken parent started time say product state nishes time production observation state nishes control returned child state children produces observation say product state started time time produced observation state starts time time children produced observation observation generated activated parent horizontal transition 
note variable calculate probability observation sequence model shown equation 
jc root jc root root root backward variable de ned equation denotes probability state entered time observations produced parent actions taken terminated time 
ja started generated finished important variable de ned equation denotes probability making horizontal transition time finished time started time ja important variable shown equation de nes probability state activated parent time action observation sequence started time started time tj variables re estimate model parameters 
vertical vectors re estimated equations 
root jc jc root horizontal transition matrices re estimated equation 
re estimation calculates average number times process went state state number times process exited state action ja ja jc observation vectors re estimated equation 
re estimation observation model calculates average number times process state perceived observation number times process state jc jc planning hierarchical pomdps solving pomdp means nd mapping belief state probability distribution states actions achieve best long term sum rewards 
belief state sucient statistic summarizes past history observations actions 
ecient bayesian update procedure calculate belief state probability distribution product states sequence observations actions 
unfortunately number belief states nite exact solutions large pomdps computationally infeasible 
fortunately heuristics solutions state heuristic mls qmdp method known provide satisfactory approximate solutions robot navigation 
extended approximate methods hierarchical pomdps implementing hierarchical versions methods mls procedure compute state recursively product state 
hierarchical pomdp model actions converted equivalent pomdp 
states equivalent pomdp product states hierarchical pomdp associated global transition matrix calculated vertical horizontal transition matrices hierarchical pomdp 
construct global transition matrix equivalent pomdp pair states need sum probabilities paths transition system action example shown 
attening hierarchical model manner destroy ability learn faster reusing sub models negate primary advantages hierarchical approach 
iv 
learning hierarchical pomdps robot navigation describe detailed set experiments comparing hierarchical pomdp models models terms learning speed data 
conducted experiments real robot platform nomad robot simulated environment 
nomad simulator constructed model second oor msu engineering building shown 
real indoor environment shown 
topological maps automatically compiled markov representation pomdp hierarchical pomdp model 
experiments initial models uninformed weak ergodic initial models 
figures show hierarchical pomdp models 
initial model provide priori appropriate connectivity actions initialize observation models location state 
observation consists components action taken probabilities robot seen wall opening sides front left back right 
probabilities observations computed neural nets take input local occupancy grid maps robot constructed sonars output probability wall opening direction 
example product state facing corridor direction initial observation model front wall opening left wall opening back wall opening right wall opening 
case uninformed ergodic initial models provide observation models state connected state parent action levels 
fig 

topological map nd oor engineering building 
numbers indicate distances meters 
edge vertex states second level hierarchical pomdp 
states representing north south direction corridors expanded number third level product states representing meters 
rst experiment compared hierarchical pomdps biased training initial model 
collected short observation sequences short sequence robot goes topological node 
trained hierarchical model hierarchical reuse model low level submodels trained separately model shown 
hierarchical reuse model collected separate sequence observations state 
result shows hierarchical reuse model converges lot faster data right due fact submodels trained 
say model converges mean forward action left action fig 

gures show represent corridor environment hierarchical pomdp model 
circles represent product states solid arrows inside circle indicate orientation 
rectangles indicate states level circles inside rectangles product states level 
dashed arrows left show transition matrix forward action level initial model 
ergodic initial model shown transitions possible states parent product states 
training set transitions 
gure right shows initial transition matrix turn left action 
turn right action similar transitions reversed 
forward action left action fig 

gures show equivalent pomdp corridor model automatically derived hierarchical pomdp model 
gure left show transitions forward action right shows left action initial models 
forward action left action fig 

gures show represent corridor environment pomdp model 
gure left shows forward action gure right turn left action initial models 
square error successive log likelihood values training traces remains stable threshold 
second experiment compared hierarchical pomdps weak uninformed ergodic models 
training convergence shown 
experiment see hierarchical reuse model ts data signi cantly better hierarchical models 
third experiment trained models experiment long sequence observations shown 
observe epochs initial models short sequences hr fig 

graph shows training convergence different models 
model convergence measured mean square error successive log likelihood values 
horizontal axis represents number training epochs vertical axis average log likelihood di erent sequences observations 
stands hierarchical model hr stands hierarchical model initial model created rst training separately di erent ergodic models level stands model 
initial models provided training cases 
training epochs ergodic initial models short sequences hr fig 

graph shows training convergence di erent models 
axis represents number training steps axis average log likelihood di erent sequences observations 
stands hierarchical model starting model ergodic hr stands hierarchical model initial model created rst training separately di erent ergodic models level stands model 
starting model ergodic 
hierarchical reuse model equivalent model data better models 
pomdp provides poorer data models 
table shows size number states various models time number seconds takes training epoch experiment 
hierarchical models equivalent models train faster pomdp model partly due smaller number states models compared model 
training epochs ergodic initial models single long sequence hr fig 

graph shows training convergence di erent models long observation sequence 
stands hierarchical model stands model equivalent hierarchical hr stands hierarchical reuse model initial model created rst training separately di erent ergodic modules level equivalent model hierarchical reuse model stands model 
cases starting models ergodic 
model time size time size time size hr table table shows size model number states time takes number seconds train epoch 
real robot experiments experiments actual indoor environment shown collected long sequence observations mobile robot shown gure 
training convergence shown hierarchical reuse model ts data better rest models 
pomdp model provides worst data took longest time train due size 
fig 

gure shows topological map real indoor environment learned pavlov nomad platform 
training epochs ergodic initial models long real sequence hr fig 

graph compares hierarchical hr model terms goodness convergence training epochs real corridor environment 
vi 
describe framework learning hierarchical models partially observable indoor corridor environments 
modi ed baum welch algorithm learning hierarchical pomdp models 
new algorithm compared hierarchical pomdp models simulated real world robot navigation environments 
experimental results show hierarchical pomdp model smaller size correspondingly faster train starting weak ergodic initial model 
furthermore hierarchical models provide natural way reusing previously learned submodels 
data hierarchical models better model 
investigating alternate ways de ning actions hierarchical nature pomdp model actions speed planning 
sven koenig reid simmons robot navigation architecture partially observable markov decision process models arti cial intelligence mobile robotics case studies successful robot systems 
mit press 
nourbakhsh powers birch eld robot ai magazine 

lawrence rabiner tutorial hidden markov models selected applications speech recognition proceedings ieee february vol 

shatkay leslie learning topological maps weak local information ijcai 
shai fine yoram singer naftali tishby hierarchical hidden markov model analysis applications machine learning vol 
july 
leslie pack michael litman anthony cassandra planning acting partially observable stochastic domains arti cial intelligence vol 

anthony cassandra leslie pack kaelbling james kurien acting uncertainty discrete bayesian models mobile robot navigation proceedings ieee rsj international conference intelligent robots systems iros 
sridhar mahadevan georgios theocharous fast concept learning mobile robots autonomous robots journal vol 
pp 


