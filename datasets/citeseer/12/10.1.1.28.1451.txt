scalable parallel data mining association rules hong sam han department computer science university minnesota minneapolis mn han cs umn edu george karypis department computer science university minnesota minneapolis mn karypis cs umn edu vipin kumar department computer science university minnesota minneapolis mn kumar cs umn edu important problems data mining discovering association rules databases transactions transaction consists set items 
time consuming operation discovery process computation frequency occurrences interesting subset items called candidates database transactions 
prune exponentially large space candidates existing algorithms consider candidates user defined minimum support 
pruning task finding association rules requires lot computation power time 
parallel computers offer potential solution computation requirement task provided efficient scalable parallel algorithms designed 
new parallel algorithms mining association rules 
intelligent data distribution algorithm efficiently uses aggregate memory parallel computer employing intelligent candidate partitioning scheme uses efficient communication mechanism move data processors 
hybrid distribution algorithm improves intelligent data distribution algorithm dynamically partitioning candidate set maintain load balance 
experimental results cray parallel computer show hybrid distribution algorithm scales linearly exploits aggregate memory better generate association rules single scan database pass 
important problems data mining sad discovering association rules databases transactions supported nsf asc army research office contract da daah cray research fellowship ibm partnership award content necessarily reflect policy government official endorsement inferred 
access computing facilities provided minnesota supercomputer institute cray research nsf cda 
see www cs umn edu han papers html extended version related papers 
transaction contains set items 
time consuming operation discovery process computation frequencies occurrence subsets items called candidates database transactions 
usually transaction databases contain extremely large amounts data large number distinct items total number candidates prohibitively large 
current association rule discovery techniques hs son sa try prune search space requiring minimum level support candidates consideration 
support measure number occurrences candidates database transactions 
apriori state art algorithm aggressively prunes set potential candidates size looking precise support candidates size gamma :10.1.1.40.6757
th iteration algorithm computes occurrences potential candidates size transactions 
task efficiently algorithm maintains potential candidates size hash tree 
algorithm require transactions stay main memory requires hash trees stay main memory 
highly effective pruning method apriori task finding association rules requires lot computation power available parallel computers 
furthermore size main memory serial computer puts upper limit size candidate sets considered iteration lower bound minimum level support imposed candidates consideration 
parallel computers offer increased memory solve problem 
parallel algorithms count distribution data distribution proposed :10.1.1.40.5742
count distribution algorithm shown scale linearly excellent speedup behavior respect number transactions :10.1.1.40.5742
algorithm works entire hash tree pass algorithm fits main memory single processor parallel computers 
count distribution algorithm sequential counterpart apriori unscalable respect increasing candidate size 
data distribution algorithm addresses memory problem count distribution algorithm partitioning candidate set assigning partition processor system 
algorithm results high communication overhead due data movement redundant computation :10.1.1.40.5742
parallel algorithms mining association rules 
intelligent data distribution algorithm improves data distribu tion algorithm communication overhead redundant computation minimized 
hybrid distribution algorithm improves intelligent data distribution algorithm dynamically grouping processors partitioning candidate set accordingly maintain load balance 
experimental results cray parallel computer show hybrid distribution algorithm scales linearly exploits aggregate memory better generate association rules single scan database pass 
extended version contains analysis performance schemes available 
rest organized follows 
section provides overview serial algorithm mining association rules 
section describes existing proposed parallel algorithms 
experimental results shown section 
section contains 
basic concepts set transactions transaction subset item set subset define support count respect oe association rule expression form ff support rule ff defined oe jt confidence ff defined oe oe 
example consider rule items implies 
support rule frequency item set transactions 
example support means transactions contain 
confidence rule defined ratio frequencies 
example transactions contain confidence rule 
rule high confidence close important provides accurate prediction association items rule 
support rule important indicates frequent rule transactions 
rules small support uninteresting describe significantly large populations 
reasons algorithms disregard rules satisfy minimum support condition specified user 
filtering due minimum required support critical reducing number derived association rules manageable size 
task discovering association rule find rules ff minimum support threshold ff minimum confidence threshold 
association rule discovery composed steps 
step discover frequent item sets candidate sets support minimum support threshold specified second step generate association rules higher confidence minimum confidence threshold frequent item sets 
number algorithms developed discovering association rules ais hs 
parallel algorithms apriori algorithm smaller computational complexity compared algorithms :10.1.1.40.6757
rest section briefly describe apriori algorithm 
reader refer details :10.1.1.40.6757

frequent item 
fk gamma oe 
ck apriori gen fk gamma 
transactions 
subset ck 
fk fc ck count 

answer fk apriori algorithm apriori algorithm consists number passes 
pass algorithm finds set frequent itemsets fk length satisfy minimum support requirement 
algorithm terminates fk empty 
high level structures apriori algorithm 
initially contains items item set size satisfy minimum support requirement 
algorithm generates ck candidates item sets length fk gamma done function apriori gen generates ck performing join operation item sets fk gamma candidate item sets frequencies computed counting transactions contain candidate item sets 
fk generated pruning ck eliminate item sets frequencies smaller minimum support 
union frequent item sets fk frequent item sets generate association rules 
computing counts candidate item sets computationally expensive step algorithm 
naive way compute counts scan transaction see contains candidate item sets subset performing string matching candidate item set 
faster way performing operation candidate hash tree candidate item sets hashed :10.1.1.40.6757
shows example candidate hash tree candidates length 
internal nodes hash tree hash tables contain links child nodes 
leaf nodes contain candidate item sets 
candidate item set generated items set stored sorted order 
candidate item set inserted hash tree hashing item internal nodes sequence links hash table 
leaf reached candidate itemset inserted leaf total number candidate item sets maximum allowed 
total number candidate item sets leaf exceeds maximum allowed items hashed candidate item set leaf node converted internal node child nodes created new internal node 
candidate item sets distributed child nodes hash values items 
example candidate item set inserted hashing item root reach left child node root hashing item node reach middle child node hashing item reach left child node leaf node 
subset function traverses hash tree root item transaction possible starting item candidate 
level tree items transaction starting item hashed 
hash function transaction candidate hash tree subset operation root candidate hash tree 
transaction candidate hash tree subset operation left subtree root candidate hash tree 
done recursively leaf reached 
time candidates leaf checked transaction counts updated accordingly 
shows subset operation level tree transaction 
item hashed left child node root transaction applied recursively left child node 
item hashed middle child node root transaction checked candidate item sets middle child node 
item hashed right child node root transaction applied recursively right child node 
shows subset operation left child node root 
items hashed middle child node transactions respectively applied recursively middle child node 
item hashed right child node remaining transaction applied recursively right child node 
bulk computation spent finding frequent item sets amount time required find rules frequent item sets relatively small 
reason parallel association algorithms focus parallelize step 
parallel implementation second step straightforward discussed :10.1.1.40.5742
parallel algorithms section focus parallelization task finds frequent item sets 
discuss parallel algorithms proposed help motivate parallel formulations :10.1.1.40.5742
discussions assume transactions evenly distributed processors 
count distribution algorithm count distribution cd algorithm proposed processor computes times candidates appear locally stored transactions :10.1.1.40.5742
done building entire hash tree corresponds candidates performing single pass locally stored transactions collect counts 
global counts candidates computed summing individual counts global reduction operation 
algorithm illustrated 
note processor needs build hash tree candidates hash trees identical processor 
excluding global reduction processor cd algorithm executes serial apriori algorithm locally stored transactions 
algorithm shown scale linearly number transactions :10.1.1.40.5742
processor compute counts independently processors needs communicate processors computation step 
algorithm works hash trees fit main memory processor 
number candidates large hash tree fit main memory 
case algorithm partition hash tree compute counts scanning database multiple times partition hash tree 
note number candidates increases number distinct items database increases minimum support level association rules decreases 
cd algorithm effective small number distinct items high minimum support level 
proc proc proc proc candidate hash tree data count data count data count data count candidate hash tree candidate hash tree candidate hash tree number data items size candidate set number processors global reduction count distribution cd algorithm data distribution algorithm data distribution dd algorithm addresses memory problem cd algorithm partitioning candidate item sets processors :10.1.1.40.5742
partitioning done round robin fashion 
processor responsible computing counts locally stored subset candidate item sets transactions database 
order processor needs scan portions transactions assigned processors locally stored portion transactions 
dd algorithm done having processor receive portions transactions stored processors fashion 
processor allocates buffers page long processor 
processor th buffer store transactions locally stored database remaining buffers store transactions processors buffer stores transactions processor processor checks buffers see contains data 
buffer ties broken favor buffers processors ties buffers processors broken arbitrarily processor processes transactions buffer updates counts candidate subset 
buffer corresponds buffer stores local transactions sent processors asynchronously new page read local database 
buffer corresponds buffer stores transactions processor cleared asynchronous receive request issued processor pk continues processor processed transactions 
having computed counts candidate item sets processor finds frequent item sets candidate item set frequent item sets sent processor broadcast operation 
shows high level operations algorithm 
note processor different set candidates candidate hash tree 
algorithm exploits total available memory better cd partitions candidate set processors 
number processors increases number candidates algorithm handle increases 
reported performance algorithm significantly worse cd algorithm :10.1.1.40.5742
run time algorithm times cd algorithm processors :10.1.1.40.5742
problem lies communication pattern algorithm redundant performed processing transactions 
communication pattern algorithm causes problems 
pass algorithm processor sends processors portion database resides locally 
particular processor reads locally stored portion database page time sends processors issuing gamma send operations 
similarly processor issues receive operation processor order receive pages 
interconnection network underlying parallel computer fully connected direct link pairs processors processor receive data incoming links simultaneously communication pattern lead performance 
particular size database assigned locally processor amount time spent communication 
proc proc proc proc local data remote data candidate hash tree count count local data remote data candidate hash tree count count local data remote data candidate hash tree count count local data remote data candidate hash tree count count data number data items size candidate set number processors data data broadcast broadcast broadcast broadcast data broadcast broadcast data data distribution dd algorithm realistic parallel computers processors connected sparser networks hypercube processor receive data send data processor time 
machines communication pattern take significantly time contention 
second look size candidate sets function number passes algorithm see passes size candidate sets increases decreases 
particular passes algorithm small number items candidate sets 
processor dd algorithm sends locally stored portions database processors 
computation decreases amount communication remains 
redundant introduced due fact processor process single transaction database 
number candidates stored processor reduced factor amount computation performed transaction proportionally reduced 
cd see transactions go hash tree candidates dd see transactions go hash tree candidates 
amount required transaction checked hash tree candidates hash tree candidates extra 
true dd algorithm average depth hash tree reduced average number candidates leaf nodes reduced happen hash tree scheme discussed section 
see consider hash tree single candidate leaf node branching factor reducing number candidates depth hash tree decrease log log 
hand hash tree completely expanded depth number candidates leaf greater number candidates leaf goes depth tree change 
real cases hash tree extreme cases 
general amount transaction go original hash tree candidates 
intelligent data distribution algorithm developed intelligent data distribution idd algorithm solves problems dd algorithm discussed section 
locally stored portions database sent processors ring broadcast described 
operation suffer contention problems takes time parallel architecture embedded ring 
shows pseudo code data movement operation 
algorithm processors form logical ring processor determines right left neighboring processors 
processor send buffer receive buffer rbuf 
initially filled block local data 
processor initiates asynchronous send operation right neighboring processor asynchronous receive operation left neighboring processor rbuf 
asynchronous operations proceeding proces done fd send receive data non blocking pipeline mpi rbuf left mpi right process transactions update hash tree subset htree mpi swap buffers tmp rbuf rbuf tmp process transactions update hash tree subset htree pseudo code data movements sor processes transactions collects counts candidates assigned processor 
operation processor waits asynchronous operations complete 
roles rbuf switched operations continue gamma times 
compared dd processors send data processors perform point point communication neighbors eliminating communication contention 
recall dd algorithm communication overhead data movements dominates computation passes process 
idd solve problem switching cd algorithm total number candidates falls threshold 
note switching cd algorithm cause communication computation overhead processor independently determine switch provided threshold parameter globally known 
choice parameter maximum number candidates single processor main memory 
order eliminate redundant due partitioning candidate item sets find fast way check transaction potentially contain candidates stored processor 
done partitioning ck round robin fashion 
partition ck processors way processor gets item sets subset possible items check items transaction subset determine hash tree contains candidates starting items 
traverse hash tree items transaction belong subset 
solve redundant problem dd intelligent partitioning ck shows high level picture algorithm 
example processor candidates starting items processor candidates starting 
processor keeps items candidates bit map 
apriori algorithm root level hash tree item transaction hashed checked hash tree 
algorithm root level processor filters item transaction checking bit map see processor contains candidates starting item transaction 
processor contain candidates starting item processing steps involved item item candidate skipped 
reduces amount transaction data go hash tree reducing computation 
example fa hg transaction processor processing subset function discussed section 
top level function processor proceed items 
page containing transaction shifted processor processor process items starting 
transaction database approach reduces amount performed processor factor eliminates redundant 
note judicious partitioning hash tree indirectly caused partitioning candidate item set filtering step required eliminate redundant 
intelligent partitioning candidate set idd requires algorithm load balancing 
criteria partitioning involved equal number candidates processors 
gives size hash tree processors provides load balancing processors 
note dd algorithm accomplished distributing candidates round robin fashion 
criteria processor mixed bag candidates 
help prevent load imbalance due skew data 
instance consider database distinct items numbered database transactions data items numbered 
partition candidates processors assign candidates starting items processor candidates starting items processor processor achieve load balanced distribution candidate item sets partitioning algorithm bin packing ps 
item database compute number candidate item sets starting particular item 
bin packing algorithm partition items buckets numbers candidate item sets starting items bucket equal 
remove data skew bin packing algorithm randomly selects item assigned bin 
shows partitioned candidate hash tree corresponding bitmaps processor 
able achieve load imbalance bin packing method described 
hybrid algorithm idd algorithm exploits total system memory minimizing communication overhead involved 
average number candidates assigned processor number total candidates 
processors number candidates assigned processor decreases 
implications 
fewer number candidates processor difficult balance 
second smaller number candidates gives smaller hash tree computation data 
eventually amount computation may communication involved reduces efficiency 
serious problem system count count candidate hash tree count count candidate hash tree count count candidate hash tree count count candidate hash tree bit map proc proc proc proc local data remote data local data remote data local data remote data local data remote data data data data number data items size candidate set number processors shift shift shift data shift data shift bit map bit map bit map broadcast intelligent data distribution idd algorithm perform asynchronous communication 
hybrid distribution hd algorithm addresses problem combining cd idd algorithms way 
consider processor system processors split equal size groups containing processors 
hd algorithm execute cd algorithm processors 
partition transactions database parts size assign task computing counts candidate set ck subset transactions groups processors 
group counts computed idd algorithm 
transactions candidate set ck partitioned processors group processor gets roughly candidate item sets transactions 
group processors computes counts idd algorithm counts computing performing reduction operation groups processors 
hd algorithm better visualized think processors arranged dimensional grid rows columns 
transactions partitioned equally processors candidate set ck partitioned processors column grid 
partitioning ck column processors processors row grid get subset ck idd algorithm executed independently column grid total counts subset ck obtained performing reduction operation rows processor grid 
illustrates hd algorithm theta grid processors 
hd algorithm determines configuration processor grid dynamically 
particular hd algorithm partitions candidate set big section assign group processors partition 
parameter determine switch cd algorithm decide size partition algorithm 
example parameter total number candidates switches cd algorithm 
find number processor groups dm ce form logical theta processor mesh configuration 
example hd algorithm executes cd algorithm processors processors correspond processor columns 
database transactions partitioned parts hypothetical processors computes local counts candidate item sets 
global counts computed performing global reduction operation discussed section 
hypothetical processors processors computation local counts candidate item sets hypothetical processor corresponds computation counts candidate item sets database transactions sitting processors 
operation performed executing idd algorithm hypothetical processors 
shown step 
note processors row exactly candidates candidate sets column partition total candidate set 
operation processor complete counts local candidates data processors column hypothetical processor 
global reduction operation broken parts corresponding step 
step perform reduction operation row candidate hash tree candidate hash tree candidate hash tree candidate hash tree candidate hash tree candidate hash tree candidate hash tree candidate hash tree candidate hash tree candidate hash tree candidate hash tree candidate hash tree frequent item set frequent item set frequent item set frequent item set frequent item set frequent item set frequent item set frequent item set frequent item set frequent item set frequent item set frequent item set step reduction operation rows broadcast operation rows step broadcast operation column broadcast step partitioning candidate sets data movement columns data shift data shift data shift data shift data shift data shift candidate hash tree candidate hash tree candidate hash tree data shift data shift candidate hash tree candidate hash tree candidate hash tree candidate hash tree candidate hash tree candidate hash tree candidate hash tree candidate hash tree candidate hash tree data shift data shift data shift data shift hybrid distribution hd algorithm theta processor mesh processor column row total counts candidates row processors 
step processors column generate frequent set candidate set perform broadcast operation column processor mesh 
processors column broadcast full frequent sets processors row broadcast operation 
point processors frequent sets ready proceed pass 
algorithm inherits features idd algorithm 
provides load balance computation maintaining minimum number candidates processor 
time amount data movement algorithm cut idd 
experimental results implemented parallel algorithms processor cray parallel computer 
processor mhz dec alpha ev mbytes memory 
processors interconnected dimensional torus network peak unidirectional bandwidth mbytes second small latency 
communication message passing interface mpi 
experiments shown kbytes obtain bandwidth mbytes seconds effective startup time microseconds 
generated synthetic dataset tool provided pro described :10.1.1.40.6757
parameters data set chosen average transaction length average size frequent item sets 
data sets transactions kb generated different processors 
due disk limitations system kept small transactions buffer read transactions buffer actual disks 
experiments involving larger data sets read data set multiple times 
performed scaleup tests transactions processor minimum support 
lower minimum support cd algorithm ran main memory 
experiment idd hd algorithms set minimum number candidates switching cd algorithm low show validity approaches 
support algorithms switched cd algorithm pass total passes response time serial code spent passes 
scaleup results shown 
noted cd algorithm scales :10.1.1.40.5742
looking performance obtained idd see response time increases increase number processors 
due load balancing problem discussed section number candidates processor decreases number processors increases 
performance achieved idd better dd algorithm :10.1.1.40.5742
particular idd times response time dd processors 
seen performance gap idd dd widening number processors increases 
due improvement idd performed similar experiments ibm sp entire database resided disks 
experiments show requirements change relative performance various schemes 
response time sec 
number processors count intelligent data hybrid data scaleup result transactions minimum support 
better communication mechanism data movements intelligent partitioning candidate set 
looking performance hd algorithm see response time remains constant increase number processors keeping number transactions processor minimum support fixed 
comparing cd see hd performs better number processors increases 
performance processors better cd 
performance advantage hd cd due number processors involved global reduction operation counts hd cd 
measured algorithms perform increase number transactions processor mb mb 
experiments fixed number processors minimum support 
results shown 
see cd hd perform identically 
algorithms response time increases linearly number transactions 
idd scales linearly load imbalance problem performance somewhat worse 
experiments far shown performance hd cd quite comparable 
real advantage hd idd cd require hash tree reside processor better exploit available memory 
allows smaller minimum support apriori algorithm 
verify performed experiments fixed number transactions processor successively decreased minimum support level 
experiments processors shown figures respectively 
couple interesting observations results 
idd hd successfully ran lower support levels cd run 
particular idd hd ran support level processors processors 
contrast cd run support level ran memory lower supports 
difference smaller support levels processors due fact idd hd algorithms exploit aggregate memory larger number processors 
response time sec 
number transactions processor count intelligent data hybrid result processors minimum support 
second thing notice hd performs better idd processors relative performance idd compared hd get worse number processors increases 
discussed earlier performance difference due load imbalance 
number processors increases load imbalance gets worse 
processors idd worse hd support level worse support 
support level decreases number candidates shown parenthesis figures increases improves load balance 
figures show performance simple hybrid algorithm obtained combining cd idd 
scheme pass apriori algorithm perform cd hash table fit memory processors idd 
see results simple hybrid algorithm performs worse hd 
particular relative performance scheme compare hd gets worse number processors increases 
example support level worse processors worse processors 
hd algorithm gradually adjusting subsets processors perform idd cd achieves better performance 
reasons 
candidate set split fewer number processors minimizes load imbalance second reduction operation obtain counts cd performed fewer processors decreases communication overhead 
experiment varied number processors measured low go minimum support idd hd algorithms 
table shows result algorithms 
result shows processors algorithms handle lower minimum support 
table shows hd algorithm chose processor configuration number candidates pass processors minimum support 
proposed parallel algorithms mining association rules 
idd algorithm utilizes total main memory available effectively cd algorithm 
response time sec 
minimum support count intelligent data hybrid simple hybrid response time processors transactions minimum support varies 
support level total number candidate item sets shown parenthesis response time sec 
minimum support count intelligent data hybrid simple hybrid response time sec 
minimum support count intelligent data hybrid simple hybrid response time processors transactions minimum support varies 
support level total number candidate item sets shown parenthesis number processors successful ran memory table minimum support reachable different number processors algorithms 
pass configuration theta theta theta theta theta theta theta theta theta cand 
table processor configuration number candidates hd algorithm processors minimum support pass 
note theta configuration dd algorithm theta cd algorithm 
total number pass passes theta configuration 
algorithms improves dd algorithm high communication overhead redundant 
communication overhead reduced better data movement communication mechanism redundant reduced partitioning candidate set intelligently bit maps prune away unnecessary computation 
number processors available increases efficiency algorithm decreases amount increased having number candidates 
hd combines advantages cd idd 
algorithm partitions candidate sets just idd exploit aggregate main memory dynamically determines number partitions partitioned candidate set fits main memory processor processor number candidates computation 
exploits advantage cd just exchanging counts information moving minimum number transactions smaller subset processors 
experimental results processor cray parallel machine show hd algorithm scales just cd algorithm respect number transactions 
exploits aggregate main memory better able find association rules smaller minimum support single scan database pass 
idd algorithm outperforms dd algorithm scalable hd cd 
works include applying algorithms real data retail sales transaction mail order history database world wide web server logs confirm experimental results real life domain 
plan perform experiments different platforms including cray ibm sp sgi smp clusters 
plan implementing ideas generalized association rules hf sa sequential patterns mtv sa 
ais agrawal imielinski swami 
mining association rules sets items large databases 
proc 
int 
conf 
management data washington 
agrawal srikant :10.1.1.40.6757
fast algorithms mining association rules 
proc 
th vldb conference pages santiago chile 
agrawal shafer :10.1.1.40.5742
parallel mining association rules 
ieee transactions knowledge data eng december 
hf han fu 
discovery multiple level association rules large databases 
proc 
st vldb conference zurich switzerland 
han karypis kumar 
scalable parallel data mining association rules 
technical report tr department computer science university minnesota 
hs swami 
mining association rules relational databases 
proc 
th int conf 
data eng pages taipei taiwan 
vipin kumar gupta george karypis 
parallel computing algorithm design analysis 
benjamin cummings addison wesley city 
mobasher jain han srivastava 
web mining pattern discovery world wide web transactions 
technical report tr department computer science university minnesota 
mtv mannila toivonen verkamo 
discovering frequent episodes sequences 
proc 
int conference knowledge discovery data mining pages montreal quebec 
pro ibm quest data mining project 
quest synthetic data generation code 
www almaden ibm com cs quest html 
ps papadimitriou steiglitz 
combinatorial optimization algorithms complexity 
prentice hall englewood cliffs nj 
sa srikant agrawal 
mining generalized association rules 
proc 
st vldb conference pages zurich switzerland 
sa srikant agrawal 
mining sequential patterns generalizations performance improvements 
proc 
fifth int conference extending database technology avignon france 
sad stonebraker agrawal dayal neuhold reuter 
dbms research crossroads vienna update 
proc 
th vldb conference pages dublin ireland 
son savasere omiecinski navathe 
efficient algorithm mining association rules large databases 
proc 
st vldb conference pages zurich switzerland 
