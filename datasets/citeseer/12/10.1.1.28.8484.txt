optimization sparse matrix kernels data mining eun jin im katherine yelick computer science division university california berkeley cs berkeley edu yelick cs berkeley edu tel fax number optimization sparse matrix kernels data mining eun jin im katherine yelick computer science division university california berkeley data mining algorithms rely eigenvalue computations iterative linear solvers running time dominated sparse matrix vector products 
sparse matrix vector multiplication modern machines runs orders magnitude slower peak hardware performance lack structure worst performance observed matrices text retrieval data mining applications 
explore set memory hierarchy optimizations sparse matrix vector multiplication concentrating matrices arises text image retrieval 
consider algorithms multiply sparse matrix set vectors show reorganizing code take advantage multiple vectors significantly speed running time 
optimization supported code generation optimization system called sparsity automatically tunes sparse matrix vector multiplication matrix structure machine 
data mining algorithms rely eigenvalue computations iterative linear solvers running time dominated sparse products 
sparse matrix operations slower dense matrix counterparts due irregular memory access patterns indirection overhead sparse data structure 
result sparse matrix vector multiplication runs orders magnitude peak hardware performance 
sparse matrix performance strongly depends nonzero structure matrix worst performance seen data mining matrices 
expect gap hardware peak sparse matrix performance worsen relative speed processors memory continues diverge size data sets mined increases 
developed system called sparsity automatically generate optimized sparse matrix vector multiplication routine matrix structure machine im 
optimization include register level blocking cache blocking blocking multiple vectors exist higher level algorithm 
absolute performance relative speedup optimization highly dependent matrix structure turn depends application domain 
matrices physical simulation contain small dense subblocks dense bands improve performance 
matrices shown register blocking ective optimization method 
contrast matrices arise data mining applications quite irregular closer random pattern 
explore memory hierarchy optimizations sparse matrix vector multiplication data mining matrices 
concentrate matrices text retrieval face recognition algorithms latent semantic indexing concept decomposition dm eigenface approximation li li 
particular show cache level blocking significantly improve performance matrices web document retrieval face recognition register level blocking highly ective matrices physical modeling proves relatively ine ective 
algorithms organized multiply sparse matrix set vectors show reorganizing code take advantage multiple vectors significantly improve running time 
optimization supported sparsity performs automatic optimization selection code generation matrix structure machine 
rest organized follows 
section show examples data mining applications sparse matrix vector multiplication describe sparsity memory hierarchy optimizations techniques section 
optimizations selected prove ective data mining matrices 
show performance improvement applications ultrasparc ii alpha mips pentium iii section conclude section 
collection applied dimension nonzeros density avg 
algorithm row web document lsi nsf abstracts cd face images ea sparse matrices data mining applications data mining algorithms sparse matrix computations introduce examples data mining algorithms sparse matrix vector multiplication latent semantic indexing concept decomposition eigenface approximation 
text clustering retrieval third face recognition images 
section matrices associated algorithms measuring ectiveness optimization techniques characteristics matrices summarized 
noted algorithms matrices chosen representative kinds problems sparse matrix vector multiplication data mining text images 
algorithms data sets exist data mining intent compare algorithms quality 
text retrieval document retrieved may done literally matching terms documents query 
direct matching may inaccurate usually ways express concept literal terms user query may match relevant document 
examples algorithms address problems latent semantic indexing concept decomposition 
address problems lexical matching statistically derived conceptual indices individual words retrieval 
lsi term document matrix projected smaller dimensional space computing truncated singular value decomposition svd matrix retrieval performed projecting query space 
literature bulk lsi processing time spent computing truncated svd sparse term document matrix kernel sparse matrix vector multiplication 
blocked version svd computation sparse matrix multiplied number vectors bcd 
dhillon introduced related idea concept decomposition document clustering dm 
concept decomposition matrix approximation scheme solves squares problem 
comparable lsi advantages truncated svd memory time 
calculate concept decomposition sparse matrix vector multiplication case multiplication performed multiple vectors range 
collected term document matrices demonstration optimization techniques 
collected documents web inktomi entire matrix collected years ago fit memory single processor 
interest uniprocessor performance rows columns refer web document matrix 
sparse matrix nonzeros 
second matrix contains nsf award abstracts 
extended collection nsf matrix dm sparse matrix nonzeros 
eigenface approximation ea eigenvector analysis widely image processing pattern matching machine vision 
face recognition algorithm referred eigenface computation 
li li li proposed multi resolution algorithm calculating primary eigenvectors large set high resolution images 
algorithm systematically images create multi resolution hierarchy image set computes eigenvectors coarsest images works way recovers primary eigenvectors original images approximate eigenvectors 
algorithm gains substantial speedups common svd approach 
original matrix dense pixel image matrix image linearized form column matrix 
algorithm combined wavelet compression techniques speedup eigenvector computation process values matrix threshold discarded 
resulting matrix sparse algorithm multiplies sparse matrix times set vectors 
code face images resolution got ren li generated face image matrix size nonzeros 
matrices text retrieval face image matrix shows strong distribution pattern top rows denser bottom rows sparser 
higher resolution images represented top rows lower resolution images represented bottom rows 
text retrieval matrices image matrix devoid dense bands 
optimization methods optimization techniques sparsity system include register blocking cache blocking blocking multiple vectors 
register blocking ective matrices contain large number small dense subblocks case data mining matrices study 
describe optimizations ective cache blocking blocking multiple vectors 
cache blocking optimization describe optimization technique improving cache utilization 
cost accessing main memory modern microprocessors tens hundreds cycles minimizing cache misses critical high performance 
basic idea reorganize matrix data structure associated computation improve reuse data source vector destroying locality destination vector 
cache blocking set values cache complete control software hardware controls selection data values level cache policies replacement associativity write strategy hp 
caches hold thousands values rearrange computation block values matrix accessed near time retain sparse structure matrix 
contrast register blocking avoids indexing loop overhead filling dense subblocks uniform practical cache blocking 
potential reuse data matrix vector computation source destination vectors matrix entry 
purpose discussion assume matrix organized rows similar optimization done column layout 
obvious matrix vector computation row layout reuse destination vector element row possibly leaving cache cache cache blocks sparse matrix gray areas sparse matrix blocks contain nonzero elements cache cache rectangle 
white areas contain nonzero elements stored 
register picks source elements demand 
large matrix especially columns source element cache needed 
idea cache blocking optimization keep cache elements source vector cache cache elements destination vector cache cache block matrix multiplied portion vector entries need saved cache decision hardware control interference elements matrix vectors problem 
di culties cache blocking irregular problem determining block sizes cache cache simplify code generation problem limit range experiments start assumption cache blocks single matrix fixed size 
words cache cache fixed particular matrix machine 
means logical block size fixed amount data computation may uniform blocks number nonzeros block may vary 
shows matrix fixed size cache blocks 
note blocks need sets row 
considered strategies cache blocking implementation referred static cache blocking involves preprocessing step reorganize matrix block stored contiguously main memory 
second implementation referred dynamic cache blocking involve data structure reorganization changes order computation retaining set pointers row current logical block 
dynamic cache blocking avoids preprocessing value col idx block ptr row start 
storage format cache blocked sparse matrix cache blocking block stored sparse format similarly csr data structures block ptr col idx value 
example matrix blocks 
row start array points row blocks block ptr array keeps pointers beginnings individual rows inside blocks 
overhead incurs significantly runtime overhead static cache blocking im static cache blocking 
practical implication decision matrix storage entire application iterative solver amortize cost reorganization 
static cache blocking sparse matrix reorganized changing order column index array nonzero elements sparse matrix augmenting array indices points block 
reorganization nonzero elements row stored sequentially memory 
matrix reorganized cache blocking rows matrix broken groups cache rows 
group rows starting column nonzero element column index smallest nonzeros appear cache columns grouped rectangular area stored similarly compressed sparse row csr format 
data structures cache blocked matrix shown 
top level array called row start points row blocks 
rows blocks row start matrix entries pointing past block ptr array 
block ptr array points row block col idx value arrays store column indices values nonzero element 
main di erence csr format extra level indirection blocks 
multiplication nonzero elements accessed order stored memory important preserving spatial locality matrix 
referring back means processing gray block indices values matrix accessed storage order portions vectors correspond block accessed repeatedly 
sub arrays sit cache processing long fit interference sub arrays matrix entries 
optimization multiplication multiple vectors improve performance sparse matrix operations take advantage fact multiple vectors multiplied 
data mining algorithms multiply sparse matrix times set vectors 
scientific computing occurs practice multiple right hand sides iterative solver blocked eigenvalue algorithms block lanczos gu gls mar block arnoldi sad lm 
application image segmentation videos set vectors starting guess subsequent frame video sm 
multiple vectors problems essentially turns kernel matrix matrix multiplication second matrix small dense 
admits potential memory hierarchy optimizations single vector case increases number floating point operations matrix element 
matrix vector multiplication accesses matrix element matrix times set vectors access matrix element times 
potential high performance multiple vectors advantage exhibited straightforward implementations organize computation single matrix vector multiplies 
change multiplication code access elements vectors allowing matrix elements reused 
code generator developed sparsity system produces code specifically register blocked multiplication fixed set vectors 
number vectors fixed code generation time loops fully unrolled vectors 
code generator creates inner kernels larger computation number vectors large loop vectors strip mined resulting inner loop unrolled loops 
processor clock cache dgemm mhz size mflops mflops mips mb ultrasparc ii mb pentium iii kb alpha kb summary machines performance improvement sparse matrix vector multiplication matrices data mining applications applied optimizations cache blocking blocking multiple vectors sparse matrices described section 
applied third optimization combination 
experiments run modern microprocessors mhz mips mhz sun ultrasparc ii mhz intel pentium iii mhz compaq alpha 
machines summarized 
shows processors clock speed cache size performance optimized dense blas routines comparison 
blas routines table dense matrix vector multiplication dense multiplication dgemm double precision floating point numbers 
measured dense matrices 
vendor supplied hand optimized blas libraries sun performance libraries ultrasparc automatically tuned blas routines pentium iii alpha atlas blas generation system wd 
upper bound expected performance sparse matrix vector multiplication dgemm upper bound multiple vector case 
figures show performance sparse matrix vector multiplication web document matrix nsf matrix face recognition matrix 
group bars shows performance machine ordered left right ultrasparc ii pentium iii alpha 
group leftmost bar shows raw performance optimization bars show performance cache blocking multiple vectors respectively 
bar shows performance combined optimizations 
speedups combined optimizations summarized 
speedup matrix mips ultrasparc ii pentium iii alpha web document nsf face images speedup sparse matrix vector multiplication ultrasparc pentium iii alpha web document matrix mflops raw performance cache blocking multiple vector cache multi 
performance sparse matrix vector multiplication web document matrix range 
note vertical scales graphs di erent performance web document matrix smallest performance face recognition matrix largest 
see density matrices order density web document matrix smallest face recognition largest 
matrix denser spatial temporal locality access operation raw performance better denser matrices 
second observation cache blocking improves performance web document matrix exhibit noticeable speedup nsf matrix face recognition matrix 
clearly due matrix size particular number columns matrix 
web document matrix columns ultrasparc pentium iii alpha nsf matrix mflops raw performance cache blocking multiple vector cache multi 
performance sparse matrix vector multiplication nsf matrix ultrasparc pentium iii alpha face recognition matrix mflops raw performance cache blocking multiple vector cache multi 
performance sparse matrix vector multiplication face recognition matrix processor cache block size block size size single vector vectors mips mb ultrasparc ii mb pentium iii kb alpha kb chosen cache block sizes web document matrix matrices combined low density likelihood source vector element cache needed low 
matrices somewhat constrained size importance cache blocking increase mining larger datasets 
number rows matrices represents number keywords pixels increase data set number columns number documents images grow 
cache block sizes chosen automatically sparsity system measuring performance block sizes powers 
shows cache block sizes chosen matrix machine 
sparsity selects block sizes number rows cache blocks larger total number rows matrix recorded table 
cache sizes shown graph see relation size cache number columns cache block 
roughly shown expression 
number columns cache block size cache sizeof double constant may exact number searched space cache block size exhaustively range expression clearly shows width number columns cache block limited cache size 
matches intuition aim cache blocking increase reuse source vector elements cache 
table shows chosen cache block size multiplication vectors loop unrolled code multiple vectors 
cache block sizes chosen way multiplication single vector 
cache block sizes smaller single vector case number columns cache block number vectors multiplied elements source vectors kept cache computation performed 
separate parameter cache block size amount unrolling vectors 
chose total vectors experiments reasonable number algorithms multiple vectors 
multiplication code unrolled times mips ultrasparc ii pentium iii code unrolled times alpha 
loop unrolling factor chosen automatically sparsity optimize performance im 
discussed section set vectors strip mined multiplied number vectors larger loop unrolling factor case alpha 
table widths cache blocks single vector times smaller widths cache blocks multiple vectors processors ratio alpha unrolled times 
ratio power chosen cache block size power 
ratios close approximations loop unrolling factors case 
matrices nsf matrix face image matrix cache blocking improve performance width cache block sizes shown larger matrices 
chosen cache block sizes matrix sizes matrices 
unrolled loop multiplication improved performance noticeably matrices 
performance multiplication multiple vectors speed web document matrix discussed earlier source vectors long elements rarely cache 
note vectors stored contiguously memory reflect application order th elements vectors stored contiguously multiple vector optimization probably significant 
current layout best performance web matrix obtained combining optimizations 
introduced optimization techniques sparse matrix vector multiplication cache blocking blocking multiple vectors 
optimizations especially important large data mining matrices 
cache blocking important dimensions large significantly smaller 
optimizations register blocking discussed detail impor tant certain scientific applications little ect data mining im 
optimizations applied sparsity toolbox automatically generates optimized sparse matrix vector code 
sparsity chooses parameters cache block size searching set possible candidates measuring performance 
demonstrated ectiveness optimizations example sparse matrices taken data mining applications 
cache blocking particularly useful sparse matrix columns 
unrolling multiple vectors effective long number columns large combination ective 
identified relationship number columns cache block size cache 
multiplication performed set vectors number columns cache block decreased accordingly 
approach produced speedups matrices measured machines 
believe optimizations increasingly important memory latency increases relative clock rate desired data set size increases 
complexity modern memory hierarchies di culty reorganizing sparse data structures computation believe sparsity approach combining search kinds analytical models derived cache block size key helping users obtain high performance 
dhillon providing nsf matrix marques web document matrix ren li face database code generating wavelet transformed matrix 
insightful discussions 
bcd bai 
chen day dongarra edelman ericsson freund gu kowalski 
li morgan ruhe saad sorensen van der vorst 
templates solution algebraic eigenvalue problems practical guide 
preparation 
michael berry susan dumais gavin brien 
linear algebra intelligent information retrieval 
siam review 
dm dhillon modha 
concept decompositions large sparse text data clustering 
technical report rj ibm july 
appear machine learning 
gls grimes lewis simon 
shifted block lanczos algorithm solving sparse symmetric eigenvalue problems 
siam matrix anal 
appl 
gu golub underwood 
block lanczos method computing eigenvalues 
rice editor mathematical iii pages 
academic press 
golub van loan 
matrix computations 
johns hopkins university press baltimore md rd edition 
hp john david patterson 
computer architecture quantitative approach 
morgan kaufman second edition 
im eun jin im 
optimizing performance sparse matrix vector multiplication 
phd thesis university california berkeley may 
li 
li 
multi resolution approach calculating primary eigenvectors large set images 
technical report department university kentucky june 
li 
li 
fast partial eigenvalue decomposition wavelet transformation large images july 
lm 
implementation implicitly restarted block arnoldi method 
preprint mcs argonne national lab 
mar marques 
user guide 
technical report tr pa 
sad 
block arnoldi chebyshev method computing leading eigenpairs large sparse unsymmetric matrices 
numer 
math 
sm jianbo shi jitendra malik 
motion segmentation tracking normalized cuts 
international conference computer vision january 
wd clint whaley jack dongarra 
automatically tuned linear algebra software atlas 
www netlib org atlas 

