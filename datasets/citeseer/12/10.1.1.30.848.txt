learning behave socially maja mataric mit artificial intelligence laboratory technology square cambridge ma phone fax email maja ai mit edu april previous introduced methodology synthesizing analyzing basic behaviors served substrate generating large repertoire higher level group interactions matari matari 
describe substrate agents learn behave socially maximize average individual maximizing collective benefit 
defined problem rational agents difficult learn situated domains 
describe sources reinforcement show necessity learning non greedy social rules 
learning strategy demonstrated group physical mobile robots learning yield share information foraging task 
previous focused analyzing synthesizing complex group behaviors simple social interactions individuals matari matari 
introduced methodology involved designing collection basic behaviors served substrate large repertoire higher level interactions 
describe agents extend basic repertoire order learn behave socially 
importance social behavior needs elaboration 
social rules simplest traffic protocols complex ethical constructs minimize conflict optimize global efficiency 
consequently social rules natural part society acquisition rules important aspect adaptive behavior 
describe social learning fundamental form adaptive group behavior acquiring social rules 
social learning social learning process acquiring new behavior patterns social context learning 
called observational learning social learning ubiquitous nature mcfarland mcfarland propensity appears innate 
animals imprint mimic imitate adults kind obtaining direct rewards successfully achieving goal behavior mcfarland gould 
crucial form learning development social learning remains important aspect social interaction animal life 
observational learning old method adapting behavior 
invertebrates birds moore aquatic mammals mitchell course primates humans 
cases faster efficient form acquiring new behaviors traditional classical conditioning counterpart 
imitation easier general imitation mimicry animals birds moore capable 
social learning includes learning perform behavior imitation perform social facilitation 
imitation defined ability observe repeat behavior animal agent 
principal modes acquiring new patterns behavior 
true imitation distinct mimicry social facilitation 
mimicry ability repeat aspects behavior agent having imitator understand goal behavior internal state agent imitated tomasello kruger 
social facilitation refers process selectively expressing behavior part animal species specific repertoire 
birds milk bottle caps order drink milk inside davis mcfarland eating groups mcfarland examples social facilitation animals learning new behavior responding releaser davis 
previous addressed problem learning behavior selection 
maes brooks demonstrated algorithm learning higher level group behaviors selecting basic primitives matari 
previous focuses learning social rules behaviors produce immediate payoff agent benefit group 
game theory dealt extensively related problems example see axelrod kraus durfee lee gmytrasiewicz exclusively domains rational agents capable correctly evaluating utility actions strategies 
contrast interested finding required learning social strategies situated agent domains due incomplete nonexistent world models inconsistent reinforcement noise uncertainty agents assumed rational 
general systems treated game theory usually simpler cleanly constrained biology motivate 
section describes key issues interference underlying motivation social rules 
section puts forth notion prototypical social states effectively prune space social interactions 
part postulates key sources reinforcement social learning 
reminder describes robot experiments test proposed theory applied learning social rules 
part summarizes current outlines continued experimental 
interference conflict universally accepted popular theory postulates social interactions evolutionarily beneficial social structure minimizes interference maximizes benefit group presumably terms reproductive success 
interference influence opposes blocks agents goal driven behavior 
societies consisting agents similar goals interference manifests competition shared resources 
diverse societies agents goals differ complex conflicts persist agents including undoing deadlocks oscillations 
functionally distinct types interference relevant interference caused multiplicity call resource competition interference caused goal related conflict call goal competition 
resource competition includes interference resulting multiple agents competing common resources space food information 
type interference causes decline performance multi agents systems agents added 
primary impetus social rules 
resource competition simply caused physical coexistence exist multi agent system goal competition applies systems heterogeneous agents 
functionally different agents create lasting interference conflicting goals 
agent undo immediate need resources due higher level goal instance establishing dominance 
goal competition studied primarily distributed ai community gasser huhns 
approaches usually involve predicting agents goals intentions requiring agents maintain models internal state huber durfee miceli cesta 
prediction abilities require computational resources scale increased group sizes 
contrast deals homogeneous societies social rules shared individuals 
consequently resource competition social rules aimed minimizing relevant addressed 
individuals vs groups social rules minimize interference agents attempt direct behavior away individual greediness global efficiency 
greedy strategies perform poorly group situations resource competition inevitable correctly managed resource competition grows size group 
group dynamics fall category 
example tasks allow efficient greedy strategies agents specialize task division demonstrated deneubourg goss pasteels 
contrast focuses tasks solutions agents specialize find means optimizing activity task developing social rules 
situations agents give individual optimality favor collective efficiency 
theory interest individuals obey social rules average individual efficiency improved 
connection individual collective benefit direct problem learning social rules difficult 
outside game theory problem addressed filed artificial life genetic learning level 
genetic algorithm allow generations agents differ global efficiency cultural context elevated common 
rate growth determined properties particular system 
ent social rules tried mutated recombined order find best fit example see strategy evolving communication chris langton related 
fundamentally different addresses problem learning social rules individuals lifetime context task case foraging 
aimed loosely modeling higher animals insects preprogrammed appropriate social strategies 
consequently directly assume social rules build deal tradeoffs individual versus global efficiency incorporate appropriately line real time learning strategies 
prototypical states social interaction animal interactions largely drawn small social repertoire 
theory number possible social situations multiple agents prohibitively large especially grows size group 
practice rules social behavior quite independent exact group size 
specifically classes group sizes prototypical relations agents relevant type interaction 
canonical form social relation dominance hierarchy order ubiquitous animal societies crabs primates people chase chase rohwer 
mating majority animal social interaction focuses establishing maintaining orders cheney 
directly derivable evolutionary benefit proven hierarchies certainly serve simplify social interactions 
dominance hierarchies prevalent social structure simplify social interaction interested learning social rules directly embedded dominance structure need derived agent interactions effectiveness tasks time 
dominance hierarchies animal social interactions classified far prevalent 
described group size classification prune state space social interactions focus learning social rules applied interaction classes 
particular yielding rules motion conflicts communication rules oneto interaction 
postulate learning social bounded sensing communication range 
rules interactions requires specific types social reinforcement described section 
social reinforcement social settings offer plethora information useful learning 
relevance behavior recognized biology innate propensity social learning 
instance young animals copy behavior adult automatically direct reward gould 
furthermore behavior peers copied especially leads reward 
type social behavior results development culture form behavior patterns passed generations 
known example monkeys repeatedly discovered washing potatoes separating dirt seeds mcfarland 
observed behavior serve negative positive reinforcement 
example animals quickly learn eat food poisonous effect avoid people davis gould mcfarland 
vicarious punishment vicarious reward effective direct counterparts 
sense vicarious learning means distributing trials multiple agents agent need perform 
long experience agent visible serve source vicarious learning trials 
evidence ethology guides derive forms reinforcement involved social learning 
type individual perception progress relative current goal 
type reinforcement inherent learning task availability varies depending specific agent environment 
tasks agent maintain measure progress critical efficient learning 
second type reinforcement comes observing behavior 
similar behavior peer considered source positive reinforcement 
constitute reliable reinforcement signal coupled direct estimate progress agent particular goal provide useful feedback agent 
third type reinforcement received 
interestingly type information require agent model agent internal state 
agents belong homogeneous society obey consistent social rules reward punishment received received agent similar situation 
consequently vicarious reinforcement useful learning signal 
tasks resemble maze learning reward goal 
robot consists differentially steerable wheeled base gripper grasp lift objects 
robots sensory capabilities include piezo electric bump gripper sensors infra red sensors collision detection proprioceptive sensors maintaining drive gripper motor current voltage position radio transmitter communication absolute positioning 
postulate described forms reinforcement necessary learning social rules 
individual reinforcement sufficient definition maximizes individual benefit 
kind rules interested learning immediately directly benefit individual cases delaying effect individual reinforcement learned reinforcement 
observing agents behavior helps learning gives impetus agent try behaviors immediately benefit 
repeating behavior enforces multiple trials rare social behavior stable reinforcement received 
observing agents behavior clearly encourages exploration group speeds learning induce individual agents behave ways reduce reinforcement 
society develop social rules individual learning centrally imposed arbiter 
accomplished agents able estimate agents reinforcement individual reinforcement positively correlated 
short indirectly 
simple model allows learning variety powerful social rules minimize interference maximize group benefit 
test hypothesis designed collection experiments situated agents mobile robots learning yield communicate order globally efficient foraging high level task 
section describes experimental environment 
robots experimental environment described designed performing variety group behavior experiments 
verifying basic behaviors demonstrating algorithm accelerated situated learning matari 
allows implementing various interactions robots capable communicating sensing manipulating objects 
experiments conducted collection mobile robots 
robots fully autonomous board power sensing 
robot consists differentially steerable wheeled base gripper grasp lift objects 
robots sensory capabilities include piezo electric bump sensor strip base detecting collisions strip inside finger gripper detecting grasping force set infra red ir sensors inside fingers detecting graspable objects obstacle avoidance set sensors top robot gripper tip see 
addition described external sensors robots equipped proprioceptive sensors supplying battery voltage current information sensors drive motor current shaft encoders gripper motors maintaining position height information 
robots equipped radio transceivers determining absolute position inter robot communication 
position information obtained triangulating distance computed synchronized ultrasound pulses fixed base stations 
inter robot communication consists locally broadcasting byte messages rate hz 
radios particularly useful transmitting information reasonably sensed available board sensors external state robots holding food finding home required social learning 
robots programmed behavior language parallel programming language subsumption architecture brooks brooks 
control systems collections parallel concurrently active behaviors 
learning environment order learning task realistic tested learning algorithms robots situated foraging task having common higher level goal collecting food home day sleeping home night 
robots world confined area contains fixed home region shared robots scaled accommodate large park night experimental area learning task conducted 
home region shaded 
pucks clustered 
relative sizes environment robots shown scale 
reasonable amount maneuvering 
food clustered single location workspace 
clustered nature food certainly effect optimal set strategies collection task 
chose single cluster arrangement reasons 
clustering food gives incentive agents cooperate exchange information 
food randomly scattered environment point communicating social rules reduced avoidance 
second clustering food reduces duration experimental run agents need spend time looking 
complexity learning task diminished finite resources battery power conserved designing experiment maximize relevance robots interactions 
reason chosen workspace small result frequent interaction interference robots order learning possible 
experimental environment meant loosely resemble society spends days foraging hunting gathering making repeated trips resource rich area getting food home 
fixed periods meant resemble night time society gathers home rests 
foraging activities resume day 
learning task task consisted learning social rules yielding communicating puck location 
rules symmetric translate behaviors social situation 
yielding consists learning side give way keep going 
sharing information consists learning broadcast position information receive store 
social rules expressed robots natural habitat context usual routines case foraging 
foraging context chosen previous matari matari provided basic behavior repertoire social rules easily added 
built foraging behavior consists finite state controller response conditions consisting internal state activates appropriate basic behaviors robots repertoire 
conditions include externally triggered events getting close robot finding puck internally generated events onset night time indicated internal clock 
basic behaviors include avoidance dispersion searching pucks picking pucks homing sleeping 
earlier shown foraging learned matari 
demonstrates improved social rules 
important note alternative behaving socially behaving randomly behaving greedily 
learning task realistic difficult agent biased built instinctive greedy individualistic behavior guarantees survival 
order learn social rules behavior repertoire include appropriate social behaviors yielding proceeding broadcasting listening storing observing remembering behaviors tried eventually conditions learned 
active behaviors require adding new abilities robots contained necessary actions yielding consists stopping waiting proceeding consists going current behavior 
non active behavior requiring observation storage added exclusively social learning algorithms existing mechanism sending receiving messages communicating positions neighbors 
job learning algorithm correlate appropriate conditions behaviors order optimize higher level behavior maximize received reinforcement 
learning task set simple search space possible strategies highest reward strategies result highest efficiency foraging simply solved game greediness basis behavior 
basic human nature implied intended 
tendency friendliness built goal experiment 
theoretic strategies derived tit tat related solutions 
described domain agents simply search condition behavior space directly completely control events world 
world stochastic noisy uncertain particular complex presence learning agents 
exactly presence ways interact constitute relevant conditions learning social rules 
postulate types social knowledge related reinforcement necessary learning proposed social rules 
direct reinforcement 
observation behavior agents 
observation reinforcement received agents 
section describes reinforcement formally implemented 
implementing social reinforcement learning algorithm produces maintains total order appropriateness social behaviors associated condition expressed 
described earlier matrix values prohibitively large number relevant social conditions behaviors relatively small 
values correlation matrix fluctuate time received reinforcement learning algorithm expected converge stable ordering 
point time value sum past reinforcement implementation direct reinforcement straightforward 
progress monitoring behavior constantly compares agent current state immediate goal 
detects progress terms reaching subgoal case finding food terms diminishing distance goal case going home gives small reward active social behavior 
analogously regress goal detected small punishment delivered 
formally progress regress note social behaviors reinforced social rules learned 
algorithm guaranteed keep learning system settling local minima system continuously adapts correlation values received reinforcement 
algorithm relies estimating progress intermittently 
progress measurements available reward function impulse goal algorithm reduces step temporal differencing sutton proven converge slowly 
environments kind algorithm bound faster 
successfully acquire basic greedy strategy individual foraging matari 
motivation progress estimators called internal critics delayed reinforcement algorithm learning comes nonmarkovian uncertainty inconsistency properties group situated agent domain 
reasoning described detail matari short progress estimators provide unbiased principled reinforcement delayed useless dynamic environment 
observational reinforcement reinforcement repeating agent behavior delivered similar form ae repeated observed behavior agent receives positive reinforcement repeats behavior observed time finds condition performed behavior 
temporal component 
expires fixed time agent effect forgets saw seen 
feature eliminates cyclic behavior patterns multiple learning agents observing 
vicarious reinforcement reinforcement received received agents delivered form vicarious positive reinforcement vicarious negative reinforcement vicarious reinforcement delivers form shared reinforcement agents involved local social interaction 
spreading individual reward punishment multiple agents serves extend individual benefit single agent 
consequence amount reward received social behaviors time outweighs received greedy strategies 
complete reinforcement function sum subset social reinforcement learning experiment 
specific examples section 
learning experiments typical learning experiment agents endowed identical basic behaviors social learning reinforcement function 
started home day go foraging task usual 
social learning algorithm activated agent finds 
near large amount food away home 
receiving agent message 
observing range stopped agent 
observing range moving agent 
interference range stopped agent 
interference range moving agent 
conditions specified designer order speed learning 
learned available statistical methods state generalization example chapman kaelbling mahadevan connell process take long social learning suffer sensory errors 
condition enables learning communicate sharable resources food 
conditions distance thresholds established priori ffi observe ffi interfere basic foraging behavior presence agent ffi interfere triggers avoidance 
social learning algorithm social behaviors attempted alternative 
event occurs conditions true current behavior agent executed terminated appropriate social reinforcement delivered 
new behavior selected strategy 
choose observed behavior appropriate 
choose untried social behavior 
choose best behavior 
choose random behavior probability confined physical area agents interact generate plethora events enabling social conditions 
consequently observe learning real time period minutes 
preliminary results mentioned previously basic learning algorithm tested shown theoretically practically results described detail matari 
average fifteen minute trial condition behavior finding food broadcast receiving message store location near stopped agent proceed near moving agent store behavior near stopped agent proceed near moving agent yield condition behavior pairings desired social policy 
run robots able learn foraging learning select appropriate individual behaviors state 
algorithm allow learning social rules social reinforcement introduced 
tested reinforcement functions 

ffd fio 
dov ffd fio weighting factors learning rules usually ad hoc 
approach uses simple scheme direct progress weighted highest observation induced experience vicarious reinforcement weighted 
second set experiments listed ff fi ff fi third set ff fi fl ff fi fi fl fl relative effectiveness reinforcement types evaluated portion social rule policy algorithms learned 
shows condition behavior pairings desired social policy 
evaluation metrics compare results different reinforcement 
percentage optimal social strategy agents managed learn 
relative amount time required learn 
relative absolute time duration learning run varies depending arrangement agents temporal distribution interactions 
consequently exact time convergence valid evaluation metric event driven situated environment kind 
relative average time hand gives measure comparative effectiveness different algorithms 
control experiment tested performance pre programmed foraging behavior contained reinforcement performance converge converge dov converges comparative performance different reinforcement functions 
desired social rules compared base case foraging 
surprisingly groups social rules outperformed groups greedy individual strategies 
convinced incentive learning social rules exist matter finding reinforcement strategy learnable environment 
shows preliminary convergence results 
convergence defined learning complete social policy 
results shown averaged multiple trials qualitative insufficient trials run perform accurate statistical analysis 
results performed trials consistent strategies converged learned small part policy 
third strategy converted sufficiently long trials trials required minutes converge 
trial duration issue case reinforcement strategies improve time uniformly failed converge regardless experiment duration 
duration learning direct effect physical hardware run learning experiments domain unavoidable intermittent error noise 
instance agents behave consistently due inability accurately sense external state 
unavoidable undetectable errors generated unintentional robots experiencing sensor error cases radio transmission delay communication occasionally failed behave socially 
effects disable learning algorithm slow described 
basic learning algorithm designed adapt lifetime agent learning suffer long term consequences intermittent errors 
terms speed learning social condition behavior pairs consistently ranked increasing order difficulty shown 
ordering directly reflects immediacy reward associated social behavior 
rules produce immediate reward learned fastest 
social rule sharing information food far hardest learn benefit agent direct payoff 
consequently required multiple instances observational reinforcement condition behavior near stopped agent proceed near stopped agent proceed receiving message store location near moving agent store behavior near moving agent yield finding food broadcast relative difficulty condition action pair increasing order 
gated exploration behavior 
attempting agent received immediate vicarious reinforcement agents received message learned store information receiving positive reinforcement passing agent originally broadcast information 
effect eliminated agents learning experts interested having social rules emerge homogeneous group 
proposed observational vicarious reinforcement strategies coupled direct reinforcement effective enabling learning social rules effectiveness varied depending rule learned 
unexpected rules certainly harder 
difficult certain learning problems particularly altruistic social rules indicates best learned genetically 
data biology support intuition animals appear learn altruism kin endowed mcfarland 
results preliminary glimpse wide variety social rules learned forms social reinforcement worth exploring 
order properly evaluate theories currently implementing battery tests produce amount learning data allows draw statistically significant 
summary continuing focused learning social rules situated multi agent domains 
studied difficulty learning behaviors direct benefit agent contradiction basic greedy survival instincts 
postulated types reinforcement useful possibly necessary learning social rules 
tested postulate applying effective situated learning algorithm social learning problem adding proposed types reinforcement 
demonstrated algorithms implementing group au mobile robots capable communication cooperation task learning yielding sharing information 
interested expanding number directions 
particular interesting consider variations learning experiments gathering task multiple food home regions order study kinds specializations emerge agents affect resulting social rules 
test social reinforcement strategies quite different types tasks order see general 
area interested exploring learning distinguish aspects situation state relevant context learning relevant group sizes dominance hierarchies 
turns difficult learn give idea types biases may genetically programmed 
progress 
data comparison evaluation different learning strategies pending gathered gradually 
full statistical analysis complete set experiments order preparation 
believe preliminary results give new insight difficult certain types social learning may may go synthesizing artificial agents order study biological mechanisms interaction social learning 
author wishes simon goss anonymous reviewer detailed helpful comments earlier draft 
research reported done mit artificial intelligence laboratory 
support research provided part jet propulsion laboratory contract part advanced research projects agency office naval research 
axelrod 
evolution cooperation basic books new york 
brooks 
hardware retargetable distributed layered architecture mobile robot control ieee international conference robotics automation raleigh nc pp 

brooks 
behavior language user guide technical report aim mit artificial intelligence lab 
chapman kaelbling 
input generalization delayed reinforcement learning algorithm performance comparisons proceedings ijcai sydney australia 
chase 
dynamics hierarchy formation sequential development dominance relationships behaviour 
chase rohwer 
methods quantifying development dominance large groups application harris animal behavior 
cheney 
monkeys see world university chicago press chicago 
chris langton 
artificial life addison wesley 
davis 
imitation review critique eds perspectives ethology vol 
plenum press 
deneubourg goss pasteels 
self organization mechanisms ant societies ii learning foraging division labor individual collective behavior social insects 
durfee lee gmytrasiewicz 
reciprocal rationality mixed strategy equilibria proceedings aaai washington dc pp 


observational learning octopus sci 
gasser huhns 
distributed artificial intelligence pitman london 
gould 
ethology mechanisms evolution behavior norton new york 
huber durfee 
observational uncertainty plan recognition interacting robots proceedings ijcai workshop dynamically interacting robots chambery france pp 

kraus 
agents contracting tasks non collaborative environments proceedings aaai washington dc pp 


evolution communication population simple machines technical report computer science department technical report cs university tennessee 
maes brooks 
learning coordinate behaviors proceedings aaai boston ma pp 

mahadevan connell 
automatic programming behavior robots reinforcement learning proceedings aaai pittsburgh pa pp 

matari 
designing emergent behaviors local interactions collective intelligence animals animats international conference simulation adaptive behavior 
matari 
kin recognition similarity group behavior proceedings fifteenth annual conference cognitive science society boulder colorado pp 

matari 
reward functions accelerated learning proceedings eleventh international conference machine learning ml 
mcfarland 
animal behavior benjamin cummings 
mcfarland 
oxford companion animal behavior oxford university press 
miceli cesta 
strategic social planning looking willingness multi agent domains proceedings fifteenth annual conference cognitive science society boulder colorado pp 

mitchell 
comparative developmental approach understanding imitation eds perspectives ethology vol 
plenum press 
moore 
avian movement imitation new form mimicry tracing evolution complex form learning behavior 
sutton 
learning predict method temporal differences journal machine learning 
tomasello kruger 
cultural learning appear journal brain behavior sciences 

