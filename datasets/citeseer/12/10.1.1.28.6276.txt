appears proceedings usenix annual technical conference june 
proportional share resource management provides flexible useful abstraction multiplexing resources 
previous proportional share mechanisms weak proportional sharing accuracy high scheduling overhead 
virtual time round robin vtrr proportional share scheduler provide proportional sharing accuracy scheduling overhead 
vtrr achieves combining benefits fair queueing algorithms round robin scheduling mechanism 
schedulers vtrr simple implement 
implemented vtrr cpu scheduler linux lines code 
performance results demonstrate vtrr provides accurate proportional share allocation constant sub microsecond scheduling overhead 
scheduling overhead vtrr orders magnitude standard linux scheduler large numbers clients 
proportional share resource management provides flexible useful abstraction multiplexing scarce resources users applications 
basic idea client associated weight resources allocated clients proportion respective weights 
usefulness proportional share scheduling mechanisms developed :10.1.1.47.4990
addition higher level abstractions developed top proportional share mechanisms support flexible modular resource management policies 
proportional share scheduling mechanisms developed decades ago weighted round robin scheduling 
fair share algorithms controlling priority values developed incorporated unix operating systems 
earlier mechanisms typi virtual time round robin proportional share scheduler jason chris hua zhong department computer science columbia university cs columbia edu cally fast requiring constant time select client execution 
limited accuracy achieve proportional sharing 
result starting late fair queueing algorithms developed network packet scheduling cpu scheduling 
algorithms provided better proportional sharing accuracy 
time select client execution algorithms grows number clients 
implementations require linear time select client execution 
server systems may service large numbers clients scheduling overhead linear time algorithms waste percent system resources large numbers clients 
hierarchical data structures reduce selection time complexity generally efficient practice 
add implementation complexity performance depends able balance data structures efficiently 
introduce vtrr virtual time round robin scheduler proportional share resource management 
vtrr combines benefits low overhead round robin execution high accuracy allocations 
provides accurate control client computation rates schedule clients execution time 
constant scheduling overhead vtrr particularly suitable server systems manage large numbers clients 
vtrr simple implement easily incorporated existing scheduling frameworks commercial operating systems 
implemented prototype vtrr cpu scheduler linux lines code 
compared vtrr linux prototype schedulers commonly practice research including standard linux scheduler fair queueing 
performance results micro benchmarks real applications demonstrate vtrr delivers excellent proportional share control lower scheduling overhead approaches 
organized follows section dis background related 
section presents vtrr scheduling algorithm 
section describes prototype linux implementation 
section presents performance results simulation studies real kernel measurements compare vtrr weighted round robin fair queueing standard linux scheduling 
concluding remarks directions 
background previous proportional sharing mechanisms classified categories fast weaker proportional fairness guarantees map existing scheduler frameworks current commercial operating systems defined proportional fairness guarantees strong proportional fairness guarantees higher scheduling overhead weaker proportional fairness guarantees higher scheduling overhead 
categories correspond round robin fair queueing lottery mechanisms 
discuss different approaches section simple proportional share model scheduling time multiplexed resource precisely define notion proportional fairness 
sections background explain round robin fair share fair queueing lottery sharing mechanisms detail 
briefly mention related section 
proportional fairness proportional share scheduling clear colloquial meaning set clients associated weights proportional share scheduler allocate resources client proportion respective weight 
term share weight interchangeably 
loss generality model process scheduling time multiplexed resource set clients steps scheduler orders clients queue scheduler runs client queue time quantum maximum time interval client allowed run scheduling decision 
note time quantum typically expressed time units constant size determined hardware 
result refer units time quanta time units tu absolute time measure seconds 
scheduler model scheduler achieve proportional sharing ways 
way adjust frequency client selected run adjusting position client queue ends front queue 
way adjust size time quantum client runs longer allocation 
manner scheduler determines client runs long client runs directly affects accuracy scheduling overhead scheduler 
proportional share scheduler accurate allocates resources manner proportionally fair 
formalize notion proportional fairness technical terms 
definition simple suffices discussion extended definitions 
definition draws heavily ideal sharing mechanism gps 
simplify discussion assume clients sleep block consume resources allocated 
define perfect fairness ideal state client received service exactly proportional share 
denote proportional share client sa amount service received client time interval wa 
formally proportional sharing algorithm achieves perfect fairness time interval client wa sa si ideal system clients consume resource allocations simultaneously ideal proportional share scheduler maintain relationship time intervals 
scheduling time multiplexed resource time units finite size possible scheduler perfectly proportionally fair defined equation intervals 
real world scheduling algorithm maintain perfect fairness algorithms stay closer perfect fairness 
evaluate fairness performance proportional sharing mechanism quantify close algorithm gets perfect fairness 
variation equation define service time error ea client interval 
error difference amount time allocated client interval algorithm amount time allocated ideal scheme maintains perfect fairness clients intervals 
service time error computed ea wa sa si positive service time error indicates client received ideal share interval negative error indicates client received 
precise error ea measures time client received ideal allocation 
goal proportional share scheduler minimize allocation error clients 
context consider effectively different classes proportional share algorithms minimizing allocation error 
round robin oldest simplest widely proportional share scheduling algorithms round robin 
clients placed queue allowed execute turn 
client shares equal client assigned size time quantum 
weighted round robin case client assigned time quantum equal share 
client larger share effectively gets larger quantum client small share 
weighted round robin wrr provides proportional sharing running clients frequency adjusting size time quanta 
variant called deficit round robin developed network packet scheduling similar behavior weighted round robin cpu scheduler 
wrr simple implement schedules clients time 
relatively weak proportional fairness guarantee service ratio error quite large 
consider example clients shares respectively 
wrr execute clients order time units error example gets low tu high tu 
real trouble comes large share values shares previous example changed error ranges tu 
large error range illustrates major drawback round robin scheduling client gets service due clients get service 
client received service ahead ideal allocation high positive error clients allocations low negative errors 
fair share fair share schedulers arose result need provide proportional sharing users way compatible unix style time sharing framework 
unix time sharing scheduling done multi level feedback set priority queues 
client priority adjusted executes 
scheduler executes client highest priority 
idea fair share provide proportional sharing users adjusting priorities user clients suitable way 
fair share provides proportional sharing effectively running clients different frequencies opposed wrr adjusts size clients time quanta 
fair share schedulers compatible unix scheduling frameworks relatively easy deploy existing unix environments 
round robin scheduling focus providing proportional sharing groups users opposed individual clients 
approaches ad hoc difficult formalize proportional fairness guarantees provided 
empirical measurements show approaches provide reasonable proportional fairness relatively large time intervals 
certainly case allocation errors approaches large 
priority adjustments done fair share schedulers generally computed quickly time 
cases schedulers need expensive periodic re adjustment client priorities required time number clients 
fair queueing fair queueing proposed demers network packet scheduling weighted fair queueing wfq extensive analysis provided parekh gallager applied waldspurger weihl cpu scheduling stride scheduling 
wfq introduced idea virtual finishing time vft proportional sharing scheduling 
explain vft explain notion virtual time 
virtual time client measure degree client received proportional allocation relative clients 
client executes virtual time advances rate inversely proportional client share 
words virtual time client time ratio wa sa wa sa client virtual time client virtual finishing time vft defined virtual time client executing time quantum 
wfq schedules clients selecting client smallest vft 
implemented keeping ordered queue clients sorted smallest largest vft selecting client queue 
client executes vft updated client inserted back queue 
position queue determined updated vft 
fair queueing provides proportional sharing running clients different frequencies adjusting position client inserted back queue size time quantum clients 
illustrate works consider example clients shares respectively 
initial respectively 
wfq execute clients order time units contrast wrr wfq service time error ranges tu example allocation error tu wrr 
difference wfq wrr greatly exaggerated larger share values chosen shares wfq service time error range wrr error range balloons tu 
shown wfq guarantees service time error client falls means client fall ideal allocation single time quantum 
fair queueing algorithms provide accurate proportional sharing guaranteeing upper bound error expense additional scheduling overhead 
fair queueing provides stronger proportional fairness guarantees round robin fair share scheduling 
unfortunately fair queueing difficult implement time takes select client execute time implementations number clients 
complex data structures possible implement fair queueing selection client requires logn time 
added difficulty managing complex data structures kernel space causes implementers fair queueing choose straightforward implementation 
lottery lottery scheduling proposed waldspurger weihl wfq developed 
lottery scheduling client number tickets proportional share 
ticket randomly selected scheduler client owns selected ticket scheduled run time quantum 
fair queueing lottery scheduling provides proportional sharing running clients different frequencies adjusting position client inserted back queue size time quantum typically clients 
lottery scheduling somewhat simpler implement fair queueing high scheduling overhead fair queueing implementations logn complex data structures 
lottery scheduling relies law large numbers providing proportional fairness accuracy worse wfq worse wrr smaller share values 
related higher level resource management abstractions developed number abstractions proportional share scheduling mechanisms 
complementary focus underlying scheduling mechanisms 
scheduling done supporting clients real time requirements improving response time interactive clients 
considering issues depth scope 
vtrr scheduling vtrr accurate low overhead proportional share scheduler multiplexing time shared resources set clients 
vtrr combines benefit low overhead round robin scheduling high accuracy mechanisms virtual time virtual finishing time fair queueing algorithms 
high level vtrr scheduling algorithm briefly described steps 
order clients run queue largest smallest share 
fair queueing client position run queue changes share changes infrequent event scheduling decision 

starting run queue run client time quantum round robin manner 
vtrr uses fixed ordering property round robin order choose constant time client run 
round robin time quantum size clients 

step client received proportional allocation skip remaining clients run queue start running clients run queue 
clients larger share values placed queue allows get service lower share clients queue 
provide depth description vtrr define state vtrr associates client describe precisely vtrr uses state schedule clients 
vtrr client values associated execution state share virtual finishing time time counter id number run state 
client share defines resource rights 
client receives resource allocation directly proportional share 
client virtual finishing time vft defined way section 
client vft implicit virtual time 
client vft advances rate proportional resource consumption divided share 
vft decide vtrr reset client queue 
described greater detail section 
client time counter ensures pattern allocations periodic perfect fairness achieved period 
specifically time counter tracks number quanta client receive period perfect fairness reached 
client id number unique client identifier assigned client created 
client run state indication client executed 
client runnable executed runnable 
example cpu scheduler client runnable blocked waiting execute 
basic vtrr algorithm initially consider runnable clients discussion basic vtrr scheduling algorithm 
discuss dynamic changes client run state section 
vtrr maintains scheduler state time quantum run queue total shares queue virtual time 
discussed section time quantum duration standard time slice assigned client execute 
run queue sorted queue runnable clients ordered largest smallest share client 
ties broken arbitrarily client id numbers unique 
total shares sum shares runnable clients 
queue virtual time qvt measure client vft received exactly proportional share allocation 
previous domain packet scheduling provides theoretical basis qvt 
qvt advances client executes rate inversely proportional total shares 
denote system time quantum share client si qvt updated follows qvt qvt si difference qvt client virtual time measure respective client consumed proportional allocation resources 
client virtual time equal queue virtual time considered received proportional allocation resources 
earlier virtual time indicates client proportional share 
sim virtual time indicates proportional share 
qvt advances rate clients run queue relative magnitudes virtual times provide relative measure degree client received proportional share resources 
explain role time counters vtrr 
relation define scheduling cycle sequence allocations length equal sum client shares 
example queue clients shares scheduling cycle sequence allocations 
time counter client reset scheduling cycle client share value decremented time client receives time quantum 
vtrr uses time counters ensure perfect fairness attained scheduling cycle 
cycle counter zero meaning client number quanta received cycle exactly sa client share value 
clearly client received service proportional share 
order guarantee counters zero cycle enforce invariant queue called time counter invariant require consecutive clients queue counter value greater counter value vtrr scheduling algorithm starts run queue executes client time quantum 
refer client selected execution current client 
current client completed time quantum time counter decremented vft incremented time quantum divided share 
denote system time quantum current client share sc current client vft updated follows sc scheduler moves client run queue 
scheduler checks violation time counter invariant counter value client greater counter current client scheduler client current client executes quantum question 
causes counter decremented preserving invariant 
client counter greater current client counter time counter invariant violated client run scheduler decision virtual time scheduler compares vft client qvt system time quantum client executes 
call comparison vft inequality 
denote system time quantum current client vft share sc vft inequality true qvt sc vft inequality true scheduler selects executes client run queue time quantum process repeats subsequent clients run queue 
scheduler reaches point run queue vft inequality true scheduler returns run queue selects client execute 
scheduling cycle time counters clients reach zero time counters reset initial values corresponding respective client share scheduler starts run queue select client execute 
note scheduling process ordering clients run queue change 
illustrate works consider example clients shares respectively 
initial respectively 
vtrr execute clients repeating order time units contrast wrr wfq vtrr maximum allocation error tu example 
allocation error better wrr comparable wfq 
vtrr simply selects client turn execute selecting client execution done time 
defer detailed discussion complexity vtrr section 
vtrr dynamic considerations previous section basic vtrr scheduling algorithm discuss vtrr deals dynamic considerations necessary part line scheduling algorithm 
discuss vtrr allows clients dynamically created terminated change run state change share assignments 
distinguish clients runnable runnable 
mentioned earlier clients runnable selected execution scheduler clients runnable 
runnable clients placed run queue 
loss generality assume client created runnable client runnable terminated 
result client creation termination affect vtrr run queue 
client runnable inserted run queue run queue remains sorted largest smallest share client 
ties broken arbitrarily unique client id numbers 
issue remains determine new client initial vft 
client created runnable consumed resources proportional share terms resource consumption 
result set client implicit virtual time qvt 
calculate vft new client share sa qvt sa client executed may runnable 
client current client runnable preempted client selected scheduler basic algorithm described section 
client runnable removed run queue 
client runnable current client client simply removed run queue 
client runnable vft updated 
client removed run queue records client run queue client run queue 
refer clients previous client client respectively 
client runnable runnable vtrr inserts runnable client back run queue 
client client valid determine position run queue 
previous valid vtrr simply traverses run queue find insertion point runnable client 
determining previous valid done efficiently follows 
previous client valid clients exited runnable clients run queue share newly runnable client previous client client 
care taken ensure previous valid dereferencing client exited deallocated previous may longer refer valid memory regions 
deal hash table kept stores identifiers valid clients 
hash function collisions resolved simple replacement table implemented array identifiers 
client identifier put table created deleted client exits 
previous pointers dereferenced identifier previous clients exist hash table 
described section hash table necessary linux vtrr implementation 
runnable client inserted run queue client vft updated 
update analogous vft initialization new client runnable 
difference account client original vft updating vft 
denote original vft client client vft updated follows max treats client runnable new client executed 
time system keeps track client vft proportional allocation game system making runnable runnable 
analogous policy set initial value client time counter 
client time counter tracks number quanta due client current scheduling cycle reset new cycle 
set time counter newly inserted client value give correct proportion remaining quanta cycle 
counter ca new client computed ca sa si sa ci note computed client inserted sa included si summation 
value modified rule similar rule enacted vft require client come back cycle receive larger time count previously 
client inserted cycle removed counter set minimum ca previous counter value 
preserve time counter invariant described section counter value restricted time counter values clients inserted client 
client share changes cases consider run state client 
client runnable run queue modifications needed 
client runnable share changes client position run queue may need changed 
operation simplified removing client run queue changing share 
removal insertion performed just described 
complexity primary function scheduler select client execute resource available 
key benefit vtrr select client execute time 
vtrr simply maintain sorted run queue clients keep track current position run queue 
updating current run queue position updating client vft time operations 
run queue needs sorted client shares ordering clients run queue change normal process selecting clients execute 
important advantage fair queueing algorithms client needs reinserted sorted run queue time executes 
result fair queueing higher complexity vtrr requiring time select client execute logn time complex data structures rarely implemented practice 
clients run queue zero counter values vtrr resets counter values clients run queue 
complete counter reset takes time number clients 
reset done times scheduler selects client execute frequently practice 
result reset time counters amortized client selections effective running time vtrr time 
addition counter resets done incrementally pass run queue new counter values 
addition selecting client execute scheduler allow clients dynamically created terminated change run state change scheduling parameters client share 
scheduling operations typically occur frequently client selection 
vtrr operations client creation termination done time directly affect run queue 
changing client run state runnable runnable done time reasonable run queue implementation involves removing respective client run queue 
scheduling operations highest complexity involve changing client share assignment changing client run state runnable 
particular client typically runnable created operation waiting completes 
client share changes client position run queue may change 
client runnable client inserted run queue proper position share 
doubly linked list run queue implementation insertion sorted queue require time number runnable clients 
priority queue implementation run queue reduce insertion cost logn probably better performance simple sorted list practice 
queue insertion required frequently client selection practice queue insertion cost dominate scheduling cost 
particular constant number queue insertions required times client selection done effective cost queue insertions time 
furthermore common scheduling operation require queue insertion client runnable blocked waiting resource 
case insertion overhead time previous client client remain valid queue insertion time 
valid position client known run queue scheduler find insertion point 
alternative implementation done allows queue insertions done time range share values fixed advance 
idea similar priority schedulers fixed range priority values separate run queue priority 
priorities separate run queue share value keep track run queues array 
find queue corresponding client share insert client corresponding queue time 
implementation maps scheduling frameworks number commercial operating systems including solaris windows nt 
implementation implemented prototype vtrr cpu scheduler linux operating system 
red hat linux version distribution linux version kernel 
add modify lines kernel code complete vtrr scheduler implementation 
describe linux vtrr implementation detail illustrate easy vtrr implement 
scheduling frameworks commonly commercial operating systems 
vtrr multiprocessor scheduling context discuss single cpu implementation 
linux scheduling framework single cpu run queue implemented single doubly linked list 
describe standard linux scheduler works discusses changes implement vtrr linux 
standard linux scheduler multiplexes set clients assigned different priorities 
priorities compute client measure called goodness schedule set clients 
time scheduler called goodness value client run queue calculated 
client highest goodness value selected client execute 
case ties client highest goodness value selected 
goodness client calculated time scheduler called scheduling overhead linux scheduler number runnable clients 
standard way linux calculates goodness clients client priority counter 
counter time counter value vtrr measure remaining time left client time quantum 
standard time unit linux counter time quantum called ms default 
basic idea goodness client priority plus counter value 
client counter initially set equal client priority value default 
time client executed client counter decremented 
client counter decremented drops zero point client selected execute 
result default time quantum client ms counters runnable clients drop zero scheduler resets counters initial value 
additional logic support static priority realtime clients clients runnable overview basic way linux scheduler works sufficient discussion 
details available 
implement vtrr linux reused existing scheduling infrastructure 
doubly linked list run queue structure standard linux scheduler 
primary change run queue sorting clients largest smallest share 
scanning clients scheduling decision needs vtrr linux implementation simply picks client run queue vtrr scheduling algorithm 
linux scheduler relevant smallest counter value may assigned client 
means smallest time quantum client 
provide comparable implementation vtrr default time quantum vtrr implementation ms addition vtrr client state fields added standard client data structure linux previous pointers optimize run queue insertion efficiency 
linux kernel memory client data structures statically allocated reclaimed new client data structures 
implementation free previous pointers check validity refer client data hash table method described section unnecessary 
measurements results demonstrate effectiveness vtrr quantitatively measured compared performance leading approaches industrial practice research 
conducted extensive simulation studies detailed measurements real kernel scheduler performance real applications 
conducted simulation studies compare proportional sharing accuracy vtrr wrr wfq 
simulator studies reasons 
simulator enabled isolate impact scheduling algorithms purposefully include effects activity actual kernel implementation 
second simulator enabled examine scheduling behavior different algorithms hundreds thousands different combinations clients different share values 
difficult obtain volume data repeatable fashion just measurements kernel scheduler implementation 
simulation results section 
conducted detailed measurements real kernel scheduler performance comparing prototype vtrr linux implementation standard linux scheduler wfq scheduler 
particular comparing standard linux scheduler measuring performance important growing popularity platform server desktop systems 
experiments done quantify scheduling overhead proportional share allocation accuracy schedulers real operating system environment number different workloads 
measurements kernel scheduler performance sections 
kernel scheduler measurements performed gateway system mhz intel celeron cpu mb ram gb hard drive 
system installed red hat linux distribution running linux version kernel 
measurements done minimally intrusive tracing facility logs events significant points application operating system code 
done light weight mechanism writes timestamped event identifiers memory log 
mechanism takes advantage high resolution clock cycle counter available intel cpu provide measurement resolution granularity nanoseconds 
getting timestamp simply involved reading hardware cycle counter register read user level kernel level code 
measured cost mechanism system roughly ns event 
kernel scheduler measurements performed fully functional system represent realistic system environment 
fully functional mean experiments performed system functions running system connected network 
time effort eliminate variations test environment experiments repeatable 
simulation studies built scheduling simulator evaluate proportional fairness vtrr comparison schedulers wrr wfq 
simulator user space program measures service time error described section scheduler set clients 
simulator takes inputs scheduling algorithm number clients total number shares number client share combinations 
simulator randomly assigns shares clients scales share values ensure sum schedules clients specified algorithm real scheduler tracks resulting service time error 
simulator runs scheduler resulting schedule repeats computes maximum positive minimum negative service time error portion schedule set clients share assignments 
simulator assumes clients runnable times 
process random share allocation scheduler simulation repeated specified number client share combinations 
compute average highest service time error average lowest service time error specified number client share combinations obtain average case error range 
measure proportional fairness accuracy ran simulations scheduling algorithm considered different combinations set ran client share combinations determined resulting average error ranges 
average service time error ranges vtrr wrr wfq shown figures 
shows comparison error ranges vtrr versus wrr graph showing error ranges vtrr showing error ranges wrr 
graph shows surfaces plotted axes scale representing maximum mini sum shares error error sum shares wrr error range number clients vtrr error range number clients vtrr vs wrr service time error mum service time error function range values shown wrr error range reaches low tu high tu 
time units expressed ms linux client wrr average get ahead correct cpu time allocation seconds seconds substantial amount service time error 
contrast shows vtrr smaller error range wrr accurate 
error axis scaled display wide range wrr error values difficult distinguish surfaces vtrr 
vtrr service time error ranges tu seen clearly 
shows comparison error ranges vtrr versus wfq graph showing error ranges vtrr showing error ranges wfq 
case graph shows surfaces plotted axes scale representing maximum minimum service time error function vtrr graph includes data vtrr graph error axis scaled naturally 
range values shown wfq average error range reaches low tu high tu opposed error sum shares error sum shares wfq error range number clients vtrr error range number clients vtrr vs wfq service time error vtrr error range tu 
error ranges wfq smaller vtrr difference wfq vtrr smaller difference vtrr wrr 
time units expressed ms linux client wfq average get ahead correct cpu time allocation ms ms client vtrr get ahead ms ms cases service time errors small 
fact service time errors threshold delay noticeable human beings response time interactive applications 
note fair queueing algorithm wf simulated error mathematically bounded tu similar wfq practice 
data produced simulations confirm vtrr fairness properties better wrr nearly wfq 
domain values simulated service time error vtrr falls average range orders magnitude smaller wrr error range 
vtrr error range quite wfq largest error measured tu unnoticeable applications size time unit schedulers 
furthermore show section average scheduling cost linux wfq wfq log vtrr number clients average scheduling overhead vtrr provides degree accuracy lower overhead wfq 
scheduling overhead evaluate scheduling overhead vtrr implemented vtrr linux operating system compared overhead prototype vtrr implementation overhead linux scheduler wfq scheduler 
conducted series experiments quantify scheduling overhead scheduler varies number clients increases 
experiment client executed simple micro benchmark performed operations loop 
control program fork specified number clients 
clients runnable measured execution time scheduling operation occurred fixed time duration seconds 
done inserting counter timestamped event identifiers linux scheduling framework 
measurements required timestamps scheduling decision variations ns possible due measurement overhead 
performed experiments standard linux scheduler wfq vtrr client clients 
shows average execution time required scheduler select client execute 
experiment particular implementation details wfq scheduler affect overhead include results different implementations wfq 
labeled wfq run queue implemented simple linked list searched scheduling decision 
second labeled wfq logn uses heap priority queue logn insertion time 
fair queueing schedulers implemented fashion due difficulty maintaining complex data structures kernel 
implementation example sep fixed length array necessary maintain heap priority queue 
number clients exceeds length array costly array reallocation performed 
chose initial array size large contain clients additional cost reflected measurements 
shown increase scheduling overhead number clients increases varies great deal different schedulers 
vtrr smallest scheduling overhead 
requires ns select client execute scheduling overhead essentially constant numbers clients 
contrast overhead linux wfq scheduling grows linearly number clients 
linux scheduler imposes times overhead vtrr scheduling mix clients 
fact linux scheduler spends times long scheduling single micro benchmark client vtrr scheduling clients 
vtrr outperforms linux wfq small numbers clients vtrr scheduling code simpler runs significantly faster 
vtrr performs better compared linux wfq large numbers clients constant time overhead opposed linear time overhead schedulers 
logn wfq smaller overhead linux wfq imposes significantly overhead vtrr particularly large numbers clients 
clients logn wfq overhead times vtrr 
wfq complex data structures require time maintain time required scheduling decision dependent number clients overhead continue grow worse clients added 
vtrr scheduling decisions take amount time regardless number clients 
microscopic view scheduling prototype vtrr implementation conducted number experiments measure scheduling behavior standard linux scheduler wfq vtrr fine time resolutions 
discuss results studies ran second workload micro benchmarks different proportional sharing parameters 
vtrr wfq ran micro benchmarks shares respectively 
provide similar proportional sharing behavior linux scheduler ran micro benchmarks user priorities respectively 
translates internal priorities scheduler respectively 
translates clients running ms ms ms ms ms time quanta respectively 
smallest time quantum schedulers 
mapping proportional sharing user input priorities non intuitive linux 
scheduling behavior workload appears similar schedulers viewed coarse granularity 
relative resource consumption rates micro benchmarks virtually identical respective shares coarse granularity 
see interesting behavior view measurements shorter time scale second 
show actual scheduling sequences scheduler time interval figures 
measurements sampling client execution client recording multiple high resolution timestamps time client executed 
see linux scheduler poorest job scheduling clients evenly predictably 
wfq vtrr better job scheduling clients proportionally fine granularity 
cases clear repeating scheduling pattern ms linux perfect repeating pattern order schedules clients changes depending exactly scheduler function called 
linux selects client execute preempt client goodness drops clients 
runs client counter drops zero interrupt scheduling event occurs 
scheduling event occurs linux consider goodness clients 
interrupts cause scheduling event occur arbitrary times resulting order clients scheduled repeating pattern 
result applications scheduled wfq vtrr receive level cpu service scheduled linux scheduler 
application workloads demonstrate vtrr efficient proportional sharing resources real applications briefly describe experiments running multimedia applications running virtual machines 
contrast performance vtrr versus standard linux scheduler wfq 
experiment performed run multiple mpeg audio encoders different shares schedulers 
encoder test implemented running copies mpeg audio encoder 
encoder clients allotted shares instrumented time stamp event client share client share client share execution time ms linux scheduling behavior execution time ms wfq scheduling behavior execution time ms vtrr scheduling behavior manner similar recorded time micro benchmark programs 
encoder took input file wrote output file 
mpeg audio encoded chunks called frames instrumented encoder records timestamp frame encoded allowing easily observe effect resource share single frame encoding time 
figures show number frames encoded time linux default scheduler wfq vtrr 
linux scheduler clearly provide sharing fairly wfq vtrr viewed short time interval 
staircase effect indicates cpu resources provided bursts time critical task audio streaming mean extra jitter resulting delays 
inferred smoother curves wfq vtrr graphs wfq vtrr scheduling provide fair resource allocation smaller granularity 
analyzed fine resolution detect differences proportional sharing behavior applications running wfq versus vtrr difference far smaller difference compared linux clearly visible 
vtrr trades precision instantaneous proportional fairness lower scheduling overhead 
schedulers explicitly support time constraints effective job just proportional share schedulers ensuring real time applications meet deadlines 
real time schedulers typically require modifying application order application time constraints 
applications soft timing constraints adapt availability resources accurate proportional sharing may provide sufficient benefit cases cost having modify applications 
experiment performed run vmware virtual machines top linux operating system compare performance applications virtual machines virtual machines scheduled different schedulers 
experiment ran virtual machines simultaneously respective shares 
executed simple timing benchmark virtual machine measure relative performance virtual machine 
careful hardware clock cycle counters doing measurements standard operating system timing mechanisms virtual machine poor measure elapsed time 
conducted experiment standard linux scheduler wfq vtrr 
results similar previous experiments linux doing worst job terms evenly distributing cpu cycles vtrr wfq scheduling providing comparable schedul mpeg frames rendered mpeg frames rendered mpeg frames rendered share share share share share time ms mpeg encoding linux share share share share share time ms mpeg encoding wfq share share share share share time ms mpeg encoding vtrr ing accuracy proportionally allocating resources 
designed implemented evaluated virtual time round robin scheduling linux operating system 
experiences vtrr show simple implement easy integrate existing commercial operating systems 
measured performance linux implementation demonstrated vtrr combines benefits accurate proportional share resource management low overhead 
results show vtrr scheduling overhead constant large numbers clients 
despite popularity linux operating system results show standard linux scheduler suffers scheduling overhead performs worse vtrr especially larger workloads 
vtrr ability provide low overhead proportional share resource allocation particularly promising solution managing resources large scale server systems 
systems typically multiprocessor machines continuing evaluation vtrr multiprocessor context demonstrate effectiveness supporting large numbers users applications systems 
acknowledgments anonymous referees helpful comments earlier drafts 
supported part nsf eia nsf career award 
banga druschel mogul resource containers new facility resource management server systems proceedings rd symposium operating design implementation usenix berkeley ca feb pp 

beck linux kernel internals 
reading ma addison wesley nd ed 
bennett zhang wf worst case fair weighted fair queueing proceedings infocom san francisco ca mar 
jeffay support real time computing general purpose operating systems supporting operating systems proceedings real time technology applications symposium ieee computer society press spring street suite silver spring md usa pp 

bryant java technology threads scheduling linux ibm developerworks library ibm linux technology center jan 
coulson campbell robin blair papathomas hutchinson design qos controlled atm communication system chorus ieee journal selected areas communications jsac may pp 

custer inside windows nt 
redmond wa usa microsoft press 
demers keshav shenker analysis simulation fair queueing algorithm proceedings acm sig comm austin tx sept pp 

duda cheriton borrowed virtual time bvt scheduling supporting latency sensitive threads general purpose scheduler proceedings th symposium operating systems principles acm press new york dec pp 

event fair share scheduler proceedings winter usenix conference usenix berkeley ca usa jan pp 

evans clarke singleton optimizing unix resource scheduling user interaction summer usenix usenix june pp 

gafni bertsekas dynamic control session input rates communication networks ieee transactions automatic control pp 

golub operating system support coexistence real time conventional scheduling tech 
rep cmu cs school computer science carnegie mellon university nov 
goyal guo vin hierarchical cpu scheduler multimedia operating system proceedings second symposium operating systems design implementation usenix berkeley ca oct pp 

gallager round robin scheduling fair flow control data communication networks tech 
rep lids th laboratory information decision systems massachusetts institute technology dec 
henry fair share scheduler bell laboratories technical journal oct pp 

jones ros ros cpu reservations time constraints efficient predictable scheduling independent activities proceedings th symposium operating systems principles acm press new york oct pp 

kay fair share scheduler communications acm jan pp 

kleinrock queueing systems volume ii computer applications 
new york john wiley sons 
lehoczky sha ding rate monotonic scheduling algorithm exact characterization average case behavior proceedings real time systems symposium ieee computer society press santa monica california usa dec pp 

liu layland scheduling algorithms multiprogramming hard real time environment journal acm jan pp 

locke best effort decision making real time scheduling 
phd thesis department computer science carnegie mellon university may 
mercer savage tokuda processor capacity reserves operating system support multimedia applications proceedings international conference multimedia computing systems ieee computer society press spring street suite silver spring md usa pp 

lam design implementation evaluation smart scheduler multimedia applications proceedings th symposium operating systems principles acm press new york oct pp 

parekh gallager generalized processor sharing approach flow control integrated services networks single node case ieee acm transactions networking june pp 

ramakrishnan chiu jain congestion avoidance computer networks connectionless network layer part iv selective binary feedback scheme general topologies tech 
rep dec tr dec nov 
shneiderman designing user interface strategies effective human computer interaction 
reading ma addison wesley nd ed 
varghese efficient fair queueing deficit round robin proceedings acm sigcomm sept pp 

silberschatz operating system concepts 
reading ma usa addison wesley th ed 
stoica abdel jeffay duality resource reservation proportional share resource allocation multimedia computing networking proceedings spie proceedings series feb pp 

unix system release internals student guide vol 
unit 
chairman assignment problem discrete mathematics pp 

waldspurger lottery stride scheduling flexible proportional share resource management 
phd thesis department electrical engineering computer science massachusetts institute technology sept 
zhang virtual clock new traffic control algorithm packet switched networks acm transactions computer systems may pp 


