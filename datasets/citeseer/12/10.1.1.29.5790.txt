fractal encoding context free grammars connectionist networks whitney university connecticut expert systems pp 
please address correspondence whitney department psychology university connecticut ct usa phone fax edu connectionist network learning context free languages far applied simple cases external stack 
learning complex context free languages homogeneous neural mechanism looks harder problem 
current takes step solving problem analyzing context free grammar computation addressing learning class analog computers called dynamical automata naturally implemented connectionist networks 
result widely applicable method fractal sets organize infinite state computations bounded state space 
appealing development parameter space maps locate various complex computers spatial relationships 
example suggests global perspective organization parameter space may helpful solving hard problem getting connectionist networks learn complex grammars examples 

smolensky argues connectionist neural networks offer opportunity overcome brittleness symbolic devices foregoing powerful computational capabilities 
brittleness refers fact symbolic devices sensitive small distortions encoding bit semicolon place bring entire system knees 
sensitivity reminiscent trademark behavior chaotic dynamical processes small differences initial conditions give rise substantial differences long term behavior 
ironic interpretation connectionist devices dynamical systems potentially chaotic behaviors led realization smolensky ideal 
character number results connecting symbolic computation multi stable dynamical systems barnsley pollack moore blair pollack press tino dorffner tino 
fractal objects turn traces chaotic processes turn especially useful instantiating powerful computing devices metric space computers exhibit graceful modification small distortions 
embracing chaotic process computational system stay effective complexity cf 
crutchfield young crutchfield 
previous focused instantiate complex symbolic computers metric space computers connectionist networks 
current suggests useful contribution metric space perspective revelation geometric relationships familiar effective symbolic devices 
possible see global topological perspective symbolic computer gradually transformed 
fractals organize computation dynamical systems symbol processing jeffrey 
tino shown points fractals associated probabilities fractal dimension useful sense geometric analog entropy 
tino dorffner applied results connectionist networks learning unknown time series fractal structure set recurrent weights leads improvement simple recurrent network srn elman variable memory markov model approaches ron singer tishby 
current complements results analyzing connectionist representations specific infinite state languages 
number researchers studied induction context free grammars cfgs connectionist networks 
external stack giles sun chen lee chen sun chen giles lee chen das giles sun mozer das zheng goodman smyth 
standard architectures wiles elman rodriguez wiles elman 
cases simple context free languages learned 
desirable able handle complex languages 
desirable avoid external stack stack harder see relationship cfg nets homogeneous connectionist architectures network responsibility challenging part task keeping track unbounded memory making accomplishment fairly similar studied case learning finite state languages servan schreiber cleeremans mcclelland zheng casey 
takes step addressing shortcomings providing representational analysis neurally inspired devices called dynamical automata das recognize context free languages languages 
approach ambitious models just cited learning attempted 
hand ambitious representational analysis structural principles governing das corresponding networks computations formally worked context free languages 
essential principle consistent experiments pollack analysis moore fractal sets provide method organizing recursive computations bounded state space 
networks recurrent linear threshold activation functions gating units may stochastic units external stack 
representations das resemble representations developed elman simple recurrent network trained syntax tasks elman widely cognitive modeling suggesting set principles may useful building cognitively plausible neural models syntax 

overview section review previous studies fractal sets organize complex computation connectionist devices 
section investigates subclass dynamical automata called pushdown dynamical automata 
das emulate pushdown automata pdas closely related type dynamical recognizer moore proposed recognizing context free languages 
moore case dimensional describe higher dimensional species naturally implemented high dimensional connectionist networks 
section contains lemma helps choose appropriate initial conditions dynamical automata dynamical recognizers process context free languages 
section explicit go encoding dynamical automata connectionist networks 
section focuses appealing consequence performing complex computations metric space noted metric provides way mapping spatial relationships machines different computational properties 
examples section suggest maps may useful addressing difficult problem learning complex grammars data 

examples fractal computers 
example pollack pollack noted simple artificial neural device recognize dyck language language left parentheses precede corresponding right parentheses 
describes machine lines shown 
insert initially activation unit 
left parenthesis network activates unit effect allowing transmission activation connection labeled wl 
similarly right parenthesis network activates unit allows transmission activation connection labeled wr 
presentation symbol updates rule wl wr wl wr 
activation function equal equal 
unit threshold unit active 
unit self reinforcing threshold unit initially inactive active stays active exceeds 
unit threshold unit computes note unit activated string right parentheses follow match left parentheses 
processing grammatical strings activations unit lie geometric series fractal 
essence unit counter keeps track right parentheses required complete string point 
set non negative integers perform function bounded fractal permits connectionist device units bounded activation 
simple example provides indication fractal objects useful forming neural recognizers infinite state languages 

example rodriguez wiles elman wiles elman study backpropagation network trained samples closely related language 
model sequence randomly chosen iteration 
task model predict successor symbols point 
training episodes different initial weight settings wiles elman network generalized pattern performed recognizing 
rodriguez 
noted networks wiles elman viewed nonlinear dynamical systems 
analyzed corresponding linear systems closely approximated behavior nonlinear systems computation organized saddle point dimensions network see 
example system states consists positions water drop mountainous terrain 
gravity pulls water drop downhill times 
system receiving string iterating map associated stable manifold saddle point effect computing successive values kt initial state positive 
receiving corresponding string iterating map associated unstable manifold situation points spread different axis 
equally spaced values exponential equation kt generates points geometric series fractal 
parenthesis balancer geometric series fractals computation time different dimensions distinction dimensions handy way distinguishing states 
examples shown particular type fractal useful modeling parenthesis balancing languages 
helpful simple case 
examples describe complex cases 

example moore moore proposes dynamical recognizers compute metric space invoking distinct map fi symbol recognizer specified point starts reading string 
lands specified final region processing symbol string string deemed part language 
moore uses cantor sets strogatz construct recognizers onedimensional metric space context free language insert table number symbols stack alphabet 
initial state 
final region 
functions simulate pushdown stack symbols 
functions correspond push symbol stack pop symbol stack respectively 
shown pushdown automata generate languages subset control state changes hopcroft ullman 
context free languages generated device consists simply pushdown stack control rules 
composing appropriately moore functions build mechanism generating context free language 
technical details need looked 
moore recognizer detect illegal pop move form 
second guarantees sequence pushes pops uniquely associated point pass separating peaks valleys 
stable manifold peaks 
regarding question illegal pops moore mechanism cleverly designed allow easy detection illegal pops move partial move illegal form legal moves keep 
order allow device record information exceeded available string processed moore introduces new variable initial value updates max requiring processing string ensures moves performed pushdown stack operations 
regarding second question uniqueness choosing ensures stack state sequence symbols stack pda places dynamical recognizer unique point obvious 
consider case 
starting value stack states generate dynamical recognizer state 
means device fail distinguish stack states 
describe easily assessed condition section guarantees uniqueness 
implement complex grammar computation connectionist networks desirable dimensions 
initially random valued hidden unit dimensions crucial way gradient descent learning mechanisms backpropagation solve symmetry breaking problem rumelhart hinton williams 
bounded metric encoding infinite state language required precision grows exponentially level embedding required precision grows cardinality stack alphabet dimensional recognizer note moore multiple dimensions eliminate growth see section 
distributed representations advantages analogy robustness noise require multiple dimensions learning distributed representations stack memory single learning mechanism desirable express similar encoding 
example illustrates dynamical automaton method extending moore technique dimensions 

example sierpinski triangle shows diagram fractal called sierpinski triangle letter labels diagram explained presently 
sierpinski triangle kind cantor set limit process successively removing middle quarter triangle produce new triangles 
fact piecewise linear forms basis moore claim dynamical recognizer piecewise linear operations recognize context free language 
insert table grammar shown table context free grammar 
grammar generates strings standard manner hopcroft ullman denotes empty string 
examples strings generated grammar 
case illustrates center embedding 
pushdown automaton language grammar need keep track abcd string started completed 
purpose store symbol corresponding letter partially completed string pushdown stack 
example stored symbol embedding occurred embedding embedding stack states members 
sierpinski triangle keep track stack states grammar 
consider labeled triangle 
note labels midpoints label cb corresponds point 
labeling scheme organized member label midpoint stacks cardinality shown 
insert define dynamical automaton da recognizes language grammar input map shown table 
essence da element vector corresponding position sierpinski triangle 
da functions follows subset plane specified compartment column possible inputs shown input column 
compartment legal input compartment change results reading input shown state change column 
specify da start state changes rules table symbols read input string return final region symbol read computer functions recognizer language grammar 
see intuitively note subsequence form invokes identity map da equivalent nested finite state machine version grammar 
illustration trajectory corresponding string shown 

position symbol processed 
position second symbol processed insert table insert foregoing example illustrated dynamical automaton dynamical recognizer partition restricts function applications 
symbol give rise function application automaton appropriate compartment partition 
assumption consequence ungrammaticality string detected line dynamical automaton may detected final symbol processed dynamical recognizer 
sense dynamical automata closely related line connectionist recognizers simple recurrent networks srns elman 
fact representational standpoint computations dynamical automaton bear close resemblance empirically observed computations srns 
elman examined dimensional hidden unit space srn trained elaborate recursive languages different lexical classes corresponded different subregions space 
likewise example lexical classes correspond distinct regions representation space class member 
elman noted srn followed similarly shaped trajectories region region processing phrase particular type slight displacements differentiating successive levels embedding 
single phrase associated characteristic triangular trajectory occurs slight displacements differentiate successive levels embedding 
construct wide variety computing devices organize computations fractals 
heart fractal computer set iterating functions associated stable states analyzed tools dynamical systems theory barnsley 
name dynamical automaton 

general case method example extended context free languages 
sketch proof 
details provided appendix 
formal definition dynamical automaton def 

dynamical automaton device structure im fr space complete metric space 
function list consists finite number functions fk wi 
item need class occurrence puts computer state corresponding classes 
partition finite partition consists compartments mk 
input list finite set symbols drawn alphabet 
input mapping place relation im specifies compartment input symbol function performed symbol system state compartment im symbol system compartment 
machine starts start state successive symbols input string transitions consistent input mapping arrives final region fr input string accepted 
define special class dynamical automata behave pushdown automata 
easy way design dynamical automata travel fractals branches branches sierpinski triangle largest 
define automata way branches isolated linear separators ii branch corresponds stack symbol iii top stack symbol corresponding current branch implementation connectionist network facilitated network layer units encoding position fractal separate layer threshold units identifies top stack determining branch fractal system see section 
separation possible branches overlap 
constructs useful regard 
def 

generalized iterated function system gifs metric space set functions wn map 
system uniquely invertible wi uniquely invertible def 

wn gifs metric space string 
consider point string called address point set points reached initial state finite sequences applications functions called trajectory 
def 

point point trajectory unique address called cascade point 
case trajectory called cascade barnsley defines iterated function system ifs metric space finite set contraction maps gifs generalized sense mappings need contraction maps see example 

symbol address denoted 
set denotes empty string 
point cascade mapped unique stack state 
construct necessary able identify cascade points 
definition lemma help regard def 

wn gifs metric space set called pooling set satisfies wi wj 
ii wi means 
set points crest wi called lemma 
wn uniquely invertible gifs metric space suppose pooling set crest cascade point proof see appendix 
lemma easy identify cascade points gifs 
example establish uniqueness stack states specific example moore context free language recognizer example suffices note pooling set gifs set crest 
set moore give rise unique mapping stack states 
example extending slightly simplifying example stack alphabet symbols vector element equal 
function list defined wn en 
en vector th element equal elements equal 
see cascade point function list open unit hypercube positive quadrant corner origin 
th coordinate wn interval th coordinate wn wn wn wm wn pooling set function system lemma cascade point 
points trajectory correspond stack states alphabet 

current position fractal call corresponds current state stack 
define analogs push pop moves 
particular analog pushing symbol change state automaton wn 
analog popping symbol legally performed current branch fractal condition enforced input map consists changing state wn 
define special class dynamical automata called pushdown dynamical automata move cascade making analogs push pop moves 
central claim stated theorem 
set languages recognized pushdown dynamical automata set languages recognized pushdown automata pdas 
proof see appendix 
described invoke extra dimension representation stack symbol exhibit growth required precision cardinality stack alphabet increases see discussion example 
remainder section gives examples show results easy design pushdown dynamical automata various context free languages 

example simple recognizes 
im relevant parts partition shown table 
input mapping im shown table 
insert table case establish context free language status proof theorem appendix consider gifs 
note cascade points disjoint cascades condition definition 
cascades called respectively 
note partition compartment index 
index 
index 
index top top 
compartment predictable conjunction index value top case condition ii 
function restricted push function 
function restricted pop function 
function equal composition switch function pop function condition iii 
start points cascade points respectively condition iv satisfies definition 
recognizes context free language 
examples provided far functions underlying gifs contraction maps 
may wonder cascades arise standard iterated function systems la barnsley functions contraction maps 
case interesting counterexample 

example crutchfield young consider gifs functions maps interval maps interval pooling set point crest record stack states symbol alphabet start state 
contraction map 
example 
example interesting part inverses studied logistic map rx 
logistic map attracted attention relatively simple dimensional function chaotic trajectories see 
crutchfield young analyzed generator string considering letting 

called onset chaos set initial character substrings constitutes indexed context free language 
taken opposite tack inverting closely related map introduces allows distinguish histories map model arbitrary grammars instance inverted logistic suffices stack alphabets symbols multiple instances accomodate stack symbols 
loosely say crutchfield young analyzed chaotic map assess specific character complexity analysis yields way map perform general class computations similarly complex sort 
crutchfield young results interesting question canonical grammar associated value inverse logistic map device just referred 
may example languages corresponding inverse logistic automaton tolerant imprecision identification final region 
leave question research 

implementation connectionist network dynamical automata implemented connectionist networks combination signaling units gating units may stochastic 
signaling unit mean standard sort unit sends signal reflecting activation state units connected 
gating unit mean unit serves block allow transmission signal connection units 
stochastic unit mean weighted random choice finite number connections transmit signal 
units compute weighted sum inputs pass activation function identity threshold sigmoid place distortion computation due nonlinearity 
simple affine functions qz define state changes dynamical automaton simple translation network signaling gating units 
coefficients determine weights connections 
connections corresponding linear terms gated connections 
connections corresponding constant terms standard connections 
insert insert table connectionist implementation grammar shown 
table specifies weight values unit types 
network processes strings representing successive symbols localist bit vectors input layer units predicting possible successor symbols output layer units elman 
units form core network 
values point time specify coordinates current position sierpinski triangle 
multiple connections going 
example self connecting loops gate gate gate 
gates enabling threshold gates sense gate activated signal transmitted corresponding connection 
units ia ib ia id input units 
ib ia id activation input symbol respectively 
input symbol ia ia takes value positive probability stochastic neuron shown implements feature 
input unit interacts units ways opens gate self recurrent connections transmits weighted signal directly unit 
units take activations equal weighted sum inputs 
means principle activations unbounded computations take place bounded region perfect performance approximated quasi linear sigmoidal activation function linear region 
units threshold units serve translate activations binary values 
output units ob od threshold units respond units 
unit oa happens need time grammar inputs threshold 
output unit letter letters corresponding interpreted possible words 
string deemed grammatical step processing activated input unit predicted outputs previous step network arrives initial state word 
network handles ambiguity way pushdown automaton guessing 
example hand ambiguous symbol guesses evenly distributed network equal chance guessing wrong right time encounters ambiguous 
consider language generated network set strings deem grammatical instance may judge legal string ungrammatical 
context determines proper interpretation ambiguous symbol occuring initially generated rule possible additional neural machinery constrain choice contextually appropriate 
case connection output unit oa stochastic neuron mentioned ensure random choice ia ia oa ia activated oa 
section 
parameter space maps 
main motivations creating mechanisms doing complex symbolic computation metric space computers leads natural metrics symbolic computers 
metrics may prove useful understanding complex computers robust noise sensitive statistical properties environment learnable data 
section initial explorations new perspective afforded symbolic computers metric space implementation described 
dynamical automaton configured pushdown dynamical automaton functions exhibit precise symmetries sense essential pop operations effect undoing push operations exactly 
wonder happens adopts physically realistic perspective allows push pop operations approximate mirrors 
result loss context freeness 
loss catastrophic case 
neighboring languages parameter space take aptly call mild context sensitivity 

example parameterized parenthesis matching simple case illustrates 
consider parameterized extension dynamical automaton language discussed examples 
im ml parameters ml 
relevant part partition shown table 
input map im shown 
insert table scalars ml leftward move rightward move parameters adjusted change language da recognizes 
illustrates operation dynamical automaton 
ml recognizes language 
insert analyze automaton follows 
recognizes strings form 
smallest integer satisfying ml jordan pollack drawing attention quality context free dynamical recognizers motivating investigation described section 
considering cases ml ml logm ml log ml denotes smallest integer greater equal ml negative integer power language described particularly simple context free grammar 
example illustrates 
example 
ml 
log 
language language generated context free grammar rules table 
insert table ml non number rational power vice versa resulting language context free grammar complicated 
example illustrates case 
example 
ml 

language recognized particular parameterization language substantially complicated language previous example 
requires rules context free grammar format table 
number rules grows length cycle coefficient insert table ml irrational power vice versa generates non context free language 
show pumping lemma context free languages hopcroft ullman 
proposition 
language qn irrational context free language 
proof see appendix 
cycle real number mean smallest positive integer pq integer 
insert examples show simplest parameterized dynamical automata emulate computing devices significant range complexities 
framework suggests interesting new way examining relationships formal languages look locations parameter space dynamical automaton 
log shows simplest rule context free languages distributed quadrant ml 
adopting natural metric space euclidean distance talk relationships languages terms distance 
view rule language surrounded complex languages rule counting sense chomsky hierarchy sense 
grammars languages near rule language substantially different grammar possessing large numbers rules requiring context sensitive rules distributional properties similar 
example language differs long strings 
assume unbiased probabilities associated rows input mapping dynamical automaton specify transitions compartment strings languages differ quite rare 
section speculate property may useful designing learning algorithms dynamical automata 

examined particular type computing device dynamical automaton variables parameters take real values 
contrast realvalued automata focuses complexity tractability issues emphasized interpretation real valued spaces metric spaces examined consequences understanding computing devices related 
identified class computing devices called pushdown dynamical automata computation organized fractals showed class corresponded class context free grammars 
illustrated simple method implementing dynamical automata connectionist networks 
examined simple dynamical automaton real valued parameters showed automaton behaved various pushdown automata parameter settings powerful automata settings 
different automata organized metric space computer parameters way nearby automata parameter space generated similar sets strings probabilistic sense 
context free grammars fewest rules occupied disconnected regions parameter space 
grammars rules including non context free grammars 
avenues worth exploring interesting questions raised results described 
chomsky hierarchy relationships 
current proposal organize languages metric space glance differ substantially standard complexity approaches 
close look example section suggests relationship current results complexity results may augmentation revision 
particular overarching contrast context free languages non context free languages preserved contrast machines rational versus irrational parameter 
questions worth exploring natural way dynamical automaton framework defining precisely recursively enumerable languages defining set recursively enumerable languages contains set context free languages proper subset 
ii dynamical automata map standard complexity classes independently motivated parameter classes 
approximations infinite machines 
just irrational numbers viewed limits infinite series rationals non context free devices model section viewed limits infinite series context free devices 
similar idea explored crutchfield young crutchfield 
authors analyze particular indexed context free grammar limit infinite series increasingly complex finite state devices 
project results approach signal analysis studies growth size successive machine approximations level chomsky hierarchy order find jump machine higher level warranted 
explore case bigger bigger finite state devices approximate context free device 
current results may useful extending method transitions higher levels 
finding 
cascade analysis possible identify certain dynamical automata parameterized dynamical automaton family generate context free languages 
doesn necessarily characterize context free language generators particular family 
case point generator described section simplest rule grammars follow single cascade computations 
desirable generalize analysis identify entire set context free language generators dynamical computing system 
universality 
promoting parameterized dynamical automata better way organizing formal languages various systems stemming chomsky hierarchy 
sense chomsky hierarchy appealing organizational tool nearly machine independent universal 
dynamical automaton spaces define depend particular parameterized automaton study provide way organizing languages generated finite alphabet 
interesting consider possibility privileged set functions serves basis general automaton space dynamical automata related 
framework useful studying processes involve incremental search wide range devices evolution signal identification 
learning 
natural approach language learning think process making small adjustments grammar order improve predictive accuracy 
approach requires define constitutes small adjustment define similarity grammars 
standard symbolic formalisms hard choose myriad ways go defining similarity grammars especially grammars infinite state devices 
examine number rules grammars common 
rules shared grammars forms hard know take account 
assign probabilities rules compare implications local symbol transition likelihoods 
hard know compare case rule belongs grammar occurs low probability case rule simply absent grammar 
hypothesis spaces defined parameterized dynamical automata example described section look promising regard 
automata organized continuum way nearby automata give rise similar transition behaviors probabilistic sense mentioned section 
may possible dynamical automata basis gradient descent search having arbitrary decision rule cost 
trying postulate arbitrary balance complexity grammar coverage data learning algorithm simply search space best fit automaton 
generally metric space computers allow see geometric relationships symbolic computers invisible standard analytic perspective 
simultaneously microscopic birds eye perspective strength lies reveal small steps connect big ostensibly independent regimes 
appendix lemma 
wn uniquely invertible gifs metric space suppose pooling set crest cascade point proof 
proof lemma follows mainly definition pooling set def 
section text 
suppose contrary fact exists recall equal minimum possibilities consider 
string equal string exists ii 
case fact fact wn imply condition ii definition pooling set 
condition definition pooling set contradiction 
loss generality assume case ii 
case fact fact wn imply 
condition ii definition pooling set implies complement crest contradicts assumption crest assumption led contradiction cases case 
definitions permit formal definition pushdown dynamical automaton support proof string generative equivalence pdas 
def 
wn gifs cascade point corresponding cascade wi called push function def 
wn uniquely invertible gifs cascade inverses wi called pop functions definition possible keep track changes control state 
def 
wn gifs 
disjoint cascades cascade points respectively 
function address equal address called switch function 
note uniquely invertible 
def 
dynamical automaton metric space say pushdown dynamical automaton exists gifs wn cascade points xk 
corresponding cascades ck ck disjoint 
ci index cascade ci containing top 
ii partition compartment determined conjunction iii compartment partition function input mapping stack function switch function composition restricted points cascades 
iv start state final region fr contained theorem 
pda 
xi proof 
refering parts pdas notation hopcroft ullman 
part 
pda 
straightforward prove direction converting moore class dynamical recognizers class 
convenience wanting implement connectionist network flesh method sketched text 
consider context free language derive pda ma recognizes strings final state hopcroft ullman 
ma goal define corresponding pushdown dynamical automaton md im fr suppose positive integer 
en vector dimension dimensions 
suppose positive integer 
define gifs wn 
en consider set ei 
members ck cascade points see consider xk open unit hypercube positive quadrant corner origin 
note nth coordinate wn interval mth coordinate wn wn wn wm xk wn pooling set lemma xk cascade point 
cascades ck corresponding xk disjoint 
assume loss generality 
finite states ma labeled qk 
assume loss generality 
define parts md follows 
partition include compartments xn xn en compartments xk 
name compartment xn mi name compartment xi mi build input mapping im follows qi hn member qi mi wh member im 
push function ii qi member qi mi wn member im 
pop function iii qi member qj mi xn member im 
switch function iv handle composite cases composition 
qi xi member fr 
processing state top stack ma current state md index top said point state ma qi top stack current state md index top definition input mapping implies situation changes course processing grammatical string 
leads qj ma qj state moves legal transitions md xj processing string vice versa 
ma md recognize language 
part ii 
pda 
consider md im fr associated gifs wn cascade points xk 
corresponding cascades ck 
define corresponding pushdown automaton ma follows 
stack ma initially empty assume ma recognizes strings emptying stack 
cascade ci md ci control state ma qi 
define qi 

defined follows 
consider point ci possible index value possible value top 
compute partition compartment belongs possible definition 
suppose partition compartment compartment examine input mapping im rows containing row defined follows wh push function qi hz member qi 
ii wh pop function qi member qi 
iii switch function switches cascade cascade ql member qi 
iv handle composite functions composition 
xi final region md qi note defined case ck disjoint cascades md performs computations union 
initial state ma initial state bear index start state md 
truly asserted index state ma qi top top stack ma situation preserved 
state moves legal transitions xj md processing string leads qj ma vice versa 
ma md recognize language 
proposition 
language qn irrational context free language 
proof 
proceed showing qn context free language rational 
pumping lemma context free languages says context free language non negative integer string length greater written way vx ii iii uv wx suppose satisfies pumping lemma 
consider string pumped accord condition iii 
clearly consist positive number consist positive number 
cl cr loss generality assume rightmost string initial 
dl dr definition write cr dr cl dl fractional part cl dl 
write cr cri cr equation false sufficiently large cr cl integers rational 
cr barnsley 
fractals 
boston academic press 
blair pollack appear analysis dynamical recognizers neural computation 
blum shub smale theory computation complexity real numbers np completeness recursive functions universal machines bulletin american mathematical society 
cosnard 
computational power dynamical systems hybrid systems 
theoretical computer science 
crutchfield 
calculi emergence computation dynamics induction 
physica 
special issue proceedings international seminar complex systems complex dynamics artificial reality 
crutchfield young computation onset chaos 
complexity entropy physics information 
redwood city addison wesley 
das giles sun prior knowledge learn context free languages 
hanson cowan giles 
eds advances neural information processing systems 
san mateo morgan kaufmann 
elman 
finding structure time 
cognitive science 
elman 
distributed representations simple recurrent networks grammatical structure 
machine learning 
giles sun chen lee chen higher order recurrent networks grammatical inference 
touretzky 
ed advances neural information processing systems 
san mateo morgan kaufmann publishers 
hopcroft ullman automata theory languages computation 
menlo park addison wesley 
kremer 
theory grammatical induction connectionist paradigm 
phd thesis department computing science edmonton alberta 
moore 
dynamical recognizers real time language recognition analog computers 
theoretical computer science 
mozer das connectionist symbol manipulator discovers structure context free languages 
hanson cowan giles editors advances neural information processing systems 
san mateo morgan kaufmann 

differential equations dynamical systems 
new york springer verlag 
pollack 
induction dynamical recognizers 
machine learning 
rodriguez wiles elman recurrent neural network learns count 
connection science 
ron singer tishby power amnesia 
machine learning 
rumelhart hinton williams learning internal representations error propagation 
parallel distributed processing volume 
cambridge massachusetts mit press 
siegelmann 
simple dynamics super turing theories 
theoretical computer science 
siegelmann sontag turing computability neural nets 
applied mathematics letters 
strogatz 
nonlinear dynamics chaos 
addison wesley reading ma 

dynamical automata 
technical report tr cornell computer science department 
tino 
press spatial representation symbolic sequences iterative function systems 
ieee systems man cybernetics part cybernetics 
tino dorffner constructing finite context sources fractal representations symbolic sequences 
technical report tr 
austrian research institute artificial intelligence austria 
wiles elman landscapes recurrent networks 
moore lehman eds proceedings th annual cognitive science conference 
lawrence erlbaum associates 
zheng goodman smyth discrete recurrent neural networks grammatical inference 
ieee transactions neural networks 
christopher bader stefano edward gibson robert jacobs dexter kozen jordan pollack paul rodriguez peter tino william anonymous reviewers inspiring discussions helpful comments 
illustration captions neural network parenthesis balancing 
indexing scheme selected points sierpinski triangle 
points analogues stack states pushdown automaton 
convention label lists added symbols left added symbols 
sample trajectory da 
network 
neural implementation grammar 
square nodes denote gating units circular nodes denote signalling units 
accepting 
bands space ml simplest rule context free languages reside 
table push pop functions moore 
name function push table grammar 
ab cd bs cs 
table dynamical automaton da 
compartment input state change table part partition example 
index compartment input map example 
compartment index symbol function table weights unit types neural implementation grammar 
unit type input weight threshold ia threshold ib ia threshold id threshold ia threshold ib ia threshold id linear ia ib linear ia linear id linear linear linear linear linear threshold oa threshold threshold ob oa threshold threshold od threshold table part partition parameterized dynamical automaton example index compartment input mapping parameterized dynamical automaton example 
compartment index symbol function table context free grammar generating rr srr table context free grammar generating ss 
ss 
ss 
ss 
ss ss 
ss ss neural network parenthesis balancing 
indexing scheme selected points sierpinski triangle 
points analogues stack states pushdown automaton 
convention label lists added symbols left added symbols 
sample trajectory da 

network 
neural implementation grammar 
square nodes denote gating units circular nodes denote signalling units 
id accepting bands space simplest rule context free languages reside 

