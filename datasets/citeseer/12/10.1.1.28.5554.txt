flexible speaker adaptation maximum likelihood linear regression woodland cambridge university engineering department street cambridge cb pz 
uk 
maximum likelihood linear regression mllr approach speaker adaptation continuous density mixture gaussian hmms application static incremental adaptation supervised unsupervised modes described 
approach involves computing transformation mixture component means linear regression 
allow adaptation performed limited amounts data small number transformations defined tied number component mixtures 
previous predetermined amount available data 
dynamic regression class generation chooses appropriate number classes transform tying adaptation phase 
allows complete unsupervised operation arbitrary adaptation data 
results static supervised adaptation non native speakers unsupervised incremental adaptation 
show effectiveness flexibility mllr approach 

years progress speaker independent si recognition system performance 
speaker independent systems speakers modelled poorly case speaker dependent sd systems give significantly better performance sufficient training data 
cases undesirable train sd system due large amount training data needed required enrollment time 
speaker adaptation sa techniques tune existing speech recognition system new speaker great interest 
adaptation methods require sample speech adaptation data new speaker models updated 
amount adaptation data needed depends way sa technique uses data type system adapted 
example map estimation requires relatively large amount data updates models examples data 
problem particularly severe hmm systems contain large numbers parameters 
considers maximum likelihood linear regression approach mllr parameter transformation technique proved successful small amounts adaptation data 
method extended flexible suitable unsupervised adaptation static incremental modes 
mllr adaptation initial set speaker independent models adapted new speaker transforming mean parameters models set linear transforms 
transformation number distributions pooling transformation training data maximum adaptation data parameters state distributions adapted 
set gaussians share transformation referred regression class 
transformations trained maximise likelihood adaptation data transformed model set 
previous tying transformations determined adaptation 
adaptation procedure enhanced calculating number membership regression classes adaptation procedure 
dynamic approach allows modes adaptation performed single framework 
approach evaluated data arpa csr spoke tests 
experiments demonstrates effectiveness static supervised adaptation non native speakers experiments show framework incremental unsupervised adaptation easily implemented 
structure follows mllr approach reviewed extension incremental adaptation discussed sec 
describes fixed dynamic approaches regression class definition sec 
compares static supervised unsupervised adaptation 
experimental evaluation csr data sec 
presents adaptation results tests discussing speaker adaptation integrated htk system test 

mllr overview section briefly reviews mllr approach gives equations estimation mllr transformations 
information covered greater detail 
sec 
shows approach extended incremental adaptation 

mllr basis state continuous density mixture gaussian hmm output distribution number component densities 
state distribution components expanded parallel single gaussian states 
mathematical description section case single gaussian output distribution states described extension mixture gaussians straightforward 
output distribution characterised mean covariance sigma adaptation procedure si means mapped estimate unknown sd means linear regression transform estimated adaptation data theta transformation matrix extended mean vector jn regression transformation estimated maximise likelihood data 
separate regression matrix trained distribution equivalent standard baum welch retraining adaptation data 
allow approach effective small amounts adaptation data regression matrix associated number state distributions estimated combined data 
tying fashion transforms required component mean produce general transformation tied components parameters represented training data updated 
tying means transformation matrices estimated robustly method effective unsupervised adaptation 
transformation probability density function state generating speech observation vector dimension sigma gamma gammaw sigma gamma gammaw 
estimation mllr matrices transformations computed maximise likelihood adaptation data 
set frames adaptation data probability occupying state time generating fl current parameter set fl jj oj jj likelihood occupying state time generating oj total likelihood model generating observation sequence 
fl computed forward backward algorithm 
assuming gaussian covariance matrices diagonal tied gaussians shown computed column column gamma th column matrix fl jr sigma gamma jr jr ii jr jr ii th diagonal element th tied state covariance scaled total state occupation probability fl jr sigma gamma jr full derivation result 
updating parameters equations constitutes iteration mllr adaptation 
change parameters results different posterior probability state occupation likelihood adaptation data increased mllr iterations 
noted assumes transformations full regression matrices simplified form obtained matrices assumed diagonal 
previously full matrices give superior performance experiments reported assume full regression matrices 

incremental adaptation basic equations mllr assume adaptation data available means updated static adaptation 
simple manipulation equations time dependent components accumulated separately obtained sigma gamma jr fl jr jr fl jr sigma gamma jr accumulating observation vectors associated gaussian associated occupation probabilities mllr equations applied point time current values mean vectors adaptation may performed incrementally 
adaptation update data associated state regression class generate transformation matrix 
noted incremental form equivalent static adaptation assumed updating change observation vector state alignment previously seen utterances 

regression classes tying transformation matrices mixture components achieved defining set regression classes 
regression class single transformation matrix associated mixture components class transformed matrix 
matrix estimated data allocated mixture components class 

fixed regression classes previous mllr class definitions predetermined assessing amount adaptation data available mixture component clustering procedure likelihood measure generate appropriate number classes 
experiments mixture gaussian tied state cross word triphones arpa resource management rm database confirmed optimal number regression classes roughly proportional amount adaptation data available see table 

dynamic regression classes predetermined class definitions assumes amount adaptation data available known advance sufficient amount data assigned regression class 
classes insufficient 
adapt 
optimal 
classes table optimal number fixed regression classes adaptation data results static adaptation rm data assigned result poor estimates transformations class may dominated specific mixture component 
computing number classes appropriate tying adaptation phase data observed desirable 
facilitate dynamic regression class definition mixture components system arranged tree 
small hmm system leaves tree represent individual mixture components higher levels tree mixture components merged groups similar components distance measure components 
tree root node represents single group containing mixture components 
tree specific set regression classes generated sufficient adaptation data 
hmm systems large numbers mixture components systems described mixture components may feasible construct tree single mixture component leaf node 
leaves initial clustering base classes 
base class contains reasonably small set components deemed similar distance measure components 
accumulate statistics required adaptation process accumulators associated mixture components 
summed state occupation probability observation vectors associated component forward backward alignment recorded 
adaptation alignment complete total amount data allocated mixture component known 
search tree starting root node find set regression class definitions 
separate regression class created lowest level tree sufficient data 
search allows data regression class ensure mixture component means updated specific regression transforms 

unsupervised static adaptation implementation static supervised static unsupervised adaptation schemes mllr similar 
supervised adaptation uses known word sequence sentence unsupervised adaptation uses output recogniser label data 
labelled data passed forward backward procedure appropriate statistics gathered mllr transforms generated 
model parameters updated 
previously reported results rm corpus fixed regression classes showed supervised unsupervised adaptation result similar performance 
due large part general regression classes reduce effects misalignments poor labelling data giving performance unsupervised adaptation 

adaptation utterances speaker independent speaker dependent supervised adapted unsupervised adapted supervised vs unsupervised adaptation rm rm experiments gender independent cross word triphone system tied states component mixture distribution state 
trained standard rm si training set 
speaker dependent version trained rm sd speakers sd training sentences 
testing sentences sd test data speaker standard word pair grammar 
static supervised unsupervised recognition experiments varying amounts speaker specific training data adaptation performed 
shows results performance si sd systems comparison 

evaluation wsj data section describes evaluation mllr adaptation approach static supervised adaptation non native speakers test incremental unsupervised adaptation improve performance native speakers test 
types adaptation baseline speaker independent system regression class tree 
cases dynamic tree approach regression class definition 
recognition results computed final transcriptions phone mediated alignments 

baseline si system baseline speaker independent system experiments gender independent cross word triphone mixture gaussian tied state hmm system hmm system similar system described 
hmm system speech parameterised mfccs normalised log energy second differentials parameters give dimensional acoustic vector 
decision tree state clustering define speech states component mixture gaussian distribution trained tied state total parameters 
acoustic training data consisted sentences si wsj set limsi wsj lexicon phone set 
recognition tests word vocabulary standard mit lincoln labs trigram language model 
decoding single pass dynamic network decoder described 

regression class tree regression class tree built divergence mixture components distance measure 
base classes generated simple clustering algorithm 
initially mixture components chosen nearest components assigned base class 
component assigned appropriate base class average distance existing members 
technique efficient assigned reasonable number mixture components base class 
regression tree built similar distance measure 
base classes compared pairwise basis average divergence members class 
speed processing search space pruned computing average distributions class considering closest detailed match 
node closest classes combined class remaining separate node 
levels combination remainder tree built average distributions node comparison 
created tree levels separate nodes 

spoke results aim spoke investigate static supervised adaptation improve performance non native speakers 
speaker supplies utterances standard set adaptation sentences recorded speakers corpus 
mllr sentences viterbi alignment procedure select appropriate pronunciation word inter word silences resulting phone string number iterations mllr performed obtain adapted model set current speaker 
iterations mllr may required case non native speakers original models poor state frame alignments may change adaptation 
word error rate si hmm models native speaker recogniser settings development test data evaluation test data 
table gives results systems recogniser settings tuned non native speakers 
effect multiple iterations mllr adaptation single global regression matrix shown 
regression iterations word error classes mllr dev nov baseline baseline tree tree tree global table word error rates non native speakers mllr static supervised adaptation 
native speakers average error rate hmm system adaptation error rate factor higher 
seen table multiple iterations mllr dynamic tree regression class definitions revised set error rate reduced average si system 
multiple regression classes gives average reduction error rate single global class multiple iterations mllr gives worthwhile reduction error 

spoke results aim test improve performance native speakers unsupervised incremental adaptation 
hmm system incremental mllr integrated dynamic network decoder 
test set contained sentences speakers fact development data evaluation data contained speakers high error rates 
performing incremental adaptation described sec 
parameters updated time 
tests performed update sentences recognised interval successive updates varied sentence sentences sentences 
furthermore global regression class updating sentence investigated 
regression update word error classes interval dev nov baseline baseline tree tree tree global table word error rates mllr unsupervised incremental adaptation 
seen table worthwhile decrease error rate obtained unsupervised adaptation average 
speaker highest initial error rate improved speakers yielded lower rate adapted systems including global regression class 
computational overhead adaptation approximately inversely proportional update interval 
update interval increased sentences small drop performance large reduction computation due adaptation 
operation tree dynamic regression class definition illustrated fig 
shows number classes defined approximately linear number sentences available accumulation adaptation statistics 
differing slopes mainly due different speaking rates different speakers 

adaptation nov system approach unsupervised speaker adaptation november htk system 
test sentences speaker speaking sentences unfiltered newspaper articles 
recogniser test word vocabulary gram lan tb tc td te 
sentences variation number regression classes recognition proceeds speaker nov test set guage model 
acoustic models adapted gender dependent set built decision tree wider phonetic context hmm set described 
total parameters hmm set hmm 
details system 
regression class tree base classes built hmm set gender speaker identified automatically system sentences 
models identified gender adapted mllr adapted second sentence 
results system development evaluation test data unsupervised incremental speaker adaptation shown table 
adaptation word error dev nov table word error rates htk evaluation system unsupervised incremental speaker adaptation 
development data error rate reduced adaptation evaluation data 
analysis error rate change speaker speaker basis showed development data speakers reduced error rate adaptation error rate speaker increased 
evaluation data speakers improved performed poorly 
speakers improve tended initially performed poorly cases improvements quite large 
cases performance deteriorated usually small amount 
htk system evaluation configured incremental unsupervised adaptation returned lowest reported error rate test 

mllr approach adapting speaker independent model system extended allow incremental adaptation dynamic allocation regression classes 
framework useful static incremental adaptation unsupervised supervised modes minimal changes system 
approach applied number different problems success including unsupervised incremental adaptation large state art hmm system 
funded epsrc studentship 
arpa provided access caip computing facility 
limsi kindly provided wsj lexicon 
members cambridge htk group help particular julian odell 

gauvain 
lee 

maximum posteriori estimation multivariate gaussian mixture observations markov chains 
ieee trans 
sap vol 


woodland 

speaker adaptation linear regression 
technical report cued tr 
cambridge university engineering department june 

woodland 

speaker adaptation continuous density hmms linear regression 
proc 
icslp vol 
pp 
yokohama 

odell valtchev woodland young 

pass decoder design large vocabulary recognition 
proc 
arpa human language technology workshop march pp 
morgan kaufmann 

woodland odell valtchev young 

large vocabulary continuous speech recognition htk 
proc 
icassp vol 
pp 
adelaide 

woodland odell valtchev young 

development htk large vocabulary speech recognition system 
proc 
arpa spoken language technology workshop barton creek 

young odell woodland 

treebased state tying high accuracy acoustic modelling 
proc 
arpa human language technology workshop march pp 
morgan kaufmann 
