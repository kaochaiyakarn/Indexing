pronunciation modeling sharing gaussian densities phonetic models sanjeev khudanpur center language speech processing johns hopkins university baltimore md usa cambridge university engineering department cambridge uk conversational speech exhibits considerable pronunciation variability shown detrimental effect accuracy automatic speech recognition 
attempts model pronunciation variation including decision trees generate alternate word pronunciations phonemic baseforms 
pronunciation models recognition known improve accuracy 
describes pronunciation models acoustic model training 
subtle difficulties straightforward alternatives canonical pronunciations illustrated shown simply improving accuracy phonetic transcription acoustic model training little benefit 
analysis paradox leads new method accommodating nonstandard pronunciations allowing phoneme canonical pronunciation realized distinct alternate phones predicted pronunciation model hmm states phoneme model allowed share gaussian mixture components hmm states model alternate realization 
qualitatively amounts making soft decision surface form realized 
quantitative experiments switchboard corpus show method improves accuracy absolute 

pronunciations spontaneous conversational speech tend variable careful read speech pronunciations words adhere citation forms 
speech recognition systems rely pronouncing dictionaries contain alternate pronunciations words 
failure capture important source variability potentially significant cause relatively poor performance recognition systems large vocabulary spontaneous conversational speech recognition tasks 
known pronunciation model recognition results moderate improvements word error rate wer 
natural extension idea incorporate pronunciation model initial training acoustic phonetic models 
state art automatic speech recognition asr systems estimate models assumption words training corpus pronounced canonical form 
word level transcription speech standard pronouncing dictionary generate phone level training transcriptions 
intuition suggests pronunciation model improve accuracy phone level training transcription lead sharper acoustic models better recognition 
contrary expectation best knowledge efforts incorporate pronunciation modeling acoustic model training spontaneous speech 
investigate failure consequently arrive novel method pronunciation modeling 
recognition method improves accuracy partially supported national science foundation extent previously methods improves acoustic model training 
structure follows 
earlier pronunciation modeling framework reviewed briefly section 
sections investigate straightforward approach training acoustic models phonetic transcriptions refined pronunciation model 
leads little improvement wer 
section considers direct hand labeled transcriptions bootstrap acoustic model training process section 
apparent paradox acoustic models resulting procedures degrade wer phone accuracy resulting word hypotheses better baseline system 
leads sections new way capturing pronunciation variation dubbed state level pronunciation modeling opposed preceding phone level pronunciation model 

pronunciation modeling framework brief review pronunciation modeling methodology see details 
main steps pronunciation model asr 
obtain canonical phonemic transcription training material 
standard pronouncing dictionary case purpose 

obtain surface form phonetic transcription material 
portion switchboard corpus phonetically hand labeled linguists see 

align phonemic phonetic transcriptions 
dynamic programming procedure phonetic feature distances purpose 

estimate decision tree pronunciation model 
decision tree constructed predict surface form phoneme asking questions phonemic context 

perform recognition pronunciation model 
pronunciation model transform phoneme dictionary phoneme level recognition network yield network surface forms 
recognition performed phone level network 
phoneme level network may derived word level language model word lattice generated initial recognition pass 
shown small amount phonetically labeled data available step pronunciation model step corresponding wer step worse absolute canonical pronunciations 
way automatically generate data step 
full training set 
starting canonical transcription entire acoustic training set just hand labeled portion steps pronunciation model step create pronunciation networks representing possible phonetic realizations training utterance 
phone sequence network chosen viterbi alignment set existing acoustic models giving refined transcription entire training set 
shown replacing small corpus step larger corpus step repeating steps leads small statistically significant absolute improvement wer switchboard corpus 

improving phonetic transcriptions acoustic training refined transcriptions resulting step may reasoned better suited acoustic model training canonical baseforms 
leads notion 
acoustic model reestimation 
new acoustic models reestimated phone transcriptions step 
step repeated new acoustic models replacing existing acoustic models earlier 
resulting phonetic transcription steps pronunciation model estimation recognition 
possible gauge quality phonetic transcription step comparing hand labels available portion switchboard training corpus 
table presents comparison sentences phones 
clear transcriptions phone error rate dictionary baseforms automatic step table 
training transcriptions compared hand labels table models step trained accurate phonetic transcriptions 
result exactly recognition performance wer acoustic models trained canonical baseforms 
hypothesis investigate transcriptions resulting step closer hand labels contain inappropriate phones due poor phone recognition performance step 
method attempt improve quality phone recognition standard speaker adaptation techniques 
vocal tract length normalization maximum likelihood linear regression mllr adjust acoustic models performing step 
adaptation method phone error rate ml mllr table 
failed attempts improve training transcriptions results adaptation techniques leads little change transcription accuracy relative hand labeled transcriptions table 
results little change transcription content evidenced comparison automatic transcription techniques table 
new transcriptions remain fairly close original transcriptions adaptation 
discussion results suggest original hypothesis step transcription poor due low phone recognition accuracy incorrect conclude set acoustic models tuned baseforms trained little change transcriptions obtained models stage 
adaptation training transcriptions simply exacerbates problem 
refined phonetic transcriptions agree better canonical baseforms accurate training acoustic phonetic models 
redoing steps step ensures final pronunciation model step matched new acoustic models recognition step 
acoustic models phone error rate relative step prev automatic baseforms transcriptions baseline unadapted ml adapted mllr adapted table 
automatic transcriptions adaptation acoustic model step phone error rate gaussian triphone models gaussian triphone models table 
simpler acoustic models improve transcription supported small increase phone transcription accuracy respect hand labeled data uses acoustic models lesser complexity table 

jack improve acoustic training transcriptions transcription accuracy improved uses smaller models trained data set natural progression training set models trained different data 
method hour switchboard training set partitioned speaker disjoint gender balanced hour subsets model sets trained half phonetically transcribe acoustics unseen half data step 
resulting transcriptions train set acoustic models step 
steps carried estimate test pronunciation model 
results phone recognition accuracy relative transcriptions essentially unchanged method 
say resulting transcriptions described preceding section 
transcriptions deviate baseforms transcriptions table 
despite refined transcriptions lead significant change recognition performance wer 
discussion conclude quite difficult obtain accurate automatic phonetic transcriptions acoustic models trained canonical baseforms 

acoustic models trained hand labeled data way obtain accurate phonetic transcriptions entire acoustic training corpus step acoustic models trained directly hand labeled portion training corpus 
investigate avenue 
method small portion hours acoustic training data transcribed phone level human labelers 
due limitation estimate set phone models called icsi models portion training set 
step performed replacing existing acoustic models icsi models 
results considerably accurate phonetic training transcription see results 
step training acoustic models entire training set performed 
resulting models named icsi bootstrap models 
followed usual procedure steps estimating testing new pronunciation model appropriate acoustic models 
results results showing phone transcription accuracy improved models trained hand labels 
models bootstrapped phonetically labeled training utterances results tables reported inappropriate compare transcription accuracy set 
utterance subset test set phonetic labels compare transcription accuracy icsi models models trained canonical pronunciations 
task step choose best phone sequence word transcription pronunciation model 
results table icsi models type models phone error rate dictionary baseforms automatic step standard automatic step icsi models automatic step icsi bootstrap table 
hand labeled data train acoustic models improved phone transcription word transcription cate transcriptions icsi bootstrap models trained accurate baseforms transcriptions preceding sections 
models appear considerably better standard models trained canonical baseforms 
recognition performance turns quite contrary 
standard acoustic models pronunciation model wer wer models 
order better understand cause degradation performance model phonetically labeled utterances test data analyzed 
addition wer performance phone error rate measured hand transcriptions 
turns table pronunciation acoustic model model standard icsi bootstrap step test wer wer dictionary tree pron 
model table 
comparison word phone error rates different acoustic pronunciation models icsi bootstrap models improve phone accuracy subset test set wer worse 
discussion clear experiments considerable deviation canonical pronunciations spontaneous speech icsi bootstrap models better capturing actual realized pronunciations models trained standard pronunciations 
conclude inability translate implicit lower phone error rate lower wer due lexical confusion decision tree pronunciation model allows words large number pronunciations overlap pronunciations words recovering right word strings accurate phone recognition difficult 
model acoustic realization phoneme allow inherent variability 
leads new way modeling pronunciations 

modeling pronunciation variability level hmm states section new way model alternate pronunciations show performs decision tree pronunciation model described 
new model accommodates alternate surface form realizations phoneme allowing hmm state model phoneme share output densities models alternate realizations 
call state level pronunciation model reasons described 
understand consider effect traditional pronunciation model allows abc alternately realized surface form asc 
sketch top illustrates hmm system permit alternative recognition network sketch middle illustrates context dependent triphone hmm system 
phone level pronunciation model monophone phone level pronunciation model triphone state level pronunciation model triphone 
effect allowing phoneme realized phone viewed level hmm states deviates methods illustrated sketch bottom 
letting phoneme realized alternate phone hmm states acoustic model phoneme allowed utilize output density hmm states acoustic model alternate realization 
acoustic model phoneme canonical alternate realizations represented different sets mixture components set hmm states 
method construct hmm system states share output densities pronunciation model 
obtain state state alignment surface form representations similar step section 

estimate probability hmm state realized alternate state alignment prob 

filter unreliable estimates 

modify output distribution state include mixture components alternate states 

train resulting tied mixture acoustic models 
state output densities system mixtures gaussians oj sigma denotes set mixture components sigma state denotes mixture weights 
example step construction replaces prob prob formalism extends easily general case phoneme may realized alternate phones 
results developed recognition experiment switchboard corpus table shows just decision tree pronunciation model results small significant reduction wer 
pronunciation model wer dictionary decision tree pronunciation model state level pronunciation model table 
recognition performance discussion may noted gaussian densities duplicated reestimation shared states 
additional parameters introduced mixture weights 
increases number free parameters acoustic models 
mimics behavior decision tree pronunciation model additional advantages 
ffl canonical phonemic transcriptions train hmms resulting construction 
output densities alternate realizations hmm state canonical pronunciation acoustic realizations match alternate phones better baum welch reestimation update densities canonical ones 
ffl dictionary need expanded include alternate pronunciations important consideration recognition speed 

introducing accurate densities model surface form realizations essential idea previous section augment hmm state phoneme model alternate surface form realizations 
origin densities model alternate realizations merits discussion 
hmm states needs account realization densities hmm trained canonical transcriptions 
alternative augment hmm states densities hmm trained accurate transcriptions section 
method modification recipe section step output densities augmented sharing mixture components existing hmms densities corresponding hmm states section 
illustrated 
training models cf 
step section achieved training mixture weights transition probabilities followed training model 
results results table indicate modified hmm set performs significantly better hmms trained canonical pronunciations giving gain absolute wer 
sets acoustic models merged fashion number parameters nearly doubled 
way fair comparison compare merged system system gaussians state 
data sparseness causes gaussians state system trained wer test set worse gaussians state baseline 
baseline acoustic models state clustered cross word triphone hmms having states gaussian densities state 
language model trigram trained words front uses mf plp derived coefficients 
test set conversations amounting hours speech words 
note substantially increase number parameters system 
merged ams icsi ams 
merging gaussian mixtures pronunciation model acoustic model wer baseline phone level pm state level pm merged training state level pm merged training table 
performance acoustic model merging discussion effort fair comparison keeping number parameters comparable baseline models sets acoustic models smaller number mixture components state merged 
resulting retrained system wer substantially better decision tree pronunciation model 

authors michael riley laboratories providing fsm tools required manipulate pronunciation models entropic cambridge research laboratory uk providing lattice generation tools experiments 
idea sharing output densities inspired doctoral dissertation luo 
riley automatic generation detailed pronunciation lexicons 
automatic speech speaker recognition advanced topics 
kluwer 

byrne pronunciation modelling conversational speech recognition status report ws ieee workshop speech recognition understanding santa barbara ca dec 
byrne pronunciation modelling corpus conversational speech recognition proc 
icassp seattle wa may 
greenberg switchboard transcription project lvcsr summer workshop technical reports www icsi berkeley edu real stp young jansen odell woodland htk book version entropic cambridge research laboratory 
luo balancing model resolution generalizability large vocabulary continuous speech recognition 
phd thesis johns hopkins university baltimore md 
