decision theoretic planning concurrent temporally extended actions department computer science michigan state university east lansing mi cse msu edu sridhar mahadevan department computer science michigan state university east lansing mi cse msu edu investigate model planning uncertainty temporally extended actions multiple actions taken concurrently decision epoch 
model options framework combines factored state space models set options partitioned classes ect disjoint state variables 
show set decision epochs concurrent options de nes semi markov decision process underlying temporally extended actions parallelized restricted markov options 
property allows smdp algorithms computing value function concurrent options 
concurrent options model allows overlapping execution options order achieve higher performance order perform complex task 
describe simple experiment navigation task illustrates concurrent options results faster plan compared case option taken time 
everyday life brain constantly planning executing concurrent parallel behaviors 
example driving parallel visually search road signs may talking passenger 
walking car parking lot oce may simultaneously reach keys continuing talk cell phone navigating environment 
parallel execution behaviors useful performing task quickly parking lot example 
situations nature task requires multiple behaviors run concurrently cooperatively order perform task driving example look road navigate car simultaneously 
investigate model planning concurrent behaviors 
adopt theoretical framework options sutton model temporally extended actions developed rigorous framework addresses planning uncertainty temporally extended actions allows looking inside behaviors improve composition temporally extended actions 
previous decision theoretic concurrent planning largely restricted focusing combining primitive actions ranging planning multi dimensional vector action spaces planning multiple simultaneous mdps singh cohn composite state space cross product state spaces individual mdp action set proper subset multidimensional primitive action space 
models decision epoch xed equal single step execution 
di ers address planning set parallel temporally extended actions may terminate time problem challenging 
exploit fact real world problems set options factored ect disjoint state variables 
factoring greatly reduces complexity planning multi dimensional composite state action spaces boutilier appear 
address planning set concurrent options assuming compete shared resource parking lot example option reaching car key option walking ect di erent portions composite state space 
navigation task involving moving rooms keys open locked doors illustrate concurrent options model facilitates faster planning 
experiments show concurrent options model improves performance compared sequential case behavior time executed 
rest organized follows 
section brie overview option framework 
section de ne concurrent options model detail 
section computational problem performance results planning concurrent options model 
section outlines problems research 
options options generalization primitive actions include temporally extended courses action context reinforcement learning sutton 
options consist components policy termination condition initiation set denotes set states option initiated 
note restrict scope application particular option controlling initiation set termination condition 
state option taken primitive actions selected terminates option markov option policy initiation set termination condition depend stochastically current state option semi markov option policy initiation set termination condition dependent prior history option initiated 
example option exit room states di erent locations room markov option location know direction move independent reached location 
set options denote set options available state initiation set 
resembles standard reinforcement learning framework denotes set primitive single step actions 
similarly introduce policies options 
decision epoch markov policy options selects option probability distribution 
option initiated terminates random time state termination condition process repeats option state denote event initiated state time total discounted reward accrued executing option state de ned efr random time terminates 
denote probability option initiated state terminates state steps 
ss reward state transition model option write bellman equation value general policy os ss similarly write option value bellman equation value option state ss corresponding optimal bellman equations follows max os ss ss max os synchronous value iteration svi compute iterates step state max os ss ss max alternatively option model unknown estimate smdp learning doing sample backups termination option transitions state steps cumulative discounted reward max concurrent options de nition option state space governed set state variables fw denote subset state variables evolve processes options independent denote subset state variables evolve solely option explicit restriction initiation set policy termination condition respect state space refer class options property partially factored options 
example consider task delivering parts set machines factory environment 
agent load part inventory load station deliver particular machine 
may de ne options deliver part load part set state variables deliver part load part part denoting position agent part available inventory load station respectively 
may de ne inventory option state variable inventory set reset part ready load available 
clear example initiation set policy termination condition options deliver part load part de ned state space spanned execution options ect state variable part ready controlled option inventory option 
example deliver part load part deliver part load part 
inventory inventory 
options called coherent partially factored options condition required ensure options ect portion state space safely run parallel 
example deliver part inventory options coherent deliver part load part options coherent state variable position controlled deliver part load part options 
assume set available options fc cn classes options partition disjoint classes options belonging di erent classes coherent run parallel options class coherent control shared state variables run parallel 
clearly set options generated drawing option separate class safely run parallel example de ne classes options property part load 
de nitions de ne concurrent options model tuple state space state space represented spanned set state variables union sets simple verify denote sub space spanned note option sub space sub space option return vector elements current value state variable state return vector elements current value state variable state return current simple verify equation sample state vector represented concatenation operator 
notation explain components model 
actions state set options belonging di erent class initiated concurrently cn concurrent option consists set options initiated parallel 
represent concurrent option om call multi option distinguish regular options represent set available options state 
need de ne event termination multi option multi option executed state set options initiated 
option terminate random time de ne event termination multi option events options terminates multi option declared terminated rest options terminated point time interrupted options terminated 
restrict discussion model rst de nition 
de nition decision epoch happens random time minft mg 
transition probabilities de ne state transition probabilities termination event explained 
ss denote probability multi option initiated state terminates state rst de nition termination event denotes probability option initiated state terminates function state system option transition probability option initiated de ned part option model 
option initiated simultaneously transition probability computed follows 
denote probability multi option initiated state terminates state steps 
ss denote probability initiated state steps transitions state compute viewed probability initiating multi option state running steps options terminated step options terminates step second term right hand side equation denotes probability options terminates state termination condition option denotes single step transition probability option executed state step state assuming option initiated 
option ects state space set state variables sets disjoint de ne terms equation get equation rewrite single step transition probability multi option om om equation get single step transition probability multi option state state product single step transition probabilities individual option state state single step execution option state option control disjoint set state variables mutually contributes formation state sets independent single step execution options running parallel 
having de ned single step transition probability equation recursively de ne step transition probability note representation clarity omitted state variables covered union sets 
cases explicitly list state variables remain unchanged 
rst term right hand side denotes probability executing multi option initiated state steps state second term denotes probability options terminate state term denotes probability option initiated state executed single step ended state equations compute ss 
reward function state multi option efr random time multi option terminates 
state value function markov policy state value function written efr ss duration multi option termination event explained 
multi option value markov policy efr efr ss duration multi option termination condition explained 
shown earlier set markov options de nes semi markov decision process smdp sutton 
natural conjecture result carries multi options 
show case assumptions discussed 
theorem mdp concurrent options smdp mdp set concurrent markov options de ned mdp decision process selects multi options executes termination multi option termination condition forms decision process 
proof sketch decision process smdp required de ne set states set actions expected cumulative discounted reward de ned pair state action de ned joint distribution state decision epoch 
concurrent options model de ned set states set actions multi options 
expected cumulative discounted reward joint distributions state decision epoch de ned terms underlying mdp 
policy termination condition option belongs multi option termination condition multi option de ned 
experimental results section simple computational example illustrates planning concurrent options 
adopt rooms example sutton add doors hallways 
agent pass locked closed doors holding key 
state environment example consists state variables position agent environment represented cells state doors state key 
state agent select actions set navigation actions set key related actions 
navigation actions comprises stochastic primitive actions left right 
navigation action probability causes agent move cell corresponding direction probability moves agent directions probability 
case movement take agent wall closed door agent holding key agent remain cell 
de ned room nop primitive action change position agent probability 
rooms de ne hallway markov options multi step take agent room hallway cells leading room 
shows policy hallway options 
termination condition hallway options zero states inside room cell target hallway cell shaded cell termination condition de left right multi step navigation options door hallways stochastic primitive actions multi step pickup key option drop key times get key key nop putback key goal agent stochastic primitive actions left right fail times room nop primitive action rooms example grid world environment includes locked doors hallway 
agent needs pickup key order unlock doors pass hallways 
stochastic primitive cell cell navigation actions plus room nop primitive action stochastic primitive key actions de ned environment 
multi step hallway options room multi step key option de ned top primitive actions respectively 
hallway options room take agent cell room hallways connected room 
state door target hallway agent holding key 
cell termination condition zero door open door closed agent holding key hallway option terminate probability 
assume agent currently executing hallway option current location cell adjacent target hallway door target hallway locked 
agent holding key continues executing hallway option unlock door takes agent target hallway stochastic process explained 
agent exits hallway door hallway changes state locked closes 
initiation set hallway option comprises states room plus non target hallway state leading room 
note cell target hallway option initiated door open door closed agent holding key 
shows states key process 
note state key ready unlock doors agent holding key 
states de ned key process agent select primitive actions get key de ned target outside room hallway key ready key ready inside room door closed door open door closed hallway option taken hallway option taken policy associated hallway options 
gure shows option taken cell room 
shaded cell adjacent target hallway option taken door open agent holding key cell 
option terminates target hallway shaded cell door closed agent holding key 
states key nop de ned key states putback key de ned state primitive action key nop stochastic ect agent may drop key probability taken state dropping key reset state key probability change state key process 
key nop action taken states change state key process 
agent advance state process action get key executed reset state process action putback key executed 
provide multi step pickup key markov option top get key primitive action 
pickup key option policy advances key state probability key ready state 
termination condition pickup key option state zero rest states 
initiation set comprises key states state shows evolution state environment hallway options key options run parallel 
note options share key state state variable ect disjoint subspaces state space hallway options control position doors state variables key options ect key state variable 
notation developed section de ne classes options hallway hallway room note hallway options di erent rooms control disjoint sub spaces state space put class initiation 
primitive action get key primitive action key nop primitive action putback key multi step option pickup key key ready representation key pickup option 
state agent holding key 
hallway options key options position doors state key state position doors state key state evolution states room navigation task 
initiation set policy termination probabilities option may share state variables parallel options hallway options pickup key options share key state variable mutually ect disjoint sets state variables hallway options control position door state variables key option controls key state variable 
hallway options room nop option key key nop putback hallway option set state variables navigation doors state key doors state speci es state door key option key 
note navigation doors key 
equation state space process spanned set state variables navigation key doors state key 
multi options members set hallway options taken room plus room nop option key options taken cell set run parallel 
note room nop key nop putback key primitive actions special case single step options 
room maximum multi options de ned state 
order evaluate concurrent options framework compare performance rooms example standard options framework 
note standard options framework option taken time 
concurrent options theorem previous section apply smdp learning 
multi option viewed indivisible opaque unit action intra multi option methods developed 
multi option initiated state transitions state multi option terminates termination condition de ned multi options 
smdp learning method bradtke du sutton update multi option value function decision epoch multi option taken state terminates max denotes number time steps initiation multi option state termination state denotes cumulative discounted reward period 
xed position starting point upper left corner cell xed goal hallway frameworks order learn policy navigate starting position target 
primitive action reward provided single step reward order learn policy optimizes time performing task 
shows median time terms number primitive actions taken success trial median trials gure shows standard options framework learns faster concurrent options framework eventually concurrent options framework learns better policy 
small solid rectangles cells represent approximate location pickup key option initiated agent moves hallway goal 
policy learned sequential execution options agent navigates cell adjacent target hallway locked door corresponding hallway option initiates pickup key option waits cell steps key state advances state point key ready 
overlapping execution hallway option pick key option agent minimizes time order reach goal 
median trials trial concurrent options standard options performance standard options concurrent options framework smdp learning rooms example 
horizontal axis represents number trials vertical axis shows median number steps success trials 
discussion introduced concurrent options model formalizes planning uncertainty parallel temporally extended actions action ects mutually disjoint subspaces environment state space 
key assumption required set options safely run concurrently markov 
restriction necessary order de ned termination condition state prediction transition probabilities consider counter example semi markov navigation option agent moves perimeter room twice deciding exit room 
key option invoked parallel semi markov option agent know long exit room option running information available current decision epoch 
provided simple computational experiment shows planning concurrent options ective option executed time 
clear connection model concurrent options proposed factored mdps boutilier goldszmidt boutilier appear dean givan 
approach relies factoring set state variables sets behaviors con ict 
compact models actions dynamic bayesian nets 
immediate problem research investigate represent options dbns facilitate compact representations multi options 
compact representations options provide form value function approximation issue ignored 
interesting directions research forms termination condition explored terminate multi option options terminate terminate multi option option terminates interrupt rest continue natural termination 
planning learning concurrent options semi markov options included addition markov options 
learn model multi option reward function transition probabilities multi option investigate termination multi option interrupting multi option higher value continuing multi option sutton 
boutilier dearden goldszmidt 
appear stochastic dynamic programming factored representations 
appear arti cial intelligence 
boutilier goldszmidt 

exploiting structure policy construction 
proceedings ijcai 
bradtke du 

reinforcement learning methods continuous time markov decision problems 
advances neural information processing systems 


learning multidimensional control actions delayed reinforcements 
eighth international symposium system modelling control smc 
poland 
dean givan 

model minimization markov decision processes 
proceedings aaai 
parr 

hierarchical control learning markov decision processes 
doctoral dissertation department computer science university california berkeley 
singh cohn 

dynamically merge markov decision processes 
proceedings nips 
sutton precup singh 

mdps semi mdps framework temporal abstraction reinforcement learning 
arti cial intelligence 
