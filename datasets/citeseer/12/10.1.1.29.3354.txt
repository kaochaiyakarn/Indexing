characterisation behaviour stochastic local search algorithms sat holger hoos thomas st utzle fb informatik fg intellektik tu darmstadt 
darmstadt germany informatik tu darmstadt de stochastic local search sls algorithms successfully applied hard combinatorial problems different domains 
due inherent randomness run time behaviour algorithms characterised random variable 
detailed knowledge run time distribution provides important information behaviour sls algorithms 
investigate empirical run time distributions walksat powerful sls algorithms propositional satisfiability problem sat 
statistical analysis techniques show hard random sat problems walksat run time behaviour characterised exponential distributions 
characterisation generalised various sls algorithms sat encoded problems domains 
result number consequences theoretical practical interest 
fact algorithms easily optimal speed achieved hard problem instances 
successes stochastic local search sls algorithms practically solve hard combinatorial problems various domains considerable interest inspired quickly growing body research 
earlier sls approaches solving satisfiability problem propositional logic sat current sls algorithms breakout method walksat novelty outperform state art systematic search methods variety problem classes shown competitive best algorithms domains planning network routing :10.1.1.47.9719
theoretical understanding behaviour stochastic local search algorithms limited field empirical methods computational experiments 
kind may drawn empirical analysis depends strongly empirical methodology applied 
particular empirical methodology take account important sources randomness performance sls algorithm 
preprint submitted elsevier science july problem instance run time needed find solution varies consequence inherent randomness sls algorithms caused randomised decisions random initial solutions randomly biased moves 
solution cost solving problem instance depends instance cases random sat randomly generated 
clearly seperate sources randomness 
methodology analysing run time behaviour sls algorithms single instances drawn randomised problem class 
empirical run time distributions observed particular sls algorithm applied individual problem instances formulate general hypothesis regarding type run time distributions algorithm problem class 
hypothesis tested validated running series experiments large number instances sampled random problem distribution 
generic methodological approach analyse performance walksat applied random sat prominent randomised np complete subclass sat consisting propositional formulae conjunctive normal form exactly literals clause 
specifically show applied hard random sat instances walksat run time behaviour characterised exponential distributions 
result holds various sat encoded problem classes blocks world planning graph colouring proposed improved variants original walksat algorithm 
number significant implications interesting fact sls algorithms displaying type behaviour easily optimal speedup 
structured way 
reviewing basic notions concerning sls algorithms sat introducing empirical methodology 
empirical analyses behaviour sls algorithms applied randomised problem distributions encoded problem instances domains lead main result 
discuss interesting implications result 
comparing approach related conclude brief main contributions pose questions indicating possible directions research 
sls algorithms sat local search widely general approach solving hard combinatorial search problems 
stochastic local search interpreted performing biased random walk search space defined problem instance sat search space set possible truth assignments variables appearing propositional formula conjunctive normal form cnf 
cnf formula truth variables domain ftrue falseg conjunction clauses clause disjunction literals literal variable negation formula satisfiable assignment truth values variables simultaneously satisfies clauses formula unsatisfiable 
general outline sls algorithm sat 
generic procedure starts truth assignment randomly chosen set possible assignments uniform distribution 
tries reduce number violated clauses iteratively flipping variable truth value selection variable depends formula current assignment maximum flips solution algorithm restarts new random initial assignment 
number tries solution algorithm terminates unsuccessfully 
procedure localsearch input cnf formula output satisfying assignment solution random truth assignment satisfies return truth value flipped return solution local search fig 

outline general local search procedure sat actual sls algorithms differ mainly variable selection function 
article concentrate sls algorithms walksat architecture best performing local search approaches sat 
architecture stage variable selection process focused variables currently unsatisfied clauses 
local search step stage currently unsatisfied clause randomly selected 
second step variables appearing selected heuristic biased increase total number satisfied clauses variable flipped obtain new assignment 
original walksat algorithm referred simply walksat pseudocode function 
function randomly selects element set uniform distribution chosen probability jt jt number elements set 
walksat heuristic chooses variable minimal value break selected clause break remainder random selections considered uniform probability distributions explicitely indicated 
number clauses satisfied current assignment unsatisfied variable flipped 
selected clause variables flipped violating clauses break randomly chosen 
fixed probability wp variable randomly chosen uniform distribution clause probability wp variables minimising number breaks picked 
walk probability wp called noise setting important parameter influencing algorithms performance 
function walksat clause satisfied sg appears break break return probability wp appears cg return wsat fig 

outline function wsat 
article computational results walksat variants 
walksat tabu search walksat tabu heuristic picks variables minimising number breaks 
variables flipped tl iterations tl parameter called tabu list length declared tabu considered flipping 
realise variable associated age age defined number local search steps variable flips flipped time 
variables chosen clause tabu variable flipped called null flip 
give pseudocode walksat tabu 
second strategy called novelty 
strategy chooses variables flipped lead maximal decrease total number unsatisfied clauses score fix break fix number clauses satisfied assignment satisfied variable flipped 
ties broken favour flipped variable 
variable highest score flipped variable clause flipped probability wp second best variable prob implementing algorithm explicitly storing updating variable ages efficient store variable number iteration flipped compare numbers actual ages 
variables selected clause identical score age rarely happens clauses typically short age variables identical flipped search initialisation ties broken ability wp best variable flipped 
pseudocode description variable selection strategy novelty 
analogy refer wp tl parameters different noise parameters 
function walksat tabu clause satisfied sg appears break minimal age fg return return fg walksat tabu fig 

outline function walksat tabu 
function novelty clause satisfied sg list variables occurring ordered decreasing score fix break age element list second element list age age return probability wp return return novelty fig 

outline function novelty 
rtd empirical analysis sls algorithms sls algorithms walksat strongly involve random decisions choice initial assignment random tie breaking biased random moves 
due inherent randomness time needed sls algorithm find solution differs run run single instance 
general run time needed algorithm find solution random variable 
sls algorithms las vegas type algorithm problem class las vegas type problem instance returns solution guaranteed valid solution ii instance run time arbitrary fixed ordering variables appearing formula :10.1.1.47.9719
random variable rt las vegas algorithms fundamentally different criteria evaluation depending characteristics environment supposed 
case time limits type situation mean run time suffice roughly characterise run time behaviour real time situations strict time limit type situation basically meaningless 
time limits considerably lower expected median run time time las vegas algorithm high expected run time give reasonable solution probability short runs 
adequate criterion type situation time limit max rt max probability finding solution time limit 
general case utility function defines usefulness utility solution depending time needed find 
case important able characterise run time behaviour run time distribution function rtd ir 
defined rtd rt approximation 
run time distribution rtd completely uniquely characterises run time behaviour las vegas algorithm 
information criteria mean run time standard deviation percentiles success probabilities rt arbitrary time limits easily obtained 
measure take account sls algorithms cutoff parameter bounding run time parameter 
practically measure empirical running respective las vegas algorithm times restart setting problem instance high cutoff value recording successful run time required find solution 
empirical run time distribution cumulative distribution associated observations 
formally rt denote run time jth successful run cumulative empirical rtd defined rt measuring run time distributions terms cpu time preferable representative operation counts machine independent measure algorithm performance 
appropriate operation count local search algorithms sat example number local search steps get run length distributions rlds run time distributions 
note obtaining run length distributions single instances involve significantly higher computation times get stable estimate mean performance algorithm 
hooker empirical analysis algorithms usually remains stage simply collecting data argues analogous empirical methodology sciences furthermore attempt formulate hypotheses data turn experimentally refuted validated :10.1.1.47.9719
rtd methodology outlined meets demand general discussion application scenarios general advantages measuring run time distributions single instances refer :10.1.1.47.9719
optimal cutoff settings may determined posteriori empirical run time distribution 
analyse run time behaviour sls algorithms sat single hard instances observations basis formulating hypotheses type run time distributions observed algorithms various subclasses sat 
validate hypotheses testing wide range individual problem instances standard statistical methodology testing rld characterisations single problem instances 
note hypotheses concerning problem classes infinite number instances sat generally experimentally verified validation finite number individual instances best 
empirical results random sat section describe generation random sat test sets experiments detail optimised walksat noise parameter problem instances report results regarding characterisation walksat behaviour test sets 
generation problem instances random sat formulae experiments propositional formulae conjunctive normal form clauses consist exactly literals 
number variables clauses formulae randomly generated fixed clause length model clause produced choosing variables random uniform distribution variable chosen independently probability negating variables probability 
clause generation process tautological clauses clauses containing literal negation clauses multiple occurrences literal rejected clauses produced clauses considering rejected clauses generated 
value random distribution random sat formulae test sets generated described correspond samples distributions 
known probability obtaining satisfiable instance sampling specific random sat instance distribution critically depends clauses variables ratio small instances underconstrained satisfiable certain critical value changes abruptly 
critical instances overconstrained unsatisfiable 
called phase transition phenomenon observed number problem classes received lot attention csp sat communities 
sat critical phase transition cross point approximately randomly generated instances soluble occurs large known point average hardness instances maximal systematic local search sat algorithms 
test sets random sat formulae phase transition region pop noise parameter setting coarse analysis refined analysis optimum fig 

functional dependency mean solution cost expected number variable flips finding solution noise parameter setting single random sat instance variables clauses 
shape curve typical walksat applied hard random sat instances see text details 
ular sat algorithm analysis easy generate hard solve 
studying incomplete local search algorithms point evaluating performance unsatisfiable instances filtered randomly generated instances fast complete sat algorithm final test sets contain satisfiable instances 
established methodology guarantees tested algorithm fails find solution instance caused instance unsatisfiable 
optimising noise parameter empirical analyses generally noise parameter walk probability settings chosen expected number steps required finding solution solution cost minimal 
step determined noise parameter settings walksat minimising mean search cost applied individual problem instances 
precise determination optimal noise setting problem instance test sets computationally feasible stage approach 
randomly selected problem instances test set determined mean local search cost noise settings increments runs algorithm 
analysis strongly indicates single instances mean solution cost function noise setting convex single minimum located shows typical example variable instances 
applied method noise settings increments randomly selected instances variable test set randomly selected instances variable test set verify results determine best noise settings accuracy 
results mean solution cost approx opt noise vs mean solution cost fig 

correlation mean solution cost noise parameter setting randomly generated random sat instances variables clauses see text details 
table basic statistics hardness distributions test set mean median stddev stddev mean vars inst vars inst vars inst analysis show mean best noise settings samples 
variance optimal noise setting instances relatively small decrease problem size variation coefficients mean standard deviation 
furthermore correlation mean solution cost optimal noise setting test sets absolute correlation coefficients 
illustrate results give scatter plot mean solution cost optimal noise settings tested instances variable test set corresponding results analogous 
noticed optimal noise value sensitivity search cost small changes noise setting low see 
results approximately optimal noise setting walksat subsequent experiments 
distribution mean solution cost get impression variability solution cost instances test sets determined hardness distributions test sets variables 
shows cumulative distributions median search cost instance measured local search steps test sets 
test vars vars vars fig 

cumulative distributions median local search cost number local search steps solution random sat test sets different problems sizes 
axis shows median search cost walksat axis shows probability median search cost instance bound see text details 
sets contain instances contains instances 
problem instance median search cost determined rld obtained running walksat approximately optimal noise parameter determined described wp tries 
extremely high cutoff parameter allowing long time search unsuccessfully aborted sure instance solved single try 
experiments walksat noise parameter specified sufficiently high cutoff parameter value solution 
indicates walksat noise parameter probabilistically approximately complete soluble problem instance probability solving single try restart converges cutoff parameter approaches infinity :10.1.1.47.9719
seen huge variability instances test set see table 
time increasing problem sizes tail distributions prominent indicating larger problems considerably variability median search cost especially hardest instances test set 
seen normalised standard deviations table 
known averaging extremely inhomogeneous test sets potentially problematic :10.1.1.47.9719
consequently step analysed rld data individual instances 
run length distributions individual instances shows rlds walksat parameter settings described applied easiest median hardest problem vari note probabilistic approximate completeness easy prove restart approximate completeness pure walksat strategy restart unproven 
probability finding solution local search steps easy problem medium problem hard problem fig 

rlds walksat wp tries easiest median hardest problem hardness distribution test set 
table parameter quality rld approximation exponential distributions ed instance median steps ed easy medium hard ables clauses test set 
hardest problem rld approximated cumulative form exponential distribution ed median distribution number steps required find solution 
testing goodness approximation standard test 
basically empirical rld done estimating parameter comparing deviations predicted distribution ed 
result comparison value low values indicate close correspondence empirical predicted distribution 
table shows estimated parameters values easy median hard instance mentioned 
clearly seen increasing median search cost value decreases indicating harder problem closer walksat rld problem approximates exponential distribution 
case pass test standard acceptance level required 
approximation hard instance passes test 
note median easiest problem approximation reasonably tail distribution long runs smaller number steps actual distribution steeper exponential distribution 
approximations done implementation levenberg algorithm fitting parametric functions set data points 
statistical literature exponential distribution exp usually defined equivalent representation ed ln 
acceptance acceptance fig 

correlation hardness problems axis median number local search steps solution values axis testing rlds individual instances versus best fit exponential distribution test set 
horizontal lines indicate acceptance thresholds acceptance level 
acceptance acceptance fig 

correlation hardness problems axis median number local search steps solution values axis testing rlds individual instances versus best fit exponential distribution test set 
horizontal lines indicate acceptance thresholds acceptance level 
ture deviations caused initial hill climb phase local search procedure cf 
walksat algorithms study starts search randomly chosen assignment typically violates clauses 
consequently algorithm needs time reach local optimum possibly satisfying solution initial phase search probability finding solution zero 
observations lead hypothesis hard random sat instances phase transition region run time behaviour walksat approximately optimal noise setting characterised exponential distributions 
investigate hypothesis apply methodology outlined entire test sets 
resulting correlation median search cost values seen scatter plots figures 
ob table number instances passing test different random sat test sets 
test set acceptance level number passed vars inst vars inst vars inst vars inst vars inst vars inst table parameter quality rld approximation exponential distributions ed instance median steps ed bw large bw large bw large 
passed test acceptance level 
strong negative correlation indicating harder problem instances values tend lower leads walksat behaviour accurately characterised exponential distributions 
figures indicate standard acceptance levels test 
seen plots high median search cost instances pass test 
table shows percentage instances passed test different acceptance levels 
data suggests increasing problem size relatively higher number instances pass test deviations rlds ideal exponential distributions prominent larger problems 
summary data tests confirms refines hypothesis hard random sat instances phase transition region run time behaviour walksat approximately optimal noise setting approximated exponential distributions 
random sat applying methodology described previous sections sls algorithms sat encoded problems domains obtain similar results described random problem distributions 
fig 
shows rlds novelty walksat variants complete rld data experiments described available authors 
probability finding solution local search steps bwa novelty wp novelty wp novelty wp fig 

rlds novelty approx 
optimal noise setting sat encoded blocksworld planning problems 
probability finding solution local search steps walksat wp walksat tabu tl novelty wp fig 

rlds walksat walksat tabu novelty approx 
optimal noise settings sat encoded graph colouring problem 
applied sat encoded problem instances blocks world planning domain 
approximately optimal noise parameter settings wp blocks world planning instances bw large determined described section settings high resp 
ensure success rate 
bw large runs problems runs approximate actual rlds described 
estimates parameter corresponding values approximation exponential distributions shown table 
critical values standard acceptance level tries tries 
means smallest instance approximation pass test 
easy random sat instances interpret effect initial hill climb phase local search 
problem instances sat formulation obtained linear encoding simplifying :10.1.1.47.9719
similar results obtained problem instances domain 
table parameter quality rld approximation exponential distributions ed algorithm median steps ed walksat walksat tabu novelty final experiment applied methodology sat encoded problem instance graph colouring domain different variants walksat standard walksat walksat tabu search novelty 
determined approximately optimal noise parameter settings described section wp walksat tabu list length walksat tabu wp novelty 
algorithm performed tries large value 
experimental results shown table 
algorithms approximations empirical rlds exponential distributions passed standard test 
summary results section show hypothesis formulated tested random sat previous section holds hard sat encoded problem instances domains 
furthermore restricted walksat applies variants basic algorithm show significantly better performance 
experimental experience conjecture regular behaviour observed algorithms applied hard problem instances general property current sls algorithms sat 
interpretation empirical results sections number theoretically practically interesting consequences 
random restart algorithms exhibiting exponential rld probability finding solution fixed time interval independent run time spent 
results holds various current sls algorithms sat approximately optimal noise parameter settings 
experimentation indicates exponential rlds characteristic noise parameter values larger optimal noise parameter settings cf 
:10.1.1.47.9719
analysing walksat behaviour random sat test set outlined section larger optimal noise settings wp get acceptance rates resp 
test instance vertices connectivity corresponding phase transition type graph colouring problem :10.1.1.47.9719
probability finding solution local search steps wp wp wp fig 

rlds novelty applied hardest instance random sat test set section approx 
optimal wp smaller optimal noise settings 
acceptance level 
approximately optimal larger optimal noise settings sls algorithms essentially memoryless total time restarting time significantly influence probability finding solution time consequently algorithms random restart ineffective 
practice result easily verified broad range settings 
due small deviations extreme left rlds low settings algorithms performance usually deteriorates 
argued section effect initial hill climbing phase sls algorithms hill climbing approaches 
smaller optimal settings noise parameter different situation cf 
:10.1.1.47.9719
rlds steep exponential distributions means efficiency search process decreases time random restart effectively speed algorithm 
typical example showing rlds novelty applied hardest instance random sat test set approx 
optimal smaller optimal noise settings 
note small runs inferior small noise settings achieve higher success probabilities 
wp restarting steps particular case gives better performance wp setting 
wp novelty performance sensitive wp rld approximated exponential distribution standard test accepts value argued algorithm performance essentially independent 
exam reported table approximately optimal noise value wp corresponding acceptance rate 
exponential distribution memoryless reliability theory describe components subject aging phenomena transistors 
ple demonstrates usefulness rld analysis tradeoff performance robustness restart easily seen rlds comparing means standard percentiles median revealed phenomenon 
consequences parallel processing randomised algorithms lend straightforward parallelisation approach performing independent runs algorithm parallel 
characterisations exponential rlds sat approach particularly effective known result statistical literature algorithm probability finding solution time units distributed exponentially ed probability finding solution independent runs time distributed ed 
consequently run algorithm time get success probability running algorithm times time means multiple independent runs corresponding local search algorithms optimal speedup achieved 
holds arbitrary numbers processors high due deviations short runs caused initial hill climb phase local search speedup optimal 
note result holds optimal larger optimal noise parameter settings 
smaller optimal settings processing time number processors time processor fixed single optimal number processors derived rtd data super optimal speedup obtained compared sequential case 
formally problem instance success probability achieved single processor total processing time success probability running independent runs different processors parallel processing time 
consequently rtd optimal number processors maximising 
easily verified achieves maximal speedup 
noted parallel execution independent tries extremely attractive model parallel processing involves basically communication overhead easily implemented run parallel hardware platform networks standard workstations specialised mimd machines thousands processors 
results relevant application sls algorithms hard combinatorial problems sat tasks robot control online scheduling distributed solving large hard problem instances 
related characterised run time distributions walksat high performing stochastic local search algorithms sat 
shown approximately optimal noise parameter settings single hard random sat instances sat encoded problems approximated tial distributions 
compared simple descriptive statistics usually done previous analysing run length distribution gives detailed information sls algorithms behaviour performance causing significant computational overhead 
additionally rlds provide information required assessing sls algorithms context general application scenarios realtime anytime situations runtime limitations imposed application environment strict expected median run time irrelevant cf 
section 
best knowledge run time distributions investigated local search algorithms sat domain 
search cost distribution finding satisfying assignment ensemble instances complete procedures sat studied 
distribution search cost sls algorithms corresponds hardness distribution shown 
hardness distributions find approximation standard families probability distributions 
mainly due long tail right side empirical hardness distributions representing hardest instances 
clearly separate different sources high variability observed sls algorithms run time behaviour applied test sets randomly generated problem instances methodology empirically studying sls behaviour single instances 
similar approach proved essential assessing potential parallel processing randomised complete backtracking algorithms graph colouring :10.1.1.47.9719
shows focussing observations single problem instances useful analysis randomised complete search algorithms 
lines observe distributions single instances find heavy tailed distributions search cost randomised complete procedures quasigroup completion problem 
sls algorithms studied contrary observe heavy tailed distributions rlds hardness distributions 
demonstrates adequate methodology empirically analysing run time behaviour sls algorithms obtain new surprisingly general hypotheses 
hypotheses concerning type rlds dependency noise parameter setting crucial parameters current sls algorithms experimentally verified standard statistical testing procedures 
hypothesis validate rlds hard random sat instances phase transition region sat encoded problems domains characterised exponential distributions 
generalising individual instance behaviour problem class main motivation approaches system automatically configures search algorithms problem class training set typical instances 
results empirical investigation derived number theoretically practically interesting consequences 
results give algorithms complete involve randomised decisions single nodes search tree 
rise number new questions common features different sls approaches leading uniform behaviour exponential run time distributions hard instances various problem classes reported 
causes observed run time behaviour 
exponential distributions characteristic simplest randomised search technique uniform random picking set solution candidates 
observing type behaviour sophisticated efficient algorithms sls algorithms studied suggests behaviour interpreted random sampling smaller space 
evidence interpretation established linking hypothetical virtual features actual search space number size topology local optima 
results generalised optimisation problems 
sls algorithms decision problems sat implicitly solve corresponding optimisation problem max sat solutions sat stochastically maximising number satisfied clauses generalisation natural provide insight behaviour sls algorithms 
convinced pursuing line research significantly contribute deepening understanding stochastic local search facilitate development application improved sls techniques 
bart selman david mcallester david poole wolfgang bibel members group tu darmstadt interesting discussions comments earlier versions article 
gratefully acknowledge comments suggestions anonymous reviewers greatly helped improve presentation 
acknowledges support german national merit foundation iris iii project interactive optimization preference elicitation bou 
acknowledges support deutsche forschungsgemeinschaft dfg systeme fur die informations und marie curie fellowship cec tmr contract 
erb gt 
alt guibas mehlhorn karp wigderson :10.1.1.47.9719
method obtaining randomized algorithms small tail probabilities 
algorithmica 
barlow 
statistical theory reliability life testing 
holt reinhart winston reprint 
crawford auton 
experimental results crossover point random sat 
artificial intelligence 
frost rish vila 
summarizing csp hardness continuous probability distributions 
proceedings aaai pages 
gent walsh 
understanding hill climbing procedures sat 
aaai pages 
mit press 
gent walsh 
empirical analysis search gsat 
journal artificial intelligence research 
gomes selman crato 
heavy tailed distributions combinatorial search 
cp volume lncs pages 
springer 
gu 
efficient local search large scale satisfiability problems 
sigart bulletin 
hogg huberman williams 
phase transitions search problem editorial 
artificial intelligence 
hogg williams :10.1.1.47.9719
expected gains parallelizing constraint solving hard problems 
aaai pages 
hogg :10.1.1.47.9719
refining phase transition combinatorial search 
artificial intelligence 
hooker :10.1.1.47.9719
needed empirical science algorithms 
operations research 
hooker :10.1.1.47.9719
testing heuristics wrong 
journal heuristics pages 
hoos :10.1.1.47.9719
stochastic local search methods models applications 
phd thesis tu darmstadt germany 
electronically available www cs ubc ca spider hoos phd thesis html 
hoos :10.1.1.47.9719
run time behaviour stochastic local search algorithms sat 
proceedings aaai appear 
electronically available www cs ubc ca spider hoos publ ai html 
hoos stutzle :10.1.1.47.9719
evaluating las vegas algorithms pitfalls remedies 
proceedings uai pages 
morgan kaufmann publishers 
hoos stutzle :10.1.1.47.9719
characterizing run time behavior stochastic local search 
technical report aida fg intellektik tu darmstadt january 
jiang kautz selman :10.1.1.47.9719
solving problems hard soft constraints stochastic algorithm max sat 
proceedings st workshop artificial intelligence operations research 
kautz selman :10.1.1.47.9719
pushing envelope planning propositional logic stochastic search 
aaai volume pages 
mit press 
luby sinclair zuckerman 
optimal speedup las vegas algorithms 
information processing letters 
mcallester selman kautz 
evidence invariants local search 
proceedings aaai pages 
mitchell selman levesque 
hard easy distributions sat problems 
proceedings aaai pages 
minton 
automatically configuring constraint satisfaction programs case study 
constraints 
morris 
breakout method escaping local minima 
proceedings aaai pages 
rohatgi 
probability theory mathematical statistics 
john wiley sons 
selman henry kautz cohen 
noise strategies improving local search 
aaai pages 
mit press 
selman levesque mitchell 
new method solving hard satisfiability problems 
aaai pages 
mit press 
yokoo 
adding constraints problem easier hill climbing algorithms analyzing landscapes csps 
proceedings cp pages 
springer verlag 

