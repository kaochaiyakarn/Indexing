ieice trans 
fundamentals vol october learning bayesian belief networks minimum description length principle basic properties joe suzuki member summary pape ne works bbn base onthe pa principle give formula tion base ml base led bbn 
se point thatthe di ea ml base coop tially inthe priors inthe xd class priors formula show usingthe formula ofthe chow liu algorithm algorithm finds ase base onthe key words minimum description length principle bayesian belief network chow liu algorithm cooper herskovits procedure mdl procedure stochastic rule learning 
bbn directed acyclic graph edge directs de represen ts cause ts ect 
suppose des prepared partially rule causes 
loss cm assumed 
ode represen ts attribute takes fm set 
structure sets set des dep en probability occur expressed probability manuscript received may 
manuscript revised april 
author faculty science osaka university osaka shi japan 
partially th conference uncertainty artificial intelligence july 
probability occurs 
subset mean addition structure dc probabilities bbn chm phase quan values des des 
posterior probabilities values dcm des des 
values des values probability eq 
maximized shows model 
qc probabilities supposed estimated examples example coma observed prior replaced posterior probabilities bayes theorem wecan kn probability tumor chan asin fig 

gen con fc struct dep en subjectivity criterion rule selected mh terms simplicity example basedon emitted bee tan ted method source exactly 
possible strategy clear hurdle mj scan en de source de basedon estimated source fin rce sen source decoded 
upper lower cases denote stochastic variable real value respectively 
ieice trans 
fundamentals vol october state de state de ece de coma de stomach coma fig 
ne 
coma 
fig 
ane ex es problem estimate source 
mdl prin suggests estimate source source ded min qcd terms sequence source replaced terms rule 
mean acquire rule examples 
particular implicitly assume stochastic rule dh proposed 
un df idea man cases examples rule emitted stochastically due fc rule stochastic proposed procedure works actual rule ch derive formula len cr examples calculate values len cr rules wecan compare fin rule mdl 
sin fc problem bbns assumed example isin pen rule bbn specifies wherex value th attribute th example sect 
derive formula len cr problem expressed log terms tropy structure examples en tcon dition structure set possible structures 
improved termin eq 
decreases mh simplicity structure gets worse termin eq 
qc jc value eq 
wecan obtain terms len cri basedon bayesian statistics similar method proposed cooper herskovits 
cooper herskovits ch procedure fin structure maximum posterior probability basedon examples sect 
di types priors con hf probabilities approaches mdl bayesian approaches di advan mdl procedure ch procedure 
mdl procedure theoretical description len cr eq 
modified version liu cl algorithm derived :10.1.1.19.371
cl algorithm fin un qh maximum tree basedon examples cited successful early modified version takes cost edges likelihood tree examples shown sect 

structure lon hm tree set trees see fig 

author suzuki bbn learning fig 
ase japan learn stochastic rules amon attributes basedon mdl prin ch wasn aware application bbns 
cf con un uai july 
coin tally lam bacchus tation en len cr di eq 
modified version cl procedure 
bouckaert author author talk con cf started subject 
result heuristic search refers mdl heuristic search algorithm ch procedure 
th methods fun crawford pearl geiger paz pearl verma pearl prin qc way attach prior probabilities ff edges sets edges addition methods threshold values determin mj er en er holds amon attributes 
previous 
show stochastic rules amon attributes applied bbns 
show di ch procedures 
fh modified cl algorithm arbitrary 

mdl procedure len cr basedon proposed bbn examples 
len cr structure wecan obtain structure achieves mdl 
formally procedure basedon stated follows algorithm 


output 
aren jc qc part sect 
sect 
sects 
learn stochastic rules attribute con problem dh stochastic rule examples wherex attribute class respectively stochastic rule mdc probability class attribute jin terms model con mm model model refers way subsets termed states 
set model foran ieice trans 
fundamentals vol october attribute states 
con cff qh probability refers probability model probabilities state probability class calculated probabilities classes 
suppose model fixed 
loss gen wecan len cr ofy log weight fun model problem determin thelen fun hd gin eq 
reduces afun satisfies eq 

weight fun expressed dirichlet distribution parameter aq gamma fun ma ofx dz lemma lemma eq 
thelen fun gin eq 
log tropy log model 
see proof 
notice reason assume eq 
jd stochastic rules 
priors mdl ch eq 
respectively 
eq 
sect 
compare procedures fd model fixed ran lemma rules er gives len cr log see proof 
learn stochastic rules amon attributes con problem dj stochastic rule amon attributes examples wherex stochastic rule probability attribute words product qc probabilities see eq 
terms model gan con tion probabilities 
model refers way iin subsets termed states stage set states model foran con probability refers probability model probabilities foran actual situation su ces compare values description len len cr rules attribute lemma 
len cr 
denotes cardinality set 
suzuki bbn learning lemma eq 
gives description len ri rules amon attributes tropy log log respectively model learn bbns con fin problem jj bbn nin la previous subsection problem tractable set fairly restricted 
basic idea decide set theorem si structures expressed bbns comparison required structure mdl respectively 
proof determin state sets su ces decide sets notice id en id sin id pen 
sin possible structures aren obtain structure mdl sin comparison isn total example suppose des prepared ordered fig 

example suppose 
paren set possible decide sets possible respectively decide sets possible respectively decide 
structures bbns example 
fig 
possible ne structure 
ben comparison gets exp tially example ben bbns evaluated isin cc qc usual computer systems evaluate compare len cr assume bbns gen stochastic rules amon attributes problem computation isan part fh bbns 
theorem eq 
gives description len bbns tion probabilities 
proof sin learn bbns isin jj learn stochastic rules amon attributes eq 
gives len cr bbn 
furthermore structure bbn paren ts sets state set holds 
eqs 
eq 
holds 

comparison bayesian approach bayesian approach struc ieice trans 
fundamentals vol october ture selected maximizes posterior probability prior probability probability ofx sin den ff maximization ch procedure sin assumed just term maximized 
han mdl procedure structure selected min description len ri log log afun satisfies afun fmc satisfies eq 
refer description len cr structure gan structure mdl procedure sin iso essen tially term log note un un prior probabilities specified 
precisely expressed probability occurs con md probabilities eqs 

see eq 

sin ch procedure assumes prior con probabilities sets selected maximize 

han rin mdl procedure eq 

ch mdl procedures priors approaches bayesian similarly bayesian approach mdl approach prior possible prior den prior parameter gen prior mdl bayesian approaches able reason :10.1.1.156.9918
prior advan properties prior favorable hypothesis exists priori kn wn bayesian theory 
simple formula asin theorem prior applied similar formula derived precisely residual eq 
case 
see 
merits simple formula eq 

thin easy stan trade simplicity examples terms hf qc tropy 
len cr asin eq 
wecan replace term log tion ofn mdl aic akaike sin mation criterion refer cases log nan respectively wecan con trol basedon criteria 
procedure lon cj mdl better obtain addition sect 
algorithm provides mdl procedure theoretical justice 

modified version chow liu algorithm probability eq 
expressed tree form suzuki bbn learning permutation hf distribution modified version cl algorithm refers algorithm fin tree description len cri trees span tree set trees see fig 

sets den distribution zero un origin algorithm 
trees cc cost edges trees mdl edges selected greedily 
simplified version ted author 
sin time con mcc bbns bin algorithm version arbitrary 
algorithm outputs set pairs trees log den maximum likelihood estimator obtain relative examples 
algorithm 
en dj pair queue qin qc order log log 
empty dequeue pair des ian di comment sets replace set add tot 
theorem algorithm fin tree min eq 
exten mc den mc distribution proof appropriate permutation eq 
form 
con fh sin attribute takes values states probabilities associated addition ifx 
log log log log holds log con cd sin attribute takes values state hff qc probabilities associated de han eq 
log wecan compute len cr log 
sin value termin eq 
con fj len cri just st value ieice trans 
fundamentals vol october log decide pair con completes proof 
algorithm term log replaced gen term sect 
order factors basedon criteria 
said cl algorithm refers case selects maximum likelihood model :10.1.1.19.371

concluding remarks gave mdl procedure len cr bbn learn mc derived 
furthermore ted mdl ch procedures priors approaches bayesian fin showed merits simple formula asin eq 
particular modified version cl algorithm derived discussion akaike ne look atthe statistical mo ieee trans :10.1.1.19.371
automatic control vol ac pp 
blahut principle addison 
construction minimum dea lee principle te ch rep ht ruu cs july 
chow liu approximating probability distributions ieee trans :10.1.1.19.371
inf vol pp may 
clarke barron prior favorable unde tropy risk statistical planning 
coop mea constructing ne works ty artificial ucla ca pp july 
fung crawford constructor induction probabilistic aaai pp boston ma july 
ge paz pea lex causal tre emd information aaai pp boston ma july 
je probability oxford :10.1.1.156.9918
lam bacchus causal information local med ne works ty artificial pp washington july 
px morgan kaufmann ca 
pew ree vex causal poly tre statistical data dx ty artificial inte pp se washington july 
pa annals statistics vol pp 
srinivas agogino automate construction ne works probabilistic domain information tainty artificial inte edx hex kanal le north holland pp 
suzuki onthe sex mex stochastic base onthe wa principle andthe state transactions information japan vol pp 
suzuki coding minimizing minimax unknown ieice trans 
vol pp july 
suzuki dw ne works base onthe algorithm usingthe branch int 
conf 
machine lee bari italy july 
pex causal ty artificial inte pp cambridge ma july 
wallace fre estimation efe compact coding royal stat 
soc 
vol pp 
yamanishi stochastic machine vol pp 
appendix proof lemma se fm aan respectively 
mcd brackets eq 
obtain eq 
fact holds 
suzuki bbn learning qh formula exp exp log log applied 
similarly odd exp log log applied 
hcm formula exp log sum jin eq 
log log log log log log log sin completes proof 
appendix proof lemma cc log alen jm fun ft exp holds 
lemma lg proof 
appendix suppose 
eq 
log log log han lemma foran log holds 
joe suzuki born tokyo japan re de tokyo japan re faculty ofthe osaka osaka japan visiting assistant stanford brown associate px osaka inte mainly analyse statistical mo tion bew ne works ges dx algorithms curve 
