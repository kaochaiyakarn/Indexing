inductive logic programming method corpus parser construction john zelle raymond mooney dept math computer science dept computer sciences drake university university texas des ia austin tx zelle zelle drake edu mooney cs utexas edu march empirical methods building natural language systems important area research years 
current approaches propositional learning algorithms applied problem acquiring broad coverage parsers relatively shallow syntactic representations 
outlines alternative empirical approach techniques subfield machine learning known inductive logic programming ilp 
ilp algorithms learn relational order rules parser acquisition system called chill learns rules control behavior traditional shift reduce parser 
approach chill able learn parsers variety different types analyses traditional syntax trees meaning oriented case role database query forms 
experimental evidence shows chill performs comparably propositional learning systems similar tasks able go broad shallow paradigm learn mappings directly sentences useful semantic representations 
complete database query application parsers learned chill outperform existing hand crafted system demonstrating promise techniques automating construction certain nlp systems 
enduring goals natural language processing design parsers translate natural language inputs internal representation suitable computer manipulation 
traditional nlp focused approach parsing problem searching perspicuous rule representations knowledge required language processing 
despite progress traditional nlp succeeded producing accurate robust broad coverage systems understanding english natural languages 
construction limited domain applications remains difficult time consuming yielding systems inefficient incomplete 
fielded systems ad hoc quality porting new domains mean essentially starting scratch 
partially response difficulties increasing interest empirical approaches natural language processing 
empirical alternative successful speech recognition replaces hand generated rules models obtained automatically training language corpora 
corpus methods may augment knowledge traditional parser example acquiring new case frames verbs manning acquiring models resolve lexical attachment ambiguities lehman hindle rooth 
radical approaches attempt replace hand crafted components altogether extracting required linguistic knowledge directly suitable corpora 
ambitious approach main focus discussion applies equally piecemeal approaches 
empirical methods effectively divide building natural language systems tasks annotation corpus building acquisition 
annotation province human experts mechanical help 
devise training corpus demonstrates type nl analysis required 
example desired system syntactic parser required corpus large sampling text paired desired syntactic parse trees 
corpus called treebank marcus santorini marcinkiewicz :10.1.1.14.9706
systems raw unannotated text grammar acquisition employing annotations produced accurate parsers 
second task acquisition machine learning problem 
suitable training corpus learning algorithms employed automatically construct parser map subsequent inputs de training examples learning system parser sentence meaning parser acquisition problem 
representation 
parser acquisition problem depicted 
development successful parser acquisition system allow human designers concentrate engineering useful representations difficult issue constructing parser representations acquisition system 
far empirical techniques employed largely attempt create broad coverage parsers relatively shallow representations part speech tagging merialdo charniak hendrickson jacobson perkowitz induction stochastic context free grammars transition networks miller bobrow ingria schwartz 
footsteps speech recognition research methods eschew traditional symbolic parsing favor statistical probabilistic methods 
current methods learn symbolic structures decision trees black lafferty magerman mercer roukos magerman transformations brill traditional statistical methods dominate 
fact term parsing frequently restricted process determining syntactic structure sentence hierarchy labeled constituents 
hierarchy considered resulting unlabeled bracketings 
parsing narrow sense represents small part understanding problem 
going syntax uncover important content requires semantically oriented representation 
traditional nlp systems employ representations deeper logical forms amenable manipulation automated deduction capture content 
dealing richer structure empirical framework presents interesting challenge 
common thread previous empirical approaches acquired knowledge represented propositional form associated probabilities 
means example decision label node parse tree considering fixed set properties syntactic category fixed context surrounding nodes parent immediate left sibling 
specifics decision policy determined acquisition algorithm context policy formed exact properties tested determined priori designer acquisition system 
machine learning approaches called feature vector representations decision context specified finite vector atomic values associated various features interest 
advantage propositional approaches corresponding learning algorithms implemented efficiently allowing systems trained large corpora 
important consideration construction broad coverage syntactic parsers 
propositional techniques difficult apply recursive richly relational domains example kind logical forms target nlp research utilizing unification grammars 
presents approach empirical parser construction employs learning algorithms structured relational knowledge representations type employed traditional nlp 
inductive logic programming ilp growing subfield machine learning addresses problem learning order logic descriptions prolog programs examples lavrac dzeroski muggleton 
due expressiveness order logic ilp methods learn relational recursive concepts represented feature languages assumed machine learning algorithms 
ilp methods successfully induced small programs sorting list manipulation quinlan produced encouraging results important applications predicting protein secondary structure muggleton king sternberg 
detailed experimental comparisons ilp feature induction demonstrated advantages relational representations language related tasks text categorization cohen generating past tense english verb mooney califf 
research attempts bridge gap rational empirical approaches nlp applying ilp problem parser acquisition 
main advantage approach flexibility 
power order rules need hand engineer appropriate features contexts system learns 
induction algorithm automatically extract relevant portions structured contexts construct new predicates represent novel syntactic semantic lexical phrasal categories needs parsing decisions 
flexibility single learning system able learn parse sentences wide variety representations including syntax trees case role mappings logical formulations predicate calculus 
contrast statistical approaches emphasize broad coverage shallow parsing interested empirical approaches rapidly construct domain specific parsers produce usable semantic representations 
describe discuss initial implementation approach called chill constructive heuristics induction language learning 
chill uses ilp techniques learn heuristic rules controlling deterministic shift reduce parser written prolog 
section provides ilp may parser acquisition 
section gives detailed description chill way simple case role parsing example 
section presents details ilp induction algorithm chill 
section presents experimental results demonstrating chill performance case role mapping tasks constructing parse trees atis corpus penn treebank logical forms database queries 
sections discuss related section presents 
ilp parser construction ilp ilp research considers problem inducing order definite clause logic program set examples background knowledge 
stands intersection traditional fields machine learning logic programming 
sample ilp task consider learning concept list membership 
input learning system consists number positive negative instances predicate member 
positive instances member member member 
instances member member serve negative examples 
additional information provided form background relations terms desired concept learned 
case list membership information include definition concept components standard notation indicate name arity number arguments predicate 
square brackets standard prolog notation list construction 
list containing 
decomposes list component head tail 
type constructor predicate typically ilp systems learn function free clauses components eliminates need list constructions xjy learned clauses 
input ilp system attempts construct concept definition entails positive training examples negatives 
case hope learn correct definition member member list components list tail 
member list components list head tail member tail 
top ilp algorithms ilp research clustered basic induction methods top bottom 
top ilp algorithms learn program clauses searching space possible clauses general specific manner analogous traditional machine learning approaches inducing decision trees 
best known example quinlan foil quinlan cameron jones quinlan uses information heuristic guide search space possible program clauses 
foil learns program clause time greedy covering algorithm summarized follows positives cover positive examples 
positives cover empty find clause covers preferably large subset positives cover covers negative examples 
add developing definition 
remove examples covered positives cover 
clause covers example head clause unified example body clause subsequently provable background relations 
notation xjy denotes prolog list head tail element list list remaining elements 
find clause step implemented general specific hill climbing search adds antecedents developing clause time 
step evaluates possible literals added selects maximizes information gain heuristic sets positive negative tuples covered clause 
tuple simply instantiation variables appearing clause cover example 
single example may give rise multiple tuples distinct proofs example producing different variable bindings 
foil considers adding literals possible predicate long arguments existing variable bound head previous literal body 
literals evaluated number positive negative tuples covered preferring literals cover positives negatives 
set tuples covered clause tuples covered extending clause literal denote number positive tuples set define gamma log jt chosen literal maximizes gain delta gamma number tuples extensions number current positive tuples covered 
computes information content knowing tuple covered current clause represents positive example 
gain difference residual information content subset tuples covered adding antecedent 
positive tuples higher concentration compared negative ones results better gain 
illustration consider learning concept member 
initially positives cover contains positive examples provided list membership 
foil starts general clause member true 
clause covers positive negative examples foil attempt specific adding literals 
background predicate provided components foil evaluates possible literals formed predicate recursive literals member 
possible literals components take form components components components components unique try predicate 
obvious literal components show positive gain covers number positive examples asserting membership element list covers negative examples 
literal may chosen generate clause member components 
clause covers negative examples complete 
foil uses clause learned definition covered examples removed positives cover 
iteration foil starts clause member true examines possible literals 
previously chosen literal components gain longer examples positives cover cover 
components positive gain 
gain comes fact positive examples non empty list negative examples empty lists non lists second argument position 
literal covers positives excludes negatives 
choosing literal produces clause member components 
clearly clause cover negative examples member foil continues add literals 
adding literal member clause consistent examples positives cover excludes negative examples 
point desired clause definition learned 
described referenced papers foil includes additional features heuristics pruning space literals searched methods including equality negation failure useful literals immediately provide gain determinate literals pre pruning post pruning clauses prevent fitting methods ensuring induced programs terminate 
bottom ilp algorithms bottom methods search program clauses starting specific clauses attempting generalize 
logic programs general clauses may prove specific consequences resolution theorem proving 
bottom induction inverts resolution process derive general clauses specific consequences 
effect compression concept definition replacing specific instances general clauses instances derived 
successful representative class muggleton feng golem muggleton feng 
foil golem may viewed greedy set covering algorithm new clauses hypothesized considering general generalizations specific clauses plotkin 
clause subsumes clause substitution variables literals subset literals informally turn dropping conditions changing constants variables 
subsumes proved proved imposes fewer conditions 
said general assuming subsume case clauses equivalent renaming variables 
lgg clauses defined general clause subsumes lgg easily computed matching compatible literals clauses literals differing structure lgg contains variable 
identical pairings differing structures occurs variable pair locations 
example consider specific clauses concerning concept uncle context known relationships uncle john deb sibling john ron sibling john dave parent ron deb parent ron ben male john male dave female deb 
uncle bill jay sibling bill bruce parent bruce jay parent bruce male bill male jay 
lgg clauses yields complicated result uncle sibling sibling parent parent parent parent male male male male 
replaces pair replaces replaces note result contains parent literals duplicates corresponding ways matching pairs parent literals original clauses 
similarly literals male 
worst case result lgg operation may contain literals input clauses length example lgg contains female literal second clause contain compatible literal 
straightforward simplification result removing redundant literals yields uncle sibling parent male 
clauses defining general concept uncle 
construction lgg clauses sense context free 
resulting generalization determined strictly form input clauses consideration potential background knowledge 
order take background knowledge account golem produces candidate clauses considering relative positive examples respect background knowledge 
idea start assumption background information relevant determining particular instance positive example 
positive example represented clause form ground ground conjunction true ground literals derived background relations 
case member include facts components components components rlgg examples simply lgg examples representative clauses 
lgg process serves generalize away irrelevant conditions 
difficulty approach interesting background relations give rise infinite number ground facts 
example finite set facts completely describes components relation lists may indefinitely long 
golem builds initial representative clauses examples considering finite subset corresponding facts derived background predicates fixed number binary resolutions 
greedy clause construction algorithm golem takes form pairs random sampling pairs positive examples fc pairs rlgg set pair best cover rlgg examples random sampling positive examples fc examples rlgg find produces greatest cover examples examples gamma cover rlgg increasing cover golem starts sampling pairs uncovered positive examples 
rlgg covers positive examples covering negatives generalized rlgg random samplings positive examples 
process terminates subsequent fail cover examples consistently covering negative examples 
foil golem includes number filtering clause pruning heuristics search process efficient prevent fitting 
overview chill straight forward application ilp parser acquisition simply corpus sentences paired representations parse trees set positive examples ilp system 
learning prolog definition predicate parse sentence representation prove goals having second argument uninstantiated producing parses input sentences 
convenient set negative examples obvious set background relations provide learned clauses 
parsers complex programs existing ilp system induce complete parser scratch generalizes new inputs 
space logic programs simply large learning problem unconstrained 
chill attempts address problem considering parser acquisition control rule learning problem 
ilp techniques directly learn logic grammar chill begins welldefined parsing framework uses ilp learn control strategies framework 
treating language acquisition control rule learning problem new idea 
berwick approach learn grammar rules marcus style deterministic parser 
system came parsing impasse new rule created inferring correct parsing action creating new rule certain properties current parser state trigger conditions application 
similar vein simmons yu final example analysis control rule induction program specialization training examples control examples control rules overly general parser parsing operator generator parser prolog prolog chill architecture controlled simple shift reduce parser storing example contexts consisting syntactic categories fixed number stack input buffer locations 
new sentences parsed matching current parse state stored examples performing action corresponding best matching previous context 
probabilistic parsing methods employed frameworks learning prefer parsing operators context briscoe carroll magerman 
systems feature vector representations limited fixed size access parsing context 
chill parser states simply represented structured logical terms 
exact form parser state depends type representation parser expected produce includes complete contents stack remaining input string 
burden discovering relevant structural differences complex unbounded context placed ilp learning algorithm 
input chill set training instances consisting sentences paired desired parses 
output shift reduce parser prolog maps sentences parses 
shows basic components system 
parser operator generation training examples analyzed formulate overly general shift reduce parser capable producing parses sentences 
initial parser overly general produces great spurious analyses input sentence 
example analysis overly general parser parse training examples extract contexts various parsing operators employed 
control rule induction employs general ilp algorithm learn rules characterize contexts 
program specialization folds learned control rules back overly general parser produce final parser 
section explains details chill context simple case role mapping problem 
concreteness simplicity problem allow comprehensible complete explanation mechanisms employed chill 
additional information general framework applied produce syntactic parse trees logical queries provided section 
acquiring case role parser chill mapping problem case theory fillmore decomposes sentence proposition represented main verb various arguments agent patient instrument represented noun phrases 
basic mapping problem decide sentence constituents fill roles 
case analysis part task sentence interpretation problem nontrivial simple sentences 
consider sentence case analysis examples mcclelland kawamoto 
boy hit window 
hit agt boy pat window 
hammer hit window 
hit inst hammer pat window 
hammer moved 
moved pat hammer 
boy ate pasta cheese 
ate agt boy pat pasta cheese 
boy ate pasta fork 
ate agt boy pat pasta inst fork sentence subject boy agent 
second subject hammer instrument 
role played subject determined grounds boys animate 
third sentence subject hammer interpreted patient illustrating importance relationship surface subject verb 
sentences prepositional phrase attached verb making fork instrument ate object cheese accompaniment pasta semantic knowledge required correct assignment 
constructing overly general parser system adopts simple shift reduce framework case role mapping simmons yu 
process best illustrated way example 
consider sentence man ate pasta 
parsing action stack contents shift shift man det man det shift ate man det agt ate agt man det shift ate agt man det shift pasta ate agt man det det pasta det ate agt man det obj ate obj pasta det agt man det shift reduce parsing man ate pasta begins empty stack input buffer containing entire sentence 
step parse word shifted front input buffer stack top elements stack popped combined form new element pushed back stack 
sequence actions stack states simple example shown 
action notation label indicates stack items combined role label item stack position head 
advantage assuming constrained parsing mechanism form structure building actions limited 
operations required construct case representation directly inferable representation 
general structure building action required unique case role appears analysis 
set actions required produce set analyses union actions required individual analysis 
shift reduce parser easily represented logic program 
state parse reflected contents stack input buffer 
distinct parsing action operator takes current stack input produces new ones 
shows overly general program sufficient parse example 
parse predicate takes list words representing sentence returns case structure 
parse predicate maps stack input buffer arguments new stack buffer third fourth arguments 
mapping performed zero applications simple actions represented op takes current stack input string produces updated stack input string 
example clause op implements agt action 
reduce predicate simply attaches value head label produce new structure 
extending program parse examples accomplished adding additional clauses op predicate 
clause direct translation required parsing action 
mentioned earlier identification necessary actions straight forward 
particularly simple approach include actions agt agt role training examples unnecessary operator clauses removed program subsequent specialization process 
example analysis overly general parser produces great spurious analyses training sentences conditions specifying appropriate various operators 
order eliminate spurious parses appropriate context operator applied needs characterized 
chill specializes parser including control heuristics guide application operators 
clause op chill constructs definition concept subgoals clause useful 
definition concept comprises set clauses examine stack input buffer satisfied exactly states operator applied 
job example analysis parse parse parse parse 
parse stack input stack input 
parse stack stack op stack stack parse stack stack 
op top second rest newtop rest reduce top agt second newtop 
op top second rest newtop rest reduce top det second newtop 
op top second rest newtop rest reduce second obj top newtop 
op stack word words word stack words 
shift operation 
overly general parser man ate pasta construct sets positive negative control examples appropriate control rules subsequently induced 
control example specific subgoal particular operator clause may applied course parsing example 
operator positive control examples represent parse states operator applied 
examples generated finding correct parsing training pair overly general parser subgoal operator applied successful parse positive control example operator 
extraction negative control examples subgoals operator applied performed assumption training corpus output complete 
means set training examples includes pair correct parsing unique sentence appearing set 
words sentence training treated having different readings sentence appear times training set paired possible representation 
sentences allowed multiple parses nl system designer 
single best parsing preferred pair sentence provided 
desired system able produce multiple parsings sentence output completeness dictates readings training sentences included training set 
set positive control examples assumption output completeness implicitly defines set negative control examples 
knowing set clauses applied subgoal identifies clauses applied 
exact mechanism generation negative control examples dependent final parser intended produce multiple parses 
parsers returning single parse positive examples operator clause considered negative examples prior clauses positive example 
solution computed subsequent clauses chance match particular subgoal need included negative example sets 
multiple output parsers positive example clause considered negative example matching clauses subgoal positive example 
necessary subsequent clauses may matched subgoal backtracking solutions 
subsequent clauses applied lead correct alternative parse case subgoal positive control example extracted proof different training pair 
agt clause op example sentence man ate pasta example analysis extract single positive control example op ate man det pasta 
subgoal agt reduction applied correct parsing sentence 
notice uninstantiated variables outputs op clause bound time clause applied 
allowing multiple parses contexts clause op applied negative control examples 
negative control examples generated operator op man ate pasta op ate agt man det pasta op pasta ate agt man det op pasta det ate agt man det control rule induction sets positive negative control examples extracted task induction component generate definite clause concept definition covers positive examples negative 
nlp task puts demands ilp algorithm 
algorithm deal gracefully highly structured examples resulting rules operating arbitrarily large parse states 
second algorithm able invent new predicates distinctions necessary accurate parsing realistic domains 
experience suggests hand crafted feature set complete 
algorithm efficient deal thousands examples 
single sentence gives rise control examples induction performed 
furthermore parsing operator gives rise control rule induction problem 
acquiring parser corpus sentences gives rise dozens induction problems hundreds thousands examples 
time chill developed existing ilp algorithm met requirements 
chill employs novel ilp algorithm combines elements top bottom methods 
rules initially generated forming clause pairs 
overly general rules specialized addition literals 
addition algorithm includes demand driven predicate invention allows create new concepts necessary discriminate positive negative examples 
details algorithm taken section ll concentrate results induction 
example control rule learned agt reduction op det animate 
animate man 
animate boy 
animate girl 
system invented new predicate help explain parsing decisions 
course new predicate system generated name called animate clarity 
rule may roughly interpreted stating agent reduction applies stack contains items second completed noun phrase head animate 
output control rule induction phase suitable set control rules clause op 
control rules passed program specialization phase 
program specialization final step fold control information back overly general parser 
control rule easily incorporated overly general program unifying head operator clause head control rule clause adding induced conditions clause body 
definitions invented predicates simply appended program 
program clause op top second rest newtop rest reduce top agt second newtop 
control rule op det animate 
animate man 
animate boy 
animate girl resulting clause op det animate reduce agt 
animate boy 
animate girl 
animate man 
animate lion 
final parser simply consist overly general parser operator clause suitably constrained 
way control rules induced resulting parser guaranteed produce correct parses training examples 
discussion shift reduce parsing appropriate point discuss number implications motivations chill framework 
consider shift reduce framework limiting nlp citing known results power lr grammars 
important note potential lookahead parser unlimited entire state parser current stack contents remaining input may examined determining action perform 
furthermore control rules learned select operators context essentially arbitrary logic programs class languages recognized principle turing complete 
potential confusion labeling learned parsers deterministic 
mean say parser potentially unbounded look ahead produce multiple parses single input sentence deterministic 
mean parser backtrack undo operation search single parse 
action taken parsing correct step finding acceptable interpretation 
multiple acceptable parses parser backtrack find alternative correct action point results appropriate analysis 
parsing deterministic sense incorrect action applied needs undone 
parser principle examine unbounded context rule induction framework favors simple rules resulting bias portions context sufficient accurate parsing 
consider learning problem search deterministic parser correctly parse training sentences 
principle general mechanisms chill conjunction parsing mechanism suitably encoded logic program 
deterministic shift reduce parsing attractive choice number reasons 
simplest constrained mechanisms promise parsing significant portions english marcus tomita 
second fits architecture acquisition control rule learning creating deterministic parser basically exercise identifying relevant control rules 
third resulting parsers efficient increasing potential utility general nlp applications experiments reported section sentences parsed quickly analysis requiring second cpu time 
shift reduce parsing provides principled control structure representation neutral 
different styles analysis produced simply inserting different parsing operators 
certain general properties language processing left right scanning compositionality maintained 
language processing mechanism provides bias simplify inductive learning component 
having learn build output structures learning problem reduces identifying states parser 
states capture generalities language processing hoped inductive learning mechanism successfully learn parse consistent compositional representation scheme 
induction algorithm overview input induction component set positive negative examples concept case control examples expressed facts set background predicates expressed definite clauses 
experiments conducted chill far initial background knowledge empty 
output induction definite clause concept definition entails positive examples negative 
summary induction algorithm zelle mooney zelle presents additional details empirical results number benchmark ilp problems 
chill employs compaction algorithm tries construct small simple program covers positive examples 
algorithm starts specific definition disjunction specific positive examples introduces generalizations definition compact determined simple measure syntactic size program 
search general definitions carried hill climbing fashion 
step number possible generalizations considered producing greatest compaction implemented process repeats 
generalizations produced notion empirical subsumption 
intuitively algorithm attempts construct clause added current definition renders clauses superfluous 
superfluous clauses eliminated produce compact definition 
formally define empirical subsumption follows set clauses fc cn set positive examples provable clause empirically subsumes iff gamma 
examples provable replaced description induction algorithm noted term subsumption interpreted empirical sense 
shows basic compaction loop 
golem generalizations constructed random sampling pairs clauses current definition 
best generalization produced pairs reduce current definition def 
reduction performed adding top definition standard prolog proof strategy find proof positive example clause proofs deleted definition subsumed def fe true repeat pairs sampling pairs clauses def fg build gen def pos neg hc clause yielding compaction def def gamma clauses subsumed compaction basic induction algorithm algorithm constructing generalized clauses outlined 
basic processes involved 
construction lgg input clauses 
generalization covers negative examples returned 
initial generalization general attempt specialize adding antecedents 
expanded clause general passed routine invents new predicate specializes clause covers negative examples 
processes explained detail subsections 
constructing initial generalization initial generalization input clauses computed finding lgg clauses 
example learning control rules agent reduction initial clauses op ate man det pasta true 
op hit boy det man true 
op ate boy det chicken true 
third clauses yield lgg follows op ate man det pasta true 
op ate boy det chicken true 
lgg op ate det true 
lgg consistent generalization covers negative examples processing required 
course generalizations consistent 
consider lgg second clauses op ate man det pasta true 
op hit boy det man true 
lgg op det true 
generalization covers potential negatives op hit hammer det window hammer attached instrument agent 
generalization requires refinement prevent coverage examples 
initial definitions consist unit clauses antecedent true definition compact clauses constructed may contain non trivial conditions 
construction clause straight forward 
golem chill independent background knowledge input clauses generally small efficiently computable 
resulting clause guaranteed general input clause may cover negative examples 
process effectively introduces relevant variables decompose functional structures appearing examples 
variables may constrained adding antecedents clause 
adding antecedents name implies add antecedents attempts specialize initial gen adding new literals antecedents 
goal minimize coverage negative examples insuring clause subsumes existing clauses 
add antecedents employs foil mechanism adds literals background previously invented predicates 
antecedents added time hill climbing process step literal added maximizes heuristic gain metric 
gain metric employed chill modification foil information theoretic gain metric 
generalizations chill subsume existing clauses 
count positive tuples loosely number covered positive examples foil metric replaced estimate function build gen def pos neg gen lgg negatives covered gen fg return gen gen add antecedents pos gen negatives covered gen fg return gen reduced def clauses subsumed gen cpos fe pos reduced literal invent predicate cpos gen gen gen literal return gen build gen algorithm number clauses def subsumed gen estimate obtained associating positive example clause def covers 
gen covers examples associated clause clause counted subsumed gen example process consider learning control rule agt reduction presence suitable background relations regarding word categories person animate 
initially def contains unit clauses representing positive control examples 
example associated unit clause constructed 
sampling pairs clauses construct 
illustrated generalization op ate det true 
clause overly general antecedents need added 
best compacting generalization sampling added top definition specific clauses subsumed generalization removed def 
course unit clauses remain cover examples having verbs ate 
cycle compaction loop lgg clauses may produce op det true 
clause overly general specialized considered 
foil component consider possible new antecedents person person person trying literal person produces clause op det person 
presumably clause consistent subsume numerous unit clauses current definition positive gain 
clause subsume generalization previous iteration examples associated ate generalization non person animate agents op ate lion det sheep 
contrast clause op det animate subsumes example subsumed person 
animate superior literal gain metric 
clause added def previous generalization remaining unit clauses superfluous 
point def collapses single clause induction complete 
discussion assumed add antecedents predicates available allow completely discriminate positive negative examples case 
situations add antecedents may may add antecedents unable extend clause literal positive gain 
partially completed clause passed invent predicate completion 
inventing new predicates clause passed invent predicate covers positive negative examples 
purpose inventing new predicate constrain variables appearing clause exclude negative examples 
suppose trying learn control rule agt reduction suitable background knowledge 
add antecedents unable specialize lgg op det true 
clause cover positive negative examples result set variable bindings shown tabular form set pos ate man pasta hit boy sheep moved girl fork neg hit hammer window hit ball pasta broke bat plate note domains certain values appear positive negative examples values taken disjoint 
new concept representing values appear positive examples specialize clause insure cover negative examples 
general separating positive negative examples may require simultaneously constraining multiple variables 
table taken separate examples individually 
chill uses approach similar employing greedy algorithm find small set variables sufficient separation 
search begins empty set variables adds variables time preferring variables eliminate overlap negative examples minimize cardinality set tuples 
instantiations variables determine sets positive negative examples new concept 
induction algorithm recursively invoked examples learn definition new concept 
returning example invent predicate select single variable create positive examples man boy girl negative examples hammer ball bat 
calling top level induction algorithm examples produces compaction learned definition just listing positive examples 
build gen completes clause adding final literal newly invented predicate representing animate 
predicate invented useful compressing definition available generalizations 
enables induction clauses having multiple invented antecedents 
discussed zelle mooney zelle actual implementation chill somewhat complex includes numerous enhancements improve efficiency 
exact analysis computational complexity difficult practical ilp systems search performed uses heuristics 
fundamental components polynomial time complexity topdown foil component exponential arity background predicates 
predicate arity generally small arguments typical generally significant problem 
chill implemented prolog utilizes prolog inference engine test example coverage 
general theorem proving result relatively high constant time space factors 
probably current implementation chill impractical corpora containing thousands sentences 
quite tractable hundreds sentences 
chill running sparcstation able induce parsers experiments reported cpu times ranging minutes hours 
experimental results chill tested number parsing tasks ranging simple case role mapping problems construction complete database query application 
subsections discuss experiments 
case role mapping chill tested artificial data case role mapping previously demonstrate certain language processing abilities artificial neural networks mcclelland kawamoto miikkulainen dyer 
corpus consists sentence case structure pairs produced set sentence templates human ate food utensil capitalized items replaced words category 
corpus contains unique sentences admit meaningful analyses 
parser trained produce multiple outputs unique sentence treated single example training corpus insured output complete 
training testing followed standard paradigm generating learning curves choosing random set test examples case creating parsers increasingly larger subsets remaining examples 
reported results averages random training test splits 
code chill available electronically ftp ftp cs utexas edu pub mooney chill testing learned parser enumerate analyses test sentence 
parsing sentence fail ways incorrect analysis may generated correct analysis may generated 
order account types errors measured accuracy number distinct analyses produced number produced analyses correct number correct analyses possible sentence 
measure viewed average parser precision recall sentence 
chill performs learning task demonstrated learning curve shown 
system achieves accuracy novel sentences seeing training sentences 
training sentences required hour cpu time generated set parsing operators comprising lines prolog code achieved accuracy 
training examples chill learning curve artificial case role corpus direct comparison previous results difficult neural network systems produce single parse sentence sentence accuracy reported 
closest comparison results miikkulainen dyer accuracy achieved assigning words case slots training pairs 
chill produces totally correct analyses greater percentage complete sentences far training data cpu time 
noteworthy chill consistently invented interpretable word classes 
example invention animate 
concept implicit analyses system animate objects assigned agent role 
invented classes clearly picked distribution words input sentences 
system regularly invented semantic classes human food possession noun generation corpus 
phrase classes useful making parsing distinctions invented 
example structure instrumental phrase invented 
instrument 
instrument fork 
instrument bat 
class instrument invented category 
necessary parsing distinguish instruments different verbs instruments various verbs hitting eating grouped 
semantic relationship words required parsing distinctions relationships learned 
chill created relation possess human possession reflects distributional relationship humans possessions corpus 
notice invented rule contains invented word categories 
syntactic parsing atis corpus set experiments chill generate syntactic parsers extant treebank 
purpose experiments investigate approach sufficiently general robust handle syntactic parsing realistic data 
facets question parsers learned chill generalize novel text 
additional issue induction mechanism efficiently process numbers examples required achieve adequate performance relatively large complex corpora 
applying chill atis selected test corpus portion atis dataset preliminary version penn treebank specifically sentences file ti tb marcus 
chose particular data represents realistic input human computer interaction studies automated grammar acquisition brill serve basis comparison chill 
corpus contains sentences average length words 
np vp show np np np np flights sbar np vp served np lunch vp departing pp np san francisco pp np april th example atis treebank analysis experiments performed variations corpus order test benefit adding information form part speech tags 
versions untagged tagged 
untagged corpus words appeared sentences attached part speech labeling 
tagged version associated part speech tags word 
tags version replaced words corresponding tags parsing tag sequences common previous corpus syntactic parsing 
atis corpus concerns queries regarding air travel information 
example analysis sentence show flights served lunch departing san francisco april th shown 
analysis fairly sophisticated syntactic parse tree representation 
illustrated example analyses may contain various types empty constituents implied subject command trace left np movement 
complication data sentences parsed phrase level leaving internal structure nps unanalyzed allowing arbitrary arity constituents 
forcing parser learn reductions arbitrary length constituents chill restricted binary branching structures 
simplifies parser allows direct comparison previous experiments binary bracketings brill 
making treebank analyses compatible binary parser required completion parses binary branching structures 
accomplished automatically introducing special internal nodes right linear fashion 
example noun phrase np big orange cat elaborated np int np big int np orange cat 
special labels int np noun phrases int sentences permits restoration original structure merging internal nodes 
technique resulting parses compared directly treebank parses 
learning component chill remained exactly case role experiments initial parsing operator generator modified produce operators appropriate syntactic analyses penn treebank 
case role parsing building overly general parser set training examples accomplished constructing clauses op predicate 
example consider phrase np np trip pp np dallas 
represent analysis prolog term form np np trip pp np dallas 
operations associated clauses required parse phrase follows notation reduce cat indicates top stack elements combined form constituent label cat reduce pp op ss words pp ss words 
reduce np op ss words np ss words 
reduce np op ss words np ss words 
shift op stack word words word stack words 
sentence analyses include empty categories detectable lexical tokens appear analyses sentence empty marker introduced shift operator consume word input buffer 
initial experiments simple representation parsing actions zelle mooney 
improved results obtained specializing operators effectively increasing number operators reducing complexity control rule induction task operator 
basic idea index operators relevant portion parsing context 
example experiments lexical tags operators indexed syntactic category front input buffer 
single operator op stack word words word stack words multiple operators slightly differing contexts op stack ws op stack ws op stack ws op stack ws experiments lexical categories operators indexed top phrase categories stack 
words reduced phrase indexed having category word 
corpus provides single preferred parse sentence chill applied single parse mode explained section 
operators placed order increasing frequency determined training set 
allows learning control rules take advantage defaults typically simpler conditions applying exceptional operators tested control falls generally applicable rules default 
atis results obviously stringent measure accuracy proportion test sentences produced parse tree exactly matches parse sentence exact match accuracy 
parse useful perfectly accurate 
parse incorrect attachments labelings may convey information required tasks 
treebank completely consistent handling structures 
better gauge partial accuracy parser adopted procedure returning scoring partial parses 
parser runs dead parsing test sentence contents stack time impasse returned single flat constituent labeled parsing operators ordered shift operator invariably frequently shift serves default reduction action applies 
time impasse words sentence stack partial constituents built 
contents stack reflect partial progress parser finding constituents 
resulting parse scored overlap computed parse correct parse recorded treebank 
constituents said match span exactly words sentence 
constituents match label identical 
overlap computed parse correct parse computed trying match constituent computed parse constituent correct parse 
identical constituent score matching constituent incorrect label scores 
sum scores constituents overlap score parse 
partial match accuracy parse computed correct number constituents computed parse correct number constituents correct tree 
result average proportion computed parse correct proportion correct parse 
accuracy measure evaluating systems bracket input sentence unlabeled constituents proportion constituents generated parse cross constituent boundaries correct tree black 
course measure allows training examples exact match partial match zero crossing brackets consistent brackets tags atis learning curves direct comparison systems generate binary branching parse trees 
ensuring output parser binary branching method described computed percentage sentences parses containing crossing constituents zero crossing brackets accuracy proportion constituents non crossing test sentences consistent brackets accuracy 
gives basis comparison previous bracketing results emphasized chill designed harder task producing complete labeled parses directly optimized bracketing task 
learning curves atis corpus showing various accuracy measures shown figures 
results averaged random training test splits 
learning curves tagged tags versions significantly different results shown 
results tags version encouraging 
training sentences chill constructed parser comprising lines prolog generated completely correct parses novel testing sentences 
partial match metric chill parses garnered average accuracy 
chill designed difficult task building complete labeled tree containing single flat constituent covering entire sentence produces perfect crossing score 
training examples exact match partial match zero crossing brackets consistent brackets untagged atis learning curves parses figures zero crossing brackets consistent brackets compare favorably reported previous studies atis corpus 
brill reports respectively 
chill scores higher zero crossing brackets slightly lower consistent brackets 
understandable brill transformation learner tries optimize value chill preference sentence accuracy tend improve correctly parsed sentences crossing brackets 
chill bracketing figures similar results reported goodman replication study stochastic grammar approaches atis corpus 
larger set training examples reports zero crossing brackets consistent brackets approach zero crossing consistent approach bod 
comparison curves untagged version show considerable advantage gained word class tags actual words 
expected tagging significantly reduces variety input 
results untagged special mechanism handling previously unseen words occurring testing examples 
achieving partial match accuracy conditions note goodman unable reproduce higher accuracies originally reported bod attributes bod results extremely fortuitous choice test set 
goodman authors previous studies averages multiple training test splits underlines importance methodology 
quite 
statistical approaches relying grams probabilistic context free grammars difficulty due large number terminal symbols appearing modest sized training corpus 
data lexical selection sparse adequately train pre defined models 
similarly transformational approach brill limited bracketing strings lexical classes words 
chill ability learn useful untagged rests learning mechanism ability automatically construct attend just features input useful guiding parsing 
clear considerably training data required significantly improve accuracy untagged case 
noted system created new categories situations 
untagged experiments chill regularly created categories preposition verb form 
tagged input various tags grouped classes verb noun forms 
cases system formed numerous categories relations defy simple linguistic explanation 
categories apparently helpful parsing new text 
created word categories difficult ascertain significant linguistic insight rules learned chill experiments 
resulting rule bases large thousands lines prolog code represented choices relatively low level control decisions grammar rules 
furthermore deterministic single parse framework experiments produced sets rules highly inter related context dependent 
atis study shows chill achieves results comparable systems designed specifically learning syntactic bracketings 
somewhat surprisingly accomplished learning traditional symbolic deterministic parser probabilistic grammar 
learned parser particularly efficient probabilistic parsers performs real search space possible parses 
current computational requirements ilp training prevents testing existing system huge corpora long sentences wall street journal portions penn treebank 
construction large broad coverage parsers relatively shallow representations useful application empirical techniques 
syntactic parsing small component larger understanding problem 
practice natural language systems concerned deeper semantically oriented issues 
application empirical techniques developing specialized parsers mapping sentences domain specific sublanguages useful meaning representations 
subsection addresses possibility 
parsing database queries logical form evaluating parser acquisition systems artificial metrics matching treebank analyses open number criticisms 
metrics certainly useful making rough comparisons results interpreted caution 
systems run identical corpora corpora may cleaned different ways goodman 
unclear compare systems tuned optimizing different metrics focusing bracketings labeled parse trees goodman 
clear measures accurately reflect actual differences performance real language processing tasks 
necessarily case system scoring parsing metric produce better final application results achieving 
acid test empirical approach allows construction better natural language systems allows designers build comparable systems time expertise 
section report experiments chill engineer natural language front simple database 
database task provides metric easily evaluable 
gold standard simply system produces correct output question determination straight forward database domains 
need accuracy partial metrics engage philosophical debates usefulness various intermediate representations 
overview problem database query task input chill consists sentences paired executable database queries 
query language considered logical form similar types meaning representation typically produced logic grammars warren pereira abramson dahl 
semantics representation grounded query interpreter executes queries retrieves relevant information database 
choice logical query language ubiquitous sql provides straight forward compositional mapping natural language utterances property necessary chill approach 
course sentence parsed capital state largest population 
answer capital largest state population 
major cities kansas 
answer major city loc equal stateid kansas 
state rivers running 
answer state river traverse 
people live iowa 
answer population equal stateid iowa 
sample database queries unambiguous logical form translation database query formalism easily automatable 
domain chosen database united states geography 
choice motivated availability existing natural language interface simple geography database 
system called geobase supplied example application commercial prolog available pcs specifically turbo prolog borland international 
having example provides database coded prolog front built serves convenient benchmark chill performance compared 
geobase data contains prolog facts asserting relational tables basic information states including population area capital city neighboring states major rivers major cities highest lowest points elevation 
database contains information concerning lengths rivers population cities 
shows sample questions english associated query representations 
queries expressed prolog conventions capitalized identifiers representing logical variables commas representing conjunction 
development database application required components framework parsing logical query representations specific query language geography database 
component domain independent consists algorithms parsing operator generation example analysis infer required operators parse training examples 
resulting parsing framework quite general generate parsers wide range logic representations 
second component domain specific query language having vocabulary sufficient expressing interesting questions geography 
database application comprises parser produced chill coupled interpreter query language 
specific query language experiments referred initially developed considering sample sentences 
simple query interpreter developed concurrently query language insuring representations grounded database query task 
query language parsing framework designed corpus sentence query pairs developed having uninformed subjects generate sample questions system 
analyst constructed appropriate query question resulting corpus pairs evaluate performance chill task 
query language query language basically order logical form augmented higher order predicates meta predicates handling issues quantification implicit sets 
general form representation useful language processing tasks 
particular constructs designed notion appropriateness representation natural language general direct method compositionally translating english sentences unambiguous logic oriented database queries 
example task specific meaning representation language 
basic constructs query representation terms represent objects referenced database basic relations 
basic forms listed 
objects interest states cities rivers places high point low point state 
order representations objects typically represented unique constants easier treat objects terms example stateid texas represent state texas 
effect typing basic objects making easier remember representation potentially ambiguous names stateid missouri vs missouri 
cities represented type form example country usa city cityname austin tx state stateid statename stateid texas river colorado place pacific basic objects argument term second argument containing abbreviation state 
done insure uniqueness different states may cities name columbus oh vs columbus ga 
convention allows natural form expressing partial information city known name uninstantiated variable second term 
basic relations shown 
relations self evident 
possible exception relation equal 
indicate certain variable bound ground term representing object database 
example phrase capital texas translates capital equal stateid texas traditional capital stateid texas 
equal allows objects introduced point named sentence 
basic predicates provide expressiveness meta predicates required form complete queries 
list implemented meta predicates shown 
predicates distinguished take completely formed conjunctive goals arguments 
important meta predicates answer 
predicate serves wrapper query goals indicating variable binding interest answers question posed 
executing query form answer goal variable appearing goal results listing unique values taken possible proofs goal generated backtracking 
queries require meta predicates expression 
meta predicates provide quantification selection extremal elements implicit sets 
form predicate capital capital city 
city city 
major major 
place place 
river river 
state state 
capital capital city 
area area capital capital equal variable ground term density population density elevation elevation high point highest point higher elevation greater 
loc located low point lowest point len length 
size size traverse traverses basic predicates form explanation answer goal variable interest goal 
largest goal goal produces solution maximizing size smallest goal analogous largest 
highest goal analogous largest elevation 
lowest goal analogous highest 
longest goal analogous largest length 
shortest goal analogous longest 
count goal count unique bindings satisfying goal 
goal goal produces maximizing count fewest goal analogous 
meta predicates parsing framework queries logical representations look different parse trees case structures discussed previous sections amenable general parsing scheme shallower representations 
adapting chill representation requires identification implementation suitable operators construction style analyses 
logical queries built shift reduce framework simple operator types 
initially word phrase front input buffer suggests certain structure part result 
appropriate structure pushed stack 
example word capital cause capital predicate pushed stack 
type operation performed introduce operator similar simple shift operation employed parse tree analyses direct analogue shift keep track actual words sentence 
explained example 
initially logical structures introduced new referenced variables 
variables may unified variables appearing stack items operator 
example argument capital structure may unified argument previously introduced state predicate 
stack item may embedded argument stack item form conjunctive goals inside meta predicates performed conjoin operation 
shows sequence states parser goes parsing sentence capital texas 
state parser shown term form ps stack input stack list constituents comprising current stack input remaining words input buffer 
individual stack items shown line state input buffer line parse state 
stack item contains portion query structure built list words shifted input stack item top stack 
done actual words introduce various structures available serve context forming control rules 
word list maintained reverse order packaged query structure functor 
query extracted state answer capital equal stateid texas 
parse sequence illustrates basic operation types construct queries parse state operation type 
ps answer capital texas shift 
ps answer capital texas shift 
ps answer capital texas shift 
ps answer capital texas introduce 
ps capital answer capital texas 
ps capital answer capital texas shift 
ps capital capital answer texas shift 
ps capital capital answer texas shift introduce 
ps equal stateid texas texas capital capital answer 
ps equal stateid texas texas capital capital answer conjoin 
ps equal stateid texas texas answer capital shift 
ps equal stateid texas texas answer capital shift 
ps equal stateid texas texas answer capital conjoin 
ps answer capital equal stateid texas sequence parse states capital texas 
sentences 
initial state consists answer structure stack input buffer containing sentence 
common operation shift simply transfers word input buffer word list top item stack 
operation accounts results states example parse 
case state attempt shift empty input buffer puts special input marker stack 
query structures introduced point presence indicated lexical items front input buffer 
example state shows result word capital introducing capital structure 
state results special operator combining shift introduce handle state name front buffer 
parsing variables unified referencing operators demonstrated states 
conjoin operator embeds stack item argument 
states product conjoin operations 
class operator overly general operators required parse example may easily inferred 
necessary introduce operators determined examining structures occur query words introduce structures appear training sentence 
operators constructed finding shared variables training queries sharing requires appropriate operator instance 
conjoin operations indicated term embedding exhibited training examples 
simple framework logical queries constructed compositional fashion style parsing 
important note operator generation phase chill modified representation control rule learning component remains unchanged 
experimental results sample questions english obtained distributing questionnaire uninformed subjects 
questionnaire provided basic information online tutorial supplied geobase existing system including verbatim list type information database sample questions system answer 
subjects asked write fifteen questions expected system capable answering 
total questions gathered 
discarded resulting corpus questions average length words 
questions discarded information provided database polluted river exact duplicates included questions 
remaining sentences potentially answerable required queries outside scope representation 
mentioned originally designed cover corpus sentences 
fact relevant questions eventually gathered representable metric relative generality representations 
evaluation purposes corpus split training sets examples remaining held testing 
chill run default values various parameters 
test differed previous ones background knowledge provided control rule learning component 
background information comprised predicates database recognizing state city river names 
testing employed stringent standard accuracy application produced correct answer question 
test sentence parsed produce query 
query executed extract answer database 
extracted answer compared answer produced correct query associated test sentence 
identical answers scored correct parsing discrepancy resulted failure 
queries resulted multiple answers order solutions considered unimportant 
shows accuracy chill parsers trial average 
line labeled geobase shows average accuracy geobase system testing sets sentences 
curves show chill outperforms existing system trained examples 
best trial chill induced parser comprising lines prolog code achieved accuracy answering novel queries 
application important distinguish modes failure 
system fail parse sentence entirely produce query retrieves incorrect answer 
case represents softer failure application smart indicate sentence request paraphrase 
parsers learned chill produced spurious parses 
shows probability test sentence produce spurious parse function training set size 
training sets examples chill outperforms original geobase interface 
training time required achieve results relatively small chill able learn parsers training examples chill geobase accuracy largest trials minutes cpu time sparcstation 
discussion geobase system probably represent state art standard natural language database query systems straw man geobase uses semantics parser scans words corresponding entities relationships encoded database 
relying extensive syntactic analysis system attempts match sequences entities associations sentences entity association network describing schemas database 
result relatively robust parser words simply ignored 
chill construct natural language application certainly eliminate initial need human expertise 
design query language nontrivial task portions parsing shell filled information database hand 
part information included lexicon relating words appear potential queries logical query structures express training examples chill geobase percentage spurious parses meaning 
design components relies strictly local considerations arise single examples 
problem devising rules consistent examples placed entirely learning component 
analyst freed concentrate issues expressiveness representation implementation grammar 
learning curves chill clearly suggest training larger corpora improve chill parsers 
similarly traditional parser construction techniques involve collection examples tweaking grammar account new information 
followed extensive regression testing insure changes damage performance prior examples hard predict inter related effects produced isolated changes 
real promise empirical techniques automate grammar improvement step allowing construction parsers consistent larger range natural language inputs achieved hand crafted rules 
principle amply demonstrated problems word class tagging syntactic analysis results suggest similar advantages level complete nl application 
related substantial amount research empirical approaches parser construction addresses somewhat different problems 
major difference type analysis provided 
chill learns parsers produce complete labeled parse trees systems learned produced simple bracketings input sentences brill probabilistic language models assign sentences probabilities charniak carroll 
dimension variation type input provided learning system 
chill requires suitably annotated corpus approaches utilized existing complex hand crafted grammar generates black black lafferty 
chill ability invent new categories allows actual words parsing decisions systems limited representing sentences strings lexical categories brill charniak carroll 
approach magerman similar chill 
system produces parsers annotated corpora sentences paired syntactic representations 
parsing treated problem statistical pattern recognition 
involves coding parse tree topography finite set construction features 
associated feature fixed set parse tree context information examined determine feature value node 
actual assignment trees sentences performed heuristic search space possible parse tree derivations guided learned probabilistic decision trees 
learned grammars shown significantly outperform hand crafted counterparts realworld parsing task involving text technical manuals 
chill differs approach mainly flexibility 
magerman system hand engineered particular representation produced 
example parse tree encoding scheme includes feature conjunction specifically introduced improve performance system 
system includes set hand generated rules determining properties node parse tree inherit nodes 
hand crafting features rules unclear easily approach adapted differing representation schemes 
approach learns semantically oriented representations hidden understanding models miller 

system learns parse tree structured meaning representations 
representations similar syntactic parse trees nodes may labeled conceptual categories analyses produced semantic grammars 
statistical model employs separate component determining said ordering concepts said choice words 
components modeled probabilistic transition network 
networks trained extensions standard statistical estimate maximize algorithms 
bootstrapping procedure utilized acquisition system help annotate portions atis corpus single annotator able produce annotated sentences day 
training sentences produced parser achieved exact match accuracy remaining sentences 
approach extended construct complete interface separate statistically trained modules syntactic semantic discourse analysis miller stallard bobrow schwartz 
mapping final semantic representation employs separate modules requiring training sentence labeled parse tree semantic frame 
chill maps directly logical form require annotating sentences additional intermediate representations 
experimental comparison chill require running systems identical corpora general differences worth noting 
hidden understanding model utilizes propositional approach forces certain markov assumptions 
incapable modeling phenomena requiring nonlocal situation hold chill may examine aspect parse context 
related limitation ordering concepts tree structured representations match order words sentence 
awkward handle forms linguistic movement 
theory chill representation suitable parsing operators inferred 
kuhn de mori propose method learning semantic mappings semantic classification trees 
variants traditional decision trees nodes contain restricted regular expression representations matched input queries 
semantic mapping performed translating possible component desired output frame classification question 
forest learned determine features output 
approach demonstrated portion atis task mapping inputs frames translated sql 
approach differs chill number dimensions 
input semantic component raw words minimally pre parsed text respect similar multi step approach miller 
parsing stage hand coded somewhat ambitious 
second method requires output mapping cast series classification problems 
propositional restriction sufficient simple flat sql queries unclear technique applied sophisticated nested queries 
chill unique flexibility employ general learning system construct variety parsers need engineer fixed set relevant features priori 
general system construct parsers producing syntactic parses case analyses semantic logical forms little corpus input output pairs 
improving accuracy parsers learned chill requires progress fronts 
obvious approach larger training sets 
making practical requires improvements efficiency induction algorithm 
difficult trials reported required hours cpu time sparcstation 
avenue incorporate biases induction process 
shift reduce framework current system weak bias compared restrictions commonly considered principles parameters approach 
nice feature ilp methods employ traditional symbolic representations exploit prior background knowledge 
initial research focussed accomplished placing burden general learning component 
providing system background knowledge tighter constraints allow accurate induction fewer examples 
parsing logical form chill currently requires semantic lexicon maps words predicates terms composed produce final output 
currently developing techniques automatically acquire lexicon training corpus symbolic induction algorithm thompson 
exploring ilp methods constructing rules information extraction task identifying specific items natural language text lehnert sundheim 
ilp techniques potentially induce complex patterns previous learning methods applied task riloff soderland fisher lehnert 
inducing unbounded relational patterns characterize context surrounding particular phrases concise rules extracting information learned training corpus filled templates califf mooney 
significant problem empirical nlp general corpus construction 
annotating large corpora parse trees logical forms filled templates difficult time consuming task 
active learning specifically selective sampling cohn atlas ladner lewis catlett potentially ease problem 
training examples equally useful learning system carefully selecting useful examples annotation effort dramatically reduced 
approach successfully employed training part speech taggers engelson dagan intend explore parsing information extraction 
chill system uses relational learning methods induce traditional parsers corpora complementing results statistical methods 
believe primary strength corpus methods particular approach type parser employed statistical connectionist symbolic fact real data automatically construct complex parsers 
experimental results suggest chill performs comparably previous approaches similar tasks 
believe main advantage inductive logic programming approach resulting flexibility 
chill capable learning parse standard syntactic representations meaning oriented case structures logical forms database querying 
addition chill able learn highly structured contexts automatically create new predicates necessary support accurate parsing 
abilities reduce need feature engineering common propositional approaches 
course obviate need engineering representations suitable particular task representations devised usefulness task learning component assumes burden identifying exploiting relevant structural differences 
potential attraction ilp approach ease may integrated traditional symbolic parsing methods 
shift reduce framework nlp may benefit direct application relational learning methods 
chill represents alternative broad shallow paradigm dominates current empirical nlp 
results geography database application suggest empirical methods may useful rapid development smaller domain specific parsers produce useful final representations 
tasks may feasible automatically construct virtually entire linguistic component complex natural language system 
envision example collecting sample database queries submitted information system course normal pairing english sentences express presenting chill system generate natural language front 
automated generation natural language interfaces exciting application empirical techniques possible learning system able learn mapping strings words useful representations task hand 
believe techniques employed chill parser acquisition control rule learning relational learning algorithms significant step direction 
chill really just starting point investigation ilp learning techniques natural language processing 
acknowledgments anonymous reviewers helpful comments initial version 
research supported national science foundation iri texas advanced research program arp 
abramson dahl 

logic grammars 
springer verlag new york 
berwick 

acquisition syntactic knowledge 
mit press cambridge ma 
black 

procedure quantitatively comparing syntactic coverage english grammars 
proceedings fourth darpa speech natural language workshop pp 

black lafferty magerman mercer roukos 

history grammars richer models probabilistic parsing 
proceedings st annual meeting association computational linguistics pp 
columbus ohio 
black lafferty 

development evaluation broad coverage probabilistic grammar english language computer manuals 
proceedings th annual meeting association computational linguistics pp 
newark delaware 
bod 

annotated language corpus virtual stochastic grammar 
proceedings eleventh national conference artificial intelligence pp 

borland international 
turbo prolog guide 
borland international valley ca 
brill 

automatic grammar induction parsing free text transformation approach 
proceedings st annual meeting association computational linguistics pp 
columbus ohio 
briscoe carroll 

generalized probabilistic lr parsing natural language corpora unification grammars 
computational linguistics 
califf mooney 

relational learning pattern match rules information extraction 
submitted 
cameron jones quinlan 

efficient top induction logic programs 
sigart bulletin 
charniak carroll 

context sensitive statistics improved grammatical language models 
proceedings twelfth national conference artificial intelligence seattle wa 
charniak hendrickson jacobson perkowitz 

equations part speech tagging 
proceedings eleventh national conference artificial intelligence pp 
washington cohen 

text categorization relational learning 
proceedings twelfth international conference machine learning pp 
san francisco ca 
morgan kaufman 
cohn atlas ladner 

improving generalization active learning 
machine learning 
engelson dagan 

minimizing manual annotation cost supervised training corpora 
proceedings th annual meeting association computational linguistics santa cruz ca 
fillmore 

case case 
bach harms 
eds universals linguistic theory 
holt reinhart winston new york 
goodman 

efficient algorithms parsing dop model 
proceedings conference empirical methods natural language processing pp 
philadelphia pa goodman 

parsing algorithms metrics 
proceedings th annual meeting association computational linguistics pp 
santa cruz ca 
hindle rooth 

structural ambiguity lexical relations 
computational linguistics 


discrimination constructive induction logic programs 
proceedings tenth national conference artificial intelligence pp 
san jose ca 
kuhn de mori 

application semantic classification trees natural language understanding 
ieee transactions pattern analysis machine intelligence 
lavrac dzeroski 

inductive logic programming techniques applications 
ellis horwood 
lehman 

essential nature knowledge sense resolution 
proceedings twelfth national conference artificial intelligence pp 
seattle wa 
lehnert sundheim 

performance evaluation text analysis technologies 
ai magazine 
lewis catlett 

heterogeneous uncertainty sampling supervised learning 
proceedings eleventh international conference machine learning pp 
san francisco ca 
morgan kaufman 
magerman 

statistical decision tree models parsing 
proceedings rd annual meeting association computational linguistics pp 
cambridge ma 
magerman 

natural parsing statistical pattern recognition 
ph thesis stanford university 
manning 

automatic acquisition large subcategorization dictionary corpora 
proceedings st annual meeting association computational linguistics pp 
columbus ohio 
marcus 

theory syntactic recognition natural language 
mit press cambridge ma 
marcus santorini marcinkiewicz 

building large annotated corpus english penn treebank 
computational linguistics 
mcclelland kawamoto 

mechanisms sentence processing assigning roles constituents sentences 
rumelhart mcclelland 
eds parallel distributed processing vol 
ii pp 

mit press cambridge ma 
merialdo 

tagging english text probabilistic model 
computational linguistics 
miikkulainen dyer 

natural language processing modular pdp networks distributed lexicon 
cognitive science 
miller bobrow ingria schwartz 

hidden understanding models natural language 
proceedings nd annual meeting association computational linguistics pp 

miller stallard bobrow schwartz 

fully statistical approach natural language interfaces 
proceedings th annual meeting association computational linguistics pp 
santa cruz ca 
mooney califf 

induction order decision lists results learning past tense english verbs 
journal artificial intelligence research 
muggleton feng 

efficient induction logic programs 
muggleton 
ed inductive logic programming pp 

academic press new york 
muggleton king sternberg 

protein secondary structure prediction logic machine learning 
protein engineering 
muggleton 
ed 

inductive logic programming 
academic press new york ny 


inside outside reestimation partially bracketed corpora 
proceedings th annual meeting association computational linguistics pp 
newark delaware 
plotkin 

note inductive generalization 
meltzer michie 
eds machine intelligence vol 

elsevier north holland new york 
quinlan cameron jones 

foil midterm report 
proceedings european conference machine learning pp 
vienna 
quinlan 

learning logical definitions relations 
machine learning 
riloff 

empirical study automated dictionary construction information extraction domains 
artificial intelligence 
simmons yu 

acquisition context dependent grammars english 
computational linguistics 
soderland fisher lehnert 

crystal inducing conceptual dictionary 
proceedings fourteenth international joint conference artificial intelligence pp 

thompson 

acquisition lexicon semantic representations sentences 
proceedings rd annual meeting association computational linguistics pp 
cambridge ma 
tomita 

efficient parsing natural language 
kluwer academic publishers boston 
warren pereira 

efficient easily adaptable system interpreting natural language queries 
american journal computational linguistics 
zelle 

inductive logic programming automate construction natural language parsers 
ph thesis university texas austin tx 
appears artificial intelligence laboratory technical report ai 
zelle mooney 

combining top bottom methods inductive logic programming 
proceedings eleventh international conference machine learning pp 
new brunswick nj 
zelle mooney 

inducing deterministic prolog parsers treebanks machine learning approach 
proceedings twelfth national conference artificial intelligence pp 
seattle wa 

