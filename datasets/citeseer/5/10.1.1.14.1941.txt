figures merit best probabilistic chart parsing sharon caraballo eugene charniak best parsing methods natural language try parse efficiently considering constituents 
merit needed compare likelihood con choice sub impact efficiency parser 
parsers described literature techniques published data efficacy attempts judge relative merits 
propose evaluate figures merit best parsing 
chart parsing commonly algorithm parsing natural language texts 
chart data structure contains constituents may occur sentence parsed 
point algorithm exist con proposed ac included parse 
proposed con stored data structure called 
constituent removed system considers constituent extend current structural hy 
general lead creation new encompassing constituents selves added 
finished processing constituent new chosen removed 
traditionally represented stack item added removed 
best chart parsing variation chart parsing attempts find parses adding constituents chart order likelihood appear correct parse simply popping con stack 
merit assigned potential constituents con maximizing value added chart 
brown university ec ocs brown edu best probabilistic chart parsing prob measure 
con sider probabilities primarily probabilistic context free grammars principle complicated schemes 
ideally merit conditional probability con entire sentence order choose constituent appears isolation maximizes likelihood sen tence pick constituent maximizes quantity sequence tags parts speech sentence numbered tn nj nonterminal type covering terms tj tk 
calculate quantity order need completely parse sentence 
examine performance proposed figures merit approximate way 
experiments tag sequences parsing 
accurate probability estimates attainable lexical information 
straight figures merit reasonable base merit inside probability fl constituent 
side probability defined probability words tags constituent con dominated particular nonterminal symbol 
reasonable basis comparing constituent probabilities additional advantage easy compute chart parsing 
inside probability constituent defined nj tj represents ith nonterminal symbol 
terms earlier discussion ideal merit rewritten nj lto nj nij tk nj tk tj nj ta apply usual independence assumption nonterminal tag sequence gen depends nonterminal giving lto tk tj inj nj tk 
term numerator just definition outside probability con 
outside probability constituent nj defined probability con rest words sentence rest tags tag sequence case 
nj nj rewrite ideal merit equation see nj represent influence surrounding words 
assumes tom ignored 
refer merit straight ft normalized side effect omitting terms inside probability tends prefer shorter con longer ones inside probabil ity longer constituent involves product probabilities 
result thrash ing effect system parses short con low probability ones avoiding combining longer constituents 
avoid thrashing typically technique normalize inside probability merit 
approach take ge mean inside probability obtain word inside probability 
ideal model term acts normalizing fac tor 
word inside probability con nj calculated refer normalized 
normalized alf previous section showed ideal merit written fl nj lt 
term representing outside probability calculated directly parse need full parse sentence compute 
figures merit quantity nj closely re lated outside probability 
call quantity left outside probability denote ai 
recursive formula compute set completed edges rule expansions nal nj appears 
edge gj com pute product nonterminal ap left hand side lhs rule probability rule non terminal appearing left nj rule 
sum products nj lhs tart rule ee formula infinitely recursive depending properties grammar 
method calculating efficiently derived calculations lafferty 
simple extension normalized fl model allows estimate word probability tags sentence constituent consideration 
allows take advantage information obtained left right parse 
calculate quantity follows geometric mean avoid thrashing compensating aj quan preference shorter constituents ex previous section 
refer merit normal ized lfl 
trigram estimate alternative way rewrite ideal merit follows nj nj tk tj tk tk tj ito tk applying usual independence assumption nonterminal tag se quence generates depends rewrite merit follows tj ito tk 
derive estimate quantity prac tical merit addi tional independence assumptions 
assume tk prob ability nonterminal independent tags sentence 
trigram model tags giving tj tk tj 
fl nj 
tj calculate nj usual 
term estimated pcfg sum counts rules having left hand side divided sum counts rules 
tj term just proba bility tag sequence tj tk trigram model 
technically trigram model model consider ing sequences tags words 
refer model trigram estimate 
results show term omit ted effect 
prefix estimate derived estimate ideal merit takes advantage statistics tags sentence tj estimate represents probability constituent context preceding tags 
nj nj tk tj nj ta tk tk nj nj independence assumption tj tk fl nj 
additionally assume independent tk giving 
denominator calcu lated model 
term just defined discussion normalized lfl model 
merit written refer prefix estimate 
experiment grammar probabilistic context free grammar learned brown corpus see francis era car roll charniak charniak carroll 
parsed sentences length including tion penn treebank wall street journal corpus best parsing method estimates nj merit 
straight 
normalized 
normalized lfl 
trigram estimate 
prefix estimate probability trigram estimate determined training data grammar learned initially 
probabilities trigram prefix es learned data deleted interpolation method smoothing 
merit compared formance best parsing merit exhaustive parsing 
exhaustive pars ing mean continuing parse constituents available added chart 
parse exhaustively determine tal probability sentence sum probabilities parses sentence 
computed quantities best parsing merit point best parsing method parses contributing probability mass sentence 
results chart presents measures merit 
percentage edges rule sions exhaustive parse best parse get probability mass edge creation generally considered best measure cfg parser ef fort 

non percentage nonzero length edges best parse get 
zero length edges required parser book keeping measure ally un 
anticipated ing consideration highlight true differences figures merit 

popped percentage constituents exhaustive parse best parse get probability mass merit straight normalized crl trigram estimate prefix estimate non popped statistics converged final values quickly 
edge count percentages gener ally final values processing sentences results quite stable sentence test corpus 
gathered statistics sentence length 
sentence length limited maximum huge number edges generated doing full parse long sentences grammar sentences length range produced edges 
shows graph non percent nonzero length edges needed get probability mass sentence length 
measured total cpu time sec needed get probability mass sentences 
results pre sented chart merit cpu time straight fl trigram estimate prefix estimate shows average cpu time get probability mass estimate sentence length 
estimate averaged low second sentences fewer words 
axis restricted normal ized trigram estimates better com pared 
previous literature shows implementations best parsing previous shares goal explicitly comparing figures merit 
bobrow grishman introduced statistical agenda parsing techniques 
grishman implemented best probabilistic parser noted parser tendency prefer shorter constituents 
proposed heuristic solution penalizing shorter constituents fixed amount word 
miller fox compare perfor mance parsers different types grammars show probabilistic context free grammar inside probability ized merit outperforms context free grammar context dependent grammar 
propose fig ure merit closely related prefix estimate 
incorporate best parser 
magerman marcus ric mean compute merit dependent constituent length 
magerman weir similar model different parsing algorithm 
tm lo 
iv 

lj sentence length nonzero length edges probability mass il fl ll sentence length average cpu time probability mass beta normalized beta normalized beta trigram estimate prefix estimate straight beta normalized beta normalized beta trigram estimate prefix estimate edge count statistics clear straight poor merit 
demonstrates performance generally ens sentence length increases 
best performance terms edge counts figures tested model information available sentence prefix model 
far additional running time needed computation terms exceeded time saved processing fewer edges clear cpu time statistics models perform sub worse straight 
chart parsing calculations done time unable find algorithm compute terms faster ns 
constituent removed affects values parse trees values propagated constituent siblings right descendants 
ing terms constituent removed done time possible constituents tal time needed compute ol terms manner 
best performer running time parser trigram estimate merit 
additional advantage easily incorporated existing best parsers merit inside probability 
cpu time statistics seen running time begins show real improvement normalized model sentences length greater trend suggests improvement greater longer sentences 
interesting note models figures merit normalized geometric mean performed similarly models shorter sentences superior perfor mance models pro sentence length increases 
see models geometric mean appear level respect tive parse parse sentences length greater 
estimates continue improving greater sentence length 
fact measurements certainly underestimate true benefits better models 
restricted sentence length maximum words order keep number edges exhaustive parse prac tical size percentage edges needed best parse decreases sentence length assume ira provement dramatic sen tences longer words 
robert bobrow 

statistical agenda parsing 
darpa speech language workshop pages 
glenn carroll eugene charniak 

learning probabilistic dependency gram mars labeled text 
working notes fall symposium series pages 
aaai 
glenn carroll eugene charniak 

experiments learning proba dependency grammars corpora 
workshop notes statistically nlp tech niques pages 
aaai 
eugene charniak glenn carroll 

context sensitive statistics improved gram language models 
proceedings twelfth national conference artificial intel pages 
mahesh ralph 

statistical parsing messages 
darpa speech language workshop pages 
nelson francis henry ku era 

frequency analysis english usage lexicon grammar 
houghton mifflin 
frederick jelinek john lafferty 

computation probability initial substring generation stochastic context free grammars 
computational linguistics 
fred joseph 

calculating probability partial parse sentence 
darpa speech language workshop pages 
david magerman mitchell mar cus 

parsing voyager domain pearl 
darpa speech language shop pages 
david magerman carl weir 

efficiency robustness accuracy chart parsing 
proceedings th acl conference pages 
scott miller fox 

au grammar acquisition 
proceedings human language technology workshop pages 
