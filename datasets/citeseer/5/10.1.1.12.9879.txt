rao blackwellised particle filtering fault diagnosis de freitas department computer science university british columbia main mall vancouver canada phone fax cs ubc ca tackle fault diagnosis problem conditionally gaussian state space models efficient monte carlo method known rao blackwellised particle filtering 
setting different state space model possible discrete state operation 
task diagnosis identify discrete state operation continuous measurements corrupted gaussian noise 
table contents model inference objectives particle filtering rao blackwellised particle filtering experiments acknowledgments 
automatic fault diagnosis fundamental problem aerospace systems autonomous robotics 
planetary rovers example able diagnose faults carry repairs ground operator intervention :10.1.1.117.9046
typical diagnosis scenario machine electronic system robot receives continuous stream data various board sensors 
subsequently processes information identify discrete state operation stuck rear wheel normal operation damaged camera 
design appropriate diagnosis system need take consideration machine environment change time measurements corrupted noise quantities interest unobservable machine state tends different different operating conditions 
address constraints need adopt probabilistic dynamic models 
models describe evolution machine ieee discrete continuous states statistical properties data 
typically continuous states measurements assumed gaussian distributed 
problem required models intractable 
motivated development algorithms approximate inference :10.1.1.117.9046
state ofthe art method monte carlo particle filter proposed :10.1.1.117.9046
method allows compute recursively time stochastic point mass approximation posterior distribution states observations 
comprehensive review monte carlo particle filtering methods see 
propose substantially efficient monte carlo particle filter fault diagnosis 
algorithm exploits analytical structure model 
particular exploits fact know values discrete states possible compute distribution continuous states exactly 
combine particle filter pf compute distribution discrete states bank kalman filters compute distribution continuous states 
approximate posterior distribution recursive stochastic mixture gaussians 
strategy known rao blackwellisation related formula see general discussion 
particle filters rbpf mixtures gaussians discussed :10.1.1.110.383:10.1.1.117.9046

model inference objectives adopt jump markov linear gaussian model jz ny denotes observations nx denotes unknown gaussian states known control signal denotes unknown discrete states 
noise processes gaussian 
clarity presentation state explicitly model implies con densities jz jx parameters jz known matrices see example parameter estimation model selection 
initial states 
important thing notice realisation single linear gaussian model 
knew solve exactly kalman filter algorithm 
aim analysis compute marginal posterior distribution discrete states jy 
distribution derived posterior distribution dx jy standard marginalisation 
posterior density satisfies recursion jy jy jx jx jy recursion involves intractable integrals 
resort form numerical approximation scheme 
particle filtering setting weighted set samples particles approximate posterior point mass distribution pn dx jy dx dx denotes dirac delta function 
approximation updated recursively equation shown 
simplicity show update marginal 
considering factorisation possible design efficient algorithms 
density gaussian computed analytically know marginal posterior density 
density satisfies alternative recursion jy jy jy jz jy notation generic vector adopt notation denote entries vector time simplicity denote random variable realisation 
consequently express continuous probability distributions pr discrete distributions pr 
distributions admit densities respect underlying measure counting lebesgue denote densities 
example considering space lebesgue measure 
particles 
example particle filter starts time unweighted measure provides approximation jy 
particle compute importance weights information time 
results weighted measure yields approximation jy 
subsequently resampling step selects fittest particles obtain unweighted measure fx yields approximation jy concentrated hypothesis allowing nonstationary tracking 
sampling prediction step introduces variety resulting measure approximation jy 
equation admit closed form expression equation admit methods required 
note term jy equation simplify jz dependency past values assuming weighted set samples fz represent marginal posterior distribution pn jy marginal density gaussian mixture pn jy jz dp jy jz jy computed efficiently stochastic bank kalman filters shown section 
rao blackwellised filter combines marginalisation sampling described section 
particle filtering particles samples fx time approximately distributed distribution dx jy particle filters enable compute particles fx approximately distributed posterior dx jy time sample posterior directly pf update accomplished introducing appropriate importance proposal distribution dx obtain samples 
basic algorithm consists steps sequential importance sampling selection 
sequential importance sampling step sample transition priors pr jz dx jx set evaluate normalize importance weights selection step multiply discard particles respect high low importance weights obtain particles 
simple sequential monte carlo algorithm time filtering purposes pf need storing resampling past trajectories 
sequential importance sampling step generic sequential monte carlo smc simulation needs extend current paths fx obtain new paths proposal distribution dbx jy integral dbx jx dp jy integral tractable propose modify particles time leave past trajectories intact 
words dbx jx set dbx jx dbx consequently dbx jy equal dx jy dbx jx samples 
weighted importance weights dbx jy dbx jy dx jy dx jy dbx jx dbx jx bx jx bx jx case transition prior bx jx simplifies markov density bx jx bx jx bz jz simplification required order implement smc algorithms 
equation note optimal importance distribution 

dbx jx 
proposal encounter difficulties ratio terms equation differs significantly :10.1.1.117.9046
optimal importance distribution difficult evaluate 
adopt transition prior proposal distribution 

dbx jx pr bz jz case importance weights likelihood function algorithm shown 
appeared names including condensation survival fittest bootstrap filter :10.1.1.117.9046
importance sampling framework allows design principled clever proposal distributions 
instance adopt suboptimal filters approximation methods information available time generate proposal distribution :10.1.1.110.383:10.1.1.117.9046
fact restricted situations may interpret likelihood distribution terms states sample directly 
doing importance weights equal transition prior 
selection step selection scheme associates particle bx number children say selection step allows track moving target distributions efficiently 
various selection schemes literature performance varies terms var 
choose minimum variance sampling algorithm :10.1.1.117.9046
sample set points interval points distance apart 
number children taken number points lie strategy introduces variance smaller multinomial residual resampling schemes var computational complexity 

rao blackwellised particle filtering rbpf similar pf sample discrete states 
sample discrete states update mean covariance continuous states exact computations 
particular sample propagate mean covariance kalman filter follows tjt jt tjt jt tjt tjt tjt tjt tjt tjt tjt tjt tjt tjt tjt tjt tjt tjt tjt cov tjt cov cov 
prior proposal applying equation find importance weights predictive density tjt new algorithm shown 
experiments experiments state space model generate synthetic data compare performance pf rbpf algorithms 
set matrices random experiment set jz state visited rare occasions 
repeated experiment times particles 
results shown 
clearly rbpf outperforms pf algorithm significantly 
require particles 
shows typical run parameters jz depicts propagated discrete distribution sequential importance sampling step set tjt tjt tjt tjt sample pr jz evaluate normalize importance weights jy selection step multiply discard particles tjt tjt respect high low importance weights obtain particles tjt tjt updating step step kalman recursion compute minimum statistics jt jt jt tjt tjt 
rbpf algorithm time computational time seconds rbpf pf 
results particles 
rbpf outperforms pf significantly 

proposed rao blackwellisation improve state art algorithms state estimation fault diagnosis 
results show considerable improvement 
currently addressing question diagnosing rare events 
question fundamental importance diagnosis faults planetary rovers 
solve problem introduced particle filter penalises particles outside region error :10.1.1.117.9046
approach easily combined rao true state rbpf map estimate pf map estimate 
typical run 
rbpf estimation mistakes 

distribution discrete states computed rbpf 
blackwellisation scheme 

penalising particles outside region error bias importance proposal distribution generate samples region error 
essential region error exponentially small respect size state space 
fortunately guidelines solving problem communications literature concerning importance sampling bit error detection :10.1.1.117.9046
adaptive techniques large deviation changes measure generate appropriate proposal distributions 
currently investigating ways extending batch framework line framework 

acknowledgments arnaud doucet verma richard washington 
:10.1.1.117.9046
random sampling approach state estimation switching environments 
automatica 
andrieu de freitas doucet 
sequential bayesian estimation model selection applied neural networks 
technical report cued tr cambridge university engineering department may 
andrieu doucet 
sequential monte carlo methods optimal filtering 
doucet de freitas gordon editors sequential monte carlo methods practice 
springerverlag 
casella robert 
rao blackwellisation sampling schemes 
biometrika 

particle filters theoretical perspective 
doucet de freitas gordon editors sequential monte carlo methods practice 
springerverlag 
de freitas niranjan gee doucet 
sequential monte carlo methods train neural network models 
neural computation 
doucet de freitas gordon editors 
sequential monte carlo methods practice 
springerverlag 
doucet godsill andrieu :10.1.1.110.383
sequential monte carlo sampling methods bayesian filtering 
statistics computing 
fox thrun burgard dellaert 
particle filters mobile robot localization 
doucet de freitas gordon editors sequential monte carlo methods practice 
springer verlag 
gordon salmond smith :10.1.1.117.9046
novel approach nonlinear non gaussian bayesian state estimation 
iee proceedings april 
isard blake :10.1.1.117.9046
contour tracking stochastic propagation conditional density 
european conference computer vision pages cambridge uk 
kanazawa koller russell :10.1.1.117.9046
stochastic simulation algorithms dynamic probabilistic networks 
proceedings eleventh conference uncertainty artificial intelligence pages morgan kaufmann 
kitagawa :10.1.1.117.9046
monte carlo filter smoother non gaussian nonlinear state space models 
journal computational graphical statistics 
pitt shephard :10.1.1.117.9046
filtering simulation auxiliary particle filters 
journal american statistical association 
smith shafi gao :10.1.1.117.9046
quick simulation review importance sampling techniques communications systems 
ieee journal selected areas communications 
van der merwe doucet de freitas wan :10.1.1.117.9046
unscented particle filter 
technical report cued infeng tr cambridge university engineering department june 
verma langford simmons :10.1.1.117.9046
nonparametric fault identification space rovers 
international symposium artificial intelligence robotics space june 
washington :10.1.1.117.9046
board real time state fault identification rovers 
ieee international conference robotics automation 
de freitas assistant professor department computer science university british columbia 
research interests include computational statistics machine learning robotics multimedia monte carlo methods 
dr de freitas obtained sc 
sc 
degrees electrical engineering wits university ph information engineering cambridge university 
worked post doctoral fellow computer science division uc berkeley 
