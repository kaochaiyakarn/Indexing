fast methods kernel text analysis taku kudo yuji matsumoto graduate school information science nara institute science technology taku ku aist nara ac jp kernel learning support vector machines successfully applied hard problems natural language processing nlp 
nlp feature combinations crucial improving performance heuristically selected 
kernel methods change situation 
merit kernel methods effective feature combination implicitly expanded loss generality increasing computational costs 
kernel text analysis shows excellent performance terms accuracy methods usually slow apply large scale text analysis 
extend basket mining algorithm convert kernel classifier simple fast linear classifier 
experimental results english basenp chunking japanese word segmentation japanese dependency parsing show new classifiers times faster standard kernel classifiers 
kernel methods support vector machines vapnik attract great deal attention 
field natural language processing successes reported 
examples include part speech tagging nakagawa text chunking kudo matsumoto named entity recognition japanese dependency parsing kudo matsumoto kudo matsumoto 
known nlp combination features contributes significant improvement accuracy 
instance task dependency parsing hard confirm correct dependency relation single set features head modifier 
dependency relations determined information phrases 
previous research feature combination selected manually performance significantly depended selections 
case kernel methodology 
instance polynomial kernel feature combinations implicitly expanded loss generality increasing computational costs 
mapped feature space quite large maximal margin strategy vapnik svms gives generalization performance compared previous manual feature selection 
main reason kernel learning delivered great results field nlp 
kernel text analysis shows excellent performance terms accuracy inefficiency actual analysis limits practical application 
example svm ne chunker runs rate byte sec previous rulebased system process kilobytes second 
slow execution time inadequate information retrieval question answering text mining fast analysis large quantities text indispensable 
presents novel methods kernel text analyzers substantially faster 
methods applicable nlp tasks general machine learning tasks training test examples represented binary vector 
specifically focus polynomial kernel degree attain feature combinations crucial improving performance tasks nlp 
second introduce fast classification algorithms kernel 
pki polynomial kernel inverted extension inverted index information retrieval 
pke polynomial kernel expanded feature combinations explicitly expanded 
applying pke convert kernel classifier simple fast liner classifier 
order build pke extend prefixspan pei efficient basket mining algorithm enumerate effective feature combinations set support examples 
experiments english basenp chunking japanese word segmentation japanese dependency parsing show pki pke perform respectively times times faster standard kernel systems discernible change accuracy 
kernel method support vector machines suppose set training data binary classification problem 
xl yl xj yj xj feature vector th training sample yj class label associated training sample 
decision function svms defined sgn sv yj xj non liner mapping function 

mapping function designed training examples linearly separable space 
larger requires heavy computation evaluate dot products xi explicit form 
problem overcome noticing construction optimal parameter omit details construction calculation decision function require evaluation dot products xi 
critical cases dot products evaluated simple kernel function 
substituting kernel function decision function 
sgn sv yj jk xj advantages kernels limited vectorial object applicable kind object representation just dot products 
polynomial kernel degree tasks nlp training test examples represented binary vectors sets examples nlp usually represented socalled feature structures 
focus cases suppose feature set 
training examples xj 
subsets xj 
case xj regarded binary vector xj xj xj 
xji xj xji 
dot product 
definition polynomial kernel degree sets corresponding binary feature vectors polynomial kernel degree kd kd kd 
referred implicit form polynomial kernel 
maximum entropy model widely applied nlp usually suppose binary feature functions fi xj 
formalization exactly representing example xj set fk xj 
known nlp combination features subset feature set general contributes accuracy 
previous research feature combination selected manually 
polynomial kernel allows feature expansion loss generality increase computational costs polynomial kernel degree implicitly maps original feature space space 

property critical reports say nlp polynomial kernel outperforms simple linear kernel kudo matsumoto 
give explicit form polynomial kernel show mapping function 
lemma explicit form polynomial kernel 
polynomial kernel degree rewritten kd cd pr pr set subsets exactly elements cd rm ml proof see appendix cd referred subset weight polynomial kernel degree function gives prior weight subset example quadratic cubic kernel sets quadratic kernel cubic kernel calculated implicit form 
lemma subset weights quadratic kernel cubic kernel calculated 
addition subsets pr follows 
similarly calculated explicit form function pki classify array initialized foreach foreach rj rj result foreach sv result result yj rj return sgn result pseudo code pki 
fast classifiers polynomial kernel section introduce fast classification algorithms polynomial kernel degree describing give baseline classifier sgn sv yj xj 
complexity sv takes calculate xj total sv support examples 
pki inverted representation item know advance set support examples contain item need calculate xj support examples 
naive extension inverted indexing information retrieval 
shows pseudo code algorithm pki 
function pre compiled table returns set support examples contain item complexity pki sv average item pki classification speed drastically faster small words feature space relatively sparse sv 
feature space sparse tasks nlp lexical entries features 
algorithm pki change final accuracy classification 
pke expanded representation basic idea pke lemma represent decision function explicit form sgn sv yj advance calculate sv cd pr xj 
yj xj indicator function subsets pr written simple linear form sgn 
pr 
classification algorithm referred pke 
complexity pke independent number support examples sv 
mining approach pke apply pke calculate degree vectors 

calculation trivial quadratic kernel just project original feature space space small calculated naive exhaustive method 
instance polynomial kernel degree higher calculation trivial size feature space exponentially increases 
take strategy 
original vector approximation 
apply subset mining algorithm calculate efficiently 
returns true returns 
definition approximation approximation 
set trivially close 
neg pos neg pos pos neg predefined thresholds 
algorithm pke approximation changes final accuracy selection thresholds pos neg 
calculation formulated mining problem definition feature combination mining set support examples subset weight cd extract subsets weights holds pos neg apply sub structure mining algorithm feature combination mining problem 
generally speaking sub structures mining algorithms efficiently extract frequent sub structures subsets sub sequences sub trees subgraphs large database set transactions 
context frequent means transactions contain sub structure 
parameter usually referred minimum support 
enumerate subsets apply subset mining algorithm times called basket mining algorithm task 
subset mining algorithms proposed focus prefixspan algorithm efficient algorithm sequential pattern mining originally proposed pei 
prefixspan originally designed extract frequent sub sequence subset patterns trivial difference set seen special case sequences sorting items set lexicographic order set sequence 
basic idea prefixspan divide database frequent sub patterns prefix grow prefix spanning pattern depth search fashion 
modify prefixspan suit feature combination mining 
size constraint enumerate subsets size plan apply polynomial kernel degree subset weight cd original prefixspan frequency subset change size 
mining task changes frequency subset weighted cd 
process mining algorithm assuming transaction support example xj frequency cd max cd cd 
cd 
weight calculated cd cd frequency original prefixspan 
positive negative support examples divide support examples positive yi negative yi examples process mining independently 
result obtained merging results 
minimum supports pos neg original prefixspan minimum support integer 
mining task give real number minimum support transaction support example xj possibly non integer frequency minimum supports pos neg control rate approximation 
sake convenience just give parameter calculate pos neg follows positive examples pos neg support examples negative examples support examples process mining set tuples obtained frequent subset weight 
trie efficiently store set 
example trie compression shown 
implementations trie double array aoe task 
actual classification pke examined traversing trie subsets 
experiments demonstrate performances pki pke examined nlp tasks english basenp chunking japanese word segmentation trie representation japanese dependency parsing 
detailed description task training test data system parameters feature sets subsections 
table summarizes detail information support examples size svs size feature set 
preliminary experiments show quadratic kernel performs best cubic kernel performs best 
experiments cubic kernel suitable evaluate effectiveness basket mining approach applied pke cubic kernel projects original feature space space large handled naive exhaustive method 
experiments conducted linux xeon ghz dual processors gbyte main memory 
systems implemented 
english basenp chunking text chunking fundamental task nlp dividing sentences non overlapping phrases 
basenp chunking deals part task recognizes chunks form noun phrases 
example sentence current account deficit narrow basenp chunk represented sequence words square brackets 
basenp chunking task usually formulated simple tagging task represent chunks types tags chunk 
non initial word 
outside chunk 
experiments settings kudo matsumoto 
standard data set ramshaw marcus consisting sections wsj corpus training section testing 
japanese word segmentation explicit spaces words japanese sentences identify word boundaries analyzing deep structure sentence 
japanese word segmentation formalized simple classification task 
cm sequence japanese characters tm sequence japanese character types associated character yi 
boundary marker 
boundary ci ci yi yi 
feature set example xi characters character types constant window ci ci ci ci ti ti ti ti 
note distinguish relative position character character type 
kyoto university corpus kurohashi nagao sentences articles january st january th training data sentences articles january th test data 
japanese dependency parsing task japanese dependency parsing identify correct dependency base phrase japanese 
previous research state art svms japanese dependency parser kudo matsumoto 
combined svms efficient parsing algorithm cascaded chunking model parses sentence deterministically deciding current chunk modifies chunk immediate right hand side 
input algorithm consists set linguistic features related head modifier word part speech inflections output algorithm value dependent independent 
standard data set corpus described japanese word segmentation 
usually japanese word boundaries highly constrained character types phonetic characters japanese chinese characters english alphabets numbers 
results tables show execution time accuracy size extracted subsets changing 
pki leads times improvements 
improvement significant 
average items relatively small 
improvement significantly depends sparsity support examples 
improvements pke significant pki 
running time pke times faster set appropriate 
settings preserve final accuracies test data 
frequency pruning pke cubic kernel tends large 
reduce size examined simple frequency pruning experiments 
extension simply give prior threshold erase subsets occur support examples 
calculation frequency similarly conducted prefixspan algorithm 
tables show results frequency pruning fix 
size set third original size 
reduction gives slight speed increase improvement accuracy 
frequency pruning allows remove subsets large weight small frequency 
subsets may generated errors special outliers training examples cause overfitting training 
frequency pruning 
reduce size half accuracy reduced 
implies features frequency contribute final decision hyperplane 
accuracy evaluated measure harmonic mean precision recall 
table details data set data set examples sv svs positive svs negative svs size feature avg 
xj avg 
note handle class problems pairwise classification building classifiers considering pairs classes final class decision majority voting 
values column averages pairwise classifiers 
discussion studies efficient classification svms 
propose expand quadratic kernel named entity recognizer drastically fast 
subsumed pke 
pke share basic idea feature combinations explicitly expanded convert kernel classifier simple linear classifier 
explicit difference pke designed quadratic kernel 
implies deal feature combination size 
hand pke general applied quadratic kernel general style polynomial kernels pke theoretical constrains limit size combinations 
addition mention expand feature combinations 
naive exhaustive method expand scalable efficient extracting feature combinations 
pke takes basket mining approach enumerating effective feature combinations efficiently exhaustive method 
works focused polynomial kernel degree widely applied tasks nlp table results pke time speedup sec sent 
ratio pki table results pke time speedup acc sec sent 
ratio pki table results pke time speedup acc sec sent 
ratio pki table frequency pruning pke time speedup acc sec sent 
ratio table frequency pruning pke time speedup acc sec sent 
ratio attain feature combination crucial improving performance tasks nlp 
introduced fast classification algorithms kernel 
pki polynomial kernel inverted extension inverted index 
pke polynomial kernel expanded feature combinations explicitly expanded 
concept pke applicable kernels discrete data structures string kernel lodhi tree kernel collins duffy 
instance tree kernel gives dot product ordered tree maps original ordered tree sub tree space 
apply pke efficiently enumerate effective sub trees set support examples 
similarly apply sub tree mining algorithm zaki problem 
appendix lemma proof cd proof 
subsets 

case dot product vector 
xn 
yn xj yj xj xj 
expanded follows kn kn 

kn 

xn yn note kj binary kj number size subsets coefficient 

cd kr kn 

kr 

aoe 

efficient digital search algorithm double array structure 
ieee transactions software engineering 
michael collins nigel duffy 

convolution kernels natural language 
advances neural information processing systems vol nips pages 
hideki 

efficient support vector classifiers named entity recognition 
proceedings coling pages 


svm kernels semi structured data 
proceedings icml pages 
taku kudo yuji matsumoto 

japanese dependency structure analysis support vector machines 
proceedings emnlp vlc pages 
taku kudo yuji matsumoto 

chunking support vector machines 
proceedings naacl pages 
taku kudo yuji matsumoto 

japanese dependency cascaded chunking 
proceedings conll pages 
kurohashi makoto nagao 

kyoto university text corpus project 
proceedings anlp pages 
lodhi craig saunders john shawe taylor nello cristianini chris watkins 

text classification string kernels 
journal machine learning research 
nakagawa taku kudo yuji matsumoto 

revision learning application part speech tagging 
proceedings acl pages 
jian pei jiawei han 
prefixspan mining sequential patterns prefix projected growth 
proc 
international conference data engineering pages 
lance ramshaw mitchell marcus 

text chunking transformation learning 
proceedings vlc pages 
vladimir vapnik 

nature statistical learning theory 
springer 
mohammed zaki 

efficiently mining frequent trees forest 
proceedings th international conference knowledge discovery data mining kdd pages 
