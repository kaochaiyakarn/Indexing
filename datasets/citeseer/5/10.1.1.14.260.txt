improving summarization rhetorical parsing tuning study relationship structure dis course set summarization heuristics employed current systems 
tight coupling enables learn genre specific combinations heuristics disambiguation dis course parsing 
coupling enables con struct discourse structures yield summaries con tain textual units important variety position title lexical similarity heuristics central main claims texts 
careful analysis results enables shed new light issues related summary evaluation learning 
motivation current approaches automatic summarization employ techniques assume textual salience correlates wide range linguistic phenomena 
approaches assume important textual units con tain words frequently luhn ed words title sec tion headings edmundson 
assume important sentences located paragraphs baxendale positions determined training particular text genre lin hovy 
systems assume important sentences texts contain bonus words phrases significant important conclu sion show unimportant sen tences contain stigma words hardly sible edmundson kupiec teufel moens :10.1.1.41.1161
systems assume important sen tences concepts highest connected entities elaborate semantic structures hoey salt allan mani bloedorn barzilay elhadad 
assume important sentences clauses derivable discourse representation texts ono marcu marcu :10.1.1.24.6671:10.1.1.51.5466:10.1.1.14.9923
variety systems edmundson kupiec teufel moens lin 
mani bloedorn designed integrate subsets heuristics mentioned 
approaches daniel marcu information sciences institute university southern california admiralty way suite marina del rey ca marcu isi edu individual heuristic yields probability distribution reflects importance sentences 
combination probability distributions defined heuristic yields sentences included summary 
multiple heuristic systems common treat texts flat sequences sentences system employs discourse heuristics 
consequence possible example sentence assigned high importance score basis position text semantic similar ity title subsidiary main ar text 
remedy shortcoming advantage structure dis course 
precisely study relationship structure discourse set summarization heuris tics employed current systems 
tight cou pling achieved applying simple learning mechanism gives advantages previ ous methods 
corpora manually built sum enable learn genre specific combinations heuristics disambiguation dis course parsing 
second discourse structures derive enable select textual units important variety position title lexically heuristics central main claims texts 
section review discourse theory algorithms constitute foundation 
explain approach fusing various summa heuristics discourse processing framework section review heuristics discourse perspective 
section evaluate ap individual heuristic sum algorithm finds combina tions heuristics yield optimal summaries 
assessing strengths limitations approach 
background rst 
discourse theory going rhetorical structure theory rst mann son 
central rst notion rhetorical relation relation holds non overlapping text spans called nucleus satellite 
exceptions rule relations contrast multinuclear 
distinction nuclei satellites comes empirical observation nucleus expresses es writer purpose satellite nucleus rhetorical relation comprehensible dependent satellite vice versa 
text coherence rst assumed arise set constraints 
constraints operate nucleus satellite combination nucleus lite 
example evidence relation holds nucleus labelled text shown low satellite labelled text nucleus presents information writer insufficiently supported accepted reader satellite presents information thought believed reader credible comprehension satellite increases reader belief nucleus 
rhetorical relations assembled rhetorical structure trees rs trees re applying spans range size clause unit text 
rhetorical parsing 
developments compu tational linguistics created means auto matic derivation rhetorical structures unrestricted texts 
example text shown input rhetorical parsing algorithm discussed detail marcu bro ken elementary units surrounded square brackets 
rhetorical parsing algorithm uses cue phrases simple notion semantic similarity der hypothesize rhetorical relations units 
eventually algorithm derives cal structure tree shown 
distant orbit percent farther sun earth slim atmospheric blanket mars ex frigid weather conditions 
surface typically average degrees celsius degrees fahrenheit equator dip degrees near poles midday sun ical latitudes warm ice occasion liquid water formed way rate instantly low atmospheric pressure 
atmosphere holds small amount water water ice clouds develop martian weather involves blowing dust carbon dioxide winter example blizzard frozen carbon dioxide pole meters dry ice snow accumulate previously frozen car bon dioxide evaporates opposite polar cap 
summer pole 
sun remains sky day long temperatures warm melt frozen elaboration 


sl discourse tree built rhetorical parser marcu text :10.1.1.24.6671:10.1.1.24.6671:10.1.1.51.5466:10.1.1.14.9923:10.1.1.14.9923
discourse structure obeys constraints put forth mann thompson marcu 
binary tree leaves elementary textual units 
node tree plays role nucleus satellite 
nuclei represented solid boxes satellites represented dot ted boxes 
internal nodes discourse structure labelled names rhetorical relations numbers 
numbers denote salient promotion units node correspond impor tant units subsumed text span 
determined bottom fashion follows salient unit leaf leaf salient units internal node union salient units imme nuclear children 
example node spans units salient units ate children node labelled relation contrast nuclei promotion units re spectively root node spans units salient unit node corresponds span nucleus salient unit 
parent nodes linked subordinated nuclei solid arrows parent nodes linked subordinated satellites dotted lines 
discourse summarization 
discourse structure shown created derive partial ordering important units orig inal text considering units promoted closer root important promoted close 
applying criterion tree obtain partial ordering shown cause unit promotion unit associated root unit unit level root units units levels root 
partial ordering obtain summary contains original text selecting units partial ordering 
applying algorithm marcu built summarization system recalled precision clause units con sidered important human judges collection texts 
framework text summarization ways integrate discourse measure textual saliency described measures saliency cohesion position similarity title simplest way compute probability distribution importance textual units discourse method combine probability distribu tions produced heuristics 
ap proach discourse heuristic just heuris tics employed system 
obtaining sum amounts determining way com implemented heuristics 
summarization system works lines described treats texts flat sequences textual units discourse method internally uses sophisticated representation 
ing approach permits selec tion textual units play central role dis course 
example text summarized con sists units text may possible combination position title discourse heuristics yield higher score unit unit unit nucleus text expresses important 
unfortunately interpret text flat sequence units rhetorical relation nu assignments respect units appropriately exploited 
complex way integrate discourse cohesion position summarization methods consider structure discourse impor tant factor determining saliency assumption sup ported experiments done mani 

approach longer interpret texts flat se quences textual units tree structures re nuclearity rhetorical relations charac textual span 
discourse taken central interpretation text obtaining sum amounts finding best discourse tations 
rest explore approach 
criteria measuring goodness discourse structures order find best discourse interpretations interpretations yield summaries similar summaries generated manually considered metrics discuss 
clustering metric 
common assumption majority current text theories texts exhibit defined topical structure 
approach assume discourse tree better exhibits high level structure matches possible topical boundaries text structure built 
order capture intuition build dis course trees associate node tree clus tering score 
leaves score internal nodes score similarity im mediate children 
similarity computed tra ditional cosine metric style hearst 
consider discourse tree better discourse tree sum clustering scores asso ciated nodes higher sum clustering scores associated nodes 
marker metric 
naturally occurring texts wide range discourse markers signal relations textual spans various sizes 
assume discourse structure reflect ex discourse relations sig discourse markers 
words assume discourse structure better discourse structure uses rhetorical relations ex signaled rhetorical clustering metric 
clustering metric discussed computes similarity textual spans 
discourse formalization proposed marcu assumed discourse relation holds textual spans relation holds salient units nuclei associated spans 
extend observation similarity introducing rhetorical clustering metric measures similarity salient units associated spans 
example clustering score associated root tree measures similarity spans 
contrast rhetorical clustering score associated root tree measures similarity units salient units pertain spans respectively 
light rhetorical clustering metric consider discourse tree better discourse tree sum rhetorical clustering scores associated nodes higher sum rhetorical clustering scores associated nodes shape metric 
disambiguation metric previous marcu shape metric best trees skewed right :10.1.1.24.6671:10.1.1.51.5466:10.1.1.14.9923
explanation metric text processing es left right process 
genres people write texts important ideas go paragraph text levels 
text writers add elaborate text went consequence incremental discourse build ing consists expansion tight branches 
shape metric consider discourse tree better discourse tree skewed right see marcu mathematical formulation tion 
title metric 
variety systems assume important sentences text words occur title 
measure similarity tex tual unit title applying traditional cosine met tic 
compute title score discourse structure computing similarity title units promoted salient struc ture 
intuition capture way discourse structure constructed pro motes close root possible units similar title 
title met tic consider discourse structure better discourse structure title score higher title score 
position metric 
research tion baxendale edmundson kupiec lin hovy shown genres stereotypical structure important sentences lo cated paragraphs documents 
position metric captures intuition signing positive score textual unit belongs sentences paragraphs 
compute position score discourse structure averaging position scores units promoted salient discourse structure 
intuition capture way discourse structure constructed promotes close root possible units located text 
ac cording position metric consider discourse structure better discourse struc ture position score higher position score 
connectedness metric 
heuristic employed current summarization systems considering important highest connected entities elaborate semantic structures hoey salton allan mani bloedorn 
barzilay elhadad 
imple ment heuristic computing average cosine sim ilarity textual unit text units 
associate connectedness score discourse structure averaging connectedness scores units promoted salient discourse structure 
case met fact 
journalists trained employ pyramid approach io writing consciously 

tics consider discourse structure better discourse structure connectedness score higher connectedness score combining heuristics approach mentioned discourse parsing am way sentence parsing rhetorical parsing algorithm derives discourse structure text 
metrics listed favors different discourse interpretation 
purpose assume best discourse structures linear combination metrics 
lines described section associate discourse structure score marker score rhetorical clustering score shape score title score position score connectedness score sco assume best tree text corre sponds discourse structure highest score 
score computed shown 
woo weights associated metric 
sr hap hop sp 

avoid data scores correspond metric normalized values 
formulation goal determine combinations weights yield discourse structures turn yield summaries close possible generated humans 
discourse terms amounts empirical summarization data dis course parsing disambiguation 
corpora study order evaluate appropriateness tion heuristics corpora corpus newspaper articles trec collec tion jing corpus articles scientific american marcu 
human judges selected sentences included summaries articles trec corpus see jing details 
articles cutoff took set sentences selected human judges gold standard summa 
initial experiments noticed rhetorical parsing algorithm needed minute order automatically generate summaries articles trec corpus highly ambiguous discourse perspective 
order en able better employment training techniques specific machine learning partitioned trec collection subsets 
subset contained documents subset included documents summarization algorithm required ex sive computation documents se lected randomly 
second subset contained rest documents algorithm generate summaries sufficiently fast 
purpose refer collection articles train ing corpus collection articles test corpus 
reader take de tations associated referents literally partitioning performed randomly 
reader see partitioning means ac process determines combination heuristics yield best summarization results texts corpus 
second corpus consisted scientific amer texts elementary textual units clause units labelled human judges important somewhat important unimportant see marcu details experiment :10.1.1.24.6671:10.1.1.51.5466:10.1.1.14.9923
texts took set textual units judges agreed impor tant gold standard summarization 
built automatically discourse structures texts corpora various combinations weights compared summaries de rived structures gold standards 
comparison employed traditional recall precision fig ures reflected percent textual units identified correctly program respect gold standards percent textual units identified correctly program respect tal number units identified program 
corpora attempted mimic closely possible summarization tasks carried human judges 
trec corpus automatically extracted summaries cutoffs scientific american corpus automatically extracted summaries reflected lengths summaries hu man judges agreed 
appropriateness summarization individual heuristics trec corpus 
initially evaluated appro text summarization heuristics cutoffs collection texts trec corpus 
assigning turn value weights weights assigned value estimated appropriateness individual metric text summarization 
tables show recall precision figures pertain discourse structures built trec corpus order evaluate appropriateness text summarization metrics cutoffs respectively 
better understanding impact heuristic tables show metric recall precision humans clustering marker rhetorical clustering shape title position connectedness lead random table appropriateness metrics text summarization trec corpus cutoff 
metric recall precision humans clustering marker rhetorical clustering shape title position connectedness lead random table appropriateness metrics text summarization trec corpus cutoff 
recall precision figures associated human judges baseline algorithms 
recall precision figures human judges computed average recall precision summaries built human judge individually compared gold standard 
recall precision fig ures interpreted summarization upper bounds collection texts characterize 
judge contributed derivation gold stan recall precision figures pertain hu man judges biased probably higher figures characterize outsider experi ment 
recall precision figures pertain base line algorithms computed follows lead algorithm assumes important units located texts random algorithm assumes important units selected randomly 
results table show newspaper ar title position metrics best individual metrics distinguishing discourse trees appropriate generating summaries discourse trees 
interestingly heuristics taken isolation better lead algorithm 
fact results table show quantitative difference terms re call precision summaries generated lead algorithm summaries generated hu 
puzzled finding investigated issue scanning collection arti cles came believe short simple inappropriate testbed summarization research 
estimate validity belief focused attention subset articles sophisticated writing style follow straightforwardly pyramid ap proach articles word computer 
evaluated performance lead algorithm subset obtained figures recall precision cutoff 
result suggests soon cated texts considered performance lead algorithm decreases significantly newspaper genre 
results table show newspaper articles shape metric best individual metric distinguishing discourse trees appropri ate summaries discourse trees 
shape heuristic better lead algorithm 
scientific american corpus 
evaluated appropriateness text summarization heuris tics clause sentence levels collection texts scientific american corpus obtained tally different distribution configuration weights yielded highest recall precision figures 
close analysis results table shows scientific american articles clustering rhetorical clustering shape metrics best individual metrics distinguishing dis course trees clause tion discourse trees 
results table show scientific articles shape metric best individual metric distinguishing discourse trees appropriate sentence summarization 
ingly title position connectedness met rics random metric 
contrast results pertain trec corpus lead algorithm performs significantly worse human judges texts scientific american corpus despite scientific american texts shorter trec collection 
discussion 
recall precision figures section suggest individual heuris tic consistently guarantees success different text genres 
figures suggest genre granularity textual units selected summarization length metric recall precision humans clustering marker rhetorical clustering shape title position connectedness lead random table appropriateness metrics text summarization scientific american corpus clause unit case 
metric recall precision humans clustering marker rhetorical clustering shape title position connectedness lead random table appropriateness metrics text summarization scientific american corpus sentence case 
summary affect appropriateness heuristic 
focusing human judgments notice newspaper genre yields higher consistency scientific american genre respect hu mans believe important 
results section show humans agree better important sen tences important clauses newspaper genre agree better im portant summaries somewhat important summaries 
learning best combinations heuristics individual applications metrics suggest heuristics appropriate summarizing texts long text genres corpora 
addition assessment interested finding com heuristics yield summaries 
employed simple learning paradigm describe 
gsat algorithm framework proposed find ing combination metrics best summa amounts finding combination weights maximizes recall precision figures associated automatically built summaries 
algorithm shown performs greedy search dimensional space defined weights approach mirrors proposed levesque mitchell solving propositional satisfiability problems 
algorithm assigns initially member vector weights maz random value interval 
assignment corresponds point dimensional space defined weights 
program attempts steps times move incrementally dimensional space direction max measure recall precision figures pertain automatically built summaries 
measure computed shown 
precision recall measure takes values values recall precision higher recall preci sion closer 
point program computes value recall precision figures summaries correspond points neighborhood distance axes lines 
set points charac neighborhood current configuration algorithm selects randomly line ofthe weight configurations yielded maximum value line 
line algorithm moves dimensional space position characterizes configuration weights selected line 
steps iterations algorithm updates configuration weights reflects combination weights yielded maximal value recall precision figures line 
algorithm re process times order increase chance finding maximum local 
lengths summaries automati cally extracted fixed cases chose look configurations weights maximized value recall precision figures 
algorithm find configurations weights maximize recall precision 
results 
experimented differ ent values aw 
ran algorithm shown collection texts training trec corpus aw obtained multiple configurations weights yielded maximal values recall precision figures cutoffs 
table shows best configurations cutoff 
best configuration weights cutoff recalls sentences considered important human judges trec corpus precision 
value recall precision figures configuration approximately lower value pertains human judges higher value pertains lead algorithm 
results ta ble show cutoff dif ference summaries built human judges rhetorical parser lead algorithm 
lead algorithm performs level draw short newspaper articles lead algorithm efficient solution 
cutoff best configuration weights recalls sentences considered important human judges corpus preci sion 
value recall precision figures configuration lower value pertains human judges higher value pertains lead algorithm 
results suggest want build longer summaries lead heuristic longer appropriate newspaper genre simple articles 
scientific american corpus 
ran algo rithm shown collection texts scientific american corpus steps au 
table shows configurations weights yielded maximal values recall precision figures clause unit level configurations weights yielded maxi mal values sentence level 
best combination weights summarization clause unit level recalls elementary units considered impor human judges precision 
value recall precision figures config lower value pertains human judges higher value pertains lead algorithm 
result outperforms significantly previous recall precision figures obtained marcu shape heuristic 
best combination weights summarization sentence level recalls sentences con sidered important human judges precision 
value recall precision fig ures configuration lower value pertains human judges higher value pertains lead algorithm 
results suggest scientific american articles summarized prop applying simple lead heuristic applying discourse algorithm 
discussion 
limited size corpora rhetorical ambiguity texts trec corpus carrying cross validation 
experiments meaningless prohibitively ex input corpus texts 
manually built summaries st texts 
output weights ii yield best summaries respect ct st 
ma wets 
wean rand rand rand 
tries 
wets rk rand rand rand 
ft 

flips 
ft aw 




fl aw 
fh aw 
ft fi 
fh 
ft 
ft 
endfor 
endfor 
return corpus training testing training testing training testing training testing gsat algorithm improving summarization 
method 
ll ctm recall precision humans program program lead humans program program lead val table combination heuristics yielded best summaries texts trec corpus 

consequence recall precision re sults reported interpreted suggestive discourse summarization performance 
experiments support con pertain integration multiple heuris tics 
analysis patterns weights tables shows corpora individual heuristic clear winner respect contribution obtaining summaries 
tr ec corpus tion rhetorical clustering connectedness heuristics heuristics contribute consistently improvement summarization qual ity 
scientific american corpus combined heuristics marker rhetorical clustering shape title heuristics contribute con improvement recall precision fig ures cases 
contrast clustering position connectedness heuristics detrimental respect collection texts considered 
supported granularity method wrn wrist recall precision val clause humans unit program lead sentence humans program lead table combination heuristics yielded best summaries texts scientific american corpus 
corpus method humans program best program best lead humans program best program best lead tt recall precision val table cross analysis summarization results trec corpus 
data tables strength sum system depend heuristic ability system optimal combination heuristics 
data shows optimal combinations need ily follow common pattern example combina tions heuristics yield highest values re call precision figures cutoff trec corpus differ dramatically combination relies entirely position heuristic combination uses balanced combination heuristics slightly biased assigning importance clustering heuristic 
addition analysis patterns weights yielded optimal summaries corpora examined appropriateness combinations weights optimal summary cutoff order summarize texts different cutoff 
table shows recall precision figures obtained patterns weights yielded optimal sum cutoff summarize texts trec corpus cutoff recall preci sion figures obtained patterns weights yielded optimal summaries cutoff summarize texts cutoff 
figures table show 
combinations heuristics yielded optimal summaries particular yield opti mal summaries cutoffs find combinations heuristics outperform lead algorithm cutoffs 
results table suggest ways train summarization system 
system going frequently summarize texts cutoff sense train produce summaries cutoff 
system going gen erate summaries various lengths different train ing methodology adopted en sure optimality cutoff spectrum 
empirical computational experiments de scribed conclu sions 

extracting summaries short articles news story genre simple lead algorithm efficient solution 

extracting longer summaries short newspaper articles extracting size summaries complex necessarily news sto ries newspaper articles simple lead algorithm provide satisfactory solution 
assertion holds text genres scientific amer 

magic key heuristic ob raining summarization results strength summarization system come ability combine multitude heuristics 

combinations heuristics yield optimal results certain sum mary extract lengths yield optimal results different lengths 

incorporating various heuristics discourse summarization framework yields results 

order assess confidently effectiveness summarization methodology introduced larger corpora required 

am grateful jing regina barzilay kathleen mckeown michael sharing trec summarization cor pus chin yew lin fruitful discussions pre vious versions 
special go eduard hovy comments discussions 
regina barzilay michael elhadad 

lex chains text summarization 
proceedings acl eacl workshop intelligent scal able text summarization pages madrid spain july baxendale 

machine index cal literature experiment 
ibm journal re search development 
carmen cumming catherine 

canadian reporter news writing reporting 
race 
edmundson 

new methods automatic ex 
journal association computing machinery april 
marti hearst 

texttiling segmenting text multi paragraph subtopic passages 
computa tional linguistics march 
michael hoey 

patterns lexis text 
oxford university press 
jing regina barzilay kathleen mckeown michael elhadad 

summarization evaluation methods experiments analysis 
proceedings aaai spring symposium intelligent text summarization pages stanford march 
julian kupiec jan pedersen chen 

trainable document summarizer 
proceedings th acm sigir annual conference research development information retrieval pages seattle washington 
chin yew lin eduard hovy 

identifying top ics position 
proceedings fifth conference applied natural language processing anlp pages washington dc march april 
chin yew lin 

assembly topic extraction mod ules summarist 
proceedings aaai spring symposium intelligent text summarization stanford ca march 
luhn 

automatic creation literature ab 
ibm journal research development april 
inderjeet mani eric bloedorn 

machine learn ing generic user focused summarization 
proceedings fifteenth national conference ar intelligence aaai madison wisconsin july 
inderjeet mani eric bloedorn barbara gates 

cohesion coherence models text summa 
proceedings aaai spring sym intelligent text summarization stanford ca march 
william mann sandra thompson 

rhetorical structure theory functional ory text organization 
text 
daniel marcu 

building rhetorical structure trees 
proceedings thirteenth national con ference artificial intelligence aaai volume pages portland oregon august 
daniel marcu 

discourse structures text summaries 
proceedings acl eacl workshop intelligent scalable text summarization pages madrid spain july 
daniel marcu 

rhetorical parsing natu ral language texts 
proceedings th annual meeting association computational linguis tics acl pages madrid spain july 
daniel marcu 

rhetorical parsing sum generation natural language texts 
ph thesis department computer science uni versity toronto december 
kenji ono kazuo sumita 

ab generation rhetorical structure extrac tion 
proceedings international confer ence computational linguistics coling pages japan 
gerard salton james allan 

selective text utilization text traversal 
international journal human computer studies 
bart selman hector levesque david mitchell 

new method solving hard ity problems 
proceedings tenth national conference artificial intelligence aaai pages san jose california 


adaptive method automatic abstracting indexing 
information processing volume pages 
north holland publish ing 
simone marc moens 

sentence ex traction classification task 
proceedings acl eacl workshop intelligent scal able text summarization pages madrid spain july 
