recursive spectral algorithm clustering pairwise similarities david cheng mit mit edu ravi kannan yale university kannan cs yale edu santosh vempala mit vempala math mit edu wang mit theory lcs mit edu practical implementation clustering algorithm described 
clustering algorithm implicit explicit representation pairwise similarities objects produces complete hierarchical clustering objects 
implementation runs log time cluster number non zero entries document term matrix common implicit representation similarities data objects 
perform thorough experimental evaluation algorithm practice 
results show algorithm better competitive existing clustering algorithms means rock qr 
decade witnessed unprecedented explosion volume readily accessible data 
challenge computer scientists nd methods locate relevant information organize intelligible way 
di erent classical database problem ways rst may time long term computer memory store structure data world wide web portion central location 
second nd interesting patterns data knowing advance exactly looking 
clustering refers process classifying set data objects groups group consists similar objects 
classi cation partition dataset hierarchical 
clustering proposed method aid information retrieval contexts 
document clustering help improve precision recall nding nearest neighbors generate hierarchical taxonomy eciently organizing results web search 
learn mixture models datasets image segmentation 
assume data objects way easy compute similarity pair objects 
example coordinates points space document term matrices feature vectors 
just pairwise similarities 
methods proposed literature especially context document clustering 
broadly speaking fall agglomerative bottom methods partitioning methods top 
take advantage special structure methods rely careful choice similarity function 
hand general purpose heuristic known means performs quite argued outperforms methods :10.1.1.125.9225
class algorithms known spectral methods applicable variety clustering contexts 
investigated :10.1.1.19.8100:10.1.1.140.3011
roughly speaking spectral algorithm uses eigenvalues eigenvectors similarity matrix nd clustering 
principal motivation spectral algorithm analyzed 
authors develop measure clustering graph pairwise similarities measure universal quite general 
prove simple spectral algorithm input similarity matrix reasonable worst case guarantees respect measure 
running time dataset objects documents 
experimental evidence provided theoretical guarantees involve large constant factors 
describe ecient implementation algorithm perform thorough experimental evaluation 
main advantage implementation described section maintains sparsity input matrices 
section show document term matrix non zero entries clustering algorithm uses space takes log time cluster produces 
algorithm generate complete hierarchical classi cation documents tree leaves documents time mn log time 
commodity hardware algorithm took minutes datasets documents terms see gures 
section gives comprehensive timing evaluation 
main contribution experimental evaluation algorithm document term matrices standard datasets randomly generated data dimensional pictures 
reported section cases algorithm quite document clustering consistently outperformed methods better heuristic known bisecting means :10.1.1.125.9225
performance evaluated measure entropy accuracy 
section discuss results er new problems consider 
algorithm setup input algorithm matrix rows data objects columns features 
data arise contexts refer input matrix document term matrix 
denote ith document row vector similarity documents de ned dot product term vectors 
similarity matrix just aa typically document unit vector similarity documents cosine angle vectors 
think similarity matrix complete graph vertex set set documents edge weights similarity vertices documents 
similarity graph 
brief description algorithm constructs hierarchical clustering vertices similarity graph recursively dividing graph pieces cut vertices 
conductance cut min 

informally edges crossing cut size lower conductance better cut graph 
conductance graph minimum conductance achieved cut denote algorithm works nding cut worse cut terms conductance 
partitions graph recurses subparts 
nd cut group vertices ordering second eigenvector similarity matrix aa worse imprecise theoretical guarantees quality cut 
algorithm describe ecient practical implementation algorithm theoretical guarantees hold 
algorithm box 
algorithm 
input matrix output tree leaves rows 
initialize zero matrix 
set 
diagonal matrix diagonal entries row sums 
compute singular vector compute second largest right singular vector matrix 

cut sort 
find value minimizes conductance cut fv fv vn submatrices rows 
normalize adjust self similarities setting ii ii 


recurse recurse steps submatrices note recursion tree results algorithm hierarchical clustering document set 
certain situations desired number clusters 
recursion certain level number clusters equal desired number 
details practice representation documents row vectors sparse zeros non zero entries 
algorithm takes particular care similarities indirectly sparse document term matrix 
vector matrix algorithm uses stored standard data structures sparse representation 
allow constant time operations retrieving particular value initialization entire vector matrix speci value 
describe exact details steps algorithm 
initialize step initialization trivial takes constant time 
compute step compute row sum similarity matrix aa sum ith row aa observe 
ik jk ik jk jk depend compute compute 
row 
computation exactly sweep non zero entries dot product compute takes time proportional non zeros result total running time 
store require space 
compute singular vector algorithm described uses second largest right eigenvector normalized similarity matrix compute cut 
compute vector compute second largest singular vector matrix note second largest eigenvector key property eigenvalues related easy check qv br note symmetric matrix compute second largest eigenvector power method iterative algorithm main computation matrix vector 
sparse computing qy vector requires sparse matrix vector multiplications maintain sparsity compute second eigenvector 
power method described power method 
construct random dimensional vector 
orthogonal 
compute jvj set jvj 
set qv repeat steps log times making random starting vector may done ways simply pick component uniform distribution 
step ensures vector compute second largest eigenvector 
note left eigenvector eigenvalue 
basic fact linear algebra second largest eigenvector orthogonal largest eigenvector 
keep orthogonal vector arbitrarily choose change rst component setting note 
power method takes log iterations converge lemma corollary proves 
lemma 
symmetric matrix chosen uniformly random unit dimensional sphere 
positive integer holds probability jja jja ln jjajj proof 
symmetric write eigenvalues arranged order corresponding eigenvectors 
express basis 
random probability ln 
older inequality says satisfying ja jb jja inequality holds older note lemma follows 
corollary 
ln ln jja jja total running time log iteration requires sparse matrix vector multiplications 
require space vector matrix cut step requires sort coordinates done log time 
step choose cut cuts tg ft ng smallest conductance 
conductance cut worse conductance graph smallest conductance cut graph see quantitative statement 
recall ig fi ng 
min numerator expression denominator compute passes note numerator value follows preceding value 





maintain partial sums compute initializing partial sums requires pass computation requires pass update partial sums 
denominator computed similar fashion 
space required store amounts 
normalize recurse submatrices de ned cut normalize row sums similarity matrices 
modifying matrix particular add diagonal element value ii ij set ii 

ii ij 

compute ii values need passes matrix recurse executing steps result cuts recurse submatrix contains row recursion tree complete hierarchical clustering rows input size number nonzero entries time function input size input size number nonzero entries space function input size performance clustering algorithm experiments time space requirements theoretically worst case time compute complete hierarchical clustering rows mn log takes log time execute steps 
practice algorithm perform quite 
figures show results performance experiment 
experiment chose random articles newsgroup newsgroups data set ran clustering algorithm nding complete hierarchical clustering 
initially increased increments 
timing graph recorded number seconds needed nd complete hierarchical clustering 
space experiment recorded amount ram megabytes clustering algorithm 
note worst case chose documents newsgroups total news articles able compute complete complete hierarchical clustering minutes 
clustering experiments tested clustering algorithm types datasets standard document term matrices categorical clustering data synthetic data mixture models dimensional pictures 
mention web search engine implementation uses clustering algorithms developed 
datasets de ned notion right clustering 
performance algorithm evaluated measures measure entropy accuracy 
measures de ned respect correct classi cation 
explain measures 
correct clustering nodes complete hierarchical clustering spectral algorithm de nes cluster nodes tree entire set 

measure correct cluster measure cluster max jc jc jc measure clustering de ned 
jc jcj measure score range higher measure score implies better clustering 
depth justi cation measure see 

entropy de ne entropy jc log jc entropy cluster measure disorder cluster 
lower entropy score clustering implies clustering better 
best possible entropy score worst 
entropy rst introduced measure clustering 
entropy clustering weighted sum entropies clusters 
jd jcj entropy complete hierarchical clustering minimum entropy choice nodes partition 
accuracy accuracy max jc accuracy clustering weighted sum accuracies 
accuracy complete hierarchical clustering maximum accuracy choice nodes partition note range accuracy score higher accuracy score better 
accuracy measure performance supervised learning clustering see 
document term matrices experiments involved common datasets prior experimentation 
cases better compare favorably known results 
reuters clustering algorithms tested reuters dataset corpus news articles classi ed distinct news topics 
ran experiments dataset 
rst attempted cluster news articles distinct new topics 
news articles kept fully intact clustering algorithm just raw document term matrix 
experiment performed 
second experiment experiment conducted 
clustering algorithm news articles largest news topics 
results algorithm prior experimental results table 
measure performance table measure clustering 
algorithm outperforms results prior experiments 
table reuters dataset measure spectral la articles articles web pages certainly clustering attempt cluster webpages semantic groups see section 
experiment run pages selected web fall distinct categories see dataset 
series experiments term vector webpage constructed slightly di erent manner ran algorithm measured entropy clustering algorithm 
ran spectral algorithm exact tests comparison results table exact details experiments 
experiments algorithm outperforms algorithm 
table webpage dataset entropy spectral smart dataset smart dataset set abstracts originating cornell university 
makeup abstracts follows medical abstracts medline aeronautical systems abstracts cran eld information retrieval abstracts cisi 
performed identical set experiments 
type experiment involved clustering document set distinct sets abstracts medline cran eld experiment involved clustering document set abstracts 
table results experiment results listed 
combination medline cran eld datasets likewise 
classic combination datasets 
measure performance table entropy compare competitively 
cluto datasets cluto software package clustering datasets variety di erent areas 
evaluate performance software package series tests document term matrices run software 
document term matrices come di erent sources san jose mercury times la times reuters trec divided categories see exact dataset 
table smart dataset entropy spectral dhillon classic table cluto dataset measure spectral zk fbis hitech la la re re reviews tr tr wap experiments performed exactly attempt cluster collection 
particular ran clustering algorithm collections additionally ran software package collections 
details results table 
quality clustering measure 
note spectral algorithm performed better dataset 
newsgroups newsgroups resource corpus articles come speci usenet newsgroups see table 
performed experiments 
experiment involved choosing random newsgroup articles speci subset newsgroups 
stripped usenet headers newsgroup article rst terms article articles terms 
article left unchanged 
clustering algorithm run corresponding document term matrix 
results table experiments clustering algorithm documents random documents distinct newsgroups alt atheism comp graphics 
set experiments conducted clustering newsgroups done 
note perform better qr proposed algorithm experiments way clustering 
outperform means variation means algorithm kmeans 
experiments measure performance accuracy 
experiment involves choosing random newsgroup articles experiment run times mean standard deviation results recorded 
noted performed experiments clustering algorithm articles newsgroups asked cluster 
perform reasons discussed section 
data zk table worse data give 
reasons case 
example preprocessing steps explicitly mentioned 
bow toolkit processing newsgroup data 
information bow toolkit www cs cmu edu mccallum bow table newsgroups labellings ng alt atheism ng rec sport hockey ng comp graphics ng sci crypt ng comp os ms windows misc ng sci electronics ng comp sys ibm pc hardware ng sci med ng comp sys mac hardware ng sci space ng comp windows ng soc religion christian ng misc ng talk politics guns ng rec autos ng talk politics mideast ng rec motorcycles ng talk politics misc ng rec sport baseball ng talk religion misc table newsgroups dataset accuracy spectral qr kmeans means ng ng ng ng ng ng ng ng ng ng ng ng categorical clustering categorical clustering similar avor document term clustering 
data object document containing terms vector characteristics 
particular example congressional voting data 
data object vector characteristics voted bill law put congress 
natural clustering exists political party 
particular case categorical clustering asks question voting record partition clusters closely match party lines 
table congressional voting data entropy spectral coolcat rock show spectral algorithm applied scenario 
table see better coolcat rock 
synthetic data mixture models tested algorithm data generated mixture model 
mixture model similar proposed literature devised model document clustering 
mixture model consists clusters mixing weights cluster de ned probability distribution terms 
generate data object document procedure pick cluster mixing weights independently pick terms probability distribution return document comprised terms 
note data object generated particular distribution notion correct classi cation document belongs distribution generated 
variation distance distributions jp smaller variation distance closer distributions 
terms mixture model expect correctly classify documents respective probability distributions large variation distance 
variation distance decreases overlap may strong eciently determine correct clustering 
experiment studies ect minimum variation distance clusters mixture model call variation distance mixture model ability algorithm cluster correctly 
generated documents mixture models di erent variation distances ran clustering algorithm corresponding document term matrices 
accuracy recorded variation distance 
exact details experiment follow 
constructed mixture models di ering clusters distributions terms 
ith mixture model distributions terms pairwise variation distance exactly divide terms equally sized blocks size 
distribution uniform jth block contains probability mass uniform blocks contains rest probability mass mixture models performed trials generated documents terms ran clustering algorithm corresponding document term matrix 
shows corresponding plot variation distance vs average accuracy trials 
worth noting performance increases number documents generated increases attributed conductance increasing cluster 
cluster performance vs variation distance variation distance percent correctly classified documents documents performance algorithm synthetic mixture model images spatial clustering studied literature see 
main idea classify visual points space objects 
experiments similar nature 
experiments clustering algorithm similarity matrix image 
non zero pixel data object similarity pixels de ned jjx yjj spirals concentric circles spatial clustering images concentric circles band spatial clustering images suitable de nition images obvious correct classi cation objects 
note images objects non convex may interwoven various complex ways 
notion conductance correctly quanti es similarity objects 
figures show interesting images 
gures pixels blue cluster pixels green cluster 
web search implementation working implementation clustering algorithm web search engine available www math mit edu cluster 
terms search returns set webpages clustered topics 
figures show example output web search 
rst takes resulting web pages search standard web search engine clusters matrix 
note amount time cluster small example searches take seconds commodity hardware 
example searches term searched exhibits polysemy term stand di erent concepts 
identi es concepts search term ritz search term airplane example searches search term driving search term cookie example searches puts webpages appropriate clusters 
discussion performance clustering algorithm clustering experiments described sensitive similarities data objects 
particular clustering documents preprocessing steps done modify pairwise similarities 
preprocessing steps include 
removal terms appear frequently 
removal terms appear infrequently 
weighting terms term frequency 
rst terms document experiments performed document clustering attempted match exact preprocessing steps 
possible preprocessing steps described explicitly modi ed parameter keeping document term vector raw form 
may explain perform worse clustering newsgroups 
practical clustering algorithm worst case theoretical guarantees 
timing experiments show reasonable clustering algorithm practice 
furthermore algorithm quite versatile works similarity matrix implicitly explicitly account structure speci application 
variety experiments real synthetic data outperform existing algorithms 
questions remain 
aspect worth investigation similarities ect results 
experimentation quality clustering dependent degree similarity 
range pattern similarities algorithm better suited 
evaluate conductance eigenvalue gap truly re ects clustering quality real data 
applications case 
allow characterize application area spectral methods suitable 
newsgroups data set 
www ai mit edu people newsgroups 
cluto software package clustering high dimensional datasets 
www users cs umn 
edu karypis cluto files datasets tar gz 
pddp data 
www users cs umn edu boley 
reuters data set 
www com resources reuters 
smart data set 
ftp ftp cs cornell edu pub smart 
uci machine learning repository 
www ics uci edu mlearn mlrepository html 
alpert yao 
spectral partitioning eigenvectors better 
nd acm ieee design automation conference pages 
douglas baker andrew mccallum 
distributional clustering words text classi cation 
proceedings st annual international acm sigir conference research development information retrieval pages 
acm press 
daniel barbara yi li julia couto 
coolcat entropy algorithm categorical clustering 
proceedings eleventh international conference information knowledge management pages 
acm press 
ester xu 
frequent term text clustering 
proc 
th int 
conf 
knowledge discovery data mining 
daniel boley 
principal direction divisive partitioning 
data mining knowledge discovery 
buckley 
optimization inverted vector searches 
proc 
acm sigir pages 
cheeseman stutz 
bayesian classi cation autoclass theory results 
fayyad piatetsky shapiro smyth uthurusamy editors advances knowledge discovery data mining 

cheng fu zhang 
entropy subspace clustering mining numerical data 
proceedings acm sigkdd international conference knowledge discovery data mining 
douglass cutting david karger jan pedersen john tukey 
scatter gather approach browsing large document collections 
proceedings th annual international acm sigir conference research development information retrieval pages 
acm press 
scott deerwester susan dumais thomas landauer george furnas richard harshman 
indexing latent semantic analysis 
journal american society information science 
dhillon 
clustering documents words bipartite spectral graph partitioning 
knowledge discovery data mining pages 
sudipto guha rajeev rastogi kyuseok shim 
rock robust clustering algorithm categorical attributes 
information systems 
thomas hofmann 
cluster abstraction model unsupervised learning topic hierarchies text data 
ijcai pages 
kannan vempala 
clusterings bad spectral 
proceedings ieee foundations computer science 
larsen aone 
fast ective text mining linear time document clustering 
proceedings fth acm sigkdd international conference knowledge discovery data mining pages 
acm press 
ng jordan weiss 
spectral clustering analysis algorithm 
advances neural information processing systems 
ng han 
ecient ective clustering methods spatial data mining 
matthias jarke carlo zaniolo editors th international conference large data bases september santiago chile proceedings pages los altos ca usa 
morgan kaufmann publishers 
adam japkowicz evangelos milios 
unsupervised learning guide re sampling imbalanced data sets 
proceedings eighth international workshop ai pages 
christos papadimitriou hisao tamaki prabhakar raghavan santosh vempala 
latent semantic indexing probabilistic analysis 
acm conference principles database systems 
shannon 
mathematical theory communication 
bell systems technical journal volume pages 
jianbo shi jitendra malik 
normalized cuts image segmentation 
ieee transactions pattern analysis machine intelligence 
noam slonim naftali tishby 
document clustering word clusters information bottleneck method 
research development information retrieval pages 
steinbach karypis kumar 
comparison document clustering techniques 
kdd workshop text mining 
theiler 
contiguity enhanced means clustering algorithm unsupervised multispectral image segmentation 
proceedings society optical engineering pages 
van rijsbergen 
information retrieval nd edition 
dept computer science university glasgow 
wang wiederhold wei 
content image indexing searching daubechies wavelets 
int 
digital library volume pages 
wei wang yang richard muntz 
sting statistical information grid approach spatial data mining 
matthias jarke michael carey klaus dittrich frederick lochovsky loucopoulos manfred jeusfeld editors third international conference large data bases pages athens greece 
morgan kaufmann 
wong fu 
incremental document clustering web page classi cation 
ieee int 
conf 
info 
society st century emerging technologies new challenges 
weiss segmentation eigenvectors unifying view 
proceedings ieee international conference computer vision pages 
oren zamir oren etzioni madani richard karp 
fast intuitive clustering web documents 
knowledge discovery data mining pages 
zha ding gu simon 
spectral relaxation means clustering 
neural info 
processing systems nips 
zha ding gu simon 
spectral relaxation means clustering 
dietterich becker ghahramani editors advances neural information processing systems pages cambridge ma 
mit press 
tian zhang raghu ramakrishnan miron livny 
birch ecient data clustering method large databases 
jagadish singh mumick editors proceedings acm sigmod international conference management data montreal quebec canada june pages 
acm press 
ying zhao george karypis 
evaluation hierarchical clustering algorithms document datasets 
proceedings eleventh international conference information knowledge management pages 
acm press 

