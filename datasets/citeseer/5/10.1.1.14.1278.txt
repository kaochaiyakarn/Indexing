anticipatory scheduling disk scheduling framework overcome deceptive idleness synchronous disk schedulers current operating systems generally conserving schedule request soon previous request finished 
schedulers re quire multiple outstanding requests process meet system level goals performance quality service 
un fortunately common applications issue disk read re quests synchronous manner successive requests short periods computation 
scheduler chooses request early induces deceptive idleness condition scheduler incorrectly assumes request issuing process requests forced switch request pro ce 
propose anticipatory disk scheduling framework solve problem simple general transparent way non conserving scheduling discipline 
freebsd implementation observed yield large benefits range microbenchmarks real workloads 
apache webserver delivers disk intensive workload 
andrew filesystem benchmark runs faster due speedup read intensive phase 
variants tpc database benchmark exhibit improvements pro share schedulers seen achieve contracts accurately efficiently 

disk scheduling integral part operating sys tem functionality early days :10.1.1.152.5459
examines disk scheduling system wide tive identifies phenomenon called deceptive idleness proposes anticipatory scheduling effective solution 
disk schedulers typically conserving se lect request service soon previous request completed 
consider processes ing disk requests synchronously process issues new permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advan tage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
sosp banff canada acm sitaram peter druschel department computer science rice university druschel cs rice edu request shortly previous request finished maintains outstanding request time 
forces scheduler making decision early assumes process issuing request momentarily disk requests selects request process 
suffers condition call deceptive idleness incapable servicing request process 
common data requested process tially positioned disk 
deceptive idleness forces seek optimizing scheduler multiplex re quests different processes 
ensuing head seeks cause performance degradation factor shown section 
related problem proportional share disk scheduling meeting contract proportion assignment may require scheduler consecutively service requests process 
deceptive idleness precludes requirement limiting scheduler capacity satisfy certain contracts 
cases scheduler reordering available requests cor rectly system wide goals met 
proposes anticipatory disk scheduling frame applies various disk scheduling policies 
solves deceptive idleness follows choosing re quest service introduces short controlled delay period disk scheduler waits ad ditional requests arrive process issued serviced request 
disk kept idle short periods time benefits gained able service multiple requests process easily outweigh loss utilization 
framework application non conserving scheduling discipline 
exact tradeoffs sensitive original scheduling policy determine long wait time propose adaptive heuristics simple cost benefit analysis 
implement anticipatory scheduling kernel module freebsd operating system evaluate range microbenchmarks real workloads observe sig performance improvements better adherence quality service objectives 
trace disk intensive workload apache webserver delivers throughput capitalizing seek re duction files 
synchronous read intensive phase andrew filesystem benchmark runs faster due seek reduction files file consequently benchmark improves 
vari ants tpc database benchmark exhibit speedups case deviating standard tpc setup subjecting read queries multiple separate databases leads seek reduction opportunities 
stride proportional disk scheduler achieves assigned allocations synchronous assuming sufficient load simultaneously de high throughput 
exposition analysis deceptive idleness describe anticipatory scheduling section delve detailed experimental evaluation section 
discuss emergent issues section describe related section conclude 

deceptive idleness section describes analyzes phenomenon de idleness examples 
case sched faces shortage desired type requests critical moments 
example seek reducing schedulers example seek reducing disk scheduler degenerate fcfs behaviour potentially suffer throughput loss factor 
consider operating sys tem equipped seek reducing scheduler short est positioning time sptf cscan 
disk intensive processes issue disk requests separate sets sequentially positioned kb blocks 
interest seek reduction throughput improvement scheduler expected tively service requests set perform expensive head repositioning operation service requests 
happens practice provided process maintains pending requests scheduler decision moments time called decision points 
experiment results sustained throughput mb disk owing service time ms kb block 
consider scenario requests synchronously processes process generates new request microseconds previous finishes 
conserving disk scheduler keeps disk idle requests pend ing service 
tries schedule request immediately say request completed 
decision point process chance perform computation required generate re quest 
forces scheduler choosing request performing large head seek part disk servicing request 
subsequent request arrives soon disk scheduling non preemptible late service nearby request 
leads scheduler alternating fcfs manner requests processes 
throughput falls mb due ms average seek time ms read time kb block 
problem persists processes issue synchronous requests 
case cscan degenerates round robin scheduler sptf pair processes 
example proportional share schedulers example shows deceptive idleness affect sched ways degrading throughput 
consider proportional share scheduler fair queueing stride scheduling lottery scheduling 
intended behaviour deliver disk service multi ple applications processes accordance arbitrary preassigned ratio 
assignment scheduler may service requests pro cess correspondingly twice requests process processes maintain outstanding request critical moments pre vious example conserving scheduler forced requests processes 
incapable adhering desired contract load achieves proportions closer 
shows results experiment 
effect proportional share schedulers noted 
desired allocation processes achieved allocation due deceptive idleness 



experimental time seconds proportional share scheduler outer pair lines denote ideal scheduler response allocation ratio processes 
inner pair lines synchronous causes requests alternately serviced processes yielding proportions closer 
active processes say shares stride forced schedule requests processes sequence achieve skewed proportions 
nontrivial reasons lot disk scheduler similar circumstances deliver proportions see details 
underlying problem examples scheduler reorders available re quests scheduling policy fails meet objectives performance quality service 
essence processes issue synchronous requests cause conserving disk scheduler receive requests process time decision point leads deceptive idleness rendering scheduler inca exploiting spatial temporal locality syn chronous requests 
happens despite system wide request queue gen long bursty loaded server systems :10.1.1.152.5459
prefetching possible partially problem tive idleness asynchronous prefetch 
involves predicting request issue pattern process issuing immediately forthcoming request current completes 
process maintains mul tiple outstanding requests decision points gives scheduler chance service consecutive requests process 
seek reduction opportunities exploited requests issued process sequential 
likewise proportional share scheduler capacity adhere contract synchronous re quests 
prefetch effected explicitly application transparently kernel 
approaches fundamental limitations terms feasibility accu racy overhead 
application driven prefetch applications embrace programming paradigms tech niques prevent onset deceptive idleness 
asynchronous apis aio prefetch requests 
alternatively roll asynchronous multiple processes kernel threads proactively issue disk requests right type sequential 
problems 
applications fundamentally unaware access pattern may incapable issuing accurate prefetch requests 
examples include filesystem metadata database index traversals predicting requests 
applications may written cumbersome pro gramming paradigm applications better suited sequential programming style 
existing ap plications rewritten purpose may desirable possible stances 
issuing explicit read requests unix api functions memory mapping file may entail data copying cache pollution come expensive memory workloads 
lastly aio read system call optional posix realtime exten sion may implemented enabled op erating systems 
kernel driven prefetch filesystems try guess request patterns applications issue separate asynchronous prefetch requests 
usual reason overlap computation prefetching pre deceptive idleness 
limitations transparent approach 
file system typically capable predicting access patterns appli cations 
prefetch needs exact notion location request penalties misprediction high 
forces prefetching complicated con 
applications database systems issue requests possessing spatial locality access patterns may extremely difficult detect effectively prefetch 
different synchronous readahead requests enlarged kb amortize seek costs larger reads 
sequentially accessed medium sized files small filesystem detect sequential access confidently issue prefetch requests 
summary prefetching potentially alleviate eliminate deceptive idle ness limitations feasibility effectiveness conditions discount general solution 
studies shown increasing trend modern disk intensive applications issue non sequential disk requests possess spatial locality 
prefetching limited utility cases vital consider complementary widely applicable alternatives 

anticipatory scheduling simple practical general application transparent low overhead solution deceptive idleness 
necessary conditions deceptive idleness manifest multiple disk intensive applications concurrently issuing synchronous disk requests non preemptible nature disk requests conserving disk scheduler schedules request immediately completion previous request 
solution takes intuitive approach eliminating condi tion wrapping disk scheduling policy non conserving anticipatory scheduling framework 
request completes framework potentially waits briefly additional requests arrive dispatching new request disk 
applications quickly gener ate request scheduler takes decision deceptive idleness avoided 
fact disk remains idle short period neces detrimental performance 
contrary show careful application method consistently improves throughput adheres closely desired service allocations 
question long wait decision point key effectiveness performance system 
practice framework waits short est period time expects high probability benefits waiting outweigh costs keeping disk idle 
assessment costs benefits possible relative particular scheduling policy seek reducing scheduler may wish wait contiguous proximal requests proportional share scheduler may prefer weighted fairness primary criterion 
allow flexibility minimizing burden developer particular disk scheduler tory scheduling framework consists components original disk scheduler implements schedul ing policy unaware anticipatory scheduling scheduler independent anticipation core adaptive scheduler specific anticipation heuristics seek reducing proportional share schedulers 
depicts architecture framework 
anticipation core implements generic logic timing mechanisms waiting relies anticipation heuris tic decide long wait 
heuristic im plemented separately scheduler access internal state scheduler 
apply anticipatory scheduling new scheduling policy merely implement appropriate anticipation heuristic 
various subsystems disk requests anticipatory scheduling framework remainder section spells assumptions workload characteristics describes tory scheduling framework followed appropriate antic heuristics seek reducing proportional share schedulers 
covers implementation issues 
workload assumptions tentatively assumptions granularity applications issue related disk requests 
assumption synchronous disk requests issued individual processes 
applications dependence tween disk requests explicitly reflected code structure uncommon multiple processes coordinate issue set synchronous requests 
assumption serves purposes considerably simplifies anticipation heuristic requiring wait process issued request allows anticipation core optimize common case process gets blocked issuing synchronous request 
assumption barring occasional deviations re quests issued individual process approximately similar degrees spatial temporal locality respect requests process properties change rapidly time 
anticipation heuris tic adaptively learns application characteristics process granularity assumption constitutes basic requirement adaptation possible 
sume process interleave disk requests markedly different locality properties 
experimental results real applications reported sec tion indirectly confirm assumptions hold sufficient degree 
relaxing assumptions date larger range workloads subject ideas direction suggested section 
anticipation core traditional conserving scheduler states idle busy transitions scheduling completion request 
applications issue requests time placed scheduler pool requests 
disk idle moment request com request scheduled scheduler select function called request chosen pool dispatched disk driver 
anticipation core forms wrapper tradi tional scheduler 
disk idle scheduler select candidate request 
dequeuing dispatching immediately passes request anticipation heuristic evaluation 
result zero indicates heuristic deemed pointless wait core proceeds dispatch candidate request 
positive inte ger represents waiting period microseconds heuristic deems suitable 
core initiates timeout period enters new wait state 
disk inactive state differs idle having pend ing requests active timeout 
timeout expires arrival new request previously chosen request dispatched ado 
new requests may arrive waiting period requests added pool 
anticipation core immediately asks scheduler se lect new candidate request pool asks heuristic evaluate candidate 
may lead im mediate dispatch new candidate request may cause core remain wait state depending scheduler selection anticipation heuristic evalu ation 
case original timeout remains effect preventing unbounded waiting repeatedly re triggering timeout 
state diagram illus decision process 
schedule heuristic don wait schedule schedule heuristic wait heuristic don wait wait timeout expired waiting mechanism state diagram scheduler independent optimization algorithm process issued request blocks issuing synchronous request assumption suggests dependent request arrive process 
anticipation heuristic short circuited chosen request immediately disp 
happens quite practice sions heuristic decided wait 
seek reducing schedulers section describes scheduler specific anticipation heuris tics seek reducing schedulers sptf aged sptf cscan 
shortest positioning time policy known shortest time shortest access time calculates positioning time available request current head position chooses minimum :10.1.1.152.5459
goal design heuristic maximizes expected throughput 
heuristic needs evaluate candidate request cho sen scheduling policy 
intuition follows candidate request located close current head position little point waiting additional requests 
assumption process issued request issue re quest soon expected median thinktime small request expected close current head position heuristic decides wait 
ig period chosen expected percentile think time probability request arrive 
simple idea generalized succinct cost benefit equation intended handle entire range values positioning times 
throughput objective translates profitably balancing benefit waiting expected gains positioning time cost wait ing additional time wasted 
lp request issuing process elapsed time passed completion previous request benefit calculate positioning time candidate lp expected positioning time cost max lp expected elapsed waiting duration max lp expected percentile thinktime elapsed return benefit cost waiting duration positioning time candidate request calculated suitable estimator section 
regard ing cost estimate requests arrive thinktime heuristic expects progressively shorter periods additional waiting elapsed subtracted expected median thinktime 
wait median heuristic expects request issued soon cost point zero 
secondly wait state anticipation core pre unbounded waiting timeout heuristic evaluation 
calculate correct value waiting duration done allow coarse granularity timers request arriving ile thinktime force immediate dispatch timeout occurred just 
adaptive component heuristic consists collect ing online statistics disk read requests estimate expected times 
expected positioning time process weighted average time position ing time requests process measured request completion 
decay factor set forget define thinktime process issuing request interval completion previous request issued process issue new request 
old positioning time value requests heuristic adapts fast 
alternate approximate method track expected seek distance request pre vious request issued process calculate expected positioning time fly 
expected median ile estimated maintaining decayed frequency table request process 
computed time completion request issued process current time 
scheduler read request queued process new request treated asynchronous thinktime set zero 
heuristic maintains process buckets store count requests arrive various think times ranging ms granularity bucket 
bucket counts decayed reduc ing original values incoming request process 
distribution usu ally looks bell curve consistent assumption 
applications crest located lms 
heuristic calculates median ile points curve incoming syn chronous request 
heuristic suitable conceptually simple sptf policy 
consider modifying seek reducing schedulers aged sptf cscan 
variant aged sptf sptf known suffer potential starvation requests distant locations disk may get ser 
bound response time aged sptf known aged weighted sptf proposed variant requests sptf queue associated priorities raised manner gradually queued time 
request sufficiently high priority sptf decision gets scheduled 
anticipation heuristic sptf works aged sptf minor limitation 
aged sptf chooses distant request old sptf heuristic unaware 
may decide wait additional nearby requests 
new request process arrives period scheduler con pick old request 
process gets blocked scheduler chosen candidate serviced desired 
incurs unnecessary thinktime occasions minor performance problem fixed customizing heuristic aged sptf policy aged sptf selects request different request sptf correspondingly choose decide wait 
variant cscan cyclic scan cscan known look extremely popular scheduling policy implemented unix operating systems 
unidirectional version el scan look moves head direction servicing requests path starts available request 
anticipation heuristic scheduler sptf additional clause 
statistics collection module heuristic additionally maintains decayed expectation seek direction forward back ward 
evaluating request current candidate involves forward seek expected request fairly high likelihood backward seek bypass cost benefit equation decide wait 
opposite case wait usual amount time 
applications performing random access roughly seeks pointing direction heuristic cscan ideal 
cscan poorly suited handle case 
proportional share schedulers anticipation heuristic designed proportional share scheduler fair queueing stride 
policies maintain weighted virtual clocks remember amount disk service re process 
request chosen pro cess smallest virtual clock advance tandem 
unfortunately deceptive idleness forces virtual clocks go sync 
processes generate requests time virtual clock lags 
pro cesses genuinely issue disk requests lag hind expected high 
heuristic simple waiting process meets conditions pending requests time requests completes expected thinktime smaller ms virtual clock smaller minimum virtual clock processes available requests 
ms threshold chosen somewhat arbitrarily consistent way balance weighted fairness performance 
ms observed larger applications large degrade performance 
wait ile point thinktime distribution process 
heuristic combination proportional share scheduler assignment service request process requests second 
alternatively enable seek reduction slightly relaxing timescale operates 
allows scheduler service requests process requests second set contain sequential requests 
variation theme suggested scheduler picks processes virtual clocks relaxation threshold second 
chooses request smallest positioning time 
propose combination heuristic scheduler hinting general methods combining anticipation heuris tics 
combination necessary heuris tic sptf applied directly wait process access pattern random violate proportion assignment heuristic stride wait process higher share enable partial seek reduction 
straightforward approach combining heuris tics separately evaluate candidate request return larger evaluations 
words waiting decision taken reason combination conservatively choose wait 
identify accommodate minor performance issues simplistic approach 
firstly stride pol icy relaxed due condition anticipation heuristic stride needs cor changed secondly consider heuristic sptf waiting se requests process successively servicing requests 
point virtual clock may larger case con decision wait pointless 
heuristic watches condition decides wait 
implementation issues implementation issues deserve tion calculating positioning time requests building inexpensive timeout mechanism 
estimating access time requests nontrivial due fac tors rotational latency track cylinder skews features modern disks block remapping 
done area possible build software predictor accuracy 
simpler logical block number approximation positioning time 
user level program performs measurements capture mapping logical block number difference requests cor responding head positioning time fits smooth curve points 
takes minutes disk installation time online non intrusive 
method automatically accounts seek time average rotational latency track buffers 
accuracy experimentally confirm sufficient insensitivity anticipation heuristic 
possible timer mechanisms choose 
programmable interval timer pit generate interrupts ps build simple timeout system 
experiments demonstrate coarse grained timer amply sufficient purposes 
interrupt causes processing overhead hardware causing cpu overhead computational workloads 
timeout mechanisms place higher accuracy lower overhead desired 
pentium class processors smps chip apic delivers fine grained interrupts overhead interrupt 
alternatively soft timers pose extremely light weight alternative 

experimental evaluation section evaluates anticipatory scheduling frame range microbenchmarks real workloads 
show transparent kernel level solution eliminates deceptive idleness achieves significant performance im provement closer adherence qos objectives applicable 
code platform implemented anticipatory scheduling framework heuristics freebsd ker nel 
code comprises kernel module lines code small patch kernel neces sary hooks scheduler disk driver 
oth stated experiments conducted single mhz pentium iii system equipped rpm ibm ide disk mb main memory 
schedulers experiments seek reducing sched aged sptf specified 
config ure scheduler perform shortest positioning time scheduling bounded request latency second 
achieve performance sptf 
anticipatory scheduling involves intrinsic latency trade servicing multiple requests process seek reduction necessarily increases request turnaround time 
server type applications find small increase acceptable exchange significant improvements throughput 
system desires lower latency may reduce delay bound say looms measured reduce throughput system 
metrics experiments employ metrics applica tion performance application observed throughput mb disk utilization 
framework disk spends time servicing requests positioning head transferring data idling define disk utilization interval percentage real time spent servicing requests 
choice utilization metric depicts fraction time disk deliberately kept idle helps understanding throughput measurements 
turning filesystem prefetch operating sys tems including freebsd implement asynchronous prefetch subsystems 
example vm sub system issue auxiliary prefetch requests page faults serviced disk 
similarly freebsd perform asynchronous prefetch 
allows effectively turn prefetching evaluation purposes mapping files memory accessing memory locations 
sets microbenchmarks exhibiting variations ac cess patterns serve illuminate ings anticipatory scheduling applied seek reducing schedulers 
microbenchmark access patterns study effect anticipatory scheduling synchro nous requests issued different access patterns filesystem prefetch enabled 
processes rapidly issue kb disk read requests separate gb files sequential sex target alternate kb chunk alter randomly positioned re files random 
experiments read sys tem call freebsd transparently issues chronous prefetch requests access pattern detected sequential disk 
experiments map file memory mmap fault memory pages contrast conserving scheduler busy workload prefer define utilization percentage service time spent transferring data disk 
subject asynchronous prefetch 
shows results 
ln read mmap 

ii il 
seq alter random sec alter random impact anticipatory scheduling disk throughput utilization sequential alternate block random access workloads read versus mmap access 
asynchronous prefetch ensures sequential accesses ing read achieve full disk bandwidth mb 
filesystems lay logically contiguous blocks large file set separate regions disk 
infrequent occasions boundary crossed freebsd prefetching mechanism temporarily assumes non sequential access conservatively backs 
anticipatory schedul ing waits processes exploiting spatial locality large file 
performance improves steadily fetching blocks file aged sptf forces switch 
mmap ed accesses subject prefetch scheduling attains times better throughput original case 
achieves throughput equal maximum disk bandwidth difference reflected equal fraction time disk kept idle 
mmap case arguably short coming freebsd prefetch implementation 
exemplified cases alter ran dom non sequential disk access read scheduling significantly improve throughput prefetching fails 
consider second set experiments alternate blocks read 
defeats freebsd prefetch heuris tic causing read mmap achieve mb anticipatory scheduling improves throughput max imum achieved alternate blocks half disk bandwidth 
see variants non sequential access real workloads 
lastly random access case smaller improvements anticipatory scheduling process performing random access respective file gains due seek reduction files 
microbenchmark varying set microbenchmarks illustrates impact waiting applications take different amounts time issue request 
processes map separate large files memory fault memory pages se asynchronous prefetch 
ev ery kb pause amount time described 
symmetric processes consider time horizontal axis repre sents duration milliseconds process spends waiting requests 
data point put graph separate experiment 
values ms original system alternates requests processes achieving mb thinktime exceeds ms waiting time comparable re quest service time utilization original system starts failing 
occasionally deceptive idleness avoided servicing successive requests process 
fades away larger values 

thinktime ms ts 

thinktime ms increasing processes anticipatory scheduling enabled situation changes follows see familiar situation throughput times original system 
larger values ms effect waiting increasingly burdensome throughput utilization improvement steadily declines 
ms wait ing time comparable request service time cost benefit equation tips way 
performance approaches original system increasing degree 
measurements indicate applications short busy region ms 
anticipatory scheduling expected achieve significant benefits real applications 
asymmetric processes consider alternative scenario slow process waits duration requests quick process issues request soon pre vious request completes 
original system alternates tween processes requests ms requests arrive quick pro cess request slow 
causes partial avoidance deceptive idleness due performance gradually improves increasing anticipatory scheduling enabled attained put exceeds original system large margin 
anticipation heuristic greedy small values thinktime decides wait processes 
results gradual throughput decrease increasing thinktime point reached ms heuristic waits quick process slow process 
put rises back maximum requests slow process serviced aged sptf induces switch 
note aged sptf guarantees non starvation fine grained fairness 
rn 

thinktime ms thinktime ms increasing process random seek understand anticipation heuris tic adapts vary rapidly experi ment 
interestingly process waits random duration uniformly distributed performs deterministic counterpart 
expected median thinktime judged roughly tl expected ile thinktime adversary heuristic copes randomly varying try exercise pathological case behaviour heuristic writing intelligent adversary 
ric processes walt duration determined follows issue rapid requests wait duration just ex timeout set heuristic repeat 
application actively fails comply assumption heuristic adapting effectively 
results varying shown 
anticipatory scheduler cast cope requests arriving slowly 
anticipation heuris tic performs slightly worse original system 
result indicates mali application assumptions section hold possible performance degradation acceptably small 
isi ir 


number rapid requests adversary application 

ih 
number rapid requests adversary issues requests rapidly followed long walt 
interestingly similar situation arises prac tice applications issue large read requests say mb freebsd kernel breaks kb chunks 
case scheduler receives kb requests rapid succession followed application typically larger thinktime period 
solve special case having filesystem flag requests anticipatory scheduling core treats large re quest 
adversary application causes timeouts expire stresses accuracy timer 
order understand sensitivity results timer fre quency reran experiment timer granularities ps ps lms 
throughput peaked ps larger timeouts allow sional heuristic error greatest difference saw trials 
supported similar experiment apache webserver difference negligible 
solving deceptive idleness clearly bring significant benefits impact real applications 
see real applications web server linker standard benchmarks filesystem database expected reflect wide range application workloads 
andrew filesystem benchmark andrew benchmark attempts capture typi cal fileserver workload software development environ ment 
consists clients performing phases mkdir creates directories cp copies standard set source files ries star aggressively lists directory contents scan reads files grep gee compiles links 
config repository size exceeds main memory 
call set directories repository instantiate repository clients aiming simulate concurrent access 
experiment uses aged sptf scheduler anticipatory scheduling enabled 
mkdir cp stat scan gee andrew benchmark 
pair bars shown scaled factor 
breakup execution times individual benchmark phases 
consider scan phase issues streams synchronous read requests 
anticipatory scheduling transparently reduces ex ecution time phase 
grep wc freebsd read mmap benefit kernel prefetch 
individual files small prefetch little effect 
major seek reduction happens due files directory closely positioned disk 
anticipatory scheduling enables scheduler capitalize seek opportunities halve execution time 
disk intensive phases improve smaller amounts mkdir metadata writes cp stat typically gets cached memory 
gcc phase cpu bound performs disk aptly demonstrates overhead system 
increase execution time due factors cpu processing additional timer interrupts cpu overhead corresponding heuristic ex ecution routines mainly statistics collection 
phase strongly dominates total execution time benchmark shows smaller improvement 
performance client scheduling stream synchronous requests anticipatory scheduling plays role 
increasing number clients shows performance difference scan phase improves case 
confirms applicability scalability anticipatory scheduling busy 
apache webserver apache webserver employs multi process architecture service requests clients 
requests main memory cache serviced disk respective process 
happens frequently large working sets point disk bound 
de fault configuration apache files smaller mb writes net socket 
larger files apache reads data application buffers done prevent swap dos attack systems 
ftp servers similar mechanisms file transfer 
configure apache exclusively read mmap experiment 
run apache web server client machines host client processes 
real websites different amounts concurrency depending amount characteristics incident load varied number clients wide range observed little difference results 
clients rapidly play requests trace selected cs de webserver university california ley 
requests median size bytes mean size kb mean size kb largest requests excluded 
trace quite disk intensive requests target distinct files 
scheduler aged sptf 
characterizes observed throughputs 
observe improvement throughput read anticipatory scheduling complements filesystem prefetch larger improvement mmap prefetch 
andrew benchmark apache clients generate requests repository requests individual apache process exhibit local ity files 
seek reduction opportunities mainly terms servicing file fully moving 
files small seek reduc tion 
intermediate sized files axe potential candidates prefetching filesystem prefetch conservative occur threshold number requests read mmap read mmap apache webserver configured modes read mmap 
exemplifies practical limitations filesystem prefetch 
sequential 
anticipatory scheduling effects im provement domain 
prefetch occurs reads large files mmap 
accounts large differ ence performance methods access 
default configuration mmap read depending file size apache yields mb original system mb anticipatory scheduling improvement lies read mmap cases 
linker experiment involves stage kernel build starting cold filesystem cache 
gnu linker reads object files disk 
files axe kb kb 
reading elf headers performs usually small non sequential reads file corresponding elf section 
reads separated computation required linking process 
aged sptf cscan instance instance 
instances ce 
gnu linker multiple concurrent instances cause deceptive idleness elimi nated anticipatory scheduling 
experiment demonstrates performance simultaneous instances disjoint repositories 
schedulers time aged sptf cscan demonstrate impact respective heuristics 
synchronous request issuer process schedulers result execution times sec 
normally expect double instances 
deceptive idleness causes increase execution time factor 
non sequential accesses preclude transparent filesystem prefetching 
anticipatory scheduling brings benefit aged sptf case causes performance scale ex expected twice execution time single process 
cscan scheduler hand services requests forward direction 
object files accessed arbitrary order cscan cally precludes anticipatory scheduling attaining full potential seek reduction 
see performance im provement execution time higher aged sptf case 
tpc database benchmark tpc benchmark specified transaction pro cessing council exercises database system simple random update operations large database intended reflect typical bank transac tions 
considered outdated serves illustrate impact anticipatory scheduling read write workload 
implement mysql database client processes 
somewhat deviate setup specified tpc main goal demonstrate gains due anticipatory scheduling ob tain performance data hardware configuration 
individual records database required bytes large 
mysql computational overheads cpu bound record sizes bytes kb records data bottleneck 
database size mb considerably exceed ing mb main memory size hardware capable supporting larger databases 
mysql sup port transactions 
databases maintain transaction log potentially performance bot 
depicts experiments 
clients experiments issue update queries required tpc replace update op eration select 
clients third experiments issue queries directed database required tpc 
second fourth ex periments variant clients issue requests separate databases 
oo 
update update select select db diff db db diff db tpc database benchmark variants clients issuing update versus select queries versus different databases 
update query reads record issues asynchronous delayed write request 
presence delayed writes give scheduler choices effect deceptive idleness 
seek reduction database severely limited due random queries experiment shows net improve ment 
second experiment physically sepa rates databases disk impact anticipatory scheduling pronounced due seek reduction op databases observe improvement despite delayed write requests 
ab performance understandably lower case due large seeks databases 
gains due anticipatory scheduling best brought absence delayed writes update op eration reduced just select involving synchronous read request 
observe throughput improvements requests different databases respectively 
summary experiments indicate database workload stands gain transparent deployment anticipatory scheduling operating system 
modern commercial databases highly optimized implement form application level prefetching explored issue 
proportional share scheduling experiment demonstrates impact anticipation heuristic proportional share schedulers combi nation heuristic 
workload chosen fourth tpc variant database experiment select operations different databases achieve throughputs transactions sec improvement anticipatory scheduling 
depicts experiment workload sub ject proportional scheduling 
stride scheduler augmented underlying seek reduction described section relaxation threshold set second 
proportions assigned tpc clients axe terms disk utilization throughput loss generality 
cases tion framework disabled separately configured stride combination heuristic respectively 

original proportional heuristic 

antic comb net heur st 
experimental time seconds proportional share scheduler 
ex periments zx original proportions proportional heuristic proportions anticipatory combination heuristic proportions maximum throughput 
original system scheduler multiplexes requests processes incorrectly achieves proportions approximately fairly low throughput tps 
turn anticipatory scheduling heuristic proportional share sched realizes process higher share lag ging waits 
average seek transfer times ms ms scheduler manages achieve proportions servicing requests request sufficient exploit locality requests process throughput improves tps half maximum possible 
results cor responding total utilization drop seen utilizations processes decreasing proportionally 
combination heuristic hand realizes seek reduction potential waiting processes 
services requests process achieves full tps throughput retaining proportions 
advanced hardware wish determine effect anticipatory scheduling modern hardware generation cpus disks controllers 
studies indicate head seek time im proves slowly data transfer time trend aggravate effects deceptive idleness 
function ality supported modern controllers tagged queueing improved track buffering controller level prefetching may synchronous hand track buffering may assist filesystem prefetching medium sized sequentially accessed files alleviate problem cases 
track buffering allows scheduler wait request requiring complete rotation read adjacent sector 
different note increase cpu speed corresponds reduction application thinktime advantageous waiting 
number tradeoffs influence precise gains due anticipatory scheduling 
explore issue perform experiments mhz athlon system rpm seagate cheetah st lw scsi disk ultra controller 
specifically repeat experiments mi different access patterns section apache webserver experiment section 
sults 


ll read il oll tic jim mmap ill ill mmap fi seq alter random read mmap microbenchmark apache webserver experiments performed advanced hardware rpm scsi disk mhz cpu 
note maximum bandwidth disk higher original ide disk due correspond ing increase rotational speed 
deceptive idleness causes disks deliver nearly low put presence large seeks magnifies best case gains anticipatory scheduling factor compared earlier factor 
aspects microbenchmark similar ide disk 
consider apache webserver experiment 
improve ments read nmap configurations 
significant lower ide counterparts 
improved rotational speed different disk ge better track buffering result relatively faster servicing short seeks common apache workload leading smaller improvements 
summarize modern hardware suffer deceptive idleness stands gain anticipatory scheduling 
actual improvements expected hardware depending precise hardware details application characteristics 
related note consider impact deceptive idle ness anticipatory scheduling disk types redundant arrays inexpensive disks raids just bunch disks network disks 
investigated issue sufficient depth believe deceptive idleness affect disks antic scheduling beneficial 
positioning time estimator need derive useful model device including head positions redundant copies data believe key step adapting antic scheduling hardware 

discussion section discusses practical impact anticipatory scheduling suggests improvements design 
relevance anticipatory scheduling applications perform non sequential read large files access small files colocated disk directory 
applications web servers databases huge working sets issue read requests satisfied memory 
general tendency applications issue concurrent synchronous non sequential disk requests rise 
requests typically benefit traditional filesystem prefetching possess lo excellent candidates seek reduction 
driven need alternative general approach complement prefetching 
anticipatory scheduling weaker form prediction feasible situations prefetching difficult 
share schedulers increasingly gaining modern systems example var ious high level quality service systems tion domains isolate hosted websites perform ing admission control guarantee predictable performance 
important disk schedulers adhere contract anticipatory scheduling facilitates applications issuing synchronous practice proportional share disk schedulers de combination seek reducing scheduler 
experiments demonstrated combination heuristic brings simultaneous improvement contract adherence performance 
real time disk schedulers pure combination seek reducing schedulers commonly serve view multimedia content 
certain stances possible deceptive idleness cause schedulers multiplex requests different pro cesses consistently violate deadlines 
believe anticipatory scheduling framework applicable real time scheduling full exploration design merits anticipation heuristic scope 
potential improvements suggest approaches improve proposed de sign 
aside obvious improvements making timing mechanism positioning time es cheaper accurate 
accumulate statistics possible anticipation heuristic decisions 
reduce chance augmenting adaptation mechanism additional statistics tracking expected positioning times collect statistics variance estimates 
gives heuristic idea accurate estimates really 
technique resetting discard previously accu statistics variance high 
heuristic keep track frequently time outs expire process exceeds thresh old rate regardless notions accuracy know wrong 
positioning time estimator may accurate mea sure positioning time request completed service 
provides indicator error estimation confidence decisions 
application aio read issue requests syn chronous heuristic determine post facto remember optimize decisions 
relax workload assumptions anticipatory scheduling framework waits request issuing process collects statistics process granularity 
easily common case relaxing assumptions section enable anticipation heuristics support wider range applications types proportional share disk schedulers notion resource principals different processes resource containers reservation domains 
times group processes may collectively issue synchronous requests 
applications may simultaneously generate dif ferent access patterns different file descriptors 
programs may issue kinds disk requests different parts program code file de 
seek reduction intrinsically deals requests region disk online clustering classify requests groups 
relax assumptions heuristic collect statistics levels abstraction processes threads instruc tion pointer thread file descriptors disk region variances 
heuristic choose highest consistent level 
low variance expected correct contains information 

related section points interesting phenomena analogous deceptive idleness methods related anticipatory scheduling domains disk cpu net interface scheduling 
anticipatory scheduling non conserving scheduling discipline 
knowledge non conserving disk scheduler solves memory manage ment issue mixed real time best effort workloads 
refrains servicing outstanding best effort requests conserves buffer space real time requests 
basic idea anticipatory disk scheduling inde suggested posting linux kernel mailing list coincidentally name 
write requests aix operating system implements pacing prevent programs saturating sys tem facilities 
enforces file high low wa ter marks number queued requests 
low water mark buffers write requests increases ties seek reduction viewed counterpart anticipatory scheduling delayed write requests 
context efficiently handling asynchronous re quests freeblock scheduling proposed crease media bandwidth utilization potentially servicing asynchronous requests enroute synchronous ones 
filesystem prefetching researched area regular workloads asynchronous prefetch transparently eliminate deceptive idleness section 
large body improving feasibility effectiveness prefetch techniques application level hints transparent compiler directed approaches 
deceptive idleness creates momentary shortage suitable requests different type scheduler starvation arises context aged sptf scheduler 
recall sec tion priorities axe assigned requests sptf queue increased time 
increase performed abruptly time threshold rate incoming requests exceeds service rate request choice get forced scheduler degenerates fcfs 
solution case involves gradually raising request priorities 
cpu scheduling discipline preemptible analog deceptive idleness 
equivalent high preemption cost switching processes affinity scheduling attempts schedule threads improve cache reuse 
different note non conserving cpu schedulers moti need handle bursty unexpected loads maintaining cpus reserve 
similarly non conserving request sched support prioritized workloads web content hosting differentiated levels service 
comparison anticipatory disk scheduling distinctly different type non conserving scheduling 
network packet scheduling discipline non preemptible deceptive idleness domain 
high band width delay products drive applications maintain win outstanding requests due packet sched faces shortage requests individual flow 
interestingly reason optimize op direction context switching overhead negligible important avoid burstiness 
wf conserving scheduling policy tries interleave requests possible wfq 
non conserving schedulers packet scheduling zhang knightly handle bursty loads holding packets network simulating original traffic stream 

identifies problem deceptive idleness disk subsystem proposes anticipatory schedul ing framework general effective solution 
sim ple application transparent method brings significant improvements throughput adherence quality service objectives synchronous disk framework consists scheduler independent core separate heuristics proposed variety seek reducing proportional share schedulers address disparate needs 
solution complements prefetching techniques deployed application kernel levels useful frequently occurring situations prefetching difficult infeasible 
easy implement suited incorporation general purpose operating systems 
evaluates anticipatory scheduling range workloads 
microbenchmarks characterize intrinsic properties solution real applications standard benchmarks evaluate applicability effective ness realistic scenarios 
apache webserver deliver throughput configura tions 
andrew filesystem benchmark runs faster synchronous phase 
variants tpc database benchmark exhibit improvements 
proportional share schedulers empowered deliver application desired proportions synchronously requests 
accomplished little overhead 

acknowledgments grateful margo seltzer shepherd anonymous reviewers detailed feedback juan navarro rajamani arvind sankar insightful discussions 
supported part nsf ccr texas ibm partnership award equip ment donation hp labs 
massachusetts institute technology hospitality visit spring 

almeida gao 
providing differentiated quality service web hosting services 
june 
aron druschel 
soft timers efficient microsecond software timer support network processing 
th acm sosp dec 
aron iyer druschel 
resource management framework predictable quality service web servers july 
submitted 
www cs rice edu 
banga druschel mogul 
resource containers new facility resource management server systems 
rd usenix osdi feb 
bennett zhang 
wf worst case fair weighted fair queueing 
ieee infocom mar 
log files university california berkeley 
www cs berkeley edu logs 
bruno gabber silberschatz 
disk scheduling quality service guarantees 
ieee june 
bruno gabber 
silberschatz 
eclipse operating system providing quality service reservation domains 
usenix annual technical conference june 
chen stankovic kurose towsley 
performance evaluation new disk scheduling algorithms real time systems 
journal real time systems sept 
lui de souza silva gail 
evaluation tradeoffs resource management techniques multimedia storage servers 
ieee june 
goyal guo vin 
hierarchical cpu scheduler multimedia operating systems 
nd usenix osdi oct 
howard kazar menees nichols satyanarayanan sidebotham west 
scale performance distributed file system 
acm transactions computer systems feb 
huang chiueh 
implementation rotation latency sensitive disk scheduler 
technical report tr suny stony brook mar 
iyer druschel effect deceptive idleness disk schedulers 
technical report cstr rice university june 
jacobson wilkes 
disk scheduling algorithms rotational position 
technical report hpl csp hewlett packard feb 
schindler ganger nagle riedel 
higher disk head utilization extracting free bandwidth busy disk drives 
th usenix osdi oct 
mowry krieger 
automatic compiler inserted prefetching core applications 
usenix osdi oct 
patterson gibson zelenka 
informed prefetching caching 
th acm sosp dec 
roselli lorch anderson 
comparison file system workloads 
usenix annual technical conference june 
smirni 
analysis non conserving processor partitioning policies 
lecture notes computer science 
ruemmler wilkes 
disk drive modeling 
ieee computer 
seltzer chen ousterhout :10.1.1.152.5459
disk scheduling revisited 
usenix winter technical conference jan 
shenoy 
cello disk scheduling framework generation operating systems 
acm sigmetrics june 
shriver small smith 
file system prefetching 
usenix annual technical conference june 
jan 
www cs rice edu linux html 
sullivan seltzer 
isolation flexibility resource management framework central servers 
usenix annual technical conference june 
transaction processing performance council 
tpc standard specification revision 
zahorjan 
implications cache affinity processor scheduling shared memory multiprocessors 
th acm sosp oct 
verghese gupta rosenblum 
performance isolation sharing isolation shared memory multiprocessors 
asplos oct 
vogels 
file system usage windows nt 
th acm sosp june 
waldspurger weihl 
lottery scheduling flexible proportional share resource management 
st usenix osdi nov 
waldspurger weihl 
stride scheduling deterministic proportional resource management 
technical report mit lcs tm june 
waters 
aix performance tuning guide chapter 
prentice hall 
worthington ganger part 
scheduling algorithms modern disk drives 
acm sigmetrics 
yu gum chen wang li krishnamurthy anderson 
trading capacity performance disk array 
th usenix osdi oct 
zhang 
providing performance guarantees non conserving disciplines 
computer communications oct 

es 
ce 
edu 
