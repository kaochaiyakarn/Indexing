sloppy hashing self organizing clusters michael freedman david mazieres nyu dept computer science dm cs nyu edu www scs cs nyu edu coral building coral peer peer content distribution system 
coral creates self organizing clusters nodes fetch information avoid communicating distant heavily loaded servers 
coral indexes data store 
actual content resides nodes local web caches 
replication happens exactly proportion demand 
novel mechanisms coral achieve scalability high performance 
new abstraction called distributed sloppy hash table dsht lets nodes locate nearby copies file regardless popularity causing hot spots indexing infrastructure 
second dsht interface introduce decentralized clustering algorithm nodes find form clusters varying network diameters 
academic community implemented number distributed hash tables dhts efficient scalable robust peer peer infrastructures 
ask dhts suited desired applications wider internet population 
example dhts implement file sharing far popular peer peer application 
dhts replace proprietary content distribution networks cdns akamai democratic client caching scheme speeds web site saves flash crowds cost server operator 
far answer questions 
dhts fail meet needs real peer peer applications main reasons 
dhts provide wrong abstraction 
suppose thousands nodes store popular music file cache cnn widely accessed home page 
hash table help find data 
cnn url key store list node web page 
course single node responsible url node list mapping quickly overloaded 
dhts typically replicate popular data replication helps fetches stores 
node seeking web page cache 
url node list mapping updated frequently fetched 
alternative approach taken cfs oceanstore past store actual content hash table :10.1.1.110.5867:10.1.1.159.9358
approach wastes storage bandwidth data stored nodes needed 
users clearly proven willing burn bandwidth sharing files interested incentive dedicate bandwidth sharing unknown data 
worse storing content dht requires large amounts data shifted nodes join leave system common occurrence 
dhts poor locality 
dhts effort route requests nodes low network latency hops lookup request essentially random 
node need send query half way world learn neighbor caching particular web page 
particular concern peer peer cdn average dht node may considerably worse network connectivity web server 
presents coral peer peer content distribution system building 
coral new abstraction call distributed sloppy hash table dsht 
currently built layer chord lookup service equally designed support kademlia existing systems 
coral lets nodes locate download files name 
web caches fetch static data nearby peers 
users employ directly share directories files 
coral principal goals avoid hot spots find nearby data querying distant nodes 
dsht abstraction specifically suited locating replicated resources 
sacrifice consistency dhts support frequent fetches frequent stores hash table key 
fundamental observation node doesn need know replicated location resource needs single valid nearby copy 
sloppy insert akin append replica pointer appended full node spills previous node lookup path 
sloppy retrieve returns randomized subset pointers stored key 
order restrict queries nearby machines coral node member call clusters increasing network diameter 
diameter cluster maximum desired round trip time nodes contains 
data cached coral cluster member cluster locate copy querying machines farther away cluster diameter 
nodes identifiers clusters data available low diameter cluster routing information returned lookup continue query larger diameter cluster 
note dhts replicate data hops lookup path increases availability popular data improves performance face readers 
unfortunately routing hops lookup precisely ones optimized 
clustering mechanism replication avoid need query distant nodes 
importantly storing pointers dht guarantees node storing pointer near node pointed 
contrast property follows naturally clusters 
coral challenge organize manage clusters decentralized manner 
described section dsht interface suited locating evaluating nearby clusters 
design section discusses coral dsht storage layer lookup protocols 
second describes coral technique forming managing clusters 
sloppy storage layer traditional dht exposes functions 
put key value stores value specified bit key get key returns stored value just normal hash table 
value stored key time 
dhts assume keys uniformly distributed order balance load participating nodes 
additionally dhts typically replicate popular key value pairs multiple get requests key 
order determine insert retrieve key underlying lookup protocol assigns node bit nodeid identifier supplies rpc find closer node key 
node receiving rpc returns possible contact information node nodeid closer target key 
systems return set nodes improve performance simplicity refer single node case 
iterating calls find closer node map key closest node dhts require expected log rpcs 
log number rpcs reflected nodes routing tables provides rough estimate total network size coral exploits described 
dhts suited keys single writer multiple readers 
unfortunately file sharing systems multiple readers writers 
discussed plain hash table wrong abstraction applications 
provides similar interface dht key may multiple values put key value stores value key get key need return subset values stored 
node stores maximum number values particular key 
number values exceeds maximum spread multiple nodes 
multiple stores key overload node 
contrast dhts replicate exact data people storing key contact closest node replicas pushed back network overloaded node 
concretely coral manages values follows 
node stores data locally inserts pointer data dsht executing put key 
example key distributed web cache hash url 
inserting node calls find closer node key locates node list stored key full reaches node closest key located node full backtrack hop lookup path 
target node appends timestamp possibly new list stored key expect records expire quickly keep fraction stale pointers 
get key operation traverses identifier space hitting node storing key returns key corresponding contact list 
requesting node contact nodes parallel application specific way download stored data 
coral sloppy store method inserts pointers lookup path popular keys 
practice spilling full helps balance load inserting pointers retrieving pointers downloading data 
rapid membership changes remain inexpensive system exchanges pointers 
sloppy stores eliminate hot spots address problem latency 
particular find closer node key may circle globe find nearby host data 
take advantage data locality coral introduces hierarchical lookup 
hierarchical lookup layer global lookup system coral uses levels called clusters 
coral nodes belong dsht level current implementation level dsht hierarchy 
goal establish fast clusters regional coverage refer low level clusters level multiple clusters continental coverage referred higher level clusters planet wide cluster level 
reasonable round trip time thresholds msec level clusters msec level global level 
section presents experimental measurements support choices 
cluster named bit cluster identifier cid global cid predefined coral uses hierarchy distance optimized lookup visualized chord kademlia routing structures 
insert key value pair node performs put levels clusters 
practice results loose hierarchical data cache higher level cluster contains nearly data stored lower level clusters members belong 
retrieve key requesting node performs get level cluster try take advantage network locality 
find closer node level may hit node caching key halt hit 
lookup reach node cluster closest target key call continues search level cluster 
returned routing information level cluster 
begins closest level node routing table 
bit id space coral hierarchical lookup visualized chord left kademlia right routing structures 
nodes maintain id clusters smaller diameter low level naturally sparser 
lookup key node searches lowest cluster 
lookup fails level node closest node store key 
occurs coral continues lookup higherlevel cluster having traversed id space prefix 
route rpcs shown sequential numbering 
search eventually switches global cluster coral require rpcs lookup service lookup restarts left id space 
coral guarantees lookups fast 
functionality arises naturally node having nodeid belongs 
note coral achieves property independent distance optimization underlying lookup protocol 
conflicting criteria impact effectiveness coral hierarchical 
clusters large terms membership 
peers dsht greater capacity lower rate 
second clusters small network diameter achieve fast lookup 
expected latency randomly selected peers cluster cluster specified threshold 
remainder section describes coral mechanisms managing multiple dsht clusters 
mechanisms summarized table 
joining cluster coral largely inherits join leave protocols underlying lookup service difference 
node join acceptable cluster latency nodes cluster diameter 
property easy node test collecting round trip times subset task coral solution discovering joining low level cluster requiring knowledge node necessarily close 
coral nodes insert contact information internet topology hints higher level clusters 
nodes reply unexpected requests cluster information 
dsht infrastructure prevents hotspots forming nodes search new clusters test random subsets nodes acceptable rtt thresholds 
hotspots distort rtt measurements reduce scalability 
merging close clusters namespace experiencing oscillatory behavior merging clusters 
coral cluster size age information ensures clear stable direction flow merging clusters 
merging may initiated byproduct lookup node switched clusters 
splitting slow clusters disjoint subsets manner results acceptable stable partitioning causing hotspots 
coral definition cluster center provides stable point separate nodes 
dsht prevents hotspots node determines relative distance known point 
table overview coral design self organizing clusters nodes cluster simply looking identifier natural part joining 
peer peer system node initially learn coral node join system 
coral adds rtt requirement node lower level clusters 
node unable find acceptable cluster creates new random cid node join better cluster learns 
mechanisms discover clusters including ip multicast merely waiting nodes learn clusters side effect normal lookups 
coral exploits dsht interface nodes find nearby clusters 
joining low level cluster node inserts higher level clusters keyed ip addresses gateway routers discovered traceroute 
routers returned executes put hash router ip 
new node searching low level acceptable cluster perform get gateway routers learn set topologically close nodes 
merging clusters small cluster diameter provides fast lookup large cluster capacity increases hit rate lowerlevel dsht 
coral join mechanism individual nodes automatically results close clusters merging nodes clusters find acceptable 
merge happens totally decentralized way expensive agreement protocol 
node knows acceptable clusters level join larger 
node switches clusters remains routing tables nodes old cluster 
old neighbors contact node replies level requests originating outside current cluster tuple cid size ctime size estimated number nodes cluster ctime cluster creation time 
nodes old cluster learn new cluster nodes diameter 
produces avalanche effect nodes switch larger cluster 
unfortunately coral count rough approximation cluster size 
nearby clusters similar sizes inaccurate estimations worst case cause oscillations nodes flow back 
perturb oscillations stable state coral employs preference function shifts hour 
node selects larger cluster holds log size log size min age age age current time minus ctime node simply selects cluster lower cid square wave function takes value number hours odd number 
clusters disproportionate size selection function immediately favors larger cluster 
clusters similar size continuously exchange members zero soon transitions nodes flow cluster lower cid clusters oscillate times larger get members returns zero 
splitting clusters order remain acceptable nodes cluster may eventually need split 
event may result network partition population expansion new nodes may push rtt threshold 
coral split operation incorporates preferred direction flow 
nodes merely randomly re merged larger clusters procedure take long stabilize form highly sub optimal clusters 
provide direction flow coral specifies node cid cluster center 
splitting nodes near center join cluster nodes far join second cluster 
specifically define cid hash cid cid cid bit flipped 
cluster center node closest key cid dsht 
nodes merely ping cluster center directly overload distorting rtt measurements 
avoid overload problem coral leverages sloppy replication 
node detects cluster longer acceptable performs get cid cid nodes split get cid resolves directly cluster center node joins cid rtt center performs put cid old cluster higher level 
concern early adopter may move small successor cluster 
left previous level cluster latency cluster approaching larger level cluster 
node gains little benefit maintaining membership smaller lower level cluster 
nodes transition gets hit sloppy replicas cid cid learn random subset nodes split new clusters 
node finds cluster cid acceptable join having needed ping old cluster center 
nodes find cid acceptable attempt join cluster cid cluster cid worse previous cluster case split 
case pathological network topologies small number splits suffice reach stable state 
maximum number unsuccessful splits node simply form new cluster random id 
measurements coral assigns system wide rtt thresholds different levels clusters 
nodes choose acceptability levels clusters experience greater instability individual thresholds differ 
cluster experience distinct merging splitting period helps return acceptable stable state 
find sensible system wide parameters 
round trip time msec nyu round trip time msec nortel round trip time msec intel round trip time msec korea round trip time msec amsterdam round trip time msec athens cdfs round trip times specified ron nodes gnutella peers 
measure network distances deployed system performed latency experiments gnutella network 
collected host addresses acting gnutella peer measured rtt ron nodes approximately gnutella peers 
operations lasted hours 
determined round trip times attempting open tcp connections high ports measuring minimum time elapsed syn rst packets 
shows cumulative distribution function cdf measured rtt gnutella hosts ron sites new york university nyu nortel networks montreal nortel intel research berkeley intel kaist south korea vrije university amsterdam ntua athens 
cdfs multiple plateaus different rtt system wide thresholds ideal 
threshold chosen fall plateau set nodes sets cluster natural size 
threshold bisect rising edge nodes cdfs yield greater instability 
measurements show cdf curves smooth 
relative freedom setting cluster thresholds ensure level cluster particular region capture expected percentages nearby nodes 
choice msec level covers smaller clusters nodes level threshold msec spans continents 
example expected rtt new york berkeley msec msec amsterdam athens 
curves suggest gnutella peers reside north america 
low level clusters especially useful sparse regions korea queries traditional peer peer system go north america 
related projects considered peer peer systems web traffic 
uses dht cache replicas proofs uses randomized overlay distribute popular content 
systems focus mitigating flash crowds normal web caching 
accept higher lookup costs prevent hot spots 
squirrel proposed web caching traditional dht lans 
examines storing pointers dht reports poor load balancing 
attribute result limited number pointers stored due lack system dht interface 
scan examined replication policies data disseminated multicast tree dht deployed isps 
coral introduces techniques enable distance optimized object lookup retrieval 
coral provides dsht abstraction 
storing actual data system stores weakly consistent lists pointers index nodes data resides 
second coral assigns round trip time thresholds clusters bound cluster diameter ensure fast lookups 
third coral nodes maintain identifier clusters 
low diameter lookup fails coral uses returned routing information continue query efficiently larger diameter cluster 
coral provides algorithm self organizing merging splitting ensure acceptable cluster diameters 
coral promising design performance driven applications 
process building coral planning network wide measurements examine effectiveness hierarchical dsht design 
acknowledgments david andersen access ron testbed vijay karamcheti eric robert grimm sameer rodrigo rodrigues helpful comments 
research conducted part iris project project iris net supported nsf cooperative agreement 
ani 
michael freedman supported onr fellowship 
placed public domain 
yan chen randy katz john kubiatowicz 
scan dynamic scalable efficient content distribution network 
proceedings international conference pervasive computing zurich switzerland august 
frank dabek frans kaashoek david karger robert morris ion stoica :10.1.1.159.9358
wide area cooperative storage cfs 
proceedings th acm symposium operating systems principles sosp banff canada october 
john kubiatowicz oceanstore architecture global scale persistent storage 
proc 
asplos cambridge ma nov 
sitaram iyer antony rowstron peter druschel 
squirrel decentralized peer peer web cache 
principles distributed computing podc monterey ca july 
maymounkov david mazieres 
kademlia peerto peer information system xor metric 
proceedings st international workshop peer peer systems iptps cambridge ma march 
sylvia ratnasamy paul francis mark handley richard karp scott shenker 
scalable content addressable network 
proc 
acm sigcomm san diego ca aug 
antony rowstron peter druschel 
pastry scalable distributed object location routing large scale peer peer systems 
proc 
ifip acm middleware november 
antony rowstron peter druschel :10.1.1.110.5867
storage management caching past large scale persistent peer peer storage utility 
proc 
th acm symposium operating systems principles sosp banff canada october 
sen jia wang 
analyzing peer peer traffic large networks 
proc 
acm sigcomm internet measurement workshop marseille france november 
petros maniatis mary baker 
peer topeer caching schemes address flash crowds 
proceedings st international workshop peer peer systems iptps cambridge ma march 
angelos dan rubenstein sahu 
lightweight robust system handle flash crowds 
ieee international conference network protocol icnp paris france november 
ion stoica robert morris david liben nowell david karger frans kaashoek frank dabek hari balakrishnan 
chord scalable peer peer lookup protocol internet applications 
ieee acm trans 
networking 
ben zhao john kubiatowicz anthony joseph 
tapestry infrastructure fault tolerant wide area location routing 
technical report ucb csd computer science division berkeley april 

