benchmarking advance research challenge software engineering susan elliott sim university toronto cs utoronto ca steve easterbrook university toronto sme cs utoronto ca richard holt university waterloo holt uwaterloo ca benchmarks computer science compare performance computer systems information retrieval algorithms databases technologies 
creation widespread benchmark research area frequently accompanied rapid technical progress community building 
observations led formulate theory benchmarking scientific disciplines 
theory challenge software engineering research scientific cohesive working community define benchmarks 
support challenge case study reverse engineering community successfully benchmarks advance state research 

purpose issue challenge software engineering start defining benchmarks key problems area 
experience developing benchmarks examining successful benchmarks observed benchmarking embraced community strong positive effect scientific maturity discipline 
creating benchmark requires community examine understanding field come agreement key problems encapsulate knowledge evaluation 
benchmark results rigorous examination research contributions improvement tools techniques developed 
benchmarking process greater communication collaboration different researchers leading stronger consensus community research goals 
technical progress increased cohesiveness community viewed positive side effects benchmarking 
argue benchmarking achieve positive effects 
initially observed benefits building benchmark program comprehension tools 
experience led examine benchmarking carefully understand community effects 
subsequently applied theory development second benchmark fact extractors programming language 
critical insight theory benchmarking research communities benchmarks operationalize scientific paradigms statement discipline research goals emerge synergistic process technical knowledge social consensus proceeding tandem 
concept scientific paradigms described thomas kuhn ground breaking book structure scientific revolutions 
scientific paradigm dominant view science consisting explicit technical facts implicit rules conduct 
benchmark succinct statement aspects discipline 
viewing benchmark technical social artefact better able understand role scientific community 
developed guidelines manage process making benefits accessible 
benchmarking widely applicable technique broad range technology 
research obviously amenable benchmarking performance measures straightforward example speed throughput 
software engineering performance measures quite complex tools techniques intended help creation large software systems 
benchmarking research community sufficiently established culture collaboration 
evidence include existing collection diverse research results increasing concern validation results 
evidence includes multi site research projects multi author publications standards reporting file formats 
base consensus process led small number key people construct benchmark endorsed research community 
argue benchmarking strong positive effect research show effects realised software engineering 
arguments power benchmarking sections 
section gives examples successful benchmarks outside software engineering 
section theory benchmarking 
includes definition account functions research community explanation effectiveness 
sections demonstrate theory applied 
section presents practical advice apply theory section illustrates application theory fact extractor benchmark 
final section re statement challenge software engineering requirements engineering model checking software evolution specific examples 

examples successful benchmarks section benchmarks successful advanced discipline improving science increasing cohesiveness community 
publications report technical aspects development various benchmarks relatively discuss social cultural aspects 
benchmarks section exceptional non technical aspects discussed literature 
believe examples representative benchmarking general consistent experience 
examples tpc tm database management systems dbms spec cpu computer systems trec ad hoc retrieval task information retrieval systems 
tpc tm full name tpc transaction processing council tpc benchmark tm online transaction processing including lan wan network 
evolved test originally published 
effort jim gray contributors industry academia author anon struck chord database community 
researchers began publish refinements variants test vendors version interpretation product appear efficient wars 
eventually number representatives industry academia formed tpc purpose supervising benchmarks dbmss 
developing tpc tm took years required nearly person days effort contributed researchers database vendors members consortium 
process involved meetings laboratory members 
tpc tm specification pages long different clauses covering issues transaction terminal profiles scaling rules response time rules full disclosure 
spec cpu spec standard performance evaluation consortium committees create variety benchmarks 
cpu evaluating computer systems 
supersedes cpu scheduled replaced 
members committees include hardware software vendors universities customers 
requirements test cases votes benchmark composition solicited committee members general public spec web site 
committee uses refine benchmark 
john henning explained point gather possible project leaders platforms benchmarks place collectively resolve technical issues involving multiple stakeholders common see employees different companies looking screen helping 
cpu consists programs integer arithmetic floating point compiled run computer system 
trec ad hoc retrieval task trec text retrieval conference annual conference information retrieval sponsored nist darpa 
trec included challenges problems open participants 
challenges trec ad hoc retrieval task 
task consists searching text corpus articles match specific topic 
example topic legal actions resulted destruction pan am flight scotland december 
corpus task originally contained articles grown twice size 
consists primarily news items wall street journal associated press 
formatting topics evolved inception task 
members community participate ways 
new set topics selected help judging relevance articles 
run information retrieval systems topics submit results conference organisers 
conference organisers participants discuss results 
ad hoc task discontinued performance previous years levelled 
benchmark longer pushing research forward organisers felt energy better spent benchmarks 
tasks trec 
ad hoc retrieval task means solved researchers years worth test collections research 

theory benchmarking examples previous section experience developing benchmarks formulated descriptive theory benchmarking functions scientific research community 
descriptive theory explanatory framework help better understand past 
understanding guide benchmarking 
section parts explaining aspect theory 
giving scope theory describing theory apply 
give definition benchmark examine benchmark emerges community benchmark effective advancing scientific community 
scope theory concerned primarily benchmarks created technical research community 
benchmarks created single individual laboratory widely tend impact community research results 
community interest may include participants academia industry government primarily interested scientific research 
benchmarks designed business marketing purposes optimised different goals theory extend cover 
definition general definition benchmark ensure wide applicability 
applies equally benchmarking tools techniques technologies terms interchangeably 
define benchmark test set tests compare performance alternative tools techniques 
benchmark components 
benchmark designed selecting components hierarchically 
benchmark emerges part community effort components developed order 
motivating comparison 
component encompasses concepts comparison motivation 
purpose benchmark compare comparison heart benchmark clearly defined 
motivation aspect refers need research area turn benchmark 
motivating comparison captures technical comparison research agenda making comparison 
task sample 
tests benchmark representative sample tasks tool technique expected solve actual practice 
possible include entire population problem domain selection tasks acts surrogates 
performance measures 
measurements computer human quantitative qualitative 
performance innate characteristic technology relationship technology 
performance measure fitness purpose 
proto benchmark set tests missing components 
common lack performance measure called case studies exemplars 
typically demonstrate features capabilities new tool technique occasionally compare different technologies exploratory manner 
benchmarks paradigms benchmarks function research communities manner scientific paradigms 
kuhn argued scientific progress occurs revolutions way social political progress occurs 
conventional view time science moved linear fashion progressively accurate truth 
dominant view discipline called paradigm revolution needed move discipline paradigm 
paradigm collection knowledge needed function scientific discipline 
scientific discipline current paradigm captures community consensus problems worthy study determines scientifically acceptable solutions 
manner paradigms convey implicit rules working community explicit rules factual knowledge 
kuhn descriptions paradigms includes lifecycle model scientific community 
new research field characterised pre scientific consensus problems need solving set research methods valid approaches problems 
consensus emerges working paradigm constitutes doing normal science 
paradigm little progress 
scientific revolution occurs dominant paradigm displaced new 
benchmark paradigm takes concept concrete serve guide action 
motivating comparison task sample statement problems worth solving 
performance measures show solutions held higher esteem 
benchmark contains implicit information problem ought solved 
paradigms benchmarks emerge process scientific discovery consensus 
progress standard benchmark emerge sufficient 
example discipline may research results necessary design benchmark lack agreement effort ought undertaken 
tight relationship knowledge consensus means existence benchmark indicative maturity scientific discipline 
effectiveness paradigms model explanation success benchmarks needs account sociological technical aspects 
discuss sociological reasons considering technical reasons 
sociological factors 
established previous subsection benchmarks encapsulate paradigms 
concrete problem solutions statements valid scientific problems solutions area implicit rules conducting research 
presence benchmark states community believes contributions ought evaluated clearly defined standards 
benchmark promotes conduct research collaborative open public 
collaboration benchmarking occurs ways 
development researchers build consensus benchmark 
deployment results different technologies compared requires researchers look contributions 
consequently researchers aware ties researchers similar interests strengthened 
evaluations carried benchmarks nature open public 
materials available general technology tested 
difficult hide flaws tool technique strengths transparency test procedures 
benchmark tools techniques attempt replicate results 
factors collaboration openness result frank detailed technical communication researchers 
kind public evaluation contrasts sharply descriptions tools techniques currently software engineering conference journal publications 
expected show novel worthy contribution field share advice tackle similar practical problems 
benchmarks ways dirty details research debugging techniques design decisions mistakes forced open shared laboratories 
technical factors 
technical reasons success benchmarking lie strengths empirical method 
characteristics case studies experiments consequently shares features understood empirical methods 
summarised table 
table comparison benchmarking empirical method experiments case studies characteristics experiments characteristics case studies features control factors replication direct comparison results features little control evaluation setting choice technology user subjects tests statistical significance open ended questions possible advantages direct comparison results advantages method flexible robust disadvantages suitable building explanatory theories disadvantages limited control reduces results experiments control task sample reduce variability results tools techniques evaluated tasks experimental materials 
little control selection tools techniques evaluated individuals operating evaluation sense benchmarking case study factors determined situation 
furthermore tests statistical significance performed benchmark results 
advantage benchmarking replication built method 
materials designed different laboratories people perform evaluation various tools techniques repeatedly desired 
benchmarks automated computer executing tests gathering data producing performance measures 
benchmarking accepted familiar evaluation technique computer science 
usually require additional training special knowledge understand 
benchmark similar doing homework assignment researchers experienced 

applying theory previous section theory benchmarking functions scientific research communities 
section examine theory guide practice 
benchmarks indicative cohesiveness discipline technical sociological level hypothesise benchmarking applied proactively advance maturity scientific community simply enjoying maturity side effect 
hypothesis suggests benchmarking help research area needs scientific needs codify technical knowledge needs cohesive 
offer evidence hypothesis correct section 
give guidance determine development benchmarks particular research area 
receptive areas describe principles benchmark development high level requirements product 
preconditions caveats theory suggests conditions exist discipline construction benchmark fruitfully attempted 
precondition minimum level maturity discipline 
early days research area established necessary appropriate go stage diverse approaches solutions proliferate 
time bounds area established different methods applied 
proliferation desirable variety tools techniques compared benchmark 
evidence community reached required level maturity ready move rigorous scientific basis comes forms 
typical symptoms include increasing concern validation research results comparison solutions developed different laboratories attempted replication results proto benchmarks attempts apply solutions common set sample problems increasing resistance accept speculative papers publication 
precondition important significant cost developing maintaining benchmark danger committing benchmark early 
walter tichy writes constructing benchmark usually intense laboratories share burden 
defined benchmark executed repeatedly moderate cost 
practice necessary evolve benchmarks prevent overfitting 
community ready incur cost developing benchmark subsequently maintaining 
continued evolution benchmark necessary prevent researchers making changes optimise performance contributions particular set tests 
effort spent optimisations indicates stagnation suggesting benchmark changed replaced 
locking inappropriate benchmark early provisional results hold back progress 
advantage having benchmark community works direction 
commitment means closing directions albeit temporarily 
selection paradigm definition excludes 
second precondition collaboration community 
words willingness solve common problems 
past history collaboration demonstrates presence working relationship sets expectation community members take part 
familiarity experience creates community receptive results benchmark 
preconditions met mean benchmarking employed 
means steps establish preconditions undertaken 
precondition addressed time scientific results 
situations merely sufficient wait critical mass sentiment technology embarking road benchmark 
situations preliminary research benchmark components may necessary 
second precondition addressed series planned activities patience necessary takes time change group 
ways build collaborative include informal meetings joint projects groups time set aside discussions conferences workshops new problems ideas explored 
process benchmark development key principle underlying benchmark development process scientific knowledge community consensus progress lock step creation benchmark 
selected benchmark components endorsed community 
choosing task sample undoubtedly controversial 
tichy observed subjective weakest part benchmark test benchmark composition 
properly documented checked skeptic 
benchmark composition debated 
creating performance measures particularly difficult software engineering 
cases obvious measures available prior benchmarking effort 
people associate benchmarking test simple dimensional attributes speed fact measures address aspect fitness purpose quite complex 
starting point identifying suitable measures existing empirical studies software engineering see example 
knowledge agreement built successful benchmark development process needs attributes 
effort led small number champions 
group keeps active identified key members group 
act primarily organisers ordinating activities opportunities provide feedback publication results 
design decisions benchmark need supported laboratory 
benchmark established research results possible 
addition prototypes small tests may needed understanding support decision making 
benchmark developed consensus 
opportunities general community participate provide feedback endorse benchmark 
tichy observation lots opportunity debate 
opportunities come variety formats 
newsgroups mailing lists informal discussion 
formal written request comment rfc procedure 
face toface meetings occur part conferences seminars essential 
desiderata successful benchmarks section requirements properties successful benchmarks 
design goals creating benchmark dimensions evaluating existing 
took gray feather expanded observations successful benchmarks 
properties accessibility primarily concerned packaging delivery benchmark 
clarity relevance solvability portability scalability deal benchmark problem 
remainder subsection describe properties detail 
accessibility 
benchmark needs easy obtain easy 
test materials results need publicly available apply benchmark tool techniques compare results 
test results easy software engineers different levels expertise empirical studies 
benchmark easy understand interpreted incorrectly higher credibility 

cost benchmark commensurate benefits 
costs commonly involve human resources software hardware 
costs reduced automating benchmark 
costs high benefits low people benchmark 
breakeven point relationship vary maturity technology status benchmark results peers potential users 
clarity 
benchmark specification clear self contained short possible 
clarity help ensure loopholes exploited 
relevance 
task set benchmark representative ones system reasonably expected handle natural meaning artificial setting performance measure pertinent comparisons 
property difficult satisfy important 
task domains sufficient naturally occurring problem 
ingenuity required include context problem realistic 
solvability 
possible complete task domain sample produce solution 
feature obvious worth stating 
task difficult tools yields little data support comparisons 
task achievable trivial provides opportunity systems show capabilities shortcomings 
portability 
benchmark specified high level abstraction ensure portable different tools techniques bias technology favour 
implication feature benchmark may need implemented different platforms different architectures 
scalability 
benchmark tasks scale tools techniques different levels maturity 
applicable research prototypes commercial products 
property influences size task sufficiently large showcase mature techniques large test techniques currently researched 

case study reverse engineering years working define benchmarks software reverse engineering tools 
time applied refined principles described previous section 
benchmark developed comparing program comprehension tools tools helped programmers understand source code purpose making modifications 
users benchmark complete number maintenance documentation tasks xfig open source drawing program unix 
second benchmark extractor test suite 
collection small test programs written primarily questions programs evaluate capabilities different fact extractors 
benchmarks developed collaboration researchers additional researchers tool developers discussed workshop conference 
benchmarks produced technically interesting results significant contribution deeper understanding tools research problem brought community 
benchmarks similar terms development impact research area describe detail 
preconditions reverse engineering community recall preconditions needed prior working community benchmark 
minimum level scientific maturity culture collaborative 
reverse engineering community began 
healthy variety tools implemented number research groups 
tools similar features different approaches 
felt easier understand relative merits different tools applying common software system 
community track record collaboration discussion 
main conference area working conference reverse engineering wcre organised maximise discussion time 
example presentations minutes long usual minutes half hour discussion presentations 
consequently culture public debate exchange ideas conferences 
evidence community desire gxl graph exchange language 
format exchanging data software tools community january adopted researchers countries 
fact extractors benchmark comparing capabilities fact extractors 
fact extraction fundamental problem reverse engineering subsequent analysis affected quantity quality facts produced 
surprisingly difficult problem particularly led implementations different approaches varying degrees success 
consequently difficult user select fact extractor meets requirements 
created address need 
design application described detail describe salient components 
motivating comparison 
find accurate robust resistant non standard input fact extractor 
task sample 
collection test buckets consisting small test programs associated question file asked different facts potentially extracted source code 
teams perform extraction test buckets show extractor produced answers questions 
solution test bucket consisted output extractor answer file served documentation concordance output 
performance measures 
points earned correct answers completeness documentation 
points allocated accuracy robustness categories 
terms desiderata benchmarks described fared follows 
accessibility 
downloaded interested person 
format benchmark straightforward 

typically took person working days complete benchmark 
teams needed time developing repairing extractors time 
clarity 
problems set benchmark clear point inconsistencies mis matches collective vocabulary 
cases vocabulary research areas compilers wide 
cases community learning apply terms phenomenon 
issue discussed section 
relevance 
benchmark contained test buckets tested variety language features buckets tested common reverse engineering problems missing source code 
solvability 
test buckets came varying degrees difficulty tool expected able earn available points 
expected extractors able parse correctly analyse test programs accuracy category 
portability 
test programs portable variety platforms compilers 
programs robustness categories contain compiler extensions keywords specific compiler preprocessor directives implementation dependent interpretations 
included represent extraction problems reverse engineering 
scalability 
test buckets benchmark relatively small easy understand score hand 
automated scoring mechanism oracle provide set canonical answers difficult include test buckets significant size 
version included subset lines code package core package stanford university suif compiler system 
development process recall section ingredients needed successful development process 
champions lead process design decisions supported research opportunities community participation feedback 
development 
benchmark primarily susan elliott sim 
joined holger university victoria version 
benchmark built discussions fact extraction place reverse engineering community 
creating benchmark selection test buckets discussed researchers implemented fact extractors 
developing benchmark extensive testing laboratories followed closely papers area 
date provided opportunities community participate development benchmark 
discussed cascon november year 
fact extractors participated evaluation acacia represented university waterloo university waterloo queens rigi extractor university victoria sn university ottawa 
discussed iwpc international workshop program comprehension june 
participants workshop acacia sn columbus university 
workshops benchmark published advance teams submitted solutions scoring prior workshop 
workshop teams gave presentations extractors benchmark 
organisers rankings teams chaired discussion benchmark 
workshops participants organisers gained new insights tools problem fact extraction 
benchmark tasks uncovered errors extractors 
similarly teams mistakes benchmark 
workshops fact extractor highest score surprise participants 
workshop success sn unexpected didn lot visibility 
second score surprise significant improvement previous workshop 
impact theory successful benchmark impact discipline 
full extent impact clear time months effects appeared 
workshops participants eager share experiences results 
day high level energy room researchers felt renewed sense purpose learned lot 
shared experience having worked successfully relationships 
strengthened ties personal history easier 
looking forward version authoring 
benchmark influenced development fact extractors 
pointed shortcomings tools raised questions researchers previously considered 
lessons learned evaluation applied creating standard schema gxl 
improved technical results cohesiveness community acting vehicle improve shared understanding problem fact extraction 
benchmark consists series small extraction problems easy identify points disagreement terminology 
able establish common vocabulary language features analysis able discuss conceptualisation fact extraction clearly 
example improved understanding relates identifying location code fragment 
consider question line definition function average start 
possible answer starts line containing function signature int average int list 
possible answer starts line containing curly brace denotes start block containing function body 
argument interpretations said correct idea fact subsequent analysis 
problem complicated preprocessor directives subsequent transformations occur compilation process 
operations may cause feature original source code move disappear entirely 
order properly frame evaluation need specify context downstream analysis required facts 
words need task sample consists just source code 
token fact extractors need clear analyses data models support 

challenge shown benchmarking strong positive effect scientific maturity research community 
benefits benchmarking include stronger consensus community research goals greater collaboration laboratories rigorous examination research results faster technical progress 
believe benefits realised areas software engineering 
conclude identifying specific areas software engineering believe ripe benchmarking 
requirements engineering requirements engineering re matured research community considerably past decade series annual conferences tenth year number smaller regular workshops 
collaborative links european funded network excellence provide strong evidence collaboration 
preconditions described section met 
areas re notably software specification proto benchmarks years 
feather characterizes exemplars identifies uses strengths weaknesses exemplars evaluating specification techniques 
promoting research comparison understanding exemplars motivating comparison task sample 
feather point exemplars lack appropriate evaluation criteria determine specification language exemplar appropriate expressiveness deductive power development process efficiency 
list provides obvious starting point defining performance measures 
challenge re community turn exemplars benchmarks 
model checking model checking obvious candidate traditional benchmarking speed essential property model checking algorithm 
proto benchmarks emerged elevator problem ryan nearly model checking papers include performance evaluation showing speed varies typically size state space 
evaluations standardized way 
speed particular model checker depend simple way size state space 
report model checkers tend sensitive particular modelling choices including order variables types modularity system 
reports raw performance model checking engines tends ignore factors 
benchmarking effort clearly needed develop consensus appropriate task samples wish know relative performance model checkers particular applications 
obvious interesting application benchmarking model checkers believe advance field dramatically 
distinguish model checking engine computes satisfaction relation particular temporal logic model checking framework includes modelling languages expressing state machine models abstraction techniques reducing large models size suitable fast checking tools translating models input language checker engine visualizing results 
applying model checking uml models statecharts falls category 
benchmarking concentrate pure performance finding analysis questions particular framework handle 
suspect impact similar seen 
software evolution contrast previous software evolution emerging research community pursuing benchmark 
couple years key people field published papers proposed workshops draw community attention problem 
motivated desire better understand research results comparing common task samples 
advice community continue pursuing feel somewhat early attain full fledged community benchmark 
feel quite attained precondition sufficient proliferation research results 
needed multiplicity approaches come time consensus results needed build benchmark 
encourage continue effort prepare community benchmark 
examples section illustrate ways benchmarking different areas software engineering 
challenge areas start benchmarking advance research 
branches software engineering stage agreement body knowledge accepted techniques fundamental problems 
branches reached normal science stage struggling codify lasting lessons research impact industrial practice 
areas stages benchmarking increase scientific maturity area 
benchmark developed consensus widely accepted provides beacon community 
lights path follow shows agreement important concentrates attention key problem 
effects emerge benchmarking process lasting positive impact scientific discipline 
people participation benchmark 
mike godfrey jeff elliott catherine morton helped test cases version 
version developed jointly holger 
ian bull rudolf mike godfrey timothy lethbridge andrew sergei volker andrew participated workshops 
armstrong evaluating architectural extractors working conference reverse engineering honolulu hi pp 
october 
victor basili dieter rombach goal question metric approach encyclopedia software engineering volume set dieter rombach eds 
new york city john wiley sons pp 

berndt harald gall evaluation reverse engineering tool capabilities software maintenance research practice vol 
pp 

ivan bowman michael godfrey ric holt connecting architecture reconstruction frameworks journal information software technology vol 
pp 

serge demeyer tom mens michel software evolution benchmark proceedings international workshop principles software evolution vienna austria pp 
september 
martin feather stephen fickas anthony finkelstein axel van lamsweerde requirements specification exemplars automated software engineering vol 
pp 

rudolf susan elliott sim richard holt rainer koschke standard schema eighth working conference reverse engineering stuttgart germany pp 
october 
jim gray benchmark handbook database transaction processing systems san mateo ca morgan kaufman publishers 
john henning spec cpu measuring cpu performance new millennium ieee computer pp 
july 
richard holt andreas winter andy gxl standard exchange format seventh working conference reverse engineering brisbane queensland australia pp 
november 
barbara ann evaluating software engineering methods tools 
parts acm sigsoft software engineering notes vol 

thomas kuhn structure scientific revolutions third edition 
chicago university chicago press 
william betty cheng generic framework formalizing uml proceeedings third international conference software engineering toronto canada pp 
may 
gail murphy david notkin william griswold lan empirical study static call graph extractors acm transactions software engineering methodology vol 
pp 

lawrence pfleeger experimental design analysis software engineering parts acm sigsoft software engineering notes vol 

ryan sfi feature integration tool advances computer science lakhnech eds 
heidelberg germany springer verlag pp 

susan elliott sim richard holt steve easterbrook benchmark evaluate extractors tenth international workshop program comprehension paris france pp 
susan elliott sim margaret anne storey structured demonstration program comprehension tools seventh working conference reverse engineering brisbane queensland australia pp 
november 
susan elliott sim margaret anne storey andreas winter structured demonstration program comprehension tools lessons learnt seventh working conference reverse engineering brisbane queensland australia pp 
november 
feasibility model checking software requirements case study proceedings gaithersburg maryland pp 
june 
walter tichy computer scientists experiment 
ieee computer pp 
may 
ellen voorhees donna harman overview eighth text retrieval conference trec text retrieval conference trec maryland pp 
november 
