searching planning operators context dependent probabilistic ects providing complete accurate domain model agent situated complex environment extremely di cult task 
actions may di erent ects depending context taken actions may induce intended ects probability success depending context 
algorithm automatically learning planning operators context dependent probabilistic ects environments exogenous events change state world 
empirical results show algorithm successfully nds operators capture true structure agent interactions environment avoids spurious associations actions exogenous events 
research classical planning assumed ects actions deterministic state world altered exogenous events simplifying task encoding domain knowledge form planning operators wilkins 
assumptions unrealistic real world domains relaxed current research planning systems kushmerick hanks weld 
planning domains complex task generating domain models 
algorithm automatically learning planning operators context dependent probabilistic ects environments exogenous events change state world 
approach problem learning planning operators rst de ning space possible operators developing cient ective methods exploring space 
operators tell state agent world changes response speci actions 
degree operator chosen operator space captures structure evaluated looking agent past experiences 
state world changed manner described operator signi cantly past 
exploration tim oates paul cohen computer science department university massachusetts box amherst ma oates cs umass edu cohen cs umass edu operator space performed algorithm called multi stream dependency detection designed nd dependencies categorical streams data time oates oates cohen 
provides general search framework relies domain knowledge guide search reason prune 
consequently nds planning operators sized space 
approach di ers learning planning operators requires minimal domain knowledge need access advice examples domain experts wang initial approximate planning operators gil 
assume learning agent initial domain model weak consisting list di erent types actions take 
agent initially knows contexts actions produce changes environment changes 
gather data learning algorithm agent explores domain random actions recording state descriptions 
agent history state descriptions learning algorithm produces planning operators characterize agent world changes takes actions particular contexts 
domain model approach learning planning operators requires minimal domain knowledge assume learning agent knowledge types actions take sensors obtain state world values returned sensors 
information de ne space possible planning operators 
agent agent assumed set sensors fs smg set possible actions fa ang 
time step sensor produces single categorical value called token clearly random exploration may ine cient approach precludes non random exploration 
nite set possible values 
ti token values associated th sensor denote value obtained sensor si time describes aspect state agent world example may indicate state robot hand values fopen 
state world perceived agent denoted simply set values returned sensors time 
fs ij mg state vector 
agent actions encoded special sensor sa indicates possible actions attempted time general sa 
time step take action 
actions require time step action allowed timestep resulting changes environment appear constant number time steps 
restrictions required algorithm particular domain learning planning operators 
loss generality assume ects actions appear time step 
assume state world change due agent action exogenous event simultaneously 
case learning problem di cult 
consider robot task pick paint blocks 
domain adapted kushmerick hanks weld explicate buridan probabilistic planner 
robot sensors determine holding block hb dry gripper gd clean gripper gc block painted bp 
addition robot take actions 
dry gripper dry pick block pickup paint block paint obtain new block new 
terms notation developed robot initial domain model summarized follows faction bp gc gd new paint tact ion new paint pickup tbp bpg tgd planning operators operator representations classical planners strips include set preconditions add list delete list fikes nilsson 
strips planner assumed actions taken world state matching operator preconditions result state changes indicated operator add delete lists fail 
take restrictive view allowing actions attempted state ects depend state actions taken 
speci cally operator speci es action context action expected induce change world state state results change probability occurring 
state world matches context action time step state world match ects probability contexts ects operators represented 
tuple speci es sensor speci value assertion value irrelevant 
denote irrelevance wildcard token de ne set ti element cross product drawn set consider sensor example fa bg 
adding wildcards fa space example fa fa set operator context speci es conjunct sensor token values serve operator precondition 
action values sensors relevant ects sensor values 
example di cult robot pick gripper wet dry success pickup action depend block 
represents contextual information gd irrelevant sensors sensor detects block specifying values relevant sensors sensor detects gripper dry 
contexts specify features world state operators apply ects specify features context change response action 
allow non wildcard values sensor context speci es non wildcard sensor 
require non wildcard ects di erent value context corresponding sensor 
operators describe changes response action stays 
restriction similar wang delta state wang di erence states world execution action drive learning operator ects 
likewise benson benson uses di erences state descriptions identify ects actions learning execution traces generated domain experts 
assume block painting robot interactions world governed rules robot successfully pick time gripper dry time gripper wet 
gripper wet robot dry chance success 
robot paints block holding block painted robot gripper dirty fail 
robot holding block painting result painted block anda dirty gripper time painted block remaining time 
robot requests new block nd state holding block block isnot painted gripper clean gripper dry time wet time 
information summarized representation planning operators 
pickup gd hb hb pickup gd hb hb dry gd gd paint bp bp paint gc hb gc paint gc hb gc new bp bp new gc gc new hb hb new gd gd new gd gd planning operators block painting robot domain 
algorithm algorithm nds dependencies unexpectedly frequent infrequent occurrences values multiple streams categorical data oates oates cohen 
general performs simple best rst search space possible dependencies terminating user speci ed number search 
adapted speci domains supplying domain speci evaluation functions 
assumes set streams th stream si takes values set ti 
denote history obtained streams xed intervals time time fx jt 
example streams shown constitute short history twelve rst whichis 
explores space dependencies pairs 
dependencies denoted prec succ evaluated respect counting frequently occurrence precursor prec followed time steps occurrence successor succ called lag dependency constant positive value 
history shown dependency strong 
times see precursor stream stream see successor stream times lag 
see successor see precursor time step earlier 
stream stream stream performs general speci best rst search space possible dependencies 
node search tree contains precursor successor 
root tree precursor successor pair composed solely wildcards streams shown earlier root tree 
node specializations generated instantiating wildcards tokens 
tokens parent exactly fewer wildcard parent 
depth exactly non wildcard tokens distributed node precursor successor 
space item dependencies clearly exponential 
performs systematic search avoiding redundant generation requiring lists open closed nodes 
speci cally node generated instantiating streams right right non stream node 
method ensures dependency explored facilitates reasoning prune 
example descendants node wildcards streams precursor stream precursor stream successor 
reason features right rightmost non wildcard instantiated new values 
aspect domain features undesirable tree safely pruned node 
refer oates cohen complete formal statement algorithm 
learning planning operators learn planning operators rst searches space operators capture structure agent interactions environment operators search ltered remove tainted noise exogenous events leaving operators capture true structure 
section describes processes 
map operator representation dependency representation 
consider planning operator described earlier pickup gd hb hb context ects operator represented 
incorporate idea pickup action taken context responsible changes described ects include action representation pickup gd hb hb added action stream context speci ed pickup value 
requires precursors successors refer set streams include action stream ects force value 
item missing representation operator probability occurrence precursor context action time step followed lag successor ects 
probability obtained empirically counting occurrences precursor successor history agent actions dividing total number occurrences precursor 
robot domain described previously wewant nd dependencies corresponding planning operators listed 
guiding search recall descendants node identical left including rightmost non wildcard encode actions rst leftmost position precursor prune nodes action instantiated position 
example node pruned descendants non wildcard action stream gd domain model requires operator ects specify non components context change response action 
ects specify value stream context context ects specify value non stream 
node pruned descendants value bp ects stream context pickup gd bp likewise node pruned descendants value gd instantiated context ects pickup gd gd search heuristic evaluation function simply counts number times precursor followed lag successor builds biases search frequently occurring precursors frequently occurring precursor successor pairs 
terms domain application biases mean things equal search prefers commonly occurring state action pairs state action pairs lead changes environment high probability 
result operators apply frequently succeed operators apply frequently fail 
filtering returned dependencies augmented search post processing ltering algorithm filter removes operators describe ects agent reliably bring contain irrelevant tokens 
filter begins removing dependencies low frequency occurrence contain wildcards successor 
occurrence deemed low cell dependency contingency table user speci ed parameter low cell 
remain sorted non increasing order generality generality measured summing number wildcards precursor successor 
algorithm iterates repeatedly retaining general operator removing consideration operators subsumes signi cantly di erent conditional probabilities measured statistic 
operators retained previous step tested ensure change context ects strongly dependent action measured statistic 
measure di erence conditional probabilities conditionals deemed di erent value exceeds user speci ed parameter sensitivity 
wehave omitted pseudocode filter due lack space 
empirical results test ciency completeness search ectiveness filter algorithm created simulator block painting robot domain described earlier 
simulator contained ves streams action bp gc gd hb 
simulation began randomly selected initial state time step robot probability attempting randomly selected action 
addition added varying numbers noise streams contained values set tn fa cg 
probability exogenous event occurring time step 
exogenous event occurred noise stream took new value probability tn 
goal rst experiment determine number nodes expands nd interesting planning operators increases size search space grows exponentially 
ran simulator time steps recording stream values iteration 
note simulator ran time steps agent took approximately actions due low probability acting time step 
values served input dependencies corresponding planning operators listed 
number noise streams increased increments repeated procedure times total runs 
scatter plot number nodes expanded vs shown 
ignore outliers andn number nodes required nd interest ing planning operators appears linear small slope 
encouraging result 
outliers correspond cases robot random exploration successfully exercise target operators frequently 
search forced explore vast space operators containing elements nd 
nodes expanded noise streams number search nodes required nd target planning operators robot domain function number noise streams 
second experiment evaluated ability filter algorithm return exactly set interesting planning operators large number potential operators 
gathered data time steps simulation noise streams 
agent took far fewer actions due low probability acting time step 
data sets generate operators expand nodes 
tells search fewer nodes nd desired operators 
goal task di cult filter including uninteresting dependencies input 
low cell sensitivity cases filter returned set dependencies 
dependencies returned shown 
note operators listed empirically derived probability associated close expected value 
noise streams contained instantiated values 
interestingly operators appear capture implicit structure robot domain 
penultimate operator says paint block clean gripper roughly chance gripper dirty 
operator specify value hb stream context includes cases robot holding block painting cases 
resulting probability probabilities having dirty gripper painting contexts respectively 
similarly operator includes cases robot attempted pick gripper chance success dry gripper chance success 
pickup gd hb hb pickup gd hb hb dry gd gd paint bp bp paint gc hb gc paint gc hb gc new bp bp new gc gc new hb hb new gd gd new gd gd paint gc gc pickup hb hb operators returned ltering search nodes generated training set noise streams 
related existing symbolic approaches learning planning operators interaction environment typically assumed deterministic world actions intended ects state world changes absence action gil shen wang 
notable exception benson primary ect durative action assumed deterministic side ects may occur probability 
contrast described applies domains contain uncertainties associated outcomes actions noise exogenous events 
subsymbolic approaches learning environmental dynamics reinforcement learning mahadevan connell capable handling variety forms noise 
reinforcement learning requires reward function allows agent learn mapping states actions maximizes reward 
approach concerned learning sequences actions lead states attempts acquire domain knowledge form explicit planning operators 
learning planning operators assumes availability fairly sophisticated forms domain knowledge advice problem solving traces generated domain experts benson wang initial approximate planning operators gil 
approach assumes learning agent initially knows dynamics environment 
model dynamics constructed agent past interactions environment 
approach expanding search tree avoid redundant generation search nodes similar algorithms schlimmer riddle segal etzioni 
search di ers mentioned explores space rules containing conjunctive lefthand sides conjunctive right hand sides 
doing allows nd structure agent interactions environment aforementioned algorithms inductive learning algorithm considers rules xed number literals right hand side 
evaluated algorithm allows situated agents learn planning operators complex environments 
algorithm requires weak domain model consisting knowledge types actions agent take sensors possesses values appear sensors 
model developed methods heuristics searching space planning operators nd capture structure agent interactions environment 
domain robot pick paint blocks demonstrated computational requirements algorithm scale approximately linearly size robot state vector spite fact size operator space increases exponentially 
extend directions 
primary interest relationship exploration learning 
ciency completeness learning ected giving agent probabilistic planner allowing interleave goaldirected exploration learning 
rst task apply approach larger complex domains 
research supported arpa rome laboratory contract numbers national defense science engineering graduate fellowship 
government authorized reproduce distribute reprints governmental purposes copyright notation 
views contained authors interpreted necessarily representing cial policies endorsements expressed implied advanced research projects agency rome laboratory government 
benson 
inductive learning reactive action models 
proceedings twelfth international conference machine learning 
fikes nilsson 
strips new approach application theorem proving problem solving 
arti cial intelligence 
gil 
learning experimentation incremental re nement incomplete planning domains 
proceedings eleventh international conference machine learning 
kushmerick hanks weld 
algorithm probabilistic commitment planning 
proceedings twelfth national conference arti cial intelligence 
mahadevan connell 
automatic programming behavior robots reinforcement learning 
arti cial intelligence 

method planning uncertain incomplete information 
proceedings ninth conference arti cial intelligence 
oates cohen 
searching structure multiple streams data 
appear proceedings thirteenth international conference machine learning 
oates schmill gregory cohen 
detecting complex dependencies categorical data 
fisher lenz eds finding structure data arti cial intelligence statistics springer verlag 
riddle segal etzioni 
representation design brute force induction boeing manufacturing domain 
applied arti cial intelligence 

search systematic set enumeration 
proceedings third international conference principles knowledge representation reasoning 
schlimmer 
ciently inducing determinations complete systematic search algorithm uses optimal pruning 
proceedings tenth international conference machine learning 
shen 

discovery autonomous learning environment 
machine learning 
wang 
learning observation practice incremental approach planning operator acquisition 
proceedings twelfth international conference 
wilkins 
practical planning extending classical ai planning paradigm 
morgan kaufmann 
