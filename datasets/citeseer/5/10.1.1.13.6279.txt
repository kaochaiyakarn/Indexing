handbook language engineers ali editor february center study language information february statistical natural language processing chris callison burch miles osborne statistical natural language processing snlp field lying intersection natural language processing machine learning 
snlp differs traditional natural language processing having linguist manually construct model linguistic phenomenon model semi automatically constructed linguistically annotated resources 
methods assigning partof speech tags words categories texts parse trees sentences semi automatically acquired machine learning techniques 
trend applying statistical techniques natural language processing came largely industrial speech recognition research groups bell laboratories ibm watson research center 
statistical techniques speech recognition vastly performance non statistical counterparts rule speech recognition systems essentially longer area research 
success machine learning techniques speech processing led interest applying broader range nlp applications 
addition useful perspective producing high quality results speech recognition snlp systems useful number practical reasons 
cheap fast authors jason stephen clark jochen leidner sarah thorough comments chapter 
handbook language engineers 
ali editor 
copyright csli publications 
february february chris callison burch miles osborne produce handle wide variety input required real world application 
snlp especially useful industry 
particular snlp affords rapid prototyping 
fully hand crafted systems extremely time consuming build statistical systems automatically trained corpora produced quickly 
allows different approaches tried evaluated short time frame 
example yarowsky described create new part speech tagger single day yarowsky 
ambitious example machine translation day experiment statistical techniques develop complete chinese english machine translation system hour period 
statistical systems robust van noord 
wide variety meanings snlp generally means system produce output matter badly formed input matter novel example text classification system may able classify text words text previously unseen 
handling kinds input necessary real world applications system fails produce output unable analyze sentence useful 
statistical systems cheaper produce hand crafted rule systems 
process creating statistical system automated process creating rule system actual number participants needed create system 
furthermore learned data statistical systems require knowledge particular language analyzed 
issue multi language project expense hiring language consultants staff specialized skills 
common theme early snlp systems pride minimizing amount linguistic knowledge system 
example fred jelinek leader ibm speech recognition research group said time fire linguist performance goes sentiment 
jelinek statement strike fear hearts linguists reading chapter 
strong opposition theoretical linguistics snlp 
snlp put linguists 
put forth positive answer chapter useful role statistical natural language processing linguistic expertise statistical systems 
jelinek infamous quote represents biases early days snlp 
decade worth research shown snlp extremely powerful tool able produce impressive results trends indicate naive approaches divorced linguistics go far 
revival interest integrating sophisticated linguistic information statistical models 
example language models speech recognition moving word ngram models incorporating statistical grammars chelba jelinek charniak 
role linguist 
chapter provide entry point linguists entering field snlp may apply expertise enhance powerful approach natural language processing 
lest represent snlp completely engineering oriented discipline point interested reader abney describes number ways snlp inform academic topics linguistics 
example snlp useful psycholinguistic research systems typically encode graduated notions formedness 
offers psychologically plausible alternative traditional binary grammatical ungrammatical distinction 
similarly academic vein johnson shows optimality theory interpreted terms statistical models 
turn suggests number interesting directions ot take 
rest chapter follows presenting simple worked example designed illustrate aspects snlp section 
motivating usefulness snlp move core methods snlp modeling learning data evaluation sections respectively 
core methods followed brief review applications snlp section 
conclude discussion section comments current state snlp possible directions take 
simple worked example imagine just founded start want automate task replying customer email queries 
imagine decide parsing sentence messages carrying sort semantic interpretation step example querying database customer orders basis interpretation automatically generate appropriate reply 
assuming grammar place problem february february chris callison burch miles osborne need addressed start ambiguity 
question simple sell apple laptops multiple parses shown corresponding multiple interpretations 
question asking stocks apple laptops sells laptop computers apple 
sentences multiple parses know interpretation 
parses possible context faced problem having select parse 
sounds perfect application probability 
vp np np nom aux pronoun verb proper noun noun sell apple laptops 
vp np np np nom aux pronoun verb proper noun noun sell apple laptops 
possible parses sell apple laptops 
assume moment start context free grammars cfgs parsing 
assume sentences message independent 
assumption clearly wrong meaning sentence message statistical natural language processing cfgs defined set rules rule form non terminal symbol sequence terminal non terminal symbols 
probabilistic context free grammars pcfgs extend cfgs associating rule probability simple grammar shown adapted jurafsky martin 
np vp det aux np vp det vp det np det noun noun laptops np proper noun noun desktops np nom verb sell np pronoun verb ship nom noun verb repair nom noun noun aux nom proper noun noun aux vp verb proper noun apple vp verb np proper noun sony vp verb np np pronoun pronoun simple probabilistic grammar english probability rule likelihood sequence terminals non terminals occur immediately dominated non terminal symbol written conditional probability 
having probabilities associated application rule useful disambiguation combined calculate probability parse tree 
competing parses single sentence compared probability see parse preferred 
probability particular parse defined product probabilities rule expand node parse tree unrelated sentences precede indicative kinds simplifying assumptions practical snlp systems 
february february chris callison burch miles osborne example probability tree corresponding question commerce stocks apple laptops aux np vp aux aux np pronoun np pronoun pronoun vp verb np vp verb sell verb np nom np nom proper noun noun nom proper noun apple proper noun noun laptops noun comparison probability tree corresponding question commerce sells computers apple aux np vp aux aux np pronoun np pronoun pronoun vp verb np np vp verb sell verb np proper noun np proper noun apple proper noun np nom np nom noun nom noun laptops noun probabilistic grammar 
conclude tree preferred second tree come customer wanted know sold laptops apple 
natural question ask probabilities assigned grammar rule come 
manually assigned inspecting parse trees looking combinations rule applications approach timeconsuming error prone 
probabilities associated statistical natural language processing cfg rules usually automatically set process called estimation 
section reviews popular estimation techniques 
really justify tied probabilities contextfree rules tying aspects tree 
models parse selection possible 
example better performance achieved include greater syntactic context rules add information lexical head phrase performance improves 
process specifying task going tackled known modeling 
modeling snlp linguistics science general thought building theories testing 
example interested seeing latest theory long distance dependencies helped question answering create model questions answered incorporate information long distance dependencies model 
test model evaluating performance question answering system 
modeling general task constructing machinery mimics task 
process building statistical model takes place number stages 
structural components model constructed 
usually takes place manually take place automatically kinds tasks text classification clustering documents similarity 
building model syntax enumerate set possible grammar rules 
non statistical linguistics step entirety modeling process 
linguist write appropriately constrained rules ill formed sentences admitted 
statistical approaches models include probabilistic part addition structural components 

model parameterized 
parameters thought variables take probabilities values 
parameters model grammar correspond rule probabilities 
probabilities specify rules combine 
free linguist having exactly constrain grammar order eliminate spurious parses letting probabilities automatically select preferred parses 

model instantiated assigning values parameters 
instantiating model grammar amount specifying probabilities application rules 
probabilities usually estimated linguistically annotated february february chris callison burch miles osborne data treebank sentences annotated parse trees 
interaction model parameterized values estimated significant concern 
specify model complex parameters estimated model training set samples phenomena interested modeling closely fail adequately predict examples phenomena 
extreme consider training set world completely fail generalize new situations 
failure generalize training data called overfitting 
extreme example grammar overfitted single rule sentence 
natural overfitted example model contained syntactic constructs treebank 
constructed grammar extracting rules treebank examples class ambiguities pp attachment contained overfitted model consider 
overfitting central concern annotated training material run risk basing decisions insufficient evidence 
contrast model performance task suffer 
incorrectly model malformed examples 
example grammar contain rules generated string possible 
called underfitting 
models simple 
modeling need strike correct balance simplicity complexity 
generally trade carried manually process trial error 
return problem talk smoothing section 
addition overfitting underfitting fundamental aspect modeling model generative discriminative 
depends concerned building machinery create language part language observed case task discriminate alternative structures 
generative models name implies concerned creating structures 
generative models natural ways thinking tasks 
grammars thought generative models generate sentences 
discriminative models try distinguish set possibilities 
particular fully model task 
machine translation thought discriminative task 
sentence source language want statistical natural language processing choose best possible translation set sentences target language 
discriminative approach source sentence modeled 
generative discriminative models fundamental difference relate probability theory 
consider generative model part speech pos tagging interested joint probability words tags 
generative model relates sentences pos tag sequences vice versa 
models marginal distributions sentences pos tag sequences isolation 
problem generative joint approaches need deal distributions points model 
discriminative model tags words model marginal distribution words words simpler joint probability words tags 
discriminative approaches model choices context waste effort context 
joint discriminative models currently intense investigation johnson lafferty 
estimation learning worked model task parameters step assign values parameters 
step called estimation statistically minded learning 
term estimation 
written set grammar rules want estimate probabilities rules training data 
number techniques estimate probabilities data 
techniques distinguished properties bias scalability bias variety meanings typically thought systematic preference type model instantiations 
bias estimation usually design property process 
occam razor example bias design simple models principle multiple explanations model consistent data keep models 
examples bias design maximum likelihood estimators section biased models give maximal consideration training set maximum entropy models section biased models probabilistically simple 
scalability practical concern estimation method large number parameters limited computational resources 
associate parameter word february february chris callison burch miles osborne need estimation technique scale appropriately 
want estimation method fast train run testing different possible models 
clearly enterprise deal hundreds thousands parameters reasonable time 
large number estimation methods assign values parameters model 
briefly look popular approaches 
concentrate supervised methods assume training material annotated manner turn weakly supervised methods section annotated unannotated training data 
maximum likelihood smoothing far popular estimation method snlp maximum likelihood estimation mle 
maximum likelihood estimator finds set parameters probability training set model high possible 
firm statistical grounding 
real reason popularity fact parameters estimated simple counting 
example word takes part speech tag times sum possible part speech tags word incorrect assumption words independent maximum likelihood estimate probability word takes partof speech tag ratio probability grammar rule applying particular word estimated counting number times applies word divided total number rules applied word treebank 
mle biased training set 
training set contains errors referred noisy data training set representative examples want classify models produced mle need modified typical language training sets models estimated mle tend overfit 
usually models smoothed attempt improve performance 
smoothing central successful mle 
example collins brooks showed simple model pp attachment estimated mle greatly improved smoothing collins brooks 
popular smoothing methods include backing linear interpolation turing smoothing combinations thereof chen goodman 
successful smoothing black art generally involves large degree engineering 
note performance increased selecting possibly simpler model statistical natural language processing applying mle smoothing 
maximum entropy counting mle acceptable model explicitly captures dependencies task 
dependencies obvious easily encoded model 
enumerating points dependencies explicitly estimation technique automatically accounts dependencies exist 
maximum entropy maxent models called log linear models capable correctly estimating parameters modeling data may contain dependencies abney 
maxent form mle parameters calculated iterative numerical optimization methods 
maxent applied snlp tasks usually producing competitive results ratnaparkhi 
maxent counting mle prone vagaries training set 
preference simplicity produce suboptimal results especially dealing sparse data 
maxent models estimated numerical optimization methods 
previously mentioned scalability important consideration building large models 
malouf showed range language tasks general purpose constrained optimization techniques limited memory variable metric approaches converged faster special purpose maxent estimation methods generalized improved iterative scaling malouf 
kernel methods previous methods assumed model abstracted training set associated parameters need estimated 
idea instantiated model summary training set 
kernel methods support vector machines take alternative approach 
model determined terms number key training examples combined functional form able act classifier 
training items usually selected resulting classifier maximally separates training examples 
frequently separation generally possible original feature space training examples transformed kernel function space training examples linearly separated 
kernel methods attractive capture non linear interactions features maxent models addressed problem gaussian prior chen rosenfeld 
february february chris callison burch miles osborne assume features related log linear manner 
kernel methods applied increasing range language tasks usually near state art performance joachims 
maxent models kernel methods require numerical optimization 
current estimation methods svms scale properly training infeasible applications 
example classifying phones timit corpus salomon 
estimated take years cpu time estimate svm model 
various extensions approximations help reduce burden 
ensemble approaches findings decade fact performance increased combining different models ensemble 
multiple models combined simply having model vote classification say part speech tag 
ensemble output tag received votes 
options include weighting constituent model vote testing set forth 
ensemble techniques boosting bagging stacking currently popular dietterich 
basic idea models biased manner unwanted bias eliminated averaging number alternative models 
language domain examples ensemble approaches applied pos tagging brill wu parsing henderson text classification ghani 
virtually cases ensemble techniques produce best results 
price pay ensemble methods greatly increase computational burden associated estimation 
example estimating single model need estimate possibly hundreds models 
furthermore ensemble models push complexity extreme hard interpret 
data snlp data intensive field 
uses machine learning automatically estimate model parameters data success failure undertaking depend quality availability appropriate data 
data computational linguistics tasks generally takes form corpora 
corpora divided categories annotated corpora unannotated corpora 
unannotated corpora simply large collections raw text 
useful tasks gram language modeling rely estimating frequency words bigrams trigrams context sensitive statistical natural language processing spelling correction 
annotated corpora add additional information text phonetic transcription part speech tags parse trees rhetorical relations early days computational linguistics statistical approaches limited availability machine readable text 
heavy increase internet past decade greatly expanded amount easily accessible machine readable text 
number interesting proposals exploit web data source 
example resnik describes method mining web bilingual texts vital statistical machine translation 
method automatically gathers web pages potential translations looking documents language links text contains name language 
example english web page link text espa ol en espa ol page linked treated candidate translation english page spanish 
web offers promising source data tasks natural language processing tasks require data specialized sort 
tasks simple part speech tagging complicated parsing require corpus linguistically annotated examples 
describes number annotated corpora commonly computational linguistics research 
available linguistics data consortium availability appropriate annotated corpus greatly facilitates statistical nlp research particular task 
example penn treebank invaluable resource statistical parsing 
syntactic structures associated sentence penn treebank estimate probabilities rules statistical context free grammar introduced earlier allow perform disambiguation mail response 
creation resource large penn treebank costly time intensive tedious 
marcus 
give detailed description process 
high cost creating annotated corpus largely having pay salaries appropriately skilled linguistics graduate students 
depending amount data required availability staff amount error checking carried process take years 
penn treebank developed year period team annotators graduate training linguistics 
marcus 
estimated team part time annotators annotating hours day able produce output www ldc upenn edu february february chris callison burch miles osborne corpus name words description brown corpus modern computer readable corpus 
consists various texts american english 
bnc large corpus spoken written british english completely annotated part speech tags 
penn treebank wall street journal sentences annotated parse trees 
various collection child language data corpora 
switchboard transcribed telephone conversations spoken texts 
includes recordings sentences penn treebank 
hcrc map task audio video transcriptions spoken dialogue individuals participating cooperative task 
canadian hansard bilingual sentence aligned french english proceedings canadian parliament 
various commonly corpora statistical natural language processing words year parse annotated sentences optimistic average rate words hour 
estimate factor additional time verifying parses 
research snlp largely guided availability appropriately annotated resources 
particular tasks statistical parsing tend get attention problems semantic interpretation simply corpora annotated parse trees exist 
corpora annotated logical forms hand tend exist sufficient quantities 
research statistical semantic interpretation far developed 
weakly supervised methods central role annotated material high costs associated creating new annotated resources research focused bootstrapping larger amounts training data existing resources 
approach combine relatively small quantities manually annotated material larger volumes unannotated material methods training 
training informally described manner blum mitchell yarowsky pick views classification problem 
build separate models views train model small set labeled data 
sample unlabeled data set find examples model independently labels high confidence nigam ghani 
take examples valuable training examples iterate procedure unlabeled data exhausted 
effectively picking confidently labeled data model add training data model labeling data 
cotraining differs iterative re estimation techniques expectation maximization em family training greedy relying addition confidently labeled material re estimate gather new parameters re estimating parameters iteration 
greediness helps prevent training falling suboptimal local minimum 
training applications word sense disambiguation yarowsky web page classification blum mitchell named entity identification collins singer statistical machine translation callison burch parsing steedman 
shows performance statistical parser trained statistical parser 
february february chris callison burch miles osborne parsers initially trained parse trees brown corpus non newswire material evaluation terms performance predicting parses domain newswire material penn treebank 
unlabeled examples raw newswire sentences 
higher curve shows happens tiny amount domain specific annotated training material added larger volume unannotated material different domain 
score cross genre training training rounds cross genre bootstrapping results steedman 

upper curve sentences labeled data brown plus wsj sentences lower curve uses sentences brown 
score measure precision recall parsers 
approach involve people annotation task apart act creating initial seed set annotated data cotraining fully automatic 
active learning similar training views predict different annotations example example labeled person 
system automatically annotates examples 
active learning language community applied task building parsers taggers 
evaluation statistical natural language processing critical parts nlp task statistical having clearly defined evaluation metric 
metric judge successful particular method comparing performance methods 
obvious method best task having defined evaluation metric allows alternative approaches quantitatively compared 
example widely studied task text classification 
newly developed machine learning techniques applied text classification standard benchmark task 
evaluation metrics text classification tasks precision recall 
context text classification precision number correctly classified documents divided number classifications posited 
recall number documents assigned particular classification divided number documents testing set belong class 
precision recall complementary measures accuracy vary 
example text classifier assigned classification document got document classification correct precision low recall lot instances documents class 
similarly text classifier assigned classification documents recall label correctly labeled instance class low precision incorrectly labeled instances classes class 
determining precision recall machine learning technique allows compared 
furthermore order machine learning techniques directly compared need compared identical tasks 
yang liu compared effectiveness various machine learning techniques including support vector machines nearest neighbors neural networks linear squares fit mapping naive bayes text classification task 
trained systems perform topic spotting identical newswire articles 
techniques trained identical set data tested ability categorize set articles resulting scores directly comparable 
cases difference scores close yang liu performed significance tests determine differences due better performance random factors 
significance testing frequently done natural language processing research february february chris callison burch miles osborne method obviously outperforms assumptions hypothesis testing violated useful experimental methodology 
interested readers referred dietterich discussion 
training testing sets notion training testing sets important 
learned data nature statistical natural language processing applications training testing data disjoint 
common pitfall train data included evaluation set 
result falsely high performance estimates 
reason performance estimates may falsely high potential overfitting testing data 
testing data included training data machine learning technique may learn classify examples exactly doing may generalize unseen data 
situations small amount data available training may difficult divide data training testing sets testing set fairly reflect data 
cases people cross validation 
cross validation data randomly divided sections 
learner trained sections evaluated remaining 
done times performance system reported average evaluations 
note reporting performance cross validation reduces need significance testing chance variation performance accounted averaging process 
system evaluation clearly defined evaluation metric help comparison different machine learning algorithms comparison full blown nlp systems 
situations useful able evaluate performance various systems particular task 
instance industry integrating people software nlp applications 
deciding commercial software package purchase purchase software open source alternative important get idea relative accuracy various systems 
cases matter dividing set labeled data testing set similar vein common practice divide training data separating held set help counteract overfitting 
learning algorithm optimize performance training data performance held begins fall 
happens may assume algorithm failing generalize overfitting 
statistical natural language processing systems trained training data may distributed system 
evaluating commercial system may prove useful develop baseline system compare 
baseline system usually simplest implementation think 
instance part ofspeech tagging baseline system assigns frequent tag particular word attempting contextual disambiguation 
having baseline system allows point determine difficult task baseline system performs task may easy case need license commercial system 
system better baseline task easy called baseline system really trivial system give pause licensing 
useful gauge upper lower bounds performance 
upper bound usually human performance task whilst lower bound chance 
baseline performance lies extremes 
component evaluation error analysis evaluating third party system possible black box evaluation system just evaluated performance 
developing system combining systems possible design evaluation metrics piece system 
allow weak points identified expose parts effective upgrade 
performing component evaluation evaluating system fruitful see exactly cases getting wrong try identify 
performing error analysis useful lead indications system may improved 
performing error analysis stage development snlp system linguistics background comes especially handy 
able inspect types errors able generalize linguistic features extremely useful subsequent redesign statistical model system 
applications snlp just traditional natural language processing computational linguistics augmented probabilities 
applications naturally handled statistical techniques 
february february chris callison burch miles osborne relatively simple statistical methods place involved rule theories 
quickly review representative set applications snlp perspective 
part speech tagging early successes snlp part speech pos tagging 
basic task assign label set pos tags token encountered 
shows example sentence pos tags 
sentence parsed wall street journal tags penn tagset 
dt stores nns prp vbp may md vb sold vbn example sentence pos tags pos tagging useful nlp tasks especially information extraction shallow parsing full parsing 
ways tag sentences 
popular method take large corpus sentences marked tags penn treebank train model tagged sentences 
formally sentence associated tag sequence construct model distribution 
joint probability 
care assigning tags sentences construct model conditional probability 
typically hidden markov models hmms construct tagging models see speech chapter discussion hmms 
noted range methods possible 
current taggers operate token accuracy 
taggers built hand 
example samuelsson voutilainen argue manually built tagger competitive stochastic cousins 
manually creating tagger requires effort creating automatically assuming corpus exists 
pos tagging high accuracy 
number reasons 
closed class words frequent usually unambiguous 
open class words word distribution possible tags usually sharply peaked tags 
means situations possible tags 
context required disambiguate words usually words surrounding pos tags 
information local 
turn means see previously observed context know decision 
statistical natural language processing non english languages current taggers effective open question equally effective languages 
statistical parsing success assigning syntactic categories words interested seeing broad coverage parsing improved statistical means 
task considerably harder tagging sure grammar parses naturally occurring sentences parse sentences need select potentially thousands alternatives 
selection efficient 
rule natural language processing probably true say problems truly solved 
example alvey natural language tools grammar parse wall street journal grover 
parsers efficient parse coverage sentences tokens carroll 
developments rule parsing increased efficiency parsers lengths sentences effectively handle fairly short kiefer 
contrast rule deep parsers alternative vein developing shallower probabilistic parsers magerman weir collins charniak collins 
parsers usually contain grammars induced parsed treebanks penn treebank 
furthermore usually contain probabilistic component enables find best parse sentence near linear time 
systems easily capable parsing naturally occurring sentences 
combining stochastic methods linguistically motivated parsers 
example johnson 
showed broad coverage lfg parser maximum entropy techniques select best parse 
osborne showed dcg parser similar techniques 
text classification moving documents useful task text classification 
means assigning text may book mail computer program label 
label meaning depending domain 
example electronic commerce labels may deal ordering products reviewing status orders authorship determination labels authors 
text classification turns relatively easy task 
usual february february chris callison burch miles osborne approach reduce text bag words order independent set words treat words vector annotated label text represents 
labeled vectors train machine learning classification algorithms yang liu 
treating document bag clearly throws away lot linguistic information 
abstraction reduces dimensionality problem number features task need tracked 
minimizing number dimensions training efficient improve performance relates problem called overfitting discuss section 
question answering task question answering moves simple document classification realm intelligent information retrieval 
question answering qa concerned retrieving short passages documents answer user question 
qa different simple web searching fully formed questions encode information type answer looked keyword queries 
example questions elected th president united states 
th president united states elected 
indicate user looking name date keyword query th president united states elected 
qa process usually involves different stages question analyzed answer type candidate documents marked named entities correspond answer type short passages selected ranked probability answering question 
tasks performed snlp framework 
example 
maximum entropy model component perform answer type classification 
leidner callison burch propose answer ranking evaluation qa systems done automatically large collection frequently asked question faq pages gathered web 
pages provide potentially valuable source information statistical question answering system constitute ready source questions paired answers 
having hand craft rules question answering system components system learned automatically corpus assembled internet resources 
machine translation statistical natural language processing unsurprisingly machine translation arguably hardest task nlp statistical formulation brown knight 
suppose translating english french 
statistical translation take view english string possible translation french string assign pair strings probability interpret probability translator produce translation 
french string job machine translation system find english string possible english strings greatest 
estimate brown 
take view translation process string re writing string source sentence expanded zero words target language word translates particular target word words translated target language rearranged reflect syntax language 
string re writing may simplistic way viewing translation advantage probabilities estimated available data takes form bilingual sentence aligned corpora canadian hansard 
statistical machine translation taken directions 
augment brown 
translation model linguistically sophisticated information 
instance yamada knight formulate syntax translation model show produces better translation results english japanese re writing method 
vein research coping scarce linguistic resources 
statistical machine translation learned parallel corpora tend language pairs extensive parallel corpora 

examines human beings cope scarce translation resources seeing manage translate new language english examples 
callison burch applies weakly supervised learning machine translation way bootstrapping parallel corpora new language pairs shows bilingual corpus consisting machine translated sentences achieves translation accuracy human translated corpus containing sentence pairs 
discussion snlp exciting field brought linguists statisticians machine learning researchers 
result synergy february february chris callison burch miles osborne computational linguistics concentration data quantitatively testable theories 
flow ideas way machine learning community draws language domain source large hard problems worthy tackling 
large part success snlp enterprise due availability annotated data penn treebank example spawned large body research 
access annotated material significantly simplifies estimation task extent useful robust tools pos taggers probabilistic parsers routinely community 
useful tools argued relatively simple 
example progress broad coverage parsers linguistically sophisticated formalisms hpsg dramatic robust methods assigning logical forms utterances discourse 
reason relative simplicity current breed tools suitable annotated material sufficient quantities simply exist 
note tools argued performance maximum mileage annotated training material 
section data touched weakly supervised approaches training active learning 
methods directly address question creating annotated training material 
areas central concern researchers snlp near 
orthogonal question annotated material need better models language works 
example reasonable ideas language behaves probabilistic models discourse varies really know language changes time domains 
language usually assumed come source modeled stationary 
moving non stationary language models current state art long time come 
simply throwing larger quantities training material bad models correct curran osborne 
need develop sophisticated models deal change language 
linguists key role play 
chapter sketched field snlp touched current state art problems need tackled fully analyze naturally occurring language 
progress field comes linguists computer scientists statisticians machine learning researchers 
cross disciplinary nature natural language exciting 
having better understanding tools trade statistics precise models language allow progress field 
reading textbooks cover snlp manning sch tze foundations statistical natural language processing comprehensive treatment field 
jurafsky martin speech language processing covers natural language processing broadly give significant treatment statistical methods including speech processing 
textbooks provide introductions relevant disciplines focus snlp tom mitchell machine learning degroot schervish probability statistics 
abney steve 

statistical methods linguistics 
klavans resnik eds balancing act 
cambridge ma mit press 
abney steven 
stochastic attribute value grammars 
computational linguistics 
jan michael kevin knight john lafferty dan melamed franz josef och david noah smith david yarowsky 

statistical machine translation 
final report jhu summer workshop 
ulrich ulf kevin knight philipp daniel marcu kenji yamada 

translating scarce resources 
proceedings national conference artificial intelligence aaai 
blum avrim tom mitchell 

combining labeled unlabeled data training 
proceedings workshop computational learning theory 
morgan kaufmann 
brill eric jun wu 

classifier combination improved lexical disambiguation 
eds proceedings sixth annual meeting association computational linguistics seventeenth international conference computational linguistics pages 
san francisco california morgan kaufmann publishers 
brown peter stephen della pietra vincent della pietra robert mercer 

mathematics machine translation parameter estimation 
linguistics 
callison burch chris 

training statistical machine translation 
master thesis university edinburgh 
february february chris callison burch miles osborne carroll john 

practical unification parsing natural language 
ph thesis university cambridge 
charniak eugene 

maximum entropy inspired parser 
tech 
rep cs department computer science brown university 
charniak eugene 

immediate head parsing language models 
meeting association computational linguistics pages 
chelba frederick jelinek 

exploiting syntactic structure language modeling 
eds proceedings sixth annual meeting association computational linguistics seventeenth international conference computational linguistics pages 
san francisco california morgan kaufmann publishers 
chen stanley joshua goodman 

empirical study smoothing techniques language modeling 
joshi palmer eds proceedings fourth annual meeting association computational linguistics pages 
san francisco morgan kaufmann publishers 
chen stanley ronald rosenfeld 

gaussian prior smoothing maximum entropy models 
tech 
rep cmu cs carnegie mellon university 
collins michael 

discriminative reranking natural language parsing 
icml collins michael james brooks 

prepositional attachment backed model 
church eds proceedings third workshop large corpora pages 
somerset new jersey association computational linguistics 
collins michael yoram singer 

unsupervised models named entity classification 
proceedings conference empirical methods natural language processing 
collins michael john 

new statistical parser bigram lexical dependencies 
th annual meeting association computational linguistics 
university california santa cruz california usa 
david yarowsky 

bootstrapping multilingual part speech tagger person day 
proceedings conll pages 
taipei taiwan 
curran james miles osborne 

large corpus doesn yield reliable estimates 
proceedings conll pages 
taipei taiwan 
degroot morris mark schervish 

probability statistics 
addison wesley 
dietterich thomas 
approximate statistical test comparing supervised classification learning algorithms 
neural computation 
dietterich thomas 
experimental comparison methods constructing ensembles decision trees bagging boosting randomization 
machine learning 
ghani 

error correcting codes text classification 
langley ed proceedings icml th international conference machine learning pages 
stanford morgan kaufmann publishers san francisco 
grover claire ted briscoe john carroll bran boguraev 

alvey natural language tools grammar th release 
tech 
rep university cambridge computer laboratory 
henderson john 
exploiting diversity natural language processing 
aaai iaai page 
abraham martin franz wei jing zhu adwait ratnaparkhi 

ibm statistical question answering system 
th text retrieval conference 
gaithersburg md joachims thorsten 

text categorization support vector machines learning relevant features 
dellec rouveirol eds proceedings ecml th european conference machine learning pages 
chemnitz de springer verlag heidelberg de 
johnson 
optimality theoretic lexical functional grammar 
proceedings th annual cuny conference human sentence processing 
johnson mark 

joint conditional estimation tagging parsing models 
meeting association computational linguistics pages 
johnson mark stuart geman stephen cannon chi stephan riezler 

estimators stochastic unification grammars 
th annual meeting acl 
jean claude van noord eds 

robustness language speech technology vol 
text speech language technology 
kluwer academic publishers 
jurafsky daniel james martin 

speech language processing 
new jersey prentice hall 
kiefer krieger 

carroll malouf 

bag useful techniques efficient robust parsing 
proceedings th annual meeting association computational linguistics pages 
knight kevin 

statistical mt tutorial 
prepared jhu summer workshop 
lafferty john andrew mccallum fernando pereira 

conditional random fields probabilistic models segmenting labeling sequence data 
proc 
th international conf 
machine learning pages 
morgan kaufmann san francisco ca 
february february chris callison burch miles osborne leidner jochen chris callison burch 

evaluating question answering systems faq answer injection 
th annual research colloquium 
edinburgh 
magerman david carl weir 

efficiency robustness accuracy chart parsing 
proceedings th acl university delaware newark delaware pages 
malouf robert 

comparison algorithms maximum entropy parameter estimation 
proceedings conll pages 
taipei taiwan 
manning christopher hinrich schutze 

foundations statistical natural language processing 
mit press 
marcus mitchell beatrice mary ann marcinkiewicz 

building large annotated corpus english penn treebank 
computational linguistics 
mitchell tom 
machine leaning 
new york hill 
nigam kamal ghani 

understanding behavior cotraining 
proceedings ninth international conference information knowledge management 
osborne miles 

estimation stochastic attribute value grammars informative sample 
th international conference computational linguistics 
saarbr cken 
ratnaparkhi 
maximum entropy models natural language ambiguity resolution 
ph thesis university pennsylvania 
resnik philip 

mining web bilingual text 
proceedings th annual meeting association computational linguistics 
salomon jesper simon king miles osborne 

phone classification support vector machines 
th international conference spoken language processing 
denver colorado 
samuelsson christer voutilainen 

comparing linguistic stochastic tagger 
cohen wahlster eds proceedings fifth annual meeting association computational linguistics eighth conference european chapter association computational linguistics pages 
somerset new jersey association computational linguistics 
steedman mark steven baker stephen clark crim julia rebecca hwa miles osborne paul anoop sarkar 

bootstrapping statistical parsers small datasets 
proceedings th european chapter association computational linguistics 
budapest 
yamada kenji kevin knight 

syntax statistical translation model 
proceedings th annual meeting association computational linguistics pages 
toulouse france 
yang yiming xin liu 

re examination text categorization methods 
nd annual international sigir pages 
berkeley 
yarowsky david 

unsupervised word sense disambiguation rivaling supervised methods 
proceedings rd annual meeting association computational linguistics 
february february 
