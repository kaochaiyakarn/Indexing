distributing streaming media content cooperative networking venkata padmanabhan helen wang philip chou microsoft research sripanidkulchai carnegie mellon university april technical report msr tr microsoft research microsoft microsoft way redmond wa distributing streaming media content cooperative networking venkata padmanabhan helen wang philip chou sripanidkulchai microsoft research carnegie mellon university microsoft com cs cmu edu discuss problem distributing streaming media content live demand large number hosts scalable way 
set context traditional client server framework 
speci cally consider problem arises server overwhelmed volume requests clients 
solution propose cooperative networking coopnet clients cooperate distribute content alleviating load server 
discuss proposed solution detail pointing interesting research issues arise preliminary evaluation traces gathered busy news site ash crowd occurred september 

years topic content distribution 
largely fallen categories infrastructure content distribution peer peer content distribution 
infrastructure content distribution network cdn akamai complements server traditional client server framework 
employs dedicated set machines store distribute content clients behalf server 
dedicated infrastructure including machines networks links engineered provide high level performance guarantees 
hand peer peer content distribution relies clients host content distribute clients 
model replaces complements clientserver framework 
typically central server holds content 
examples content distribution systems include napster gnutella 
discuss cooperative networking coopnet approach content distribution combines aspects infrastructure peer peer content distribution 
focus distributing streaming media content live demand 
infrastructure content distribution seek complement replace traditional client server framework 
speci cally consider problem arises server overwhelmed volume requests clients 
instance news site may overwhelmed large ash crowd caused expanded version appearing acm nossdav 
information please visit coopnet project web page www research microsoft com projects coopnet 
event widespread interest sports event earthquake 
home computer birthday party live friends family overwhelmed small number clients limited network bandwidth 
fact large volume data relatively high bandwidth requirement associated streaming media content increases likelihood server overwhelmed general 
server overload cause signi cant degradation quality streaming media content received clients 
coopnet addresses problem having clients cooperate distribute content alleviating load server 
case demand content clients cache audio video clips viewed past 
period overload server redirects new clients clients downloaded content previously 
case live streaming clients form distribution tree rooted server 
clients receive streaming content server turn stream peers 
key distinction coopnet pure systems gnutella coopnet complements replaces client server framework web 
server hosts content directly serves clients 
coopnet invoked server unable handle load imposed clients 
presence central server simpli es task locating content 
contrast searching content pure system entails expensive distributed search :10.1.1.105.3673
individual clients may participate coopnet short period time say just minutes contrast longer participation times reported systems napster gnutella :10.1.1.160.7346
instance case live streaming client may tune minutes time may willing help distribute content 
client tunes may longer willing participate coopnet 
calls content distribution mechanism robust interruptions caused frequent joining leaving individual peers 
address problem coopnet employs multiple description coding mdc 
streaming media content live demand divided multiple sub streams mdc sub stream delivered requesting client di erent peer 
improves robustness helps balance load peers 
rest organized follows 
section discuss related 
section discuss operation coopnet live demand content outline multiple description coding 
section traces ash crowd occurred september evaluate coopnet performed live demand content 
section 
related noted section areas related infrastructure cdns peer peer systems 
cdns akamai employ dedicated network thousands machines distributed locations leased links inter connecting serve content behalf servers 
client request arrives streaming media content cdn redirects client nearby replica server 
main limitation cdns cost scale appropriate large commercial sites cnn msnbc 
second issue unclear cdn fare face large ash crowd causes simultaneous spike trac sites hosted cdn 
peer peer systems napster gnutella depend little dedicated infrastructure implicit assumption individual peers participate signi cant length time instance reports median session duration hour napster gnutella :10.1.1.160.7346
contrast coopnet seeks operate highly dynamic situation ash crowd individual client may participate minutes 
disruption cause especially challenging streaming media compared static le downloads primary focus napster gnutella 
short lifetime individual nodes poses challenge distributed search schemes chord pastry tapestry :10.1.1.105.3673
application level multicast almi system multicast scattercast directly relevant live streaming aspect coopnet :10.1.1.19.7440
coopnet bene ecient tree construction algorithms developed previous 
focus real traces evaluate ecacy coopnet 
view complementing existing application level multicast 
consider demand streaming case quite application level multicast framework 
existing distributed streaming directly relevant coopnet 
key distinction focus packet loss caused node arrivals departures signi cant highly dynamic environment 
traces september ash crowd able evaluate issue realistic setting 
systems closest spirit 
coopnet attempt deliver streaming content peer peer approach 
di ers coopnet couple ways 
uses single distribution tree vulnerable disruptions due node departures 
second tree management algorithm nodes orphaned departure parent bounced multiple potential parents settling new parent 
contrast coopnet uses centralized protocol sec napster central servers hold indices content 
tion enables quicker repairs 
hard speci comparison absence published information 

cooperative networking coopnet section details coopnet applies distribution streaming media content 
rst consider live streaming case discuss analyze multiple description coding mdc distribution tree management 
turn demand streaming case 
live streaming live streaming refers synchronized distribution streaming media content clients 
content may truly live pre recorded 
multicast natural paradigm distributing content 
ip multicast widely deployed especially inter domain level coopnet uses application level multicast 
distribution tree rooted server formed clients members 
node tree transmits received stream children unicast 
outdegree node constrained available outgoing bandwidth node 
general degree root node server larger nodes server higher bandwidth individual client nodes 
issue peers coopnet far dedicated servers 
ability willingness participate coopnet may time 
instance client participation may terminate user tunes live stream 
fact user tuned live stream coopnet related activity machine may scaled stopped immediately user initiates unrelated network communication 
machines crash disconnected network 
single distribution tree departure reduced availability node severe impact descendants 
descendants may receive stream tree repaired 
especially problematic node arrivals departures may quite frequent ash crowd situations 
reduce disruption caused node departures advocate having multiple distribution trees spanning set nodes transmitting di erent mdc description tree 
diminish chances node losing entire stream temporarily departure node 
discuss section 
distribution trees need constantly maintained new clients join existing ones leave 
section advocate centralized approach tree management exploits availability server node coupled client cooperation greatly simplify problem 
multiple description coding mdc multiple description coding method encoding audio video signal separate streams descriptions subset descriptions received decoded signal distortion respect original signal commensurate number descriptions received descriptions received lower distortion higher quality enc de dec de enc de dec de base layer multiple description coding 
layered coding 
bits di 

packet packet packet packet packet 
rs 
bit stream priority encoded packetization group frames gof 
packets recover initial rm bits bit stream gof 
reconstructed signal 
di ers layered coding mdc subset descriptions decodable layered coding nested sequence subsets decodable illustrated 
extra exibility mdc incurs modest performance penalty relative layered coding turn incurs slight performance penalty relative single description coding 
simple mdc system video 
original video picture sequence subsequences putting mth picture im mth subsequence subsequences independently encoded form descriptions 
subset descriptions decoded pictures reconstruct video sequence frame rate essentially proportional number descriptions received 
sophisticated forms multiple description coding investigated years highlights 
overview see 
particularly ecient practical system layered audio video coding reed solomon coding priority encoded transmission optimized bit allocation 
system audio video signal partitioned groups frames group having duration second 
gof independently encoded error protected packetized packets shown 
packets received initial rm bits bit stream gof recovered re layered coding known embedded progressive scalable coding 
pkt pkt pkt pkt pkt pkt 
description stream description stream description stream gof gof gof 
pkt pkt pkt construction mdc streams packetized 
distortion rm 
rm consequently 
rm 
packets equally important number received packets determines reconstruction quality gof 
expected distortion rm probability packets received 
operational distortion rate function expected distortion minimized simple procedure adjusts rate points rm subject constraint packet length 
sending mth packet gof mth description entire audio video signal represented descriptions description sequence packets transmitted rate packet gof illustrated 
simple matter generate optimized descriptions assuming signal coded layered codec 
coopnet analysis quality multiple failures consider multiple description coding achieves robustness coopnet 
suppose server encodes av signal descriptions described transmits descriptions di erent distribution trees rooted server 
distribution trees conveys description destination hosts 
ordinarily destination hosts receive descriptions 
destination hosts fail leave session hosts descendents failed hosts mth distribution tree receive mth description 
number descriptions particular host receive depends location tree relative failed hosts 
speci cally host receive mth description ancestors mth tree fail 
happens probability number host ancestors probability host fails assuming independent failures 
hosts placed random sites tree unconditional probability host receive mth description average hosts tree 
number descriptions particular host receive randomly distributed binomial distribution large fraction descriptions received approximately gaussian mean variance 
seen shows bars distribution various values 
gure compute assumed balanced binary trees nodes probability host failure 
note grows large performance slowly degrades depth tree grows log distribution optimize multiple description code choosing rate points rm snr db line distribution bars function number descriptions received probability host failure 
minimize expected distortion rm subject packet length constraint 
shows lines quality associated measured snr db log rm function number received descriptions gure compute rate points rm assumed operational distortion rate function asymptotically typical source variance expressed bits symbol assumed packet length constraint 
coopnet analysis quality single failure time takes repair trees called repair time 
hosts fail repair time average length time host participates session repair times 
number hosts small compared repair times may pass single failures 
case time hosts receive descriptions quality excellent 
degradation occurs single host fails 
may preferable optimize mdc system minimizing distortion expected repair interval single host fails minimizing expected distortion time 
analyze case suppose single host fails randomly 
remaining host receive mth description failed host ancestor host mth tree 
happens probability number ancestors host hosts place random sites tree unconditional probability host receive mth description average 
number descriptions particular host receive randomly distributed binomial distribution 
equivalently expected number hosts receive descriptions failure distribution optimize multiple description code failure single host 
illustrates distribution corresponding optimized quality function number descriptions received 
note increases xed distribution gaussian 
implication expected number hosts receive descriptions snr db line distribution bars function number descriptions received failure single host 
decreases 
case expected number hosts receive fewer descriptions decreases resulting increase quality average 
increases xed performance nearly perfect log goes 
large increasingly dicult repair trees second failure occurs 
analyses analyses extended ary trees 
dicult see ary trees log nodes height performance binary tree nodes 
node large degree host large uplink bandwidth larger populations handled 
interestingly analysis applies 
host devote uplink bandwidth downlink video bandwidth typically case modem users descriptions distributed peer peer arranging hosts chain bucket brigade 
shown order hosts chain random independent description single failure number hosts receiving descriptions binomially distributed parameters holds suitable smaller larger may possible repair chains failures occur 
fact goes nity probability host receives descriptions goes zero 
section proposed optimizing mdc system unconditional distribution derived averaging trees hosts 
set trees distribution number received descriptions varies widely set hosts function upstream connectivity 
optimizing mdc system unconditional distribution minimizing expected distortion host minimizing sum expected distortions hosts equivalently minimizing expected sum distortions hosts 
tree management discuss problem constructing maintaining distribution trees face frequent node arrivals departures 
con icting goals tree management algorithm 
short wide tree trees short possible minimize latency path root deepest leaf node minimize probability disruption due departure ancestor node 
short tree balanced wide possible degree node bandwidth allow 
making degree large may leave little bandwidth non coopnet higher priority trac emanating node 
interference due trac cause high packet loss rate coopnet streams 

eciency versus tree diversity distribution trees ecient structure closely re ect underlying network topology 
instance wish connect nodes located new york ny san francisco sf los angeles la structure ny sf la far ecient sf ny la 
denotes parent child relationship 
striving eciency may interfere equally important goal having diverse distribution trees 
ectiveness mdc distribution scheme described section depends critically diversity distribution trees 

quick join leave processing node joins leaves quick 
ensure interested nodes receive streaming content quickly possible case join minimal interruption case leave 
quick processing joins leaves may interfere eciency balanced tree goals listed 

scalability tree management algorithm scale large number nodes correspondingly high rate node arrivals departures 
instance extreme case ash crowd msnbc september average rate node arrivals second peak rate second 
requirements mind describe approach tree construction management 
rst describe basic protocol discuss optimizations 
basic protocol exploit presence server node build simple ecient protocol process node joins leaves 
centralized argue protocol scale face extreme ash crowd situations occurred september 
despite ash crowd server overloaded burden distributing content shared peers 
centralization simpli es protocol greatly consequently joins leaves quick 
general criticism centralization introduces single point failure 
context coopnet point centralization server source data 
source server fails may really matter tree management breaks 
recall section goal coopnet complement replace client server system 
server full knowledge topology distribution trees 
new node wishes join system rst contacts server 
new node informs server available network bandwidth serve downstream nodes 
server responds list designated parent nodes distribution tree 
designated parent node tree chosen follows 
starting server way tree get level nodes necessary spare capacity primarily network bandwidth serve parent new node 
server new parent sucient spare capacity early stages tree construction 
server picks node random designated parent new node 
top procedure ensures short largely balanced tree 
randomization helps trees diverse 
receiving server message new node sends concurrent messages designated parent nodes get linked child distribution tree 
terms messaging costs server receives message sends 
designated parent receives message sends 
new node sends receives messages number mdc descriptions distribution trees 
node departures kinds graceful departures node failures 
case departing node informs server intention leave 
distribution tree server identi es children departing node executes join operation child implicitly subtree rooted child top procedure described 
messaging cost server sends receives number children departing node ith distribution tree 
note cost somewhat lower general children may common multiple trees 
child sends receives messages 
reduce messaging load server determination designated parent child tree leave node departing node available convey information child 
case server send receive just message 
node failure corresponds case departing node leaves suddenly unable notify server node departure 
may happen computer crashing turned disconnected network 
general approach dealing quality degradation due packet loss node failure special case packet loss rate experienced descendants failed node 
node monitors packet loss rate experiencing distribution tree 
packet loss rate reaches unacceptable level threshold needs ne tuned research node contacts parent check parent experiencing problem 
source problem network congestion node failure upstream parent node leaves parent deal 
node sets suciently long timer take action case parent resolved problem reasonable period time 
parent experiencing problem respond ected node contact server execute fresh join operation subtree moved new location distribution tree 
optimizations discuss optimizations basic protocol 
rst optimization seeks distribution trees ecient discussed 
basic idea preferentially attach new node child existing node nearby terms network distance latency 
de nition nearby needs broad accomodate signi cant tree diversity 
trying insert new node server rst identi es suciently large subset nodes close new node 
randomized top procedure discussed section tries nd parent new node tree set nearby nodes 
procedure quite parents new node various distribution trees vicinity bene cial eciency viewpoint 
argue provides sucient diversity primary failure mode concerned node departures node failures 
matter parents may located vicinity metropolitan area 
determine network distance nodes procedure previous network distance estimation geographic location estimation overlay construction nding nearby hosts 
node determines network measuring network latency say ping set landmark hosts distributed landmark hosts suce practice 
coordinate node tuple 
dn number landmarks 
server keeps track coordinates nodes currently system information may need updated time time 
new node contacts server nds nearby nodes comparing coordinates new node existing nodes 
comparison involve computing distance coordinates nodes computing di erent distance metric manhattan distance simply comparing relative ordering various landmarks measured latency 
second optimization motivated observation bene cial stable nodes close root tree 
context stable nodes ones participate coopnet long duration network connectivity due competing trac applications 
having nodes close root tree bene descendants 
background process server identify stable nodes monitoring past behavior migrate tree 
research needed determine feasibility identifying stable nodes bene ts migrating nodes tree impact tree diversity 
feasibility centralized protocol main question regarding feasibility centralized tree management protocol server keep 
answer question consider september ash crowd msnbc arguably extreme ash crowd situation 
peak nodes system rate node arrivals departures second 
average numbers nodes arrivals departures second 
calculations assume number distribution trees number mdc descriptions average node children tree 
consider various resources bottleneck server focus impact tree management server memory store entire topology tree memory server need store pointers nodes system 
assuming pointer size bytes bit machine auxiliary data bytes node memory requirement kb 
trees memory requirement trees mb 
addition node server needs store network coordinates 
assuming dimensional vector delay values bytes additional memory requirement kb 
total memory requirement server mb trivial amount modern machine 
network bandwidth node departures expensive node arrivals focus departures 
server needs designate new parent distribution tree child departing node 
assuming nodes identi ed ip addresses bytes assuming ipv children tree average total amount data server need send kb 
departures second bandwidth requirement mbps 
small fraction network bandwidth large server site msnbc 
cpu node departure involves nding new set parents child departing node 
cpu cost roughly equal number children departing node times cost node insertion 
insert node server scan tree levels starting root reaches level containing nodes spare capacity support new child 
server picks node random new parent 
simple array data structure keep track nodes level tree free capacity cost picking parent random small constant 
number levels tree log number nodes system node insertion cost tree log 
average children node depth tree 
departure rate second result insertions second departures times children departing node times trees 
memory speed far lags cpu speed focus memory lookups insertion 
assuming ns memory cycle allowed memory accesses insertion sucient 
reason high rate churn may users discouraged degradation audio video quality caused ash crowd stay long 
position con rm case 
general centralized approach scaled terms cpu memory resources having cluster servers partitioning set clients set server nodes 
process benchmarking implementation con rm rough calculations 
distributed protocol centralized tree management protocol appears adequate large ash crowd situations experienced msnbc september clear limits scalability 
instance conceivable ash crowds streaming media content web cases large television audiences highly popular events hundreds millions billions clients 
centralized solution may break situation necessitating alternative approach tree management 
leverage distributed hash tables dhts chord pastry tapestry build construct maintain trees distributed fashion :10.1.1.105.3673
brie dhts provide scalable unicast routing framework peer peer systems 
multicast distribution tree constructed reverse path forwarding systems bayeux scribe :10.1.1.1.4196
construct multiple diverse distribution trees node assigned multiple ids tree 
number open research issues 
exist algorithms support node joins leaves dynamic behavior dhts poorly understood 
second unclear incorporate constraints limited node bandwidth dht framework 
systems pastry maintain multiple alternate routes hop 
easier construct multicast trees node capacity constraints 
demand streaming turn demand streaming refers distribution pre recorded streaming media content demand user clicks corresponding link 
streams corresponding di erent users synchronized 
server receives request starts streaming data response current load condition permits 
server overloaded say ash crowd sends back response including short list ip addresses clients peers downloaded part requested stream expressed willingness participate coopnet 
requesting client turns peers download desired content 
large volume streaming media content burden server terms cpu disk network bandwidth doing redirection quite minimal compared serving content 
believe redirection procedure help reduce server load orders magnitude 
procedure described similar apply static le content couple important di erences arising streaming nature content 
peer may part requested content instance user may stopped stream halfway skipped portions 
initial handshake peer client nds part requested content available peer accordingly plans requests peers missing content 
second issue live streaming case peers may fail depart scale back participation coopnet time 
contrast le download time sensitive nature streaming media content especially susceptible disruptions 
solution propose distributed streaming stream divided number substreams may served di erent peer 
substream corresponds description created mdc section 
distributed streaming improves robustness disruptions caused departure peer nodes network connectivity problems respect peers 
helps distribute load evenly peers 

performance evaluation performance evaluation coopnet simulations driven traces live demand content served msnbc september 
live streaming evaluate mdc live streaming design traces kbps live stream 
trace started gmt est lasted hour seconds 
trace characteristics shows time series number clients simultaneously tuned live stream 
peak number simultaneous clients exceeds 
average clients departing second 
unable de nitely explain dip mark possibly due glitch logging process 
shows distribution client lifetimes 
clients remain tuned live stream minute 
suspect short lifetimes users frustrated poor quality video stream ash crowd 
quality improved say coopnet relieve server client lifetimes may longer 
turn increase ectiveness coopnet 
effectiveness mdc evaluate impact mdc distribution section quality stream received clients face client departures 
departures clients receive mdc descriptions perceive full quality live stream 
conducted simulation experiments 
rst experiment construct completely random distribution trees repair interval client departure 
analyze stream quality received remaining clients 
random trees diverse uncorrelated improves ectiveness mdc distribution 
second experiment simulate tree management algorithm described section 
distribution trees evolved node arrivals departures recorded trace 
compare results experiments section 
detail conducted random tree experiment follows 
repair interval construct distribution trees corresponding descriptions mdc coder spanning nodes system interval 
number departing clients node arrivals departures time seconds number clients departures 
duration distribution minutes duration distribution 
table random tree experiment probability distribution descriptions received vs number distribution trees recorded repair interval randomly remove nodes tree compute number descriptions received remaining nodes 
perceived quality stream client determined fraction descriptions received client 
set distribution trees characterized parameters number trees equivalently descriptions maximum outdegree nodes tree degree root live streaming server 
degree node typically function bandwidth capacity 
root server tends larger degree bandwidth constrained clients 
random tree construction client assigned random degree subject maximum 
varied degree root number descriptions study impact received stream quality 
set repair time second investigate impact repair time section 
table shows number distribution trees affects fraction descriptions received expressed percentage 
compute distribution averaged client departures 
set maximum degree random tree experiment snr db line distribution bars function number descriptions received time seconds random trees multiple descriptions single description random tree experiment snr time mdc sdc cases 
time instant compute average snr clients 
client root degree 
vary number descriptions 
column represents range values pair range number descriptions list average percentage clients receive level quality 
example rst table entry indicates descriptions clients receive descriptions descriptions 
number descriptions increases percentage clients receive descriptions decreases 
percentage clients corresponding small values decreases dramatically 
descriptions clients receive descriptions 
descriptions clients receive description 
shows corresponding snr 
compares snr time description case single description sdc case 
mdc demonstrates clear advantage sdc 
table shows root degree ects distribution descriptions received 
set number descriptions maximum degree client 
root degree increases distribution shows improvement 
shows snr probability distribution 
compared case nodes including root degree root degree shortens tree log means fewer ancestors nodes tree discussed section increases probability node receive particular description 
table random tree experiment probability distribution descriptions received vs root degree random tree experiment snr db line distribution bars function number descriptions received root degree table evolving tree experiment probability distribution descriptions received vs number distribution trees second experiment evolved distribution trees simulating tree management algorithm section 
set root server degree 
maximum degree client set 
table shows probability distribution descriptions received client departures 
shows corresponding snr 
results comparable random tree experiment 
suggests tree management algorithm able preserve signi cant tree diversity long period time hour case 
impact repair time evaluate impact time takes repair tree node departure 
clearly longer repair time greater impact ected nodes 
longer repair time increase chances nodes departing repair completed causing disruption 
divide time non overlapping repair intervals assume leaves happen interval 
compute fraction descriptions received averaged nodes quantity discussed section 
section assume balanced binary tree times 
shows average number descriptions received function time di erent settings repair time seconds 
repair time second clients receive descriptions average 
second repair time fraction drops 
believe results encouraging practice tree repair done quickly especially tree management algorithm centralized section 
second evolving tree experiment snr db line distribution bars function number descriptions received average fraction descriptions received various repair times 
repair interval permit multiple round trips server nodes ected repair children departed node 
demand streaming evaluate potential coopnet case ondemand streaming 
goals evaluation study ects client cooperation reduction load server additional load incurred cooperating peers amount storage provided cooperating peers likelihood cooperating proximate peers improve performance 
cooperation protocol simulations server redirection 
server maintains list ip addresses url coopnet clients contacted 
get content client initially sends request server 
client willing cooperate server redirects request returning short list ip addresses coopnet clients requested le 
turn client contacts coopnet peers arranges retrieve content directly 
peer may di erent portion le may necessary contact multiple peers content 
order select peer set peers distributed streaming download content peers run greedy algorithm picks peer longest portion le list returned server 
client retrieve content peer retrieves entire content server 
note server provides means discovering coopnet peers 
peers independently decide cooperate 
server maintains list ip addresses url returns list ip addresses redirection messages simulations 
traces collected msnbc ash crowd sep evaluation 
ash crowd started pm gmt am edt persisted rest day 
peak request rate orders magnitudes average 
report simulation results ash crowd pm pm gmt 
requests hour period 
requests time day server server coopnet clients coopnet average bandwidth server cooperating peers 
degree parallelism average bandwidth peers distributed streaming 
bandwidth active peers bps stream streams streams stream loaded distribution bandwidth active peers 
performance coopnet demand streaming 
successfully served average rate mbps mean session duration minutes 
unsuccessful requests analysis lack content session duration information 
bandwidth load evaluation load measured bandwidth usage 
model available bandwidth peers 
assume peers support full bit rate kbps kbps encoded stream 
place bound number concurrent connections peer 
practice nding peers sucient available bandwidth overloading peer important considerations investigating issues ongoing 
depicts bandwidth usage hour period systems traditional client server system coopnet system 
vertical axis average bandwidth horizontal axis time 
peaks pm pm new streams added server 
client server system server distributing content average mbps 
client cooperation reduce bandwidth orders magnitude average kbps 
result server available serve client requests 
average bandwidth contribution coopnet clients need system kbps 
average bandwidth contribution reasonably small peers actively serving content time 
nd typically peers active second 
average bandwidth contribution active coopnet peers need system high kbps average bandwidth active peers computed total number bits served total length peers active periods 
reduce load individual coopnet clients disjoint portions content retrieved parallel multiple peers distributed streaming section 
bandwidth requirement placed peer correspondingly reduced 
depicts average bandwidth contributed versus degree parallelism 
degree parallelism upper bound number peers parallel 
example clients retrieve content peers parallel simulation degree parallelism 
actual number peers parallel may depending peers provide content byte range needed client 
load active peer reduced degree parallelism increases 
degree parallelism peers serving content kbps 
bandwidth active peers depicted gure slightly reduced kbps 
large amount bandwidth required serve content pm pm uence average bandwidth 
cumulative distribution bandwidth contributed active coopnet peers depicted illustrates impact distributed streaming bandwidth utilization 
solid line represents amount bandwidth peers contribute degrees parallelism 
median bandwidth requirement kbps content streamed peer bps degrees parallelism 
bandwidth requirement imposed peer reduced degree parallelism increases 
reduction signi cant small portion peers contribute mbps degrees parallelism 
believe combination factors contribute wide range bandwidth usage greedy algorithm client uses select peers algorithm server uses select set ip addresses give clients 
better load distribution server run load aware algorithm redirects clients seen peers loaded terms network bandwidth usage 
order implement algorithm server needs know load individual peers 
peers constantly report current load status server 
report interval second simulations 
server caches xed size list ip addresses peers currently server list need send status updates 
information server selects loaded peers accessed url requesting client return redirection message 
algorithm replaces described earlier section server redirects clients peers re storage allocated peer bytes storage requirement coopnet peers 
seen 
clients greedy algorithm select peers 
nd new algorithm active clients serve content kbps 
dashed line depicts cumulative distribution bandwidth contributed coopnet clients load aware algorithm server 
simulation clients stream content peer degree parallelism 
part distribution similar observed server redirects request seen peers 
di erence lies tail distribution 
peers contributed kbps bandwidth server runs original algorithm compared server runs load aware algorithm 
addition total number active peers system doubles load aware algorithm 
nd client cooperation signi cantly reduces server load freeing bandwidth support client connections 
addition combination distributed streaming load aware algorithm server reduces load individual peers 
storage requirement order facilitate cooperation clients contribute storage caching content 
simulations peers cache streams downloaded entire duration simulation 
depicts cumulative distribution amount storage peer needs provide 
storage sizes range mb 
half peers store mb content peers store mb content 
storage requirement reasonable modern computers 
nearby peers look likelihood cooperating nearby peers 
finding nearby peers greatly increase eciency peer peer communications 
evaluation peers close belong bgp pre domain 
cluster ip addresses clients successfully received content hour trace bgp tables obtained router jan 
trace sampled randomly drawing minute windows 
look probability nding peers domain degree parallelism ranging 
sampling repeated window sizes minutes 
window minutes probability nding peer requested content belongs bgp pre cluster 
window size increases minutes probability slightly increases accordingly 
distributed streaming degree parallelism increases probability nding nearby peers decreases 
minute window probability nding peers peers bgp pre cluster low 
better understand small number ip addresses ects probabilities nding proximate peers clustered ip addresses entire hour trace including unsuccessful requests 
part probabilities higher reported successful requests 
finding proximate peer sucient available bandwidth part ongoing 
summary initial results suggest client cooperation improve system performance 
distributed streaming load aware server promising solutions reduce load individual peers improving robustness 

coopnet peer peer content distribution scheme helps servers tide crisis situations ash crowds 
focussed application coopnet distribution streaming median content live demand 
challenge clients may participate coopnet extended length time 
coopnet employs distributed streaming multiple description coding improve robustness distributed streaming content face client departures 
evaluated feasibility potential performance coopnet traces gathered msnbc ash crowd occurred september 
extreme event ash crowd standards traces helps stress test coopnet design 
results suggest coopnet able reduce server load significantly placing unreasonable burden clients 
live streams multiple independent distribution trees coupled mdc improves robustness signi cantly 
currently building prototype implementation coopnet streaming media distribution 
grateful steven ted dave roth providing msnbc streaming media logs september 
anonymous nossdav reviewers insightful comments 

bl omer edmonds luby sudan 
priority encoding transmission 
ieee trans 
information theory november 
chawathe 
scattercast architecture internet broadcast distribution infrastructure service ph dissertation university california berkeley december 
chu rao seshan zhang 
enabling conferencing applications internet overlay multicast architecture acm sigcomm august 
davis 
joint source channel coding image transmission lossy packet networks 
conf 
wavelet applications digital image processing denver august 
spie 
deshpande bawa garcia molina 
streaming live media peer peer network technical report stanford university august 
stanford edu pub goyal vetterli 
multiple description transform coding robustness erasures tight frame expansions 
proc 
int symp 
information theory page cambridge ma august 
ieee 
goyal 
multiple description coding compression meets network 
ieee signal processing magazine pages september 
shankar bhattacharjee 
finding close friends internet ieee icnp november 
krishnamurthy wang 
network aware clustering web clients acm sigcomm august 
lu pearlman 
ecient low complexity audio coder delivering multiple levels quality interactive applications 
proc 
workshop multimedia signal processing pages redondo beach ca december 
ieee 
mohr ladner 
unequal loss protection graceful degradation image quality packet erasure channels forward error correction 
ieee selected areas communications june 
mohr ladner 
approximately optimal assignment unequal loss protection 
proc 
int conf 
image processing vancouver bc september 
ieee 
nguyen zakhor 
distributed video streaming internet multimedia computing networking mmcn january 
ng zhang 
global network positioning acm sigcomm internet measurement workshop november 
padmanabhan sripanidkulchai 
case cooperative networking iptps march 
padmanabhan subramanian 
investigation geographic mapping techniques internet hosts acm sigcomm august 
padmanabhan wang chou sripanidkulchai 
distributing streaming media content cooperative networking acm nossdav may 
shi verma waldvogel :10.1.1.19.7440
almi application level multicast infrastructure usits march 
pearlman 
kim xiong 
embedded video subband coding 
editor wavelet image video compression 
kluwer 
puri ramchandran 
multiple description source coding forward error correction codes 
proc 
asilomar conference signals systems computers asilomar ca october 
ieee 
ratnasamy francis handley karp shenker 
scalable content addressable network acm sigcomm august 
rowstron druschel 
storage management caching past large scale persistent peer peer storage utility acm sosp october 
rowstron :10.1.1.1.4196
kermarrec castro druschel scribe design large scale event noti cation infrastructure ngc november 
saroiu gummadi gribble :10.1.1.160.7346
measurement study peer peer file sharing systems multimedia computing networking mmcn january 
stoica morris karger kaashoek balakrishnan :10.1.1.105.3673
chord scalable peer peer lookup service internet applications acm sigcomm august 
vaishampayan 
design multiple description scalar quantizers 
ieee trans 
information theory may 
vaishampayan 
design entropy constrained multiple description scalar quantizers 
ieee trans 
information theory january 
wang orchard reibman 
optimal pairwise correlating transforms multiple description coding 
proc 
int conf 
image processing chicago il october 
ieee 
wicker 
error control systems digital communication storage 
prentice hall 
zhao kubiatowicz joseph 
tapestry infrastructure fault resilient wide area location routing technical report ucb csd university california berkeley april 
zhuang zhao joseph katz kubiatowicz 
bayeux architecture scalable fault tolerant wide area data dissemination acm nossdav june 
www com publically available route server telnet ner routes net 

www com 
