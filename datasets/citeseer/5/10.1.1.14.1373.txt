learning implicit user interest hierarchy context personalization kim department computer sciences florida institute technology melbourne fl usa fit edu provide robust context personalization desire extract continuum general long term specific short term interests user 
proposed approach learn user interest hierarchy uih set web pages visited user 
devise divisive hierarchical clustering algorithm group words topics hierarchy general interests represented larger set words 
web page assigned nodes hierarchy processing learning predicting interests 
approach analogous building subject taxonomy library catalog system assigning books taxonomy 
approach need user involvement learns uih implicitly 
furthermore allows original objects web pages assigned multiple topics nodes hierarchy 
focus learning uih set visited pages 
propose similarity functions dynamic threshold finding methods evaluate resulting hierarchies meaningfulness shape 
categories subject descriptors information storage retrieval information search retrieval clustering information filtering 
general terms algorithms 
keywords user interest hierarchy user profile concept clustering clustering algorithm 

user browses web different times accessing pages pertaining different topics 
example looking research papers time information conference travel 
user permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
iui january miami florida usa 
copyright acm 
philip chan department computer sciences florida institute technology melbourne fl usa pkc cs fit edu exhibit different kinds interests different times provide different contexts underlying user behavior 
different kinds interests motivated kind interest higher abstraction level computer science research example 
user possess interests different abstraction levels higher level interests general lower level ones specific 
furthermore general interests sense correspond longer term interests specific interests correspond shorter term interests 
browsing session general interests back mind specific interests current foci 
news generates long term short term model model continuum long term short term interests :10.1.1.44.8942
believe identifying appropriate context underlying user behavior important accurately pinpointing interests 
web static new documents new words phrases created day 
clustering methods cluster objects documents 
representation inadequate dynamic environment web 
consider librarian form taxonomy subjects books library 
identify subject book cluster books bases subject 
books categorized taxonomy 
stc rely fixed vector word features clustering documents 
similar approach clustering documents cluster features documents documents assigned clusters 
propose model general long term specific short term interests concept hierarchy called user interest hierarchy uih 
resulting hierarchy uih build page interest estimator pie providing context :10.1.1.35.2866
cluster uih associated documents positive examples learning pie 
constructed uih corresponding learned pie estimating interest new document 
current clustering methods generate clusters possess key characteristics desire uih 
search engines sensitive user interest 
improved interface user rank results user profile 
uih represents user specific general interests help rank results returned search engine 
pages match specific interests receive higher score match general interests 
furthermore uih provides context disambiguate words multiple meanings different contexts 
example java mean programming language coffee uih learned user reading computer science related pages 
helps user searching relevant pages web 
common obvious solution building uih user specify interests explicitly 
explicit approach includes disadvantages time effort specifying interests 
user interest may change time 
alternatively implicit approach identify user interests inference 
leaf nodes uih generated algorithm represent list specific short term user interests 
internal nodes represent general longer term interests 
main objective research build uih capture general specific interests user involvement implicitly 
devise divisive hierarchical clustering algorithm constructs hierarchy supports overlapping clusters original objects web pages case 
note clustering web pages objectives overlapping property allows associate web page potentially multiple topics 
believe approach significant benefits possesses interesting challenges 
main contributions characterization user interest hierarchy algorithm constructs uih similarity functions dynamic threshold finding methods evaluation techniques real data collected departmental web server 
rest follows section discusses related clustering algorithms building user interest profiles section introduces user interest hierarchies uih section details approach building implicit uih section describes experiments section analyzes results experiments section summarizes findings suggests possible 

related research agglomerative bottom hierarchical clustering algorithms initially put object cluster repeatedly merge similar clusters resulting tree shape structure contains clustering information different levels 
merges usually binary merging entities clusters initial data points 
parent forced children hierarchy 
divisive top hierarchical clustering algorithms similar agglomerative ones initially objects start cluster repeatedly split 
splits usually binary usual stopping criterion desired number clusters 
divisive algorithm necessarily generate binary splits uses minimum cluster size stopping criteria 
partitioning clustering algorithms means algorithm initially create partitioning clusters 
initial clusters iteratively refined achieve final clustering clusters 
major drawback approach number clusters specified input parameter perkowitz developed method automatically determine value ran means algorithm multiple times starting large value gradually decreasing 
able efficiently determine value clustering web pages :10.1.1.27.2889
algorithm needs cluster strongly connected words means algorithm divides words clusters removing weak relations 
cobweb incremental conceptual clustering algorithm 
cluster records probability attribute value probabilities updated time object added 
category utility determine child clusters generated graph method different similarity function 
build user interest profiles web personalization richardson domingos enhanced pagerank intelligent web surfer 
method collects relevant web pages queries probabilistically combined page contents link structure 
research performed method group web pages distinct topics list authoritative informative web pages topic 
similarity metric incorporates comprehensive information regarding text hyperlink structure citation unsupervised clustering method spectral graph partitioning normalized cut 
method concerned text allows overlapping clusters 
news agent called news developed billsus pazzani learns stories news user interested :10.1.1.44.8942
news agent uses multi strategy machine learning approach create separate models user short term long term interests 
news approach model continuum long term short term interests 
syskill webert predefined profile significantly increases classification accuracy previously unseen web pages 
emphasize importance user profile 
perkowitz etzioni introduced concept learning algorithm extracts concepts set data :10.1.1.27.2889

user interest hierarchy user interest hierarchy uih organizes user general specific interests 
root uih general longer term interests represented larger clusters words leaves specific shorter term interests represented smaller clusters words 
generate uih user clustering algorithm details sec 
accepts set web pages visited user input 
words web page ignore link image information 
web pages stemmed filtered ignoring common words listed list 
table sample data set 
numbers left represent individual web pages content words stemmed filtered list 
words web pages represented uih shown 
cluster node represent conceptual relationship example perceptron ann italic categorized belonging neural network algorithms id bold node 
words nodes mutually related words machine learning 
set mutual words machine learning performs role connecting italic bold words sibling clusters forms parent cluster 
illustrate notion dashed box 
table sample data set page content ai machine learning ann perceptron ai machine learning ann perceptron ai machine learning decision tree id ai machine learning decision tree id ai machine learning decision tree hypothesis space ai machine learning decision tree hypothesis space ai searching algorithm bfs ai searching algorithm dfs ai searching algorithm constraint reasoning forward checking ai searching algorithm constraint reasoning forward checking ai machine learning ann perceptron decision tree id hypothesis space searching algorithm bfs dfs constraint reasoning forward checking machine learning ann perceptron decision tree id hypothesis ann perceptron decision tree id hypothesis searching algorithm bfs dfs constraint reasoning forward checking constraint reasoning forward checking sample user interest hierarchy 
approach desire learn hierarchy topics interests web pages visited user provide context personalization 
approach take generate hierarchy similar clustering pages pages may belong multiple clusters 
allow overlapping clusters pages clustering pages directly cluster words pages pages associated clusters subsequently 
directly clustering original objects web pages cluster features words objects objects assigned clusters features cluster 
clustering similarity distance features relationship objects 
consequently objects clustered possessing similar related features object may belong multiple clusters 
challenging step initial hierarchical clustering features primary focus devising evaluating algorithms step 
divisive hierarchical clustering algorithm recursively partitions words smaller clusters represent related words 
assume words occurring close window size related 
investigated similarity functions measure close words related 
investigated techniques dynamically locate threshold decides words strongly related 
words determined strongly related cluster different clusters 
subsections detail algorithm similarity functions threshold finding techniques choice window size minimum cluster size leaves 
algorithm algorithm divisive hierarchical clustering method called recursively divides clusters child clusters meets stopping conditions 
illustrates pseudo code hdc algorithm 
preparation clustering algorithm extract words web pages visited user filter list stem 
similarity function calculate strength relationship pair words 
build weighted undirected graph vertex representing word weight denoting similarity words 
related words appear document unrelated terms measure occurrence words document 
graph called clustering algorithm recursively partitions graph subgraphs called cluster represents sibling node resulting uih 
documents contain words cluster cluster 
note document terms different clusters document cluster 
partitioning step edges weak weights removed resulting connected components constitute sibling clusters consider cliques clusters computation required 
treat determining value considered strong weak clustering problem details sec 

recursive partitioning process stops stopping criteria satisfied 
criterion current graph connected components weak edges removed 
second criterion new child cluster formed number words cluster falls predetermined threshold 
uih examples examples set web pages visited user 
function calculates closeness words 
function calculates cutoff value determining strong weak similarity values 
maximum distance number words related words calculating similarity value 

words extracted examples stemmed filtered list 

cluster distinct words information web page membership 
return cluster cluster 
cluster 
threshold 
similarity values threshold return 
remove weights threshold 
size 
return algorithm function takes similarity function details sec 
cluster window size parameters return similarity matrix window size affects far words terms number words considered related 
function takes threshold finding method similarity matrix parameters returns threshold 
similarity function method greatly influence clustering algorithm discussed 
similarity functions similarity function calculates strongly words related 
related words close unrelated words assume words occurring window size related 
simplify discussion assuming window size entire length document details sec 

words occur document 
aemi aemi augmented expected mutual information similarity function :10.1.1.35.2866
aemi enhanced version mi mutual information emi expected mutual information 
mi considers corner confusion matrix emi sums mi corners confusion matrix aemi sums supporting evidence subtracts counter evidence 
chan demonstrates aemi find meaningful multi word phrases mi emi :10.1.1.35.2866
concretely consider aemi events words 
probability document containing probability document having term defined likewise 
probability document containing terms probabilities estimated documents visited user 
aemi defined aemi log log term computes supporting evidence related second term calculates counter evidence 
running example table shows examples space aemi computed 
aemi value searching algorithm higher aemi value constraint 
table aemi values ab ab ab aemi searching algorithm space constraint ann perceptron aemi sp inspired information retrieval community enhance aemi incorporating component inverse document frequency idf similarity function 
document frequency word calculates number documents contain word 
words commonly documents usually informative characterizing content documents 
inverse document frequency reciprocal document frequency measures informative word characterizing content 
formulation sophisticated idf involves pair words word idf different name call function specificity sp 
estimate probability word occurrence documents just document frequency scale quantity 
desire give high sp values words probability approximately gradually decreasing values low values 
behavior approximated sigmoid function commonly smoother threshold function neural networks needs smoother 
shows shape sp function respect defined max 
choose larger probability sp conservative 
sp defined exp factor smoothes curve constants shift range 
new range slightly asymmetrical give small bias specific words 
instance ann perceptron sp ann sp 
sp similarity function aemi sp defined aemi sp 
usual range aemi sp 
scale sp similar range aemi divide sp 
example table aemi sp value searching algorithm lower value ann perceptron sp value ann higher aemi value lower 
searching algorithm ann perceptron sp function table aemi sp values aemi sp aemi sp similarity functions investigated existing similarity functions 
jaccard function defined word describes general topic expect occur quite appear different specific words 
sense general word connects specific related words 
desire general connecting words exist higher levels uih 
example ai general preferably appear lower levels 
running example jaccard value ai machine value ai search 
threshold pairs cluster ai may perform role connect machine search 
threshold ai remains child cluster machine similarity value threshold wrong decision 
hard child clusters means proper making hierarchical clusters 
min method defined min 
idea assign similarity value connected words connecting words go 
instance ai connects machine searching grouped cluster 
divided child clusters ai removed ai general 
min ai machine machine ai yielded relatively higher value average 
alternatively max function defined max distinguish value ai machine value machine learning pair stronger relationship 
jaccard min max generate desirable cluster hierarchies excluded experiments 
threshold finding methods fixed user provided threshold stc differentiate strong weak similarity values pair words examine methods dynamically determine reasonable threshold value 
weights weak similarity removed child clusters identified sec 

valley determine threshold find sparse region lot similar values 
frequency weights region low 
determine highest observed lowest desirable similarity values quantize interval regions equal width 
lowest desirable similarity value defined value achieved pair words occur document 
determine frequency values region 
generally lower weights higher frequency higher weights lower frequency 
frequency monotonically decreases regions higher weights picking region lowest frequency region highest weights 
unfortunately threshold high edges cut 
case threshold set average plus standard deviation biasing removing edges lower weights 
frequency decrease monotonically attempt identify widest steepest valley 
steepness measured slopes sides valley width regions valley covers 
regions equal width calculate quality valley freq freq successive regions sides valley 
widest steepest valley located identify threshold region constitutes bottom lowest frequency valley 
table distribution frequency number children region range freq 
children counted counted counted counted counted applicable example table valleys region quality region quality region quality 
widest steepest valley valley bottom regions 
identify threshold inside bottom region ignore frequency information find clusters similarity values 
case dimensional cluster task accomplished sorting weights splitting largest gap successive weights sec 

example table bottom zero frequency value threshold 
method selects threshold maximum child clusters generated 
ensures resulting hierarchy degenerate tall thin tree case methods 
preference stems fact topics general diverse detailed library catalog taxonomy typically short wide 
calculates number child clusters boundary value quantized regions 
guarantee selected threshold low method ignores half boundary values 
example table boundary value regions generates children selected threshold 
threshold finding methods threshold finding methods initially studied inferior valley included 
sorts values split largest gap successive values method valley method bottom largest valley 
motivated trying form clusters dimensional space 
initial experiments largest gap close largest observed value resulting tree usually small 
prevent threshold large top selects threshold retains values top 
method generates tall thin trees 
keep abnormally large values studied average select threshold standard deviation larger average 
combined valley method 
window size minimum size cluster window size parameter specifies maximum physical distance terms number words pair words consideration occurrence 
entire document length window size simplify discussion 
considering words occurring page related optimistic 
investigated smaller window sizes roughly cover paragraph words sentence words 
experiments window size significant difference 
minimum size cluster affects number clusters 
larger number clusters hierarchy comprehensible requires computation 
picked minimum size cluster 

experiments experiments conducted data obtained departmental web server 
analyzing server access log january april identified hosts accessed times months months 
filtered proxy crawler computer lab hosts identified single user hosts rooms local :10.1.1.35.2866:10.1.1.35.2866
yielded different users collected web pages visited 
number words web pages visited user average minimum number words maximum 
evaluate effectiveness algorithms analyzing generated hierarchies terms meaningfulness shape 
separate experiments conducted evaluate effectiveness different similarity functions threshold finding methods window sizes 

analysis evaluate uih qualitative quantitative measures 
qualitatively examine cluster hierarchies reasonably describing topics meaningfulness 
quantitatively measure shape cluster trees calculating average branching factor abf 
abf defined total number branches non leaf nodes divided number non leaf nodes 
categorized meaningfulness fair bad 
leaf clusters specific meaning non leaf clusters hard interpret due size evaluated leaf clusters meaningfulness 
measure interpretability usability checks properties leaf existence related words possibility combining words 
instance related words consider formal graphic taken cluster taken relationship words words classified class name cluster evaluated 
possibility combining words consider research activ class web cluster 
case meaning cluster estimated research activity research class regard cluster 
cluster marked words related possible composite phrases 
hard measure tried skeptical possible 
example suppose cluster test info cours avail appear 
case say test info cours info possible composite phrases test info conceptual meaning opinion count phrase 
cluster marked bad leaf cluster words big leaf cluster hard interpret 
fair leaf clusters bad 
categorized shape thin medium fat 
tree abf value tree considered thin tree marked tables 
abf value tree tree considered fat tree marked 
rest medium trees marked 
consider tree type conceptual tree marked subsumes type trees 
conceptual tree node child clusters words child cluster similar meaning 
instance explained section 
prefer tree represent meaningful concepts type trees desirable 
type trees degenerate imagine node hierarchy child hierarchy resembles list usually concepts organized undesirable 
evaluation criteria analyze different similarity functions sec 
threshold finding methods sec 
window sizes sec 

similarity function compared similarity functions aemi versus aemi sp 
fixed threshold finding method valley window size entire page tables illustrate results 
letter stands user means number leaf nodes 
means calculated dividing number leaves 
aemi yielded significantly meaningful leaf clusters aemi sp 
means groups significantly different test level 
methods generated trees shapes medium 
aemi generated conceptually related tree tree node child clusters contain words course titles represent concepts different classes 
aemi sp generated tree fat abf value 
threshold finding method compared threshold finding methods valley versus 
fixed similarity function aemi window size entire page 
tables illustrate results 
generated meaningful leaf clusters valley 
means groups statistically different test level 
tree shapes similar medium methods 
generally trees generated shorter indicates reduces number iterations algorithm dividing cluster early stage 
faster valley 
table combination aemi entire page user sum fair bad abf shape window size compared performance different window sizes entire page versus words paragraph length 
fixed similarity function aemi threshold finding method valley 
tables illustrate results 
window size entire page generated slightly meaningful clusters window size 
window size yields leaf clusters window size entire page 
clear window size produces meaningful clusters 
methods resulted medium trees 
window size generated thin tree 
tree table nodes root leaf 
table combination aemi sp entire page user sum fair bad abf shape table combination aemi valley entire page user sum fair bad abf shape table combination aemi words user sum fair bad abf shape 
concluding remarks create robust context personalization proposed learning user interest hierarchy uih represent continuum general long term specific short term interests set web pages visited user 
approach nonintrusive allows web pages associated multiple clusters topics 
proposed divisive hierarchical clustering algorithm evaluated data obtained users web server 
introduced similarity functions threshold finding methods clustering algorithm 
empirical results suggest aemi similarity function threshold finding method yield meaningful leaf clusters 
aemi generated interpretable uih analyze differences uih obtained various users large amounts web pages experiments 
window size significant difference window size recommended meaning paragraph usually cohesive document 
results experiments reported indicate stemmed words effective words 
minimum cluster size affected number leaf clusters size easy produce reasonable results 
till considered single words phrases may provide information topics compared words 
instance apple different meanings apple tree apple computer 
phrases aemi :10.1.1.35.2866
nodes child undesirable lead degenerate trees improve hdc ensure parents exist 
threshold determined child exists child added 
repeatedly apply threshold finding method child child produced 

acknowledgments members laboratory learning research llr comments 

bellegarda exploiting local global constraints multi span statistical language modeling ieee proc 
intl 
conf 
acoustics speech signal processing vol 

billsus pazzani hybrid user model news story classification conf :10.1.1.44.8942
user modeling 
chan non invasive learning approach building web user profiles kdd workshop web usage analysis user profiling :10.1.1.35.2866
fisher knowledge acquisition incremental conceptual clustering 
machine learning 
frakes baeza yates information retrieval data structures algorithms prentice hall 
han data mining concepts techniques san francisco morgan kaufmann publishers 
ding 
automatic topic identification webpage clustering ieee icdm 
james frank san francisco pub 
pazzani billsus learning revising user profiles identification interesting web sites machine learning 
perkowitz etzioni adaptive web sites conceptual framework case study artificial intelligence :10.1.1.27.2889
richardson domingos intelligent surfer probabilistic combination link content information pagerank advances neural information processing systems 
russell norvig artificial intelligence modern approach 
prentice hall 
voorhees implementing agglomerative hierarchical clustering algorithms document retrieval information processing management 
zamir etzioni dynamic clustering interface web search results eighth international world wide web conference toronto 
zamir etzioni web document clustering feasibility demonstration 
proc 
sigir 
