supervised term weighting automated text categorization franca istituto di dell informazione consiglio nazionale delle ricerche pisa italy iei pi cnr construction text classifier usually involves phase term selection relevant terms classification task identified ii phase term weighting document weights selected terms computed iii phase classifier learning classifier generated weighted representations training documents 
process involves activity supervised learning information membership training documents categories 
traditionally supervised learning enters phases iii 
propose learning training data affect phase ii information membership training documents categories determine term weights 
call idea supervised term weighting stw 
example propose number supervised variants tfidf weighting obtained replacing idf function function phase term selection 
experimental results obtained standard reuters benchmark classifier learning method support vector machines term selection functions information gain chi square gain ratio local global term selection weighting 
keywords machine learning text categorization text classification 
text categorization tc activity automatically building means machine learning ml techniques automatic text classifiers programs capable labelling natural language texts domain thematic categories predefined set 

construction automatic text classifier relies existence initial corpus 
docu permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
sac melbourne florida usa copyright acm 
fabrizio sebastiani istituto di dell informazione consiglio nazionale delle ricerche pisa italy fabrizio iei pi cnr ments preclassified general inductive process called learner automatically builds classifier learning characteristics training set tr 
tr documents 
classifier built effectiveness capability take right categorization decisions may tested applying test set te tr checking degree correspondence decisions classifier encoded corpus 
called supervised learning activity learning supervised information membership training documents categories 
construction text classifier may seen consisting essentially phases 
document indexing creation internal representations documents 
typically consists term selection consisting selection set contains terms occur documents tr subset terms dimensions document representation expected yield best effectiveness term weighting term tk selected phase document dj weight wkj computed represents loosely speaking term tk contributes discriminative semantics document dj 
phase classifier learning creation classifier learning internal representations training documents 
traditionally supervised learning affects phases 
propose supervised learning phase weight wkj reflect importance term tk deciding membership dj categories interest 
call idea supervised term weighting stw 
concerning computation term weights propose phase capitalizes results phase selection best terms usually accomplished scoring term tk means function tk ci measures capability discriminate category ci selecting terms maximize tk ci 
proposal tk ci scores discarded term selection active ingredient term weight 
tc literature discusses main policies perform term selection local policy different sets terms selected different categories ci global policy single set terms selected extracting single score tk individual scores tk ci 
experiment policies policy term selection term weighting 
consequence adopting local policy reusing scores term weighting weights traditionally function term tk document dj depend category ci means principle representation document vector terms set vectors terms 

organized follows 
section discusses roles term selection term weighting play current approaches tc 
section describe detail idea stw introduce example weighting functions idea 
section experiment functions reuters standard benchmark tc research 
experiments performed classifier learning method support vector machines term selection functions information gain chi square gain ratio local global term selection weighting 
section concludes 

document indexing tc term weighting text categorization applications crossroads ir ml term weighting usually tackled means methods borrowed text search methods involve learning phase 
weighting methods developed text search variety 
noted zobel moffat passages quoted monotonicity assumptions form appear practically weighting methods rare terms important frequent terms idf assumption ii multiple appearances term document important single appearances tf assumption iii quantity term matching long documents important short documents normalization assumption 
assumptions exemplified tfidf function standard ltc variant tr tfidf tk dj tf tk dj log tr tk tr tk denotes number documents tr tk occurs tf tk dj log tk dj tk dj tk dj denotes number times tk occurs dj 
tr tf tk dj log components equation tr tk enforce tf idf assumptions respectively 
weights obtained equation usually normalized cosine normalization wkj tfidf tk dj tfidf ts dj enforces normalization assumption 
term selection classifier induction methods computationally hard computational cost function length vectors represent documents 
key importance able vectors shorter usually number tens thousands 
term selection techniques select subset terms deemed useful compactly representing meaning documents 
value called reduction factor 
usually techniques consist scoring term means category term evaluation function selecting set terms maximize functions tradition information theory statistics tc interest tk tk ci ci log tk ci tk ci tk ci tk ci tk ci ig tk ci gr tk ci ci ci tk tk ci ci tk tk log log called chi square information gain gain ratio respectively 
formulae probabilities interpreted event space documents tk ci indicates probability random document term tk occur belongs category ci estimated maximum likelihood 
functions try capture intuition valuable terms categorization ci distributed differently sets positive negative examples ci 
interpretations principle may vary subtly different functions see section discussion 
equations refer specific category ci order assess value term tk global sense globalization technique applied extract global score tk tk ci scores relative individual categories 
common globalization techniques sum tk tk ci weighted sum tk ci tk ci maximum fmax tk max tk ci values tk ci 

supervised term weighting normalized tfidf function equation term weighting functions ir literature routinely ir applications involving supervised learning tc think contexts far optimal choice 
particular challenges idf assumption 
standard ir contexts assumption reasonable encodes quite plausible intuition term tk occurs documents sufficiently helpful occurs query discriminating documents relevant irrelevant 
training data query available documents relevance irrelevance known stronger intuition brought bear best discriminators terms distributed differently sets positive negative training examples 
training data available queries standard ir contexts available categories tc contexts 
contexts category score terms differently distributed sets positive negative training examples better substitutes idf functions 
attractive aspect stw tc category term selection scores attribute terms available 
approach propose puts scores computed phase term selection maximum discarding selecting terms take part representations term weighting phase 

experiments conducted number experiments test validity stw idea 
experiments run standard benchmark different employed local global policies term selection function component term weighting function 
speak ig stw technique mean ig global policy denoted local denoted term selection function substitute log 
tr tr equations term evaluation functions experiments illustrated equations 
chosen frequently category tc literature document frequency category third chosen discuss consider theoretically better motivated variant second 
discuss chi square statistics frequently experimental sciences order measure results observation differ independent results expected initial hypothesis lower values indicate lower dependence term selection measure independent tk ci 
terms tk lowest value tk ci independent ci interested terms select terms tk tk ci highest 
second employ information gain ig information theoretic function measures amount information random variable contains words reduction uncertainty ran statistics usually best viewed terms actual counts contingency table terms probabilities 
formulated probabilistic terms better comparability 
dom variable knowledge brings independent variables grows monotonically dependence 
term selection measure information term tk contains category ci interested selecting terms informative indicative presence absence category select terms ig tk ci highest 
third discuss gain ratio gr defined ratio information gain ig variables entropy orh 
knowledge gr feature selection purposes claim term selection better alternative ig manning sch tze note ig grows degree dependence variables entropy 
dividing ig tk ci ci log allows compare different values term tk different categories equal basis 
note fact ig tk ci min tk ci gr tk ci 
comparing different scores tk obtained different categories especially important applying globalization techniques described section 
instance clear choose ig fmax tk max tk ci globalization function score ig tk category high entropy higher probability selected score ig tk category low entropy 
gr categories enjoy unfair advantage 
learning method document dj belong zero categories tackle classification problem independent problems deciding dj belongs ci 

learning method experiments support vector machine svm learner implemented svmlight package version 
svms attempt learn hyperplane dimensional space separates positive training examples negative ones maximum possible margin minimal distance hyperplane training example maximum results computational learning theory indicate tends minimize generalization error error resulting classifier unseen examples 
simply opted default parameter setting svmlight particular means linear kernel 
extended version discuss analogous experiments carried learners rocchio method nn algorithm different reduction factors 
experimental setting experiments reuters distribution corpus currently widely benchmark tc research reuters consists set information gain known mutual information pp 

tc researchers function name fact names refer object gone undetected 
reuters corpus freely avail news stories partitioned split adopted training set documents test set documents 
documents labelled categories average number categories document ranging minimum maximum 
number positive examples category ranges minimum maximum 
results reported set categories training example reuters set categories training example test example reuters set categories highest number training examples reuters 
sets obviously hardest include categories positive instances inducing reliable classifiers obviously haphazard task 
experiments discussed section words removed list provided pages 
punctuation removed letters converted lowercase numbers removed stemming performed means porter stemmer 
measured effectiveness terms precision wrt ci recall wrt ci defined usual way 
values relative individual categories averaged obtain values precision recall global entire category set alternative methods microaveraging macroaveraging 
note computation macroaveraging conforming common practice taken resp 
denominator tpi fpi resp 
tpi fni 
measure effectiveness combines contributions known function defined 
similarly researchers set places equal emphasis 
results experiments reported 
term selection performed global policy fmax tk globalization technique preliminary experiments run consistently outperformed globalization techniques described section 
reason fmax tk performs prefers terms separators single category terms fair separators categories 
fact tk separator ci tk ci going high chances fmax tk tk ci means chances tk selected means turn separator ci selected term set 
experiments stw techniques compared baseline formed cosine normalized tfidf weighting ltc variant equations 
note stronger weighting functions ltc tfidf reported literature monotonicity assumptions mentioned section means stw techniques applied probably yielding similar performance able experimentation purposes www com resources reuters differentials 
analysis results stw functions thorough experiments performed shown uniform superiority stw respect standard term weighting cases tfidf outperformed stw techniques cases stw techniques improved tfidf 
try analyze results detail ease discussion refer results obtained reuters 
weighting techniques gr best performers svms svms tfidf just microaveraging 
fact gr achieved improvement vs macroaveraged effectiveness best tfidf svms basically maintaining microaveraged effectiveness particular relevance svms currently best performing tc method literature 
ig disappointing performer macroaveraging 
local policies gr generally best ig usually better 
surprised performance gr remarked section consider gr theoretically superior alternative ig 
disappointing performance produced striking contrast known performance ig term selection function 
note ig gr perform identically 
due fact differ entropy ci normalization factor gr 
quite obvious locally category ci ig gr select terms give weights differ constant multiplicative factor 
surprising result global stw techniques superior corresponding local technique 
say surprising global policy openly contradicts decision view classification problem independent binary classification problems 
problems really seen independent problem building representations viewed category category basis local policy 
conjecture surprising behaviour due fact statistics collected scarcely populated categories robust local policy effective categories global policy unreliable statistics providing robust statistics collected entire category set 

proposed supervised term weighting stw term weighting methodology specifically designed ir applications involving supervised learning text categorization text filtering 
supervised term indexing leverages training data weighting term different distribution positive negative training examples 
proposed take form replacing idf category term evaluation function previously term selection phase stw efficient reuses weighting purposes scores computed term selection purposes 
microaveraged svm categories tf idf tf chi tf chi tf ig tf ig tf gr tf gr macroaveraged tf idf tf chi tf chi tf ig tf ig tf gr tf gr svm categories plots micro averaged leftmost macro averaged rightmost svms 
axis indicates major subsets reuters described section 
tested stw combinations involving learning methods different term weighting functions tested local global version 
functions gain ratio known tc term selection literature proposed think theoretically superior alternative widely information gain aka mutual information function 
results confirmed superiority gain ratio information gain chi square stw function 
proving consistently superior tfidf stw interesting results 
particular stw technique gain ratio results board showing improvement tfidf macroaveraging svms currently best performing tc method literature 

luigi making available real cat software experiments performed 
similar goes thorsten joachims making available svmlight package 
henri pio guido ricci alessandro sperduti fruitful discussions 

cover thomas 
elements information theory 
john wiley sons new york 
sebastiani 
supervised term weighting automated text categorization 
technical report tr istituto di dell informazione consiglio nazionale delle ricerche pisa 
submitted publication 
sebastiani simi 
experiments feature selection negative evidence automated text categorization 
baker editors proceedings ecdl th european conference research advanced technology digital libraries pages lisbon pt 
springer verlag heidelberg de 
published lecture notes computer science series number 
joachims 
making large scale svm learning practical 
sch lkopf burges smola editors advances kernel methods support vector learning chapter pages 
mit press cambridge 
lewis 
representation learning information retrieval 
phd thesis department computer science university massachusetts amherst 
lewis 
evaluating autonomous text classification systems 
fox ingwersen fidel editors proceedings sigir th acm international conference research development information retrieval pages seattle 
acm press new york 
manning sch tze 
foundations statistical natural language processing 
mit press cambridge 
quinlan 
induction decision trees 
machine learning 
salton buckley 
term weighting approaches automatic text retrieval 
information processing management 
reprinted pp 

sebastiani 
machine learning automated text categorization 
acm computing surveys 
sparck jones willett editors 
readings information retrieval 
morgan kaufmann san mateo 
yang pedersen 
comparative study feature selection text categorization 
fisher editor proceedings icml th international conference machine learning pages nashville 
morgan kaufmann publishers san francisco 
zobel moffat 
exploring similarity space 
sigir forum 
