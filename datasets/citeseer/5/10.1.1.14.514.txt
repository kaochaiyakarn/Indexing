journal arti cial intelligence research submitted published robust agent teams socially attentive monitoring gal kaminka milind tambe tambe isi edu information sciences institute computer science department university southern california admiralty way los angeles ca usa agents dynamic multi agent environments monitor peers execute individual group plans 
key open question monitoring agents states required ective monitoring selectivity problem 
investigate question context detecting failures teams cooperating agents monitoring focuses monitoring failures social relationships agents 
empirically analytically explore family socially attentive teamwork monitoring algorithms dynamic complex multi agent domains varying conditions task distribution uncertainty 
show centralized scheme complex algorithm trades correctness completeness requires monitoring teammates 
contrast simple distributed teamwork monitoring algorithm results correct complete detection teamwork failures despite relying limited uncertain knowledge monitoring key agents team 
addition report design socially attentive monitoring system demonstrate generality monitoring coordination relationships diagnosing detected failures line line applications 
ai access foundation morgan kaufmann publishers 
rights reserved 
kaminka tambe 
agents complex dynamic multi agent environments able detect diagnose recover failures run time toyama hager 
instance robot grip may slippery opponents behavior may intentionally di cult predict communications may fail examples environments include virtual environments training johnson rickel calder smith mar high delity distributed simulations tambe johnson jones laird rosenbloom kitano tambe stone veloso coradeschi osawa matsubara noda asada multi agent robotics parker balch 
rst key step process execution monitoring doyle atkinson steel cohen hart tate atkins durfee shin veloso pollack cox 
monitoring execution multi agent settings requires agent monitor peers correct execution depends state peers cohen levesque jennings parker jennings grosz kraus tambe 
monitoring peers particular importance teams team members rely closely related tasks monitoring allows team members coordinate actions plans teammates help teammates cooperate interference 
example drivers cars convoy drive monitoring cars convoy convoy help drivers cars break 
monitoring allows team members peers dynamic information sources learning new information 
instance driver convoy sees cars front suddenly turn left infer existence obstacle milestone despite directly seeing 
previous investigated di erent ways monitoring context teams cooperating agents 
example theoretical sharedplans grosz kraus distinguished passive monitoring agent noti ed proposition changes communications active monitoring agent actively seeks nd proposition changes observations inference unobservable attributes 
practical implementations investigated passive monitoring communications jennings active monitoring plan recognition huber durfee active implicit monitoring environment kraus rosenschein di erent combinations methods parker jennings tambe lesh rich sidner 
approach clearly superior passive monitoring generally perceived costly active monitoring reliable grosz kraus huber durfee kaminka tambe 
regardless monitoring method bandwidth computational limitations prohibit monitoring agent monitoring agents full extent time jennings durfee grosz kraus 
key open question monitoring agents required ective teams jennings grosz kraus 
call challenging problem monitoring selectivity problem problem selectivity observing inferring state observations monitoring 
raised past framework minimal constraints answers provided jennings grosz kraus 
instance theory sharedplans requires agents verify intentions con ict teammates grosz kraus 
methods veri cation take place left investigation grosz kraus 
section provides details related 
begins address monitoring selectivity problem teams investigating monitoring requirements ective failure detection 
focus investigation detecting failures robust multi agent teams social relationships ideally hold agents monitored team 
call monitoring social relationships socially attentive monitoring di erentiate types monitoring monitoring failures progress agents goals 
term social relationship denote relation attributes multiple agents states 
monitoring convoy example involves verifying agents common destination heading beliefs driving convoy mutual instance agents observed head di erent directions clearly common heading 
di erent monitoring chosen common heading leads agreed destination 
monitoring relationships team socially attentive monitoring critical task monitoring team members 
failures maintain team relationships lead catastrophic failures part team lack cooperative behavior lack coordination 
failures result individual agent failures failures agent sensors actuators 
socially attentive monitoring covers large class failures promotes robust individual operation 
explore socially attentive monitoring algorithms detecting teamwork failures various conditions uncertainty 
analytically show despite presence uncertainty actual state monitored agents centralized active monitoring scheme guarantee failure detection sound incomplete complete unsound 
requires reasoning multiple hypotheses actual state monitored agents monitoring agents team 
show active distributed teamwork monitoring results sound complete detection capabilities despite simpler algorithm 
distributed algorithm uses single possibly incorrect hypothesis actual state monitored agents involves monitoring key agents team necessarily team members 
transformation analytical constructs show analogous results centralized mutual exclusion coordination relationships 
conduct empirical investigation socially attentive monitoring teams 
implemented general socially attentive monitoring framework expected ideal social relationships maintained agents compared actual social relationships 
discrepancies detected possible failures diagnosed 
apply framework different complex dynamic multi agent domains service monitoring various social relationships line line 
domains involve multiple interacting agents collaborative adversarial settings uncertainties perception action 
domain provide empirical results active monitoring con rm analytical results 
domain show line socially attentive monitoring provide quantitative teamwork quality feedback designer 
provide initial diagnosis procedures detected failures 
focus explorations practical algorithms guarantees performance real world applications 
algorithms seek complement passive communications monitoring unreliable domains explore key hole plan recognition alternative 
rule communications simply seek provide techniques communications fail 
analytical guarantees failure detection soundness completeness hold monitoring done communications plan recognition 
organized follows section presents motivating examples background 
section presents socially attentive monitoring framework 
section explores monitoring selectivity centralized teamwork monitoring 
section explores monitoring selectivity distributed teamwork monitoring 
section demonstrates generality framework applying line con guration 
section presents investigations additional relationship models 
section presents related section concludes 
appendices contain proofs theorems appendix pseudo code socially attentive monitoring algorithms appendix 
kaminka tambe 
motivation background monitoring selectivity problem addresses monitoring required failure detection teams rose growing frustration signi cant software maintenance orts application domains 
modsaf domain high delity battle eld virtual environment calder involved development synthetic helicopter pilots tambe 
robocup soccer simulation domain kitano involved developing synthetic soccer players marsella kaminka muslea tambe 
environments domains dynamic complex uncertainties behavior agents adversarial cooperative unreliable communications sensors actions may execute intended agents environments countless opportunities failure despite designers best orts 
examples may serve illustrate 
examples actual failures occurred modsaf domain 
illustrate explore socially attentive monitoring example 
team helicopter pilot agents speci ed way point position team members scout forward enemy teammates attackers land wait signal 
agents monitored way point 
due unexpected sensor failure attackers failed sense way point 
attacker correctly landed failing attacker continued forward scout see screen shot illustrating failure 
example 
di erent run agents reached way point detected scout gone forward identi ed enemy 
sent message waiting attackers join attack enemy 
attackers receive message remained inde nitely scout attacker continued mission 
collected dozens similar reports modsaf robocup domain 
general failures di cult anticipate design time due huge number possible states 
agents easily nd novel states foreseen developer monitoring conditions communications place proved insu cient failure cases reported agents involved detect correct erroneous behavior 
agent believed agents acting coordination communication received agents indicate 
agents violating collaboration relationships agents came disagree plan executed collaboration relationship failure occurred 
preliminary empirical results show upwards failures reported involved relationship violations relationship failures 
human observers typically quick notice failures clear social misbehavior agents cases 
able infer failure occurred despite knowing exactly happened 
instance seeing attacker continuing ahead despite teammates switching di erent plan human observers inferred fact teammates attacker landed su cient observer detect gone knowing di erent plan 
analysis showed agents monitoring su ciently 
naive solution continuous communications agents clearly impractical agents operating hostile environment ii communications overheads prohibitive iii fact communications equipment broke cases 
sought practical ways achieve quick detection failure limited ambiguous knowledge available monitoring agent 
robust multi agent teams scout ahead failing attacker trailing landing attacker enemy plan view display modsaf domain illustrating failure example 
thick lines contour lines 

socially attentive monitoring overview general structure socially attentive monitoring system shown 
consists social relationship knowledge base containing models relationships hold monitored agents enabling generation expected ideal behavior terms relationships section agent team modeling component responsible collecting representing knowledge monitored agents actual behavior section relationship failure detection component monitors violations relationships monitored agents contrasting expected actual behavior section relationship diagnosis component veri es failures provides explanation section 
resulting explanation diagnosis recovery negotiations system kraus sycara general re planner steel 
knowledge base relationship models take relationship agents relation state attributes 
relationship model speci es di erent attributes agent state related agents multi agent system 
attributes include beliefs held agents goals plans actions example teamwork relationship models require team members mutual belief joint goal cohen levesque jennings 
spatial formation relationship parker balch speci es relative distances velocities maintained group agents domain helicopter pilots 
coordination relationships may specify temporal relationships hold actions agents business contractors malone crowston 
relationships social explicitly specify multiple agents act believe maintain relationships 
kaminka tambe agent attributes monitored agent monitored agent agent team modeling component social relationships knowledge base diagnosis detections failure relationship relationship detected failure actual behavior agents monitor diagnosis expected attribute values actual values expected behavior socially attentive monitoring system communications observations general structure socially attentive monitoring system 
relationship knowledge base contains models relationships supposed hold system speci es agents participating relationships 
knowledgebase guides agent modeling component selecting agents monitored attributes state need represented detection diagnosis 
failure detection component generate expectations contrasted actual relationships maintained agents 
provides diagnosis component detailed information agents states attributes related drive diagnosis process 
implementation socially attentive monitoring teams uses types relationships formations role similarity mutual exclusion teamwork 
teamwork monitoring steam tambe general domain independent model teamwork cohen levesque joint intentions framework levesque cohen nunes cohen levesque grosz sidner kraus sharedplans grosz sidner grosz kraus 
teamwork models may steam 
steam pilot soccer agents generate collaborative behavior reused independently service monitoring monitored agents assumed team steam monitoring teamwork 
steam teamwork models cohen levesque jennings rich sidner require mutual belief team members joint goals plans 
characteristic monitor teamwork system 
relationship models secondary monitoring role 
discussed greater length section 
knowledge monitored agents team agent modeling component responsible acquiring maintaining knowledge monitored agents 
knowledge construct actual relations exist agents states attributes compared ideal expected relations 
section describe plan recognition capabilities agent modeling component implementation experiments extent knowledge maintained monitored agents plans necessary 
sections show fact limited possibly inaccurate knowledge su cient ective failure detection 
implementations may optimized agent modeling algorithms full capabilities 
section discuss additional agent modeling capabilities necessary diagnosis 
robust multi agent teams representation monitoring teamwork relationships representing agents terms selected hierarchical reactive plans enables quick monitoring state facilitates inference monitored agents beliefs goals unobservable actions capture agents decision processes 
representation reactive plans firby newell form single decomposition hierarchy tree represents alternative controlling processes agent 
reactive plan hierarchy referred simply plan selection conditions referred preconditions applicable termination conditions terminate suspend plans 
moment agent executing single path root leaf hierarchy 
path composed plans di erent levels 
presents small portion hierarchy created modsaf domain 
case example prior way point agents executing path execute mission highest level plan fly flight plan fly route traveling low level 
reaching way point supposed switch fly flight plan descendents wait point 
attackers select just wait child wait point scout select scout forward descendents 
course failing attacker detect way point termination conditions fly flight plan selection conditions wait point satis ed failing attacker continued execute fly flight plan descendents 
wait point execute mission nap earth contour low level just wait scout forward traveling fly flight plan join scout ordered halt fly route portion hierarchical reactive plan library modsaf domain team plans boxed 
explained section 
acquisition practical perspective agents may cooperatively report monitoring agent state communications requires communication channels su ciently fast reliable secure 
unfortunately possible realistic domains examples demonstrate section 
alternatively monitor may plan recognition infer agents unobservable state observable behavior 
approach robust face communication failures 
course monitor may bene focused communications agents critically dependent 
kaminka tambe enable plan recognition reactive plans chosen representation employed reactive plan recognition algorithm called real time situated commitments 
key capability required allow explicit maintenance hierarchical plan hypotheses matching agent observed behavior pruning hypotheses deemed incorrect useless monitoring purposes 
works expanding entire plan library hierarchy modeled agent tagging paths matching observed behavior agent modeled see appendix pseudo code algorithm 
heuristics external knowledge may eliminate paths hypotheses deemed inappropriate heuristics explored shortly 
basic approach similar previous reactive plan recognition rao team tracking tambe successfully modsaf domain share properties 
adds belief inference capabilities diagnosis process discussed section 
gives simpli ed presentation plan hierarchies variation example agents correctly detected way point failure occurred note plans intermediate levels abstracted gure 
scout attackers figures switched fly flight plan plan denoted wait point plan denoted 
outside observer infers explanations agent behavior observing agents 
scout continues ahead speed altitude matching low level possible ight methods fly flight plan wait point plans 
tagged possible hypotheses scout executing plan hierarchy 
similarly attackers land recognizes executing just wait plan 
plan service ordered halt plan plan helicopters ordered headquarters land immediately 
tagged explanations attackers states second level hierarchies 
agents identi es plan execute mission top level plan 
illustration actual executing paths agents marked lled arrows 
individual modeling hypotheses match observed behavior marked dashed arrows 
outside observer course way knowing possible hypotheses correct 
execute mission execute mission just wait just wait just wait low level execute mission wait point ordered halt wait point fly flight plan low level wait point just wait ordered halt scout attackers actual recognized abbreviated reactive plan hierarchies 
individual modeling hypotheses acquired individual agent plan recognition implementation potentially communications monitoring agent combine create team modeling hypotheses state team 
monitoring agent selects single individual modeling hypothesis individual agent combines single team modeling hypothesis 
team modeling hypotheses possible multiple hypotheses individual agents 
instance team hypotheses execution mission top level plan di erent team hypotheses di erentiated second level plan 
observer member team knows executing robust multi agent teams multiple hypotheses teammates states 
instance attacker monitoring teammates hypotheses second level 
avoid explicitly representing combinatorial number hypotheses explicitly maintains candidate hypotheses agent individually combinations individual models team hypotheses 
combinations implicitly represented 
number hypotheses explicitly maintained grows linearly number agents 
relationship violation detection failure detection component detects violations social relationships hold agents 
done comparing ideal expected relationships actual maintenance agents 
teamwork speci cally relationship model requires team members agree team plan jointly executed team similarly joint responsibility jennings sharedplans grosz kraus 
requirement fails actuality agents executing di erent team plans teamwork failure occurred 
basic teamwork failure detection algorithm follows 
monitored agents processed top manner 
detection component uses teamwork model tag speci plans team plans explicitly representing joint activity team plans boxed figures 
team plans equal depths hierarchies create team modeling hypotheses 
hypothesis plans di erent agents compared detect disagreements 
di erence indication failure 
di erences comparison reaches individual plans non team non boxed gures failure detected 
individual plans may chosen agent individually service team plans boxed gures handled relationships discussed section instance suppose failing attacker example monitoring attacker 
shows view hierarchical plan left 
path right represents state attacker landed 
state inferred example observations monitoring attacker assuming plan recognition process resulted correct hypothesis agent 
discuss realistic settings 
di erence detected marked arrow plans second level top 
failing attacker executing fly flight plan team plan left attacker executing wait point team plan right 
disagreement team plan executed failure teamwork 
execute mission wait point just wait fly flight plan fly route traveling low level execute mission comparing hierarchical plans 
top di erence level 
kaminka tambe detecting disagreements di cult multiple team modeling hypotheses may imply contradictory results respect failure detection hypotheses may imply failure occurred team may 
unfortunately expected realistic applications 
instance section shows hypotheses possible observations 
hypotheses implies failure occurred agents agreement team plan executing hypothesis implies failures occurred 
limit reasoning small number team hypotheses restricting capabilities disambiguation heuristic ranks team modeling hypotheses level coherence represent 
heuristic provided initial solution 
sections examine additional heuristics 
de nition 
coherence level multi agent modeling hypothesis de ned ratio number agents modeled number plans contained hypothesis 
de nition results partial ordering hypotheses set coherent hypothesis assigns agent di erent plan team mates coherent hypothesis assigns plan team members 
instance hypothesis lowest level coherence implies complete breakdown teamwork agent executing di erent plan 
hypothesis coherence level highest level coherence group agents assigned plan 
ranked hypothesis single teamwork failure disagreement coherence level 
detection component selects single maximally coherent team modeling hypothesis ties broken randomly 
intuition coherence failures agree occur despite agents attempts teamwork 
expect agreements disagreements team 
coherence level team hypothesis inversely related number teamwork failures implied hypothesis 
selecting maximally coherent hypothesis corresponds minimum number failures heuristic commonly diagnosis hamscher console de kleer 
case depicted complete detection process may conceptualized follows suppose attackers hierarchy described monitoring team 
collects plan hypotheses top hierarchy agent including 
case execute mission execute mission execute mission 
team modeling hypothesis built execute mission execute mission execute mission 
hypothesis shows disagreement occurs level process continues second level 
hypotheses rst agent left monitoring second agent knows state possibility third agent 
saw maximally team coherent hypothesis selected 
indicate failure process continues third level 
agents executing individual plans comparison process stops 
algorithm appendix provides greater details process 
sub teams introduced di erence team plans may explained agents question part di erent sub teams 
sub team members agree joint sub team plans may di er sub team 
assume teams consideration simple teams de ned de nition 
de nition service analytical results appear condition 
return issue sub teams section 
de nition 
say team simple plan hierarchy involves di erent team plans executed di erent sub teams 

implementations may optimized algorithms heuristics integrated agent modeling algorithm 
robust multi agent teams intuitively idea simple team members team jointly execute team plans hierarchy 
de nition somewhat similar de nition ground team kinny ljungberg rao sonenberg tidhar werner allow sub team members team joint plan di erent members 
relationship diagnosis diagnosis component constructs explanation detected failure identifying failure state facilitating recovery 
diagnosis terms set agent belief di erences inconsistencies explains failure maintain relationship 
starting point process detected failure di erence team plans 
diagnosis process compares beliefs agents involved produce set inconsistent beliefs explain failure 
problems exist practical applications procedure 
monitoring agent access beliefs held monitored agents feasible practice communicate agents beliefs 
second agent real world domain may beliefs vary agents irrelevant diagnosis 
relevant knowledge may simply accessible may hidden mountains irrelevant facts 
gain knowledge beliefs monitored agents relying communications diagnosis process uses process belief ascription 
agent modeling component implementation maintains knowledge selection termination conditions recognized plans hypotheses 
recognized plan hypothesis modeling component infers termination conditions plan believed false monitored agent terminated plan 
useful additional heuristic infer selection conditions preconditions plan just begun execution true 
idea plan selected execution preconditions hold short period time 
heuristic involves explicit assumption part system new plan recognized soon begins execution 
designers domains need verify assumption holds 
agent inferred termination selection conditions set beliefs agent 
instance suppose agent hypothesized just switched executing fly flight plan wait point 
infers agent believes way point just detected selection condition wait point 
addition infers agent believes enemy seen order received base halt mission negated termination conditions wait point 
determine facts relevant failure diagnosis component uses teamwork model 
teamwork model dictates beliefs agents hold mutually believed agents team 
di erence detected beliefs certain failure team members agree issues agreement mandatory participation team 
teamwork model speci es beliefs contained sets mutual consistent 
inconsistency detected diagnosis procedure looks contradictions disagreements cause di erence team plan selection 
di erence beliefs serves diagnosis allowing monitoring agent initiate process recovery negotiating con icting beliefs kraus 
example shown section attackers example section di er choice team plan attacker continuing execution fly flight plan plan kaminka tambe helicopters formation 
attacker detected way point terminated fly flight plan switched wait point landing immediately 
failing attacker monitors team mate detects di erence team plans section detected di erence passed diagnosis 
failing attacker inferences 
fly flight plan termination conditions seeing enemy detecting way point receiving order halt 
failing attacker left hierarchy knows belief conditions hold oint enemy 
wait point selection condition way point detected 
termination condition scout sent message join having identi ed enemy position 
diagnosis component case infers attacker right hierarchy oint oint oint enemy inconsistent 
inconsistency disagreement attackers oint contradictory beliefs waypoint 
failing attacker knows team mate seen way point 
choose quietly adapt belief terminating fly flight plan selecting wait point may choose recovery actions negotiating attacker way point reached 
diagnosis procedures useful failures detected monitoring see section evaluation discussion 
focuses monitoring selectivity problem detection leave investigation diagnosis procedures 

monitoring selectivity centralized teamwork monitoring socially attentive framework section systematically examine failure permutations examples section centralized teamwork monitoring con guration single team member monitoring team 
vary agents failing attacker attacker scout role monitoring agent attacker scout 
report empirical results detecting diagnosing failures cases 
empirical results guide explore centralized teamwork monitoring analytically 
show monitoring uncertainty centralized teamwork monitoring provide sound complete detection results 
starting point exploration monitoring agent uses single maximally coherent team modeling hypothesis discussed section 
example 
normal order execution wait point followed join scout 
execution attackers land wait scout visually identify enemy position 
identi cation scout sends message join triggers selection plan termination plan 
executing scout hovers low altitude waiting attackers join 
failures part attackers receive message part scout send 
failures arise instance radio broken team members range 
agent fails continues execute switching table summarizes permutations example 
permutation number appear rst column 
columns show actual plans selected agents permutation 
second column shows relationship failure occurred case disagreement exists agents 
column details physical conditions case 
possible failure permutations case agents failed 
cases attacker failed 
case scout failed send message attackers failed receive 
case scout identify enemy position robust multi agent teams message sent agents continue execute plan 
permutations possible attacker switch plan scout 
case actual executing plans relationship failure physical attacker attacker scout occurred 
failure fails receive fails receive message lost enemy identi ed table possible failure permutations broken radio link scenario example 
instance case table corresponds example 
scout detected enemy switched plan sent message attackers join 
attacker received message switched plan began ying scout 
remaining attacker failed receive message maintains position continuing execute failing switch agents longer agreement team plan jointly executed teamwork failure occurred 
condition monitors original failure case monitor scout message 
failures communications resulted monitoring conditions rendered useless 
key issue raised case table 
due scout inability identify enemy position due failure scout part enemy simply helicopter pilots remain agreement enemy identi ed 
clearly pilots failing progress task goals scout continues search enemy inde nitely relationship failure place agents maintaining teamwork relationship failing progress 
clearly demonstrates failures necessarily relationship failures 
table presents results scout monitoring teammates example maximally team coherent hypothesis basis detection 
rst column shows case number table 
columns show scout hypothesis plan agent executing maximal coherence heuristic 
columns show failure detected diagnosed correctly 
column shows detection class discussed 
case hypothesized executing plans relationship failure diagnosis detection attacker attacker scout detected 
success 
class true negative true positive true positive true positive true negative table scout monitoring results permutations example 
example case table shows results scout monitoring original failure example section 
selecting maximally coherent hypothesis scout hypothesizes non moving attacker executing case column moving attacker executing case column 
scout course knows selected plan case column 
violation teamwork relationship detected case column kaminka tambe agreement rest team furthermore diagnosis successful identifying cause failure fact enemy position identi ed scout knowledge passed failing attacker case column 
column table shows detection class failure 
detection class case true positive true negative false positive false negative 
correspond possible monitoring outcomes true positive outcome relationship failure occurred detected 
true negative failure occurred system correctly reports detected 
false positive failure occurred system incorrectly detects false negative failure occurred system fails detect 
table shows permutations example teamwork monitoring techniques encounter problematic false positive false negative cases 
closer look results hints key contribution addressing monitoring selectivity problem ective failure detection take place despite uncertain limited knowledge monitored agents 
case table monitoring agent able detect failure despite wrong state agents involved 
scout believes attackers executing ordered halt plan executing selected command received headquarters halt execution hover place 
scout perspective hovering attacker inferred executing equally ranked maximally coherent hypotheses exist attackers executing executing random selection case resulted wrong hypothesis selected 
violation teamwork relationships detected agrees scout column case shows table diagnosis procedures sensitive selection team modeling hypothesis 
hypothesis case correctly re ect true state agents despite scout success detect failure case diagnosis procedures fail provide correct diagnosis diagnosis successful failure cases 
phenomenon repeats empirical results provide diagnosis failed hypothesis chosen incorrect su cient detection 
intend explore ways improve accuracy hypotheses address issue anymore 
failure detection capabilities signi cant improvement agents know certainty failure occurred diagnosis incorrect 
social physical failures successfully captured team coherence heuristic monitoring selectivity 
fact permutations example matter agents monitor failures maintain relationship physical failures team remains agreement detected reliably diagnosis failed 
result especially surprising considering single agent monitoring 
previous monitoring methods condition monitors communications unable detect failures despite agents tables empirical results basis example 
table presents failure permutations example format table 
normal order execution plans follows agents jointly execute fly flight plan plan detect way point 
switch wait point plan attackers land scout continues ahead identify enemy 
failures part agents detect way point switch plan 
table monitoring results permutations example 
attacker monitoring team maximally team coherent hypothesis detecting failures 
results show successful detecting teamwork failures cases highlighted bold face 
robust multi agent teams case actual executing plans relationship failure physical attacker attacker scout occurred 
failure vision fails vision fails vision fails vision fails vision fails vision fails vision fails table failure permutations undetected way point scenario example 
case hypothesized executing plans relationship failure detection attacker attacker scout detected 
class true negative true positive true positive false negative false negative true positive true positive true negative table attacker monitoring results permutations example 
false outcomes false negatives 
cases monitoring attacker picked incorrect hypothesis scout scout actions lead ambiguous interpretations 
scout forward scout enemy detected way point plan ying formation plan 
maximal team coherence heuristic causes prefer hypothesis scout agreement attackers fact 
example case attackers failed detect way point executing observing scout monitoring attacker sure scout executing believing scout executing results maximally coherent team modeling hypothesis agents agreement believing scout executing results coherent hypothesis 
selects wrong hypothesis case fails detect teamwork failure 
maximal team coherence heuristic detect failures despite incorrect hypotheses 
unfortunately hypotheses lead false negatives seen table 
experiments resulted false positive result result system detected failure reality occurred 
heuristic provided sound results cases 
able formally prove property holds general maximal team coherence heuristic 
address matter notation 
agent monitor agent executing plan denote set agent modeling hypotheses component constructs observable behavior execution words set plans match observable behavior 
note monitors direct access state fpg 
modeling kaminka tambe notation de nitions ground assumptions underlying knowledge monitoring de nition 
monitoring agent monitored agent say agent complete plan may executed 
set typically include matching hypotheses correct hypothesis guaranteed include de nition individual agent modeling completeness de ne group wide team modeling completeness de nition 
agent monitoring team agents 
bn say team modeling team complete agent modeling 
bn complete 
de nition critical guarantee capabilities explore analytically section 
generally holds modsaf robocup domains explicit service applications techniques domains 
armed de nitions formalize failure detection capabilities suggested empirical evidence theorem 
theorem 
monitoring agent monitor simple team team modeling complete uses maximally team coherent hypothesis detection teamwork failure detection results sound 
proof 
show failure occurred detected failure detected fact failure 
agent members agent executing plan 
collectively group executing pn 
failure occurred agents executing plan team modeling complete correct hypothesis going set hypotheses maximally team coherent hypothesis selected di erent hypothesis coherence level selected 
hypothesis coherence level correct implies failure detected 
detection procedure sound 
despite uncertainty knowledge sound failure detection guaranteed maximal team coherence heuristic 
answer monitoring selectivity problem 
seen table failures may pass undetected heuristic may result false negatives 
detection maximal team coherence may unfortunately incomplete 
may prefer monitoring system complete guaranteed detect teamwork failures 
experimented maximal team incoherence heuristic inverse maximal team coherence heuristic 
heuristic prefers hypotheses suggest failures 
table gives monitoring attacker view team similar table maximally team incoherent hypothesis 
shows maximally hypothesis lead false negative detections cases contrast cases table 
guided results formally show team incoherence heuristic leads detection procedure complete 
theorem 
monitoring agent monitor simple team team modeling complete uses maximally team incoherent hypothesis detection teamwork failure detection results complete 
proof 
analogous theorem proof provided appendix robust multi agent teams case hypothesized executing plans relationship failure detection attacker attacker scout detected 
class false positive true positive true positive true positive true positive true positive true positive false positive table attacker monitoring results permutations example team incoherence 
successes set false positive outcomes cases table 
cases failures occurred monitoring system falsely reported detected failures 
practice may lead costly processing false alarms 
ideally detection capabilities sound complete 
unfortunately show coherence disambiguation scheme exists results sound complete detection 
show theorem provide sound complete detection disambiguation method inconsistent set possible matching hypotheses rank hypothesis top 
theorem 
complete team modeling hypotheses set modeling simple team 
exists disambiguation scheme uses coherence basis disambiguation deterministic selection results sound complete failure detection 
proof 
disambiguation scheme leads complete sound detection uses knowledge coherence hypotheses selecting disambiguated hypothesis 
suppose contradiction deterministic consistent selection hypothesis set candidate hypotheses applies deterministic procedure choose hypothesis coherence 
knowledge outside coherence candidate hypotheses set candidates choose hypothesis 
am monitoring agent monitored agent actions identical executing team plans am determine executing am am fp am executing am hypotheses set leads complete sound detection choose 
am executing respectively matching hypothesis set de ned 
select 
set candidate hypothesis case information supplied non deterministic selection disambiguated hypothesis contradicting assumption 
empirical analytical results show single disambiguated hypothesis leads improved imperfect failure detection results compared monitoring conditions communications previously 
empirical results tables establish bene ts teamwork monitoring technique physical failures detected 
analytical results theorems show results perfect 
algorithms kaminka tambe sound complete 
complete monitoring require additional procedures di erentiate true positives false ones focused communication 
procedures expensive 
reduce need costly veri cation letting go insistence single hypothesis focusing maintaining hypotheses maximally coherent hypothesis hypothesis 
table shows portion full set team hypotheses available attacker monitoring team 
total number hypotheses table existing single case maintaining full set hypotheses expensive 
inverse heuristics team coherence incoherence represent extremes space hypotheses 
agree failure exists failure occurred team coherent hypothesis guarantees soundness theorem 
agree failure exists failure took place team incoherent hypothesis guarantees completeness theorem 
disagree team coherent hypothesis imply failure team incoherent hypothesis monitoring system sure way revert back veri cation 
case hypothesized executing plans relationship failure detection attacker attacker scout detected 
class false positive false positive false positive true negative true positive true positive true positive true positive true positive true positive true positive false negative true positive true positive true positive false negative true positive true positive true positive true positive true positive true positive false positive true negative table portion attacker monitoring hypotheses implied results ranking select single hypothesis case 
revised detection algorithm ers signi cant computational savings compared single team incoherent hypothesis approach 
complete unsound signi cantly reduces need veri cation team coherent hypothesis implies failures veri cation robust multi agent teams necessary 
requires representing hypotheses computationally cheaper maintaining exponential number hypotheses 
example maximally team incoherent hypothesis permutations example results need verify cases seen 
combine hypothesis maximally team coherent hypothesis table need verify cases 
cases agreement hypotheses failure occurred veri cation required 
monitoring agent address monitoring selectivity problem balancing resource usage guaranteed performance monitoring algorithm 
simpler single hypothesis algorithms utilize hypothesis case detection capabilities guaranteed sound complete 
complex algorithm hypotheses reasoned case algorithm complete require veri cation fewer cases compared simple hypothesis complete algorithm 

monitoring selectivity distributed teamwork monitoring section focuses monitoring selectivity exploiting key opportunity execution monitoring multi agent environments monitored agents distributed monitoring agents distributed 
simple scheme selecting single maximally team coherent hypothesis 
centralized teamwork monitoring successful addressing permutations example focus permutations example table centralized teamwork monitoring attacker resulted false negative detections cases table 
distributed teamwork monitoring scheme single attacker monitor teammates scout attacker engage monitoring 
table presents monitoring results failure permutations scout monitoring agent 
nd scout successfully detects failure cases attacker failed detect compensating attackers monitoring mistakes 
furthermore scout maximal coherence heuristic detection sound veri cation required 
reason scout success attackers actions case ambiguous support hypothesis matched scout plan 
words regardless plan attackers executing cases di erent plan executed scout 
case hypothesized executing plans relationship failure detection attacker attacker scout detected 
class true negative true positive true positive true positive true positive true positive true positive true negative table scout monitoring results permutations example team coherence 
agents engaged monitoring permutations example detection sound complete 
actual failure cases team member detects failure 
attempt formally de ne general conditions phenomenon holds 
kaminka tambe de nition 
say team plans observably di erent roles agent ful lls roles plans resp monitoring agent di erent 
say observably di erent roles call key agent 
intuitively key agent observably di erent roles plans monitoring agent di erentiate behavior executing executing instance attackers observably di erent roles land 
observably di erent roles require land 
scout observably di erent roles ying landing 
key agent basis conditions self monitoring team detect failure agent team coherence 
rst prove lemma conditions single agent detect failure 
lemma prove conditions agent team detect failure 
lemma 
suppose simple team self monitoring members team monitor maximally team coherent heuristic assumption agent complete 
monitoring agents members executing respectively 
detect failure maintaining teamwork relationships agent key agent proof 
see appendix knows executing executing key agent guaranteed notice di erence exists acting observably di erent executing note may may detect di erence perspective behavior may may explained detect di erence roles observably di erent 
detected failure alert teammates diagnose failure choose corrective action 
want guarantee teamwork failure detected agent sure possible combination plans key agent roles observably di erent 
lemma shows agents monitoring agent notice failure occurs 
aim de ne observably partitioned set plans employed team 
de nition 
set team plans said observably partitioned plans exists key agent ij set ij agents called key agents set instance set team plans helicopter pilots team examples fly flight plan wait point ordered halt join scout 
attackers land scout lands ies table shows agents observably di erent roles plans set 
instance nding cell intersection row column nd scout observably di erent roles plans 
scout lands command received halt execution ies scout enemy position executing agents observably di erent roles plans key agents set includes members team attackers scout 
theorem 
simple team employs observably partitioned set team plans team members monitor members key agents set complete team modeling maximally team coherent hypotheses teamwork failure detection results sound complete 
robust multi agent teams fly flight plan wait point ordered halt join scout attackers attackers scout attackers scout scout attackers attackers scout attackers scout scout attackers attackers table observable partitioning helicopter pilot team modsaf 
proof 
theorem know detection sound 
show complete prove agent detect di erence team members executing plan failure occurring 
suppose team currently divided team plans executed agents team executing team plans respectively failure occurred 
key agents set team observably partitioned exists key agent cases case 
executing case agent executing detect di erence detect failure lemma 
case ii 
executing case agent executing detect di erence detect failure lemma 
case iii 
executing plan roles observably di erent agent executing detect failure 
case roles observably di erent impossible monitoring agent am am am fqg contradicting key agent cases agent detect failure occurred 
failure detection complete 
sound seen detection sound complete 
theorem shows distributed teamwork monitoring result sound complete simple algorithm 
team member monitors key agents maximally team coherent hypothesis 
detects failure certainly occurred 
agent detects failure failure occurred 
simple distributed algorithm attention focusing features guaranteed soundness completeness contrasts complex centralized algorithm discussed previous section section 
algorithm ectiveness lies condition set plans distribution monitoring 
corollary theorems key agents available distributed case failure detection sound complete 
key agents available centralized teamwork monitoring complete sound 
fortunately observable partitioning di cult property design teams composed agents role plan general roles observable di erences 
instance helicopter pilot team modsaf domain typically executes set plans property table demonstrates 
team observably partitioned may case agents executing di erent plan agent able detect team coherence 
monitoring team member know key agents knows exist monitor team members 
increases monitoring sound complete failure detection guaranteed 
kaminka tambe heuristic 
minimal case occurs agents executing plans respectively observably di erent fp result believing agreement 
check situation part plan design process marking risky points execution detection sound complete theorem veri cation communications prescribed pro actively 
check inserted protocol run time analysis agent simulate hypotheses matching actions detect risky points dynamically 

socially attentive monitoring line con guration demonstrate generality socially attentive monitoring framework section examines re teamwork monitoring domains diagnosis recovery failure infeasible execution 
examples domains include team sports military human team training cannon bowers multi agent domains 
dynamic nature domain hard real time deadlines complexity agents involved human team members diagnosis recovery di cult 
failure diagnosed late ective recovery 
environments monitoring agent concerned trends performance 
information important long term design evaluation analysis need necessarily calculated line 
results analysis meant feedback agents designer coach supervisor humans 
developing line socially attentive monitoring system called teamwork monitoring review 
currently uses execution traces monitored agents perform monitoring plan recognition 
need worry uncertainty plan recognition real time performance 
knows certainty agent plans execution 
accumulates quantitative measures related teamwork including average time agreement measure ata short measure level agreement team 
build failure detection algorithm aggregate failures quantitatively 
focus ata measure 
de nes switch time interval point team member selects new team plan execution team point team agreement team plan executed 
perfect teamwork team members select new team plan jointly remain agreement 
realistic scenario agents take longer switch initially teamwork failure occur 
rst select new plan disagreement teammates rejoins executing original plan join selecting new plan 
switch begins detected failure ends failures detected 
shows illustration switch 
agents initial state agreement joint execution plan lled line 
agent rst agent switch plan dotted line followed agent nally agent 
switch interval begins instance agents selected plan time agents regained agreement time plan 
keeps track lengths time failures detected resolved 
ata measure average switch length time ticks complete team run mission modsaf game robocup 
perfect team switches length zero ata 
worst team task execution agree team plan executed 
instance robocup game lasts ticks 
worst possible team robust multi agent teams legend plan plan agent agent agent time switch illustration switch 
agents switch plan plan 
switch game length 
ata scale robocup goes perfect worst 
ata measure analyze series games robocup simulation league teams isis isis marsella xed opponent 
games varied communications teams evaluate design decisions communications 
approximately half games players allowed communications service teamwork 
half communications agents disabled 
isis played approximately games settings isis played games communication settings 
table shows mean ata values games sub teams having members isis isis ata values calculated separately sub team 
rst column shows sub team results refer row 
second columns shows mean ata sub team communications 
third column shows mean ata communications 
column shows size ata reduction drop mean ata values communications introduced 
column shows probability null hypothesis tailed test di erence ata means 
probability di erence due chance smaller numbers indicate greater signi cance 
isis mean ata mean ata ata test prob 
sub team comm 
comm 
reduction null hypothesis defenders defenders table average time agreement ata games 
clearly signi cant di erence emerges communicating non communicating versions sub team 
ata values indicate sharing information way communications signi cantly decreases time takes team members come agreement selected plan 
result agrees intuitions role communications sense may surprising 
ata reduction magnitudes indicate isis may sensitive loss communications isis 
di erences ata values isis approximately triple nearly times great isis 
explanation phenomenon isis composed players improved capabilities monitoring environment better knowledge environment 
isis dependent communications kaminka tambe teams isis composed players lesser environment monitoring capabilities 
isis players better able select correct plan relying teammates 
able maintain level performance communications 
contrast isis players rely passing information monitoring communications took longer establish agreement communications available 
validate hypothesis suggested ata measurements looking games measured score di erence game 
table shows mean score di erence series games 
rst column lists communications settings 
second third columns show mean erence games isis isis 
bottom row summarizes results tests run set games determine signi cance level di erence mean score di erences 
score di erence results corroborate ata results 
di erence mean score di erence statistically signi cant isis games signi cant isis games 
supports explanation aware isis better able handle loss communications isis 
isis isis communication communication test null hypothesis table isis isis mean score di erence changing communications settings general lesson emerging experiments trade exists addressing monitoring selectivity problem 
knowledge maintained teammates communications traded extent knowledge maintained environment 
designer range alternative capabilities choose agents 
di erent domains may better facilitate implicit coordination monitoring environment require agents rely communications explicit knowledge team members handle coordination 
ata results support additional especially combined general performance measure score di erence 
illustrate consider plots actual data games 
plots ata values variants sub team 
graph plots approximately data points 
see communications isis ata values generally better isis ata communications 
despite importance individual situational awareness able fully compensate lack communications 
demonstrates reuse teamwork monitoring techniques developed earlier sections line con guration 
designer isis set agents communications signi cant improvement score di erence 
contrast communications isis players able maintain collaboration 
communications takes precious resources relatively safely eliminated isis agents design development orts directed components agents 
robust multi agent teams isis comm 
isis comm 
isis comm 
isis comm 
average time agreement ata sub team ata values subteam ata values sub teams games 

teamwork general socially attentive monitoring framework detect failures maintaining agreement joint team plans 
ective operation teams relies additional relationships brie address section 
richer agreement model agreeing disagree teamwork model requires joint execution team plans 
service agreed joint plans agents may agree execute di erent sub plans individually split sub teams execute di erent sub team plans 
examples may serve illustrate 
example 
modsaf domain helicopters engage enemy repeatedly steps hiding hill trees masking popping shooting missiles enemy back hiding 
variations plan required sure helicopters shooting time 
course due limits communications helicopters fail time 
example 
robocup domain players isis isis marsella divided sub teams mid elders attackers defenders goalie close defenders 
division sub teams modeled agents selecting team plans service play team plan see 
mid elders select plan select defend goal plan ideally attacker select plan attack defender select plan defend due communication failures players may abandon intended sub team execute team plan sub team 
examples certain di erences agents agreed sign correct execution failure 
lack di erence selected plans kaminka tambe win game play interrupt 
attack defend defend goal simple advance flank attack score goal pass simple goal defense intercept kick reposition 
portion plan hierarchy isis robocup agents 
indicate failure cases 
term mutual exclusion coordination refer relationships 
example ideally pilots executing shooting plan time 
example members di erent sub teams attacker defender executing plan service play defend 
examples demonstrate clear need monitoring mutual exclusion coordination 
results previous sections re service socially attentive monitoring relationships 
require transformation implementation theory 
hierarchies compared usual manner failures signi ed equalities di erences 
instance attacker staying team half eld teammates may come suspect mistakenly attackers sub team believes defender 
analytical results inverted 
maximal team coherence heuristic lead completeness prefers hypotheses contain equalities agents failures mutual exclusion coordination 
maximal team incoherence heuristic lead sound detection prefers hypotheses imply equalities occurred 
properties proven formally 
theorem 
monitoring agent monitor mutual exclusion relationships group agents modeling complete uses maximally team incoherent hypothesis detection failure detection results sound 
proof 
provided appendix theorem 
monitoring agent monitor mutual exclusion relationships group agents modeling complete uses maximally team coherent hypothesis detection failure detection results complete 
proof 
provided appendix mutual exclusion relationships teamwork relationships guaranteed failure detection results may provided despite limited uncertain knowledge monitored agents 
centralized teamwork monitoring algorithms easily transformed monitoring mutual exclusion relationships 
unfortunately results distributed case theorem easily transformed rely property observable partitioning associated di erences equalities 
leave issue 
monitoring role similarity relationships section applies socially attentive monitoring role similarity relationships monitoring individual performance teams 
particular service team plans agents may select individual sub plans necessitate agreement team members constrained robust multi agent teams agents roles 
instance service executing team plan fly flight plan pilots individually select individual plans set velocity heading constraints formation ight method speci ed mission 
role similarity relationships specify ways individual plans similar extent 
agents role executing dissimilar plans considered violation role similarity relationships 
enables socially attentive monitoring system detect failure role execution 
monitor individual plans agent executing compares selection agents role similarly method teamwork 
plans considered similar role similarity relationship model failure detected 
failure may occurred diagnosis component called verify provide explanation 
illustrate failure modsaf domain system able detect role similarity relationship example 
team helicopters take base head mission 
pilot agents failed correctly process mission statement 
kept helicopter hovering base teammates left execute mission 
failures detected role similarity relationship monitoring 
agreed selected agents problem teamwork relationship detected 
team plan involved agent selecting individual methods ight determine altitude velocity 
agents di ered 
failing helicopter remained hovering teammates moved forward 
role similarity relationship failing helicopter compared selected plan teammate shared role subordinate formation realized plans dissimilar announce possible failure 
unfortunately actual similarity metrics domain task speci easy re domains 
furthermore detected failures necessarily real failures detected failures weight 
currently investigating ways address challenging issues 

related investigation socially attentive monitoring relationship knowledge maintained agents states monitoring ectiveness builds research di erent sub elds multi agent systems 
address sub elds section explain investigation related existing literature 
related teamwork previous teamwork recognized monitoring agents critical teams 
past investigations raised monitoring selectivity problem addressed depth 
building investigations begins provide depth answers problem 
theory sharedplans grosz kraus touches teamwork monitoring selectivity problem ways provides initial answers 
theory requires agents know teammates capable carrying tasks team 
authors note agents communicate plans convince teammates ability carry actions grosz kraus 
second theory requires agents mutual belief shared recipe state requires agents reason nite recursion agent beliefs 
unfortunately attainment mutual belief undecidable theory halpern moses approximated practice jennings rich sidner 
approximations may impose strong monitoring requirements 
third theory introduces kaminka tambe intention construct service coordination helpful behavior implying monitoring progress assess need behavior grosz kraus axiom 
fourth sharedplans requires intentions agent con ict grosz kraus axiom intentions particular intentions may involve attitudes agents monitoring detect avoid con icts implied 
authors point theoretically con icts detected infeasible practice grosz kraus 
suggest con ict detection prevention investigated problem speci manner minimal constraints monitoring capabilities mutual belief progress lack con icts provided sharedplans framework 
joint intentions levesque cohen levesque requires agent privately comes believe joint goal achieved unachievable irrelevant commit having entire team mutually believe case 
theory sharedplans mutual belief approximated practice imposes strong monitoring requirements 
monitoring selectivity problem raised practical implementations joint intentions 
jennings hypothesized central constructs cooperative multi agent coordination commitments agents conventions rules monitor commitments jennings 
conventions decide information needs monitored agents monitored 
instance convention may require agent report teammates changes privately detects respect team goal 
jennings raises monitoring selectivity problem provides example speci conventions high low bandwidth situations knowledge communicated agents bandwidth available 
jennings explore depth question conventions selected trade guarantees associated selection particular conventions 
instance guarantees ects low bandwidth convention example 
theoretical investigations described raise monitoring selectivity problem implicitly explicitly 
builds address problem depth context socially attentive monitoring teams 
reports soundness completeness properties teamwork relationship failure detection analytically guaranteed despite uncertainty knowledge acquired monitored agents 
analytical guarantees applicable plan recognition communications corroborated empirical results 
building theoretical practical teamwork systems include jennings rich sidner tambe 
jennings investigation joint responsibility teamwork model grate jennings builds joint intentions similarly implementation requires agents agree team plans execute 
grate industrial settings foolproof communications assumed jennings passive monitoring communications 
jennings provides evaluation grate performance respect communication delays guarantees provided respect failure detection 
grate maintains knowledge agents acquaintances models keep track team members capabilities service forming teams 
question knowledge models left unaddressed 
rich sidner investigate collagen collaborative user interface system communications reliable rich sidner 
human usability perspective limiting amount communications desirable 
address issue empirical lesh sidner rich utilizes plan recognition collagen focus collaborative settings plan recognition tractable 
instance ambiguities plan recognition may resolved asking user clari cation 
collagen investigate knowledge maintained ective collaborative dialogue robust multi agent teams user 
contrast able provide guarantees failure detection results algorithms 
dialogue plans risky points may allow systems collagen decide communications clari cation regardless plan recognition ambiguity 
steam tambe maintains limited information ability team members carry roles 
steam allows team members reason explicitly cost communication deciding communicate 
signi cantly extends capabilities plan recognition provides analytically guaranteed fault detection results 
furthermore teamwork failure detection capabilities useful trigger steam re planning capabilities 
related coordination huber huber jif investigated probabilistic plan recognition service active teamwork monitoring motivated unreliability costs passive monitoring military applications 
washington explores observation coordination markov models washington focusing making computations tractable 
contrast huber washington focuses monitoring selectivity problem 
showed strengths limitations centralized distributed approaches guaranteed failure detection results coherence disambiguation plan recognition hypotheses 
durfee discusses various methods reducing amount knowledge agents need consider coordinating 
methods discussed involve pruning parts nested models communications hierarchies abstractions focus methods modeling limited focus question modeling required guaranteed performance monitoring selectivity problem 
provide analytical guarantees trade involved limited knowledge agents failure detection purposes 
sugawara lesser report comparative reasoning analysis techniques service learning specializing coordination rules system distributed agents coordinate diagnosing faulty network 
investigation focused optimizing coordination rules minimize ine ciency redundancy agent coordinating messages 
detecting sub optimal coordination fault model agents exchange information local views system problem solving activity construct global view 
compare local view global view nd critical values attributes missing local view gave rise sub optimal performance problem 
values attributes constructing situation speci rules optimize coordination particular situations 
example network diagnosis agents may learn rule guides choose coordination strategy agent performs diagnosis shares result rest diagnosis agents 
socially attentive monitoring similarly uses comparison agents views drive monitoring process 
comparison product relationship monitoring 
sugawara lesser viewed letting agents incrementally optimize monitoring requirements results analytically explore level monitoring required ective failure detection di erent con gurations 
teamwork monitoring technique addresses uncertainty acquired information construct global view attributes system extremely expensive 
technique focuses triggering failure detection contrasting plans incrementally expanding search di erences diagnosis process 
robotics literature raised monitoring selectivity problem 
parker investigated monitoring selectivity problem di erent perspective formation maintenance task 
empirically examined ects combining socially attentive information referred local knowledge team goals concludes fault tolerant strategy agents monitor progress goals 
kuniyoshi kaminka tambe kuniyoshi ishii kita framework cooperation observations robots visually attend prerequisite coordination 
framework presents standard attentional templates monitors 
de ne team attentional structure agents monitor 
focuses monitoring selectivity problem socially attentive monitoring teamwork relationships provides analytical empirical results 
treat attentional templates product relationships hold system 
results show monitoring teams may necessarily require monitoring team members 
related 
lesser vincent xuan distributed diagnosis system multi agent intelligent home environment system uses fault models identify failures ine ciencies components guide recovery 
schroeder wagner proposed distributed diagnosis technique cooperating agents receive requests tests diagnoses send responses agents 
construct global diagnosis local ones produce receive assumption con icts occur 
frohlich nejdl investigates scheme multiple diagnosis agents cooperate blackboard architecture diagnosing physical system 
agents may di erent diagnosis models systems centralized con ict resolution agent employed handle con icts diagnoses 
approaches address monitoring selectivity problem 
social measures related ata 
goldberg mataric investigate multi robot foraging task measure interference amount time robots spend avoiding 
balch uses social entropy bailey measure behavioral diversity multi agent tasks soccer foraging formation maintenance 
investigations focus characterizing multi agent systems contexts speci tasks 
contrast focus providing useful feedback designer 
interference behavioral diversity ata measure domain task independent ideal value perfect teamwork may useful cross task comparisons 

motivated practical concerns 
begun investigation monitoring selectivity problem result observation failures continue occur despite agents monitoring conditions communications 
analysis failures revealed agents su ciently informed state 
need monitor teammates recognized repeatedly past jennings grosz kraus tambe monitoring selectivity problem question monitoring required remained largely unaddressed jennings grosz kraus 
provide key answers monitoring selectivity problem 
context monitoring teams demonstrate teamwork relationship failures detected ectively uncertain limited knowledge team members states 
show analytically centralized active teamwork monitoring provides failure detection complete unsound sound incomplete 
centralized teamwork monitoring requires multiple hypotheses monitoring team members 
contrast distributed active teamwork monitoring results complete sound failure detection despite simpler algorithm monitoring key agents team 
implemented general framework socially attentive monitoring empirically validate results modsaf domain 
provide initial results monitoring role similarity relationships initial diagnosis procedures 
demonstrate generality framework applying robocup domain show useful robust multi agent teams quantitative analysis generated line 
modsaf robocup dynamic complex multi agent domains involve uncertainties perception action 
attempted demonstrate results techniques applied domains 
explicitly pointed necessary conditions theorems hold team modeling completeness 
diagnosis algorithm sensitive accuracy knowledge may require assuming plans recognized soon selected 
conditions veri ed designer target application domain 
reactive plans chosen representation commonly dynamic multiagent domains 
focus monitoring agreements joint plans stems centrality similar notions agreement agent human teamwork literature jennings grosz kraus tambe 
additional areas conduct investigations 
important topic plan investigate depth strong requirements distributed teamwork monitoring algorithm terms observability 
order provide soundness completeness guarantees distributed algorithm relies ability team members monitor key agents 
investigating ways relax requirement providing guaranteed results 
addition diagnosis procedures extended formalized investigate ways alleviate sensitivity procedures choice team modeling hypothesis 
acknowledgments article partially aaai kaminka tambe agents kaminka tambe authors 
research supported part nsf isi part afosr contract 
je rickel george bekey victor lesser dan leary david pynadath useful comments 
anonymous reviewers helping ideas contributions revisions 
appendix proofs theorem 
page 
monitoring agent monitor simple team complete uses maximally team coherent hypothesis detection teamwork failure detection results sound 
proof 
show failure occurs detected failures detected 
agent members agent executing plan 
collectively group executing pn 
failure occurred agents executing plan executing plan team modeling complete correct hypothesis pn set team modeling hypotheses 
choose maximally team incoherent hypothesis choose correct hypothesis incoherent hypothesis implying failure occurred select hypothesis greater incoherence hypothesis equivalent level 
case failure detected detection procedure complete 
lemma 
page 
suppose simple team self monitoring members team monitor maximally team coherent heuristic assumption agent team modeling complete 
monitoring agent member executing detect failure maintaining teamwork relationships agent member executing di erent plan observably di erent role kaminka tambe proof 
knows executing members monitor monitoring observably di erent role executing observably di erent role 
perspective case assigns agent modeling hypothesis team modeling hypothesis executing executing plan words perspective team coherent hypothesis di erence detected theorem 
page 
monitoring agent monitor mutual exclusion relationships group agents modeling complete uses maximally team incoherent hypothesis detection failure detection results sound 
proof 
show failure occurred detected failure detected fact failure 
agent members agent executing plan 
collectively group executing pn 
failure occurred agent executing di erent plan 
group modeling complete correct hypothesis going set group modeling hypotheses maximally incoherent hypothesis selected di erent hypothesis coherence level selected 
hypothesis coherence level correct implies failure detected 
detection procedure sound 
theorem 
page 
monitoring agent monitor mutual exclusion relationships group agents modeling complete uses maximally team coherent hypothesis detection failure detection results complete 
proof 
show failure occurs detected procedure complete 
agent members agent executing plan 
collectively group executing pn 
failure occurred agents executing plan executing plan group modeling complete correct hypothesis pn set group modeling hypotheses 
choose maximally team coherent hypothesis choose correct hypothesis coherent hypothesis implying failure occurred select hypothesis greater coherence hypothesis equivalent level 
case failure detected 
detection procedure complete 
appendix socially attentive monitoring algorithms bring algorithms pseudo code plan recognition algorithm comparison test supporting detection simple non simple teams monitoring algorithms centralized distributed cases 
works rst expanding complete operator hierarchy agents modeled tagging plans non matching 
plans preconditions termination conditions agged non matching 
plans actions set expectations behavior 
initializing plan recognition hierarchy monitored agent observations agent continuously matched actions expected plans 
plans expectations match observations tagged matching ags propagated hierarchy complete paths hierarchy agged matching 
paths specify possible matching interpretations observations 
addition precondition robust multi agent teams termination conditions agged true signifying inferred appropriate belief modeled agents 
process described algorithm 
algorithm main loop matching observation making inferences hierarchy single agent 

get observations agent 
plan set expected observations compare observations expectations succeed ag plan matching successfully ag plan failing match 
plan agged matching successfully flag parents matching successfully propagate matching 
plan children agged failing match flag failing match propagate non matching detection failure centralized distributed teamwork monitoring algorithm shows comparison hierarchical plans carried 
limit simple teams 
algorithm accepts input sets hierarchical plan hypotheses associated agents clarity algorithms assume agents 
generalization agents straightforward 
algorithm accepts policy ag policy 
optimistic policy causes algorithm maximal team coherence provide sound incomplete detection 
pessimistic policy causes algorithm maximal team incoherence provide complete unsound detection 
set hierarchical plans marked hierarchy hierarchy 
agents marked agent agent 
algorithm predicate sub team agent agent depth true agents belong di erent sub teams level hierarchy 
algorithm hierarchical comparison agents allowing sub teams 

set depth look top di erence rst 
plans depth depth team plans policy optimistic plan plan maximally team coherent plans level depth hierarchy hierarchy respectively 
ii 
plan plan maximally team incoherent plans level depth hierarchy hierarchy respectively 
plan equal plan return failure ii 
bottom hierarchies reached return failure increase depth go 
plan team plan return failure return failure 
kaminka tambe aid algorithm de ne centralized distributed failure detection algorithms 
centralized teamwork monitoring algorithm algorithm utilizes algorithm twice checking failures pessimistic optimistic policies 
results policies agree certain 
results agree pessimistic policy causes failure detected optimistic policy causes failure detected monitoring agent certain failure taken place needs verify failure 
algorithm returns failure failure possible failure 
algorithm centralized teamwork monitoring applying optimistic pessimistic views 

optimistic result detect agent agent hierarchies hierarchies optimistic algorithm 
pessimistic result detect agent agent hierarchies hierarchies pessimistic algorithm 
optimistic result pessimistic result 
return optimistic result failure failure 
return possible failure distributed monitoring algorithm pseudo code form call algorithm optimistic policy parameter 
power derived fact members team monitor key agents team 
steel 

planning execution monitoring 
proceedings seventh national conference arti cial intelligence aaai minneapolis st paul mn 
aaai press 


re nement soccer agents positions reinforcement learning 
kitano 
ed robocup robot soccer world cup vol 
lnai pp 

springer verlag 
atkins durfee shin 

detecting reacting unplanned world states 
fourteenth national conference arti cial intelligence aaai pp 
providence ri 
aaai press 
bailey 

social entropy theory 
state university new york press 
balch 

behavioral diversity learning robot teams 
ph thesis georgia institute technology 
calder smith mar 

modsaf behavior simulation control 
proceedings third conference computer generated forces behavioral orlando florida 
cohen hart 

early warnings plan failure false positives envelopes experiments model 
tech 
rep technical report university massachusetts 
cohen levesque 

teamwork 
nous 
robust multi agent teams doyle atkinson 

generating perception requests expectations verify execution plans 
national conference arti cial intelligence aaai durfee 

ignorance knowing just coordinate 
rst international conference multi agent systems icmas pp 

kraus rosenschein 

coordination communication experimental validation focal point techniques 
international conference multi agent systems icmas pp 
california usa 
firby 

investigation reactive planning complex domains 
national conference arti cial intelligence 
frohlich nejdl 

resolving con icts distributed diagnosis 
wahlster 
ed th conference arti cial intelligence ecai 
john wiley sons goldberg mataric 

interference tool designing evaluating multirobot controllers 
fourteenth national conference arti cial intelligence aaai pp 
providence ri 
aaai press 
grosz kraus 

evolution sharedplans 
wooldridge rao 
eds foundations theories rational agency pp 

grosz kraus 

collaborative plans complex group actions 
arti cial intelligence 
grosz sidner 

plans discourse 
cohen morgan pollack 
eds intentions communication pp 

mit press cambridge ma 
halpern moses 

knowledge common knowledge distributed environment 
distributed computing 
hamscher console de kleer 
eds 

readings model diagnosis 
morgan kaufmann publishers san mateo ca 
lesser vincent xuan 

diagnosis integral part multi agent adaptability 
tech 
rep technical report university massachusetts amherst 
huber durfee 

acting communication 
working notes aaai spring symposium representing mental states mechanisms pp 
stanford ca 
jennings 

commitments conventions foundations coordination multiagent systems 
knowledge engineering review 
jennings 

controlling cooperative problem solving industrial multi agent systems joint intentions 
arti cial intelligence 
johnson rickel 

steve animated pedagogical agent procedural training virtual environments 
sigart bulletin 
kaminka tambe 

wrong 
improving robustness social diagnosis 
fifteenth national conference arti cial intelligence aaai pp 
madison wi 
aaai press 
kaminka tambe kaminka tambe 

ok re ok re ok experiments distributed centralized social monitoring diagnosis 
third international conference autonomous agents agents seattle wa 
acm press 
kinny ljungberg rao sonenberg tidhar werner 

planned team activity 
castelfranchi werner 
eds arti cial social systems lecture notes ai pp 

springer verlag new york 
kitano tambe stone veloso coradeschi osawa matsubara noda asada 

robocup synthetic agent challenge 
international joint conference arti cial intelligence ijcai nagoya japan 
kraus sycara 

agreements negotiations logical model implementation 
arti cial intelligence 
kuniyoshi ishii kita 

cooperation observation framework basic task patterns 
ieee international conference robotics automation pp 
san diego ca 
ieee computer society press 
lesh rich sidner 

plan recognition human computer collaboration 
proceedings seventh international conference user modelling ban canada 
levesque cohen nunes 

acting 
national conference arti cial intelligence menlo park ca 
aaai press 
malone crowston 

interdisciplinary theory coordination 
tech 
rep ccs tr ss wp msa massachusetts institute technology 
marsella kaminka muslea tambe 

teammate experiences acquired design robocup teams 
third international conference autonomous agents agents seattle wa 
acm press 
newell 

uni ed theories cognition 
harvard university press cambridge massachusetts 
parker 

designing control laws cooperative agent teams 
proceedings ieee robotics automation conference pp 
atlanta ga rao 

means plan recognition theory reactive recognition 
international conference knowledge representation reasoning kr pp 

tate 

synthesizing protection monitors causal structure 
arti cial intelligence planning systems aips chicago il 
rich sidner 

collagen agents collaborate people 
johnson 
ed international conference autonomous agents agents pp 
marina del rey ca 
acm press 
schroeder wagner 

distributed diagnosis vivid agents 
autonomous agents agents pp 
marina del rey ca 
acm press 
sugawara lesser 

learning improve coordinated actions cooperative distributed problem solving environments 
machine learning 
tambe 

tracking dynamic team activity 
proceedings national conference arti cial intelligence aaai 
robust multi agent teams tambe 

exible teamwork 
journal arti cial intelligence research 
tambe johnson jones laird rosenbloom 

intelligent agents interactive simulation environments 
ai magazine 
toyama hager 

rst don succeed 
fourteenth national conference arti cial intelligence aaai pp 
providence ri 
veloso pollack cox 

rationale monitoring planning dynamic environments 
arti cial intelligence planning systems aips pittsburgh pa cannon bowers 

impact cross training team functioning empirical investigation 
human factors 
washington 

markov tracking agent coordination 
second international conference autonomous agents agents pp 
minneapolis st paul mn 
acm press 

