volume roc surface multi class problems 
exact computation evaluation approximations technical report april ferri hern ndez dep 
inform tics computaci univ polit cnica de val ncia spain upv es receiver operating characteristic roc successfully applied classifier problems classes 
area roc curve auc determined better way evaluate classifiers predictive accuracy error 
extension area roc curve classes addressed date complexity precise definition 
real extension area roc curve form volume roc surface vus showing compute polytope corresponds absence classifiers trivial classifiers best classifier set classifiers 
compare real vus approximations extensions auc classes 
keywords cost sensitive learning evaluation roc analysis auc constraint satisfaction 
general classifiers predictions decision support 
predictions wrong important know effect predictions incorrect 
situations error consequences 
errors greater cost especially diagnosis 
instance wrong diagnosis treatment different cost dangers depending kind mistake done 
fact usually case misclassifications minority classes majority classes predicting system safe greater costs misclassifications majority classes minority classes predicting system safe 
obviously costs misclassification problem dependent case uniform single problem 
consequently accuracy generally best way evaluate quality classifier learning algorithm 
cost sensitive learning realistic generalisation predictive learning models allow better decision making 
quality model measured terms cost minimisation terms error minimisation 
cost matrices provided priori learning takes place matrices fully exploited obtain models minimise cost 
circumstances costs known priori models just evaluated chosen 
receiver operating characteristic roc analysis proven useful evaluating classifiers cases cost matrix known classifiers constructed :10.1.1.34.9927:10.1.1.34.9927
roc analysis provides tools select set classifiers behave optimally reject useless classifiers 
order convex hull classifiers constructed giving curve convex polygon 
roc analysis auc measure extensively area medical decision making field knowledge discovery data mining pattern recognition science general 
trivial case single class classifier forms segment roc curve polygon strict sense point classifier trivial classifiers classifier says class classifier says class origin area computed 
area called area roc curve auc better alternative accuracy error percentage instances correctly classified respectively incorrectly classified evaluating classifiers 
applicability roc analysis auc shown problems classes 
roc analysis extended theory multidimensional problems practical issues computational complexity representational comprehensibility especially preclude practice 
major hindrance high dimensionality 
confusion matrix obtained problem classes positions dimensions possible misclassification combinations needed evaluate classifier 
problem representation visualisation fact complexity computing convex hull points dimensions cost 
instance problem classes cost evaluating classifiers 
difficult possible perform roc analysis classes compute auc precisely volume roc surface vus 
trivial classifiers classes minimum volume maximum volume identified date literature 
approximations extensions auc measure classes hand till 
extension average possible pairs classes combination 
class shown classes 
approximations nature intuitive extensions lack theoretical justification goodness justification quite difficult obtained 
consequently able compute real vus classes important assess quality approximations 
trivial classifiers equations maximum minimum vus classifiers classes 
compute real vus classifier 
compare experimentally real vus approximations showing approximation best 
notions cost sensitive learning section include classical notions confusion matrices cost matrices roc analysis 
familiar issues skip section subsection 
misclassification results confusion misclassification matrix classifier usual accuracy lower say instance 
case may interesting know class misclassified goes error distributed 
confusion matrix practical intuitive way seeing distribution 
test examples classifier example confusion matrix classes follows actual predicted matrix understood follows 
examples class correctly classified class correctly classified misclassified misclassified 
class correctly classified misclassified misclassified 
notation matrix refers element predicted class actual class note easy obtain derived information confusion matrix 
vertical sums give distribution classes actual examples horizontal sums give distribution classes produced classifier 
confusion ratio matrix obtained normalising column actual predicted matrix represented note matrix original lost class distribution 
discussed frequently accuracy simplified measure quality classifier 
instance dataset distribution classes pa pb pc examples class simple classifier predicting class accuracy 
apart confusion matrices avoid kind oversimplification misleading assessing quality classifiers measures introduced separate predictive accuracies 
mean separate predictive accuracies product maximum derived informativeness measures 
try balance results accuracy different classes order improve results minority classes 
processing cost information classification problem domain information cost correct wrong classification different degrees detail 
cost matrix complete way provide information misclassification costs cost matrix known loss matrix indicates costs correct incorrect classifications 
example cost matrix classes follows actual predicted example shows usual portrait diagonal matrix shows costs correct classification 
values usually negative zero correct classification benefits costs 
values represent different cases misclassification 
instance value cell means classifying incorrectly instance instance cost 
notation matrix refers element predicted class actual class matrix confusion matrix easy compute cost classifier dataset just matrix product resulting matrix instance previous examples resulting matrix actual predicted just adding elements matrix cost cost small datasets costs computed parts model part decision tree may useful compute laplace corrected confusion matrix obtained determines strength laplace correction number classes cardinality :10.1.1.34.9927
cost matrix properties elkan presents desirable cost matrix properties classes case 
extend properties multiclass problems 
reasonable assume costs greater misclassification correct classification 
reasonableness condition stated sign replaced condition looser 
property expected cost matrix dominant rows row costs corresponding costs row 
formally 
case classes predicted situation whatsoever 
cost matrix normalisation cost matrix easy see divide element matrix constant resulting cost divided constant 
property normalise matrix give advantage 
usual normalisation performed cost matrix 
provided cost matrix lower costs correct classifications incorrect classification reasonableness property normalisation performed 
column select correct classification cost 

add value ith column 
see example 
cost matrix actual predicted corresponding normalised matrix actual predicted normalised matrix original correction derived cost independent specific dataset distribution :10.1.1.34.9927
instance class absolute frequencies na nb nc original cost computed derived cost traditional roc analysis receiver operating characteristic roc analysis allows evaluation classifier performance independent complete way just accuracy :10.1.1.34.9927:10.1.1.34.9927
roc analysis usually classes easy define interpret computationally feasible 
roc analysis classes notation confusion matrix actual true positives tp false positives fp predicted false negatives fn true negatives tn said roc analysis performed ratios easily obtained true positive rate tpr tp tp fn false negative rate fnr fn tp fn false positive rate fpr fp fp tn true negative rate tn fp tn forms confusion ratio matrix predicted actual tpr fpr fnr logically tpr fnr fpr 
equivalences provides means just selecting ratios construct bidimensional space working area 
roc analysis plotting true positive rate axis rate axis 
instance confusion matrix actual predicted tpr fpr 
easily draw point roc space called lorentz diagram shown fi gure 
true positive rate classifier false positive rate 
example roc diagram points represent respectively classifier classifies negative classifier classifies positive 
usually known trivial classifiers 
interesting things roc analysis summarised test set actual cost classifier computed actual probabilities classes cost matrix cost fnr fpr assuming correct classifications cost :10.1.1.34.9927:10.1.1.34.9927:10.1.1.34.9927
previous formula classifiers cost tpr tpr fpr fpr seen slope line 
classifiers line performance lines called iso performance lines 
classifiers obtain derived classifiers want segment connects just voting different weights 
consequently point segment cost class distribution cost matrix lower true positive rate higher false positive rate 
property classifiers discard classifiers fall convex hull formed points representing classifiers 
convex hull formed classifiers jointly points known roc curve 
due previous rationale best learning system produces set classifiers maximises area roc curve auc 
typical snapshot roc diagram illustrated 
suppose classifiers plotted obtained classifiers fall roc curve convex hull formed classifiers trivial classifiers 
discarded 
true positive rate false positive rate 
example roc curve extending roc analysis previous section shows usual way represent roc space opinion coherent way true class represented incrementally correct predictions false class represented incrementally incorrect predictions 
see choice extensible classes 
consequently previous classifier fnr fpr draw roc space shown 
false negative rate classifier false positive rate 
example inverse roc diagram points represent respectively classifier classifies negative classifier classifies positive 
roc curve computed points 
obviously new diagram looking maximisation area roc curve auc look minimisation 
better option compute area roc curve aac 
order maintain notation classical terminology refer aac auc 
confusion ratio matrix actual predicted representation area classifiers point representing classifier 
trivial classifiers classified classified 
wrong classifier 
area illustrated false negative rate auc false positive rate 
example auc inverse roc diagram roc analysis dimensions srinivasan shown theoretically roc analysis extends classes directly 
classes assuming normalised cost matrix construct vector dimensions classifier 
general cost classifier classes cost confusion ratio matrix absolute frequency class previous formula classifiers cost hyperplane 
values hyperplane straightforward easy obtain understand slope value bi dimensional case 
way bi dimensional case convex hull constructed forming polytope 
know classifier rejected seen intersection current polytope polytope new classifier give new polytope new polytope included polytope 
provided direct theoretical extension problems 
dimensions doubling doubling probability class effect performance doubling cost halving cost 
true dimensions 
answer direction change class distributions infinite corresponding cost matrices due degrees freedom 
best algorithm convex hull generation log 
case relatively straightforward detect trivial classifiers points minimum maximum cases 
computational limitations representational ones 
roc analysis dimensions nice understandable representation hyperplane defined mk xk mk arbitrary set 

directly extended classes classes dimensional space quite difficult represent screen try extend points classes case classes :10.1.1.34.9927
hasty extension maximum minimum polytopes classes know maximum polygon point representing best classifier classifier error 
trivial classifiers classified true classified false 
wrong classifier 
gives points segments auc 
minimum polygon trivial classifiers classified true classified false 
wrong classifier 
gives points segments auc 
extend classes 
wrong extension cost ratio matrix represent misclassification cells 
instance consider cost ratio matrix classes actual predicted ha hb hc gives dimensional point :10.1.1.34.9927
values ha hb hc dependent need represented ha hb hc think extension trivial just behaving way class case 
maximum point representing best classifier 
trivial classifiers 
extreme wrong classifiers corresponds corresponds appendix show graphical alternatives classical roc representation classes 
corresponds corresponds corresponds corresponds corresponds corresponds volume points minimum trivial classifiers 
extreme wrong classifiers corresponds corresponds corresponds corresponds corresponds corresponds corresponds corresponds volume points 
natural consequence obtain maximum times bigger minimum quite similarly classes case maximum times bigger minimum 
see extension valid correspond real roc analysis classes 
back discarding conditions considering maximum volume 
maximum volume represent volume containing possible classifiers 
maximum vus point long hypercube classifier valid classifier conditions easy obtain volume space determined equations just probability random numbers uniform distribution follow previous conditions :10.1.1.34.9927
precisely values uniform distribution represented probability point formed values follows previous conditions vus max easy see probability sum random numbers distribution exactly consequently vus max quite different previous value shown incorrect :10.1.1.34.9927
know exact maximum volume roc surface classes minimum 
minimum vus try derive minimum vus 
knowledge construct trivial classifiers follows actual ha ha ha predicted hb hb hb hc hc hc ha hb hc 
obviously include extreme trivial classifiers 
classifier actual vba predicted vab vbb vcb vac vbc vcc discard classifier iff trivial classifier formally ha hb hc ha hb hc vba ha ha vab hb vcb hb vac hc vbc hc derive theorem theorem knowledge classifier discarded min min min 
proof classifier equal worst actual predicted logically exists trivial classifier predicted ha hb hc vbb vcc actual ha ha ha hb hb hb hc hc hc ha ha hb hb hc hc discarded 
classifier discarded similar way ha hb hc 
consequently 
ha hb hc ha hb hc ha ha hb hb hc hc ha ha min ha min hb min hb previous property compute space classifiers follow condition min min min obtain minimum volume corresponding total absence information 
precisely compute volume formed condition jointly valid classifier conditions min min min volume difficult obtained probability estimation due min function 
compute volume monte carlo method 
monte carlo method obtaining max min vus monte carlo methods randomly generate subset cases problem space estimate probability random case follows set conditions 
methods particularly interesting approximate volumes volume roc curve dealing 
purpose generate increasing number points hypercube length generate variables uniform distribution check follow previous maximum minimum conditions :10.1.1.34.9927
working length hypercube proportion cases conditions exactly volume looking 
particular obtained results maximum cases matches quite exactly theoretical vus max 
minimum cases approximately 
obtained exact maximum obtained exact minimum conjectured 
obtain real vus min importantly obtain roc polytopes form volumes 
constraint satisfaction obtaining roc polytopes previous section developed conditions maximum minimum vus respectively best classifier known classifier absence information 
interested way obtain border points space polytopes represent cases 
need way compute polytopes set conditions 
general system able available quite 
system hsa 
search algorithm hsa nowadays real problems efficiently modelled constraint satisfaction problems csp 
problems naturally modelled non binary constraints continuous variables 
researchers traditionally focused binary constraints discrete variables due simplicity dealing binary constraints fact non binary csp transformed equivalent binary 
transformation may practical problems 
traditional csp techniques obtain solution searching systematically possible assignments values variables 
complexity techniques increases exponentially number variables number constraints domain length 
search algorithm hsa solves non binary continuous constraint satisfaction problems natural way non binary csp solver 
hsa constraint propagation algorithm carries search maintains vertices solutions satisfy non binary constraints 
hsa handling non binary constraints linear inequations seen global constraint 
initially created cartesian product variable domain bounds 
constraint hsa checks consistency updating constraint consistent means linear programming techniques 
constraint hyperplane intersected obtain new vertices 
resulting convex set solutions csp 
solution csp assignment value domain variable constraints satisfied 
objective csp solver may determining solution exists csp consistent solution solution extreme solutions minimal variable domain optimal solution means objective function defined terms certain variables 
roc surface problem focus objective hsa determine extreme solutions order calculate convex hull resulting 
hsa handle open forming closed polytope hsa compute volume 
purpose going qhull 
qhull things algorithm implements quick method computing convex hull set points volume hull 
ready obtain points conform max min volumes 
maximum vus points classes recover equations maximum volume valid classifier conditions introduce equations hsa look solutions variables 
obtain points volume expected 
hsa generates convex polytope check points eliminated 
case points exactly surface volume removed modifying volume 
simplified set points vus max points volume contains point representing best classifier 
trivial classifiers 
extreme wrong classifiers corresponds corresponds corresponds corresponds corresponds corresponds corresponds corresponds points representing classifiers classify correctly classes third class wrong class :10.1.1.34.9927
corresponds 
corresponds 
corresponds 
corresponds 
corresponds 
corresponds 

points representing classifiers classify correctly class mixed 
corresponds corresponds corresponds points representing classifiers classify correctly class mixed way class predicted :10.1.1.34.9927
corresponds corresponds corresponds corresponds corresponds corresponds points summarised classifiers column minimum vus classes theorem order compute minimum vus compute space classifiers follow condition min min min obtain minimum volume corresponding total absence information 
condition jointly hyper cube conditions min min min min function directly handled hsa convert equation equations obtain points volume approximately matches volume obtained monte carlo method 
points exactly surface volume removed modifying volume 
simplified set points volume contains vus min points trivial classifiers 
extreme wrong classifiers corresponds corresponds corresponds :10.1.1.34.9927
included corresponds corresponds corresponds 
included 
corresponds corresponds detected classifiers included minimum polytope include wrong extension section 
fact express clear way points points correspond trivial classifiers modified way classify class original class corresponds corresponds corresponds corresponds corresponds corresponds importantly set classifiers defined exactly classifiers row :10.1.1.34.9927
summing vus classes theoretical monte carlo cases vus max exact hsa vus min conjecture computing vus classifier obtain vus classifier just adding coordinates point represents adding new point minimum computing convex hull 
hasty step 
surprise come take minimum points add origin best classifier error 
case obtain points volume greater volume maximum 
best classifier obtain maximum volume 
reason 
perfect classifier represented point classifier value equal greater coordinate discardable logically give 
issue add new classifier consider conditions produces 
perfect classifier generates discard equations disequations null values positive valid classifier conditions maximum volume 
consider thing arbitrary classifier actual zca predicted zab zac discarded 
classifier improved classifier combined trivial classifiers classifier greater values dimensions :10.1.1.34.9927
consequently new classifier actual vba predicted vab vbb vcb vac vbc vcc look classifiers constructed linear combination trivial classifiers classifier see worse constructed classifiers 
formally linear combination defined ha hb hc hd zca zab zac discard ha hb hc hd ha hb hc hd vba ha hd ha hd zca vab hb hd zab vcb hb hd vac hc hd zac vbc hc hd gives system disequations variables input hsa obtained variables point :10.1.1.34.9927
represents way obtain vus point 
see examples monte carlo cases exact hsa 
example vus points see methods agree significantly hsa method gives exact value quicker monte carlo method 
points match maximum minimum volumes expected 
real vus classifier way set classifiers compute true vus set just generalising previous formula 
illustrate classifiers fact consider linear combination trivial classifiers classifiers ha hb hc discard zca zab zac wca wab wac xab yac ha hb hc hd ha hb hc vba ha ha zca wca 
vab hb zab wab xab vcb hb vac hc zac wac yac vbc hc gives system variables solved hsa retain just variables obtain polytope :10.1.1.34.9927
maximum vus classes obtain maximum vus number classes 
point xc xc classifier valid classifier conditions 
xc 
xc 
easy see volume space determined equations vus max probability sum random numbers distribution difficult obtained 
particular probability density function sum uniform variables interval obtained characteristic function uniform distribution 
cost sin 
cumulative distribution function dx sgn consequently probability sum random numbers distribution 
dn lim dx sgn dx 
considering conjecture dn 

lo 
gives gives gives conjecture characterisation points maximum classifiers column rest minimum vus classes exact minimum classes obtained hsa arrive direct theoretical value 
observing results classes conjecture classes 
gives gives gives 
points minimum polytope defined conjecture classifiers row 
conjecture matches classes 
table shows summary results general case conjectures exact results classes 
vus general max 
min 
theoret 
monte carlo exact hsa theoret 
monte carlo exact hsa 
evaluation multi class approximations vus previous section developed method conditions hsa obtain real vus classifier arbitrary number classes 
exact computation quite efficient classes impractical higher number classes higher number classifiers 
literature approximations extension auc measure multi class problems 
appraisal estimation theoretical practical 
section gather remind approximations auc classes known date macro average point trivial auc extension hand till variants 
going comparison measures exact vus hsa method 
give definitions classes easily extended classes 
definitions consider class classifier actual vba predicted vab vbb vcb vac vbc vcc macro average macro average just defined average partial accuracies class vbb vcc measure simple way handle appropriately unbalanced datasets roc analysis 
macro average modified measure employs average geometric means 
defined follows mod 

aa modify original definition macro average consider standard deviation points 
instance classes point obtains auc point points identical macro average 
measures mse logloss auc measure tells separated estimated distributions class class hand till 
develop measures try approximate separated distributions 
measure kind known mean squared error measure 


mse actual probability example class estimated probability example class denominator gives normalised mse 
classification problems depending class 
considered measures derived original mse mce mpe bb 





cc measure log loss claimed measure goodness probability estimates bernardo smith mitchell 
aa bb cc logloss log 

note measures closely related 
said measure tells separated estimated distributions class class hand till 
quite measured expression expression log 
measures advantage easier understood computed 
obviously problems generalisation classes 
point trivial auc extension going back classes area point vba vab representation defined auc max vba vab extending trivially previous formula extension point extension auc pt max vba vab vcb vac vbc easy see extension quite macro average columns matrix sum 
difference pt measure lower 
point hand till extension hand till generalisation auc measure soft classifiers classifiers assign different score reliability probability prediction 
deal soft classifiers adapt hand till formulation crisp classifier classifier predict possible classes giving additional information reliability probability predicted class classes 
hand till extension classes idea compute auc classes denote compute extension auc arbitrary number classes choosing possible pairs 
simplified shown hand till function pursuing idea going introduce variants 
variant consider macro average extension 
ht max vbb max vcc max vbb vcc turns similar pt going take failures account hits ht max vba vab max vac max vcb vbc measure slightly different previous ones 
different way obtain normalise 
instance normalise classes actual predicted vab vba vba vbb vab vab vbb vba vbb max rest combinations 
ht max vba vba vbb vab vab max vcc vac vac max vcb vcb vcc vbc vbb vbc define third variant computing partial aucs pairs classes computes auc class rest average results 
instance auc class rest joined obtained condensed matrix predicted vab vac rest cells rest rest actual rest vab vac vab vac vba vba vbb vbc vcb vcc vbb vbc vcb vcc vba vbb vbc vcb vcc rest max vab vac vab vac vba vba vbb vbc vcb vcc way obtain rest rest 
allows define ht ht rest rest rest monte carlo estimation saw previous sections monte carlo method quite exact obtaining maximum minimum vus 
arbitrary classifier condition ha hb hc hd ha hb hc hd vba ha hd ha hd zca vab hb hd zab vcb hb hd vac hc hd zac vbc hc hd condition incorporate new loop monte carlo method emulate existential quantifier 
consequently outer loop number instances inner loop generates possible values ha hb hc hd uniform distribution ha hb hc hd 
slow obtain approximations 
case compare possible monte carlo estimation outer loop iterations inner loop iterations 
experimental evaluation previous approximations ready evaluate comparison exact computation hsa method 
going examine results methods arbitrary points shown table classifier point monte carlo exact hsa macro avg trivial ht ht ht 



complete complete complete notice take hsa monte carlo behave quite similarly order :10.1.1.34.9927
hand approximations give ranking specially part classifier discriminated order swapped 
expected approximations fail cases 
evaluate approximation best going experimental methodology size experiment initialise matrices hsa monte nxn auc pt 
initialise matrices ht ht ht 
generate valid classifiers randomly 
generation classifier performed way compute exact vus hsa 
methods 
endfor endfor mark hsa value value value methods endif endfor compare matrices way matrices different methods compare discrepancy disc formula evaluate discrepancy methods class problems respect real vus computed method 
results accuracy macro avg new macro trivial ht ht ht mse mce mpe discrepancies methods 
results best approximation macro average modified 
measure obtains lower discrepancy studied approximations 
computing real vus soft classifiers computed vus point set points represent crisp classifiers classifiers prediction probabilities scores 
increasingly usual machine learning methods devised obtain soft classifiers classifiers accompany prediction reliability better estimated probabilities class 
class case soft classifier construct infinite classifiers changing predictions threshold 
thing class case predictions different estimated probability vector classifiers considered 
soft classifiers classes 
instance soft classifier classes generate classifiers different probability vectors gives 
case decision tree learner number leaf nodes tree cases may number examples 
instance class decision tree classifier nodes node estimated class prob 
vector crisp classifier maj class generate classifiers form polytope :10.1.1.34.9927
theoretically obtain polytope method solving system classifiers trivial classifiers included 
practice quite unfeasible great values open question see assignments discarded order reduce complexity 
preliminary ideas appendix approximations area roc curve classes soft classifiers computing real vus point small set points quite feasible practice 
true soft classifiers seen want consider possible assignments 
interested approximations perform evaluation approximations 
hand till function hand till generalisation particular auc measure 
shown dimensions auc measure equivalent gini measure gini measure gini splitting criterion cart algorithm 
idea auc measure dimensions estimated probabilities example xi pertaining class denoted estimated training set rank pairs gk fk gk fk defined gi fj examples test set class examples test set class 
note ordering nodes order examples 
instance consider nodes training set node class prob node class prob consider test set distributed way decision tree node node elements class elements class :10.1.1.52.9010
class class class class rank described :10.1.1.34.9927
denote ri rank ith class test set point 
denote ri 
derive area area auc equivalence gini main differences respect usual roc curves similar proposal step stairs area diagonals points computed 
convex order training set examples test set 
apart relevant novelty hand till understand measure separated estimated distributions class class computed pair classes interpretation allows call simple generalisation auc multiple class classification problems 
define new measure fawcett extension extension similar hand till includes probability 
definition follows rest rest computes auc class times considers classes 
optimisation hand till function 
main difference lies fact includes probability class factor independent class probabilities biased datasets 
roc analysis extension classes 
way problem simplified approximate problem dimensions classes 
class case permits graphical representation 
presents interesting representation class soft classifiers 
consider soft classifier example provides estimated probabilities class pa pb pc 
consider pa pb pc plot vectors triangular estimate plane labelling point true class validation test set 
instance picture shows examples classifier gives different class vector estimations interesting graph classes remarkable proposal idea class decision rule decision rule pa classify pb pc classify classify instance fix areas triangle dimensional plot just diagonal confusion matrix completely ignoring way gives different classifier consequently different point value choose 
choosing infinite different surface compute volume surface vus 
computing volume gives vus different extension auc classes 
depending priorities classes different vus ab vus ac vus ba vus bc vus ca vus cb 
define vus mean 
interesting thing interpretation auc alternative forced choice decision task examples class correctly classified classify greater pa classify 
extends class vus vus probability examples class correctly classified decision rule choose 
alternative forced choice decision task 
instance decision rule approximate probability just selecting triplets examples different classes obtain class vectors soft classifier applying decision rule 
gives probabilistic interpretation vus particular wide range different 
additionally change decision rule 
instance proposes second decision rule decision rule ii classify greater pa remaining classify greater pb 
classified 
depending variant rule vus vus ab vus ac vus ba vus bc vus ca vus cb 
define vus mean 
third decision rule decision rule iii plot points triangular estimate plane 
assign tree points class way total length segments minimised 
rule illustrated note third decision rule gives interpretation vus case graphical probability 
opinion reasonable 
approximations evaluated 
easy extended classes especially vus vus variants 
consequently follows refer vus 
evaluation approximations performed experimental evaluation previous approximations similar way done section crisp classifiers 
roc analysis techniques stratification generate set points soft classifiers order compute curve classifier 
due limitations number equations method apply method soft classifiers 
simulate soft classifier generating points way explained section roc space 
compute exact vus method 
rest approaches compute vus independent point final vus average points 
construct discrepancy matrix different simulated soft classifiers 
matrices discrepancy approaches respect exact vus computed method accuracy macro avg trivial ht ht ht mse mce mpe discrepancies methods 
results best approximation ht approach 
note discrepancy case higher due important increment complexity problem 
scattering factor vus set points closely related space scattering points 
way estimate vus compute disaggregate points space 
idea define new factor defined follows set points dimensions dimension coordinates ranked pd compute partial dissemination mi pn vi pn pn pn pn mi global dissemination computed average dimensions 
md employ factor final estimation follows vus hn exp approximation vus point exp correction value scattering factor 
experiments value best performance obtained applied correction ht approach discrepancy matrix computed classifiers simulated points respect method ht application scattering correction improves points approximately ht regard method 
highlighted limitations current approaches problems classes proposing extensions alternatives 
identified trivial classifiers neglected direct wrong ways extend class auc general vus 
derived discard conditions identified maximum minimum vus polytopes vus arbitrary set crisp classifiers 
computed hsa algorithm 
compared experimentally real vus approximations crisp classifiers showing approximation best 
best approximation ht simplification hand till function crisp classifiers 
soft classifiers shown compute polytope form possible assignments recognised limitations computing practice 
case performed limited comparison showing best approximation soft classifiers ht 
case introduced correction dissemination points space allows improve ht approximation 
soft classifier case trying find way simplify set points order better evaluation derive method compute real vus soft classifiers reasonable time 
prove conjectures introduced 

adams hand comparing classifiers costs uncertain pattern recognition vol 
pp 


barber qhull geometry center university minnesota www geom umn edu software qhull 

bernardo smith bayesian theory john wiley sons 

blockeel classifiers experiments sisyphus data set ecml pkdd workshop integrating aspects data mining decision support meta learning 

algorithmic geometry 
cambridge university press 

bradford kunz kohavi brunk brodley pruning decision trees misclassification costs proc 
european conference machine learning pp 


breiman friedman olshen stone classification regression trees belmont ca wadsworth 

domingos metacost general method making classifiers cost sensitive proc 
fifth international conference knowledge discovery data mining pp 
new york acm 

ohno machado binder comparing tests way roc analysis medical decision making 

drummond holte exploiting cost sensitivity decision tree splitting criteria proc 
seventeenth international conference machine learning pp 


elkan foundations cost sensitive learning proc 
seventeenth international joint conference artificial intelligence ijcai 

fan stolfo zhang chan misclassification cost sensitive learning proceedings sixteenth international conference machine learning icml pp bled slovenia june 

fawcett rule sets maximize roc performance ieee international conference data mining icdm 
ferri ram rez flach hern ndez rocking roc analysis decision trees technical report dep 
computer science university bristol 

hand construction assessment classification rules 
chichester wiley 
se 
hand till simple generalisation area roc curve multiple class classification problems machine learning 

hanley mcneil meaning area receiver operating characteristic roc curve radiology 


kearns mansour boosting ability top decision tree learning algorithms proceedings eighth acm symposium theory computing pp 
new york acm press 

cost sensitive pruning decision trees proc 
european conference machine learning ecml pp 
berlin germany springer verlag 

kononenko cost sensitive learning neural networks proc 
thirteenth conference artificial intelligence chichester ny wiley 

lane extensions roc analysis multi class domains icml workshop learning 

lavrac turney cost sensitive feature reduction applied hybrid genetic algorithm proc 
seventh international workshop algorithmic learning theory pp 
springer berlin 

dietterich learning decision trees loss minimization multi class problems technical report department computer science oregon state university 

dietterich bootstrap methods cost sensitive evaluation classifiers proceedings seventeenth international conference machine learning icml pp morgan kaufmann san francisco ca 

comparing areas independent roc curves med 

making 

mitchell machine learning mcgraw hill 

way medical decision making 

roc curves test accuracy description diagnostic tests 
clin 
neurosci 


pazzani merz murphy ali hume brunk reducing misclassification costs proceedings th international conference machine learning morgan kaufmann 

provost goal directed inductive learning trading accuracy reduced error cost aaai spring symposium goal driven learning 

provost fawcett analysis visualization classifier performance comparison imprecise class cost distribution proc 
third international conference knowledge discovery data mining kdd pp 
menlo park ca aaai press 

provost fawcett kohavi case accuracy estimation comparing induction algorithms icml fifteenth international conference machine learning july 

provost fawcett robust classification imprecise environments machine learning 
quinlan 
programs machine learning san francisco morgan kaufmann 

quinlan improved continuous attributes journal artificial intelligence research 

barber incremental non binary csp solver search algorithm short version proceedings seventh international conference principles practice constraint programming cp 
springer verlag lncs pp 

barber constraint satisfaction means dynamic polyhedra operations research proceedings 
springer verlag isbn pp 

smith jain testing uniformity multidimensional data ieee trans 
pattern analysis machine intelligence pp :10.1.1.34.9927


srinivasan note location optimal classifiers dimensional roc space technical report prg tr oxford university computing laboratory wolfson building parks road oxford 

swets monahan better decisions science scientific american october 

turney cost sensitive classification empirical evaluation hybrid genetic decision tree induction algorithm journal artificial intelligence research pp 


turney types cost inductive concept learning proceedings workshop cost sensitive learning seventeenth international conference machine learning icml 

university california uci machine learning repository content summary www ics uci edu mlearn html 

weiss provost effect class distribution classifier learning empirical study technical report ml tr department computer science rutgers university 

zweig campbell receiver operating characteristic roc plots fundamental evaluation tool clinical medicine clin 
chem 
appendices appendix graphical alternatives roc analysis classes cobweb representation dimensional points roc space corresponding classifiers draw cobweb representation 
instance classifiers confusion ratio matrices predicted point point point actual actual actual obtain values classifier case point space :10.1.1.34.9927
values different dimensions point formed values confusion ratio matrix ignoring diagonal 
represented graphically cobweb representation follows 
point point point note point discarded point coordinates 
previous representation allows determining classifier strong weak points simple cases discarded 
previous representation disadvantages classifiers representation gets highly confusing classifiers get close 
convex hull drawn recognised consequently classifiers misclassification coordinates coordinates classifier discarded 
graphically ignores pair classifiers combined produce infinitely classifiers stochastically combining predictions 
precisely convex hull computed 
lattice representation partially graphical representation quite related previous defining partial order classifiers defined way dimensional points iff pi qi just consider points confusion ratio matrices point pi 
consequently set classifiers add points construct lattice 
instance previous example lattice point discarded point lattice representation cobweb representation disadvantages points representation gets large 
convex hull recognised consequently points misclassification coordinates coordinates point discarded 
representation cobweb representation equivalent 
appendix class assignments needed 
know class case possible assignments assignments strictly necessary supposing test set behave similarly train set 
similar reduction classes 
class assignment cost matrix derived weights provided user class node rule computed majority class class minimises cost examples fall node current cost matrix 
concretely cost class selected cost number training examples class assigned class arg min apparently difference dimensions 
strange assignments classes 
instance classes node rule elements class supposed selected supposing cost matrix reasonable sense described section 
see case dimensions 
just study behaviour node rule class problem depending cost matrix 
context cost matrix actual predicted costs greater 
leaf ea eb ec leaf assigned iff eb ec ec leaf assigned iff ec eb ec leaf assigned iff ec ea ec express problem shortly defining parameters easy choice xa xb xa xc class class xb xc class class suppose elements class say ea 
show node assigned iff eb ec ec consequently node assigned iff eb ec ec imagine situation ec eb iff node assigned happen having element class node node assigned class issue just case eb ec say leaf assigned proof obvious case assigned iff ec ec ea true means assigned 
