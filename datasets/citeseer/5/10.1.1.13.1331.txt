wearable sensing annotate meeting recordings kern bernt schiele perceptual computing computer vision eth zurich kern schiele inf ethz ch propose wearable computers sensor systems generate personal contextual annotations audio visual recordings meetings 
argue annotations essential effective allow retrieval relevant information large audio visual databases 
proposes useful annotations derived cheap unobtrusive sensors 
describes hardware platform designed implement concept presents experimental results 

interestingly tera bytes storage sufficient record audio visual information person perceives entire lifespan amount storage available average person distant 
wearable recording computing device remember talk discussion environment saw 
today usefulness data limited lack adequate methods accessing indexing large audio visual databases 
interestingly humans remember events retrieve memories information time date location content discussion 
humans additional personal experience contextual information remember retrieve memories 
propose wearable sensors order enhance recorded data allow associative access 
context wearable computers particularly interesting allow truly personal audio visual record environment person 
hat camera microphones attached chest shoulders person enable recording perspective 
additionally wearable sensors accelerometers biometric sensors enhance assuming lifespan years recording day mb min recording results approximately tb holger junker paul lukowicz gerhard tr ster wearable computing lab eth zurich junker lukowicz ife ee ethz ch recording additional personal information 
sensor information annotate structure data stream access 
obviously automatically annotating structuring entire life record person extremely ambitious probably general problem 
deals specific problem annotation meetings presents diverse setting 
meetings week 
wearable record meetings won meetings efficient 
may allow user recall encountered discussed agreed disagreed arguments participant 
may easier reconstruct decision taken 
meetings may take place room instrumented dedicated hardware 
generally meetings take place outdoors mobile setting 
important discussions may take place break corridor 
wearable computers stay person time particularly suited general meeting scenario 
contributions firstly discussion possible annotations meeting recording facilitate associative retrieval section 
secondly investigate audio data section accelerometer data section automatically generate interesting annotations 
feasibility annotations shown experimentally section 
thirdly designed implemented distributed accelerometer network extract information user movements postures section 
section discusses approach gives brief outlook 

related idea computer support human memory retrieval new 
lamming flynn example point importance context retrieval key cues location phone calls interac tion different pdas 
conference assistant supports organization conference visit annotation talks discussions retrieval information visit :10.1.1.41.737
cooperation communication different wearables environment essential part system 
rhodes proposed text remembrance agent help people retrieve notes previously computer :10.1.1.16.9692
speech recognition automatic speech transcription meetings extremely challenging task due overlapping spontaneous speech large vocabularies difficult background noise 
multiple microphones close talking table microphones microphone arrays 
project example aims retrieve information roughly transcribed speech recorded meeting 
summarization topic currently investigation speech recognition video processing :10.1.1.27.9310
strongly believe summarization allow effective particular associative access recorded data see section 
noted methods complementary proposed approach integrated eventually 
richter le propose device predefined commands record conversations take photos 
university tokyo researchers investigate possibilities record subjective experience recording audio video heartbeat skin conductance recall experience various aspects 
wearable device tries mimic wearer selective memory 
idea mann related idea constantly recording visual environment 

annotating meeting recording ultimate goal system facilitate efficient indexing retrieval audio visual data recorded meetings 
general idea support extend human memory means wearable computer 
context interesting note human brain heavily uses associative memory access 
humans retrieve memories event time date name person precise attributes 
humans remember retrieve things context information weather happened meeting people discussion 
proposes enhance annotate meeting recordings context information order enable associative retrieval information 
interesting annotations meetings 
standard generate summaries meetings written digital form 
summaries close humans retrieve information memories 
looking particularly envisioned meeting scenario identified classes relevant annotations 
different meeting phases flow discussion user activity reactions interactions participants 
meeting phase includes time presentations breaks somebody coming leaving meeting 
flow discussion annotations attach speaker identity changes audio stream indicate level intensity discussion 
help differentiate single person presentations interactive questions answers heated debate 
user activity reactions indicate user level interest focus attention agreement disagreement particular issues comments 
tracking interaction user participants personal discussions differentiated general discussions 
wearable sensors annotate meetings 
wearable sensors opens opportunity add relevant annotations classes 
concentrate audio identify speakers speaker changes 
propose distributed accelerometer network identify user reactions activities walking standing sitting 
hand movements shaking hands clear social meaning detect interactions participants 
additional information derived correlating channels 
example speaker change head turning indicates shift focus attention 
similarly coincidence speaker change head nodding shaking indicate agreement disagreement just said 
advantage approach lies fact complex information derived small unobtrusive lowpower devices 
collaborating wearables 
interesting aspect meeting wearable devices individual participants collaborate 
extreme user access data recorded annotated wearable 
case computing sensing consequently power requirements quite high 
extreme participants possess wearable share information 
case decision speaking simpler task relatively simple detect user wearable device talking see section 
wearables share information obvious question trust 
sharing information trusted wearables rich source additional information slides presenter transcribed speech presenter near mixture extremes wearable designed adapt scenarios appropriate fashion 
sn 
identification model single speaker left segmentation network right 
audio context speaker segmentation pointed earlier text transcript meeting may sufficient associative retrieval 
flow discussion indicates intensity allows tell presentation discussion 
transcription speech setting multiple speakers spontaneous simultaneous speech large vocabularies microphone worn user hard problem despite advances speech recognition technology 
concentrate finding speaker changes identities 
setting microphone attached user wearable computer 
exploit fact detect user speaking mainly looking energy recorded audio signal 
section show method effectively improves speaker recognition 
related problems speaker recognition segmentation addressed fundamentally different approaches clustering hidden markov models hmms 
uses agglomerative clustering distance segmentation detect speaker changes bayesian information criterion discard invalid changes :10.1.1.20.9543
methods combine reliability reasonable cost price non real time performance 
identification speakers done hmms similar speech recognition 
topology hmm distorted identification speaker actual utterance really time dependent 
uses single state gaussians uses parallel states single speaker hmm :10.1.1.127.6858
case multiple speakers hmm viterbi algorithm allows speaker identification real time 
speaker models need training approaches require audio data speaker advance 
speaker segmentation speaker identification identification speakers speaker seg cm mentation 
assume know participating speakers 
allows take approach wilcox performs real time produces segmentation identification speakers :10.1.1.20.9543
hmms trained mel cepstral coefficients ms non overlapping windows 
topology speaker hmm depicted left 
system states 
speaker hmms combined segmentation network see right 
speaker models trained separately segmentation network recognition 
viterbi algorithm finds optimal path hmm speaker detects speaker changes 
selected empirically discourage short speaker changes due isolated speech vectors 
training recognition hmm toolkit htk :10.1.1.41.737
analysis approach monitoring user activity reactions importance human posture gesture 
situations activities characterized specific body position limbs motion pattern 
person presenting talk standing possibly slowly walking back forth moving arms 
contrast somebody eating lunch sitting predominantly looking periodically lifting sandwich plate mouth 
detect postures body parts motions rely network axis accelerometers distributed user body 
accelerometer provides information orientation movement corresponding body part 
advantage approach lies small size energy efficiency acceleration sensors 
addition modest amount preprocessing minimal communication bandwidth needed read relevant information 
network unobtrusively integrated arbitrary 
devoted context detection exception relied sensors distributed hand distributed network studied :10.1.1.41.737
detailed description approach movement posture recognition scope 
section provides overview hardware principles classification postures motions sensor data 
hardware sensor node consists dual axis accelerometers analog devices adxl combined allow measurement linear acceleration space msp low power bit mixed signal microprocessor mpu texas instruments running mhz maximum clock speed 
mpu reads sensor signals handles communication modules dedicated pins 
setup relies analog outputs accelerometers second order key low pass filters 
optionally single axis gyroscope mounted board 
modules miniaturized mm smaller devices desirable locations head fingers 
modules partitioned consist parts main part microcontroller filters amplifiers sub part sensors mounted directly main unit connected wires 
illustrates assembly node block diagram 
modules adxl control leds interfaces msp murata gyroscope optional filters gain amplifiers 
left main board sub board sensor node dollar coin right corresponding block diagram sensor node powered single central power supply consisting step regulator small mobile phone camcorder battery 
power supply unit part central control module 
module gps receiver blox gps ms hitachi sh processor 
apart serving central control unit network serial interface computer module provide absolute location information 
network communication sensor network wire bus 
wires implement communication nodes bus third synchronize sensors 
sensor platform partitioned subnetworks reflecting anatomical relations body parts 
example sensors upper lower leg possibly foot constitute single subnetwork 
subnetwork particular sensor module acts master handles communication sensor nodes slaves channel 
masters subnetworks slaves upper network layer central module hitachi sh processor serves master 
layered hierarchical network architecture allows optimize communication terms network load considerable amount pre processing done locally subnetwork 
communication layers consists high level features represented numbers large amounts raw data 
second advantage distributed data processing approach allows reduce computational load central master node layer 
shows hierarchical network structure possible sensor locations 
sensors labeled experiments 
central master master subnetwork slaves subnetworks sensor locations experiments right upper leg right wrist right lower arm right upper arm forehead chest left lower arm 
hierarchical network observation channels 
recognition methodology approaches activity recognition wearable accelerometers rely parameters directly derived raw accelerometer data :10.1.1.30.5923
automatic clustering algorithms derive features classification 
contrast approach emphasizes physical models human motion decomposition complex motions elementary postures gestures body part 
possible distributed multisensor accelerometer network provides detailed information relevant body part 
summarizes underlying physical model sketches feature extraction procedure 
features provide excellent separation relevant movements postures cases simple easy derive decision trees sufficient reliable recognition 
complex ambiguous motions statistical pattern classification algorithms hmm neural networks applied 
physical model readings accelerometers consist components gravity change speed forces 
gravity component determine orientation sensor corresponding body part vertical plane 
change speed part reading basis motion analysis 
force results rotational motions limbs respect corresponding joints 
cases component reading 
general single sensor components non separable 
cases approximate separation achieved frequency separation acceleration signal appropriate sensor placement 
gravity contribution showing orientation body parts predominantly contained low frequency part sensor signal remaining unchanged seconds 
contrast strong acceleration body parts longer tenths second 
terms sensor placement utilize fact sensors placed close joint arm leg readings dominated gravity contribution 
feature extraction features recognition user activity approximate orientation motion patterns relevant body parts 
derived sensor reading steps 
sensor output filtered separated low high frequency components 
steps readings sensors torso propagated network hierarchy allowing bottom sensors located limbs head compute motion relative torso 
low frequency component compute orientation corresponding body parts vertical plane 
high frequency component analyzed motion artifacts 
initial evaluation phase results propagated network control node 
knowledge anatomical constraints human body previous position motion state controller combines data individual sensors approximate description posture motion pattern 
forwarded main computer unit performs actual classification situation user activity 
experiments acquired audio acceleration data validate idea evaluate methods described sections 

speaker recognition validate audio retrieval algorithms conducted experiments increasing difficulty 
desktop microphones wearable clip microphone sony ecm ts 
user vs world considering personal annotations information user somebody speaking highly interesting 
wearable microphone allows simple energy thresholding algorithm distinguishing proves successful 
recording minute sequence recognition error reading reading clean dialog normal dialog clip mic clip mic table 
speaker recognition experiments meeting labelled tested 
energy thresholding second intervals achieve error rate sufficient retrieval applications 
controlled setting set recordings increasing difficulty evaluate performance speaker recognition algorithm 
see table summary retrieval results 
male female speaker recorded 
sequences minutes recorded desktop microphones training data 
lines table show recognition results training sets obviously 
speakers recorded desktop microphones involved dialog 
lasts min clean contains distinct pauses speakers simultaneous speech little laughter 
second min normal unconstrained dialog 
considering problem harder lower performance quite natural see rd th row table 
speakers recorded dialogs wore wearable microphone 
microphones changed sequences serve test training sequences 
rows table show corresponding results 
wearable meeting order validate approach recorded entire meeting minutes 
participants user equipped clip microphone 
hmms described section results recognition error 
described distinction wearer microphone reliably energy threshold 
energy threshold applying remaining part audio sequence results decrease error rate 
user relatively far apart constantly moving results promising 
point raw error rate measure evaluate usefulness retrieval 
believe obtained recognition rates sufficient retrieval 
retrieval error misclassified segment length seconds 
retrieval error different segment lengths 
retrieval analyzing results previous section reveals speakers identified correctly time speaker change accurate 
substantial part error rates table due 
retrieval scenarios interested speaking speakers participate discussion know exactly time somebody speaks 
motivated fact propose scheme allows trading error rate speaker identification time accuracy 
specifically start looking specific constellation speakers long segments shorten incrementally 
order avoid looking wrong segments missing correct segments need low error rate long segments 
time allow coarse time accuracy 
looking shorter segments interested listening actual utterances specific people relying higher accuracy time somebody speaks 
shows plot error rate speaker identification versus length time segments recognition 
corresponds result clean dialog highest error rate experiments see table 
easily seen error rate drops quickly segments seconds 
decrease error significantly enlarging segment question 
price obviously time accuracy speaker decreased 
result supports validity mentioned retrieval scheme 
acceleration wrist horizontal axis longitudinal axis chest horizontal axis sagittal axis longitudinal axis sagittal axis longitudinal axis sagittal axis right upper leg knee horizontal axis time 
raw accelerometer data stand handshake sequence 
activity detection verify relevant indexing cues detected distributed accelerometer network looked different event sequences typical meeting scenario 
section results selected sequences 
measurement setup measurements accelerometer axes aligned principal body axes longitudinal axis vertical axis body upright position horizontal axis perpendicular longitudinal axis runs left right sagittal axis axis runs front back 
assignment body axes axes accelerometers anatomical position person standing upright head eyes toes pointing forward feet arms side 
hands pointing forward 
greeting new participant experiment subject sitting chair hands table 
position stands shakes hands newly arrived meeting participant sits 
context acceleration vertical sagittal axes upper legs chest vertical longitudinal axes right wrist particular interest 
raw sensor data channels shown 
left leg omitted virtually identical right leg signal 
sequence contains shake hands events 
features extracted signal processing algorithm shown diagrams 
channel left diagram shows filtered low frequency component proportional vertical orientation corresponding body part 
leg channel shows transition upper leg horizontal sitting vertical standing position back 
chest channel shows forward leaning motion torso characteristic sitting longitudinal axis accelerometer wrist arms table shaking hands standing arms supporting sagittal axis accelerometer chest sitting standing standing sitting sagittal axis accelerometer upper right leg sitting standing sitting longitudinal axis accelerometer wrist shaking hands sagittal axis accelerometer chest sagittal axis accelerometer upper right leg 
low left high right frequency components relevant channels stand handshake sequence 
standing 
taken channels provide reliable indication user standing sitting 
low frequency component hand channels shows user arm falling vertical position stands followed horizontal orientation actual handshake vertical horizontal transition user sits 
high frequency components shown far right hand channel shows significant change amplitude easily identified vertical handshake motion 
head movements discussion second scenario concentrates head movements 
described section head motion important indicator user reaction events focus interest 
particular spontaneous nodding head shaking sign agreement disagreement particular issue comment 
head channel sensor mounted forehead looked nodding head shaking head turning events 
shows features extracted channel sensor typical nodding event 
low frequency channel essentially constant amplitude nodding motion small frequency high 
high frequency channel contains sequence bumps corresponding individual nods easily identified simple signal analysis techniques 
looking sensors network sure bumps result head motions 
longitudinal axis accelerometer forehead longitudinal axis accelerometer forehead 
low left high right frequency components head channel typical head nodding motion 

examples different postures recognized system 
head nodding reliably detected features extracted approach 
corresponding pattern head shaking head turns signal horizontal sagittal axis 
complex gestures posture simple gestures nodding shaking ones head raising shoulders constitute just small simple subset human body language 
shown human body language rich complex variety postures gestures deduce peoples attitudes emotions 
elements body language involve facial expressions subtle gesture nuances scope network accelerometers recognition approach 
number potentially interesting expressions reliably recognize 
third scenario exemplifies showing sensors placed arm chest head upper leg distinguish different postures 
considered postures shown interpreted concentrated left laid back right 
shows appropriately processed low frequency components sensors axes affected change orientation corresponding body parts 
discussion outlook wearable computers record annotate meetings interesting application wearable computing great potential 
propose automat longitudinal axis upper arm longitudinal axis lower arm axis chest 
raw data left preprocessed low frequency component relevant channels change postures shown ically generate personal annotations personalized contextual information wearable sensors 
particular show feasibility segment audio stream sequences assigned different speakers 
allows reconstruct speaker flow 
introduce distributed accelerometer network analyze body movements postures user 
cues step enable facilitate efficient indexing retrieval audio visual meeting recordings 
obviously issues remain addressed 
far complex postures gestures concerned recognition just part problem 
cases correct interpretation complex body language poses great challenge 
obviously number sensor types potentially useful annotate meeting recordings 
particular physiological data user may prove valuable asses user reaction events importance issues 
wearable cameras rich source recognize faces objects situations 
proposed system human appropriate interface indexing methodology developed evaluated 
usefulness proposed cues additional cues evaluated large number real life meetings 
point important issue privacy legal ethical issue linked audio visual recordings 
icsi berkeley meeting recorder project icsi 
www icsi berkeley edu speech 
nist automatic meeting transcription project 
www itl nist gov iad 
choudhury clarkson jebara pentland 
multimodal person recognition unconstrained audio video 
audio video biometric person authentication 

detection speaker changes audio document 
eurospeech 
dey salber abowd :10.1.1.41.737
conference assistant combining context awareness wearable computing 
iswc pages 
healey picard 
cybernetic wearable camera 
iswc pages 
hinckley pierce sinclair horvitz 
sensing techniques mobile interaction 
user interface software technology pages 
janin morgan 
portable meeting recorder 
workshop hands free speech communication 
wilcox 
acoustic segmentation audio browsers 
proc 
interface conference 

recording life 
www com dec 
lamming flynn 
forget intimate computing support human memory 
friends pages 

successful nonverbal communication principles applications 
allyn bacon 
mann 
smart clothing wearable computer 
personal technologies 

recognizing human motion multiple acceleration sensors 
systems man cybernetics pages 
fisher hollar pister :10.1.1.41.737
acceleration sensing glove asg 
iswc pages 
randell muller 
context awareness analysing accelerometer data 
iswc pages 
rhodes :10.1.1.16.9692
wearable remembrance agent system augmented memory 
iswc pages 
schmidt tuomela laerhoven de velde 
advanced interaction context 
huc pages 
sekine tamura fujimoto 
classification walking pattern acceleration waveform elderly people 
engineering medicine biology society volume pages 
hirose 
study experience recording recalling wearable computer 
correspondences human interface 
van laerhoven 
real time analysis data sensors neural networks 
iswc pages 
waibel finke :10.1.1.27.9310
meeting browser tracking summarizing meetings 
proceedings darpa broadcast news workshop 
wilcox chen 
audio indexing speaker identification 
eurospeech pages 
yoshida yonezawa caldwell 
wearable posture behavior activity recording system 
engineering medicine biology soc volume page 
young odell valtchev woodland :10.1.1.41.737
htk book 
cambridge 
