proceedings eacl representing text chunks erik tjong kim sang center dutch language speech university antwerp belgium uia ac dividing sentences chunks words useful preprocessing step parsing information extraction information retrieval 
marcus introduced convenient data rep resentation chunking converting tagging task 
examine different data repre sentations problem ing noun phrase chunks 
show data representation choice minor influence chunking formance 
equipped suitable data representation memory learning chunker able improve best published chunking results standard data set 
text corpus tasks parsing information extrac tion information retrieval benefit di sentences chunks words 
ramshaw marcus describe error driven transformation learning tbl method finding np chunks texts 
np chunks non overlapping non recursive noun phrases 
experiments modeled chunk recognition tagging task words inside basenp marked words outside basenp received tag special tag word inside basenp basenp 
text example original early trading hong kong monday gold quoted tagged early trading hong veenstra computational linguistics tilburg university box le tilburg netherlands veenstra nl kong monday gold quoted representations np chunking 
example representation ratnaparkhi chunk initial words receive start tag tag remainder words chunk paired different tag 
removes tagging ambiguities 
representation equal noun phrases receive tag sequence regardless context appear 
data representation choice influence performance chunking systems 
pa discuss large influence fore compare different data rep resentation formats basenp recognition task 
particularly interested finding representation formats best reported results task im proved 
second section presents general setup experiments 
results third section 
fourth section describe related 
methods experiments section explain data representation formats machine learning algorithm 
final part describe feature representation experiments 
data representation compared complete partial data representation formats basenp recog nition task ramshaw marcus 
complete formats tag words inside basenp tag words outside basenp 
differ proceedings eacl iob iob ioe ioe io table chunk tag sequences example sentence early trading hong kong monday gold quoted different tagging formats 
tag words inside basenp words outside basenp basenp initial words basenp final words 
treatment chunk initial chunk final words iob iob ioe ioe word inside basenp immediately basenp receives tag ramshaw marcus 
basenp initial words receive tag ratnaparkhi 
final word inside basenp immediately preceding basenp receives tag 
basenp final words receive tag 
wanted compare data representa tion standard bracket representa tion 
chosen divide bracketing exper iments parts recognizing opening brackets recognizing closing brackets 
additionally worked partial representation promising tag ging representation disregards boundaries adjacent chunks 
boundaries recovered combining format bracketing formats 
partial rep basenp initial words receive tag words receive tag 
final words receive tag words receive tag 
io words inside basenp receive tag receive tag 
partial representations combined ill pairs encode complete basenp structure tile data io word sequence regarded basenp word re tag final word received tag brackets signed words sequence 
io format tags words received tag tag changed tags 
result interpreted iob format 
io format tags words received tag tag axe changed tags 
result interpreted ioe format 
examples complete formats partial formats table 
memory learning build basenp recognizer training machine learning algorithm correct tagged data testing unseen data 
ma chine learning algorithm memory learning algorithm mbl 
train ing stores symbolic feature representation word training data classi fication chunk tag 
testing phase algo rithm compares feature representation test word training data item chooses classification training item clos est test item 
version algorithm ibi ig distances feature rep computed weighted sum distances individual features 
equal features defined distance distance pairs feature dependent value 
value equal information gain feature information theoretic measure contains proceedings eacl word pos context iob iob ioe ioe io io table results experiment series best scores different left right word pos tag pair context sizes representation formats fold cross validation section wsj corpus 
normalized entropy decrease classification set caused presence feature 
details algorithm daelemans representing words features important decision mbl experiment choice features representing data 
ibi ig thought sensitive redundant features data dependent feature weighting included algorithm 
presence redundant features negative influence performance basenp recognizer 
ramshaw marcus set trans rules modifying clas words 
rules context infor mation words part speech tags assigned chunk tags associated 
information feature representation words 
tbl rules different context information successively solving different prob lems 
context information data 
optimal context size determined comparing results different context sizes training data 
perform steps 
start testing dif context sizes words part speech tag 
classifica tion results best context size determining optimal context size classification tags 
third step evaluate combinations classification results find best combina tion 
examine influence mbl algorithm parameter number exam ined nearest neighbors 
lr part timbl software package available ilk nl results basenp data ramshaw marcus 
data divided parts 
part training data consisted words taken sections wall street journal corpus wsj 
second part test data consisted words taken section corpus 
words part speech pos tagged brill tagger word classified inside outside basenp iob representation scheme 
chunking classification ramshaw marcus pars ing information wsj corpus 
performance basenp recognizer measured different ways computing percentage correct classification tags ac percentage recognized correct precision percentage inthe corpus recall 
follow argamon com bination precision recall rates precision recall precision recall 
experiment series tried discover best word part speech tag context representation format 
computational reasons limited working section wsj corpus 
section con tains words 
run fold cross validation experiments combinations left right contexts word pos tag pairs size range 
summary results table 
basenp recognizer performed best rel small word pos tag pair contexts 
differ ent representation formats required different con text sizes optimal performance 
formats data described ramshaw marcus available ftp ftp cis upenn edu pub chunker proceedings eacl word pos context chunk tag context iob iob ioe ioe io io table results second experiment series best scores different left right chunk tag context sizes representation formats fold cross validation section wsj corpus 
iob iob ioe ioe word pos chunk tag combinations io io table results third experiment series best scores different combinations chunk tag context sizes representation formats fold cross validation section wsj corpus 
explicit open bracket information preferred larger left context formats explicit closing bracket information preferred larger right context size 
combinations partial representations systematically outperformed complete representations 
probably caused fact able different context sizes solving different parts recognition problem 
second series experiments cas classifier 
classifier stages cascades 
cascade similar clas described experiment 
second cascade added classifications cascade extra features 
extra features consisted left right context classification tags 
focus chunk tag clas current word accounts cor rect classification cases 
mbl algorithm assigns large weight put feature harder features contribute result 
avoid refrained tag 
goal find optimal number ex tra classification tags input 
performed fold cross validation experiments com left right classification tag con texts range tags tags 
summary results table achieved higher representations bracket pair representation 
third experiment series similar second adding output ex periment added classification results experiments series 
ing supplied learning algorithm information different context sizes 
formation available tbl rules different contexts 
limited examining successive combinations experiments lists 
summary results table 
results representa tion formats improved 
fourth experiment series exper different value number nearest neighbors examined ibi ig algo rithm parameter 
algorithm standardly uses single training item closest test number cases different base configuration experiment series outperformed best base configuration previous series 
sec ond series outperformed ioe chunk tags added third series chunk tag context outperformed iob dif ferent combinations tested 
proceedings eacl word pos chunk tag combinations fb iob iob ioe ioe io io table results fourth experiment series best fz scores different combinations left right classification tag context sizes representation formats fold cross validation section wsj corpus obtained ibi ic parameter 
iob best representation format differences results formats significant 
item 
daelemans report basenp recognition better results obtained making algorithm consider classification values closest training items 
tested repeating experiment series part third experiment series 
revised version repeated best experiment third series results replaced re sults outperformed revised experiment series 
results table 
formats benefited step 
final experiment series best results obtained iob dif ferences results formats significant 
optimal experiment configura tions obtained fourth experi ment series processing complete ramshaw marcus data set 
results table 
better results section training data experiments 
best result obtained iob im best reported rate data set ramshaw marcus 
apply learning approach large data set mentioned ramshaw marcus wall street journal corpus sec tions training material section test material 
hardware apply ing optimal experiment configuration data require months computer time 
best stage approach iob tags left right con xt words pos tags combined 
time chunker achieved score half point better results obtained ramshaw marcus chunker rates data accuracy precision 
related concept chunking introduced ab ney abney 
suggested develop chunking parser uses part tic analysis creating word chunks partial trees attaching chunks create complete syn tactic trees 
abney obtained support chunking stage psycholinguistic literature 
ramshaw marcus transformation learning tbl developing ramshaw marcus 
trained recognize trained recognize np chunks vp chunks 
ramshaw marcus approached chunking task tagging problem 
basenp training test data wall street journal corpus benchmark data current chunking experiments 
ramshaw marcus shows basenp recognition fz easier finding np vp chunks fz increasing size training data increases performance test set 
ramshaw marcus inspired groups build chunking algorithms 
argamon introduce memory sequence learning different chunk ing experiments 
algorithm stores sequences pos tags chunk brackets uses formation recognizing chunks unseen data 
performed slightly worse basenp recognition ramshaw marcus experi ments fz 
cardie pierce uses related method store pos tag sequences forming complete 
sequences applied unseen tagged data ai ter post processing repair rules fixing frequent errors 
approach performs worse reported approaches fo 
iob iob ioe ioe io io ramshaw marcus veenstra argamon cardie pierce proceedings eacl accuracy precision recall table scores ramshaw marcus test set training training data set 
data processed optimal input feature combinations fourth experiment series 
accuracy rate contains fraction chunk tags correct 
rates regard basenp recognition 
bottom part table shows reported results data set 
formats ibi ig achieves better fz rates best published result ramshaw marcus 
veenstra uses cascaded decision tree learning basenp recognition 
gorithm stores context information words pos tags chunking tags decision tree clas new items comparing training items 
algorithm fast reaches performance argamon 
daelemans uses cas mbl ibi ig similar way tasks basenp recognition 
report rates tag accuracy rates lot better accuracy rates reported 
ramshaw marcus data set different training test division fold cross validation compare results 
concluding remarks hay 
rent tata 
formats recognition memory learning ibi ig 
iob format introduced ramshaw marcus consistently ame best format 
dif ferences formats significant 
representation formats achieved better pre rates better recall rates 
infor mation ibr tasks require chunking structures tasks high precision rates interested high recall rates 
ibi ig algorithm able im prove best reported rates stan lar data set versus ramshaw mar 
result aided ing non standard parameter values algorithm sensitive redundant input fea tures 
means finding optimal formance task requires searching large parameter feature configuration space 
inter topic research embed ml ig standard search algorithm hill climbing explore parameter space 
room improved performance lies com puting pos tags data better tagger presently 
steven abney 

parsing chunks 
principle parsing 
kluwer academic publishers 
shlomo argamon ido dagan yuval 

memory approach learning shallow natural language patterns 
proceedings th international confer ence computational linguistics coling acl 
claire cardie david pierce 

error driven pruning treebank grammars base noun phrase identification 
proceedings th international conference compu tational linguistics coling acl 
walter daelemans zavrel ko van der van den bosch 

timbl tilburg memory learner version guide 
ilk tilburg university netherlands 
ilk nl ilk papers ilk ps gz 
walter daelemans van den bosch zavrel 

forgetting exceptions harmful language learning 
machine learn ing 
lance ramshaw mitchell marcus 

text chunking transformation learning 
proceedings third cl workshop large corpora 
adwait ratnaparkhi 

maximum entropy models natural language ambiguity lution 
phd thesis computer information science university pennsylvania 
veenstra 

fast np chunking ing memory learning techniques 
proceedings eigth belgian dutch conference machine learn ing 
ato dlo report 
proceedings eacl 
