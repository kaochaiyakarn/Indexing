pals peer peer adaptive layered streaming reza rejaie antonio ortega department computer science integrated media systems center university oregon university southern california reza cs uoregon edu ortega usc edu presents new framework peer peer adaptive layered streaming called pals 
pals receiver driven approach quality adaptive playback layer encoded streaming media group congestion controlled sender peers single receiver peer 
effective throughput sender variable known priori challenging coordinate delivery active senders 
pals receiver coordinated delivery active senders adaptively determining subset senders maximize throughput quality number layers delivered senders distribution throughput active layers importantly required packets delivered active sender order effectively cope sudden change throughput individual senders 
describe pals framework identify key components framework interesting design challenges sample solution key components preliminary results 
categories subject descriptors computer communications networks distributed systems distributed applications 
general terms design performance measurement 
keywords peer peer networks congestion control quality adaptive streaming layered encoding 

peer peer networks increasingly popular alternative communication paradigm traditional clientserver architecture 
research networks focused questions form network cooperative peers locate piece content network 
applications networks exchange files peers napster actual delivery permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
nossdav june monterey california usa 
copyright acm 
content network received little attention simply requires file transfer peers 
streaming realtime multimedia audio video content networks challenging problem single peer may willing able commit sufficient resources bandwidth cpu stream media file peer 
peers collectively stream requested content peer 
approach result better load balancing sender peers congestion network 
furthermore assuming receiver access link bottleneck group sender peers provide higher throughput receiver peer deliver higher quality stream 
enable streaming content multiple peers challenging issues addressed mechanism identify subset available peers desired content provide maximum throughput receiver peer 
note throughput group sender peers may increase additional senders added multiple senders may reside bottleneck 
second sender peer perform tcp friendly congestion control cc rap tfrc :10.1.1.154.9133
implies throughput available sender known priori significantly change session 
furthermore internet heterogeneity characteristics bandwidth rtt connections different senders significantly different 
delivery mechanism designed operate multiple senders quality adaptive able adjust smoothly quality bandwidth delivered stream throughput changes 
third subset sender peers main problem coordinate group active senders cooperate streaming maximum deliverable quality supported throughput 
example peers cooperatively streaming video need coordinate peer responsible time delivery segment video 
fourth sender peer potentially leave session delivery mechanism able cope dynamics peer participation minimize negative impact dynamics delivered quality 
new framework streaming networks called adaptive layered streaming pals 
pals receiver driven approach allows receiver orchestrate adaptive delivery stored layer encoded streams multiple sender peers single receiver 
set sender peers pals progressively evaluates various combinations senders determine subset senders collectively provide maximum throughput 
subset senders selected receiver monitors throughput periodically determines target quality total number coding layers delivered senders 
receiver determines proper distribution throughput active layers portion throughput allocated delivery layer divides allocated bandwidth layer active senders segments layer delivered sender order effectively cope sudden change throughput individual senders 
pals built previous design quality adaptation qa mechanism congestion controlled playback layer encoded video internet 
goal pals essence similar previous key differences pals unicast qa mechanism pals performs qa multiple independent connections potentially different characteristics single connection pals receiver driven sender driven 
approach qa address new problems receiver may information patterns change throughput 
second receiver effectively monitor manage delivery segments multiple senders requires mechanisms receiver driven qa 
differences introduce new set challenges exist unicast qa mechanism 
main contribution pals receiver driven coordination adaptation framework streaming multiple congestion controlled sender peers able cope unpredictable variations throughput sender peer dynamics peer participation 
motivated pals framework streaming networks pals framework streaming multimedia content potentially distributed group multimedia servers best effort network single client 
main goals describe framework key components required mechanisms coordination senders adaptation delivered quality dynamics network connection peer participation provide sample mechanisms key components discuss interesting challenges arise design mechanisms preliminary results 
discuss initial set sender peers identified 
issue appears similar realtime non realtime content achieved different ways contacting server hash function 
detailed analysis various design issues including analysis general mechanisms address key challenges extensive evaluation pals remain 
rest organized follows section related 
justify key design choices section 
section describes pals framework key components sample solutions component 
preliminary result section 
section concludes presents plans 

related basic idea streaming multiple servers single client new 
proposed mechanism streaming multiple servers multiple description md encoding 
distortion model md encoding model study effect server content placement delivered quality md single description sd encodings 
consider variations throughput sender receiver focused content placement server selection mechanisms 
nguyen mechanism delivery streaming media multiple mirror servers single client 
assumed different flows share bottleneck bandwidth servers higher stream bandwidth 
proposed solution receiver periodically reports throughput delay senders back control packets 
senders run distributed algorithm determine send packet 
main difference approach pals pals receiver driven adapts quality delivered stream variations throughput 
related streaming networks 
coopnet mechanism distributing md encoded streams peers live demand sessions able cope flash crowd 
coopnet leverages md encoding send different description separate tree interested peers 
ondemand sessions new client contacts single sender peer set candidate peers peer asked deliver content 
sender peer unavailable unwilling serve client contacts peer sender peer 
systems form distribution tree participating clients similar coopnet 
sufficient information systems comparison 
tran technique called zigzag building maintaining efficient single source media distribution tree 
key distinction quality adaptive delivery mechanism multiple congestion controlled senders 
pals rlm receiver driven mechanisms leverage layered encoding fundamental differences 
rlm receiver adjust number delivered layers joining different number multicast sessions 
allows receiver regulate incoming throughput delivered quality level cause congestion network receiver implements type congestion control mechanism regulating incoming throughput 
pals framework flows unicast unicast congestion control mechanism implemented sender 
incoming throughput receiver aggregate congestion controlled bandwidth senders 
receiver control incoming throughput controls quality stream delivered incoming throughput multiple senders 

justifying design choices describing details pals need justify key design choices adopting receiver driven adaptation coordination layered hierarchical encoding 
coordination adaptation machinery cooperative playback multiple senders implemented receiver senders 
believe receiver driven approach natural solution receiver permanent member session complete knowledge packets successfully delivered current subset active sender peers available throughput sender peer 
puts receiver unique position orchestrate delivery senders 
receiver predict available throughput sender able leverage degree multiplexing senders advantage 
advantage receiver driven approach require significant processing overhead senders coordination adaptation primarily done receiver 
receiver driven approach introduces network overhead coordination messages periodically sent receiver active senders 
overhead higher associated overhead conceivable sender driven coordination approach uses unicast messaging approach may require availability detailed metadata requested stream variations stream bandwidth vbr streams 
information provided central server sender peers perform encoding specific packet scheduling 
obtaining information content delivery starts leads small overhead respect sender driven approaches believe benefits receiver driven approach outweigh drawback 
second layered organization data streams presents useful structure cooperative playback multiple senders 
layer encoding multiple description encoding provide organization 
selected layered encoding achieves higher compression efficiency md layer encodings resilient losses lower layers specially base layer comparing md describe section pals lost packets retransmitted window time 
note pals accommodate types data representations 
example purely layered representation specific packet servers requested 
additional robustness desired possible request packet server 
approach step possible incorporate md formats receiver request redundant identical versions stream different servers 

adaptive layered streaming pals section describe pals framework detail 
presenting target environment assumptions subsection provide overview pals framework identify key components subsection 
design issues key components sample solutions discussed subsections 
target environment shows target environment sender peers internet cooperatively playback requested stream receiver peer 
peer expected perform tcp friendly congestion control 
throughput sender peer exist fair way outgoing traffic sender providing different contents peers 
sender peers potentially scattered internet connection sender peer exhibit significantly different characteristics bandwidth rtt connections senders 
pals able arbitrary set sender peers network long throughput senders higher bandwidth single layer 
currently assume requested stream entirely available sender peer 
clarity discussion assume layers constant bit rate 
assumptions required pals 
general information requested stream number layers layer bandwidth distribution stream length provided receiver initial list sender peers original server multicast messaging may reduce coordination overhead sender driven approach judgment benefits receiver driven approach outweighs potential benefit 
pals sender pals receiver internet demux bw bw bw bw buf architecture pals buf buf buf decoder mechanism locate sender peers initial setup phase 
table summarizes notation 
overview pals framework primary goal pals stream maximum quality delivered set available sender peers single receiver peer 
key challenge available throughput sender known priori significantly change session 
implies pals able gracefully cope sudden decrease throughput effectively leveraging sudden increases throughput 
basic idea pals simple intuitive 
receiver periodically sends ordered list packets sender 
sender simply transmits requested packets order rate determined cc mechanism 
ordered lists provides benefits allows receiver better control delivered packets sender ensures graceful degradation quality throughput sender suddenly decreases ordering list importance packets enables different receivers implement different quality adaptation algorithms delivery stream 
requests sender piggy backed cc feedbacks periodically sent sender sent separately 
machinery pals protocol implemented receiver 
receiver keeps track exponentially weighted moving average ewma throughput 
point time receiver assumes current value remain unchanged period estimates total number incoming packets period follows quality adaptation qa mechanism receiver distributes packets active layers throughput receiver buffer state buf buf 
example receiver expects receive packets period layers currently played qa mechanism may allocate packets layer 
respectively 
controlling distribution incoming packets layers receiver essentially allocates distribution throughput active layers bw bw 
period turn determines evolution receiver buffer state 
distribution total packets layers period 
kn packet assignment pa mechanism receiver maps subset packets possibly different layers sender sends request contains list assigned packets sender 
packet assignment strategy allows receiver loosely control allocation sender throughput sj sender li layer 
active layers max 
number layers ewma throughput ewma ewma throughput sj buffered data li bwi allocated bw li buf target buffer li packet size srt tj ewma rtt sj srt tmax max 
value srt tj interval requests estimated 
incoming packets table summary notation active layers 
number assigned packets sender proportional expected contribution sender throughput throughput 
example sender si provides throughput half packets interval assigned si 
receiver initiates playback needs mechanism receiver keep senders loosely synchronized receiver 
specifically playout time requested packets determined respect actual playout time ongoing session receiver order ensure time delivery requested packets 
pals employs complementary mechanisms achieve goal 
pals uses sliding window sw approach shown 
interval receiver considers packets playout time higher tmin tmin tp 
window slide forward playout time proceeds remains sufficiently ahead playout time 
furthermore sw mechanism ensure sender outstanding packets deliver sender may idle throughput may drop congestion controlled limit desirable 
second new list requested packets receiver overwrites outstanding list delivered sender sender receives new list requested packets receiver starts delivery packets new list abandons pending packet previous list 
overwriting mechanism keeps slow senders loosely synchronized receivers playout 
receiver requires peer selection ps mechanism order periodically examine available peers add subset active sender peers participation delivery increases throughput session 
summary pals receiver requires key components quality adaptation packet assignment sliding window peer section 
discuss design issues components sample mechanism subsections primarily focus components 
quality adaptation main goal qa mechanism maximize delivered quality minimizing variations playback quality despite unpredictable changes available bandwidth 
key design issue manage receiver buffer state order effectively absorb short term mismatch stream consumption rate available network bandwidth 
receiver buffer state controlled proper allocation available bandwidth active layers 
earlier designed qa mechanism client server streaming receiver reports buffer state sender sender regulates bandwidth allocation packet basis keep receiver buffer state close optimal state 
optimal buffer state depends pattern variations bandwidth additive increase multiplicative increase known sender 
follow design philosophy design qa mechanism pals 
important differences qa pals unicast streaming require new approach qa pals 
qa mechanism implemented receiver adds delay control loop qa mechanism receiver determine control bandwidth allocation sender throughput 
second receiver deal multiple independent senders potentially different variations bandwidth 
furthermore receiver knowledge pattern changes throughput derive optimal buffer distribution 
third performing receiver qa mechanism packet basis sending new request packet really expensive qa mechanism invoked periodically 
remaining subsection sketch receiver driven qa mechanism pals 
qa mechanism degrees control effectively control distribution total buffered data active layers buf buf proper allocation throughput active layers controlling bw bw 
bwi change number playing layers adding dropping top layer adjusting quality bandwidth delivered stream 
short term changes throughput absorbed buffered data long term changes throughput trigger adjustment stream quality 
throughput higher stream bandwidth receiver utilize excess bandwidth fill buffers 
call filling phase 
receiver buffers filled appropriate level receiver increase stream bandwidth adding new layer 
contrast throughput lower stream bandwidth receiver drain buffered data compensate bandwidth deficit 
total buffered data distribution sufficient absorb bandwidth deficit draining phase receiver drop top layer avoid buffer underflow buffered data layers 
key observation total amount buffered data distribution active layers crucial effectively absorb variations throughput 
illustrate observation assume scenario layers played 
note buffered data layer drained faster packet playout time min time sliding window scheme loose synchronization requested packets playout time consumption rate 
implies buffered data layer compensate bps deficit throughput 
bigger deficit throughput larger total required buffering larger number buffering layers drained simultaneously compensate deficit throughput 
specifically minimum number buffering layers determined illustrates requirement different draining scenarios different pattern changes throughput 
scenarios require roughly amount total buffering scenario requires buffered data proper distribution layers deficit throughput scenario ii absorbed buffering layer 
observation suggests distribution buffered data active layer appropriate 
note layer dropped amount buffered data layer leveraged absorbing variations throughput turn leads lower buffering efficiency 
expected bandwidth deficit optimal buffer distribution distributes buffered data minimum number required buffering layers skewed fashion allocating maximum amount data drained buffer draining phase buf maximum buf 
optimal buffer distribution directly depends pattern variations throughput 
mentioned earlier challenges receiver qa receiver sufficient information pattern changes throughput 
considered alternative solutions determine proper buffer distribution receiver able measurement technique progressively derive pattern changes throughput incoming stream determine new optimal buffer distribution accordingly receiver pre specified fixed buffer distribution 
currently second approach linear buffer distribution pals call target buffer state buf buf srt tmax configuration parameter determines slope linear increase buffering layer 
target buffer state target amount buffering layer layers active specified buf 
approach static optimal effective 
design measurement techniques deriving pattern changes throughput remains 
target buffer distribution time qa mechanism invoked goes steps keep buffer state close possible target buffer state 
compares throughput stream bandwidth determine filling draining phase implements corresponding mechanisms follows scenario scenario ii impact pattern variations throughput inter layer buffer distribution filling phase filling phase layers receiver tries fill buffers target state layers 
starts base layer sequentially determines number packets layer requires reach target buffer level interval packets allocated layers reach target buffer levels 
algorithm described pseudo code fill layers target state buf buf ki ki denotes number packets consumed layer period ki number allocated packets li 
buffered data layers reach target levels packets available qa mechanism repeats algorithm fill active layers target level layers 
fills buffers existing layers point add new layer 
layers filled level packets available new layer added available throughput higher stream bandwidth additional layer 
draining phase receiver draining phase determines active layers sustained interval current buffer state 
total amount buffered data distribution sufficient compensate deficit throughput qa mechanism progressively drops top layer buffer state remaining layers sufficient compensate deficit throughput 
qa mechanism essentially reverses filling algorithm 
specifically tries drain layers target level starting top layer 
data needs drained top layer dropped receiver repeats steps previous target state layers 
summary key differences qa mechanism pals sender qa mechanism unicast streaming 
qa mechanism pals determine inter layer bandwidth allocation period time packet basis 
mechanism determine proper client buffer distribution knowledge pattern changes throughput 
expect effect change number sender peers due departing existing sender peer availability new sender peer similar sudden decrease increase throughput 
qa mechanism reacts events way 
sliding window sliding window sw mechanism goals keep senders loosely synchronized playout time receiver order prevent senders sending packets playout time passed ensure senders packets send idle 
pals achieves goal sliding window coupled overwriting mechanism 
shown receiver maintains window periodically forwarded seconds order stay seconds ahead playout time 
receiver overestimates throughput sender window slides forward seconds receiver sends request sender 
timer driven approach overwriting prevents sender falling ongoing session 
achieve second goal receiver keeps track number delivered packets sender interval 
number pending packets sender goes threshold receiver sends request sender 
mechanism reacts sudden increase throughput sender triggers transmission request sender idle 
call mechanism reverse flow control rfc receiver tries ensure sender buffer list pending packets underflow 
key parameter rfc mechanism threshold threshold sender specified portion srtt sender 
example setting sender means new request sent sender half srtt worth packets deliver 
threshold translated maximum number remaining packets trigger rfc mechanism follows srt ipg ewma small threshold results late reaction sudden increase sender throughput may cause sender idle 
contrast set large value rfc sends new request sender early frequently overwrites previous list sender 
call overwriting effect 
larger threshold rfc larger portion list overwritten larger number packets ignored interval 
note packets due overwriting requested senders delivered intervals 
key design question couple qa mechanism receiver requests different senders 
throughput senders overestimated senders finish close interval receiver invoke qa mechanism interval determine required packets interval throughput send new request senders simultaneously new interval 
practice throughput sender suddenly increases interval rfc mechanism triggers receiver send new request fast sender 
key issue determine new request sent slower senders 
devise different approaches address issue follows synchronized requesting new request sent senders time interval 
synchronized approach simple tightly couples sliding window mechanism qa mechanism 
window forward seconds soon rfc mechanism triggered fastest sender 
receiver invokes qa mechanism window determine required packets senders throughput sends new request senders simultaneously 
approach qa mechanism require factor throughput individual senders 
asynchronous requesting receiver send new requests different senders asynchronous fashion 
new request sent fast sender soon rfc mechanism triggered new request senders sent interval sliding window 
approach suffer overwriting effect 
approach sliding mechanism decoupled qa mechanism complicates coupling qa mechanism outgoing requests 
qa mechanism invoked interval determine packets interval throughput request sent sender interval execution qa mechanism 
network conditions significantly change interval approach lead poor performance frequent layer add drop qa mechanism 
alternatively receiver invoke qa mechanism sending request sender sending batch concurrent requests subset senders 
case qa mechanism incremental fashion means execution time needs send request sender qa mechanism consider requested packets senders factor variations throughput individual senders 
clearly adds complexity qa mechanism needs cope higher degree network dynamics 
plan explore new techniques incremental qa 
basic configuration parameter sw mechanism window size 
dynamics variations sender depend srtt length interval function srtt 
synchronized requesting approach interval senders selected order accommodate senders 
directly controls responsiveness qa mechanism frequency network overhead receiver requests senders 
small window allows qa quickly react changes throughput maintain buffer state closer target buffer state 
window small cause qa mechanism oscillate due delay control loop receiver sender 
obviously srtt different senders span wide range difficult set window order satisfy considerations senders 
asynchronous requesting approach receiver potentially separate interval sender 
scheme allows receiver control sender separate frequency 
turn shifts complexity design qa mechanism asynchronous approach mentioned earlier 
summary chosen order achieve proper balance responsiveness qa mechanism network load receiver requests 
current version pals synchronized requesting approach set srt tmax srt tmax maximum srtt active senders window 
adaptive packet assignment qa mechanism determines ordered list packets requested multiple senders invoked rtt packet assignment mechanism needed properly distribute packets active senders 
note total required packets window may include different number packets various layers 
example qa mechanism may require packets respectively 
number assigned packets sender proportional expected throughput window senders deliver assigned packets relatively time 
achieve receiver keeps track short term ewma window throughput active sender ewma uses determine number requested packets sender follows ki ewma ewma ki 
packet assignment mechanism assign ki specific packets total list required packets sender tries satisfy goals tries assign required packets layer single sender possible 
strategy reduces size request messages requires network bandwidth sending request messages 
second important consideration distribute packets senders order minimize negative impact delivered quality due sudden change sender throughput 
discuss basic examples illustrate impact packet assignment strategies behavior pals framework 
coping slow senders receiver overestimates throughput senders senders deliver assigned packets current window 
main goal packet assignment mechanism ensure available throughput deliver important packets 
receiver know priori sender slow assigning packets layer single sender achieve goal 
packet assignment strategy cope slow senders number packets assigned sender ki determined throughput ordered list packets distributed active senders weighted round robin fashion 
example senders contribute throughput ordered list packets divided round robin fashion means repeatedly assign packets packets packets 
strategy attempts proportionally distribute important packets packets higher layers higher timestamp lists 
packets opportunity delivered windows excess throughput available 
configuration parameter packet assignment mechanism controls size batch packets distributed senders round 
larger smaller amount control information smaller number senders deliver packets layer undelivered packets important ones 
limiting overwriting effect overwriting effect affect slow senders synchronized requesting approach 
round robin packet assignment strategy synchronized requesting approach requested packets higher layers frequently overwritten ignored lead starvation higher layers 
limit negative impact overwriting effect packet assignment strategy extended follows window partitioned smaller windows length equal portions original window sequentially apply weighted round robin packet assignment strategy smaller windows example window partitioning packet assignment der shown 
example shows scenario window packets layers partitioned windows 
approach negative impact overwriting affects layers proportionally qa mechanism better control buffer state 
configuration parameter called partitioning factor set expected level overwriting 
peer selection mentioned earlier increasing number sender peers monotonically increase effective throughput senders may share bottleneck 
pals leverages observation uses simple iterative mechanism identify subset senders maximize throughput follows 
receiver starts randomly selected peer list available peers 
periodically adds random peer list available peers subset active senders monitoring variations throughput throughput individual senders 
throughput increases new sender kept 
receiver drops new sender tries random peer period 
impact new sender throughput monitored sufficiently long period period order avoid reacting artifacts transient congestion due startup phase similar peer selection experiments located receivers 
clearly access link receiver bottleneck changing number sender peers improve throughput 

evaluation conducted preliminary evaluations pals protocol ns simulation initial results section 
simulations version pals synchronized requesting approach window partitioning packet assignment 
simplified pals ignoring time stamp individual packets 
period rfc sliding window mechanism triggers qa determine number packets delivered layer specific time stamp uses packet assignment mechanism distribute required packets senders 
simulations demonstrate dynamics quality adaptation packet assignment sliding window mechanisms allow keep track duplicate late packets 
configuration parameters pals receiver summarized table 
depicts simulation scenario pals session mbps ms mbps ms ms mbps tcp 
tcp ms tcp cross traffic ms mbps simulation setup sink 
sink ew ma actor kbyte sec byte srtt table pals configuration parameters sender peers cooperatively deliver layered stream single receiver peer 
sender uses rap congestion control different rtt receiver :10.1.1.154.9133
shows pals mechanism action sender peers share bottleneck link tcp flows 
line variations rtt average throughput sender smoother line ewma throughput step wise line number played back layers delivered quality function time 
furthermore throughput individual senders shown 
despite wide variations rtt average throughput qa mechanism manages rapidly increase number playing layers layers smoothly adjusts delivered quality variations throughput 
examine behavior qa mechanism presence major changes throughput repeated previous simulation added cbr flow starts sec stops sec consumes mbps bandwidth bottleneck link 
depicts behavior qa pals presence cbr source 
clearly shows throughput sender peers bandwidth rap flows quickly decreases response change network condition 
turn triggers qa mechanism quickly adjust delivered quality dropping layers base layer 
cbr source stops bandwidth available qa mechanism detects changes rapidly increases number layers previous level 

new receiver driven framework adaptive layered streaming called pals receiver coordinates delivery layer encoded stream multiple senders 
described framework discussed key components framework coordination adaptation addressed various design issues tradeoffs 
identified challenging problems arise design receiver driven mechanism quality adaptive streaming 
obviously starting point pals 
plan pursue directions 
currently conducting extensive detailed simulations obtain deeper bandwidth byte sec bandwidth byte sec behavior quality adaptation mechanism pals delivered quality layers rtt average throughput ewma throughput bw bw bw time sec qa pals presence tcp background traffic behavior quality adaptation mechanism pals delivered quality layers rtt average throughput ewma throughput bw bw bw time sec qa pals major variations background traffic standing dynamics different mechanisms pals effect various configuration parameters interactions key components 
particular plan explore various techniques perform asynchronous requesting incremental quality adaptation 
working measurement techniques derive pattern variations throughput incoming packets 
plan examine proposed peer selection mechanism 
peer selection mechanism added pals examine impact dynamics peer pals performance 
plan extend pals support delivery vbr layered encoded md encoded streams 
acknowledgments anonymous nossdav reviewers feedback 

ratnasamy francis handley shenker scalable content network proceedings acm sigcomm aug 
stoica morris kaashoek balakrishnan chord scalable peer peer lookup service internet applications proceedings acm sigcomm aug 
rejaie handley estrin rap rate congestion control mechanism realtime streams internet proceedings ieee infocom new york ny mar :10.1.1.154.9133
floyd handley padhye widmer equation congestion control applications proceedings acm sigcomm 
rejaie handley estrin quality adaptation congestion controlled playback video internet proceedings acm sigcomm cambridge ma sept 
padmanabhan wang chou sripanidkulchai distributing streaming media content cooperative networking workshop network operating system support digital audio video miami beach fl 
wong 
tan wee multiple description streaming content delivery networks proceedings ieee infocom 
nguyen zakhor distributed video streaming internet spie multimedia computing networking jan 
www com 
www com 
www com 
www com 
tran hua zigzag efficient peer peer scheme media streaming proceedings ieee infocom 
mccanne jacobson receiver driven layered multicast proceedings acm sigcomm stanford ca aug pp 

ortega expected run time distortion scheduling delivery scalable media proc 
packet video workshop pittsburgh pa apr 
wang ortega robust video communication combining scalability multiple description coding techniques ei san jose ca jan 
chou rate distortion optimized streaming best effort networks submitted transactions multimedia 
network simulator ns version software line www isi edu nsnam ns 
