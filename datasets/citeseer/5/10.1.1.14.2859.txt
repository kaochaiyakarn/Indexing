efficient probabilistic context free parsing algorithm computes prefix probabilities andreas stolcke university california berkeley international computer science institute describe extension earley parser stochastic context free grammars computes quantities stochastic context free grammar input string probabilities successive prefixes generated grammar probabilities substrings gen erated nonterminals including entire string generated grammar viterbi parse string posterior expected number applications grammar production required rule probabilities 
probabilities computed incrementally single left right pass input 
algorithm compares favorably standard bottom parsing methods scfgs works efficiently sparse grammars making earley top control structure 
process context free rule format conversion normal form combines computations single algorithm 
algorithm simple extensions processing partially bracketed inputs finding partial parses likelihoods ungrammatical inputs 

context free grammars widely models natural language syntax 
probabilistic version defines language probability distribution strings variety applications selection parses ambiguous inputs fujisaki guide rule choice efficiently parsing jones eisner compute island probabilities non linear parsing 
speech recognition probabilistic context free grammars play central role integrating low level word models higher level language mod els ney non finite state acoustic phonotactic modeling lari young 
context free grammars combined scoring functions strictly probabilistic nakagawa context sensitive semantic probabilities magerman marcus man weir jones eisner briscoe carroll 
clearly perfect model natural language stochastic context free grammars scfgs superior nonprobabilistic cfgs probability theory pro sound theoretical basis ranking pruning parses integration models aspects language 
applications listed involve potentially speech technology research laboratory sri international ravenswood ave menlo park ca 
mail stolcke speech sri com 
association computational linguistics computational linguistics volume number standard tasks compiled jelinek lafferty 

probability string generated grammar 
single parse derivation 
probability occurs prefix string generated prefix probability 
parameters rule probabilities chosen maximize probability training set strings 
algorithm described article compute solutions problems single framework number additional advantages previ ously isolated solutions 
probabilistic parsers generalization bottom chart pars ing cyk algorithm 
partial parses assembled just nonprobabilistic parsing modulo possible pruning probabilities substring ties known inside probabilities computed straightforward way 
cyk chart parser underlies standard solutions problems baker jelinek 
jelinek lafferty solu tion problem direct extension cyk parsing authors algorithm terms similarities computation inside proba bilities 
algorithm computations tasks proceed incrementally parser scans input left right particular prefix probabilities available soon prefix seen updated incrementally extended 
tasks require reverse pass chart constructed input 
incremental left right computation prefix probabilities particularly impor tant necessary condition scfgs replacement finite state language models applications speech decoding 
pointed je lafferty knowing probabilities xo xi arbitrary prefixes xo xi enables probabilistic prediction possible follow words xi xi xo xi xo xo xi 
conditional probabilities word transition probabilities viterbi style decoder incrementally compute cost function stack decoder bahl jelinek mercer 
application prefix probabilities play central role extrac tion gram probabilities scfgs stolcke segal 
efficient incremental computation saves time common prefix strings shared 
key features algorithm top parsing method nonprobabilistic cfgs developed earley 
earley algorithm appealing runs best known complexity number special classes grammars 
particular earley parsing efficient bottom methods cases top prediction rule potential parses substrings 
worst case computational expense algorithm complete input incrementally new word phrases problem terms context free probabilistic grammars generalize obvious ways classes models 
andreas stolcke efficient probabilistic context free parsing known specialized algorithms substantially better known grammar classes 
earley parser deals context free rule format seamless way requiring conversions chomsky normal form cnf assumed 
advantage probabilistic earley parser extended take advantage partially bracketed input return partial parses ungrammatical input 
extension removes common objections top predictive opposed bottom parsing approaches man weir 

overview remainder article proceeds follows 
section briefly reviews workings earley parser regard probabilities 
section describes parser needs extended compute sentence prefix probabilities 
section deals modifications solving viterbi training tasks processing partially bracketed inputs finding partial parses 
section discusses miscellaneous issues relates literature subject 
section summarize draw 
get idea probabilistic earley parsing sufficient read sections 
section deals crucial technicality sections fill details add optional features 
assume reader familiar basics context free grammar ory aho ullman chapter 
prior familiarity probabilistic context free grammars helpful 
jelinek lafferty mercer provide tutorial covering standard algorithms tasks mentioned 
notation 
input string denoted ix length individual input symbols identified indices starting xl 

input alphabet denoted substrings identified positions xi variables reserved integers referring positions input strings 
latin capital letters denote nonterminal symbols 
latin lowercase letters terminal symbols 
strings mixed nonterminal terminal symbols written lowercase greek letters empty string denoted 
earley parsing earley parser essentially generator builds left derivations strings set context free productions 
parsing functionality arises generator keeps track possible derivations consistent input string certain point 
input revealed set possible derivations corresponds parse expand new choices introduced shrink result resolved ambiguities 
describing parser appropriate convenient generation terminology 
parser keeps set states position input describing pending derivations state sets form earley chart 
state earley states known items lr parsing see aho ullman section section 
computational linguistics volume number form nonterminal grammar strings nonterminals terminals indices input string 
states derived pro grammar 
state derived corresponding production semantics current position input xo xi processed far 
states describing parser state position collectively called state set note state set input symbols set describes parser state input processed set contains states input symbols processed 
nonterminal expanded starting position input generates substring starting position expansion proceeded production expanded right hand side rhs position indicated dot 
dot refers current position state dot right entire rhs called complete state indicates left hand side lhs nonterminal fully expanded 
description earley parsing omits optional feature earley states lookahead string 
earley algorithm allows adjustable amount lookahead parsing order process lr grammars deterministically obtain computational complexity specialized lr parsers possible 
ad dition lookahead orthogonal extension probabilistic grammars include 
operation parser defined terms operations consult current set states current input symbol add new states chart 
strongly suggestive state transitions finite state models language parsing analogy explored probabilistic formulation 
types transitions operate follows 
prediction 
state kx nonterminal rhs rules expanding add states iy 
state produced prediction called predicted state 
prediction corresponds potential expansion nonterminal left derivation 
index implicit earley 
include clarity 
andreas stolcke efficient probabilistic context free parsing scanning 
state kx terminal symbol matches current input xi add state kx move dot current symbol 
state produced scanning called scanned state 
scanning ensures terminals produced derivation match input string 
completion 
complete state jy 
state set right dot add state kx kx move dot current nonterminal 
state produced completion called completed state 
completion corresponds nonterminal sion started matching prediction step 
input symbol corresponding state set earley parser performs operations exhaustively new states generated 
crucial insight working algorithm prediction com feed finite number states possibly produced 
recursive prediction completion position terminate eventually parser proceed input scanning 
complete description need specify initial final states 
parser starts sentence nonterminal note empty left hand side 
processing symbol parser verifies produced possibly length input intermediate stage state set remains empty states previous stage permit scanning parse aborted impossible prefix detected 
states empty lhs useful contexts shown section 
refer collectively dummy states 
dummy states enter chart result initialization opposed derived grammar productions 
note difference complete completed states complete states dot right entire rhs result completion scanning step completion produces states complete 
computational linguistics volume number table example grammar tiny fragment english 
earley parser processing sentence circle touches triangle 
predicted np vp np det det det np det circle square triangle vp vt np vt touches vp vi pp np circle touches square scanned scanned scanned scanned scanned circle 
vt touches 
det triangle 
completed completed completed completed completed det det vp vt np np det np det predicted os np vp predicted predicted vp vt np 
circle predicted np det circle os np vp 
square vp vt np det square triangle vp vi pp triangle vt touches vi state set easy see earley parser operations correct sense chain transitions predictions scanning steps completions corresponds pos sible partial derivation 
intuitively true parser performs transitions exhaustively complete finds possible derivations 
formal proofs properties literature aho ullman 
rela earley transitions derivations stated formally section 
parse trees sentences reconstructed chart contents 
illustrate section discussing viterbi parses 
table shows simple grammar trace earley parser operation sample sentence 
earley parser deal type context free rule format null productions replace nonterminal empty string 
productions require special attention algorithm description complicated necessary 
sections assume null productions dealt summarize necessary changes section 
choose simply preprocess grammar eliminate null productions process described 

probabilistic earley parsing stochastic context free grammars stochastic context free grammar scfg extends standard context free formalism adding probabilities production andreas stolcke efficient probabilistic context free parsing rule probability usually written 
notation extent hides fact conditional probability production chosen expansion 
probabilities rules nonterminal lhs sum unity 
context freeness prob setting translates conditional independence rule choices 
result complete derivations joint probabilities simply products rule probabilities involved 
probabilities interest mentioned section defined formally 
definition quantities defined relative scfg nonterminal string alphabet probability partial derivation tk inductively defined tk 
tk 
tk strings terminals nonterminals production derived replacing occurrence 
string probability sum probabilities left derivations 
producing sentence probability string probability start symbol definition probability assigned grammar prefix probability sum probabilities sentence strings having prefix particular 
xy assume probabilities scfg proper con sistent defined booth thompson grammar contains useless nonterminals ones appear derivation 
restrictions ensure nonterminals define probability measures strings proper distribution formal definitions conditions appendix left derivation step replaces nonterminal furthest left partially expanded string 
order expansion irrelevant definition multiplicative combination production probabilities 
restrict summation left derivations avoid counting duplicates left derivations play important role 
computational linguistics volume number earley paths probabilities order define probabilities associated parser operation scfg need concept path partial derivation executed earley parser 
definition unconstrained earley path simply path sequence earley states linked prediction scanning completion 
purpose definition allow scanning operate generation mode states terminals right dot scanned just matching input 
completed states predecessor state defined complete state state set contributing completion 
path said constrained generate string terminals immediately left dot scanned states sequence form string path complete state matches dot moved rhs 
say path starts nonterminal state predicted state lhs 
length path defined number scanned states 
note definition path length somewhat counterintuitive moti fact scanned states correspond directly input symbols 
length path length input string generates 
constrained path starting initial state contains sequence states state set derived repeated prediction followed single state set produced scanning symbol followed sequence states produced completion followed sequence predicted states followed state scanning second symbol 
significance earley paths correspondence left derivations 
allow talk probabilities derivations strings prefixes terms actions performed earley parser 
derivation imply left derivation 
lemma earley parser generates state kx partial derivation xo xo xo deriving prefix xo input 
mapping partial derivations earley paths production applied derivation corresponds predicted earley state 
andreas stolcke efficient probabilistic context free parsing invariant underlying correctness completeness earley algo rithm proved induction length derivation aho ullman theorem 
slightly stronger form follows way pos sible prediction steps defined 
established paths correspond derivations convenient associate derivation probabilities directly paths 
uniqueness condition irrelevant correctness standard earley parser justifies prob counting paths lieu derivations 
definition probability path product probabilities rules predicted states occurring lemma paths starting nonterminal gives probability partial derivation represented particular string probability sum probabilities paths starting complete constrained sentence probability sum probabilities complete paths starting initial state constrained prefix probability sum probabilities paths starting initial state constrained scanned state 
note summing paths starting initial state summa tion paths starting definition initial state 
follows directly definitions derivation probability string probability path probability correspondence paths derivations established lemma 
follows start nonterminal 
obtain prefix probability need sum probabilities complete derivations generate prefix 
constrained paths scanned states represent exactly beginnings derivations 
grammar assumed consistent useless nonterminals partial derivations com probability 
sum constrained incomplete paths sought sum complete derivations generating prefix 
forward inner probabilities string prefix probabilities result summing derivation probabilities goal compute sums efficiently advantage earley control structure 
accomplished attaching probabilistic quantities earley state follows 
terminology derived analogous similar quan commonly literature hidden markov models hmms rabiner juang baker 
definition definitions relative implied input string forward probability oq kx sum probabilities constrained paths length state kx 
computational linguistics volume number inner probability sum probabilities paths length start state kx kx generate input symbols xk xi helps interpret quantities terms unconstrained earley parser operates generator emitting recognizing strings 
tracking possible derivations generator traces single earley path randomly determined choosing prediction steps associated rule probabilities 
notice scanning completion steps deterministic rules chosen 
intuitively forward probability oq kx probability earley generator producing prefix input position passing state kx position due left recursion productions state may appear times path occurrence counted total really expected number occurrences state state set having said refer simply probability sake brevity keep analogy hmm terminology generalization 
note scanned states probability definition scanned state occur path 
inner probabilities hand represent probability generating substring input nonterminal particular production 
inner probabilities conditional presence nonterminal expansion starting position forward probabilities include generation history starting initial state 
inner probabilities defined correspond closely quantities name baker 
sum states lhs exactly baker inner probability essentially restatement lemma terms forward inner probabilities 
shows obtain sentence string probabilities interested provided forward inner probabilities computed ef 
lemma assumes earley chart constructed parser input string provided gl xo possible left derivation grammar probability nonterminal generates substring xk xi computed sum kx 
sum inner probabilities complete states lhs start index 
technical complication noticed wright computation probabilistic lr parser tables 
relation lr parsing discussed section 
incidentally similar interpretation forward probabilities required hmms non emitting states 
andreas stolcke efficient probabilistic context free parsing particular string probability computed rl 

prefix probability computed oq kx xl sum forward probabilities scanned states 
restriction preceded possible prefix necessary earley parser position pursue derivations consistent input position constitutes main distinguishing feature earley parsing compared strict bottom computation standard inside probability computation baker 
inside probabilities positions nonterminals computed regardless possible prefixes 
computing forward inner probabilities forward inner probabilities subsume prefix string probabilities straightforward compute run earley algorithm 
fact weren left recursive unit productions computation trivial 
purpose exposition ignore technical complications introduced productions moment return picture clear 
run parser forward inner probabilities attached state updated incrementally new states created types transitions 
probabilities set unity initial state consistent interpretation initial state derived dummy production alternatives exist 
parsing proceeds usual probabilistic computations detailed 
probabilities associated new states computed sums various combinations old probabilities 
new states generated prediction scanning completion certain probabilities accumulated corresponding multiple paths leading state 
state generated multiple times previous probability associated incremented new contribution just computed 
states probability contributions generated order long summation state finished probability enters computation successor state 
appendix suggests way implement incremental summation 
notation 
intuitive abbreviations describe earley transitions succinctly 
avoid unwieldy notation adopt con 
expression means computed incrementally sum various terms computed order accumulated yield value transitions denoted predecessor states left definitions forward inner probabilities coincide final state 
notation suggests simple implementation obviously borrowed programming language computational linguistics volume number successor states right 
forward inner probabilities states notated brackets state kx shorthand ai kx fi 
prediction probabilistic 
kx iy productions new probabilities computed note forward probability accumulated step 
rationale 
sum path probabilities leading kx times probability choosing production value just special case definition 
scanning probabilistic 
lt states terminal matching input position rationale 
scanning involve new choices terminal ready selected part production prediction 
completion probabilistic 
jy kx kx ky note 
rationale 
update old forward inner probabilities cd respectively probabilities paths expanding factored 
exactly paths summarized inner probability 
different parsing scenarios scanning step may modify probabilities 
example input symbols attached likelihoods integrated multiplying symbol scanned 
way possible perform efficient earley parsing integrated joint probability computation directly weighted lattices describing ambiguous inputs 
andreas stolcke efficient probabilistic context free parsing coping recursion standard earley algorithm probability computations described previous section sufficient weren problem recursion prediction completion steps 
nonprobabilistic earley algorithm recursing soon predic tions completions yield states contained current state set 
com putation probabilities mean truncating probabilities re repeated summing contributions 
prediction loops 
example consider simple left recursive scfg 
sb prediction loop position producing states os sb 
leave forward probabilities ao os sb corresponding just infinity possible paths 
correct forward probabilities obtained sum infinitely terms accounting possible paths length 
ao os ao os sb qp lq sums corresponds choice production choice second production 
didn care finite computation resulting geometric series computed letting prediction loop summation continue indefinitely 
fortunately repeated prediction steps including due left recursion productions collapsed single modified prediction step corresponding sums computed closed form 
purpose need probabilistic version known parsing concept left comer heart prefix probability algorithm jelinek lafferty 
definition definitions relative scfg nonterminals said left comer relation iff exists production rhs starting ya 
computational linguistics volume number probabilistic left corner relation pl pl matrix probabilities defined total probability choosing production left corner ya 
relation gl defined reflexive transitive closure iff nonterminal gl probabilistic reflexive transitive left corner relation rl rl matrix probability sums gl 
defined series za 
alternatively rl defined recurrence relation delta function defined recurrence rl conveniently written matrix notation rl closed form solution derived rl pl 
existence proof rl appendix appendix shows speed computation rl inverting reduced version matrix pl significance matrix rl earley algorithm elements sums probabilities potentially infinitely prediction paths leading state kx predicted state iy number intermediate states 
rl computed grammar table lookup modified prediction step 
probabilistic relation replaced set theoretic version iff closure operations reduce traditional discrete counterparts choice terminology 
andreas stolcke efficient probabilistic context free parsing prediction probabilistic transitive 
kx iw oj productions gl nonzero 
dr 
new gl factor updated forward probability accounts sum path probabilities linking covers case single step prediction rl defined reflexive closure 
completion loops 
prediction completion step earley algorithm may imply infinite summation lead infinite loop computed naively 
unit productions give rise cyclic completions 
problem best explained studying example 
consider grammar ca 
input string grammar generates cycle prediction earley chart contains states 
lq lq os tp factors result left corner sum 

scanning os completion truncation enter infinite loop 
completed yielding complete state allows completed leading complete state nonprobabilistic earley parser just prediction lead truncated probabilities 
sum probabilities needs computed arrive correct result contains infinitely terms possible loop production 
loop adds factor forward inner probabilities 
summations completed states turn 
lq pq pq 
lq pq pq 
ol pq pq 
pq pq 
lq pq pq lq pq pq unit productions called chain productions single productions literature 
computational linguistics volume number approach taken compute exact probabilities cyclic completions analogous left recursive predictions 
main difference unit productions left corners form underlying transitive relation 
proceeding convince case worry 
lemma 
completion cycle kl xc xc case 
productions involved unit productions xc xc proof completion chains true start indices states monotonically increasing kl 
state complete expansion started previous position 
kl kc follows kl kc 
current position dot refers input index states nonterminals xc expanded substring input kl current position 
assumption grammar contains nonterminals generate 
formally define relation nonterminals mediated unit pro analogous left corner relation 
definition definitions relative scfg nonterminals said unit production relation iff exists production rhs 
probabilistic unit production relation pu pu matrix probabilities 
relation defined reflexive transitive closure iff nonterminal probabilistic reflexive transitive unit production relation ru ru matrix probability sums 
defined series zl zl null productions earley transitions see section 
andreas stolcke efficient probabilistic context free parsing zi 

matrix inversion compute relation ru closed form ru pu 
existence ru shown appendix modified completion loop probabilistic earley parser ru matrix collapse unit completions single step 
note iterative completion non unit productions 
completion probabilistic transitive 
jy ct kx oe kx az nonzero unit production lu 
example consider grammar zg 
ss highly ambiguous grammar generates strings number possible binary parse trees number terminals 
states involved parsing string aaa listed table forward inner probabilities 
example illustrates parser deals left recursion merging alternative sub parses completion 
grammar single nonterminal left corner matrix pl rank pl transitive closure rl pl 
consequently example trace shows factor introduced ward probability terms prediction steps 
sample string parsed aa aa parse having probability 
total string probability computed values final state 
oe values scanned states sets prefix probabilities aa aaa respectively gl gl aa aaa 
computational linguistics volume number table earley chart constructed parse aaa grammar 
columns right list forward inner probabilities respectively state 
columns separates old factors new ones equations 
addition indicates multiple derivations state 
ss state set predicted os lp os ss lq lq state set scanned os lp completed os lq pq predicted lp ss lq lq state set scanned completed lq pq os ss 
pq pq os lq pq predicted pq lp ss pq lq state set scanned 
completed pq ss 
pq pq lq pq os ss 
pq pq os lq andreas stolcke efficient probabilistic context free parsing null productions null productions introduce complications relatively straight forward parser operation described far due specifically probabilistic aspects parsing 
section summarizes necessary modifications process null productions correctly previous description baseline 
treatment null productions follows nonprobabilistic formulation graham harrison ruzzo original earley 
computing expansion probabilities 
main problem null productions allow multiple prediction completion cycles scanning steps null productions matched input symbols 
strategy collapse predictions completions due chains null productions regular prediction completion steps way recursive predictions completions handled section 
prerequisite approach precompute nonterminals prob ability expands empty string 
note recursive problem may null production expand nonterminal 
computation cast system non linear equations follows 
ex abbreviation 
example productions pl yi semantics context free rules imply expand rhs nonterminals productions expand translating probabilities obtain equation ex pl ey ey ey words production contributes term rule probability multiplied product variables corresponding rhs nonterminals rhs contains terminal case production contributes ex possibly lead 
resulting nonlinear system solved iterative approximation 
variable ex initialized repeatedly updated substituting equation right hand sides desired level accuracy attained 
conver gence guaranteed ex values monotonically increasing bounded true values 
grammars cyclic cies producing nonterminals procedure degenerates simple backward substitution 
obviously system solved grammar 
probability ex seen precomputed inner probability sion empty string sums probabilities earley paths derive justification way probabilities modified prediction completion steps described 
prediction null productions 
prediction mediated left corner re lation 
occurring right dot generate states computational linguistics volume number reachable way relation 
reachability criterion extended presence null productions 
specifically production wi yi left corner iff yi nonzero probability expanding contribution production left corner probability yi 
yi ii old prediction procedure modified steps 
replace old pl relation takes account null productions sketched 
resulting pl compute reflexive transitive closure rl generate predictions 
second predicting left corner production 
yi iyi add states dot positions rhs nonterminal expand say 
yi yi 
yi yi call procedure spontaneous dot shifting 
accounts precisely derivations expand rhs prefix 
wi consuming input symbols 
forward inner probabilities states created state 
yi multiplied factors account implied expansions 
factor just product dot position 
completion null productions 
modification completion step follows similar pattern 
unit production relation extended allow unit production chains due null productions 
rule 
yi 
yj effectively act unit production links yi nonterminals rhs expand contribution unit production relation yi 
yi 
yj resulting revised pu matrix compute closure ru usual 
second modification instance spontaneous dot shifting 
completing state moving dot get additional states added obtained moving dot nonterminals nonzero expansion probability 
prediction forward inner probabilities multiplied corresponding expansion probabilities 
eliminating null productions 
added complications con sider simply eliminating productions preprocessing step 
straightforward analogous corresponding procedure nonprobabilistic cfgs aho ullman algorithm 
main difference updating rule probabilities expansion probabilities needed 
delete null productions start symbol case grammar produces nonzero probability 
scale remaining production probabilities sum unity 
original rule contains nonterminal andreas stolcke efficient probabilistic context free parsing create variant rule set rule probability new rule 
rule exists sum probabilities 
decrement old rule probability amount 
iterate steps rhs occurrences null able nonterminal 
crucial step procedure addition variants original produc tions simulate null productions deleting corresponding nonterminals rhs 
spontaneous dot shifting described previous sections effec tively performs operation fly rules prediction completion 
complexity issues probabilistic extension earley parser preserves original control structure aspects major exception collapsing cyclic predictions unit completions steps efficient 
complexity analysis earley applies summarize important results 
worst case complexity earley parser dominated completion step takes input position length current prefix 
total time input length complexity standard inside outside baker lri jelinek lafferty algorithms 
grammars bounded ambiguity incremental word cost reduces total 
deterministic cfgs incremental cost constant total 
possible start indices state set contain earley states giving worst case space complexity 
apart input length complexity determined grammar size 
try give precise characterization case sparse grammars ap gives hints implement algorithm efficiently grammars 
fully parameterized grammars cnf verify scaling algorithm terms number nonterminals verify time space requirements inside outside lri algorithms 
completion step dominates computation compute probabilities states 
organizing summations summed lhs nonterminals entire completion operation accomplished 
time cost matrix inversions compute left corner unit production relation matrices 

extensions section discusses extensions earley algorithm go simple parsing computation prefix string probabilities 
extensions quite straightforward supported original earley chart structure leads view part single unified algorithm solving tasks mentioned 
computational linguistics volume number viterbi parses definition viterbi parse string grammar left derivation assigns maximal probability possible derivations definition viterbi parse computation straightforward gener corresponding notion hidden markov models rabiner juang computes viterbi path state sequence hmm 
pre approach earley parser fact derivation corresponds path 
standard computational technique viterbi parses applicable 
original parsing procedure sums probabilities correspond alternative derivations grammatical entity summation replaced maximization 
forward pass state keep track maximal path prob ability leading predecessor states associated maximum probability path 
final state reached maximum probability parse recovered tracing back path best predecessor states 
modifications probabilistic earley parser implement ward phase viterbi computation 
state computes additional probability viterbi probability viterbi probabilities propagated way inner probabilities completion summation replaced maximization vi kx maximum products vi jw vj kx contribute completed state kx 
position predecessor jy 
associated maximum recorded viterbi path predecessor kx predecessor state kx inferred 
completion step uses original recursion collapsing unit production loops 
loops simply avoided lower path probability 
collapsing unit production completions avoided maintain continuous chain predecessors backtracing parse construction 
prediction step need modified viterbi computation 
final state reached recursive procedure recover parse tree associated viterbi parse 
procedure takes earley state kx input produces viterbi parse substring output 
input state complete result partial parse tree children missing root node 
viterbi parse kx 
return parse tree root labeled children 
andreas stolcke efficient probabilistic context free parsing ends terminal call procedure recursively obtain parse tree viterbi parse adjoin leaf node labeled right child root return ends nonterminal find viterbi predecessor state jw 
current state 
call procedure recursively compute viterbi parse kx viterbi parse jy 
adjoin right child root return rule probability estimation rule probabilities scfg iteratively estimated em expectation maximization algorithm dempster 
sample corpus esti mation procedure finds set parameters represent local maximum grammar likelihood function product string probabilities xed samples assumed distributed identically independently 
steps algorithm briefly characterized follows 
step compute expectations grammar rule corpus current grammar parameters rule probabilities 
step reset parameters maximize likelihood relative expected rule counts step 
procedure iterated parameter values likelihood con verge 
shown round algorithm produces likelihood high previous em algorithm guaranteed find local maximum likelihood function 
em generalization known baum welch algorithm hmm esti mation baum original formulation case scfgs attributable baker 
scfgs step involves computing expected number times production applied generating training corpus 
step consists simple normalization counts yield new production probabilities 
section examine computation production count expectations re quired step 
crucial notion introduced baker purpose outer probability nonterminal joint probability generated prefix suffix terminals 
essentially method earley framework extending definition outer probabilities apply arbitrary earley states 
computational linguistics volume number definition string ix outer probability fli kx earley state sum probabilities paths 

start initial state generate prefix xo 
xk pass generate suffix xi 
starting state kx final state 
outer probabilities complement inner probabilities refer precisely parts complete paths generating covered corresponding inner probability kx 
choice production part outer probability associated state kx 
fact definition part rhs states sharing identical outer probabilities 
intuitively fli kx probability earley parser operating string generator yields prefix xo suffix xi passing state kx position independent 
case forward probabilities fl expectation number states path unit production cycles result multiple occurrences single state 
gloss technicality terminology 
name motivated fact fl reduces outer probability defined baker dot final position 
computing expected production counts 
going details com puting outer probabilities describe obtaining expected rule counts needed step grammar estimation 
denote expected number uses production derivation string alternatively expected number times prediction complete earley path generating number occurrences predicted states production path 
lx derives derives xo 
ix summation predicted states production quantity xo lxt sum probabilities paths passing ix inner outer probabilities defined quantity obtained precisely product corresponding yi fli 
andreas stolcke efficient probabilistic context free parsing expected usage count rule computed 
ix 
ix sum computed completing forward backward passes backward pass scanning chart predicted states 
computing outer probabilities 
outer probabilities computed tracing complete paths final state start state single backward pass earley chart 
completion scanning steps need traced back 
reverse scanning leaves outer probabilities unchanged operation concern reverse completion 
describe reverse transitions notation forward coun annotating state outer inner probabilities 
reverse completion 
jy 
fl kx ay fl kx fl pairs states jy 
kx chart 
fl fl fl fl inner probability 
rationale 
relative fl fl missing probability expanding filled 
probability surrounding fl probability surrounding fl plus choice rule production expansion partial lhs 
note computation inner probabilities computed forward pass 
particular way fl defined turns convenient production probabilities needs computation 
forward pass simple reverse completion terminate pres ence cyclic unit productions 
version collapses chains productions 
reverse completion transitive 
jy 
fl az fl kx fl pairs states jy kx chart unit production relation nonzero 
fl fl fl 
flr summation carried state kx mz second summation applied choice az unit production computational linguistics volume number rationale 
increments fl equivalent times accounting infinity surroundings occur derived cyclic productions 
note computation tip unchanged includes infinity cyclically generated subtrees appropriate 
parsing bracketed inputs estimation procedure described em estimators general guaranteed find locally optimal parameter estimates 
unfortunately case unconstrained scfg estimation local maxima real problem success dependent chance initial conditions lari young 
pereira schabes showed partially bracketed input samples alleviate problem certain cases 
bracketing information constrains parse inputs parameter estimates steering clear suboptimal solutions 
earley parser minimally modified take advantage bracketed strings invoking recursively left parenthesis encountered 
recursive stance parser passed predicted states position processes input matching right parenthesis hands complete states back invoking instance 
technique efficient explicitly rejects parses consistent bracketing 
convenient leaves basic parser operations including left right processing probabilistic computations unchanged 
example prefix probabilities conditioned partial bracketings computed easily way 
parsing bracketed inputs described detail stolcke shown bracketing gives expected improved efficiency 
example modified earley parser processes fully bracketed inputs linear time 
robust parsing applications ungrammatical input dealt way 
tra seen drawback top parsing algorithms earley sacrifice robustness ability find partial parses ungrammatical input efficiency gained top prediction magerman weir 
approach problem build robustness grammar 
simplest case add top level productions xs expand nonterminal including unknown word category 
grammar cause earley parser find partial parses substrings effectively behaving bottom parser constructing chart left right fashion 
refined variations possible top level productions model phrasal categories sentence fragments follow 
probabilistic information pruning version earley parser section arrive compromise robust expectation driven parsing 
alternative method making earley parsing robust modify parser accept arbitrary input find chosen subset pos sible substring parses 
case earley parser simple extension andreas stolcke efficient probabilistic context free parsing accomplish just notion wildcard state wildcard stands arbitrary continuation rhs 
prediction wildcard left dot causes chart seeded dummy states phrasal category interest 
conversely minimal modification standard completion step allows wildcard states collect abutting substring parses jy 

way partial parse represented exactly wildcard state final chart position 
detailed account technique stolcke 
advantage grammar modifying approach tailored various criteria runtime decide partial parses follow 

discussion online pruning finite state parsing especially speech decoding forward probabilities pruning partial parses having seen entire input 
pruning formally straightforward earley parsers state set rank states values remove states small probabilities compared current best candidate simply rank exceeds limit 
notice omit certain parses underestimate forward inner probabilities derivations remain 
pruning procedures evaluated empirically invariably sacrifice completeness case viterbi algorithm optimality result 
earley line pruning awaits study reason earley framework inherent advantages strategies bottom information including called top parsers 
context free ward probabilities include available probabilistic information subject assump tions implicit scfg formalism available input prefix usual inside probabilities take account nonterminal prior probabilities result top relation start state 
top constraints necessarily mean sacrificing robustness discussed section 
contrary earley style parsing set carefully designed estimated fault tolerant top level productions possible probabilities bet ter advantage robust parsing 
approach subject ongoing context tight coupling scfgs speech decoders jurafsky wooters segal cke morgan 
relation probabilistic lr parsing major alternative context free parsing paradigms earley algo rithm lr parsing aho ullman 
comparison approaches probabilistic nonprobabilistic aspects interesting provides useful insights 
remarks assume familiarity approaches 
computational linguistics volume number sketch fundamental relations important tradeoffs frameworks 
earley parser lr parsing uses dotted productions called items keep track progress derivations input processed 
start indices part lr items may term item refer lr items earley states start indices 
earley parser constructs sets possible items fly possible partial derivations 
lr parser hand access complete list sets possible items computed runtime simply follows transitions sets 
item sets known states lr parser 
grammar suitable lr parsing transitions performed deterministically considering input contents shift reduce stack 
generalized lr parsing extension allows parallel tracking multiple state transitions stack actions graph structured stack tomita 
probabilistic lr parsing wright lr items augmented certain conditional probabilities 
specifically probability associated lr item terminology normalized forward probability denominator probability current prefix lr item probabilities conditioned forward probabilities compute conditional probabilities words xi sum items having xi right dot extra required item corresponds reduce state dot final position 
notice definition independent start index corresponding earley state 
ensure item probabilities correct independent input position item sets constructed probabilities unique set 
may impossible probabilities take infinitely values general depend tory parse 
solution wright collapse items prob abilities small tolerance identical 
threshold simplify number technical problems left corner probabilities computed iterated prediction resulting changes probabilities smaller subject approximations probabilistic lr parser compute prefix probabilities multiplying successive conditional probabilities words sees 
alternative computation lr transition probabilities scfg estimate probabilities directly traces parses earley parsers lr parsers built various amounts lookahead operation parser deterministic efficient 
case zero lookahead lr considered correspondence lr parsers lookahead earley parsers discussed literature earley aho ullman 
helpful compare closely related finite state concept states lr parser correspond sets earley states similar way states deterministic fsa correspond sets states equivalent nondeterministic fsa standard subset construction 
identity expression item probabilities wright proved induction steps performed compute shown stolcke 
clear numerical properties approximation errors accumulate longer parses 
andreas stolcke efficient probabilistic context free parsing training corpus 
imprecise relationship lr probabilities scfg probabilities clear model estimated corresponds particular scfg usual sense 
briscoe carroll turn incongruity advantage lr parser probabilistic model right show lr probabilities extended capture non context free contingencies 
problem capturing complex distributional constraints natural language clearly important scope article 
simply possible define interesting nonstandard probabilities terms earley parser actions better model non context free phenomena 
apart considerations choice lr methods earley pars ing typical space time tradeoff 
earley parser runs linear time space complexity lr parser grammars appropriate lr class constant factors involved favor lr parser compiled transition action table 
size lr parser tables exponential size grammar number potential item subsets 
furthermore generalized lr method dealing nondeterministic grammars tomita runtime arbitrary inputs may grow exponentially 
bottom line application needs evaluated pros cons approaches find best solution 
theoretical point view earley approach inherent appeal general exact solution computation various scfg probabilities 
related literature earley probabilistic parsers sparse presumably precedent set inside outside algorithm naturally formulated bottom algorithm 
nakagawa nonprobabilistic earley parser aug mented word match scoring 
truly probabilistic algorithms similar viterbi version described find parse optimizes accumulated matching scores regard rule probabilities 
prediction completion loops come play precise inner forward probabilities computed 
magerman marcus interested primarily scoring functions guide parser efficiently promising parses 
earley style top prediction suggest worthwhile parses compute precise probabilities argue inappropriate metric natural language parsing 
vidal exhibit earley parser processes weighted necessarily probabilistic cfgs performs computation isomorphic inside probabilities shown 
schabes adds inner outer proba bilities earley algorithm purpose obtaining generalized estimation algorithm scfgs 
approaches restricted grammars unbounded ambiguities arise unit null productions 
dan jurafsky personal communication wrote earley parser ley restaurant project speech understanding system originally computed forward probabilities restricted grammars left corner unit production recursion 
parser uses method described provide exact scfg pre fix word probabilities tightly coupled speech decoder jurafsky wooters segal stolcke morgan 
computational linguistics volume number essential idea probabilistic formulation earley algorithm collapsing recursive predictions unit completion chains replacing lookups precomputed matrices 
idea arises formulation need compute probability sums infinite series 
graham harrison ruzzo nonprobabilistic version technique create highly opti mized earley parser general cfgs implements prediction completion operations boolean matrices 
matrix inversion method dealing left recursive prediction borrowed lri algorithm jelinek lafferty computing prefix probabilities scfgs cnf idea second time deal similar recursion arising unit productions completion step 
suspect proved earley computation forward probabilities applied cnf grammar performs computation isomorphic lri algorithm 
case believe parser oriented view afforded earley framework intuitive solution prefix probability problem added advantage restricted cnf grammars 
algorithms probabilistic cfgs broadly characterized di 
dimension quantities entered parser chart defined bottom cyk fashion left right constraints inherent part definition probabilistic earley parser shares inherent left right character lri algorithm contrasts bottom algorithm 
probabilistic parsing algorithms may classified fully parameterized cnf grammars arbitrary context free rules typ ically advantage grammar sparseness 
respect earley approach contrasts cnf oriented lri algorithms 
approach avoiding cnf constraint formulation probabilistic recursive tran sition networks kupiec 
similarity goes kupiec approach state transitions dotted productions earley states turn equivalent rtn states rtn constructed cfg 

earley parser stochastic context free grammars appealing combination advantages existing methods 
earley control structure lets algorithm run best known complexity number gram mar subclasses worse standard bottom probabilistic chart parsers general scfgs fully parameterized cnf grammars 
bottom parsers computes accurate prefix probabilities tally scanning input usual substring inside probabilities 
chart constructed parsing supports viterbi parse extraction baum welch type rule probability estimation way backward pass parser chart 
input comes partial bracketing indicate phrase structure connection ghr algorithm pointed fernando pereira 
exploration link led extension algorithm handle productions described section 
method uses transitive reflexive closure left corner relation pl chose symbol ql 
chose symbol rl article point difference 
course cyk style parser operate left right right left reordering computation chart entries 
andreas stolcke efficient probabilistic context free parsing information easily incorporated restrict allowable parses 
simple ex tension earley chart allows finding partial parses ungrammatical input 
computation probabilities conceptually simple follows directly ear ley parsing framework drawing heavily analogy finite state language models 
require rewriting grammar normal form 
algorithm fills gap existing array algorithms scfgs efficiently combin ing functionalities advantages previous approaches 
appendix existence rl ru section defined probabilistic left corner unit production matrices rl ru respectively collapse recursions prediction completion steps 
shown matrices obtained result matrix inversions 
appendix give proof existence inverses assured grammar defined senses 
terminology taken booth thompson 
definition scfg alphabet start symbol say proper iff nonterminals rule probabilities sum unity consistent iff defines probability distribution finite strings xl xe induced rule probabilities definition 
useless nonterminals iff nonterminals appear derivation string nonzero probability ax useful translate consistency process terms 
view scfg stochastic string rewriting process step consists simultaneously re placing nonterminals sentential form right hand sides productions randomly drawn rule probabilities 
booth thompson show grammar consistent probability stochastic rewriting start symbol leaves nonterminals remaining steps goes 
loosely speaking rewriting terminate finite number steps probability grammar inconsistent 
unfortunately terminology literature uniform 
example jelinek lafferty term proper mean defined 
state mistakenly sufficient condition 
booth thompson show write scfg satisfies generates derivations terminate probability give necessary sufficient conditions 
computational linguistics volume number observe property holds grammar useless terminals 
nonterminal admitted infinite derivations nonzero probability derivations assumption reachable nonzero probability 
prove existence rl ru sufficient show corresponding geometric series converge rl pl 
pl ru pu 
pu 
lemma proper consistent scfg useless nonterminals powers left corner relation unit production relation converge zero oo 
proof entry left corner matrix pl probability generating immediately succeeding left corner similarly entry nth power probability generating left corner intermediate nonterminals 
certainly bounded probability entire derivation starting terminates steps derivation couldn terminate expanding left symbol terminal opposed nonterminal 
probability tends oo entry 
unit production matrix pu similar argument applies length derivation long takes terminate initial unit production chain 
lemma proper consistent scfg useless nonterminals series rl rt defined converge finite non negative values 
proof converging implies magnitude pl largest eigenvalue spectral radius turn implies series converges similarly pt 
elements rl ru non negative result adding multiplying non negative elements pl pu respectively 
interestingly scfg may inconsistent converging left corner unit production matrices consistency stronger constraint 
example ss inconsistent choice left corner relation single number case defined 
case left fringe derivation guaranteed result terminal finitely steps derivation may terminate 
andreas stolcke efficient probabilistic context free parsing appendix implementation notes appendix discusses experiences gained implementing prob earley parser 
prediction collapse transitive predictions step implemented efficient straightforward manner 
explained section perform single pass current state set identifying nonterminals occurring right dots add states corresponding productions reachable left corner relation indicated equation contributions forward probabilities new states summed paths lead state 
summation equation optimized values old states nonterminal summed multiplied gl 
quantities summed nonterminals result multiplied rule probability give forward probability predicted state 
completion prediction completion step involves iteration 
complete state de rived completion potentially feed completions 
important detail ensure contributions state summed proceeding state input completion steps 
approach problem insert complete states prioritized queue 
queue orders states start indices highest 
states corresponding expansions completed lead completion expansions earlier derivation 
start index entries managed queue ensuring dependency graph formed states traversed breadth order 
completion pass implemented follows 
initially complete states previous scanning step inserted queue 
states re moved front queue complete states 
new states produced complete ones added queue 
process iterates states remain queue 
computation probabilities ready includes chains unit productions states derived productions need queued ensures iteration terminates 
similar queuing scheme start index order reversed reverse completion step needed computation outer probabilities section 
efficient parsing large sparse grammars moderate sized application specific natural language grammar taken speech system jurafsky wooters segal stolcke foster morgan opportunity optimize implementation algorithm 
relate lessons learned process 
speeding matrix inversions 
prediction completion steps matrix defined geometric series derived matrix 

computational linguistics volume number indexed nonterminals grammar 
matrix de rived scfg rules probabilities left corner relation unit production relation 
application fixed grammar time taken precomputation left corner unit production matrices may crucial occurs line 
cases cost minimized rule probabilities iteratively reestimated 
matrix sparse matrix inversion prohibitive large numbers nonterminals empirically matrices rank bounded number nonzero entries row independent inverted time full matrix size require time 
cases grammar relatively small number nonterminals productions involving nonterminals left corner rhs unit production 
nonterminals nonzero contributions higher powers matrix fact substantially reduce cost matrix inversion needed compute subset entries elements indexed non terminals nonempty row example left corner computation obtained deleting rows columns indexed nonterminals productions starting nonterminals 
identity matrix set nonterminals 
computed inverse denotes matrix multiplication left operand augmented zero elements match dimensions right operand speedups obtained technique substantial 
grammar nonterminals nonterminal productions left corner matrix computed seconds including final multiply addition 
inversion full matrix took minutes seconds 
linking bottom filtering 
discussed section worst case run time fully parameterized cnf grammars dominated completion step 
necessarily true sparse grammars 
experiments showed computation dominated generation earley states prediction steps 
worthwhile minimize total number predicted states gen erated parser 
predicted states affect derivation lead subsequent scanning input symbol constrain relevant pre 
compute extended left corner relation rlt indicating terminals appear left corners nonterminals 
rlt boolean figures meaningful absolute values 
measurements obtained sun sparcstation clos implementation generic sparse matrices particularly optimized task 
andreas stolcke efficient probabilistic context free parsing matrix rows indexed nonterminals columns indexed terminals 
computed product rlt plt nonzero entry iff production nonterminal starts terminal rl old left corner relation 
prediction step ignore incoming states rhs nonterminal dot current input left corner eliminate remaining predictions lhs produce current input left corner 
filtering steps fast involve table lookup 
technique speeding earley prediction exact converse linking method described pereira shieber chapter improving efficiency bottom parsers 
extended left corner relation top filtering bottom application grammar rules 
case linking provide bottom filtering top application productions 
test corpus technique cut number generated predictions fourth speeded parsing factor 
corpus consisted sentence average length words 
top prediction generated states parsed rate milliseconds sentence 
bottom filtered prediction states generated resulting mil sentence 
acknowledgments due dan jurafsky steve omohundro extensive discussions topics fernando pereira helpful advice pointers 
jerry feldman terry regier jonathan segal kevin thompson anonymous reviewers provided valuable comments improving content presentation 
aho alfred ullman jeffrey 

theory parsing translation compiling volume parsing 
prentice hall 
bahl jelinek frederick mercer robert 

maximum likelihood approach continuous speech recognition 
ieee transactions pattern analysis machine intelligence 
baker james 

trainable grammars speech recognition 
speech communication papers th meeting acoustical society america edited jared wolf dennis klatt 
baum leonard petrie ted soules george weiss norman 
maximization technique occuring statistical analysis probabilistic functions markov chains 
annals mathematical statistics 
booth taylor thompson richard 

applying probability measures languages 
ieee transactions computers 
briscoe ted carroll john 
generalized probabilistic lr parsing natural language corpora unification grammars 
computational linguistics 
vidal 

parsing algorithm weighted grammars substring recognition 
syntactic structural pattern recognition volume nato asi series edited gabriel theo pavlidis alberto horst bunke 
springer verlag 
anna de mori renato roberto satta giorgio 
computation probabilities island driven parser 
ieee transactions pattern analysis machine intelligence 
dempster laird rubin 

maximum likelihood incomplete data em algorithm 
journal royal statistical society series 
earley jay 
efficient context free parsing algorithm 
communications acm 
fujisaki jelinek cocke black 

probabilistic parsing method sentence disambiguation 
current issues parsing technology edited masaru tomita 
kluwer academic computational linguistics volume number publishers 
graham susan harrison michael ruzzo walter 

improved context free recognizer 
acm transactions programming languages systems 
jelinek frederick 
markov source modeling text generation 
impact processing techniques communications volume nato asi series edited 
nijhoff 
jelinek frederick lafferty john 

computation probability initial substring generation stochastic context free grammars 
computational linguistics 
jelinek frederick lafferty john mercer robert 

basic methods probabilistic context free grammars 
speech recognition understanding 
advances trends applications volume nato asi series edited pietro renato de mori 
springer verlag 
jones mark eisner jason 

probabilistic parser applications 
aaai workshop statistically nlp techniques 
jurafsky daniel wooters chuck segal jonathan stolcke andreas eric gary morgan nelson 
stochastic context free grammar language model speech recognition 
proceedings ieee conference acoustics speech signal processing 
detroit michigan 
jurafsky daniel wooters chuck gary segal jonathan stolcke andreas eric morgan nelson 
berkeley restaurant project 
proceedings international conference spoken language processing 
yokohama japan 
kupiec julian 
hidden markov estimation unrestricted stochastic context free grammars 
proceedings ieee conference acoustics speech signal processing san francisco california 
lari young 

estimation stochastic context free grammars inside outside algorithm 
computer speech language 
lari young 

applications stochastic context free grammars inside outside algorithm 
computer speech language 
magerman david marcus mitchell 

pearl probabilistic chart parser 
proceedings second international workshop parsing technologies 
cancun mexico 
magerman david weir carl 
efficiency robustness accuracy chart parsing 
proceedings th annual meeting association computational linguistics 
newark delaware 
nakagawa sei ichi 
spoken sentence recognition time synchronous parsing algorithm context free grammar 
proceedings ieee conference acoustics speech signal processing 
dallas texas 
ney hermann 
stochastic grammars pattern recognition 
speech recognition understanding 
advances trends applications volume nato asi series edited pietro renato de mori 
springer verlag 

modification earley algorithm speech recognition advances speech understanding dialog systems volume nato asi series edited niemann lang 
springer verlag 
pereira fernando schabes yves 
inside outside reestimation partially bracketed corpora 
proceedings th annual meeting association computational linguistics 
newark delaware 
pereira fernando shieber stuart 

prolog natural language analysis 
lecture notes series number 
center study language information stanford california 
rabiner juang 

hidden markov models 
ieee assp magazine 
schabes yves 
inside outside algorithm estimating parameters hidden stochastic context free grammar earley algorithm 
second workshop mathematics language new york 
stolcke andreas segal jonathan 
precise gram probabilities stochastic context free grammars 
proceedings lth annual meeting association computational linguistics 
las cruces new mexico 
stolcke andreas 
efficient probabilistic context free parsing algorithm computes prefix andreas stolcke efficient probabilistic context free parsing probabilities 
technical report tr international computer science institute berkeley ca 
revised 
tomita masaru 
efficient parsing natural language 
kluwer academic publishers 
wright 

lr parsing probabilistic grammars input uncertainty speech recognition 
computer speech language 

