importance sampling cristian sminchisescu bill triggs inria rh ne alpes avenue de europe montbonnot france 
cristian sminchisescu bill triggs inrialpes fr www inrialpes fr people sminchisescu triggs sequential random sampling markov chain monte carlo popular strategy vision problems involving multimodal distributions high dimensional parameter spaces 
applies importance sampling wants sample points importance calculation fairly global optimization wants find minima starting points local minimization regardless fairness 
unfortunately sequential samplers prone trapped long periods unrepresentative local minima leads biased highly variable estimates 
general strategy reducing mcmc trapping generalizes voter sampling computational chemistry 
local gradient curvature input distribution construct adaptive importance sampler focuses samples low cost negative curvature regions contain transition states codimension saddle points representing mountain passes connecting adjacent cost basins 
substantially accelerates inter basin transition rates preserving correct relative transition probabilities 
experimental tests difficult problem articulated human pose estimation monocular images show significantly enhanced minimum exploration 
keywords markov chain monte carlo importance sampling global optimization human tracking 
vision problems formulated global minimizations highly nonconvex cost functions minima statistical inferences fair sampling expectation value integrals highly multi modal distributions 
importance sampling promising approach applications particularly combined sequential markov chain monte carlo layered annealed samplers optionally punctuated bursts local optimization :10.1.1.29.2078
sampling methods flexible tend computationally expensive level accuracy 
particular multi modal cost surfaces current sequential samplers prone trapped long periods cost basins containing unrepresentative local minima 
trapping poor mixing leads biased highly variable estimates character best quasi local global 
trapping times typically exponential large scale parameter buying faster computer helps little 
current samplers myopic mainly consider size integrand evaluated cost optimized judging importance 
efficient global estimates critically important include appear eccv sminchisescu triggs effective strategy reducing trapping explicitly devoting fraction samples moving cost basins 
describes method reducing trapping boosting dynamics sequential sampler 
approach voter originally developed computational chemistry accelerate estimation transition rates different atomic arrangements atom level simulations molecules solids 
dynamics basically thermally driven random walk point configuration space combined atomic coordinates subject effective energy potential models combined inter atomic interactions 
configuration space potential highly multimodal corresponding different large scale configurations molecule simulated 
trapping significant problem especially fine scale dynamics quite short time steps ensure accurate physical modelling 
mixing times steps common 
target applications vision sampler need satisfy strict physical constraints trapping remains key problem 
reduces trapping boosting number samples fall near transition states low lying saddle points system typically pass moving thermally adjacent energy basins 
modifying cost function adding term gradient curvature original potential raises cost near cores local potential basins reduce trapping leaving cost intact regions original potential negative curvature eigenvalue low gradient characteristic transition neighborhoods 
viewed generalized form mcmc importance sampling importance measure considers gradient curvature values original cost function 
key point specific form adopted potential refined notion importance deliberately adding samples speed mixing reduce global bias finite sample effects added samples directly important calculation performed 
general approach multi modal optimization annealing initially sampling reduced sensitivity underlying cost higher temperature progressively increasing sensitivity focus samples lower cost regions 
annealing times vision works applications important limitations general method reducing trapping :10.1.1.46.1344
main problem samples indiscriminately certain energy band regardless points sampled lead basin minimum simply lead potential wall 
applications especially high dimensional ill conditioned ones cost surface relatively narrow corridors connecting adjacent basins important steer samples local information cost appears changing 
attempt doing 
fact methods complementary may possible speed annealing modified potential investigate 
raising temperature unacceptable chemistry applications may significantly change problem 
solid simulated melt 
multiple mode sampling function importance sampling curse dimensionality causes difficulties high dimensional search 
stochastic methods long sampling runs needed hit distribution typical set areas probability mass concentrated 
sequential samplers due inherently local nature sampling process tends trapped individual modes moving infrequently 
generally choosing importance sampling distribution compromise tractable efficient focusing sampling resources places look 
issues design multi modal sampler approximation accuracy high dimensions original distribution complex highly multi modal case vision finding approximating function difficult limiting applicability method 
appealing look ways modified version original distribution instance annealing methods 
ii trapping approximation locally accurate sampling original distribution avoiding artifacts sampling procedures tend get caught mode closest starting point sampling 
long runs needed sample infrequent transition events lie far tails modal distributions huge difference results 
iii biased transition rates annealing changes absolute inter mode transition rates reducing trapping relative sizes 
guarantee modes visited correct relative probabilities implied dynamics original cost surface 
may irrelevant aim simply discover modes best mode levels annealing needed difficult transitions frequent significantly increase number modes state space volume available visited cause vast bulk samples wasted fruitless regions especially important applications tracking neighboring modes separated current lowest energy barriers need recovered 
summarize complex high dimensional problems finding approximating distributions hard useful look sequential samplers distributions derived original 
trade sampling local computational accuracy requires samples important regions usually mode cores sampling mixing requires frequent samples tails distribution focused regions lead inter modal transitions 
defining regions delicate practice clear steering samples regions low gradient negative curvatures increase likelihood finding transition states saddle points negative curvature direction relative purely cost methods annealing 
analogy chemist melting solid liquids regions state space huge numbers small interconnected minima saddles solids fewer clearly defined minima 
remember state space volume increases rapidly sampling radius high dimensions dense distant sampling simply infeasible 
sminchisescu triggs related briefly summarize relevant high dimensional search especially domain human modelling estimation 
cham rehg perform tracking scaled prismatic models 
method combines squares cost function particle filtering dynamical noise style sampling local optimization mixture gaussians state probability representation 
deutscher track body motion multi camera silhouette edge likelihood function annealed sampling temporal particle filtering framework 
sampling procedure resembles neal neal includes additional importance sampling correction designed improve mixing 
sidenbladh intensity cost function particle filtering importance sampling learned dynamical model track model walking person image sequence 
choo fleet combine particle filtering hybrid monte carlo sampling estimate human motion cost function joint re projection error input motion capture data 
sminchisescu triggs recover articulated motion monocular image sequences edge intensity cost function combination robust constraint consistent local optimization oversized covariance scaled sampling focus samples probable low cost regions 
uses stochastic dynamics cost gradient sampling boosts dynamics novel importance sampler constructed original probability surface local gradient curvature information 
annealing methods try increase transition rates sampling modified distribution specifically focuses samples regions contain transition states 
deterministic local optimization methods designed find transition states 
see companion 
sampling transition state theory importance sampling importance sampling works follows 
suppose interested quantities depending distribution quantity probability density proportional 
suppose feasible evaluate pointwise able sample directly distribution defines approximating distribution density fb 
base estimates sample independent points xn drawn fb 
expectation value quantity respect estimated wi xi wi importance weighting xi wi xi fb xi 
proved importance sampled estimator converges mean value increases difficult assess reliable estimate practice 
issues affect accuracy variability importance weights due deviations fb statistical fluctuations caused sampling infrequent events tails distribution especially critical estimating stochastic dynamics importance sampling various methods available speeding sampling 
stochastic dynamics method potential surface defined cost function negative loglikelihood state probability observations log 
canonical samples obtained simulating phase space dynamics defined hamiltonian function kinetic energy momentum variable 
averages variables canonical ensemble computed classical dimensional phase space integrals temperature constant 
dynamics sampling done locally integrating hamilton equations dx dp df dt dt dx langevin monte carlo type integration rejection scheme guaranteed perform sampling canonical distribution phase space xi xi sd df dx ni vector independently chosen gaussian variables zero mean unit variance stochastic dynamics integration step 
compared called hybrid methods langevin method larger step size advantageous problem step calculations relatively expensive see complete discussion relative advantages hybrid langevin monte carlo methods physical dynamics represents physical time statistical calculations simply represents number steps performed start simulation 
simulation time estimate acceleration infrequent events produced proposed biased potential 
transition state theory continuing statistical mechanics analogy begun previous section behavior physical system characterized long periods vibration note momenta represented implicitly langevin formulation need update values leapfrog step immediately replaced new ones drawn canonical distribution start iteration 
approximate cost hessian information available gradient projected hessian eigen basis components weighted local eigen curvatures give effective newton step 
steps near saddle points bias potential essentially zero avoid inefficiencies random walk behavior 
sminchisescu triggs cost function transition states state biased cost function original cost function fig 

original cost function bias added 
state energy basin followed infrequent transitions states saddle points 
transition state theory tst approximation transition rates states computed sample flux dividing surface separating 
state dimensional surface separating state neighbors 
rate escape state tst dirac delta function positioned dividing surface velocity normal surface 
crossings dividing surface correspond true state change events assume system loses memory transition event 
accelerating transition state sampling formalism tst rate evaluated follows tst dx dp dx dp consider adding positive bias boost cost fb corresponding biased state sb original cost property fb potential unchanged transition state regions 
tst rate tst fb fb dx dp dx dp fb sb fb sb sb fb sb boost term increases escape rate state cost shallower leaves ratios escape rates sb states invariant tst tst sb tst sb holds escape rates partition function denominator replacing partition function sb leaves ratios unchanged 
importance sampling concretely suppose nt steps classical dynamics simulation biased cost surface encounter ne escape attempts dividing surface 
computation assume simulation artificially confined basin state reflecting boundaries 
happen real simulations estimate biased boost time 
tst escape rate state estimated simply ratio number escape attempts total trajectory length tst ne nt 
consequently mean escape time inverse transition rate state estimated esc tst fb sb sb nt nt fb xi ne nt ne nt fb xi effective simulation time boost achieved step simply fb xi dynamical evolution system state state correct works distorted time scale depends exponentially bias potential 
system passes regions high fb equivalent time tb increases rapidly originally tended linger regions precisely return average owing low original cost 
conversely zones small fb equivalent time progress standard stochastic dynamics rate 
course reality simulation integration time step sampling coarseness simulation 
boosting time just gives intuition time sampler probably wasted making uninteresting samples near cost minimum 
largely point wastage factors astronomical practice samplers escape local minima 
biased cost main requirements bias potential zero dividing surfaces introduce new sub wells escape times comparable main escape time original cost definition require prior knowledge cost wells saddle points knew avoid trapping efficiently including explicit jumping samples 
sampling important regions cost surface minima hessian matrix strictly positive eigenvalues transition states exactly negative eigenvalue 
gradient vector vanishes cases 
rigorous definition tst boundary necessarily global locally near transition state boundary contains state adjacent points hessian negative eigenvalue vanishing gradient component corresponding eigenvector gp basin state defined set configurations gradient descent minimization leads minimum basin surrounded hypersurface outside local descent leads states sminchisescu triggs gradient vector hessian eigenvector 
voter advocates bias cost fb hb hb constant controlling strength bias length scale estimate typical nearest neighbour distance minima available 
note voter fb properties required 
particular zero dividing surface seen 
increasing hb increases bias nominal boosting 
principle permissible raise cost minimum level surrounding transition states 
risk doing entirely block sampling pathways minimum causing system trapped newly created old 
usually safer select moderate boosting 
difficulty voter potential direct differentiation dynamics requires third order derivatives 
inexpensive numerical estimation method order derivatives proposed 
completeness summarize appendix 
calculations complex needed standard gradient stochastic simulation see bias provides degree acceleration pays practice 
human domain modelling section briefly describes humanoid visual tracking models boosting experiments 
details see 
representation body models contain kinematic skeletons articulated joints controlled angular joint parameters covered flesh built superquadric ellipsoids additional global deformations 
typical model joint parameters xa internal proportion parameters xi encoding positions hip skull tip joints deformable shape parameters body part gathered vector xd 
complete model encoded single large parameter vector xa xd xi 
tracking static pose estimation usually estimate joint parameters 
model follows 
superquadric surfaces discretized meshes parameterized angular coordinates topological domain 
mesh nodes ui transformed points pi predicted image points ri composite nonlinear transformations ri pi xa xi xd ui represents sequence parametric deformations construct corresponding part frame represents chain rigid transformations map kinematic chain position represents perspective image projection 
model estimation prediction image matching cost metrics evaluated predicted model feature ri nearby associated image features ri results summed features produce image contribution importance sampling parameter space cost function 
cost robust function prediction errors ri ri ri 
cost gradient gi hessian hi computed assembled observations 
estimation aim probabilistic interpretation optimal estimates model parameters maximizing total probability bayes rule exp ri di ri cost density associated observation integral observations prior model parameters 
discretizing continuous problem map approach minimizes negative log likelihood total posterior probability log log fl fp observation likelihood experiments simple gaussian likelihood model image joint correspondences 
negative log likelihood observations just sum squared model joint reprojection errors 
full tracking system uses cost function initialization provides interesting difficult handle degree multimodality owing kinematic complexity human model large number parameters unobservable singular monocular image 
practice find search important initialization tracking cost function significantly cheaper evaluate full image allowing extensive sampling experiments 
priors constraints hard soft priors accommodated framework 
include anthropometric priors model proportions parameter stabilizers hard estimate useful modelling parameters terms collision avoidance body parts joint angle limits 
estimation values gradients hessians priors evaluated added contributions observations 
experiments results section illustrate method toy problem involving dimensional multi modal cost surface problem initial pose estimation articulated human model joint image correspondences 
cases compare method standard stochastic dynamics original cost surface 
parameters methods temperature integration step number simulation steps identical requires values additional parameters hb control properties bias potential 
ller cost surface ller potential fig 
left simple analytic cost function local minima saddle points chemistry sminchisescu triggs fig 

ller potential left standard stochastic dynamics gradient sampling simulation right gets trapped basin starting minimum 
fig 

sampling hb hb 
fig 

sampling hb hb 
literature illustrate transition state search methods inter minimum distance form ai ea xi bi xi yi ci yi 
boost time simulation time importance sampling boost time simulation time fig 

effective boost times mild left aggressive right bias potentials 
order length unit transition states energy units lowest minimum 
fig 
right shows result standard stochastic dynamic sampling original cost surface 
despite simulation steps reasonable step size basin starting minimum sampled extensively successful escape taken place 
fig 
shows runs parameters set moderate boosting 
note reduced emphasis sampling core minimum fact minimum replaced set higher energy ones fact runs escape initial basin 
right hand plot clear focusing samples region corresponding saddle point linking adjacent minima 
fig 
shows results aggressive bias potentials cause basins minima visited strong focusing samples transition regions 
bias turns lowest positive curvature region initial minimum local maximum 
plots show voter potential somewhat complicated local steps ridges 
near hypersurfaces hessian eigenvalue passes zero bias jumps hb increases length scale increases sic gradient projection gp decreases owing term 
small transitions smoother increases ridges potential occur hypersurfaces passes zero 
fig 
plots simulation boosting time bias potentials 
left plot milder potential simply encourages exploration saddle points right plot aggressive able explore jump individual modes rapidly 
note large different sizes boosting time scales plots 
monocular pose estimation explore potential method monocular human pose estimation model image joint correspondences 
problem adapted illustrating algorithm cost surface highly multimodal 
sminchisescu triggs kinematic model subject reflective kinematic ambiguities forwards vs backwards slant depth potentially creates local minima cost surface physically feasible automatically pruned simulation see 
find difficult ensure initialization correct pose kind data 
simulation enforces joint limit constraints reflective boundary conditions reversing sign particle normal momentum hits joint limit 
gives improved sampling acceptance rate compared simply projecting proposed configuration back constraint surface leads cascades rejected moves momentum direction gradually swings 
ran simulation steps original cost surface fig 
boosted fig 

easy see original sampler gets trapped starting mode wastes samples exploring repeatedly 
conversely boosted method escapes starting mode relatively quickly subsequently explores minima resulting depth reflection ambiguities 
fig 
plots estimated boosting times different bias potentials hb 
computed mean state variance original estimator compared boosted 
underlined fact global investigation strongly multimodal high dimensional cost functions importance samplers need devote samples reducing trapping local minima focusing performing target computation 
mind mcmc sampler designed accelerate exploration different minima method computational chemistry 
uses local cost gradients curvatures construct modified cost function focuses samples regions low gradient negative curvature contain transition states low cost saddle points negative curvature direction original cost 
experimental results demonstrate method significantly improves inter minimum exploration behaviour problem monocular articulated human pose estimation 
focus deriving alternative computationally efficient biased sampling distributions 
supported eiffel doctoral european union fet open project vibes 
alexandru implementation discussions 
appendix estimating gradient voter potential direct calculation gradient voter potential requires third order derivatives inexpensive numerical estimation method order derivatives importance sampling fig 

human poses sampled cost surface model joint correspondences seen camera viewpoint 
finds variety different poses including separated reflective ambiguities expected look similar camera viewpoint 
contrast standard stochastic dynamics underlying cost surface identical parameters essentially remains trapped original starting mode simulation steps fig 

boost time simulation time boost time simulation time fig 

boosting times human pose experiments mild left strong right bias 
proposed 
eigenvalue computed numerical approximation corresponding eigenvector direction sminchisescu triggs fig 

stochastic dynamics original cost surface leads trapping starting mode 
eigenvector direction estimated numerically gradient descent method random initialization previous dynamics step de ds lowest eigenvector obtained minimization compute corresponding eigenvalue 
procedure repeated higher pairs maintaining orthogonality previous directions 
derivative projected gradient obtained applying minimization matrices gg gg minimizes dei dx si approximation gp obtained gp dgp dx de dx de dx barr 
global local deformations solid primitives 
computer graphics 
black rangarajan 
unification line processes outlier rejection robust statistics applications early vision 
ijcv july 
cham rehg 
multiple hypothesis approach tracking 
cvpr volume pages 
choo fleet 
people tracking hybrid monte carlo filtering 
iccv 
importance sampling deutscher blake reid 
articulated body motion capture annealed particle filtering 
cvpr 
deutscher north blake 
tracking singularities discontinuities random sampling 
iccv pages 
duane kennedy 
hybrid monte carlo 
physics letters 
forsyth ioffe 
joy sampling 
ijcv 
gavrila davis 
model tracking humans action multiview approach 
cvpr pages 
heap hogg 
shape space tracking discontinuities changes shape 
iccv pages 
howe leventon freeman 
bayesian reconstruction human motion single camera video 

king forsyth 
condensation behave finite number samples 
eccv pages 
lee chen 
determination human body postures single view 
cvgip 
maccormick isard 
partitioned sampling articulated objects interface quality hand tracker 
eccv volume pages 
metropolis rosenbluth rosenbluth teller teller 
equation state calculations fast computing machines 
chem 
phys 
morris rehg 
singularity analysis articulated object tracking 
cvpr pages 
neal 
probabilistic inference markov chain monte carlo 
technical report crg tr university toronto 
neal 
annealed importance sampling 
statistics computing 
fua 
articulated soft objects video body modeling 
iccv pages 
rosales sclaroff 
inferring body pose tracking body parts 
cvpr pages 
bell 
chain states method investigating infrequent event processes occuring multidimensional systems 
chem 
phys 
sidenbladh black fleet 
stochastic tracking human figures image motion 
eccv 
sminchisescu 
consistency coupling human model likelihoods 

sminchisescu triggs 
robust multiple hypothesis approach monocular human motion tracking 
technical report rr inria 
sminchisescu triggs 
covariance scaled sampling monocular body tracking 
cvpr 
sminchisescu triggs 
building roadmaps local minima visual models 
eccv 
sorensen voter 
temperature accelerated dynamics simulation infrequent events 
chem 
phys 
vineyard 
frequency factors effects solid state rate processes 
phys 
chem 
solids 
voter 
method accelerating molecular dynamics simulation infrequent events 
chem 
phys 
voter 
accelerated molecular dynamics infrequent events 
physical review letters 
