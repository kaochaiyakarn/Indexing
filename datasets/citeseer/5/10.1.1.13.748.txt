poster supercomputing myth reality usage behavior large data intensive physics project adriana ripeanu department computer science university chicago chicago il anda cs 
uchicago edu motivation sustained effort ongoing support various scientific communities large scale data sharing data analysis needs distributed transparent infrastructure griphyn project ppdg eu datagrid 
infrastructure necessarily includes components file location management computation data transfer scheduling 
little information available specific usage patterns emerge data intensive scientific projects 
consequence current designs employ cover approach provisioning possible usage patterns optimizing start assumptions user behavior extrapolating results systems file systems web 
inappropriate assumptions may lead inadequate design decisions performance evaluations unrealistic conditions 
approach overcome problems study data usage patterns medium scale project experiment 
grid terminology experiment virtual organization consisting hundreds physicists institutions countries 
purpose provide worldwide system shareable computing storage resources solve common problem extracting physics results measured simulated data 
system data files read typical jobs analyze produce new processed data files 
tracing system utilization possible software layer sam provides centralized file data management 
analyzed logs months amounting project runs submitted users involve millions requests distinct files exact figures see table 
projects run multiple files average files project 
shows distribution number files project 
study objectives 
study applicability workload characterizations systems file systems web gnutella second discover emergent patterns user collaboration exploited system design 
learnt traditional workload models appropriate environment job inter arrival time existence diurnal usage patterns file size distribution file popularity distribution misleading 
observed user collaboration graph exhibits large clustering coefficient suggests design solutions file location possibly replica management mechanisms 
poster supercomputing table project runs 
average file accessed times projects accessed es approximately distinct 
average file size requests mb mb distinct files 
files distinct files month runs total total users number number size tb size tb january february march april may june total loo lo number files project 
number es project log log scale 
verifying traditional system characterizations aimed characterize aspects system users behavior files size popularity job submissions inter arrival time patterns 
user behavior despite homogeneous user community highly variable usage behavior confirms similar results different areas users submit requests 
oooo day 
number requests day month interval 
poster supercomputing jan june distinct files jan june files june distinct files june files io rank user 
number file requests user time intervals january june june 
users sorted number distinct files requested interval 
daily usage patterns find pronounced diurnal cycles expected system times loaded hours am pm central time times 
week weekend days exhibit similar load patterns specific type users scientists 
load measured terms files requested left axis triangles number jobs launched fight axis squares 
measures display similar patterns 
long timescales load system relatively smooth continuous lines represent hour moving averages observe regular client activity shorter time scales minutes spikes load order magnitude average 
outlier job requesting files files system eliminated 
daily usage patterns ffis lo 
daily usage patterns averaged month interval 
poster supercomputing distribution job inter arrival times note distribution distribution job inter arrival times fx log scale log looks normal gaussian 
estimated poisson models job arrival process leading exponential distributions job interarrival times generally model queuing systems partially due analytical tractability 
environment study model misleading 
obviously distribution heavy tailed job arrival process self similar see argument consistent observations burstiness timescale 
provisioning resources service somewhat simplified 
log normal plotted job interval time log 
job inter arrival time distribution non zipf file popularity distribution studies shown file popularity follows zipf distribution web 
gnutella requests follow pattern closer zipf 
shown requests data follow expected pattern 
reasons may complex claim understood 
potential explanations 
related type data scientific data may uniformly interesting explaining plateau users interests 
second explanation relatively small number users may lead erroneous non zipf distribution 
file popularity distribution scientific communities similar observed consequences system design 
caching efficient 
traditional workload models may misleading ecl rank supercomputing 
file popularity distribution 
file size distribution file sizes span large range kb gb average mb standard deviation median mb 
contrary previous results file size distribution heavy tailed 
important observation rules govern file sizes scientific data 
characteristics may domain dependent example event recorded accelerator kb file sequence events 
second decisions may dictate file size raw data maintained gb files 
file size log scale 
file size distribution heavy tailed 
user collaboration patterns analysis file requests large scientific collaboration reveals interesting patterns 
define user graph file sharing collaboration follows definition user collaboration graph graph nr set users active sent requests interval edge connects nodes users users share files observed user graphs various values exhibit small world characteristics average path length close random graph clustering coefficient encapsulates information connected node neighbors significantly poster supercomputing larger random graph size 
observation shows fact users cluster common file interests maintaining relatively short average distance graph terminology 
intuition motivated analysis 
lo avg 
path length avg 
path length random gra diameter clustering coefficient clustering coef 
random graph 
average path length user graphs days close smaller average path length random graphs size 
note diameter maximum node node distance small 

clustering coefficient user graphs days significantly larger random graphs number nodes edges 
significance small world characteristics figures describe particular graph topology properties graph contains highly connected subgraphs second average distance nodes small 
highly connected subgraphs refer clusters formed common data interests topology suggests new search methods combine information dissemination request propagation techniques 
specifically idea disseminate file location information locally stored files users common interests clusters propagate requests different groups interests 
assuming probabilistic information dissemination technique gossip tt file location information spread reliably fast members cluster 
requests files stored nodes group solved local lookup 
dynamic environment users change interests time natural question arises dynamic interest groups users 
data analysis reveals significant percentage users remain interval 
poster supercomputing 
significant percentage users stay interest group day interval 

user collaboration graph january 
exploiting 
small world file location file sharing collaboration users provide access locally stored data request access data stored users workstations want design flexible efficient file location mechanism suitable highly dynamic environments 
sources dynamism intermittent user participation collaboration changing user behavior data interests variation set shared files insertion new files 
file location mechanism exploits small world characteristics user collaboration graph requires components connects users small world overlay mirrors usage patterns performs search 
solution component allow nodes organize user collaboration graph 
nodes need identify peers common file interest 
user collaboration graph formed search component node needs distinguish neighbors disseminate information group interests neighbors propagate requests 
preliminary results poster supercomputing results hopefully soon mature publication 
grateful gabriele ruth john colleagues fermi national accelerator laboratory generous help 
supported national science foundation contract itr 
poster supercomputing 
arlitt friedrich jin workload characterization web proxy cable modem environment technical report hpl packard 

avery foster griphyn project virtual data grids technical report griphyn 

barford bestavros bradley crovella changes web client access patterns characteristics caching implications technical report bucs tr boston university 

breslau cao li fan phillips shenker web caching ipf distributions evidence implications 
proceedings conference ieee press new york ny 

technical report datagrid eu datagrid project 

douceur bolosky proceedings acm sigmetrics international conference measurement modeling computer systems atlanta georgia usa 

experiment 
www nal 
gov 

foster kesselman tuecke anatomy grid enabling scalable virtual organizations 
international journal high performance computing applications 


gribble brewer system design issues internet middleware ser vices deductions large client trace 
usenix 
iamnitchi ripeanu foster locating data small world 
peer peer scientific collaborations 
st international workshop peer peer systems springer verlag 
kermarrec massoulie ganesh reliable probabilistic communication large scale information dissemination systems technical report msr tr microsoft research cambridge 
carpenter moore white white sam particle physics data grid 
proceedings computing high energy nuclear physics beijing china 
particle physics data grid project ppdg www ppdg net 
sripanidkulchai popularity gnutella queries implications scalability technical report 
