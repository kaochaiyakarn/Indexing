face analysis synthesis photo realistic talking heads hans peter graf eric tony labs research schulz drive red bank nj usa hpg eric research att com mit carleton street cambridge ma ai mit edu describes techniques extracting bitmaps facial parts videos talking person 
goal synthesize photo realistic talking heads high quality show picture perfect appearance realistic head movements lip sound synchronization 
synthesis talking head bitmaps facial parts combined form heads sequences images integrated audio text speech synthesizer 
seamless integration facial parts animation shape visual appearance known high accuracy 
recognition system find location facial features able determine head orientation recognize facial expressions 
face recognition proceeds multiple steps increased precision 
motion color shape information head position location main facial features determined 
smaller areas searched matched filters order identify specific facial features high precision 
information head orientation calculated 
facial parts cut image head orientation warped bitmaps normalized orientation scale 

animated characters talking heads particular playing increasingly important role computer interfaces 
animated talking head attracts immediately attention viewer task engaging adds entertainment value application 
generating animated talking heads look real people challenging task far synthesized heads far reaching goal 
considered natural face photo realistic appearance exhibit realistic head movements emotional expressions proper plastic deformations lips synchronized speech 
trained birth recognize faces facial expressions highly sensitive slightest imperfections talking face 
approaches exist modeling human head achieving different degrees photo realism flexibility 
surge interest sample techniques referred data driven modeling synthesizing photo realistic heads 
techniques combine real images parts videos generate new animated sequences 
purpose person recorded speaking face parts extracted video 
new sequence talking head synthesized integrating parts new faces 
main difficulty approach large numbers images need analyzed generate set data samples allow synthesizing lively sequences 
high precision recognition required ensure synthesized faces look natural lip head movements smooth 
integrating facial parts new face placed accuracy typically pixel artifacts visible 
recorded parts vary orientation scale appearance compensated effects 
precise shape location appearance facial part orientation head measured 
researchers multiple cameras markers face find facial features derive geometry head 
systems shown impressive animations facial expressions demonstrated speech production 
talking head synthesis technique recorded mouth sequences tri phones subsequent phonemes demonstrated bregler 
parameterizes samples acoustic information limits appearances new sequences synthesized 
demonstrated sample talking head system uses morphing generate intermediate appearances mouth shapes small set manually selected mouth samples 
system produces smooth transitions mouth shapes take coarticulation account 
sample talking head uses layers bit planes model 
facial parts head modeled system limited new expressions movements synthesize 
approach attempt reduce limitations previous systems combining modeling head sample techniques 
system allows synthesizing speech provides limited range head movements emotional expressions 
coarticulation derived recorded samples resulting naturally looking lip movements 
special emphasis put keeping recording process data samples easy generating minimal human intervention 
single video camera features extracted automatically having place markers face 
recorded person move head 
extraction facial parts challenging provides environment natural articulation head movements typically accompany speech recorded 

model key problem sample techniques control number image samples need recorded stored 
face appearance changes due talking emotional expressions head orientation leading combinatorial explosion number different appearances 
keep number samples manageable level divide face hierarchy parts model part independently 
face model defined follows 
hierarchy parts head separated base face number facial parts 
base face covers area face serving substrate facial parts integrated 
facial parts mouth cheeks jaw eyes forehead eyebrows 
nose ears modeled separately part base face 

model shape facial part approximated small number planes 
set planes guide map facial parts base face pose 
positions orientations planes follow movements head shapes remain constant corresponding facial parts undergo non rigid deformations 
model plane local window facial part projected polygon traditional model 

sample bitmaps facial part sample bitmaps recorded cover range possible appearances produced nonrigid deformations 
base face bitmap samples 
top left recorded face top right normalized facial parts bottom left head model bitmaps bottom right head model strongly rotated illustrate shape model recorded head different orientations 
range head rotations consider moment frontal view 
generate face certain mouth shape emotional expression proper bitmaps chosen facial parts 
head orientation known base face adapt bitmaps base face warping 
operation similar traditional texture mapping 
difference nonrigid deformations select different bitmaps trying squeeze single bitmap new shape 

capturing sample bitmaps head model instantiated steps 
measurements subject face determine geometry 
measure positions eye corners nostrils mouth corners bottom chin 
measurements model planes adapted facial part 
second step facial part bitmaps extracted videos 
person recorded speaking freely text chosen cover frequent triphones english language 
lip shapes depend phoneme articulated moment context 
phenomenon known coarticulation taken account order synthesize naturally looking speech 
recorded frame videos analyzed determine head location orientation 
facial parts cut normalized warped new shape compensate different head orientations scales 
normalization necessary order characterize compare appearance facial parts different sequences 
facial part labeled easy identification 
example mouth labeled geometric parameters width position upper lower lip 
addition store phonetic context recorded plus parameters describing appearance 
interested capturing natural behavior speaker includes typical head movements speech emotional expressions try keep capture process simple non intrusive possible 
robust recognition algorithms need special markers subject face exploit natural richness features face 

recognition sample synthesis talking heads depends reliable accurate recognition face positions facial features 
main challenge face recognition system high precision facial features located 
error small single pixel position feature distorts pose estimation head noticeably 
achieve high precision analyze image steps increased accuracy 
large number features measured providing determined system equations computation head pose errors individual features averaged 
step finds coarse outline head plus estimates positions major facial features 
second step areas mouth nostrils eyes analyzed detail 
third step zooms specific areas facial features corners eyes mouth eyebrows measures positions high accuracy 
recognition works distinct types algorithms color analysis motion analysis texture shape analysis matched filters 

locating face step image searched presence heads locations determined 
color analysis type analysis color segmentation find areas skin colors colors representative hair 
hue segmentation hue tends fairly constant face regardless shadows fall 
image analysis locating head main facial features 
top row shape analysis bandpass filtered image left thresholded image center 
bottom row optical flow left thresholded flow field center image right shows head outline color segmentation main facial features area largest motion chin area 
camera goes saturation significant change hue skin 
training color segmentation done leader clustering set images segmentation done manually 
color analysis outputs binary blobs identifying areas skin hair 
shape texture analysis second type analysis segments image textures shapes 
analysis uses luminance image 
image filtered band pass filter removing highest lowest spatial frequencies 
filters adjusted pass spatial frequencies typical mouth eye areas face 
morphological operation followed adaptive thresholding results binary image 
filter parameters learned analyzing training set labeled images 
analysis produces color analysis binary blobs marking areas facial features 
motion analysis motion picture estimated optical flow algorithm 
algorithm block matching alternatively algorithm similar described lucas kanade 
thresholding output optical flow identify areas large displacements occur mark binary blobs 
color analysis texture motion analysis produce blobs connected binary pixels marking areas facial feature may 
representation compact way describing shapes relative positions 
features width height position moments measured blobs evaluated classifiers 
example area marked color analysis candidate face combined candidates eye areas produced texture analysis 
relative sizes positions match closely face combination evaluated combined features 
discarded 

locating facial features finding exact dimensions facial features challenging person recorded moving head changing facial expressions speaking 
lead great variations appearance facial feature affect lighting conditions 
example nod shadow may fall eyes 
analysis described produce accurate results facial features need analyze areas eyes mouth lower nose 
algorithm proceeds analyzing color space periodically retraining small number frames 
example area mouth cut frames leader clustering algorithm prominent colors area identified 
analyzing shapes color segments assign colors different parts skin mouth cavity teeth lips 
repeating color calibration periodically keep track changes appearances facial features 
shape analysis adapted particular facial feature investigation adjusting filter parameters size shape feature 
way combination texture color analysis produces reliable measurements positions outlines facial features 
color segmentation mouth 
errors system types 
type complete failure identify facial feature second type inaccuracy measurements 
failure identify feature happens frames head moves wider range seen training images hair covers part eye 
accuracy achieved dimensions mouth typically pixels standard deviation width mouth pixels 

high accuracy feature points calculating head pose points face measured high accuracy preferably error pixel 
techniques described tend produce variations example pixels eye corners 
filtering time improve errors significantly precise measurement preferable 
add third level analysis measure feature points highest accuracy 
training set frames representative examples feature point selected 
example measuring position left lip corner examples selected 
samples chosen dimensions mouth 
means training procedure selects mouth images different widths different heights 
images areas left corner cut 
analyzing new image sample images chosen mouth width height similar kernel scanned area left half mouth 
measure similarity kernel area analyzed filtered high pass filter multiplying pixel pixel calculating pixel difference 
correlation identifies precisely feature point located 
standard deviation measurements typically pixel eye corners filtering time reduces error pixels 
brute force computation correlations time consuming fairly large kernels 
features eye mouth corners kernel size typically pixels 
identifying chin mouth kernel may pixels 
order speed computation correlation implemented line searches 
correlation function minimum tends smooth approximated parabolic function 
surface minimum quickly conjugate gradient techniques 
features measure mouth chin nostrils eyes eyebrows 
knowing positions shapes features sufficient identify visemes mouth prominent emotional expressions 
interior mouth analyzed get better measure lip protrusion stress put lips 
locating corner mouth matched filter 
samples left corner belonging mouth similar dimensions mouth right chosen system 
kernel scanned area mouth corner find precise location 

pose estimation compute pose head estimation technique reported feature points face eye corners nostrils 
technique starts assumption model points lie plane parallel image plane corresponds orthographic projection model image plane plus scaling 
iteration algorithm adjusts model points projections image plane coincide observed image points 
pose model obtained solving iteratively linear system equations mi xi mi yi position object point base vectors camera coordinate system object coordinates focal length distance object origin camera 
unknown quantities determined 
yi scaled orthographic projection model point origin model plane correction term due depth model point 
parameter adjusted iteration algorithm converges 
algorithm stable measurement errors converges just iterations 

generating normalized face parts image samples entered database corrected shape scale compensate different head orientations recorded 
recognition module position shape facial parts pose head known 
extract facial parts images project planes model image plane 
projected planes mark extent facial part 
areas warped normalized bitmaps 
information shape produced recognition module mapped normalized view stored bitmap data structure 
samples face part extracted video sequences normalized need labeled sorted way retrieved efficiently 
parameter describe mouth shape phoneme sequence spoken recording 
recorded sequences segmented phonemes speech recognition system segmentation human listener 
second set parameters measurements produced recognition system 
example parameterize mouth parameters width distance corner points position upper lip outer lip contour position lower lip minimum outer lip contour 
samples facial parts parameterized similar way 
geometric features parameters describing appearance facial part 
filtering processes described provide convenient way characterizing texture sample 
filtering bitmap band pass filter measuring intensity frequency bands obtain characterization texture parameterize samples 
model defines areas cut facial part left 
bitmaps normalized facial part parameterized right 
way differentiate samples geometrical dimensions different visual appearance 

creating animated talking heads talking head animation driven output text speech synthesizer tts 
starting ascii text plus annotation controlling intonation tts produces sound file 
addition outputs phonetic transcription including precise timing information phoneme plus information stress 
sequence phonemes durations search database appropriate mouth shapes 
search calculates time step mouth sample fits sequence 
evaluation takes account phonetic context including durations phonemes match new sequence 
compares geometric parameters mouth shapes coming guarantee smooth lip movements 
checks parameters visual appearance sure discontinuities appearance see 
handle animation facial parts model similar developed mpeg facial animation subsystem 
special markers put text control amplitude length onset offset facial animations 

rendering frame final animation generated bitmaps face parts retrieved database 
bitmap base face copied frame buffer bitmaps face parts projected base face model pose base face 
moment consider limited range rotation angles need hidden surface removal 
avoid artifacts overlaying bitmaps gradual blending masks 
masks created blending value edges center 
operations implemented basic opengl calls frame rendered fly just texture map operations possible render talking head real time low cost pc 

results discussion order obtain feedback quality animated sequences conducted subjective tests close people 
test evaluated talking head improve intelligibility spoken text noisy environment 
head models improved intelligibility significantly cutting error rate 
test focused perception talking head user interface 
people exposed head clearly preferred interface head version head 
thirds respondents judged head natural natural 
lip synchronization judged 
complaint heard heads stiff 
clearly lively animation important keep viewer attention 

parke waters computer facial animation peters wellesley massachusetts 
grimm wood making faces proc 
siggraph pp acm siggraph july 
szeliski salesin synthesizing realistic facial expressions photographs proc 
siggraph acm siggraph july pp 
bregler slaney video rewrite driving visual speech audio proc 
siggraph pp acm siggraph july 
poggio talking facial display morphing visemes proc 
computer animation ieee computer society pp june 
graf sample photo realistic talking heads proc 
computer animation ieee computer society pp june 
barron fleet beauchemin performance optical flow techniques int 
computer vision vol pp 
dementhon davis iterative pose estimation coplanar feature points internal report car tr university maryland july 
ostermann animation synthetic faces mpeg proc 
computer animation ieee computer society june pp 
ostermann schroeder potamianos countless helpful discussions comments 
synthesized sequence mouth shapes 
bottom curve indicates mouth height top curve width 
final animation mouth bitmaps warped adapt head orientation base face 
