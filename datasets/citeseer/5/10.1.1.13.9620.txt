learning module networks eran segal computer science dept stanford university stanford ca usa eran cs stanford edu dana pe er computer science eng 
hebrew university jerusalem israel cs huji ac il aviv regev bauer ctr genomic research harvard university cambridge ma usa cgr harvard edu daphne koller computer science dept stanford university stanford ca usa koller cs stanford edu nir friedman computer science eng 
hebrew university jerusalem israel nir cs huji ac il methods learning bayesian networks discover dependency structure observed variables 
methods useful applications run computational statistical problems domains involve large number variables 
consider solution applicable variables similar behavior 
introduce new class models module networks explicitly partition variables modules share parents network conditional probability distribution 
define semantics module networks describe algorithm learns modules composition dependency structure data 
evaluation real data domains gene expression stock market shows module networks generalize better bayesian networks learned module network structure reveals regularities obscured learned bayesian networks 
decade research problem learning bayesian networks data successfully applying density estimation discovering dependency structures variables :10.1.1.112.8434
real world domains complex involving thousands relevant variables 
examples include modeling dependencies expression levels activity genes cell changes stock prices :10.1.1.130.4453
unfortunately complex domains amount data rarely robustly learn model underlying distribution 
gene expression domain typical data set includes thousands variables instances 
situations statistical noise lead spurious dependencies resulting models significantly overfit data 
propose approach address issue 
start observing large domains variables partitioned sets approximation variables set similar set dependencies exhibit similar behavior 
example genes cell organized modules sets genes required biological function response regulated inputs order coordinate joint activity 
example reasoning thousands nasdaq stocks entire sectors stocks respond sector influencing factors oil stocks tend respond similarly war iraq 
define new representation called module network explicitly partitions variables modules 
module represents set variables statistical behavior share set parents local probabilistic model 
enforcing constraint learned network significantly reduce complexity model space number parameters 
reductions lead robust estimation better generalization unseen data 
module network viewed simply bayesian network variables module share parents parameters 
probabilistic models shared parameters common variety applications general representation languages dynamic bayesian networks object oriented bayesian networks probabilistic relational models :10.1.1.101.3165:10.1.1.30.3832:10.1.1.38.9253
see section discussion relationship module networks formalisms 
cases shared structure imposed designer model prior knowledge domain 
key contribution design learning algorithm directly searches finds sets variables similar behavior defined module 
noise data extremely modular structure arise naturally bayesian network learning algorithm exists domain 
making modular structure explicit module network representation provides insight domain obscured intricate details large bayesian network structure 
describe basic semantics module network framework bayesian scoring function module networks provide algorithm learns assignment variables modules bayesian network module network simple bayesian network stock price variables stock price intel intl annotated visualization cpd described different multinomial distribution value influencing stock price microsoft msft 
simple module network boxes illustrate modules stock price variables share cpds parameters 
tic model module 
evaluate performance algorithm real datasets domains gene expression stock market 
results show learned module network generalizes unseen test data better bayesian network 
illustrate ability learned module network reveal high level structure provides important insights 
module network framework start example introduces main idea module networks provide formal definition 
concreteness consider simple toy example modeling changes stock prices 
bayesian network describes dependencies different stocks 
network random variable corresponds change price single stock 
simplicity random variables take values denoting change particular trading day 
example stock price intel intl depends microsoft msft 
cpd shown indicates behavior intel stock similar microsoft 
microsoft stock goes high probability intel stock go vice versa 
similarly bayesian network specifies cpd stock price stochastic function parents 
example network specifies separate behavior stock 
stock domain higher order structural features explicitly modeled bayesian network 
instance see stock price microsoft msft influences stock price major chip makers intel intl applied materials motorola mot 
turn stock price computer makers dell dell hewlett packard influenced stock prices chip suppliers intel applied materials 
approximation say stock price chip making companies depends microsoft way 
similarly stock price computer makers buy chips intel applied materials depends chip makers stock way 
model type situation divide stock price variables groups call modules require variables module probabilistic model variables module set parents cpd 
example contains modules containing microsoft second containing chip makers intel applied materials motorola third containing computer makers dell hp see 
model need specify cpds module variables module share cpd 
comparison different cpds required bayesian network representation 
notion module key idea underlying module network formalism 
provide formal definition module network 
assume domain random variables 
xn 
val denote domain values variable described module represents set variables share set parents cpd 
notation represent module formal variable placeholder variables module 
module set set formal variables 
mk variables module share cpd domain values 
represent val set possible values formal variable th module 
module network relative consists components 
defines template probabilistic model module variables assigned module share probabilistic model 
definition module network template defines module set parents pam conditional probability template cpt pam specifies distribution val assignment val pam 
denote dependency structure encoded pam denote parameters required cpts pam 
example modules pam pam msft pam intl 
second component module assignment function assigns variable modules 
mk clearly assign variable module domain 
definition module assignment function function 
val val 
example msft mot intl 
module network defined module network template assignment function 
definition triple module set module network template module assignment function defines directed module graph gm follows nodes gm correspond modules gm contains edge variable say module network module graph gm acyclic 
example module network module graph structure module network defines probabilistic model formal random variables associated cpts templates encode behavior variables assigned module 
specifically define semantics module network unrolling bayesian network variables assigned module share parents conditional probability template assigned definition module network defines ground bayesian network bm follows variable define parents bm pam conditional probability distribution pam specified distribution associated represented bayesian network bm returning example bayesian network ground bayesian network module network 
show semantics module network welldefined need prove ground bayesian network defines coherent probabilistic model 
need show result proposition gm directed acyclic graph dependency graph bm acyclic 
corollary module network bm defines coherent probability distribution see module network provide succinct representation ground bayesian network 
realistic version stock example thousands stocks 
bayesian network domain needs represent thousands cpds 
hand module network represent approximation domain model uses dozen cpds 
bayesian scoring turn task learning module networks data 
training set 
consisting instances drawn independently unknown distribution 
assume set modules wish estimate distribution module network provide complete description module network definition need learn assignment function nodes modules parent structure specified parameters local probability distributions pam 
remainder discussion omit 
take score approach learning module networks 
section define scoring function measures candidate model fits observed data 
adopt bayesian philosophy derive bayesian scoring function similar bayesian score bayesian networks :10.1.1.156.9918
section consider find high scoring model 
likelihood function start examining data likelihood function 
function plays key role parameter estimation task definition structure score 
semantics module network defined ground bayesian network case complete data likelihood decomposes product local likelihood functions variable 
setting additional property variables module share local probabilistic model 
aggregate local likelihoods obtaining decomposition modules 
precisely pam parameters associated cpt pam 
decompose likelihood function product module likelihoods calculated independently depends values pam parameters pam pa pam pam pam learning conditional probability distributions exponential family discrete distribution gaussian distributions local likelihood functions reformulated terms sufficient statistics data 
sufficient statistics summarize relevant aspects data 
similar bayesian networks key difference :10.1.1.112.8434
module network variables module share parameters 
pool data variables calculate statistics pooled data 
precisely sufficient statistic function cpt 
value statistic data set pa 
example case multinomial table cpts sufficient statistic function joint assignment val val pam pa indicator function takes value event pam holds 
statistic data pam sufficient statistics formula module likelihood function pam pam val pam term precisely likelihood bayesian networks 
difference vector sufficient statistics local likelihood term pooled variables corresponding module 
example consider likelihood function module network 
network modules 
consists single variable parent vector statistics statistics variable msft 
second module contains variables sufficient statistics module cpt sum statistics collect ground bayesian network msft msft mot msft intl msft 
intl dell intl intl 
usual decomposition likelihood function allows perform maximum likelihood map parameter estimation efficiently optimizing parameters module separately 
details standard omitted lack space 
priors bayesian score discussed approach learning module networks bayesian score 
specifically define model score pair posterior probability pair integrating possible choices parameters 
define assignment prior structure prior parameter prior 
describe preferences different networks seeing data 
bayes rule term marginal likelihood 
define bayesian score log ignoring normalization constant score log log log main question evaluate score different choices going examine large number alternatives need able efficiently 
case bayesian network learning perform task efficiently priors satisfy certain conditions 
general ideas carry module networks review briefly 
definition assignment structure parameter priors 
satisfies parameter independence pam 
satisfies parameter modularity pam pam structures pa pa satisfies assignment independence 
satisfies structure modularity denotes choice parents module distribution possible parent sets module satisfies assignment modularity choice variables assigned module 
family functions positive reals 
parameter independence parameter modularity structure modularity natural analogues standard assumptions bayesian network learning :10.1.1.156.9918
parameter independence implies product terms parallels decomposition likelihood eq 
prior term local likelihood term parameter modularity states prior parameters module depends choice parents aspects structure 
structure modularity implies prior structure product terms module 
assumptions new module networks 
assignment independence priors parents parameters module independent exact set variables assigned module 
assignment modularity implies prior proportional product local terms corresponding module 
reassignment variable module change preferences assignment variables modules standard conditions bayesian network priors conditions define universally justified easily construct examples want relax 
simplify computations significantly useful rough approximation 
assumptions restrictive allow broad flexibility choice priors 
example encode preference restrictions assignments particular variables specific modules 
addition encode preference particular module sizes 
priors satisfy assumptions definition bayesian score decomposes local module scores score score pam score log log log denotes chose structure parents module denotes shall see decomposition plays crucial rule ability devise efficient learning algorithm searches space module networks high score 
question evaluate integral score 
depends parametric forms cpt form prior 
usually choose priors conjugate parameter distributions 
choice leads closed form analytic formula value integral function sufficient statistics pam pam 
details standard omitted lack space :10.1.1.112.8434
learning algorithm scoring function networks consider find high scoring module network 
problem challenging involves searching combinatorial spaces simultaneously space structures space module assignments 
simplify task iterative approach repeats steps step optimize dependency structure relative current assignment function optimize assignment function relative current dependency structure 
structure search step 
type step iterative algorithm learns structure assuming fixed 
step involves search space dependency structures attempting maximize score defined eq 

problem analogous problem structure learning bayesian networks 
standard heuristic search combinatorial space dependency structures 
define search space state space legal parent structure set operators take state 
traverse space looking high scoring structures search algorithm greedy hill climbing 
cases obvious choice local search operators involves steps adding removing variable parent set pam 
note edge reversal defined operator module networks edge variable module represents relation variable variables module 
operator causes parent added module need verify resulting module graph remains acyclic relative current assignment note step quite efficient tested module graph contains nodes dependency graph ground bayesian network contains nodes usually 
note bayesian networks decomposition score provides considerable computational savings 
updating dependency structure module module score module change changes score induced various operators applied dependency structure applying operator pam need update delta score operators involve module assignment search step 
second type step iteration learns new assignment function data assuming module network structure 
specifically fixed structure want find argmax score 
naively think decompose score variables allowing determine independently optimal assignment variable unfortunately case 
obviously assignments different variables constrained module graph remains acyclic 
example pam pam simultaneously assign subtly bayesian score module depends non additively sufficient statistics variables assigned module 
log likelihood function additive sufficient statistics different variables log marginal likelihood 
compute delta score moving variable module fixed assignment variables modules 
sequential update algorithm variables modules 
idea simple 
start initial assignment function round robin fashion iterate variables time consider changing module assignment 
considering reassignment variable keep assignments variables fixed find optimal legal acyclic assignment relative fixed assignment 
continue reassigning variables single reassignment improve score 
key correctness algorithm sequential nature time variable assignment changes assignment function associated sufficient statistics updated evaluating variable 
change assignment function leads legal assignment improves score 
algorithm terminates longer improve score 
converges local maximum sense single assignment change improve score 
computation score expensive step sequential algorithm 
decomposition score plays key role reducing complexity computation reassigning variable module local score modules changes 
convergence 
algorithm starts initial guess assignment see applies steps described iteratively convergence 
constructed iterative algorithm steps structure update assignment update guaranteed improve score leave unchanged 
theorem iterative module network learning algorithm converges local maximum score 
initialization 
remaining question choose initial module assignment iterative algorithm 
recall need find way group variables initial modules 
ideally initialization put variables behaved similarly different instances 
problem thought clustering problem objects clustered variables module network features behavior different instances original data set 
example stock market example cluster stocks similarity behavior different trading days 
note viewing data perspective learning bayesian network module network instances trading days attributes stocks 
standard clustering procedure come initial clustering 
choose procedure suitable problem evaluates partition variables modules measuring extent module model fit data variables module 
algorithm best thought performing model merging module network specific structure :10.1.1.145.9683
merging values random variables merge modules 
start building module network follows 
introduce dummy variable encodes training instance identity create modules pam note network instance variable local probabilistic model 
consider possible legal module mergers corresponding modules domain change assignment function replace modules new module note merger instance different probabilistic model variables share parameters 
evaluate merger computing score resulting module network 
greedily choose merger leads best scoring network 
procedure merge modules similar different instances 
continue mergers reach module network desired number modules specified original choice learning regression trees briefly review conditional distribution experiments 
domains suited module network models contain continuous valued variables gene expression price changes stock market 
domains conditional probability model represented regression tree 
purposes regression tree defined rooted binary tree node tree leaf interior node 
interior node labeled test variable ir 
interior node outgoing arcs children corresponding outcomes test true false 
tree structure captures local dependency structure conditional distribution 
parameters distributions associated leaf 
implementation leaf associated univariate gaussian distribution values parameterized mean variance learn module networks regression tree cpts extend previous discussion adding component represents trees 
tk associated different modules 
specify components discussion applies small differences 
issues similar encountered introducing decision trees bayesian networks briefly touch :10.1.1.157.3189:10.1.1.29.6166
regression tree pam corresponding sufficient statistics statistics distributions leaves tree 
leaf tree data instance denote leaf reached tree assignment pam 
module likelihood decomposes product terms leaf 
term likelihood gaussian distribution usual sufficient statistics gaussian distribution 
performing structure search module networks regression tree cpts addition choosing parents module choose associated tree structure 
search strategy proposed search operators leaf splits :10.1.1.157.3189
split operator replaces leaf tree internal node test variable branches newly created internal node point new leaves associated gaussian 
operator check acyclicity implicitly adds parent performing search consider splitting possible leaf possible parent value regression tree learning consider real values possible split points suffices consider values arise data set 
experimental results evaluated module network learning procedure synthetic data real data sets gene expression data stock market data 
cases data consisted solely continuous values 
variables domain definition module set reduces simply specification total number modules 
regression trees local probability model modules 
search algorithm beam search lookahead splits evaluate operator 
learning bayesian networks comparison precisely structure learning algorithm simply treating variable module 
synthetic data 
basic test procedure controlled setting synthetic data generated known module network 
gives known ground truth compare learned models 
data realistic generated synthetic data model learned gene expression dataset described 
generating model modules total variables parent module 
learned module network selected variables including parents 
tested algorithm ability reconstruct network different numbers modules procedure run training sets various sizes ranging instances instances repeated times different training sets 
evaluated generalization unseen test data measuring likelihood ascribed learned model unseen instances 
results summarized show training set sizes smallest instances model modules performs best 
expected models learned larger training sets better run correct number modules gain increasing number data instances samples small 
closer examination learned models reveals cases module network 
shown models learned instances modules assigned variables modules 
models achieved high performance 
models learned larger number modules wider spread assignments variables modules consequently achieved poor performance 
evaluated model ability recover correct dependencies 
total number parent child relationships generating model 
model learned report fraction correct relationships contains 
shown procedure recovers true relationships learning dataset size instances 
see variables fragmenting large number modules learned structure contains spurious relationships 
results suggest domains modular structure statistical noise prevent overly detailed learned models bayesian networks extracting commonality different variables shared behavior 
gene expression data 
evaluated performance method real world data set gene expression measurements 
microarray measures activity level mrna expression level thousands genes cell particular condition 
view experiment instance expression level measured gene variable :10.1.1.130.4453
cases coordinated activity group genes controlled small set regulators encoded genes 
activity level regulator gene predict activity genes group 
goal discover modules regulated genes regulators 
expression data measured response yeast different stress conditions 
data consists genes experiments 
domain prior knowledge genes play regulatory role 
subsequently restricted possible parents yeast genes may play role 
selected genes varied significantly data learned module network genes 
learned bayesian network data set 
evaluated generalization ability different models terms log likelihood test data fold performance learning synthetic data function number modules training set size 
cases axis corresponds number modules curve corresponds different number training instances point shows mean standard deviations sampled data sets 
log likelihood instance assigned held data 
fraction variables assigned largest modules 
average percentage correct parent child relationships recovered 
cross validation 
show difference module networks different size baseline bayesian network demonstrating module networks generalize better unseen data choices number modules 
tested biological validity learned module network modules 
selected modules due biological plausibility having average genes module 
examined genes module shared functional characteristics 
annotations genes biological functions saccharomyces genome database 
systematically evaluated module gene set testing significantly enriched annotations 
suppose find genes certain module size check enrichment calculate value numbers probability finding genes annotation random subset genes 
example protein folding module contains genes annotated protein folding genes 
data set genes annotation 
value annotation probability choosing genes category choosing random genes evaluation showed resp 
modules significantly enriched annotation value resp 

furthermore enriched annotations reflect key biological processes expected dataset 
annotations label modules meaningful biological names 
annotations reason dependencies different biological processes module level 
example find cell cycle module regulates module 
cell cycle process cell replicates dna divides known regulate key proteins charge maintaining controlling dna structure 
module regulated cell cycle module nitrogen ncr module cellular response activated nitrogen sources scarce 
find ncr module regulates amino acid metabolism metabolism protein synthesis modules representing nitrogen requiring processes regulated ncr module 
examples demonstrate insights gleaned higher order model obscured unrolled bayesian network genes 
stock market data 
different application examined data set nasdaq stock prices 
collected stock prices companies period covering trading days 
took stock variable instance correspond trading day value variable log ratio day previous day closing stock price 
choice data representation focuses relative changes stock price eliminates magnitude price depends irrelevant factors number outstanding shares 
potential controllers selected stocks average trading volume largest dataset 
gene expression data cross validation generalization ability different models 
see module networks perform significantly better bayesian networks domain 
test quality modules measured enrichment modules network modules annotations representing various sectors stock belongs 
significant enrichment annotations covering wide variety sectors 
compared results clusters stocks obtained applying autoclass data 
described instance corresponds stock described random variables representing trading day 
cases enrichment far significant modules learned module networks compared learned autoclass seen 
looked structure module gene expression stock stock comparison generalization ability module networks learning different numbers modules gene expression stock data sets 
axis denotes number modules 
axis denotes difference log likelihood held data learned module network learned bayesian network averaged folds error bars show standard deviation 
comparison enrichment annotations sectors modules learned module networks clusters applying 
point corresponds annotation axes negative log values enrichment models 
network cases structure fit understanding stock domain 
modules corresponded primarily high tech stocks 
consisting software semi conductor communication broadcasting services main predictors large manufacturer electronic electrical fiber optic interconnection products systems atmel specializing design manufacturing marketing advanced semiconductors 
parent module consisting primarily software semiconductor medical equipment companies module additional parents maxim develop integrated circuits affymetrix designs develops gene microarray chips 
cases parents module similar sectors stocks module 
discussion introduced framework module networks extension bayesian networks includes explicit representation modules subsets variables share statistical model 
bayesian learning framework module networks learns partitioning variables modules dependency structure module 
showed experimental results complex real world data sets including measurements thousands variables domains gene expression stock market 
results show learned module networks higher generalization performance bayesian network learned data 
reasons learned module network better model learned bayesian network 
obviously parameter sharing variables module allows parameter estimated larger sample 
allows learn dependencies considered weak statistics single variables 
known advantages parameter sharing interesting aspect method determine automatically variables shared parameters 
interestingly assumption shared structure significantly restricts space possible dependency structures allowing learn robust models learned classical bayesian network setting 
variables module behave model underlying distribution case empirical distribution finite number samples 
bayesian network learning algorithm treat variable separately optimizing parent set cpd variable independent manner 
high dimensional domains interested bound spurious correlations arise sampling noise inducing algorithm choose parent sets reflect real dependencies generalize unseen data 
conversely module network setting spurious correlation arise possible parent large number variables algorithm find worthwhile introduce dependency 
module networks related framework object oriented bayesian networks oobns framework relational models prms :10.1.1.101.3165:10.1.1.30.3832:10.1.1.38.9253
frameworks extend bayesian networks setting involving multiple related objects allow random variables class share parameters dependency structure 
module network framework view variable object module class variables single module share probabilistic model 
module assignments known advance module networks correspond closely variant frameworks type uncertainty uncertainty class assignment objects 
despite high level similarity module network framework differs certain key points oobns prms significant impact learning task 
oobns objects class internal structure parameterization depend different sets variables specified mapping variables object interface actual inputs 
contrast module network variables module class specific parents 
assumption greatly reduces size complexity hypothesis space leading robust learning algorithm 
hand assumption requires careful making certain steps structure search global effects just variables 
due differences simply apply oobn structure learning algorithm proposed nielsen complex high dimensional domains 
prms probabilistic dependency structure objects class determined relational structure domain cost attribute particular car object depend income attribute object representing particular car owner 
case module networks known relational structure probabilistic dependencies attached 
relational structure prms allow dependency models specified class level 
assert objects class depend aggregate quantity objects 
state dependence particular object class relationship specified model 
getoor attempt address issue class hierarchy approach different requiring fairly complex search steps easily applied types domains considered 
module networks apply broadly prms allow flexible parameter sharing dependency structures domains apply 
important extensions 
obviously addressed issue selecting number modules 
adapt bayesian scoring criteria evaluate standard clustering methods problem evaluating different choices number modules :10.1.1.145.9683
remains done problem proposing new modules initializing 
focused statistical properties method 
companion biological module network learned gene expression data described predict gene regulation relationships 
performed comprehensive evaluation validity biological structures reconstructed method 
analyzing biological databases previous experimental results literature confirmed regulatory relations method automatically inferred correct 
furthermore model provided focused predictions genes previously function 
performed wet lab biological experiments confirmed novel predictions tested 
demonstrated module network model robust learn approximation dependency structure genes samples 
results show learning structured probabilistic representation identify regulation networks gene expression data successfully address problems analysis gene expression data 

anonymous reviewers useful comments previous version 
segal koller friedman supported part nsf aci itr program 
segal supported stanford graduate fellowship 
regev supported colton foundation 
pe er supported fellowship 
friedman supported alon fellowship harry abe sherman senior computer science israeli ministry science 
breiman friedman olshen stone 
classification regression trees 
wadsworth brooks monterey ca 
cheeseman kelly self stutz taylor freeman 
autoclass bayesian classification system 
ml 

cherry ball harris sherlock binkley jin weng botstein 
saccharomyces genome database 
genome www stanford edu saccharomyces 
chickering heckerman meek :10.1.1.157.3189
bayesian approach learning bayesian networks local structure 
uai 

cooper herskovits 
bayesian method induction probabilistic networks data 
mach 
learn 
dean kanazawa 
model reasoning persistence causation 
comp 
intel 

friedman :10.1.1.145.9683
learning dimensionality hidden variables 
uai 

friedman getoor koller pfeffer 
learning probabilistic relational models 
ijcai 

friedman goldszmidt 
learning bayesian networks local structure 
jordan editor learning graphical models pages 
kluwer dordrecht netherlands 
friedman linial nachman pe er :10.1.1.130.4453
bayesian networks analyze expression data 
comp 
bio 
genomic expression program response yeast cells environmental changes 
mol 
bio 
cell 
getoor koller friedman 
instances classes probabilistic relational models 
proc 
icml workshop attribute value relational learning 

heckerman :10.1.1.112.8434
tutorial learning bayesian networks 
jordan ed learning graphical models 

heckerman geiger chickering :10.1.1.156.9918
learning bayesian networks combination knowledge statistical data 
mach 
learn 
koller pfeffer :10.1.1.38.9253
object oriented bayesian networks 
uai 
koller pfeffer 
probabilistic frame systems 
aaai 
lander 
array hope 
nature genetics 
nielsen 
fusion domain knowledge data structural learning object oriented domains 
mach 
learn 
res 
appear 
segal regev pe er botstein koller friedman 
module networks identifying regulatory modules condition specific regulators gene expression data 
nature genetics 
