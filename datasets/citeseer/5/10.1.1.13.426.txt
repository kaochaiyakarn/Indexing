search engine crawler symbiosis gautam pant gautam pant uiowa edu web crawlers nearly decade search engine component create update large collections documents 
typically crawler rest search engine closely integrated 
purpose search engine large collection possible serve general web community close integration may necessary 
search engine caters specific community shared focused interests take advantage integration 
investigate tightly coupled system crawler search engine engage symbiotic relationship 
crawler feeds search engine search engine turn helps crawler better performance 
show symbiosis help system learn community interests serve community better focus 
search engine crawler symbiosis step general model envision truly distributed collaborative search web peers 
categories subject descriptors information storage retrieval content analysis indexing information storage retrieval information search retrieval information storage retrieval systems software performance evaluation general terms algorithms design experimentation human factors measurement keywords community search engine web crawler 
general purpose search engines typically exhaustive crawlers build update large collections documents 
cost crawling indexing collections amortized millions queries received search engines 
large size dynamic nature diversity web warrant focused solutions allow direct indirect collaboration web searchers similar interests 
solutions may scalable distributable effective efficient 
may lead new ways searching hard imagine centralized exhaustive approach followed current search engines 
copyright held author owner 
www may budapest hungary 
acm xxx 
shannon bradshaw shannon bradshaw uiowa edu department management sciences university iowa iowa city ia menczer menczer uiowa edu web communities focused interests professional casual settings 
example set software engineers workplace may focused interests 
surprising queries search engines day narrow topic 
fact small collection web pages say pages may satisfy needs short period time 
non trivial identify small focused collection larger web representative community interests 
important tweak collection time remains focused current interests community 
collection community search engine indexes may able better serve community 
example owing small size collection search engine kept extremely fresh crawling daily weekly basis 
addition sophisticated information retrieval text mining visualization tools may applied efficient effective larger corpus 
system provide collaboration opportunities users 
purpose search engine large collection possible serve general web community close integration crawler components engine may necessary 
main goal crawler keep coverage freshness search engine index high task informed user interactions 
reason crawler rest search engine typically little communication 
search engines may crawlers focus crawl heuristics similar search engine rank documents 
closely integrate crawling algorithm search engine 
believe search engine caters specific community focused interests integration crawler key achieving high efficiency high effectiveness 
discuss particular web searching model topical focused crawler search engine engage mutually beneficial relationship order cater particular community users 
specifically goal incrementally refine collection broad set topics order focus collection set topics relevant community 
flexibility model allows adaptation drifting interests community 
validate model capturing interests specific community reason cater individual user 
model proposed fact step larger peer peer search system bring added opportunities identifying connecting communities users 
se crawler application distribution intelligence protocol web peer peer se crawler web search model application distribution intelligence protocol 
symbiotic model brief overview vision collaborative peer search model order form broader context symbiotic search engine crawler system motivated 
distributed search model web search system layered structure shown 
bottom layer called protocol refers protocol gnutella allow communication peers internet 
intelligence layer messages layers learning signals 
may information learned route messages appropriate peers recommend preferred peers protocol layer 
distribution layer sure messages passed right components application layer 
search engine crawler part application layer 
layer may components text mining data mining tools 
application peer able talk application peer 
peer try optimize local collection web pages user maintain connections peers provide relevant information 
search engine crawler peer tightly coupled learn local queries search engine past 
local queries queries generated peer 
learning process involving search engine crawler symbiosis prepare focused collection may better suited queries near 
process may repeated daily weekly basis 
peer quality search resource topic responding queries peers related expertise observe peers similar expertise 
peers able route queries peers prior interactions 
collaborative search referral process peers ultimately lead emerging topology peer network connections match clusters peers note rest term search engine refer search engine components crawler 
www limewire com developer gnutella protocol pdf new collection foreach query representative queries repeat max iter intersect old seed set seed set theta old seed set seed set seed set search engine query hits new pages crawler query seed set max pages index new pages new collection add new collection new pages clear index index new collection pseudo code symbiotic process search engine crawler communities related expertise 
vision collaborative peer search model motivates long term research project remainder concentrate just symbiotic process crawler search engine single peer capability incrementally refine collection focus topics relevant community users 
symbiosis engine crawler peer live large server desktop machine 
serving single user set users 
local queries serve approximation interests peer user 
may sample queries representative requests 
representative queries capture focused set web documents answering queries near representative query learning opportunity 
topical crawler picks representative query time queries search engine 
search engine responds hits urls satisfy query urls link top urls 
gives crawler seed set urls 
crawler crawls max pages starting seed set representative query guide 
pages crawled query search engine indexes new pages retrieved 
crawler queries search engine representative query steps mentioned repeat 
search engine crawler loop may continue max iter iterations convergence level achieved seed sets consecutive iterations 
new pages iteration added new collection 
iterations repeated representative queries 
current index deleted new collection create new index 
new index search engine answer queries entire process repeats 
idea symbiotic process crawler exploit existing search engine index order obtain focused collection search engine may better satisfy user queries 
note iteration representative query crawler trying get best pages search engine index 
turn search engine helping crawler perform better iterations loop providing better seeds 
pseudocode illustrating symbiotic process shown 
pages max iter theta number representative queries fixed resource availability 
example system runs desktop single user may index pages 
hand systems runs large server users may desirable index millions pages 
fix maximum number pages indexed max index max pages time time new collection search engine crawler queries queries new pages new collection search engine crawler new pages creation new index old derived follows max pages max index representative queries representative queries number representative queries 
parameters max iter theta influenced available disk space lead temporary increase size index new collection ready 
number local queries representative queries may amount time taken iterations single query 
may restrict total time taken representative queries say hours peak hours day 
process shown new collection indexed size equal index 
maintain upper bound size index search engine answer user queries 
way looking process temporal sequence 
pseudo code shown may repeated regular intervals create new collections cater queries 
shows index time process described create new index time 
scale time day week month need index freshness time available maximum size collection max index 

implementation currently search engine crawler symbiosis implemented search engine called rosetta best crawler :10.1.1.1.9422
search engine crawler built specifically application 
independent searching crawling tasks 
want demonstrate symbiotic model picking offthe shelf search engine generic topical crawler 
rosetta architecture describe type indexing retrieval system matter particular approach crawling rosetta search engine particularly suited architecture 
rosetta indexing technique called directed indexing 

technique designed idea topic community web users interested topic find identify evolving body useful information way findings leveraged help informed pages www com 
text immediate vicinity link provides excellent description target page 
comparative analysis identifies terms search engine users queries information provided www com 
find need 
application described demonstrate rosetta leverages knowledge useful information maintained virtual communities provide physical communities people information need 
rosetta uses hyperlinks contexts created basis indexing retrieving documents 
authors introduced variety ways link information search systems rosetta approach novel way uses combined evidence multiple document determine popularity document isolate words best identify popular queries relevant 
example depicted page www com pages include url 
drawing program microsoft windows platform allows easily draw scratch import modify images variety formats 
key feature permits users export figures formats including acceptable inclusion postscript pdf rendered layout editor 
comparative analysis text immediate link www com yields terms frequently document drawing program windows export pdf eps 
com includes description extracted com draw inexpensive vector drawing program creating svg eps illustrations 
intended scientists engineers graphic artists creating technical illustrations 
import ai wmf gif jpeg bmp formats 
export svg eps ps ai pdf wmf gif jpeg bmp tiff formats 
draw export smooth free bitmaps 
web authors tool useful referenced homepage language similar 
doing indicate simply draw useful useful specific set reasons identified terms listed 
drawing program windows platform allows export images pdf eps formats 
different document tend emphasize features document 
result terms naturally overlap 
particular term document quite searchers term queries information document contains 
rosetta indexes document collection incrementally discovers documents pages gathered crawler 
technique voting mechanism uses terms immediate vicinity hyperlink document 
referring page voter permitted vote index term document 
continuing example lists top index terms extracted www com referring pages 
number votes indicates number pages term immediate vicinity link www com 
term votes draw drawing program format illustrations windows pdf eps editing gif 
rosetta uses number votes term measure term frequency weighting metric similar tfidf 
combined evidence multiple contexts document referred extremely accurate identifier index terms document better fact measures word document 
addition inherent model measure relative importance documents indexed terms 
number votes index term receives indicates relative value term association particular document number chosen direct readers document versus 
example query drawing program equally relevant www com pages simple paint program distributed instance microsoft windows 
quick look links pages indicates web users point draw drawing program microsoft paint situation accurate reflection relative utility programs 
popular opinion determine subject documents relative value shown provide significantly useful search results techniques applied collections scientific literature 
aim demonstrate similar performance benefits applying technology web 
term weighting retrieval ranking implementation pertains uses term weighting metric loosely tfidf ranking scheme probably best described ranked boolean rosetta weights index terms document terms individual document weighted heavily provided appear frequently useless discriminators 
rosetta term weighting metric defined nid wid wid importance word index term document nid number times word ni number documents word index term 
term weights calculated metric rosetta ranks search results basis number query terms matched document combination term weights 
equation defining metric follows sd nd wid nd number query words matching index term document set words query wid weight query word index document metric causes documents sorted number query words index terms match sum weights query words index terms document 
theory hyperlinking document web authors describe document language similar type language searcher queries information document contains 
response query rosetta associates importance documents described referrer language contained query 
best crawler best crawler uses cosine similarity page query score urls page 
similarity measure simple term frequency common terms conflated standard stemming algorithm 
crawl frontier unvisited urls kept priority queue score 
time crawler needs fetch page picks best queue 
previous evaluation studies best crawler strong competitor algorithms short crawls pages general crawling tasks :10.1.1.1.9422
multi threaded java infra structure implement algorithm described detail 
crawler number threads share single crawl frontier 
thread picks best url crawl frontier fetches corresponding page scores unvisited urls page add urls frontier appropriate positions 
allow crawler spawn threads maximum size frontier set 
order avoid web server requests frontier enforces constraint batch urls fetched different server host names 
due multi threaded nature crawler enforced ethics crawler follow strict best order 
multiple threads crawler behave best crawler function number threads 
best crawler generalized version best crawler picks best urls crawl time 
best perform especially performance measured recall relevant pages 
set example queries odp category page 
evaluation want investigate search engine crawler symbiosis capturing community interests 
terms search system imagine peer multiple users similar interests 
assume peer serves local community users 
search engine crawler peer try find optimal collection web pages satisfy user queries near 
initial collection search engine may generated bookmark files users doing breadth crawl certain number pages max index retrieved 
community queries portion open directory project odp basis simulation 
particular business ecommerce category simulate community 
category levels deep hierarchy odp topics sufficiently broad enable simulation community people shared interests individual interests 
business commerce root category sub categories external urls 
assume fictitious community interests lie categories selected 
seed urls simulation selected urls random included categories 
bootstrapping search engine real community urls acquired web browser bookmarks members community pool urls listed community resource page kind 
rest refer bookmark urls 
having selected bookmark urls collected pool queries represent inquiries community period week days 
odp editors include brief summary url listed category 
summaries derive phrases simulate user queries 
split summaries tokens set words delimiters keeping tokens words processing 
manually filtered queries remove incoherent groups words representative type errors shallow parsing technique 
process left nearly queries sample listed 
queries obtained form query pool simulation follow 
associated query odp category derived 
knowledge available system provide understanding context query evaluation phase 
simulation dmoz org simulated days search engine crawler system 
initial collection created day breadth crawl retrieved max index pages web starting bookmark urls 
simulate day usage randomly picked queries query pool 
simulated day ran symbiotic process described section queries create new index day 
simulation set pages maximum pages query iteration parameter pages maximum number iterations max iter number top urls seeds iteration hits 
owing small max iter check convergence current simulation 
real world process may run peak hours overnight new index ready morning 
fact implemented system rosetta search engine best crawler takes hours complete process shifting old index new ghz pentium iii ibm thinkpad running windows operating system 
note current rosetta implementation parallelization optimizations ease implementation 
speed process optimization 
performance metrics purpose technology incrementally refine collection broad set topics order focus collection set topics relevant particular community 
test degree system meets objective measured relative performance progressed days simulation 
chose treat system black box measure performance search engine response queries days way user experiences merits system 
judge search engine results hundreds queries days time consuming task 
decided sample daily queries evaluation 
twelve test subjects evaluated queries randomly selected day sample queries evaluation 
test subjects graduate students class information technology awarded extra credit participating study 
asked subjects determine relevance top search results query context query originated 
mentioned earlier context query provided category odp query drawn 
subjects asked browse relevant category order acquire understanding meaning query 
step important real world user submits query search engine specific set circumstances need information 
note search results query different days evaluation going different indexes 
maintained indexes existed days submitted queries sampled day day index 
avoid manual bias evaluation hid information indicated day query originated 
binary relevance assessments obtained subjects computed precision top hits returned search engine query 
average performance measure sample queries day plot mean performance time 
addition black box approach mentioned want evaluate quality collections created crawler 
day days simulation 
error bars subsequent plots correspond standard error 
quantify new collection ability satisfy queries follow 
note precision affected collection quality quality indexing ranking mechanism 
want isolate quality collection created crawler 
gives idea performance crawler 
way measure new collection quality calculating average cosine similarity pages collection representation centroid queries submitted corresponding day 
represent day queries simply concatenate 
note collection created queries submitted system see 
measure average cosine similarity collection queries follows vq vp vq vp collection pages particular day concatenated query text day vq vp tfidf vector representations concatenated queries page respectively vq vp inner product vectors euclidean norm vector results results study measure search engine performance days simulation metric defined section 
depicts values judged test subjects averaged queries day 
initial collection system retrieved approximately relevant documents top search results average 
performance dropped slightly second third days simulation 
reason speculate initially system may overfit collection set queries day possibly day 
seen type behavior systems learn interests users 
evaluation suggests initial decline performance improves level greater initial collection 
statistical significance preliminary result allow definitive confirmation experiments required extensive evaluations queries longer period time 
significant terms result stronger may appear system achieves level cost day ratio precision cost gathering maintaining collection day simulation day relevance collection queries submitted days 
collection third smaller collection day simulation 
size collection decreases approximately pages day approximately pages fifth day 
due crawler focused result interaction search engine 
specifically crawler explores regions web near search results query finds urls encountered crawls queries 
store url collection redundancy information gathered day results reduction size collection 
may negatively affect generalization performance initial phase symbiotic process cf affords significant efficiency gains terms saved disk space crawling indexing time bandwidth 
quantify gain look ratio average precision relative size collection cost 
cost collection equal size collection divided max index pages 
plot indicates perfomance cost perspective symbiotic system lead substantial benefits 
measured cosine similarity collection day queries day 
plots ratio day 
time performance queries occurred day 
crawler help search engine able fetch pages lexically similar queries day 
error bars plot extremely small clearly visible 
find significant improvement collection quality simulation period 
analysis queries appeared manually evaluated set queries 
plotted metric repeating queries days appeared 
noticed queries value improved time 
particular queries result time appeared subsequent system relevant results 
average system relevant results repeating queries time submitted system 

purpose symbiotic system describe incrementally refine broad collection order bring focus set topics relevant particular community 
experimentation needed strong claims benefits users demonstrates short amount time type symbiotic system developed eliminate irrelevant information initial collection achieve desired focus 
important note system learns behavior users implicitly requiring effort type simple searches doing 
supports theory individual interests may vary common ground community creates environment inquiries member community helpful satisfying information needs 
demonstrated convergence system performance level just better performance day collection thirds size 
demonstrated system improved performance queries occurred day particularly improvement queries initially relevant search results 
related large size dynamic nature web prompted different efforts build focused search engines 
attempt build focused search engine peer approach adaptive changing interests user 
furthermore tightly couples search engine crawler general applied topic 
idea distributing search process achieve scalable search model new 
harvest project probably earliest attempt direction model ultimately successful due requirement strong coordination effort 
topical crawlers motivated part arguing moving part crawling effort closer user may improve quality searches causing significant increase network traffic 
collaborative peer search model partly inspired highlighted mediation referral lead emergent communities peer networks 
referential text identify semantic similarity pages new 
addition idea example find web sites categorize pages crawl pages rank crawled pages 
despite active referential text variety information retrieval tasks demonstrated effectiveness technique generalpurpose search 
large growing body topical focused crawlers 
starting early breadth depth crawlers defining beginnings research crawlers see variety crawler algorithms 
shark search aggressive variant de bra fish search 
crawlers decisions rely heavily link criteria 
exploit lexical conceptual knowledge provided topic hierarchy 
emphasize contextual knowledge topic including received relevance feedback 
relates collaborative filtering queries submitted users help preparing collection similar queries users 
queries collaborate users studied past 
obvious extension integrate crawler engine 
example crawler bfs strategy tfidf similarity just tf 
generic crawler luxury idf index collection available 
model collection indexed engine previous iteration crawler current iteration generate idf weights improve link scores 
merit exploiting inherent structure html page document object model dom tree restricted crawling tasks 
investigate dom tree derive context link search engine crawler 
addition crawler tap global information available search engine hubs multiple contexts 
larger project aims discover serve communities interactions search system 
peer specializes topics peers put help users discover information related variety interests 

acknowledgments builds earlier search engine design topical crawler design evaluation acknowledge contributions collaborators kristian hammond rik belew srinivasan earlier projects 
go students volunteered help evaluation phase open directory project making data publicly available 
funded part nsf career 
iis fm 

aggarwal yu 
intelligent crawling world wide web arbitrary predicates 
www hong kong may 
amitay 
common hypertext links identify best phrasal description target web documents 
proceedings sigir post conference workshop hypertext information retrieval web 
arasu cho garcia molina paepcke raghavan 
searching web 
acm transactions internet technology 
attardi gull sebastiani 
categorization context 
proc 
th international world wide web conference 
shoham 
content collaborative recommendation 
communications acm 
cm bowman pb danzig manber mf schwartz 
scalable internet resource discovery research problems approaches 
communications acm 
bradshaw hammond 
automatically indexing documents content vs 
sixth international conference intelligent user interfaces san francisco ca january 
bradshaw scheinkman hammond 
guiding people information providing interface digital library basis indexing 
fourth international conference intelligent user interfaces new orleans la january 
shannon bradshaw 
directed indexing indexing scientific literature context 
phd thesis northwestern university 
brin page 
anatomy large scale hypertextual web search engine 
computer networks 
chakrabarti 
mining web discovering knowledge hypertext data 
morgan kaufmann san francisco 
chakrabarti dom raghavan rajagopalan gibson kleinberg 
automatic resource compilation analyzing hyperlink structure associated text 
computer networks 
chakrabarti van den berg dom 
focused crawling new approach topic specific web resource discovery 
computer networks 
chau chen qin zhou qin sung mcdonald 
comparison approaches building vertical search tool case study nanotechnology domain 
proceeding second acm ieee cs joint conference digital libraries 
cho garcia molina page 
efficient crawling url ordering 
computer networks 
craswell hawking robertson 
effective site finding link anchor information 
proc 
th annual intl 
acm sigir conf 
research development information retrieval 
bd davison 
topical locality web 
proc 
rd international acm sigir conference research development information retrieval pages 
de bra post 
information retrieval world wide web making client searching feasible 
proc 
st international world wide web conference 
diligenti coetzee lawrence giles gori 
focused crawling context graphs 
proc 
th international conference large databases vldb pages cairo egypt 
giles bollacker lawrence 
citeseer automatic citation indexing system 
proceedings third acm conference digital libraries 
glance 
community search assistant 
proceedings th international conference intelligent user interfaces 
haveliwala 
efficient computation pagerank 
technical report stanford database group 
th haveliwala gionis klein indyk 
evaluating strategies similarity search web 
david dave de roure arun iyengar editors proc 
th international world wide web conference 
acm press 
maarek pelleg ur 
shark search algorithm application tailored web site mapping 
www 
kantor melamed neu 
capturing human intelligence net 
communications acm 
lashkari metral maes 
collaborative interface agents 
media lab technical report mit 
mccallum nigam rennie seymore 
automating construction internet portals machine learning 
information retrieval 
menczer belew 
adaptive retrieval agents internalizing local context scaling web 
machine learning 
menczer pant ruiz srinivasan 
evaluating topic driven web crawlers 
proc 
th annual intl 
acm sigir conf 
research development information retrieval 
menczer pant srinivasan 
topic driven crawlers machine learning issues 
acm toit submitted 
dollar biz uiowa edu fil papers toit pdf 
menczer street monge jakobsson 
intellishopper proactive personal private shopping assistant 
proc 
st acm int 
joint conf 
autonomous agents multiagent systems aamas 
pant menczer 
topical crawling business intelligence 
www 
submitted 
pant srinivasan menczer 
exploration versus exploitation topic driven crawlers 
www workshop web dynamics 
pinkerton 
finding people want experiences webcrawler 
proc 
st international world wide web conference 
porter 
algorithm suffix stripping 
program 
salton wong yang 
vector space model automatic indexing 
communications acm 
mp singh yu venkatraman 
community service location 
communications acm 
srinivasan menczer pant 
general evaluation framework topical crawlers 
ieee trans 
knowledge data engineering submitted 
dollar biz uiowa edu fil papers tkde pdf 
