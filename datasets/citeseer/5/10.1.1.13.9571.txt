search strategies ensemble feature selection medical diagnostics cunningham department computer science trinity college dublin ireland mails cs tcd cunningham cs tcd department computer science information systems university jyv skyl jyv skyl finland mails cs fi cs fi goal propose evaluate compare search strategies ensemble feature selection consider application medical diagnostics focus problem classification acute abdominal pain 
ensembles learnt models constitute main current directions machine learning data mining 
ensembles allow get higher accuracy sensitivity specificity achievable single models 
technique proved effective ensemble construction feature selection 
lately strategies ensemble feature selection proposed including random hill climbing search genetic search 
propose new sequential search strategies ensemble feature selection evaluate constructing ensembles simple bayesian classifiers problem acute abdominal pain classification 
compare search strategies regard achieved accuracy sensitivity specificity average number features select 

current electronic data repositories especially medical domains contain enormous amounts data 
data includes currently unknown potentially interesting patterns relations uncovered knowledge discovery data mining methods 
methods successfully applied number medical domains localization primary tumor recurrence breast cancer diagnosis thyroid diseases rheumatology 
popular method creating accurate classifier set training data train different classifiers combine predictions 
ensemble accurate single classifiers ensemble 
theoretical empirical research demonstrated ensemble base classifiers ensemble accurate tend err different parts input space high diversity predictions 
efficient way construct ensemble diverse classifiers different feature subsets 
important issue creating effective ensemble choice function combining predictions base classifiers 
shown increasing coverage ensemble diversity ensure increased prediction accuracy integration method utilize coverage benefit arises integrating multiple models 
effective approach generating ensemble accurate diverse base classifiers ensemble feature selection :10.1.1.44.7302
varying feature subsets generate base classifiers possible promote diversity produce base classifiers tend err different subareas instance space 
traditional feature selection algorithms goal finding best feature subset relevant learning task selected inductive learning algorithm task ensemble feature selection additional goal finding set feature subsets promote disagreement base classifiers :10.1.1.44.7302
feature selection algorithms including ensemble feature selection typically composed components search strategy searches space feature subsets fitness function inputs feature subset outputs numeric evaluation :10.1.1.17.626
search strategy goal maximize function 
technique building ensembles simple bayesian classifiers random subspaces 
considered hill climbing refinement cycle improved accuracy diversity base classifiers built random feature subsets 
considered application technique problem acute abdominal pain classification 
main fitness function guiding search ensemble feature selection accuracy diversity important degree importance differs different data sets 
focus search strategy ensemble feature selection fitness function 
develop new strategies addition known strategies include random hill climbing search genetic search 
new strategies sequential greedy search time consuming genetic search hill climbing 
section general issues ensemble simple bayesian classifiers ensemble feature selection considered 
section search strategies ensemble feature selection section experiments discussed 
conclude briefly section summary research topics 

feature selection ensembles simple bayesian classifiers ensemble classifiers created training data build base classifiers applied combination derive final classification 
effective ensemble consist high accuracy classifiers disagree predictions 
ensembles generated comprise simple bayesian classifiers separately formed training set account features corresponding selected feature subset 
ho shown simple random selection feature subsets may effective technique ensemble feature selection lack accuracy ensemble members compensated diversity 
random base number ensemble feature selection strategies gefs hc :10.1.1.44.7302
measure disagreement base classifier ensemble calculate diversity base classifier instances validation set average difference classifications possible pairs classifiers including 
research feature subset calculate goodness measure fitness function proposed opitz :10.1.1.44.7302
fitness classifier corresponding feature subset proportional classification accuracy diversity classifier fitness acc div coefficient degree influence diversity 
class distribution uneven accuracy replaced average sensitivity specificity research 
major approaches applied forming method integration ensembles ys combination approach base classifiers produce classifications final result composed selection approach classifiers selected final result result produced 
approaches static dynamic methods 
contrast static methods integration procedure dynamic methods depends instance processed 
experiments different integration methods cross validation majority static selection approach ss weighted voting wv static combination approach dynamic selection ds dynamic selection approach dynamic voting dv dynamic combination approach dynamic voting selection dvs dynamic hybrid approach 
dynamic approaches local accuracy estimates obtained weighted nearest neighbor prediction 

search strategies feature subset selection ensembles section consider different search strategies ensemble feature selection hill climbing hc genetic ensemble feature selection gefs ensemble forward sequential selection efss ensemble backward sequential selection ebss 
hill climbing search local search wrapper approach shown effective single feature subset selection 
hill climbing hc ensemble feature selection strategy research proposed composed major phases construction initial ensemble random subspaces iterative refinement ensemble members sequential mutation hill climbing 
initial feature subsets constructed random subspace method 
initial ensemble formed 
iterative refinement ensemble members improve accuracy diversity base classifiers 
iterative refinement hillclimbing search 
feature subsets attempt switch include delete feature 
resulting feature subset produces better performance validation set change kept 
process continued improvements possible 
genetic search important direction feature selection research 
genetic algorithms shown effective global optimization techniques feature subset selection 
genetic algorithms ensemble feature selection proposed :10.1.1.44.7302
genetic ensemble feature selection gefs strategy begins hc creating initial population classifiers classifier generated randomly selecting different subset features :10.1.1.44.7302
new candidate classifiers continually produced genetic operators crossover mutation feature subsets 
number generations fittest individuals population comprises ensemble :10.1.1.44.7302
implementation representation individual feature subset simply constant length string bits bit corresponds particular feature 
crossover operator uses uniform crossover feature children takes randomly value parents 
feature subsets individuals current population chosen proportional fitness 
mutation operator randomly toggles percentage bits individual 
propose new ensemble feature selection strategies efss ebss 
sequential feature selection strategies add subtract features hill climbing procedure polynomial complexity 
frequently studied variants plain sequential feature selections algorithms select single feature subset forward backward sequential selection fss bss 
fss begins zero attributes evaluates feature subsets exactly feature selects best performance 
adds subset feature yields best performance subsets larger size 
cycle repeats improvement obtained extending current subset 
bss begins features repeatedly removes feature removal yields maximal performance improvement 
efss ebss iteratively apply fss bss form base classifiers predefined fitness function 
efss ebss polynomial complexity regard number features number base classifiers total number features number features included deleted average fss bss search 
hc similar polynomial complexity passes passes average number passes feature subsets hc improvement usually 
complexity gefs depend number features gen number individuals feature subsets generation gen number generations 

experiments experiments conducted large data sets cases acute abdominal pain aap small aap medium aap ii large aap iii numbers instances respectively 
data sets represent problem separating acute diseases cause acute abdominal pain 
data set includes features history clinical examination 
data set sake performance comparison division training test sets 
reduced training data sets approximate ratio instances classified half classified diagnoses 
additionally percent instances original training sets transferred validation sets random sampling 
test runs train validation splits original training sets algorithms 
experimented different values diversity coefficient 
size ensemble selected equal 
run algorithm collected accuracies types integration classifiers ss wv ds dv dvs 
dynamic integration methods number nearest neighbors local accuracy estimates pre selected set values data set 
classification accuracies base classifiers ensemble corresponding sensitivity specificity values collected characteristics total ensemble diversity ensemble coverage average relative number features base classifiers 
characteristics averaged runs 
test environment implemented mlc framework machine learning library 
simple bayesian classifier numeric features discretized equal length intervals observed value whichever 
parameter settings genetic search gefs include mutation rate proposed population size search length feature subsets offsprings current population classifiers generated crossover operator mutated offsprings :10.1.1.44.7302
generation individuals produced pilot experiments shown creating generations increase performance decreases probably due overfitting training data 
table experimental results search strategies data sets 
table includes name data set best selected average sensitivity specificity integration methods ss wv ds dv dvs search strategies hc gefs efss ebss average sensitivity specificity simple bayes feature set bayes average relative number features selected feat improvement final ensemble comparison random subspace ensemble regard average sensitivity specificity impr 
best results search strategy italic type data set bold type 
table 
results search strategies data set strategy ss wv ds dv dvs bayes feat impr small aap medium aap ii large aap iii hc gefs efss ebss hc gefs efss ebss hc gefs efss ebss table see data sets ensembles perform significantly better single global simple bayes 
data sets aap aap iii best integration technique dvs data set aap ii best integration technique ds give significantly better results single simple bayes statistical significance checked tailed student test level significance 
interesting finding best search strategy efss data set 
average sensitivity specificity cases rivals best previously published results data sets 
performance efss explained fact efss able generate classifiers better diversity starting zero feature subsets comparison ebss strategies 
efss generates extremely compact base classifiers including features average features 
dynamic integration general better static integration data sets better utilizing diversity base classifiers supporting results 
selected values different different search strategies means ensemble diversity important shown degree importance depends search strategy data set 

considered search strategies ensemble feature selection new sequential search strategies efss ebss 
conducted number experiments collection data sets medical field acute 
cases ensembles simple bayesian classifiers higher performance single global simple bayesian classifier 
best search strategy efss generating diverse ensembles compact base classifiers 
average sensitivity specificity efss best previously published results 
proposed search algorithms useful medical domains especially including features complex dependencies 
research interesting consider search strategies beam search simulated annealing try find better configuration gefs results genetic search disappointing improved generations 
interesting topic research check findings data sets different characteristics 
acknowledgments science foundation ireland financial support 
research partly supported graduate school university jyv skyl finland 
machine learning library source code study 
acute abdominal pain aap data sets kindly provided laboratory system design faculty electrical engineering computer science university slovenia theoretical surgery unit department general trauma surgery heinrich heine university germany 

aha bankert comparative evaluation sequential feature selection algorithms fisher lenz eds proc 
th int 
workshop artificial intelligence statistics pp 

bauer kohavi empirical comparison voting classification algorithms bagging boosting variants machine learning vol 
nos 
pp 

cunningham carney diversity versus quality classification ensembles feature selection dem plaza eds proc 
ecml th european conf 
machine learning barcelona spain lncs springer pp 

dietterich ensemble learning methods arbib ed handbook brain theory neural networks nd ed mit press 
fayyad piatetsky shapiro smyth uthurusamy advances knowledge discovery data mining aaai mit press 
ho random subspace method constructing decision forests ieee transactions pattern analysis machine intelligence vol 
pp 

kohavi sommerfield dougherty data mining mlc machine learning library tools artificial intelligence ieee cs press pp 

kohavi wrappers performance enhancement oblivious decision graphs dept computer science stanford university stanford usa phd thesis 
opitz feature selection ensembles proc :10.1.1.44.7302
th national conf 
artificial intelligence aaai pp 

dynamic integration algorithm ensemble classifiers ras eds foundations intelligent systems ismis lnai vol 
springer pp 

ensemble feature selection simple bayesian classification medical diagnostics proc 
th ieee symp 
computer medical systems cbms slovenia ieee cs press pp 

patterson feature selection ensembles simple bayesian classifiers foundations intelligent systems ismis lnai vol 
springer pp 


comparison databases decision tree approach medical field acute patel 
eds proc 
th world congress health medical informatics medinfo vol london uk ios press pp 

