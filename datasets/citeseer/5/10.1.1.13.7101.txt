efficient probabilistic top left corner brian roark mark johnson cognitive linguistic sciences box brown university providence ri usa brian roark brown edu mj cs 
brown edu examines efficient predictive broad coverage parsing dynamic program ming 
contrast bottom methods depth top parsing produces partial parses fully connected trees spanning entire left context kind non local dependency partial semantic inter principle read 
con trast predictive parsing approaches top left corner parsing find viable 
addition find enhance ment non local information im proves parser accuracy substantially improves search efficiency 
strong empirical evidence past years indicating hu man sentence processing mechanism line contextual information ing discourse crain steedman alt mann steedman visual environment tanenhaus 
results lend support mark steedman intuition sentence interpretation takes place incrementally partial built sentence perceived 
commonly held view today 
possible models human sentence pro cessing consistent view general assumption un explicit relationships tween lexical items sentence spec ified incrementally 
processing mecha material supported national science foundation 
sbr 
nism stands marked contrast dynamic pro gramming parsers delay construction constituent sub constituents completed partial parses consist disconnected tree fragments 
ex ample parsers integrate main verb tree structure subject np vp completely parsed cases final step entire parsing process 
explicit line inte difficult sible produce partial interpretations line 
similarly may difficult non local statistical dependencies subject main verb actively guide parsers 
predictive parser dynamic programming maintains fully con nected trees spanning entire left context explicit relationships constituents required partial interpretation 
parser uses probabilistic best pars ing methods pursue analy ses beam search avoid non termination problems typical non statistical top predictive parsers 
main results 
ap proach works appropriate attention specific algorithmic details surprisingly efficient 
second just accuracy efficiency improves language model accurate 
fu ture research non local lexical semantic information guide parser 
addition show improvement accuracy associated left corner parsing top attributable non local information supplied strategy obtained methods utilize information 
parser architecture parser proceeds incrementally left right item look ahead 
nodes expanded standard top left right fashion 
parser utilizes tic context free grammar pcfg induced standard relative frequency estimation corpus parse trees ii look ahead prob abilities described 
multiple ing partial parses analyses held priority queue call pending heap 
ranked merit fom discussed 
analysis stack nodes ex history probability fom 
highest ranked analysis popped pending heap category top stack expanded 
category ex rule eventually reach look ahead terminal 
rule expansion new analysis created pushed back pending heap 
fom analysis product probabilities pcfg rules deriva tion call look ahead probabil ity lap 
lap approximates product probabilities rules re quired link analysis current state look ahead terminal 
grammar stack state 
look ahead terminal item lap pg 
cn wa recursively estimate ically observed conditional probabilities ev ery non terminal ci stack ci ci 
lap approximation stack state look ahead terminal pg ci 
ca ci topmost stack category analy sis matches look ahead terminal termi nal popped stack analysis count parser state rule expansion considered measure efficiency 
non lexicalized grammar tak ing pre terminal pos markers terminal items 
pushed second priority queue call success heap 
analyses success heap remaining pending heap discarded 
success heap pending heap look ahead moved forward item input string 
input string reached analysis highest probability empty stack returned parse 
parse error returned 
specifics beam search dictate analyses success heap constitute 
approach set constant beam width analyses suc cess heap point parser moves item input 
problem approach parses bottom success heap may relative top little chance parse day causing wasted effort 
approach dynamically vary beam width stipulating factor say proceed best analysis pend ing heap fom times probability best analysis success heap 
number anal fall range creating nearly large processing burden approach 
compromise approaches stipulated base beam factor usually ac tual beam factor number analyses success heap 
small beam stays relatively wide include analyses possible grows beam narrows 
simple successful compromise 
course left recursive grammar top parser may terminate 
analysis success heap defines beam search top depth search left recursive grammar terminate 
avoid place upper bound number analyses allowed pushed pend ing heap 
bound exceeded parse fails 
left corner strategy prey left recursion upper bound necessary 
np np dt jj jj nn dt np dt dt jj jj cat jj np dt jj dt jj happy fat jj nn fat happy cat np np dt np dt dt np dt tle jj np dt jj jj np dt jj fiat jj np dt jj jj fat jj np dt jj jj happy nn happy nn np dt jj jj nn cat cat trees left lb right binary rb right unary rb right binarized rb grammar transforms nijholt characterized parsing strategies terms announce points point parent category announced identified rel ative children point rule expanding parent identified 
pure top parsing parent category rule expanding announced children 
pure bottom parsing identified children 
gram mar transforms method changing announce points 
top parsing appropriately grammar pax ent identified rule expanding parent children 
left corner parsers announce parent category ex rule leftmost child completed children 
delaying rule identification binarization suppose category top stack np determiner dt look ahead 
situation information distinguish rules np dt jj nn dt jj nns 
decision delayed time relevant pre terminal look ahead parser formed decision 
grammar way allowing parser rule np dt np dt new non terminal np dt expand follows dt np 
expansion np dt occurs pre terminal look ahead 
delay essential efficient implementation kind incremental parser proposing 
axe ways grammar binary better parser 
distinction drawn call left lb versus right rb see 
leftmost items righthand side rule grouped rightmost items righthand side rule grouped gether 
notice top left right parser rb appropriate transform cause right siblings 
lb top parser identify siblings reaching leftmost item aid purposes 
rb transforms variation respect long rule specification maintained 
method final underspecified category rewrite binary rule rb see lb 
final underspecified category rewrite unary rule rb lc 
final underspecified category rewrite rule rb ld 
tice original motivation rb delay specification relevant items look ahead served rb second child specified look ahead 
rb pushes look ahead item string constituent expanded ful deciding rules unequal length np dt nn np dt nn nn 
table summarizes trials binarization rules percent avg 
states avg 
labelled avg 
mlp ratio avg 
grammar sentences considered precision labelled prob avg 
parsed recall prec rec mlp prob lb rb beam factor length sentences avg 
length tof sentences parsed table effect different approaches binarization ing effect different binarization ap proaches parser performance 
gram mars induced sections penn wall st journal treebank marcus tested section 
transform tested tree training cor pus transformed grammar tion resulting transformed pcfg look ahead probabilities estimated standard way 
parse returned parser de transformed evaluation 
parser trial identical base beam factor 
performance evaluated measures percentage didate sentences parse coverage ii average number states rule expansions considered candidate sentence efficiency iii average la precision recall sentences parse accuracy 
grammars exhaustive bottom cky parser ascertain accuracy probability maximum parse mlp 
additionally compare parser performance mlp sentences 
expected left binarization conferred benefit parser 
right binarization con trast improved performance board 
rb provided substantial improvement cov erage accuracy rb decrease efficiency 
efficiency hit partly attributable fact tree nodes rb 
effi ciency improvement right binarization standard grammar interesting light great increase size grammars 
see johnson details transform de transform paradigm 
worth noting point rb grammar parser viable broad coverage statistical parser coverage accuracy efficiency 
considered left corner parsing strategy 
left corner parsing left corner lc parsing rosenkrantz lewis ii known strategy uses bottom evidence left corner rule top prediction rest rule 
rosenkrantz lewis showed transform context free gram mar grammar top parser follows search path lc parser 
lc grammars allow exactly predictive parser evaluate top versus lc parsing 
naturally lc grammar performs best parser right binarized reasons outlined 
transform composition apply transform output 
denote 
applying left corner transform resulting gram mar lc rb 
probabilistic lc parser investigated manning carpenter lc parsing architecture trans formed grammar got performance boost efficient bottom statistical parser de tailed charniak 
measured efficiency terms total edges popped 
edge case parser state considered probability calcu lated felt better efficiency measure simply popped 
baseline parser considered average edges sentence section wsj corpus 
lc transform involves nullary pro rb needed nullary pro need introduced source 
binarization left corner unary rb 
transform rules pct 
avg 
states avg labelled avg 
mlp ratio avg 
grammar sentences considered precision labelled prob avg 
parsed recall prec rec mlp prob left corner lc lb lc lc rb lc rb ann rb lc beam factor length sentences avg 
length tof sentences parsed right binarization 
equivalent rb lc differ ent grammar lc rb 
bi orientations lb rb possible compositions binarization lc transforms lb lc rb lc lc lb lc rb table shows left corner results various conditions 
interestingly options encode information leading nearly identical performance 
stated right binarization moves rule announce point children 
lc transform lc rb delays parent identification 
transform lc rb ann moves parent announce point back left corner introducing unary rules left corner simply identify parent binarized rule 
allows test effect position parent announce point performance parser 
see ef fect slight similar performance measures 
rb lc performs higher accuracy exhaustive parser require massive beam order approach performance mlp level 
manning carpenter beam width parses success heap input item resulted order magnitude rule expansions considering option appropriate kind binarization parser argued previous section omitted 
difference due vacuous unary rules rb 
table left corner results average labelled precision recall fell mlp accuracy grammar 
investigating grammar func tions poorly incremental parser 
non local annotation johnson discusses improvement pcfg models annotation non local formation non terminal nodes trees training corpus 
simple example copy parent node non terminal rule np vp np vp idea distribution rules expansion particular non terminal may differ depending non terminal parent 
shown additional information improves mlp accuracy dramatically 
looked kinds non local infor mation annotation parent pa left corner lca 
left corner parsing gives improved accu racy top bottom parsing grammar 

reason may ancestor category exerts kind non local influence parser parent category parent annotation 
test annotated left corner ancestor category leftmost non terminal cat 
results annotation trials shown table 
important points notice results 
pa get previously reported improvement accuracy additionally fairly dramatic decrease number parser states vis find parse 
non local formation improves final product parse guides parser quickly transform rules pct 
avg 
states avg labelled avg 
mlp ratio avg 
grammar sentences considered precision labelled prob avg 
parsed recall prec rec mlp prob rb pa rb lc rb lca rb pa lc rb beam factor length sentences avg 
length tof sentences parsed final product 
annotated grammar times rules slow bottom cky parser proportionally 
parser considers far fewer states en route accurate parse 
second lc annotation gives nearly accuracy gain left corner parsing support hypothesis ancestor information responsible observed accuracy im provement 
result suggests determine information anno troublesome rb lc transform may able get accuracy improve ment relatively narrow beam 
parent annotation lc transform gave best performance states considered average excellent accuracy non lexicalized grammar 
accuracy efficiency tradeoff point deserves accuracy efficiency tradeoff regards base beam factor 
re sults far func tions pretty transforms investigated 
figures show formance measures transforms base beam factors 
dramatically increasing effi ciency burden beam widens vary ing degrees payoff 
top trans forms rb pa rb ratio av erage probability mlp probability improve substantially beam grows marginal improvements coverage accuracy 
increasing beam left corner transforms 
rest noise 
table non local annotation results research examined probabilistic predic tive parser variations shown ap proach general viable terms quality parses ef 
shown improvement grammars non local information results better parses guides parser efficiently contrast dynamic programming methods 
shown accuracy improvement demonstrated left corner approaches attributed non local information method 
relevant study human sentence processing mechanism insofar demonstrates possible model explicit syntactic relationships items input incrementally scaling broad coverage 
research include lexicalization parser utilization fully connected trees ad ditional syntactic semantic processing syntactic predictions beam language modeling examination predictive parsing left branching language german addition may interest psy community introduce time variable model compare competing sentence processing models race competition parsing 
altmann steedman 

interac tion context human sentence pro cessing 
cognition 
lo average states considered sentence rb 
lc rb pa rb 
pa lc rb base beam factor percentage sentences parsed 
rb lc rb pao rb 

base beam factor changes performance beam factor variation 

interaction referential ambiguity argument structure 
journal memory language 
charniak johnson 

edge best chart parsing 
proceedings sixth workshop large corpora pages 
crain steedman 

ing led garden path con text psychological parser 
dowty karttunen editors natu ral language parsing 
cambridge university press cambridge uk 
johnson 

pcfg models linguistic tree representations 
computational linguis tics 
manning carpenter 

prob parsing left corner language models 
proceedings fifth interna tional workshop parsing technologies 
average labelled precision recall 
rr rb 
lc rb pao rb pa lc rb base beam factor average ratio parse probability maximum likelihood probability rb 
lc rb pao rb 
base beam factor changes performance beam factor variation marcus santorini marcinkiewicz 

building large annotated corpus english penn treebank 
computational linguistics 
nijholt 

context tee grammars cov ers normal forms parsing 
springer verlag berlin 
rosenkrantz lewis ii 

de left corner parsing 
ieee con ference record th annual symposium switching automata pages 
steedman 

grammar tion processing lexicon 
marslen wilson editor lexical represen tation process 
mit press cambridge ma 
tanenhaus spivey knowlton hard 

integration vi linguistic information spoken language comprehension 
science 
