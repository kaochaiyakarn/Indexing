performance address space multiplexing pentium uhlig uwe andreas heiser presents analysis performance potential limitation called small space scheme logical address spaces securely multiplexed single hardware address space 
achieved ia architecture segment registers relocate address spaces transparently applications 
results show scheme provide significant performance improvements cases processes small working sets interact frequently case client server applications particularly microkernel systems 
investigate potentially costly revocation mappings prevented clustering communicating processes 
gap processor memory speed continues widen modern architectures 
result dependence system performance high hit rates cpu caches increasing 
computer architects achieve high hit rates increasing cache capacity increasing depth cache hierarchy 
large cache implies significant probability finding part cache hot context switch possibility reducing indirect context switch costs resulting cold cache 
potential exists switching lehrstuhl universit karlsruhe contact ka org threads belonging address space 
exists switching processes provided architecture supports secure sharing caches different address spaces 
similarly critical performance translation look aside buffer tlb cache address translations 
tlb implies cost dozen cycles assuming hardware loaded tlb cache hit page table 
indirect context switching costs reduced tlb shared contexts 
modern architectures support sharing cpu caches tlbs address spaces usually tagging tlb entries address space identifier physically tagged caches 
case ia architecture presently dominates pc low server markets 
architecture tlbs virtually tagged cpu caches flushed switch operation costly processors implies significant indirect costs resulting subsequent cache tlb misses 
imposes performance limits applications high context switching rates client server type applications microkernel systems 
liedtke shown pentium segment registers simulate results showing context switching costs reduced times favorable conditions 
presents thorough investigation performance potential small address space approach wide range application scenarios benefits expected 
scenarios generally characterized high context switching rates moderate working sets 
examine ways reduce potentially high revocation costs associated promotion processes allocated small space 
section explains address space multiplexing detail examines best case benefits 
section presents setup experiments results section 
section discusses limitations scheme overcome 
related section section 
address space multiplexing describing small address space approach detail give overview cache memory management architecture ia processors 
significant differences processor generations concentrate latest pentium 
pentium memory architecture pentium chip physically tagged data cache cache 
instruction cache cache features virtual trace cache stores instructions pre translated microcode pentium core 
virtually tagged trace cache flushed address space switch 
caches physically tagged require flushing 
ia virtual memory architecture uses combination segmentation paging 
bit virtual address translated bit linear address usually implicitly specified segment register 
translated physical address level page table shown 
page size kb page directory map mb super page pointing page table 
hardware caches seg architecture allows turning page translation virtual address segmentation paging page directory segment register dir 
tab 

page table base limit linear address physical address virtual space desc 
table seg 
desc 
linear space physical space segmentation paging ia 
ment descriptor page table lookups separate instruction data tlbs called itlb dtlb 
tlb tagging architectures featuring tagged tlbs essentially extend virtual address process tag 
combination virtual page number translated physical frame number processors 
basic idea small space approach reduce application usable part virtual address bits segment registers simulate bits shown 
completely transparent application size usable address space 
applying case linear address physical address 
provides alternative level page table format kb mb pages 
pid vaddr vaddr tlb tag vaddr vaddr tlb tag tagging tlb entries hardware supported emulated 
system small large processes 
trick suitable address spaces ensure processes requiring full size address space able run 
specifically pentium processor gb address space split regions large space area say gb small space area remainder hardware address space 
small space area split number regions hold small address space 
process run small address space assigned small space number identifying small space regions 
segmentation registers relocate process address space region 
large process relocated access large space area 
number small processes limited number small space regions 
time address spaces large itlb entries itlb repl 
cycles dtlb entries dtlb repl 
cycles associativity full lru repl 
way table tlb configuration replacement costs ghz pentium processor small processes visible hardware shown 
tlb large process usual handled hardware walking page table 
initial small space generates fault handled kernel copying appropriate page directory entry small process appropriate relocated entry current page table 
addition global bit set small space tlb entries prevent flushed switching large processes 
result context switch small processes large small process change hardware addressing context require tlb cache flushes 
flushing required switching large processes affect tlb entries small processes 
analysis costs savings context switch potential savings resulting small spaces scheme determined knowledge characteristics architecture summarized table 
various contributions costs follows 
direct costs flushing tlbs trace cache fully eliminated suitable process switch 
savings amount cycles cost executing reload cr instruction changes page table flushes trace cache tlbs 
tlb replacement costs 
depend tlb working set switched process kept alive execution processes 
processor fully associative tlbs pentium total tlb size minus combined tlb working sets processes running switched process executing 
sensitive composition process mix 
upper limit cost savings tlb size times cost reload single entry cycles itlb cycles dtlb ghz pentium 
assumes page table lookups hit cache reasonable assumption scenario savings relatively high 
trace cache replacement costs 
cost reloading trace cache difficult measure estimate order cycles 
frequent branch mispredictions add 
context switch costs cost associated scheme reloading segment registers cycles 
savings maximum savings context switch particularly high small space scheme produce significant savings conditions high context switching rates 
typically appear client server scenarios particularly workload reasonably evenly balanced client server 
includes scenarios client acts server third party applications cooperate pipelined fashion 
high context switching rates ability keep caches warm context switches critical seeing significant effect 
means total page working set kernel applications order tlb size 
page working set small average saving context switch small 
big hot entries remain order benefit 
making qualitative statements effects seen difficult estimate amount savings expected reallife scenarios 
performed quantitative study potential interesting cases 
experimental test bed microkernel test bed experiments 
reason choice easier implement mechanism small kernel compared large system linux 
experiments required modifications low level components page table handling context switching require api changes control assignment small space regions processes easier perform 
second equally important reason microkernel systems particularly sensitive context switching costs systems components run separate processes called multi server systems 
ran experiments linux port linux kernel 
address space multiplexing version ka portable re implementation liedtke original assembler kernel 
ka written optional assembly implementation critical components delivery ipc messages 
spite written higherlevel language ka outperforms original assembly kernel ipc implementation pentium iii pentium systems 
small space mechanism implemented ka follows 
process including small ones associated normal way hardware address space means process page table 
kernel hardware address space dispatching thread small process 
modifies segment descriptors address space memory accesses go small space re allocated small process 
described section process address space populated lazily copying level page table entries process page table current page table large process 
thread accesses memory size region automatically promoted large space 
small spaces completely transparent performance user level applications 
kernel configured small space area gb balance gb hardware address space available large processes 
small space regions differ size minimum mb mb depending configured size small space area 
default link address linux application programs ia just mb size mb small spaces experiment avoid having relink linux applications 
linux linux single server system linux kernel runs single user level process top possibly side side microkernel applications real time components 
binary compatible normal linux kernel ia ia linux distribution 
linux applications execute separate address spaces top linux server 
applications communicate server dedicated shared page mapped address space applications server 
order achieve binary compatibility native linux linux system calls cause exception mirrored microkernel emulation library 
code mapped linux server application address space 
emulation library stores system call parameters communication page sends linux system call request ipc linux server 
linux server decodes request executes linux system call stores results shared communication page 
sends ipc back application reads system call results respective registers resumes execution system call instruction 
linux system call ipcs required 
cross address space ipc performance crucial linux performance 
ipc performance ia dominated hardware costs switching kernel mode back 
actual ipc path kernel accounts cycles instructions entering leaving kernel add cycles 
addition context switching costs discussed section 
obviously linux performance suffers extremely high context switch cost 
simple system call getpid line code linux kernel causes complete invalidation dtlb itlb trace cache pentium system 
small address spaces costs reduced kernel entry exits compared monolithic linux segment register reloads basically costs round trip ipc costs cycles plus additional costs dispatching system call linux server 
difference cycles linux system call depending application size 
considering mentioned costs obvious candidate put small space linux server 
linux runs global pages multiple address space switches result systematic tlb invalidations reduction tlb misses expected approach native linux system small amount additional tlb misses uses page mapping thread control blocks thread linux application 
furthermore communication page linux application needs mapped linux application consuming pages application 
client server application scenario consume extra dtlb entries linux compared native linux dtlb capacity 
plus extra processing cost ipc slightly increased cache misses costs resulting running linux user level 
cycles large space small space trace cache working set bytes trace cache cycles large space small space tlb working set pages instruction tlb cycles large space small space tlb working set pages data tlb execution time ipc round trip averaged executions function trace cache tlb working sets 
linux applications modified linux support applications running small spaces 
required minor changes memory layout linux applications 
precisely modifications 
limited application initial virtual address space size allocating stack mb 

changed start mapping area mmap shared libraries gb mb 
course limiting large applications databases actual mapping address easily configured application basis 
encountered case necessary don tend run large databases 

linux systems emulation library pages located outside valid application address space address xa order provide usable application address space gb 
needed relocated inside size 
chose region normally linux applications 
modified mmap deny explicit maps memory region 
having implemented changes linux applications able execute unmodified 
results obtained described 
experiments results ping pong order establish upper limits performance benefits small spaces benchmark high context switching rates adjustable working sets 
simple ping pong application normally benchmark ipc performance systematically filled tlbs trace cache 
performed ping pong ipc sending empty message thread different address space receiving empty response 
proceeded accessing previously accessed cache entries 
partner thread perform operation reply 
generated synthetic loads different caches follows trace cache continuous execution nop instructions 
instruction byte long 
tlb relative jump bytes 
jump instruction bytes long 
tlb byte read access bytes 
reason offsets page granularities tlb measurements avoid evictions second level cache due self interference 
ping pong results show expected growing trace cache working set ipc cost grows slower small spaces culminating fold difference execution time point trace cache reaches capacity nops corresponding trace cache size kb 
trace cache exhausted large small spaces perform identically 
dramatic trace cache working set measurements dependency itlb working set size small spaces performing times faster large spaces point tlb capacity exhausted 
contrast trace cache case small space scenario performance advantage large working sets 
results fact kernel ipc code trace cache survives execution smaller process 
dtlb working set similar effect dramatic case itlb 
execution times twice fast small spaces significantly lower working set sizes 
linux vs linux performance linux thoroughly analyzed 
result significant performance difference linux linux micro benchmarks factor case getpid slowdown lmbench hbench mhz pentium 
basic system calls worst case scenario linux best case scenario small space approach 
measured performance penalty system calls linux native linux difference linux server running large small space 
seen results table overhead running linux server dramatically reduced putting server small space 
native linux system call linux large small getpid gettimeofday read write table comparison cost cycles normalized small space costs parentheses selected linux system calls native linux linux executing small large space pentium ghz 
linux client linux server large spaces 
server linux client small spaces 
pipe communication linux system applications running large versus small spaces 
client server pipe client server environment monolithic operating system linux communication pipes unix sockets ip sockets 
repeated ping pong experiment linux system pipe communicate client server task 
performed experiment linux system linux server running small space 
measured pipe performance application processes running large small address spaces 
indicated results hardware context switches packet label case zero 
shows comparison setups different working set sizes corresponding communication costs cycles 
results show behavior large vs small spaces seen 
remarkably linux system small space outperforms native linux test long trace cache itlb capacity exceeded 
clear indication native linux stands benefit small spaces 
cat wc typical pipe real life unix application piped large file wc utility counts words text 
text delivered multiple chained cats 
measured cycles number tlb misses mb file large small space configurations 
number itlb misses reduced number dtlb misses 
total execution time shorter small spaces 
obviously cat wc tiny applications savings accounted reduced number dtlb misses 
perf ran perf performance test program server 
application reasons stresses communication linux tasks server demonstrates benefits small spaces part system believe user sensitive gui 
perf exercises set drawing primitives windows system protocol dots rectangles circles different line styles text rendering bitmap copies measures performance operations 
experiment linux server server ran small space 
ignoring ordinary preemptive scheduling hardware address space switches required 
measured total execution times cycles different perf operations 
surprise performance improve quite limited number tested functions especially functions accessing video memory 
large small operation space space improvement dot table comparison cycles object multiple operations tested perf 
large setup linux running small space 
small setup server executing small space 
multiple objects may drawn time 
account finding large tlb footprint server bundling multiple drawing functions request 
conclude break object basis lead significant performance difference 
table gives average cycles ratio server executing large versus small space 
general see performance benefit drawing functions 
web server fastcgi web serving active content classical tier application scenario 
remote client requests web page active content web server responds cache forwards request server database 
web database servers run node results local communication unix sockets 
depending working set sizes may beneficial run web server database server small address spaces 
analysis configured apache fastcgi support 
fastcgi high performance language independent cgi extension unix sockets local tcp ip sockets remote communication 
implemented small hello world fastcgi server 
server benchmarked running small large address spaces 
requests received network machine 
running standard linux system setup re cycles native large space small space tlb working set pages instruction tlb cycles native large space small space tlb working set pages data tlb cycles native large space small space trace cache working set bytes trace cache performance comparison pipe client server communication running monolithic linux linux 
sults full context switches fastcgi request apache fastcgi apache 
small spaces expected see measurable decrease tlb cache misses 
handle incoming request apache linux generate dtlb itlb replacements 
obviously far capacity tlbs see performance improvement running fastcgi server small address space 
hand result indicative significant performance problems apache server 
experiment replaced apache small efficient web server thttpd 
thttpd single threaded server supporting file serving cgi 
extended thttpd experimental fastcgi interface repeated measurements 
thttpd working set significantly smaller apache leading expected performance improvement results 
benchmark measures processing time point time request received thttpd full reply generated sent back client 
compares processing times requests fastcgi running small large spaces different working set sizes 
average gain com thttpd fifth largest number installations worldwide 
performance improvement running fastcgi server small address space 
mysql considering memory requirements large database servers sound prime candidates executing small spaces 
large applications databases benefit small spaces serving local clients thin run small spaces servers 
benefits small spaces depends working set needed handle database requests 
evaluate potential performance gains realm database servers measured execution times number small select queries database served mysql popular relatively light weight open source database server numerous heavily loaded web server setups globe 
measurements set mysql server run single threaded mode 
done avoid expensive operation forking separate worker processes database request causing invalidation tlbs virtually tagged caches 
performance suffer running single thread server experiment needed handle simultaneous re cycles large space small space tlb working set pages instruction tlb cycles large space small space tlb working set pages data tlb processing time thttpd fastcgi request different fastcgi server tlb working set sizes 
black lines show minimum number cycles seen best case gray lines show average 
quests 
believe server running modern operating system better distributing load cheap intra threads anyway 
experiments show gain mysql small spaces environment 
simple queries gained performance increase small spaces 
complex queries completely dominated execution time mysql server large working set impact performance numbers 
light weight database servers smaller working set common queries able benefit small spaces 
representative class applications games chose version shoot em game doom originally released id software 
interactive setups higher update rate displayed information result increased acceptance user 
frame rate render player view screen reasonable measure application performance 
experiments replayed previously recorded session file minutes level benchmark mode sound output disabled 
mode recorded session rendered fast possible achieved frame rate reported 
additionally counted number itlb misses dtlb misses cycles trace cache spent building micro ops instructions fetched cycles trace cache spent deliver micro ops order execution core 
shows normalized numbers executing server small space compared large space 
running server small space see dramatic reduction itlb misses 
instructions executed remained number cycles trace cache spent delivering micro ops core inverse execution time 
reduction number cycles trace cache spent building micro ops shows increased hit rate trace cache turn causes itlb misses 
number dtlb misses reduced little 
confirms data working set server far dtlb capacity 
conclude small space approach impact trace cache itlb re frame rate itlb misses dtlb misses trace build trace deliver large small comparison performance measurements running server large small space 
numbers normalized executing large space 
sults higher frame rate 
friends prominent macro benchmark compilation programs linux kernel source tree 
gcc compile source file ka measured execution time dtlb misses itlb misses different system configurations 
second measured values configurations complete build ka clean 
system configurations linux small space linux linux tasks small spaces linux tasks small spaces linux large space 
ka source tree consisted header files kb files kb assembler files kb 
files held file cache avoiding disk accesses 
results reproducible surprising satisfying measure reduction itlb dtlb misses configurations compared configuration 
execution time remained compile 
working set measured jobs simply large compile tlb misses tlb misses draw benefits small space approach 
differences configurations negligible 
multi server operating system running top 
linux kernel decomposed separate orthogonal services 
services protected running servers separate address spaces 
operating system extremely stresses ipc performance context switching overhead remotely invoking functions system servers 
evaluated performance impact small spaces running tcp ip stack driver network interface card nic separate address spaces 
ping packet sent machine round trip time interrupt arrived network driver icmp reply packet enqueued network card measured 
handling single ping packet requires full context switch driver intra space context switch bottom half handler thread driver address space full context switch ip stack full context switch back driver 
full context switches involving tlb trace cache invalidation saved small spaces 
large small spaces spaces improvement cycles dtlb misses itlb misses table execution times tlb misses handling ping packet nic driver tcp ip stack 
table summarizes measurements 
see data tlb misses instruction tlb misses saved running nic driver tcp ip stack servers small spaces 
savings trace cache savings results performance improvement 
summary measurements performed linux running small space top allow estimate benefits small spaces native linux system having implement scheme linux 
explained section running linux server small space eliminating microkernel overhead completely eliminates practically address space switching overheads resulting running linux user level 
relative performance differences applications running small large address spaces summarize table indication expected benefits small spaces native linux system 
table shows zero 
application improvement linux client server pipe cat wc perf apache fastcgi thttpd fastcgi mysql doom gcc table average execution time improvements small address spaces large address spaces 
limitations described section small address spaces implemented manner completely transparent applications 
achieved automatically transferring small space larger accessed memory outside limited address space 
application small space system aware fact application limited virtual memory region take appropriate steps sure stays bounds 
notably stack space longer located upper part virtual memory area typically just gb dynamically loaded libraries located fit limited virtual space 
fortunately adjustments done transparently application dynamic linker operating system 
application binary usually linked relatively high virtual address typically just mb upwards relinking binary necessary application run truly small space 
revocation pressing issue limited number available system virtual memory area dedicated small spaces 
recalling running unmodified linux applications requires mb virtual memory gb address space shared large space small spaces apparent number system vastly insufficient 
mechanism recycling devised 
unfortunately recycling extremely costly 
requires existing preempted revoked application 
revoking expensive fact page table entries lazily copied hardware address space system implies affected page table entries small space area purged single existing page table 
considering possible number existing tasks page tables evident operation performed frequently 
tremendous cost preempting sensible scheduling policy paramount performance system 
finding policy hard 
system spend un alternatively lazy purging page table entries possible 
scheme dramatically increase worst case switching time threads particular result unacceptably high worst case interrupt latencies 
necessary cycles doing preemption scheduling algorithm choose inappropriate revocation nature applications running small spaces tend aggravate cost preemption 
application running small space respond quickly request applications system suffer heavily increased latency 
performance reason running application small space place 
far able come reasonable scheduling policy decreases recycling frequency level suitable deployment real system 
section describes exists solutions solving preemption problem 
application groups observing number small preemption deemed expensive performed frequently conclude recycling impractical limited number small space tasks supported 
looking applications benefit executing small spaces client server applications realizes tend communicate limited group applications 
example seen different pipeline stages compilation cpp cc communicate 
likewise web server dynamic content communicate linux certain servers fastcgi servers 
communication tasks group usually task issues system call releases blocked task sending signal providing data empty pipeline 
context switches usually occur different tasks group 
operating system performs scheduling decision task explicitly communicates task outside group infrequent operations task outside group scheduled 
applications grouped gcc cpp cc sh sh gcc cpp cc sh sh gcc cpp cc sh sh cmd pid compiling source files linux kernel tree 
switches happens clockwise fashion 
line width indicates number times certain switch occurs width logarithmic function number switches 
relationships switches groups require preemption 
longer recycled groups 
recycling cheap group restricted single hardware address space need purge hardware spaces system 
simple switch hardware address space sufficient 
having ability group applications simple optimization implemented observing tasks linux server communicate tasks system member application groups 
implemented help global pages pages tlb entries affected tlb flushes 
having global small space tasks operate global pages tlb working set flushed switching application groups 
illustrates system multiple groups single task global groups 
httpd linux server httpd linux tasks communicate linux server 
shows communicate small groups 
related small spaces originally proposed liedtke indicative data ipc performance small spaces 
results obtained kernel modified specifically benchmark report date complete implementation small spaces performed 
small spaces apparently implemented eros performance figures available 
basic idea multiplexing large hardware address space smaller ones restricted ia segmented architectures 
degree hardware support necessary securely 
hardware support available strongarm processor 
features pid register sole purpose relocate small address space transparently application 
utilized windows ce example 
windows ce provide full protection address spaces 
arm domains provide full protection small spaces strongarm general multiplexing hardware address space processes 
performance data available time 
strongarm system application groups global small space task virtual cache addition virtual icache untagged tlbs hardware support small spaces direct costly pentium expect performance benefits small spaces higher architecture ia 
investigated performance potential limitations idea securely transparently multiplexing small logical address spaces single hardware address space 
implemented scheme microkernel linux execution environment 
results show benefits small spaces pronounced microkernel systems linux performance improved 
cases significant performance improvements evident explained working sets exceeding tlb capacity 
client server applications running linux long feature high context switching rates small working sets benefit order extreme cases 
cases linux small spaces outperforms native linux 
conclude results support small spaces beneficial native linux 
main limitation scheme poten tially high revocation cost processes allocated small spaces 
shown cost avoided appropriate grouping communicating processes 
implementation scheme remains done 
availability ka kernel including support small spaces available ka org 
mark brown 
fastcgi high performance gateway interface 
programming web search apis 
paul dubois 
mysql 
new riders december 
alain trent jaeger park jochen liedtke kevin uhlig jonathon luke lars 
approach 
th sigops european workshop denmark september 
hermann michael jochen liedtke sebastian sch jean wolter 
performance microkernel systems 
th acm symposium operating system principles sosp france october 
intel 
intel strongarm sa microprocessor developer manual 
jochen liedtke 
improving ipc kernel design 
th acm symposium operating system principles sosp asheville nc december 
jochen liedtke 
improved address space switching pentium processors transparently multiplexing user address spaces 
technical report gmd german national research center information technology november 
jochen liedtke 
kernel construction 
th acm symposium operating system principles sosp copper mountain resort december 
john murray 
inside 
microsoft press september 
robert scheifler 
rfc window system protocol version alpha update april june 
status unknown 
david seal editor 
arm architecture manual 
addison wesley nd edition 
jonathan shapiro jonathan smith david farber 
eros fast capability system 
th acm symposium operating systems principles december 
adam wiggins heiser 
fast switching strongarm sa processor 
th australasian computer architecture conference pages canberra australia january 
ieee cs press 
