exploiting probabilistic hierarchical model generation previous stochastic approaches generation include tree representation syntax 
may adequate advantageous applications ap plications profit syntactic knowledge available leaving tic model issues deter mined grammar 
initial re suits showing tree model derived tree annotated corpus improves tree model derived unannotated corpus tree stochastic model hand crafted grammar 
apt natural language gen eration nlg range linguistic expres sions generated quite restricted grammar tbr generation spec ified hand 
ma cases important deviate certain linguis tic standards generation case hand crafted grammars give excellent control 
applications tbr nlg variety output bigger demands quality output somewhat gent 
typical example nlg con text interlingua machine translation 
reason reb xing quality output may time available develop grammar tbr new target language nlg 
cases stochastic empiricist methods pro vide alternative hand crafted rational ist approaches nlg 
knowledge stochastic techniques nlg langkilde knight 
fergus flexible em generation syntax 
srinivas bangalore owen rambow labs research park avenue florham park nj rambow research art 
com follows langkilde knight seminal gram language model augment tree stochastic model traditional tree syntactic grammar 
aspects stochastic gen eration include langkilde knight malouf ratnaparkhi 
describe detail stochastic models nlg recall basic tasks nlg rainbow re iter 
text planning content structure target text determined achieve communicative goal 
dur ing sentence planning linguistic means particular lexical syntactic means de convey smaller pieces meaning 
realization specification chosen sentence planning surface string line words sentence typically adding function words 
langkilde knight ignores text planning stage address sentence planning tion stages 
structure 
section underlying ical lexicalized tree adjoining gram mar ltag 
section describe ar chitecture system mod ules 
section discuss experiments 
section langkilde knight 
conclude summary going 
modeling syntax order model syntax existing wide coverage grammar english xtag grammar developed university xtag 
xtag tree adjoining grammar tag joshi 

trees derivation aux ni ji cost estimate second phase supertags training corpus ill xq ag gr um lm derive th 
wa st stim tc fi second phase dotted lines show le ti ms tag elementary structures structure trees ot er tions sut ion ts tree fl mtd ins rts tree mi ll im 
hi rei ll lo tes ion take lac dow arrows 
ic uses tag asso ial lexical item anchor tree typically trees lexical ire result obtain lexi tag ltag 
ea lexi item associated tree just phrase ture rule tbr exa nl le cm st oth re argument struc ture lexeme nodes arguments sut syntactic constraints sut je verb agree men sl ure associated lexeme 
property tag domain locality 
ltag distinction en lexicon grammar 
le grammar shown 
depart fl om xtag treatment rees tbr adjuncts stead 
xtag elementary tree ad sl ru ure hat atta hes ll tes tree anchored ux pro lj direction np right right vp right np vp ft right right table tbr frag sl label say vp specified di say left trees adjuncts simply express active va connect lexical item modi ion kept adjunct table associated 
grammar excerpt shown 
trees hat adjoin trees entries adjunct table re called gamma trees trees substituted trees alpha trees 
note refer tree combi nation name called supertag anchor 
example supertag ha tree anchored noun projects np lie ag gamma tree anchored noun assume adjectives adjoined adjunction table shows right adjoin estimate particular tree ltag grammar 
tree su associated rep resents predicative noun nouns associated nominal supertags cq 
derive sentence ltag combine elementary trees fl om adjunction substitution 
pie derive sentence cost estimate second phase gram mar substitute tree tbr tree tbr estimate 
adjoin trees tbr auxiliary determiner ing noun cost 
note adjunctions occur different nodes vp np respectively 
adjoin preposition substitute ph ase adjoin second 
note adjunctions gamma trees sub alpha trees 
want represent derivation cally derivation tree obtain follows adjoin sub tree tree add new daughter labeled node labeled tg 
explained name tree lexeme supertag 
omit address substitution adjunction takes place 
derivation tree br deriva tion shown 
seen structure dependency tree resembles representation lexical argument structure 
claims tag properties particularly suited syntactic rep resentation tbr generation 
specifically ex tended domain locality genera tion tbr localizing syntactic properties includ ing word order agreement morphological processes lexicalization useful tbr providing seman tics tion tree represent sentence predicate argument structure 
ltag extensively generation start ing mcdonald pustejovsky 
sentences peter doctor analyzed head usual doctor head done xtag really behaves auxiliary verb 
estimate cost phase second derivation tree tbr ltag tion cost estimate second phase system overview fergus composed modules ee chooser linear dence lp chooser 
input system dependency tree shown 
note nodes labeled lexemes supertags 
tree chooser uses stochastic tree model choose tag trees fbr nodes input structure 
step seen analogous supertag ging bangalore joshi supertags names trees tbr words tree tbr words linear sequence 
uses xtag grammar produce lattice possible linearizations arc compatible tree xtag 
lp chooser chooses traversal lattice language model 
dis components detail 
tree chooser draws tree model representation xtag derivation tbr words wall street journal 
chooser simplifying system experiments de scribed section words including words need tt representation 
course unrealistic applications 
aim show ee model improves performance stochastic generator 
see section discussion 
constructed penn ls ee bank ing heuristics bank contain hill head dependent result heuristics tree model correct 
estimate cost phase gus second tions tree 
tbr node dei ends daughter nodes allow ing tot dynamic algo ril hln 
st node si ru ture assigned sui rt th tt rol fin ling rod dl rs ini ut sl ure ha oml tit le mother tll sut sin 
omt hat tree ret ed adjoined tree ret resented ling xtag gra 
le en ini ui ree shown ul fi om ee tree 
ts shown 

le tion tree tag fully sl derivation mte lmt fl om ee chooser 
reasons 
exi laine section fin trees ing adjuncts rest ect adjunction site aat ion direction left fl right tree mother node re ad ts tbr ex adjective ordering 
secondly sul ert ags nl hose ly ill takes input derivation tree ml ro duces word lattice 
node tion tree lexi item su 
linear order rs rest cot td ion sut st ag 
informa tion order laughter nodes tag tree ut lcc scl tree specified ag nd ar hii ture fergus head le vel ion tree 
cases daughter node ll thin lie head sul se le disjunction positions 
assigned node 
algorithm constructs lattice ell odes strings rei re sented level th 
derivation tr 

root tr result um 
fhe resulting 
ml nce shown 
ti 
veh en codes word sequences derivation 

word es order hoo composing lattice finite state machine rel bmgu ge tel 
mo ee words dl journal 
est path lattice re algorithm ranking word sequence ut lp chooser 
experiments results order show ll tl lhe tl ce doe hell pe pe experiments word lattice tbr example sentence tree chooser supertag model baseline experiment impose random tree structure ibr sentence build tree model parameters consist lexeme precedes mother lexeme lm 
call baseline left right lr model 
model generates estimate phase second cost example input 
second experiment derive tbr lr model fl om notated corpus particular xtag derivation tree 
model gener ates th crc estimate second phase cost tbr example input 
third experiment described section employ supertag tree model parameters consist lexeme supertag sd zt dependent im supertag sin 
fm thermore supertag provided xtag grammar der dependents 
model generates cost estimate second phase tbr example input sentence wsj 
case machine translation evalu ation generation complex issue 
metrics suggested mt literature string edit distance generation system corpus string front wsj 
metrics simple accuracy generation accuracy allow evaluate human intervention automatically objectively 
simple accuracy insertion deletion substitutions errors target language strings test corpus strings produced genera tion model 
metric summarized equa tion 
number tokens target string 
metric similar string dis tance metric measuring speech recog nition accuracy 
address issue metrics comparative evaluation genera tion systems 
tree le go ner average time model ac ura accuracy baseline lr model ms derived li 
model ms sut model ms performance results front tree models 
sl recognition task gener ation involves reordering tokens 
simple accuracy metric penalizes mist token twice deletion ct posi tion insertion different 
wc second metric generation ura shown tion treats ion token tt location string md th insertion tok location tim string single mov mt 
addition rem insertions deletions dl 
ge racy lc ur tim av ag time ti cst tim tin xl xl le 
test set consist xl ws mt ml age words 
seen tim sut mo rot lr model derived data md models improv baseline lr mod sul te richer st oh mid tion types 
cxt performance bas model features 
ongoing vc developed tree metrics addition string order sto gener tion models 
vc attempted correlate quantitative metrics human mts 
ado tail dis experiments results bangalore 
comparison langkilde knight knight hand maps semantic represen tations sequences words constraints 
lex semantic st ted lattice mid mode hell lo surface strings moo led 
system knight nitrogen similar fergus generation di vided phases results lattice fl om si ring chosen cond language model case trigram model nitrogen case ml 
ih ver nr quit mt fei gus si lex pr dit st ru ur ni mantic 
gus nt ro maps mti rc ro mtal ion ore syn ta ti inl ut focus sc ch 
ther imt orl differ es 
ed ni maps dir semantics linear sentation skipping tho nr mt rci rc sentation usually tbr rod ion syntax 
stochastic tree model re tr trees 
fei gus tied arc ma tc stochastically tim tree rcl ce chooser 
allows capture stochastically certain long ance ts sct ration ts collocations pet form ad john pet formed long somewhat te quite frustrating hi border 
second tim hand cd gram ln tr fell crafted fl om xl gent rat ion rcl rcs english syntax 
handle morphological ef agreement gen eral clone gram model time descriptively straightforward handled non stochastic generation modules 
outlook empirical evidence ing tree model addition language model improve stochastic nlg 
fergus ready module applications 
specifically add morphological compo nent component handles words auxiliaries determiners component handles 
cases provide knowledge tic components aim comparing behaviors type back tbr type 
explore fi ous applied language tbr limited xtag grammar available example ying basic sentence word order sw svo speci ying subject verb agreement 
long run intend fei ous flexible system hand crafted knowledge possible stochastic models necessary 
alshawi srinivas bangalore douglas 

automatic acquisition hi transduction models tbr machine tr 
proceedings th annual meeting association computational lin montreal canada 
srinivas bangalore aravind joshi 

supertagging approach pars ing 
computational linguistics 
bangalore owen rainbow steve whittaker 

metrics generation 
proceedings international cor natural language generation ramon 

aravind joshi 

tree adjoining grammars 
editor mathematics language pages 
john benjamins amsterdam 
aravind joshi 

relevance tree adjoining grammar generation 
gerard editor natural language generation new results artificial psychology linguistics pages 
kluwer academic publishers dor boston lancaster 
irene langkilde kevin knight 

gen eration exploits corpus statistical knowledge 
th meeting associa tion computational linguistics th international cor computational linguistics coling cl pages canada 
irene langkilde kevin knight 

practical value grams genera tion 
proceedings ninth interna tional natural language generation shop inlg niagara lake 
irene langkilde kevin knight 

forest statistical sentence generation 
proceedings north american cl seattle usa may robert malouf 

methods tbr re order english 

david james 

gs grammatical formalism tbr generation 
rd meeting associa tion computational linguistics cl pages chicago il 
owen 

ap plied text generation 
third conference applied natural language processing pages italy 
adwait 

trainable methods surface natural language generation 
proceedings north american acl seattle usa may ehud reiter 

consensus nl gen eration architecture appeared psy plausible 
proceedings th international workshop natural language generation pages maine 
xtag group 

lexicalized ee adjoining grammar english 
technical report rw 
cis 
upenn edu xtag tech report tech report research cognitive science uni versity pennsylvania 
