segmenting time series survey novel approach eamonn keogh chu david hart michael pazzani department information computer science university california irvine california usa eamonn pazzani ics uci edu years explosion interest mining time series databases 
computer science problems representation data key efficient effective solutions 
commonly representations piecewise linear approximation 
representation various researchers support clustering classification indexing association rule mining time series data 
variety algorithms proposed obtain representation algorithms having independently rediscovered times 
undertake extensive review empirical comparison proposed techniques 
show algorithms fatal flaws data mining perspective 
introduce novel algorithm empirically show superior literature 

years explosion interest mining time series databases 
computer science problems representation data key efficient effective solutions 
high level representations time series proposed including fourier transforms wavelets symbolic mappings piecewise linear representation plr :10.1.1.42.3240:10.1.1.40.4034:10.1.1.45.9405
confine attention plr frequently representation :10.1.1.42.1358
intuitively piecewise linear representation refers approximation time series length straight lines 
contains examples 
typically smaller representation storage transmission computation data efficient 
specifically context data mining piecewise linear representation support fast exact similarly search 
support novel distance measures time series including fuzzy queries weighted queries multiresolution queries dynamic time warping relevance feedback :10.1.1.42.1358
support concurrent mining text time series 
support novel clustering classification algorithms 
support change point detection 
time series piecewise linear representation 
space shuttle telemetry 
ecg 
surprisingly spite ubiquity representation exception little attempt understand compare algorithms produce 
appear consensus call algorithm 
clarity refer types algorithm input time series return piecewise linear representation segmentation algorithms 
segmentation problem framed ways 
time series produce best representation segments 
time series produce best representation maximum error segment exceed user specified threshold max error 
time series produce best representation combined error segments user specified threshold total max error 
shall see sections algorithms support specifications 
segmentation algorithms classified batch online 
important distinction data mining problems inherently dynamic 
data mining researchers needed produce piecewise linear approximation typically independently rediscovered algorithm approach suggested related literature 
example fields cartography computer graphics 
review major segmentation approaches literature provide extensive empirical evaluation heterogeneous collection datasets finance medicine manufacturing science 
major result experiments online algorithm literature produces poor approximations data algorithm consistently produces high quality results scales linearly size data batch algorithm 
results motivated introduce new online algorithm scales linearly size data set online produces high quality approximations 
rest organized follows 
section provide extensive review algorithms literature 
explain basic approaches various modifications extensions data miners 
section provide detailed empirical comparison algorithms 
show popular algorithms data miners fact produce poor approximations data 
results motivate need new algorithm introduce validate section 
section offers directions 

background related section describe major approaches time series segmentation detail 
algorithms dimensional analogues ironically better understood 
discussion higher dimensional cases scope 
refer interested reader contains excellent survey 
appearing different names slightly different implementation details time series segmentation algorithms grouped categories 
sliding windows segment grown exceeds error bound 
process repeats data point included newly approximated segment 
top time series recursively partitioned stopping criteria met 
bottom starting finest possible approximation segments merged stopping criteria met 
table contains notation 
time series form tn subsection ta ta tb seg ts piecewise linear approximation time series length segments 
individual segments addressed seg ts 
create segment function takes time series returns linear segment approximation 
calculate error function takes time series returns approximation error linear segment approximation 
table notation going approximate time series straight lines ways find approximating line 
linear interpolation approximating line subsequence simply line connecting ta tb 
obtained constant time 
linear regression approximating line subsequence taken best fitting line squares sense 
obtained time linear length segment 
techniques illustrated 
linear interpolation tends closely align endpoint consecutive segments giving piecewise approximation smooth look 
contrast piecewise linear regression produce disjointed look datasets 
aesthetic superiority linear interpolation low computational complexity technique choice computer graphic applications 
quality approximating line terms euclidean distance generally inferior regression approach 
linear interpolation linear regression segment approximations data 
approximation created linear interpolation smooth aesthetically appealing appearance endpoints segments aligned 
linear regression contrast produces slightly disjointed appearance tighter approximation terms residual error 
deliberately keep descriptions algorithms high level technique imagined approximation technique 
particular pseudocode function create segment imagined interpolation regression technique 
segmentation algorithms need method evaluate quality fit potential segment 
measure commonly conjunction linear regression sum squares residual error 
calculated vertical differences best fit line actual data points squaring summing 
commonly measure goodness fit distance best fit line data point furthest away vertical direction norm line data 
kept descriptions algorithms general encompass error measure 
particular pseudocode function calculate error imagined sum squares furthest point measure 
sliding window algorithm 
sliding window algorithm works anchoring left point potential segment data point time series attempting approximate data right increasing longer segments 
point error potential segment greater user specified threshold subsequence anchor transformed segment 
anchor moved location process repeats entire time series transformed piecewise linear approximation 
pseudocode algorithm shown table 
algorithm seg ts sliding window max error anchor finished segmenting time series calculate error anchor anchor max error seg ts concat seg ts create segment anchor anchor anchor anchor table generic sliding window algorithm sliding window algorithm attractive great simplicity intuitiveness particularly fact online algorithm 
variations optimizations basic algorithm proposed 
koski noted ecg data possible speed algorithm incrementing variable leaps length 
hz algorithm times faster little effect output 
depending error measure may optimizations possible 
noted residual error monotonically non decreasing addition data points test value final chosen value 
suggest initially setting mean length previous segments 
guess pessimistic measured error max error algorithm continues increment classic algorithm 
decrement measured error max error 
optimization greatly speed algorithm mean length segments large relation standard deviation length 
monotonically non decreasing property residual error allows binary search length segment 
surprisingly aware suggested 
sliding window algorithm give poor results circumstances 
researchers reported tested algorithm stock market data relative performance best noisy data 
shatkay contrast notice problem gives elegant examples explanations 
consider variants basic algorithm designed robust certain case underline difficulty producing single variant algorithm robust arbitrary data sources 
park 
suggested modifying algorithm create monotonically changing segments 
segments consist data points form tn tn 
modification worked smooth synthetic dataset demonstrated 
real world datasets amount noise approximation greatly 
variations sliding window algorithm particularly popular medical community known fan patient monitoring inherently online task 
top algorithm 
top algorithm works considering possible partitioning times series splitting best location 
subsections tested see approximation error user specified threshold 
algorithm recursively continues split subsequences segments approximation errors threshold 
pseudocode algorithm shown table 
algorithm seg ts top max error best far inf length find best place split time series 
improvement approximation improvement splitting improvement approximation best far breakpoint best far improvement approximation recursively split left segment necessary 
calculate error breakpoint max error seg ts top breakpoint recursively split right segment necessary 
calculate error breakpoint length max error seg ts top breakpoint length table generic top algorithm variations top algorithm including dimensional case independently introduced fields early cartography known douglas peucker algorithm image processing known algorithm 
researchers machine learning data mining community introduced algorithm classic textbook duda calls iterative points fits 
data mining community algorithm support framework mining sequence databases multiple abstraction levels 
shatkay zdonik considering alternatives sliding windows support approximate queries time series databases 
park introduced modification perform scan entire dataset marking peak valley 
extreme points create initial segmentation top algorithm applied segments case error individual segment high 
segmentation support special case dynamic time warping 
modification worked smooth synthetic dataset demonstrated 
real world data sets amount noise approximation greatly 
lavrenko uses top algorithm support concurrent mining text time series 
attempt discover influence news stories financial markets 
algorithm contains interesting modifications including novel stopping criteria test 
smyth ge algorithm produce representation support hidden markov model approach change point detection pattern matching 
bottom algorithm 
bottom algorithm natural complement top algorithm 
algorithm begins creating finest possible approximation time series segments approximate length time series 
cost merging pair adjacent segments calculated algorithm begins iteratively merge lowest cost pair stopping criteria met 
pair adjacent segments merged algorithm needs perform bookkeeping 
cost merging new segment right neighbor calculated 
addition cost merging segments new larger neighbor recalculated 
pseudocode algorithm shown table 
algorithm seg ts bottom max error length create initial fine approximation 
seg ts concat seg ts create segment length seg ts find cost merging pair segments 
merge cost calculate error merge seg ts seg ts min merge cost max error finished 
index min merge cost find cheapest pair merge 
seg ts index merge seg ts index seg ts index merge 
delete seg ts index update records 
merge cost index calculate error merge seg ts index seg ts index merge cost index calculate error merge seg ts index seg ts index table generic bottom algorithm dimensional analogues algorithm common field computer graphics called decimation methods 
data mining algorithm extensively current authors support variety time series data mining tasks :10.1.1.42.1358
medicine algorithm hunter mcintosh provide high level representation medical pattern matching system 
feature comparison major algorithms deliberately deferred discussion running times algorithms readers intuition various approaches developed 
running time approach data dependent 
reason discuss worst case time gives upper bound best case time gives lower bound approach 
standard notation lower bound upper bound function lower upper bound 
definitions assumptions 
number data points number segments plan create average segment length actual length segments created algorithm varies refer lengths li 
algorithms top perform considerably worse allow li large say assume algorithms limit li multiple cl average length 
trivial code algorithms enforce time analysis follows exact algorithm includes limit 
algorithms top perform considerably worse allow li large say assume algorithms limit maximum length multiple average length 
trivial code algorithms enforce time analysis follows exact algorithm includes limit 
empirical results show segments generated limit length tightly clustered average length limit little effect practice 
assume set points compute best segment compute error time 
reflects way algorithms coded practice packaged algorithm function linear regression 
note believe produce asymptotically faster algorithms custom codes linear regression best fit algorithms reuse computed values computation done time subsequent steps 
leave topic 
follows computations best segment error assumed 
top best time top occurs split occurs midpoint data 
iteration computes split point best line points points 
takes split point total split points 
iteration finds split points 
gives recurrence solves 
lower bound assumed data best possible split points 
worst time occurs computed split point side leaving just points side middle 
recurrence iterations giving time 
sliding windows algorithm compute best segments larger larger windows going cl assumption discussed 
maximum time cl compute single segment 
number segments cl time ln 
best case worst case bound 
bottom iteration computes segment pair points costs merging adjacent segments 
easily seen take time 
iterations look minimum error pair merge merge pair new segment snew delete heap keeping track costs best done heap costs merging segments merging segments compute costs merging snew si si insert costs heap costs 
time look best cost time add delete costs heap logn 
time construct heap 
best case merged segments equal length final segments length time merge set length segments length segment half segments time compute best segment pair merged segments counting heap operations 
iteration takes time repeating log times gives segment size number times produce length segments total time log log 
heap operations may take nlogn 
lower bound proven just log 
worst case merges involve short long segment final segments length cl time compute cost merging length segment cl length segment time reach length cl segment 
cl segments compute time cl ln 
time heap operations inconsequential 
complexity study summarized table 
algorithm user specify online complexity top bottom ln sliding window ln table feature summary major algorithms 
key maximum error segment maximum error segment entire time series number segments 
possibly modifications extensions addition time complexity features practitioner consider choosing algorithm 
question algorithm online batch 
secondly question user specify quality desired approximation 
trivial modifications bottom algorithm allows user specify desired value maximum error segment total error approximation 
non recursive implementation top support options 
sliding window allows maximum error segment specified 

empirical comparison major segmentation algorithms section provide extensive empirical comparison major algorithms 
possible create artificial datasets allow algorithms achieve zero error measure forces approaches produce arbitrarily poor approximations 
contrast testing purely random data forces algorithms produce essentially results 
overcome potential biased results tested algorithms diverse collection datasets 
datasets chosen represent extremes datasets experiments 
radio waves 
exchange rates 
ii 
water level 
manufacturing 
ecg 
noisy sine cubed 
sine cube 
space shuttle dimensions stationary non stationary noisy smooth cyclical non cyclical symmetric asymmetric addition data sets represent diverse areas data miners apply algorithms including finance medicine manufacturing science 
illustrates datasets experiments 
experimental methodology simplicity brevity include linear regression versions algorithms study 
linear regression minimizes sum squares error minimizes euclidean distance euclidean distance just square root sum squares 
euclidean distance measure derived far common metric data mining time series 
linear interpolation versions algorithms definition greater sum squares error 
immediately encounter problem attempting compare algorithms 
compare fixed values sliding windows allow specify number segments 
give algorithms fixed max error measure total error entire piecewise approximation 
performance algorithms depends value max error 
max error goes zero algorithms performance produce segments error 
opposite max error large algorithms performance simply approximate single best fit line 
test relative performance reasonable value max error value achieves trade compression fidelity 
reasonable value subjective dependent data mining application data 
chose considered reasonable value max error dataset bracketed values separated powers 
lowest values tends produce fragmented approximation highest tends produce coarse approximation 
general performance mid range values consider important 
illustrates idea 
interested relative performance algorithms setting max error data set normalized performance algorithms dividing error worst performing approach 
fine approximation correct approximation coarse approximation max error max error max error max error max error max error interested comparing segmentation algorithms setting userdefined threshold max error produces intuitively correct level approximation 
setting subjective chose value max error brackets range reasonable approximations 
experimental results experimental results summarized 
obvious result generally poor quality sliding windows algorithm 
exceptions worse performing algorithm usually large amount 
comparing results sine cubed noisy sine supports conjecture noisier dataset difference expect algorithms 
suggests exercise caution attempting generalize performance algorithm demonstrated single noisy dataset 
top occasionally beat bottom small amount 
hand bottom significantly performs top especially ecg manufacturing water level data sets 
bottom top sliding windows poor approximation approximation space shuttle comparison major times series segmentation algorithms diverse datasets range parameters 
experimental result 
triplet histogram bars normalized dividing performance worst algorithm experiment 
ecg tic ra dio wa sine ub manufacturing tic noisy sine cubed water level exc ra te 
new approach noted shortcomings major segmentation algorithms investigated alternative techniques 
main problem sliding windows algorithm inability look ahead lacking global view offline batch counterparts 
bottom top approaches produce better results offline require scanning entire data set 
impractical may unfeasible data mining context data order terabytes arrive continuous streams 
introduce novel approach capture online nature sliding windows retain superiority bottom 
call new algorithm sliding window bottom 
segmentation algorithm algorithm keeps buffer size buffer size initially chosen data create segments 
bottom applied data buffer leftmost segment reported 
data corresponding reported segment removed buffer datapoints read 
number datapoints read depends structure incoming data 
process performed best line function basically just classic sliding windows 
points incorporated buffer bottom applied 
process applying bottom buffer reporting leftmost segment reading best fit subsequence repeated long data arrives potentially forever 
intuition algorithm 
best line function finds data corresponding single segment relatively poor sliding windows gives buffer 
data moves buffer relatively bottom algorithm chance refine segmentation semi global view data 
time data ejected buffer segmentation breakpoints usually ones batch version bottom chosen 
pseudocode algorithm shown table 
algorithm seg ts max error seg num seg num integer read number data points approximate seg num segments 
lower bound upper bound data input bottom max error call classic bottom algorithm seg ts concat seg ts sliding window right 
deletes points data input add points best line concat best line max error check upper lower bound adjustment necessary flush approximated segments buffer 
seg ts concat seg ts function best line max error returns points approximate error max error potential segment 
read additional data point concat error approx segment return table sliding window bottom algorithm buffer allows gain semi global view data set bottom 
important impose upper lower bounds size window 
buffer allowed grow arbitrarily large revert algorithm pure bottom small buffer deteriorate sliding windows allowing excessive fragmentation may occur 
algorithm upper lower bound twice half initial buffer 
algorithm seen operating continuum extremes sliding windows bottom 
surprising result demonstrated allowing buffer contain just times data normally contained single segment algorithm produces essentially results bottom able process stream data 
new algorithm requires small constant amount memory time complexity small constant factor worse standard bottom algorithm 
experimental validation repeated experiments section time comparing new algorithm pure batch bottom classic sliding windows 
result summarized new algorithm produces results identical bottom 
comparison algorithm pure batch bottom classic sliding windows diverse datasets range parameters 
experimental result 
triplet histogram bars normalized dividing performance worst algorithm experiment 

directions bottom sliding windows poor approximation approximation space shuttle ec tic kw ise ra dio wa sine manufacturing tic noisy sine cubed water level exc ha nge ra te carried extensive review empirical comparison time series segmentation algorithms data mining perspective 
shown popular approach sliding windows generally produces poor results second popular approach top produce reasonable results scale 
contrast known bottom approach produces excellent results scales linearly size dataset 
addition introduced new online algorithm scales linearly size dataset requires constant space produces high quality approximations data 
plan extend directions 
performance bottom particularly surprising explores smaller space representations 
initialization phase algorithm begins line segments having length merged segments lengths 
contrast algorithms allow segments odd lengths 
interesting see removing limitation bottom improve performance 
simplicity brevity assumed inner loop algorithm simply invokes bottom algorithm time 
clearly results computation redundancy 
believe may able reuse calculations previous invocations bottom achieving speedup 
reproducible results statement interests competitive scientific inquiry datasets code available spreadsheet detailing original unnormalized results author 
agrawal faloutsos swami 

efficient similarity search sequence databases 
proceedings th conference foundations data organization algorithms 
agrawal lin sawhney shim 

fast similarity search presence noise scaling translation times series databases 
proceedings th international conference large data bases 
pp 
agrawal psaila wimmers zait 

querying shapes histories 
proceedings st international conference large databases 
chan fu 

efficient time series matching wavelets 
proceedings th ieee international conference data engineering 
das lin mannila smyth 

rule discovery time series 
proceedings rd international conference knowledge discovery data mining 
pp 
douglas peucker 
algorithms reduction number points required represent digitized line caricature 
canadian vol 
december 
pp 

duda hart 
pattern classification scene analysis 
wiley new york 
ge smyth 

segmental semi markov models endpoint detection plasma etching 
appear ieee transactions semiconductor engineering 
heckbert garland 

survey polygonal surface simplification algorithms multiresolution surface modeling course 
proceedings th international conference computer graphics interactive techniques 
hunter mcintosh 

knowledge event detection complex time series data 
artificial intelligence medicine 
pp 

springer 


scan polygonal approximation data compression 
ieee transactions biomedical engineering 
bme 
koski 

syntactic recognition ecg signals attributed finite automata 
pattern recognition pp 

keogh 
chakrabarti 
pazzani mehrotra 
dimensionality reduction fast similarity search large time series databases 
journal knowledge information systems 
keogh pazzani 

relevance feedback retrieval time series data 
proceedings th annual international acm sigir conference research development information retrieval 
keogh pazzani 

enhanced representation time series allows fast accurate classification clustering relevance feedback 
proceedings th international conference knowledge discovery data mining 
pp aaai press 
keogh smyth 

probabilistic approach fast pattern matching time series databases 
proceedings rd international conference knowledge discovery data mining 
pp 
lavrenko schmill lawrie jensen allan 

mining text time series 
proceedings th international conference knowledge discovery data mining 
pp 

li 
yu castelli 
framework mining sequence database multiple abstraction levels 
proceedings th international conference information knowledge management 
pp 
mckee evans owens 

efficient implementation fan algorithm fixed point arithmetic 

vol 
pp 
shimada 

extraction primitive motion human motion recognition 
nd international conference discovery science 
pp 
park kim chu 

segment approach subsequence searches sequence databases appear proceedings th acm symposium applied computing 
park lee chu 

fast retrieval similar subsequences long sequence databases proceedings rd ieee knowledge data engineering exchange workshop 
pavlidis 

waveform segmentation functional approximation 
ieee transactions computers 
wang zhang parker 

landmarks new model similaritybased pattern querying time series databases 
proceedings th international conference data engineering 
qu wang wang 

supporting fast search time series movement patterns multiples scales 
proceedings th international conference information knowledge management 


iterative procedure polygonal approximation planar curves 
computer graphics image processing 
pp 

shatkay 

approximate queries representations large data sequences 
technical report cs department computer science brown university 
shatkay zdonik 

approximate queries representations large data sequences 
proceedings th ieee international conference data engineering 
pp 
ogden 

testing change points linear trend communications statistics simulation computation 



ecg segmentation time warping 
proceedings nd international symposium intelligent data analysis 
wang wang 

supporting content searches time series approximation 
proceedings th international conference scientific statistical database management 
