contact close encounters developmentally deep perceptual system humanoid robot paul michael fitzpatrick eng university limerick eng university limerick submitted department electrical engineering computer science partial fulfillment requirements degree doctor computer science engineering massachusetts institute technology june massachusetts institute technology 
rights reserved 
author 
department electrical engineering computer science may certified 
rodney brooks fujitsu professor computer science engineering thesis supervisor accepted 
arthur smith chairman department committee graduate students contact close encounters developmentally deep perceptual system humanoid robot paul michael fitzpatrick submitted department electrical engineering computer science may partial fulfillment requirements degree doctor computer science engineering thesis presents perceptual system humanoid robot integrates abilities object localization recognition deeper developmental machinery required forge competences raw physical experiences 
shows robotic platform build maintain system object localization segmentation recognition starting little 
robot starts direct solution achieving ground separation simply region visual ambiguity watches happens 
arm passes area area recognized free space 
arm collides object causing move robot motion segment object background 
robot acquire reliable segmented views objects learns recognizes segments objects contact 
low level high level visual features learned way examples orientation detection affordance recognition respectively 
motivation simple 
training large corpora annotated real world data proven crucial creating robust solutions perceptual problems speech recognition face detection 
powerful tools training systems typically stripped away deployment 
ideally remain particularly unstable tasks object detection set objects needed task tomorrow different set objects needed today 
key limiting factor access training data thesis shows need problem robotic platform actively probe environment carry experiments resolve ambiguity 
instance general approach learning new perceptual judgment find special situations perceptual judgment easy study situations find correlated features observed generally 
thesis supervisor rodney brooks title fujitsu professor computer science engineering acknowledgments rod brooks support advice time mit running diverse interesting research group letting part 
am grateful deb roy trevor darrell members committee helpful comments thesis 
robots thesis fruit combined labor students 
am grateful particularly indebted brian scassellati matthew marjanovi cynthia breazeal matthew williamson bryan adams 
take opportunity deny existence tea conspiracy group existed doubt pleasant break working day working night ai lab 
eduardo torres strikes sort ring lead conspiracy existed absolutely evidence members plotting lab coup tat 
eduardo humor 
giorgio metta great friend colleague 
charlie clarke kemp innumerable interesting challenging conversations 
hideki kozima making office fun place 
living machines group martin martin una may reilly aaron jessica banks jeff weber jessica howe annika mysterious juan 
journey herding rural ireland doing robotics research cambridge long 
boundless parents ann william possible 
siblings mary john support 
aunt josephine writing receiving little return 
various groups governments ireland paying education herding wrong 
am grateful books terry providing endless amusement inspiration 
quoted start chapter thesis bear connection main text 
mi giving confidence learn pronounce name accomplish 
tom jerry 
contents place perception ai 
robot 
replacing annotation 
active perception 
developmental perception 
interpersonal perception 
roadmap 
campaign real time robot bodies brains cog strong silent type 
low level arm control 
low level head control 
kismet cute 
cluster 
cluster communication 
contact tapping world active vision 
manipulation driven vision 
implementing active segmentation 
contact 
ground separation 

experimental results 
directions 
outer limits learning edges orientation orientation 
approaches orientation detection 
empirical orientation detection 
results 
discussion 
close encounters recognizing nearby objects contact approaches object recognition 
geometry recognition 
appearance recognition 
hashing rich features 
details matching 
searching synthetic object synthetic scene 
searching real objects synthetic scenes 
recognizing real objects real images 
dealing multiple objects simultaneously 
online training 
extracting object prototype 
comparing segmentations 
stabilized perceptual interface 
completion illusory contours 
reaching discovering manipulators hand eye coordination 
objects intermediaries 
canonical mirror neurons 
implementation details 
modeling manipulator 
rock roll exploring exploiting object affordance affordances 
think affordances 
exploring affordance 
mimicry application 

final frontier working space keeping track objects approach 
human gaze 
social gaze 
visual attention 
maintaining gaze 
maintaining egocentric map 
flat track compound coordinate system 
pose detector 
evaluation 
words working speech microphones 
infant directed speech 
discussion 
automatic language modeling 
clustering algorithm 
extracting oov phone sequences 
dealing rarely additions 
dealing competing additions 
testing convergence 
offline vocabulary extension 
real time vocabulary extension 
stabilized perceptual interface 
interpersonal perception learning activity 
places objects words 
learning structure novel activity 
learning rules novel activity 
limitations extensions 
summary 
directions summary significant contributions 
grounding operational definitions 
fully autonomous platform 
philosophy 
list figures training data ice cream 
motivation active segmentation 
summary active segmentation 
segmentation recognition 
robotic platforms 
kinematics cog arm 
control joint arm 
motors cog head 
kismet cute 
interprocess communication model 
problems segmentation 
poking active segmentation 
stages poking sequence 
detecting moment impact 
framework label problems graph cuts 
relationship connectivity accuracy perimeter length 
segmentation applied synthetic test images 
collecting evidence foreground background 
series segmentations single object 
active segmentation applied challenging sequences 
poking different directions 
zooming segmentation 
consistency shape statistics 
orientation detection 
steerable filters orientation detection 
sampling appearance edges object boundary 
examples boundary samples 
empirical appearance edges 
frequency occurrence edge fragments 
frequency occurrence horizontally oriented edge fragments 
frequency occurrence diagonally oriented edge fragments 
synthetic circle square test image 
synthetic cube test images 
expanding orientation filter 
orientation detection natural image 
perturbations ideal horizontal edge 
perturbations ideal diagonal edge 
perturbations thick line 
perturbations thin line 
orientation label frequencies 
geometric hashing 
hashing rich features 
finding circle mondrian 
searching real objects synthetic scenes 
example searching real objects synthetic scenes 
recognizing real objects real images 
multiple objects image 
orientation histograms 
illusory contours 
online training recognition 
automatically generated object prototypes 
localization examples 
overview causal chain robot human arm 
canonical mirror neurons 
detecting manipulator poking act 
detecting human poking act 
automatically generated manipulator prototypes 
detecting manipulator endpoint 
objects roll 
characterizing actions 
rolling probabilities 
basic affordance 
mimicry example 
cog baby 
influences gaze 
gaze types 
social amplification 
low level attention filter 
reading robot gaze 
looking watch 
manipulating low level attention 
acquiring target tracking 
tracking long periods 

keeping track locations 
flat track 
associating coordinate system surface object 
finding outline head 
head tracker action 
eye detection 
frontal pose recognized 
initializing mesh structure tracking 
synchronizing mesh human face 
tracking pose human head 
extended tracking 
microphone arrangement 
iterative clustering procedure processing speech 
keyword error rate speech recognition system 
converging vocabulary 
circle development 
perceptual judgements identity 
association invocation 
summary task segmentation procedure 
recovering structure simple sequence 
communicating sorting task 
communicating search task 
perceptual biases task communication 
finding correlations perceptual features 
example circle 
opportunities versus training data 
robot 
chapter starts physicists disagree 
people aware problems start things 
wonder aloud driver gets makers dictionaries look spellings words 
goal build perceptual system robot integrates useful mature abilities object localization recognition deeper developmental machinery required forge competences raw physical experiences 
motivation doing simple 
training large corpora real world data proven crucial creating robust solutions perceptual problems speech recognition face detection 
powerful tools training systems typically stripped away deployment 
problems stable time face detection benign conditions acceptable 
problems conditions requirements change line training deployment reasonably drawn 
resources training ideally remain available support structure surrounding maintaining current perceptual competences 
barriers doing 
particular annotated data typically needed training difficult acquire online 
challenge thesis addresses 
show robotic platform build maintain quite sophisticated object localization segmentation recognition system starting little 
place perception ai human brain car message overlaid mental reflections caution perceptual judgements may subtler appear 
time time difficulty implementing analogues human perception underestimated ai researchers 
example summer vision project mit ai lab apparently expected implement ground separation object recognition limited set objects balls cylinders month july extend cigarette packs batteries tools cups august papert 
blind spot continues current day example proposal thesis reading assumed existence perceptual abilities consume entire chapters 
progress 
results neuroscience continue drive home sophistication perceptual machinery humans animals 
computer vision speech recognition fields right 
advances consumer electronics led growing drive advanced human computer interfaces bring machine perception forefront 
mean ai traditional focus representation search planning plan execution 
devices need operate rich unconstrained environments emphasis planning may premature suspect field exist long considered acceptable test schemes realistic perceptual interface 
workers confronted perception hand harder problem action selection hand squarely faced difficulties action selection eliminated arise inadequate perceptual access place chapman undeniable planning search crucial applications complex logistics shipping chess 
robotics particular simply projecting real world form planning search applied key research problem abstraction process essence intelligence hard part problem solved brooks 
early approaches machine perception ai focused building maintaining detailed integrated models world complete possible sensor data available 
proved extremely difficult time practical approaches developed 
cartoon caricatures stay physical stay close raw sensor data possible 
simple cases may possible world model avoid difficulties involved creating maintaining representation partially observed world brooks 
tasks obstacle avoidance achieved reactively connell gives example task temporal structure performed maintaining state world robot body control system 
clearly demonstrates structure task logically distinct structures required perform 
activity sensitive external structure world imply control system directly mirrors structure organization 
stay focused adopt point view describe world sufficient task simplifies kind need hopefully point easily accurately maintained 
examples include deictic representations pengi chapman agre toto representations space mataric 
stay open multiple representations flexible switching representations run trouble minsky 
idea overlaps notion encoding common sense lenat multiple partial theories searching single unified representations 
real conflicts various approaches adopted common thread running 
ask minimal representation possible choice representation allow develop system rapidly lenat 
steps away singing dancing monolithic representation external world 
summarized doubt kicking robustness perspective look problem right way may relatively easy 
idea ai emphasis finding right representations problems get lost division labor set problems cases got redefined match representations 
approach robust perception developed described robustness experience 
drawing tools machine learning just module operating sensor input improved 
minimum performance characterized empirically determine relied fails output appropriately weighed sources 
process applied finer granularity parameters module affect performance traceable way 
statistical learning kind seriously leads architectures contradict approaches derive benefit representations integrated possible 
example training speech recognition system useful able combine acoustic phonological language models optimization occurs largest scope possible mou zue 
success statistical corpus methods suggests additional organizing principle ones enunciated stay connected statistical training creates empirical connection parameters system experience world leads robustness 
maintain connection environment changes maintain robustness 
require integrating tools typically training deployed system engineering opportunities replace role annotation plays 
thesis argues robots just particular perceptual competences tools forge competences raw physical experiences 
important tools extending robot perceptual abilities importance recognized individually related brought 
active perception robot employs motor action reliably perceive properties world 
second development experience improve perception 
third interpersonal influences robot percepts guided external agent 
examples object segmentation object recognition orientation sensitivity initial action understanding described 
robot 
fact vision aided action noted researchers aloimonos bajcsy ballard gibson 
area focuses uniformly advantages afforded moving cameras 
example bovik pair cameras mounted track achieve precise stereoscopic vision 
track acts variable baseline system physically interpolating case cameras close images easy put correspondence case cameras separated large baseline images different correspondences hard 
tracking correspondences second case allows accurate depth estimates wider baseline supported 
thesis described chapter extends basic idea action aided vision include simple manipulation just moving cameras 
just conventional active vision provides alternate approaches classic problems stereo vision object tracking approach developed addresses classic problem object segmentation giving visual system power recruit arm movements probe physical connectivity 
thesis ice cream ice cream ice cream ice cream ice cream ice cream ice cream ice cream ice cream ice cream automatic speech recognition fluent english speaker read sentences video camera feb feb am pm pm pm building ne room call arrange time 
questions ice cream sls lcs mit edu earn gift certificate minutes training data worth weight ice cream speech recognition research community certificate created kate 
step visual monitoring robot action specifically manipulation purposes correction 
robot clumsy grasp due object incorrectly segmented visual system ends just brushing object thesis shows exploit motion correctly segment object exactly robot needs get grasp right time 
object shaped tends slip away grasped certain manner affordance recognition approach needed learn combat 
ability learn clumsy motion important tool real general purpose manipulation system 
certain elements thesis abstracted robotic implementation passive system object recognition module described chapter 
protocol developed allow human teacher object system enrolled object recognition requiring physical action robot part 
example nayar 
detects scene camera changes triggering segmentation object enrollment 
relies constrained environment dark background clutter extraneous environmental motion 
approach uses human generated motion segmentation waving pointing described 

sail robot weng object placing object gripper rotates depth recording views goes 
protocols admit autonomous exploration necessarily limit types applications robot applied 
thesis serves proof concept limitation essential 
researchers working autonomous development motivated appeals biology software complexity weng 
main argument added autonomy simply unavoidable wish achieve maximum robustness 
absence perfect visual algorithms crucial able adapt local conditions 
particularly clear case object recognition 
robot moves locale meet objects seen 
autonomously adapt greater range applicability 
example imaging robot asked clear junk basement degree required deal shaped situated objects challenging task experimental manipulation helpful technology 
cartoon motivation active segmentation 
human vision excellent ground separation top left machine vision center 
coherent motion powerful cue right robot invoke simply reaching poking 
replacing annotation suppose property environment value robot usually determine 
suppose special situations robot reliably determine property 
potential robot collect training data special situations learn robust ways determine property process referred developmental perception thesis 
active interpersonal perception identified sources special situations allow robot temporarily reach current perceptual abilities giving opportunity development occur 
active perception refers motor action simplify perception ballard proven worth times history robotics 
allows robot experience percepts initially motor action 
interpersonal perception refers mechanisms robot perceptual abilities influenced human helper 
example may necessary correct category boundaries communicate structure complex activity 
placing perception developmental framework perceptual competence result experience evoked set behaviors 
machinery development sufficient reliably lead perceptual competence place able regenerate somewhat changed circumstances avoiding brittleness 
active perception idea action aid perception basis field active perception robotics computer vision ballard sandini 

known instance active perception active vision 
term active vision essentially synonymous moving cameras need 
gained advantage fact robots actors environment simply passive observers 
opportunity examine world causality performing probing actions learning response 
conjunction developmental framework allow robot experience expand outward sensors environment arm objects encounters objects back robot outwards actors encounter objects 
active vision humanoid robot cog oriented opening potentially active segmentation object shape samples edge samples object appearance samples arm appearance samples object behavior samples benefits active segmentation poking 
robot accumulate training data shape appearance objects 
locate arm strikes objects record appearance 
lower level robot sample edge fragments segmented boundaries annotate orientation facilitating empirical approach orientation detection 
tracking motion object poking straightforward segmentation initialize tracker robot record motion poking causes different objects 
rich area manipulation aided vision largely unexplored 
object segmentation important step 
chapter develops idea active segmentation robot poking behavior prompts select locations environment sweep arm 
object area swept motion generated impact arm segment object background obtaining reasonable estimate boundary see 
image processing involved relies ability fixate robot gaze direction arm 
coordination achieved hard wired primitive learning 
context possible collect views objects robot robot arm 
giving robot behavior benefits 
motion generated impact arm object greatly simplifies segmenting object background obtaining reasonable estimate boundary 
prove key automatically acquiring training data sufficient quality support forms learning described remainder thesis 
ii poking activity leads consequences different objects respond poking different ways 
example toy car tend roll forward bottle roll side 
iii basic operation involved striking objects performed robot human companion creating controlled point comparison robot human action 
ground separation long standing problem computer vision due fundamental ambiguities involved interpreting projection world 
matter passive system segmentation times active approach visual appearance arbitrarily deceptive 
course plenty limitations active segmentation 
segmentation poking objects robot move small large 
constraint means matched space manipulable objects important class robotics 
object prototype robot manipulator foreign manipulator top row shows sample views toy car robot sees poking 
views collected segmented 
views aligned give average prototype car robot arm human hand acts 
give sense quality data bottom row shows segmented views best match prototypes 
car robot arm hand belong fundamentally different categories 
robot arm human hand cause movement actors car suffers movement object arm robot control part self 
developmental perception active segmentation provides special situation robot observe boundary object 
outside situation locating object boundary basically guesswork 
precisely kind situation developmental framework exploit 
simplest information empirically characterize appearance boundaries oriented visual features general 
object boundary known appearance edge object background sampled labelled orientation boundary neighborhood 
subject chapter 
higher level segmented views provided poking objects collected clustered shown 
views just needed train object detection recognition system allow robot locate objects non poking contexts 
developing object localization recognition topic chapter 
poking moves step outwards causal chain away robot world gives simple experimental procedure segmenting objects 
way extend chain try extract useful information seeing familiar object manipulated 
offers opportunity development case learning manipulators 
locating manipulators covered chapter 
opportunity poking provides learn objects move struck general objects specific objects cars bottles tend roll particular directions 
information robot strike object direction tends move getting strongest response essentially evoking rolling affordance offered objects 
subject chapter 
interpersonal perception perception completely objective process choices 
example objects judged depends features considered essential considered incidental 
robot useful draw distinctions human task 
achieve mechanisms allow robot perceptual judgements caregiver 
useful situations robot abilities simply challenge need helping hand 
thesis identifies channels particularly accessible sources shared state space speech task structure 
robot human inhabit space 
observe state workspace manipulate equal extents 
chapter covers set techniques observing maintaining spatial state 
useful channel communicating state speech covered chapter 
temporal structure states state transitions topic chapter 
roadmap chapter overview robot platforms computational architecture chapter active segmentation objects poking chapter learning appearance oriented features chapter learning appearance objects chapter learning appearance manipulators chapter exploring object affordance chapter spatially organized knowledge chapter recognizing responding words chapter interpersonal perception task structure chapter discussion chapter campaign real time robot bodies brains written actual computer game 
called journey alpha screen dots 
said happened real time heard computers 
seen tv took years get alpha 
written kept computer years rewarded little dot appearing middle screen message saying welcome alpha 
go home implemented robots cog kismet see developed humanoid robotics group mit ai lab various students past decade 
accurately implemented brains computers connected bodies maze cables sacrifice offered real time performance 
chapter dips minimum detail systems necessary understand rest thesis 
interested reader referred excellent theses williamson breazeal scassellati shoulders author stands trying peer 
cog strong silent type cog upper torso humanoid previously abilities visually guided pointing marjanovi rhythmic operations turning crank driving slinky williamson responding simple forms joint attention scassellati 
overview research agenda cog embodies see brooks 

low level arm control cog arms degrees freedom organized shown 
joints driven series elastic actuators williamson essentially motor connected load spring think strong torsional loosely coiled 
arm designed enact trajectories high fidelity 
stiff arm preferable 
designed perform interacting poorly characterized environment 
spring acts right arm dofs eyes dofs head dofs torso dofs left arm dofs stand dofs facial dofs neck dofs robots cog top kismet bottom 
kismet expressive anthropomorphic head useful human interaction cog upper torso humanoid adept object interaction 
low pass filter friction effects introduced gears protects gear teeth shearing impact shock loads 
drawback series elastic actuators limit control bandwidth cases applied force needs change rapidly 
force applied electric motor normally changed rapidly directly proportional current supplied 
putting motor series spring ability lost motor drive displacement spring mass applied force changes 
robot head normal operation come contact environment needs move continuously rapidly series elastic actuators 
arms tradeoff control bandwidth safety appropriate 
robot arms usually employed purposes manipulation serve primarily visual system 
target reaching operation assumed characterized fact reaching operation serves better define characteristics target active segmentation see chapter 
arm colliding objects 
collisions rigid structures table 
collisions movable objects robot potentially manipulate 
collisions people 
important physical nature arms manner controlled tolerant obstacles 
arms driven nested controllers 
implements force control driving shoulder elbow shoulder elbow wrist wrist kinematics arm williamson 
total joints divided pair shoulder elbow wrist 
series elastic actuator arm dynamics control joint arm williamson 
inner loop controls series elastic actuator terms force working achieve desired deflection spring measured strain gauge 
outer loop controls deflection setpoint achieve desired joint angle measured potentiometer 
motor desired deflection associated spring achieved measured strain gauge 
high speech control loop implemented axis motor controller motion engineering second loop controls deflection setpoint achieve desired joint angle measured potentiometer 
shows second loop williamson 
various extensions modifications basic approach example incorporate feed forward gravity compensating term details scope thesis 
low level head control shows degrees freedom associated cog head 
eye pair cameras different fields view provides step wise approximation smoothly varying resolution human fovea scassellati 
eyes pan independently tilt 
head rolls tilts differential drive 
pan tilt associated neck 
number redundancies degrees freedom permit rapid movement eyes followed slower compensating motion relatively massive head 
head contains axis inertial sensor simplify gaze stabilization 
motors head connected optical encoders driven axis motor controller motion engineering motor controller configured permit position right eye pan neck tilt left eye pan eye tilt bottom differential neck pan top differential motors cog head scassellati 
degrees freedom loosely organized pertaining eyes head neck 
pan tilt roll eyes achieved high speed moving mass head 
kismet cute 
velocity control 
written low level strategic control head see example scassellati details omitted 
kismet cute parts developed reported kismet 
kismet infant robot form behavior designed elicit responses humans breazeal 
essentially active vision head augmented expressive facial features send receive human social cues 
kismet large set expressive features eyelids eyebrows ears jaw lips neck eye orientation 
schematic shows degrees freedom relevant visual perception omitting eyelids 
eyes turn independently horizontal pan turn vertical tilt 
neck turn head horizontally vertically crane forward 
cameras narrow fields view rotate eyes 
central cameras wide fields view rotate neck 
cameras unaffected orientation eyes 
reason mixture cameras typical visual tasks require high acuity wide field view 
high acuity needed recognition tasks controlling precise visually guided motor movements 
wide field view needed search tasks tracking multiple process thread port portlet link communications model 
process thread number ports 
port directed send data number ports 
different processes access data different rates useful consider port owning portlets manage individual link port 
conservative quality service settings data persist communications system long necessary send slowest link 
objects compensating involuntary ego motion common trade biological systems sample part visual field high resolution support set tasks sample rest field adequate level support second set 
seen animals foveate vision humans density photoreceptors highest center falls dramatically periphery 
implemented specially designed imaging hardware space variant image sampling schwartz multiple cameras different fields view done 
cluster cog controlled network computers mhz processors 
kismet controlled similar smaller network motorola processors 
network designed demands real time vision mind clearly acceptable run slowly say update second single machine 
primary engineering challenge efficient interprocess communication computer nodes 
chose meet challenge qnx real time operating system clean transparent message passing system 
top build abstraction support streaming communications modular subsumption design 
cluster communication process thread create set ports 
ports capable communicating shield complexity communication owner 
far client process thread concerned port fairly simple object 
client assigns name port gets registered global namespace 
client hand port piece data transmit read data port received polling blocking callback 
subtleties type service required 
client specify kind service required sender specify transmission guaranteed new data override data sent receiver independently specify data sender attempts pass reception guaranteed new data received port override data read owner conditions sending port wait receiver 
objects passed communications system obey pool interface 
cloned recycled 
port clone objects necessary associated pool growing size required 
depend rates links attached port portlets read data 
default owner port insulated needing know 
simple objects cloning achieved simple copies 
complex objects images counting approach worth 
approach avoids unnecessary copies minimizes allocation deallocation objects communications system 
compatible existence special memory areas managed entities 
ports portlets native qnx messaging transport sockets running communicating non qnx system 
name server qnx service simple socket service communicating non qnx system 
default issues transparent client code 
system operate transparently alongside methods communication doesn require special resources control main process 
chapter contact tapping world 
pot said peering closely quite old ming vase waited 
called ming said cue 
tapped pot 
went ming 
vision action intertwined basic level humans 
researchers machine vision pragmatic reasons integrating sensing tightly motor control active vision head 
chapter extends logic simple object manipulation showing simple tapping poking behavior help ground separation 
poking object move motion powerful cue visual segmentation 
poking require object accurately segmented performed simply sweep arm general neighborhood periods immediately moment impact turn particularly informative give visual evidence boundary object suited segmentation graph cuts 
course experienced adult interpret visual scenes perfectly acting ideally robots 
poking proposed fallback segmentation method fails developmental opportunity training contact free object segmentation module 
topic elaborated chapters 
contribution clearly formulate new object segmentation challenge attended machine vision literature increasingly important robotics 
challenge segmentation best performed exploratory manipulation permissible 
contribution demonstrate approach rudimentary manipulation possible achieve segmentation establishing qualitative lower bound possible showing benefits non trivial 
course segmentation just start ultimately learned manipulation start complexity manipulation encouraging simple motor control lead worthwhile results 
edges table cube overlap cube misleading surface pattern color cube table poorly separated grad student glued cube table cube table illustrate problems segmentation 
edges table cube happen aligned colors cube table separated cube potentially confusing surface pattern 
dense information available way really sure cube independently manipulable entity connected table 
active vision vision system said active embedded platform change physical configuration improve perceptual performance 
example robot cameras servo rapidly moving target order stabilize image keep target view 
term processing adapted current situation 
historically number logically distinct ideas associated active vision 
vision approached context task purpose aloimonos 
idea observer engage controlled motion integrate visual data moment moment solve problems ill posed statically 
chosen motion simplify computation required widely studied vision problems stereo matching bajcsy ballard 
interwoven ideas active vision apart tarr black 
seeks add new threads mix 
active vision equated moving cameras entire body robot potentially recruited cooperate vision system 
chapter movement robot arm recruited augment visual system particular solve ground separation problem active means 
second thread active systems potential perform experiments get close accessing physical ground truth potentially admit perceptual system develops autonomously 
poking behavior gives robot access high quality training data support object localization segmentation recognition 
provides simpler fall back mechanism segmentation robot entirely mercy failures higher level competences 
manipulation driven vision clear situations useful manipulation guide vision way typical robotics resolving visual ambiguity active means 
robot left reaches object environment fixating camera 
robot view shown right 
boundary cube table sitting clear human eyes subtle reliably segmented current automatic methods 
robot arm comes contact object easily segmented background motion due impact 
experimentation making progress perception ambiguous 
correction recovering perception misleading 
development bootstrapping perception dumb 
experimentation simply failing visually ambiguous situations active robotic platform potential perform experiments environment resolve ambiguity 
consider example 
visually difficulties segmenting scene due unfortunate coincidences alignment color cube table 
simply giving situations simply dispatch robot arm ambiguous region poke bit 
methods characterizing shape object tactile information developed shape probing cole yap pushing jia erdmann moll erdmann 
chapter exploits fact visual feedback generated robot moves object highly informative motion short poorly controlled accidental 
vocabulary describe robot motion tapping poking opposed probing deliberately chosen convey idea quick evoke visual data extended tactile data 
tactile visual information usefully combined tactile proprioceptive information assumed chapter determine robot contact object 
find effector sweep contact 
withdraw upper sequence shows arm extending workspace tapping object retracting 
exploratory mechanism finding boundaries objects essentially requires arm collide objects normal operation occasional accident 
lower sequence shows shape identified tap simple image differencing tracking 
recovery robot grasp object depends size shape 
parameters estimated visually bound fallible particularly unrecognized unfamiliar objects 
failure may result clumsy grasp glancing blow object 
robot learn encounter apt repeat mistake 
chapter shows recover information object extent poking accidentally deliberately 
opens door extracting information failed actions glancing blow object attempt manipulation giving robot data needs better time 
development cumbersome poke segment object time comes view 
cleanly segmented views objects generated poking exactly needed train object recognition system turn contact free segmentation possible 
kind active segmentation proposed serve online teacher passive segmentation techniques 
analogously experienced adult interpret visual scenes perfectly acting linking action perception crucial developmental process leads competence fitzpatrick metta 
implementing active segmentation shows frames early experiment robot arm driven preprogrammed open loop trajectory swept area table watched fixed camera 
course trajectory arm came contact cube sitting table 
challenge identify isolate disturbance segment cube object arm encounter 
video stream similar experiments develop baseline implementation active segmentation clarify requirements terms processing behavior 
remainder chapter fits actual behaving robot 
reasonable way segment object track motion arm swings outwards look motion plausibly associated arm appears physically adjacent 
simple motivating example effector localized arm sweeps rapidly outwards heuristic lies highest point region optic flow swept arm image 
reaching trajectory robot relative camera orientation controlled true 
sweeping motion gentle minimize opportunity motion arm cause confusion 
motion bounded endpoint location know tracking extension phase subtracted easily 
flow connected effector ignored distractor 
sequence shown simplest case possible segmenting motion object 
practice constraints motion arm approach object convenient direction 
desirable able explore areas object simply sweeping blindly 
objects segmented target poking come 
fact straightforward 
described section cog attentional system allows locate track salient visual stimuli 
entirely low level features color motion binocular disparity defined small patches image opposed features shape size pose sense segmented objects 
cog attention system locates patch image reachable disparity robot pose needs know reach attempt poke determine physical extent object patch belongs 
human easily encourage behavior bringing object close robot moving robot leaving table 
robot track object table need ability segment observe reached poke 
things go wrong 
list potential pitfalls result inaccurate segmentation object motion may particularly visible highly textured may regions projection optic flow low non existent 
motion manipulator incorrectly separated motion object comes contact 
unrelated motion background mistaken movement manipulator impacted object 
manipulator fail come contact object 
manipulator obscure robot view object hits 
object move rigidly move little processed 
motion camera mistaken movement manipulator impacted object 
points dealt segmentation method graph cuts allows diverse local evidence factored making approximation globally optimal segmentation 
optic flow textured regions provides evidence movement lack optic flow textured regions suggests lack motion comparing motion moment impact moment ground truth detecting point impact robot arm object 
arm swings motion tracked frame frame aggregated relatively low resolution bins highlighted squares 
large spread motion detected bins higher resolution processing activated segmentation begins 
gives evidence part image manipulator 
points dealt careful engineering kinds motion robot 
final point dealt simply keeping camera fixated poking 
real advantage moving segmentation motion viewed fixed camera understood explored exhaustively see example ross stauffer 
contact object segmented motion need differentiate motion sources scene particularly robot 
high quality opportunity arises right moment contact robot object 
contact detected tactile information straightforward detect visually method described 
advantage visual information techniques applied contact events robot privileged knowledge human hand poking object see section 
real time operation moment contact detected low resolution processing images contact subjected detailed slower analysis described section 
shows visualization procedure 
robot attempting poke target suppresses camera movement keeps target fixated maximum sensitivity motion 
simple gaussian model maintained color values pixel value frames third second received 
significant changes pixel values frame frame detected flagged possible motion 
arm moves scene motion tracked discounted shadow background motion 
area arm moves marked clear object brief period permanently arm may cross object swinging back strike 
impact event detected signature explosion movement connected arm spread wider distance arm reasonably moved pixel pixel foreground background foreground node background node pixel nodes pixel pixel foreground background foreground node background node pixel nodes label problem image input minimum cut algorithm typically shown left 
node pixel special nodes corresponding labels foreground background 
visual evidence encoded edges nodes 
output algorithm shown right 
graph cut disjoint sets containing exactly special nodes total cost edges cut approximately minimized 
time available 
object stationary robot expect variance gaussians associated individual pixel models low 
sensitive pixel value changes associated sudden motion object 
impact detected drop briefly real time operation seconds perform detailed analysis required cleanly segment object apparent motion 
ground separation moment contact known motion visible contact compared motion visible contact isolate motion due object 
observe pixel variation true motion factor expect relate example highly textured region observed change time confidently declared stationary homogeneous region may motion little observed change 
general information sparse image framed probabilities pixel belongs foreground object background 
look simpler version problem pixels foreground background information completely confident assignments 
suppose information pixels image part foreground part background 
represent background unassigned foreground wish assign pixel image foreground background best sparse evidence 
approach create cost function evaluate potential segmentations choose segmentation minimum cost 
willing accept constraints kind cost function family maximum flow minimum cut segmentation algorithm sensitive length perimeters foreground regions 
important local pixel connectivity sparse introduces artifacts perimeter 
example suppose just connected regions 
cost zig zag approximation diagonal edge times ought 
connected regions better distort perimeter cost significantly factor 
neighborhood shown connected plus knight moves distortion 
increases neighborhood size increases computation time bringing significant benefit 
gorithms provide approximate solutions problem boykov kolmogorov 
apply need translate problem form graph shown 
pixel maps node graph connected edges nodes represent neighboring pixels 
special nodes corresponding labels wish assign pixel foreground background 
problem minimum cut algorithms solve split graph disjoint parts foreground node background node total cost edges broken achieve split minimized 
goal assign costs edges minimum cut graph correspond sensible segmentation 
node corresponding pixel 
node representing foreground node representing background 
completely confident classification pixel background foreground may encode knowledge assigning infinite cost edge zero cost edge 
force minimum cut algorithm assign pixel desired layer 
practice visual information ambiguous weights correspondingly softer 
costs need assigned edges pixel nodes 
suppose expect foreground information available reliably edges object fact case motion data 
reasonable goal minimum cut minimize total perimeter length segmented regions merge partial boundary segments bounding region 
simply assign actual euclidean distance pixels cost 
quite sufficient edge information noisy permits zero area cuts individual isolated foreground pixels 
need place extra cost cutting foreground pixel preferable group near neighbors start generating regions non zero area 
example simply double cost cutting edges connected pixels known foreground background 
edges placed neighboring pixel nodes prevent explosion connectivity 
neighborhood defined shown 
shows examples minimum cuts operation 
image top left noisy lines known foreground pixels length minimum cut place pixels inside foreground region 
regions disjoint total perimeter 
lines placed inside region cost little distance lines shows fact solution minimum cut algorithm finds 
examples show minimum perimeter criterion group leave separate 
fourth example shows introducing known background pixels segmentation change radically 
patch background increases perimeter cost previous segmentation poking hole large tip balance favor individual merged regions 
basic formulation extended difficulty natural data foreground background assignments soft 
previous section showed evidence available pixels part foreground part background straightforward induce plausible segmentation entire image 
shows example necessary visual evidence derived practice 
statistical significance changes pixel values apparent motion measured frames directly contact event continuously updated gaussian models 
measurements combined frames avoid situations contact event occurs just frame early generate motion contact event detected late generate motion successful segmentation 
frames aligned searching translation best matches apparent motion frames rotation neglected short intervals 
similar measurement apparent motion immediately contact event aligned partially mask motion belonging robot arm shadow unrelated movement environment 
remaining motion passed segmentation algorithm giving pixels strong foreground high cost edge special foreground node 
importantly motion mask contact passed algorithm strong background high cost edge background node 
prevents segmented region growing include arm requiring masking procedure precise 
maximum flow known foreground pixels proposed segmentation known background pixels simple segmentation examples 
input images shown upper row output shown filled regions lower row 
cases border image set background dark pixels foreground 
fourth case small extra patch pixels known background added splits large segmented region previous case 
final case shows algorithm robust noise pixels assigned foreground background random 
fact harsh kind noise assumed complete certainty data 
implementation due boykov kolmogorov 
perimeter minimization particularly appropriate kind motion data available textureless objects textureless background worst case motion segmentation motion evident edges object magnitude increases angle edge direction motion 
textured cluttered background life simpler easier confidently assert background regions fact moving 
experimental results active segmentation 
segmentation object shown cube yellow exterior sitting yellow table 
active segmentation clear advantage situations color texture difference object background small conventional segmentation sufficient generate apparent motion object 
shows poking different directions 
shows successive cube give sense kinds errors occur 
figures shows results particularly difficult situations 
shows area plotted second hu moment measure anisotropy set objects repeatedly 
second hu moment region centroid area pq dxdy motion frame immediately impact aligned motion impact masking prior motion result segmentation largest connected region refinement segmentation collecting motion evidence required segmentation 
apparent motion contact masked motion contact identifies seed foreground object regions 
motion generally contain fragments arm environmental motion escaped masking 
motion contact identify background non object regions 
prevents region assigned object motion growing include fragments 
largest connected region minor post processing clean taken official segmentation object 
features build simple nearest neighbor classifier leave cross validation gives classification accuracy chance level 
shape information predictor object identity 
qualitatively poking turned quite robust procedure data gathered opportunistically unconstrained interaction human robot 
example robot trained visiting laboratory happened wander robot curious doing 
put baseball cap cog table promptly got correctly segmented part robot training data 
directions unique advantage robots object segmentation reach touch world 
imagine classical face vase illusion trivial resolve simply poke see part free space 
poking simply lowest hanging fruit set active strategies robot achieving object segmentation 
robot unsure boundaries object lie strategies 
poke object gently 
tapping solid object induce small motion object 
result coherent region optic flow image plane 
object non rigid attached objects response messy complicated sense inevitable just cases idea unique object boundary runs trouble 
object 
big disturbance apt generate confusing motion hard process directly 
move object away local surroundings giving role dice opportunity robot see object new background better contrast 
frequently visual ambiguity local accidental effect 
results training session toy cube repeatedly offered robot poking 
image cube corresponds segmentation single poke 
common failure mode inclusion robot arm segmentation 

try get arm endpoint object 
endpoint reach presumably free space constraining boundary object 
arm endpoint mobile object confirm theories free space lies 

try get arm endpoint object 
advantage putting known background object 
imagine arm painted bright red see advantage identifying object boundary 

ask human object 
human bringing object near robot offers dual advantage motion cues known complicated partial background hand 

alternative displace robot head body get role dice access dimensional information longer baseline available stereo cameras 
exhaust space active strategies possible object segmentation humanoid robotics group mit investigating 
challenging segmentations 
example right blue white box glossy poster particularly difficult complex shadows reflections algorithm successfully distinguishes blue white part box background 
impact impact motion motion segmentation side tap segmentation back cog cube different directions 
images column moment collision arm cube detected automatically 
middle column shows motion information point contact 
red new motion purple blue pre existing motion 
notice bottom row chair moving 
bright regions images final column show segmentations produced object 
table car scene scene action action object object example power active segmentation 
images marked scene show presentations yellow toy car sitting yellow table 
robot extends arm table 
upper sequence strikes lower sequence strikes side action images 
arm comes contact car begins move segmented stationary background object 
left zoomed view car table boundary shown difference subtle 
square root second hu moment cube car bottle ball area large collection segmentations grouped object identity plotted area versus second hu moment 
enlarged markers show hand segmented values 
segmentations quite consistent area tends fraction smaller hand segmented instances 
chapter outer limits learning edges orientation disc flat real horizon 
got funny ideas staring eggs oranges long set soon learned reason distant ships looked disappearing edge world disappearing edge world 
previous chapter showed elementary sensitivity motion sufficient gather segmentations objects robot vicinity support robot behavior evoke easily processed scenarios 
data coming lot learned 
reasonable data learn appearance specific objects chapter chapter address 
possible simply learn appearance boundaries robot collection boundaries side side visual appearance 
particular allows orientation detector trained automatically annotated data 
orientation information images scales 
typically detected quadrature filters applied locations scales freeman approach developed independent contrast polarity act equally edges lines 
data robot collects opportunity arises take complementary empirical approach appearance edges learned experience derived theoretically 
main challenge appearance edges sampled densely get coverage reasonable timescale 
answer shown primarily orientation information quite robust pixel level transformations 
turns useful orientation filter constructed simple interpolating look table mapping small window size pixels directly orientation 
allows extremely rapid access orientation information right finest scale visible 
contribution demonstrate orientation detection amenable empirical treatment performed high speed 
critical real time implementation object recognition method proposed chapter 
goal orientation detection take image shown left annotate point direction defined orientation associated 
example right color coded orientation map corresponding image horizontal lines edges colored red map produced methods developed chapter 
shows orientation clear local information illusory contours kanizsa triangles detected 
orientation 
natural images full discontinuities local changes 
anisotropy associate directions regions image 
directions potentially robust image wide transformations individual pixels 
obvious example luminance edge discontinuity dark light region 
direction associated edge remains unchanged illumination regions change appearance dramatically 
contours constant luminance shaded surface behave somewhat edges luminance change minimal parallel contour maximal measured perpendicular 
directional changes luminance property natural associate direction orientation change minimal 
chapter concerned orientation associated edges luminance finest scale available 
certainly said orientation see example 
useful case particularly object localization recognition 
orientation detection prove key achieving orientation scale invariance tasks 
orientation associated neighborhoods individual points image inherently scale dependent 
fine scales relatively pixels available judge orientation 
lines edges scales extremely rough 
orientation filters derived analytic considerations parameters chosen assuming smooth ideal straight lines edges example chen 
suited larger neighborhoods redundant information 
fine scales empirical approach promising particularly number pixels involved low practical sample space possible appearances pixels quite densely 
fine scales interpretation image patch hinge relatively small number pixels 
noise sensitivity critical issue 
assignment labels image patches quite non linear process 
approaches orientation detection methods detecting local orientation fall categories 
gradient approaches kass witkin relatively direct operate applying spa example steerable filter freeman adelson 
second derivative gaussian approximation hilbert transform 
filters said quadrature 
form respond vertical lines 
odd respond vertically oriented step edges 
theory associated steerable filters shows response image small set basis filters discrete angles shown compute response filter rotated angle 
orientation detection applying filters computing angles give maximum response 
tial derivatives output isotropic edge detecting filter laplacian difference gaussians 
different approach examine response neighborhood image set oriented filters chosen respond edges cosine phase respond bars sine phase analogous receptive fields hubel wiesel visual cortex cats hubel wiesel 
filter set may overcomplete nonorthogonal image reconstruction goal 
shows example possible filter set 
filter chosen carefully need replicated discrete number orientations response image orientation computed response 
filters said steerable freeman adelson :10.1.1.18.6984
orientation computed finding orientation maximizes response image filter cosine phase sine phase filters thought real imaginary components single quadrature filter 
empirical orientation detection poking allows robot build catalog manifold appearances real edges take 
fine scales relatively pixels hope explore space possible appearances neighborhood quite exhaustively collect empirical data appearance relates orientation 
chapter basically exploration edges natural images appear viewed extremely small window pixels 
window size chosen large allow orientation defined small complete range possible appearances easily characterized visualized 
scale manual data collection labelling extremely tedious advantageous sampling appearance edges object boundary 
object detected segmented described chapter 
boundary sampled quantized window appearance stored actual angle boundary point 
examples boundary samples 
dotted pixels belong segmented object 
grid overlaid boundary shows result thresholding 
robot take care 
robot automatically compiles database appearance oriented features poking behavior 
oriented features extracted sampling image patches object boundaries turn determined active segmentation 
resulting catalog edge appearances proved remarkably diverse frequent appearances ideal straight noise free edge section 
simple matter take catalog appearances fast memory image processing filter section 
details robot behavior described chapter briefly reviewed 
robot equipped arm active vision head simple poking behavior selected objects environment tapped lightly fixating 
described chapter motion signature generated impact arm rigid object greatly simplifies segmenting object background obtaining reasonable estimate boundary 
boundary known appearance visual edge object background sampled see 
samples labelled orientation boundary neighborhood estimated simple discrete deriva edges diverse appearances 
shows orientations assigned test suite prepared hand 
grid single test edge patch dark line centered grid orientation patch observed training data 
oriented features represented include edges thin lines thick lines zig corners tive position boundary 
samples assumed contain components distinguished luminance 
pixels sample quantized binary values corresponding average average luminance 
quantization necessary keep space possible appearances exploding size 
binary quantization gives manageable possible appearances 
object boundaries recorded sampled 
possible appearances fact observed remaining hamming distance observed appearance 
orientation unobserved appearances interpolated immediate neighbors hamming space 
appearance observed multiple times orientations associated observations averaged double angle representation granlund 
straightforward matter data collected filter image fine scale orientation features 
window moved image sampling described earlier section 
sample index table mapping appearance orientation 
results shows data collection procedure operates views simple physical edges appearance edges quite complex 
common appearances observed ideal noise free edges shows 
appearances shown top row left observed appearances 
line edges common occur means perfectly possible surfaces side edge edge 
completely serendipitous anticipated obtaining automatically labelling examples difficult 
shows frequently occurring image appearances particular orientation 
clearer frequent patches generally ideal forms edges followed variations themes distracting noise 
amidst edge patterns examples line single pixel thickness pair lines running parallel 
encouraging examples appearances collected difficulty united classical edge patches orientation 
frequently observed edge appearances 
patches observed replicated rotations mirror flips inversion foreground background 
frequent top simple straight edges 
line center patch shows orientation associated patch 
straight edges completely empty patch common produced saturated regions followed tube feature third row boundary visually distinct side edge 
followed corner features thousands variations themes seen 
frequently observed appearances orientation horizontal 
clear orientation assigned patches deviate great deal ideal edges lines showing robustness examined systematically 
frequently observed appearances orientation range clear orientation assigned patches deviate great deal ideal edges lines 
orientation filter applied synthetic test images left modeled example freeman adelson :10.1.1.18.6984:10.1.1.18.6984
second column shows output orientation filter color coded angle viewed color 
third column shows information vector form 
fourth column shows orientation determined steerable quadrature filters pinter applied scale 
results remarkably similar quadrature filters computationally expensive apply 
test images smaller scale individual pixels plainly visible smoothing applied 
tests modeled example pinter significantly scaled 
shows orientations measured image consisting circle square 
example freeman adelson :10.1.1.18.6984:10.1.1.18.6984
detector gives results solid edges arbitrary contrast various kinds lines 
response edges diffuse design data collection samples taken boundary slightly side treated identically 
sharper response desired side samples dropped offset boundary recorded 
shows filter operating small image cube 
visible edge cube clearly faithfully represented output 
systematically explores effect adding noise ideal edge 
resilience orientation measure encouraging small number gaps coverage revealed suggesting data collected 
discussion orientation detection scheme chapter unusual combination properties essential approach incidental details data driven versus model 
detection relies heavily existence training data achieved directly formal model edges instantiated algorithm 
uses look table versus neural network support vector machine 
training data simply populate look table elaborate 
autonomous data collection versus human annotation 
training data collected robot human 
data driven edge orientation detection historically model data driven 
progress analytically nature edges grossly simplified example researchers worked additive gaussian noise overlaid luminance step see example canny 
long pointed edges take diversity forms steps lines perona malik 
diverse cases empirical approach attractive 
jitendra malik group looking locate boundaries objects images features trained human produced segmentations martin 
parameters modern edge detector profit empirical training optimized domain konishi 
clearly considerable scope data driven approach edge detection improve performance 
look table look tables important place ai computer science huge look table problem philosophy block implementation elementary arithmetic operations cpu design wong flynn 
interpolating look table just simplest possible learning module 
results learning simpler understand case neural networks support vector machines example mcdermott training neural network detect junctions ran problem sensitivity analysis hard understand network failure modes 
look table trivial 
chapter exploited fact provide visualizations look table 
index look table quantized pixel values 
stays closer raw image konishi martin focuses optimizing combination existing hand designed features 
theory means approach capture unanticipated domain specific properties show hand designed cases 
possibility explored implemented robot inhabiting single fixed space 
populating look table fast run time operation 
possible filter bank approach runs comparable speeds example orientation detected output filters willing put interpreting different responses step line edges essentially line edges give doubled responses appear pair close step edges 
look table approach encapsulates interpretation step automatically trained judgement required pixels angles 
autonomy training examples edges generated ways 
example computer graphics images known ground truth human labelled datasets martin 
konishi 

konishi 
shown domain dependent improvements edge detection sense argument adaptivity 
autonomous empirical approach holds promise developing wise low level perceptual system context sensitive guesses making job higher level modules simpler 
scope thesis certainly motivating consideration direction 
shown idealized edges empirically grounded occur frequently variants shows exotic forms occur profitably modeled 
fine scales number pixels compute orientation low practical approach sample appearance edges empirically average noise see 
large cache size modern processors memory approach orientation detection facilitate extremely rapid orientation detection important real time vision systems alford 
rectangular windows natural size real time machine vision applications 
memorybased approach proposed advantage pixel window principled way 
filters orientation detection typically circular nature ignore pixels lie outside largest circle fits inside window 
possibilities expanding size orientation filter 
technique applied larger windows 
easily 
fact window size earliest papers orientation detection diameter pixels completely reach 
window binary pixels take possible values allowing symmetries 
hard sample exhaustively quantization look table size impossible 
intermediate possibility shown involves fewer pixel symmetric shape window augmented extra pixels round 
empirical approach features orientation 
isn clear features robust pixel wise transformation orientation may easy explore space appearances exhaustively 
orientation detector applied image 

top row shows left right original image output detector output memory detector simple enhancement output region growing 
second row filters output orientation range horizontal vertical respectively 
final row shows output steerable filter comparison steered nominal orientations reinforce orientation pop immediately filters note example significant response third column orientation image require level additional processing memory approach bypasses 
top row shows ideal view horizontal edge 
rows show patches single pixel perturbation ideal 
estimated angle remains close horizontal 
rows follow show pixel perturbations pixel weight edge 
behavior orientation estimate generally reasonable 
cases insufficient data estimate just sample available 
perturbations ideal view diagonal edge 
cases little training data available example divergent direction estimate fourth row bottom third column right 
perturbations ideal view tube 
perturbations idea view line 
pixel weight line low perturbations correspondingly drastic effect 
lines seen training data require special conditions object boundaries sampled boundary surface side 
considerable room improvement sources ground truth acquired 
example orientation information propagated time space neighboring patches known orientation frequently encountered patches 
frequency count angle degrees frequency count angle degrees plot left shows frequency thick step edge shown labelled possible angle 
distribution peak appropriate values occur 
samples lie close right angles nominally correct value 
plot right shows results thin line shown 
basic shape pattern occurs frequently hundreds times versus tens thousands 
chapter close encounters recognizing nearby objects contact followers om lit halls just prophet said counted said minutes earlier looking 
active segmentation behavior introduced chapter robot familiarize appearance nearby objects poking 
chapter concerned learning locate recognize segment objects contact 
approaches object recognition physical objects vary greatly shape composition 
variety reflected visual appearance 
unfortunately straightforward matter recover object properties appearance factors illumination relative pose distance occlusions 
central challenge object recognition sensitive identity objects maintaining invariance face incidental properties 
broad approaches recognition geometry appearance 
geometry recognition image formation geometric process way approach recognition model invariant geometric relationships hold particular class object 
relationships points lines surfaces volumes 
may known possible views object just 
new scene geometric relationships measured matched model 
details measure matching review selinger 
main difficulty combinatorics search involved 
lot free parameters search try match unsegmented scene object model particular elements scene correspond object transformation elements object 
high speed performance geometric hashing useful technique review see wolfson rigoutsos 
method geometric invariants quasi invariants computed points model training images stored hash tables 
recognition simply involves accessing counting contents hash geometric hashing recognition 
set points shown left pair considered turn normalize rest translation orientation scale 
normalized locations points permutation stored hash table model pair points generated 
buckets 
possibility geometric invariants take set points selected interest operator pair points turn normalize remainder scale rotation 
position normalized points stored hash table shown 
invariants difficult achieve various solutions proposed 
appearance recognition world geometric nature geometric features particularly easy extract reliably images 
appearance recognition focus shifted intrinsic nature object properties measured images object including geometric properties surface properties color texture 
example swain ballard proposed set colors segmented views object representation 
regions image contain color mix determined histogram intersection contain object 
histogram back projection quickly filter regions contain object assigning pixel weight frequency color histogram 
form region growing method accumulates evidence find plausibly colored regions 
method fast objects distinctive colors useful pre filter computationally expensive processing 
color intrinsically somewhat robust scale rotation sensitive changes spectral profile illumination 
appearance methods window 
classifier built operates rectangular region interest image 
window moved entire image multiple scales multiple orientations 
responses classifier locations scales combined various heuristics 
variation orientation rotation depth typically dealt training multiple recognizers various poses 
poses sampled quite sparsely pose requires iteration search procedure 
ways speed example cascade classifiers reject clearly non target windows early devoting full analysis plausible targets 
actual classifier eigenspace methods possibilities 
rich features hashing 
pair edges object recognized stored terms relative position orientation samples colors 
representation invariant translation scale plane rotation 
hashing rich features approach geometric hashing uses richer features include non geometric information 
geometric hashing works pairs points informative single points 
ordered pair points defines relative scale translation orientation 
points may needed general transformations affine projective move wolfson rigoutsos 
staying case just points somewhat problematic 
distinctive points image match points model 
hashing doesn require distinctiveness useful pre filter 
secondly redundancy noise points directly reflected transformation imply 
possibility triplets points 
distinctiveness redundancy 
explosion number possible combinations 
pairs points just manageable better drawn constrained subset image 
example roy pentland uses histograms distance angles pairs points boundary object recognition 
pairs edges generally region defined coherent orientation pairs points 
pairs edges distinctive pairs points relative orientation size 
carefully matching contain redundant information transformation image model 
disadvantage edges subject occlusion edges regions automatically incomplete broken segments 
trivial objects pairs edges approach doomed start 
orientation filter developed earlier applied images simple region growing algorithm divides image sets contiguous pixels coherent orientation 
real time operation adaptive thresholding minimum size regions applied number regions bounded independent scene complexity 
model training views pair regions belonging object considered exhaustively entered hash table indexed relative angle relative position color sample points regions inside object boundary 
useful extension geometric hashing coherency match implies particular transformation coherent matches aggregated example see gros 
applied instance 
speed abbreviated version filter centroid location match implies object information anyway 
coherence checking scale orientation matching stage 
procedure means perform object localization simultaneously matching 
oriented regions relatively sparse 
experiments showed fast machine mhz low resolution possible triplets regions features close real time 
distinctive redundant non trivial objects possible triplets 
frame rate just slow approximately hz worth 
extreme possibility just single edges 
distinctive sampling colors edge generally high variance area problematic 
details matching basic feature pairs oriented regions containing information angle regions 
angle associated region mean response orientation filter region principle axis region measures generally highly correlated 
positioning oriented regions relative projected intersection point normalized scale 
position associated region centroid silhouette 
color sample points regions 
points sampled quarter length intervals line region centroids colors compared 
color judgements normalized luminance quantized just bits 
aim number regions pixels row column image square order number pixels image scale computational architecture designed comfortably real time 
basic feature prediction object center simply accumulate see convergence evidence 
automatically gives high quality locations scales target may plausibly 
segmentation object possible seeing regions contributed locating object 
point useful find consensus scale eliminate matches scales 
proposed regions object methods previous chapter confirm presence object 
histograms matched constructed merging features training views available 
histograms modeling noise sensing variation appearance object 
index invariant translation place rotation robustness precise boundaries segmented region 
clearly unlucky small changes push histogram bin boundary 
smoothing multiple samples 
multiple targets remove intersections histograms assign target feature frequent 
objects simply oriented regions may greater response random background 
importance independent confirmation method 
searching synthetic object synthetic scene simple example works consider test case shown 
system model view circle test image 
simplicity model view case centered view object segmentation required 
processing model view test image oriented regions detected grouped best match color best match color simple example object localization finding circle mondrian 
model test image orientation filter applied regions coherent orientation detected 
circle regions small fragments perimeter 
straight edges test image long 
finding circle reduces locating region edge fragments diverse angles distance generally large respect size 
color quite sufficient localization case 
perimeter circle estimated looking edges contribute peak match strength 
algorithm works equally image circles square 
searching real objects synthetic scenes take single instance object poking search synthetic image containing version various distractors 
algorithm picks best match lets rank distractors order salience 
clear yellow square match having internal purple square adds boost 
closest distractor yellow square purple square inside rotated shows example 
object question cube green face containing red triangle 
image containing numerous variations theme reasonable match author judgement selected 
recognizing real objects real images shows examples cube real images 
testing set images objects robot half images training half testing gives recognition error rate median localization error pixels image determined comparing center segmented region automatic segmentation 
segmenting image grouping looking best match cube poking image synthetic version cube set distractors 
superimposed lines rightmost image bottom row indicate detected position object edges implicated 
image immediate left shows strength evidence object entire image lets rank distractors order attractiveness 
regions implicated locating object filling median object recovered background mistakenly included determined comparison results automatic segmentation 
dealing multiple objects simultaneously dealing multiple matches image shown 
fact important robotic implementation uses foveated approach objects viewed sequentially 
recognition system trained real images green cube typical segmentation shown left synthetic version cube set distractors middle evaluate features recognition 
superimposed circle lines indicate detected position object edges implicated 
image right shows strength evidence object entire image lets rank distractors order attractiveness 
case prominent feature recognition outer green square 
cube recognized localized segmented real images 
image column system trained 
image remain columns test images 
note scale orientation invariance demonstrated final image 
camera image oriented regions response object filters implicated edges grouped possible deal multiple objects image 
online training geometric hashing procedure applied image recognition time essentially identical procedure applied training time 
fact integrate training fully online system allowing behavior shown previously unknown object segmented active segmentation immediately localized recognized interaction 
extracting object prototype model developed localization recognition difficult visualize directly 
useful powerful easily viewable model get quick sense things working 
section develops simple procedure doing 
view object segmentation mask try align masks average views get prototype object 
masks centered 
rotated minimize moment vertical direction object profile asymmetric normalize object possible orientations 
iterative approach flip masks corresponding object views similar possible 
resulting transformed views averaged shown 
average typically blurry may aspect pose wasn normalized see example green cube 
final step find segmentation best matches average 
gets back particular view object representative possible 
gives feel segmentations 
results show example objects segmented 
bottle systematically losing cap small strip label 
suggests may problems strong internal edge slightly inside boundary segmentation procedure may switch minimize perimeter length 
point easier see kind effect representation earlier useful localization purposes 
comparing segmentations build object model useful combine information multiple segmentations 
different segmentations may come different objects 
segmentations need compared clustered 
images coming online experience timestamps associated 
images close time object 
useful able pool data different training episodes 
cues color boundary shape oriented features important 
variety measures evaluated 
comparing segmented views objects relatively easy problem done unnecessary spend time 
simple measure color histogram comparison adopted 
clustering happens online offline 
online implementation optimized speed offline method optimized accuracy 
offline updates available replace online object models 
clustering color histogram classic swain ballard style implementation giving recognition accuracy set images objects shown measured leave cross validation 
clustering orientation histogram color information replaced histogram orientation angles detected object accuracy achieved see 
orientation complicated fact histograms degree freedom object rotates comparing histograms need aligned 
slow compared color 
clustering boundary shape shape information hu moments segmented boundaries accuracy achieved 
clustering behavior theory objects clustered move 
inaccuracies motor control impractical 
topic revisited chapter aggregate statistical measures object behavior shown measurable 
stabilized perceptual interface problem trying continually refine models recognizing objects changing models confuse modules downstream refer models 
deal stabilized interface approach 
object word see chapter recognized feature line allocated 
contract recognizing module rest control frequency occurrence frequency occurrence orientation degrees aligned orientation degrees comparing object segmentations orientation histograms 
system semantics feature line preserved possible respond situations past attempts refine purify semantics affected noise example responds basic property extended range situations 
offline updates initially regard contract shelf clustering algorithms step models compared previous models aligned appropriately 
completion illusory contours object recognition process consider completing breaks edges edges orientation extended overlap 
main purpose compensate limitations region grouping erroneously split oriented region fragments 
byproduct simple illusory contours dealt kanizsa triangle shown 
breaks edges considered completion object recognition process 
certain illusory contours triangle right possesses recognized 
shows stills minute interaction cog 
area frame highlighted square shows state robot left box gives view robot camera right shows image associates current view 
initially robot familiar objects right box empty 
cube frame 
shown cube recognizes recognition evidenced showing image recorded object 
cube turned side robot longer recognizes third frame 
side cube robot poke fourth frame recognize fifth frame differentiate green side sixth frame 
confuses object seen ball seventh frame easily fix poking eighth ninth frames 
final frames show invariance recognition system scale 
top row shows objects experiment seen robot perspective 
middle row shows prototypes derived objects na alignment procedure 
prototypes contain part robot manipulator environment 
prototypes find best available segmentations objects bottom row 
localization examples 
left column shows object prototype mask training 
top half shows letter located various positions scales orientations fine letters physical supersets center distinguished 
small circle indicates best matching location full map responses underneath image 
lower half shows algorithm working examples different class object colored shapes simple square 
chapter reaching discovering manipulators hand fed 
harder hand feed tomorrow 
sense poking provides robot operational definition objects giving effective procedure learning 
perfect example robot effectively blind objects small large objects appropriate scale manipulation works 
robot familiar set objects go provide operational definition manipulator acts objects 
chapter develops effective procedure grounding definition 
get training images manipulator need find opportunity segment background sure segmented region fact manipulator 
constraining environment having prior training period hand eye mapping trained quite hard 
ideal opportunity moments poking event 
fairly narrow time window robot fixating actively trying move arm view 
independent measure arm fact view proceeding smoothly contact detection algorithm 
identify short period time manipulator visible moving field view 
hand eye coordination robot privileged knowledge state arms 
principle predict proprioceptive feedback arms appear images cameras 
learning mapping joint angles retinotopic coordinates favorite task robotics fitzpatrick metta marjanovi metta 
detection endpoint manipulator training trivial giving special color shaking repeatedly 
mapping learned simplification longer necessary mapping depend visual appearance 
want learn mapping depends appearance 
example useful robot independently estimate location arm visual evidence motor feedback precise closed loop visually guided left robot establishes causal connection commanded motion manipulator probes manipulator effect object 
object serves literal point contact link robot manipulation human manipulation right 
control just blind open loop reaching 
endpoint obvious color repeated motion order detect manipulator careful move away constraint training 
solution adopted identify special situation robot arm identified visual field normal behavior 
consider basic poking behavior introduced chapter 
visual collision detection mechanism developed chapter operates appearance model arm 
detect collision near point fixation arm driven collision arm object 
chapter motion caused collision segment object motion regions appeared originate collision discarded due arm shadow background motion 
turn reasoning try segment object moving collision 
segmentations contain arm 
shown chapter sufficiently segmentations collected refined don need perfect 
behaviors poking possible open loop reaching real reason develop visually guided reaching 
seen chapter open loop poking fine segmentation purposes leaves lot desired trying move object controlled way 
objects intermediaries motivation choice poking behavior vehicle detecting manipulator 
clearly contact objects possible way locate robot arm willing construct special training behavior simple analogue human infant hand regard behavior 
advantage objects serve point contact robot human kozima 
thesis shown robot manipulator familiarize objects poking robot observes known objects behaving poking canonical neurons active manipulable objects visually mirror neurons active object manipulation observed performed animal canonical neurons active manipulable object observed sufficient activate mirror neurons 
mirror neurons active goal directed manipulation object observed 
manipulation may performed animal gallese 
classes neuron observed area monkeys humans 
monkey drawings giorgio metta 
reasonably deduce acted entity see 
robot able perceive poking carried 
easy general robot gaze directed appropriate location 
familiar object maintain fixation long period time 
sees reachable object familiar unfamiliar begins poke fixate 
simple add behavior suppresses poking unexpected motion detected object due robot movement 
means human noticing robot preparing poke object take poke 
machinery developed active segmentation operate foreign manipulator human hand fixated object 
course robot easily distinguish segmentations produced arm simply checking commanding arm move target time 
way build model foreign manipulators belong environment 
canonical mirror neurons strong reason identify representation robot arm arms 
vision research motivated hints biology 
primates neurons concerned vision motor control 
example 

observed neurons receptive fields somatosensory visual motor domains area 
motor information appears keep somatosensory visual receptive fields anchored particular part body forearm body moves 
called canonical neurons located area respond host acts object particular way grasping precision grip experiments segmenting robot arm human arm poking object 
segmentation performed working backwards point collision object occurs frame immediately ones shown 
simply object 
responses specific type object type action interpreted neural analogue affordances gibson gibson 
affordances discussed detail chapter briefly simply possible actions particular actor apply particular object 
related class neurons called canonical neurons identified primates including humans respond host performing particular action grasping host observes performing action gallese 
response specific hard fool neuron selective particular type grasp respond tool 
neurons interpreted possible basis imitative behavior language rizzolatti arbib 
existence neurons motivation 
implementation details manipulator segmented hypothesizing moves object constant velocity period immediately preceding moment contact 
estimating velocity gross apparent motion allows segmentation problem expressed form introduced chapter foreground taken regions moving desired velocity background 
apparent motion computed finding frame translation best aligns differences successive frames rotation ignored short timescale 
pixel assigned background layer moving estimated rate 
typical results segmentation procedure shown robot arm human hand 
isn relevant current discussion segmentation object happens way human action robot action shows example 
segmentation algorithm human poking operations robot fixating object human 
robot fixate objects bringing attention means discussed chapter 
modeling manipulator test sure segmentation data usable quality passed alignment averaging procedure described objects chapter 
modification segmentation masks right aligned center aligned differing lengths manipulator view 
builds assumption manipulator long thin 
shows results alignment 
segmentation best matches averaged prototype segmentation 
basic goal procedure acquire images manipulator reasonably met 
segmentations passed directly object localization system developed chapter modification 
center manipulator defined better working endpoint 
detected manipulator strikes object segmentation procedure shortcut endpoint simply defined rightmost point object works fine robot left arm 
typical localization results shown 
robot manipulator top left automatically segmented poking sequences 
segmentations aligned averaged giving mask appearance shown adjacent images 
best matching view shown top right 
similar result human hand shown bottom data poking sequences hands individuals 
training endpoint robot arm reliably detected view indicated orange circle despite variations distance arm arm view 
chapter rock roll exploring exploiting object affordance waterfall second highest disc discovered year revolving crab noted explorer guy de yoyo 
course lots dwarfs native people hunters merely badly lost discovered daily basis thousands years 
weren explorers didn count 
matters life robotics action perception reflect priority 
perception seen basically implicit preparation respond 
chapter introduces approach perception explicitly preparation respond 
perceptual system assigned task continually preparing set actions possible robot current situation simply need selected activated take effect 
approach similarities gibson notion affordances gibson reviewed 
affordances 
affordances possibilities action 
creature perform action object object said afford action action affordance object 
example cup affords grasping drinking 
idea affordance actor specific leaf afford support ant elephant 
existence affordance depends creature perform appropriate actions depend ability creature perceive 
authors term different ways 
concerned interface design human computer interface community perception action defining characteristics term see ho review 
take perceived affordances refer actions creature believes possible object potentially distinct true affordances physically realizable 
gibson implication affordances perceived directly sense picked environment opposed inferred 
particularly helpful notion robotics significant literature notion direct perception reviewed see hurley discussion 
gibson points vision easier done dynamically moving perspective ideas cropped active animate vision 
gibson pointed power optic flow information thesis benefited collaborative fitzpatrick metta 
think affordances 
robotics possibilities action captured concisely robot configuration space 
configuration space contains parameters joint angles necessary uniquely specify robot physical state 
actions correspond trajectories configuration space 
need way think space possible actions 
configuration space useful planning details motor control getting point trying move impossible joint angles 
complicated constraints action tactical level analysis unavoidable 
strategic level isn helpful 
robot deciding joint angle trajectories wrong level abstraction 
choice switch space representation goals possible operators planning translate operators back motor actions plan execution 
involves significant architectural commitment 
useful consider alternatives don involve dramatic phase change motor control perception 
affordances offer alternative 
predominantly bottom system assessing possible robot current situation prepare appropriate control parameters available actions describe actions low bandwidth way relative awkward details suppressed 
different planning picking action assessing parameters appropriate carry 
principle practice significantly simplify decisions need 
configuration space ideas benefit formalized clear affordances 
define affordance space set control parameters output perception initiated actions appropriately set action flags specifying actions possible 
example affordance perceptual system mobile robot chose signal turn possible action behavior system setting appropriate control parameters achieve turn continue straight 
robot navigate benefit robot wide vocabulary actions may useful simplification 
danger weaker perception system minimal judgements add delay potentially leave decisions hands informed module 
course evident perception integration important 
exploring affordance examples affordances commonly discussed include different kinds grasping twisting 
require quite sophisticated motor control 
starting point sensible choose actions properties affordance lower cost entry terms dexterity 
author identified object rolling excellent candidate 
certain objects roll roll requires matching robot action object pose intelligent manner 
example shows objects quite distinct properties terms rolling affordance 
rolling affordance perfectly reach robot capabilities developed 
poke object different directions locate familiar objects recognize identity 
active segmentation played roles toy car rolls forward bottle rolls side toy cube doesn roll ball rolls direction different objects roll different ways 
toy car rolls forward bottle rolls side ball rolls direction cube doesn roll easily 
experiment collecting data object recognition localization providing segmentation tracking motion object contact 
chronologically experiment performed techniques tracking recognition localization described thesis fully developed simpler methods color histogram back projection localization recognition optic flow tracking small number frames 
system developed collaboration giorgio metta 
designed experiments poking visual segmentation described chapter move object basis rolling affordance 
experiment robot set objects shown orange juice bottle toy car cube colored ball possible actions motor repertoire 
actions labelled convenience side tap pull push away 
actions correspond different patterns poking 
side tap robot sweeps arm field view 
back robot raises arm draws torso sweeps outwards 
normally actions interchangeably random poking segmentation algorithm agnostic source object motion see example 
toy car bottle tend roll definite direction respect principal axis 
car rolls principal axis bottle rolls orthogonal 
cube doesn really roll shape 
ball rolls direction 
shape information extracted segmentation produced poking relationships principle learned goal experiment 
robot set objects shown times approximately distractors 
segmented views clustered color histogram 
poking episode shape statistics gathered point impact translational motion object tracked dozen frames impact 
poking events gross translation caused poking computed function type poking applied back slip side tap pull push away shown 
necessary effect poking fixed action pattern known robot perceptual system procedure recovers effect reveals motor control cog arm erratic 
procedure robot automatically learns poking left causes object slide roll right general rule 
similar consideration applies actions 
object specific models built relating effect object orientation translation occurs poking 
shows estimated probability observing objects rolling particular direction respect principal axis 
peculiar properties car bottle reveal preferred direction rolling 
ball cube preference 
learning procedure robot built representation object terms estimated probability pull side tap push away direction movement degrees histogram direction movement object possible poking action 
plots abscissa direction motion object direction parallel axis axis 
ordinate empirical probability distribution direction motion objects 
pictorial information form color histograms swain ballard 
shape information form measure average size object index elongation object respect principal axis set hu moments hu 
detailed histograms displacement object respect initial orientation particular motor primitive 
summary histograms shown capture response object poking 
training stage known objects cog object recognized localized orientation estimated principal axis 
recognition localization color histogram procedure training swain ballard 
cog uses understanding affordance object geometry poking object roll 
localization procedure error perfectly acceptable coarseness motor control performed simple qualitative test performance robot 
trials robot mistakes 
trial classified mistaken robot failed poke object direction roll 
judgements appropriate direction robot succeeded achieving external observation behavior robot 
twelve mistakes due imprecise control example manipulator moved excessively quickly object outside field view 
estimated probability occurrence estimated probability occurrence estimated probability occurrence bottle car difference angle motion principal axis object degrees cube rolls right angles principal axis difference angle motion principal axis object degrees estimated probability occurrence difference angle motion principal axis object degrees rolls principal axis ball difference angle motion principal axis object degrees probability observing roll particular direction set objects cog experiments 
represent difference principal axis object observed direction movement 
ordinates estimated probability 
principal axis computed second hu moment object silhouette hu 
anisotropy silhouette measured higher order moment low object defined principal axis case cube ball 
car bottle clear directions tend roll 
contrast cube slides ball rolls direction 
histograms represent accumulation trials average complicated dynamics objects robot arm capture trend simple robot exploit 
remaining errors genuine mistakes due misinterpretation object position orientation 
potential mistake occur robot object example believes sees bottle fact sees car 
robot poke object wrong way correctly determines object position orientation 
mimicry application knowledge objects collected previous experiment set second experiment robot observes human performing action set objects mimics 
fact visual processing analyzing robot generated action situation detect contact segment object human arm described chapter 
robot identifies action observed respect motor vocabulary 
done comparing displacement object possible actions characterized choosing action effects closer observed watch contact object segmented tracked frames moment contact shown 
object segmentation tracked frames combination template matching optic flow 
big circles represent tracked position bottle successive frames 
arrow displayed frame contact rd left projects position time contact th frame respectively 
sequence bottle robot orientation side tap appropriate rolling robot 
second sequence car different angle 
appropriate action exploit affordance bottle roll back 
displacement 
procedure orders magnitude simpler trying completely characterize action terms observed kinematics movement 
robot mimic observed behavior human sees object 
angle preferred direction motion object characterized observed displacement measured 
mimicry object localized previous experiment robot picks motor action produce observed angle relative object 
example car right angle respect principal axis cog mimic action poking car right angle despite fact car preferred behavior move principal axis 
examples observation poking generation mimicry actions shown figures 
describing problem right way important step solving 
affordances provide means implement bottom influence terms current situation described 
example described perceptual system detects robot looking object roll motor options automatically change 
poking automatically push object right direction object roll 
option strike object available robot pretty anyway deliberately mimic human action example 
control terms side taps back possible course level detail longer necessary 
demonstration human mimicry similar situation mimicry object rotated invoking object natural rolling affordance going object natural rolling affordance mimicry example toy car 
row shows human demonstration poking operations robot mimics 
sequences left show robot mimicking human exploiting car rolling affordance 
sequences right show happens human hits car contrary fashion going preferred direction motion 
robot mimics unnatural action suppressing usual behavior trying evoke rolling 
mimicry shown independent orientation car 
don high dexterity explore properties objects 
chapter final frontier working space keeping track objects don think ponder said want tell machine stops working take teddy bear away 
just don think want live kind world er know sort say needs enabled objects live space 
move change pose 
chapter introduces array interconnected methods track objects locations low level visual attention egocentric maps 
approach extends overlaps previous efforts cog kismet scassellati breazeal author 
attention addressed active vision social setting breazeal framework social cues advantage robot vision system breazeal fitzpatrick 
breazeal scassellati implemented model low level visual attention measures intrinsic salience brightness motion behavioral modulation 
author extended introduce mechanism controlling persistence able deliberately hold gaze object dynamically control trade responsive changes environment complete slave fluctuations 
chapter goes encompass influences attention see object recognition spatial memory 
shows basic architecture robot gaze controlled 
influences coming modules operate different speeds different levels noise versus stability robot head eyes direct control modules behavior erratic 
visual control robot gaze direction mediated tracking module operates fastest rate possible hz 
means robot respond fast moving objects parts vision system react quickly 
implemented humanoid robot crucial robot carefully controls gaze convey veridical impression state human 
helps robot moves eyes manner consistent human eye movement 
low level salience filters object recognition localization wide object recognition localization foveal egocentric map poking sequencer tracker motor control arm motor control eyes head neck influences gaze 
object recognition subsumes low level salience filters 
spatial awareness important tasks adult humans cognition traded physical space kirsh 
human gaze eye movement primitives implemented kismet cog modeled human system 
human system providing stable percept world little intuitive appreciation physical constraints operates 
humans foveate vision 
fovea center retina higher density photoreceptors periphery 
means see object clearly humans move eyes image object falls fovea 
human eye movement smooth 
composed quick jumps called saccades rapidly re orient eye project different part visual scene fovea 
saccade typically period fixation eyes relatively stable 
means stationary continue engage corrective micro saccades small movements 
eyes fixate moving object follow continuous tracking movement called smooth pursuit 
type eye movement evoked voluntarily occurs presence moving object 
periods fixation typically hundreds milliseconds new saccade occur goldberg 
eyes normally move lock step making equal conjunctive movements 
close object eyes need turn somewhat correctly image object eyes 
disjunctive movements called vergence rely depth perception see 
eyes located head need compensate head movements occur fixation 
ocular reflex uses inertial feedback vestibular system keep orientation eyes stable eyes move 
fast response prone accumulation error time 
kinetic response slower compensation mechanism uses measure visual slip image retina correct drift 
mechanisms give humans stable gaze head moves 
ocular motor system implemented cog kismet approximation human right eye left eye vergence angle ballistic saccade new target smooth pursuit vergence operate track object humans exhibit characteristic types eye motion 
saccadic movements highspeed ballistic motions center target field view 
smooth pursuit movements track moving object low velocities 
ocular kinetic reflexes act maintain angle gaze head body move world 
vergence movements serve maintain object center field view eyes object moves depth 
robotic eye movements controlled mirror pattern 
system 
kismet eyes periodically saccade new targets chosen targeting system tracking smoothly move 
kismet vergence eye movements scale head robot ends looking cross correctly 
cog disparity measure computed comparing left right camera views drives vergence movements simply add tracking movements conjunctive disjunctive channels operate independently 
analogue vestibular ocular reflex developed cog axis inertial sensor 
crude approximation kinetic reflex performed implementation smooth pursuit 
social gaze apart functional constraints eye movements humans communicative value 
needs considered designing humanoid robots 
human observer robot eyes indicate locus attention 
robot degree engagement conveyed communicate strongly robot behavior organized currently looking 
robot eyes flick place place resting indicates low level engagement appropriate visual search behavior 
prolonged fixation smooth pursuit orientation head target conveys greater level engagement suggesting robot behavior strongly organized locus attention 
kismet great deal gaze head neck posture convey state goal give cooperative human natural cues help robot 
example kismet number coordinated motor actions designed deal various limitations kismet visual perception see 
person visible distant face imaged adequate resolution kismet engages calling behavior person closer 
people come close robot cause difficulties cameras narrow fields view small part face may visible 
circumstance withdrawal response invoked kismet draws back close withdrawal response person backs fast close threat response comfortable interaction distance person draws closer comfortable interaction speed far calling behavior fast irritation response sensor range regulating interaction 
people distant seen clearly called closer come close robot signals discomfort withdraws 
withdrawal moves robot back somewhat physically effective signaling human back 
toys people move rapidly cause irritation 
physically person 
behavior aids cameras somewhat increasing distance kismet human 
behavior secondary greater effect social amplification human close kismet withdrawal response strong social cue back away analogous human response personal space 
similar kinds behavior support visual perception objects 
object close kismet lean away far away kismet crane neck 
social context actions power immediate physical consequences 
human reading intent robot actions may amplify actions 
example toy may interpreted interest toy resulting human bringing toy closer robot 
limitation visual system quickly track moving objects 
objects people move excessive speeds kismet difficulty tracking continuously 
bias people away excessively behavior movements movement objects manipulate kismet shows irritation tracker limits ability 
limits physical maximum rate eyes neck move computational maximum displacement frame cameras target searched 
see visual motor system driven requirements nominally unrelated sensory modality just behaviors completely orthogonal vision ear call behavior attract person attention recruited purposes regulation 
mechanisms help protect robot 
objects suddenly appear close robot trigger looming reflex causing robot quickly withdraw appear 
event repeated response quickly robot simply appears annoyed best strategy repetitions clearly signal unde skin tone filter responds possible values 
grid left shows response filter values red green fixed value blue 
image right shows filter operation 
typical indoor objects may consistent skin tone include wooden doors cream walls 
similarly rapidly moving objects close robot threatening trigger escape response 
mechanisms designed elicit natural intuitive responses humans special training 
carefully crafted mechanisms clear human kismet perception failing corrective action help robot perception reflected behavior familiar way 
inferences human preconceptions 
general motor control humanoid robot poses challenges issues stability accuracy 
motor actions perceived human observers semantically rich regardless imputed meaning intended 
powerful resource facilitating natural interactions robot human places constraints robot physical appearance movement 
allows robot readable behavioral intent motivational state transparent intuitive level interacts 
allows robot regulate interactions suit perceptual motor capabilities intuitive way humans naturally cooperate 
gives robot leverage world extends far physical competence social amplification perceived intent 
visual attention cog kismet attention systems designed attract robot features humans find visually salient motion presence skin tone bright colors size 
advantage doing interactive situations people may intuitively provide right cues direct robot attention shaking object moving closer waving hand see figures 
attention system take care tasks need fast response times 
example kismet looming objects detected pre measure optic flow expansion facilitate fast reflexive withdrawal 
output low level feature detectors color motion combined weighted average produce single attention map 
combination allows robot select regions visually salient direct computational behavioral resources regions 
operation representative low level feature detector shown 
filter simple skin tone detector computationally inexpensive means find regions may images sequence instructor wanted robot attend green object moved away central location 
image robot clearly attending second just clearly fixated instructors face 
knowing prompted instructor wave object little regained robot attention 
kismet interacting test subject details robot implementation behavior 
subject decides show kismet watch brings forward taps left 
motion plus size plus skin color attractive target kismet looks center 
motion stops kismet looks away right 
contain faces hands 
filters course imperfect information available better simply staring wall ceiling hours robots default 
higher level modules compensate limitations opportunity arises example cog kismet frontal face detector developed viola jones 
manipulating low level attention 
images top row come directly robot camera 
images bottom summarize contemporaneous state robot attention system 
brightness lower image corresponds salience rectangles correspond regions interest 
rectangles correspond robot locus attention 
pair images robot kismet attending face engaging mutual regard 
shaking colored block salience increases cause switch robot attention 
third pair images shows head tracks toy moves giving feedback human robot locus attention 
eyes continually tracking target tightly neck 
fourth pair images robot attention switches back human face tracked moves 
tracking system preference moving objects 
mean robot staring want bring robot attention simply move object front robot frames 
shows frames second sequence robot cog tracking rapidly moving ball suspended ceiling elastic crashes author face 
shows current tracked target 
notice wide range motion compare frames distance ball compare frames short sequence 
tracker continually looks pixels forward backward direction motion shifts whichever location moving rapidly 
keeps tracker target stay locked specific part target 
maintaining gaze presence multiple salient objects useful able commit attention objects period time 
gives time post attentive processing carried object downstream processes organize object 
kismet example visual search robot scans visual field dwelling long point fixation decide fixated object behaviorally relevant example may lack eyes searched post 
cog robot needs keep object fixated time vergence stabilize get accurate measure distance 
committing object useful behaviors need atomically applied target 
kismet example calling behavior robot needs stay looking person calling gesture socially readable 
cog poking object robot needs maintain fixation 
allow commitment attention system augmented tracker 
tracker follows target visual field simple correlation successive frames 
usually changes tracker target reflected movements robot eyes behaviorally inappropriate 
tracker loses target chance able reacquire attention system 
figures shows tracker operation cog kismet respectively 
behavior tracker longer period kismet 
frames taken second intervals 
white squares indicates position target 
target centered images taken camera fixed respect head 
third row face slips away tracker immediately attention system 
images taken minute session tracker slipped times 
typical performance faces tend move rapidly 
short term memory objects locations sight mind egocentric map locations objects tracked respect robot 
maintaining egocentric map low level attention visual tracking memory objects goes view completely forgotten 
useful robot 
rectify deficit map objects robot observed maintained 
map egocentric locations expressed relative robot position 
fact distance objects ignored direction stored 
purpose map allow robot return gaze object previously observed object left field view require knowledge distance object extremely close 
kinematic model head computed eye gaze relative robot torso fixating object 
object familiar robot poking identity stored dimensional grid bins indexed spatial dimensions similar latitude longitude see time observation 
robot needs object consults grid observation object directs robot gaze turn approximately right direction 
object recognition module requested locate object question robot fixate precisely 
flat track compound coordinate system important aspect objects pose 
section develops pose tracking mechanism designed objects recognized pose generally 
important scenario thesis poking offers segmented views part object facing camera 
head tracking initially treated 
useful case suitable face detection currently better developed frontal presentations arbitrary pose 
reason head tracking data sets available evaluating fidelity head pose estimation 
space dimensions associated pose rigid object translational rotational 
tracking objects camera changes pose dimensions difficult recover accurately 
approach deal strong model object tracked particularly successful head tracking see example black yacoob 
shape human head broadly similar location marked target robot looks away robot looks back target gone target reappears keeping track locations 
circles cross hairs represent locations contain particular object 
object removed detected color histograms swain ballard indicated small circle cross hair 
upper row cartoon sequence illustrate happening views taken directly cog egocentric map 
initially yellow car table front cog 
robot looks away door looks back car longer 
reappears immediately detected 
behavior object tracking implemented give basics representation robot workspace 
species 
characterizes distribution face length scales ratios different sub groups 
distributions quite narrow subject gender race age known 

estimate head orientation monocular images 
show pose recovered tracking just points face eye corners fifth tip nose necessary anthropometric data available 
propose stage system estimates subjects gender race age indexes appropriate table anthropometric data performs pose estimation 
scale pose tracking systems require prior model general application systems rely special characteristics head example harville harville 
points spectrum include application eigenspace techniques directly recognize pose specific user opposed tracking changes pose mckenna gong 
systems designed run real time wide variety simple cues hair outline wang 
representations prone accumulated errors considerable research coordinate systems tracking various situations 
introduced goal minimize effect mis estimation object shape tracking allow opportunistic calibration known view object observed 
rigid object viewed camera rotate depth free explore space object pose specified completely just numbers position image plane specified coordinates giving ray camera particular point object 
coordinate specifying rotation object plane parallel camera rotational freedom object rotate depth 
coordinate specifying scaling projection object image plane scalar size metric distance object 
coordinates completely describe object pose sense camera configuration known shape object known full pose object recovered parameters 
need shape object arises implicit points coordinates 
non planar component part object facing camera 
surface coordinate planar component camera facing surface located oriented 
retinotopic coordinate distance size measure plane orientation flat track compound coordinate system 
component surface coordinate object tracked left 
second component degrees freedom flat surface facing camera position measure scale distance plane rotation 
object starts rotating depth degrees freedom factor 
goal introduce destroying simplicity image plane coordinates defined 
suppose object tracked basically convex awkward shape chance pose recognized silhouette directly 
moment ideally unique region surface object close parallel image plane 
object rotates depth region shift part surface 
parameterize region lies surface object dimensions 
region construction parallel image plane coordinates developed earlier recast follows coordinates specify projection parallel region lies image left object rotates depth different region object parallel image plane 
right regions object parallel movement head explore surface surface explore may thought euclidean running serious contradictions full excursions 
plane 
coordinate specifying parallel region rotated respect image plane 
rotational degree freedom parallel region construction 
coordinate specifying scaling parallel region equivalently projection entire object 
combined coordinates determine part surface object currently parallel image plane dimensional coordinate system fully specifies pose object shape object known 
choice coordinates virtues 
contrast euler angles example coordinates considered separately order 
obvious rotation coordinate clear coordinate thought counter rotation camera optical axis 
crucial issue addressed kind coordinates span surface object tracked 
possible coordinate systems specifying location convex surface example latitude longitude angles 
challenge coordinates related projection object knowledge shape 
magical coordinate system technically point dimensions objects estimated proceeding 
suspending disbelief moment consider setting euclidean coordinate system surface thought flattening surface plane standard rectangular coordinates 
course isn possible flatten surface way introducing inconsistencies 
anyway coordinates surface object lie parallel region map image plane simply just scaling plane rotation 
try relate coordinates region relate small steps image plane small steps surface object integrate surface coordinates needing know actual shape object 
discussion imposes conditions 
able determine part projection object originated surface parallel image plane 

path parallel region traces surface object lie strip thin relative curvature object 
wider strip euclidean strip full excursion matter thin condition tractable addressed shortly 
regard second condition practice estimated curvature object factored surface coordinate system argument kinds movements accuracy estimate matters 
answer expected tracking accuracy insensitive estimate shape movements combining plane translation scaling translation depth rotation rotation depth surface patches successively parallel image plane lie strip 
includes important case turning away turning back approximately symmetric manner 
pose detector human face rich structure admit possibilities pose recognition frontal pose 
approximate bilateral symmetry human body projection face close symmetric pose 
relatively clear cut features face eyes nose pose relatively easy detect 
pose special behavioral status attentive orienting occurs frequently face face human robot interaction domain interest 
profile view 
head defined silhouette yaw particularly nose 
hair line 
wang wang argue hair line indicative pose 
recognition trajectories 
different possibility output relative tracking feature right 
movement head strongly constrained neck possible constraints may tight give unambiguous interpretations certain types head movement particularly enriched knowledge head outline 
frontal pose option adopted 
profile problematic extracting accurate orientation silhouette changes slowly changes roll yaw 
hair line variable subjects 
trajectory recognition practice require great deal training data learn priors clear 
outline head tracked collection techniques typical real time systems image differencing ellipse fitting 
implementation described qualitatively similar smith smith traces back birchfield birchfield 
head outline tracked head needs detected place 
head movements marked translational component 
particularly case walking scene perfect time initialization 
movement relatively easy distinguish head body background image differencing 
simple template tracker assigned largest blob detected way 
image modeled generated overlaying layers body layer moving tracker background layer stationary 
pixel independently assigned layers intensity difference pixel predicted location previous frame layer 
gives cleaner persistent outline body raw image differencing discounts fraction pixels moving objects background 
outline cleaned various heuristics implemented viterbi optimization scanlines 
probes sent directions point close top body characterize outline particular identify location head 
probes filtered eliminate wander back body oriented ellipse fit remainder 
shows example 
finding outline head detected 
probes shown small crosses location near top head body shown circle 
large range scales silhouette head extracted contour points encountered probes matched elliptic model 
snapshots head tracker action 
hair problematic 
included 
individuals great deal hair rightmost ellipse deviate great deal basic shape head 
ellipse fit interior initialize color histogram 
tradeoff trying include hair color histogram avoiding including background 
necessary err side caution include contents entire ellipse histogram meant hair color included 
shows examples kind variation lead putative head outline means 
low resolutions real time performance mandates researchers attempt locate eyes fact generally somewhat associated pixels tend darker surrounding skin 
face may unevenly illuminated difficult translate model statement pixel intensity color thresholds example 
statement intensity color differences tractable sinha differential measure subject noise small regions eyes 
approach adopted relative measure support extended large fraction face 
paths different points face considered path assigned cost sums distance individual pixels simple model skin color mentioned eyes relatively poorly illuminated overhead path example points 
grid laid area points shown 
orientation shown path starts left moves successive grid intersections shown moving right moving step giving maximum slope 
analogy hmms step right time step possible vertical level state transition matrix sparse entries state 
simple cost function described text optimal path efficiently computed viterbi lattice structure 
grid resolution shown artificially low clarity 
path picked left just easily gone eyes relevant localization 
light intensity factored 
paths pass eye higher cost paths detour eye 
viterbi calculation assign optimal paths pairs points opposite sides face searching paths remain face don exceed maximum curvature see 
paths computed half pixels face 
paths combined localize eyes correspond regions avoided paths 
series heuristic tests paths avoided regions serve distinguish actual eyes regions simply quite attractive neighboring area 
pairs avoided regions roughly aligned horizontally considered 
regions give reasonable estimate deviation horizontal angle eyes useful initializing roll 
location bridge nose serves useful origin surface face 
degree symmetry estimated see pose close zero yaw initialization practical 
pitch initialized comparing bridge location head outline determined head tracker 
estimated size eyes distance dimensions head outline contribute estimate size head code reliable 
size estimate relative measure interaction scale factor recovered 
implement pose tracking system coordinate system mesh laid projection head illustrated 
nodes mesh kept correspondence face simple template trackers destroyed misbehave measured set consistency checks recreated 
scaling plane rotation plane translation straightforward compute deformations mesh 
head rotates depth trackers lose support surface tracking occluded destroyed 
new parts head visible trackers assigned surface 
frontal pose recognized number individuals 
noted text roll head problematic parallel image plane recovered directly angle eyes horizontal 
mesh initialization 
mesh initially distributed arbitrarily 
pruned head outline detected heuristics relative motion different parts mesh 
frontal pose detected surface coordinates mesh initialized parallel region part face parallel image plane 
visualization surface coordinates mesh 
mesh colored sign surface coordinate appears halves locked side face 
mesh maintain surface coordinate system follows 
parallel region determined heuristically 
translational component motion eliminated parallel region identified easily flow due rotation peaks motion surface completely parallel parallel image plane 
translational motion accounted normalizing flow relative outline head 
crude procedure works better practice translations rotations head coupled sum parallel region cancel 
exceptions include pure rolls translations depth 
extent parallel region chosen scale heuristic way head outline theory infinitesimally small practice assigned extent useful 
luckily surface distortions nose don cause trouble 
parallel region seen mask overlaid image safe relate image coordinates surface coordinates 
pose recognition events detected manner described previous section choose origin surface initial translation scaling plane rotation surface coordinate system respect image plane 
association represented assigning surface coordinates points mesh lie parallel region augmenting image plane coordinates jointly possess 
parallel region shifts rotation depth new points entering region assigned surface coordinates image plane coordinates transformation easy maintain rotation scaling translation mesh recovered 
independently argument earlier types movements tracked accurate knowledge shape head mesh allows new set trajectories tracked leave portion face visible 
surface coordinates points mesh covering part face landmarks 
recovery location head straightforward knowledge camera parameters course scale depth ambiguity absolute depth information recovered 
recovery orientation equally straightforward shape dependent 
output tracker effectively procedure turning specified point surface object camera rotating specified degree 
convert euler angles example requires knowledge shape object surface points associated vectors center head taken 
point estimates dimensions head head tracker conversion simple ellipsoidal model 
crucial point inaccuracies process feed back tracker 
evaluation system tested data set available sclaroff la cascia consisting video head movements ground truth measured flock birds sensor subjects heads 
sequences frames duration 
test stability tracker long intervals sclaroff sequences artificially extending looped forward back iterations 
shows tracking results sequence appeared largest rotation depth case unfortunately eyes occluded better demonstration advantages system developed 
angular measurements limited accuracy initialized turns roll yaw pitch 
re initialization events estimates pose contain discontinuities drift corrected brought 
dealt estimation pose pre recorded video sequence vision interface discontinuities unavoidable 
best estimate current pose truly change instantaneously initialization occurs point propagating information backwards previous frames real time interaction background processing going high latency 
empirical estimated frame index yaw empirical yaw estimated frame index roll empirical roll estimated frame index results sequence containing yaw movement horizontal translation parameters remaining basically unchanged slight roll 
top row shows ground truth 
second row shows estimated pose parameters change significantly sequence 
estimated coordinate left terms image plane 
values plotted averaged occurrence particular frame single tracking run constructed sequence played played reverse repeated iterations 
error bars show standard deviation estimates frame 
error angles case means roll estimate noise 
tracking object cube 
robot familiar purple green face cube 
tracking cube flat track faces revealed views object 
chapter words working speech trouble having open mind course people insist coming trying put things 
speech sounds form special category percept speech cultural invention 
properties simply agreed grounded immediate physical necessity course physical constraints speech space huge potential diversity 
fact communication protocol speech flexible 
special schemes talking children pets 
quite easy imagine borrow schemes robots 
goals kismet robot group evoke style speech functional benefits 
robotics projects looking various aspect speech development vocabulary grammar various forms experience roy pentland steels 
goal chapter produce real time system extending vocabulary augmented slower offline process refinement just case object recognition chapter 
microphones natural language interface desirable component humanoid robot 
ideal allows natural hands free communication robot necessitating special skills human user part 
practice trade flexibility interface robustness 
trade physical interface 
best results contemporary speech recognition techniques high quality microphone close mouth desirable 
kismet wireless clip hand held microphone shown 
caused difficulties kismet anthropomorphic face prominent bright pink ears people expected robot able hear directly intermediary 
unfortunately placing microphones ears head completely useless motors controlling facial features noisy ear motors 
cog microphone array installed torso 
meant person interacting robot need instrumented natural human behavior want heard speaking louder coming closer fact robot hear better 
background noise high auxiliary wireless microphone subsumes microphone array 
kismet clip hand held microphone left 
interacting robot needed informed 
experience showed people frequently forget microphone clipped intuitive interface face face communication 
cog commercial microphone array installed right clip microphone available excessive background noise cog located right busy machine shop 
meant robot respond voice vicinity responses poor human move closer speak louder natural responses pick back microphone 
transition microphones handled automatically 
infant directed speech crucial factor suitability current speech recognition technology domain expected perplexity sentences drawn domain 
perplexity measure average branching factor space possible word sequences generally grows size vocabulary 
example basic vocabulary weather related queries may quite small dictation may larger constrained grammar 
case speech recognition applied successfully large user population noisy telephone lines zue second quality headset extensive user training required practice 
important determine robot directed speech lies spectrum 
presumably depend nature task robot applied character robot 
evaluated kismet 
interacting appearing robot kismet hope speech input may specialized characteristics similar infant directed speech ids 
particular interested speech directed kismet include substantial proportion single word utterances 
presenting words isolation side steps problematic issue word segmentation 
speech clearly enunciated slowed compared normal speech 
speech may helpful infants challenging artificial speech recognizers trained normal speech 
isolated words parental speech help infants learn matter debate 
shown infant directed utterances usually short longer pauses words see example 
necessarily contain significant proportion isolated words 
study brent siskind presents evidence isolated words fact reliable feature infant directed speech infants early word acquisition may facilitated presence 
particular authors find frequency exposure word isolation better predictor word learned total frequency exposure 
suggests isolated words may easier infants process learn 
equally importantly evidence substantial presence isolated words ids brent siskind reported 

kismet achieves purpose eliciting behavior humans expect similar proportion kismet directed speech consist single word utterances 
tendency humans slow utterances meet misunderstanding reported problem asr community hirschberg 
enunciated speech degrades considerably performance speech recognition systems trained natural speech 
find human tend address kismet speech presence important issue addressed robot perceptual system 
study interactions young children kismet robot context teaching robot new words 
sessions organized mit initiative technology self 
sessions robot engaging proto conversational turn responses utterances children random affective babble 
minimal mechanism vocal mimicry vocabulary extension 
purpose study identify ways improve speech interface robot better knowledge properties speech directed particular robot 
experiments robot engaging proto conversational turn described breazeal augmented command control style grammar 
sentences began phrases say say try treated requests robot repeat phonetic sequence followed 
robot repeated sequence positive phrase robot heard sequence entered vocabulary 
action taken human utterance similar case assumed correction robot repeat 
relatively low accuracy phoneme level recognition corrections rule exception 
video children aged years old interacting robot analyzed 
session lasted approximately minutes 
sessions children playing robot time 
rest sessions child robot 
interested determining strategies kismet directed speech single word utterances words spoken isolation enunciated speech vocal shaping partial directed corrections vocal mimicry kismet babble total utterances transcribed sessions children playing robot 
observed wide variation strategies subjects 
preliminary results include measure standard deviations mentioned give idea wide range data read imply data follows gaussian distribution 
total number utterances varied subject subject range mean standard deviation sample utterances subject 
isolated words fairly common utterances consisted single word said isolation 
percentage single word utterances distribution subjects mean deviation 
exclude greetings robot name counts single word utterances get distribution centered standard deviation 
accounts substantial proportion recorded kismet directed speech 
half subjects isolated words teaching context 
enunciated speech common enunciated speech transcribed utterances contained enunciated speech 
utterance counted enunciated speech deliberate pauses words syllables word vowel lengthening 
count includes frequent examples subject ask robot repeat word kismet say green 
examples green enunciated part utterance question counted containing enunciated speech 
mean proportion enunciated speech deviation shows large variation 
vocal shaping body data discovered plausible instances vocal shaping 
may important teaching strategy may evoked mimicry system responding reliably teacher 
vocal mimicry cases children imitating babbling sounds kismet accounts transcribed utterances 
children strategy 
discussion interaction sessions set controlled experiments necessarily represent spontaneous kismet directed speech 
particular occasions point interaction children instructed currently implemented command system get robot repeat words 
cases happened subject concerned getting robot repeat word simply disappeared interaction 
occasions subjects instructed say keyword soon sat front robot 
subjects clearly focused teaching scenario expect proportion isolated words instance high 
note measure accuracy transcriptions done hand transcriber audio poor quality 
focus analysis kismet directed speech noted interaction excluding conversations child may humans session 
deciding utterances transcribe clearly judgment call validate 
speech transcribed hand claim scientific definition utterance pause duration rely person judgement call 
preliminary analysis shows promise instances isolated words kismet directed speech suggesting kismet environment may word learning 
fluent speech prevalent teaching scenario unsupervised learning algorithm needed find new words case 
substantial proportion speech enunciated 
counter intuitively speech problems speech recognizer time opens new possibilities 
improved word learning interface may possible discriminate natural enunciated speech detect instances pronunciation teaching approach taken asr community example hirschberg 

hand strategy vocal shaping clearly interactions cases mimicry 
automatic language modeling section develops technique bootstrap initial vocabulary distilled isolated word utterances building explicit model unrecognized parts utterances 
purpose background model improve recognition accuracy initial vocabulary automatically identify candidates vocabulary extension 
draws research word spotting speech recognition 
bootstrap minimal background model similar word spotting stronger model word phrase clusters moved foreground explicitly modeled 
intended boost performance original vocabulary increasing effectiveness language model identify candidates automatic vocabulary extension 
remainder section shows conventional speech recognizer convinced cluster frequently occurring acoustic patterns requiring existence transcribed data 
clustering algorithm speech recognizer phone oov vocabulary model able recover approximate phonetic representation words word sequences vocabulary 
commonly occurring phone sequences located adding vocabulary allow language model capture occurrence words original vocabulary potentially boosting recognition performance 
suggests building clustering engine scans output speech recognizer correlates oov phonetic sequences utterances updates vocabulary frequent robust phone sequences finds 
feasible kind judgments clustering engine needs acoustic similarity alignment exactly speech recognizer adept 
clustering procedure adopted shown 
ngram language model initialized uniformly 
unrecognized words explicitly represented phone oov model described section 
recognizer run large set data 
phonetic word level outputs recognizer compared occurrences oov fragments assigned phonetic transcription 
randomly cropped subset tentatively entered vocabulary attempt evaluate significance occur frequently similar existing vocabulary 
hypotheses recognizer retrain language model making sure give new additions probability model 
recognizer runs new language model process iterates 
recognizer output evaluate worth new vocabulary entries 
sections detail eliminate vocabulary items recognizer finds little detect resolve competition similar items 
extract oov fragments add lexicon hypothesized transcript run recognizer identify additions remove lexicon best hypotheses update language model identify competition update lexicon baseforms iterative clustering procedure segmenting speech 
conventional speech recognition system evaluate useful particular phoneme sequences describing training data 
useful sequences added lexicon dropped 
extracting oov phone sequences speech recognizer system developed spoken language systems group mit glass 
recognizer augmented oov model developed glass 
model match arbitrary sequence phones phone bigram capture phonotactic constraints 
oov model placed parallel models words vocabulary 
cost parameter control oov model expense vocabulary models 
value fixed zero experiments described convenient control usage level language model 
bigram project exactly glass training particular domain 
phone sequences translated phonemes inserted new entries recognizer lexicon 
dealing rarely additions phoneme sequence introduced vocabulary common sound sequence acoustic data recognizer pick iteration 
just appear hypotheses 
iteration histogram phoneme sequence occurrences output recognizer generated threshold cut 
dealing competing additions similar phoneme sequences added vocabulary 
sounds represent fact commonly occurring interchangeably recognizer 
unfortunate language modeling purposes statistics pooled robust 
happily output recognizer situations easy detect 
particular kind confusion uncovered analysis best utterance hypotheses 
imaging aligning set best hypothesis sentences particular utterance competition indicated vocabulary items exhibit properties horizontally repulsive items appears single hypothesis appear nearby location hypothesis vertically attractive items frequently occur location different hypotheses utterances domain generally short simple prove necessary rigorously align hypotheses 
items considered aligned simply vocabulary items preceding succeeding 
important measure attractive repulsive conditions distinguish competition vocabulary items simply occur close proximity 
accumulating statistics properties utterances gives reliable measure vocabulary items essentially acoustically equivalent recognizer 
merged pruned statistics maintained language model trained 
clear cut cases competing items merged alternatives list pronunciation variants single vocabulary unit 
item simply deleted appropriate 
example process operation 
example phone keyword initial vocabulary 
best hypotheses utterance phone number victor zue oov phone oov phone oov phone uw oov phone oov phone oov phone oov oov oov phone oov phone uw oov symbol corresponds vocabulary sequence 
sequences parentheses uses items added vocabulary prior iteration algorithm 
single utterance acquire evidence entry ax aa ah may competing keyword phone 
holds statistically utterances entry destroyed 
ah er er axr ah er may competing 
compared followed sequence ih er preceded word phone 
uw uw uw may competing patched iteration 
best utterance hypotheses reminiscent application computing measure recognition confidence hazen 
testing convergence iterative procedure important know 
collection transcribed utterances track keyword error rate data halt increment performance sufficiently small 
keywords refer initial vocabulary 
transcribed data directly measure error rate 
bound rate changing comparing keyword locations output recognizer iterations 
keywords shifting location error rate changing certain bound 
place convergence criterion bound actual keyword error rate 
important just measure changes keyword locations changes vocabulary items added clustering 
offline vocabulary extension unsupervised procedure described previous section intended improve recognition accuracy initial vocabulary identify candidates vocabulary extension 
section describes experiments demonstrate degree goals achieved 
facilitate comparison component asr systems results quoted domain called glass weinstein developed spoken language systems group mit 
domain consists queries personnel addresses phone numbers preliminary results kismet directed speech 
results clustering session initial vocabulary keywords email phone room office address run set utterances 
transcriptions utterances available testing clustering procedure 
top clusters discovered typical run ranked decreasing frequency occurrence ah er iy eh ih ae ng uw ah ih ow eh iy hh aw ax aw ix uw uw clusters consistently recognizer places corresponding number tell please group respectively transcription 
ah er frequent phrases phone number room number office number 
appears cluster language model immediately able improve recognition performance keywords 
clustering parasite appears dh ax ow instance phone recognizer fails spot iy eh email 
potential interfere detection keywords resemble acoustically 
soon success detected eliminated described earlier 
possible parasite doesn get greedy example limits person pronunciation keyword detected didn see examples happening 
experiments involving small vocabularies appropriate measure performance terms keyword error rate ker 
taken keyword error rate baseline performance performance clustering coverage keyword error rate baseline recognizer clustering recognizer total coverage varies 
ker number false poorly localized detections number missed detections true number keyword occurrences data detection counted occurs right time 
specifically midpoint hypothesized time interval lie true time interval keyword occupies 
take forced alignments test set ground truth 
means testing better omit utterances artifacts words outside full vocabulary forced alignment sufficiently precise 
experiments designed identify clustering leads reduced error rates keyword vocabulary 
form clustering addressed fundamentally extending vocabulary expect little effect vocabulary large give coverage 
expect offer greatest improvement vocabulary smallest 
measure effect coverage complete vocabulary domain smaller smaller incrementally removing infrequent words 
set keywords chosen kept constant vocabulary experiments results confounded properties keywords 
set keywords previous section 
clustering performed making transcripts 
truly eliminate dependence transcripts acoustic model trained different dataset 
reduced performance easier interpret results 
shows plot error rates test data size vocabulary varied provide different degrees coverage 
striking result clustering mechanism reduces sensitivity performance drops coverage 
scenario error rate achieved full vocabulary gives coverage training data 
coverage low clustered solution error rate remains relative terms error increases half best value 
straight application language model gives error rates double treble error rate 
destroy green robot spaghetti yellow ih ao iy ae ay ow ao ix eh iy eh aw ih oy iy ae ay ow ao ax eh iy eh ow ih ay iy ae ay ow ao ix eh iy ae ow ao iy ae ay ow aw iy ax eh ow dh ax ao iy ae ay ow ao ix eh ax aw dh ax oy iy ae ay ow ae ix ih eh aw ih ao iy ae ay aw ao ix eh iy ey ao iy ae ay ow aa dh ey ao iy ae ay ow aa ih ao iy ah ay ow ah ih ay iy ae ay ow ae iy ae ix ay iy ae ay converging vocabulary 
top row shows english words spoken robot repeatedly 
second row shows phonemic version words robot chose 
remaining rows show transcripts individual utterance 
version chosen robot speaks recognize words close variants corresponding word 
person says spaghetti robot hears ix ih recognize mimic word ix eh iy 
clearly limit size robot vocabulary necessary trade current state art 
point keyword error rate language model trained full vocabulary full set transcriptions acoustic model trained available data gives ker 
experiment carried data drawn robot directed speech collected kismet robot 
data comes earlier series recording sessions described breazeal 
semantically salient words kismet sorry robot okay appeared top clusters 
real time vocabulary extension actual operation ideally new vocabulary items added instantaneously extracted slow offline procedure 
achieve robot simpler vocabulary extension mechanism novel isolated words mimicked back immediately robot added lexicon 
words heard grouped weak measure similarity statistics pairs phonemes words common see 
similar sounding words merged accepted difficult reliably differentiate anyway 
sense robot permit sufficiently different sounds converge vocabulary 
method appropriate desired working vocabulary point relatively small number words 
really supported noisy environment user specific training placed microphones anyway 
initially behavior achieved dynamic vocabulary api ibm 
proved simpler raw phonemic recognition external viterbi alignment procedure ideally merged speech recognition system optimal performance 
stabilized perceptual interface just object recognition system discussed chapter recognized words communicated rest system stabilized interface 
vocabulary items created assigned unique feature line meaning feature line conserved possible line respond situations past 
offline clustering done refine online vocabulary grouping 
initially done regard stabilized interface shelf clustering algorithms step models compared previous models aligned appropriately 
chapter interpersonal perception thing anyway said dean inspecting implement hands 
called said senior 
seen 
stick sharp ground 
gets bit technical harnad argues creatures learn categories objects entities theft 
sensorimotor term trial error learning guided corrective feedback consequences inherently expensive terms time risk 
linguistic theft hand allows categories passed individuals reduced cost recipient 
harnad concerned arguing theft way grounding 
thesis robot far doing lot interesting see start doing theft 
goal chapter build tools necessary robot familiarize novel activities 
automatic action understanding currently limited social interaction scaffolding learning process steal structural information activities cooperative human 
learning activities important provide tools exploring environment 
chapter showed built poking activity robot reliably segment objects background similar appearance poking 
determine shape object boundary special situation normally 
desirable feature activities learning provide special enabling contexts 
fact key creating open ended developmental cycle see 
particular familiar situations allow robot perceive objects object properties perceived outside situations 
objects properties tracked familiar situations characterized discovery 
just segmented views provided poking objects actors poking collected clustered discussed chapter provided precisely needed train object detection recognition system tracking objects provides exactly needed learn activities turn learning 
constraint familiar activity discover unfamiliar entity familiar activities reveal structure unfamiliar activities tracking familiar entities familiar entities objects actors properties robot engaged known activity top may sufficient constraint identify novel elements activity bottom 
similarly known elements take part unfamiliar activity tracking help characterize activity 
potentially development open ended loop discoveries 
familiar activities learn components activities example object struck poking tracked novel activities robot familiar activities turn learning 
learning activity intersection communication perception development encompasses established fields research example language acquisition 
observed language acquisition involves search large search space models guided relatively sparse feedback examples 
called poverty stimulus relative complexity models acquired taken imply infants search strategy biases matched nature appropriate solution 
claim innate constraints historically controversial 
examples stressing determination language learning include quine example quine quine invites imagine walking native guide foreign country seeing rabbit pass just guide says consider possible meanings utterance 
pragmatic constraints offer way sea ambiguity 
example markman proposes set particular constraints infants map words meanings 
constraints style variations elaborations caveats object assumption 
adult labels assume referring object part 
taxonomic assumption 
organize meanings natural categories opposed thematic relationships 
example child asked find dog may fetch cat won fetch dog food 
mutual exclusivity 
assume objects label 
look unnamed object new label applied 
constraints intended explain spurt vocabulary acquisition infants acquire words examples called fast mapping 
advanced absolute rules biases search 
tomasello raises objections constraint approach represented markman tomasello 
tomasello favors social pragmatic model language acquisition places language context joint referential activity shared attention 
rejects word meaning mapping formulation language acquisition 
tomasello proposes role activity verbal context object identity physical location physical appearance perceptual judgements fundamentally identity different 
identity judgements depend activity location appearance verbal context 
turn influenced teacher 
language invite experience world particular way 
tomasello social pragmatic approach problem referential indeterminacy begins rejecting truth conditional semantics form mapping metaphor child maps word world adopting view language linguistic symbols human beings invite experience situations particular ways 
attempting map word world help situations piece real estate may called shore coast ground beach 
regardless utility tomasello theory proper domain language acquisition infants useful mindset tackling interpersonal perception essence inviting robot view world particular way 
tomasello collaborators developed series experiments designed systematically undermine constraints approach learning typified markman 
experiments investigate word learning children context various games 
experiments instructive showing range situations simple rules directly gaze affect fail case 
experiments avoid giving children months old naming contexts requiring pull meanings flow interaction 
example experiment adult eye contact child subject says go find toma toma nonsense word child heard 
go row buckets contains object child familiar 
objects randomly designated toma 
session control adult goes directly bucket containing toma finds hands child 
adult goes buckets sequence time object replacing finding toma 
child tested ability comprehend produce new word appropriately 
results show equally performance test control scenarios 
tomasello argues situation counts children simple word learning rules object adult looking saying novel word new object adult looks saying novel word new object infant sees hearing novel word variants 
tomasello theories experiments provocative suggest approach quite different simple associative learning seen robotics 
interpersonal perception cog draws heavily grossly simplified caricature ideas 
basic idea interpersonal perception drawn tomasello information identity object needs easily transferred perception activity location speech appearance 
flexibility hard imagine scenarios experiment described proposed tomasello dealt 
places objects words currently unreasonable expect robot understand flow interaction help 
unaided segmentation activity challenging problem see goldberg mataric effort robotic domain 
human interacting robot greatly simplify task making structure activity unambiguous 
mechanisms particularly easy deal vocalizations location 
places words consistently activity straightforward model basic flow interaction define 
robot verbal chatting behavior augment object directed poking behavior developed 
vocabulary extension mechanism developed chapter egocentric map developed chapter ability recognize objects developed chapter 
robot hears word fixating particular object word heard context word associated object 
happens times association permanent session 
invocation object name triggers egocentric map drive eyes known location object foveal object recognition module search object visually see 
simple naming capability serves baseline rest chapter show robot learn new opportunities associating names objects situations showing 
learning structure novel activity robot learn activity able learn activity 
remain restricted set built activities provided programmer 
ideally possible demonstrate task robot learn 
mentioned unaided segmentation activity challenging problem machine perception 
productive see activity segmentation explicitly communicated robot learns autonomously 
individual parts task may difficult describe formally structure control flow amenable simple description 
example branchand loop flow sorting task easily expressed actual sorting criterion may depend differentiating classes objects small difference appearance easier demonstrate describe 
go ahead communicate task structure robot guide interpretation easily expressed components 
shows schematic may achieved 
basic idea robot interact instructor acquire sequencing model task ground model demonstration task 
demonstration annotated instructor terms sequencing model terms previously grounded elements 
human tutor demonstrates task expected verbalize activity 
initially robot physical demonstration process speech stream attempt recover structure task 
particular robot attempt determine states task points demonstration returns effectively association car 
association invocation car 
invocation ball 
ball 
association invocation egocentric map 
robot looks object recognizes head rolls look 
word spoken point car ball top frames note human bringing robot attention object hand word associated object robot viewing 
word spoken lower frames note human standing back interacting speech robot queries egocentric map known location associated object turns looks object 
training data instructor demonstrated task task modeling task grounding perceptual system task learning mechanism sequencing model state grounding perceptual network model task segmentation 
instructor demonstrates task providing verbal annotation 
vocal stream construct model task 
generic machine learning methods ground model robot perceptual network guided feature selection input human 
idea avoid presenting robot hard learning problem learning algorithms intended decoders allowing human communicate changes representation learn conventional sense 
mode 
straightforward human tutor speaks simple vocal labels corresponding actions configurations objects tutor finds mnemonic 
type labels need pre specified vary word word 
method recover task structure gram modeling procedures developed speech recognition methods murphy chosen simple easily predicted behavior 
estimate probability event sequences models trained sequence frequency counts corpus 
models vary amount history incorporate bigram models trigram models low order models limited dependencies capture trained relatively little data 
high order models expressive harder train 
best results achieved gram models different orders interpolated amount training data available context see simulated example 
robot model task structure goal relate actual physical demonstration human tutor making 
machine perception necessarily noisy full ambiguity 
degree task fundamentally limit complexity modeling robot permit uncertainty compound uncertainty 
establishing task model relatively noise free protocol depend error correcting feedback human tutor limit impact uncertainty grounding element model 
shows example sorting activity implemented robot kismet 
note words robot needing know meanings sufficient consistently structure task obvious 


top row shows simple artificial sequence task segmentation system 
purposes visualization current estimate task structure converted state machine rendered automatically graphviz gansner north 
initially sequence interpreted alternating left 
data available model expands incorporate fact second order alternation right 
human speech human action robot speech robot action 
say yellow shows yellow toy yen looks toy say yellow 
say green green 
yellow shows yellow toy looks toy left moves toy left left tracks toy green shows green toy green looks toy right moves toy right right tracks toy yellow shows yellow toy looks toy left moves toy left left tracks toy 
yellow shows yellow toy looks toy 
left 
nods left 
moves toy left left 
green shows green toy green looks toy 
right 
nods right 
moves toy right right 
left extracts dialogue kismet 
extract say yellow 
illustrates robot active vocabulary extended 
cog replaced automatic mechanism described chapter 
second extract shows simple sorting activity annotated robot 
final extract shows robot tested understanding form activity 
robot utterances transcribed phonetically written simple form clarity 
right shown simple state machine model activity deduced robot graph drawn hand 
right green learning rules novel activity structure learning mechanism previous section useful person interacting robot cooperative choice vocabulary fact overkill 
deal nested activities activity suspended temporarily deal example sorting behavior person wants check robot knows name object 
transferring mechanism kismet cog emphasis shifted learning global task structure learning local rules grow support long distance interactions 
cog seeing objects hearing words treated basic events system 
robot continually searches useful new ways describe events useful means having predictive power 
events considers conjunctions events noted occur frequently rarely occur event called conjunction formed 
event defined occur events fact occur 
formation event simply means statistics related tracked 
event formed doesn matter conditions creation cease hold 
disjunctions events noted occur frequently occur independently situations event called disjunction formed 
event defined occur original events occur 
implications causal versions events exist sensitive event order timing 
composite events intended allow robot meaningful generalizations allowing physical event viewed ways sensitive past history 
demonstrates generalizations solve tomasello experiments linking object name extended search activity 
searches robot fairly strict script word find uttered name object search mentioned 
series objects fixated 
word uttered object target search 
word indicates search succeeded object currently fixated target search 
facts discovered event generalization 
word spoken find gets special implication event associated call word find course symbols internally word find initially special significance replaced word seek 
search object name robot knows pre established disjunction noted simultaneous event find 
object seen object said matches implication formed 
implication sufficient link unknown word find object seen said find generalizations choice word special significance replaced frob 
rule learning mechanism integrated full cog code base search activity simpler learn requiring generalization 
chatting behavior robot internal state track hears name object looking direct gaze object 
structure built robot simply map search activity just observations find followed mention absent object said previously absent object view generalizations built robot state sufficient achieve tomasello scenario 
human speech human action robot speech robot action 
say shows ball say looks ball beh ball say shows car say looks car car say shows cube say looks cube cube say say waits cube shows ball looks ball say say waits ball 
attracts attention looks person find find ball ball shows cube looks cube shows car looks car shows ball looks ball 
attracts attention looks person find find toma toma shows ball looks ball shows cube looks cube shows bottle looks bottle say shows cube say looks cube cube say shows bottle say looks bottle toma 
extracts dialogue cog 
robot taught name object looking word say spoken 
done speaking word prompting robot short utterance beh example 
short utterances prompt robot take responsibility saying sees 
link formed say prompting say alternate way prompt robot 
robot shown instances searching object name knows example ball target 
robot shown instance searching unfamiliar object name mentioned toma 
allows demonstrate learned structure search task correctly linking unfamiliar name toma target search bottle 
ideally match tomasello experiment objects search unfamiliar done 
infant case leave open possibility infant associated unfamiliar word unfamiliar object saw 
robot case access internal operations know cue 
task structure allow robot perceptual biases overruled 
example objects differentiated robot purely color histogram 
cause problems object looks different different sides toy cube top 
views united task treated way example performing action cube toy 
distinct objects treated robot color similarity ball baseball cap bottom difference exaggerated differently task 
limitations extensions limitations activity learning described chapter including cues robot sensitive impoverished relative human infant perceive 
example direct representation teacher perception prosody non verbal cues 
multiple activities share similar vocabularies potential interference 
issue capturing activity context addressed 
basic events word object occurrences capture kind real world events possible 
robot respond non speech sounds changes distance infinite possible events simply word object appearances 
deal point simple mechanism developed get robot attention unnamed feature feature combination opposed simply object periodicity detection 
perceptual features cog monitored second time window detect occurrence periodicity 
desired robot attend color objects opposed identity size example objects contrasting colors simply parameter parameter parameter parameter searching correlations robot perceptual features 
joint probability distribution pairs features estimated compared product independent distributions 
shows top correlations experiment robot applied actions object tapping side away 
highest ranking correlation left captures physical constraint angle approach moment impact 
correlation right captures gross displacement object away robot function type gesture correlation noisy erratic motor control 
verbal annotation actions correlation enhanced tagging failed actions removal selected 
shown robot 
periodic signal oscillation increased salience channel manner similar behavioral influences kismet breazeal scassellati 
time writing strongly integrated activity learning mechanisms 
idea influencing robot perception shared activity developed 
perception completely objective process choices 
example objects judged depends features considered essential considered incidental 
robot useful draw distinctions human task 
achieve mechanisms allow robot perceptual judgements teacher 
useful situations robot abilities simply challenge need helping hand 
structure tasks communicated robot possible high level structure modify robot perception 
easiest see case modifying biases pre existing abilities robot 
example emphasize difference objects robot sees identical draw connections different views object robot sees distinct see 
generally task structure initialize set focused problems machine learning divergent paths task treated labels initially unknown physical features cause divergence 
correlating features robot perceptual space labels select contribute decision train classifier 
shows example searching correlations robot perception poking behavior 
summary chapter shown circle development possible see 
want robots able cope novel tasks need deep understanding activities 
treat range naming situations robot deal test depth understanding 
consider search robot understands purpose searches succeed fail naturally extends range naming situations deal poking chatting objects words names poking chatting search search objects words names search poking chatting search objects words names chapter developed specific example circle development 
poking allows robot explore objects chatting allows names associated objects 
robot tracks named objects human demonstrates search task learning structure search examples 
robot uses knowledge new way learn names objects having see object hear name simultaneously case chatting 
simple associations chapter showed 
infant development literature considerable emphasis placed child ability interpret behavior terms intent theory mind 
ability powerful computational viewpoint processes branches loops sequences 
alternative route establish initial shared perspective human robot potentially complement theory mind approach example scassellati cog 
activity learning system described meanings words grow role activity 
search activity come denote presence absence respectively search target 
scenario may denote entirely different 
example possible train robot keep holding arm said drop hearing case words denote action termination respectively 
plasticity means avoid problem trying form global theory meanings word take 
richer meanings possible multiple word utterances permitted roy isolated words dealt chapter 
interesting direction research derive grammatical forms compression structure extended activity single sentence 
chapter directions worth having philosophers place 
minute truth beauty beauty truth falling tree forest sound hear just think re going start dribbling em says incidentally putting foot parabolic reflector high place shoot rays sun enemy ship interesting demonstration optical principles thesis motivated transience 
humanoid robots sophisticated mechanically perceptual abilities severe limiting factor 
absence perfect perception important simple experimental methods resolve ambiguity methods derive information clumsy actions repeated 
active segmentation example 
may expect humanoid robots need considerable flexibility task robot may change day day 
best build adaptivity 
thesis steps building perceptual system robot grow develop contact world 
theoretical effort show example adaptive modules persistent interfaces practical effort identifying engineering opportunities robot develop see 
areas explored part complementary development robotics metta roy pentland weng 
chapter summarizes specific contributions identifies important directions research 
summary significant contributions active segmentation thesis showed passive methods object segmentation augmented physical exploration 
appearance catalog appearance small low level features exhaustively characterized thesis showed oriented features results competitive classical model driven approaches 
open object recognition robot important integrate object recognition mechanism new objects far objects world algorithms training data robust perception algorithms opportunities training data algorithms robust perception route autonomy switch emphasis collecting training data top engineering methods create exploit opportunities collecting labeling data autonomously 
reasonably catalogued 
thesis showed false detections serious problem distracting objects simply enrolled modelled explicitly having come accurate background model 
affordance recognition robot sense switch object centric perception recognizing action opportunities 
concrete example rolling affordance particular importance robot needs manipulate awkward objects 
collaboration giorgio metta 
open speech recognition speech recognition trade recognition accuracy vocabulary size 
thesis assumes time vocabulary robot needs small task dependent 
creating explicit run time mechanisms vocabulary modification robot quickly vocabulary appropriate current task needing large pre existing vocabulary 
circle development familiar activities identify components roles activities 
components tracked unfamiliar activities discover structure activities 
processes dovetail give circle development 
grounding operational definitions thesis appearances objects manipulators characterized operational definitions 
definitions translate measurements operational definition procedure agreed translation concept measurement kind 
deming effective procedure finding objects seen physically coherent structures poke see moves 
effective procedure finding manipulators defined acts objects watch objects 
course procedures completely general worth generalizing 
example active segmentation gives clear results rigid object free move happens non rigid objects objects attached objects 
results poking complicated robot jeff weber 
interpret sense sign just cases idea object defined 
poking potential offer operational theory object hood tractable vision approach give better true nature physical 
fully autonomous platform cog kismet fixed platforms access limited environment 
new project humanoid robotics group ai lab seeks remedy see 
project combines important threads mobility robot modified base expressiveness robot head simple face eyes dexterity robot arms 
combines elements needed autonomous object exploration activity learning 
philosophy thesis focused primarily learning perception complementary cog addresses learning action marjanovi 
animals robots perception fundamentally action perceptions ideas analysis factual significance meaning terms ultimately overt operation 
meaning derives potential effect difference may behavior 
phylogenetic ontogenetic histories mental activity develops overt action 
influenced alternative intelligence enumerated brooks 
development social interaction embodiment integration 
attempts bring threads system show fact reinforce 
strong integration perception action provides means development occur social interaction embodiment provide opportunities 
familiar murder mysteries missing element motive complete treatment topic examine move gracefully training activity goal learn actual performance task goal achieve specific 
bibliography gibson 

development perception affordances 
advances infancy research 
aloimonos weiss 

active vision 
international journal computer vision 
fitzpatrick kemp metta 

world hand active interactive segmentation 
accepted publication proceedings third international workshop epigenetic robotics 
woodward 

models word segmentation fluent maternal speech infants 
morgan editors signal syntax bootstrapping speech grammar early acquisition 
lawrence erlbaum associates mahwah nj 
bajcsy 

active perception 
proceedings ieee 
ballard 

behavioral constraints animate vision 
image vision computing 
ballard 

animate vision 
artificial intelligence 
bard anderson 

speech children effects referent availability 
journal child language 
basu essa pentland 

motion regularization model head tracking 
proceedings international conference pattern recognition vienna austria 
glass 

modeling vocabulary words robust speech recognition 
proceedings sixth international conference spoken language processing beijing china 
beardsley 

qualitative approach classifying head eye pose 
proceedings ieee workshop applications computer vision pages florence italy 
billard 

imitation means enhance learning synthetic proto language autonomous robot 
dautenhahn nehaniv editors imitation animals artifacts 
mit press 
billard dautenhahn 

grounding communication situated social robots 
technical report umcs university manchester 
birchfield 

elliptical head tracking intensity gradients color histograms 
proceedings ieee conference computer vision pattern recognition pages 
black yacoob 

tracking recognizing rigid non rigid facial motions local parametric models image motion 
proceedings international conference computer vision pages 
block 

troubles 
perception cognition issues foundations psychology minnesota studies philosophy science 
bloom 

children learn meaning words 
cambridge mit press 
blumberg 

old tricks new dogs ethology interactive creatures 
phd thesis mit 


causal reconstruction 
technical report aim mit artificial intelligence laboratory 
boykov kolmogorov 

experimental comparison min cut max flow algorithms energy minimization vision 
energy minimization methods computer vision pattern recognition pages 
breazeal 

sociable machines expressive social exchange humans robots 
phd thesis mit department electrical engineering computer science 
breazeal 

recognition affective communicative intent speech 
proceedings international ieee rsj conference humanoid robotics cambridge ma 
breazeal fitzpatrick scassellati 

active vision sociable robots 
ieee transactions systems man cybernetics 
breazeal fitzpatrick scassellati 

social constraints animate vision 
ieee intelligent systems 
breazeal fitzpatrick 

certain look social amplification animate vision 
proceedings aaai fall symposium socially intelligent agents human loop north ma usa 
breazeal scassellati 

context dependent attention system social robot 
proceedings sixteenth international joint conference artificial intelligence pages stockholm sweden 
breazeal scassellati 

infant social interactions robot human caretaker 
adaptive behavior 
breazeal 

teaching robot infant emotive communication acts 
proceedings simulated adaptive behavior workshop 
brent siskind 

role exposure isolated words early vocabulary development 
cognition 
brooks 

robust layered control system mobile robot 
ieee journal robotics automation ra 
brooks 

intelligence reason 
proceedings international joint conference artificial intelligence pages 
brooks 

intelligence representation 
artificial intelligence journal 
originally appeared mit ai memo may 
brooks breazeal irie kemp marjanovi scassellati williamson 

alternative intelligence 
proceedings american association artificial intelligence pages 
brooks breazeal marjanovic scassellati 

cog project building humanoid robot 
lecture notes computer science 
brooks stein 

building brains bodies 
autonomous robots 


speech interpersonal 
cambridge university press cambridge london 
francis kitamura paterson 

little pussy cat 
acoustic phonetic affective qualities infant pet directed speech 
proceedings fifth international conference spoken language processing volume pages 
butterworth 

ontogeny phylogeny joint visual attention 
whiten editor natural theories mind 
blackwell 
canny 

computational approach edge detection 
ieee transactions pattern analysis machine intelligence 
cassell pelachaud badler steedman becket douville prevost stone 

animated conversation rule generation facial expression gesture spoken intonation multiple conversational agents 
siggraph 
yang 

corner orientation detector 
image vision computing 
chapman 

vision instruction action 
technical report mit ai laboratory 
chapman agre 

pengi implementation theory activity 
proceedings sixth national conference artificial intelligence pages 
chen sato tamura 

orientation space filtering multiple orientation line segmentation 
ieee transactions pattern analysis machine intelligence 
chen amd shimada 

head pose estimation color information 
proceedings sixth ieee international conference multimedia computing systems florence italy 
cole yap 

shape probing 
journal algorithms 
colombetti dorigo 

training agents perform sequential behavior 
adaptive behavior 
connell 

colony architecture artificial creature 
technical report mit ai laboratory 


real time head pose recovery model video coding 
proceedings ieee instrumentation measurement technology conference baltimore md usa 
decarlo metaxas 

integration optical flow deformable models applications human face shape motion estimation 
proceedings ieee computer society conference computer vision pattern recognition pages 
deming 

new economics industry government education 
mit center advanced engineering cambridge massachusetts 
dennett 

intentional stance 
mit press 
duda hart 

pattern classification scene analysis 
wiley new york 


analysis clustering algorithms 
technical report university washington 
ferrell 

learning scaffolding 
mit ph thesis proposal 
ferrell kemp 

ontogenetic perspective scaling sensorimotor intelligence 
embodied cognition action papers aaai fall symposium 
aaai press 
firby 

task networks controlling continuous processes 
proceedings second international conference ai planning systems chicago il 
fitzpatrick metta 

manipulation driven vision 
ieee rsj conference intelligent robots systems 
gallese rizzolatti 

coding space inferior premotor cortex area 
journal neurophysiology pages 
pinter 

primitive features steering quadrature scale 
ieee transactions pattern analysis machine intelligence 
freeman 

steerable filters local analysis image structure 
phd thesis media arts sciences mit 
freeman adelson 

design steerable filters 
ieee transactions pattern analysis machine intelligence 
gallese rizzolatti 

action recognition premotor cortex 
brain 
gansner north 

open graph visualization system applications software engineering 
software practice experience 
garland lesh 

learning hierarchical task models demonstration 
technical report mitsubishi electric research laboratories 
gat 

esl language supporting robust plan execution embedded autonomous agents 
plan execution problems issues papers aaai fall symposium pages 
aaai press menlo park california 
gibson 

theory affordances 
shaw editors perceiving acting knowing ecological psychology pages 
hillsdale nj lawrence erlbaum associates publishers 
glass chang 

probabilistic framework feature speech recognition 
proceedings international conference spoken language processing pages 
glass weinstein 

facilitating spoken dialogue systems development 
proceedings seventh european conference speech communication technology aalborg denmark 
goldberg mataric 

augmented markov models 
technical report usc institute robotics intelligent systems 
goldberg 

control gaze 
kandel schwartz editors principles neural science 
mcgraw hill rd edition 
goodman 

fact fiction forecast 
harvard university press cambridge massachusetts 
gorin riccardi wright 

learning spoken language transcriptions 
proceedings ieee automatic speech recognition understanding workshop colorado 
granlund 

search general picture processing operator 
computer graphics image processing 
hu gross 

visuo spatial properties ventral premotor cortex 
journal neurophysiology 
grice 

logic conversation 
cole morgan editors syntax semantics volume pages 
academic press new york 
grimson huttenlocher 

sensitivity hough transform object recognition 
ieee transactions pattern analysis machine intelligence 
haigh veloso 

planning execution learning robotic agent 
proceedings fourth international conference artificial intelligence planning systems pages 
halliday 

learning mean explorations development language 
elsevier new york ny 
harnad 

symbol grounding origin language 
editor new directions pages 
mit press 
harville darrell gordon woodfill 

pose tracking linear depth brightness constraints 
proceedings international conference computer vision pages 
hauser 

evolution communication 
mit press 
hazen 

comparison combination methods oov word detection word confidence scoring 
proceedings international conference acoustics salt lake city utah 
zelinsky 

robust real time face tracking gesture recognition 
proceedings international joint conference artificial intelligence volume pages 
held hein 

movement produced stimulation development behavior 
journal comparative physiological psychology 
hirschberg litman 

prosodic cues recognition errors 
proceedings automatic speech recognition understanding workshop 
horn 

robot vision 
mit press 
yacoob davis 

anthropometric shape model estimating head orientation 
proceedings third international workshop visual form capri italy 
horswill 

specialization perceptual processes 
phd thesis mit 
hu 

visual pattern recognition moment invariants 
ire transactions information theory pages 
hubel wiesel 

receptive fields binocular interaction functional architecture cat visual cortex 
journal physiology 


operator locates edges digitized pictures 
journal association computing machinery 
hurley 

perception action alternative views 
synthese 
woods brass mazziotta rizzolatti 

cortical mechanisms human imitation 
science 
jacobs 

robust efficient detection convex groups 
ieee transactions pattern analysis machine intelligence 
jacobs 

fragment completion humans machines 
neural information processing systems 


cognitive neuroscience action 
blackwell publishers cambridge massachusetts oxford uk 
ng siu rohlicek gish 

phonetic word spotter various configurations application event spotting 
proceedings european conference speech communication technology eurospeech 
jia 
erdmann 

observing pose motion contact 
proceedings ieee international conference robotics automation 
johnson 
press 
building knowledge perception infancy 
stowe editors building object categories developmental time 
hillsdale mahwah nj 


discovery spoken language 
cambridge mit press 


infants detection sound patterns words fluent speech 
cognitive psychology 
kaelbling littman moore 

reinforcement learning survey 
journal artificial intelligence research 
kaelbling oates hernandez finney 

learning worlds objects 
aaai spring symposium 
kamp 

theory truth semantic representation 
janssen editors formal methods study language pages 
mathematical center tract amsterdam 
kass witkin 

analyzing oriented patterns 
computer vision graphics image processing 
johnson 

visual statistical learning infancy evidence domain general learning mechanism 
cognition 
kirsh 

complementary strategies hands think 
proceedings seventeenth annual conference cognitive science society hillsdale nj 
lawrence erlbaum 
kirsh 

intelligent space 
artificial intelligence 
kirsh 

adapting environment oneself 
adaptive behavior 
bovik 

fovea foveated active stereo system dynamic dimensional scene recovery 
ieee transactions robotics automation 
demiris kaiser 

human robot communication machine learning 
applied artificial intelligence journal 
koga kondo latombe 

planning motions intentions 
computer graphics 
konishi yuille zhu 

statistical edge detection learning evaluating edge cues 
pattern analysis machine intelligence 
kozima 

attention sharing behavior sharing human robot communication 
ieee international workshop robot human communication roman pages 
kozima nakagawa 

emergence imitation mediated objects 
second international workshop epigenetic robotics edinburgh scotland 


orientational filters real time computer vision problems 
phd thesis school electrical computer engineering georgia institute technology 
alford 

computation orientational filters real time computer vision problems implementation methodology 
real time imaging 
la cascia sclaroff athitsos 

fast reliable head tracking varying illumination approach robust registration texture mapped models 
ieee transactions pattern analysis machine intelligence volume pages 
lakoff 

women fire dangerous things categories reveal mind 
university chicago press chicago illinois 
gros 

rapid object indexing recognition enhanced geometric hashing 
proceedings th european conference computer vision volume pages cambridge england 
lenat 

cyc large scale investment knowledge infrastructure 
communications acm 
marjanovic 

learning functional maps sensorimotor systems humanoid robot 
master thesis mit department electrical engineering computer science 
marjanovi 

teaching old robot new tricks learning novel tasks interaction people things 
phd thesis massachusetts institute technology department electrical engineering computer science cambridge ma 
marjanovi scassellati williamson 

self taught visually guided pointing humanoid robot 
animals animats proceedings society adaptive behavior pages cape cod massachusetts 
markman 

categorization naming children problems induction 
mit press cambridge massachusetts 
martin fowlkes malik 

learning detect natural image boundaries brightness texture 
sixteenth annual conference neural information processing systems 
mataric 

distributed model mobile robot environment learning navigation 
technical report massachusetts institute technology 
mataric 

getting humanoids move imitate 
ieee intelligent systems 
kobayashi 

human interface humanoid robot realizing group communication real space 
proceedings second international symposium humanoid robots pages 
mccarthy hayes 

philosophical problems standpoint artificial intelligence 
meltzer michie editors machine intelligence pages 
edinburgh university press 
mcdermott 

experiments junctions real images 
master thesis university college london 
ho 

affordances clarifying evolving concept 
proceedings graphics interface 
mckenna gong 

real time face pose estimation 
international journal real time imaging special issue real time visual monitoring inspection 


orientation estimation conventional techniques new non differential method 
european signal processing conference tampere finland 
metta 

study sensorimotor development 
phd thesis lira lab dist metta sandini 

developmental approach visually guided reaching artificial systems 
neural networks 
minsky 

society mind 
simon schuster new york 
minsky 

logical vs analogical symbolic vs connectionist neat vs 
winston editor artificial intelligence mit expanding frontiers volume 
mit press 
reprinted ai magazine 
mitchell 

need biases learning generalizations 
technical report computer science department rutgers university 
moll erdmann 

reconstructing shape motion tactile sensors 
proceedings ieee rsj international conference intelligent robots systems maui hi 
mou zue 

sub lexical modelling finite state transducer framework 
proceedings ieee international conference acoustics speech signal processing salt lake city utah 
nch kaiser 

robot programming demonstration rpd machine learning user interaction methods development easy comfortable robot programming systems 
proceedings th international symposium industrial robots 
murata gallese 

selectivity shape size orientation objects grasping neurons monkey parietal area aip 
journal neurophysiology 
murphy 

passively learning finite automata 
technical report santa fe institute 
nayar nene murase 

real time object recognition system 
proceedings ieee international conference robotics automation 
needham 

object recognition object segregation month old infants 
journal experimental child psychology 
needham 

object segregation month old infants 
cognition 
nelson selinger 

approach object recognition 
proceedings international conference computer vision pages 
mataric 

experience learning task representations human robot interaction 
ieee international symposium computational intelligence robotics automation pages alberta canada 


role features preattentive vision comparison orientation motion color cues 
vision research 
oates 

identifying distinctive subsequences multivariate time series clustering 
knowledge discovery data mining pages 
oates walker cohen 

natural language interfaces robotic agents grounding linguistic meaning sensors 
proceedings th international conference autonomous agents pages 
oates jensen cohen 

discovering rules clustering predicting asynchronous events 
predicting ai approaches time series problems pages 
aaai press 


modeling mirror grasp learning action recognition 
phd thesis university southern california 
arbib 

schema design implementation grasp related mirror neuron system 
biological cybernetics 
papert 

summer vision project 
memo aim mit ai lab 


fast construction near optimal probing strategies 
master thesis university california berkeley 


visual representations natural visuo motor task 
phd thesis brain cognitive science university rochester 


referential mapping technique attaching functional significance innovative utterances african grey parrot 
applied psycholinguistics 
perona malik 

detecting localizing edges composed steps peaks roofs 
proceedings third international conference computer vision pages osaka japan 
fitzgibbon fisher 

ellipse specific direct square fitting 
ieee international conference image processing lausanne 


light fantastic 
st martin 


publishers 


moving pictures 



man 


abroad 



save mankind 
doubleday 


small 







fifth elephant 
doubleday 
quine 

word object 
harvard university press cambridge massachusetts 
darrell 

reducing drift parametric motion tracking 
international conference computer vision 
rizzolatti arbib 

language grasp 
trends neurosciences 
ross 

exploiting texture motion duality optical flow image segmentation 
master thesis massachusetts institute technology 
roy 

learning words sights sounds computational model 
phd thesis mit 
roy mukherjee 

trainable spoken language understanding system visual object selection 
proceedings international conference spoken language processing 
roy hsiao 

conversational robots building blocks grounding word meanings 
submitted hlt naacl workshop learning word meaning non linguistic data 
roy pentland 

learning words sights sounds computational model 
cognitive science 
sandini grosso 

vision action 
aloimonos editor active perception pages 
lawrence erlbaum associates hillsdale nj 
scassellati 

binocular foveated active vision system 
technical report mit artificial intelligence lab memo 
scassellati 

imitation mechanisms joint attention developmental structure building social skills humanoid robot 
nehaniv editor computation metaphors analogy agents volume springer lecture notes artificial intelligence 
springer verlag 
scassellati 

theory mind humanoid robot 
proceedings international ieee rsj conference humanoid robotics 
scassellati 

foundations theory mind humanoid robot 
phd thesis mit department electrical engineering computer science 
schneiderman kanade 

object detection statistics parts 
international journal computer vision 
schwartz greve 

space variant active vision definition overview examples 
neural networks 
selinger 

analysis applications feature object recognition 
phd thesis university rochester rochester new york 
gong 

fusion perceptual cues robust tracking head pose position 
pattern recognition volume 
shi tomasi 

features track 
proceedings ieee computer society conference computer vision pattern recognition pages 
sigal sclaroff athitsos 

estimation prediction evolving color distributions skin segmentation varying illumination 
proceedings ieee computer society conference computer vision pattern recognition volume pages 
sinha 

object recognition image invariants case study 
investigative visual science 
smith 

design application head detection tracking system 
master thesis mit 
kellner 

thoughtful elephant strategies spoken dialog systems 
ieee transactions speech audio processing 


neurology mind brain problem 
american scientist 
stauffer 

adaptive background mixture models real time tracking 
proceedings ieee conference computer vision pattern recognition pages 
stauffer grimson 

adaptive background mixture models real time tracking 
proceedings ieee computer society conference computer vision pattern recognition fort steels 

emergent adaptive lexicons 
proceedings fourth international conference simulation adaptive behavior pages cape cod ma 
strom jebara basu pentland 

real time tracking modeling faces ekf analysis synthesis approach 
proceedings modelling people workshop ieee international conference computer vision 
swain ballard 

color indexing 
international journal computer vision 
hirschberg litman 

corrections spoken dialogue systems 
proceedings international conference spoken language processing beijing china 
tarr black 

computational evolutionary perspective role representation vision 
cvgip image understanding 
thrun 

framework programming embedded systems initial design results 
technical report cmu cs carnegie mellon university 
tomasello 

pragmatics word learning 
japanese journal cognitive science 


communication cooperation early infancy description primary 
editor speech interpersonal communication 
cambridge university press 
ullman 

visual routines 
cognition 
visual cognition pinker ed 
vaidya 

geometry helps matching 
proceedings twentieth annual acm symposium theory computing pages 
acm press 
fitzpatrick breazeal 

characterizing processing speech 
proceedings international ieee rsj conference humanoid robotics tokyo japan 
viola jones 

robust real time object detection 
technical report compaq cambridge research laboratory cambridge ma 
vygotsky 

thought language 
mit press cambridge ma 
wang 

hybrid real time face tracking system 
proceedings ieee international conference acoustics speech signal processing seattle 
wang 

planning learning operators 
editor proceedings third international conference artificial intelligence planning systems pages 
aaai press 
weng hwang zhang yang smith 

developmental humanoids humanoids develop skills automatically 
proceedings ieee ras international conference humanoid robots cambridge ma 
weng mcclelland pentland sporns sur thelen 

autonomous mental development robots animals 
science 
lloyd polka 

putting baby bootstraps complete understanding role input infant speech processing 
morgan editors signal syntax bootstrapping speech grammar early acquisition pages 
lawrence erlbaum associates mahwah nj 
williamson 

series elastic actuators 
master thesis massachusetts institute technology cambridge massachusetts usa 
williamson 

neural control rhythmic arm movements 
neural networks 
williamson 

robot arm control exploiting natural dynamics 
phd thesis massachusetts institute technology cambridge massachusetts usa 
williamson 

postural primitives interactive behavior humanoid robot arm 
fourth international conference simulation adaptive behavior pages cape cod massachusetts 
williamson 

exploiting natural dynamics robot control 
fourteenth european meeting cybernetics systems research vienna austria 
winston 

learning structure descriptions examples 
psychology computer vision pages 
mcgraw hill new york 
wolfe oliva horowitz butcher 

segmentation objects backgrounds visual search tasks 
vision research 
wolfson rigoutsos 

geometric hashing overview 
ieee computational science engineering 
wong flynn 

fast division accurate quotient approximations reduce number iterations 
ieee transactions computers 
wren azarbayejani darrell pentland 

pfinder real time tracking human body 
ieee transactions pattern analysis machine intelligence 
wu huang 

wide range person illumination insensitive head orientation estimation 
proceedings international conference face gesture recognition grenoble france 
yip sussman 

sparse representations fast shot learning 
proceedings national conference artificial intelligence 


edge detection techniques overview 
technical report dept math informatique 
universit de 
zue glass 

conversational interfaces advances challenges 
proceedings ieee special issue spoken language processing vol 

zue glass pao hazen 

jupiter telephone conversation interface weather information 
ieee transactions speech audio processing 

