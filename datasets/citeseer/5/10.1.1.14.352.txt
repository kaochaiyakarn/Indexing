ieee transactions information theory 
vol 
may context tree weighting method basic properties frans willems member ieee yuri shtarkov member eee describe sequential universal data compression procedure binary tree sources performs double mixture 
context tree method weights efficient recursive way coding distributions corresponding bounded memory tree sources achieves desirable coding distribution tree sources unknown model unknown parameters 
computational storage complexity proposed procedure linear source sequence length 
derive natural upper bound cumulative redundancy method individual sequences 
terms bound identified coding parameter model redundancy 
bound holds source sequence lengths asymptotically large lengths 
analysis leads bound standard techniques turns extremely simple 
upper bound redundancy shows proposed context tree weighting procedure optimal sense achieves rissanen lower bound 
index terms sequential data compression universal source coding tree sources modeling procedure context tree arithmetic coding cumulative redundancy bounds 
concepts memo tree source property symbol probabilities depend finite number symbols 
number general depends actual values symbols 
binary sequential universal source coding procedures finite memory tree sources context tree contains string context number zeros number ones followed context source sequence seen far 
standard approach see rissanen langdon rissanen 
weinberger lempel ziv past source symbols uses context tree estimate actual state finite memory tree source 
subsequently state estimate distribution generates source symbol 
estimated distribution arithmetic coding procedures see rissanen langdon encode decode source symbol efficiently manuscript received august 
material part ieee symposium theory san antonio tx 
january 
willems eindhoven university technology 
electrical engineering department mb eindhoven netherlands 
shtarkov eindhoven university technology 
electrical engineering department mb eindhoven netherlands leave institute problems information transmission 
gsp russia 
ieee log number 
low complexity negligible additional redundancy 
rissanen pioneering weinberger lempel ziv developed procedure achieves optimal exponential decay error probability estimating current state tree source 
authors able demonstrate coding procedure achieves asymptotically lower bound average redundancy stated rissanen theorem theorem 
feder prove optimality sense achieving rissanen lower bound redundancy algorithm rissanen 
unpleasant fact standard approach specify parameters rissanen procedure lempel ziv method affect asymptotic procedure 
may big influence behavior finite realistic source sequence lengths 
artificial parameters necessary regulate state estimation characteristics 
gave authors idea state estimation concept may natural believes 
better starting principle just find coding distribution 
trivial guideline immediately suggests application model weighting techniques 
advantage weighting procedures average individual sequence 
model weighting twice universal coding new 
suggested ryabko class finite order markov sources see similar approach prediction 
known literature model weighting resulted probability assignments require complicated sequential updating procedures 
finding implementable coding methods concentrated achieving low redundancies 
follows describe probability assignment bounded memo tree sources allows efficient updating 
procedure tree recursive model weighting results coding method easy analyze desirable performance realized redundancy complexity 
ii 
binary bounded memory tree sources strings string concatenation binary symbols lq qo 


note index symbols string right left starting going negative 
length string ieee ieee transactions information theory 
vol 

may write 
semi infinite string qo length empty string length 
strings ql lq qo ql lq qo concatenation 
set strings 
vq 
say string tq qo suffix string qo 
empty string suffix strings 
bounded memory tree source definition binary tree source generates sequence digits assuming values alphabet 
denote sequence trm allow rn infinitely large 
statistical behavior binary finite memory tree source described means suffix set suffix set collection binary strings isl 
require proper complete 
suffix set implies string string completeness guarantees semi infinite sequence string suffix belongs suffix unique proper 
fixed 
bounded memo tree source suffix set satisfies say source memory larger completeness suffix set possible define su function maps semi infinite sequences unique suffix suffixes length larger symbols semi infinite sequence determine suffix qb suffix corresponds parameter 
parameter probability source assumes value specifies probability distribution 
parameters form parameter vector tree source emitted semi infinite sequence suffix function tells parameter generating binary digit wt source ds wt fg 

model suffix set parameters 
definition actual probabilities bounded memory tree source suffix set parameter vector 


block probabilities products actual symbol probabilities tree sources suffix set am said model 
model suffix set am equivalent 
set tree models having memo called model class cp 
possible specify model model class natural code encoding suffix set 
code code empty string code string void il followed codes strings natural code number bits needed specify model cr equal definition cost model respect model class cp defined 
assumed example 
consider source suffix set oo see fig 

probability source generating sequence past symbols 
calculated follows oo ore 
ihe model set specified code code code code code code tree sources related sources described rissanen 
sources considered tree sources suffix set closed 
suffix set said closed generator suffix belongs suffix generator suffix qo ql 
note 

tree model model 
willems el 
context tree weighting finite memory tree source suffix set finitestate machine implementation 
number states isl 
tree sources closed suffix set sources number states equal isl ill codes redundancy 
source sequence encoder sends codeword qc consisting components decoder 
decoder able reconstruct source sequence codeword 
assume encoder decoder access past source symbols implicitely suffix probability distribution source symbols available 
encoder depends source sequence denote functional relationship write cl 
codeword digits denoted la 
restrict pre codes see ch 

codes uniquely decodable instantaneous self implies immediately recognize codeword see 
set codewords produced fixed form prefix code codeword prefix codeword set 
sequences ct 
prefix clc codeword lengths rl individ ual redundancies 
definition individual redundancy sequence past symbols respect source model cd parameter vector os defined ti length codeword consider sequences positive probability 
value log regarded information contained past 
ideal codeword length 
note divide redundancies source sequence length consider cumulative redundancies 
note redundancies negative 
objective universal source coding design methods achieve small redundancies respect sources class 
important methods low storage computational complexity appropriate say emphasis basis log 
assumed 
source coding finding desirable tradeoff achieving small redundancies keeping complexity low 
iv 
arithmetic coding arithmetic encoder computes codeword corresponds actual source sequence 
corresponding decoder reconstructs actual source sequence codeword computation 
arithmetic codes possible process source sequences large length needed reduce redundancy source symbol 
arithmetic codes elias algorithm unpublished described abramson jelinek enumeration cover 
arithmetic coding rissanen solved accuracy issues involved 
discuss issues 
assume computations carried infinite precision 
suppose encoder decoder access called coding distribution pc 

require satisfies 
possible ah possible sequences sequences occur sequences 
note stands empty sequence 
appendix describe elias algorithm 
results theorem 
theorem coding distribution 
elias algorithm achieves codeword lengths satisfy possible codewords form prefix code 
difference codeword length zh log xt bits 
say individual coding redundancy bits 
conclude section observation elias algorithm combines acceptable coding redundancy desirable sequential implementation 
number operations linear source sequence length crucial 
encoder decoder access probabilities pc 
xt pc xt having processed rl 

case say coding distribution sequentially available 
ieee transactions information theory 
vol ii may noted view arithmetic code slightly different usual 
assume block probabilities fed encoder decoder conditional probabilities usual 
reason creates better match modeling algorithm arithmetic code avoids multiplications 
ready accept loss bits coding redundancy left problem finding sequentially available coding distributions 
probability estimation probability memoryless source parameter generates sequence zeros ones weight probability dirichlet distribution obtain called es see 
definition kt estimated probability sequence containing zeros ones defined 
estimator properties listed lemma follows 
lemma proved appendix ii 
lemma kt probability estimator computed sequentially 

satisfies inequality 
sequential behavior kt estimator studied shtarkov 
estimator laplace estimator investigated rissanen 
estimator obtained weighting uniform 
kt estimator parameter redundancy bounded lower bound see lemma 

impossible prove uniform bound laplace estimator 
vl coding unknown tree source definition tree weighting method consider case compress sequence supposed generated tree source suffix set cd parameter vector os unknown 

weighted context tree 
encoder decoder 
define weighted coding distribution situation study ils performance discuss implementation 
coding distribution concept context tree see fig 

definition context tree tz set nodes labeled binary string length td nodes 

node called parent nodes turn children node 
correspond counts 

children parent node counts satisfy node corresponds 
weighted probability defined recursively context tree td 
doubt thc basic 
definition node td 
assign weighted probability 
defined context tree weighted probabilities nodes called weighted context tree 
definition shows weighting estimated probability node product weighted probabilities correspond children 
lemma gives way looking weighting performed 
explains weighted probability node regarded weighting estimated probabilities corresponding sub models live node 
cost see sub model determines weighting factor 
proof lemma appendix 
context tree weighting method lemma weighted probability node ro 
cd summation complete proper suffix sets able define weighted coding distribution assume 
bs 
td source sequence seen assuming past symbols 
definition respectively lm number times respectively weighted probabilities nodes denoted ml sequence past symbols define weighted coding distribution 
root node context tree tv 
coding determines context tree weighting metro note counts restrictions mentioned definition 
verify satisfies lemma 
proof lemma appendix iv 
lemma tn suffix iz suffix lt ps 
check weighted coding distribution defined allowable coding distribution observe lz 
subsequently note lemma states strings 
may weighted coding distribution satisfies having verified weighted probabilities positive 
ready investigate redundancy context tree weighting method 
bound redundancy give definition 

log 

convex continuation 
basic result concerning context tree weighting technique stated 
theorem individual redundancies respect source model cd parameter vector upper bounded lr sequence past symbols weighted coding distribution specified 
note rewritten see bottom page 
redundancy bound theorem holds respect sources model cd parameter vector actual source 
definition redundancy see immediately obtain upper bound codeword lengths 
coding distribution codeword lengths rl upper bounded sequence past symbols 
consider sequence suffix set cd parameter vector os 
sk 
split individual terns model redundancy parameter redundancy coding redundancy og log log hs ts ao 
ifd 
si ieee transactions information theory 
vol 


may term coding redundancy obtain theorem log pc tl 
treat parameter redundancy middle term follows product log 
possible split parameter redundancy isl terms representing parameter redundancies corresponding isl suffixes 
term corresponding suffix upper bounded log seen lbr 
bs term contribute redundancy 
introduced function convexity possible apply jensen inequality see cover thomas 
remains investigated term model redundancy term 
follows lemma obtain upper bound model redundancy log es 
combining yields theorem 
basic result 
theorem recognize coding redundancy model redundancy 
model redundancy knowing actual best sense model able take distribution coding distribution 
results loss model redundancy upper bounded bits 
note section described natural code need bits specify model weighted method pass method best model determined transmitted followed code sequence model 
example suppose source generated sequence sequence past symbols 
plotted weighted context tree td fig 

node contains counts 
estimate 
weighted probability 
coding probability corresponding sequence 
upper bound model redundancy respect model source example bits 
follows quite easily tree weighting method discussing implementation issues refer appendix notation concerning encoding decoding 
encoding set 
create nodes necessary dummy update nodes find update lx actual update nodes 
xt results having processed xx xt compute ix 
willems context tree weighting method decoding 
set determine clc cl cl 
create nodes 
dummy update nodes find find update ix update nodes having processed rt compute know stm codeword 
assume node td contains pair estimated probability weighted probability node created counts bs am probabilities pc 
doing dummy update nodes means assume xt 
update indicated 
bs tilde variable variable 
form compute xt changed remained see lemma 
eventually results 
clear see bottom page 
noted block probabilities feed arithmetic encoder decoder conditional probabilities usual 
avoids multiplications arithmetic encoder decoder pleasant side effect weighted approach 
xt actual update identical difference update increment computing temporary values bs xt actual update requires incrementing note update nodes nodes path context tree determined past symbols codeword cl computed definition appendix transmitted decoder 
decoder appendix note compared threshold xt see appendix length computed definition 
complexity issues symbol visit nodes 
nodes created 
follows total number allocated nodes 
storage linear 
note number nodes total number nodes 
shows exponential behavior wk take account infinite precision arithmetic number digits arc needed specify counts probabilities increasing making storage space node measured bytes getting bigger time 
computational number additions multiplications divisions proportional number nodes visited 
complexity linear neglected fact infinite precision arithmetic number digits needed specify counts probabilities pi growing rapidly making additions multiplications divisions complex increasing vii 
weightings coding distribution defined yields model cost 
linear il assume leaves depth achieved 

dj xt 
eee transactions information theor vol 


may giving equal weight pop internal node td 
quite possible assume weights equal suppose different different nodes section assume node depends depth node context tree td 
ct ctt ad 
note model regarded empty memoryless model number nodes may added 
cost empty model log say model cost parameter log bits 
objective add new node parameter model model cost increases bit matter level add node 
words aa cd 
assume implies models fit equal cost find 

ad yields cost log bits models bits note number models cd grows fast incrementing results roughly number models cd 
context tree weighting method working models simultaneously efficient way take log obtain model cost proportional number il 
find log bit fr get bits bits fr find bits viii 
final remarks seen lemma weighting distributions corresponding models cd 
may conclude weighting components os assumed dirichlet distributed 

may say 
ah weighting models parameter vectors called double mixture see 
stress context tree weighting method induces certain weighting models see lemma changed section vii order achieve specific model redundancy behavior 
redundancy upper bound theorem shows method achieves lower bound obtained rissanen see theorem finite state sources 
redundancy bound fact stronger holds source sequences averaged source sequences large 
bound stronger sense hat precise terms tell model redundancy 
context tree weighting procedure ieee international symposium information theory san antonio tx see 
rissanen feder studied finite tree sources proposed state estimation 
artificial constant function needed regulate selection process 
claim context tree eliminated artificial parameters admit basic context tree method described parameter specified advance making method models models memory larger possible see modify algorithm constraint maximum memory depth involved 
demonstrated necessary access 
implementation realizes infinite context tree depth storage complexity remains linear furthermore shown implementation context tree weighting achieves entropy stationary source 
weinberger merhav feder consider class containing finite state sources bounded memory tree sources 
strengthened shtarkov pointwise minimax lower bound ual redundancy theorem lower bound equivalent rissanen lower bound average redundancy holds sequences types 
investigated weighted mixing approach finite state sources 
weinberger el showed redundancy weighted achieves strong lower bound 
furthermore shows example state estimation approach authors call plug approach source sequences achieve lower bound 
finite accuracy implementations context tree weighting method combination arithmetic coding studied 
context weighting methods described perform general model classes studied 
model classes bounded mem ory proposed schemes lot constructive just context tree weighting method described 
context tree weighting method considered binary sources exist straightforward generalizations context tree weighting method nonbinary sources see 
appendix elias algorithm idea elias algorithm source sequence corresponds subinterval 
principle traced back shannon 
definition interval rs corresponding defined note sequence length consequently 
observe fixed value intervals disjoint union 
interval length equal corresponding coding probability 
just source sequences codeword qc cr associated 
definition interval codeword defined cl cl understand note considered fraction cl 
followed codewords decoder receives stream code digits digits correspond decoder determine value represented binary fraction formed total stream 
noted length tot stream necessarily infinite 
may say code word compress sequence search codeword cz code interval contained sequence interval 
definition lh codeword cr source sequence consists og binary digits 
smallest integer consider cr ri may conclude 
disjoint decoder reconstruct source sequence note decoder compute cr just encoder find location digit codeword 
note code codeword prefix codeword 
implies code satisfies prefix condition 
definition immediately obtain 
second idea elias algorithm order sequences length lexicographically 
sequences 
hat exists ff 
lexicographical ordering possible compute sequentially 
transform interval 
respectively 
consequence lexicographical ordering source sequences ords computed xt 
encoder decoder easily find having easy probabilities xt xx xt having processed observe hen symbol processed inte rt ieee transactions information 
vol 
may subdivided subintervals encoder proceeds subintervals depending symbol rt xs ctl 
implies 
decoder determines source symbols rt respectively comparing thresholds 
definition thresholds defined tl xt xt observe thai threshold splits interval see 
upper boundary point 
xt lower boundary point 
xt 
xtx xl 
xt 
tl 
decoder easily find rt comparing threshold words operate sequentially 
code satisfies prefix condition necessary access complete decoding 
shown digits needed 
appendix ii properties kt estimator proof 
proof consists pans 
fact 
follows sin cos rr sin easy see obtain ci il clo 
define assume 
consider ix analyze define 
oc functions tt 
derivatives functions arc take dr 
observe obtain af dl lim 
similarly willems context tree weighting method may conclude dg results 

combining yields 
investigate case 
note implies consider fact tg find hat 

inequality implies ma fora 

lemma observation easily proved bounds tight 
appendix ill weighting properties proof prove induction hypothesis lemma holds 
true 
assume hypothesis holds node induction hypothesis second step derivation 
hypothesis holds induction cd proved similarly note ro appendix iv updating properties proof note suffix descendant suffix descendants counts remain consequently estimated probabilities having observed symbol implies weighted probability change holds 
td suffix show hypothesis holds induction 
observe holds see note 
notation 
bs holds consider nodes corresponding strings 
postfix os vice versa 
postfix pc 
po px ieee transactions information theory 
vol 

may 
induction obtain fourth equality 
second equality follows 
proof analogous postfix xt acknowledgment research carried may second author visited information theory group eindhoven university 
authors wish supporting visit 
authors wish participated research pertaining section vii 
comments reviewers advice associate editor feder acknowledged 
abramson information theory coding 
new york mcgrawhill 
pp 
cover enumerative source encoding 
ieee trans 
inform 
theo 
vol 

pp 
jan 
cover thomas elements information theory 
new wiley 
jelinek probabilistic information theory 
new york mcgraw hill 

pp 

performance universal encoding ieee trans 

theo vol 
pp 

mar source coding algorithms fast data compression ph dissertation 
stanford univ stanford 
ca 
rissanen 
generalized kraft inequality arithmetic coding ibm res 
devel vol 
universal data compression 
ieee trans 


vol 
pp 
sept 
universal coding prediction estimation eee trans 

vol 
pp 
july 
complexity strings class markov sources 
ieee tram 

theory vol 
pp 
july 
st ti 
nj scientific 
langdon 
jr 
universal modeling ieee ans 
farm 
vol 

pp 
jan 
ya 
ryabko twice universal coding lq 
tram 

pp 
july sept prediction random sequences universal coding probl 
vol 
pp 
apr june 
jk algorithm lbr source coding iei trans 
inform 
theory vol 
pp 
may 
shannon mathematical theory bell syst tech 
vol 
pp 
july 
key theory ed 
new york eee press 
pp 

shtarkov universal sequential coding single messages probl 

ol 
pp 

sept 
tj shtarkov mi 
sequential weighting algorithms sources th joint edi lnt 
workshop formation woo molle sweden aug pp 

weinberger lempel 
ziv algorithm universal coding sources 
ieee ans 
vol 
pp 
may weinberger feder 
optimal sequential probability assignment lot sequences 
ieee ans 

vol 
pp 
mar 
feder universal memo source submitted publication aug appear 
shtarkov tree weighting sequential universal source coding procedure br sources proc 
eee int syrup 
theo san antonio 
tx jan 
context general context sources submitted ieee trans 
rm 
theory 
sept 
willems context tree weighting method truncated updating submitted ieee trans 

theor aug 
extensions context tree weighting method proc 
ieee lnt 
syrup norway june july 
