adaptive optimizing compilers st century keith cooper subramanian linda torczon department computer science rice university main street ms houston tx historically compilers operated applying fixed set optimizations predetermined order 
call ordered list optimizations compilation sequence 
describes prototype system uses biased random search discover program specific compilation sequence minimizes explicit external objective function 
result compiler framework adapts behavior application compiled pool available transformations objective function target machine 
describes experiments attempt characterize space adaptive compiler search 
preliminary results suggest optimal solutions rare local minima frequent 
holds true biased random searches genetic algorithm find solutions quickly simpler strategies hill climbing 
changing landscape year microprocessors microcontrollers computing engines find application new areas 
number computers growing rapidly diversity systems 
variety processors different instruction sets different performance parameters different memory hierarchies increasing 
commodity microprocessors come low power versions embedded versions variety high performance versions performance parameters versions differ widely 
processors grown complex multiple functional units exposed pipelines myriad latencies managed 
cases computers execute code produced compiler translator consumes source code produces equivalent code target machine 
time application computing new problems created demand compilers optimize programs new criteria new objective functions 
early speed compiled code dominant concern users 
late size compiled code issue driven limited memory embedded systems importance compiled applications transmitted internet 
rise embedded systems sparked interest compiler techniques reduce power consumed execution 
classic approach appearance new objective function formulate new transformations add optimizer 
community building optimizing compilers years 
know build optimizing compilers produce efficient code single uniprocessor target 
modern processors 
learned build compilers easier retarget produce optimized code 
retargetable compilers situations economics justify large standalone compiler effort 
developed economical way produce high quality compilers wide variety target machines 
unfortunately learned building highquality compilers expensive primarily requires years effort experts usually short supply 
resources devoted compiler development vary widely 
contrast example excellent code produced compiler cray tera mta architecture installed systems code quality achieved typical compilers pentium systems huge number installed units 
source code front optimizer back classic compiler structure target code describes framework implementing optimizing compilers easily automatically adapt behavior circumstances operate different applications different target machine performance parameters different sets transformations different objective functions optimization 
goal change economics producing high quality compilers fundamental way automating required tune compiler new circumstances possible build retargetable compilers produce excellent code 
today exploring ideas research compiler 
expect years combination faster processors better understanding adaptive compilation fast routine 
improvements apply ideas harder problems compilation selecting best strategy data distribution parallelization fast performance estimators 
new structure compilers compilers consisted fixed sequence passes applied preselected order shown 
compiler runs sequence passes input program 
example original fortran translator passes classic fortran compiler bliss compiler 
ibm pl compiler hp compiler pa risc followed basic organization 
modern systems retain basic structure passes 
example suif compiler eighteen passes optimizer released pro compiler silicon graphics passes 
compilers differ number passes selection specific algorithms passes order application passes basic structure remains 
choice specific transformations order application play major role determining effectiveness optimizing compiler 
call ordered list transformations compilation sequence 
compiler writers chosen compilation sequences ad hoc fashion guided experience limited benchmarking 
efforts find best sequence due complexity problem 
transformations create suppress opportunities transformations 
different techniques problem catch different subsets available opportunities 
example different ways performing redundancy elimination different cases 
combinations techniques achieve result single techniques 
unfortunately best compilation sequence depends factors including specific details code compiled pool available transformations target machine performance parameters vary model model particular aspect code user desires improve speed space power 
classic compilers try address second third factors design time decisions ignore 
difficult predict impact changes compilation sequence compiled code 
today lack knowledge analytically predict results particular sequence particular set circumstances prevents purely analytical process deriving code sequences 
describe new approach source target code code front pool transformations steering algorithm back objective function measured results structure new compiler structuring compilation promises simplify construction high quality optimizing compilers wide variation factors 
new system shown replaces fixed order optimizer pool transformations steering algorithm explicit external objective function 
steering mechanism selects compilation sequence compiles program sequence 
compiler evaluates objective function resulting target machine program 
measured results serve input steering algorithm allowing refine choices explore space possible compilation sequences 
repeated experiments steering algorithm discovers compilation sequence minimizes objective function source code available transformations target machine 
approach addresses fundamental challenges design implementation optimizing compiler choosing specific set transformations order application computing solutions 
relies speed modern computers replace fixed order compiler structure adapts new performance parameters new input programs new transformations new objective functions 
applies inexpensive cycles solve problem compiler design theory practice years 
compiler objective function explicit changeable multi dimensional implicit fixed dimensional 
resulting compilers optimize variety objectives including running time code size page faults energy consumption combinations objectives 
done preliminary experiments particular search technique find program specific compilation sequences 
date experimented objective functions optimize code size generating compact executables optimize speed generating fast code optimize property related power consumption generating power efficient code 
describe computation best compilation sequence sequential search problem 
show biased random sampling combinatorial space possible compilation sequences effective means finding solutions 
sections describe approach related prior preliminary experimental results detail 
searching compilation sequences currently effective compilers include transformations drawn hundreds proposed literature 
picking best compilation sequence specific program objective function hard little theoretical understanding effect particular compilation sequences external objective function space compilation sequences large approaches relying exhaustive search 
compilers offer small number compilation sequences 
discovered manually designers 
sequences fit application user real performance goals user recourse 
picking compilation sequences instance family combinatorial problems called sequential decision making problems 
problems properties solving problem requires making sequence decisions 
effect outcome decision function decisions past random factors entirely decision maker control 
decision point time alters set choices 
step impact decision considered 
objective function depends complex way interactions individual decisions stochastic outcomes 
problem finding compilation sequences specific circumstances problem 
traveling salesman problem tsp discrete combinatorial optimization problems members problem class 
standard approach solving problems uses deterministic stochastic dynamic programming 
traditional dynamic programming implementations need excessive amounts space complete search algorithms branch bound algorithms tsp 
complete search algorithms guarantee globally optimal solution 
practical problems effective pruning techniques known 
example available theory tsp permits design efficient heuristics lin kernighan heuristic prune unpromising paths early search 
unfortunately little known picking compilation sequences enable kind early pruning 
deeper analytical understanding search differentiate promising unpromising subsequences 
biased random sampling key insight approach randomization exploration compilation sequences 
design adaptive sampling algorithms learn construct sequences randomly sampling evaluating keeping statistics various sequences perform respect external objective function statistics guide sampling 
paradigm biased random search biased random sampling 
initially algorithm performs random walk space sequences absence information appear equally promising 
sequences sampled evaluated search algorithm builds probabilistic model relating subsequences evaluation biases sampling strategy probabilities 
regions yield unpromising results sampled regions yield promising results 
adaptive biased randomized sampling strategy best heuristics pruning partial analytical models interactions sequence elements 
method performs better pure random walk strategies 
experiments generated compilation sequences genetic algorithm kind biased random sampler compared rate convergence genetic algorithm search unbiased random walk strategy 
genetic algorithm best solution far fewer probes random sampling 
practical perspective adaptive biased randomized sampling anytime algorithm 
retains best result seen stopped time 
lets construct stopping criteria practical considerations resource limits rate change solution quality 
example wall time limited search return best solution discovered 
compilers benchmarking activity directly affects sales computers myriad flags benchmarking specialist hand tune compiler behavior specific program 
effective flags individually combination requires depth knowledge compiler inner workings application compiled 
precisely sort tuning automated routinely available users 
general schema adaptive biased randomized sampling includes wide range specific algorithms applied mathematics artificial intelligence 
examples include parallel direct search iterative repair algorithm selection statistical sampling search trajectories genetic algorithms 
methods differ information past searches generate new candidate solutions choose starting points 
techniques come guarantees convergence local optima 
case biased random sampling designing prototype adaptive compiler chose biased random sampling paradigm pursuing analytical technique derive appropriate transformation sequence 
compiler predict reasonable accuracy impact specific compilation sequence specific program execution context open avenues research pursue 
factors predictions difficult inaccurate today 
improvement transformation isolation varies widely function detailed properties input program 
optimization targets specific opportunities improve code opportunities exist 
estimate impact accuracy estimator need discover sites transformation applies estimate site impact execution time 
finding sites large part transformation cases cost accurate estimator roughly cost performing transformation 
complicate matters transformations produce negative results example briggs cooper reported improvements ranging algebraic technique 
interactions transformations overlapping effects isolated predictions inaccurate 
consider trying predict improvement accrue performing transformation compilation sequence abc 
predictor determine number occurrences code sequences improve estimate execute 
rewrite code eliminate opportunities move places execute 
similarly eliminate opportunities create situations efforts counter productive 
perform accurate prediction predictor operate code input transformation result previous transformations sequence 
fact accurate standalone prediction expensive compiling code 
understand behavior optimizations compile time context analytical prediction behavior sequences remain impractical 
principal argument sampling approach expense 
cost accrues evaluation proposed sequences 
exploring techniques approximations proxies estimate behavior sequence available evaluations related sequences 
recognize behavioral complexity optimizer may preclude development efficient approximators 
approach fast research compiler today 
years combination faster computers better understanding adaptive compilers allow routine techniques commercial compilers researchers apply harder problems compilation strategies data distribution parallelization 
analytical approach limited success example lam recast loop transformations improve memory behavior framework unimodular transformations able analytically derive appropriate sequence 
model included limited set transformations attacked single problem cache locality single objective function 
generalization include arbitrary optimization techniques proposed 
related prior previous attempts building adaptive compilers focused feeding dynamic profile information program execution back compiler guide optimization 
attempts search optimization include system genetic algorithms attempt parallelize loop nests massalin exhaustive search attempt perform optimal instruction selection 
system ineffective probably search fit problem 
massalin technique produced results expensive routine 
granlund adapted massalin ideas produce design time tool generates assembly sequences gcc code generator 
preliminary genetic algorithm find compilation sequences suggests search fit problem adaptive randomized sampling yield results reasonable amount time 
preliminary experimental results built preliminary system uses biased random sampling search compilation sequence minimizes external objective function 
tested system different sampling methods genetic algorithms hill climbing randomized restarts 
implemented distinct objective functions 
code size motivated need compact code embedded systems 
compressing code resulting standard compilation genetic algorithm find compilation sequences produced smaller code 
search compilation resulted code average smaller code produced compiler original optimization sequence 
broke ties favor speed resulting code code typically faster code produced original sequence 
contrast adding direct compression suffix trees procedure abstraction original compiler produced reduction code size 
search compilation code times direct technique 
furthermore procedure abstraction slow code 
contrast compilation sequences adaptive compiler led faster code 

running time part experiment reversed order objective function considered space speed 
optimizing speed space tie breaker prototype system produced code faster slightly smaller produced original compiler 
combination adaptive behavior consistent tie breaking led sequences improved criteria 

inter operation name transitions prototype system investigate impact compilation power consumption microprocessor 
objective function minimizes number inter operation bit transitions name fields instructions prototype produced reductions unoptimized code compiler default compilation sequence adding new transformations compiler 
continue add transformations compiler enhance effect adaptive compiler discover apply 
increase improvements objective function 
case adaptive compiler compilation sequence produced better solutions original fixed sequence compiler 
sequences included passes original compiler 
time contained fewer passes 
tie breaking regimen reducing number bits instruction stream change operation operation leads lower power consumption processor 
structure fmin experiments created dimensional objective function clear priority preferred dimension 
observed clear improvement dimensions 
analysis solution space preliminary experiments shown promise adaptive compilation finding program specific compilation sequences produce code closely fits stated objective 
understand approach biased random sampling effective conducted round experiments 
focused single benchmark program fmin thatis small lines fortran permit near complete mapping solution space complex exhibit interesting behavior 
shows control flow graph primary procedure 
optimized simple objective function number operations executed run program 
goal address questions 
solution density space 
sequences combinatorially possible ones assuming available transforms sequences length yield lowest operation count 
equally solutions 

local minima 
random sampling strategy get stuck 

distribution solutions 
clustered tightly space distributed 
probability random sampling strategy stumble solution quickly 
answers questions dictate approach finding program specific compilation sequences 
sequences widely distributed local minima rare local search technique high probability find optimal sequence 
hand sequences rare local minima common local search require restarts ability move uphill local minimum 
solution clusters dispersed widely space search techniques explore multiple starting points parallel mutate sequence guesses drastically iteration genetic algorithms important 
recognize answers questions may program specific began focusing single program fmin 
randomized sampling strategies hill climbing random restarts genetic algorithms 
hill climber begins random sequence mutates single position time 
change yields improvement objective function accepted 
hill climber finds sequence improve indicating minimum local global records sequence fitness value starts generating new random sequence 
genetic algorithm maintains population sequences 
tests sequence compiling code measuring objective function 
creates generation sequences fitness biased selection crossover 
tables top show particularly runs hill climber 
column shows ordinal number trial sequence derived 
second column shows actual sequence letter denotes specific optimization pass compiler 
third column shows number cycles required run resulting code simulated single issue risc machine 
runs hill climber quickly got optimal solution cycles 
run required larger experiments running written reviewed 
symposium additional data 
experimented number strategies crossover mutation fitness scaling 
changing parameters genetic algorithm change behavior affect comparison hill climbing 
trial sequence cycles trial sequence cycles sequences hill climber runs assertion insertion logical peephole optimization scc value numbering loop peeling global constant propagation dead code elimination copy coalescing partition value numbering strength reduction partial redundancy elimination local value numbering global renaming lazy code motion useless control flow elimination interpreting sequences hill climber runs cycle count distribution solutions fmin trials get cycles second required trials 
trial mutates position evaluates 
improvement takes longer 
run converges minimum cycle count 
sequences runs shown demonstrate solution space contains significant number local minima minima dispersed solution space 
suggests parallel exploration multiple sequences mechanisms generating new sequences powerful single position mutation necessary obtain faster convergence 
hill climber solutions small percentage best solution 
progress slowed markedly objective function values approached minimum 
genetic algorithm variable length sequences strategy eliminates duplicates mutating unique outperforms hill climber 
best sequences genetic algorithm sequence cycles note take single position mutations transform sequences hill climber second sequence genetic algorithm 
furthermore sequence hill climber local minimum 
suggests hill climber cross deep valleys finds deepest valley space 
find true minimizer complex space require search algorithm capable valleys 
better visualize solution space chose commonly occurring transformations sequences fmin genetic algorithm 
sequence length ran sequences optimizer determine sequences yield smallest cycle count 
histogram sequences shows distribution cycle counts sequences drawn possible sequences 
show solutions cycles extremely rare 
experience hill climber suggests preponderance local minima complexity solution space 
results suggests possibility may algorithmic solution finding best sequence 
promise search compilation long term goal address economic problem confronts compiler writers handle rapid proliferation processors applications objective functions environmental constraints abandoning high quality optimization 
economically feasible produce distinct compilers circumstances current practices 
new way organize build tune optimizing compilers forced accept poor quality code fails meet users real needs 
adaptive compilers search open new research practical application 
create market economy transformations allowing competitive evaluation different techniques level playing field 
create environment compiler writer include niche transformations high payoff narrow applicability 
apply power search new issues compilation 
example discover appropriate compilation sequence java jit compiler writer limit sequence transformations optimize run time speed plus compile time 
strategy building adaptive compilers tools automate process configuring ties strength compilers speed machines 
resource compilers exploited past 
adaptive compilers broaden range input programs routinely attain performance 
responsive new performance goals expressed form new external objective functions 
easily accommodate new results research new transformations simply added pool 
remaining challenges building robust adaptive optimizing compiler major challenge 
require strategies minimize explicit user selected objective functions complex poorly characterized space viz combinatorial set distinct compilation sequences 
require new techniques implementing optimizations modular fashion managing reconfiguration measuring results compilation 
require careful consideration stopping criteria strategies producing storing results incrementally apply knowledge gained exploring space compilation sequences 
require major implementation effort evaluate effectiveness ideas 
engineering reconfiguration diagram appear classic compilers modular components reordered 
practice inspecting internals compiler usually reveals critical ordering constraints imposed implementation 
constraints may explicit pass allocates structure fills information pass uses information frees structure 
constraints may implicit pass relying 
approach simplify implementation passes keeping narrowly focused popularized ibm pl compiler 
compilers designed modularity goal subtle order dependences arise implicit constraints 
inter pass constraints explicit implicit major impediment construction adaptive compilers 
heart system pool transformations run essentially arbitrary order 
envision distinct complementary efforts solving problem engineering reconfigurable compilers aimed set design principles writing new transformations early experiments genetic algorithms find compilation sequences framework exposed gone undetected years 
aimed understanding constraints exist ensuring proposed compilation sequences violate constraints 
deriving practical compilers adaptive compilers result allow researchers compiler writers explore space compilation sequences impact sequences code quality 
ideas useful practice design mechanisms results full blown adaptive compilations compiles 
build efficient production compilers configurable base require additional research implementation 
intend explore alternative strategies 
training compiler representative set programs find best sequences having production compiler try sequences input program find best result 
small say produce benefit limiting increase compile time 
adopting incremental strategy sampling compiler retains partial results compiles 
trades minor cost increase compile long term improvement code quality 
scenario may require periodic randomized disturbance model help avoid local minima 
invoking full algorithm strict wall time limit compiler returns best code find hour hours 
provides direct way limiting resource coupled incremental sampling strategy 
limiting focus adaptive compiler performance critical routines application 
require mechanism identifying routines user directives run time profiling merit investigation 
varying size training set maximum length compilation sequence amount time allowed search compiler writer able achieve variety effects 
particularly important codes user may want version limits training set program 
gain experience adaptive sampling compilation hope learn behavior optimizations interactions allow compiler perform part search analytically 
strategies fit model include building database program characteristics versus compilation sequences restricting set optimizations smaller set predictable effects interactions wholesale approximations effects 
hope learn compiler prune search space aggressively early eliminating unproductive search paths 
may lead techniques complete search pruning tractable 
people contributed understanding issues initial experiments arena ability describe vision adaptive compilation 
members scalar compiler group rice past built tools explore ideas 
phil tim harvey steve reeves contributed insight hard long discussion 
stephanie forrest university new mexico suggested number improvements initial genetic algorithm 
initial adaptive compilation reduce code size supported darpa contract 
reducing power consumption supported part state texas advanced technology project 
remainder supported los alamos computer science institute 
marc auslander martin hopkins 
overview pl compiler 
sigplan notices june 
proceedings acm sigplan symposium compiler construction 
backus best goldberg nelson sheridan stern hughes nutt 
fortran automatic coding system 
proceedings western joint computer conference pages february 
john backus 
history fortran ii iii 
wexelblat editor history programming languages pages 
academic press 
jonathan bradley gene 
dsp microprocessor power management novel approach 
texas instruments technical white 
preston briggs keith cooper 
effective partial redundancy elimination 
sigplan notices june 
proceedings acm sigplan conference programming language design implementation 
keith cooper 
redundancy elimination hard 
excerpt talk rice computer science affiliates meeting 
available www cs rice edu keith october 
keith cooper tim harvey 
study estimated name transitions fortran codes 
technical report preparation available web rice edu publications html april 
keith cooper nathaniel mcintosh 
enhanced code compression embedded risc processors 
proceedings acm sigplan conference language design implementation may 
keith cooper philip subramanian 
optimizing reduced code space genetic algorithms 
proceedings workshop languages compilers tools embedded systems may 
john dennis virginia torczon 
direct search methods parallel machines 
siam journal optimization november 
nicolas fournier 
enhancement evolutionary optimising compiler 
master thesis department computer science university manchester september 
rn granlund richard 
eliminating branches gnu compiler 
sigplan notices july 
proceedings acm sigplan conference programming language design implementation 
holland 
adaptation natural artificial systems 
university michigan press 
mark scott johnson terrence miller 
effectiveness machine level global optimizer 
sigplan notices july 
proceedings acm sigplan symposium compiler construction 
kandemir vijaykrishnan irwin ye 
influence compiler optimizations system power 
proceedings international symposium computer architecture june 
monica lam suif group 
documentation suif compiler release 
available suif web site suif cs stanford edu lionel 
branch bound algorithm selection performance prediction 
aaai 
lowry 
object code optimization 
communications acm pages january 
henry massalin 
look smallest program 
proceedings second international conference architectural support programming languages operating systems pages palo alto ca 
minton johnston phillips laird 
minimizing conflicts heuristic method constraint satisfaction scheduling problems 
artificial intelligence 
thomas night 
www ai mit edu projects transit tn tn html 
web site transit project 
andy 
gaps iterative feedback directed parallelisation genetic algorithms 
proceedings workshop profile feedback directed compilation paris fr june 
workshop held conjunction pact 
randolph harwood 
improved optimization fortran object programs 
ibm journal research development november 
philip 
stochastic instruction scheduling 
phd thesis rice university department computer science may 
silicon graphics documentation sgi pro compiler release 
sgi released compiler open source form summer 
code available 
thornton 
arc weights improve iterative repair 
aaai 
tiwari malik wolfe 
compilation techniques low energy overview 
proceedings ieee symposium low power electronics 
tiwari malik wolfe 
power analysis embedded software step software power minimization 
ieee transactions vlsi systems 
virginia torczon 
direct search methods unconstrained optimization parallel sequential machines 
technical report rice university department computational applied mathematics 
michael wolf monica lam 
data locality optimizing algorithm 
sigplan notices june 
proceedings acm sigplan conference programming language design implementation 
william wulf richard johnson charles weinstock steven hobbs charles 
design optimizing compiler 
programming language series 
american elsevier publishing 

