detection agreement vs disagreement meetings training unlabeled data mari ostendorf university washington ee mo ee washington edu support summarization automatically transcribed meetings introduce classifier recognize agreement disagreement utterances utilizing word prosodic cues 
show hand labeling efforts minimized unsupervised training large unlabeled data set combined supervised training small amount data 
asr transcripts wer system recovers nearly agree disagree utterances confusion rate 
meetings integral component life organizations records meetings important helping people recall learn time took place meeting 
audio audio visual recordings meetings offer complete record interactions listening complete recording impractical 
facilitate browsing summarization meeting recordings useful automatically annotate topic participant interaction characteristics 
focus interactions specifically identifying agreement disagreement 
categories particularly important identifying decisions meetings inferring decisions controversial useful automatic summarization 
addition detecting agreement important associating action items meeting participants understanding social dynamics 
study focus detection prosodic language cues contrasting results automatically transcribed data 
agreement disagreement labels thought sort speech act categorization 
automatic classification speech acts subject studies 
builds shriberg showed prosodic features useful classifying speech acts lead increased accuracy combined word cues 
studies look prediction speech acts primarily word cues elizabeth shriberg sri international icsi ees speech sri com language models syntactic structure discourse history chu carroll reithinger 
informed studies departs significantly exploring unsupervised training techniques 
approach experiments subset meeting recordings collected transcribed icsi morgan 
meetings segmented automatically human adjustment total 
define spurt period speech speaker pauses greater half second shriberg 
sentences goal asr outputs unsupervised training paradigms hand labeled sentence segmentations available 
define categories positive backchannel negative 
frequent single word specifically right uh huh ok separated positive category backchannels trivial nature detection may reflect encouragement speaker continue actual agreement 
examples include neg doesn answer question pos sounds great back uh huh move topic meetings hand labeled categories listening speech viewing transcripts right labeled disagreement despite positive wording 
comparing tags labelers produced kappa coefficient siegel castellan generally considered acceptable 
additionally unlabeled hand transcribed training meetings unsupervised training experiments described 
total number automatically labeled times amount hand labeled data 
system development control learning word cues training 
evaluate model hand transcribed words asr output 
category labels hand transcriptions mapped asr transcripts assigning asr spurt hand labeled half time wise asr spurt overlaps spurt 
feature extraction 
features classification include heuristic word types counts word features derived gram scores prosodic features 
simple word features include total number words spurt number positive negative keywords class positive negative backchannel discourse marker word keywords 
keywords chosen effectiveness ratio defined frequency word word pair desired class divided frequency dissimilar classes combined 
minimum occurrences required instances ratio greater selected keywords 
word features computing perplexity average log probability sequence words spurt bigram language model lm classes 
perplexity indicates goodness fit spurt class 
word class lms part speech classes words keywords 
addition word lm score words spurt contain information agreement disagreement 
label class type lm categorical feature compute posterior probability class 
prosodic features include pause fundamental frequency duration baron 
features derived word entire spurt 
average maximum initial pause duration features 
average maximum features computed different methods normalizing relative speaker dependent baseline mean max 
duration average maximum vowel duration forced alignment unnormalized normalized vowel identity phone context 
spurt length terms number words 
classifier design feature selection 
approach classifying uses decision tree classifier breiman combine word prosodic cues 
order facilitate learning cues frequent classes data duplicated number training points class 
decision tree size determined error cost complexity pruning fold cross validation 
reduce initial candidate feature set iterative feature selection algorithm involved running multiple decision trees shriberg 
algorithm combines elements brute force search leave paradigm previously de heuristics narrowing search space 
entropy reduction tree cross validation criterion selecting best subtree 
unsupervised training 
order train models data possible unsupervised clustering strategy incorporating unlabeled data 
bigram models class initialized dividing hand transcribed training data classes keywords 
contain negative keywords assigned negative class 
backchannels pulled spurt contains word falls backchannel word list 
selected agreements contain positive keywords 
remaining associated class 
keyword separation gives initial grouping regrouping involves unsupervised clustering maximum likelihood criterion 
preliminary language model trained initial groups 
evaluating spurt corpus language models new groups formed associating language model produces lowest perplexity 
new language models trained reorganized groups process iterated movement groups 
final class assignments truth unsupervised training language prosodic models contributing features decision trees 
results discussion hand labeled data meeting held test data hand labeled subset meetings training decision trees 
unlabeled taken meetings different test meeting unsupervised training 
performance measured terms way classification accuracy merging backchannel agreement classes 
accuracy results compared chance rate testing way data 
addition report confusion rate agreements disagreements recovery recall rate classes important application 
results table models word cues 
simple keyword indicators decision tree give best performance speech performance degrades dramatically asr output wer 
training conditions degradation performance system asr transcripts large significant 
system unsupervised training clearly outperforms system trained small amount hand labeled data 
interestingly hand transcriptions asr transcriptions features accuracy confusion recovery accuracy confusion recovery keywords hand trained lm unsupervised lm word table results detection different classifiers word features 
keywords combination language model provide benefit case system uses asr transcripts 
results table correspond models prosodic cues 
models trained small amount hand labeled data accuracy similar system keywords operating asr transcript 
performance somewhat better chance hand vs asr transcripts associated word alignments little impact 
small gain accuracy large gain agree disagree recovery data labeled unsupervised language model clustering technique 
unfortunately prosody features combined word features performance gain case asr transcripts 
transcripts train test accuracy confusion recovery hand hand unsup hand hand asr unsup asr table results classifiers prosodic features 
summary described approach automatic recognition agreement disagreement meeting data prosodic word features 
methods implemented small amount hand labeled data unsupervised lm clustering label additional data leads significant gains word prosody classifiers 
approach extensible types speech acts especially important domains little annotated data exists 
operating asr transcripts high obtain rate recovery agreements disagreements low rate confusion classes 
prosodic features provide results models asr transcripts additional benefit word features 
performance prosody offers hope performance gains richer set speech acts lexically ambiguous cases 
acknowledgments supported part nsf darpa nasa ncc 
opinions recommendations expressed material authors necessarily reflect views agencies 
baron 
automatic punctuation disfluency detection multi party meetings prosodic lexical cues 
proc 
icslp pages 
shriberg 

automatically generated prosodic cues lexically ambiguous dialog acts multi party meetings 

breiman 
classification regression trees 
wadsworth international group belmont ca 
chu carroll 

statistical model discourse act recognition dialogue interactions 
applying machine learning discourse processing 
papers aaai spring symposium pages 
morgan 
meeting project icsi 
proc 
conf 
human language technology pages march 
reithinger 

dialogue act classification language models 
proc 
eurospeech pages september 
shriberg 
prosody aid automatic classification dialog acts conversational speech 
language speech pages 
shriberg 
prosody automatic segmentation speech sentences topics 
speech communication september 
shriberg 
observations overlap findings implications automatic processing multi party conversation 
proc 
eurospeech pages 
siegel castellan 

nonparametric statistics behavioral sciences 
mcgraw hill new york ny second edition edition 
