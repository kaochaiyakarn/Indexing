organic grid self organizing computation peer peer network gerald baumgartner mario dept computer information science ohio state university lab neil ave columbus oh usa email gb cis ohio state edu desktop grids perform largest computations world potential grow orders magnitude 
current approaches utilizing desktop resources require centralized servers extensive knowledge underlying system limiting scalability 
propose biologically inspired fully decentralized approach organization computation autonomous scheduling strongly mobile agents peerto peer network 
radical departure current models envision large scale desktop grids agents autonomously organize maximize resource utilization 
encapsulating computation behavior agents organization computation customized different classes applications 
time design underlying infrastructure greatly simplified resulting system naturally lends true peer peer implementation node time provider user computing utility infrastructure 
demonstrate concept reduced scale concept implementation executes data intensive independent task application set heterogeneous geographically distributed machines 
detailed exploration design space system performance evaluation implementation metrics appropriate assessing self organizing desktop grids 
largest computations world carried collections pcs workstations internet 
tera flop levels computational power achieved systems composed heterogeneous computing resources number hundreds thousands millions 
large distributed systems allow internet computing referred desktop grids allow scientists run applications unprecedented scales greatly reduced costs 
impressive efforts tiny fraction desktops connected internet 
order magnitude improvements achieved novel systems organization computation introduced overcome limits systems 
describe novel infrastructure designed scratch maximize utilization large desktop grids 
questions tried answer best model utilization system harvesting idle cycles hundreds thousands millions pcs 
system designed order consistent grid computing ideals computation ubiquitous easily accessible utility 
planetary scale internet computing handled traditional grid scheduling models goes range current centralized master worker solutions :10.1.1.42.8707:10.1.1.12.8273:10.1.1.12.8273
new approach needed organize computation completely decentralized model 
different requirements different classes applications model easily customizable deployable 
addition due extremely dynamic nature underlying system realistic solution capable autonomously adapting current system conditions 
nature provides numerous examples complex systems comprising millions organisms organize autonomous adaptive way produce complex patterns 
systems emergence complex patterns derives superposition large number interactions organisms relatively simple behavior 
order apply approach task organizing computation complex systems desktop grids devise way breaking large computation small autonomous chunks endowing chunk appropriate behavior 
approach encapsulate computation behavior mobile agents 
similar concept explored montresor project showing ant algorithm solve problem tasks uniformly network :10.1.1.107.446
approach behavior designed produce desirable patterns execution current grid engineering principles 
specifically pattern computation resulting synthetic behavior agents reflects general concepts autonomous grid scheduling protocols studied 
approach extends previous results showing basic concepts extended accommodate highly dynamic systems ii practical implementation concepts 
consequence encapsulation behavior computation agents easily customized different classes applications 
desirable consequence underlying support infrastructure system extremely simple 
approach naturally lends true peer peer implementation node time provider user computing utility infrastructure 
scheme easily adapted case source computation node initiating computing job different source data 
main contributions description new organization principle desktop grids combines biologically inspired models organization autonomous scheduling strongly mobile agents ii demonstration principles working proof prototype iii detailed exploration design space system iv performance evaluation design metrics appropriate assessing self organizing desktop grids 
purpose initial exploration novel concept intended give quantitative assessment aspects implications new approach 
particular detailed evaluations scalability degree tolerance faults adaptivity rapidly changing systems left studies 
ii 
background related peer peer internet computing goal utilizing cpu cycles idle machines realized worm project xerox parc 
progress academic projects condor 
growth internet large scale efforts gimps seti home folding home feasible :10.1.1.12.8273
commercial solutions entropia united devices developed :10.1.1.12.8273
idea combining internet peer peer computing attractive potential unlimited computational power low cost ease universality access dream true computational grid 
technical challenges posed architecture scheduling formidable organize computation highly dynamic system planetary scale relying negligible amount knowledge state 
scheduling decentralized scheduling field attracted considerable attention 
level scheduling schemes considered scalable internet 
scheduling heuristic described machine attempts map tasks best neighbors 
appears require machine estimate execution time subtasks neighbors bandwidth links machines 
clear scheme practical large scale dynamic environments 
commerce study dynamic resource allocation grid terms computational market economies applications buy resources market price influenced demand 
conceptually decentralized implemented scheme require equivalent centralized commodity markets banks auction houses offer demand meet commodity prices determined 
new autonomous decentralized approach scheduling proposed address specifically needs large grid peer peer platforms 
protocol computation organized treestructured overlay network origin tasks root 
node system sends tasks receives results best neighbors bandwidth constraints 
shortcoming scheme structure tree consequently performance system depends completely initial structure overlay network 
lack dynamism bound affect performance scheme limit number machines participate computation 
self organization complex systems organization complex biological social systems explained terms aggregations large number autonomous entities behave simple rules 
theory complicated patterns emerge interplay agents despite simplicity rules 
existence mechanism referred emergence proposed explain patterns shell motifs animal coats neural structures social behavior 
particular certain complex behaviors social insects ants bees studied detail applications solution specific computer science problems proposed :10.1.1.107.446
departure methodological approach followed previous projects try accurately reproduce naturally occurring behavior 
started problem designed completely artificial behavior result satisfactory solution 
inspired particular version emergence principle called local activation long range inhibition shown responsible formation complex pattern clever experiment ants 
strongly mobile agents progress presence frequent desktop machines current systems rely different forms checkpointing automatic seti home voluntary legion 
storage computational overheads checkpointing put constraints design system 
avoid drawback desktop grids need support asynchronous transparent migration processes machine boundaries 
mobile agents relocation autonomy 
agents offer flexible means distributing data code network dynamically moving hosts resource availability varies carrying multiple threads execution simultaneously perform computation decentralized scheduling communication agents 
majority mobile agent systems developed java 
execution model java virtual machine permit agent access execution state java mobility libraries provide weak mobility 
weak mobility forces programmers difficult programming style 
contrast agent systems strong mobility provide abstraction execution agent uninterrupted location changes 
applications agents migrate host host communicating severely restricted absence strong mobility 
strong mobility allows programmers far natural programming style 
ability system support migration agent time external thread termed forced mobility 
essential desktop grid systems owners need able reclaim resources 
forced mobility difficult implement strong mobility 
provide strong forced mobility full java programming language preprocessor translates strongly mobile source code weakly mobile source code 
generated weakly mobile code maintains movable execution state thread times 
iii 
autonomic scheduling agent behavior design organization computation distributed system account specific communication pattern application 
initial exploration scheme selected parameter sweep template application class applications frequently studied context grid scheduling number results available 
works inspired project bandwidth centric protocol proposed grid computation organized treestructured overlay network origin tasks root 
tree overlay network represents natural intuitive way distributing tasks collecting results 
drawback original scheme performance degree utilization system depend entirely initial assignment overlay network 
contrast developed systems adaptive absence knowledge machine configurations connection bandwidths network topology assuming minimal amount initial information 
scheme tree overlay network keeps changing adapt system conditions 
tree adaptation mechanism driven perceived performance node children measured passively part ongoing computation 
point view network topology system starts small amount knowledge form friends list keeps building overlay network fly 
information node friends list shared nodes initial configuration lists critical 
assumption rely friends list available initially node prime system solutions construction lists developed context peer peer file sharing addressed :10.1.1.140.3129
local activation long range inhibition rule types interactions positive reinforcing works short range negative destructive works longer distances 
retain principle different form definition distance performance metric 
experiment distance perceived throughput function communication bandwidth computational throughput 
nodes initially recruited friends list way completely oblivious distance propagating computation distant nodes probability close ones 
course computation agents behavior encourages propagation computation connected nodes discouraging inclusion distant responsive agents 
methodology followed design agent behavior follows 
engineering approach selected tree structured overlay network desirable pattern execution 
empirically determined simplest behavior organize communication task distribution mobile agents pattern 
augmented basic behavior way introduced desirable properties 
total computation time performance metric addition basic scheme separately evaluated contribution total performance quantitatively assessed 
property constant adaptation 
overlay tree incrementally restructured computation adjust performance nodes 
property performance monitoring child nodes 
assumed knowledge available system child performance determined feedback 
functions critical performance automatic determination parameters prefetching task size detection cycles detection dead nodes computation 
scheme general accommodate different classes applications focus solution particular problem scheduling independent identical subtasks independent task application ita data initially resides location 
size individual subtasks results large transfer times neglected 
application experiments ncbi nucleotide nucleotide sequence comparison tool blast 
basic agent design large computational task written strongly mobile agent 
task divisible number independent subtasks 
user starts computation agent machine 
thread agent begins executing subtasks sequentially 
agent prepared receive requests machines 
machine subtasks receives request machine sends clone requesting machine 
requester machine child 
clone asks parent certain number subtasks thread begins compute subtasks 
threads created required communicate parent machines 
requests received agent dispatches clone requester 
computation spreads manner 
topology resulting overlay network tree originating machine root node 
agent requests parent executed subtasks 
parent requested number subtasks respond send child 
parent keeps record number subtasks remain sent sends request parent 
time node tree obtains results computed obtained child sends parent 
message includes request pending subtasks 
maintenance child lists node arbitrarily large number children 
data transfer times subtasks large node wait long time request satisfied 
node fixed number children number children small avoid deep trees long delays data propagation 
children ranked basis performance 
performance metric application dependent 
ita child evaluated basis rate sends results 
child sends results node measures time interval time sent results 
final result rate child calculated average time intervals 
ranking reflection performance just child entire subtree child node root 
addition children node parent potential children 
children node able evaluate 
potential child send results node added list node children 
node children slowest child sc removed child list 
described sc list nodes contact try get back tree 
current node keeps record children sc placed list 
nodes removed list sufficient userdefined time period elapses 
interval time messages sc ignored 
avoids thrashing excessive dynamism tree 
restructuring overlay network topology overlay network tree desirable best performing nodes close root 
principle applicable entire tree 
case ita minimizes communication delay root best nodes overlay network structured nodes highest throughput close root pushing low throughput leaves 
node periodically informs parent child 
parent checks grandchild list children 
adds grandchild list potential children tells node willing consider grandchild 
node instructs child contact grandparent directly 
node updates child list decides remove slowest child sc simply discard child 
prepares list children descending order performance slowest node 
list sent sc attempts contact nodes turn 
nodes contacted slower ones tree sought kept balanced 
size result burst agent ita ranks children basis time taken send results node 
time required obtain just result burst result burst size measure performance child 
nodes poor decisions children keep discard 
child propagation algorithm benefits average result burst intervals setting result burst burst size greater 
better measure performance child time taken node obtain results 
set large values overlay network take time take form get updated 
fault tolerance parent node inaccessible due machine link failures node descendants disconnected tree 
node able contact parent ancestors necessary 
node keeps list ancestors 
list updated time parent sends message 
child waits certain user defined time response sending message parent th node 
parent able respond 
child receive response check request satisfied subtasks waiting case 
response obtained timeout period child sends message th node list 
goes ancestor responds node request 
ancestor parent current node normal operation resumes 
node ancestor list goes size computation agent node self stationary agent begins send requests list friends 
cycles overlay network overlay network tree failures cause formation cycle nodes 
cycle nodes eventually run subtasks compute 
situation avoided having node examine ancestor list receiving parent 
node finds list knows cycle occurred computation agent self 
cycle involves large number nodes ancestor list may small include current node 
node keeps track total time elapsed received subtask 
time exceeds userdefined limit cycle assumed taken shape computation agent node destroys 
termination root tree determines computation terminated 
sends termination message actual potential children 
computation agent root self 
children root 
termination messages spread leaves computation terminates 
scenarios termination incomplete termination message reach node 
situation described subsection iii 
consider computation agents executing nodes 
receives termination message failure 
agent destroys 
sends request messages friends 
clone agent sent 
unchecked spread computation occur agents send clones subtasks 
eventually run fast medium slow origin knows fig 

configuration priori knowledge parameter name parameter value maximum children maximum potential children result burst size self adjustment linear number subtasks initially requested child propagation table original parameters subtasks destroy explained subsection iii 
self adjustment task list size node requests certain number subtasks obtains results requesting subtasks 
ita type application utilization high performance machine may poor requesting fixed number subtasks time 
node may request subtasks order increase utilization resources 
node requests certain number subtasks compute 
finished computing subtasks compares average time compute subtask run previous run 
depending performed better worse node requests subtasks run increasing decreasing functions respectively 
prefetching node determines request subtasks parent 
optimistic prediction subtasks require function self adjustment 
subtasks requested parent 
node finishes computing set subtasks subtasks readily available request submitted parent 
prefetching reduce delay obtaining new subtasks increases amount data needs transferred time root current node increasing synchronization delay data transfer time 
excessively aggressive prefetching result performance degradation 
iv 
measurements conducted experiments evaluate performance aspect scheduling scheme 
experiments fast medium slow child potential child origin fig 

final node organization result burst size initial configuration number nodes time sec fig 

code ramp performed cluster eighteen heterogeneous machines different locations ohio 
machines ran weak mobility agent environment top linux solaris 
application test system gene sequence similarity search tool ncbi nucleotide nucleotide blast independent task application 
task match kb sequence data chunks size kb 
subtask match sequence chunk 
eighteen machines offered performance fast connections internet high processor speeds large memories 
order obtain heterogeneity performance introduced delays application code simulate effect slower machines slower network connections 
divided machines fast medium slow categories introducing delays application code 
shown nodes initially organized randomly 
dotted arrows indicate directions request messages sent friends 
thing machine knew friend url 
ran computation parameters described table linear means increasing decreasing functions number subtasks requested node linear 
time required code subtask arrive different nodes seen 
experiments 
comparison knowledge scheme purpose tests evaluate quality configuration autonomously determined scheme different initial conditions 
fast medium slow knows origin fig 

random configuration machines configuration running time sec original table ii effect prior knowledge scheme running time sec table iii effect child propagation experiments conducted parameters table manually created initial configuration assuming priori knowledge system parameters 
ran application verified final configuration substantially depart initial 
consider configuration fast nodes nearer root 
figures represent start experiment 
final tree configuration shows fast nodes kept near root system constantly re evaluating node possible relocation shown rightmost children evaluation root 
began second experiment completely random configuration shown 
resulting configuration shown substantially similar configurations previous experiment execution time longer migration root fast nodes depths complete 
effect child propagation performed computation child propagation aspect scheduling scheme disabled 
comparisons running times topologies table iii figures 
child propagation mechanism results improvement running time 
reason improvement difference topologies 
child propagation turned best performing nodes closer root 
subtasks results travel nodes faster rate improving system throughput 
result burst size experimental setup table 
ran experiment different result burst sizes 
running times tabulated table iv 
child fast medium slow child potential child origin fig 

final node organization result burst size child propagation fast medium slow child origin potential child fig 

final node organization result burst size child propagation evaluations nodes basis result poor 
nodes child lists change frequently far ideal 
qualitative improvement child lists result burst size increases 
structure resulting overlay networks result burst sizes figures 
large result bursts takes longer tree overlay form adapt slowing experiment 
seen 
prefetching initial task size data ramp time time required subtasks reach single node 
prefetching positive effect 
minimum number subtasks node requests affects data ramp 
greater number greater amount data needs sent node slower data ramp 
seen table prefetching improves ramp paramount importance effect running time experiment 
closely related minimum number subtasks requested node 
prefetching improves system throughput minimum number subtasks requested 
minimum number subtasks requested node increases data needs transferred time root node effect prefetching negligible 
number increases prefetching causes degradation throughput 
table summarize results 
fast medium slow result burst size running time sec table iv effect result burst size child potential child origin fig 

node organization result burst size self adjustment ran experiment configuration table constant exponential functions linear 
data compared table vi 
ramp exponential self adjustment appreciably faster linear constant self adjustment 
aggressive approach performs better nodes prefetch larger amount subtasks subtasks quickly reach nodes farthest root 
compared running times runs table vi 
interestingly run exponential performed poorly respect runs 
due nodes prefetching extremely large numbers subtasks 
nodes spend time waiting requests satisfied resulting degradation throughput node 
linear case expected perform better constant observed difference insignificant 
expect difference pronounced longer experimental runs larger number subtasks 
number children experimented different child list sizes data ramp time maximum number children set maximum number children set 
results table vii 
root able take children cases spread subtasks nodes originally far root takes time 
exhibiting better performance runs large numbers children allowed approximately total running time run maximum number children set 
children wait longer time requests satisfied 
order obtain better idea effect children waiting requests satisfied ran fast medium slow child potential child origin fig 

node organization result burst size 
ramp ramp running running subtasks time sec time sec time sec time sec prefetching prefetching prefetching prefetching table effect prefetching minimum number subtasks experiments initial configuration star topology nonroot node adjacent root experiment 
maximum sizes child lists set respectively 
overlay networks organized little change topology computation progressed minimal impact changes running time 
effect size child list clearly observed table viii 
similar results observed child propagation mechanisms turned 
designed autonomic scheduling algorithm multi threaded agents strong mobility form treestructured overlay network 
structure tree varied dynamically nodes currently exhibit performance brought closer root improving performance system 
experimented scheduling massively parallel application data initially resides location subtasks considerable data transfer times 
experiments conducted set machines distributed ohio 
nodes evaluated basis throughput 
extensive analysis performance scheme various mechanisms show feasibility approach 
research problem assigning friend lists consider best apply :10.1.1.140.3129
experiment incorporating interruptible communication mechanism scheme 
concentrated scheduling scheme independent task applications experiment adapting algorithm wide class applications 
intention desktop grid user simple software time sec prefetch prefetch number initial sub tasks fig 

effect prefetching min 
subtasks self adjustment ramp running function time sec time sec linear constant exponential table vi effect self adjustment function interface allow customize scheduling schemes characteristics application 
experimental platform set heterogeneous machines 
plan harness computing power idle machines internet ohio state university particular create desktop grid scale tens hundreds thousands 
researchers free deploy scientific applications system 
vi 
partially supported ohio supercomputer center pas pas 
grimshaw wulf legion vision worldwide virtual computer communications acm vol 
jan 
berman wolski casanova cirne hayes schopf shao spring su adaptive computing grid apples ieee transactions parallel distributed systems vol 
pp 

abramson giddy high performance parametric modeling nimrod killer application global grid proceedings international parallel distributed processing symposium may pp :10.1.1.42.8707

taylor shields wang grid resource management 
kluwer june ch 
resource management services 

online 
available www mersenne org prime htm seti home 
online 
available ssl berkeley edu folding home :10.1.1.12.8273
online 
available folding stanford edu chien calder bhatia entropia architecture performance enterprise desktop grid system journal parallel distributed computing vol :10.1.1.12.8273
pp 

litzkow livny mutka condor hunter idle workstations proceedings th international conference distributed computing systems june 
maheswaran ali siegel hensgen freund dynamic matching scheduling class independent tasks heterogeneous computing systems proceedings th heterogeneous computing workshop apr pp 

livny adaptive scheduling master worker applications computational grid proceedings international workshop grid computing pp 

max 
time children sec table vii effect 
children data ramp max 
time children sec table viii effect 
children running time kindberg adaptive parallelism proceedings nd international workshop configurable distributed systems mar pp 

tracy vernon wright near optimal adaptive control large grid application proceedings international conference supercomputing june 
karonis foster mpich grid enabled implementation message passing interface journal parallel distributed computing vol 
pp 

montresor meling babaoglu messor load balancing swarm autonomous agents proceedings st workshop agent peer peer systems july :10.1.1.107.446
carter casanova ferrante autonomous protocols bandwidth centric scheduling independent task applications proceedings international parallel distributed processing symposium apr pp 

john worm programs early experience distributed computation communications acm vol 
mar 
devices 
online 
available www ud com james scheduling independent tasks metacomputing systems proceedings parallel distributed computing systems aug 
van hierarchical job scheduling clusters workstations proceedings th annual conference advanced school computing imaging june pp 

potter scott dynamic task mapping algorithms distributed heterogeneous computing environment proceedings heterogeneous computing workshop apr pp 

wolski plank bryan analyzing market resource allocation strategies computational grid international journal high performance computing applications vol 

turing chemical basis morphogenesis philos 
trans 
soc 
london pp 

theory biological pattern formation kybernetik pp 

bonabeau dorigo theraulaz swarm intelligence natural artificial systems 
oxford university press santa fe institute studies sciences complexity 
theraulaz bonabeau nicolis sol blanco fournier 
joly 
deneubourg spatial patterns ant colonies pnas vol 
pp 

lange oshima reasons mobile agents communications acm vol 
mar 
cugola ghezzi picco vigna analyzing mobile code languages mobile object systems programmable internet 
wang baumgartner implementation strong mobility multi threaded agents java proceedings international conference parallel processing 
ieee computer society oct 
implementation strong mobility multi threaded agents java dept computer information science ohio state university tech 
rep osu tr feb 
baumgartner organic grid self organizing computation peer peer network dept computer information science ohio state university tech 
rep osu tr oct 
gnutella 
online 
available www gnutella com ratnasamy francis handley karp shenker scalable content addressable network proceedings acm sig comm 
basic local alignment search tool 
online 
available www ncbi nlm nih gov blast 
