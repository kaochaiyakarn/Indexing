bayesian extension language model ad hoc information retrieval hugo zaragoza microsoft research cambridge microsoft com propose bayesian extension ad hoc language model 
smoothed estimators multinomial query model ad hoc language models including laplace bayes smoothing approximations bayesian predictive distribution 
derive full predictive distribution form amenable implementation classical ir models compare currently estimators 
experiments proposed model outperforms bayes smoothing combination linear interpolation smoothing outperforms estimators 
categories subject descriptors retrieval models general terms algorithms performance theory keywords information retrieval ad hoc retrieval ad hoc language model bayesian language model 
years language models promising areas progress information retrieval theory practice expected 
language model computes relevance document respect query estimating factorised form distribution 
alternative formulations derivations language model different generalisations :10.1.1.43.7803
despite fact ways remain controversial language models great interest elegant mathematical models ad hoc retrieval shown produce excellent empirical results 
permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
sigir july august toronto canada 
copyright acm 
hiemstra university twente netherlands hiemstra cs utwente nl michael tipping microsoft research cambridge microsoft com propose bayesian extension language model 
bayesian statistics provide useful concepts tools estimation great interest information retrieval community 
provide powerful intuitive mathematical framework data modelling data scarce uncertain prior knowledge 
particular interested bayesian statistics language model away need explicitly smooth parameters 
uncertainty data taken account inference framework 
fact best smoothing techniques today language models bayes smoothing dirichlet smoothing 
bayes smoothing approximation full bayesian inference model fact maximum posterior approximation predictive distribution 
derive analytically predictive distribution commonly query language model show experimentally improves performance usual bayes smoothing solution ii yields systems stable choice learning parameters 
similar study smoothed gram language models developed section describe standard language model ad hoc document retrieval section propose new bayesian predictive model 
section ties new model existing ones particular widely estimators linearly interpolated maximum likelihood smoothing bayes smoothing 
section describes evaluation models 

unigram query model describe specific form language model consider exactly model proposed :10.1.1.136.8113
refer model remainder query unigram model 
consider query document collection documents dl queries documents represented vectors indexed term counts qi qv dl dl dl dl qi number times term appears query size vocabulary 
furthermore consider multinomial generation model document parameterised vector indicates probabilities emission different terms vocabulary 
define length query nq document nl sum components nq qi 
model probability generating particular query counts product similarly documents zq dl dl nq zd qv nl dl dl constants respect model parameters unigram query model postulates relevance document query measured probability query generated document 
meant likelihood query parameters estimated dl sample underlying distribution 
central problem model estimation cfi dl parameters document counts dl collection counts size collection infinite amount data case infinitely long documents value parameters easily estimated empirical estimates dl nl referred maximum likelihood estimates maximised likelihood documents defined unfortunately little data estimation parameters case single document empirical estimator greatly underestimates probability rare words estimates probability frequent ones 
specially dangerous terms query document dl qi referred unseen words empirical estimate driving zero document score regardless matching terms query document 
alleviate effect small data samples different estimation schools propose different techniques different philosophies 
lead different adjustments empirical estimate referred smoothed estimates 
smoothing techniques favoured past language models maximum posterior estimator linearly interpolated maximum likelihood estimator 
discussed section 
mk 
ki mi 

bayesian language model problem small data samples resulting parameter uncertainty suggests bayesian techniques 
approach offers natural principled way take account uncertainty integrating unknown model parameters 
initially find single point estimate parameter vector distribution obtained combining prior distribution model parameters observation likelihood dl bayes rule dl dl dl document dl large expect posterior dl reflect relatively narrow 
case small document posterior broader encapsulating uncertainty value mode posterior exploited existing maximum posterior techniques powerful approach take account posterior uncertainty evaluating probability computing predictive distribution dl dl dl dl fact document query assumed generated distribution seen predictive distribution results averaging probability model possible parameter values weighted posterior probability dl 
case abundant data posterior dl peaked value seen dl conventional maximum likelihood predictor recovered 
conversely posterior broad averaging process accounts uncertainty parameter values 
choice prior probability distributions central bayesian inference especially context small data samples 
theory choose prior distribution reflects available knowledge solution 
practice restricted distributions compute integral 
cases available choice prior natural conjugate generating distribution defined 
distribution called natural conjugate distribution resulting posterior distribution functional form prior section 
natural conjugate multinomial distribution dirichlet distribution vi depend parameters 
verify prior resulting posterior alternatively consider separate distributions sufficiently similar valid approximation 
distribution dl nd dl choose prior distribution 
distribution number hyper parameters equal number parameters model 
virtue prior interpreted additional data pseudo counts discuss set value 
compute predictive distribution follows see detailed derivation appendix dl dl qi qi dl zq nq nd 
constitutes new document scoring function 
log separating terms query appearing document rewrite final form log dl qi di nq dl log log nd qi log log zq terms dropped document independent :10.1.1.136.8113
discuss similarities differences function traditional multinomial query model section 
setting hyper parameter values value hyper parameters depends prior knowledge problem document dl know form queries generated 
possibilities exist 
attribute equal probability words query set constant 
see section leads different maximum likelihood smoothed estimates 
better option fit prior distribution collection statistics known 
absence information assume documents query resemble average document 
average term count term ti proportional vi nl prior probability observing term vi document 
hand mean posterior distribution known appendix 
setting mean equal average term count obtain constraint vi satisfied setting vi andn new parameter undetermined 
free parameter empirical evaluation model 

relationship smooth ing models types smoothed maximum likelihood estimators implement language model bayes smoothing linear interpolation smoothing :10.1.1.136.8113:10.1.1.131.5458
standard approximation bayesian predictive distribution called maximum posterior mp distribution 
approximation consists replacing integral posterior single maximum value mp mp prior maximum posterior distribution known analytically mp dl nl setting obtain maximum likelihood estimator ml dl nl setting setting obtain laplace smoothing estimators la dl nl la dl nl setting vi described section obtain bayes smoothing estimate bs dl vi nl see different smoothed estimators approximations full estimator obtained replacing predictive distribution maximum posterior distribution ii choosing particular value linear interpolation li smoothing referred mercer smoothing written li ml vi estimator derived predictive distribution fact type smoothing viewed mixture generative models 
stage smoothing estimator developed combine bayes linear interpolation estimators achieved replacing ml bs 
approximation full bayesian treatment linear interpolation smoothing method 
full predictive distribution mixture model underlying method analytical solution treatment scope 
look scoring functions resulting estimators 
note case bs li probability unseen word dl bayesian statistics way derive estimators 
alternative treatment see example 
qi written lp vi document dependant constant vi defined 
case rewrite unigram query model log rank qi log nq log lp vi term involves query document matches :10.1.1.136.8113:10.1.1.136.8113:10.1.1.136.8113
estimators section dl holds replacing term fall back smoothing model estimator true 
quite general formulation unigram query model 
arriving equation form crucial efficient implementation ad hoc system reasons fast inverted index retrieve weights needed compute term ii number operations compute term depends number term indices matching iii cost computing second term 
implementation cost estimators considered similar 
exist estimators written form implementation real ir system problematic considered 
note bayesian predictive model proposed leads scoring function similar excepting number operations compute term depends number terms number indices matching ii term pre computed depends query computational cost remains negligible 
proposed bayes predictive model leads adhoc model slightly expensive compute original implemented real scale ir system 
fact scoring functions resulting bayes predictive distribution bayes smoothing similar 
looking term score matching terms observe functions converge long documents short queries uncertainty document score 
great similarity functions indication practice maximum posterior approximation bayes smoothing 

empirical evaluation measuring performance ad hoc retrieval systems attempt estimate true performance system averaged performance unknown documents queries 
known true performance arbitrarily far performance observed training collection collection optimise model parameters 
reason important differentiate training test collection 
ad hoc retrieval differentiation tricky 
document collections tend stable completely fixed sense train test document collections 
case queries 
performance ad hoc system evaluated test collection queries relevance judge ments different training collection 
model parameters depend document counts affected choice query relevance judgements set collection 
smoothing parameters hyper parameters depend choice 
optimising parameters draw performance observed particular set queries 
order simulate process deciding optimal learning parameter values real setting trec document collection trec trec queries query relevance sets 
produced results set trec queries separately range smoothing parameters looked performance set obtained parameter setting optimal set 
crude form fold cross validation advantage producing results comparable previously published trec collections 
data pre processing standard terms stemmed porter stemmer words removed words appearing fewer times 
queries constructed concatenating title description topic 
trec document collection trec relevance judgements congressional records collection ignored 
experiments reported performed exploratory types queries shorter longer collections experiments yielded results similar 
exhaustive evaluation proposed model remains done 
report performance measures averaged queries macro averages average precision top retrieved documents precision retrieving relevant documents relevant documents total 
model indicated bold underlined value obtained trec query set optimal parameter settings obtained trec query set 
tables results obtained models discussed previously different values models parameters sets queries 
performance ml laplace estimators worse rest reported 
note new model yields comparable results best reported smoothing models mixture model 
second note case bayes predictive model optimal parameter setting roughly query sets measures 
average precision peaks roughly sets 
conversely bayes smoothing value varies greatly 
example model yields excellent results trec poor results trec 
observe effect new bayes predictive model 
hopes developing bayesian predictive model take account difference data uncertainty short long documents common rare terms 
fact model improves model indicate succeeded doing extent 
gains chose measure traditional prec measure compare performance different estimators low recall regime 
table average precision results different smoothed estimators 
bayes predictive trec trec bayes smoothing trec trec linearly interpolated trec trec table precision recall results different smoothed estimators 
bayes predictive trec trec bayes smoothing trec trec linear interpolation trec trec impressive precision recall reported table new model improve results especially low recall region indicating documents receiving high scores bayes smoothing successfully demoted bayes predictive model 
linear interpolation smoothing yields slightly better results bayes smoothing bayes predictive model optimal parameter value quite stable 
reported past bayes smoothing leads better performance linear interpolation smoothing seen experiments :10.1.1.136.8113
cases expect bayes predictive model produce higher performances 
furthermore argued linear interpolation smoothing provides extra level smoothing natural ir tasks models background terms appearing query 
reason combined bayes smoothing linear interpolation smoothing methods described 
argued earlier easily done fully bayesian model currently investigating approximations achieve 
interesting combine strengths bayes predictive model linear interpolation smooth table average precision results pair wise combinations score products bs bayes predictive bp linear interpolation smoothing li 
trec trec bp li bp bs bs li ing 
adopted mixture experts approach combined systems uncorrelated sum log scores :10.1.1.136.8113
comparison purposes pair models bayes predictive bp linear interpolation li ii bayes smoothing bs li iii bp bs 
results shown table 
best absolute results average precision best relative gain obtained combining bayes predictive model linear interpolation smoothing 
evidence strength bayes predictive model derived bayes smoothing complementary linear smoothing combined 

bayesian analysis query unigram language model ad hoc retrieval proposed new scoring function derived bayesian predictive distribution smoothed estimators approximate 
furthermore shown computational cost slightly greater existing estimators 
empirical evaluation new method shows new model performs better bayes smoothing linear interpolation smoothing remains done combine adequate manner approaches 
encouraging result direction simple combination scores produced best performance 
remains done automatically adapt scaling parameter currently investigating techniques exploiting analytical form predictive distribution 
think bayesian inference framework applied language models extend model tasks relevance feedback query expansion adaptive filtering 

additional authors additional authors stephen robertson microsoft research cambridge email ser microsoft com 
berger lafferty :10.1.1.43.7803
information retrieval statistical translation 
hearst tong editors sigir proceedings nd annual international acm sigir conference research development information retrieval pages 
acm press 
stanley chen joshua goodman :10.1.1.131.5458
empirical study smoothing techniques language modeling 
technical report tr center research computing technology 
harvard university august 
croft harper kraft zobel editors 
sigir proceedings th annual international acm sigir conference research development information retrieval 
acm press 
gelman carlin stern andd rubin 
bayesian data analysis 
chapman hall crc 
hiemstra kraaij 
trec ad hoc cross language track 
voorhees harman pages 
nist special publication 
lavrenko croft 
relevance language models 
croft pages 
david mckay linda peto 
hierarchical dirichlet language model 
natural language engineering 
miller leek schwartz 
bbn trec hidden markov models information retrieval 
voorhees harman pages 
nist special publication 
ponte croft 
language modeling approach information retrieval 
croft moffat van rijsbergen wilkinson editors sigir proceedings st annual international acm sigir conference research development information retrieval pages 
acm press 
robertson hiemstra 
language models probability relevance 
proceedings workshop language modeling information retrieval pages 
voorhees harman editors 
seventh text retrieval conference trec 
gaithersburg md nist 
nist special publication 
grace wahba 
spline models observational data volume 
siam 
zhai lafferty :10.1.1.136.8113
study smoothing methods language models applied ad hoc information retrieval 
croft 
zhai lafferty 
stage language models information retrieval 
beaulieu baeza yates myaeng editors sigir proceedings th annual international acm sigir conference research development information retrieval pages 
acm press 
appendix dirichlet multinomial distribution dl zq zq zq di nd qi qi qi dl nq nd qi dl nd di nq nd qi dl nq nd line property 
