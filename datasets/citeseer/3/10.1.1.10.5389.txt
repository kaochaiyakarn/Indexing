probability estimates multi class classification pairwise coupling ting fan wu chih jen lin ruby weng national taiwan university national university pairwise coupling popular multi class classification method combines pairwise comparisons pair classes 
presents approaches obtaining class probabilities 
methods reduced linear systems easy implement 
show conceptually experimentally proposed approaches stable existing popular methods voting 


multi class classification problem refers assigning obser classes 
class problems easier solve authors propose class classifiers multi class classification 
focus techniques provide multi class classification solution combining pairwise comparisons 
common way combine pairwise comparisons voting 
constructs rule discriminating pair classes selecting class winning class decisions 
voting procedure requires just pairwise decisions predicts class label 
scenarios probability estimates desired 
numerous pairwise clas provide class probabilities authors proposed probability estimates combining pairwise class probabilities 
observation class label assume estimated pairwise class probabilities rij ij available 
rij obtained binary classifiers 
goal estimate pi pi 
ams subject classifications 
key words phrases 
pairwise coupling probability estimates random forest support vector machines department computer science national taiwan university taipei taiwan 
department statistics national university taipei taiwan 
propose obtain approximate solution identity select label highest estimated class probability 
existence solution guaranteed theory finite markov chains 
motivated optimization formulation method propose second approach 
interestingly regarded improved version coupling approach 
proposed methods reduced solving linear systems simple practical implementation 
furthermore conceptual experimental points view show proposed methods stable voting method 
organize follows 
section review existing methods 
sections detail proposed approaches 
section presents relationship different methods corresponding optimization formulas 
section compare methods simulated data 
section conduct experiments real data 
classifiers considered support vector machines random forest 
preliminary version 

survey existing methods 
voting rij estimates ij pi pi pj 
voting rule rij rji 
simple estimate probabilities derived rij rji 

method authors consider rij rji ij ji pi pj making equality may way solve pi 
number equations number unknowns proposes choose rij condition pi obtained solving linear system 
pointed results strongly depend selection rij section considering propose method remedies problem 

method price personnaz dreyfus authors consider 
obtains rij ij pi 
rij pi hold normalize approach simple easy implement 
rest refer method 

method hastie tibshirani authors propose minimize kullback leibler kl distance rij ij log rij ij pi pi pj nij number training data ith jth class 
find minimizer calculate pi rij nij pi ij pi pj letting proposes find point satisfying nij ij pi pi 
point obtained algorithm algorithm 
start initial pi corresponding ij pi pi pj 

repeat 

nij ij ij ij ij ji pi pi normalize optional ji ij consecutive close ones criteria 

pi remarks algorithm 
initial pi positive pi positive defined 
second optional operation normalize affect values ij 
proves algorithm generates sequence points kl distance strictly decreasing 
indicated strict decrease guarantee limit point satisfies 
discusses convergence algorithms generalized bradley terry models algorithm special case 
points proved initial point sequence generated algorithm converges point satisfying point unique global minimum constraints pi pi 
denote global minimum 
shown theorem satisfies ris pj pi sufficient requires classification rule 
fact pointed derived approximation identity pi pi pj replacing pi pj ij rij 
pi pi pj pi pj ij sections propose methods simpler practical implemen tation algorithmic analysis 

approach note ht essentially argmax pi approximate solution 
replacing pi pj section propose solve system pi pi pj rij subject denote solution 
resulting decision rule argmax pi 
pi pi ht relies pi pj section examples illustrate possible problems rule 

solving solve rewrite qp pi rij pi qij ris observe qij 
qij 
exists finite markov chain transition matrix rij qij implies markov chain irreducible aperiodic 
theorem 
conditions guarantee existence unique stationary probability states positive recurrent 
theorem theorem rij unique solution pi note constraints pi linear system qp pi unique solution 
method section special iterative procedure implemented solve simple linear system 
practically remove equality qp square linear system solved standard gaussian elimination 
column sum vector ones verified square linear system equations unique solution 
hand stationary solution markov chain derived limit step transition probability matrix solve repeatedly multiplying initial vector 

look arguments show solution global minimum meaningful optimization problem 
re express qp 
property rij rji solution fact unique global minimum convex problem min subject pi pi 
reason object function nonnegative attains zero 
constraints pi necessary 

second approach note approaches sections involve solving optimization problems relations pi pi pj rij 
motivated suggest optimization formulation follows min subject pi pi note method described section considers random selection equations form 
considers just viewed improved version 
denote corresponding solution 
define classification rule argmax 

linear system unique solution obtained solving simple linear system desired see minimization problem nice properties 
subsection show solved simple linear system mild condition unique solution 
theorem shows nonnegative constraints redundant 
theorem problem equivalent min subject pi 
proof appendix note rewrite objective function min qij pt qp si positive semi definite vt qv 
constraints pi linear constrained convex quadratic programming problem 
consequently point global minimum satisfies tucker kkt optimality condition scalar vector ones vector zeros lagrangian multiplier equality constraint pi 
solution obtained solving simple linear system 

solving solved direct methods numerical linear algebra 
shows matrix invertible gaussian elimination easily applied 
matrix symmetric directly apply cholesky factorization save computational time matrix positive definite 
positive definite cholesky factorization obtain bq theorem ii shows positive definite quite general conditions 
positive semi definite theorem proves ee positive definite constant 
fact equivalent eet cholesky factorization ee solve similarly matter positive definite 
theorem ee positive definite 
addition unique global minimum 
ii 
positive definite 
leave proof appendix ris rij invertible addition direct methods propose simple iterative method solving algorithm 
start initial pi pi 
repeat 

satisfied 
pt normalize qp assumption rij ensure right hand side ative 
pi defined 
see explanation 
note qp obtained motivated tth equality replaced qp 
convergence algorithm established theorem theorem rsj pi sequence generated algorithm convergent sub sequence goes global minimum 
theorem indicates general positive definite sequence pi algorithm usually globally converges unique minimum 

relations different methods methods discussed decision rules ht written argmax pi derived optimization formulations constants pi pi ht min min min min rij pi rij rji pj rji rij pi note easily verified explained sections 
solution pi rji rij normalizing constant argmax pi 
detailed derivation appendix clearly obtained letting pj rji 
approximations ignore differences pi 
rij replaced rij rji may enlarge differences pi 
compared allows difference get canceled may tend underestimate differences pi 
conceptually extreme tends underestimate differences pi overestimate 
arguments supported simulated real data sections 
approach decision rule written kp argmin 
rij form looks similar ht rij obtained 
notice differences rij tend larger rij rij rij 
discussion rules section 
experiments synthetic data section synthetic data compare performance existing methods described section new approaches proposed sections 
include method section results strongly depend choice rij second method improved version 
designs simple experiment pi fairly close method ht outperforms voting strategy conduct experiment assess performance proposed methods 
define class probabilities pj 
set rij pi zij pi pj rji rij rij ji defined consider rij rji generally true 
addition ji ij optimal solution pi pj resulting decision 
zij standard normal variates 
rij required truncate rij example class highest probability correct class 
shows accuracy rates methods 
denotes largest integer exceeding accuracy rates averaged replicates 
note experiment classes quite competitive highest vote occurs different classes 
handle problem randomly selecting class ties 
partly explains performs poor 
explanation rij close uses stated previous section solution may severely biased 
rules done example 
ht relies approximation pi pj rule may suffer losses class probabilities highly balanced 
examine point consider sets class probabilities odd define pi 
pi 

define pi 
setting pi define pairwise comparisons rij 
experiments repeated times 
accuracy rates shown figures 
scenarios pi balanced 
expected ht quite sensitive imbalance pi 
situation worse approximation pi pj seriously violated especially large 
analysis shows large rij zij zij standard normal variates 
decision rule ht case mainly comparing 
difference sums table data set statistics dataset dna waveform satimage segment usps mnist letter class attribute 
large decision strongly depends normal variates probability choosing class approaching half 
hand kp relies comparing 
difference larger accuracy rates decline increases situation serious 
analyze mean square error mse mse pi probability estimate obtained jth replicates 
ht higher mse confirming stable 
summary sensitive pi performance fairly stable 
observations ht agree analysis section 
despite similarity ht kp outperforms ht general 
experiments done matlab 

experiments real data section experimental results multi class problems dna satimage segment letter statlog collection waveform uci machine learning repository usps mnist 
numbers classes features reported table 
dna takes possible values attribute data scaled 
scaled data randomly select training testing instances thousands data points 
selections generated testing error rates averaged 
similarly experiments larger sets training testing 
training testing sets available www csie ntu edu tw cjlin papers data 
accuracy rates log accuracy rates log accuracy rates log fig 

accuracy predicting true class methods ht solid line cross marked dashed line square marked dotted line circle marked dashed line asterisk marked kp line diamond marked 
mse log mse log mse log fig 

mse methods ht solid line cross marked dashed line square marked dotted line circle marked dashed line asterisk marked kp line diamond marked 

svm binary classifier consider support vector machines svm rbf kernel xi xj binary classifier 
regularization parameter kernel pa rameter selected cross validation 
training set fold cross validation conducted points 


done modifying libsvm library svm 
sequentially folds training set fold validation set 
training folds consists binary svms 
binary svm ith jth classes employ improved implementation platt posterior probabilities estimate rij rij estimated minimizing negative log likelihood function decision values training data 
instance validation set apply pairwise coupling methods obtain classification decisions 
error validation sets cross validation error 
rule obtains best 
decision values fold cross validation best employed find final model testing data tested 
average mses left panel solid line represents results small sets training testing dashed line large sets training testing 
definition mse correct pi problems pi data ith class 
measurement called brier score popular meteorology 
figures show smaller number classes ht kp similar mses larger ht largest mse 
mses larger methods included figures 
summary proposed approaches fairly insensitive values observations agree previous findings sections 
left panels figures average test errors problems small size training testing large size training testing respectively 
sub shows average test errors multi class implementation libsvm 
rule voting merely pairwise svm decision values denoted dv discussion 
figures show errors methods fairly close smaller suggests validation training 
example requires cross validation fold data 
simplicity directly training 
parameter sets return smallest cross validation error simply choose smallest training decision values best results similar 
recommended validated decision values possible 
quite different larger notice smaller figures differences averaged errors methods particular trend figures 
problems larger figures differences bigger ht competitive 
particular letter problem outperform ht 
test errors mse indicate problems larger posterior probabilities pi closer setting 
notable feature larger results closer closer ht small large training testing sets 
kp performance competitive clear relationships methods 

random forest binary classifier subsection consider random forest binary classifier conduct experiments data sets :10.1.1.46.6032
random forest provide multi class probability estimates denote corresponding rule rf compare coupling methods 
classes data construct trees random forest classifiers 
try randomly selected features bootstrap sample thirds training data employed generate full tree pruning 
test instance rij simply proportion trees class wins class set number trees fixed parameter left tuning try similar select try fold cross validation number attributes 
cross validation procedure section sequentially folds training set construct pairwise random forests obtaining decision instance validation set pairwise coupling methods calculating cross validation error try error validation sets 
course efficient bag validation random forest consider cross validation consistency 
experiments conducted interface code :10.1.1.46.6032
mse right panel shows yield stable results ht small large sets 
right panels figures give average test errors 
sub shows averaged error random forest multi class classifier rf 
notice random forest bears resemblance svm errors slightly different methods smaller tend outperform ht larger summary results random forest binary classifier strongly support previous findings regarding methods 

miscellaneous observations recall section consider dv platt posterior probabilities 
experimental results show dv slightly better dna usps mnist worse probability methods waveform 
similar observations waveform reported comparison dv ht explain results probability decision value methods distinct 
problems parameters selected dv quite different rules 
example waveform parameters probability methods gives higher cross validation accuracy dv observe example decision values validation sets data classes data validation sets classified class error high 
contrary probability methods fit decision values sigmoid function better separate classes cutting decision value 
observation shed light difference probability decision value methods 
results random forest multi class classifier reported sub figures 
observe figures number classes larger random forest multi class classifier better coupling binary random forests 
dna result way 
focus different pairwise coupling methods probability estimates different classifiers shall leave observation research issue 
acknowledgments 
authors keerthi helpful comments 
supported part national science council taiwan nsc nsc 
blake merz 
uci repository machine learning databases 
technical report univer sity california department information computer science irvine ca 
available www ics uci edu mlearn mlrepository html 
boser guyon vapnik 
training algorithm optimal margin classifiers 
proceedings fifth annual workshop computational learning theory 
breiman :10.1.1.46.6032
random forests 
machine learning 
brier 
verification forecasts expressed probabilities 
monthly weather review 

chang 
lin 
libsvm library support vector machines 
software available www csie ntu edu tw cjlin libsvm 
cortes vapnik 
support vector network 
machine learning 
duan keerthi 
best multiclass svm method 
empirical study 
technical report cd control division department mechanical engineering national university singapore 
friedman 
approach classification 
technical report department statistics stanford university 
available www stat stanford edu reports friedman poly ps hastie tibshirani 
classification pairwise coupling 
annals statistics 
hull 
database handwritten text recognition research 
ieee transactions pattern analysis machine intelligence may 
hunter 
mm algorithms generalized bradley terry models 
annals statistics 
appear 
personnaz dreyfus 
single layer learning revisited stepwise procedure building training neural network 
fogelman editor neurocomputing algorithms architectures applications 
springer verlag 
lecun bottou bengio haffner 
gradient learning applied document recog nition 
proceedings ieee november 
mnist database available yann lecun com exdb mnist 
wiener 
classification regression 
news december 

lin 
lin weng 
note platt probabilistic outputs support vector machines 
tech nical report department computer science information engineering national taiwan university 
michie spiegelhalter taylor 
machine learning neural sta tistical classification 
prentice hall englewood cliffs 
data available www ncc pt ml statlog datasets html 
platt 
probabilistic outputs support vector machines comparison regularized likelihood methods 
smola bartlett sch lkopf schuurmans editors advances large margin classifiers cambridge ma 
mit press 
price personnaz dreyfus 
pairwise network classifiers probabilistic outputs 
tesauro touretzky leen editors neural information processing systems volume pages 
mit press 

probabilistic approach multiclass classification neural networks 
proceedings international conference artificial networks pages 
ross 
stochastic processes 
john wiley sons second edition 
tong culberson sheridan 
random forest tool classification regression compound classification modeling 
journal chemical information computer science 

wu 
lin weng 
probability estimates multi class classification pairwise coupling 
proceedings nips 
zermelo 
die berechnung der ergebnisse als ein der 
mathematische zeitschrift 
proof theorem suffices prove optimal solution satisfies pi 
true loss generality assume 
pr pr 
pk pi 
define new feasible solution pi 
rij rji obtain 
pr 
pk contradicts assumption optimal solution 
proof theorem ee positive definite vector vi qv vt 
vt rti vi 
rit vt rti rit vi contradicts 
ee rank ee invertible 
unique solution 
positive definiteness ee implies ii positive definite vector vi qv 
vs rsi vi implies contradicts 
ris vi vj rji vi vs rsj vj 
ris rij rij proof theorem need lemma show strict decrease objective function lemma rij consecutive iterations algorithm pn qp pt qp 
proof 
assume pt component updated 
obtained calculation pi pi qp pi valid operation pi strictly positive 
show suppose pi pi pi pi equality pi implies pt 
pt pi pt 
contradicts situation pi 
prove take 
observe pi qp qp pt pt pt pt qp pt pt pt pt pt pt qp suffices prove negative 
pn pt pt 
pt pt pt qp 
pt qp properties pt pt jt 
fact consider cases case qp qp pt pt 
case pt pt 
pt pt qp calculation shows negative case qp pt pt qp qp pt pt qp 
case pt pt 
derive negative 
pt pt qp qp pt pt qp 
ready prove theorem 
result hold convergent sub sequence optimal 
note index 
updated infinitely iterations 
loss generality assume updated generate iteration optimal starting 

component qp 
applying iteration algorithm explanation similar obtain satisfying lemma note takes steps lim pi lim qp qp pi pi qp qp lim pi lim pi lim pi lim pi pi contradicts fact lemma optimal 
derivation lim pi qp qp qp lim pi qp qp qp qp rij rji pj rji rij pi rij rji rji rij rji rij rji rij constraint pi optimal solution satisfies rj optimal solution 
pk ht kp dna binary svms ht kp waveform binary svms ht kp satimage binary svms ht kp segment binary svms ht kp dna binary random forests ht kp waveform binary random forests ht kp satimage binary random forests ht kp segment binary random forests ht kp usps binary svms ht kp mnist binary svms ht kp letter binary svms ht kp usps binary random forests ht kp mnist binary random forests ht kp letter binary random forests fig 

mse probability estimates methods binary svms left binary random forests right 
mse large 
solid line training testing points dotted line training testing points 
ht kp dna binary svms dv ht kp waveform binary svms dv ht kp satimage binary svms dv ht kp segment binary svms dv ht kp dna binary random forests rf ht kp waveform binary random forests rf ht kp satimage binary random forests rf ht kp segment binary random forests rf ht kp usps binary svms dv ht kp mnist binary svms dv ht kp letter binary svms dv ht kp usps binary random forests rf ht kp mnist binary random forests rf ht kp letter binary random forests rf fig 

average test errors probability estimates methods binary svms left binary random forests right 
test errors training testing points 
sub shows averaged error voting pairwise svm decision values dv multi class random forest rf 
ht kp dna binary svms dv ht kp waveform binary svms dv ht kp satimage binary svms dv ht kp segment binary svms dv ht kp dna binary random forests rf ht kp waveform binary random forests rf ht kp satimage binary random forests rf ht kp segment binary random forests rf ht kp usps binary svms dv ht kp mnist binary svms dv ht kp letter binary svms dv ht kp usps binary random forests rf ht kp mnist binary random forests rf ht kp letter binary random forests rf fig 

average test errors probability estimates methods binary svms left binary random forests right 
test errors training testing points 
sub shows averaged error voting pairwise svm decision values dv multi class random forest rf 

