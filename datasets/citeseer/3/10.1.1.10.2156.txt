minimum error rate training statistical machine translation franz josef och information sciences institute university southern california admiralty way suite marina del rey ca och isi edu training procedure statistical machine translation models maximum likelihood related criteria 
general problem approach loose relation final translation quality unseen text 
analyze various training criteria directly optimize translation quality 
training criteria proposed automatic evaluation metrics 
describe new algorithm efficient training unsmoothed error count 
show significantly better results obtained final evaluation criterion taken directly account part training procedure 
tasks natural language processing evaluation criteria go simply counting number wrong decisions system 
criteria example measure parsing mean average precision ranked retrieval bleu multi word error rate statistical machine translation 
statistical techniques natural language processing starts simplifying implicit assumption final scoring simply counting number wrong decisions instance number sentences incorrectly translated machine translation 
mismatch basic assumptions statistical approach final evaluation criterion measure success task 
ideally train model parameters performance application optimal 
investigate methods efficiently optimize model parameters respect machine translation quality measured automatic evaluation criteria word error rate bleu 
statistical machine translation log linear models assume source french sentence translated target english sentence possible target sentences choose sentence highest probability argmax fpr argmax operation denotes search problem generation output sentence target language 
decision eq 
minimizes number decision errors 
called zero loss function decision rule optimal duda hart 
note different loss function example induced bleu metric different decision rule optimal 
notational convention follows 
symbol pr 
denote general probability distributions nearly specific assumptions 
contrast model probability distributions generic symbol 
true probability distribution pr unknown develop model approximates pr 
directly model posterior probability pr log linear model 
framework set feature functions hm feature function exists model parameter direct translation probability pr exp mhm exp mhm framework modeling problem amounts developing suitable feature functions capture relevant properties translation task 
training problem amounts obtaining suitable parameter values standard criterion loglinear models mmi maximum mutual information criterion derived maximum entropy principle argmax log jf optimization problem criterion nice properties unique global optimum algorithms gradient descent guaranteed converge global optimum 
ultimate goal obtain translation quality unseen test data 
experience shows results obtained approach reason assume optimization model parameters eq 
yields parameters optimal respect translation quality 
goal investigate alternative training criteria corresponding training algorithms directly related translation quality measured automatic evaluation criteria 
section review various automatic evaluation criteria statistical machine translation 
section different training criteria try directly optimize error count 
section sketch new training algorithm efficiently optimizes unsmoothed error count 
section describe feature functions approach compute candidate translations basis training procedure 
section evaluate different training criteria context mt experiments 
automatic assessment translation quality years various methods proposed automatically evaluate machine translation quality comparing hypothesis translations translations 
examples methods word error rate position independent word error rate tillmann generation string accuracy bangalore multi word error rate bleu score papineni nist score doddington 
criteria try approximate human assessment achieve astonishing degree correlation human subjective evaluation fluency adequacy papineni doddington 
methods multi word error rate method hypothesis translation compared various translations computing edit distance minimum number substitutions insertions deletions hypothesis closest translations 
multi position independent error rate criterion ignores word order treating sentence bag words computing minimum number substitutions insertions deletions needed transform hypothesis closest translations 
bleu score criterion computes geometric mean precision grams various lengths hypothesis set translations multiplied factor bp 
penalizes short sentences bleu bp 
exp log denotes precision grams hypothesis translation 

nist score criterion computes weighted precision grams hypothesis set translations multiplied factor bp 
penalizes short sentences nist bp 
denotes weighted precision grams translation 

nist bleu accuracy measures larger values reflect better translation quality 
note nist bleu scores additive different sentences score document obtained simply summing scores individual sentences 
training criteria minimum error rate training assume measure number errors sentence comparing sentence function 
exposition easily adapted accuracy metrics metrics multiple 
assume number errors set sentences obtained summing errors individual sentences 
goal obtain minimal error count representative corpus translations set different candidate translations fe input sentence argmin argmin argmax cs mhm stated optimization criterion easy handle includes argmax operation eq 

possible compute gradient gradient descent methods perform optimization 
objective function different local optima 
optimization algorithm handle 
addition manage solve optimization problem face problem overfitting training data 
section describe efficient optimization algorithm 
able compute gradient objective function smoother error criterion essentially smoothed error count parameter adjust smoothness argmin jf jf extreme case eq 
converges unsmoothed criterion eq 
case ties 
note resulting objective function local optima optimization hard compared objective function eq 
different local optima 
type smoothed error count common approach speech community juang schluter ney 
shows actual shape smoothed unsmoothed error count parameters translation system 
see unsmoothed error count different local optima unstable 
smoothed error count stable fewer local optima 
show section performance task obtained smoothed error count differ significantly obtained unsmoothed error count 
optimization algorithm unsmoothed error count standard algorithm optimization unsmoothed error count eq 
algorithm combined grid line optimization method press 
start random point dimensional parameter space unsmoothed error count smoothed error rate alpha unsmoothed error count smoothed error rate alpha shape error count smoothed error count different model parameters 
curves computed development corpus see section table alternatives source sentence 
smoothed error count computed smoothing parameter 
try find better scoring point parameter space making dimensional line minimization directions optimizing parameter keeping parameters fixed 
avoid finding poor local optimum start different initial parameter values 
major problem standard approach fact grid line optimization hard adjust performance efficient search guaranteed 
fine grained grid algorithm slow 
large grid optimal solution missed 
describe new algorithm efficient line optimization unsmoothed error count eq 
log linear model eq 
guaranteed find optimal solution 
new algorithm faster stable grid line optimization method 
computing probable sentence set candidate translation fe see eq 
line 
parameter results optimization problem functional form argmin ft 


constants respect candidate translation corresponds line 
function min ft 
piecewise linear papineni 
allows compute efficient exhaustive representation function 
sketch new algorithm optimize eq 
compute ordered sequence linear intervals constituting sentence incremental change error count previous interval 
obtain sentence sequence denote interval boundaries corresponding sequence change error count involved corresponding interval boundary 



denotes change error count position error count position 
merging sequences 
different sentences corpus complete set interval boundaries error count changes corpus obtained 
optimal computed easily traversing sequence interval boundaries updating error count 
straightforward refine algorithm handle bleu nist scores sentence level error counts accumulating relevant statistics computing scores gram precision translation length length baseline translation approach basic feature functions model identical alignment template approach och ney 
translation model sentence translated segmenting input sentence phrases translating phrases reordering translations target language 
addition feature functions described och ney system includes phrase penalty number alignment templates special alignment features 
altogether log linear model includes different features 
note feature functions derived probabilistic models feature function defined negative logarithm corresponding probabilistic model 
feature functions informative instance binary feature functions standard maximum entropy models natural language processing 
search dynamic programming beam search algorithm explore subset possible translations och extract best candidate translations search 
best approximation face problem parameters trained list translations yield worse translation results parameters dynamic programming search 
possible new search produces translations errors training corpus 
happen modified model scaling factors best list change significantly include sentences existing best list 
avoid problem adopt solution perform search manually defined set parameter values compute best list best list train model parameters 
second new model parameters new search compute new best list combined existing best list 
third extended best list new model parameters computed 
iterated resulting best list change 
algorithm convergence guaranteed limit best list contain possible translations 
experiments compute iteration alternative translations 
practice algorithm converges iterations 
result error rate increase training corpus 
major problem applying mmi criterion fact translations need part provided best list 
quite translations part best list search algorithm performs pruning principle limits possible translations produced certain input sentence 
solve problem define mmi training new pseudo selecting best list sentences minimal number word errors respect true 
note due selection approach results mmi criterion biased criterion 
major advantage minimum error rate training necessary choose pseudo 
results results tides chinese english small data track task 
goal translation news text chinese english 
table provides statistics training development test corpus 
system include rule components translate numbers dates names 
basic feature functions trained training corpus 
development corpus optimize parameters log linear model 
translation results reported test corpus 
table shows results obtained development corpus table shows results obtained table effect different error criteria training development corpus 
note better results correspond larger bleu nist scores smaller error rates 
italic numbers refer results difference best result indicated bold statistically significant 
error criterion training bleu nist words confidence intervals mmi smoothed smoothed bleu nist table characteristics training corpus train manual lexicon lex development corpus dev test corpus test 
chinese english train sentences words singletons vocabulary lex entries dev sentences words test sentences words test corpus 
italic numbers refer results difference best result indicated bold statistically significant 
error rates show maximal occurring confidence interval experiments column 
confidence intervals computed bootstrap resampling press 
column provides number words produced translations compared average number words occurring development test corpora table 
observe choose certain error criterion training obtain cases best results criterion evaluation metric test data 
differences quite large optimize respect word error rate results better optimize respect bleu nist difference statistically significant 
bleu nist differences moderate optimizing nist obtain large improvement measured nist compared optimizing bleu 
mmi criterion produces significantly worse results error rates 
note due re definition notion translation minimum edit distance results mmi criterion biased 
expected suitably defined gram precision define pseudo mmi edit distance possible obtain better bleu nist scores 
important part differences translation scores due different translation length column table 
mmi criteria prefer shorter translations heavily penalized bleu nist brevity penalty 
observe smoothed error count gives identical results unsmoothed error count 
due fact number parameters trained small serious overfitting occurs unsmoothed error count 
related log linear models statistical machine translation suggested papineni 
och ney 
minimum classification error training smoothed error count common pattern recognition speech table effect different error criteria training test corpus 
note better results correspond larger bleu nist scores smaller error rates 
italic numbers refer results difference best result indicated bold statistically significant 
error criterion training bleu nist words confidence intervals mmi smoothed smoothed bleu nist recognition community duda hart juang schluter ney 
rosenfeld minimum classification error training optimizing parameters sentence maximum entropy language model 
technically different approach similar goal minimum bayes risk approach optimal decision rule respect application specific risk loss function normally differ eq 

loss function identical closely related final evaluation criterion 
contrast approach training criterion statistical models remain unchanged minimum bayes risk approach 
field natural language processing approach applied example parsing goodman word alignment kumar byrne 
alternative training criteria loglinear statistical machine translation models directly related translation quality unsmoothed error count smoothed error count development corpus 
unsmoothed error count new line optimization algorithm efficiently find optimal solution line 
showed approach obtains significantly better results mmi training criterion method define optimizing error rate part training criterion helps obtain better error rate unseen test data 
result expect actual true translation quality improved previous shown evaluation criteria correlation human subjective evaluation fluency adequacy papineni doddington 
different evaluation criteria yield quite different results chinese english translation task expect correlate equally human translation quality 
important questions answered parameters reliably estimated unsmoothed minimum error rate criteria development corpus size 
expect directly optimizing error rate parameters lead serious overfitting problems 
possible optimize parameters smoothed error rate criterion 
error rate optimized training 
relates important question automatic evaluation measure optimally correlated human assessment translation quality 
note approach applied evaluation criterion 
improved automatic evaluation criterion developed better correlation human judgments bleu nist plug alternative criterion directly training procedure optimize model parameters 
means improved translation evaluation measures lead directly improved machine translation quality 
course approach places high demand fidelity measure optimized 
happen directly optimizing error measure way described weaknesses measure exploited yield better scores improved translation quality 
approach poses new challenges developers automatic evaluation criteria 
tasks natural language processing instance summarization evaluation criteria go simply counting number wrong system decisions framework yield improved systems tasks 
supported darpa ito 
srinivas bangalore whittaker 

evaluation metrics generation 
proceedings international conference natural language generation ramon israel 
george doddington 

automatic evaluation machine translation quality gram occurrence statistics 
proc 
arpa workshop human language technology 
duda peter hart 

pattern classification scene analysis 
john wiley new york ny 
joshua goodman 

parsing algorithms metrics 
proceedings th annual meeting acl pages santa cruz ca june 
juang chou lee 

statistical discriminative methods speech recognition 
rubio lopez editors speech recognition coding new advances trends 
springer verlag berlin germany 
shankar kumar william byrne 

minimum bayes risk alignment bilingual texts 
proc 
conference empirical methods natural language processing philadelphia pa sonja franz och hermann ney 

evaluation tool machine translation fast evaluation machine translation research 
proc 
second int 
conf 
language resources evaluation lrec pages athens greece may franz josef och hermann ney 

discriminative training maximum entropy models statistical machine translation 
proc 
th annual meeting association computational linguistics acl philadelphia pa july 
franz och christoph tillmann hermann ney 

improved alignment models statistical machine translation 
proc 
joint sigdat conf 
empirical methods natural language processing large corpora pages university maryland college park md june 
chris roni rosenfeld 

minimum classification error training exponential language models 
nist darpa speech transcription workshop may kishore papineni salim roukos ward 

feature language understanding 
european conf 
speech communication technology pages rhodes greece september 
kishore papineni salim roukos todd ward wei jing zhu 

bleu method automatic evaluation machine translation 
technical report rc ibm research division thomas watson research center yorktown heights ny september 
kishore papineni 

discriminative training linear programming 
proceedings ieee international conference acoustics speech signal processing atlanta march 
william press saul teukolsky william vetterling brian flannery 

numerical recipes 
cambridge university press cambridge uk 
ralf schluter hermann ney 

model mce bound true bayes error 
ieee signal processing letters may christoph tillmann stephan vogel hermann ney alex hassan 

accelerated dp search statistical translation 
european conf 
speech communication technology pages rhodes greece september 
nicola franz josef och hermann ney 

generation word graphs statistical machine translation 
proc 
conference empirical methods natural language processing pages philadelphia pe july 
