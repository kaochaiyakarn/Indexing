ieee transactions pattern analysis machine intelligence vol 
november binary partitioning perceptual grouping restoration semidefinite programming jens christoph schn rr christian daniel cremers introduce novel optimization method semidefinite programming relaxations field computer vision apply combinatorial problem minimizing quadratic functionals binary decision variables subject linear constraints 
approach tuning parameter free computes high quality combinatorial solutions interior point methods convex programming randomized hyperplane technique 
apart symmetry condition assumptions metric pairwise interactions respect objective criterion 
consequence approach applied wide range problems 
applications unsupervised partitioning ground discrimination binary restoration extensive ground truth experiments 
viewpoint relaxation underlying combinatorial problem show superiority approach relaxations spectral graph theory prove performance bounds 
index terms image partitioning segmentation graph cuts perceptual grouping ground discrimination combinatorial optimization relaxation convex optimization convex programming 
motivation overview optimization problems occur fields computer vision pattern recognition 
important design decisions concerns compromise adequacy optimization criterion difficulty computing solution 
inadequate optimization criterion solve application problem matter easy compute optimum 
conversely sophisticated criteria optimized elaborate parameter tuning sufficient priori knowledge starting point useless practice 
reason optimization approaches attractive help making compromise sense 
introduce novel optimization technique semidefinite programming relaxations field computer vision apply minimize quadratic functionals defined binary decision variables subject linear constraints 
numerous problems computer vision including partitioning grouping lead combinatorial optimization problems type 
contrast related specific assumptions respect functional form symmetry condition 
consequence approach covers graph optimization problems unsupervised supervised classification tasks order markov random field estimates depending specific assumptions problem formulations 
utilized wide range applications 
combinatorial complexity optimization task dealt steps decision variables authors group department mathematics computer science university mannheim mannheim germany 
mail cremers uni mannheim de 
manuscript received apr revised jan accepted may 
recommended acceptance figueiredo hancock pelillo 
information obtaining reprints article please send mail tpami computer org ieeecs log number 
ieee published ieee computer society lifted higher dimensional space optimization problem relaxed convex optimization problem 
specifically resulting semidefinite program comprises linear objective functional defined cone matrix space number application dependent linear constraints 
second decision variables recovered global optimum relaxed problem small set randomly computed hyperplanes 
optimization technique amounts compromise follows 
advantageous properties original combinatorial problem transformed optimization problem convex 
consequence global optimum transformed problem computed mild conditions 
interior point algorithm approximation global optimum numerically determined polynomial time 
tuning parameters necessary 
contrast spectral relaxation choice suitable threshold value necessary 
approach especially suited unsupervised classification tasks 
negative side number variables optimization problem squared 
limits application problems variables sufficient problems related image partitioning perceptual grouping 
furthermore increase problem dimension necessary order approximate intricate combinatorial problem simpler convex optimization problem 
intuitively nasty combinatorial constraints original space lifted higher dimensional matrix space constraints better approximated convex sets turn convenient numerical optimization 
add high quality combinatorial solutions computed solving appropriate convex optimization problem 
binary partitioning perceptual grouping restoration semidefinite programming fig 

color scene gray value scene comprised natural textures 
partition scenes coherent groups unsupervised way pairwise dis similarities local measurements 
high quality means solutions obtained far unknown global optimum computation np hard intractable terms original optimization criterion 
absence specific assumptions objective criterion properties listed motivated investigation 
partitioning grouping restoration section illustrate problems lead different instances class optimization problems considered 
indicate significance problem class computer vision exemplify nontrivial specific problems 
formal problem definitions sections 
fig 
shows images taken vistex database mit 
common goal low level computer vision partition images unsupervised way coherent groups locally computed features color texture motion 
representation images graph structures attracted interest researchers :10.1.1.160.2324:10.1.1.160.2324:10.1.1.112.6806
show approach assumptions literature concerning admissible objective criteria dropped 
study detail unsupervised bipartitioning images constrained minimal cuts underlying graphs show optimization point view convex approximation provides tighter relaxation underlying combinatorial optimization problem suggested methods spectral graph theory 
fig 
shows section office table top 
probably human observers focus partially occluded keyboard 
typical problem computer vision model global decisions solving optimization problem defined terms locally extracted primitives 
context optimization criterion considered saliency measure respect decision variables indicating primitives belong foreground background respectively 
show quadratic saliency measures considered difficult due combinatorial complexity conveniently dealt approach 
fig 
shows noisy map iceland 
restoration images long history particular context markov random fields 
show binary restoration problems modeled restrictive conditions previous approaches 
related optimization approaches computer vision energy minimization problems computer vision image labeling partitioning perceptual grouping graph matching involve discrete decision variables intrinsically combinatorial nature 
accordingly optimization approaches efficiently compute minimizers long history literature 
important class optimization approaches stochastic sampling introduced geman geman widely applied markov random field mrf literature 
known corresponding algorithms slow due annealing fig 

section office table shown top 
keyboard probably attracts attention observer 
compute ground discrimination global decision pairwise dis similarities local measurements 
noisy binary image map iceland restored 
ieee transactions pattern analysis machine intelligence vol 
november schedules prescribed theory 
renewed interest years conjunction bayesian reasoning complex statistical models 
aspects refer :10.1.1.29.2078
speed computations approaches computing suboptimal markov random field estimates highest confidence heuristic multiscale approaches approximations developed :10.1.1.112.6806:10.1.1.118.3857
important class approaches comprises continuation methods leclerc partitioning approach graduated non convexity strategy blake zisserman various deterministic approximate versions annealing approach applications surface reconstruction perceptual grouping graph matching clustering 
apart simulated annealing annealing schedules slow real world applications mentioned approaches guarantee find global minimum general goal elusive due combinatorial complexity minimization problems 
consequently important question concerning approximation problem arises computed minimizer relative unknown global optimum 
certain quality solutions terms suboptimality guaranteed application 
best knowledge approaches apart simulated annealing immune getting trapped poor local minimum meet criteria 
problem relates algorithmic properties approaches 
apart simple greedy strategies approaches involve hidden parameters computed local minimum critically depends :10.1.1.112.6806
typical example artificial temperature parameter deterministic annealing approaches corresponding iterative annealing schedule 
known approaches exhibit complex bifurcation phenomena transitions branch follow controlled user furthermore numerical fixed point iterations tend oscillate parallel synchronous update mode see 
approach belongs mathematically understood class convex optimization problems contributes problems discussed 
exists global optimum mild assumptions turn leads suboptimal solution original problem clear numerical algorithms compute 
abstracting computational process simply think mapping data solution 
evidently hidden parameter involved 
second certain conditions bounds derived respect quality suboptimal solution 
bounds tight respect better performance measured practice 
noted alternative optimization approaches performance bounds corresponding route research missing 

notable exception respect restricted class optimization problems :10.1.1.112.6806
fig 

representing image partitions graph cuts weights edges cut provide measure dis similarity resulting groups 
graph partitioning clustering perceptual grouping illustrated section wide range problems optimization approach applied 
depth discussion possible applications possible briefly discuss relates applications illustrate optimization approach 
graph partitioning 
approaches unsupervised image segmentation graph partitioning proposed :10.1.1.160.2324:10.1.1.160.2324
images represented graphs locally extracted image features vertices pairwise dis similarity values edge weights ir fig 

classical approach efficient computation suboptimal cuts spectral decomposition laplacian matrix 
approach applications different fields 
accordingly shi malik propose normalized cut criterion minimizes weight cut subject normalizing terms prevent unbalanced cuts :10.1.1.160.2324:10.1.1.160.2324
resulting combinatorial problem relaxed methods spectral graph theory 
survey direction refer 
gdalyahu suggest compute partitions typical average cuts underlying graph stochastic sampling method 
approach interesting directly relate optimization criterion discussed 
criticized methods spectral graph theory able partition highly skewed data distributions clusters 
show straightforward remedy base similarity measure suitable path metric 
furthermore approach yields tighter relaxation underlying combinatorial problem better suboptimal solutions 
approaches supervised graph partitioning image labeling include :10.1.1.112.6806:10.1.1.112.6806
authors consider case nonbinary labels xi class optimization criteria di xi pi xi xj boykov require pi semi metric ishikawa stronger assumption pi xi xj xi xj convex :10.1.1.112.6806
consider case binary labels assumptions binary partitioning perceptual grouping restoration semidefinite programming respect pairwise interaction terms pi example pi may vanish xi xj negative 
clustering 
approaches unsupervised image partitioning discussed may understood clustering methods course 
focus detail image bipartitioning computing constrained minimal cuts underlying graph 
consecutive partitions lead hierarchical clustering method cf 

important issue context cluster normalization order avoid unbalanced partitions 
general normalization criteria lead rational terms cost functional optimization approach directly applied 
investigate cluster normalization imposing various linear constraints introduced shi malik relaxation specific normalization criterion :10.1.1.160.2324
natural path metrics dis similarity clustering advocated 
perceptual grouping 
vast literature perceptual grouping vision 
survey refer :10.1.1.21.1429
merely focus optimization point view quadratic saliency measure herault horaud application considered difficult due combinatorial complexity 
show grouping criterion conveniently optimized approach 
mathematical programming optimization methods semidefinite programming relatively novel techniques successfully applied optimization problems diverse fields nonconvex combinatorial optimization statistics control theory 
survey refer 
method relaxing combinatorial constraints goes back seminal lov sz schrijver 
concerning interior point methods convex programming refer numerous textbooks surveys 
recover combinatorial solution global optimum relaxation adopt randomized hyperplane technique developed goemans williamson :10.1.1.3.9509:10.1.1.3.9509
classical optimization problem combinatorial graph theory max cut authors able show suboptimal solutions worse percent relative unknown global optimum 
convenient algorithm design convex optimization fact motivated 
organization section formally define optimization problems related unsupervised partitioning section perceptual grouping ground discrimination section binary image restoration section 
mathematical relaxation corresponding combinatorial problem class subject section 
explain derivation corresponding semidefinite program section feasibility section related algorithms section performance bounds section superiority convex relaxation spectral relaxation section 
section discuss numerical results real scenes ground truth experiments 
conclude indicate section 
notation notation 
basic concepts graph theory refer 
vector ones diagonal matrix vector diagonal dii xi 
matrix diagonal elements set zero 
unit matrix 
space symmetric matrices set matrices sn positive semidefinite 
standard matrix scalar product tr 
undirected graph vertices ng edges weight function graph ir sum edge weights subgraph induced vertex subset complement vertex subset weight cut defined partition weighted adjacency matrix graph wij 
laplacian matrix graph eigenvalues laplacian matrix graph kxk euclidean norm vector kxk problem statement binary combinatorial optimization section formally define optimization criteria problems introduced section 
criteria turn special instances quadratic functionals binary decision variables subject linear constraints 
relaxations difficult combinatorial problems computing suboptimal solutions polynomial time studied section 
unsupervised partitioning consider graph locally extracted image features vertices pairwise dis similarity values edge weights ir compute partition set coherent groups depicted fig 

representing partitions indicator vector weight cut cf 
section xi xj lx weight function encodes similarity measure pairs features coherent groups correspond low values 
order avoid unbalanced partitions minimizing shi malik suggested normalized objective function ieee transactions pattern analysis machine intelligence vol :10.1.1.160.2324:10.1.1.160.2324
november optimization problem intractable derived relaxation normalized cut inf lx number known 
integer constraint dropped practice 
writing shorthand inf kyk ly ld eigenvector laplacian matrix eigenvalue respect normalized laplacian matrix consequently solves integer constraint eigenvector corresponding second smallest eigenvalue 
integer constraint taken account thresholding eigenvector suitable criterion :10.1.1.160.2324
approach close classical partitioning approach spectral graph theory see survey inf lx criterion clear interpretation determine cut minimal weight cf 
subject constraint group equal number vertices 
similarly dropping normalization setting interpretation determine cut minimal weight parts sum 
context image partitioning may appropriate constraint explains success shi malik approach 
foregoing discussion raises natural questions constraints useful unsupervised image partitioning 
take account integer constraint respect xi deriving appropriate relaxation combinatorial optimization problem opposed doing just thresholding 
investigate different constraints define criterion unsupervised image partitioning inf lx focus appropriate relaxation integer constraint section 
vector constraint vector defining mean balanced cut section provide exact conditions vector result feasible relaxations 
examples section 

note conform optimization problems form corresponding assumptions 
perceptual grouping ground discrimination horaud investigated combinatorial problem minimizing functional terms binary labels ground discrimination perceptual grouping primitives 
degree vertex sum incident edge weights 
ir pi interaction coefficients encode similarity measures pairs primitives smoothness proximity contrast see 
accordingly term measures mutual reinforcement pairs primitives labeled foreground pi pj 
second term penalizes primitives receive feedback primitives probably belong coherent group 
horaud investigated various annealing approaches order find minimizers 
disadvantages class optimization approaches discussed section 
accordingly comparison combinatorial complexity involved considered decisive disadvantage approach saliency measure perceptual grouping 
show minimizer conveniently computed approach 
transform variables variables obtain problem formulation constant terms inf ee ni matrix entries wij 
formulation explicit role global parameter acts twofold way threshold parameter primitives reinforce similarity value wij larger term primitive additionally favored average degree similarity value larger second term 
terms result meaningful global measure coherency pairwise comparisons locally computed primitives 

note conform optimization problems form corresponding assumptions 
restoration consider scalar valued feature gray value color feature texture measure ir locally computed image plane 
suppose pixel feature value gi known originate prototypical values 
practice course real valued due measurement errors noise 
restore discrete valued image function vector measurements minimize functional xi gi xi xj hi ji second term sums pairwise adjacent pixels regular image grid 
functional comprises terms familiar regularization approaches data fitting term smoothness term modeling spatial context 
due binary partitioning perceptual grouping restoration semidefinite programming integer constraint xi optimization problem considered difficult standard regularization problems 
constant terms leads optimization problem inf qx bi gi matrix entries qij adjacent pixels qij 
note contrast problems introduced previous sections case problem matrix sparse advantageous computational point view 

aware conform optimization problems form solved optimality methods :10.1.1.112.6806
depending application considered useful modify terms model properties imaging device data fitting term take consideration priori knowledge spatial regularities smoothness term see 
modifications lead entries violate assumptions affect applicability approach 
exploring possibilities scope 
optimization mathematical relaxation section introduce optimization approach 
note perceptual grouping problem restoration problem written form introduced unsupervised partitioning problem 
fact objective functions special cases general quadratic functional qx homogenized way qx problems special instances size ifl generalized symmetric matrix subject constraints 
need laplacian matrix graph relaxation 
section assume refer 
results apply problems section stated special choice constraint vector relaxation approach consists lifting problem variables matrix space section solving resulting convex optimization problem interior point techniques recovering corresponding combinatorial solution section 
semidefinite relaxation order relax replace linear integer constraint respectively quadratic ones denoting lagrangian multiplier variables yi lagrangian reads lx xn yi cc fig 

set feasible solutions fx jd ig convex problem relaxation 
subset feasible combinatorial solutions contains extreme points 
set additionally intersected hyperplane cc 
results lagrangian relaxation sup inf cc unconstrained inner minimization finite valued cc positive semidefinite 
arrive relaxed problem zd sup cc important point convex optimization problem 
set cone special convex set self dual coincides dual cone fy sn 
obtain connection original problem derive lagrangian dual 
choosing lagrangian multiplier similar reasoning yields zd sup inf inf inf cc sup cc sup cc inner maximization equation finite cc 
obtain problem dual zp inf cc convex 
final semidefinite relaxation obtained intuitively direct way original problem rewriting objective function infx lx infx xx note matrix xx positive semidefinite rank 
relaxation consists replacing xx arbitrary matrix dropping rank condition lifting constraints higher dimensional space accordingly 
order illustrate convex relaxation approximates combinatorial nonconvex problem consider case 
case matrix unknowns due symmetry upper lower triangular part 
intersection convex set hyperplanes defined yields convex set fx jd ig shown fig 

ieee transactions pattern analysis machine intelligence vol 
november looks polytope vertices correspond combinatorial solutions problem nonlinear faces 
set feasible solutions obtained additionally intersecting set hyperplane cc 
shows original combinatorial problem feasible solution extreme points fx jd ig lies hyperplane 
relaxed solution determined minimizing numerically linear functional feasible set provided empty see section 
nearest extreme point may considered combinatorial solution combinatorial solution best approximates constraint 
simple example illustrates fundamental fact intricate constraints represented simpler sets higher dimensional spaces 
fact known fields pattern recognition statistical learning 
duality feasibility optimization problems primal dual belong class positive semidefinite programs 
elegant duality theory corresponding class convex optimization problems 
duality theorem provided theorem strong duality positive semidefinite programming 
feasible strictly interior point optimal primal dual solutions exist corresponding optimal values yield duality gap zp zd 
convex optimization problems considered known behaved theorem 
strictly interior point dual problem setting ae large 
primal problem feasible solution ee may possible feasible solution primal problem exists vector chosen inappropriately 
situation illustrated example case constraints yield additionally hold positive semidefinite 
obviously valid 
choices primal problem feasible solution case 
general possible characterize exactly situations primal problem feasible 
result mainly proposition theorem 
problem feasible positive constraint vector ci balanced cj ci proof 
matrix cc positive semidefinite 
balancing constraint yields cc tr cc cc 
positive semidefinite cc follows immediately cc null matrix 
equivalent xc contained null space ker proposition concludes proof linear space generated contained ker matrix balanced 
proof proposition 
tu due result consider examples section balanced 
interior point algorithm randomized hyperplanes compute optimal solutions wide range iterative interior point algorithms 
typically sequence minimizers fx parameterized parameter computed duality gap falls threshold remarkable result asserts family self concordant barrier functions done polynomial time complexity depending number variables value note due constraint cc smallest eigenvalue equal cf 
proof theorem strictly interior point primal problem exists 
observation led dual scaling algorithm experiments 
algorithm advantage need calculate interior solution primal problem iterations dual problem 
capable exploiting sparsity structure problem better methods 
primal solution matrix computed optimal dual solution reached 
solution matrix convex optimization problem find combinatorial solution original problem 
achieve randomized hyperplane technique proposed goemans williamson :10.1.1.3.9509:10.1.1.3.9509
interpretation relaxation described section convenient compute vn cholesky decomposition 
constraint follows relaxation step section may interpreted associating primitive xi vector vi unit sphere high dimensional space 
accordingly matrix entries xx ij xixj replaced matrix entries xij vj 
choosing random vector unit sphere combinatorial solution vector calculated setting xi xi 
done multiple times different random vectors letting final solution yields minimum value objective function lx 
technique may interpreted selecting different hyperplanes origin identified normal partition vectors vi nin sets 

course solution obtained technique need feasible required satisfy constraint 
may yield objective value smaller optimal value semidefinite relaxation zp 
modifications randomized hyperplane technique proposed binary partitioning perceptual grouping restoration semidefinite programming literature special case guarantee find feasible solution original problem give performance ratio objective value obtained 
stuck original randomized hyperplane technique applications considered mandatory find feasible solution interested solutions quite balanced need exactly balanced cuts associated graph 
constraint may seen strong bias guide search meaningful solution strict requirement especially cases feasible combinatorial solution exists 
performance bounds examples sections combinatorial solution obtained technique feasible 
results suboptimality bound objective value calculated case see proof theorem :10.1.1.10.366:10.1.1.3.9509
expected value objective function lx calculated randomized hyperplane technique bounded zp min cos 
drawback bound contains constant 
omitted may contain negative entries 
bound allows having negative entries nesterov extended results goemans williamson maximization problems form :10.1.1.3.9509
results easily reformulated minimization problems considered giving max denoting optimal value max denoting maximum value objective function subject integer constraint 
relative bound depends problem instance employs difference maximum minimum values objective function usually estimated advance 
observe relations different mentioned values objective function hold true zd zp max mentioned bounds tight respect better performance measured practice cf 
section 
alternative optimization approaches applicable general problem class considered performance bounds lacking completely 
relation spectral relaxation section compare convex relaxation approach spectral relaxation approaches 
results show convex relaxation compares favorably computation called fiedler vector segmentation graphs 
reformulate semidefinite relaxation section eigenvalue optimization problem 
idea dates back delorme poljak 
starting dual problem formulation parameterize 
constraint cc cc equivalent min cc results representation zd sup sup sup min cc spectral relaxation approach idea keeping constraint lagrangian formulation problem minimizing process 
parameterizing standard lagrangian relaxation leads spectral relaxation sup min ir contains orthonormal basis complement formulation straightforward generalization special case provided boppana rendl wolkowicz independently 
poljak rendl showed equivalence spectral relaxation semidefinite relaxation case investigating broader class general graph bisection problems 
result extended general case considered proof see theorem 
semidefinite relaxation yields lower bound objective function spectral relaxation zd sup min note feasible values unbounded 
want derive comparison semidefinite relaxation approach computation called fiedler vector take closer look weaker spectral relaxation min ir lx combinatorial constraint relaxed kxk directly lemma holds lemma 
ir denote matrix defined 
min lv solution ffiffiffi eigenvector corresponding smallest eigenvalue lv norm kw 
proof 
kck orthonormal lx lv attains minimum ieee transactions pattern analysis machine intelligence vol 
november fig 

signal comprising multiple spatial scales 
fig 

representative example illustrating statistics shown fig 

noisy input signal 
optimal solution 
suboptimal solution proportional smallest eigenvector kw lv pu follows calculation vw value follows immediately inserting objective function 
tu special case spectral relaxation corresponds computation fiedler vector eigenvector second smallest eigenvalue matrix follows directly observing lp ffiffi ffiffi ffiffi lv ffiffi lv lv min fig 

average relative errors lv objective function suboptimal solution comparison optimal signal synthetic signal respectively different values scale parameter shown average percentage misclassified pixels suboptimal solution compared optimal solution defined proof lemma 
fact shows superiority convex relaxation approach follows immediately comparing result lemma corollary 
inequality lower bounds valid zd apart fact tight concerning value objective function spectral relaxation fiedler vector disadvantage obtain corresponding combinatorial solution threshold value set entries xi tand xi 
raises question appropriate choice fig 

skewed data distribution spiral shaped groups 
level lines parzen estimate data distribution 
application metric scaling technique yields euclidean approximation space weighted path distances points project equal locations compared spiral shaped groups form compact clusters 
shortest euclidean path delaunay graph points group original data distribution 
weighted shortest paths density compared euclidean distance group paths shorter 
partition problem trivial shortest paths points group lie group 
binary partitioning perceptual grouping restoration semidefinite programming fig 

point set clustering fig 
distances weighted paths method 
convex relaxation computed correct partition 
partition computed fiedler vector thresholded 
correct separation possible due tight relaxation underlying combinatorial problem 
threshold value 
natural approaches promising set original constraint set equal median meet balancing constraint 
show unsupervised choice threshold value may fail completely 
hand course mentioned computational effort solving spectral relaxation fiedler vector smaller semidefinite relaxation allows tackling larger problem instances 
experiments discussion section investigate performance convex relaxation approach experimentally 
section start reporting statistical results ground truth experiments restoration problems described section noisy dimensional signals 
application convex relaxation approach different real scenes problem types mentioned section section 
furthermore brief discussion different aspects semidefinite relaxation approach section 
ground truth experiments able analyze performance convex relaxation approach described section statistically ground truth data global optimum available problem consideration 
decided investigate restoration noisy dimensional signals functional case global optimum easily computed dynamic programming 
fig 

fiedler vector example fig 

experiments took synthetic signal depicted fig 
involves transitions multiple spatial scales superimposed gaussian white noise standard deviation 
fig 
shows example noisy signal 
global optimum combinatorial solution obtained convex relaxation computed noisy input signal compared 
representative example restoration fig 

derive significant statistics experiment repeated times varying values different noisy signals 
value calculated quantities sample mean gap measured percent optimum respect objective function values suboptimal solution optimal solution sample standard deviation gap sample mean gap jz measured percent optimum respect objective function values suboptimal solution synthetic signal sample standard deviation gap calculated sample mean number misclassified pixels comparison optimal solution 
results shown fig 

reveal accuracy suboptimal solutions obtained semidefinite relaxation average relative error objective function value number correctly classified pixels percent compared optimum values objective function 
corresponding measures lie percent percent 
shows practice performance semidefinite relaxation approach better bounds section 
concerning restoration original signal mentioned best solution functional results indicates appropriate criteria restoration fig 

point set clustering 
input data points weights calculated method 
solution computed convex optimization 
solution computed fiedler vector thresholded median value spectral relaxation fails 
ieee transactions pattern analysis machine intelligence vol 
november fig 

color image partitioning method 
input image pixels yielding clusters 
segmentation computed convex optimization similar colors grouped 
segmentation computed fiedler vector thresholded median 
thresholding just separates pixel rest image 
signals incorporating suitable priors respect cf 

derivation criteria objective 
performance remarkably cf 
fig 
values scale parameter average relative error objective function value percent corresponding measures lying percent percent 
high error rates explained dominating larger spatial scales signal real scenes section results semidefinite relaxation approach applying problems different fields section 
unsupervised partitioning examples compare results segmentation obtained thresholding fiedler vector 
preliminary similarity measures graph extracted image features vertices coherent groups 
edge weights building similarity matrix computed distances extracted image features chosen application dependent 
studied different methods calculate similarity measures 
compute feature pairs directly including spatial information 

compute neighboring features derive edge weights calculation path connecting 
done computing shortest paths graph derived changing similarity weights dissimilarities transforming back afterward 
results similarity measure favors spatially coherent structures 
motivate method consider fig 
shows set points shape spirals 
critically observed spectral methods fail partition skewed coherent groups 
fig 
shows corresponding delaunay graph shortest euclidean path points group traverses group 
consequence direct pairwise comparison euclidean distances general method ignores spatial context appropriate 
method provides simple remedy situation cf 

apart location additional attributes color texture typically define pairwise distances similarities edge weights 
result weighted paths distance measure spatial coherency exploited appropriate way results shorter paths group 
example shown fig 
simulated additional attribute parzen estimate spatial data distribution fig 

fig 
visualizes resulting distances approximating euclidean distances space classical metric scaling technique 
result shows points coherent group similar 
accordingly partition task defined trivial course weighted paths groups shortened fig 
shortest paths points group lie group fig 

mainly interested results semidefinite relaxation approach optimization point view elaborate computations values 
survey numerous dis similarity measures see 
fig 

color image partitioning image fig 
method 
segmentation computed convex optimization spatially coherent structures favored 
segmentation computed fiedler vector thresholded median requirement parts size influences result negatively 
binary partitioning perceptual grouping restoration semidefinite programming fig 

color image partitioning method 
input image pixels yielding clusters 
segmentation computed convex optimization image cut coherent parts 
segmentation computed convex optimization constraint vector entries ci equal number pixels cluster largest cluster separated rest image 
unsupervised partitioning point sets 
fig 
shows partitions computed convex fig 
spectral fig 
relaxation respectively example previous section fig 

spirals number points experiment point defining vertex corresponding graph 
similarity weights calculated path metric method spectral relaxation fiedler vector fails compute correct cut convex relaxation 
reflects theoretical results section showing superiority convex relaxation approach optimization point view 
particularly relevant disadvantage spectral relaxation unsupervised case known heuristic thresholding eigenvector yield desired result 
hand note convex relaxation works threshold 
situation depicted fig 

point set comprises dense cluster middle equally distributed background clutter containing points 
similarity weights computed directly euclidean distances points method 
results example figs 
show superiority convex optimization approach successfully separates dense cluster background spectral relaxation achieves unsatisfactory partition 
due fact fiedler vector give clear cut value cf 
fig 

note solution obtained convex relaxation balancing constraint enforced accordance visual impression parts contain points respectively 
color images 
study partitioning large real world images computed oversegmentation applying mean shift technique fine spatial scale order destroy perceptually significant structure 
obtained clusters computed color difference clusters perceptually uniform luv space 
applied methods color image shown fig 
constraint vector results approve wide range applicability success semidefinite relaxation approach similarity measure method groups pixels similar colors see figs 
method yields segmentation reasonable spatially coherent parts see figs 

example results obtained thresholding fiedler vector median value quite reasonable see figs 
crucial point threshold value emerge naturally looking fiedler vector detail shows basically cluster separated rest image entry large positive value contain small negative values 
note hand choice threshold value necessary semidefinite relaxation approach 
choice far size clusters influence similarity weights 
may yield unsatisfactory separation results 
fig 
gives example sky accounts nearly half image approximately percent oversegmentation puts pixels cluster 
clusters importance matter large semidefinite relaxation approach segments image parts cutting city contains small clusters see figs 

derive segmentation takes account different sizes clusters balancing fig 

segmentation computed fiedler vector thresholded median image fig 
separation spatially coherent parts fails completely 
ieee transactions pattern analysis machine intelligence vol 
november fig 

grayscale texture partitioning 
input image pixels yielding vertices pixel windows similarity weights computed method 
segmentation computed convex optimization note parts size balancing constraint enforced 
segmentation computed fiedler vector threshold value 
constraint changed way calculate number pixels mi contained cluster set constraint vector entries ci mi ci 
search segmentation partitions image coherent parts containing approximately number pixels number clusters 
figs approach sky separated rest image giving segmentation accordance balancing constraint enforcing exactly 
note example fiedler vector fails completely give meaningful separation see fig 
thresholding median value yields coherent segmentation thresholding separates clusters city rest image 
texture 
final experiment binary partitioning deals gray scale images comprising natural textures 
example shown fig 

derive texture measure image subdivided pixel windows calculated local histograms texture features windows 
window corresponds graph vertex computed distance histograms window pairs method 
considering simplicity texture measure segmentation result obtained way excellent see figs 

order yield satisfactory result fiedler vector thresholded example 
median threshold sense image contain parts size 
note unsupervised case known 
perceptual grouping ground discrimination fig 
depicts result computed minimizing convex relaxation approach 
input data developed group professor 
fig 
shows line fragments computed scene depicted fig 

similarity measure primitives line fragments relative angle primitives 
correspondingly graph shows fig 
lines similar relative angle close multiple 
refer elaborate similarity measures essential testing approach optimization point view 
note groups exist fig 
coherent similarity measure minimizer shown fig 
determines keyboard coherent group expected visual inspection scene 
restoration section results convex relaxation approach respect restoration noisy dimensional signals 
result concerning restoration dimensional binary image shown fig 

considering desired object comprises structures large small spatial scales restoration result fairly 
discussion combinatorial optimization 
experimental results demonstrate approach versatile tool solving fig 

perceptual grouping 
section office table shown top 
output line finder 
similarity measure function angle line fragments 
fragments similar nearly orthogonal parallel 
coherent groups different cardinality exist 
minimizer determines coherent group line fragments suppresses groups 
binary partitioning perceptual grouping restoration semidefinite programming fig 

restoration 
binary noisy original image map iceland 
suboptimal solution computed convex optimization 
original adding noise 
table sizes computation times experiments section results obtained running dual scaling algorithm mhz pentium iii linux pc 
broad range difficult combinatorial problems convenient way 
example user focus choose constraint vector appropriate application interested worrying heuristics technical details order avoid bad local minima 
different application fields obtained meaningful solutions criterion optimized 
optimization problem suggested herault horaud instance useful saliency measure perceptual grouping gained mixed reputation literature due combinatorial complexity involved 
approach considerably mitigates problem 
convex versus spectral relaxation 
shown section convex relaxation provides tighter relaxation underlying combinatorial problem comparison spectral relaxation 
fact improvement explicit representing convex optimum solution eigenvalue optimization problem terms multiplier variables 
cases theoretical result turned significant practice spectral relaxation may yield solution doesn sense respect chosen optimization criterion 
furthermore spectral relaxation decisive disadvantage case unsupervised classification suitability criterion thresholding eigenvector depends particular data processed 
note cf 
section alternative improvements spectral relaxation techniques exist :10.1.1.160.2324:10.1.1.160.2324
concerning normalized cut criterion suppose choice different constraint vector improves classical spectral approach fiedler 
respect considerably generalized approach account arbitrary constraint vectors 
effect normalizing laplacian matrix tightness relaxation thresholding problem difficult 
computational viewpoint representation convenient underlying convex optimization problem 
analyze left open problem 
normalized cut criterion refer 
computational complexity 
price convenient properties optimization approach listed section squared number variables semidefinite relaxation 
approach benson able exploit sparse problem structure computation time quickly grows number variables problems variables solved 
problem perceptual grouping couple primitives prevents application large scale problems instance combinatorial image restoration cf 
table 
interesting theoretical result context concerns bounds derived maximal rank matrix solving semidefinite program 
applying result program obtain bound large means principle large number problem variables reduced setting rows matrix decomposition zero cf 
section 
show algorithms come exploit property considerable saving memory speed computation 
worked semidefinite programming framework applicable broad class binary combinatorial optimization problems computer vision 
opinion major contribution introduce fairly general novel optimization technique alternative established techniques particularly attractive sound underlying mathematical principles absence tuning parameters 
far focus primarily mathematical optimization convex relaxation existence feasible constraints solutions performance bounds 
ieee transactions pattern analysis machine intelligence vol 
november demonstrated applicability approach different nontrivial problems spend time working tailor similarity measures specific applications 
accordingly focus shift related general problem learning suitable metrics classification 
furthermore investigate case nonbinary classification intricate constraints relational graph matching 
acknowledgments supported deutsche forschungsgemeinschaft dfg schn 
preliminary version conference energy minimization methods computer vision pattern recognition 
amir lindenbaum generic grouping algorithm quantitative analysis ieee trans :10.1.1.21.1429
pattern analysis machine intelligence vol 
pp 
feb 
problems distance geometry convex properties quadratic maps discrete computational geometry vol 
pp 

benson ye zhang mixed linear semidefinite programming combinatorial quadratic optimization optimization methods software vol 
pp 

poggio torre ill posed problems early vision proc 
ieee vol 
pp 

besag statistical analysis dirty pictures royal statistical soc 
vol 
pp 

blake zisserman visual reconstruction 
mit press 
boppana eigenvalues graph bisection average case analysis proc 
th ann 
ieee symp 
foundations computer science pp 

borges estimation markov random field parameters ieee trans 
pattern analysis machine intelligence vol 
pp 
mar 
boykov veksler zabih markov random fields efficient approximations proc 
ieee conf 
computer vision pattern recognition cvpr pp 

boykov veksler zabih fast approximate energy minimization graph cuts ieee trans :10.1.1.112.6806
pattern analysis machine intelligence vol 
pp 
nov 
chou brown multimodal reconstruction segmentation markov random fields hcf optimization proc :10.1.1.112.6806
darpa image understanding workshop pp 
apr 
comaniciu meer mean shift robust approach feature space analysis ieee trans 
pattern analysis machine intelligence vol 
pp 
may 
cover geometrical statistical properties systems linear inequalities applications pattern recognition ieee trans 
electronic computers vol 
pp 

cox cox multidimensional scaling 
london chapman hall 
delorme poljak combinatorial properties complexity max cut approximation european combinatorics vol 
pp 

delorme poljak laplacian eigenvalues maximum cut problem math 
programming vol 
pp 

devroye automatic pattern recognition study probability error ieee trans 
pattern analysis machine intelligence vol 
pp 

graph theory 
springer 
duda hart pattern classification scene analysis 
new york john wiley sons 
homepage www uni bonn de projects html inst 
photogrammetry univ bonn germany 
fiedler property eigenvectors nonnegative symmetric matrices application graph theory math 
vol 
pp 

fischer ller buhmann path pairwise data clustering application texture segmentation proc 
energy minimization methods computer vision pattern recognition figueiredo jain eds pp 

forsyth ioffe joy sampling int computer vision vol :10.1.1.29.2078
pp 

frieze jerrum improved approximation algorithms max cut max bisection algorithmica vol 
pp 

fukunaga statistical pattern recognition 
academic press 
gdalyahu weinshall werman self organization vision stochastic clustering image segmentation perceptual grouping image database organization ieee trans 
pattern analysis machine intelligence vol 
pp 
oct 
geiger girosi parallel deterministic algorithms mrf surface reconstruction ieee trans 
pattern analysis machine intelligence vol 
pp 
may 
geman random fields inverse problems imaging ecole de probabilit de saint flour xviii ed vol 
pp 

geman geman stochastic relaxation gibbs distributions bayesian restoration images ieee trans 
pattern analysis machine intelligence vol 
pp 

goemans williamson improved approximation algorithms maximum cut satisfiability problems semidefinite programming acm vol :10.1.1.3.9509
pp 
june 
gold rangarajan graduated assignment algorithm graph matching ieee trans 
pattern analysis machine intelligence vol 
pp 
apr 
heitz perez bouthemy multiscale minimization global energy functions visual recovery problems cvgip image understanding vol 
pp 

herault horaud ground discrimination combinatorial optimization approach ieee trans 
pattern analysis machine intelligence vol 
pp 
sept 
hofmann buhmann pairwise data clustering deterministic annealing ieee trans 
pattern analysis machine intelligence vol 
pp 
jan 
ishikawa global optimization embedded graphs phd dissertation dept computer science courant inst 
math 
sciences new york univ 
jacobs robust efficient detection salient convex groups ieee trans 
pattern analysis machine intelligence vol 
pp 
jan 
karger stein new approach minimum cut problem acm vol 
pp 

kaufman rousseeuw finding groups data 
new york john wiley sons 
schn rr cremers binary partitioning perceptual grouping restoration semidefinite programming technical report computer science series group univ mannheim www uni mannheim de publications tr pdf :10.1.1.10.366

perception bayesian inference knill richards eds 
cambridge univ press 
laurent poljak positive semidefinite relaxation cut polytope linear algebra applications vols 
nos 
pp 

leclerc constructing simple stable descriptions image partitioning int computer vision vol 
pp 

li markov random field modeling computer vision 
tokyo springer verlag 
lov sz schrijver cones matrices set functions optimization siam optimization vol 
pp 

malik belongie leung shi contour texture analysis image segmentation int computer vision vol 
pp 

binary partitioning perceptual grouping restoration semidefinite programming mohar poljak eigenvalues combinatorial optimization combinatorial graph theoretical problems linear algebra klee eds vol 
pp 

nesterov quality semidefinite relaxation nonconvex quadratic optimization technical report core universit catholique de louvain belgium 
nesterov nemirovskii interior point polynomial methods convex programming 
siam 
rank extreme matrices semidefinite programs multiplicity optimal eigenvalues math 
operations research vol 
pp 

peterson artificial neural networks local search combinatorial optimization aarts lenstra eds chapter 
chichester wiley sons 
poljak rendl relaxations graph bisection problems siam optimization vol 
pp 

puzicha buhmann rubner tomasi empirical evaluation dissimilarity measures color texture proc 
int conf 
computer vision iccv pp 

rendl wolkowicz projection technique partitioning nodes graph annals operations research vol 
pp 

rose gurewitz fox constrained clustering optimization method ieee trans 
pattern analysis machine intelligence vol 
pp 
aug 
sarkar boyer perceptual organization computer vision review proposal classificatory structure ieee trans 
systems man cybernetics vol 
pp 

sato ishii bifurcations mean field theory annealing physical rev vol 
pp 

schn rr image labeling grouping minimizing linear functionals cones proc 
energy minimization methods computer vision pattern recognition figueiredo jain eds pp 

shi malik normalized cuts image segmentation ieee trans :10.1.1.160.2324
pattern analysis machine intelligence vol 
pp 
aug 
vandenberghe boyd semidefinite programming siam rev vol 
pp 

vapnik estimation dependencies empirical data 
springer 
vision texture database www white media mit edu vismod imagery vistex html 

weiss segmentation eigenvectors unifying view proc 
int conf 
computer vision iccv pp 

williams comparison measures detecting natural shapes cluttered backgrounds int computer vision vol 
pp 

winkler image analysis random fields dynamic monte carlo methods applications math vol 
heidelberg springer 
handbook semidefinite programming wolkowicz vandenberghe eds 
boston kluwer academic 
wright primal dual interior point methods 
siam 

wu cluster expansions deterministic computation bayesian estimators markov random fields ieee trans 
pattern analysis machine intelligence vol 
pp 
mar 
wu zhu liu equivalence julesz ensembles frame models int computer vision vol 
pp 

ye interior point algorithms theory analysis 
wiley 
ye approximation algorithm max bisection math 
programming vol 
pp 

zhu mumford prior learning gibbs reaction diffusion ieee trans 
pattern analysis machine intelligence vol 
pp 
nov 
jens received diploma degree mathematics university ck 
research assistant computer vision graphics pattern recognition group university mannheim 
focus current research application convex optimization methods image partitioning segmentation 
christoph schn rr received dipl ing 
degree electrical engineering dr nat 
degree computer science technical university karlsruhe habilitation degree computer science university hamburg germany 
held positions researcher fraunhofer institute information data processing iitb karlsruhe researcher assistant professor cognitive systems group university hamburg 
visiting researcher computer vision active perception laboratory kth stockholm sweden 
department mathematics computer science university mannheim set head computer vision graphics pattern recognition group 
dr schn rr serves editorial board journal mathematical imaging vision member dagm siam 
research interests include computer vision pattern recognition related aspects mathematical modeling optimization 
christian received diploma degree physics university dortmund 
currently phd student computer vision graphics pattern recognition group professor schn rr university mannheim germany 
current research interests include combinatorial optimization problems pattern recognition related convex optimization methods 
daniel cremers received ms degree physics distinction university heidelberg phd degree computer science summa cum laude university mannheim 
fulbright scholar state university new york stony brook 
currently postdoctoral researcher university california los angeles 
research interests areas computer vision image processing focus integration statistical shape knowledge image segmentation processes 
information computing topic please visit digital library computer org publications dlib 
