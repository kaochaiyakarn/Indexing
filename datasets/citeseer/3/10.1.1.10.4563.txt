comparison fast blocking methods record linkage baxter csiro mathematical information sciences gpo box canberra act australia baxter csiro au record linkage millions individual health records approved research purposes computationally expensive task 
blocking methods record linkage systems reduce number candidate record comparison pairs feasible number whilst maintaining linkage accuracy 
new blocking methods implemented high dimensional indexing clustering algorithms 
compare new blocking methods bigram indexing canopy clustering tfidf term frequency inverse document frequency older methods standard traditional blocking sorted neighbourhood blocking 
results show blocking methods bigram indexing canopy clustering provide scalable blocking methods maintaining improving record linkage accuracy 
potential large performance speed ups better accuracy achieved new blocking methods 
peter dept computer science australian national university canberra act australia cs anu edu au categories subject descriptors pattern recognition clustering information storage retrieval information storage retrieval clustering general terms performance evaluation keywords record linkage object reconciliation data integration technical report 
page version published workshop data cleaning record linkage object consolidation kdd washington dc august 
tim churches centre epidemiology research nsw department health locked bag north sydney australia health nsw gov au process diagram record linkage system 
record linkage techniques link records relate entity patient customer data sets unique identifier available 
record linkage important initial step research data mining projects biomedical sectors improve data quality assemble longitudinal data sets available 
shows processing view standard record linkage system architecture implemented tailor febrl automatch :10.1.1.12.4018:10.1.1.3.9195:10.1.1.34.4329
major challenges record linkage computational complexity linkage accuracy 
linking data sets millions records take hours days modern computing systems 
developments information retrieval database systems machine learning data mining potential improve efficiency accuracy record linkage system components 
developments include efficient blocking methods adaptive distance metrics evaluation record pair similarity learning methods classification task deciding record pair match non match possible match 
potentially record data set compared records second data set number record pair comparisons grows quadratically number records matched 
approach computation ally infeasible large data sets 
reduce huge number possible record pair comparisons traditional record linkage techniques blocking fashion record attribute sub set attributes split data sets blocks 
record pairs detailed comparison generated records block records value blocking attribute 
detailed comparison functions include approximate string comparisons names addresses date age comparisons date birth 
focus comparing speed accuracy new blocking methods established blocking method implementations 
performance bottleneck record linkage system usually evaluation similarity measure pairs records 
choice blocking method greatly reduce number record pair evaluations performed achieve significant performance speed ups 
consider alternative clustering methods forming blocks record linkage process 
mccallum nigam unger cohen richman proposed highdimensional similarity indexing improve efficiency blocking methods :10.1.1.12.4018:10.1.1.3.9195:10.1.1.34.4329
similarity blocking clustering previously observed :10.1.1.12.4018:10.1.1.34.4329
compare standard blocking sorted neighbourhood method bigram indexing canopy clustering tfidf :10.1.1.46.6676:10.1.1.34.4329
contribution empirically compare speed accuracy sensitivity specificity performance blocking methods 
blocking methods directly affect sensitivity record pairs true matches block compared matched indirectly affect specificity better reduction ratio number record pair comparisons allows computationally intensive comparators employed 
particular purpose record linkage public health records approved research purposes 
linkage accuracy critical importance avoiding unnecessary noise linkage results 
needed enable reliable testing public health hypotheses addressed research projects 
note linkage accuracy applications mail merge bibliographic matching web site source integration desirable critical 
decision model incorporating costs record linkage system proposed verykios 
structured follows 
section describe details blocking methods investigation 
section presents experimental protocol evaluation metrics data sets section discuss results various experiments 
section 
blocking methods standard blocking standard blocking sb method clusters records blocks share identical blocking key 
blocking key defined composed record attributes data set 
example blocking key characters surname attribute 
blocking key composed attribute example postcode attribute combined age category attribute 
cost benefit trade considered choosing blocking keys 
resulting blocks contain large number records record pairs necessary generated leading inefficiently large number comparisons 
example gender attribute blocking key puts available records large blocks 
hand blocks records small true record pairs may missed reducing linkage accuracy sensitivity 
example blocking social security number ssn attribute leads small blocks individuals data sets 
errors ssn may mean true record pair matches included blocks 
consideration choice blocking keys error characteristics record attributes 
achieve linkage accuracy preferable error prone attributes available 
multiple blocking keys way mitigate effects errors blocking keys 
passes iterations different blocking keys performed example automatch resulting different blocks different record pair comparisons 
multiple passes improve linkage accuracy efficient implementation tuning multiple blocks multiple sets record comparisons achieve 
strategy reduce effects spelling transcription errors record attributes blocking keys typically name address attributes phonetic encodings :10.1.1.3.9195
assuming data sets records linked blocking method resulted blocks size containing records resulting number record pair comparisons :10.1.1.3.9195:10.1.1.3.9195
course ideal case hardly achievable real data 
number record pair comparisons dominated largest block 
sorted neighbourhood sorted neighbourhood sn method sorts records sorting key moves window fixed size sequentially sorted records 
records window paired included candidate record pair list 
window limits number possible record pair comparisons record 
resulting total number record pair comparisons assuming data sets records sorted neighbourhood method wn :10.1.1.3.9195:10.1.1.3.9195
similar standard blocking advantageous passes iterations different sorting keys smaller window size pass large window size 
problem sorted neighbourhood method arises number records larger window size value sorting key 
example having sorting key surname hundreds records value smith blocking method number blocks parameter standard blocking standard blocking standard blocking bigram indexing bigram indexing bigram indexing table number blocks produced standard blocking bigram indexing 
length blocking key values bigram threshold 
window size small records surname value smith compared 
bigram indexing bigram indexing bi method implemented febrl record linkage system allows fuzzy blocking :10.1.1.12.4018
basic idea blocking key values converted list bigrams sub strings containing characters sub lists possible permutations built threshold 
resulting bigram lists sorted inserted inverted index retrieve corresponding record numbers block 
example blocking key value baxter result bigram list ba ax xt te er 
threshold sub lists length calculated length bigram list times threshold inserted inverted index ax xt te er ba xt te er ba ax te er ba ax xt er ba ax xt te record numbers contain blocking key value baxter inserted blocks increasing number record pair comparisons compared standard blocking 
number sub lists created blocking key value depends length value threshold 
lower threshold shorter sub lists sub lists blocking key value resulting smaller blocks inverted index 
information retrieval field bigram indexing robust small typographical errors documents :10.1.1.12.4018:10.1.1.3.9195
standard blocking number record pair comparisons data sets records blocks containing number records :10.1.1.3.9195:10.1.1.3.9195
discussed number blocks larger bigram indexing 
demonstrated particular data set table 
canopy clustering tfidf canopy clustering tfidf term frequency inverse document frequency forms blocks records records placed canopy cluster 
canopy cluster formed choosing record random candidate set records initially records putting cluster records certain loose threshold distance 
record chosen random records certain tight threshold distance removed candidate set records 
tfidf distance metric bigrams tokens 
algorithm details :10.1.1.12.4018:10.1.1.34.4329
number record pair comparisons resulting canopy clustering fn number records data sets number canopies average number canopies record belongs :10.1.1.34.4329
threshold parameter set small large order reduce amount computation 
small method able detect typographical errors 

data sets evaluation metrics linkage software febrl flexible modular testbed :10.1.1.12.4018
febrl version implements standard blocking bigram indexing 
implemented sorted neighbourhood canopy clustering tfidf 
written object oriented scripting language python published open source software febrl ideal platform implement new algorithms techniques aspects data cleaning standardisation record linkage 
data sets blocking fields artificially generate mailing list data containing surnames names attributes 
results experiments dependent error characteristics data source documented 
default parameters specify uniformly sized clusters 
choose number clusters half number records results records having single duplicate 
records record true match duplicates 
blocking key febrl specified surname attribute truncated characters concatenated name attribute truncated characters 
note names data sets characters long actual length blocking key variable maximum length characters 
parameterise blocking key length values truncated characters 
example surname value baxter name result blocking key value 
febrl configured standardisation cleaning performed input data sets values generated directly form blocking indexes 
evaluation metrics added evaluation module febrl calculate performance metrics blocking methods :10.1.1.3.9195
methods require true identity information record pairs available test data sets 
metric reduction ratio rr defined rr number record pairs produced blocking method comparison number possible record pairs entire data sets assuming link data sets records 
rr relative reduction number record pairs compared 
rr measure time taken particular implementation blocking algorithm 
time taken methods rr vary considerably 
methods may require sort large data sets time consuming operation 
second metric pairs completeness pc metric defined sm number true match record pairs set record pairs produced comparison blocking method nm total number true match record pairs entire data 
third metric score combines rr rr harmonic mean score captures rr trade pairs completeness reduction ratio metrics 
focus rr precision recall linkage results allows direct evaluation indexing methods possible confounding results comparison decision methods 

experimental results considered standard blocking blocking key values truncated characters denoted graphs 
sorted neighbourhood method windows denoted graphs 
standard blocking sorted neighbourhood methods shows pairs completeness results reduction ratio results score results 
results show trends similar produced tai lor similar experimental framework :10.1.1.3.9195
standard blocking trades pairs completeness reduction ratio performance number blocks increases 
smaller blocks results comparisons true match pairs missed 
sorted neighbourhood method avoids extremes performance standard blocking behaviour changes predictably window size increased 
larger windows pairs completeness results improve reduction ratio decreases 
bigram indexing canopy clustering tfidf shows pairs completeness results reduction ratio results score results 
bigram indexing canopy clustering outperform earlier blocking methods right parameter settings 
increased performance significant 
pairs completeness data size records pairs completeness standard blocking sorted neighbourhood methods reduction ratio data size records reduction ratio standard blocking sorted neighbourhood methods score data size records score standard blocking sorted neighbourhood methods pairs completeness data size records bigram bigram bigram canopy canopy canopy pairs completeness bigram indexing canopy clustering methods reduction ratio bigram bigram bigram canopy canopy canopy data size records reduction ratio bigram indexing canopy clustering methods score data size records bigram bigram bigram canopy canopy canopy score bigram indexing canopy clustering methods data set canopy cluster canopy cluster size average size maximum size table canopy cluster average maximum sizes different data set size loose threshold example pairs completeness earlier methods maximum maximum canopy clustering tfidf optimal parameter settings 
data set records amounts missing true matches blocking component record linkage 
bigram indexing performs best threshold parameter 
results blocks bigrams data sets 
canopy clustering performs best loose threshold set 
loose threshold leads poor reduction ratio huge run times 
canopy clustering reduction ratio drops slightly data set records 
looked closely causes degradation tracking size canopy clusters produced loose threshold 
shown table 
fixed threshold cluster size growing leading record pairs generated 
canopy clustering stochastic blocking method discussed results vary run run 
ran experiment times produce average 
standard deviation results metrics considered larger 
shows variation canopy clustering runs affect ranking results 

describes progress 
wish consider promising fast indexing methods 
class candidates vector subspace mapping 
jin li mehrotra applied methods fastmap record linkage 
empirical theoretical comparison fastmap vector subspace mapping methods methods discussed interest 
experimental comparisons extended non data sets investigate dependencies data sources error characteristics 
indexing methods extended non name address attributes dates 
implementation issues indexing methods effects run time considered 
main contribution direct evaluation reduction ratio pairs completeness diverse indexing methods artificial data sets widely database generator 

acknowledgments development febrl record linkage system funded australian national university anu nsw department health anu industry collaboration scheme 
additional funding provided australian partnership advanced computing 

churches 
febrl freely extensible biomedical record linkage manual release edition april 
churches datamining anu edu au linkage html :10.1.1.12.4018
cohen richman :10.1.1.12.4018:10.1.1.3.9195
learning match cluster large high dimensional data sets data integration 
sigkdd 
verykios elmagarmid :10.1.1.3.9195
tailor record linkage toolbox 
proc 
th int 
conf 
data engineering 
ieee 
hernandez stolfo 
merge purge problem large databases 
proc 
act sigmod conf pages 
hernandez stolfo 
real world data dirty data cleansing merge purge problem 
journal data mining knowledge discovery 
jaro :10.1.1.34.4329
software demonstrations 
proc 
international workshop exposition record linkage techniques arlington va usa 
jaro 
advances record linkage methodology applied matching census tampa florida 
journal american statistical society 
jin li mehrotra 
efficient record linkage large data sets 
int 
conf 
database systems advanced applications dasfaa tokyo japan march 
alvey editors 
record linkage techniques 
proceedings workshop exact matching methodologies arlington virginia may 
internal revenue service publication washington dc 
mccallum nigam ungar :10.1.1.34.4329
efficient clustering high dimensional data sets application matching 
proc 
sixth acm sigkdd int 
conf 
kdd pages 
verykios 
bayesian decision model cost optimal record matching 
vldb journal 

big match program extracting probably matches large file record linkage 
rrc census bureau 
