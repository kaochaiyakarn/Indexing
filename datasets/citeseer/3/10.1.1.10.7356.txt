characterizing performance network intrusion detection sensors lambert thomas branden moore department computer science engineering university notre dame 
network intrusion detection systems nids important tool protecting critical information infrastructure 
quality nids described percentage true attacks detected combined number false alerts 
high quality nids algorithm effective processing cost high resulting loss packets increases probability attack detected 
study measures compares major components nids processing cost number diverse systems pinpoint performance bottlenecks determine impact operating system architecture differences 
results show moderate speed networks systems inadequate nids platforms 
performance depends processor performance large extent memory system 
trends processor microarchitecture deep pipelines negative impact systems nids capabilities multiprocessor architectures usually lead significant performance improvements 
results provide valuable guidelines nids developers adopters choosing suitable platform highlight need consider processing cost developing evaluating nids techniques 
network intrusion detection increasingly important tool detect analyze security threats organization network 
complements network security techniques firewalls providing information frequency nature attacks 
network intrusion detection system nids consists sensor analyzes network packet segment observation forwards packets deemed interesting alert message backend system stores analysis correlation events 
author address department computer science engineering university notre dame fitzpatrick hall notre dame indiana usa 
tel 

fax 
mail lambert cse nd edu sensor implemented general purpose computer system running network intrusion detection software 
separate system may host database similar software provide long term storage additional analysis capabilities 
relying shelf hardware software approach produces costeffective flexible network intrusion detection system 
network observation sensor operator analysis backend fig 
common nids architecture commonly performance network intrusion detection system characterized probability attack detected combination number false alerts 
equally important system ability process traffic maximum rate offered network minimal packet loss 
significant packet loss leave number attacks undetected degrades effectiveness system 
high performance sensor able process packets higher rate apply sophisticated detection techniques reduce number false alerts 
networking components nids hosts rely flow control mechanisms acknowledgments control incoming data rate 
nids able process packets maximum rate offered network segment 
focuses performance nids sensor especially hardware platform critical component network intrusion detection system deficiencies propagate entire system 
presents methodology quantify network intrusion detection capabilities general purpose computer systems 
set experiments test platform capabilities different traffic characteristics separating nids processing load distinct components 
combined observed behavior predict performance nids network link 
results provide valuable guidelines researchers designers adopters network intrusion detection systems 
comparative analysis variety systems running snort rule nids sensor reveals general purpose computer systems inadequate nids sensor platforms moderate speed networks 
analysis shows single factor determines performance system number architectural system parameters operating system structure main memory bandwidth latency processor microarchitecture contribute system suitability nids sensor platform 
furthermore trends deep processor pipelines maximize cpu clock frequency small scale multiprocessors significantly improve nids performance may detrimental effects 
past dram performance improvements kept pace advances processor network speeds nids sensors increasingly significant bottleneck 
section describes design rationale experimental methodology detail 
section describes measured platforms presents discusses results 
section contrasts related areas performance characterization high speed network intrusion detection high performance networking 
section draws outlines 
experimental methodology network ids performance model network intrusion detection sensor inspects packet network observation effort identify suspicious packets related intrusion attempts 
common approach user defined rules describe fingerprint potentially harmful interesting packets nids software 
intrusion detection algorithm applies rules patterns packet forwards packet positive match alert message analysis backend 
processing load exerted algorithm depends characteristics rules network traffic 
rules generally fall categories depending apply packet header payload 
header rules inspect packet header attempt detect specific combinations features source destination address port numbers checksums sequence numbers 
payload rules attempt match specific byte sequence packet payload 
nids rules may combine header payload specific match conditions 
header size generally fixed processing cost applying header rules nearly constant packet regardless actual packet size cost payload rules scales packet size 
real network traffic hand comprised packets different sizes 
small packets involve larger relative overhead carry payload header larger packets 
applications wishing maximize effective bandwidth generally utilize large packets effective nids able handle packets size 
different classes nids rules lead separate trends sustained performance nids platform 
analysis traffic consisting small packets dominated constant cost header rules larger packets cost payload analysis begins dominate 
network segment fixed capacity number packets transferred second inversely proportional packet size 
reason header rules exhibit highest processing load small packets 
hand relative header overhead decreases larger packet sizes cost payload rules scales packet size 
addition nids processing cost regardless type rule applied packet incurs processing cost due interrupt system call handling related protocol processing memory copy involved reading packets user space 
similar classes nids rules interrupt protocol cost largely constant packets memory copy cost scales packet size 
noted packets nids platforms traverse complete network protocol stack 
nids software inspects packet headers payload packets usually read raw network device normally enter tcp ip protocol stack 
internally nids software may replicate protocol stack functionality inspects ip header encapsulated higher level protocol header 
measurements comprehensively describe performance envelope network ids platform measurements performed different packet payload sizes bytes bytes bytes bytes covering range minimum maximum size packets ethernet networks 
separate experiments performed header rules payload rules 
separation allows attribute observed bottlenecks particular type rules 
network traffic generated pair hosts public domain ttcp utility 
ttcp transmits specified amount data server client tcp connection 
traffic generation hosts connected mbit second full duplex ethernet segment half duplex tap send copy data packet ttcp conversation sensor platform running snort network intrusion detection software 
sending hosts able nearly saturate mbit second network link effective bandwidth mbit second 
precisely determine processing cost nids rules number nids rules increased number packets reported intrusion detection software actual number packets sent indicating packets dropped nids platform 
header rule unique eliminate possibility optimization pattern matching engine rules identical structure incur identical cost 
payload rules scan entire packet payload matching string 
rules designed rule matches observed packet stream alerts generated nids deployments attacks exception norm 
design ensures rules applied packet 
rule triggers alert intrusion detection system may skip remaining rules generating forwarding alert incurs additional cost cases comparable exceed cost remaining rules 
experiments run seconds idle systems repeated multiple times minimize impact measurement error 
total number rules platform able support measure platform nids capabilities 
approach varying number rules network traffic rate chosen closely corresponds usage intrusion detection systems field administrators little control packet rate bandwidth network adjust number rules 
experiments modeled realistic nids setups provide meaningful insights recommendations users intrusion detection systems 
experiments specific network intrusion detection system approach decomposing nids cost constant payload dependent components applicable nids software relies pattern matching techniques 
nearly system receiving network traffic incurs constant packet cost interrupt handling protocol processing done inside kernel nids software 
addition cases inspection packet payload incurs cost scales packet size 
advances pattern matching algorithms optimization techniques reduce cost signature intrusion detection may change relationship number rules packet byte cost 
hand experiments percent cpu time spent inside operating system handling interrupts system calls 
portion nids processing cost independent particular nids algorithm employed system 
consequently drawn experiment concerning system nids platform applicable nids systems provide meaningful insights designers users network intrusion detection systems 
shows plot percentage dropped packets function number payload rules ghz pentium system running snort 
writing snort distributed set rules different classes 
percent packet loss header rules fig 
dropped packets versus number header rules pentium mhz byte packets example demonstrates small numbers rules nearly packets lost number rules exceeds maximum processing capability system number dropped packets increases drastically 
magnitude increase lost packets underlines need understand performance limitations general purpose systems nids platforms 
results shown section maximum number rules supported platform packet loss percent 
experimental systems set experiments described performed ia systems diverse processing capabilities configurations 
table summarizes relevant configuration parameters 
processor mmx mhz table test system configuration pp pentium iii mhz pentium iii mhz single dual processor cache kbyte kbyte kbyte cache kbyte kbyte kbyte system bus mhz mhz mhz memory mb dram mbyte sdram mbyte sdram chipset intel fx intel iii le pci bus bit mhz bit mhz bit mhz nic com com compaq nc os freebsd freebsd debian linux kernel processor celeron ghz pentium ghz dual pentium xeon ghz cache kbyte kbyte kbyte cache kbyte kbyte kbyte system bus mhz mhz mhz memory mbyte sdram mbyte sdram mbyte ddr sdram chipset iii le intel gc pci bus bit mhz bit mhz bit mhz nic compaq nc com compaq nc os freebsd debian linux kernel freebsd debian linux kernel platforms cover wide range system architectures capabilities provide insight contribution various system characteristics observed nids performance 
number parameters vary considerably test platforms nids software instruction set remain fixed allow meaningful comparison 
systems run snort libpcap 
results sections compare different subsets systems provide insight contribution system architecture configurations nids capabilities platform 
results comparison table summarizes maximum number header rules supported platforms tested 
increasing number rules values leads significant packet loss negatively impacts intrusion detection system ability detect attacks 
table maximum number header rules supported system packet payload size bytes system results lead significant 
generalpurpose systems tested appear inadequate serve nids platform especially considering snort distribution includes rules various classes 
systems able process network traffic consisting packets saturated mbit second network 
scenario normal network conditions occasional bursts short packets overwhelm intrusion detection system 
potential intruders exploit weakness hiding attacks large number short packets 
experiments keep network bandwidth constant small packets result significantly higher packet rate fewer rules applied platform 
second platform nids capabilities directly related microprocessor affected system parameters 
evaluation comparison performed sections uncover sources performance bottlenecks deficiencies 
table summarizes maximum number payload rules supported set test platforms 
total number payload rules notably smaller maximum number header rules platform support 
header rules payload rules search entire data portion packet matching pattern 
sequential scan significantly expensive test packet header 
addition header rules check match exactly known location packet header payload rules may required search sequence bytes packet body 
table maximum number payload rules supported system packet payload size bytes system generally hold experiments 
generalpurpose systems cases able perform significant processing packets fully saturated network link 
furthermore cpu performance sufficient indicator systems nids capabilities 
gain better understanding various bottlenecks platforms sections compare different subsets systems 
normalized performance experiments described total network bandwidth constant different packet sizes 
consequently tests small packets produce higher packet rate tests larger packets 
hand header rules expected incur constant cost regardless packet size payload rules incur interrupt costs independent total packet size 
investigate processing costs independently packet rate graphs show product rules packets second constant cost header processing product number rules data rate payload processing 
rules packets rules mbyte packet size bytes header rule cost payload rule cost packet size bytes single fig 
normalized rule processing cost dual dual single graph plots product number header rules packet rate different packet sizes systems tested 
header rules exert constant processing load product packet rate rule count expected approximately constant 
graph shows systems byte packets expensive process 
smaller packets performance drops sharply due excessive interrupt rates 
tests fully saturated mbit second ethernet link transfers approximately byte packets second 
interrupt cost tens microseconds cpu utilization interrupt handling approach significant percentage total cpu time 
furthermore interrupt handling interferes application processing evicting cache translation lookaside buffer tlb entries frequent interrupts increase pressure caches tlbs 
larger packets slightly expensive due packet copy operation read system call 
header rules inspect packet payload entire packet copied kernel user space 
larger packets operation expensive 
second graph shows product payload rules data rate packet size systems 
notice order packet size reversed previous graph improve clarity 
processing cost payload rules proportional payload size product data rate number rules expected constant 
results show smaller packets expensive large packets 
effect attributed interrupt system call handling cost nearly constant packet sizes 
discussed earlier small packets arriving high rate incur significant interrupt costs leaving cpu time actual payload processing 
operating system sensitivity gauge impact operating system differences nids performance compares header payload rule processing capabilities ghz pentium system different operating systems debian linux kernel freebsd compiled default configuration nids specific optimizations 
classes rules processing capabilities normalized multiplying number rules packet rate data rate respectively shown previous section 
linux freebsd operating systems chosen widely nids platforms freely available understood proven stable platforms network intensive applications 
cases linux platform outperforms freebsd system 
difference significant constant cost header rules linux platform able support percent rules 
payload rules difference ranges percent 
results indicate linux kernel handles interrupts efficiently freebsd 
header rule incurs relatively small constant cost faster interrupt processing directly benefits type processing 
payload rules hand scan entire packet depend largely architectural characteristics operating system 
rules packets header rule cost packet size bytes payload rule cost linux bsd packet size bytes fig 
pentium os dependencies linux bsd multiprocessor issues past years cost effective small scale multiprocessors available sources 
potential divide interrupt handling nids processing cost multiple processors system attractive platform network intrusion detection 
compares normalized processing capabilities system processors 
mhz platform selected supports choice processors 
furthermore nids capabilities close best performing system apply current high systems 
header processing dual cpu system performs significantly better single cpu system minimum size packets 
linux process scheduler support assignment process particular cpu appears interrupt handling effectively loaded second processor 
fact dual processor system able apply header rules traffic single cpu system completely saturated support rules 
byte packets dual processor system outperforms single cpu host approximately percent 
rules packets rules mbyte header rule cost packet size bytes payload rule cost dual single dual single packet size bytes fig 
pentium multiprocessor dependencies large packets hand additional processor offers smaller performance improvement percent 
type traffic packets arrive slow rate interrupt handling significant source processing load 
interrupts handled cpu nids software executes sharing packet buffers leads cache coherency traffic cpus slowing memory requests 
addition synchronization inside kernel interrupt system call handler imposes limits speedup 
payload processing similar trend observed benefit second cpu ranging percent 
small packets interrupt rate sufficiently high offloading second processor improves performance larger packets coherency traffic counteracts effect 
performance advantage dual cpu system smaller expected 
benefit dividing interrupt handling rule processing processors limited due os internal synchronization cache coherency overhead 
sensitivity architectural parameters section presents comparative results pentium pentium pentium dual pentium systems 
eliminating operating system dependencies comparison provides insight contribution various architectural parameters nids performance 
addition configuration parameters available public documentation system parameters measured lmbench 
table summarizes processor clock speed memory hierarchy performance system call latencies peak bus performance lists observed nids sensor performance platform 
addition rightmost columns show relative improvement parameter compared baseline pentium system 
table architectural parameters observed performance absolute values improvement processor clock mhz cache latency ns cache latency ns dram latency ns cache copy bw mb cache copy bw mb dram copy bw mb system call latency ns bus bw mb header rules byte header rules byte payload rules byte payload rules byte memory latency measured lmbench sequence dependent load instructions reported results true load latencies observed programs 
bandwidth measured system native memcpy routine 
reported part nids cost stems memory copy operation kernel user space 
system call latency measured getpid system call 
measured systems code path involved system calls external interrupts identical actual handler function microprocessors mechanisms handle interrupts software traps system call latencies indication system interrupt performance 
generally reading network packet raw device involves system call network interrupt 
unfortunately lmbench measure bus performance 
give indication systems pci bus capabilities peak performance reported 
header payload processing pentium ghz system shows speedup baseline mhz pentium platform exceeds cpu clock frequency improvement 
effect attributed advances memory subsystem 
cache latency copy bandwidth bus bandwidth show improvements 
system call latency measurement indicates faster memory system leads significantly faster system call interrupt handling 
ghz pentium system shows moderate improvements baseline system despite fact runs times higher processor clock rate modern microarchitecture 
level cache main memory bandwidth level cache latency improved memory systems aspects exhibit lower performance baseline system 
interestingly system call latencies percent higher baseline system 
pentium system features deep pipeline achieve high clock rates 
microarchitecture benefits compute intensive codes regular structures interrupt handling operating system codes perform poorly systems due expensive pipeline flushes branch mispredictions serialization conditions 
disadvantages lead poor performance header processing pentium system 
payload processing high clock frequency slightly higher memory bandwidth compensate effects deep pipeline 
ghz pentium xeon system shows similarly small improvements header processing outperforms systems payload processing 
irregular branch intensive header processing penalized deep processor pipeline significantly improved memory subsystem results high payload processing performance 
network adapter transfers incoming packets main memory dma invalidating previously cached copies receive buffers cpu cache 
subsequently packet contents incur cache misses satisfied main memory 
consequently high bandwidth main memory system combination processors high clock frequency lead significant payload processing improvements 
shown previously architecture relatively small impact nids performance 
ghz pentium xeon processor dual cpu system implements form simultaneous multithreading 
architectural technique implements logical processors chip improve system small cost increase 
operating system logical processors appear independent cpus execute different processes handle interrupts 
logical processors share execution resources including caches system interface performance improvement second logical processor significantly smaller traditional multiprocessor 
consequently contribution nids capabilities ghz pentium xeon system relatively minor 
unfortunately impact bus nids performance clear experiments 
fastest systems tested feature mhz bit pci bus slower mhz bit bus easily sustain moderate data rate testbed network 
fully saturated mbit second ethernet link transfers mbytes second including packet headers 
standard buses pose bottleneck transfer rate 
addition writing network packets main memory bus processor access control registers interrupt handling 
faster clock rate bus leads slightly improved control register read latency benefits interrupt costs somewhat 
related efforts systematically study performance requirements network ids sensors variety platforms attribute bottlenecks specific system features 
previous evaluating intrusion detection systems focused testing quality ids 
prominent effort darpa ids evaluation carried mit lincoln labs 
reports design test traffic rational provide valuable resource attempting similar effort 
evaluation geared comparing wide variety systems unable provide insights sources performance bottlenecks 
industrial whitepapers add valuable practical experience testing evaluating intrusion detection systems nature limited scope 
describe integrated approach nids evaluation combines quality performance metrics 
designed compare different intrusion detection systems terms number alerts generated variety loads including overload situations intended subvert nids 
approach takes capabilities nids platform account compare variety platforms running nids software 
contrast mainly concerned throughput network ids sensor platform designed give insights sources inadequacies 
addition experimental setup intentionally kept simple methodology widely applicable 
proposed network ids approaches tested evaluated respect performance 
experiments usually restricted test peak performance system addressing sources bottlenecks relationship architectural parameters scalability different platforms 
previous high performance networking characterized bottlenecks various systems proposed solutions form hardware support protocol stack optimizations 
largely agree results emphasizing cost interrupt handling data copying 
nids systems actively participating network communications proposed optimizations larger frame sizes applicable nids platforms 
furthermore remain general previous studies usually consider applications impact performance studies combined performance requirements device driver operating system network intrusion detection software 
presents simple methodology measure characterize performance general purpose systems network intrusion detection sensors 
methodology constructs performance profile measuring cost main classes nids processing different packet sizes 
varying number rules applied packet peak performance configuration established need control packet rate bandwidth test traffic 
performance profile obtained way predict performance computer system network ids sensor 
comparative study distinct systems shows general purpose computers generally inadequate act sensors moderate speed networks 
nearly saturated mbit second network link system support maximum header rules losing packets 
larger numbers rules significant percentage packets dropped degrading nids effectiveness detecting security breaches 
packets systems able perform significant processing 
point comparison default rule file supplied snort distribution contains rules 
results highlight need understand processing capabilities network intrusion detection platforms consider processing cost nids algorithms addition quality 
addition results indicate single architectural parameter determines network ids capabilities combination factors contributes sustained performance 
particular processor speed suitable predictor nids performance demonstrated nominally slower pentium system outperforming pentium system higher clock frequency 
memory bandwidth latency significant contributor sustainable throughput 
furthermore comparison popular operating systems reveals efficient interrupt handling linux kernel leads non negligible performance improvements 
multiprocessor architectures hand offer relatively small advantage network intrusion detection 
additional processor able offload interrupt processing kernel synchronization cache coherency traffic resulting shared buffers limits benefit 
current trends processor memory network performance improvements show main memory increasingly important bottleneck system performance 
network intrusion detection systems largely memory bound nids sensor performance remain critical 
results optimization rule intrusion detection systems remains important concern 
advances pattern matching algorithms clustering rules compilation rules optimized detection engines reduce number comparisons needed cost individual comparisons may process increase memory footprint signature matching engine 
nids performance shown memory bound improving cache behavior pattern matching techniques promising approach 
minimizing memory requirements instance blocking tiling internal data structures may processors keep larger portion frequently accessed data cache improving performance 
promising approaches improve nids throughput include distribution network traffic number sensors pipelining processing packets series nids processes distribution different rules multiple sensors 
large percentage cpu time spent inside operating system kernel optimizations nids software limited benefit 
effective optimizations include interface intrusion detection software operating system 
focuses rule nids sensors signature matching involves extending methodology network ids approaches protocol filtering analysis 
addition highspeed networks highly effective sensors may produce alerts rate greater analysis backend absorb 
consequently important performance analysis components network intrusion detection systems accurately quantified 
authors wish frank irving matthew contributions carrying numerous experiments aaron anonymous reviewers encouraging helpful comments 
part supported faculty research university notre dame graduate school 
material national science foundation 
opinions findings recommendations expressed material authors necessarily reflect views national science foundation 
banks high performance network architecture pa risc workstation ieee journal selected areas communications vol 
feb pp 

cheung crawford frank levitt staniford chen yip design grids graph intrusion detection system tech 
report cse computer science dept univ california davis calif 
clark jacobson analysis tcp processing overhead ieee communications magazine vol 
june pp 

staniford faster string matching intrusion detection exceeding speed snort proc 
darpa information survivability conference exposition discex ii ieee cs press los alamitos calif pp 

acid analysis console intrusion databases sourceforge net 
edwards vulnerabilities network intrusion detection systems realizing overcoming risks 
case flow mirroring whitepaper top layer networks 
optimizing compiler snort rules whitepaper security systems chase trapeze ip tcp ip near gigabit speeds proc 
usenix technical conference usenix assoc berkeley calif pp 

haines lippmann fried das darpa intrusion detection system evaluation design procedures tech 
report mit lincoln laboratory technical report boston mass 
hinton microarchitecture pentium processor intel technology journal 
toth automatic rule clustering improved signature intrusion detection tech 
report distributed systems group technical univ vienna austria 
vigna kemmerer stateful intrusion detection high speed networks proc 
ieee symposium security privacy ieee computer society press calif 
marr hyper threading technology architecture microarchitecture intel technology journal vol 
february pp 

paxson bro system detecting network intruders real time computer networks vol 
pp 

protocol analysis vs pattern matching whitepaper network ice 
zhang chung mukherjee olsson methodology testing intrusion detection systems ieee transactions software engineering vol 
pp 

experiences benchmarking intrusion detection systems whitepaper network flight recorder security www snort org docs benchmarking ids nfr pdf snort lightweight intrusion detection networks proc 
usenix lisa conf november 
www snort org docs txt rosenblum bugnion herrod witchel gupta impact architectural trends operating system performance proc 
th acm symp 
operating system principles acm press new york 
sekar guang verma high performance network intrusion detection system proc 
th acm symp 
computer communication security acm press new york 
snort detection revisited whitepaper network security 
snort rules version march 
www snort org dl rules stable tar gz steenkiste systematic approach host interface design high speed networks ieee computer vol 
march pp 

mcvoy staelin lmbench portable tools performance analysis proc 
usenix ann 
technical conference usenix assoc berkeley calif pp 

