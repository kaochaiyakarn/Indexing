ieee trans 
pami july 
eigenfaces vs fisherfaces recognition class speci linear projection peter belhumeur jo ao hespanha david kriegman center computational vision control dept electrical engineering yale university new haven ct phone fax belhumeur yale edu develop face recognition algorithm insensitive gross variation lighting direction facial expression 
pattern classi cation approach consider pixel image coordinate high dimensional space 
take advantage observation images particular face varying illumination xed pose lie linear subspace high dimensional image space face lambertian surface shadowing 
faces truly lambertian surfaces produce self shadowing images deviate linear subspace 
explicitly modeling deviation linearly project image subspace manner discounts regions face large deviation 
projection method fisher linear discriminant produces separated classes lowdimensional subspace severe variation lighting facial expressions 
eigenface technique method linearly projecting image space low dimensional subspace similar computational requirements 
extensive experimental results demonstrate proposed fisherface method error rates lower eigenface technique tests harvard yale face databases 
index terms appearance vision face recognition illumination invariance fisher linear discriminant 
person seen di erent lighting conditions appear dramatically di erent left image dominant light source nearly head right image dominant light source right 
years numerous algorithms proposed face recogni tion detailed surveys see 
progress ing faces small variations lighting facial expression pose reliable techniques recognition extreme variations proven elusive 
outline new approach face recognition insensitive large variations lighting facial expressions 
note lighting variability cludes intensity direction number light sources 
evident person facial expression seen viewpoint appear dramatically di erent light sources illuminate face di erent directions 
see 
approach face recognition exploits observations 
images lambertian surface taken xed viewpoint varying illumination lie linear subspace high dimensional image space 

regions shadowing specularities facial expressions observation exactly hold 
practice certain regions face may variability image image deviates signi cantly linear subspace consequently reliable recognition 
observations nding linear projection faces high dimensional image space signi cantly lower dimensional feature space insensitive variation lighting direction facial expression 
choose projection directions nearly orthogonal class scatter projecting away variations lighting facial expression maintaining discriminability 
method fisherfaces derivative fisher linear discriminant fld maximizes ratio class scatter class scatter 
eigenface method linearly projecting image space low dimensional feature space 
eigenface method uses principal components analysis pca dimensionality reduction yields projection directions maximize total scatter classes images faces 
choosing projection maximizes total scatter pca retains unwanted variations due lighting facial expression 
illustrated figures stated moses ullman variations images face due illumination viewing direction larger image variations due change face identity :10.1.1.51.3607
pca projections optimal reconstruction low dimensional basis may optimal discrimination standpoint 
point fisher linear discriminant classical technique pattern recognition rst developed robert fisher taxonomic classi ca tion 
depending features applied di erent ways computer vision face recognition 
cheng method fisher discriminator face recognition features obtained polar quantization shape 
baker nayar developed theory pattern re class linear discriminant 
contemporaneous cui swets weng applied fisher discriminator di erent termi nology call discriminating feature mdf method recognizing hand gestures :10.1.1.10.3247
implementation reported suggest method applied face recognition variable illumination 
sections follow compare methods face recognition variation lighting facial expression correlation variant linear subspace method suggested eigenface method fisherface method developed 
comparisons done subset harvard database images database created yale images 
tests databases fisherface method lower error rates methods 
claim relative performance algorithms larger databases 
point attempt deal variation pose 
appearance method extended handle limited pose variation multiple view representation pentland moghaddam starner view eigenspace nayar appearance manifolds 
approaches face recognition accommodate pose variation include 
furthermore assume face located aligned image numerous methods nding faces scenes :10.1.1.18.3330
methods problem simply stated set face images labeled person identity learning set unlabeled set face images group people test set identify person test images 
section examine pattern classi cation techniques solving face recognition problem comparing methods quite popular face recognition literature correlation eigenface methods alter native methods developed authors 
approach problem pattern classi cation paradigm considering pixel values sample image coor high dimensional space image space 
correlation simplest classi cation scheme nearest neighbor classi er image space 
scheme image test set recognized classi ed assigning label closest point learning set distances measured image space 
images normalized zero mean unit variance procedure equivalent image learning set best correlates test image 
normalization process result independent light source intensity ects video camera automatic gain control 
procedure subsequently referred correlation known disadvantages 
images learning set test set gathered varying lighting conditions corresponding points image space may tightly clustered 
order method reliably variations lighting need learning set densely sampled continuum possible lighting conditions 
second correlation computationally expensive 
recognition correlate image test face image learning set ort reduce computation time implementors algorithm described developed special purpose vlsi hardware 
third requires large amounts storage set contain numerous images person 
eigenfaces correlation methods computationally expensive require great amounts stor age natural pursue dimensionality reduction schemes 
technique commonly dimensionality reduction computer vision particularly face recognition principal components analysis pca 
pca techniques known karhunen loeve methods choose dimensionality reducing linear projection maxi scatter projected samples 
formally consider set sample images fx xng values dimensional image space assume image belongs classes fx 
consider linear transformation mapping original dimensional image space dimensional feature space new feature vectors yk ir de ned linear transformation ir matrix orthonormal columns 
total scatter matrix st de ned yk xk nx st xk xk number classes ir mean image samples applying linear transformation scatter transformed feature vectors fy st pca projection chosen maximize determinant scatter matrix projected samples arg max jw st wm mg set dimensional eigenvectors st corresponding largest eigenvalues 
eigenvectors dimension original images referred eigenfaces 
classi cation performed nearest neighbor classi er reduced feature space chosen number images training set eigenface method equivalent tothe correlation method previous section 
approach scatter maximized due class scatter useful classi cation class scatter classi cation purposes unwanted information 
recall comment moses ullman variation image due nation changes :10.1.1.51.3607
pca images faces varying illumination projection matrix contain principal components eigenfaces re tain projected feature space variation due lighting 
consequently points projected space clustered worse classes may smeared 
suggested discarding signi cant principal compo nents variation due lighting reduced 
hope rst principal components capture variation due lighting better clustering projected samples achieved ignoring 
rst principal components correspond solely variation lighting consequence information useful discrimination may 
linear subspaces correlation eigenface method expected su er variation lighting direction 
method exploits observation lambertian surface shadowing images particular face lie linear subspace 
consider point lambertian surface illuminated point light source nity 
ir column vector signifying product light source intensity unit vector light source direction 
surface viewed camera resulting image intensity point unit inward normal vector surface point anda isthe albedo surface 
shows image intensity point linear ir absence shadowing images lambertian surface viewpoint taken known linearly independent light source directions albedo surface normal recovered known method photometric stereo 
alternatively reconstruct image surface arbitrary lighting direction linear combination original images see 
classi cation fact great importance shows xed viewpoint images lambertian surface lie linear subspace high dimensional image space 
observation suggests simple classi cation algorithm recognize lambertian surfaces insensitive lighting conditions 
face images taken di erent lighting directions con struct basis linear subspace 
note basis vectors dimensionality training images thought basis images 
perform recognition simply compute distance linear subspace choose face corresponding shortest distance 
call recognition scheme linear subspace method 
point method variant photometric alignment method proposed special case elaborate recognition method described 
subsequently nayar murase exploited apparent linearity augment appearance manifold 
noise shadowing linear subspace algorithm achieve error free classi cation lighting conditions provided surfaces obey lambertian re model 
compelling reasons look 
due self shadowing specularities facial expressions regions images face variability agree linear subspace model 
images faces able learn regions recognition regions 
second recognize test image wemust measure distance linear subspace person 
improvement correlation scheme needs large number images represent variability ofeach class computationally expensive 
storage standpoint linear subspace algorithm keep images memory person 
fisherfaces previous algorithm takes advantage fact admittedly idealized con ditions variation class lies linear subspace image space 
classes convex linearly separable 
perform dimensionality reduction linear projection preserve linear separability 
strong argument linear methods dimensionality reduction face recog nition problem seeks insensitivity lighting conditions 
learning set labeled sense information build reliable method reducing dimensionality space 
argue feature feature class class 
comparison principal component analysis pca fisher linear discriminant fld class problem data class lies near linear subspace 
class speci linear methods dimensionality reduction simple classi ers reduced feature space gets better recognition rates linear subspace method eigenface method 
fisher linear discriminant fld example class speci method sense tries shape scatter order reliable classi cation 
method selects way ratio class scatter class scatter maximized 
class scatter matrix de ned sb cx fld class scatter matrix de ned sw cx pca ni xk xi xk xk mean image class xi ni number samples class xi 
sw nonsingular optimal projection chosen matrix orthonormal columns maximizes ratio determinant class scatter matrix projected samples determinant class scatter matrix projected samples arg max jw jw sw wm mg set generalized eigenvectors sb sw corre sponding largest generalized eigenvalues mg wi note nonzero generalized eigenvalues upper bound number classes 
see 
illustrate bene ts class speci linear projection constructed low dimen sional analogue classi cation problem samples class lie near linear subspace 
comparison pca fld class problem samples class randomly perturbed direction perpendicular linear subspace 
example andm 
samples class lie near line passing origin feature space 
pca fld project points 
comparing pro gure pca classes longer linearly separable projected space 
clear pca achieves larger total scatter fld achieves greater class scatter consequently classi cation easier 
face recognition problem confronted di culty class scatter matrix sw ir singular 
stems fact rank sw general number images learning set smaller image means possible choose matrix class scatter projected samples exactly zero 
order overcome complication singular sw propose alternative criterion 
method call fisherfaces avoids problem projecting image set lower dimensional space resulting class scatter matrix sw nonsingular 
achieved pca reduce dimension feature space applying standard fld de ned reduce dimension 
formally opt fld pca arg max jw st arg max jw pca jw pca sw note optimization performed matrices mal columns optimization performed matrices orthonormal columns 
computing thrown away smallest prin components 
certainly ways reducing class scatter preserving class scatter 
example second method currently investigating chooses maximize class scatter projected samples having rst reduced class scatter 
taken extreme maximize class scatter projected samples subject constraint class scatter zero 
arg max jw set matrices orthonormal columns contained kernel sw experimental results section discuss aforementioned face recognition tech niques di erent databases 
speci hypotheses wanted test relative performance considered algorithms standard databases inappropriate 
database harvard robotics laboratory lighting systematically varied 
secondly con structed database yale includes variation facial expression lighting 
variation lighting rst experiment designed test hypothesis variable illumination face recognition algorithms perform better exploit fact images lambertian surface lie linear subspace 
speci cally recognition error rates algorithms described section compared image database constructed hallinan harvard robotics laboratory 
image database subject held head steady illuminated dominant light source 
space light source directions parameterized spherical angles sampled increments 
see 
database images people 
extracted subsets quantify ects varying lighting 
sample images subset shown fig 

subset contains images longitudinal angles light source direction camera axis including lighting yale database available download cvc yale edu 
subset subset subset subset subset 
highlighted lines longitude latitude indicate light source directions subsets 
intersection longitudinal line right side illustration corresponding image database 
subset subset subset subset subset 
example images subset harvard database test algorithms 
direction coincident camera optical axis 
subset contains images greater longitudinal angles light source direction camera axis 
subset contains images greater longitudinal angles light source direction camera axis 
subset contains images greater longitudinal angles light source direction camera axis 
subset contains images greater longitudinal angles light source direction camera axis 
experiments classi cation performed nearest neighbor classi er 
training images individual projected feature space 
images cropped face contour head excluded 
eigenface correlation tests images normalized zero mean unit variance improved performance methods 
eigenface method results shown principal components 
suggested rst principal components primarily due lighting variation recognition rates improved eliminating error rates principal components thirteen 
performed experiments harvard database extrapolation tion 
extrapolation experiment method trained samples subset tested samples subsets 
images observed error rates reduced methods contour included subject front uniform background 
methods performed worse background varies 
test methods image subset image removed training set employed leaving strategy 
eigenface eigenface correlation linear subspace fisherface subset subset subset lighting direction subset extrapolating subset eigenface correlation eigenface linear subspace fisherface method reduced space error rate subset subset subset eigenface eigenface st correlation linear subspace fisherface 
extrapolation methods trained images near frontal illumination subset graph corresponding table show relative performance extreme light source conditions 
training set correlation equivalent eigenface method principal components 
shows result experiment 
interpolation experiment method trained subsets tested methods subsets 
shows result experiment 
experiments reveal number interesting points 
algorithms perform perfectly lighting nearly frontal 
subset subset subset lighting direction subset eigenface eigenface correlation fisherface linear subspace interpolating subsets method reduced space error rate subset subset subset eigenface eigenface st correlation linear subspace fisherface 
interpolation methods trained images near frontal extreme lighting subsets graph corresponding table show relative performance intermediate lighting conditions 
lighting moved axis signi cant performance di erence class speci methods eigenface method 

noted eigenface method equivalent correlation number eigenfaces equals size training set perfor mance increases dimension eigenspace eigenface method better correlation 
empirically demonstrated 

eigenface method removing rst principal components results better performance variable lighting conditions 

linear subspace method error rates competitive fisherface method requires storing times information takes times long 

fisherface method error rates lower eigenface method re quired computation time 
variation facial expression eye wear lighting 
yale database contains frontal face images covering sixteen individuals taken di erent conditions normal image ambient lighting glasses images taken di erent point light sources di erent facial expressions 
second database constructed yale center computational vision control designed tests determine methods compared di erent range conditions 
sixteen subjects images acquired session front simple background 
subjects included females males facial hair wore glasses 
shows images subject 
rst image taken number principal components eigenface eigenface components fisherface 
demonstrated yale database variation performance eigenface method depends number principal components retained 
dropping rst appears improve performance 
ambient lighting neutral facial expression person wore glasses 
second image glasses removed 
person normally wore glasses random pair borrowed 
images acquired illuminating face neutral expression position 
images acquired ambient lighting di erent expressions happy sad surprised 
eigenface correlation tests images normalized zero mean unit variance improved performance methods 
images manually centered cropped di erent scales larger images included full face part background closely cropped ones included internal structures brow eyes nose mouth chin extend occluding contour 
test error rates determined leaving strategy classify image person image removed data set dimen reduction matrix computed 
images database excluding test image projected reduced space classi cation 
recognition performed nearest neighbor classi er 
note test person learning set represented projection images test person represented 
general performance eigenface method varies number principal components 
comparing linear subspace fisherface methods eigenface method rst performed experiment determine number principal components yielding lowest error rate 
shows plot error rate vs number principal components closely cropped set initial principal components retained dropped 
relative performance algorithms self evident fig 

fisherface method error rates better half method 
fisherface method chooses set projections performs range lighting variation facial expression variation presence glasses 
note linear subspace method comparatively worse experiment lighting experiments previous section 
variation facial expression images longer lie linear subspace 
fisherface method tends discount portions image signi cant recognizing individual resulting projections tend mask regions face highly variable 
example area mouth discounted varies quite bit di erent facial expressions 
hand nose cheeks brow stable class variation signi cant recognition 
conjecture fisherface methods tend reduce class scatter classes produce projection directions recognizing faces training set 
eigenface correlation linear subspace recognition algorithm eigenface close crop full face fisherface leaving yale database method reduced space close crop error rate full face error rate eigenface eigenface st correlation linear subspace fisherface 
graph corresponding table show relative performance algorithms applied yale database contains variation facial expression lighting 
algorithms performed better images full face 
note dramatic improvement fisherface method error rate reduced 
method trained entire face pixels corresponding occluding contour face chosen features discriminating individuals 
shape face powerful feature face identi cation 
practical note expected recognition rates lower full face images background hair styles varied may worse closely cropped images 
glasses recognition 
left image image yale database person wearing glasses 
right image fisherface determining person wearing glasses 
glasses recognition method reduced error space rate eigenface fisherface table 
comparative recognition error rates glasses glasses recognition yale database 
class speci projection methods learning set divided classes di erent manners 
example selecting classes individual people set images divided classes wearing glasses wearing glasses 
classes images projected line fisherface methods 
pca choice eigenfaces independent class de nition 
experiment data set contained images superset yale database half glasses 
recognition rates obtained cross validation classify images person images person removed database projection matrix computed 
table presents error rates di erent methods 
pca recognition rates near chance cases classi ed images glasses class 
hand fisherface methods viewed deriving template suited nding glasses ignoring characteristics face 
conjecture supported observing fisherface fig 
corresponding projection matrix naturally expected techniques applied identifying facial expressions set training images divided classes facial expression 
experiments suggest number 
methods perform image test set similar image training set 

fisherface method appears best extrapolating interpolating variation lighting linear subspace method close second 

removing largest principal components improve performance eigenface method presence lighting variation achieve error rates low methods described 

limit principal components eigenface method formance approaches correlation 
similarly rst principal components removed performance improves dimensionality ofthe feature space increased 
note performance level principal components 
kirby similar point returns eigenfaces represent face images 

fisherface method appears best simultaneously handling variation lighting expression 
expected linear subspace method su ers confronted variation facial expression 
extensive experimentation interesting questions remain fisherface method extend large databases 
variation lighting conditions accommodated individuals observed lighting condition 
additionally current face detection methods break extreme lighting conditions subsets fig 
new detection methods needed support algorithms 
shadowing domi performance degrades recognition methods techniques model mask shadowed regions may needed 
currently investi gating models representing set images object possible illumination conditions shown set pixel images object shape arbitrary re function seen possible illumination conditions forms convex cone ir 
furthermore relevant appears convex illumination cone lies close low dimensional linear subspace 
acknowledgments belhumeur supported aro daah 
hespanha supported nsf ecs afosr daah 
kriegman supported nsf nyi iri onr 
authors peter hallinan providing harvard database alan yuille david mumford useful discussions 
list figures person seen di erent lighting conditions appear dra matically di erent left image dominant light source nearly head right image dominant light source right 
comparison principal component analysis pca fisher linear discriminant fld class problem data class lies near linear subspace 
highlighted lines longitude latitude indicate light source directions subsets 
intersection longitudinal line right side illustration corresponding 
example images subset harvard database test algorithms 
extrapolation methods trained images near frontal illumination subset graph corresponding table show relative performance extreme light source conditions 
interpolation methods trained images near frontal extreme lighting subsets graph corre sponding table show relative performance intermediate lighting conditions 
yale database contains frontal face images covering sixteen individ taken di erent conditions normal image ambient lighting glasses images taken di erent point light sources di erent facial expressions 
demonstrated yale database variation performance eigenface method depends number principal components retained 
dropping rst appears improve performance 
graph corresponding table show relative performance algorithms applied yale database contains variation facial expression lighting 
left image image yale database person wearing glasses 
right image fisherface determining person wearing glasses 
list tables comparative recognition error rates glasses glasses recognition yale database 
footnotes 
yale database available download cvc yale edu 

observed error rates reduced methods contour included subject front uniform background 
methods performed worse background varies 

test methods image subset image removed training set employed leaving strategy 
contact information peter belhumeur center computational vision control dept cal engineering yale university new haven ct phone fax belhumeur yale edu 
jo ao hespanha center computational vision control dept electrical engineering yale university new haven ct phone fax hespanha eng yale edu 
david kriegman center computational vision control dept cal engineering yale university new haven ct phone fax kriegman yale edu 
chellappa wilson human machine recognition faces survey proceedings ieee vol 
pp 

samal iyengar automatic recognition analysis human faces facial expressions survey pattern recognition vol 
pp 

amnon shashua geometry photometry visual recognition phd thesis mit 
duda hart pattern classi cation scene analysis wiley new york 
fisher multiple measures taxonomic problems ann 
vol 
pp 

kirby low dimensional procedure characterization human faces optical soc 
america vol 
pp 

turk pentland eigenfaces recognition cognitive neuroscience vol 

turk pentland face recognition eigenfaces proc 
ieee conf 
comp 
vision patt 
recog pp 

moses ullman face recognition problem compensating changes illumination direction european conf :10.1.1.51.3607
computer vision pp 

cheng liu yang zhuang gu human face recognition method statistical model small sample size spie proc intelligent robots computer vision algorithms techn pp 

baker nayar pattern rejection proc 
ieee conf 
comp 
vision patt 
recog pp 

belhumeur hespanha kriegman eigenfaces vs fisherfaces recognition class speci linear projection european conf :10.1.1.10.3247
computer vision pp 

cui swets weng learning hand sign recognition int 
conf 
computer vision pp 

peter hallinan low dimensional representation human faces arbitrary light ing conditions proc 
ieee conf 
comp 
vision patt 
recog pp 

peter hallinan deformable model face recognition arbitrary lighting conditions phd thesis harvard university 
pentland moghaddam starner view modular eigenspaces face recognition proc 
ieee conf 
computer vision pattern recognition pp 

murase nayar visual learning recognition objects int 
computer vision vol 

beymer face recognition varying pose proc 
ieee conf 
computer vision pattern recognition pp 

gee cipolla determining gaze faces images image vision computing vol 
pp 

lanitis taylor cootes uni ed approach coding inter face images int 
conf 
computer vision pp 

chen wu yachida face detection fuzzy pattern matching int 
conf 
computer vision pp 

craw tock bennet finding face features proc :10.1.1.18.3330
european conf 
computer vision pp 

leung burl perona finding faces cluttered scenes labeled random graph matching int 
conf 
computer vision pp 

lee kimura tsuji automatic recognition human facial expressions int 
conf 
computer vision pp 

moghaddam pentland probabilistic visual learning object detection int 
conf 
computer vision pp 

brunelli poggio face recognition features vs templates ieee trans 
pattern anal 
mach 
intelligence vol 
pp 

gilbert yang real time face recognition system custom vlsi hardware proceedings ieee workshop computer architectures machine perception pp 

horn computer vision mit press cambridge mass 
silver determining shape re multiple images phd thesis mit cambridge ma 
analysing images curved surfaces arti cial intelligence vol 
pp 

nayar murase dimensionality illumination appearance matching ieee conf 
robotics automation 
belhumeur kriegman set images object possible lighting conditions ieee proc 
conf 
computer vision pattern recognition 
