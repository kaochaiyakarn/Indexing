appears proceedings usenix annual technical conference june 
handling churn dht sean rhea dennis geels timothy roscoe john kubiatowicz university california berkeley intel research berkeley geels cs berkeley edu intel research net addresses problem churn continuous process node arrival departure distributed hash tables dhts 
argue dhts perform lookups quickly consistently churn rates high observed deployed systems kazaa 
show experiments emulated network current dht implementations handle churn rates 
identify explore factors affecting dht performance churn reactive versus periodic failure recovery message timeout calculation proximity neighbor selection 
context mature dht implementation called bamboo modelnet network emulator models network queuing cross traffic packet loss 
factors typically missing earlier dht studies show careful attention bamboo design allows function effectively churn rates higher observed file sharing applications lower maintenance bandwidth dht implementations 
popularity widely deployed file sharing services motivated considerable research peer topeer systems 
line research focused design better peer peer algorithms especially area structured peer peer overlay networks distributed hash tables simply call dhts :10.1.1.140.3129:10.1.1.16.4785:10.1.1.105.3673
systems map large identifier space set nodes system deterministic distributed fashion function alternately call routing lookup 
dhts generally perform lookups log overlay hops network nodes node maintains log neighbor links research explored tradeoffs storing state 
second line research systems focused observing deployed networks :10.1.1.160.7346:10.1.1.13.1523:10.1.1.11.4677
significant result research networks characterized high degree churn 
metric churn node session time time node joins network time leaves 
median session times observed deployed networks range long hour short minutes 
explore performance dhts dynamic environments 
dhts may better able locate rare files existing unstructured peer peer networks 
hard imagine proposed uses dhts show similar churn rates file sharing networks application level multicast low budget radio stream example 
spite promise show short session times cause variety negative effects mature dht implementations tested 
systems exhibit dramatic latency growth subjected increasing churn implementation network eventually partitions causing subsequent lookups return inconsistent results 
remainder dedicated determining dht built continues perform churn rates increase 
demonstrate dhts fact handle high churn rates identify explore factors affect behavior dhts churn 
important factors identify reactive versus periodic recovery failures calculation message timeouts lookups choice nearby distant neighbors reactive recovery mean strategy dht node tries find replacement neighbor immediately noticing existing neighbor failed 
show bandwidth limited conditions reactive recovery lead positive feedback cycle overloads network causing lookups high latency return inconsistent results 
contrast dht node may recover neighbor failure fixed periodic rate 
show strategy improves performance churn allowing system avoid positive feedback cycles 
manner dht chooses timeout values lookups greatly affect performance churn 
node performing lookup sends message appears proceedings usenix annual technical conference june 
node left network eventually timeout request try neighbor 
demonstrate timeouts significant component lookup latency churn explore methods computing timeout values including virtual coordinate schemes chord dht 
consider proximity neighbor selection pns dht node choice neighbors tries select nearby network latency 
compare algorithms discovering nearby neighbors including algorithms similar chord pastry tapestry dhts show tradeoffs offer latency reduction added bandwidth 
augmented bamboo dht configured design choices described :10.1.1.10.5979
examine design decision independently 
examine performance configuration running large cluster emulated wide area network 
methodology particularly important regard choice reactive versus periodic recovery described 
existing studies churn dhts simulations emulated network model effects network queuing cross traffic message loss 
experience effects primary factors contributing dhts inability handle churn 
measurements conducted isolated network sources queuing cross traffic loss dhts presence heavy background traffic expect network realities exacerbate ability dhts handle lower levels churn 
course study limitations 
building testing complete dht implementation emulated network major effort 
consequently limited studying single dht single network topology relatively simple churn model 
furthermore studied effects implementation decisions affect performance dht churn including alternate routing table neighbors kademlia tapestry iterative versus recursive routing 
believe effects factors studied dramatic important early study effort build dht successfully handles churn 
rest structured follows section review dhts perform routing lookup particular pastry routing algorithm bamboo uses 
section review existing studies churn deployed file sharing networks describe way model churn emulated network quantify performance mature dht 


neighbors pastry bamboo 
node neighbors divided leaf set shown dashed arrows routing table shown solid arrows 
implementations churn 
section study factors listed isolation describe bamboo uses techniques 
section survey related section discuss important 
conclude section 

dht routing section brief review dht routing pastry example 
geometry routing algorithm bamboo identical pastry difference main contribution lies bamboo maintains geometry nodes join leave network network conditions vary 
dhts structured graphs term geometry mean pattern neighbor links overlay network independent routing algorithms state management algorithms :10.1.1.3.8344
node pastry assigned numeric identifier derived sha hash ip address port node receives packets sha hash public key 
distributed identifier space 
pastry node maintains sets neighbors leaf set routing table see 
node leaf set set nodes immediately preceding circular identifier space 
denote set notation li denote members node 
contrast routing table set nodes identifiers share successively longer prefixes source node identifier 
treating identifier sequence digits base denoting routing table entry row column rl node chooses neighbors entry rl node identifier matches exactly digits appears proceedings usenix annual technical conference june 
lk hop li li minimal rl null hop rl hop li li minimal bamboo routing algorithm 
code shown chooses routing hop message destination matches identifier local node digits 
th digit experiments bamboo uses binary digits configured base 
basic operation dht consistently map identifiers nodes point system function call routing lookup 
pastry achieves consistent lookups directing identifier node numerically closest identifier 
algorithmically routing proceeds shown 
route message key node checks lies leaf set forwards numerically closest member set modulo 
member local node routing terminates 
fall leaf set node computes length longest matching prefix identifier 
denote ith digit rl empty message forwarded node 
conditions true message forwarded member node leaf set numerically closest destination node reached sends message back originating node identifier network address lookup complete 
note node choose different neighbors entry routing table 
example node identifier begins needs neighbor identifier begins nodes roughly half total network 
situations node choose possible candidates metric 
proximity neighbor selection term indicate nodes dht network latency metric choose neighbor candidates 
design pastry bamboo perform lookups log hops leaf set allows forward progress exchange potentially longer paths case routing table incomplete 
leaf set adds great deal static resilience geometry gummadi show leaf set nodes random links broken connected paths node pairs :10.1.1.3.8344



recursive lookup 
find node closest identifier node identifier starts sends lookup message neighbor digit 
node forwards query neighbor digits node forwarded neighbor digits 




iterative lookup 
iterative lookup involves nodes recursive forwarding message intermediate node responds source address hop 
network nodes 
resilience important handling failures general churn particular reason chose pastry geometry bamboo 
pure ring geometry chord extending account proximity neighbor selection described :10.1.1.3.8344
manner described routing far commonly called recursive routing 
contrast lookups may performed iteratively 
shown iterative lookup involves nodes recursive entire process controlled source lookup 
asking neighbor forward lookup network behalf source asks neighbor network address hop 
source asks node question repeating process progress point lookup complete 
session time appears proceedings usenix annual technical conference june 
lifetime join leave join leave time metrics churn 
respect routing lookup functionality dht session times nodes relevant lifetimes 
problem churn large scale dht application deployments date hard derive requirements churn resilience 
filesharing networks provide useful starting point 
systems provide simple indexing service locating files peer nodes currently connected network function naturally mapped dht mechanism 
example overnet filesharing system uses kademlia dht store index 
dht applications file storage cfs require greater client availability may show similar churn rates file sharing networks system multicast rendezvous service instant messaging :10.1.1.3.8344
believe dhts handle churn rates observed today file sharing networks 
section survey existing studies churn deployed file sharing networks describe way model churn emulated network quantify performance mature dht implementations churn 
studies existing file sharing systems mainly metrics churn see 
node session time elapsed time joining network subsequently leaving 
contrast node lifetime time entering network time leaving network permanently 
sum node session times divided lifetime called availability 
representative study observed median session times order tens minutes median lifetimes order days median availability :10.1.1.13.1523
respect lookup functionality dht argue session time important metric 
temporary loss routing neighbor weakens correctness performance guarantees dht unavailable neighbors reduce node effective connectivity forcing choose suboptimal routes increasing destructive potential failures 
nodes unavailable long periods remembering neighbors failed little value performing lookups 
remembering neighbors useful applications storage little value lookup operations :10.1.1.13.9085
author systems observed session time saroiu gnutella napster min :10.1.1.160.7346
chu gnutella napster min :10.1.1.11.4677
sen fasttrack min :10.1.1.136.3479
bhagwan overnet min :10.1.1.13.1523
gummadi kazaa min 
table observed session times various peer peer systems 
median session time ranges hour minute 
empirical studies surveyed published studies deployed file sharing networks :10.1.1.10.5979
table shows summary observed session times 
sight values surprising may due methodological problems study question malfunctioning system observation 
easy image user joining network downloading single file failing find leaving making session times minutes plausible 
conservative dht robust median session times hour little minute 
experimental methodology platform measuring dht performance churn cluster ibm pcs dual ghz pentium iii processors gb ram connected gigabit ethernet running debian gnu linux freebsd 
modelnet impose wide area delay bandwidth restrictions inet topology generator create node widearea level network client nodes connected distinct stubs mbps links :10.1.1.13.1523
increase scale experiments capacity modelnet running client nodes client node runs dht instances total dht nodes 
control software uses set wrappers communicate locally dht instance send requests record responses 
running dht instances cluster nodes cpu produces cpu loads highest churn rates 
ideally measure larger networks node systems demonstrate problems surely affect larger ones 
experiment bring network nodes seconds randomly assigned gateway node distribute load bootstrapping newcomers 
churn nodes system performance levels phase normally lasts minutes take hour 
node deaths timed poisson process uncorrelated bursty 
new node started time killed appears proceedings usenix annual technical conference june 
maintaining total network size 
model churn similar described liben nowell 
poisson process event rate corresponds median inter event period ln 
event select node die uniformly random node session time expected span events network size 
churn rate corresponds median node session time ln 
example node network median session times hour see node arrive leave seconds 
experiments churn rates ranging second minute equal median session times minutes hours 
live node continually performs lookups identifiers chosen uniformly random timed poisson process rate second aggregate system load lookups second 
lookup simultaneously performed nodes report completes consistent key 
majority results key nodes majority said see consistent result considered inconsistent 
majority nodes said see inconsistent results 
metric consistency strict required dht applications 
mit chord bamboo implementation show consistency minute median session times unreasonable :10.1.1.10.5979
ways lookups fail tests 
perform retries lookup may fail complete node middle lookup path leaves network forwarding lookup request node 
observed behavior primarily freepastry described 
second lookup may return inconsistent results 
failures occur node aware correct node forward lookup erroneously believes correct node left network congestion poorly chosen timeouts 
dht implementations tested show inconsistencies churn carefully chosen timeouts judicious bandwidth usage minimize 
existing dhts section report results testing mature dht implementations churn 
intent place definitive bound performance implementation 
motivate demonstrating handling churn dhts important non trivial problem 
discussed experiments extensively authors percent lookups min consistent completed min time minutes freepastry churn 
percentage successful lookups node freepastry network churn 
session times minute churn period indicated arrows churn period separated minutes churn 
churn rate doubles successive period 
systems possible alternative configurations improved performance 
systems seen subsequent development newer versions may show improved resilience churn 
freepastry tested freepastry rice university implementation pastry 
shows effect churn network freepastry nodes ran default node leaf sets logarithm base 
enforce proximity new node gateway suggested best freepastry performance decision effects proximity node neighbors efficiency routing 
clear successful lookups consistent freepastry fails complete majority lookup requests heavy churn 
explanation failure nodes wait long lookup requests time frequently leave network requests queues 
behavior probably exacerbated freepastry java rmi tcp message transport way freepastry nodes handle loss neighbors 
evidence support ideas section 
final comment graph 
freepastry generally recovers churn periods correctly completing lookups 
difficulty real systems quiet period network continual state churn 
mit chord tested mit chord implementation cvs snapshot default node successor lists location cache disabled option cache causes poor performance churn 
mean latency appears proceedings usenix annual technical conference june 
chord bamboo pns bamboo pns median session time min chord churn 
shown mean latency lookups node mit chord network increasing levels churn 
churn increases left 
contrast freepastry lookups chord network complete return consistent results 
chord shortcoming churn lookup latency shown shows result running chord workload shown averaged lookup latency churn period 
shown comparison lines representing bamboo performance test proximity neighbor selection pns 
churn rates bamboo slightly bytes second node chord slightly 
discuss detail differences enable bamboo outperform chord sections difference latency bamboo chord due routing styles 
bamboo performs lookups recursively chord routes iteratively 
chord easily changed route recursively fact newer versions chord support recursive routing pns 
note chord latency grows quickly increasing churn bamboo section show evidence support belief growth due chord method choosing timeouts lookup messages independent lookup style employed 
summary summarize section note observed effects churn existing dht implementations 
dht may fail complete lookup requests altogether may complete return inconsistent results lookup launched different source nodes 
hand dht may continue return consistent results churn rates increase may suffer dramatic increase lookup latency process 
handling churn having briefly described way dhts perform lookups having evidence indicating ability hindered churn turn heart study factors contributing difficulty comparison solutions overcome 
turn discuss reactive versus periodic recovery neighbor failure calculation timeout values lookup messages techniques achieve proximity neighbor selection 
remainder focuses bamboo dht implemented alternative design choice studied 
working entirely single implementation allows minimize differences experiments comparing design choice 
reactive vs periodic recovery early implementations bamboo suffered performance degradation churn similar freepastry 
mit chord performance degrade way 
significant difference behavior design choice handle detected node failures 
call alternative approaches reactive periodic recovery 
reactive recovery reactive recovery node reacts loss existing leaf set neighbors appearance new node added leaf set sending copy new leaf set node 
save bandwidth node send differences message total number messages leaf set nodes 
algorithm converges quickly freepastry early versions bamboo 
uses bandwidth efficient complex variant reactive recovery :10.1.1.11.4677
periodic recovery contrast periodic recovery node periodically shares leaf set members set responds kind leaf set 
process takes place independently node detecting changes leaf set 
simple optimization node picks random member leaf set share state period 
change saves bandwidth converges log phases size leaf set 
details :10.1.1.10.5979
algorithm currently bamboo periodic nature algorithm shared chord method keeping successor list correct 
bandwidth kb node appears proceedings usenix annual technical conference june 
reactive periodic min min time minutes th percentile latency reactive periodic min min time minutes reactive versus periodic recovery 
churn reactive recovery efficient messages sent response actual changes 
reasonable churn rates periodic recovery uses bandwidth lower contention network leads lower latencies 
positive feedback cycles reactive recovery runs risk creating positive feedback cycle follows 
consider node access link network sufficiently congested timeouts cause believe neighbors failed 
node recovering reactively recovery operations node add packets congested network link 
added congestion increase likelihood node mistakenly conclude neighbors failed 
process continues node eventually cause congestion collapse access link 
observations cycles early bamboo examination chord code originally led propose periodic recovery handling churn 
decoupling rate recovery discovery failures periodic recovery prevents feedback cycle described 
lengthening recovery period observation message timeouts introduce negative feedback cycle improving resilience 
way mitigate instability associated reactive recovery conservative detecting node failure 
effective approach conclude failure consecutive message timeouts neighbor 
timeouts backed multiplicatively maximum seconds node conclude failure due congestion 
drawback technique neighbors failed remain node routing table time 
lookups route neighbors delayed resulting long lookup latencies 
remedy problem node stops routing neighbor seeing consecutive message timeouts neighbor 
changes reactive recovery feasible small leaf sets moderate churn 
scalability experiments show little difference correctness periodic reactive recovery 
see consider node joins network node existing network identifier closely matches pastry retrieves initial leaf set contacting adds leaf set immediately confirming ip address port probe message 
arrival propagates network node may route messages go just forward messages likewise fail leaf set routing messages time nearby nodes generally agree best choice 
periodic reactive recovery achieve roughly identical correctness large difference bandwidth consumed different churn rates leaf set sizes 
commonly accepted rule thumb provide sufficient resilience massive node failure size node leaf set logarithmic system size 
low churn reactive recovery efficient messages sent response actual changes periodic recovery wasteful 
churn increases reactive recovery expensive behavior exacerbated increasing leaf set size 
node see failures leaf set larger set nodes notify resulting changes leaf set larger 
contrast periodic recovery aggregates changes period single message 
shows contrast bamboo leaf sets nodes default leaf set size freepastry 
ran bamboo configurations minute churn periods minute median session times separated minutes churn 
note periods test appears proceedings usenix annual technical conference june 
churn reactive recovery uses half bandwidth periodic recovery 
hand churn bandwidth jumps dramatically 
discussed bamboo suffer positive feedback cycles account increased bandwidth usage 
extra messages sent reactive recovery compete lookup messages available bandwidth churn increases see corresponding increase lookup latency 
shown number hops lookup virtually identical schemes implying growth bandwidth due contention available bandwidth 
goal handle median session times minutes low lookup latency explore reactive recovery 
remainder bamboo results obtained periodic recovery 
timeout calculation section discuss role timeout calculation lookup messages plays handling churn 
understand relative importance timeouts dht opposed traditional networked system consider traditional client server system networked file system nfs 
nfs server fail generally options recovery alternative servers fail 
response nfs request received expected time client usually try exponentially increasing timeout value 
peer peer system churn contrast requests frequently sent node left system possibly forever 
time dht routing flexibility static resilience alternate paths available complete lookup 
simply backing request period poor response request timeout better retry request different neighbor 
node ensure timeout request judiciously selected routing alternate neighbor 
short node original sent may receive may processing response may queued network 
injecting additional requests may result additional bandwidth beneficial result example case local node access link congested 
conversely timeout long requesting node may waste time waiting response node left network 
request rate fixed low value long waits cause unbounded queue growth request node avoided shorter timeouts 
reasons nodes accurately choose timeouts late response indicative node failure network congestion processor load 
techniques discuss study alternative timeout calculation strategies 
fix timeouts conservative value seconds control experiment 
second calculate tcp style timeouts direct measurement past response times 
explore indirect measurements virtual coordinate algorithm calculate timeouts 
tcp style timeouts dht routes recursively rarely communicates nodes direct neighbors overlay network 
number neighbors logarithmic size network node periodically probes neighbor availability node easily maintain past history neighbor response times calculating timeouts 
bamboo implemented strategy style early tcp node maintains exponentially weighted mean variance response time neighbor 
specifically estimate round trip timeout rto neighbor calculated rto avg var avg observed average round trip time var observed mean variance time 
timeouts virtual coordinates contrast recursive routing iterative routing node potentially timeout node network 
scenarios iterative routing attractive properties 
example source lookup request controls entire process iterative routing easy explore different lookup paths parallel 
constant increase bandwidth technique prevents single timeout delaying lookup 
virtual coordinates provide approach computing timeouts previously measuring response time node system 
scheme distributed machine learning algorithm employed assign node coordinates virtual metric space distance nodes space proportional latency underlying network 
bamboo includes implementation vivaldi coordinate system employed chord 
vivaldi keeps exponentially weighted average error past round trip times calculated coordinates computes rto rto mean latency appears proceedings usenix annual technical conference june 
fixed vivaldi tcp style median session time min tcp style versus virtual coordinate timeouts bamboo 
timeouts chosen vivaldi competitive tcp style timeouts moderate churn rates 
predicted round trip time average error 
constant term milliseconds added avoid unnecessary retransmissions destination local host 
results tcp style timeouts assume recursive routing algorithm virtual coordinate system necessary routing iteratively 
ideally compare approaches measuring intended environment prevent isolating effect timeouts differences caused routing styles 
study schemes recursive routing 
timeouts calculated virtual coordinates provide performance comparable calculated tcp style recursive routing expect virtual coordinate scheme prohibitively expensive iterative routing 
issues may remain iterative routing churn congestion control see section result useful 
shows direct comparison timeout calculation methods increasing levels churn 
cases experiment bamboo configurations differed choice timeout calculation method 
proximity neighbor selection latency measurements pns separate direct probing virtual coordinates 
light levels churn fixing timeouts seconds causes lookup timeouts pull mean latency twice configurations confirming intuition importance timeout values dht routing churn 
comparing note high churn timeout calculation greater effect lookup latency pns 
virtual coordinate timeouts achieve similar mean latency tcp style timeouts low churn 
fur thermore perform factor measurements median churn rate drops minutes 
past point performance quickly diverges virtual coordinates continue provide mean lookup latencies seconds median session times 
note similarity shape compared performance chord bamboo suggesting growth lookup latency chord high churn rates due timeout calculation virtual coordinates 
proximity neighbor selection studied aspects dht design proximity neighbor selection pns process choosing potential neighbors routing table entry network latency choosing node 
research motivated 
stretch lookup operation defined latency lookup divided round trip time lookup source node discovered lookup underlying ip network 
dabek argument experimental data suggest pns allows dht nodes achieve median stretch independent size network despite log hops 
proved pns provide constant stretch locating replicas restricted network model :10.1.1.160.7346:10.1.1.38.1850
study aware compare methods achieving pns churn 
take moment discuss common philosophy techniques shared algorithms study 
commonalities earliest insights dht design separation correctness performance distinction neighbors leaf set neighbors routing table :10.1.1.105.3673
long leaf sets system correct lookups return correct results may take hops 
leaf set maintenance priority routing table maintenance dhts 
manner note long entry routing table appropriate neighbor correct identifier prefix lookups complete log hops take longer neighbors chosen proximity 
say lookups efficient may low stretch 
argument reason desirable fill routing table entry quickly optimal neighbor finding nearby neighbor lower priority 
argument treating proximity appears proceedings usenix annual technical conference june 
lower priority presence churn 
expect set neighbors change time part churn process little sense hard find absolute closest neighbor time expend considerable bandwidth find see leave network shortly afterward 
general approach run algorithms described periodically 
case churn high technique allows routing table network changes 
churn low rerunning algorithms latency measurement errors caused transient network conditions previous runs 
general approach finding nearby neighbors takes form 
algorithms find nodes may near local node 
measure latency nodes 
existing neighbor routing table entry measured node fill closer existing routing table entry replace entry leave routing table unchanged 
bandwidth cost multiple measurements high storage cost remember past measurements low 
compromise perform single latency measurement discovered node particular run algorithm keep exponentially weighted average past measurements node average value deciding relative closeness nodes 
average occupies bytes memory measured node expect approach scale comfortably large systems 
techniques techniques proximity neighbor selection study global sampling sampling neighbors neighbors sampling nodes neighbors neighbors 
describe techniques turn 
global sampling global sampling called global tuning earlier lookup functionality dht find new neighbors 
routing table entry requires neighbor prefix perform lookup random identifier prefix node returned lookup desired prefix 
example case note lookup identifier may return node identifier starts node largest identifier ring numerically closer node smallest identifier 
samples nodes prefix eventually probed 
motivation technique comes gummadi showed sampling nodes routing table entry provides optimal proximity :10.1.1.3.8344
sampling neighbors neighbors 
joins gateway initial level neighbors assume dashed line 
contacts level neighbor asks level neighbors 
learn manner 
may path ideal neighbors cases global sampling take unreasonably long find closest possible neighbor 
example consider nodes separated core internet high latency access link shown 
relatively high latency seen nodes nodes network attractive neighbors different digits network logarithm base drastically reduce cost hop routes learning 
time nodes find global sampling proportional size total network may find sessions 
drawback global sampling leads consider techniques 
neighbors neighbors technique consider sampling neighbors neighbors process called routing table maintenance pastry local tuning earlier :10.1.1.28.5987
technique contact existing routing table neighbor level routing table ask level neighbors 
nodes share prefix digits contacted neighbor appropriate routing table 
global sampling having discovered new nodes probe latency closer existing neighbors 
motivation sampling neighbors neighbors illustrated relies expectation proximity network roughly transitive 
node discovers nearby node node neighbors probably nearby 
way expect node walk graph neighbor links set nodes near 
see possible shortcoming sampling neighbors neighbors consider 
isolated nodes discover nodes network prefer neighbors isolation unattractive routing lookups originate appears proceedings usenix annual technical conference june 
ms sampling neighbors inverse neighbors 
nodes isolated remainder network long latency initially unaware 
situation possible example european nodes join network primarily north american nodes 
unattractive neighbors nodes find 
neighbor find asking inverse neighbors 
rare case result lookups 
neighbor links dhts rarely symmetric path graph neighbor links lead isolated node despite relative proximity 
neighbors inverse neighbors argument presents obvious alternative approach 
sampling neighbors neighbors sample nodes neighbors local node 
technique originally proposed tapestry nearest neighbor algorithm call sampling neighbors inverse neighbors 
motivate technique consider 
remote nodes neighbors nodes existing neighbors nearby choose neighbors outside isolated domain 
reason find set neighbors inverse neighbors 
normally dht node record set nodes neighbor 
actively managing list fact requires additional probing bandwidth 
currently bamboo implementation actively manage set easily approximated node keeping track set nodes sent liveness probes minute 
plan implement optimization 
recursive sampling consider final time assume single bit digits remote nodes different digits respectively 
node identifier starts neighbor identifier begins level neighbor 
likewise node identifier starts neighbor starts 
set neighbors inverse neighbor sets isolated neighbors find small 
isolated nodes function nearest neighbors highest nonempty rt level longest matching prefix forall get inverse rt neighbors closest tapestry nearest neighbor algorithm 
nearby level neighbors find neighbors inverse neighbors 
remedy final problem perform sampling nodes manner similar tapestry nearest neighbor algorithm pastry optimized join algorithm 
pseudo code technique shown 
starting highest level routing table node contacts neighbors level retrieves neighbors inverse neighbors 
latency newly discovered nodes measured closest discarded 
node decrements retrieves level neighbors non discarded node 
process repeated 
way discovered neighbor considered candidate routing table 
keep cost algorithm low limit having outstanding messages neighbor requests latency probes time 
note process starts sampling routing table set nodes recurses constrained prefix matching structure table 
suffer small rendezvous set problem discussed 
fact certain network assumptions proved process finds node nearest neighbor underlying network 
results order compare techniques described important consider effective finding nearby neighbors bandwidth cost 
example global sampling high rate relative churn rate achieve perfect proximity cost large number lookups latency probes 
comparison ran algorithm combinations various periods plotted mean lookup latency churn versus bandwidth 
results median session times minutes shown split graphs clarity 
shows interesting results 
note little bit global sampling necessary produce drastic improvement latency versus mean latency ms appears proceedings usenix annual technical conference june 
pns nn nin global nn recursive nin recursive bandwidth bytes node mean latency ms global rand nn rand nin rand nn recur rand nin recur bandwidth bytes node comparison pns techniques 
pns control case proximity ignored 
global sampling uses lookup function sample nodes dht 
nn sampling neighbor neighbors nin sampling inverse neighbors 
recursive versions nn nin mimic nearest neighbor algorithms pastry tapestry respectively 
note scales different figures 
configuration pns 
virtually increase bandwidth global sampling drops mean latency ms ms surprise find simple sampling neighbor neighbors inverse neighbors terribly effective 
argued result may part due constraints routing table expect effect dramatic 
hand recursive versions algorithms effective global sampling 
result agrees contention gummadi small amount global sampling necessary achieve near optimal pns 
shows combinations various algorithms 
global sampling plus sampling neighbors neighbors combination earlier offering small decrease latency additional bandwidth 
combinations offer similar results 
point prudent say effective technique combine global sampling technique 
may differences techniques revealed analysis see clear reason prefer 
related noted start dhts subject research years studies resilience real implementations scale difficulty deploying instrumenting creating workloads deployments 
substantial amount theoretical simulation 
gummadi comprehensive analysis static resilience various dht geometries :10.1.1.3.8344:10.1.1.3.8344
argued earlier static resilience important step dht ability handle failures general churn particular 
liben nowell theoretical analysis structured peer peer overlays point view churn continuous process 
prove lower bound maintenance traffic needed keep networks consistent churn show chord algorithms logarithmic factor bound 
contrast focused systems issues arise handling churn dht 
example observed call false suspicions failure appearance functioning node failed shown reactive failure recovery exacerbate conditions 
mahajan simulation analysis pastry study probability dht node forward lookup message failed node function rate maintenance traffic 
algorithm automatically tuning maintenance rate failure rate 
algorithm increases rate maintenance traffic response losses concerned may cause positive feedback cycles observed reactive recovery 
believe failure model pessimistic consider hop hop retransmissions lookup messages 
acknowledging lookup messages hop dht route failed nodes middle lookup path shown timeout values computed minimize cost retransmissions 
castro number optimizations appears proceedings usenix annual technical conference june :10.1.1.11.4677
performed microsoft research implementation pastry simulations 
li performed detailed simulation analysis different dhts churn varying parameters explore latency bandwidth tradeoffs 
inspired analysis different pns techniques 
opposed emulated network study simulations usually consider network issues queuing packet loss doing simulate far larger networks studied able explore far larger space possible dht configurations 
hand reveal subtle issues dht design tradeoffs reactive periodic recovery 
reveal interactions lookup traffic maintenance traffic competing network bandwidth 
interested useful middle ground exists approaches 
number useful features handling churn proposed implemented bamboo 
example kademlia maintains neighbors routing table entry ordered length time neighbors :10.1.1.16.4785
newer nodes replace existing neighbors failure 
design decision aimed mitigating effects high infant mortality observed peer peer networks 
approach handling churn introduce hierarchy system stable superpeers 
explicit hierarchy viable strategy handling load cases shown fully decentralized non hierarchical dht fact handle high rates churn routing layer 
discussed limitations study think provide important 
algorithmic level study effects alternate routing table neighbors kademlia tapestry 
continue study iterative versus recursive routing 
discussed congestion control iterative lookups challenging problem 
implemented chord stp congestion control algorithm currently investigating behavior churn definitive results performance 
methodological level broaden study include better models network topology churn 
far single network topology results taken word pns 
particular distribution internode latencies modelnet topology gaussian distribution latencies measured internet 
unfortunately purposes measured latency distributions include topology information simulate kind network cross traffic important study 
existence better topologies welcome 
addition realistic network models include realistic models churn 
idea suggested anonymous reviewer scale traces session times collected deployed networks produce range churn rates realistic distribution 
explore approach 
believe effects factors studied dramatic remain important models improve 
shown resistance bamboo routing layer churn important step verifying dhts ready dominant building block peer peer systems limited 
clearly issues remain 
security possibly anonymity issues unclear relate churn 
currently studying resilience churn algorithms dht storage layer 
hope existence routing layer robust churn provide useful substrate remaining issues may studied 
summarized rates churn observed deployed peer peer systems shown existing dhts exhibit desirable performance higher churn rates 
bamboo explored various design tradeoffs effects ability handle churn 
design tradeoffs studied fall broad categories reactive versus periodic recovery neighbor failure calculation timeouts lookup messages proximity neighbor selection 
danger positive feedback cycles reactive recovery discussed ways break cycles 
dht cautious declaring neighbors failed order limit possibility recovering non faulty node network congestion 
second technique periodic recovery 
demonstrated reactive recovery efficient periodic recovery reasonable churn rates leaf sets large large system 
respect timeout calculation shown tcp style timeout calculation performs best argued appears proceedings usenix annual technical conference june 
appropriate lookups performed recursively 
long known recursive routing provides lower latency lookups iterative result presents argument recursive routing lowest latency important 
shown effective tcp style timeouts timeouts virtual coordinates quite reasonable moderate rates churn 
result indicates respect timeouts iterative routing infeasible moderate churn 
concerning proximity neighbor selection shown global sampling provide reduction latency virtually increase bandwidth 
additional bandwidth decrease latency achieved 
techniques effective especially adaptations pastry tapestry nearest neighbor algorithms simple global sampling 
merely sampling neighbors neighbors inverse neighbors effective comparison 
combination global sampling techniques provide best performance cost 
acknowledgments number people help 
shepherd atul adya anonymous reviewers provided valuable comments guidance 
frank dabek helped tune vivaldi implementation emil sit helped get chord running 
likewise peter druschel provided valuable debugging insight freepastry 
david becker helped modelnet 
sylvia ratnasamy scott shenker ion stoica provided valuable guidance stages development 
freepastry 
www cs rice edu cs systems pastry 
gnutella 
www gnutella com 
inet topology generator :10.1.1.13.1523
topology eecs umich edu inet 
mit chord 
www pdos lcs mit edu chord 
bhagwan savage voelker 
understanding availability 
proc 
iptps feb 
blake rodrigues 
high availability scalable storage dynamic peer networks pick 

castro costa rowstron :10.1.1.11.4677
performance dependability structured peer peer overlays 
technical report msr tr microsoft 
castro jones 
kermarrec rowstron theimer wang wolman 
evaluation scalable application level multicast built peer peer overlays 
apr 
chu levine 
availability locality measurements peer peer file systems 
proc 
scalability traffic control ip networks july 
dabek kaashoek karger morris stoica :10.1.1.3.8344
wide area cooperative storage cfs 
proc 
acm sosp oct 
dabek li sit robertson kaashoek morris 
designing dht low latency high throughput 
proc 
nsdi 
gummadi gummadi gribble ratnasamy shenker stoica :10.1.1.3.8344
impact dht routing geometry resilience proximity 
proc 
acm sigcomm aug 
gummadi dunn saroiu gribble levy zahorjan 
measurement modeling analysis peerto peer file sharing workload 
proc 
acm sosp oct 
hildrum kubiatowicz rao zhao 
distributed object location dynamic network 
proc 
spaa 
jacobson karels 
congestion avoidance control 
proc 
acm sigcomm 
li stribling gil morris kaashoek 
comparing performance distributed hash tables churn 
proc 
iptps 
liben nowell balakrishnan karger 
analysis evolution peer peer systems 
proc 
acm podc july 
loo huebsch stoica hellerstein 
case hybrid search infrastructure 
proc 
iptps 
mahajan castro rowstron 
controlling cost reliability peer peer overlays 
proc 
iptps feb 
maymounkov mazieres :10.1.1.16.4785
kademlia peer peer information system xor metric 
proc 
iptps 
plaxton rajaraman richa :10.1.1.160.7346:10.1.1.38.1850
accessing nearby copies replicated objects distributed environment 
proc 
acm spaa june 
ratnasamy francis handley karp shenker :10.1.1.136.3479
scalable content addressable network 
proc 
acm sigcomm aug 
rhea geels roscoe kubiatowicz 
handling churn dht 
technical report ucb csd university california berkeley december 
rowstron druschel 
pastry scalable distributed object location routing large scale peer peer systems 
proc 
ifip acm middleware nov 
saroiu gummadi gribble 
measurement study peer peer file sharing systems 
proc 
mmcn jan 
sen wang 
analyzing peer peer traffic large networks 
proc 
acm sigcomm internet measurement workshop nov 
stoica morris karger kaashoek balakrishnan 
chord scalable peer peer lookup service internet applications 
proc 
acm sigcomm aug 
vahdat walsh mahadevan chase becker 
scalability accuracy large scale network emulator 
proc 
osdi dec 
zhao duan huang joseph kubiatowicz 
landmark routing overlay networks 
proc 
iptps march 
zhao huang stribling rhea joseph kubiatowicz 
tapestry resilient global scale overlay service deployment 
ieee jsac jan 
