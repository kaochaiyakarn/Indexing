quantifying machine availability networked desktop grid systems ucsb computer science technical report number cs john department mathematics computer science college norton ma examine problem predicting machine availability desktop enterprise computing environments 
predicting duration machine run restarts availability duration critically useful application scheduling resource characterization federated systems 
describe parametric model fitting technique non parametric prediction techniques comparing accuracy predicting quantiles empirically observed machine availability distributions 
describe method analytically evaluate precision synthetic trace machine availability constructed known distribution 
detail practical efficacy apply machine availability traces separate desktop enterprise computing environments evaluate method terms accuracy predicts availability trace driven simulation 
results indicate availability duration predicted quantifiable confidence bounds bounds conservative bounds lifetime predictions 
non parametric method binomial approach generates accurate estimates 
supported national science foundation numbered eia grads project ccr project ngs doe scidac program 
rich wolski department computer science university california santa barbara santa barbara ca daniel department computer science university california santa barbara santa barbara ca rapid proliferation computational grid computing combined commercial illegal success peer peer file sharing systems sparked interest volatile desktop machines aggregated compute storage platform 
enterprise computing systems developed entropia united devices avaki provide various technologies designed harvest compute power personal computers commercial setting 
grid computing systems condor globus net solve possible combine user controlled resources workstations personal computers largescale clusters machines form integrated computing environment 
community driven efforts seti home rc effort demonstrated significant spare compute cycles promising significant new results 
part challenge desktop resources comes relative volatility compared shared managed counterparts 
owner desktop machine typically exercises ultimate control processes run connectivity network reboot cycle 
system administrators may go great lengths ensure shared server resources computational storage highly available rarely exercise degree control resources assigned individual users 
describe methodology predicting machine availability monitoring data distributed computing environments 
specifically focus ability estimate specified quantile distribution availability confidence level associated estimate 
phrase problem follows set availability measurements taken resource set resources assumed homogeneous desired percentile confidence level largest availability duration say confidence percent availability time measurements greater equal 
answer question data set percentile interest take desired confidence level lower bound estimate qth quantile data set 
prediction exact availability duration estimate quantile provides lower bound long machine collections machines available confidence measure provides quantitative probabilistic guarantee estimate accuracy 
example scheduler may wish establish availability duration smaller possible durations certain number confidence 
belief application schedulers described estimates automatic decisions long run distributed application components 
goal develop quantile estimation methodology supports live predictions availability schedulers human automatic scheduling programs decisions dynamically 
compare parametric automatic model fitting technique maximum likelihood estimation mle non parametric techniques terms bound observed quantile value trace driven simulation 
apply method machine availability data gathered different distributed computing environments 
university california santa barbara instrumented student accessible machines computer science department record available unavailable periods 
developed method recording processor occupancy duration condor cycle harvesting system developed deployed university wisconsin 
ensure measurement implementation introduce unforeseen bias analyze availability data survey internet hosts conducted long muir golding university california santa cruz gratefully acknowledge dr agrawal university california santa barbara dr miron livny university wisconsin dr darrell long university california santa cruz support 
motivation usefulness techniques applied empirical data short verification experiment performs lower bound quantile estimate method synthetic fixed weibull distribution 
empirical data set perform experiment individual machine availability traces split training set estimate quantile lower bound experimental set verify accuracy estimate 
training set precedes experimental set machine trace results detail estimation method predicts machine availability machine time period covered experimental set 
remainder organized follows 
section section describes techniques producing lower confidence bounds quantiles 
section describes data sets investigate methods 
section compare estimation methods empirically 
conclude investigation section 
inference quantiles section examine problem determining lower bounds fixed level confidence quantiles population distribution unknown 
typically statistical inference aims find confidence intervals application concerned lower bounds placing potential error bottom interval allows produce somewhat accurate values 
time provides minimum quality service guarantee quantifiable estimate probability guarantee violated 
example scheduler machine user know minimum amount time machine run reboots quantile true availability distribution provides number confidence 
random variation cause machine availability quantile times quantile exact 
practice know exact distribution quantile estimated 
variety techniques estimating quantiles describe section guarantee require confidence value estimated quantile 
exact quantile uncertain model random variable calculate confidence bound quantile order guarantee 
choosing lower confidence bound ensure true quantile larger bound value specified confidence 
machine availability larger bound specified confidence effect conservative estimate high confidence conservative estimate low quantile availability 
quantile give minimum availability estimate lower confidence bound give minimum quantile estimate methods outlined adapted easily producing confidence intervals course upper bounds 
parametric approach model fitting intuitive method making quantile inferences uses optimization model fitting technique compute continuous model data set computes confidence intervals necessary parameters way bounding estimate quantile 
example machine availability data described section modeled reasonably distribution weibull family 
density distribution functions fw fw respectively parameter weibull distribution fw fw maximum likelihood estimation mle technique estimate parameters data resulting weibull density function fw 

comparison empirical data set mle determined weibull depicted 
notice discrepancy mle weibull model actual empirical data especially near left distribution model quantiles may inadequate 
possible calculate confidence intervals parameters 
matlab mle parameter confidence interval computations uses fisher matrix method computing independent confidence bounds parameter distribution specified confidence level 
simplifying assumption true weibull model bounded weibull models corresponding computed lower upper parameter pairs 
furthermore parameter confidence interval computed independently take region bounding distributions confidence region 
resulting graphs shown 
generate graphs endpoints confidence range parameter 
example confidence range parameter range 
consider bounded region confident confident gives confidence region 
data generated weibull parameters weibull chance outside range chance lower chance upper 
demonstrates mle determine parameters yields weibull distribution approximate 
practice confidence interval fitted weibull may accurately predict number values fall inside outside interval 
example confidence range weibull confidence intervals calculated parameters 
practical purposes prediction interested ensuring machine availability measures larger leftmost distribution confidence level 
range example confidence interval symmetric expect measured values fall left boundary 
technique calculate graphs confidence range allowing left edge tuned needed 
non parametric methods possible determine quantiles confidence intervals hypothesizing underlying distribution weibull 
advantages methods rely specific properties particular distribution shape require potentially large number parameters estimated concomitant estimation error 
complexity associated determining bounding curves increases exponentially number parameters model 
case weibull example curves generated confidence intervals parameters corresponding possible combinations low high values parameters respectively 
phase hyperexponential distribution may conforming fit weibull note number parameters estimated yielding different curves 
weibull case obvious definition density function high estimates yield lowest valued quantiles similarly lowest values yield largest quantiles 
distributions hyperexponential choice clear making automatic implementation part scheduler difficult 
reasons examine methods data set assumption distribution may drawn 
empirical weibull 
empirical mle fitted weibull cdfs machine uptime data gathered lab ucsb 
resample method method term resample method standard result sample size asymptotic distribution sample th quantile normal mean xq true population th quantile variance xq xq population density function evaluated xq cf 
pp 
ff 
principle establish lower confidence bound specific quantile sample quantile calculate standard error variance equation subtract suitable critical value normal distribution times standard error sample mean 
result non parametrically try safe estimate xq histograms data estimate xq reasonably large sample sizes 
estimated value xq small expression appears denominator formula variance extremely sensitive small variations estimate rendering histogram impractical practice 
difficulty circumvented resampling methods creating distribution sample quantiles artificially 
distribution quantiles asymptotically normal 
extent distribution approaches asymptote constructs level lower bound xq th quantile resampled quantiles 
mle mle lower mle upper 
confidence interval graphs weibull shown binomial method second method term binomial method simple observation random variable real number xq th quantile distribution single observation xq probability independent sample xn inferences xq directly making assumptions actual distribution method follows 
probability xi xq equal similarly probability exactly xi xq probability exactly xi xq probability fewer xi xq equal observe calculation valid just asymptotically correct sole assumption xi depends desired confidence level quantile interest xq equation obtain level lower bound xq 

represent order statistics permutes sample increasing order 
say confident level xq equivalent saying priori probability xq equal equation gives equation largest equation holds gives xk level lower bound xq 
noted usual normal approximation binomial produce accurate results relatively small sample sizes extreme quantiles typically concern 
investigated possibility enhancing binomial method applying linear interpolation order statistics associated sums surround confidence level interest 
see section proven successful small quantiles model empirical cdfs tend quite linear 
data sets smaller minimum size allow binomial method conventionally investigated possibility linear interpolation absolute population minima results shown section 
experimental data data study measures resource availability different settings 
university california santa barbara ucsb collected measurements time machine reboots publicly accessible workstations computer science instructional laboratory 
second experiment measured process occupancy time observed single user condor pool university wisconsin month period 
gratefully acknowledge dr darrell long university california santa cruz dr james plank university tennessee supplying original test data derive results respectively 
data sets measures machine availability different way reflecting different definitions availability grid users may choose 
goal plurality measurement methods determine sensitive quantile prediction methods way availability measured 
ucsb data set ucsb computer science students unrestricted access workstations located rooms campus 
systems computer science instructional laboratory 
physical access provided students hours day school session remote access times computer science students 
administrator scheduled reboots school session software failures security hardware failures result unplanned restarts administrative staff 
relevant study power switch workstation physically protected 
student access machine console wish share machine remote users background processes clean machine power cycling 
remote users choose new machine logged warning background processes written automatically restart 
reported anecdotally students normal user response observed machine slowness try power cycle immediately potential remedy 
may believe mode usage administration accurately reflects failure patterns enterprise global desktop computing settings 
users willing accept background computing load introduce unacceptable slowness reclaim resources control catastrophic means need externally generated load great obviously user different tolerance level external load may known priori individual user patience time situation dependent 
combination user administrative restarts hardware failures availability distribution observe externally 
measure availability designed uptime sensor network weather service nws reads time machine reboot proc file system 
workstations currently run linux records time reboot proc directory 
nws designed gather maintain dynamic performance measurements grid resources introducing little load possible 
deployed nws uptime sensor workstations recorded duration reboots feb oct corresponds quarters school year summer quarter 
resultant data set captures production period machines period relatively low resource usage 
condor data set condor cycle harvesting system designed support high throughput computing 
condor model owner machine allows condor launch externally submitted job generated owner machine idle owner expected specify machine consid ered idle respect load average memory occupancy keyboard activity condor detects machine idle takes idle job queue maintains assigns idle machine execution 
machine owner begins machine condor detects local activity external job 
result resource owners maintain exclusive access resources condor uses idle 
process evicted machine machine owner reclaiming begins typing console keyboard condor offers options 
evicted condor process checkpointed saved restart killed 
condor implements checkpointing series libraries intercept system calls ensure job properly restarted 
libraries places certain restrictions system calls job issue 
vanilla jobs unrestricted terminated checkpointed resource reclamation 
condor extensive documentation details features greater extent 
study take advantage vanilla terminate eviction execution environment build condor occupancy sensor nws 
set sensors study submitted condor execution 
condor assigns sensor processor sensor wakes periodically reports number seconds elapsed began executing 
sensor terminated due eviction recorded elapsed time value measures occupancy sensor enjoyed processor 
nws associates measurements internet address port number sensor subsequently restarted particular machine condor determined machine idle new measurements associated machine running sensor 
difficult determine machines available wisconsin condor pool 
number fluctuates new machines added users old machines study condor different linux workstations run nws sensors month measurement period 
notice study consider availability machine condor user nws case machine assigned nws 
consider time assignments particular machine busy owner condor scheduled useful 
data set durations seconds linux reboot time depending machine question 
condor distribution resource unavailability constant 
complete simulation condor pool computational engine require distribution availability distribution unavailability 
treat availability distribution plan full analysis condor dynamics near 
long muir golding data set authors identify hosts connected internet cooperatively respond vacuous query rpc system process commonly systems running network file system nfs 
hosts chosen act cross section internet connected hosts time probing mechanism periodic randomized rpc calls rpc 
successful response rpc constitutes heartbeat machine question failure respond indicates machine failure 
long muir golding data convincing argument availability accurately modeled poisson process 
plank separately plank thomason analyzed extensively terms suitability poisson exponential models context process checkpoint scheduling 
studies authors reach models study accurately reflect behavior captured measurements 
discussion chosen study data sets measure observable machine availability different ways different conditions different times 
data set students engaged collaborative competitive activities resources hand strongly influence measured availability durations 
condor availability measurements capture idle busy distribution resource owners theory unaware condor resources idle periods 
perspective grid peer peer scheduler data sets record quantities amount time application process able resource process exogenously terminated 
include long muir golding data set study ensure results biased measurement techniques 
condor data sets measure availability different sensors developed nws monitoring infrastructure 
result wished data gathered separate group different measurement techniques remove possibility nws biasing results unforeseen way 
note age data indicates time sensitivity non stationarity effects observe 
clearly internet usage patterns evolved sub gathered data 
observing similar distributions data sets indicates effects measuring persistent potentially fundamental 
analysis investigate effectiveness techniques described previous section compare predictive performance parameter weibull model term weibull method section nonparametric resample method binomial method 
test attempts verify predictive power method synthetic distribution availability measurements generated known distribution 
investigation compares method ability recover lower bound quantile known exactly distribution different sample sizes 
illustrates smallest sample size methods generate accurate results 
apply methods machines culled data sets described section detail relative accuracy 
verifying predictive power section verify efficacy methods estimate specific quantile lower bound sample known distribution 
results indicating machine process lifetime data typically modeled heavy tailed distribution shown characterize synthetic machine availability distribution 
population distribution choose parameter weibull distribution shape parameter scale parameter believe typical accurate heavytailed model availability measurements 
distribution population known exactly samples drawn consistent observed machine availability 
population distribution calculate quantiles numerically 
example quantile weibull study 
hypothetically machine availability distribution survive longer time units time probability value larger quantile 
determine accuracy function sample size associated quantile bound estimation method repeatedly sampling synthetic population distribution fixed sample size sample estimate quantile lower bound comparing estimate actual known quantile 
repeat procedure large number random samples record percentage estimates true estimate measure confidence estimate 
example draw samples size population distribution 
sample calculate quantile lower bound confidence particular method weibull resample binomial 
calculate percentage estimates generated method true quantile synthetic population distribution 
synthetic case examine parametric model captures true quantile lower bound 
chosen parameter weibull population distribution weibull parametric model method termed quantile method represents ideal parametric setting 
expectation quantile method estimates true quantile 
motivation expectation sample quantiles asymptotically normal center true quantile lower bound skewed small sample size center may better represented 
table reflect sample sizes large sample quantile shows substantial bias fact distribution noticeably skewed 
quantile lower bound methods expect percentage values equivalent minus confidence level 
example estimating lower bound quantile confidence expect estimates true quantile confidence bound accurate 
table shows results generated calculating quantile estimate different methods variety sample sizes 
case apply relevant method sample drawn synthetic population obtain estimate quantile record estimate true quantile 
column shows sample size percentage samples true quantile shown remaining columns 
table clear surprisingly sample size dramatically affects accuracy associated estimation method 
fact striking binomial method captures desired percentage quantiles sample small 
resample method shows reasonable success samples drops dramatically sample sizes 
weibull method parametric lower bound estimation technique shows low success rate sample sizes large 
instance weibull method samples size resulted mere computed lower bound values true distribution quantile population distribution weibull 
contrast resample method starts showing significant failure sam subsample size weibull method binomial method resample method quantile method table 
percent estimated lower bounds weibull binomial resample methods quantile quantile method different subsample sizes equal true quantile set weibull distribution 
subsample size weibull method variance binomial method variance resample method variance table 
variances quantile lower bound estimates methods difference subsample sizes 
quantiles fitted normal 
cdf quantiles subsamples samples set weibull distribution fitted normal cdf 
mean quantiles true population quantile indicating considerable bias 
ple sizes binomial method results high success rates sample size extremely small samples 
sample size estimate important indicates minimum number measurements particular machine estimate confidence bound estimate trusted 
remainder study assume predictions little data possible 
weibull model fit true machine trace data believe sample size give reliable results non synthetic trace data 
table shows comparison variance estimators quantile bound estimation methods addition percentage reliability estimator provides desirable variance estimator relatively small overly susceptible sampling variation 
notice sample size table variance binomial method estimator considerably smaller resample method weibull method estimators 
binomial method produce reliable confidence bounds full range sample sizes numbers obtained tighter sense variable random sample 
empirical results verification experiment learned methods predicting lower bounds quantiles empirically functioning method gives accurate results far smaller sample size method resampling 
clear results hold behaved model distribution step explore usefulness technique real world lifetime data outlined section 
experiment apply estimation methods availability traces individual machines 
machine divide availability times training period experimental period follows chronologically 
training period data derive lowerbound estimate estimation methods tested experimental period 
results study demonstrate method uses observed data occurring training period predict values experimental period individual machines 
verification experiment noticed samples sufficient making accurate lower bound estimate binomial method machines training experimental periods contains measurements 
methods functioning properly result estimates similar observed verification experiment 
need data parsimony demonstrated experiment 
data sets condor long muir golding machines availability measurements observation period covered data set 
table shows result experiment lower bound quantile estimation methods different data sets 
values reported percentages individual machine traces set method successful machine trace method record success method estimate training period measurements experimental period 
results experiment close results observed verification experiment clearly show real machine process lifetime data little measurements base estimate binomial method finds value values machine traces 
resample method conditions correct estimates machines 
weibull method shows approximate success rate expect long data dramatic condor data 
reason high success rate unfortunately stems fact condor data modeled weibull distribution extremely conservative estimates experiment 
total combined experiments binomial method produced valid lower bound quantile total time resample weibull methods succeeded cases respectively 
emphasize strength result binomial method just high success rate fact success rate close target 
fact observed percentage provide evidence significance level global success rate different exactly 
method produced lower bounds meaningful desired level confidence conservative producing success level close 
converse seen case weibull method condor data obtained high success rate estimates extremely conservative 
success rate exceeds target indicates method exhibiting evidence confidence level meaningfully specified 
discussion experiment allowed predictions address question long expect machine process live time 
noteworthy binomial method making successful predictions time measurements 
predictions investigate unconditional 
result predict long machine available time reboots 
practice scheduler want prediction remaining availability arbitrary point time 
underlying population distributions memoryless conditional prediction remaining lifetime depend long particular machine running time prediction 
population distributions modeled heavy tailed distributions weibull hyperexponential unconditional estimates generate study necessarily conservative 
longer process lived longer live expected availability random point time longer expected total availability restart 
note control confidence bound unconditional prediction binomial method yields tightest bounds quantify conservative unconditional prediction respect conditional 
part investigating similar methods making instantaneous conditional predictions conservative require scheduler interact predictive methodology 
data set number machines weibull success binomial success resample success condor long table 
percent machine traces set method estimate experimental period measurements 
shown methods establishing confidence lower bound population quantile population sample 
gauge effectiveness method performed verification experiment methods form confidence bounds random samples fixed size known population distribution 
quantile experiment strongly indicated binomial method performed far better resample method weibull method small subsample sizes 
attribute fact resample method fails perform small sample size underlying assumption method subsample quantiles population asymptotically normally distributed 
poor performance weibull method indicate parameter estimate technique mle sensitive variations data produce models small subsample sizes accurately capture true population distribution 
verification experiment showed samples small binomial method tested method successfully estimates lower bound population quantile 
results hand performed similar experiment real process machine uptime data collected separate sources 
experiment split machine process lifetime trace training set size experimental set size 
lower bound quantile estimation techniques training period count measurements experimental period greater lower bound estimate 
results experiment similar verification experiment revealing fact resample method weibull method captures samples true population quantile binomial method correctly estimates lower bound expected number times experimental period 
performed test different individual machine process lifetime traces traces binomial method correctly producing lower bound resampling method produced lower bound traces 
weibull method produced success time machine availability data sets produced somewhat high success rate condor data set unfortunately due weibull model applied condor traces results unusable conservative quantile estimates 
produced effective method estimating lower bound quantile estimates binomial method realize estimates confidence lower bounds quite conservative 
purpose determining lifetime existing process estimates particularly conservative due heavy tailed nature distribution availability measurements 
attempt adapt methods current order address data distributions type 
allcock foster chervenak deelman kesselman leigh sim shoshani 
high performance remote access climate simulation data challenge problem data grid technologies 
proceedings ieee sc conference high performance computing 
avaki home page 
www avaki com january 
berman chien cooper dongarra foster dennis gannon kennedy kesselman reed torczon wolski 
grads project software support high level grid application development 
international journal high performance computing applications winter 
berman fox hey 
grid computing making global infrastructure reality 
wiley sons 
berman wolski casanova cirne hayes schopf shao spring su 
adaptive computing grid apples 
ieee transactions parallel distributed systems april 
rc project distributed net rc 
casanova dongarra 
netsolve network server solving computational science problems 
international journal supercomputer applications high performance computing 
casanova berman wolski 
apples parameter sweep template user level middleware grid 
proceedings ieee sc conference high performance computing nov 
condor home page www cs wisc edu condor 
condor manual 
www cs 
wisc edu condor manual 
cramer 
mathematical methods statistics 
princeton university press 
entropia home page 
www entropia 
com 
foster kesselman 
globus metacomputing infrastructure toolkit 
international journal supercomputer applications 
foster kesselman 
grid blueprint new computing infrastructure 
morgan kaufmann publishers 
long muir golding 
longitudinal survey internet host reliability 
th symposium reliable distributed systems pages september 
matlab home page 
www mathworks 
com 
wolski 
modeling machine availability enterprise wide area distributed computing environments 
technical report cs santa barbara computer science department october 
dongarra ellis fagg roche 
numerical libraries grid 
proceedings ieee sc conference highperformance computing november 
plank 
experimental assessment workstation failures impact checkpointing systems 
th international symposium fault tolerant computing pages june 
plank thomason 
processor allocation checkpoint interval selection cluster computing systems 
journal parallel distributed computing november 
ripeanu iamnitchi foster 
cactus application performance predictions grid environment 
proceedings european conference parallel computing europar august 
schopf 
resource management grid computing 
kluwer academic press 
seti home 
ssl 
berkeley edu march 
tannenbaum litzkow 
condor distributed processing system 
dr journal february 
united devices home page www ud com home htm january 
wolski 
experiences predicting resource performance line computational grid settings 
acm sig metrics performance evaluation review march 
wolski spring hayes 
network weather service distributed resource performance forecasting service metacomputing 
generation computer systems october 

