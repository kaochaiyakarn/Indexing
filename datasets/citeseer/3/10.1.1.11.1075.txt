exploring design space parallel realizations mpeg decoder case study jan paul balakrishnan indian institute technology delhi new delhi india cse ernet philips research eindhoven netherlands philips com applications lend parallelism di erent levels granularity 
rst identify key issues involved creating parallel model application 
done view estimate performance explore parallel design space select suitable design point 
framework provides opportunity perform exploration target architecture independent target architecture dependent manner 
mpeg decoder model yapi parallelism improved performance 
model mapped architecture study architectural parameters 
detailed results obtained yapi simulation target architecture independent tss simulation process processor binding mpeg decoder application establish ectiveness approach 
keywords mpeg decoder yapi parallel realization process thread fifo 
advances network microprocessor technology possible introduce new set applications services 
high de nition tv hdtv broadcast satellite service video conferencing interactive storage media typical examples 
applications need huge amount data processing video audio domain 
high data rates involved applications computation time consuming 
designers mainly follow architectural approaches signal processing systems dedicated programmable 
dedicated architectures target algorithm set algorithms 
architectures fully exploit computational features algorithm vlsi implementations dedicated architectures optimized area power performance 
overview architectural approaches signal processing systems 
dedicated architectures provide performance lack exibility extend algorithm set 
hand programmable approach ers number advantages 
programmable solutions er greater exibility target algorithm set extended applying proper software modi cations 
large number applications run hardware application hardware cost reduced 
hand computational properties algorithms fully exploited requires architecture application models faster 
architecture faster employing multiprocessing strategy 
parallel model application running multiprocessor architecture offers potential solutions 
computational resources multiprocessor architecture exploited fully application model sucient parallelism 
parallelism signal processing applications explicit models kahn process networks 
variants model reported including 
drawback models kahn process network model reactiveness 
limitation overcome control ow models statecharts esterel 
parallel model application built signi cant speed achieved application runs multiprocessor architecture 
main objective identify modeling issues involved creating parallel model yapi starting point expand application set estimate performance application models 
mpeg decoder modeled increased parallelism model improved performance 
model study architectural parameters architecture 
remainder organized follows 
section introduce yapi model mpeg decoder 
section discusses modeling issues 
section discusses mpeg decoder model yapi describes performance improved 
section describes experimental environment 
section presents results experiments section 
terms process thread interchangeably 

yapi yapi chart application programmer interface library set rules model signal processing applications process networks 
process network variant kahn process network 
process network composed number process networks processes fifos 
process network process represents computing station fifo represents communication channel 
process network part process network hierarchy process networks created 
shows simple process network processes communicate fifo process process process network fifo process network processes de ne functionality application 
process interacts environment input output ports 
process running state blocked state ready state 
process gets blocked tries read empty fifo tries write fifo full 
primitives provided yapi communication channels 
primitive read read channel primitive write write channel primitive select non deterministic applications 
furthermore multiple tokens transferred fifo vector communication mechanism yapi ecient 
application model created yapi architecture independent application model mapped architecture 

modeling issues parallel model application quite di erent sequential model 
state space parallel model quite large 
parallel models impose overheads context switching communication synchronization 
prediction performance parallel application dicult execution speed highly architecture dependent 
section modeling issues ect performance discussed 
focus coarse grain parallelism context yapi 
amount parallelism 
amount parallelism application depends application 
thorough data dependency analysis application required fully extract data functional parallelism application 
example mpeg decoder application independent tasks variable length decoding motion compensation idct identi ed data parallelism slice macroblock block level exploited providing instances tasks 
application model having parallelism improve performance provided total number tokens communicated processes increase 
unidirectional communication 
application model processes handshaking request tokens processes may lead deadlock 
handshaking increases number tokens transferred violates streaming behavior data ows direction 
application model unidirectional communication processes give better performance 
improvement comes sources reduction number context switches number tokens communicated 
data ows forward direction unidirectional communication reduces synchronization overhead debugging time 
communication overhead 
multiprocessor environment con ict communication resources lots buses hardware possible avoid contention altogether expensive 
number processors increases architecture communication expensive 
application model optimized reduced communication give better speed 
achieved carefully choosing token structure controlling number tokens transferred communication channels 
granularity operation 
granularity operation signi cantly ects structure application model 
compilers able extract instruction level parallelism ne level granularity 
mainly concentrate coarse grained parallelism 
signal processing applications parallelizing ner granularity may ects data parallelism ner granularity exploited 
communication primitives called frequently number tokens transferred transfer 
communication workload increases 
total amount data transfer goes 
ner granularity data parallelism increased increases communication workload 
performance improves computation workload relatively decreases 
balanced pipelines 
process network processes communicate pipelined manner 
slowest process pipeline determines throughput 
computation properly balanced processes reduce ective parallelism application model 
shows pipelines converge process sink 
latency lower path nite space fifos processes upper path get blocked 
increase number context switches reduce ective parallelism application 
situation application model perform better balanced pipelines 
synchronization overhead 
yapi application modeled process network 
processes communicate sink source process network demonstrating pipelines fifos transferring tokens 
important place process sends receives tokens 
need mechanisms global events noti ed actions started 
example arrival new picture mpeg decoding kind global event 
processes mpeg decoder model noti ed update picture properties required correct decoding 
application programmer take care identi cation points token required synchronization sent 
mechanism notifying processes global events 
solution employ broadcast mechanism case special tokens communicated relevant processes 
mechanism communicating sourcing sinking tokens processes repeating operation idct 
multiple instance processes 
process network instances process process network throughput stage process increase roughly factor 
scheme increases synchronization overhead 
process source adopt policy distribute tokens properly processes pi similar policy adopted process sink collect tokens 
pn source sink pn pn process network demonstrating multiple instance process large processes source sink may respond demands processes pi quickly may lead increase context switching 
large value performance improvement may get saturated 
memory usage 
chip memory speeds system performance limited amount 
suggests memory usage optimized 
increase parallelism increases number processes communication channels application model 
increases memory requirements 
trade size parallelism space requirements 
eliminated fully problem reduced ne tuning sizes fifos experiments 
scalability 
scalability model de nes capability grow 
application model scalable data parallelism provided just plugging instances processes providing idct processes mpeg decoder application 

mpeg decoder model number parallel models mpeg decoder software studied 
focus methodology 
focus extracting parallelism di erent levels granularity gop slice macroblock studying variation performance 
explores ectiveness parallel mpeg decoder runs 
extend kind study 
issues discussed previous section modeled mpeg decoder yapi 
levels hierarchy model 
top level process reads input video sequence process extracts header sequence process manages frame memory process outputs decoded frames process network extracts slice header decodes slices 
sync infile prop slice bits mem id ref mem id prop pic prop seq slice cmd prop seq rdy mem id process network mpeg decoder process network gets slices bit stream decodes 
process variable length decoding 
process network tmc provides motion compensation 
inverse quantization followed idct provided process network idct add process writes decoded macroblocks frame memory 
processes level operate macroblocks 
process network idct add composed processes 
process provides inverse scan inverse quantization 
process provides idct operation process adds idct component prediction component 
microprocessor architecture java computing prop pred prop mv prop pic prop mb tmc ref mem id mem id mb prop pic mb prop pic prop pic prop seq prop slice slice idct add idct add mb prop mb process network prop pic prop mb mb mb fi prop mb mb mb fj idct prop mb fk idct prop mbk mb fj add prop mb fk add prop mbi idct prop mbi mb fi add prop mbk process network idct add processes decodes motion vectors provides predictions process network tmc provide motion compensation 
prop pic prop pic mb predict prop pic predict prop mv predict prop pred predict ref mem id process network tmc mpeg decoder model described extracts data parallelism slice macroblock level simultaneously 
model exibility grow 
instances idct add provided increase parallelism application 
bidirectional communication 
avoided limited frame memory 
fifos resized utilize fifo memory space eciently 

experimental setup simulation setup composed layers 
uppermost layer application 
application modeled primitives yapi 
thread created corresponding process application model yapi uses thread scheduler provide thread related services 
thread scheduler responsible thread management activities context switches maintaining status threads bottom layer architecture 
cpu architecture thread scheduler 
thread scheduler small operating system manages resources cpu 
application architecture yapi thread scheduler layered structure experiment environment simulated mpeg decoder application environments 
yapi run time tss environments 
yapi run time environment application runs workstation yapi provides application workload information 
simulated mpeg decoder application yapi environment sun platform sunos 
environment tss mapped mpeg decoder application tss model architecture 
architecture homogeneous multiprocessor architecture 
basic unit repetition tile 
tile consists heterogeneous mix memories general purpose processors mips arm dsps study early version architecture consisting single tile con gurable number low mips cpus communicate pi bus 
architecture cpus close pr 
compiled application model mips linked yapi library generate executable application 
nally runs tss model architecture control thread scheduler 
process describes mapping yapi model application tss model architecture 

experimental results taken number mpeg decoder models 
rst model named old model introduced 
rest models identi ed mpeg ijk 
indicates number process networks indicates number process network idct add indicates number processes idct add 
processes old model 
number processes model mpeg ijk calculated follows number processes input mpeg video sequence tennis table tennis sequence frames frame size 
yapi level simulation yapi run time environment multiprocessor environment application runs single processor 
gives important feedback application 
feedback terms parameters number context switching total number thread tss cycle accurate language simulation framework philips 
switching processor parallelism number average number processes ready list processor time 
table shows parameters 
seen number context switching comes increasing value models mpeg ijk increases goes 
implies quite possible certain point providing instances processes process networks increase number context switches parallelism number increases 
model number parallelism name context switching number old model mpeg mpeg mpeg mpeg mpeg table number context switching parallelism number various mpeg decoder models tss level simulation instances architecture cpus cpus cpus 
various mpeg decoder con gurations run tss model architecture 
simulation results corresponding total number cycles cpi cycles instruction bus wait cycles total number snooping requests 
shows number cycles number cpus various models 
total number cycles di erent con gurations normalized total number cycles taken simulation old model cpus 
old model models show decrease number cycles increasing number processors architecture 
improvement speed seen mpeg compared old model 
gain speed going cpus cpus compared gain cpus cpus 
normalized number cycles number cpus old model mpeg mpeg mpeg mpeg number cycles vs number cpus old model contains quite processes handshaking 
old model er parallelism cpu con guration communication increased handshaking bidirectional communication 
reason new models handshaking place er signi cant performance improvement 
new models variation performance increases processors 
case having processes application model ers advantage 
cpi ratio total number cycles total number instructions taken application decode tennis 
tss simulation 
old model models show increase cpi indicates decrease total number instructions relative total number cycles 
number cpus old model mpeg mpeg mpeg mpeg cpi vs number cpus shows variation bus wait cycles di erent con gurations 
plot bus wait cycles indicates average number cycles cpu blocked cache ll request progress 
old model models show kind behavior variation high 
curve nearly straight line 
increase bus wait cycles units processor old model show slightly di erent behavior increase bus wait cycles units processor 
reason increase bus wait cycles cpus share communication resource bus 
number cpus old model mpeg mpeg mpeg mpeg bus wait cycles vs number cpus shows total number snooping requests cpus cache coherence 
tss model cpu uses msi cache coherence protocol cache coherence cpus 
clear plot number cpus increased required snooping requests go 
curves nearly straight lines 
increase snooping request approximately units cpu old model units cpu 
relative decrease number snooping requests new models compared old model factor indicates relatively cache coherence activity compared old model 
parallelism number taken yapi level simulations 
seen variation total number cycles taken tss simulations large particular number cpus 
implies ideally total number cycles taken tss simulations decrease parallelism number increases communication bottleneck prevents 
number snooping requests millions cpu number cpus tile old model mpeg mpeg mpeg mpeg number bus snooping requests vs number cpus number cycles millions parallelism number cpus cpus cpus number cycles vs parallelism 
number factors directly ect performance application model 
unidirectional communication balanced pipelines granularity operation typical examples 
model features bidirectional communication unbalanced pipelines feedback loops reduce speed signi cantly lead deadlocks 
experiments number processors architecture increases con icts communication resources increases 
certain number processors increasing number cpus improve performance signi cantly 
observed mpeg decoder application presence cpus tile gives performance going cpu improve performance signi cantly 
adding cpus backed communication bandwidth 
observed xed number cpus architecture limit increasing number processes application model improve performance 
current implementation mpeg decoder model allowed process get access video sequence directly 
rest processes get access bu ering mechanism 
model improved reducing bu ering allowing processes particularly variable length decoders direct access video sequence proposed 
hand scheme increase synchronization overhead 

peter 
vlsi implementations image video multimedia processing systems 
ieee trans 
circuits systems video technology november 
kahn 
semantics simple language parallel programming 
proc 
ifip congress 
north holland publishing 
edward lee data ow process networks 
proc 
ieee may 
de kock yapi application modeling signal processing systems 
proc 
th design automation conference dac june 
paul jan 
homogeneous multiprocessing silicon design paradigms 
proc 
international symposium vlsi technology systems applications vlsi tsa april 
david skillicorn domenico talia 
models languages parallel computation 
acm computing surveys june 
joan mitchell william pennebaker chad fogg didier 
mpeg video compression standard 
chapman hall new york 
information technology generic coding moving pictures associated audio information video 
iso iec 
pieter van der wolf mpeg decoder case study driver system level design methodology 
proc 

iwata olukotun 
exploiting coarse grain parallelism mpeg algorithm 
technical report csl tr stanford university computer systems laboratory september 
angelos real time parallel mpeg decoding software 
proc 
th international parallel processing symposium ipps april 
documentation 
mpeg video decompression multi processing vliw microprocessor 
www sun com microelectronics 
mpeg video decompression simultaneous multithreaded multimedia processors 
proc 
int 
conf 
parallel architectures compilation techniques pact october 
brian smith patel lawrence rowe 
performance software mpeg video decoder 
proc 
acm multimedia conference 
pr user manual 
philips semiconductors 
