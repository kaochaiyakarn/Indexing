measuring anonymity claudia az bart preneel leuven esat leuven heverlee belgium claudia diaz esat kuleuven ac www esat kuleuven ac 
introduces information theoretic model allows quantify degree anonymity provided schemes anonymous connections 
considers attackers obtain probabilistic information users 
degree probabilities attacker observing system assigns di erent users system originators message 
proof concept model applied existing systems 
model shown useful evaluating level privacy system provides various attack scenarios measuring amount information attacker gets particular attack comparing di erent systems 
today expanding line world increasing concern protection anonymity privacy electronic services 
past technical solutions proposed hide user identity various applications services 
anonymity important issue electronic payments electronic voting electronic auctions email web browsing 
distinction connection anonymity data anonymity 
data anonymity ltering identifying information data exchanged particular application 
connection anonymity hiding identities source destination actual data transfer 
model focuses level connection anonymity system provide indicate level data anonymity 
information theory proven useful tool measure amount information see cover thomas 
try measure information obtained attacker 
model proposed shannon de nition entropy allows quantify degree anonymity electronic system 
degree dependent power attacker 
model shown useful evaluate anonymity system provides di erent circumstances compare di erent systems understand system improved 
appeared proceedings pet april san francisco hannes ed designing privacy enhancing technologies lecture notes computer science 
related knowledge attempts quantify degree anonymity user provided anonymous connection system 
reiter rubin de ne degree anonymity probability assigned particular user attacker 
believe degree useful get idea anonymity provided system user worst case give information distinguishable user anonymity set 
system large number possible senders user worst case may assigned probability distinguishable attacker rest users low associated probabilities 
berthold de ne degree anonymity log number users system 
degree depends number users system take account information attacker may obtain observing system 
useful measure robustness system attacks 
degree propose measures information attacker gets account set users probabilistic information attacker obtains 
wright analyze degradation anonymous protocols 
assume recurring connection sender message receiver 
anonymity measurement model similar proposed independently proposed serjantov danezis 
main di erence models system normalize degree order get value relative anonymity level ideal system number users 
outline organized follows section describes system attack model actual measurement model proposed section 
proof concept model applied existing systems section 
open problems 
system model focus systems provide anonymity mixes 
system model consider consists entities senders 
users send ability send messages recipients 
messages emails queries database requests web pages stream data 
senders grouped set senders called anonymity set 
entities system anonymity want protect 
appeared proceedings pet april san francisco hannes ed designing privacy enhancing technologies lecture notes computer science 
attack consider number senders constant senders behaving independent identical poisson processes 
standard assumption modeling behavior users making phone calls 
means users send average amount messages interval time message follows exponential distribution 
recipients 
entities receive messages senders 
recipients active send back answers senders passive react received message 
depending system large variety recipients 
examples web servers databases email accounts bulletin boards users post messages 
attacker may reply messages gain information 
mixes 
nodes typically solutions anonymous connections 
take messages input output correlation corresponding input messages hidden 
di erent ways implement mix single mix usually done order achieve better security methods route message chain mixes summary 
systems crowds nodes mixing properties ones described chaum 
cases actual properties intermediate nodes mentioned 
note systems intersection di erent sets non empty sender time recipient mix 
examples systems provide anonymous connections crowds onion routing 
proposed measurement model shown suitable systems 
generally applicable kind system 
attack model degree anonymity depends probabilities users sent particular message probabilities assigned attacker 
degree measured respect particular attack results obtained system longer valid attack model changes 
concrete assumptions attacker clearly speci ed measuring degree anonymity 
brie describe attacker properties consider internal external internal attacker controls entities part system attacker prevent entity sending messages may access internal information entity external attacker compromise communication channels eavesdrop tamper messages 
passive active passive attacker listens communication reads internal information active attacker able add remove modify messages adapt internal information 
appeared proceedings pet april san francisco hannes ed designing privacy enhancing technologies lecture notes computer science 
local global global attacker access communication system local attacker control part resources 
di erent combinations previous properties possible instance global passive external attacker able listen channels local internal active attacker control example particular mix unable get information 
model attacker carry probabilistic attack 
pointed raymond attacks thoroughly addressed far 
attack adversary obtains probabilistic information form probability sender message 
proposed measurement model give precise de nition anonymity 
adopt de nition 
anonymity state identi able set subjects anonymity set 
sender identi able get information linked ip address machine sender 
consider sender anonymity 
means particular message attacker wants nd subject anonymity set originator message 
anonymity set case de ned set honest users send message 
clear minimum size anonymity set user anonymity set possible protect identity 
de nition degree anonymity probabilities observing system attacker assign user probability sender 
degree anonymity provided system previous de nitions system users maximum degree anonymity achieved attacker sees subjects anonymity set equally probable originator message 
model degree anonymity depends distribution probabilities size anonymity set contrast previous 
way able measure quality system respect anonymity provides independently number users 
note size anonymity set calculate distribution probabilities sum probabilities 
proposed model compares information obtained attacker observing system optimal situation honest users users controlled attacker considered part anonymity set aware control 
appeared proceedings pet april san francisco hannes ed designing privacy enhancing technologies lecture notes computer science 
equally probable originator message system users situation attacker sees users originator probability observing system attacker may assign probabilities sender originator message information system leaking means trac analysis timing attacks message length attacks sophisticated attacks 
distribution probabilities concept entropy information theory provides measure information contained distribution 
entropy tool calculate degree anonymity achieved users system particular attacker 
entropy system attack compared maximum entropy number users 
way get idea information attacker gained words compare distinguishable sender set possible senders attack 
lex discrete random variable probability mass function represents possible value may take 
case corresponds element anonymity set sender 
denote entropy system attack taken place 
sender belonging senders set size attacker assigns probability calculated log hm maximum entropy system want measure actual size anonymity set hm log number honest senders size anonymity set 
information attacker learned attack expressed hm 
divide hm normalize value 
de ne degree anonymity provided system hm hm hm particular case user assume zero 
degree anonymity provided system quanti es amount information system leaking 
particular system user small group users shown originators high probability respect system providing high degree anonymity 
follows immediately hand note system equiprobable distribution provide degree anonymity system senders assigned probability 
de nition anonymity independent number senders 
appeared proceedings pet april san francisco hannes ed designing privacy enhancing technologies lecture notes computer science 
user appears originator message probability 
users appear originator probability 
measuring degree anonymity provided systems section apply proposed measurement model order analyze degree anonymity provided existing systems particular crowds onion routing 
simple example mix email 
rst example consider system shown fig 

system provides anonymous email potential senders mix network recipient 
attacker wants nd senders sent email particular recipient 
means timing attacks trac analysis attacker assigns certain probability user sender 
aim example give idea values degree anonymity di erent distributions probabilities 
mix network recipient fig 

simple example mix email system active attack 
rst consider active internal attacker able control senders means users excluded anonymity set 
able perform trac analysis mix network assign probabilities remaining senders 
probability assigned user probability assigned user 
distribution probabilities maximum entropy honest users hm log appeared proceedings pet april san francisco hannes ed designing privacy enhancing technologies lecture notes computer science 
fig 
show variation degree anonymity respect expect de nitions see reaches maximum value users equiprobable 
case attacker gained information active users real sender message analyzing trac mix network 
minimum level reached attacker assign probability users 
simple example useful get idea minimum degree anonymity adequate 
roughly suggest system provide degree 
corresponds user 
examples look probability distributions correspond value degree order compare di erent systems 
minimum acceptable degree particular system may depend anonymity requirements system believe minimum suggested intensively testing model 
passive attack 
consider passive global external attacker able analyze trac system control entities anonymity set composed users 
maximum entropy system hm log attacker comes distribution case groups users users 
users belonging group seen attacker having probability 
fig 
see variation parameter maximum degree achieved equiprobable distribution 
case drop zero worst case attacker sees users possible senders probability identify single user sender message 
value reached users assigned probability remaining users assigned probability 
crowds overview system 
crowds designed provide anonymity users want access web pages 
achieve goal designers introduce notion blending crowd users grouped set forward requests set request sent web server 
web server know member request originated gets request random member crowd forwarding message appeared proceedings pet april san francisco hannes ed designing privacy enhancing technologies lecture notes computer science 
degree anonymity degree anonymity fig 

degree anonymity simple example behalf real originator 
users members crowd called jondos 
system works follows jondo wants request web page sends request second randomly chosen jondo 
jondo probability forward request third jondo randomly chosen probability submit server 
jondo path rst chooses forward submit request independently decisions predecessors path 
communication jondos encrypted symmetric techniques nal request server sent clear text 
jondo observe contents message address target server know predecessor originator message just forwarding message received member 
note system mixes jondos expected characteristics 
particular ort hide correlation incoming outgoing messages 
attacker 
calculate degree anonymity provided crowds respect collaborating crowd members set corrupted jondos collaborate order disclose identity jondo originated request 
assumptions attacker internal attacker controls entities part system 
passive corrupted jondos listen communication 
ability add delete messages gain extra information identity originator doing 
local assume attacker controls limited set jondos perform trac analysis rest system 
degree anonymity 
shows example crowds system 
appeared proceedings pet april san francisco hannes ed designing privacy enhancing technologies lecture notes computer science 
server fig 

example crowds system jondos example jondos controlled attacker collaborating crowd members 
non collaborating jondo creates path includes corrupted jondo attacker wants know jondos real originator message 
generally number members crowd number collaborators probability forwarding probability assigned attacker jondo having sent message 
jondos control attacker excluded anonymity set 
maximum entropy hm account size anonymity set equal hm log know attack model probability assigned predecessor rst collaborating jondo path jondo number equals pc probabilities assigned collaborating jondos remain zero assuming attacker extra information rest probabilities assigned members pc entropy system attack log pf pf log pf degree anonymity provided system function order show variation respect parameters path go collaborating jondo attacker get information 
appeared proceedings pet april san francisco hannes ed designing privacy enhancing technologies lecture notes computer science 
chose fig 
fig 
fig 

degree represented gure function number collaborating jondos minimum value attacker maximum value user attack 
case obtain collaborating jondos know real sender remaining non collaborating jondo 
users number collaborating jondos degree anonymity pf pf users number collaborating jondos pf pf users number collaborating jondos pf pf fig 

degree anonymity crowds deduce gures decreases number collaborating jondos increases variation similar systems di erent number users 
regarding tolerated number collaborating jondos obtain observe system tolerate corrupted jondo system tolerates users users users 
degree anonymity de ned sender sender probability assigned attacker particular user sender 
measure gives idea degree anonymity provided system particular user complementary degree proposed 
interesting compare results obtained reiter rubin ones obtained attack model consider worst acceptable case situation jondos seen attacker sender probability 
come appeared proceedings pet april san francisco hannes ed designing privacy enhancing technologies lecture notes computer science 
maximum number collaborating jondos system tolerate 
chosen examples obtain users users users 
degree anonymity point view sender 
calculated degree anonymity user sends message goes corrupted jondo happens probability time message forwarded jondo 
take account rst jondo forwards message randomly chosen jondo crowd subsequent jondos forward probability jondo independently previous decisions 
probability ph message going honest jondos ph message go collaborating jondo attacker assign honest senders probability degree anonymity maximum degree achieved attacker distinguish sender rest honest users 
discussion implications fact appendix onion routing overview system 
onion routing solution application independent anonymous connections 
network consists number onion routers 
functionality ordinary routers combined mixing properties 
data sent path onion routers determined onion 
onion layered encrypted data structure sent onion router 
de nes route anonymous connection 
contains hop information key seed material generating symmetric keys onion router actual routing data embedded onion sent onion router 
data encrypted multiple times symmetric keys distributed onion routers path 
carried small data cells containing appropriate anonymous connection identi er 
onion router removes adds layer encryption symmetric keys generated key seed material onion depending direction data forwards backwards 
attack model 
attack models described reed syverson goldschlag 
example consider attacker able narrow set possible paths 
attacker obtains result attack subset anonymity set contains possible senders 
appeared proceedings pet april san francisco hannes ed designing privacy enhancing technologies lecture notes computer science 
assumption attacker control user system 
abstraction attack order illustrate example carried performing brute force attack starting recipient possible reverse paths senders 
alternative attacker controls onion routers able eliminate group users anonymity set 
degree anonymity 
gives example onion routing system 
total users system 
assume attacker server fig 

example onion routing managed exclude users set possible senders 
generally size anonymity set maximum entropy users hm log attacker able obtain subset anonymity set contains possible senders 
size subset 
assume attacker assign di erent probabilities users belong subset entropy attack taken place degree anonymity log hm log log shows degree anonymity respect 
obviously increases number users attacker able exclude anonymity set decreases 
order appeared proceedings pet april san francisco hannes ed designing privacy enhancing technologies lecture notes computer science 
degree anonymity fig 

degree anonymity onion routing obtain users need users need users need 
comparing number collaborating jondos crowds system onion routing tolerant failing users jondos crowds 
remaining honest users jondos equal probability attack model onion routing system crowds jondo higher probability 
open problems solutions anonymous communication proposed implemented past 
problem measure actual anonymity provide studied thoroughly 
proposed general measurement model quantify degree anonymity provided system particular attack circumstances 
applied model existing solutions anonymous communication 
suggested intuitive value minimum degree anonymity system provide adequate anonymity 
model showed useful evaluating system comparing di erent systems 
examples chosen calculate degree particular message take account behavior system time 
attacker may gain useful information observing system longer time fact re ected distribution probabilities 
apply model account changes probabilities obtain information evolution degree anonymity time 
open problems 
model probabilities attacker assigns users nding probability distribution real situations easy 
appeared proceedings pet april san francisco hannes ed designing privacy enhancing technologies lecture notes computer science 
interesting take account priori information attacker may model see amount information gained attack 
focused sender anonymity recipient anonymity treated analogously unlinkability sender recipient depends probability nding match 
usefulness model intensively tested example interesting measure ect dummy trac advanced anonymous communication solutions order nd right balance performance privacy 
acknowledgments claudia az funded research leuven 
funded research institute promotion innovation science technology flanders iwt 
partially supported iwt project anonymity privacy electronic services apes concerted research action goa sto flemish government 
extension model systems may get di erent distributions certain probability 
example crowds cases message goes corrupted jondo probability pc goes honest jondos probability ph pc ph want calculate degree anonymity ered system account possibilities may combine obtained degrees follows degree obtained particular circumstances probability occurrence circumstances 
number di erent possibilities 
degree anonymity case composite degrees obtained di erent cases 
alternative solution may case particular system requirement minimum acceptable degree anonymity formulated users appeared proceedings pet april san francisco hannes ed designing privacy enhancing technologies lecture notes computer science 
degree anonymity equivalent system users perfect indistinguishability 
case compare actual entropy system required 
compare obtained entropy log normalizing best system number current users 
bigger system minimum smaller may want extra protection system dummy trac 
useful see system meeting requirements launch alarm case degree anonymity lower de ned minimum 

berthold federrath 
web mixes system anonymous unobservable internet access 
hannes ed designing privacy enhancing technologies lecture notes computer science lncs pp 
springer verlag 

berthold 
free mix routes overcome hannes ed designing privacy enhancing technologies lecture notes computer science lncs pp 
springer verlag 

chaum 
untraceable electronic mail return addresses digital pseudonyms 
communications acm vol 
pp 


cover thomas 
elements information theory 
john wiley sons 
isbn 

feller 
probability theory applications 
john wiley sons third edition 


anonymity unobservability pseudonymity proposal terminology 
hannes ed designing privacy enhancing technologies lecture notes computer science lncs pp 
springer verlag 


raymond 
trac analysis protocols attacks design issues open problems 
hannes ed designing privacy enhancing technologies lecture notes computer science lncs pp 
springer verlag 

reed syverson goldschlag 
anonymous connections onion routing 
ieee journal selected areas communication 
special issue copyright privacy protection 

reiter rubin 
crowds anonymity web transactions 
communications acm vol 
pp 


serjantov danezis 
information theoretic metric anonymity 
hannes ed designing privacy enhancing technologies lecture notes computer science 

shannon 
mathematical theory communication 
bell system tech 


wright adler levine shields 
analysis degradation anonymous protocols 
proceedings network distributed system security symposium february 
appeared proceedings pet april san francisco hannes ed designing privacy enhancing technologies lecture notes computer science 
