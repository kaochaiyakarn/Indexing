journal machine learning research submitted revised published bottom relational learning pattern matching rules information extraction mary elaine califf edu department applied computer science illinois state university normal il usa raymond mooney mooney cs utexas edu department computer sciences university texas austin austin tx usa editor david cohn information extraction form shallow text processing locates specified set relevant items natural language document 
systems task require significant domain specific knowledge time consuming difficult build hand making application machine learning 
algorithm rapier uses pairs sample documents filled templates induce pattern match rules directly extract fillers slots template 
rapier bottom learning algorithm incorporates techniques inductive logic programming systems 
implemented algorithm system allows patterns constraints words part speech tags semantic classes filler surrounding text 
encouraging experimental results domains 
keywords natural language processing information extraction relational learning 
wake explosive growth line text web places come need systems help people cope information explosion 
number researchers language processing begun develop information extraction systems systems pull specific data items text documents 
information extraction systems promising way deal certain types text documents 
difficulty information extraction systems difficult time consuming build generally contain highly domain specific components making porting new domains time consuming 
efficient means developing information extraction systems desirable 
situation information extraction systems attractive application machine learning 
researchers begun learning methods aid construction information extraction systems soderland riloff kim moldovan huffman :10.1.1.21.2755:10.1.1.21.6045
systems learning part larger information extraction system 
system rapier robust automated production information extraction rules learns rules complete information extraction task rules producing desired information pieces mary elaine califf raymond mooney 
califf mooney directly documents prior parsing post processing 
structured relational symbolic representation learning classifiers rules developed general rule templates 
corpus documents paired filled templates rapier learns eliza patterns weizenbaum 
current implementation patterns limited syntactic semantic information freely available robust knowledge sources part speech tagger lexicon 
rules built patterns consider unbounded context giving advantage limited representations consider fixed number words 
relatively rich representation requires learning algorithm capable dealing complexities 
rapier employs relational learning algorithm uses techniques inductive logic programming ilp systems lavrac dzeroski 
techniques appropriate developed rich relational representation order logic clauses 
algorithm incorporates ideas ilp systems consists primarily specific general bottom search 
show learning build useful information extraction rules relational learning effective learning simple features fixed context 
simultaneous rapier development learning systems developed task relational learning freitag soderland 
approaches problem include hidden markov models hmms freitag mccallum combining boosting learning simpler wrappers freitag kushmerick 
experiments rapier performed different domains 
domains set computer related job postings usenet newsgroups 
utility domain evident success job posting website www com developed whizbang 
www com information extraction techniques 
noted template detailed specific jobs 
second domain set seminar announcement compiled carnegie mellon university 
results compared relational learners naive system 
results encouraging 
remainder article organized follows 
section presents background material information extraction relational learning 
section describes rapier rule representation learning algorithm 
section presents discusses experimental results including comparisons simple bayesian learner relational learners 
section suggests directions 
section describes related applying learning information extraction section presents 

background section provides background task information extraction relational learning algorithms immediate predecessors learning algorithm 
information extraction information extraction shallow form natural language understanding useful certain types document processing focus arpa message understanding conferences muc lehnert sundheim darpa 
useful situations set text documents exist containing information easily human learning information extraction posting newsgroup subject tn software programmer date nov gmt organization com posting service message id software programmer position available software programmer experienced generating software pc voice mail systems 
experienced programming 
familiar communicating controlling voice cards preferable experience natural microsystems okay 
prefer years experience pc voice mail consider little years 
need find senior level person come board pick code little training 
operating system dos 
may go os unix 
please reply kim anderson fax com sample job posting newsgroup 
computer information available uniform database format 
information extraction system set documents template slots filled information document 
information extraction systems locate way identify specific pieces data needed document 
different types data may extracted document commonly system identify string taken directly document cases system selects set values possible fillers slot 
type slot filler may items dates useful consistent format may simply set terms provide consistent values information document necessarily consistently useful way 
limit dealing strings taken directly document question 
information extraction useful variety domains 
various muc focused tasks latin american terrorism domain mentioned joint ventures microelectronics management changes 
information extraction track medical patient records soderland track mergers huffman extract biological information craven ray craven :10.1.1.21.2755
researchers applied information extraction formal text genres rental ads soderland web pages freitag hsu dung muslea 
califf mooney filled template computer science job id com title software programmer salary state tn city country language platform pc dos os unix application area voice mail req years experience desired years experience req degree desired degree post date nov filled template corresponding message shown 
slot fillers strings taken directly document 
slots filled filler 
domain appropriate particularly light dealing wealth online information extract information text documents order create easily searchable databases information making wealth text online easily accessible 
instance information extracted job postings usenet newsgroups misc jobs offered create easily searchable database jobs 
example information extraction task system limited computer related jobs appears figures 
relational learning empirical natural language processing employed statistical techniques manning schutze charniak miller smadja wermter section discusses potential advantages symbolic relational learning 
order accurately estimate probabilities limited data statistical techniques base decisions limited context bigrams trigrams word contexts 
nlp decisions frequently larger contexts include variety syntactic semantic pragmatic cues 
consequently researchers begun employ learning techniques handle larger contexts decision trees magerman miller aone bennett exemplar case methods cardie ng lee maximum entropy modeling method ratnaparkhi 
techniques require system developer specify manageable finite set features making decisions 
de learning information extraction set features require significant representation engineering may exclude important contextual information 
contrast relational learning methods birnbaum collins allow induction structured examples include order logical predicates functions unbounded data structures lists trees 
consider learning algorithm relational uses representation examples goes finite feature vectors handle unbounded number entities representation example uses notion relations entities example just single precedes relation token entities allows representing unbounded sequences strings 
particular inductive logic programming ilp lavrac dzeroski muggleton studies induction rules order logic prolog programs 
ilp systems induced variety basic prolog programs append reverse sort potentially useful rule bases important biological problems muggleton srinivasan 
detailed experimental comparisons ilp feature induction demonstrated advantages relational representations language related tasks text categorization cohen generating past tense english verb mooney califf :10.1.1.28.8552
research demonstrated usefulness relational learning classifying web pages slattery craven 
information extraction learning algorithms prior rapier development structured representations kind autoslog riloff crystal soderland artificially limited possible rules learned autoslog learning rules fit particular provided templates crystal drastically limiting examples sentence extracted phrase occurred :10.1.1.21.6045
contrast rapier patterns limited ways 
rapier ilp algorithm relational learning algorithm learning structured rule representation algorithm inspired ideas ilp systems 
ilp ideas appropriate designed learn rich unbounded representations 
sections discuss general design issues developing ilp rule learning systems briefly describe relevant aspects ilp systems directly influenced rapier learning algorithm golem progol 
general algorithm design issues design issues rule learning systems structure algorithm 
primary forms outer loop compression covering 
systems compression creating initial set highly specific rules typically example 
iteration general rule constructed replaces rules subsumes compressing rule set 
iteration positive examples consideration extent metric evaluating new rules biased greater compression rule set 
rule learning ends new rules compress rule set 
systems compression include duce propositional rule learning system inverse resolution muggleton cigol ilp system inverse resolution muggleton buntine zelle mooney 
systems covering set positive examples 
rule learned positive examples new rule covers removed consideration creation rules 
rule learning ends positive examples covered 
probably common way structure rule learning system 
examples include foil quinlan golem califf mooney muggleton feng progol muggleton claudien de raedt bruynooghe various systems foil focl pazzani lavrac dzeroski foidl mooney califf :10.1.1.28.8552:10.1.1.31.1630:10.1.1.35.951
trade offs designs 
primary difference trade efficient search thorough search 
covering systems tend somewhat efficient seek learn rules examples covered 
search thorough compression systems may prefer rules cover remaining examples subsume existing rules 
covering systems may set fairly specific rules cases thorough search discovered general rule covering set examples 
second major design decision direction search construct individual rules 
systems typically directions bottom specific general systems create specific rules generalize cover additional positive examples top general specific systems start general rules typically rules cover examples positive negative specialize rules attempting uncover negative examples continuing cover positive examples 
systems duce cigol golem pure bottom systems foil systems pure top systems 
progol combine bottom top methods 
clearly choice search direction creates tradeoffs 
top systems better finding general rules covering large numbers examples start general rule specialize avoid negative examples 
bottom systems may create overly specialized rules don perform unseen data may fail generalize initial rules sufficiently 
fairly small search space background relations constants top search may efficient 
branching factor top search high ways specialize rule bottom search usually efficient constrains constants considered construction rule example rule 
systems combine bottom top techniques seek take advantage efficiencies 
ilp algorithms mentioned golem muggleton feng uses greedy covering algorithm :10.1.1.35.951
construction individual clauses bottom construction general generalizations specific clauses plotkin 
order take background knowledge account golem creates relative positive examples respect background knowledge 
golem randomly selects pairs examples computes pairs selects best resulting clause 
additional examples randomly selected generalize clause improvement clause coverage 
second ilp algorithm helped inspire rapier zelle mooney example ilp algorithm uses compression outer loop 
combines elements top bottom induction techniques including mechanism predicate invention 
starts specific definition set positive examples introduces generalizations definition compact measured cigol size metric muggleton buntine 
search general definitions carried hill climbing fashion 
step number possible generalizations con learning information extraction sidered producing greatest compaction theory implemented process repeats 
determine clauses current theory new clause replace uses notion empirical subsumption 
clause covers examples covered clause additional examples empirically subsumes individual clause creation algorithm attempts construct clause empirically subsumes clauses current definition covering negative examples 
step construct lgg input clauses 
lgg cover negative examples refinement necessary 
clause general attempt refine foil mechanism adds literals derivable background previously invented predicates 
resulting clause general passed routine invents new predicate discriminate positive examples negatives covered 
progol muggleton combines bottom top search :10.1.1.31.1630
foil golem progol uses covering algorithm outer loop 
propositional rule learner aq michalski individual clause construction begins selecting random seed example 
mode declarations provided background predicates predicate learned progol constructs specific clause random seed example called bottom clause 
mode declarations specify argument predicate argument type constant variable bound predicate called variable bound predicate 
bottom clause progol employs search set clauses containing literals bottom clause order find simplest consistent generalization add definition 

rapier system discussion important distinguish rapier algorithm rapier system 
basic concept rule representation general algorithm applicable variety specific choices terms background knowledge features 
describe specific implementation choices 
seen section choices effective 
note terminology convenience brevity term slot filler refer string extracted 
term pre filler pattern refer pattern matches left context string extracted term post filler pattern refer right context string extracted 
rule representation rapier rule representation uses eliza patterns weizenbaum limited syntactic semantic information 
extraction rule patterns pre filler pattern match text immediately preceding slot filler slot filler pattern match actual slot filler post filler pattern match text immediately filler 
extraction rules contain information template slot apply 
purpose patterns course limit strings rule matches strings correct extractions slot particular template 
element pattern set constraints text element match 
implementation rapier allows kinds constraints pattern elements constraints words element match califf mooney pre filler pattern filler pattern post filler pattern syntactic nn nnp word semantic price list length syntactic jj rule extracting transaction amount newswire concerning corporate acquisition 
nn nnp part speech tags noun proper noun respectively jj part speech tag adjective 
part speech tags assigned words element match semantic class words element match 
constraints disjunctive lists words tags semantic classes document items match words tags classes fulfill constraint 
note part speech tags semantic classes theory source 
rapier operation depend particular tagset tagging method 
practice eric brill tagger trained wall street journal corpus brill 
rule representation require particular type semantic class wordnet synsets semantic classes miller rapier handling semantic classes heavily tied representation :10.1.1.105.1244
pattern sequence possibly length zero case pre post filler patterns pattern elements 
rapier types pattern elements pattern items pattern lists 
pattern item matches exactly word symbol document meets item constraints 
pattern list specifies maximum length matches symbols document limited form kleene closure match list constraints 
shows example rule shows various types pattern elements constraints 
rule constructed rapier extracting transaction amount newswire concerning corporate acquisition 
rules represented columns column representing patterns rule 
column individual pattern elements numbered 
note pattern elements multiple constraints take multiple lines 
rule extracts value phrases sold bank amount paid honeywell price 
pre filler pattern consists pattern elements 
item part speech constraining matching word tagged noun proper noun 
second list maximum length constraints 
filler pattern single item constrained word pos tag labeling adjective 
post filler pattern single pattern item semantic constraint price patterns extract information apply rules slot document take extracted strings slot fillers eliminating duplicates 
rules may apply 
cases multiple slot fillers possible system seldom proposes multiple fillers slots filler occur 
learning information extraction learning algorithm describes rapier learning algorithm specific implementation issues decisions 
algorithm design choices rapier noted inspired ilp methods particularly golem pro gol 
compression primarily consists specific general bottom search 
choice bottom approach reasons 
reason large branching factor search space particularly finding word semantic constraints 
learning systems operate natural language typically mechanism handling search imposed large vocabulary significant amount text speech 
systems handle problem imposing limits vocabulary considered frequent words considering words appear times training corpus yang pederson 
type limitation may effective bottom approach reduces consideration constants creation rule appearing example rule generalized limiting search imposing artificial hard limits constants considered 
second reason selecting bottom approach decided prefer overly specific rules overly general ones 
information extraction natural language processing task typically trade high precision avoiding false positives high recall identifying true positives 
task building database jobs partially motivated wished emphasize precision 
information database performing keyword search original documents giving maximal recall extract strings taken directly document relatively low precision 
bottom approach tend produce specific rules tend precise rules 
choice bottom approach compression outer loop fit 
bottomup approach strong tendency producing specific precise rules 
compression outer loop may partially counteract tendency tendency thorough search general rules 
zelle mooney rapier begins specific definition attempts compact definition replacing rules general rules 
rapier rule representation rules different slots independent system creates specific definition compacts separately slot template 
algorithm overview basic outer loop algorithm appears 
fairly standard compression algorithm 
note learning done separately slot 
algorithms constructing initial specific rules rule generalization discussed detail sections 
parameter algorithm determines maximum number times algorithm fail compress rulebase 
allow multiple attempts find acceptable rule randomness built rule generalization algorithm 
maximum number compression failures exceeded algorithm ends 
default 
califf mooney slot template learned specific rules example documents failures failures examples acceptable add remove empirically subsumed rules add failures rapier algorithm definition acceptable rule considered discussion evaluating rules 
short acceptable rule covers positive examples may cover relatively small number negative examples 
acceptable rule rapier uses notion empirical subsumption determine rules considered covered new rule removed rulebase 
initial rulebase construction step compression learning algorithm construct initial rulebase 
ilp algorithms done simply set examples set facts initial definition predicate learned 
rapier construct specific rules example documents filled templates 
rapier begins process locating instance string extracted corresponding document 
constructs rule instance string extracted filler pattern document preceding extracted string pre filler pattern document extracted string post filler pattern 
rules maximally specific constructed patterns contain pattern item token document 
pattern lists arise generalization 
constraints item specific constraints correspond token item created 
word part speech tag constraints implementation quite straightforward word constraint simply token document pos tag constraint simply pos tag token 
semantic class information creates issues construction initial rulebase 
semantic class left unconstrained single word multiple possible semantic classes homonymy polysemy language 
semantic constraints immediately created rapier disjunction possible classes lowest level generality case wordnet synsets word item created belongs choose semantic class 
choice somewhat problematic resulting constraint quite general 
second choice best correct semantic class word context known difficult problem 
selecting frequent choice wordnet cases certainly cases issue domain specificity 
frequent meaning learning information extraction initialize rulelist empty priority queue length randomly select pairs rules find set generalizations fillers rule pair pattern create rule filler empty pre post fillers evaluate add rulelist loop increment rule rulelist evaluate rule add rulelist rule rulelist evaluate rule add rulelist best rule rulelist produces valid fillers value best rule rulelist failed improve iterations rapier algorithm inducing information extraction rules word contexts may frequent meaning word particular domain question 
course single domain words multiple meanings determining frequent meaning word specific domain may wrong choice 
implementation rapier avoids issue altogether waiting create semantic constraints generalization 
implicitly allows disjunction classes selecting specific class item generalized containing different word 
postponing choice semantic class multiple items required fit semantic constraint narrow number possible choices semantic class classes cover words 
details concerning creation semantic constraints discussed 
rule generalization rapier method learning new rules inspired aspects ilp algorithms discussed 
basic idea take random pairs rules generalize pair select best generalization new rule 
due issues computational complexity rapier employs combination top bottom approach produce generalizations pair rules 
outlines algorithm learning new rule 
parameters algorithm length priority queue defaults number pairs rules generalized defaults number specialization iterations allowed improvements value best rule improvements defaults 
algorithm bit complex straightforward method generalizing rules simply find general generalization lgg corresponding patterns rules 
find lgg pre filler patterns califf mooney pre filler pattern new rule filler pattern new rule lgg filler patterns post filler pattern 
problems straightforward approach led hybrid search rapier employs 
problem expense computing pre filler post filler patterns 
patterns may long pre filler post filler patterns rules may different lengths 
generalizing patterns different lengths computationally expensive individual pattern element shorter pattern may generalized elements longer pattern known ahead time elements combined produce lgg 
computation lgg pre filler post filler patterns entirety may prohibitively computationally expensive 
issues involved generalizing patterns different lengths discussed detail 
expense computing generalizations length deal fact generalization algorithm return multiple generalizations patterns different lengths 
second problem issue having multiple generalizations pair pattern elements 
implementation allow constraints words tags unlimited disjunctions words tags lgg word tag constraints union 
disjunct may desirable generalization generalization simply removes constraint desirable generalization cases 
useful consider multiple generalizations pattern elements constraints approach implementation rapier uses 
choice clearly aggravates problems generalizing lengthy patterns causing process produce possible generalizations 
rapier rule generalization method operates principle relevant information extracting slot filler close filler document 
rapier begins generalizing filler patterns creates rules resulting generalized filler patterns empty pre filler post filler patterns 
specializes rules adding pattern elements pre filler post filler patterns working outward filler 
elements added patterns created generalizing appropriate portions pre fillers post fillers pair rules new rule generalized 
working way takes advantage locality language preclude possibility pattern elements fairly distant filler 
rulelist priority queue length maintains list rules consideration parameter algorithm 
priority rule value rapier heuristic metric determining quality rule see section 
rapier search basically beam search breadth search keeping best items pass 
search differ somewhat standard beam search nodes rules fully expanded pass iteration specialization algorithms consider pattern elements distance filler old rules thrown fall priority queue 
sections discuss specifics rule generalization algorithm looking rules evaluated issues involved generalizing constraints issues involved generalizing patterns 
learning information extraction rule evaluation difficulty designing rapier algorithm determining appropriate heuristic metric evaluating rules learned 
issue measurement negative examples 
clearly task information extraction large number possible negative examples strings extracted number large explicit enumeration negative examples difficult best 
issue question precisely substrings constitute appropriate negative examples strings length considered negative examples strings lengths similar positive examples slot 
avoid problems rapier enumerate negative examples uses notion implicit negatives zelle 
rapier assumption strings extracted slot specified strings rule extracts specified template assumed spurious extractions negative examples 
rule evaluated applied document training set 
fillers match fillers slot training templates considered positive examples extracted fillers considered negative examples covered rule 
method determining negative positive examples covered rule rule evaluation metric devised 
rapier simple search technique hill climbing metric information gain quinlan measures proposed new rule improves current rule order pick new rule greatest improvement 
rule needs inherent value compared rules 
value rule metric information gain quinlan 
log 
measures degree rule separates positive negative examples case identifies valid fillers spurious fillers distinction simple complex rules 
problem rules cover number positives negatives different levels complexity constraints constraints expect simpler rule generalize better new examples want rule preferred 
machine learning algorithms encode preference top hill climbing algorithms rule covering negatives preference simple complex rules 
rapier search encode preference consideration multiple ways generalizing constraints produce rules widely varying complexities step generalization specialization evaluation metric rules needs encode bias complex rules 
want evaluation metric biased favor rules cover larger number positive examples 
metric rapier uses takes rule weights size rule divided number positive examples covered rule 
computed laplace estimate probabilities 
size rule computed simple heuristic follows pattern item counts pattern list counts disjunct word constraint counts disjunct pos tag constraint semantic constraint counts 
size divided bring heuristic size estimate range allows rule size influence value overwhelmed 
califf mooney evaluation metric computed log number correct fillers extracted rule number spurious fillers rule extracts 
rapier allow coverage spurious fillers 
primary reason human annotators errors especially errors omission 
rapier rejects rule covering large number positives extracts negative examples prevented learning useful patterns failure human annotator notice single filler fits pattern fact extracted 
rapier specialization ends due failure improve best rule iterations best rule extracts spurious examples best rule meets criteria number valid fillers extracted rule number spurious fillers extracted 
equation taken ripper cohen uses pruning rules measuring hold set 
rapier usually learning relatively small number examples hold set internal cross validation evaluation rules cover spurious fillers uses higher default value cohen uses default rapier default value 
note rapier noise handling involve pruning noise handling 
pruning appropriate top approaches noise handling goal avoid creating rules specialized fit data pure top systems way generalize specific rule sort pruning 
rapier primarily bottomup compression system depend subsequent iterations compression algorithm generalize rules may specific 
noise handling mechanism need allow acceptance noisy rules best rule rule evaluation metric covers negative examples 
constraint generalization starting point generalization pair pattern elements necessarily generalization corresponding constraints pattern 
basic concept generalization application simple binary constraints straightforward 
constraints corresponding constraint generalized pattern element 
constraint generalized pattern element lgg constraints 
case binary constraints simply removal constraint 
implementation rapier uses constraints complicated generalize 
discussion emphasizes issues particular types constraints implementation 
algorithm applied variety constraint types discussion indicate issues may arise constraint generalization 
mentioned issue introduced word tag constraints simply allow unlimited disjunction constraints leading prefer produce different generalizations cases constraints differ disjunction words tags constraint removal constraint 
learning information extraction dealing semantic constraints hierarchy wordnet introduces complications generalization constraints 
issue ambiguous words 
indicated specific rules rapier constructs create semantic class constraint difficulties selecting particular semantic class word 
algorithm creating generalization words take account generalizing semantic constraint 
second issue arises dealing semantic hierarchy 
stated semantic constraints word senses synsets wordnet 
structure hierarchy typically possible generalizations word senses interested finding general 
easily efficiently guarantee finding correct generalization purposes especially issue may multiple possible senses word breadth search try minimize total path length word senses generalization 
generalizing semantic class determined previous generalization step simply search upward wordnet synset represents class 
generalizing words simultaneously search upwards hypernym hierarchy synsets containing word 
synset reached ancestor possible synset pattern elements generalized assumed general generalization elements 
shows possible results generalization process 
different generalizations word man shown bold 
generalizing man world results synset bold meaning words 
generalizing man woman results synset person 
generalizing man rock results physical object 
purposes simplicity figures show possible meanings word indicate directions generalization go individual word 
generalization process common ancestor exists generalized pattern element semantically unconstrained 
noted implementation semantic constraints generalization closely tied wordnet miller semantic hierarchy research :10.1.1.105.1244
code carefully modularized order process substituting alternative source semantic information modifying generalization method allow disjunctions classes relatively easy 
generalizing pattern elements rules generalizing constraints generalization pair pattern elements fairly simple 
generalizations word tag semantic constraints pattern elements computed described 
set generalizations rapier computes combinations word constraint tag constraint semantic constraint creates pattern element combination 
see example combination 
original pattern elements pattern items new elements pattern items 
new elements pattern lists 
length new pattern lists maximum length original pattern lists length pattern list case pattern item pattern list generalized 
califf mooney adult female female person person male person adult male senses woman selected senses man rock stone natural object organism living thing object physical object entity physical thing world humanity group human rock music popular music music genre style communication skilled worker senses rock worker portion wordnet hypernym hierarchy showing different generalizations word man generalizing patterns generalizing pair patterns equal length quite straightforward 
rapier pairs pattern elements patterns computes generalizations pair 
creates patterns combining generalizations pairs elements order 
shows example 
generalizing pairs patterns differ length complex problem combinatorial explosion greater 
suppose patterns elements long elements long 
need determine group elements generalized 
assume element shorter pattern match element longer pattern element longer pattern match exactly element shorter pattern total ways match element shorter pattern elements longer pattern total ways match elements patterns 
patterns grow longer difference length grows larger problem severe 
order limit problem somewhat creating possible generalizations rapier searches exact matches elements patterns generalized making assumption element patterns exactly matches element pattern elements paired problem broken matching segments patterns side matching elements 
search matching elements confined assumption matching element shorter pattern generalized element longer pattern 
shorter pattern elements longer element compared elements learning information extraction elements generalized element element word man word woman syntactic nnp syntactic nn semantic semantic resulting generalizations word word man woman syntactic nn nnp syntactic nn nnp semantic person semantic person word word man woman syntactic syntactic semantic person semantic person example generalization pattern elements 
words man woman form possible generalizations disjunction dropping word constraint 
tags nn noun nnp proper noun possible generalizations 
total generalizations elements 
element elements element elements matches greatly limit number generalizations need computed 
exact matches break patterns segments generalized 
pair segments treated pair patterns need generalized corresponding pattern segments equal length handled just pair patterns length described 
patterns uneven length generalized 
special cases different length patterns 
shorter pattern may elements 
case pattern elements longer pattern generalized set pattern lists pattern list alternative generalization constraints pattern elements 
resulting pattern lists able match document tokens elements longer pattern length pattern lists sum lengths elements longer pattern pattern items naturally having length 
demonstrates case 
second special case shorter pattern single element 
similar previous case generalization single pattern list constraints generalized pattern elements patterns 
case length pattern lists greater length pattern element shorter pattern sum lengths elements longer pattern 
length shorter pattern considered case list length greater length longer pattern 
example case appears 
third special case patterns long different length 
case number generalizations large rapier simply creates single pattern list constraints length equal longer patterns measuring sums lengths elements 
case happens primarily slot fillers disparate length califf mooney patterns generalized pattern pattern word ate word hit syntactic vb syntactic vb word word syntactic dt syntactic dt word pasta word ball syntactic nn syntactic nn resulting generalizations word ate hit word syntactic vb syntactic vb word word syntactic dt syntactic dt word pasta ball word pasta ball syntactic nn syntactic nn word ate hit word syntactic vb syntactic vb word word syntactic dt syntactic dt word word syntactic nn syntactic nn generalization pair patterns equal length 
simplicity semantic constraints shown generalization 
pattern generalized word bank syntactic nn word vault syntactic nn resulting generalizations list length list length word bank vault word syntactic nn syntactic nn generalization pattern items matched pattern elements pattern 
useful generalization useful rule context structure actual slot filler 
learning information extraction patterns generalized pattern pattern word bank list length syntactic nn word word vault syntactic nnp syntactic nn resulting generalizations list length list length word word syntactic nn nnp syntactic generalization pattern items matched pattern element pattern 
pattern pattern list length resulting generalizations length 
special cases holds rapier create full set generalizations described 
rapier creates set generalizations patterns creating generalizations elements shorter pattern possible set elements longer pattern assumptions mentioned element shorter pattern correspond element longer pattern element longer pattern corresponds exactly element shorter pattern grouping 
possible generalizations elements computed generalizations patterns created combining possible generalizations elements possible combinations include element pattern exactly order 
case exact matches step remains various resulting pattern segment pairs generalized 
generalizations patterns computed creating possible combinations generalizations pattern segment pairs 
specialization phase final piece learning algorithm specialization phase indicated calls 
functions take parameters rule specialized integer indicates elements pre filler post filler patterns original rule pair specialization 
incremented specialization uses context working outward slot filler 
order carry specialization phase rule maintains information rules created referred base rules pointers base rules pre filler pattern base rule incorporated current rule pattern base rule incorporated current rule 
specialization functions return list rules specialized adding rule generalizations appropriate portions pre fillers post fillers base rules 
issue arises functions 
system simply considers adding element pattern step away filler may useful generalizations lengths califf mooney rules created pre filler pattern pre filler pattern pre filler pattern length length element element generalizations elements elements generalizations elements elements generalizations elements elements empty set concatenate create pre filler add return rapier algorithm specializing pre filler rule patterns generalized 
example assume rules required years experience created phrases years experience required years experience required 
fillers generalized algorithm need specialize resulting rule identify number years experience required desired 
iterations create items years experience third iteration match required 
helpful fourth iteration match occurrences required creating list order allow happen specialization functions consider result adding element pattern consider results adding element pattern second adding element second pattern 
pseudocode appears 
analogous 
order allow pattern lists created appropriate functions generalize pairs pattern segments 
patterns generalized determined determining pre filler post filler original pair rules current rule incorporates 
pre filler case example current rule empty pre filler patterns generalized elements pre filler elements pre filler elements pre filler elements pre filler elements pre filler base learning information extraction rules 
current rule specialized portion pre filler elements incorporates pattern pre filler start place number elements generalized specifies portion pre filler considered iteration 
post filler case analogous pre filler case portion pattern considered algorithm works outward filler 
complete sample induction trace example entire process creating new rule consider generalizing rules phrases located atlanta georgia offices kansas city missouri 
phrases sufficient demonstrate process rules practice longer 
initial specific rules created phrases city slot job template pre filler pattern filler pattern post filler pattern word located word atlanta word tag vbn tag nnp tag word word georgia tag tag nnp word tag pre filler pattern filler pattern post filler pattern word offices word kansas word tag nns tag nnp tag word word city word missouri tag tag nnp tag nnp word tag purposes example assume semantic class states cities 
simplicity assume beam width 
fillers generalized produce possible rules empty pre filler post filler patterns 
filler items generalize list words 
word constraints generalize disjunction words constraint 
tag constraints items generalized rule tag constraints 
words belong single semantic class lexicon semantics remain unconstrained 
fillers produced pre filler pattern filler pattern post filler pattern list max length word atlanta kansas city tag nnp pre filler pattern filler pattern post filler pattern list max length tag nnp rules cover spurious examples add pre filler post filler generalizations 
iteration specialization algorithm considers pattern item side filler 
results califf mooney pre filler pattern filler pattern post filler pattern word list max length word tag word atlanta kansas city tag tag nnp pre filler pattern filler pattern post filler pattern word list max length word tag tag nnp tag items produced commas identical unchanged 
alternative useful rules produced lists place items pre filler post filler patterns specializations produced generalizing element pattern elements pattern 
continuing specialization alternatives algorithm moves look second elements pre filler pattern 
generalization elements produce possible specializations rules current beam list length list length word located offices word located word offices tag vbn nns tag vbn tag nns word word word located offices tag vbn nns tag tag specializations improve rule specialization proceeds second elements post fillers 
pattern lists created pattern item pattern 
pattern items generalized 
assume lexicon contains semantic class states generalizing state names produces semantic constraint class tag constraint nnp word constraint disjunction states 
final best rule pre filler pattern filler pattern post filler pattern word list max length word tag tag nnp tag tag nnp semantic state 
experimental evaluation results data sets set computer related job postings austin jobs newsgroup set seminar announcements cmu 
order analyze effect different types knowledge sources results different versions rapier tested 
full representation words pos tags assigned brill tagger brill semantic classes taken wordnet 
versions words tags labeled rapier wt tables words labeled rapier 
experiments default values rapier parameters 
results learning information extraction systems 
naive bayes system uses words fixed length window locate slot fillers freitag 

seminar dataset annotated dayne freitag graciously provided data 
learning information extraction training examples rapier rapier words tags rapier words naive bayes precision job postings systems developed goals similar rapier 
relational learning systems depend syntactic analysis 
representations algorithms differ significantly rapier 
srv freitag employs top set covering rule learner similar foil quinlan 
uses pre determined predicates allow express information length fragment position particular token relative positions tokens various user defined token features capitalization digits word length 
second system whisk soderland rapier uses pattern matching employing restricted form regular expressions 
semantic classes results syntactic analysis require 
learning algorithm covering algorithm rule creation begins selection single seed example creates rules top restricting choice terms added rule appearing seed example similar progol 
ran naive bayes system jobs data set splits identical rapier 
results reported systems author cited papers 
computer related jobs task extracting information computer related job postings create database available jobs 
computer job template contains slots including information employer location salary job requirements 
slots languages platforms take multiple values 
performed fold cross validation examples trained smaller subsets training examples test set order produce learning curves 
measures precision percentage slot fillers produced correct recall percentage slot fillers correct templates produced system 
statistical significance evaluated tailed paired test 
califf mooney training examples rapier rapier words tags rapier words naive bayes recall job postings shows learning curve precision shows learning curve recall 
clearly naive bayes system perform task shown fairly competitive domains seen 
performs slots quite poorly especially usually multiple fillers 
order compare reasonably similar levels recall naive bayes recall considerably rapier set naive bayes threshold low accounting low precision 
course setting threshold obtain high precision results lower recall 
results clearly indicate advantage relational learning simpler fixed context representation naive bayes appears insufficient produce useful system 
contrast rapier precision quite high words words pos tags 
fact surprising bias bottom algorithm specific rules 
high precision important tasks having correct information database generally important extracting greater amount reliable information 
learning curve quite steep 
rapier algorithm apparently quite effective making maximal small number examples 
precision curve flattens quite bit number examples increases recall rising slowly examples 
active learning intelligently select training examples improve rate learning califf 
results encouraging 
looking performance versions rapier obvious word constraints provide power 
pos semantics provide useful classes capture important generalities sufficient examples relevant classes implicitly learned words 
addition pos tags improve performance lower number examples 
recall version tag constraints significantly better level point training curve examples 
apparently examples word constraints capable representing concepts provided pos tags learning information extraction system stime etime loc speaker prec rec prec rec prec rec prec rec rapier rap wt rap srv whisk wh pr table results seminar announcements task differences statistically significant 
wordnet semantic classes provided significant performance increase words pos tags 
recall increases semantic classes precision decreases 
probably indicates semantic classes wordnet fit problem semantic generalizations producing overly general rule 
learning system whisk applied data set 
soderland reports fold cross validation documents randomly selected data set whisk achieved precision recall soderland 
slightly worse rapier performance examples part speech tags precision recall 
making comparison important note test sets different whisk system performance counted bit differently duplicates eliminated 
entirely clear whisk perform quite rapier possibility restriction context whisk single sentence 
seminar announcements seminar announcements domain ran experiments versions rapier report results previous results data data splits naive bayes system srv freitag 
dataset consists documents randomly split approximately half runs 
training testing sets approximately examples 
results systems reported individual slots 
report results whisk 
results fold cross validation documents randomly selected training set 
soderland presents results post pruning rule set 
table shows results systems slots seminar announcement task 
line labeled whisk gives results unpruned rules labeled wh pr gives results post pruned rules 
systems perform start time time slots rapier semantic classes performs significantly worse start time systems 
slots predictable contents context high performance surprising 
start time time difference distribution reason difference performance naive bayes slots 
difference impact srv performance rapier performs comparably resulting better performance time slot cmu systems 
whisk performs start time task post pruning performs time task 
looking performance califf mooney slots noted results counted bit differently cmu systems rapier 
freitag systems assume possible answer slot 
slots may multiple correct answers 
pm answer considered correct answer counted slot 
rapier assumption allows possibility needing extract multiple independent strings 
performance measured assuming possible strings need extracted 
somewhat harder task partially accounting rapier weaker performance 
noted srv binary features look orthographic issues length tokens kinds features may useful recognizing times word pos tag semantic class features implementation rapier available 
location somewhat difficult field pos tags help quite bit 
surprising locations typically consist sequence cardinal numbers proper nouns pos tags recognize consistently 
srv higher recall rapier substantially lower precision 
clear relational systems better naive bayes slot despite fact building names recur data words informative 
difficult slot extraction task speaker 
slot naive bayes whisk rapier words perform quite poorly speaker names seldom recur dataset systems word occurrence information kind orthographic features srv uses pos tags provide information speaker names proper nouns 
rapier pos tags performs quite task worse recall srv better precision 
general domain semantic classes little impact rapier performance 
semantic constraints rules apparently positive negative effect utility rules start time slot semantic classes may discouraged system learning precise contextual rules appropriate slot 
pos tags help location speaker slots ability identify proper nouns numbers important 
discussion results show relational methods learn useful rules information extraction effective propositional system naive bayes 
differences various relational systems probably due factors 
systems quite different learning algorithms biases may appropriate particular extraction tasks 
second systems different representations features 
word occurrence capable representing constraints unbounded ordered sequences 
rapier srv capable explicitly constraining lengths fillers rapier case sequences pre post fillers whisk 
rapier pos tags presumably modified 
srv uses orthographic features systems access information cases pos tags provide similar information capitalized words usually tagged proper nouns numbers tagged cardinal numbers 
issue addressed examine effect various features seeing differences performance depend features basic representational algorithmic biases 
algorithms adaptable different learning information extraction features certainly adapting rapier binary features type srv employ straightforward 
sample learned rules final interesting thing consider rapier types rules creates 
common type rule learned certain kinds slots rule simply memorizes set possible slot fillers 
example rapier learns mac mvs aix vms platforms computer related jobs domain word appears documents extracted platform slot filler 
interesting rule lines extracts visual language slot 
pre filler post filler patterns empty filler pattern consists pattern list length word constraint visual pattern items 
seminar announcements domain rule location slot extracts doherty wean weh name buildings cmu followed cardinal number 
rules memorize slot fillers include context ensure filler extracted particular case 
example rule area slot jobs domain extracts gui rpc followed software 
rules rely context filler patterns 
formal patterns message id job posting pre filler pattern filler pattern post filler pattern word message list length word word word id word word probably majority rules mix context contents filler 
example rule title computer related jobs domain pre filler pattern filler pattern post filler pattern word seeking consultant dba seminar announcements domain rule start time relies combinations structure filler context pre filler pattern filler pattern post filler pattern word syntactic cd word syntactic syntactic cd syntactic nn 
number directions extended 
list consider immediately promising helpful 
califf mooney mentioned understanding various relational learning systems information extraction benefit systematic study systems features system distinguished contributions available features vs algorithms 
little evidence indicate systems best promising step improvements 
adding additional constraint types rapier representation features employed srv straightforward task 
useful extension rapier ability learn rules extract fillers multiple slots 
advantages learning rules 
slots appear particular relationship document learning single rule slots may help focus search rule 
helpful learning start time time seminar announcements domain position management changes domain 
certain situations multiple fillers slots fillers way connected 
instance rental ads domain whisk tested soderland common different sized apartments different prices listed ad 
simply extract numbers bedrooms prices connecting helpful 
learning rules extract number bedrooms related price help solve problem 
modifying rapier handle multiple slot extraction rules fairly straightforward 
rule simply additional patterns slot filler extracted patterns slot fillers context patterns slot filler slot filler 
primary issue problematic generalization patterns slot fillers 
probably contain useful information long different sizes causing generalizing pair prohibitively expensive 
necessary take top approach learning connecting patterns starting unconstrained pattern list breaking pattern items smaller lists adding constraints taken original rule pair limit search long constraints improved rule quality 
desirable modification rapier enable algorithm take advantage kinds pre processing tag token text parsing phrase chunking named entity recognition 
straightforward handling additional constraint types single token clearly complicate generalization specialization phases rapier algorithm 
named entity recognition particular prove useful identifying filler patterns phrase chunking provide useful information information extraction rules ray craven 
final direction research considering applying rapier representation algorithm natural language processing tasks 
quite representation fit types tasks possibly allow success engineering features learning systems currently employ 

related closest rapier discussed previous section 
section briefly mention related systems 
previous researchers generally applied machine learning parts information extraction task required human interaction providing texts filled templates 
crystal uses form clustering create dictionary extraction patterns generalizing patterns identified text expert soderland learning information extraction 
autoslog creates dictionary extraction patterns specializing set general syntactic patterns riloff assumes expert filter patterns produces :10.1.1.21.6045
learns extraction patterns relying concept hierarchy guide generalization specialization kim moldovan 
systems rely prior detailed sentence analysis identify syntactic elements relationships output requires processing produce final filled templates 
liep learns information extraction patterns huffman requires sentence analyzer identify noun groups verbs subjects assumes relevant information entities identifies interesting :10.1.1.21.2755:10.1.1.21.2755
robotag uses decision trees learn locations slot fillers document bennett 
features available decision trees result pre processing text fixed context 
robotag learns trees identify possible start tokens slot fillers uses matching algorithm pair start tokens identify actual slot fillers 
requiring mention learning information extraction text categorization rules ilp junker 
rapier whisk srv text specific representations algorithms informed ilp methods logic representation algorithm focused text 
comparisons possible results 
effective approaches learning information extraction rules studied 
approaches shown portions tasks 
tested complete set tasks 
particularly tested slots require ability produce multiple fillers slot 
approach learning hidden markov models freitag mccallum mccallum lafferty 
hmm learning methods tested slots job seminar datasets tasks generally generally difficult srv rapier 
limited locating single string extract applied slots multiple correct fillers 
approach simpler learner develop wrappers accomplishing information extraction structured texts web pages applying boosting freitag kushmerick 
bwi system tested slots seminar announcement job posting tasks applied full job postings task 
applied extraction multiple fillers slot 
results bwi inconclusive positive 
roth yih system snow learn relational representation desirable information extraction task propositional learning mechanisms 
system performs seminar task tested job task fact geared specifically extraction filler slot 
successful approach information extraction task ciravegna 
symbolic rule learner learns rules insert tags text independently proceeding phases initial tag insertion phase contextual rules phase rules dependent presence tags correction phase rules applied adjust placement tags validation phase tags matches removed tags tags vice versa 
system benefits morphological dictionary linguistic evidence 
outperforms existing rapier outperform slots job task indicating room improvement systems 
califf mooney 
ability extract desired pieces information natural language texts important task growing number potential applications 
tasks requiring locating specific data newsgroup messages web pages particularly promising applications 
manually constructing information extraction systems laborious task learning methods potential help automate development process 
rapier system described uses relational learning construct unbounded pattern match rules information extraction database texts filled templates 
learned patterns employ limited syntactic semantic information identify potential slot fillers surrounding context 
results realistic applications demonstrate fairly accurate rules learned relatively small sets examples results superior probabilistic method applied fixed length context 
acknowledgments dayne freitag supplying seminar announcements data 
anonymous reviewers comments earlier drafts 
research supported fellowship awarded author national science foundation iri 
aone bennett 
evaluating automated manual acquisition anaphora resolution strategies 
proceedings rd annual meeting association computational linguistics pages cambridge ma 
bennett aone lovell 
learning tag multilingual texts observation 
proceedings second conference empirical methods natural language processing pages providence ri 
birnbaum collins editors 
proceedings eighth international workshop machine learning part vi learning relations evanston il june 
eric brill 
advances rule part speech tagging 
proceedings twelfth national conference artificial intelligence pages seattle wa 
mary elaine califf 
relational learning techniques natural language information extraction 
phd thesis department computer sciences university texas austin tx may 
available www cs utexas edu users ai lab 
cardie 
case knowledge acquisition domain specific sentence analysis 
proceedings eleventh national conference artificial intelligence pages washington dc 
eugene charniak 
statistical language learning 
mit press 
learning information extraction fabio ciravegna 
adaptive information extraction text rule induction generalisation 
proceedings seventeenth international joint conference artificial intelligence pages seattle wa 
cohen 
text categorization relational learning 
proceedings twelfth international conference machine learning pages san francisco ca 
morgan kaufman 
william cohen 
fast effective rule induction 
proceedings twelfth international conference machine learning pages san francisco ca 
mark craven 
constructing biological knowledge bases extracting information text sources 
proceedings th international conference intelligent systems molecular biology pages heidelberg germany 
darpa editor 
proceedings fourth darpa message understanding evaluation conference san mateo ca 
morgan kaufman 
darpa editor 
proceedings fifth darpa message understanding evaluation conference san mateo ca 
morgan kaufman 
de raedt bruynooghe 
theory clausal discovery 
proceedings thirteenth international joint conference artificial intelligence pages chambery france 
dayne freitag 
information extraction html application general learning approach 
proceedings fifteenth national conference artificial intelligence pages madison wisconsin 
dayne freitag 
multi strategy learning information extraction 
proceedings fifteenth international conference machine learning pages madison wisconsin 
dayne freitag 
machine learning information extraction informal domains 
machine learning 
dayne freitag nicholas kushmerick 
boosted wrapper induction 
proceedings seventeenth national conference artificial intelligence pages austin tx 
dayne freitag andrew mccallum 
information extraction hmm structures learned stochastic optimization 
proceedings seventeenth national conference artificial intelligence pages austin tx 
chun nan hsu nim dung 
wrapping semistructured web pages finite state transducers 
proceedings conference automated learning discovery pittsburgh pa 
huffman 
learning information extraction patterns examples 
wermter riloff editors connectionist statistical symbolic approaches learning natural language processing pages 
springer berlin 
califf mooney junker sintek 
learning text categorization information extraction ilp 
cussens dzeroski editors learning language logic 
springer 
lecture notes computer artificial intelligence 
jun tae kim dan moldovan 
acquisition linguistic patterns knowledge information extraction 
ieee transactions knowledge data engineering october 
john lafferty andrew mccallum fernando pereira 
conditional random fields probabilistic models segmenting labeling sequence data 
proceedings eighteenth international conference machine learning pages ma 
lavrac dzeroski 
inductive logic programming techniques applications 
ellis horwood 
wendy lehnert beth sundheim 
performance evaluation text analysis technologies 
ai magazine 
magerman 
statistical decision tree models parsing 
proceedings rd annual meeting association computational linguistics pages cambridge ma 
manning schutze 
foundations statistical natural language processing 
mit press cambridge ma 
andrew mccallum dayne freitag fernando pereira 
maximum entropy markov models information extraction segmentation 
proceedings seventeenth international conference machine learning pages ma 
michalski 
theory methodology inductive learning 
artificial intelligence 
miller beckwith fellbaum gross miller 
wordnet line lexical database 
available ftp clarity princeton edu 
scott miller david stallard robert bobrow richard schwartz 
fully statistical approach natural language interfaces 
proceedings th annual meeting association computational linguistics pages santa cruz ca 
mooney califf 
induction order decision lists results learning past tense english verbs 
journal artificial intelligence research 
muggleton 
duce oracle approach constructive induction 
proceedings tenth international joint conference artificial intelligence pages milan italy aug 
muggleton buntine 
machine invention order predicates inverting resolution 
proceedings fifth international conference machine learning pages ann arbor mi june 
learning information extraction muggleton feng 
efficient induction logic programs 
muggleton editor inductive logic programming pages 
academic press new york 
muggleton king sternberg 
protein secondary structure prediction logic machine learning 
protein engineering 
muggleton editor 
inductive logic programming 
academic press new york ny 
steve muggleton 
inverse entailment progol 
new generation computing journal 
ion muslea steve minton craig knoblock 
wrapper induction semistructured web information sources 
proceedings conference automated learning discovery pittsburgh pa 
ng lee 
integrating multiple knowledge sources disambiguate word sense exemplar approach 
proceedings th annual meeting association computational linguistics pages santa cruz ca 
pazzani brunk silverstein 
information approach integrating empirical explanation learning 
muggleton editor inductive logic programming pages 
academic press new york 
plotkin 
note inductive generalization 
meltzer michie editors machine intelligence vol 

elsevier north holland new york 
quinlan 
induction decision trees 
machine learning 
quinlan 
learning logical definitions relations 
machine learning 
adwait ratnaparkhi 
linear observed time statistical parser maximum entropy models 
proceedings second conference empirical methods natural language processing pages providence ri 
ray craven 
representing sentence structure hidden markov models information extraction 
proceedings seventeenth international joint conference artificial intelligence pages seattle wa 
riloff 
automatically constructing dictionary information extraction tasks 
proceedings eleventh national conference artificial intelligence pages washington 
dan roth yih 
relational learning propositional algorithms information extraction case study 
proceedings seventeenth international joint conference artificial intelligence pages seattle wa 
sean slattery mark craven 
learning exploit document relationships structure case relational learning web 
proceedings conference automated learning discovery pittsburgh pa 
califf mooney frank smadja kathleen mckeown vasileios hatzivassiloglou 
translating collocations bilingual lexicons statistical approach 
computational linguistics 
stephen soderland 
learning information extraction rules semi structured free text 
machine learning 
stephen soderland fisher lehnert 
crystal inducing conceptual dictionary 
proceedings fourteenth international joint conference artificial intelligence pages montreal quebec 
srinivasan muggleton sternberg king 
theories mutagenicity study order feature induction 
artificial intelligence 
weizenbaum 
eliza computer program study natural language communications men machines 
communications association computing machinery 
wermter riloff editors 
connectionist statistical symbolic approaches learning natural language processing 
springer verlag berlin 
yiming yang jan pederson 
comparative study feature selection text categorization 
proceedings fourteenth international conference machine learning pages nashville tn 
zelle mooney 
combining top bottom methods inductive logic programming 
proceedings eleventh international conference machine learning pages new brunswick nj july 
zelle thompson califf mooney 
inducing logic programs explicit negative examples 
proceedings fifth international workshop inductive logic programming pages leuven belgium 

