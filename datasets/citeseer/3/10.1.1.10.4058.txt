journal machine learning research submitted published online choice active learning algorithms yoram baram baram cs technion ac il ran el yaniv cs technion ac il luz cs technion ac il department computer science technion israel institute technology haifa israel editor manfred warmuth concerned question combine online ensemble active learners expedite learning progress pool active learning 
develop active learning master algorithm known competitive algorithm bandit problem 
major challenge successfully choosing top performing active learners online reliably estimate progress learning session 
propose simple maximum entropy criterion provides effective estimates realistic settings 
study performance proposed master algorithm ensemble containing best known active learning algorithms new algorithm 
resulting active learning master algorithm empirically shown consistently perform outperform best algorithm ensemble range classification problems 
keywords active learning kernel machines online learning multi armed bandit entropy maximization 
goal active learning design analyze learning algorithms effectively choose samples ask teacher label 
incentive active learning mainly expedite learning process reduce labeling efforts required teacher 
lack theoretical understanding active learning particular generalization power computationally practical active learning algorithms understood substantial empirical evidence active learning dramatically expedite learning process 
focus pool active learning classifiers viewed game composed trials 
learner fixed pool unlabeled instances 
trial learner chooses instance pool labeled teacher 

noise free settings query committee qbc algorithm freund 
provably provide exponential speedups learning rate random selection 
time practically efficient implementation technique reach see example bachrach 
yoram baram ran el yaniv luz 
baram el yaniv luz teacher provides learner true label instance learner induces new classifier labeled samples seen far possibly unlabeled instances pool 
new trial begins variants problem considered 
important variants stream active learning freund learning membership queries angluin see section details :10.1.1.20.8521
consider variants 
seeking top performing active learning algorithms numerous algorithms proposed literature algorithms appear best performers empirical studies 
algorithm relies kernel machines independently proposed research groups tong koller schohn cohn campbell 
algorithm called simple tong koller uses current svm classifier query instance closest decision hyperplane kernel space 
theoretical motivation simple developed tong koller terms version space bisection 
second algorithm consider proposed roy mccallum different motivation algorithm chooses example labeled attempting reduce generalization error probability 
true error rates unknown learner attempts estimate self confidence heuristic utilizes current classifier probability measurements 
call algorithm self conf 
original self conf proposed roy mccallum bases probability estimates classification naive bayes calculations shown significantly outperform known active learning algorithms text categorization tasks 
studies svm variant self conf appears stronger original 
empirical studies conducted reveal simple self conf consistent winner problems 
algorithms exhibit severe pitfall appear learning problems xor structure see section 
single active learning algorithm expected consistently perform better problems problems clearly favor particular algorithms 
situation motivates online learning approach attempts utilize ensemble algorithms online aiming achieve performance close best algorithm hindsight 
scheme extensively studied computational learning theory mainly context online prediction expert advice see example bianchi 
main contribution algorithm actively learns combining active learners 
reasonable approach combining ensemble active learning algorithms experts evaluate individual performance dynamically switch best performer far 
obstacles stand way successfully implementing scheme 
standard classifier evaluation techniques cross validation leave bootstrap tend fail estimate performance active learner labeled examples chosen learner 
reason set labeled instances selected active learner tends acutely biased hard instances reflect true underlying distribution 
section show example phenomenon 
second overcome problem time choose utilize certain expert get see label example chosen online choice active learning algorithms expert observe consequence choices corresponding experts wasting labeled examples 
overcome obstacles ideas 
standard statistical techniques cross validation novel maximum entropy semi supervised criterion utilizes pool unlabeled samples faithfully evaluate relative progress various experts second cast problem instance multi armed bandit problem expert corresponds slot machine trial allowed play machine choose algorithm generate query 
utilize known online multi armed bandit algorithm proposed auer 

algorithm enjoys strong performance guarantees statistical assumptions 
extensive empirical study new active learning master algorithm compare performance ensemble members consisting algorithms simple self conf novel active learning heuristic furthest traversals hochbaum shmoys 
master algorithm shown consistently perform best algorithm ensemble problems outperforms best algorithm 

active learning section define pool active learning discuss performance measures active learners 
consider binary classification problem pool 
xn unlabeled instances xi vector space instances assumed distributed unknown fixed distribution 
instance xi label yi case distributed unknown conditional distribution 
start labels known learner 
stage active learning game set labeled instances known learner 
active learner consists classifier learning algorithm querying function mapping querying function determines unlabeled instance labeled teacher 
trial active learner applies choose unlabeled instance label revealed pair added removed learner applies induce new classifier ct possibly training set new trial begins active learner generates sequence classifiers 
clearly maximal number trials initial size focus active learners svm induction algorithm 
best knowledge literature consensus appropriate performance measures active learning 
number performance measures algorithms sense 
example authors instance tong koller test accuracy achieved active learner predetermined number learning trials 
authors example schohn cohn campbell roy mccallum simply show active learning curves visually demonstrate advantages learning speed :10.1.1.28.9963
propose natural performance measure aims quantify deficiency querying function respect random 
assume initially contains examples class 
baram el yaniv luz definition active learner deficiency 
alg maximal achievable accuracy 
acct active average accuracy achieved hypothetical active learner active 
acct alg average accuracy achieved passive learner alg queries randomly uniformly pool 
case active learning curve passive learning curve deficiency defined equation ratio areas sampling pool corresponds standard passive learning fixed inductive learning algorithm alg 
fix particular classification problem 
random pool instances 
acct alg true average accuracy achievable alg training set size randomly uniformly chosen hypothetical acct alg depicted lower learning curve 
active active learning algorithm uses alg inductive learning component define acct active average accuracy achieved active active learning trials starting pool see hypothetical acct active depicted higher learning curve 
deficiency active defined defn active alg acct active alg 
acct alg words deficiency simply ratio areas depicted 
measure captures global performance active learner learning session 
notice numerator simply area maximal achievable accuracy alg entire pool learning curve active learning algorithm area 
denominator area maximal accuracy learning curve passive algorithm sum areas 
purpose denominator normalize measure problem independent 
measure non negative smaller values 
cases see example schohn cohn better accuracy achieved early stopping see section 
online choice active learning algorithms indicate efficient active learning 
defn active desired property sufficiently large alg achieves maximal accuracy classifier defn active defn active 

related consider utilization ensemble active learners 
discuss selected results related 
main focus techniques devising querying functions methods evaluate progress active learner 
note general method estimating value unlabeled point construct querying function method evaluates gain newly acquired labeled point estimator active learner progress 
presentation various techniques construct querying functions 
focuses pool active learning number interesting relevant ideas appear active learning frameworks 
addition active learning setting introduced section consider settings stream active learning see example freund learner provided stream unlabeled points :10.1.1.20.8521
trial new unlabeled point drawn introduced learner decide request label 
note stream model viewed online version pool model 
active learning membership queries angluin called selective sampling trial learner constructs point input space requests label 
model viewed pool game pool consists possible points domain 
stream setting seung 
query committee qbc algorithm 
algorithm seminal theoretical result stating halving version space query generalization error decreases exponentially relative random active learning 
approximately bisect version space proposed method randomly samples version space induces number classifiers 
label stream point requested voting classifiers point label results tie 
main obstacle implementing strategy sampling version space 
currently known efficiently sample version spaces uniformly random hypothesis classes interest see discussions bachrach herbrich 
variation qbc algorithm proposed mccallum nigam 
expectation maximization em create committee classifiers implement querying function qbc voting idea diversified committee classifiers created sampling population naive bayes distributions 
em procedure iteratively classify unlabelled data rebuild classifiers process converges 
experimental results show algorithm advantage random sampling qbc 

qbc comparison utilizes committee created sampling naive bayes distributions employing em procedure 
baram el yaniv luz interesting ideas considered learning membership queries setting angluin 
cohn 
version space reduction strategy 
distant hypotheses selected version space finding specific concept classifies negative domain possible general classifies positive points possible 
selective sampling done randomly searching domain point specific general hypotheses disagree 
method ensures version space size reduced query reduced hypothesis 
algorithm implemented hypothesis class consisting feed forward neural networks trained backpropagation algorithm 
authors method works simple concepts 
selective sampling model lindenbaum 
propose algorithm nearest neighbor classifier 
proposes random field model estimate class probabilities 
class probabilities unlabeled examples utility function training set defined 
querying function algorithm constructed game tree models game learner teacher 
unlabeled example expected utility measured utility function training set expected probabilities possible classes unlabeled example 
set domain points constructed randomly example highest expected utility chosen 
algorithm suffers extensive time complexity depends depth game tree number near examples taken construct random field 
pool setting independent working groups schohn cohn campbell tong koller propose querying function active learners support vector machines svms 
querying function chooses query unlabeled point closest decision hyperplane kernel space point smallest margin 
theoretical motivation function terms version space reduction lines qbc ideas tong koller see section details 
experimental results papers show resulting active learner provide significant sample complexity speedups compared random sampling 
schohn cohn encountered phenomenon true accuracy learner decreases reaching certain peak active session progresses 
phenomenon motivates idea early stopping authors suggest querying example lies svm margin 
campbell 
offer stopping criterion trigger running test current classifier 
test randomly uniformly choose small subsample unlabeled pool points request labels points teacher test current classifier points 
algorithm decides error estimated test satisfying user defined threshold 
zhang oles analyze value unlabeled data active transductive learning settings focusing svm learning 
value unlabeled data evaluated fisher information matrices 
proved selecting unlabeled data low confidence small margin subsumed close previous choices 
specific resp 
general concept classifying unlabeled examples negative resp 
positive 
online choice active learning algorithms cause large change model true label known 
numerical examples show svm active learner criterion superior random selection 
roy mccallum offer pool active learning algorithm attempts directly optimize true generalization error rate reduce version space 
algorithm chooses query points strengthen belief current classifier pool classification 
learner estimates error unlabeled pool current classifier posterior class probabilities taken proxies true ones 
example pool possible label expected loss classifier trained adding example training set calculated 
example pool lowest total expected loss chosen query 
computational complexity required implement scheme hopelessly impractical noted authors 
various heuristic approximations optimizations suggested 
optimizations example subsampling general designed specific implementation provided roy mccallum naive bayes 
authors report resulting active learner exhibits excellent performance text categorization problems 
section elaborate pool algorithms mentioned 
active learning explored contexts regression probabilistic estimation 
provost examine active learning class probability estimation contrast exact hard classification 
algorithm proposed creating number subsamples training set training soft classifier capable giving class probability estimates subsample 
generated classifiers form ensemble 
querying function works drawing pool point probability distribution proportional variance probability estimates computed various ensemble members 
variance normalized average probability minority class 
empirical results indicate algorithm performs better random sampling soft hard classifier 
context regression cohn 
assume learner approximately unbiased propose active learning algorithm chooses query instance minimizes average expected variance learner integrated input domain 
algorithm outlined general feed forward neural networks mixture gaussians locally weighted regression 
learning schemes method efficient 
method ignores learner bias 
algorithm requires closed form calculation learner variance developed learning schemes considered 
context ensemble methods regression krogh vedelsby show nice equality giving squared error loss regression generalization error weighted sum generalization errors individual members minus diversity measure called ambiguity related anti correlation ensemble members 
increasing ambiguity increasing weighted sum individual errors reduce error 
increasing ambiguity done dividing training set number 
implementation algorithm discussed section uses svms naive bayes utilizes subsampling approximation idea suggested roy mccallum 
baram el yaniv luz disjoint subsets training ensemble member distinct training subset 
nice property ambiguity measure computed labels 
krogh vedelsby apply relation guarantees weighted ambiguity lower bound weighted sum individual ensemble generalization errors context pool active learning follows 
assuming beneficial pool point sample increases weighted sum individual ensemble errors search point contribution ensemble ambiguity maximal 
turn discuss approaches measuring value labeled points 
methods potentially useful obtaining information progress active learners may useful implementing approach combines ensemble active learners 
bayesian setting mackay attempts measure information gained unknown target hypothesis new labeled point 
gain measures considered shannon entropy 
assumed training set probability distribution possible hypotheses defined 
measure entropy hypothesis distribution decreased new labeled point 
decrease entropy indicate support hypothesis distribution shrinks 
second measure cross entropy hypothesis distributions new labeled point added 
increase cross entropy indicate support changed due new information 
proved gain measures equivalent sense expectations equal 
guyon 
propose methods measure information gain labeled points data set 
information gain labeled point respect trained probabilistic soft classifier defined probability classification point correct 
probability equals shannon information gain class probability point measured probabilistic classifier 
labeled data set information gain point measured definition leave estimator 
addresses information gain labeled points context minimax learning algorithms svm 
svm measures information gain labeled point alpha coefficient induced weights vector 
coefficient point support vector zero information gain 
support vectors larger coefficients informative 
ideas discussed context data cleaning large databases 
note context svm active learning general case support vectors identified early trials remain support vectors 
note active learning way exploiting availability unlabeled data 
years broader topic semi supervised learning labeled unlabeled examples gaining popularity 
distinguish inductive semi supervised methods transductive ones vapnik see survey seeger review 

active learning algorithms main purpose section motivate challenge considered 
contrast may implied various papers field closely online choice active learning algorithms examining state art active learning algorithms various learning problems consistent single winner 
necessarily surprising remains unclear choose best active learning algorithm problem hand 
demonstrate point focus known active learning algorithms simple tong koller schohn cohn campbell algorithm roy mccallum call self conf 
selected algorithms reasonably motivated achieve high performance real world data surpass various known algorithms appear complement 
particular show algorithm consistently tops 
algorithms fail learning problems xor structures sense perform considerably worse random sampling 
consider novel algorithm excels xor problems exhibits quite poor performance problems simple structures 
altogether algorithms form ensemble new master algorithm experimentally applied section 
rest assume basic familiarity svms 
algorithm simple algorithm uses svm induction component 
querying function simple trial uses induced classifier ct choose unlabeled instance closest decision boundary ct 
querying function computed time linear assuming number support vectors constant 
intuitive interpretation simple chooses query instance label certain current classifier 
formal theoretical motivation simple tong koller terms version space bisection 
argument utilizes nice duality instances hypotheses 
version space mitchell defined set hypotheses consistent training set 

xm ym training set set hypotheses case set hyperplanes kernel space 
version space defined 
hyperplane constructed kernel space training svm entire pool true labeling clearly computed active learner querying entire pool 
strategy active learner choose query bisects version space brings faster question find instance approximately bisects version space 
version space viewed subsurface unit hypersphere parameter space entire surface contains possible hypotheses 
unlabeled instance corresponds hyperplane parameter space 
hypotheses classify positively lie side hyperplane hypotheses classify negatively lie side 
hyperplane constructed kernel space training svm 
best knowledge previous attempts compare algorithms conducted 

deficiency simple observed tong koller 

textbooks subject written cristianini shawe taylor sch lkopf smola 
baram el yaniv luz current set labeled instances 
tong koller show center largest hypersphere placed version space surface intersect hyperplanes corresponding labeled instances 
radius hypersphere margin hyperplanes touch hypersphere corresponding support vectors 
cases hypersphere sufficiently approximates version space approximates center mass version space 
closer unlabeled instance closer hyperplane center mass version space 
motivates strategy querying closest instance bisect version space quickly advance algorithm unknown target hypothesis tong koller require classifiers svms computed operation simple consistent training set 
essential guarantee non vacuous version space 
requirement easy fulfil kernel trick discussed shaw taylor guarantees training set linearly separable kernel space 
details specified appendix considering simple binary classification problems strategy provides rapid refinement decision boundary results effective active learning tong koller schohn cohn campbell 
experience algorithm simple high performance active learning algorithm hard beat wide range real world problems 
particular algorithm performs quite text categorization problems tong koller 
note querying functions called maxmin proposed tong koller 
version space bisection principle achieve efficient version space reduction simple 
main drawback functions computational intensity impractical 
specifically query computation functions requires induction svms unlabeled point pool 
algorithm self conf second algorithm discuss proposed roy mccallum different motivation 
algorithm chooses example labeled directly attempting reduce generalization error probability 
true error rates unknown learner attempts estimate self confidence heuristic utilizes current classifier probability measurements 
call algorithm self conf 
start trial algorithm holds trained probabilistic soft classifier denoted 
algorithm trains new classifier estimates resulting self estimated expected log 
approximation heuristics subsampling pool incremental decremental svm algorithms poggio speed algorithms 
explored possibilities 

self confidence approach somewhat similar proposed lindenbaum 

loss defined online choice active learning algorithms log 
calculates self estimated average expected loss 
lowest self estimated expected loss chosen queried 
original self conf algorithm proposed roy mccallum bases probability estimates classification naive bayes calculations shown outperform known active learning algorithms text categorization tasks 
studies svm variant self conf appears stronger original naive bayes algorithm 
case probabilistic estimates obtained standard way logistic regression 
note algorithm extremely inefficient query svms induced unlabeled point pool 
various optimizations approximations proposed roy mccallum running time practically feasible 
methods random subsampling implementation algorithm trial estimate expression random subset subsample active session trial contains points subsequent trial decrement subsample size point reach minimum points keep remaining trials 
observe motivation self conf simple sense complementary 
simple queries instances confidence measured current model self conf queries instances provide maximal current model 
algorithm kernel farthest kff propose simple active learning heuristic farthest traversal sequences kernel space 
farthest ff sequences previously computing provably approximate optimal clustering center problems hochbaum shmoys 
ff traversal points data set defined follows 
start point find farthest point find farthest point distance point set defined minimum distance point set metric space ff traversals computing approximation solutions center clustering problem seeks optimal clustering data optimality measured maximum diameter clusters 
particular elements ff traversal centroids assigning 
roy mccallum considered zero loss log loss 

empirical results roy mccallum considered multinomial models particular text categorization enabled required calculations 

performed extensive comparison naive bayes svm variants algorithm 

confidence rated svm value point label take exp yh baram el yaniv luz point closest centroid obtains clustering cost factor optimal hochbaum shmoys 
ff traversals active learning way 
current set labeled instances choose query instance farthest training set active learner induces classifier 
heuristic nice intuitive appeal context instance query farthest sense dissimilar instance pool observed 
simple algorithms querying function classifier ff querying function applied classifier learning algorithm 
apply svm 
compatibility svm compute ff traversals kernel space follows 
kernel instances input space embedding kernel space measure dk distance kernel space 
call resulting algorithm kff 
examples shows learning curves simple self conf kff random sampling active learner call rand artificial xor problem top left uci problems twonorm 
learning problems demonstrate active learning algorithms discussed consistently better rest 
uci problems simple performs better self conf twonorm data set self conf performs better simple data set 
kff inferior cases 
xor problem simple self conf performances significantly worse random sampling 
hand kff clearly shows active learning expedite learning problem 
weakness simple self conf typically occurs confronting problems xor structure 
kff relative simple self conf rand typically occurs learning problems simple structure 
main advantage considering kff ensemble algorithms 
master active algorithm benefits kff xor problems significant compromises problems kff weaker 

multi armed bandit mab problem major ingredient online learning approach active learning known competitive algorithm multi armed bandit problem 
section problem connection online choice active learners particular multi armed bandit algorithm 
multi armed bandit mab problem gambler choose slot machines play sequence trials 
machine yield rewards distribution unknown gambler gambler goal maximize total reward sequence 
classic problem represents fundamental 
querying function rand chooses example labeled uniformly random true accuracy self conf simple kff online choice active learning algorithms rand training set size test accuracy test accuracy kff xor problem simple rand self conf training set size simple kff twonorm rand self conf training set size top left xor problem consisting points cluster points form pool rest form test set 
top right learning curves simple self conf kff rand xor problem kff exhibits superior performance 
bottom left learning curves learners data set self conf superior 
bottom right learning curves learners twonorm data set simple superior 
point learning curve represents average folds measured test set error bar represents standard error mean 
error bars diluted enhance visibility 
essence tradeoff exploration exploitation sticking single machine may prevent discovering better machine hand continually seeking better machine prevent achieving best total reward 
straightforward analogy problem online combining ensemble active learners mab problem 
active learning algorithms ensemble slot machines 
trial choosing query generated active learning algorithm corresponds choosing slot machine 
true generalization accuracy achieved combined algorithm augmented training baram el yaniv luz set includes newly queried data point corresponds gain achieved chosen machine 
course rough analogy immediately provide solution combining active learners 
particular main obstacles mab algorithms combining active learners define reward query 
optimal reward true accuracy achieved learner augmented training set accuracy unknown 
estimate way 
reward estimation technique developed section 
rest section assume non negative bounded reward function 
known mab algorithms analyses assume rewards distributed certain statistical models 
typically simple statistical models including independence time invariance assumptions taken example gaussian rewards 
active learning context example analogy overly simplistic statistical assumptions reward distributions violated 
particularly useful active learning context adversarial mab results auer 
provide mab algorithms guaranteed extract total gain close best slot machine hindsight statistical assumptions 
particular mab algorithms developed auer 
potentially useful implementing online choice active learners 
algorithm called exp see section auer directly matches analogy :10.1.1.130.158
second algorithm called exp see section auer appears suitable purposes see :10.1.1.130.158
describe exp algorithm describe exp algorithm chosen 
exp algorithm standard mab game slot machines played 
trial slot machine 
chosen played yielding reward gi gi non negative bounded 
game consisting trials define gmax max gi expected reward best slot machine hindsight 
goal online player game achieve reward close possible gmax 
expected reward algorithm 
regret exp defined gmax 
upper bound gmax guaranteed auer regret exp bounded gmax gn ln bound holds assignment rewards number trials note bound holds rewards range :10.1.1.130.158
algorithm rewards range see section 
problem providing upper bound gmax solved standard doubling algorithm guesses bound runs exp algorithm bound reached 
reached guessed bound doubled exp restarted new bound 
guaranteed bound regret algorithm gmax exp ln ln exp expected reward doubling algorithm 
bound holds reward function number trials 
combining active learners exp done manner 
active learning algorithms ensemble modelled slot machine 
online choice active learning algorithms trial active learner chosen provide query 
reward query associated chosen learner 
modeling approach points considered exp active learner slot machine black box 
approach directly utilize useful information unlabeled points may provided active learners 
algorithm auer 
called exp designed deal sophisticated mab variant standard mab game 
goal combine utilize number strategies experts giving advice play slot machines 
employ exp context associate experts ensemble active learning algorithms 
slot machines associated unlabeled instances pool approach modeling active learning considerable benefit choice query directly opinions ensemble members 
algorithm exp operates follows 
trial expert 
provides weighting bj 
bj bj represents confidence probability expert playing ith machine 
trial denoting vector rewards machines trial 
gn gi non negative bounded expected reward expert trial bj 
note mab game reward revealed online player player chooses machine trial game consisting trials define gmax max bj expected reward best expert hindsight 
goal online player game utilize advice experts achieve reward close possible gmax 
expected reward algorithm 
upper bound gmax regret exp defined gmax bounded gmax gn ln regret bound holds number trials provided experts ensemble uniform expert provides uniform confidence vector slot machines 
problem providing upper bound gmax solved employing guess double technique exp 
guaranteed bound regret algorithm gmax exp ln ln exp expected reward doubling algorithm 
mentioned exp active learning modeling active learning algorithms experts unlabeled pool points slot machines 
note performance bound exp hold include rand pool active learners corresponds uniform expert 
modeling requires expert advice vectors probabilistic recommendations points required algorithm ensemble provide rating entire pool trial 

alternative possibility modeling pool samples slot machines clearly misses exploitation dimension problem choose sample utilize 
addition clear utilize ensemble learners approach 
baram el yaniv luz practice algorithms consider naturally provide ratings discussed section 
classification entropy maximization order utilize mab algorithm exp see section context need receive trial gain instance chosen queried corresponding slot machine 
ultimate reward context true accuracy classifier resulting training label quantity available 
outset may appear standard error accuracy estimation methods useful 
entirely case sufficiently large standard methods cross validation leave provide substantially biased estimates active learner performance 
fact pointed schohn cohn result biased sample acquired active learner 
order progress quickly learner focus hard informative samples 
consider left 
shows leave loo estimates active learning algorithms simple self conf kff rand uci ringnorm data set 
training set size point curve generated loo estimate currently available labeled set middle see true accuracy algorithms estimated independent test set 
loo severely fail estimate true accuracy fails order algorithms relative success active learners 
unfortunate behavior quite typical loo data sets standard error estimation techniques including cross validation 
techniques avoided general receiving feedback relative progress active learners especially cares active learner performance small number labeled points 
loo accuracy estimation kff rand ringnorm loo simple self conf training set size true accuracy simple ringnorm test accuracy self conf kff rand training set size pool entropy cem ringnorm cem self conf simple kff rand training set size left loo estimates active learning sessions simple self conf rand kff ringnorm data set middle true accuracy algorithms estimated test set right cem entropy scores algorithms 
estimates averages folds 
error bars diluted reduce clutter represent standard error mean 
online choice active learning algorithms propose semi supervised estimator call classification entropy maximization cem 
define cem score classifier respect unlabeled set points binary entropy classification induces unlabeled set 
specifically binary classifier giving values positively negatively classified subsets unlabeled set respectively determined cem score respect binary entropy 
difficult see cem score larger division pool classification classes balanced 
right provides cem curves active learners discussed 
clearly cem measure orders algorithms accordance true accuracy depicted middle ignore scales cem curves example appear surprisingly similar corresponding true accuracy curves 
behavior cem typical empirical examinations somewhat surprisingly cem succeeds correctly evaluating performance positive negative priors balanced 
comprehensive discussion analysis cem criterion provided section 
interesting note cem criterion useful svm model selection semi supervised learning settings labeled training set small set unlabeled points available 
appendix empirical comparison cem loo setting 

combining active learners online section describe master algorithm combining active learners 
combination algorithm called short comb exp multi armed bandit mab algorithm discussed section cem criterion section 
provide annotated pseudocode comb 
algorithm utilizes ensemble active learning algorithms tracks online best algorithm ensemble 
steps code adapted exp mab algorithm auer 
particular steps 
refer reader auer 
detailed exposition proof performance guarantee exp 
elaborate steps require explanation remaining steps self explanatory 
steps compute advice probability vectors active learners required original exp algorithm 
algorithm ensemble provides step scoring vector rates point pool practice algorithms consider naturally provide ratings simple uses kernel distance decision hyperplane self conf uses expected loss kff uses kernel distance current training set 
scale scoring vectors step scaling parameter gibbs probability function exp 
experiments sensitivity analysis parameter provided section 
step producing step advice probability vectors active learners project pool high probability candidate instances 
projected 
binary entropy bernoulli random variable bias log log 
baram el yaniv luz algorithm comb input pool 
xn ii ensemble active learners iii initial training set parameters probability threshold ii probability scaling factor iii bound gmax maximal reward init initialize expert weights wj 


receive advice scoring vectors 

ej 
score ith point pool 
scores normalized lie 


compute advice probability vector 
bj scaling advice scoring vectors 


bj probability vector 
exp ej normalizes 
extract effective pool ue thresholding low probability points point xi leave xi ue iff maxj 
ue reconstruct set ne ue 

set ne ln gmax 
set wj 
ne set pi 
randomly draw point xq ue 

ne 

receive label yq xq teacher update training set pool lt lt xq yq ut ut xq 
train classifier ct lt 
ct classify points calculate ht ht entropy resulting partition cem score see section 

calculate reward utility xq xq ht ht 


set ri xq pq ri 

reward punish experts wj wj exp ne 
algorithm comb pool denoted ue 
projection controlled parameter instance remains ue active learner assigns probability mass greater 
experiments described sensitivity analysis parameter provided section 
step learner chooses unlabeled point xq ue query 
exp choice random distribution computed step 
practice experiments described section greedily picked online choice active learning algorithms point largest probability case ties randomly chose points 
deterministic implementation useful reducing additional variance introduced random choices 
step calculate utility query 
utility defined convex function entropic reward calculated step cem score discussed section 
utility function essentially difference ht ht ht entropy partition generated queried instance training set 
ht entropy partition pool generated queried instance 
clearly function emphasizes entropy changes upper range possible entropy values 
rationale utility function substantially harder improve cem scores accuracy large 
additional transformation normalizes utility 
reward bound parameter gmax setting optimal value step eliminated experiments standard guess double technique 
particular operate comb algorithm rounds round set reward limit gr ne ln restart comb algorithm gmax gr 
round continues maximal reward reached ensemble algorithms exceeds gr ne details reader referred discussion exp algorithm section auer 


empirical evaluation comb algorithm evaluated performance comb algorithm entire benchmark collection selected tsch 
consisting binary classification problems extracted uci repository 
problems collection includes fixed folds consisting fixed training test partition 
set particularly convenient allows easier experimental replication 
collection added artificial xor problem see section 
essential characteristics data sets appear table 
problem specify size dimension bias proportion largest class maximal accuracy achieved entire pool training set rounded number instances required worst learner ensemble achieve maximal accuracy average fraction support vectors entire pool size utilized svm trained entire pool average computed folds 
experiments described active learner provided initial examples class learning problem 
examples randomly chosen possible pairs 
initial training set pair learners 
active learning algorithms applied experiments svm rbf 
experimented random query choices prescribed exp 
slight advantage deterministic variant algorithm observed 

data sets collection image splice include folds 

xor data set consisting points constructed folds randomly uniformly splitting data training test partitions 
baram el yaniv luz kernel learning component 
particular implementation details essential replication appendix test accuracy test accuracy waveform simple comb kff self conf training set size self conf comb simple kff image training set size true accuracy true accuracy comb simple xor kff self conf training set size comb kff self conf flare solar simple training set size learning curves comb ensemble members data sets 
estimates averages folds 
error bars diluted reduce clutter represent standard error mean 
top left waveform data set comb performs winner simple 
top right xor data set comb performs better winner kff 
bottom left image data set comb performs winner self conf 
bottom right flare solar data set comb winner significantly beats ensemble members 
depict learning curves comb ensemble members obtained data sets 
notice data sets different ensemble member winner 
image data set self conf xor data set kff waveform data set simple 
cases comb tracks 
waveform data set accuracy decreases certain point 
noise data may benefit stopping early 
see discussion phenomenon schohn cohn 
online choice active learning algorithms winner 
fourth data set flare solar data set comb winner significantly beats ensemble members 
data set size dim bias max acc 
sv proportion sample size banana breast cancer flare solar german heart image ringnorm splice thyroid titanic twonorm waveform xor table data sets essential characteristics 
problem provide size dimension bias proportion largest class maximal accuracy achieved entire pool rounded number instances required worst learner ensemble achieve maximal accuracy average fraction number support vectors pool size utilized svm trained entire pool average computed folds 
data set simple kff self conf comb banana breast cancer flare solar german heart image ringnorm splice thyroid titanic twonorm waveform xor table average deficiency standard error mean achieved comb ensemble members 
data set winner appears boldface marked star 
runner appears boldface 
baram el yaniv luz table shows average deficiency comb ensemble members data sets 
recall definition deficiency active learner equation smaller values represent larger active learning efficiency 
averages calculated corresponding folds 
evident ensemble algorithms consistently sets self conf simple kff win cases respectively 
self conf dominant algorithm winning half data sets 
cases kff performs poorly inferior rand 
algorithm significantly worse algorithms 
noted kff usually excels xor problems example banana flare solar xor 
cases comb winner close runner 
cases flare solar german splice titanic xor comb winner 
striking feature comb suffer presence kff ensemble cases algorithm significantly worse rand clearly benefit kff cases kff excels 
cases heart thyroid breast cancer smallest data sets comb winner runner cases far winner 
behavior reasonable comb needs sufficient number trials exploration sufficient number trials exploitation 
case data set comb completely failed 
closer inspection case revealed entropy criterion failed online choosing best ensemble member 
turn examine possibility standard error estimation techniques cem 
table compare deficiencies comb computing query rewards cem standard fold cross validation cv training set 
cv results obtained running comb algorithm step pseudocode calculate cv current training set lt denote quantity cvt 
step utility function applied cem estimator cv outcome xq cvt cvt 
table indicates cem reliable cv online estimator active learners performance 
cv unreliable performs cases poorly 
particular cem beats cv data sets data sets ringnorm heart example difference quite large 
cv estimator outperforms cem data sets titanic breast cancer difference small 
defined comb algorithm parameters see probability threshold probability scaling factor 
experimental results obtained assignments 
assignments optimized fact priori set values appeared reasonable 
rest section provide sensitivity analysis parameters 
analysis indicates better performance may obtained optimizing parameter 
table show comparison comb performance obtained different values probability threshold parameter determines size effective pool 
training sets size smaller leave loo estimator 
online choice active learning algorithms data set comb cem comb cv banana breast cancer flare solar german heart image ringnorm splice thyroid titanic twonorm waveform xor table comb deficiency operated cem fold cross validation cv computing query rewards 
data set winner appears boldface 
computed step pseudo code 
presentation selected data sets appearing 
recall data sets favors standard value different ensemble member fourth data set flare solar comb significantly beats ensemble members 
applying comb data sets significant difference deficiencies demonstrated comb see table 
result indicates comb overly sensitive choices values range 
data set comb comb comb flare solar image waveform xor table comb deficiency different values probability threshold parameter see 
data set winner appears boldface 
table show comparison comb performance values probability scaling factor parameter see step 
data sets table check sensitivity comb respect parameter recall experiments 
observing deficiency comb operated see performance dependent parameter 
clear value experiments optimized table indicates yields better results 
baram el yaniv luz room improvements pursued 
data set comb comb comb flare solar image waveform xor table comb deficiency different values probability scaling factor parameter see 
data set winner appears boldface 

cem criterion formal connections cem generalization currently unknown informal discussion section provides insights cem attempts characterize conditions effectiveness 
sequence sets 
called inclusion sequence consider inclusion sequence training sets 
sequence training sets generated active learner inclusion sequence initial training set learner 

xm ym binary labeled set samples classes majority empirical proportion size majority class 
consider classifier giving label say classification sc 
xm xm majority biased respect majority class majority class sc proportion sc larger equal st inclusion sequence labeled samples 
say learning algorithm alg majority biased respect classification st classifiers 
ct induced alg majority biased ci induced alg si training set 
main empirical observation learning algorithm majority biased respect inclusion sequence training sets generated learner cem growth rate corresponds growth rate true accuracy case cem criterion compare online performance active learners 
words comparing growth learner pool classification entropy get useful indication growth true accuracy 
consider couple examples demonstrate behavior consider negative example majority bias property hold cem fails 
examples consider setting prior majority class significantly larger class 
left depicts synthetic ring learning problem majority class ring blue circles minority class consists small clusters red squares 
class proportion data set ring majority class 
ran active learners data set 
consider showing pool classification decision boundaries training sets chosen learners online choice active learning algorithms true accuracy simple ring test accuracy kff random self conf training set size pool entropy simple self conf ring cem kff random training set size left synthetic ring problem consisting points circles large ring cluster equally divided small clusters squares cluster points taken uniformly random form pool rest form test set 
middle true accuracy curves active learners kff simple self conf rand ring data set estimated independent test set 
right corresponding pool classification entropies cem values learners 
estimates averages folds 
error bars diluted reduce clutter represent standard error mean 
active learning iterations 
example pool classifications majority biased 
intuitively progress active learner corresponds fast learner discovers small clusters boundaries 
better active learner kff discovered red clusters second best learner simple 
self conf clusters rand 
see clear correspondence pool classification entropy cem true accuracy learners 
fast exploration minority class clusters corresponds fast entropy maximization fast learning generalization 
graphs middle plot true accuracy learners estimated independent test set 
graphs right represent corresponding pool classification entropies cem values 
striking similarity curves exhibited table giving performance active learners queries 
specifically table provides learner proportion majority class training subset consisting samples 
call training proportion 
ii proportion majority class pool classification generated classifier trained samples 
call pool proportion 
iii cem value entropy pool classification 
iv true accuracy estimated independent test set 
usual numbers averages random folds 
baram el yaniv luz kff simple self conf rand decision boundaries generated active learners queries ring example left 
queries darker pool points 
rand simple kff self conf training proportion pool proportion pool classification entropy cem true accuracy table characterization state progress active learners querying samples pool ring data set left 
entry provides mean random folds standard error mean 
example true proportion majority class learners exhibited significantly smaller training proportion example simple sampled equally classes self conf favored minority class 
svms induced minority biased training sets generated online choice active learning algorithms majority biased classification 
particular generated pool proportions larger 
note behavior typical svm inducers learning algorithms 
clearly example shows cem criterion measured pool proportion correctly ranks true accuracy learners 
true accuracy satellites true accuracy self conf simple random kff training set size pool entropy simple random satellites cem self conf kff training set size left satellites data set consisting points circles ring cluster equally divided large round clusters squares cluster points taken randomly form pool rest form test set 
middle true accuracy active learners kff simple self conf rand satellites data set estimated independent test set 
right corresponding pool classification entropies learners 
estimates averages folds 
error bars diluted reduce clutter represent standard error mean 
example shown left 
example viewed inverse ring data set 
data set called satellites data set contains clusters majority class squares small cluster minority class circles 
class proportion data set 
data set satellites rand simple kff self conf training proportion pool proportion pool classification entropy cem true accuracy table characterization state progress active learners querying samples pool satellites data set left 
entry provides mean random folds standard error mean 
previous example shows decision boundaries obtained active learners 
similarly learning curves show true accuracy 
running nearest neighbor bayes point machine kernel perceptron sampling samples pool proportions obtained significantly minority biased 
baram el yaniv luz kff simple self conf rand decision boundaries generated active learners queries satellites example left 
queries darker pool points 
middle cem values right table similar table ring data set 
ring data set pool classifications majority biased 
contrast ring example performance corresponds quickly finding minority clusters example performance correspond quickly finding boundaries single minority cluster 
better active learner simple mapped rapidly areas minority cluster learners 
note rand treats entire minority class points noise 
see clear correspondence pool classification entropy cem true accuracy learners fast exploration minority cluster boundaries corresponds fast entropy maximization fast learning generalization 
true proportion learners exhibited significantly smaller training proportion svms induced online choice active learning algorithms training sets generated majority biased classification 
example shows cem criterion correctly identifies true accuracy learners best learner simple followed self conf kff rand 
example shown left hand side referred concentric rings 
data set consists large small ring clusters small ring cluster 
example considers case learning algorithm svm majority biased respect particular inclusion sequence generated simple querying function 
example increase cem criterion match increase true accuracy 
happens estimated pool entropy point larger true entropy estimated entropy eventually decrease true level generalization accuracy simultaneously improve 
left concentric rings problem consists points points inner ring cluster points small round cluster middle rest big outer ring cluster class consists points inner ring consisting circles class union small round middle cluster outer ring consisting squares points form pool rest form test set 
right decision boundary generated simple queries problem 
queries darker pool points 
right observe simple decision boundary queries 
boundary misclassifies small central cluster favors minority class 
pool classification entropy case larger final entropy 
clearly central cluster discovered entropy decrease true accuracy increase 
note size central isolated cluster related discovery rate larger clusters discovered faster active learner 
example point cluster immediately change pool classification 
example nearest neighbor bayes point machine learning algorithms majority biased 
baram el yaniv luz majority biased 
general motivated example learning algorithm minority biased respect inclusion sequence cem criterion fail sense entropy correspond true accuracy 
summarizing discussion considering experimental results section observe success cem criterion depends properties data set learning algorithm 
appears data sets isolated clusters total proportion small easily allow generation inclusion sequences training sets learning algorithm minority biased 
dependency cem learning algorithm intuitively tied algorithmic stability 
example learning algorithm stable majority biased prefix inclusion sequence training sets stability algorithm prevent generation classifiers minority biased 
speculate success cem context tied algorithmic stability svms see example bousquet elisseeff niyogi 
hand limited experiments stable learning algorithms suggests cem estimates accurate 
go back concentric rings data set svm inclusion sequence training sets produced simple 
reason simple minority biased classification training set include points small isolated cluster belonging majority class training set include points minority class surrounding small cluster 
consequence configuration classifier misclassify majority class small cluster 
problem circumvented including training set point majority class small cluster 
formulating setup bound probability configuration occur due random choice initial training set size standard choice training set size see section 
total number points pool 
number points small cluster majority class 
nmin number points subset points minority class surrounding small cluster 
classifier svm misclassify small cluster resulting training set include point cluster time include points minority class subset induce support vectors guarantee wrong classification small cluster 
zx probability choosing random training set satisfies nmin nmin exp 
online choice active learning algorithms assuming bound smaller solve nmin exp ln nmin ln nmin ln ln ln ln ln 
nmin nmin probability choose random initial training set size bad configuration occur 
particular argument ln smaller sufficient take 
example nmin nmin data 
summary discussion indicates sampling points initial training set provided active learner svms cem criterion fail high confidence 
cem estimator derived information bottleneck framework tishby follows 
random variable representing data target variable information bottleneck method computes partition attempting conserve possible information contains formally seeks mutual information maximized constraint magnitude 
cem estimator derived applying information bottleneck principle target variable data 
context binary classification binary partition non intersecting subsets consistent current training set give higher scores consistent partitions higher information content data 
consider data set size assuming uniform prior samples noting 
partition log log log log log 

fact discovered cem framework 

particular standard applications information bottleneck method forced sufficiently small achieve compression see tishby 
details 

concluding remarks baram el yaniv luz online algorithm effectively combines ensemble active learners 
algorithm successfully utilizes elements statistical learning online adversarial learning 
extensive empirical results strongly indicate algorithm track best algorithm ensemble real world problems 
quite surprisingly algorithm quite outperform best ensemble member 
practitioners significantly benefit new algorithm situations known classification problem hand 
questions require investigation 
experience classification entropy maximization cem semi supervised criterion tracking active learning progress outperforms standard error estimation techniques 
studies overly simple effective criterion may revealing 
interesting examine alternative semi supervised estimators 
farther improvements master algorithm may achieved developing mab bounds depend game duration 
bounds help controlling tradeoff exploration exploitation small data sets 
interesting extend techniques multi valued classification problems binary learning tasks regression 
acknowledgments ron meir ran bachrach useful discussions 
simon tong providing essential information reproducing results tong koller 
el yaniv partially supported technion fund promotion sponsored research 
appendix implementation details appendix provide particular implementation details essential replication 
operated svms kernel correction method discussed shaw taylor guarantees training set linearly separable kernel space required algorithms simple 
specifically done modifying kernel training point xi modified kernel xi xi xi xi positive constant arguments kernel remains 
experiments described took fixed 
rbf kernel parameter 
svm implementation chang lin parameter denoted 
obtain high performance crucial appropriate values 
issue model parameter selection main concern 
assume svm active learners reasonably parameters learners parameters 

value crudely chosen guarantee zero training error test error optimization 

learning problem different values selected fold randomly splitting training set half 
half pool active learner 
half choosing value fixed grid values fold cross validation 
online choice active learning algorithms normalized feature lie recommended chang lin 
standard method eliminate bias term increasing input dimension fixed component 
noisy settings active learners simple tend unstable early stages learning process 
description phenomenon proposed solution described appendix proposed solution buffering labeled examples obtained learner postponing inclusion buffered points training set 
buffer size experiments 
appendix semi supervised svm model selection cem briefly describe numerical examples cem criterion section model selection criterion choosing kernel parameters svm rbf kernel 
consider semi supervised binary classification setting 
small training set example containing instances larger pool unlabeled samples 
goal train svm classifier classification problem hand 
clearly bad parameter assignment svm kernel result poor performance 
kernel parameters course chosen standard methods cross validation leave loo 
show cem criterion slightly better leave cross validation computation time compromises 
emphasize appendix concerns cem criterion discuss active learning 
applied cem loo entire benchmark data set collection tsch 
described table 
experimental design follows 
data sets svm inducer rbf kernel 
relevant parameter kernel determines rbf kernel resolution 
fixed crude feasible set values data sets 
set 
training fold partition fixed train test folds original benchmark set consisting parts 
fold performed procedure 
randomly selected instances designated labeled training part denoting rest instances labels instances kept hidden loo cem clearly cases loo cem see instance 

applied loo cem 
loo means training classifiers classifier trained different examples tested example count success percentage classifiers 
cem means training classifier computing entropy resulting partition respect 
loo cem choose best candidate 
loo means parameter corresponding highest average precision cem parameter corresponding maximal entropy 

kernel correction trick mentioned training sets guaranteed linearly separable feature space need consider soft margin cost parameter 
baram el yaniv luz 
svms winning parameters loo cem trained corresponding classifiers tested 
order get correct perspective performance loo cem computed performance best worst models hindsight 
specifically computed resulting accuracy corresponding svm trained 
results procedure table 
row table corresponds data set accuracy results methods specified svm employing best parameter value obtained loo cem 
note number table average folds standard errors means specified 
striking observation loo cem perform quite 
particular tiny training set estimators achieve performance quite close best possible 
second evident cem outperforms loo 
experiments performed training set sizes show relative advantage cem increases training set size decreases 
training set size increases cem advantage loo eventually disappears 
instance sample size loo reliable slightly outperforms cem 
similar results obtained loo fold cross validation standard values example 
data set best possible worst possible loo cem accuracy accuracy accuracy accuracy banana breast cancer flare solar german heart image ringnorm splice thyroid titanic twonorm waveform averages table average accuracy standard error achieved classification entropy maximization cem leave loo estimators uci problems tsch 

data set winner cem loo appears boldface 
accuracy best worst possible models hindsight 
online choice active learning algorithms appendix active learner performance mentioned tong koller kernel correction method shaw taylor 
correction guarantees linear separability feature space guarantees existence version space 
correction introduce severe classification instability early stages active learning process active learners simple learning noisy data sets 
appendix briefly problem propose simple solution buffering 
kernel correction shaw taylor works adding constant diagonal kernel matrix providing extra additive bias classification training points 
main effect correction training points correctly classified 
correction introduces discontinuities decision boundary 
true accuracy simple twonorm enhanced simple training set size left data set twonorm created projecting uci twonorm data set dimensions 
data set demonstrates unstable general behavior active learners early stages learning session 
right learning curves simple enhanced simple buffering twonorm data set 
consider example left showing projection twonorm data set see details data set table 
shows pool classification training sets generated simple active learner iterations 
decision boundary changes drastically iteration 
note kernel correction enables correct classification training set decision boundaries 
learning curve simple showing true error right 
clearly true accuracy extremely unstable 
propose solution idea buffering classification entropy estimator 
symptoms drastic decision boundary instability described drastic change classification entropy 
observe boundary shifts border clusters middle clusters iterations entropy decreases 
solution propose look change entropy pool training set classification trial 
baram el yaniv luz pool classification training sets points generated simple active learner iterations twonorm data set 
long entropy decreases new examples buffered added training set 
entropy decreased buffered points added training set 
want keep bounded buffer solution introduces new parameter buffer size 
experience small buffer sufficient experiments buffer points 
buffering approach provides effective solution problem 
right see learning curves simple twonorm data set enhancement 
evident learning curve original algorithm unstable 
adding buffering enhancement smoothes learning curve 
shows pool classification training sets generated enhanced simple active learner iterations 
decision boundary change drastically iteration 
online choice active learning algorithms pool classification training sets points generated enhanced simple active learner iterations twonorm data set 
angluin 
queries concept learning 
machine learning 
auer cesa bianchi freund schapire 
bandit problem 
siam journal computing 
bachrach fine shamir 
query committee linear separation random walks 
proceedings euro colt th european conference computational learning theory 
bousquet elisseeff 
stability generalization 
journal machine learning research pages 
baram el yaniv luz campbell cristianini smola 
query learning large margin classifiers 
proceedings icml th international conference machine learning pages 
poggio 
incremental decremental support vector machine learning 
neural information processing systems nips pages 
bianchi freund haussler helmbold schapire warmuth 
expert advice 
journal acm may 
chang lin 
libsvm library support vector machines 
url www csie ntu edu tw cjlin papers libsvm pdf 
cohn atlas ladner 
improving generalization active learning 
machine learning 
cohn ghahramani jordan 
active learning statistical models 
journal artificial intelligence research 
cristianini shawe taylor 
support vector machines 
cambridge university press 
freund seung shamir tishby 
selective sampling query committee algorithm 
machine learning 
guyon matic vapnik 
discovering informative patterns data cleaning 
advances knowledge discovery data mining pages 

url citeseer nj nec com guyon discovering html 
herbrich graepel campbell 
bayes point machines 
journal machine learning research 
url citeseer nj nec com herbrich bayes html 
hochbaum shmoys 
best possible heuristic center problem 
mathematics operations research 
krogh vedelsby 
neural network ensembles cross validation active learning 
tesauro touretzky leen editors advances neural information processing systems volume pages 
mit press 
url citeseer nj nec com krogh neural html 
niyogi 
algorithmic stability generalization error 
technical report tr university chicago 
lindenbaum markovitch 
selective sampling nearest neighbor classifiers 
machine learning 
mackay 
information objective functions active data selection 
neural computation 
url citeseer nj nec com html 
online choice active learning algorithms mccallum nigam 
employing em pool active learning text classification 
proceedings icml th international conference machine learning 
morgan kaufmann publishers 
mitchell 
generalization search 
artificial intelligence 
tsch onoda ller 
soft margins adaboost 
machine learning 
roy mccallum 
optimal active learning sampling estimation error reduction 
proceedings icml th international conference machine learning pages 
provost 
active learning class probability estimation ranking 
url citeseer nj nec com active html 
schohn cohn 
active learning support vector machines 
icml th international conference machine learning pages 
sch lkopf smola 
learning kernels 
mit press 
seeger 
learning labeled unlabeled data 
url citeseer nj nec com seeger learning html 
seung opper sompolinsky 
query committee 
computational learning theory pages 
url citeseer nj nec com seung query html 
shaw taylor 
results margin distribution 
proceedings th annual acm conference computational learning theory colt pages 
shaw taylor 
generalization soft margin algorithms 
ieee transactions information theory 
tishby pereira bialek 
information bottleneck method 
th allerton conference communication computation 
tong koller 
support vector machine active learning applications text classification 
journal machine learning research 
vapnik 
statistical learning theory 
john wiley sons 
zhang oles 
probability analysis value unlabeled data classification problems 
international joint conference machine learning pages 

