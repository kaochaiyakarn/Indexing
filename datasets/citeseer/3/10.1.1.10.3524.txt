ph proposal department computer sciences university texas austin may integrating statistical relational learning semantic parsing applications learning natural language interfaces databases tang department computer sciences university texas taylor hall austin tx rupert cs utexas edu supervising professor dr raymond mooney may development natural language interfaces databases interesting problem natural language processing 
need pronounced widespread access complex databases available internet 
systems difficult build tailored application 
current research topic involves machine learning methods automate development nli 
proposal presents method learning semantic parsers systems mapping natural language logical form integrates logic probabilistic methods order exploit complementary strengths competing approaches 
precisely inductive logic programming ilp method tabulate developed learning multiple models integrated linear weighted combination produce probabilistic models statistical semantic parsing 
initial experimental results different domains suggest integration statistical logical approaches semantic parsing outperform purely logical approach 
research develop integrated approach demonstrate ability improve automated development nli 
semantic parsing refers process mapping natural language input sentence structured meaning representation suitable manipulation machine allen 
example building natural language interface nli commercial database may want map user data request expressed natural language underlying database access language sql 
target query expressed sql case serve meaning representation user request 
choice semantic representation language entirely domain dependent developed semantic representation language expressive handle world possible meaning structures 
semantic parsing difficult problem natural language processing nlp attempts approach necessarily tackle difficult task natural language understanding 
discussion proposal important questions care semantic parsing 
care empirical statistical approaches problem 
semantic parsing interesting problem nlp part interesting nlp applications particularly require translation natural language input specific command 
research semantic parsing focus developing natural language interfaces database querying started woods waltz carries miller stallard bobrow schwartz zelle kuhn de mori 
advent information age applications definitely widen information delivery bottleneck 
online database access natural languages information available users necessarily possess knowledge underlying database access language information lot accessible 
great potential impact utility world wide web information delivered implemented web pages 
success semantic parsing definitely cornerstone development interesting applications 
second resurgence statistical empirical approaches natural language processing late 
success approaches areas speech recognition rabiner bahl jelinek mercer part speech tagging charniak hendrickson jacobson perkowitz syntactic parsing ratnaparkhi manning carpenter charniak collins pereira text discourse segmentation litman evidential 
fact coined revolution nlp community hirschberg 
reasons approaches experienced resurgence success information networking technology large volumes real world corpora text available serve role raw data empirical approach empirical approaches proven successful develop systems satisfy desirable properties nlp application acquisition automatically acquiring knowledge domain specific necessary task coverage handling potentially wide range possibilities arise application robustness accommodating real data building databases emphasized means imply important application semantic parsing 
may perfect having noise able perform reasonably portability easily applicable different task new domain armstrong warwick 
statistical approaches parsing bear mentioned advantages existing methods especially syntactic parsing hand crafted set contextual features probabilistic parsing models built 
chill system zelle represents approach learning relevant contextual information represented relational knowledge task disambiguation complete contexts entire parse state relying features parsing 
original system builds deterministic parser organized decision list parsing action applicable current parse state selected applied 
problem parser parsing action corrupts entire parse meaningful parse possibly constructed 
parsing action wrongly chosen due generalization control rule learned action happens appear right parsing action specialization control rule right parsing action 
overcome robustness problems retain advantages relational learning approach parsing propose build probabilistic framework task integrate inductive logic programming ilp learning method chill statistical learning techniques learning probabilistic semantic parsers 
remainder proposal organized follows 
section provides brief overview research semantic statistical parsing overview chill working parser employed background inductive logic programming brief overview integrating statistical relational methods learning 
section explains new ilp learning algorithm chill learn multiple models 
section describes probabilistic parsing framework multiple learned models ilp algorithm integrated statistical techniques produce probabilistic models learning semantic parser 
section presents preliminary experimental results new approach followed discussion 
section discusses possible explored current framework 
section provides brief discussion related 
summarize section 
background semantic parsing early semantic parsing dated back emphasis discovering learning mechanism language acquisition cognitive modelling human language learning 
focused cognitive modelling language acquisition focused building realistic nlp applications 
traditional nlp approaches tackling tasks building databases include augmented transition networks woods operationalize context free grammars producing semantic representations semantic grammars hendrix sacerdoti brown burton context free grammars non terminals represent domain specific concepts syntactic cate gories logic grammars abramson dahl warren pereira encode linguistic dependencies structure building operations logical unification 
traditional approaches constructing semantic parsers involve hand crafting expert knowledge represented rules limited automation 
hand crafted parsers suffer problems robustness incompleteness domain specific applications 
task scales size hand crafting difficult called problem knowledge engineering bottleneck exists interesting ai domains 
results applications timeconsuming build perform poorly incomplete inefficient brittle 
approaches shifted knowledge engineering perspective empirical paradigm parsers constructed learning algorithms large corpus training data 
instance miller presents statistical approach task mapping flight information requests english sql access relevant flight information 
frame semantic representation parse tree user request transformed sql choosen statistics collected training data 
method semantic classification trees parser construction described kuhn de mori 
classification trees semantic interpretation learned corpus training data 
zelle employs inductive logic programming techniques learn control rules specialize parser acquired chill system 
provide thorough discussion chill section mentioned systems section 
statistical parsing emergence statistical approaches parsing natural languages largely influenced success statistical techniques hidden markov models hmms area speech processing rabiner bahl 
corpus learning statistical model learned large corpus annotated text proven successful far performance concerned part speech pos tagging task involves assigning appropriate lexical categories noun verb article words sentence 
level accuracy close human beings merialdo charniak church 
influence corpus statistical approach apparent pos tagging 
syntactic parsing probabilistic context free grammars pcfgs charniak probabilistic left corner grammars manning carpenter dependency grammars collins maximum entropy models ratnaparkhi developed task building syntactic trees sentences 
going briefly describe key ideas statistical parsing 
probabilistic parsing build probabilistic language model language rank different possible parse trees sentence 
intuitively idea building language model generative grammar assumed capable generating sentences language build probabilistic model parse trees parse tree resulting parsing sentence grammar grammar assumed database category database objects city austin tx state stateid mississippi river mississippi place death valley table sample objects categories geography database generative estimate probability derivational rule grammar calculate probability parse tree estimates 
normally large amount different parse trees sentence heuristic beam search find probable parse tree argmax estimation probability grammar rule usually relies handcrafted contextual features course probabilistic context free grammar 
instance probabilistic left corner grammar left corner syntactic category goal category parse tree decide particular grammar rule applied 
overview chill discuss statistical model going develop parser chill provide detailed discussion system explain working parser contextual information learned utilized parsing operators 
natural language interface developed geography database example application 
details system zelle 
syntactic structure sentence express meaning 
instance np catch different meanings depending talking baseball game fishing expedition 
talk different possible readings phrase catch define specific sense phrase 
representation context independent meaning sentence called logical form allen 
database items ambiguous item listed attribute column relational database 
example term mississippi ambiguous river name state name words different logical forms geography database 
different senses represented distinctly interpretation user query 
databases usually accessed defined structured languages instance sql 
languages bear certain characteristics similar logic require expression quantification variables available www cs utexas edu users ml geo html 
predicates description city city capital capital state density population density state loc located len length river state borders traverse river traverses state table sample predicates interest database access attributes database notion logical operations 
different pieces information database may related relational knowledge useful constructing parser 
order logic choice knowledge representation framework logical forms database objects relations information related representing meaning user query 
case parser chill strictly logical representation 
choice representational scheme flexible 
instance chill applied database containing facts northern california restaurants semantic representation scheme resembles sql 
examples semantic representation database items geography database shown table 
briefly describe language representing meaning natural language query parsing framework employed approach taken chill parser acquisition 
semantic representation query language basic constructs representation language terms describe objects database basic relations 
examples objects interest domain states cities rivers places 
semantic categories objects 
instance stateid texas represents database item texas object database category state 
course database item member multiple categories 
database objects bear relationships related objects interest user requesting information 
fact large part accessing database information sort tuples satisfy constraints imposed relationships database objects user query 
instance user query capital texas data interest city bears certain relationship state called texas precisely capital 
capital relation predicate defined handle questions require 
relations possible interest domain shown table 
need handle object modifiers user query largest city california 
object interest belongs database category city instance sql express logical relationships constraints attributes query 
meta predicates description answer goal answer retrieve goal largest goal largest object satisfying goal smallest goal similar largest highest goal highest place satisfying goal lowest goal similar highest longest goal longest river satisfying goal shortest goal similar longest count goal total number satisfying goal goal satisfies goal maximizes fewest goal similar table sample meta predicates database queries largest california represented largest city loc stateid california 
meaning object modifier depends type argument 
case means city california largest population number citizens 
allow predicates describe predicates natural extension order framework handling kind cases 
property arguments take conjunction predicates 
object argument certain predicate appear point sentence requires predicate const means object equals object parser 
const explained section working parser discussed 
list meta predicates shown table 
sample database queries geography domain shown table 
geography capital state largest population 
answer capital largest state population 
state rivers running 
answer state river traverse 
people live iowa 
answer population const stateid iowa 
table sample geography questions different domains actions parser parser builds logical query sentence standard shift reduce parsing framework 
thorough discussion shift reduce parsing allen tomita 
explicit semantic grammar parsing actions derived examples pair sentence logical query guaranteed complete respect exists sequence parsing actions derivation leads right logical query sentence 
parser actions generated templates logical query action template instantiated form specific parsing action 
templates introduce coref vars drop conj lift conj shift 
introduce pushes logical form parse stack information lexicon 
coref vars binds arguments different logical forms variable 
drop conj lift conj takes logical form parse stack puts arguments 
drop conj assumes logical form precedes meta predicate parse stack lift conj assumes way 
shift pushes word input buffer parse stack 
actions summarized table 
parsing actions tried exactly order set parsing actions resemble decision list applicable choice taken 
parser requires lexicon interpret meaning phrases specific logical forms 
lexicon learned set sample sentence query pairs thompson mooney 
briefly illustrate action template showing trace parsing simple example sentence capital texas 
logical query answer capital const stateid texas 
thing need lexicon 
simple lexicon maps capital capital texas const stateid texas suffice 
parser begins initial stack buffer holding input sentence initial parse state 
predicate parse stack attached buffer hold context introduced words input sentence shifted stack buffer parsing 
contextual information may useful learning contextual knowledge disambiguation 
initial parse state shown parse stack answer input buffer capital texas 
words input buffer map logical forms sequence steps shift actions result parse state parse stack answer input buffer capital texas 
capital head input buffer mapped capital lexicon 
action apply introduce instantiated introduce capital capital 
notice particular phrase general mapped different logical forms due lexical ambiguities 
contextual knowledge required proper interpretation phrase learned induction algorithm 
resulting parse state shown parse stack capital answer input buffer capital texas 
actions description introduce term phrase put term parse stack phrase occurs input buffer input parse state output parse state coref vars ar ar unify th argument term th argument term parse stack having arity ar ar respectively drop conj ar ar place term th argument term form new conjunct comes parse stack having arity ar ar respectively lift conj ar ar similar drop conj term comes term parse stack shift word input buffer shifted buffer top predicate parse stack input buffer empty table summary parse actions action coref vars 
possible choices coref vars capital answer coref vars capital answer 
question asking capital proper choice pick 
general knowledge required properly selecting coref vars action learned 
resulting parse state shown parse stack capital answer input buffer capital texas 
sequence steps shift followed introduce instantiated introduce const stateid texas texas 
resulting parse state parse stack const stateid texas capital capital answer input buffer texas 
notice looking ahead input buffer texas introducing capital stateid texas introduced capital second argument left instantiated coref vars parser comes term texas 
helps avoid problem having combine different disambiguation decisions point 
instance question capital state borders texas decision introducing capital stateid texas capital precisely point capital input buffer 
easier parser decisions relevant context available parse stack point 
sequence actions coref vars instantiated coref vars const capital shift 
possible coref vars instantiations proper chosen 
resulted parse state shown parse stack const stateid texas texas capital capital answer input buffer choice coref vars capital answer eliminated inspecting predicates meta predicate argument positions hold variables 
steps drop conj 
remember drop conj applied variables predicate dropped instantiated previous actions coref vars 
drop conj const answer drop conj capital answer 
resulted parse state parse stack answer capital const stateid texas texas capital input buffer reached final parse state point parser actions applied 
logical query constructed read parse stack 
chill approach chill constructive heuristic induction language learning framework empirical approach parser construction integrated symbolic knowledge acquisition framework learning representation semantic knowledge 
parser construct logical queries natural language input natural implement parser logic program parsing operators horn clauses 
corpus sentence query pairs task induce parser translate sentences appropriate queries mapped target database access language 
consider inducing parser directly pairs space possible parsers large unfortunately developed machine learning handle task complexity 
initial parser generated instantiating action templates examples viewed overly general initial domain theory problem inducing parser reduced learning control rules 
induction logic programming ilp techniques learning search control knowledge order logical knowledge representation framework employed 
ilp growing paradigm machine learning discussed section 
idea learning control rules parser traced back earlier acquiring syntactic knowledge parsing berwick 
shows architecture chill 
working chill divided phases indicated generating initial parser analysing examples inducing control rules specializing initial parser 
briefly describe 
initial parser generation 
set training examples lexicon initial parser generated instantiating template introduce coref vars drop conj lift conj shift set specific parsing actions 
template example specific parsing action obtained inspecting logical query sentence 
instance previous example capital texas specific action obtained instantiating term capital phrase capital lexicon gives introduce capital capital 
actions parsing example generated due natural language ambiguities 
example capital mapped money amount money state government lexicon training examples generator operator parsing initial parser final parser specialization program control rules example analysis control rule induction architecture chill generated additional redundant action introduce money capital 
set actions generated training examples initial overly general parser 
initial parser guaranteed complete respect examples 
example analysis 
initial parser produce spurious parses training examples may contain redundant actions may ambiguities actions employed applied particular parse state 
job example analysis determine right set actions exactly action applied parse state correctly parse example construct right logical query 
result example analysis set actions parse training example paired corresponding parse states applied 
instance previous example parse state consists parse stack answer input buffer capital texas 
paired introduce capital capital 
training analysed results collected final set 
parse states actions useful inducing control rules parser 
control rule induction 
example done set actions order action coupled set parse states successfully applied 
parse states positive examples control rule induction component parse states applicable action paired actions action considered negative examples 
parse states appear action ignored parser implemented decision list action applicable states applied parser backtrack prolog backtracking mechanism actions decision list 
general possible derivation sentence different ways getting correct logical query grouped order coref vars introduce drop conj lift conj shift 
sentence false negative examples parsing action applied different resulting states lead final state 
checking false negative examples expensive computationally simply treat noise training data rely induction algorithm noise handling 
discuss noise handling section 
principle ilp algorithm induce control rules 
particular algorithm employed chill discussed section 
program specialization 
control rule produced action viewed kind guard action 
rule hopefully capture contextual knowledge parse states necessary classifying parse states action apply 
control rules incorporated initial overly general parser specialize 
inductive logic programming inductive logic programming ilp growing subfield ai intersection machine learning logic programming 
problem defined follows 
set examples gamma consisting positive negative examples target concept background knowledge find hypothesis language hypotheses conditions hold muggleton raedt 
prior satisfiability 
gamma posterior satisfiability 
gamma prior necessity 
posterior sufficiency 
sufficiency criterion called completeness regard positive examples posterior satisfiability criterion known consistency negative examples 
due expressive order formalism ilp techniques proven effective tackling problems require learning relational knowledge traditional propositional approaches quinlan 
major approaches design ilp learning algorithms top bottom 
approaches viewed generally kind set covering algorithm 
differ way clause constructed 
top approach builds clause general specific order search usually starts general clause successively specializes background predicates search heuristic 
representative example approach foil algorithm quinlan cameron jones quinlan 
bottom approach search begins space starts specific hypothesis set examples constructs clauses specific general order generalizing specific clauses 
representative example approach golem algorithm muggleton feng 
ilp systems briefly reviewed 
problem setting called normal semantics ilp 
procedure foil input vk target concept phi examples gamma psi examples output set learned clauses positives cover positives cover empty search clause covers preferably large subset positives cover covers examples gamma add clause building definition 
vk positives cover gamma contains negative tuples find literal maximizes gain add clause form new set extending tuple satisfies new variable bindings replace add remove examples covered positives cover return procedure foil algorithm foil foil learns function free order horn clause definition target concept background predicates defined extensionally 
foil contains outer loop finds clauses covers portion positive examples consistent negative examples 
loop stops set clauses covers positive examples 
inner loop builds single clause starting general hypothesis adding literals covers negative examples 
literals ranked information gain metric literal maximizes gain chosen 
formally denote number positive tuples set information defined gamma log information gain literal defined gain delta gamma number tuples extensions number current positive tuples covered new training set created procedure golem input set positive examples gamma set negative examples pairs random sampling pairs fc pairs rlgg consistent wrt gamma pair fe rlgg greatest cover output set learned clauses examples random sampling examples fc examples rlgg consistent wrt gamma find produces greatest cover add rlgg examples examples gamma cover rlgg increasing cover return procedure golem algorithm summarizes foil algorithm 
golem golem contains outer loop find set consistent clauses covering positive examples foil 
builds clause considering relative general generalization rlgg pairs positive examples 
called relative background knowledge taken account performing general generalization lgg pair positive examples example sequence ground background literals added body 
lgg terms new variable lgg lgg 
lgg clauses fl fm defined lgg lgg 
simple example consider clauses 
lgg clause 
detailed discussion lgg plotkin 
rlgg examples produce large clause lot redundant literals body 
reduce clause size search considers restricted model background knowledge easy model set herbrand instantiations easy atoms 
atom easy respect derivation involving resolutions 
golem starts sampling pairs uncovered positive examples chooses greatest coverage generalization 
stops building clause rlgg generalized generalization produces inconsistent clauses 
summary algorithm 
integrating statistical relational methods learning years methods combine statistical relational learning approaches produce classifiers accurate approach slattery craven ali pazzani 
precisely take approach uses relational learning algorithm learn multiple models training data combines statistical method 
shown learning multiple models improve classification accuracy ali pazzani kwok carter breiman quinlan 
going briefly review system similar approach called hydra uses form bayesian learning combine multiple models acquired relational learning algorithm ali pazzani 
hydra system uses relational learning algorithm similar foil quinlan learn multiple descriptions set training data 
particular approaches employed system stochastic hill climbing kononenko kovacic fold partition learning gams 
stochastic hill climbing stores set literals margin oe best literal ranked certain metric literals info gain chooses literal randomly set 
probability literal chosen goodness metric gain literal 
fold partition learning generates models partitioning training data sets equal size learn model ith partition 
totally ways excluding partition 
learning set models methods hydra combines learned models single model bayesian combination buntine 
learning multiple models tabulate section going discuss details new induction algorithm chill 
design strongly motivated induction algorithm zelle mooney going provide brief overview algorithm 
proceed explain motivation new algorithm discuss details various ilp issues addresses 
combining top bottom methods top bottom approaches ilp strength weaknesses 
instance golem requires extensional background knowledge background knowledge expressed listing ground facts result building clauses lot redundant literals 
specific constraints easy model background knowledge enforced deal efficiency problems 
hand foil requires target hypothesis function free needs specific constructor functions part background knowledge 
instance learn concept member element non empty list needs provide foil background predicate head essentially function returns element list size background knowledge grows number constructor functions learner complexity hypothesis space search larger branching factor 
combination different methods takes advantage strength approach may open new approaches ilp perform better 
attempt combining approaches chill learning control rules 
shows outline 
procedure input phi examples gamma psi example output def set learned clauses def fe repeat pairs sampling pairs clauses def fg find clause def gamma hc pairs clauses yielding compaction def def gamma clauses subsumed compaction return def procedure outline algorithm set covering foil consists compaction outer loop builds general hypothesis iteration 
iteration tries find clause maximizes coverage set positive examples compaction 
clause built finding lgg random pairs clauses building definition def lgg overly general specialized adding literals body way similar foil 
search hypothesis done bottom manner begins specific hypothesis set positive examples continues generalize compaction loop 
specialization clause resembles top algorithm literals added body specialization heuristics information gain discriminate literals 
clause incorporated current theory 
clause covered subsumed removed theory 
novel kind subsumption adopted called empirical subsumption 
clause empirically subsumes set ground unit instances covered clause subset clause stands chill induction algorithm 
motivation new algorithm tested learning simple list processing programs append shown effective foil golem zelle mooney 
shown successful attempt combining top bottom approaches ilp suffers weaknesses 
search basically hillclimbing search hypothesis space may get stuck local minimum 
may interesting consider search methods beam search attempt partially overcome local minima 
beam search requires design metric evaluating hypothesis beam 
explain details metric section 
goal search find simplest consistent hypothesis queue hypotheses guided explicitly defined theory evaluation metric 
new algorithm described detail section 
second relies positive examples capture theory constants logical constants appear definition may useful 
learning theory constants reliable method 
instance relevant constant certain word appears different locations input buffers different parse states result parse states replace word variable fail capture useful lexical information 
consider making literals theory constants explicit process appropriate predicates literals background knowledge learner 
described section 
third considered adding capability handling noisy data lacking 
mentioned noisy data arise due presence false negative examples 
discuss issue noise handling section 
new algorithm designed learn multiple models training data integrated statistical learning methods produce probabilistic models semantic parser 
observations motivation design tabulate 
compression accuracy ideal solution ilp problem hypothesis minimum size predictive power 
practice hardly achievable due reasons finding minimum program undecidable minimum encoding function computable uncertain minimum program predictive power 
form bias lead close ideal desirable goal search find hypotheses perform 
despite arguments generality webb occam razor principle widely form bias learning algorithms basis algorithmic tabulate stands top bottom clause construction theory evaluation 
famous occam razor ockham says entities multiplied necessity 
complexity theory 
occam razor principle best followed rissanen minimum description length mdl approach rissanen hypothesis minimizes theoretical minimum encoding hje chosen set examples hypothesis defined hypothesis space 
theoretical minimum encoding computable practice employs reasonable encoding scheme approximation notion 
califf approaches mdl give weight complexity hypothesis accuracy course search may best guide heuristic search hill climbing beam search 
leads idea modifying metric mdl puts emphasis accuracy hypothesis 
reasonable choice accuracy metric estimate cestnik 
estimate expected accuracy accuracy delta number positive examples covered hypothesis total number examples covered prior probability class phi parameter 
metric calculating program size similar muggleton buntine 
size clause having head body defined follows size variable constant arity arg size clause roughly counts number symbols symbol variable constant predicate 
size hypothesis finite set clauses sum size clauses 
metric search heuristic defined accuracy log size hypothesis search space constant 
constant balancing factor accuracy complexity hypothesis meaning trying find hypothesis optimizes compression accuracy 
hypothesis search space including inconsistent hypotheses want find compresses examples losing classification information accuracy 
need balancing factor set priori bias accuracy complexity particular hypothesis space 
constant set bias accuracy hypothesis larger value accuracy emphasized 
constant may determined different ways 
delta kolmogorov complexity function kolmogorov 
original definition general setting classification problem ary 
refined scheme muggleton srinivasan bain employed estimate number bits required encoding 
accuracy complexity possible projection hypothesis space metric space assumption general hypothesis poor specific hypothesis terms quality 
shows possible projection hypothesis space metric space 
metric space represents reduction hypothesis space programs score considered equivalent 
refined definition metric course give better model hypotheses terms goodness 
extreme points represent general hypothesis specific respectively estimates general hypothesis specific hypothesis respectively sizes respectively 
generally represent classes programs size accuracy 
points equally assumption formally expressed definition expanded resolved gamma gamma ready describe new algorithm 
tabulate algorithm top bottom methods normally search hypothesis hypothesis space tabulate explores parts search space akin bi directional search 
precisely considers refinements general hypothesis general generalizations existing clauses theory 
general may case amount information content xn represent worst cases ends search space 
tabulate compaction outer loop 
search starts specific hypothesis set positive examples 
iteration loop attempts compact hypotheses current search queue 
iteration corresponds single search step generating children nodes 
search employed modified version standard beam search call beam search 
standard beam search considers children nodes selecting best 
size big due time space restriction search run situation best search nodes look similar eventually dominate entire search queue search essentially gets stuck local minimum 
instance hypothesis refinements clause built hypothesis refinements children occupy large part search queue iterations entire queue consist descendants 
problem particular beam search 
case genetic algorithm get called problem lack diversity population similar problem 
beam search window size posted upper bound number children nodes search consider parent node 
words parent produce children search queue 
partially avoid domination problem mentioned sharing search queue parents 
notice beam search reduced standard beam search defined maximum branching factor search infinity 
cases iteration existing clause refined new clause begun 
search node refined top bottom manner hypotheses algorithm may consist clauses built fashion 
tabulate algorithm taken compaction approach cigol muggleton buntine clause search put aside included part theory refined 
compaction give general consistent hypothesis set covering clauses built search may combined form general clauses point search 
outline tabulate algorithm 
outline refinement operator refine clause 
incorporated noise handling predicate invention refinement operator discussed section 
possible outcomes refinement current clause satisfies noise handling criterion need refined simply returned set empty current clause satisfy noise handling criteria possible refinements returned set empty jth refined clause satisfies noise handling criterion set refined clause current clause satisfy noise handling criterion refinements empty set clauses returned set fail 
practice may possible refinements decided choose start set correct respect examples proceed search 
helps boost bottom search bit large number positive examples 
instance may literals yield similar scores particular literal selection metric 
posted predicate arity bound predicate invention routine avoid straight memorization examples 
case happen requires invented predicate arity bigger refine clause 
procedure tabulate input xn target concept learn phi examples gamma psi examples output queue learned theories theory fe initial theory theory theory starting search node empty current clause built search queue repeat cq search node time build new clause start general hypothesis existing clauses 
keep refining current clause needs refinement 
set clause refinements node empty fail pairs sampling pairs clauses find lgg pairs greatest cover refine clause xn refine clause refine clause current clause refined accurate need build new clause 
incorporate refined clause theory current search node check refined clause acceptable needs refined 
cq set children nodes cq children nodes produced parent node cq fht cq empty satisfies noise criteria cq cq cq best nodes cq ranked metric termination criteria satisfied return procedure tabulate algorithm procedure refine clause input clause refined arity bound invented predicate bg set background knowledge current search node output set refinements gamma fcg check clause accurate wrt noise handling criterion 
returned 
needs refined 
clause refined background literal checked inventing predicate suitable invented predicate requires arity 
empty set clauses returned refinement possible indicating search try build different clause 
satisfies noise handling criterion fcg usefully refined bg fg add literal invented predicate requires arity fe gamma fe gamma gamma gamma lip invent gamma fadd literal lip return procedure clause refinement operator refine clause best positive information gains avoid having deal complexity full fledged search evaluate possible refinements hypothesis evaluation metric 
possible cases refinement clause 
case refinement new clause built theory 
case check clauses current theory empirically subsumed new refinement 
subsumed removed theory 
existing clauses empirically subsumed newly refined clause considered redundant eliminated theory 
second case specialization existing clause theory 
positive examples covered resulting theory due specializing clause added back 
theory maintained complete entire course search 
done complete procedure 
different possible termination criteria defined depending goal search 
instance wants emphasize quality solution may impose requirements termination expense resources 
termination criterion case checks conditions satisfied 
taken sum metric hypothesis entire search queue represents quality queue hypotheses 
condition satisfied search queue improve sum 
hill climbing search space search queues 
second check sure clause currently built theory search nodes search queue finished clause theory satisfies noise handling criterion node empty node search queue 
committee hypotheses algorithm returned 
set hypotheses viewed multiple models target concept learned algorithm 
learning theory constants domains language learning inductive learner utilize synthesize theory constants desirable kind knowledge valuable learner discriminating features 
parsing needs contextual information disambiguating different possible parses sentence information represented theory constants inductive learner 
example previous sample trace parsing sentence capital texas phrase capital mapped money amount money state government lexicon need disambiguate introducing capital money parse stack 
case context helpful disambiguating cases absence word government input buffer 
predicate phrase buffer phrase appears input buffer parse state background knowledge learner literal phrase buffer government useful constructing control rule parsing action introduce capital capital 
ilp systems quinlan background knowledge domains described proposal predicates phrase buffer predicate stack checks particular predicate parse stack basic predicates background knowledge 
domains background predicates going details 
handle theory constants checking value variable equals zero 
requires prior knowledge set constants relevant necessary learning task 
may possible domains learning functional definitions relatively easier identify set important constants may relevant number learning tasks 
domains language learning identifying set useful constants reasonably comprehensive difficult required prior knowledge relevant contextual information learning system suppose find 
possibilities throwing entire dictionary ineffective inefficient 
engineering prior knowledge system obtain possible theory constants training data 
requires system generate extract theory constants examples set background predicates 
precisely idea set positive negative examples target concept set background knowledge background predicate comes mode declaration argument type definition generate new set literals constants appear set examples learner 
phrase buffer example sentence capital texas positive example fraction texas government state capital spent highway construction negative example parsing action introduce capital capital generate set literals restrict considering word phrases phrase buffer phrase buffer texas phrase buffer phrase buffer phrase buffer texas phrase buffer government phrase buffer spent phrase buffer phrase buffer highway phrase buffer construction phrase buffer predicate invention earlier ilp systems assume sufficient amount background predicates start approaches abandoned assumption allow learner set background knowledge contain predicates take theory constants arguments 
set relevant background predicates easier choose set constants 
extend vocabulary set background knowledge sufficient learning 
purpose inventing literal clause constrain variables clause exclude negative examples clause covering 
general separating positive negative examples may require constraining multiple variables 
adopted approach similar predicate invention tabulate 
greedy algorithm employed find smallest set variables separate positive negative examples set instantiations positive negative examples form disjoint sets 
set exists long set positive negative examples mutually disjoint 
search begins empty set variables 
variable added set time separates positive examples negative examples chosen 
set instantiations variables forms new set positive negative examples new literal 
predicate invention algorithm recursively called learn new concept 
noise handling task parsing sentences logical queries noise arise exists possible consistent logical queries sentence different ways annotating training data give rise ambiguities parsing actions artificial lexical case false negative examples collected learner 
checking collecting training data enforcing particular style annotation time consuming impractical treat noise training data learning algorithm handle 
adopted approach taken ripper cohen handle noise 
particular clause needs refinement meets criteria gamma fi number positive examples covered clause number negative examples covered gamma fi noise parameter 
ripper fi fixed constant selected assumption amount noise data set fi high value close decrease value sum metric hypothesis search queue improve search nodes unfinished clause failed clause 
words estimate value fi amount noise data relying assumptions data 
equivalent logical queries sentence exist may various ways structuring query mean thing 
instance meaning answer capital const stateid texas answer state city capital const stateid texas queries give exactly answer 
distinct queries 
statistical semantic parsing approach taken miller explicit generative semantic grammar build probabilistic model parser approach involve grammar may readily available domains 
different probabilistic model assume grammar developed 
model described followed discussion probability estimation 
parsing model proceed describe statistical parsing model going build definitions essential discussion 
parser relation parser sentences theta queries sentences queries sets natural language sentences logical queries respectively 
sentence set meaning fq queries hl qi set logical queries possible interpretations sentence task learn semantic parser implements target relation parser 
parse state tuple stack list lexicalized logical forms meaning lexical entry buffer list words input sentence 
set states set syntactically formed parse states 
parsing action ith action learned parser function states set states action applicable states set states constructed action input states 
function sentence maps sentence corresponding unique initial parse state states starting state learned parser suppose learned parser total parsing actions partial function queries defined action retrieves logical query final state states exists 
right assume learned parser complete respect data path sentence logical queries meaning 
assumption true 
learned parser derived training data suffer missing certain parsing actions essential completing parse part training data 
problem discussed section 
final states may contain logical query function partial function 
cases happens parser simply report failure 
state called final state exists parsing action applicable 
path finite sequence parsing actions 
sentence state exists path logical query meaning 
bad state 
parse states input sentence constructed corresponding parse state set parse states uniquely divided set states set bad states parser 
words states states states gamma states denotes set states states gamma denotes set bad states 
lexicalized logical forms attaching logical form stack buffer contains words input sentence form introduced 
see section 
ready discuss parsing model 
input sentence goal learned parser search logical query probability meaning maximized 
words want find argmax meaning path denoted 
building probabilistic model logical query generated sentence cases statistical syntactic parsing build model estimate parse sentence represent correct meaning 
need define meaning notice meaning states set final states 
drop conditions denote probabilities meaning respectively long assumed context discussion 
say probability logical query result parsing meaning probability final state logical query retrieved state definition state 
precisely final state produced parsing meaning obviously need determine general probability having resulting parse state precisely parse state action states set output states 
parse state jth step derivation derivation path parsing action action applicable producing state states set input states action 
meaning equation probability certain parse state sum probability assuming previous parse state application action produce parse state probability assuming bad state parsing action produce probabilities weighted probabilities previous parse state bad respectively 
definition parsing action produce parse state bad second term simply zero ready derive method estimating meaning 
suppose final state meaning gamma am gamma gamma am gamma delta delta delta gamma am gamma gamma gamma gamma denotes index action applied kth step 
initial state state know meaning gamma proceed discuss estimate probability action parse state estimating probabilities parsing actions chill collection positive negative examples learning control rule parsing action facilitates learning decision list set parsing actions probabilities parsing actions estimated model 
alternatively collect negative examples parsing actions treat parser set independent parsing actions decision list 
issue discussed section 
current method may best resemblance learning decision list direct comparison performance approaches parsing intuitive learner system exactly set positive negative examples 
learning parsing action decision list negative examples collected treat probability estimation differently 
discussion probabilities estimated actions gamma result learning control rules parser parsing action learned set hypotheses serve identify conditions parsing action applied 
hypotheses viewed contextual information useful making decision apply action 
hypotheses may important sense carry weight decision 
committee hypotheses set features estimate probabilities goodness various actions parse state 
weighting parameter priority weight included lower probability estimate depending position action decision list actions applicable parse state action decision list applied 
actions gamma pos gamma parse state pos position action list actions applicable state weighting parameters chosen subset hypotheses learned induction algorithm action sum equal 
words probability action estimated linearly combining conditional probability estimates learned models weighting exponential decay factor depending position action decision list 
discuss determined 
ready discuss probability model action build probability model action maximum likelihood estimate relatively large number examples 
just ml estimate directly mean ignoring contextual information available particularly learning action 
recall equation yield estimate goodness action gamma devise simple test checks maximum set estimates obtained subset actions gamma applicable equal certain threshold ff 
intuition goodness action conditioned best estimate previously applicable action greater certain threshold 
empty just take maximum zero 
precisely max ff ff threshold count number states produced action count number states action applicable 
discuss estimated 
suppose set positive negative examples collected action set training data may noise need include factor estimation 
noisy data appear set negative examples 
positive examples noisy collected example analysis parsing operator wrongly applied certain parse state correct parse chance discovered require cardinality entire set positive examples 
typical number examples actions usually range 
number examples action 
threshold set experiments performed section 
set negative examples induce hypotheses collected parsing operators current operator decision list 
set negative examples probability estimation include current operator 
done primarily reason accuracy estimation 
considered positive example operator 
degree noise assumed parameter fi stated equation 
need compute probability having noisy negative examples fi particular set examples think fi lower bound degree noise freeness gamma fi fi estimate number negative examples allowed covered clause number positive examples define nc number negative examples estimate probability negative example corrupted 
labels state operator delta number positive examples covered number negative examples covered 
delta number positive examples rejected number negative examples rejected 
variety linear combination methods estimate weights taken simple approach 
determined complexity hypothesis size gamma jhj size gamma intuitively means complex hypothesis probable weight carries combined decision 
discuss linear combination methods section 
searching parse find probably correct parse parser employs beam search starting initial parse state 
similar beam search find probable parse tree probabilistic syntactic parsing ratnaparkhi collins 
step derivation parser finds parsing actions applicable parse state calculates probability correctness equations 
computes probability correctness derivation point equation 
search queue sorted probability derivation 
parse state expanded parser find applicable action procedure input input sentence beam size parse queue ops set parsing actions output query resulted logical query initial parse state created input sentence head contain query parse state find sublist parsing action ops applicable expand action get list children parse states contains query best parse states query query contained head return query procedure parsing algorithm beam search parse state parser checks logical query obtained parse state 
parse state remains parse queue 
removed 
parser stops complete parse top parse queue certain time limit passed case failure reported parser 
summary parsing algorithm shown assuming parse 
experimental results domains different domains demonstrating performance new approach 
united states geography domain 
database contains facts implemented prolog relational tables containing basic information states population area capital city neighboring states major rivers major cities highest lowest points elevation 
contains information rivers screenshots user request english population cities 
handcrafted parser called geobase constructed domain people built database 
parser experiments comparison results 
second application restaurant database query system 
database contains information restaurants northern california including bay area 
types information database name restaurant location specialty restaurant rating quality restaurant customers 
database currently contains nineteen entries rows relational table 
purpose application provide tourists restaurant information online guides web 
require user select entries possibly large tables enter kind html forms access information databases provided natural language interface database user ask questions english 
sample screenshots web interface developed system shown 
third domain consists set computer related job postings job announcements usenet newsgroup austin jobs 
information job postings extracted create database califf mooney contains types information job title location salary languages platforms required desired years experience degrees 
database updated daily basis currently entries 
experimental design geography domain corpus sentences 
approximately sentences collected user requests web months system put rest collected undergraduate students department 
compare new system original included test result subset sentences zelle mooney 
restaurant database query system corpus sentences artificially generated hand partly user requests 
job database information system corpus sentences 
artificially help simple grammar generates certain obvious types questions people may ask 
experiments conducted fold cross validation 
corpus divided partitions equal size trial uses particular partition test data rest partitions training 
test result average results trials 
test recall accuracy precision parser reported 
recall precision defined follows recall correct queries produced sentences precision correct queries produced successful parses recall number correct queries produced divided total number sentences test set 
precision number correct queries produced divided number sentences test set parser produced query successful parse 
query considered correct produces answer set correct logical query 
results beam size window size tabulate algorithm experiments 
results running fold cross validation test corpora shown table 
different beam sizes probabilistic parser illustrate effects performance parser 
experiment sentences geography domain reported results recall precision chill tabulate best hypothesis committee hypotheses control rule parsing action recall precision chill probabilistic parsing different beam sizes recall original chill uses induction algorithm recall geobase hand crafted parser built domain 
best recall precision chill probabilistic parsing respectively beam size twelve chill tabulate respectively 
performance probabilistic parser degraded decreasing beam size 
drop performance rapid log online user requests 
current total amounts nearly 
system deployed years 
geo geo jobs rest chill chill chill chill chill chill tabulate chill handcrafted parser table results experiments 
geo consists sentence geography domain 
geo consists sentences domain 
jobs consists sentences job postings domain 
rest consists sentences northern california restaurant domain 
recall precision 
probabilistic parser beam size handcrafted parser geography domain geobase 
case beam size 
recall original system geobase 
experiment sentences domain set results reported original chill geobase 
best recall precision chill probabilistic parsing respectively beam size twelve chill tabulate respectively 
drop performance probabilistic parser due decreasing beam size rapid beam size beam size 
set results reported experiment sentences usenet newsgroup job postings domain 
best recall precision chill probabilistic parsing respectively chill tabulate respectively 
time drop performance probabilistic parser smaller beam size twelve significant beam size size 
experiment sentence corpus northern california restaurant domain best recall precision chill probabilistic parsing respectively chill tabulate 
show performance probabilistic parser various beam sizes different domains 
discussion proceed discuss results consider potential advantages disadvantages approach 
discuss results understanding conditions system perform 
beam size corpus corpus corpus corpus recall parser various beam sizes different domains approach largely motivated observation original system brittle takes overly general specialized control rule correct parse 
probabilistic approach parsing adds layer robustness system considering set parses quality parse considered 
allows room making mistakes course parsing sentence presence imperfect control rules 
probabilistic parser perform better original approach correct parse best quality probable beam size big overcome local minima places parser mistakes 
second advantage probabilistic classifier combining multiple learned models 
committee hypotheses usually perform better just single hypothesis 
demonstrated domains 
probabilistic approach potential advantages robustness system relies precision probability estimation 
lack data domain hard achieve certain level accuracy required performance system means replying default models may necessary 
second potential disadvantage decrease precision considering set parses lead spurious parses system 
third potential disadvantage amount time needed successfully find parse 
consider general performance different systems domains 
experimental results different domains demonstrated system gain robustness considering set parses performance system increased monotonically beam size domains 
apparent third experiment sentences job postings domain system signifi beam size corpus corpus corpus corpus precision parser various beam sizes different domains cantly outperformed original system 
case lack data domains beam size rendered search effectively best search decision list lead significantly worse performance original system probabilistic classifier performing better decision list 
precision system somewhat decreased significant amount second experiment 
experiments run mhz ultrasparc station sicstus prolog 
results parsing time different systems formally reported noted difference beam size original system seconds average amount time required find successful parse domains significantly increased seconds beam size twelve 
improvement new approach far recall concerned performance varied greatly domain 
second experiment best improvement recall merely 
beam size system improvement recall original system 
suggests factors picture specific particular domain 
currently certain factors suspected factors quality lexicon system relative amount data available calculating probability estimates problem learning incomplete parser respect test data potential bottlenecks picture 
performance systems close domain performance near perfect recall precision 
primarily domain relatively easier systems achieved recall precision roughly training data 
results training systems various amount data shown collected domains 
recall chill tabulate significantly better 
shows background knowledge theory constants beam searching hypothesis space builds better control rules parsing actions 
experience inspecting learned control rules hypotheses discovered tabulate tend general readable set positive negative examples 
geobase performed worst results largely due hand crafting rules scale task 
areas look possible directions 
areas discussed 
precisely explore listed areas accomplish part proposal 
suggested areas interesting directions long term goal project 
performing extensive experiments currently biggest corpus experimented geography domain sentences 
interesting expand corpora different attempted domains see approach scale tasks 
domains implemented online demos accessible world wide web collect real world data 
instance geography domain nli system deployed years requests database far 
dealing incompleteness assumption parser complete respect unseen data means correct parse input sentence parsed query parser simply hold 
words cases parser just proceed right parsing operator missing 
due large part fact parser acquired training examples parsing operators parse training examples learned may parsing operators required parse test cases parsing training data 
way solve problem allow parser invent parsing operators comes impasse due missing right operators inspecting current parse state 
precisely invent operators coref vars drop conj lift conj checking remaining predicates parse stack processed 
instance predicate parse stack dropped body meta predicate try dropping see correct query produced 
invent operators introduce target logical query sentence 
need invent operators shift 
estimation probabilities invented parsing operators different current approach training data 
potential method estimating probabilities estimating probability instance drop conj operator existing parser application operator parse state give resulting parse state 
method similar estimating probability grammar rule probabilistic context free grammar 
incorporated ability invent operators existing parser chill 
preliminary results different domains improvement recall precision 
control rules learned tabulate 
improving precision second look ways improve precision parser 
possible way implement test resulted parse queue see probability best parse significantly higher say second parse 
set parses similar probabilities suggest correct parse question truly ambiguous 
problems parsing precision partially overcome tackling problem parser incompleteness improving recall parser significantly probably improve precision 
possible avenue consider mapping queries parser back english done reversing mapping lexicon inspecting structure logical query user pick right interpretation cases best query significantly better second query 
potentially allows online learning user input discussed section 
exploring various linear weighted combination methods various methods estimating weights linear evidence combination model developed em algorithm iterative weight updating bayesian combination buntine likelihood combination duda gaschnig hart 
particular explore bayesian combination method closest optimal bayes classification 
precisely method estimates probability class example training data set hypotheses produced learning algorithm estimated equations better appropriate smoothing techniques lack training data discussed 
estimation going discussed involves heavy amount details 
interesting improve existing method tolerant presence noise 
improving probability estimation smoothing techniques currently conditional probabilities overestimated results close poorly learned models resulting worse classification performance 
estimate cestnik method smoothing ml estimates conditional probabilities entirely satisfying due extreme lack data cases 
new smoothing techniques base priori assumptions quality learned models may need developed 
potential method linearly interpolate additional model stanley goodman jelinek mercer interpolated gamma class hypothesis set hypotheses produced learning algorithm parameter interpolated delta delta interpolated probability estimate delta delta ml estimate represents default model instance priori probability poorly learned model smaller value ml estimate 
interpolated estimate overestimated ml estimate 
abandoning decision list framework current approach modelling semantic parser decision list 
negative examples parsing action collected parsing actions list exponential decay factor model priori probability parsing action depending position decision list explicit model parsing action built improve performance 
restriction modelling decision list necessary 
new way modelling semantic parser consider parsing actions set decision list negative examples collected parsing actions 
potential benefit new way collecting examples learning algorithm learn discriminative set hypotheses 
current approach parsing actions closer decision list fewer training examples prone poor probability estimation suffer learning 
practice may lack training data parsing actions realistic approach combining decision list modelling new framework parsing actions may negative examples training data learning possible 
meta learning lack data parsing actions learning default model parsing action shift easy task normally training examples parsing action 
suggests directly learning models capture contextual information great number parse states may effective approach problem 
considers learning models capture results decisions parsing actions potentially compact set hypotheses learned default parsing action 
similar meta learning sense new set examples generated parsing action including information parsing decisions parsing actions 
online learning idea online learning parser produces set queries correct set best probably correct user give feedback system instance picking right system set queries parser learn online new piece information appropriately adjusting weights multiple learned models subset parsing actions 
precisely suppose set queries parsing sentence best query correct query derivations respectively delta delta delta delta delta delta delta delta delta delta delta delta transition state represents single step derivation 
term transition probability context represent conditional probability transition state represents state state 
know meaning meaning transition probabilities derivation overestimated transition probabilities derivation underestimated 
assume cases occur 
set transitions probabilities overestimated derivation set transitions probabilities underestimated derivation goal learning reduce classification errors classifiers produce probabilities sets proceed discuss may achieved need discuss sets determined 
transitions shared derivations part 
altering probabilities meaning meaning 
consider derivation know states states rest bad states 
state bad state probability transition overestimated 
fact zero 
set simply consists transition 
transitions included certain probabilities overestimated 
set determined heuristically removing transition time checking product rest transition probabilities greater meaning 
transitions lower probabilities considered 
goal find minimal set transitions probability estimates improved yield improvement estimation meaning 
ready discuss classifiers produce probability estimates improved 
restrict discussion case transition set done shift operator 
case shift operator involved little complicated 
transition set corresponding classifier produces overestimation transition probability need adjust parameters classifier probability lowered 
need adjust parameters classifiers set probability estimates transitions increased 
precisely suppose classifier set models set weights change weights probability estimates maximized minimized 
avoid overfitting single training example needs define learning parameter similar perceptron learning algorithm update weights amount errors 
case assume target goal maximize probability estimates target zero 
perform step computation want weight updating procedure overfit single training example 
similar performing step weight updating particular misclassified example perceptron learning algorithm linear weight updating algorithms 
probabilistic relational models research learning probabilistic relational models prms databases friedman getoor koller pfeffer generalizes traditional approach learning bayesian networks pearl 
learning bayesian networks prm learns structured representation probabilistic model structural dependency attributes random variables captured complex probability distribution built 
prm learning go bound propositional attribute value representation build learning framework order representation captures relational knowledge domain 
explore relatively new type learning approach problem relational knowledge probabilistic models necessary task see build classifiers techniques new approach 
discourse processing current approach database information retrieval natural language interface assumes necessary information interpret user database access context sentence 
reality information exchange happens dialog 
suggests extending current approach allow dialog user computer desirable 
requires processing discourse context information integrating meaning sentence fully interpret meaning user database access miller pietra epstein roukos 
precisely discourse history contains previous user input sentences current session database access need find query sentence argmax meaning sm meaning set correct queries sentence discourse history final state parsing sentence acquired semantic parser operator invention relation relates final state possible completion state parsed query possibly operator invention 
completion state discourse context result transformation state information context 
discourse context part probabilistic model needs included new model 
definition state needs extended pre discourse post discourse model 
pre discourse model probabilistic model parsing sentence certain final state discourse processing primarily handled properly constructing relation building probabilistic model 
post discourse model probabilistic model parsing resulting completed state target query immediately obvious current approach special case identity relation relates suppose rh fs set possible completions 
state pre discourse model exists path target query precisely exists rh state post discourse model simply definition state current framework 
interesting verify definition state pre discourse model reduced post discourse model identity relation 
construct probabilistic model meaning conditions dropped simplicity discussion meaning max sm rh sm gamma delta delta gamma final state post discourse model represents generally notion state state models 
terms right side equation left right represent pre discourse model discourse processing model post discourse model respectively 
estimation probabilities post discourse current approach 
intuitively equation means probability query correct meaning sentence discourse context product probability parsed final state pre discourse model probability resulting transformed state discourse context state model probability state parsed final state post discourse model 
general path just choose maximum probability 
course needs done verify probabilistic model defined reasonable 
go trace example illustrate task discourse processing 
assume relation properly constructed 
suppose database access session user capital texas 
system display answer austin 
user california 
system display answer sacramento 
system starts empty discourse session begins 
question asked user simply parsed logical query 
precisely parse state logical query parsing parse stack answer capital const stateid texas texas capital input buffer query answer capital const stateid texas user asks second question discourse history contains final parse state logical query shown 
system parses sentence final state suppose parse stack const stateid california california answer input buffer point system constructs possible completion final state discourse context 
assume completion 
possible completion discourse context parse stack capital const stateid california california answer input buffer case assume system recognizes user asking information capital city california adds necessary predicate parse stack 
system proceeds parse resulting state parse stack answer const stateid california capital california input buffer query answer const stateid california capital final parse state system proceed retrieve answer database 
course imagined example real database access session look 
focusing developing method constructing relation discourse context probabilistic model 
related approach novel sense combines strength relational statistical learning approach problem semantic parsing 
relatively approaches problem going briefly review related different pieces semantic parsing 
applied task air travel information service atis project miller bobrow ingria schwartz 
goal project develop spoken natural language interface air travel information obtaining flight information 
semantic parsing discourse modelling miller describes system maps input user request flight information corresponding frame structure translated sql discourse context 
logical queries meaning sentence represented parse tree non terminal nodes contain syntactic semantic information components sentence 
example word user request flights leave boston arrive atlanta 
miller represented tree node labelled prep preposition location location indicator 
standard frame slot representation capture information expressed parse tree 
parse tree decide frame type slots contain necessary constructing target sql hopefully retrieve relevant flight information 
parse tree tagged specific frame slot 
discourse processing part focused resolving hidden constraints user request 
problems pronoun resolution addressed relevant task 
instance possible hidden constraint user request flights available tuesday context user asked flight information boston denver flights may referring boston denver 
statistical model built parser broken components model meaning sentence model post discourse meaning 
pre discourse model built grammar encoded recursive transition network resembles statistical syntactic parsing 
approach explicit grammar constructed domains model built directly parsing actions learned training data 
post discourse model tasks assume database querying done dialogue orient environment 
ambiguity resolution possible different frames done selecting product statistical models current discourse context 
semantic classification trees semantic interpretation system called developed handle task kuhn de mori 
intermediate representation language represent meaning input sentence automatically translated sql 
intermediate representation language components list displayed database attributes set constraints attributes 
similar approach taken northern california restaurant domain representation language mapped sql logical query 
semantic interpretation handled semantic classification tree sct 
sct similar standard decision tree quinlan 
internal nodes contain patterns expressed form regular expression matching input sentence 
patterns check specific combination words input sentence 
training sct similar decision tree learning information gain metric 
sct built attribute input sentence classified positive negative particular database attribute included displayed attribute list 
creating list constraints done 
involved details explained 
map user input sql system creates partial parse hand crafted chart parser 
output transferred robust matcher create displayed attribute list set constraints translated sql 
semantic parsing important area natural language processing proved useful tackling realistic nlp tasks building natural language interfaces 
applications time consuming ineffective resulting poor performance scalability 
automated parser acquisition desirable 
avoid robustness problems building deterministic parser may want consider probabilistic framework parsing 
proposal probabilistic framework semantic parsing 
framework models parser directly assume generative semantic grammar may available domain interest 
new ilp learning system tabulate introduced learn multiple models set training data 
multiple learned models integrated statistical techniques linear weighted evidence combination produce probabilistic models learning semantic parser 
experimental results show approach outperform purely logical approach terms accuracy parser 
existing research integrating statistical relational learning methods puts emphasis producing classifier certain classification task emphasis just produce classification system precise probability model allow parsing performance 
precision probability estimation takes higher priority 
current system suffered problems probability estimation performed relatively close deterministic parsing approach domains data may readily available 
research direction focusing improving problems encountered existing approach demonstrating improved ability automate construction natural language interfaces databases 
extend gratitude supervising professor dr raymond mooney patience course timely critical comments come far 
committee time effort 
special people daimlerchrysler research technology center experimental database northern california restaurant domain available research purposes 
research supported national science foundation iri daimlerchrysler research technology center palo alto california 
abramson dahl 

logic grammars 
springer verlag new york 
ali pazzani 

hydra mm learning multiple descriptions improve classification accuracy 
international journal artificial intelligence tools 
ali pazzani 

error reduction learning multiple descriptions 
machine learning journal 
allen 

natural language understanding nd ed 
benjamin cummings menlo park ca 
armstrong warwick 

preface special issue large corpora 
computational linguistics iii iv 
bahl jelinek mercer 

maximum likelihood approach continuous speech recognition 
ieee transactions pattern analysis machine intelligence 


improving accuracy artificial neural network multiple differently trained networks 
neural computation 
berwick 

acquisition syntactic knowledge 
mit press cambridge ma 
breiman 

bagging predictors 
machine learning 
brown burton 

multiple representations knowledge tutorial reasoning 
bobrow collins 
eds representation understanding 
academic press new york 
buntine 

theory learning classification rules 
ph thesis university technology sydney australia 
califf mooney 

relational learning pattern match rules information extraction 
proceedings sixteenth national conference artificial intelligence pp 
orlando fl 
califf 

relational learning techniques natural language information extraction 
ph thesis department computer sciences university texas austin tx 
appears artificial intelligence laboratory technical report ai see www cs utexas edu users ai lab 
cameron jones quinlan 

efficient top induction logic programs 
sigart bulletin 
cestnik 

estimating probabilities crucial task machine learning 
proceedings ninth european conference artificial intelligence pp 
stockholm sweden 
charniak 

tree bank grammars 
proceedings thirteenth national conference artificial intelligence pp 
portland 
charniak hendrickson jacobson perkowitz 

equations partof speech tagging 
proceedings eleventh national conference artificial intelligence pp 
washington church 

stochastic parts program noun phrase parser unrestricted text 
proceedings second conference applied natural language processing pp 
austin tx 
association computational linguistics 
cohen 

fast effective rule induction 
proceedings twelfth international conference machine learning pp 

collins 

new statistical parser bigram lexical dependencies 
proceedings th annual meeting association computational linguistics pp 
santa cruz ca 
collins 

generative lexicalised models statistical parsing 
proceedings th annual meeting association computational linguistics pp 

duda gaschnig hart 

model design consultant system mineral exploration 
michie 
ed expert systems micro electronic age 
edinburgh university press edinburgh england 
friedman getoor koller pfeffer 

learning probabilistic relational models 
proceedings th international joint conference artificial intelligence ijcai stockholm sweden 
gams 

new measurements highlight importance redundant knowledge 
european working session learning th france 
hendrix sacerdoti 

developing natural language interface complex data 
acm transactions database systems 
hirschberg 

time fire linguist performance goes myths statistical natural language processing revolution 
invited talk fifteenth national conference artificial intelligence aaai 
jelinek mercer 

interpolated estimation markov source parameters sparse data 
proceedings workshop pattern recognition practice amsterdam netherlands 


discrimination constructive induction logic programs 
proceedings tenth national conference artificial intelligence pp 
san jose ca 
kolmogorov 

approaches quantitative definition information 
problems information transmission 
kononenko kovacic 

learning optimization stochastic generation multiple knowledge 
machine learning proceedings ninth international workshop aberdeen scotland 
pietra epstein roukos 

statistical approach language modeling atis task 
eurospeech madrid 
kuhn de mori 

application semantic classification trees natural language understanding 
ieee transactions pattern analysis machine intelligence 
kwok carter 

multiple decision trees 
uncertainty artificial intelligence 
litman 

cue phrase classification machine learning 
journal artificial intelligence research 
manning carpenter 

generative lexicalised models statistical parsing 
proceedings fifth international workshop parsing technologies pp 

merialdo 

tagging english text probabilistic model 
computational linguistics 
miller bobrow ingria schwartz 

hidden understanding models natural language 
proceedings nd annual meeting association computational linguistics pp 

miller stallard bobrow schwartz 

fully statistical approach natural language interfaces 
proceedings th annual meeting association computational linguistics pp 
santa cruz ca 
muggleton buntine 

machine invention order predicates inverting resolution 
proceedings fifth international conference machine learning pp 
ann arbor mi 
muggleton feng 

efficient induction logic programs 
muggleton 
ed inductive logic programming pp 

academic press new york 
muggleton srinivasan bain 

compression significance accuracy 
proceedings ninth international conference machine learning 
muggleton raedt 

inductive logic programming theory methods 
journal logic programming 
pearl 

probabilistic reasoning intelligent systems networks plausible inference 
morgan kaufmann san mateo ca 
pereira 

inside outside reestimation partially bracketed corpora 
proceedings th annual meeting association computational linguistics pp 
newark delaware 
plotkin 

note inductive generalisation 
machine intelligence 
quinlan 

induction decision trees 
machine learning 
quinlan 

learning logical definitions relations 
machine learning 
quinlan 

bagging boosting 
proceedings thirteenth national conference artificial intelligence pp 
portland 
quinlan 

learning order definitions functions 
journal artificial intelligence research 
rabiner 

tutorial hidden markov models selected applications speech recognition 
proceedings ieee 
ratnaparkhi 

learning parse natural language maximum entropy models 
machine learning 


computational study language acquisition 

eds advances computers vol 
pp 

academic press new york 
rissanen 

modeling shortest data description 
automatica 


natural language learning computer 
simon 
eds representation meaning experiments information systems 
prentice hall englewood cliffs nj 
slattery craven 

combining statistical relational methods learning hypertext domains 
page 
ed proceedings th international workshop inductive logic programming pp 

springer berlin 
stanley goodman 

empirical study smoothing techniques language modeling 
proceedings th annual meeting association computational linguistics 
thompson mooney 

automatic construction semantic lexicons learning natural language interfaces 
proceedings sixteenth national conference artificial intelligence pp 
orlando fl 
tomita 

efficient parsing natural language 
kluwer academic publishers boston 
waltz 

english language question answering system large relational database 
communications association computing machinery 
warren pereira 

efficient easily adaptable system interpreting natural language queries 
american journal computational linguistics 
webb 

experimental evidence utility occam razor 
journal artificial intelligence research 
woods 

transition network grammars natural language analysis 
communications association computing machinery 
zelle 

inductive logic programming automate construction natural language parsers 
ph thesis department computer sciences university texas austin tx 
appears artificial intelligence laboratory technical report ai 
zelle mooney 

combining top bottom methods inductive logic programming 
proceedings eleventh international conference machine learning pp 
new brunswick nj 
zelle mooney 

learning parse database queries inductive logic programming 
proceedings thirteenth national conference artificial intelligence pp 
portland 

