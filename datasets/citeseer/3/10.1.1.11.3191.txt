integrating perceptual cognitive modeling adaptive intelligent human computer interaction zoran wayne gray ric student member ieee li rosenfeld michael christian harry wechsler fellow ieee invited describes technology tools intelligent human computer interaction human cognitive perceptual motor affective factors modeled adapt interface 
emphasizes human behavior encompasses apparent human behavior hidden mental state behavioral performance 
expands interpretation human activities known 
addresses apparent perceptual aspect human behavior technology described addresses questions solution requires recognizing specific cognitive states 
integrates parsing interpretation nonverbal information computational cognitive model user turn feeds processes adapt interface enhance operator performance provide rational decision making 
technology proposed general stage interactive framework moves parsing raw sensory motor input interpreting user motions emotions building understanding user current cognitive state 
diagnoses various problems situation adapts interface appropriately 
interactive component system improves processing stage 
examples perceptual behavioral cognitive tools described 
adaptive intelligent hci important novel applications computing including ubiquitous human centered computing 
manuscript received may revised february 
li wechsler department computer science george mason university fairfax va usa mail cs gmu edu cs gmu edu fli cs gmu edu wechsler cs gmu edu 
gray cognitive science department rensselaer polytechnic institute troy ny usa mail gray rpi edu 
rosenfeld center automation research university maryland college park md usa mail ar umd edu 
department psychology arch laboratory program george mason university fairfax va usa mail gmu edu 
department psychology learning research development center university pittsburgh pittsburgh pa usa mail pitt edu 
publisher item identifier 
keywords adaptation behavioral performance cognitive modeling decision making feedback human centered computing human computer interaction hci intelligent interfaces interpretation human behavior nonverbal information perceptual modeling ubiquitous computing 
ieee imagine computer interface predict diagnose user confused frustrated momentarily distracted gathering variety nonverbal information responses eye fixations facial expressions upper body posture arm movements keystroke force 
imagine interface adapt simplify highlight tutor improve human computer interaction hci diagnoses predictions 
nonverbal information facilitates special type communication goal probe inner cognitive affective states mind verbal communication contemplated expressed 
addresses technology tools required develop novel computer interfaces suitable handling nonverbal information 
assume private single engine plane wanders commercial flight sector 
air traffic controller 
noticed plane evaluated flight path concluded shortly leave sector posing threat commercial aviation 
plane slipped unnoticed controller considered need alert reroute commercial flights sector 
simple data computer gets operator decisions impossible know busy controller attention directed intruder left focus urgent matters 
time intruder entered sector controller upper body erect tilted proceedings ieee vol 
july forward seat point gaze visual angle intruder pupils dilated facial expression indicated surprise force mouse click commercial intense normal 
imagine computer interface gathered information operator correctly diagnosed operator current cognitive state 
data decide 
combination nonverbal information decide intruder icon blink 
third combination zoom screen intruder icon controller point gaze 
dramatic types human computer problems benefit processing nonverbal information adaptive intelligent interfaces 
example operator repeatedly uses mouse gesture point circle indicate classified target 
confused frustrated simply 
confused interface automatically simplified optimal display complexity relative expertise operator tutorial offered lull 
diagnosis remedial action carried computer access nonverbal information operator 
arm movements indicate cognitive states surprise fatigue addition substitute verbal communication suitable deaf mute people gestures appropriate noisy environments 
example nonverbal information infer cognitive state user comes psychology response 
general agreement pupils increased cognitive activity return previous baseline activity decreases particular problem solved relaxation sets 
evidence support assertion constant motion pupil referred accentuated conditions fatigue 
knapp hall provide evidence regarding nonverbal information context expressions emotions locations 
particular note rarely eye area tested separately entire face judging emotions 
glance brow eye area may provide deal information emotion expressed 
example see tears certainly conclude person emotionally aroused cues may know tears reflect grief physical pain joy anger complex blend emotions 
similarly downcast eyes associated feelings sadness shame embarrassment nonverbal information new communication medium suitable behavior interpretation 
example existing facial processing extended task relevant expressions typical arbitrary set expressions identified face processing research 
technology tools proposed added benefit developing framework improve predictions consequences various interface decisions behavior important goal science hci 
particular emphasizes human behavior en apparent performance hidden mental state performance 
suggest integrated system approach measure corresponding perceptual cognitive states user adapt hci intelligent fashion enhanced human performance satisfaction 
outline follows 
section ii provides conceptual intellectual framework needed address issues related adaptive intelligent nonverbal interfaces 
section iii describes research related interpretation human activities known 
shortcomings dealing apparent perceptual aspect discussed provide motivation novel proposed methodology questions directly related recognizing specific cognitive states 
section iv describes detail methodology motivates choices 
addition migration emphasis placed fact performance needs monitored terms apparent external internal behavior 
contrast framework traditional bayesian networks dynamic belief networks meter external behavior 
section describes tools required implement perceptual processing module focusing interpretation lower arm movements facial expressions pupil size eye gaze location 
section vi describes technology required behavioral processing focusing novel area mouse gesture interpretation 
section vii overviews components embodied models cognition extended include affect 
section viii elaborates user interfaces adapted dynamically embodied model cognition additional issues need considered 
conclude section ix summary novel technology recommendations research tool development 
ii 
background hci developed competing methodologies direct manipulation intelligent agents known delegation 
approaches contrasted computer sitting passively waiting input human versus computer human 
dimension hci affective computing 
affective computing concerned means recognize emotional intelligence emotional intelligence includes bodily physical mental cognitive events affective computing presently focuses mainly apparent characteristics verbal nonverbal communication hci studies elicit emotions relatively simple settings 
specifically recognition affective states focuses physical form blinking face distortions underlying human emotions implicit behavior function impact user employs interface 
contrast established paradigms direct manipulation intelligent agents intelligent human computer interaction uses computer intelligence increase bandwidth integrating perceptual cognitive modeling adaptive intelligent hci fig 

system architecture adaptive intelligent hci 
humans interact computers 
nonverbal information facial expressions posture point gaze speed force mouse moved clicked parsed interpreted computer iteratively construct refine model human cognitive affective states 
availability users models adaptive fashion enhance appear intelligent causal outside observer 
computer technology needs change novel interfaces reality 
people change adapt interface computer presents 
people computer understand intentions motivations provide feedback necessary eventually adapt 
systems examples novel intelligent interfaces transition hci people computers augment capabilities display characteristics team behavior 
methodology propose see fig 
integrates parsing interpretation nonverbal information computational cognitive model user turn feeds processes adapt interface enhance operator performance provide rational decision making 
adaptive intelligent hci combines advanced perceptual recognition machine learning affective computing computational modeling embodied cognition 
methodology general stage interactive framework 
system moves parsing raw sensory motor input interpreting user motions emotions building understanding user current cognitive state 
diagnoses various problems situation adapts interface appropriately 
interactive component system improves processing stage 
example knowledge user current cognitive state helps predict changes eye head location turn improves image parsing 
expect approach potential benefits broad class 
integrated methodology advance areas basic research computer vision facial processing perception cognition human learning adaptation 
view approach necessary step developing systems human cognitive perceptual motor affective factors fully modeled adapt interface 
promotes human activity creativity 
part emerging intelligent synthesis environments supports human centered immersive computing infrastructure distributed collaboration rapid synthesis simulation tools life cycle system integration validation 
combines computational ability perceive mixed affordance input patterns reasoning abstraction learning adaptation communication language visualization 
concepts echo kant perception abstraction blind abstraction perception empty learning thought useless thought learning dangerous 
ubiquitous pervasive computing new metaphor computing provides users constant access information computation form mobile wireless computing devices personal digital assistants pdas cell phones wearable computers appliances endowed intuitive user interfaces 
ubiquitous computing maintains computing core removes central focus 
computing embedded surrounding invisible friendly world order facilitate collaborative creation dissemination knowledge 
ubiquitous computing virtual reality puts people inside computer generated world pdas 
ubiquitous computing involves explicit representations oneself humans possibly avatars representation cognitive affective social organizational aspects human avatar natural expressive faces gestures representing reasoning places organizational systems social relationships 
boundaries real world augmented reality virtual environments blurred create mixed reality 
virtual reality mixed reality seeks enhance real environment replace 
interface agent pda alert pilot impending collision ubiquitous computing display pilot airspace information provides continuous spatial awareness surrounding objects 
mixed reality metaphor avoids making systems appear human cases limited intelligence brittle interaction 
ubiquitous computing possible continuously adapting interface medium meet specific user needs demands 
emergence human centered interaction intelligent systems utilization verbal nonverbal communication create richer versatile effective environment human activity 
human centered design problem driven context bound employs computing technology tool user substitute 
emphasis supporting human activity adaptive intelligent interfaces building fully autonomous systems mimic humans 
approach human centered intelligent system technology seeks systems team players context human activity people computer technology proceedings ieee vol 
july interact achieve common purpose 
possible approach focuses building effective computational tools modeling interpreting fusing analyzing cognitive social interactions speech vision gesture haptic inputs affective state expressed body language 
goal expand human perceptual intellectual motor activities 
people tend bounds systems capabilities ranging reliance system performance cases inappropriate loss trust lack acceptance situations system performs 
ubiquitous computing seeks derive benefits truly complementary relationship human partners forcing computing thrive integrated virtual physical world people predictable comprehensible informative human partners 
forge trusted partnership expand human intellect abilities computing compliant demands communicative regarding processes cooperative endeavors 
ubiquitous computing emphasizes distributed affordances focused expertise 
people effective fully engaged mind body world 
apparent situated grounded computing leading practical intelligence facilitated shared context acquired intersection perception senses affective physiological language communication thought reason action purposive functional 
shared context leads human behavior subsequent 
soon reach point computing power storage cheap commodities relative challenge making readily effectively available 
vision ubiquitous computing reality emergence components 
wearable devices need supply correct just time information reduce wearer cognitive load 
devices combine communication computation context sensitivity supporting increased collaboration 
users able leave desktops continue daily tasks possibly engaging hands free tasks remaining connected computing communication resources 
wearable computers interaction real world primary task making current windows icons menu pointers wimp interfaces obsolete 
emerging augmented system interfaces people computing devices promotes mutual understanding including background goals motivations plans optimal sharing computational load 
iii 
review briefly review research related interpretation human activities 
apparent discussion deals apparent perceptual aspect cognitive element responsible aspect 
extensive analyzing images humans activities began 
listed 
large number papers face gesture recognition international conferences subject 
review early motion understanding approaches applications done shah 
review research papers hand gesture recognition hci done pavlovic broader review research papers visual analysis human motion done gavrila 
review papers nonrigid motion analysis particular articulated elastic motion aggarwal 
comprehensive review various methods computer vision capture human motions done moeslund granum 
remainder section review motion analysis understanding primary force human activities 
main criteria classify research human motion analysis 
research classified terms tasks focuses detection tracking recognition 
second classified terms models represent objects humans 
third classified terms control mechanisms 
detection humans static video images addressed background subtraction matching 
background subtraction method uses colors edges described 
authors background subtraction part system combining detection body labeling tracking humans :10.1.1.47.9503
cases cues skin color detect humans images 
authors motion single multiple cameras detect label track humans body parts video images :10.1.1.47.9503
authors approached problem matching 
humans parts detected tracked configurations points light displays markers image features configurations edges collections particularly shaped strips cylinders superquadrics 
tracking authors focused motions image points edges 
human models initialized hand frame sequence 
authors considered problem action activity gesture recognition humans shape motion information 
dynamic recognition appropriate interpreting video sequences done recursive neural networks deformable templates spatio temporal templates graphical models offer dynamic time warping clear bayesian semantics individual hmm interacting coupled chmm generative processes 
authors implemented systems combine detection tracking recognition 
second set criteria classifying research human motions model humans 
humans modeled elongated blob shapes implicitly integrating perceptual cognitive modeling adaptive intelligent hci explicitly 
deformable models utilized body part hand facial feature tracking 
authors modeled humans articulated stick figures approach particularly effective moving light display analysis 
humans modeled articulated objects parts correspond blobs strips tapered superquadrics cylinders :10.1.1.47.9503
third set criteria classifying research human motions mechanisms control search detection tracking recognition 
kalman filtering frequently examples include 
bayesian inference methods known condensation 
strategies include search algorithms best winner take 
bobick proposed taxonomy movement activity action 
taxonomy movements primitives requiring contextual sequence knowledge order recognized 
activities sequences movements states knowledge required recognize involves statistics sequence 
bobick gesture understanding falls category 
actions larger scale events typically include interactions environment causal relationships 
important distinction levels degree time explicitly represented manipulated ranging simple linear scaling speed constraint reasoning temporal intervals 
related includes biomechanics human modeling computer graphics movement notations choreography 
biomechanics researchers interested modeling forces torques applied human bodies tissues various physical activities models provide tools analyzing relationship movements actions 
computer graphics researchers interested producing realistic images virtual reality applications human factor analysis computer animation 
formalisms describing motions humans include movement notations dance notation sign languages 
iv 
adaptive intelligent hci methodology methodology quite general outlined fig 

main modules perceptual processing behavioral processing embodied cognition adaptive system interface 
user interacting adaptive system interface changes function current task state cognitive mental state user 
nonverbal front includes perceptual behavioral processing modules input consists raw sensory information user 
perceptual module processes images face eye gaze location pupil size upper body analyzes relative motions behavioral module processes information actions done computer interface directly keystroke choices strength keystrokes mouse gestures 
perceptual behavioral modules provide streams elementary features grouped parsed tracked converted eventually subsymbolic summative affective representations information processing modality 
words output perceptual behavioral processing modules stream affective states point time 
states recognized include confusion fatigue stress task relevant affective states 
quest subsymbolic summative affective representations motivated abstraction generalization communication reasoning particular perception control action cycle 
furthermore signal symbol integration transformation old difficult problem 
comes world surrounding mixture continuous space time functions discontinuities 
recognition discontinuities world leads representations different states world turn place demands behavioral strategies 
similarly agent biological artificial closed loop interactions world environment modeled continuous process switching behaviors naturally discrete 
furthermore tasks externally agents internally self imposed discretize continuous behavior 
sources discretization agent world behavioral space natural space time discontinuities world model agent world dynamics execution task task 
furthermore computer vision symbols served mainly data reduction mechanism ai missing explicit acknowledgment transformation signals symbols results loss information self correction updating mechanisms obtained symbolic information explicit models dynamic interaction agent world 
symbols provide nice abstractions low level strategies allow move level modeling hierarchy observe properties systems interactions environment macroscopic level 
symbolic representation mediates reasoning sequential repetitive nature various tasks 
adaptive intelligent hci methodology proposed addresses problems raised embodied cognition connect apparent perceptual behavioral subsymbolic affective representations symbolic mental states process adaptively derive summative subsymbolic states raw signals adapt user system interface enhanced performance human satisfaction 
task description language chosen manipulation tasks adaptive intelligent hci act pm cognitive architecture see section vii 
affective fed embodied cognition module mediate fusion reasoning possible cognitive states 
correspond external manifestations affective states cognitive proceedings ieee vol 
july states hidden directly observable 
embodied cognition module generates hypotheses possible task relevant cognitive states resolves resulting ambiguity drawing contextual temporal information optimally adapts interface order enhance human performance 
knowledge user state system state diagnose potential problems diagnoses trigger adaptive compensatory changes computer interface 
process described linear process fact interactive process information phases feed back augment processing earlier phases 
example knowledge current cognitive activities improve recognition affective states 
development perceptual behavioral processing embodied cognition modules interactions key making progress constructing adaptive intelligent interfaces 
embodied cognition module novel addition traditional hci approaches bridges direct manipulation intelligent agents physical modeling users augments emotional intelligence cognitive modeling user behavior 
capability modeling effects affective state cognitive performance impact choice models computational techniques employed 
experimental platform envisions continuous operation system extended periods time single user particular task environment 
possible personalize user interface able detect characteristics user automatically assume system properly initialized particular user 
comprise initialization hardware software acquiring physical perceptual behavioral cognitive model user calibration video cameras eye tracker detection face upper body 
initial localization facial landmarks crucial successfully tracking features time 
time user generic information concerning user expertise experience initialize cognitive model 
return users cognitive model user session retrieved instantiated current setting 
raw video data perceptual processing module include color intensity 
standard low level computer vision techniques extract additional features corners edge information motion feature maps 
feature extraction process guided initialized model spatial locations head upper body eyes mouth determined 
previous research perceptual processing includes detecting faces upper body automatic detection facial landmarks 
measurements acquired color intensity edge information motion considered order features 
features combined order acquire reliable estimates shape contour motion fields eye mouth facial regions arms 
immediate level hierarchy lower order parametric descriptions shapes motion fields associated smaller spatial regions corresponding eyes mouth sought 
modes parametric descriptions accumulated time processed learned vector quantization lvq yield subsymbolic indicators contributing assessment affective state 
variety eye movements involving pupils irises eyelids eyebrows captured different modes 
example movement eyelids reveal information stress level tension user 
level capture lower arm hand movements section provides additional description module 
level hierarchy uses upper body shape motion information 
estimate independently poses head shoulders undergo independent combined motions 
information poses abstracted modal analysis fed embodied cognition module 
processing raw eye data pupil location size requires additional computations currently performed effectively special purpose hardware 
eye tracker data includes time stamped coordinates point gaze diameter pupil samples second 
particular state information corresponds spatial location fixation occurred transitions states events correspond saccadic eye movements 
changes recorded eye positions parsed fixations saccades magnitudes directions 
eye blinks calculated raw data detecting consecutive samples zero pupil dilation 
eye blink indicated samples span time ms fixation data number eye blinks rate eye blinks mouse clicks calculated 
behavioral processing module processes keystroke choice rate mouse data clicks movements 
keystroke data include key choice timing keystrokes 
mouse data include time stamped coordinates pointer force frequency mouse clicks acceleration applied mouse movements 
keystroke data primary means cognitive model user updated process model tracking see 
raw mouse data collected time raw eye data sample collected 
mouse motion movement position screen dynamics describe applied force duration movement 
parsing interpreting mouse data deserve additional notes represent novel uses mouse data 
mouse data provide obvious performance data fast accurately users choices 
analyze force data hard individuals click mouse trajectory data users move mouse 
force data divided dimensions average force click duration click 
trajectory data treated form gesture data 
domains people gesture various aspects screen mouse mouse gestures indicators preliminary 
example people circle objects trace trajectories move rapidly objects 
informally seen behavior argus domain described 
recognize mouse gestures integrating perceptual cognitive modeling adaptive intelligent hci technique developed context sign language recognition 
hand gestures corresponding american sign language located projection analysis normalized size recognition takes place hybrid mixture connectionist symbolic experts consisting ensembles radial basis functions decision trees dts 
mouse data different ways 
corresponding mouse gestures passed embodied cognition module goal providing additional information aspects screen attended 
second addition corresponding combined mouse gestures force data allow possibility recognizing combinations affective states user 
person face may reflect fatigue person mouse gestures may reflect confusion 
research hand gestures people reflect different information internal cognition speech occurring gestures 
similarly real affective states combination basic states hypothesis components combinations may externalized simultaneously different external forms fatigue mouse movements disgust facial expressions 
simple alternative approach try go directly diagnoses affective states adaptations interface confusion simplify interface 
simple method take account cognitive state individual respect task performed 
best adapt interface usually depend cognitive operations currently performed 
example simplifying interface removing information information needed computations currently performed individual 
affective states directed particular aspects current task interface 
example particular object screen aspect interface source confusion better clarify simplify offending object aspect simplify random aspects interface entire interface cause confusion 
embodied cognition module uses process model tracing understand user behavior making intelligent interface adaptation possible 
model tracing cognitive model built capable solving human tasks way solved humans 
model aligned task behavioral choice data state world human chose see internal cognitive steps human taken order produce observed behavioral actions 
embodied cognition model uses affective degrees belief derived earlier perceptual behavioral processing modules 
embodied cognition module described section vii 
adaptive system interface module adapts interface current needs human participant 
different affective cognitive diagnoses include confusion fatigue stress momentary lapses attention misunderstanding procedures 
different adaptations include simplifying interface highlighting critical information tutoring selected misunderstandings 
instance examples described earlier force controller mouse click parsing facial expressions concur suggesting participant visual attention totally consumed commercial system intervene alert controller intruder presence 
similarly shift controller facial expressions wandering indicate attention cognitive model interprets resulting decrease cognitive resources due fatigue steps may taken load parts tasks increase salience components relieve controller 
types interface adaptations consider include addition deletion task details addition deletion help feedback windows changing formatting organization information addition removal automation simple subtasks 
details section viii 
perceptual processing describe tools perceptual processing including lower arm movements facial data processing eye gaze tracking mouse gestures 
additional tools possible including upper body posture head shoulders 
interpretation lower arm movements describe method detecting tracking interpreting lower arm hand movements color video sequences details see 
method relevant parsing raw sensory motor input particular interpreting user hand motions 
corresponds perceptual processing see fig 
role transform signals expressing affective state suitable embodied cognition component 
method works follows 
moving arm detected automatically manual initialization foreground background modeling 
dominant motion region detected normal flow 
expectation maximization em uniform sampling dijkstra shortest path algorithm find bounding contour moving arm 
affine motion model fit arm region residual analysis outlier rejection robust parameter estimation 
estimated parameters prediction location moving arm motion representation 
analogy linguistic analysis processed sensory information compact suitable interpretation lvq task motion information 
lvq maps affine motion parameters discrete set codes final transition signals hierarchical subsymbolic representation enabled clustering 
particular clustering map discrete set codes generated lvq codes circle specific activity swirling 
activity expression cognitive state corresponds sequence proceedings ieee vol 
july fig 

frames image sequences corresponding normal flow 
left frame sequence frames 
right frame swirling sequence frames 
upper row images 
lower row normal flows 
images collected sony vl progressive scan camera frame rate frames resolution pixels frame 
fig 

delineating foreground objects images fig 

top points high normal flow values high gradient magnitudes 
bottom foreground object outlines 
properly distinguished activities affective states mind 
figs 
show steps sible parsing raw signal generate subsymbolic description 
integrating perceptual cognitive modeling adaptive intelligent hci fig 

residual reestimated flows detected arms fig 

top residual flow computed difference computed normal flow estimated affine normal motion field 
bottom reestimated affine flow outlier rejection 
fig 

facial expressions individual baseline easy difficult load conditions 
processing facial data cognitive emotional states person correlated visual features derived images mouth eye regions 
fig 
illustrates pilot data facial expressions complex simulated radar classification task expressions subject baseline condition targets track low load condition targets high load condition targets 
detectable differences type expect differences subtle particular mouth eye regions display increase tension difficult task 
eye region visual features related cognitive states person include gaze direction position irises relative eyes pupil dilation degree occlusion iris pupil eyelids 
ex proceedings ieee vol 
july fig 

eye parameters pupil diameter iris diameter distance center iris upper eyelid distance center iris lower eyelid distance center iris eyebrow ample pupil dilation indicates arousal heightened cognitive activity gaze may indicate increased mental activity associated processing data 
visual features related emotional states include degree openness eyes positions eyelids relative irises positions shapes eyebrows raised drawn existence shape lines particular eye regions eye corners eyebrows lower eyelids 
example surprise indicated wide open eyes lower eyelids drawn raised eyebrows fear indicated wide open eyes upper eyelids raised exposing white eye lower eyelids tensed drawn eyebrows raised drawn happiness indicated primarily lower eyelids wrinkles may raised tense 
fig 
illustrates parameters measured eyes 
note expect parameters positive small eyes closed 
note parameters density lines eyes curvature eyelids eyebrows added complement parameters 
eye parameters acquired high resolution color images 
color edges detected combining gradients red green blue color bands edges thinned suppression 
irises pupils located generalized hough transform multiple size templates assumed shapes circular 
eyelids eyebrows detected variation method described edges vicinity irises labeled candidates eyelids eyebrows 
left column fig 
shows eye regions corresponding anger surprise happiness right column shows results detecting irises eyelids eyebrows corresponding images left 
numerical results examples shown fig 
follows 
images showing anger top row irises detected positions radii left eye image distance upper eyelid iris distance lower eyelid iris center distance iris center eyebrow right eye image distance upper eyelid iris distance lower eyelid iris center distance iris center eyebrow images showing surprise middle row irises detected positions radii left eye image distance upper eyelid iris distance lower eyelid iris center distance iris center eyebrow right eye image distance upper eyelid iris distance lower eyelid iris center distance iris center eyebrow images showing happiness bottom row irises detected positions radii left eye image distance upper eyelid iris distance lower eyelid iris center distance iris center eyebrow right eye image distance upper eyelid iris distance lower eyelid iris center distance iris center eyebrow computing ratios obtain results left right eye pairs anger surprise happiness 
eye gaze tracking people consider discard various aspects task quickly ms eye movements provide detailed estimates information individual considering 
eye tracking increasingly popular online measure high level cognitive processing 
gathering data location duration eye fixations psychologists able inferences microstructure cognition 
eye tracking estimating cognitive states rests immediacy assumption people process information seen eye mind assumption eye remains fixated object object processed 
long visual information requires fine discrimination assumptions generally considered valid visual information coarse scale people process information fixating 
order reliably separate eye fixations saccades needs sample gaze data times second accuracy visual angle 
variety eye tracking methods exist 
terms data collected eye popular methods light eye detecting corneal reflection simply visual images eye locating dark iris area 
method best depends external lighting conditions 
compute world person fixating popular methods 
method simplifies integrating perceptual cognitive modeling adaptive intelligent hci fig 

left column eye regions displaying top bottom anger surprise happiness 
right column processed eye regions 
calculations having fixed geometries forcing person hold biting bar putting head restraint 
second method person wear head sensor tracks head orientation location dimensions combines information eye direction information 
third method places eye tracking apparatus person head scene camera visual image displayed showing person currently looking point image indicating object fixated 
achieve high levels accuracy required methods require recalibration individual tracked session methods exist automatic recalibration 
method computing point fixation accurate purely research method applicability obvious practical reasons 
wants track upper body facial gestures time head mounted camera practical 
remote camera accurate method extreme levels precision probably needed 
separate fixations raw point regard data popular method movement time threshold distance consecutive points regard threshold sufficient length time fixation assumed 
sophisticated accurate approach uses centroid submodel tracing methodology developed anderson 
methodology involves categorizing eye movements hidden markov models hmms model tracing 
raw eye data categorized fixations saccades state hmm velocity information 
centroid fixation determined 
examine object screen closest centroid simply assume person looking object 
noise eye data frequently fixation 
hmm fitting process takes account closeness fixation objects screen context objects just fixated 
model fitting process done comparing sequence fixations plausible sequences fixations selecting sequence highest probability best fit 
fig 
presents example point regard data extracted user interacts complex computer display 
locations fixations determine objects encoded detailed level 
durations fixations determine objects involved detailed computations 
vi 
behavioral processing behavioral processing focuses kinds data input keyboard mouse 
keyboard mouse data primary inputs computer interface 
proposing perceptual processing sources information replace mouse keyboard 
addition serving direct interaction interface keyboard mouse input additional functions providing insights cognitive affective states user 
keystroke data provide information cognitive state user process model tracing described section vii 
mouse data provide information user cognition user affect process described 
mouse data divided primary types mouse gestures mouse move clicks 
mouse gestures movements mouse result mouse clicks 
proceedings ieee vol 
july fig 

example eye tracking data complex simulated radar classification task 
moving targets identified represented numbers left half screen 
details target track table right half screen 
overlaid interface image data changing dark light time 
identified eye fixations minimum indicated disks larger disks longer fixations 
hci environments movements nonfunctional systems provide information 
moment treat cases involve mouse click 
mouse gestures nonfunctional mouse movements viewed windows mind 
indicate objects currently reasoned 
common mouse gestures include circling objects linking objects circling groups objects shape tracing large objects groups 
object circling represents indecision object 
repetitive movement objects linking gesture circling groups objects represents categorical decision linked objects similar important dimension 
shape tracing larger objects represents reasoning shape object 
move click movements important dimensions speed movement force click directness movement clicked object 
dimensions indicators general level arousal indecision confusion 
slower movements weaker clicks combined direct movements indicate low levels arousal fatigue 
slower movements weaker clicks combined indirect movement indicate confusion 
fast movements strong clicks combined indirect movements indicate frustration 
recognize mouse gestures technique developed context sign language recognition 
hand gestures corresponding american sign language located projection analysis normalized size recognition takes place mixture connectionist symbolic experts consisting dts 
display robustness facing variability data acquisition process training original data distortions caused geometrical changes blurring preserving topology characteristic raw data 
addition similar boosting rbf components trained capture subregion perceptual behavioral landscape properly recognize 
inductive learning dts calls numeric subsymbolic data conversion suitable embodied cognition 
erbf output vectors chosen training tagged correct positive example incorrect negative examples properly quantized 
input dt implemented consists string learning positive negative events described vector discrete attribute values 
parse move click movements hmms user stay affective state movements 
states markov model diagnosed affective states fatigue confusion 
vii 
embodied cognition embodied cognition module core embodied cognitive model model tracing function 
cognitive model capable solving tasks cog integrating perceptual cognitive modeling adaptive intelligent hci nitive steps humans solve tasks 
embodied cognitive model affective states match user states ability perceive interact external world user 
model tracing model aligned task behavioral choice data state world human chose see internal cognitive steps human taken order produce observed behavioral actions 
embodied cognition model uses affective degrees belief derived earlier perceptual behavioral processing modules 
currently best way build models embodied cognition cognitive architecture act soar epic caps relatively complete validated framework describing basic cognitive activities fine grain size 
currently developed framework works building models embodied cognition act pm system combines act cognitive architecture modal theory visual attention motor movements 
act hybrid production system architecture representing knowledge symbolic level declarative memory elements productions subsymbolic level activation memory elements degree association elements probability firing productions 
act pm contains precise successful methods predicting reaction times probabilities responses take account details regularities motor movements shifts visual attention capabilities human vision 
task embodied cognition module build detailed mapping interpretations motion affective state parsed sensory motor data act pm model 
extend act pm true model embodied cognition incorporating effects affect performance 
example addition handling interactions memory vision motor movements model time distracted attend 
better merely distracted extended act pm model effects fatigue distraction memory vision motor behavior performance 
people model changes may occur 
model slows increasing interval physical actions shifts visual attention increasing time needed store retrieve information memory 
second accuracy responses decreases includes physical accuracy due increased noise eye hand coordination mental accuracy due increased noise memory retrieval retrieving target old current flight information 
third model distracted losing focus attention running risk applying right response wrong object wrong response right object 
fourth narrower chooses encode 
incorporation affective models embodied cognition product right 
capability applied task environments simu lated prototypes real systems determine changes human performance time 
models embodied cognition important tool designers real time safety critical systems see 
novelty lies broader range nonverbal data guiding model tracing process 
cognitive science suggests nonverbal information gestures provides important insights individual cognition 
mouse gestures eye data affective states important tools improve model tracing process 
explore qualitatively different methods incorporating affect cognitive model 
affect thought directly modifying parameters cognitive model produce relatively simple changes behavior 
example fatigue may affect processing speed fast thinks working memory capacity information kept mind 
similarly confusion frustration may influence noise parameter decision process likelihood making nonoptimal choices threshold amount effort person expend task influences probability giving 
parameters controlling processing speed working memory capacity noise effort expended formally defined act architecture 
second affect change structural strategic aspects cognitive model 
example people confused frustrated may adopt entirely different way thinking task making choices alternative strategies 
performance parameters cognitive model may held constant action decision rules may change affect changes 
third possibility combination types changes model changing affect 
individuals wide variety qualitatively different strategies solve type problem changes model performance parameters produce changes strategy choice 
example classic decision making study payne showed cognitive effort required task performance increased placing greater demands limited capacity working memory system decision making strategies people adopted changed 
lohse johnson showed changes decision making strategies induced tradeoffs perceptual motor versus cognitive effort 
may changes strategies induced changes affective state mediated changes underlying cognitive parameters 
act contains clear predictions certain parameter changes influence strategy choice assuming characterization features strategy 
process model tracing keeps model aligned user 
takes primary input behavioral interactions interface keystroke mouse click data tries match symbolic steps model 
production system model amounts matching sequences production firings 
factors shape model tracing process 
realistic model human cognition acknowledges stochastic variability proceedings ieee vol 
july human choices 
points time model choose randomly typically biases set alternative actions 
model tracing examines behavioral data identifies possible alternative paths model taken best fits observed behavioral data 
second factor shaping model tracing typically internal steps external step 
model run steps step potentially having alternative choices produce full set possible matches behavioral data 
internal steps external behaviors large set internal paths may need generated 
third factor behavioral data may uniquely distinguish different model paths 
circumstances select currently probable path 
addition eye tracking data density observable data points goes significantly making easier match models data 
viii 
adaptation user system interface system adapt interface current needs human participant embodied model cognition 
stated earlier different affective cognitive diagnoses include confusion fatigue stress momentary lapses attention misunderstanding procedures 
different adaptations include simplifying interface highlighting critical information tutoring selected misunderstandings 
types interface adaptations consider include addition deletion task details addition deletion help feedback windows changing formatting organization information addition removal automation simple subtasks 
changes described generically 
respect addition deletion task details important insight modern interfaces contain details relevant subtasks 
operator confused distracted may details relevant subtask interfere attention details needed accomplish subtask general strategy identify currently critical subtask goal eliminating details relevant subtasks enhancing details relevant critical subtask 
interface details relevant subtasks restored user appears able handle 
combination data eye tracking affective response data facial expressions provides important information regarding aspects interface change manner change 
example important aspect screen attended individual appears aspect highlighted 
contrast aspect screen attended unusually long period time coupled look confusion situation relevant help window displayed 
possible interface structures possible advantages disadvantages vary cognitive affective state user 
different interface structures optimal different points time particular structure gen suboptimal reason 
example having help window display help messages may useful confused individual may distracting individual 
alternatively having information screen may helpful individual harmful fully attentive individual appropriate extra information handle subtasks 
particular interface structure better situations avoid strange feedback loops user trained implicitly explicitly look frustrated task easier 
users trained correctly externalize internal states 
example frustrated look frustrated produce change useful dealing particular source frustration frustrated look frustrated produce changes reduce optimal performance frustrated 
model embodied cognition continuously updated reflect individual cognitive perceptual motor affective states possible different methods adapting interface reactive proactive 
reactive adaptation system waits external evidence cognitive affective change adapting interface 
example user confused confusion manifested confused look longer choice latencies longer fixations broader range entities 
reactive system adapts interface confusion manifested 
alternatively proactive system applies model embodied cognition capable performing task correct task state predicts kinds problems user encounter 
predictions adapt interface interface changes user confused frustrated bored diagnosed outward performance changes 
model tracing approached high level accuracy believe broadened set inputs explore including proactive interface adaptation system 
proactive reactive adaptation adaptation conservative relatively infrequent relatively small changes time 
interface constantly changing source frustration 
relatively small set possible changes interface set needs introduced initial training 
embodied model provides insights conservative predict disruptive various interface changes addition providing insights interface adaptations helpful 
ix 
described methodology extends current methods interpreting human activities 
approach central pieces 
integrating perceptual cognitive modeling adaptive intelligent hci behavioral interactions user interface processed rich fashion including novel mouse gestures provide richer understanding user cognitive affective states 
second additional nonverbal information gathered perceptual processing eye gaze pupil size facial expressions arm movements enrich understanding user cognitive affective states 
third embodied model cognition synchronized behavioral perceptual data produce deep understanding user state 
fourth computer interface adapted reaction problems diagnosed user cognitive affective states task sensitive way 
complete methodology implemented running system described tools required implement system 
tools appear current computational capabilities 
currently engaging research flesh computer science cognitive psychology underlying tools 
subtle components methodology require comment 
particular process building embodied cognitive model separate advantages intelligent adaptation interface 
forces develop highly detailed models precise cognitive affective problems user experience model designed perform task way user 
enforced detail allows precise diagnosis sources problems 
second embodied cognitive model allows test consequences different changes interface understanding interface changes help help 
embodied cognitive model rely simple rules thumb past experiences determine changes effective 
third embodied cognitive model predictive component allows predict problems user warn user advance fatigue occur load current arousal level 
developing running system implements methodology recommend strategy simulated task environment 
field research complexity allow definite laboratory research usually little complexity allow interesting 
study complex situations wish generalize results complex situations faced dilemma succinctly framed rner 
simulated task environments solution dilemma 
term simulated task environment meant restrictive inclusive 
types simulations term restricted intended simulations task environments 
time term includes range task simulations high fidelity ones intended substitute real thing way enable performance existing tasks 
common denominator simulated task environments researcher desire study complex behavior 
task environment complex challenge current state art malleable task complexity interface adaptivity controlled increased research progresses 
requirements met simulated task environments 
working approach context human operators interacting argus simulated task environment radar operator tasks 
tasks represent real time safety critical environment improving hci utmost importance 
similar issues relating image processing cognitive modeling intelligent interface adaptation hci wide variety domains medical educational business 
collect time stamp mouse click subject system response mouse movement accuracy ms interleave record data collected times second 
act pm models currently interact argus 
addition argus code written lisp simulated task environment easy modify 
perception general form behavior analysis particular important describe things aristotle realized long ago know bring light differences things categorize properly respond affordances 
forms behaviors represented important functionality serve discrimination classification 
recognition perceptual form behavior associated functionalities 
form behavior analysis considers things average prototypes similarity functionality perceptual behavioral layout innate physical geometrical constraints sensor motor affordances corresponding cognitive mental states 
view functional purposive recognition takes precedence perceptual behavioral reconstruction 
things changing constancy illusion form behavior recognition require generalization motivate learning adaptation 
form behavior analysis require bits ways destroy relations may essence say dissect embodied cognition described advocated provides glue connecting apparent visual form behavior hidden mental models bear functionality performance 
emphasize important role functionality plays perception instructive recall oliver sacks known book man wife hat 
book describes see interpret sees shown glove man calls receptacle moral people see eyes brain 
words perception involves purposive cognitive process advocates terms technology tools 
proceedings ieee vol 
july aggarwal cai nonrigid motion analysis articulated elastic motion comput 
vis 
image understanding vol 
pp 

image sequence analysis real world human motion pattern recognit vol 
pp 

goldin meadow gesture speech mismatch mechanisms learning hands reveal child state mind cogn 
psychol vol 
pp 

anderson boyle corbett lewis cognitive modeling intelligent tutoring artif 
intell vol 
pp 

anderson re eds atomic components thought 
hillsdale nj erlbaum 
anderson re act theory higher level cognition relation visual attention hum comput 
interaction vol 
pp 

badler phillips webber simulating humans 
new york oxford univ press 
badler smoliar digital representations human movement comput 
surveys vol 
pp 

bajcsy problem signal symbol integration study cooperative mobile autonomous agent behavior dagm symp germany 
barzel physically modeling computer graphics 
boston ma academic 
bobick movement activity action role knowledge perception motion philosophical trans 
roy 
soc 
london vol 
pp 

bregler learning recognizing human dynamics video sequences proc 
computer vision pattern recognition pp 

rner experiments computer simulated escaping narrow laboratory deep blue sea field study comput 
hum 
behavior vol 
pp 

bregler malik tracking people twists exponential maps proc 
computer vision pattern recognition pp 

buxton watching behavior role context learning proc 
int 
conf 
image processing vol 
pp 

byrne anderson perception action atomic components thought anderson re eds 
hillsdale nj erlbaum pp 

shah motion recognition survey image vis 
comput vol 
pp 


cham rehg multiple hypothesis approach tracking proc 
computer vision pattern recognition vol 
pp 

cohen schlesinger new dictionary sign language 
hague netherlands mouton 
davis bobick representation recognition human movement temporal templates proc 
computer vision pattern recognition pp 

davis harwood haritaoglu ghost human body part labeling system silhouettes proc 
arpa image understanding workshop pp 

deutscher blake reid articulated body motion capture annealed particle filtering proc 
computer vision pattern recognition vol 
pp 

li wechsler recognition arm movements proc 
int 
conf 
automatic face gesture recognition washington dc pp 

movement notation london nicholson 
essa pentland facial expression recognition dynamic model motion energy proc 
int 
conf 
computer vision pp 

coding analysis interpretation recognition facial expressions ieee trans 
pattern anal 
machine intell vol 
pp 

felzenszwalb huttenlocher efficient matching pictorial structures proc 
computer vision pattern recognition vol 
pp 

gavrila visual analysis human movement survey comput 
vis 
image understanding vol 
pp 

gavrila davis model tracking humans action multi view approach proc 
computer vision pattern recognition pp 

gavrila real time object detection smart vehicles proc 
int 
conf 
computer vision pp 

goldin meadow church transitions concept acquisition hand read mind psychol 
rev vol 
pp 

gould shah trajectory primal sketch multi scale scheme representing motion characteristics proc 
computer vision pattern recognition pp 

gray simulated task environments role high fidelity simulations scaled worlds synthetic environments basic applied cognitive research cogn 
sci vol 
pp 

gray patern special issue interface issues designs safety critical interactive systems acm trans 
computer human interaction vol 
pp 

guest graphics comparison dance notation systems century 
new york gordon breach 
wechsler hand gesture recognition ensembles radial basis function rbf networks decision trees int 
pattern recognit 
artif 
intell vol 
pp 

haritaoglu harwood davis real time system detecting tracking people proc 
computer vision pattern recognition pp 

hodgins pollard adapting simulated behaviors new characters proc 
siggraph pp 

hogg model vision program see walking person image vis 
comput vol 
pp 

huang wechsler detection human faces decision trees proc 
int 
conf 
automatic face gesture recognition killington vt pp 

ioffe forsyth finding people sampling proc 
int 
conf 
computer vision pp 

jabri rosenfeld wechsler detection location people video images adaptive fusion color edge information proc 
int 
conf 
pattern recognition 
hne digital image processing 
berlin germany springer verlag 
johansson visual perception biological motion model analysis perception psychophysics vol 
pp 

spatio temporal differentiation integration visual motion perception psychol 
res vol 
pp 

ju black yacoob cardboard people parameterized model articulated image motion proc 
int 
conf 
automatic face gesture recognition nara japan pp 

jung motion analysis articulated object optical motion capture ph dissertation kaist korea 
tech 
memo 
kakadiaris metaxas human body model acquisition multiple views proc 
int 
conf 
computer vision pp 

kieras meyer overview epic architecture cognition performance application human computer interaction hum comput 
interaction vol 
pp 

knapp hall nonverbal communication human interaction 
new york harcourt brace jovanovich 

lee chen determination human body posture single view comput 
vis 
graph 
image process vol 
pp 

leung 
yang human body segmentation complex scene pattern recognit vol 
pp 

sight human body outline labeling system ieee trans 
pattern anal 
machine intell vol 
pp 

science metamorphosis new york reviews books 
integrating perceptual cognitive modeling adaptive intelligent hci lohse johnson comparison process tracing methods choice tasks org 
behavior human decision processes vol 
pp 

task representations strategy variability base rate neglect experimental psychol general vol 
pp 

mckenna jabri rosenfeld wechsler tracking groups people comput 
vis 
image understanding vol 
pp 

mckenna jabri wechsler tracking interacting people proc 
int 
conf 
automatic face gesture recognition grenoble france pp 

moeslund granum survey computer vision human motion capture comput 
vis 
image understanding vol 
pp 

niyogi adelson analyzing recognizing walking figures proc 
computer vision pattern recognition pp 

oliver rosario pentland bayesian computer vision system modeling human interactions ieee trans 
pattern anal 
machine intell vol 
pp 

oren papageorgiou sinha osuna poggio pedestrian detection wavelet templates proc 
computer vision pattern recognition pp 

pavlovic sharma huang visual interpretation hand gestures human computer interaction review ieee trans 
pattern anal 
machine intell vol 
pp 

payne johnson adaptive decision maker 
new york cambridge univ press 
pearl probabilistic reasoning intelligent systems networks plausible inference 
san francisco ca morgan kaufmann 
davis quasi random sampling condensation proc 
eur 
conf 
computer vision vol 
pp 

picard affective computing 
cambridge ma mit press 
polana nelson detection recognition periodic nonrigid motion int 
comput 
vis vol 
pp 

annotated computer vision bibliography price 
online 
available iris usc edu vision notes bibliography contents html quinlan programs machine learning 
san francisco ca morgan kaufmann 
rashid system interpretation moving light displays ieee trans 
pattern anal 
machine intell vol 
pami pp 

kanade model tracking self occluding articulated objects proc 
int 
conf 
computer vision pp 

blake classification human body motion proc 
int 
conf 
computer vision pp 

rohr model recognition human movements image sequences cvgip image understanding vol 
pp 

anderson automated eye movement protocol analysis human computer interaction vol 
pp 

source individual differences strategy adaptivity changing rates success experimental psychol general vol 
pp 

gestures reveal scientist mind data analyzes data analysis ser 
inst 
brown bag series george mason univ 
shneiderman maes direct manipulation vs interface agents interactions vol 
pp 

sidenbladh black fleet stochastic tracking human figures image motion proc 
eur 
conf 
computer vision 
rosenfeld method detecting tracking irises eyelids video pattern recognit vol 
pp 

song goncalves di bernardo perona monocular perception biological motion detection labeling proc 
int 
conf 
computer vision pp 

starner pentland visual recognition american sign language hidden markov models proc 
int 
workshop automatic face gesture recognition zurich switzerland pp 

wachter nagel tracking persons monocular image sequences comput 
vis 
image understanding vol 
pp 

wechsler computational vision 
orlando fl academic 
wren azarbayejani darrell pentland pfinder real time tracking human body ieee trans :10.1.1.47.9503
pattern anal 
machine intell vol 
pp 

yacoob davis recognizing human facial expressions long image sequences optical flow ieee trans 
pattern anal 
machine intell vol 
pp 


yang ahuja recognizing hand gestures motion trajectories proc 
computer vision pattern recognition vol 
pp 

kinematics human motion 
champaign il human kinetics 
proc 
int 
workshop automatic face gesture recognition zurich switzerland 
proc 
int 
conf 
automatic face gesture recognition killington vt 
proc 
int 
conf 
automatic face gesture recognition nara japan 
proc 
int 
conf 
automatic face gesture recognition grenoble france 
zoran received degree electrical engineering university bosnia ph degree computer science university maryland college park 
joined faculty george mason university fairfax va fall assistant professor computer science 
published technical papers various aspects motion understanding computer vision journals conferences 
major focus research understanding physical constraints motions vehicles humans constraints building robust efficient vision systems 
wayne gray received ph degree university california berkeley 
prominent researcher fields human computer interaction hci cognitive task analysis computational models embodied cognition human error 
position army research institute worked tactical team training monterey field unit application artificial intelligence ai technology training air defense systems hawk ari hq alexandria va 
spent post doctoral year prof anderson lab carnegie mellon university pittsburgh pa joining ai laboratory nynex science technology division 
nynex applied cognitive task analysis cognitive modeling design evaluation interfaces large commercial telecommunications systems 
joining received government industry private foundations 
review board cognitive science journal associate editor journal human factors acm transactions computer human interaction 
chaired fourth international conference cognitive modeling chair annual conference cognitive science society 
rensselaer polytechnic institute troy ny professor cognitive science program director cognitive science ph program 
proceedings ieee vol 
july ric student member ieee received degree computer engineering university cincinnati cincinnati oh degree information systems american university washington dc 
currently working ph degree information technology george mason university fairfax va spent years various positions defense industry navy ibm lockheed martin 
presently associate professor information technology northern virginia community college serves program head computer science microelectronics campus 
research areas human computer interaction computer vision focusing monitoring affective cognitive states humans eye region biometrics 
member acm ieee computer society 
li received degree electrical engineering university science technology china degree computer science institute automation chinese academy sciences china 
currently working ph degree george mason university fairfax va research interests include automatic hand gesture recognition video tracking surveillance image processing pattern recognition model selection 
rosenfeld received ph degree mathematics columbia university new york ny 
distinguished university professor founding director center automation research university maryland college park 
held affiliate departments computer science electrical engineering psychology 
widely known researcher field computer image analysis 
published books book chapters journal articles associate editor journals directed nearly ph dissertations 
dr rosenfeld fellow professional societies won numerous professional society awards received doctoral degrees 
interactive behavior 
michael received ph degree george mason university fairfax va 
currently research scientist applied research cognition human factors laboratory george mason university 
research focuses computational modeling human computer interactions 
modeling methodology combines embodied unified cognitive theory task knowledge computer interface design constraints produce christian received ph degree psychology carnegie mellon university pittsburgh pa 
currently research scientist learning research development center assistant professor psychology department intelligent systems program university pittsburgh pittsburgh pa research uses combination psychological experiments computational cognitive modeling field observations study cognition underlying adaptive behavior scientific thinking basic psychology research questions apply improving education improving human computer interfaces 
research includes studying collaboration distance expertise science spatial thinking complex domains submarine sonar domain diagnosing repairing problems low level leadership strategies intelligent tutoring 
coauthored scientific papers chapters 
edited book designing science implications professional instructional everyday science hillsdale nj erlbaum 
chaired number international conferences including designing science th annual act workshop th international conference cognitive modeling th annual meeting cognitive science society 
harry wechsler fellow ieee received ph degree computer science university california irvine 
presently professor computer science director center distributed intelligent computation george mason university fairfax va research field intelligent systems areas perception computer vision automatic target recognition signal image processing machine intelligence pattern recognition neural networks data mining evolutionary computation genetic algorithms animats human computer intelligent interaction face hand gesture recognition biometrics video tracking surveillance interpretation human activity 
director nato advanced study institutes asi active perception italy statistics neural networks les arcs france face recognition theory applications stirling uk served chair international conference pattern recognition held vienna austria 
authored scientific papers book computational vision new york academic editor neural networks perception new york academic vols 

dr wechsler fellow international association pattern recognition 
integrating perceptual cognitive modeling adaptive intelligent hci 
