mining relevant text unlabelled documents daniel barbar ning kang information software engineering department george mason university fairfax va gmu edu automatic classification documents important area research applications fields document searching forensics 
methods perform classification text rely existence sample documents class labels known 
situations obtaining sample may easy possible task 
focus classification unlabelled documents classes relevant irrelevant topic interest 
dividing set documents buckets instance answers returned different search engines association rule mining find common sets words buckets efficiently obtain sample documents large percentage relevant ones 
sample train models classify entire set documents 
prove experimentation method capable filtering relevant documents adverse conditions percentage irrelevant documents buckets relatively high 

information retrieval content image retrieval web page classification face asymmetry positive negative examples 
suppose example submit query multiple search engines 
engine retrieves collection documents response query 
collections include general relevant irrelevant documents 
suppose want discriminate relevant documents irrelevant ones 
set relevant documents retrieved collections represent sample positive class drawn underlying unknown distribution 
hand irrelevant documents may come unknown number different negative classes 
general approximate distributions negative classes may representatives 
facing problem unknown number classes user interested 
modelling problem class problem may impose misleading requirements yield poor results 
definitely better focusing class interest positive examples scenario compact support reflects correlations feature values 
class labels data unknown data large expert label expert exists 
eliminate assumption having partially labelled data 
focus document retrieval develop technique mining relevant text unlabelled documents 
specifically objective identify sample positive documents representative underlying class distribution 
scenario query submitted multiple search engines serve running example technique applied variety scenarios data 
approach reflects asymmetry positive negative data particular unnecessary assumption negative examples 
related authors discuss hierarchical document clustering approach frequent set words 
objective construct hierarchy documents browsing increasing levels specificity topics 
authors consider problem enhancing performance learning algorithm allowing set unlabelled data augment small set labelled examples 
driving application classification web pages 
similar scenario technique depends existence labelled data 
authors exploit semantic similarity terms documents unsupervised fashion 
docu ments share terms different semantically related considered unrelated text documents represented bag words 
purpose overcome limitation learning semantic proximity matrix corpus documents consideration high order correlations 
methods yielding definition kernel function discussed 
particular model documents highly correlated words considered having similar content 
similarly words contained correlated documents viewed semantically related 
algorithm document possible associate bag words 
specifically represent document binary vector entry records particular word stem occurs text 
dimensionality determined number different terms corpus documents size dictionary entry indexed specific term 
going back example suppose submit query different search engines 
obtain collections buckets documents documents retrieved specific search engine bad irrelevant relevant ones expected frequent majority buckets 
addition assume positive documents drawn single underlying distribution compact support unifies buckets 
hand negatives manifest large variation 
characteristics develop technique discriminates relevant documents irrelevant ones 
details proceed follows 
mine bucket find frequent itemsets satisfy support level 
resulting itemset set words 
result process collection sets itemsets set bucket frequent itemset bucket possible compute itemsets frequent buckets distinct general experiments set consider limited number buckets driven number available documents topic 
wish retrieve documents support itemsets frequent buckets 
select buckets contain frequent itemset documents expressed 
resulting collection documents represent presumed positive documents relevant query 
algorithm call document mining summarized 
algorithm takes input buckets documents minimum support computation frequent itemsets 

input buckets documents 
compute frequent itemsets bucket 
compute itemsets frequent buckets 
set 
contains 
output set presumed positive documents important algorithm tuned ignore itemsets small size 
words fact may common documents different topics discriminate 
experience tells instance combinations frequent words sufficient discriminate different topics 
experimental results test feasibility approach reuters text categorization collection omitting empty documents labels 
common rare words removed vocabulary stemmed porter stemmer 
stemming vocabulary size 
experiments consider buckets documents vary percentage relevant documents concerning topic interest bucket topics interest select topics largest number documents available data set 
identified topic non relevant documents randomly selected remaining topics 
observe documents reuters data multiple topics associated grain crops 
experiments document considered positive topic interest associated topics 
topic examined test different values minimum support 
investigated different threshold values cardinality frequent itemsets 
frequent itemsets size equal threshold considered retrieval relevant documents 
rationale test item common different documents little discriminating power 
setting proper threshold allows discard frequently words removed preprocessing discriminating 
experiments show threshold values depending value minimum support give results 
tables report value number retrieved documents number positive relevant documents percentage positive documents precision percentage positive documents retrieved recall 
parenthesis total number positive documents versus total number documents buckets 
considered different topics experiments 
lack space report results topic earn documents 
similar results obtained topics 
distribute available positives buckets adjust number negatives accordingly value considered 
tables show results 
figures plot precision values topic earn increasing threshold itemset size line corresponds value percentage positive documents bucket 
plots show case setting allows achievement precision value close 
larger support values suffices selection pure sample documents 
adverse condition documents buckets algorithm able achieve high precision 
results promising purpose constructing classifier uses selected collection documents positive sample 
introduced new algorithm association rule mining select representative sample positive examples set unlabelled documents 
experiments show method capable selecting sets documents precision cases frequent itemsets cardinality considered 
emphasize cases precision tends reach high levels cardinality common itemsets grows regardless value support percentage relevant documents original buckets 
table 
topic earn 
table 
topic earn 
table 
topic earn 

blum mitchell 

combining labelled unlabelled data training 
proceedings conference computational learning theory 
chen zhou huang 

class svm learning image retrieval 
proceedings international conference image processing 
dumais littman landauer 

automatic cross language retrieval latent semantic indexing 
aaai spring symposium cross language text speech retrieval 
fung wang ester 

hierarchical document clustering frequent itemsets 
proceedings siam international conference data mining 
joachims 

text categorization support vector machines 
proceedings european conference machine learning 
kandola shawe taylor cristianini 

learning semantic similarity 
neural information processing systems nips 
leopold kindermann 

text categorization support vector machines represent texts input space 
machine learning 
lewis reuters text categorization test collection distribution 
kdd ics uci edu databases reuters reuters html porter 

algorithm suffix stripping program www org martin zhou huang 

small sample learning multimedia retrieval 
proceedings ieee conference computer vision pattern recognition 
precision 
precision values topic earn axis minimum cardinality common itemsets 
precision precision table 
topic earn 

precision values topic earn axis minimum cardinality common itemsets 

precision values topic earn axis minimum cardinality common itemsets 
