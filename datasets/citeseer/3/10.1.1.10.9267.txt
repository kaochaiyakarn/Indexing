power aware qos aware service model wireless networks studies show wireless network interface wni accounts significant part power consumed mobile terminals 
putting wni sleep idle effective technique save power 
support streaming applications existing techniques put wni sleep due strict delay requirements 
novel power aware qos aware service model wireless networks 
proposed model mobile terminals proxies buffer data sleep long time period 
achieve power aware communication satisfying delay requirement flow scheduling scheme called bulk scheduling pbs designed decide flow served time 
analysis prove pbs service model provide delay assurance achieve power efficiency 
audio demand web access case studies evaluate performance pbs service model 
experimental results show pbs achieves excellent qos provision flow significantly reduces power consumption 
index terms power aware simulations qos scheduling buffer management wireless networks 
advent third generation wireless infrastructure rapid growth wireless communication technology pervasive computing possible people battery powered mobile terminals cellular phones pdas handheld computers access various kinds services time place 
goal achieving ubiquitous connectivity small size low cost mobile terminals mts challenged power constraints 
mts powered battery rate battery performance improves fairly slow 
aside major breakthroughs doubtful significant improvement expected foreseeable 
trying improve amount energy packed power source carefully design communication protocols mts perform functions provide services minimizing power consumption 
understanding power characteristics wireless network interface wni mts important designing power efficient communication protocols 
typical supported part national science foundation career ccr itr 
hao zhu cao department computer science engineering pennsylvania state university university park pa mail cse psu edu wni may exist active sleep state 
active state wni may transmit receive idle modes 
studies show power consumed active state similar significantly higher power consumed sleep state 
result power management concentrates putting wni sleep idle 
stemm katz studied transport layer approaches application driven approaches help power wni 
protocols proposed put wni sleep conditions wni idle wni may collide mts wni suffers interference 
works focus reducing power consumption 
applied data applications qos requirements may streaming applications audio video ondemand due lack qos provisions 
applications popular internet possible mobile environments 
example nokia models start support mp 
idc predicts europe users listen music delivered wireless channel 
compared power consumed music playing wni consumes energy total power nokia 
achieve audio demand aod wireless networks reducing power consumption wni major issue 
streaming applications qos requirement achieve power saving violating qos big challenge supporting streaming applications wireless networks 
takes time wni wake sleep 
reported transition time active sleep back active order tens milliseconds 
due state transition delay existing power management schemes may directly applied streaming applications inter packet arrival time small mt power wni violating delay requirement 
deal transition delay propose support power save mode buffers 
proposed solution proxy added mt side 
proxy buffers data server lets wni enter sleep buffered data run 
wakes wni downloads ieee ieee infocom data fill buffer 
base station bs may serve large number mts simple solutions may able manage proxy violating qos 
example simple solution mt sends request bs buffer near empty bs serves mt request mt buffer full serving 
approach minimize power consumption may violate qos multiple mts send requests time 
condition bs serve mt time mts may wait long time delay requirement may violated 
propose new scheduling scheme called priority bulk scheduling pbs utilize client buffer save power provide qos 
pbs scheduler keeps track amount prefetched buffered data flow 
flow sufficient buffered data suspended buffered data runs flow insufficient buffered data served priority determined delay requirement 
buffered data wni sleep long offset impact state transition delay 
suspending flows active flows sharing channel obtain bandwidth take time fill buffer 
extend service model consider channel errors applications strict delay requirements 
analysis prove pbs provide delay assurance real time applications power efficient conventional rate fair queuing models 
audio demand web access case studies evaluate performance pbs service model 
experimental results show pbs achieves excellent qos provision flow significantly reduces power consumption 
rest organized follows 
section describe system model 
section iii describe details pbs service model 
section iv evaluate performance 
section presents related section vi concludes 
ii 
system model geographical area divided cells wireless network 
inside cell base station bs communicates mobile terminals mts uplink downlink channels 
uplink downlink channels divided time slots 
uplink assume channel randomly accessed mts granted downlink reservation 
location dependent errors may happen due channel fading interference 
simplicity assume modulation techniques coding techniques fixed 
certainly link adaptation schemes select suitable modulation coding technique current channel quality complement solution 
order achieve reliable transmission downlink packet acknowledged 
channel condition measured number packet retransmissions 
wni spends significantly higher amount power times active compared sleep accumulated wni sleep time measure power efficiency different schemes 
order accurately measure power consumption notations 
toff time spent transit sleep active 
ton time spent transit active sleep 
assume power consumed state transition active sleep sleep active similar active mode larger power consumed sleep mode 
iii 
pbs service model section pbs service model 
looking details look drawbacks existing scheduling algorithms terms power efficiency qos provision 
background motivation order provide guaranteed service shared link rate service disciplines proposed 
principle service models provide flow guaranteed data rate affected mis behaving flows sharing link 
scheduling algorithm classified conserving non conserving 
conserving scheduling server idle packet send 
non conserving scheduling packet served eligible server idle time 
applying existing scheduling algorithms wireless networks power issues considered 
explained section putting wni sleep widely method save power 
conserving service discipline difficult put wni sleep 
reason follows 
mt shares link mts conserving guaranteed service model applied service sequence link depends scheduling pattern flows 
scheduling pattern related number backlogged flows deadlines head line packets flows 
unfortunately mt know service sequence due lack global information regarding scheduling pattern flows system 
wni stay active know packet arrive 
may cause wni waste lot power 
example shown suppose flows flow mt flow mt link mt flow fig 

example conserving link sharing ieee ieee infocom share link capacity flow mt receiver 
suppose flows want send bits data rates respectively 
conserving service model quite large mt active time approximately mt effective receive time easy see power wasted 
non conserving virtual clock nvc non scheduling save power 
basic idea wni enter sleep 
simple approach bs mt mutually agree scheduling pattern 
bs sends packet mt scheduler piggybacks information eligible time packet transmitted 
note eligible time calculated flow data rate 
scheduler works non conserving manner serve flow eligible time channel idle 
mt enter sleep eligible time packet 
simple approach referred non conserving virtual clock nvc scheduling 
nvc save large amount power theory may possible practice 
due reason takes time power wni transit sleep active 
suppose toff ms ifthe packet interval time denoted flow ms toff 
nvc scheme put wni sleep violating qos requirement flow ton toff power saved ton toff 
packet packet fig 

relationship state transition packet interval time see ton toff total packet interval time state transition 
addition transition costs lot power nvc scheduling algorithm save power ton toff 
bulk scheduling bks reasoning approach called bulk scheduling bks reduce power 
service policy channel divided bulk slots 
flow needs served wakes bulk slot 
scheduler randomly selects flow serve time selected flow served bulk slot 
losing flows enter sleep wake wait case order provide qos wni stay active scheduler serves flow conserving manner 
service bulk slot 
bulk slot bulk slot bulk slot bulk slot mt served mt served mt served mt served fig 

example bulk scheduling shows example bulk scheduling 
example flows share link receivers mt mt mt respectively 
bulk slot equal number bits capacity link 
mt wakes enters sleep scheduler selected mt serve 
procedure happens 
att wakes starts receive data 
suppose mt wants transmit bits 
large power state transitions idle active negligible active time mt allows mt stay sleep maximum amount time 
bulk slot significantly larger ton toff power consumption state transition neglected bulk scheduling optimal service model terms power efficiency 
bulk scheduling provide qos multiple flows request data time 
example suppose mt mt deadline waiting time slot scheduling mt serve force mt deadline 
order address drawbacks nvc approach bks approach propose priority bulk scheduling pbs service model considering qos provision power efficiency 
basic idea pbs mt buffer data possible affecting qos requirement flows 
relying buffered data mt put wni sleep wake prefetched data satisfy qos requirement 
way wni power time slots 
furthermore mt enters sleep mts share channel fewer mts ideally mts 
mts spend small amount time active mode prefetch data saves power 
pbs detail pbs service model parts scheduler bs side proxy mt side 
scheduler control channel access multiple mts 
proxy coordinate scheduler mt side 
describe algorithm scheduler show proxy works 
solutions deal channel errors calculate computation complexity prove properties service model 
pbs scheduler pbs packet flow assigned deadline 
scheduler orders transmission packets deadlines 
flow aggregated service goes minimum service required ieee ieee infocom maintain qos removed scheduling region needs data maintain qos 
result flow suspended periodically data transmitted form runs packets 
service accounting loss generality flow assume served packet entering scheduling region indexed 
packet assigned deadline packet length flow data rate 
formally deadlines seconds computed follows ei dj lj ri jth packet flow fi ei eligible time fi deadline packet pj lj length pj ri data rate fi bps 
suppose head line packet fi time ahead service seconds fi denoted computed follows max ln returns fi served returns 
trace amount prefetched data mt side negative time 
scheduling state management bs side flow scheduling states idle active 
transitions scheduling states fi denoted statei controlled scheduler 
purpose flow control upper limit ahead service flow fi denoted 
scheduler stops serving changes statei idle 
suppose scheduler provides ahead service fi system parameter represent lower bound ahead service 
exists flow say fj got ahead service scheduler lets fi yield channel flows changing statei idle 
statei changed idle eligible time fi current time plus 
time scheduler updates value eligible time indicate fi moved back scheduling region 
fi changed idle scheduler serve eligible time expires 
eligible time expires state changed active shown 
statei set idle scheduler notify mti shutdown wni 
assume bs mark packet transmitted mt power wni receiving marked packet 
mt address equal destination address packet bs simply bit packet header represent time mt flow prefetched data 
simplicity say flow got ahead service 
ri notations set flows active state di deadline head line packet fi current time schedule null idle time slot goto primary flow select primary flow fi eq 
arg min dj deadline secondary flow fj violated serve fj fi deque get packet transmitted fj mark send transmission successful di di length ri marked ei statei idle goto fig 

pbs algorithm packet marked 
mt receives marked packet replies ack puts wni sleep 
bs receives ack knows wni powered suspends related flow 
scheduler pbs scheduler works follows 
flows active scheduler selects flow primary flow flows secondary flows 
time scheduler exclusively serves primary flow provided deadlines secondary flows violated 
deadline secondary violated scheduler serve secondary flow order meet qos requirement flow 
words scheduler serves primary flow conserving manner secondary flow served conserving way 
ri rj see property section iii approximation fast flow fi ahead service primary flow scheduler selects flow take shortest time get ahead service primary flow 
formally time primary flow selected follows arg min ri rj set flows active state channel ieee ieee infocom capacity 
principle eq similar shortest job policy minimize average waiting time 
average time flow get minimized pbs 
head head fig 

illustration pbs scheme shows pbs scheme works 
backlogged flows system 
flow kbps data rate unlimited 
suppose seconds kbps packets packet length kb 
time eligible time flows expires ahead service flow 
suppose selected primary flow time 
meet deadlines scheduler serves 
time violating deadlines equal served back back 
time eq ahead greater 
suspended eligible time set 
time primary flow 
follow procedure suspended time 
time active flow scheduler serves time eligible time expires 
head head fig 

illustration wfq scheme time time demonstrate power efficiency pbs compare time period flow get ahead service wfq pbs 
shown wfq needs seconds get ahead service needs seconds 
comparing correspondent time periods needs second see average time period flow get ahead service pbs smaller wfq 
application aware extensions compared streaming applications applications ftp www may stringent delay requirements 
suppose non streaming flow say fk requires data channel utilization high 
fk admitted scheduling region eq see time spent primary flow get ahead service increased secondary flows wait longer primary flow 
active flows spend time active state power consumption increased 
fk strict delay requirement better postpone serving time fk specified time period denoted 
assign integer relax factor flow fi bounded max flow strict delay requirement upper bound simply set 
fi deadline expires scheduler decides serve current system utilization measured number active flows 
current system utilization greater threshold denoted thresh scheduler lets fi yield channel period 
fi served 
avoid starvation adaptive scheme manage follows 
scheduler decides fj yield channel decreased fj leaves channel ahead service greater increased 
service loss due yielding compensated decreasing ahead service 
adaptive scheme maximum delay fi admitted scheduling region 
pbs proxy proxy associated receiver flow 
proxy downloads data bs monitors amount prefetched data manages operation modes wni 
proxy coordinates server decides wni enter sleep 
similar scheduler proxy calculate ahead service flow flow data rate packet length arrival time packet 
proxy finds packet marked wni shutdown time period equal calculated ahead service 
way control overhead reduced scheduler need tell length sleep period 
multiple applications supported wni shut proxies running mt requested 
wni wakes proxy needs time 
mt knows proxies running easily implemented 
dealing channel errors wireless communication channel error prone error bursty 
channel errors exist probability successful transmission low bandwidth power may wasted re transmissions 
similar deal channel errors swapping time slots flows suffering channel errors flows channel conditions 
focus ieee ieee infocom minimizing influence channel errors qos power consumption flow pbs service model 
approach packet delivered data ack order 
bs receive ack packet knows transmission fails 
transmission failure scheduler re transmits packet times 
packet delivered bs assumes flow say fi experiencing channel error 
case bs stops fi 
time proxy fi realizes error problem transmission failures shuts wni 
may worth power wni actual sleep time short 
scheduler stops serving fi pre specified short period called backoff period proxy fi lets wni stay active 
backoff period scheduler resume serving fi 
iffi suffers channel errors backoff procedure applied fi 
channel errors bursty leaving channel time flow may get channel state served 
flow leaves channel total number flows sharing channel decreases allocated data rate remaining flow increases 
result active mts spend time active reduce power consumption 
rare situations channel error may long violate qos requirement 
time solution left change modulation coding schemes 
major concern discuss 
computation complexity pbs takes division addition get ahead service seconds mt side 
bs side operation consists selection primary flow cost log updates ahead service flow cost 
pbs computationally feasible wireless networks moderate number flows bs 
mts easily get data rate flow backoff period non streaming applications session initialization 
performance terms qos power efficiency pbs sensitive selection system heavily loaded see section iv require precise information length state transition delay 
requirement larger delay 
property pbs section important properties pbs scheme 
prove pbs achieve power efficiency qos provision flows system 
simplicity assume channel channel capacity error free flow data rate proofs shown appendix 
property delay guarantee set backlogged flows system pbs scheduler serve packet lmax time server starts serving max maximum packet length 
property power efficiency suppose set backlogged flows system consider process flow prefetches ahead service greater equal leaves channel 
lmax average active time pbs weighted fair queuing wfq denoted tact bs tact respectively follows tact tact bs max max property gives lower bound ratio average active time wfq pbs 
give example show numerical results ratio function 
suppose kbps kbps ms max bits 
shown increases ratio lower bound increases 
shows pbs power efficient wfq 
lower bound recv wfq recv fig 

numerical results lower bound act act bs iv 
performance evaluations experimental setup evaluate performance pbs service model case studies consisting audio demand aod www services 
aod streaming service evaluated trace driven simulation 
downloaded demo mp audio streams trace source 
mp streams variable bit rate vbr extracted information frame frame size frame bit rate frame sample rate get bit rate packet 
interval successive songs distributed randomly 
www service ieee ieee infocom total nit sec throughput kbyte bks pbs nvc bks pbs nvc aod aod aod aod bks pbs nvc www www bks pbs bks nvc pbs bks pbs nvc nvc time sec bks pbs nvc bks pbs nvc bks pbs nvc bks pbs nvc bks pbs nvc bks pbs nvc aod aod aod aod www www switch buffer size kbyte buffer size kbyte buffer size kbyte buffer trace aod bks buffer trace aod pbs buffer trace aod nvc quality service power consumption buffer trace aod fig 

performance comparisons bks pbs nvc channel errors emulated simple traffic model mimics web user access behavior 
period start new web page requested 
run data finished period user studies information just downloaded 
assume total page size period exponentially distributed mean kb length period exponentially distributed mean seconds 
capacity wireless channel assumed kbps tdma 
time slot ms transmit bytes data including header 
mt represents user having aod www flow 
flow allocated data rate kbps 
simulation time seconds 
ms toff ms 
pbs server sets ms thresh 
addition backoff period flow fi set ms ms respectively 
relax factor set www flows set ms aod flows 
channel errors modeled state markov chain states bad 
probability state bad state bad state state 
channel state packets transmitted correctly 
channel bad state packet transmissions fail 
evaluate performance proposed service model factors amount prefetched data qos time spent active sleep state transition 
total noticeable interrupt time nit measure quality playback audio 
tiny interrupts noticeable human continuous interrupts greater ms counted 
normal delay requirement telephone voice service dealing music 
simulations total nit equal aggregated noticeable interrupt time intervals 
www service strict delay requirement qos measured throughput equal total amount data bytes transmitted 
evaluate time spent operation mode ton toff denote total time spent active sleep state transition respectively 
compare performance pbs scheduling bulk scheduling bks non conserving virtual clock nvc scheduling scheme 
choose bulk slot time second bks 
buffer mt side bks approach nvc approach 
bks mt stays sleep served prefetched data run 
nvc mt aod flow goes sleep buffer full wakes buffer near empty 
evaluation considers scenarios 
scenario channel error free 
scenario error prone channel considered 
evaluate impacts 
scenario error free channel scenario show fundamental difference pbs bks nvc 
evaluation includes aod flows www flows 
see playback quality pbs approach nvc approach perfect total 
compared pbs nvc bks approach provides poor qos total nit aod flow greater seconds throughput www flow pbs nvc 
flows sharing channel highly possible flow request data bulk slot 
bks scheduler randomly selects winning flow serve 
result losing flows served bulk slot delay requirements violated 
shown flows www www higher throughput nvc pbs pbs lets www www yield channel system utilization greater 
hand shown power consumption wni nvc significantly higher pbs bks 
data rate quite high kbps average inter packet arrival periods ton toff 
result wni go sleep nvc approach 
wni enter sleep actual sleep period reduced ton toff 
ieee ieee infocom total nit sec throughput kbyte bks pbs nvc bks pbs nvc aod aod aod aod bks pbs nvc www www bks pbs bks nvc pbs bks pbs nvc nvc time sec bks pbs nvc bks pbs nvc bks pbs nvc bks pbs nvc bks pbs nvc bks pbs nvc aod aod aod aod www www switch buffer size kbyte buffer size kbyte buffer size kbyte buffer trace aod bks buffer trace aod pbs buffer trace aod nvc quality service power consumption buffer trace aod fig 

performance comparisons bks pbs nvc channel errors shows approaches buffer trace flow aod 
buffer size goes wni receives data active mode 
time period buffer size goes buffer size near zero wni stays sleep 
slope buffer increment indicates fast flow fills buffer 
bks flow served bulk slot actual data rate equal channel capacity ideal power efficiency 
see slope buffer increment pbs equal bks shows power efficiency pbs 
pbs time scheduler serves primary flow provided deadlines secondary flows violated 
result actual data rate primary flow may quite high secondary flows 
hand suspending primary flow gets ahead service new selected primary flow competes channel flows gets higher data rate 
compared pbs bks slope nvc bks time period time period 
data rate flow quite high receiver wni chances go sleep nvc 
time scheduler serves flows conserving manner 
large number flows share channel actual data rate flow small reduces power efficiency 
example see pbs combines advantages bks nvc 
throughput www services pbs nvc considering saved power believe benefit outweighs disadvantages 
scenario error prone channel subsection evaluate impact channel errors scheduling approaches 
introduce channel errors scenario assume channel errors bursty location dependent 
assume aod www experience channel errors users channels 
shown channel errors exist playback quality bks approach nvc approach worse pbs approach 
poor playback quality bks approach explained scenario reason valid example 
nvc approach consider deal bursty location dependent channel errors flows channel conditions affected flows channel errors 
result playback quality flow severely degraded 
contrast time slot pbs scheduler lets flow suffering channel errors yield channel flows clean channel flows clean channel qos 
aod suffers channel errors playback quality aod aod don channel errors better bks nvc 
pbs approach aod channel prefetches data 
prefetched data channel condition bad aod leave channel 
channel errors bursty mechanism offset impact channel errors 
channel errors long time qos may violated total nit aod seconds 
shown ton flow pbs greater scenario flows channel errors stay scheduling region due lack ahead service 
state management scheme pbs flows suspended ahead service equal little bit 
ms receiver wni flows sleep long time number state transitions increases 
explains increases flows channel errors verified buffer trace aod 
see pbs average amount data buffer 
impacts increases number transitions sleep active drops 
large time spent getting ahead service long 
workload ieee ieee infocom time sec aod aod aod aod aod aod aod aod aod aod aod aod aod aod aod aod aod aod ms switch total number transitions aod aod aod aod aod aod aod aod aod aod aod ms aod aod aod aod aod aod aod buffer size kbyte buffer size kbyte buffer size kbyte buffer trace aod ms buffer trace aod ms buffer trace aod ms power consumption total number transitions buffer trace aod system heavy cases number flows insufficient ahead service small 
result actual data rate flows high time spent getting ahead service short 
pbs sensitive workload small 
average rate aod flow kbps maximum number aod flows reach average flow rate admission control 
scenario increase workload aod flows assume channel error free 
evaluate performance ms ms ms respectively 
flows show due limited space 
simulation results shown 
increases time get ahead service increases ton longer 
smaller number state transitions increases larger 
sum active time state transition time different values difference 
power consumed state transition similar active state performance pbs sensitive 
power consumption state transition higher small 
total transition time close different show number transitions different 
seen number transitions ms half ms 
decreases number flows time spent getting ahead service increases decreases 
flow takes small amount time receive data 
small prevents wni staying sleep long time period wni switch frequently 
result increases 
due similar reason decreases increases 
see behavior wni different different 
related power management wireless networks received considerable attention 
ieee supports power saving mode wni needs active periodically 
fig 

impacts pbs wireless lan wni sleep mode wakes periodically check possible incoming packets bs 
bs transmits beacon frame regular beacon interval 
beacon frame traffic indication map tim contains information wni buffered incoming packets 
wni finds incoming packets stay active receive packets 
mechanism streaming applications continuously arriving packets forces report new data keeping wni stay active 
energy conserving medium access control ec mac scheme wireless mobile atm networks proposed 
ec mac designed supporting multimedia traffic providing qos wireless atm networks 
authors proposed priority frame round robin scheduling scheme considering dynamic reservation update error compensation 
power saving achieved allocating contiguous time slots flow 
frame wni needs active data phase 
ec mac consider state transition delay 
frame length short wni may able go sleep due transition delay 
achieve high power efficiency frame length significantly increased may increase queuing delay 
compared ec mac rbs scheme considers issue state transition delay allocates bandwidth granularity packet frame flexible handle problems variable packet lengths dynamic packet arrival patterns 
prabhakar studied power conservation regard scheduling 
show power consumption significantly reduced lowing transmission power transmitting packet long period time 
motivation lazy packet scheduling lps approach proposed reduce transmission rate packet violating deadline packet 
approach proven power optimal 
main difference lps rbs lps focuses reducing power consumed wni sender changing transmission rate rbs focuses reducing power ieee ieee infocom consumption wni receiver mts powering wni 
transport layer protocol proposed save power 
protocol coordinates sender receiver active idle 
state transition state sender output buffer 
data send specified period sender notify receiver go sleep 
idea approach direction 
different consider qos provision 
fitzek reisslein proposed prefetching protocol support high performance streaming applications wireless links 
parts ongoing media streams prefetched buffers clients join shortest queue jsq policy 
jsq dynamically allocates bandwidth clients small buffered data allocating bandwidth clients large prefetched reserves 
buffered data clients smooth playback quality periods adverse transmission conditions wireless links 
basic idea pbs similar jsq 
pbs focuses aspect power conservation jsq deals channel errors wireless links 
furthermore pbs considers achieve power efficient communication regard scheduling 
vi 
deadline priority bulk scheduling pbs service model save power provide qos guarantees 
pbs scheduler decides serve suspend flow amount prefetched data 
flows insufficient prefetched data flow selected primary flow secondary flows 
primary flow exclusively served provided deadlines secondary flows violated 
flow buffered data suspended buffered data run 
flows strict delay requirement pbs scheduler may flow yield channel workload system high 
prefetched data wni sleep long offset impact state transition delay 
suspending flows active flows sharing channel obtain bandwidth take time fill buffer 
analysis prove service model delay guarantee power efficient rate fair queuing service model 
extensive experiments carried evaluate proposed methodology 
compared nvc bks pbs service model significantly reduce power consumption provide excellent qos 
extend pbs service model improve error resiliency 
add channel condition model determining priority flow adjust wakeup time channel condition flow 
bennett zhang wf worst case fair weighted fair queueing infocom march 
bhagwat bhattacharya tripathi enhancing throughput wireless lans channel state dependent packet scheduling infocom march 
chen jamieson balakrishnan morris energy efficient coordination algorithm topology ad hoc wireless networks acm mobicom 
chen agrawal acharya scheduling multimedia services low power mac wireless mobile atm networks ieee acm transactions multimedia vol 
june 
reuters news music mobiles hits high note young crowd biz yahoo com rc column html 
fitzek reisslein prefetching protocol continuous media streaming wireless environments ieee selected areas communications vol 
october 
goyal vin cheng start time fair queuing scheduling algorithm integrated serv packet switching networks acm sigcomm august 
ieee wireless lan medium access control mac physical layer phy spec ieee standard 
jung vaidya power control mac protocol ad hoc networks acm mobicom 
balakrishnan minimizing energy wireless web access bounded shutdown acm mobicom 
kravets krishnan power management techniques mobile communication mobicom october 
li aslam rus online power aware routing wireless ad hoc networks mobicom july 
lu bharghavan wireless fair service algorithm packet cellular networks mobicom october 
ng stoica zhang packet fair queueing algorithms wireless networks location dependent errors infocom march 
nokia nokia specifications www nokia com phones specifications html 
mpeg org mp test streams www mpeg org mpeg mp html 
parekh gallager generalized processor sharing approach flow control integrated services networks single node case ieee acm transactions networking vol 
pp 
june 
powers batteries low power electronics proc 
ieee vol 
pp 
april 
prabhakar el gamal energy efficient transmission wireless link lazy packet scheduling ieee infocom march 
boyd managing power consumption networks chips acm date 
sinha raghavendra pamas power aware multiple access protocol signaling ad hoc networks computing communication review vol 
pp 

stemm katz measuring reducing energy consumption network interfaces handheld devices ieice transactions communications vol 
august 
xu lipton fundamental tradeoff delay bounds computational comp packet scheduling algorithm acm sigcomm august 
xu heidemann estrin geography informed energy conservation ad hoc routing mobicom july 
zhang service disciplines guaranteed performance service packet sw networks proceedings ieee vol 
october 
zhu cao das adaptive power conserving service discipline bluetooth ieee icc 
appendix proof property proof set partitioned subsets set active flows denoted set idle flows denoted cases ieee ieee infocom case fi suppose packet served fi suspended 
fi fi suspended property holds 
case fi suppose head line packet fi time definition deadline packet start time fair queuing fi highest priority similar arguments theorem get max pbs provided lmax proof property proof flow served generalized processor sharing gps actual data rate flow equal flow fi aggregated service bits time period equal consider situation scheduler applies wfq scheme flow served granularity packet 
flows continuously backlogged data rate wfq scheduler behaves similar worst case fair weighted fair queuing wf scheduler 
theorem relationship amount fi aggregated service gps wfq interval denoted wi wi gp respectively follows wi wi gp lmax wi lmax loss generality suppose flow flow leaves channel spends get ahead service equal greater 
needs satisfy wi rt ineq get lmax flow gets ahead service ineq lmax tact pbs time set partitioned set flows got ahead service left channel flows served 
secondary flows served non conserving manner similar proof lemma aggregated service secondary flow fj time interval denoted bs follows max max suppose primary flow fi takes ti bs get greater equal 
similar proof theorem aggregated service fi ti bs denoted bs ti bs follows bs ti bs ti bs lmax ti bs max fi leaves channel gets greater equal ti bs satisfies bs ti bs max combined ineq get ti bs lmax loss generality suppose order primary flows process 
max ineq flow secondary flow 
result time spent fi leave system denoted ti bs follows ti bs tk pbs time period fi primary flow 
ineq eq get tact bs max ineq ineq easy find property holds 
different fair queuing model may different fairness property 
assume flow continuously backlogged date rate results ineq holds rate fair queuing models 
property valid fair queuing models 
ieee ieee infocom 
