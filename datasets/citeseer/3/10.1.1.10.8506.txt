design implementation evaluation duplicate transfer detection jeffrey mogul yee man chan terence kelly internet systems storage laboratory hp laboratories palo alto hpl february mail acm org stanford edu terence kelly hp com aliasing duplicate transfer detection organizations web caches avoid transferring data twice path 
numerous studies shown forward proxy caches practice incur rates 
traditional web caches rely reuse responses urls 
previous analyses real world traces revealed complex relationship urls reply payloads shown complexity frequently causes redundant transfers caches 
example redundant transfers may result payload aliased accessed different urls resource rotates alternates different values cache revalidation mechanisms fully exploited 
implement evaluate technique known literature duplicate transfer detection dtd web cache digests detect potentially eliminate redundant payload transfers 
show support dtd protocol changes dtd enabled proxy cache interoperate unmodified existing origin servers browsers permitting incremental deployment 
simulated experimental results quantify benefits dtd 
internal accession date published symposium network systems design implementation march san francisco ca approved external publication copyright hewlett packard jeffrey mogul hp labs palo alto ca acm org design implementation evaluation duplicate transfer detection organizations web caches avoid transferring data twice path 
numerous studies shown forward proxy caches practice incur rates 
traditional web caches rely reuse responses urls 
previous analyses real world traces revealed complex relationship urls reply payloads shown complexity frequently causes redundant transfers caches 
example redundant transfers may result payload aliased accessed different urls resource rotates alternates different values cache revalidation mechanisms fully exploited 
implement evaluate technique known literature duplicate transfer detection dtd web cache digests detect potentially eliminate redundant payload transfers 
show support dtd protocol changes dtd enabled proxy cache interoperate unmodified existing origin servers browsers permitting incremental deployment 
simulated experimental results quantify benefits dtd 
web caches widely save bandwidth improve latency 
numerous studies shown practice forward proxy caches shared web caches near clients incur rates byte weighted rates 
warm caches infinite storage eliminate misses 
specifically concerned redundant payload transfers cases payload transmitted recipient previously received 
traditional web cache cache entry indexed url 
subsequent request arrives url cache satisfy request misses forwards request origin server normally generates reply containing payload section gives careful definition payload 
yee man chan stanford human genome center palo alto ca stanford edu terence kelly hp labs palo alto ca terence kelly hp com exact payload previously received cache define redundant payload transfer 
identified problem redundant payload transfers world wide web quantified prevalence explored range possible solutions 
measurement payload transfers origin servers proxies redundant 
know causes redundant transfers 
result common phenomena aliasing content referenced different urls rotation content referenced twice single url intervening url resolves different content absent faulty metadata causes avoidable revalidation failures 
previously proposed technique called duplicate transfer detection dtd allows web cache potentially eliminate redundant payload transfers regardless cause 
dtd uses message digests detect redundant transfers occur 
digests detect duplication dtd similar approaches developed contexts router packet transfers file systems environments 
alternative proposal eliminating redundant transfers dtd require soft state scales number clients size responses 
propose concrete protocol design describe implementation dtd measure impact client latency 
show standard explicit protocol changes support dtd relying additional semantics naming mechanisms validation mechanisms cooperation origin servers 
allows dtd enabled cache interoperate unmodified existing origin servers browsers permitting smooth incremental deployment 
describe implement dtd web cache report experiments showing accomplish goal completely eliminating redundant transfers 
quantify benefits dtd experimental measurements implementation simulation results 
main contributions defined protocol specification dtd design real implementation dtd performance evaluations dtd 
eliminate redundant transfers 
dtd proposal reduce number times cache contact origin server reduces number response bodies transferred 
worthwhile 
eliminating redundant transfers improve metrics bandwidth web caches deployed reduce bandwidth requirements half large companies surveyed cited bandwidth savings motivation web caching 
redundant transfers consume bandwidth increase peak bandwidth requirements 
latency eliminating redundant transfer save latency ways directly making result available sooner having wait redundant transfer finish indirectly reducing channel utilization reducing queueing delays subsequent responses 
byte charges network flat rate 
particular wireless data range dollars tens dollars mbyte 
redundant transfers networks directly waste money 
energy studies shown energy consumption wireless portable networking somewhat dependent amount data transferred 
eliminating redundant transfers improve battery life 
previous study large real world traces showed roughly payload transfers origin servers proxy caches redundant 
solution redundant transfer problem yield significant savings metrics listed 
concentrate quantifying improvements 
related published suggestion eliminate redundant payload transfers message digests trace evaluation impact web cache hit rates appeared 
unpublished undergraduate dissertation develops similar idea gprs web access 
santos wetherall spring wetherall describe protocol independent network level analogues dtd employ packet digests save bandwidth 
muthitacharoen designed network file system low bandwidth environments performs similar operations chunks files 
web caches payload digests avoid wasting storage bandwidth 
implemented natural counterpart dtd see section 
report digests avoid storing redundant copies payloads web cache reduce storage footprint increase hit rates 
inktomi patented scheme 
variety duplicate suppression schemes proposed web 
differ dtd chiefly typically mechanisms requiring participation servers dtd hop hop level cache hierarchy avoid extra round trip variants dtd suffer reduce eliminate redundant transfers 
mogul reviews duplicate suppression schemes distribution replication protocol drp van hoff reported improve hit rates modest margins best 
previous studies shown redundant payload transfers web caused complexities relationship urls reply payloads aliasing rotation deficiencies cache management algorithms server supplied metadata 
rhea describe sophisticated generalization dtd called value web caching 
dtd operates entire payloads detects eliminates redundant transfers finer granularity employing fingerprints calculated variable sized blocks 
block boundaries computed spring wetherall approach 
editing file affects payload blocks immediate neighborhood change ensuring minor changes don eliminate bandwidth savings 
rhea implemented evaluated polling seventeen popular web sites evaluation includes comparisons delta encoding 
evaluate actual client proxy stream 
dtd entails additional round trip client server requires additional server state 
contrast proxies explicitly track client cache state order avoid extra rtt rare circumstances 
soft state scales number clients size responses easily deployable dtd 
harder evaluate anonymized traces existing traces include md digests response bodies compute partial payload fingerprints 
designed run isp proxy clients 
dtd server server proxy proxy proxy proxy 
cases dtd imposes store forward cost computing digest proxy entire payload store forward costs block potentially smaller 
know significant overheads 
duplicate transfer detection motivated wish eliminate redundant transfers proposed duplicate transfer detection dtd 
solution applies equally redundant payload transfers regardless cause 
provide overview dtd derived discuss general design issues 
section detailed protocol design showing dtd defined simple compatible extension 
overview dtd consider behavior traditional cache refer url indexed cache confronted request url cache finds currently hold entry url cache cache issues forwards request url origin server normally send response containing payload 
cache hold expired entry url may send conditional request server view resource changed may return modified response payload 
suppose idealized infinite cache retains storage payload received payloads considered valid cache entries 
finite url indexed cache differs idealization implements update policy stores payload received url replacement policy stores finite set entries 
concept duplicate transfer detection quite simple idealized cache determine receiving server response previously received avoid transferring payload 
cache suffer compulsory misses experience redundant transfers 
finite cache realization dtd course suffer capacity misses 
cache know received payload server sends entire response 
dtd server origin server intermediate proxy cache initially replies digest payload cache checks see entries matching digest value 
cache signal server send payload server send message headers different 
dtd avoid request response message headers cache avoid transfer payload received previously 
say dtd hit occurs dtd prevents payload transfer occurred conventional url indexed cache 
idealized dtd cache stores payloads received able look cached payload url payload digest 
particular delete payload storage simply received different payload url realistic dtd cache finite capacity may eventually delete payloads storage replacement policy 
payload 
described dtd operating payloads order precisely specify dtd precisely specify term payload set bytes digest calculated 
servers term server includes origin servers proxies send response messages containing full current value resource partial response containing sub ranges full value complex partial responses delta encoding rsync 
responses encoded various compression formats chunked encoding 
format response ultimate client wants obtain full current value referenced resource 
introduced term instance mean entity returned status response get request current time 
specified resource ietf standards track document specifying extend support instance digests 
instance consists instance body instance headers dtd design equates payloads instance bodies servers provide instance digests cache entry indexed digest instance body stores 
imagine alternative dtd digests computed message bodies partial responses 
eliminate redundant transfers partial responses instance span range 
payloads instance bodies model works nicely partial responses 
example client re quests bytes url server responds digest entire instance body dtd client checks cache matching instance digest 
entry transfer avoided client easily extract required byte range cache entry relying server extraction 
dtd design prevents cache computing digests non instance data partial responses encoded responses matching incoming instance digests cached non instance data 
intuition matches occur rarely justify additional overhead 
deployment dtd dtd best thought hop hop optimization caching implemented server client proxy dtd implemented data sender receiver 
particular dtd deployed unilaterally organization controls browser proxy caches aol msn 
deployed incrementally implementor clients servers proxies optional transfer 
experiments described section demonstrate dtd enabled purely proxy modifications origin server supports digest generation 
dtd main requirement server implementors compute send instance digests 
algorithm compute digest value server cpu time digest representation consume bytes cost speculatively sending digests exceed benefits dtd hits 
digest essentially yield collisions client wrong payload 
cryptographic hash algorithm md right properties 
assume md section covers issues choice digest algorithm 
note dtd inherently require client compute digests servers send digests 
check transmission errors servers sending bogus digests clients probably compute digests anyway see section 
protocol design issues previous briefly covered protocol design issues dtd 
section expand discussion including mechanisms suppressing data transfer specific mechanisms support dtd 
options suppressing data transfer key aspect dtd mechanism client avoids receiving payload digest matches existing cache entry 
accomplished deferring transfer digest checked aborting transfer progress digest matches cache entry 
category approaches server sends response headers defers sending payload client sends explicit proceed message 
category server sends payload immediately headers stops client sends abort message 
proceed model imposes extra round trip time rtt cache sends redundant payload bytes 
abort model imposes additional delays abort message may fail reach server time save bandwidth 
choice alternatives requires consideration implementation issues magnitude rtt concerned optimizing bandwidth utilization latency 
basic models allows alternatives 
include pure proceed receiving client request server replies headers including digest 
client sends proceed message cache server sends body payload 
messages sent 
proceed don bother pure proceed alternative server need buffer responses indefinitely waiting possible proceed message 
proceed don bother alternative addresses concern allowing client send don bother message digest match cache entry message allows server free buffer quickly 
auto proceed short responses proceed model risks exchanging extra set headers delaying extra rtt 
short payloads transfer time saved dtd hit worth overhead 
server optimize case sending payload immediately payload sizes threshold 
abort server sends payload immediately headers normal operation 
client sends special abort message digest matches cache entry telling server terminate transfer soon possible 
note proceed model payload need delayed 
web pages include multiple images example previously image html uncached stream images html client cached stream 
client pipelines requests images pipeline proceed messages 
extra rtt delay amortized im ages web page paid image 
examine pure proceed model reasons space simplicity 
extending support dtd changes required extend support dtd depend transfer suppression approach chosen 
pure proceed approach dtd implemented changes existing ietf standards track proposals 
client uses mechanisms specified proposed standard instance digests obtain current instance headers including instance digest 
obtains head request prevents server sending instance body section 
client finds cache entry matching instance digest non dtd server fails return digest client simply issues get request obtain full instance body 
protocol design simple drawbacks potentially adds extra rtt client sends head get request dtd add extra rtt latency request 
practice requests images embedded html pages allows client pipeline page image requests transmission server likewise batch head get responses 
typical compound web pages pure proceed approach adds additional mandatory rtts html container embedded images 
adds extra set request response headers cuts bandwidth savings offered dtd 
dtd worth doing mean savings response body bytes smaller sum mean request re sponse header lengths see section 
depends request idempotency head get sequence different side effects single get request uri give dtd incorrect semantics 
specification recommends get head methods significance action retrieval section sites ignore recommendation 
dtd clients need apply heuristics issuing extra head request urls containing dtd embedded images 
server send digest serv ers required send instance digests current mechanism discover server send 
client incur costs listed respect server gaining benefit 
clients need cease dtd approach server fails send digest threshold number requests 
shows example messages client server dtd dtd hit second pair messages simply omitted 
headers described rfc headers standard 
right implementation dtd works responses extensible digest algorithms md avoids unnecessary digest computations origin server 
rfc widely implemented tested dtd support available major web servers apache iis 
sub optimal allow server avoid computing md client 
pure proceed approach equally usable hop intermediate proxy generate check digests 
proxy proxy implementation section specifically prohibits proxies adding note proxy client proxy dtd impose extra store forward delay proxy computes digest header 
existing proxies buffer short responses case 
trace performance analysis section presents measured performance actual dtd implementation 
measurements driven synthetic stream prove frequent redundant transfers realworld workloads 
analyze real world traces show redundant transfers bytes eliminated dtd 
relatively existing client proxy traces include response body digests needed analysis 
example trace douglis may lost disk crash traces unavailable due proprietary considerations 
re analyzed anonymized client proxy traces prior study 
collected respectively webtv networks september compaq early 
webtv trace client caches disabled traces proxy caching 
traces include md digest payload transferred 
webtv trace client request second client request server response second server response message body omitted example messages pure proceed approach 
cludes clients urls servers sixteen days compaq trace includes clients urls servers days 
details traces described omitted space reasons 
request url results reply instance body properties may may hold exists url instance body ii exists url past instance body 
iii past instance body 
iv instance body properties iii iv mutually exclusive combination possible total twelve possibilities exist transaction properties seen 
analyzed webtv compaq traces categorization 
results tables respectively 
cold start results cover entire traces 
consistent earlier methodology warm start results somewhat arbitrarily warm simulated cache webtv compaq 
webtv warm start results transfers involve payloads seen trace new payloads kind cache 
property iv traditional infinite cache perfect revalidation avoid payload transfer 
hit rate high remember webtv trace client caches disabled 
remainder transfers dtd avoid 
words traditional url indexed cache see rate compared dtd cache rate dtd eliminate conventional cache misses 
compaq warm start results new payloads property iv 
remainder transfers dtd avoid 
traditional cache see rate versus dtd cache rate dtd eliminate roughly conventional cache misses trace 
restrict dtd implementation save entry url store entries traditional cache dtd cache require transfers properties ii iii avoid transfers property 
situation dtd avoid transfers webtv trace transfers compaq trace assuming warm cache 
values sums warm start transfers column rows property holds property iv 
weighting results bytes transferred better describes bandwidth savings course 
looking just warm cache data new mandatory transfer payloads account webtv bytes compaq bytes 
variations property iv hits perfect traditional cache account webtv bytes compaq bytes 
transfers dtd avoid account webtv bytes compaq bytes 
words traditional url indexed cache see byte weighted rate webtv trace compared dtd cache rate vs compaq trace 
terms reduction number bytes sent origin server dtd save relative url indexed cache webtv trace compaq trace 
overheads proceed model proceed model dtd causes extra pair request response headers digest match evaluate byte transfer savings model compare bytes saved dtd properties ii iii number property cold start cold start warm start warm start iv iii ii transfers mbytes transfers mbytes current reply payload 
returned url returned url returned current url current url totals table webtv trace categorization 
property cold start cold start warm start warm start iv iii ii transfers mbytes transfers mbytes current reply payload 
returned url returned url returned current url current url totals extra header bytes spent new payload transfers 
ignore property iv assuming cache hits 
dtd warm start saves mean bytes payload transfer webtv trace warm start bytes new payload compaq trace 
savings larger mean request response header sizes reported previous studies proceed model waste potential savings 
dtd requires digests response headers md bytes plus bytes syntax overhead reduces savings 
digests useful integrity checks sent dtd 
match multiple entity tags supports entity tags validate cache entries server may provide entity tag response header client may send entity tag back server request header check cache entry valid 
may carry multiple entity tags case server return modified current entity tag table compaq trace categorization 
tags current 
feature allow non dtd cache avoid transfers property iii holds 
referring warm start columns tables see avoid transfers bytes webtv trace transfers bytes compaq trace 
upper bounds simple analysis assumes response carries entity tag servers exactly entity tag distinct instance body 
true practice responses webtv trace carried entity tags know servers assign different entity tags identical instance bodies 
summary dtd avoids transferring significantly bytes avoided multiple entity tags multiple cache entries url 
full benefit dtd accrues cache stores payload url 
natural dtd cache design treats payloads urls basic storage type 
urls merely way index underlying store payload digests 
cache may store multiple payloads url payloads response url case rotated resources 
properties desirable difficult retrofit legacy cache implementations help 
helps property ii iii having property iv 
represent just warm start transfers webtv trace warm start transfers compaq trace probably useful store multiple payloads url 
model latency analysis analysis section concentrates number bytes saved dtd may economic interest network operators 
users care latency 
predicting latency effects change web protocols difficult variables affect latency 
developed simple model understanding pure proceed dtd improve latency traditional web cache 
model ignores issues response pipelining network congestion tcp algorithms slow start correlations hit ratio duplication ratio parameters help guide intuition 
parameters rtt round trip time cache server bw effective link bandwidth bits sec response length bits conventional cache hit ratio dtd hit ratio lookup cache lookup latency derive latencies simplify assuming headers negligible length lookup rtt bw rtt rtt extra rtt comes head operation dtd cache performs conventional lookup misses 
extra lookup comes need lookups url digest cases 
simplify assuming reasonable approximation implemented cache 
express expected latencies conventional dtd caches break response size bytes scenario rtt bandwidth webtv compaq ms kb modem ms kb dsl ms kb wan ms kb table examples model output 
hr hr dtd improves expected latency algebra true bw rtt hr dtd pay effective link bandwidth rtt decrease transfer length hit ratios increase 
evaluated equation warm cache hit ratio values taken webtv compaq trace analyses tables various combinations rtt bandwidth 
table shows results scenarios modem dsl wan corresponding respectively results shown figures 
break response sizes shown table imply dtd improve latency modem links dsl links typical mean response sizes summarized table 
dtd hurt latency high speed wan links restricted relatively large responses 
implementation design experience new code required dtd proceed model located cache implementations 
needed server support digests relied existing support partially appropriate see section clients browsers proxies caches experiments limited modifying proxy cache server 
running private proxy cache located browser emulate benefits integrating dtd browser cache 
simpler add dtd browser cache add proxy cache 
chose implement pure proceed approach dtd modifications squid proxy server version stable 
code available major changes creating payload datatype separate cache entry 
inverts existing data structure dependence payload url 
indexing payload database digest url 
generating preliminary head request obtain server digest 
checking returned digest dtd related head requests generating get request digest cache digest returned 
modified squid uses duplicate storage avoidance dsa 
distinct payload digest stored payload current urls url indexed entries incorporate payload see 
dtd dsa changes involve lines simple tedious diffs squid new code represents modified versions existing squid code 
third new lines pre processor directives ifdef 
cache supports partial content status responses careful associate digest stored partial instance body dtd unwittingly supply incomplete bodies 
implementation support partial content 
hindsight choice modify squid may mistake 
existing squid code extremely complex hard understand bugs code resulted failure maintain poorly documented invariants expected rest squid 
know bugs remain 
experimental results analysis section traces real users predicts bandwidth savings dtd tell dtd affects latency 
help answer question ran experiments modified version squid 
experimental design tested dtd implementation different environments emulated wan environment systems server proxy client physically close connected mbit sec lan 
emulated variety wan environments dummynet feature freebsd allowed choose variety latency bandwidths server proxy enabling measure dtd performance varies network characteristics 
second real wan environment server worcester polytechnic institute wpi massachusetts dtd capable proxy client ran system university michigan 
tests ran proxy modified unmodified system client simulate client cache support dtd 
systems unloaded real wan origin server 
hosts ran linux emulated wan server ran freebsd 
server wpi uses apache emulated wan server uses apache 
emulated wan experiments proxy client mhz pentium iii server mhz alphaserver ds 
real wan experiments proxy client cpu mhz pentium ii server mhz pentium iii 
measured mean rtt msec real wan path approximate effective bandwidths mbits sec 
emulated wan tests dummynet impose symmetric rtts msec bandwidth limits bits sec 
ran trials file body sizes including headers bytes kb mb 
file byte derived pseudo random number generator making difficult network element modem compress files change effective transfer sizes 
combination network characteristics body size ran experiments different proxy configurations proxy unmodified squid dtd capable modified squid proxy 
unmodified squid ran trials arranged compulsory cache misses trials guaranteed cache hits 
squid ran compulsory guaranteed hit dtd hit trials category arranged cache contained entry matching digest value matching url 
arranged compulsory cache misses restarting proxy software cold cache necessary arranged guaranteed hits careful choice sequence ensuring working set smaller cache size 
set experiments measured response time httperf 
program reports latency issuing request receiving byte response headers time byte latency receiving byte response headers byte response body transfer duration td 
kb body size headers body fit packet case td negligible 
total response latency td 
trial httperf fetch bunches distinct files length 
network configuration measure latencies bunch combination body size proxy configuration repeat set measurements times 
results show mean noted 
measured overheads proxy server introduces overheads dtd implementation integrated client cache 
squid known add significant latency due fundamental design choices 
estimate overheads imposed implementation strategy squid integrated client cache comparing proxy latencies latencies cache retrievals unmodified squid 
mean overhead msec mean overhead msec time byte transfer time total response time body size kbytes measured lan time byte transfer time total response time body size kbytes measured real wan overhead imposed unmodified squid shows overheads imposed unmodified squid connected server full speed lan wan path described 
lan case squid adds latency larger trial measurement errors cause negative overheads errors total latencies 
overheads wan tests harder interpret unmodified squid consistently improve transfer times body sizes 
effect holds run experiments emulated wan similar delay bandwidth 
offer plausible explanation results compare performance modified squid unmodified version proxy case leave mystery 
lan latency difference squid proxy operation body sizes msec 
places upper bound cache lookup latency squid imposes overheads lookup confirms assumption section lookup latency negligible 
dtd requires origin server send digest payload body 
experiments md digest algorithm computation imposes cost 
principle servers cache md computations frequently accessed content 
moore law suggests md computation decline cost relative speed light latencies 
current servers apache cache md values dtd adds computational overhead 
quantified cost comparing latencies proxy retrievals md computation enabled apache server 
mean overhead msec time byte transfer time total response time body size kbytes overhead md computation shows overheads md imposes lan configuration 
bodies smaller kbytes overheads negligible msec 
larger bodies md computation adds measurable overhead tenth absolute response time msec byte bodies 
increase response time smaller increase larger sizes probably md pass effectively prefetches file server file buffer prefetching implies tcp transfer slightly efficient 
emulated wan experiments shows time byte total response time results left right columns respectively selected emulated wan experiments 
reasons space show results msec kbits sec rt plausible cell phone link msec kbits sec rt typ ical dialup msec kbits sec modem rtt dsl connection regional server rt sec bad case dtd msec mbits rtt bandwidth high 
combinations network parameters tested latency dtd hit slightly rtt approximately cache expect cost head mean msec mean msec mean msec mean msec key graphs body size kbytes proxy unmodified proxy unmodified proxy hit modified proxy modified proxy conventional hit modified dtd hit mean total resp 
time msec body size kbytes msec rtt kbits sec body size limited keep experiment durations reasonable body size kbytes body size kbytes body size kbytes operation 
total response latency dtd hit approximately rtt body transferred origin server cache 
cache colocated client transfer cost agents 
mean total resp 
time msec msec rtt kbits sec typical modem mean total resp 
time msec msec rtt kbits sec typical dsl mean total resp 
time msec body size kbytes msec rtt mbits sec bad case dtd emulated wan results body size kbytes body size kbytes total latency compulsory cache rtt higher traditional cache 
clearly visible left column figures log scale visible right column results dominated bandwidth induced delays 
penalty dtd cache improved latency hits respect conventional misses displace 
dtd hit higher total latency conventional non dtd cache lower conventional incurs large transfer cost 
example body size just kbytes total latency significantly lower dtd hit conventional dtd shows latency benefit large body sizes high bandwidth minimizes transfer cost high rtt dominates total latency 
note shows dtd hits faster conventional misses replace knowing various hit ratios see section infer dtd provides net benefit 
real wan experiments mean msec mean total resp 
time msec proxy unmodified unmodified hit body size kbytes modified modified conv 
hit mod dtd hit real wan time byte results body size kbytes real wan total response time results show respectively time byte total response time results real wan experiments 
experiment 
results agree quite closely emulated wan results shown similar rtt bandwidth 
implications results experimental results generally confirm analytic model section experiments model ratios 
evaluate dtd beneficial particular point parameter space 
example assume ratios reported webtv trace section dtd client cache vs conventional client cache assume ratios independent response size 
results modem user rtt msec kbits sec retrieves number kbyte files mean expected latency improvement dtd msec compared expected mean dtd msec 
user retrieving number kbyte files see mean improvement msec vs non dtd mean msec 
user slower network rtt msec kbits sec see larger improvements dtd 
user relatively wan connection see net latency loss dtd body sizes break point kbytes 
web responses smaller wan links want dtd special tasks downloading software original motivation drp 
security considerations measures improve performance computing systems create subtle security vulnerabilities caching prime example 
timing attacks processor memory hierarchies known decades famous password attack pp 

felten described variants applicable web caching 
dtd adds additional security problems 
attacker generate payload digest collisions cause dtd proxy deliver incorrect payloads 
details omitted available 
attack straightforward prevented secure message digest functions see section 
subtle problem involves information leakage interestingly attack rely timing information kind 
server exploit dtd learn contents client cache digest 
user bob browser dtd 
server em 
bob issues request uninteresting url 
replies receives serves requests interesting payload 

bob browser fails retrieve full payload revealing bob 
sophisticated implementations attack employ javascript html pages systematically search client cache interesting payloads analogous timing attacks described felten 
attacks form detected easily simply retrieving full payload verifying digest previously obtained server 
furthermore attacks avoided client simply refrains employing dtd communicating untrusted sites 
possible countermeasure employ dtd sites example bob browser fetch payloads match supplied server 
ensures dtd reveals bob surfing server doesn know 
approach may severely limit benefits dtd aliasing occurs sites sites 
choice digest algorithm dtd unreliable digest function prone accidental collisions normal usage 
md sufficient widespread deployment achieve arbitrarily low rate accidental collisions increasing hash size cost slightly higher overheads 
henson discusses risks associated digest protocols disagree 
dtd vulnerable attack computationally feasible generate digest collisions deliberately 
assumed md md collision resistance questioned 
algorithms sha appropriate 
see possible extensions 
explore evaluate protocol alternatives section unify dtd similar techniques rsync 
see trace analysis section applied broader set traces 
improve synthetic benchmarks ratio response length distributions taken traces 
model original squid code base supports pipelining known benefit performance general ought improve tradeoff favor dtd evaluation pipelined dtd cache require shifting new code base 
dtd cache traditional cache store multiple entries url cache replacement policies designed traditional caches interact poorly dtd 
suspect natural replacement policy dtd redefine existing policy respect unique instances urls 
evaluated policies believe dtd cache policy suf fer higher rate conventional url indexed cache analogous policy 
summary described duplicate transfer detection implemented explicit protocol changes briefly sketched alternative designs 
showed real world traces dtd reduce rates bandwidth requirements bytes transferred traces 
provided simple model show dtd reduce expected latency relative conventional cache 
described simple implementation dtd squid 
tests real emulated wans showed measurements clarify conditions dtd reduces latency 
realistic hit ratios response sizes dtd provide net latency benefit common network environments 
acknowledgments microsoft allowing study data especially stuart arnold de leon jay listed gathering trace david jake brutlag describing webtv client caches 
hp labs gave access compaq trace generous equipment support 
glenn cooper hp labs jeff michigan ai lab provided computer support 
especially alex spending late nights adding aliased content support polygraph answering novice questions 
duane wessels helped squid 
mikhail lent server wan tests possible configured order answered numerous questions 
anja feldmann james hall kevin jeffay provided information request sizes 
fred douglis reviewers usits nsdi shepherd geoff voelker provided helpful comments 
lee noh min koh 
replica aware caching web proxies 
computer communications feb 
broder glassman manasse zweig 
syntactic clustering web 
proc 
th www conf apr 
cellular news 
gprs architecture 

tariff data disappeared page 
clark 
optimising web gprs link 
undergraduate dissertation univ cambridge 
douglis feldmann krishnamurthy mogul 
rate change metrics live study world wide web 
proc 
st usits pages dec 
feldmann rexford caceres 
efficient policies carrying web traffic flow switched networks 
ieee acm trans 
networking dec 
felten sept 
personal communication 
felten schneider 
timing attacks web privacy 
proc 
th acm conference computer communications security nov 
fielding gettys mogul frystyk masinter leach berners lee 
rfc hypertext transfer protocol june 
flinn de lara satyanarayanan wallach zwaenepoel 
reducing energy usage office applications 
proc 
ifip acm int conf 
distributed systems platforms middleware pages heidelberg germany nov 
howe chan buss 
caching matters 
technical report forrester research oct 
henson 
analysis compare hash 
proc 
hotos ix hi may 
hernandez campos jeffay smith 
tracking evolution web traffic 
proc 
mas cots orlando fl oct 
kelly 
optimization web caching 
phd thesis university michigan july 
kelly 
thin client web access patterns measurements cache busting proxy 
computer communications mar 
kelly mogul 
aliasing world wide web prevalence performance implications 
proc 
th intl 
world wide web conf pages honolulu hi may 
richardson grunwald 
performance issues enterprise level web proxies 
proc 
sigmetrics pages seattle wa june 
plevyak haines beguelin 
patent alias free content indexed object cache sept 
mogul 
squeezing bits caches 
ieee network may june 
mogul hoff 
instance digests 
rfc ietf jan 
mogul krishnamurthy douglis feldmann goland van hoff hellerstein 
delta encoding 
rfc ietf jan 
mosberger jin 
tool measuring web server performance 
proc 
workshop internet server performance pages madison wi june 
muthitacharoen chen mazieres 
network file system 
proc 
th sosp pages oct 
national institute standards technology 
secure hash standard 
fips pub 
dept commerce apr 
nielsen gettys baird smith prud hommeaux lie lilley 
network performance effects css png 
proc 
acm sig comm pages sept 
padmanabhan mogul 
improving latency 
proc 
nd www conf pages chicago il oct 
rabinovich spatscheck 
web caching replication 
addison wesley dec 
rhea liang brewer 
value web caching 
proc 
www pages budapest may 
rivest 
rfc md message digest algorithm apr 
rizzo 
dummynet simple approach evaluation network protocols 
computer communication review 

results md md md 
rsa labs bulletin nov 
santos wetherall 
increasing effective link bandwidth suppressing replicated data 
proc 
usenix annual technical conf june 
spring wetherall 
protocol independent technique eliminating redundant network traffic 
proc 
acm sigcomm pages aug 
squid team 
squid web proxy cache aug 
tanenbaum 
modern operating systems 
prentice hall 
isbn 
touch 
performance analysis md 
proc 
sig comm pages cambridge ma aug 
tridgell 
algorithm 
technical report tr cs dept computer science australian national university june 
van hoff carter medin 
distribution replication protocol 
technical report note drp world wide web consortium aug 
wallach sept 
personal communication 
wessels 
web caching 
ly june 
wills 
examining user requested web resources 
proc 
th web caching workshop apr 
wills 
better understanding web resources server responses improved caching 
proc 
th www conf may 
notes rare cases client may want render welldefined sub part chapter pdf file 
proceed model described section supports endto 
traces compaq trace include data header size data webtv trace appears unreliable possibly result incorrect logic recording header lengths trace gathering process 
web responses low range previously summarized results traces showing mean sizes medians 
ribeiro pointing attack 
far determine form attack previously reported literature 
