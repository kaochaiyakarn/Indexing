analysis musical audio polyphonic transcription st year report stephen hainsworth september signal processing group department engineering university cambridge report centres issues involved automatic transcription polyphonic musical audio signals 
representing information contained audio way recognisable usable musician 
review various fields bearing subject put forward including music music psychology auditory psychology signal processing 
thorough appraisal previous automated polyphonic transcription 
original time frequency reassignment front imparted ideas expounded timetable forthcoming research 
contents literature review musical background 
pitched sounds 
percussive sounds 
rhythm 
musical structure music psychology 
auditory psychology 
physical structure ear 
psychoacoustic effects 
models pitch perception 
auditory scene analysis 
signal processing 
fourier analysis 
methods improving resolution 
autocorrelation methods 
bilinear distributions 
parametric methods 
methods 
transient analysis 
polyphonic transcription research 
historical overview 
related research musical processing 
instrument recognition 
rhythm tracking 
stereo processing 
chord detection 
post processing techniques 
instrument models synthesis 
related research signal processing 
computational auditory scene analysis 
speech processing 
audio coding 
noise reduction 
time frequency signal classification 
notes 
analysis reassigned spectrograms 
classification reassigned spectrogram 
classification method 
data association 
sinusoid test 
transient classification 
noise classification 
classification performance 
discussion 

zero padding reassigned spectrograms 
thoughts general things believe 
thoughts front 
tracking 
attentional model 
bayesian model formulations 
sterian method 
model built frame frame sinusoid estimates 
walmsley method 
possible directions 
timetable research 
bibliography music attempt understand analyse long active area research time pythagoras ages modern day 
increasingly computers try automate approximate innate human ability listen understand music active area study 
computers powerful operations carried faster techniques signal manipulation realistic decade ago easily implementable leading opening field 
main classes audio signals speech music 
major research area years somewhat ignored mainly due complexity involved 
inside general field musical audio analysis number sub tasks may examined manipulation waveform effects processing analysis coding resynthesis transcription representing signal way allow musicians recreate 
report concerned transcription called dictation specifically looking polyphonic case multiple notes playing time question ask musical transcription 
process representing audio signal fashion musician able understand purposes reproducing original performance 
usually taken score traditional musical notation format 
easy evaluation performance output transcriber written midi format perform reproduction 
essentially polyphonic transcription process described non technical terms trying notes played instruments song normal cd 
obviously trivial task 
various commercial packages exist perform successfully 
monophonic transcribers monophonic commercial package unable test 
amazing midi polyphonic transcriber uses tone template matching successful 
various research groups written nice user interfaces analysis software 
consider motivation automated transcription task purpose simple academic interest 
firstly evidence attempts process music computers led greater understanding underlying principles music 
commercial application cd recordings popular jazz music scores academic music circles transcription refers process re scoring piece music performance different instruments report monophonic refer signal note sounding time polyphonic refers number notes sounding concurrently 
refers sound stereo nature reverse termed monophonic referred monaural avoid confusion 
exist demand obscure performances imagine bedroom wants jimi hendrix solo child 
currently acceptable money publishing companies produce transcriptions song demand goes unsatisfied met poor amateur attempts internet 
simply matter devoting computer time problem individual requests scores met suitable charge levied 
transcription program researching large corpus recorded music score invaluable aid 
applications performance transcription program real time field computer performance part ensemble opened 
instance program automatically acts accompanist realised 
area application archive searching increasingly large amounts multimedia stored vast archives transcription tool useful accessing efficiently 
similar line current forthcoming coding standards mpeg mpeg include structured audio definitions allow combinations parametric note information midi style format combined traditionally coded sound samples 
coding include transcription stage allow efficient coding 
literature review subject automated transcription broad brings elements variety fields 
including engineering mathematics auditory psychology music 
chapter review important elements fields concentrating elements relevant music transcription 
musical background music essentially mathematical formulation 
section mathematical relationships explored 
pitched sounds fundamentally music consists sounds generated concurrently number different sources usually musical instruments varying kinds 
sources generally fall categories harmonic percussive 
forms sounds regarded notes identifiable pitch series harmonically related tones 
tones ideally periodic sine waves real instruments non linearities source deliberate variations introduced performer usually mean quasi periodic 
pitch perceptual quality determined frequency fundamental tone harmonic tones theory integer multiples fundamental 
inharmonicity effect due non linearity sources means rarely exactly integer multiples 
example piano strings hammer action creates waves string interact non linearly hammer contact causing inharmonicity variety effects contribute 
see excellent discussion cambridge university music school part mathematics faculty centuries 

musical background plot harmonics physics musical instruments 
word partial describe tones series 
partial fundamental second partial harmonic 
perceptual qualities associated pitch chroma height 
western music quality chroma classified twelve semitones labelled flats 
twelfth semitone note chroma higher percept height 
termed octave equivalence interval octave comes concept scales discussed 
cultures evolved scales equally tempered note scales south east asia note scales india considered 
shall introduce properly concept interval 
musical construction relates notes different chroma instance difference semitones interval label major third semitones minor seventh 
step away concept scale series notes forming natural sounding set played patterns chords discussed section 
common scales major minor various accepted forms contain separate chroma eighth octave common ones include jazz scales 
key tonal context section music scale best fits notes 
frequency relationships various chroma intervals investigated pythagoras compared lengths strings formed consonant sounds 
octaves frequency ratio fifths ratio major third alternative pythagorean scale breaks small intervals equal scale predominantly today divides octave twelve logarithmically spaced semitones 
means fifths longer exact ratios 
chroma height percepts eventually led helical theory pitch postulated 
shephard conducted interesting experiment tones constructed set sinusoids amplitude envelope determined gaussian fixed centre frequency 
cycle tones infinitely increasing height fact repeating octave 
giving names notes advent midi identifying number equations log 
musical background chords western music concept harmony developed notes sound concordant formed chords 
simple combination notes major triad chord frequency ratio 
comes fact third harmonic note second harmonic third note 
commonality harmonic content leads fused pleasing percept 
sharing harmonics extended give concept root chord note octaves note major triad notes triad harmonics 
say triad explains taken root 
shows note relations harmonics note 
minor chords relationship tune 
basic chords diminished augmented triads 
degrees scale added produce chords different feels th major minor commonly added degree 
jazz different notes added scale ths ths flattened ths sharpened ths gives jazz characteristic feel 
krumhansl conducted extensive studies scales tonal context 
produced profiles type scale defining semitone perceptually fitted tonal context developments 
percussive sounds percussive sounds hand lack harmonic structure analogous noise clouds 
sound modelled stochastic signal usually characterised envelope fact spectrum broadband noisy 
drums obvious examples class 
percussive sounds classed pseudo pitch hierarchy sound classed higher lower 
reflection centre frequency noise cloud drums toms kit tuned kind pitch 
structure harmonic sense described section 
bells hybrid harmonic percussive sounds 
exhibit structure resonance near perceived fundamental 
pitch determined th th harmonics 
shows time frequency spectra single note harmonic periodic structure drum hit noise spectrum 
noted instruments transient onset common percussive sounds 
usually due excitation mechanism producing sound harmonic resonances set 
examples picking action guitar string breath noise start flute note 
rhythm facet music mathematical organisation rhythm metre 
music structured time conform usually steady pulse usually changes slowly time generally notes played time metrical grid examples jazz case 
pulse subdivided smaller regions usually power triplets 
bilmes termed lowest subdivision tatum note inter onset intervals integer multiples 

musical background time samples time plot harmonic sound amplitude time samples time plot percussive sound frequency bins frequency spectrum harmonic sound amplitude frequency bins frequency spectrum percussive sound time frequency plots harmonic percussive sound 
auditory psychology pulse grouped larger structures bars higher level trends 
discussion time signatures meter reader unfamiliar concepts 
musical structure music psychology low level structures notes bars music global structure usually known term form 
simple case verse chorus pop song 
rigidly defined forms exist classical music form theme exposition section explored development repeated recapitulation 
extreme expression form possibly fugue strict mathematical rules apply individual voice part texture 
form way expressing various sections musical piece relate 
exist various theories abstracting higher level information form pieces music 
lerdahl instance generative theory music goal provide account musical intuitions listener experienced particular musical idiom pp 
done sequential reduction simplification structure set rules grammar loosely linguistics 
propose mental image underlying structure built surface features harmonic relations important 
deli ege different theory lerdahl 
suggests cue abstraction mechanism listener extracts cues level proportional musical knowledge 
experiments agree theory support findings 
clarke krumhansl performed experiments test human perception musical structure trained musicians able extract form information 
lewin gives model music perception specifically includes context 
cross mentions cultural conditioning important factor music perception looks models melody perception 
just selection examples methods music perception field study extensive 
heading musical structure concept melody accompaniment mentioned 
generally popular jazz music large amount classical music instrument voice dominant feature melody line rest texture consists backing 
leads way segmenting piece music breaking music constituent components 
goto examines computers detect predominant pitch 
usually melody line 
auditory psychology dealing computers signal processing learn human ear brain tackles auditory process 
significantly computer program hardware hear biological system developed evolution 
physical structure ear ear consists number structures different functions 
outer ear consists visible part auditory canal 
filtering effect sound 
auditory psychology especially high frequency 
shown plays important effect spatial perception chapter 
sound travels causes membrane 
middle ear vibrations transmitted bones hammer anvil 
passed oval opening inner ear cochlea 
main purpose middle ear transmit sound waves air outer ear fluid filled inner ear provides means gain control allowing ear perceive sound large loudness range 
diagram ear cochlea fluids conduct oscillations membrane bm travelling waves set 
bm acts mechanical frequency selection device differing regions respond different frequencies high frequencies produce maximum response near oval window low frequencies maximum far bm regions respond slightly frequency 
frequency gives maximum response point called characteristic frequency cf place 
research conducted cfs tuning patterns stimuli differing frequency 
pioneer von ek human 
experiments live animals produced sharper tuning curves due active feedback mechanisms take place possible 
hair cells detect motion bm motion create firings auditory nerve 
generally synchronisation phase signal khz necessarily fire cycle signal 
brain interprets nerve firings process little understood 
detail physical side audition see moore review contained 
psychoacoustic effects section relevant psychoacoustic effects briefly discussed 

auditory psychology masking masking refers phenomenon louder sounds inhibit perception sounds close frequency 
prevalent theory bm divided channels bark scale masking take place channel 
significance effect human audition system hear partial auditory segment 
effect utilised various compression algorithms mpeg 
information see 
binaural processing human auditory system sensitive spatial awareness system 
speech allows discrimination single speaker crowded room effect known cocktail party effect music certainly helps discrimination different instruments ensemble 
different psychoacoustic effects localisation sound perceived originating discrete position dimensional space 
phenomenon sound appears located head usually encountered subject wearing headphones 
spatial awareness combination effects interaural time difference itd interaural intensity difference iid 
cues varying effect frequency 
itd measured phase difference ears greatest effect low frequency wavelength longer distance ears 
higher frequency path length ambiguous cue useful 
iid conveniently reverse property low frequency sounds easily head little attenuation higher frequency sounds iid db 
see chapter detail 
models pitch perception simple model pitch perceptual parallel frequency perception unable account phenomena observed 
obvious complex tone perceived complex tone composed sinusoids integer multiples fundamental frequency 
human audition perceive single sound pitched fundamental single tones fuse perceptual common perceptual phenomenon sensation pitch frequency fundamental 
called virtual pitch residue pitch 
example non existent fundamental evokes pitch frequency 
competing established theories ear perceives pitch place models temporal models 
place models model works lines pitch assigned pattern recognition analysis sound spectrum 
bm acts frequency analyser passes set spectral peaks central processor determines pitch 
place model refers fact pitch extracted excitation different places bm 
certain conditions ear hear individual tones ohm acoustical law requires experimental conditions 

auditory psychology classic example model goldstein optimal processor 
model peaks signal time extracted passed maximum likelihood processor pitch decision 
number phenomena explained theory virtual pitch pitch ear receives different harmonics 
pattern transformation model pitch principle different instruments play middle give percept pitch 
lossy informational process encodes peripheral activity pattern fourier representation extract spectral information central processor infer pitch 
virtual pitch theory place model combines analytic listening give spectral pitch global perception provides inference stage missing information 
schroeder place model uses multiples detected periods form histogram greatest peak taken pitch 
hermes produced opposite sub harmonic summation method pitch extraction sano connectionist model neural network type architecture example place model 
disadvantages models pitch firstly require greater spectral resolution ear known possess 
explain phenomena iterated noise signals spectrally flat perceptual pitch 
take account temporal information essentially snapshot instantaneous pitch 
temporal models temporal models assume pitch temporal information frequency analysis pitched sounds periodic fluctuation nerve firings locked 
behaviour shown human audition frequencies khz 
propose temporal model calling duplex theory 
consisted dimensional network delay lines coincidence detectors 
output spectral height axis autocorrelation delay 
meddis hewitt proposed temporal model signal filtered bandpass filters passed hair cell simulation model find probability spike occuring channel 
autocorrelation channel summary autocorrelation sum channels lag 
highest peak resulting spectrum perceived pitch 
model explain virtual pitch chord perception root chord returned perceptual phenomena 
patterson produced functional model entitled auditory image model aim designed physiologically accurate 
set gammatone filters modelled cochlea followed neural encoding stage temporal summation 
gammatone filterbank bandwidths moore erb formulae adopted researchers usual choice modelling frequency properties ear 
slaney lyon produced various methods computing called 
dimensional representation output neural encoding stage audition time filter channel axes 
converted correlogram channel range time delays produce dimensional plot lag extra axis see section 

signal processing auditory scene analysis side audition follows lesser understood psychological side covers processes occurring brain 
research starts psychologists early part th century 
outcome humans group information impinging senses number cues 
include common fate common onset offset evolution time proximity similarity continuity familiarity applied equally vision audition 
bregman book auditory scene analysis results years experiments came theory generally accepted today audition 
concepts grouping streaming low level events auditory system grouped streams number rules 
sources built streams 
important cues grouping music harmonicity common onset 
important cues common frequency variation vibrato leads common occurrence vibrato clearly heard louder accompanying ensemble conducted studies common offset 
common amplitude variation generally deemed effect 
processes take place brain memory learning 
generally accepted human years musical training hear individual notes recording certainly due fact perform sophisticated recognition learned memorised information 
mcadams explores processes 
noted humans ability attend certain sounds complex environment brain capable selecting small fraction total information impinging senses detailed analysis 
attention psychological effect 
slaney compares concepts pure hears analyse leisure interactive audition perception evolved satisfy attentive demand 
promotes second take place 
contains thorough review research audition 
large body literature concerning area relating vision desired 
terms music blurring field specifically music psychology discussed briefly section papers falling fields 
signal processing time domain waveform applications desired transform time varying frequency domain signal 
analogous process takes place membrane 
methods proposed task different applications differing levels suitability 
fourier analysis process extracting sinusoids signal applications varying speech analysis audio coding currently considered application musical transcription quite thoroughly researched 

signal processing oldest methods fourier transform described continuous case 
dt inverse 
time localised 
digital audio signals sampled discrete continuous 
case discrete fourier transform dft appropriate calculated range dependent length time domain signal longer time domain signal greater resolution frequency domain frequency th component signal sampling frequency 
clearly increasing decreases frequency separation bins 
increasing time domain resolution decreases dft performed samples 
stationary data issue musical signals highly time varying 
trade time resolution frequency resolution dft analysis 
analogous heisenberg uncertainty principle defined inequality 



effective duration effective bandwidth signal 
fourier transform achieves minimum energy localisation permitted 

musical signals exhibit large amplitude frequency variation time better representation short time fourier transform stft 
applies window data short comparison total signal length window non zero range transform time localised compromise reached frequency resolution reasonable time duration signal short assumed stationary 
inefficient calculate transform moving window forward sample time 
hop introduced stft calculated multiples hop length explicitly expressed il 
signal processing useful properties fourier transform multiplication window function signal time domain convolution frequency domain ft 

means window functions various properties give various amounts convolutive effect frequency domain 
simplest rectangular window ft sinc wave 
dt sin desirable window function significant side lobes introduce spurious detection artifacts 
windows commonly hamming hanning blackman kaiser windows 
harris explores different windows terms resolution ability estimation accuracy finding kaiser bessel blackman harris windows generally best resolving simple test signals generating spurious detections 
elie proposed set windows side lobes spectral peak picking 
main advantage dft stft computationally efficient methods calculating exist fast fourier transform fft 
speed implementation desirable especially real time applications considered 
methods improving resolution detect peak corresponding sinusoid particular frequency maximum fourier spectrum obvious rule 
frequency resolution limited bin resolution due quantisation 
low frequencies semitones fall single bin obvious need better resolution 
zero padding adding number zeros usually increasing length factor times windowed data greater bin resolution achieved simply increasing eqn 
process interpolates lower resolution bins specifically useful peak detection low snr peaks missed spectrum fell close give better estimate frequency 
accurate frequency 
signal processing estimation achieved efficiently accurately methods require expensive ft calculation see examples 
shows various effects zero padding 
shows dft hanning windowed frame consisting sinusoids hz hz amplitude ratios additive gaussian noise 
zero padding actual peak lower amplitude sinusoid detected 
zero padding sinusoids detectable peaks due interpolation effect frequency estimates peaks improved 
frequency hz amplitude zero padding frequency hz amplitude zero padding plots sinusoids gaussian noise showing effects zero padding 
constant methods membrane logarithmic frequency response suited music 
expressed eqn intervals music logarithmic relationships 
number researchers proposed constant methods sinusoidal analysis 
measure resolution compared centre frequency normal fourier analysis constant increasing increasing frequency 
kept constant frequency resulting analysis logarithmic 
proposed bounded transform produces constant number bins octave 
method follows fft calculated top octave stored rest fft discarded 
time domain signal low pass filtered downsampled factor 
new fft calculated twice frequency resolution top octave stored 
continued lowest desired octave calculated 
just extension zero padding concept suffers limitations described 
method proposed constant transform brown efficient implementation described 
method uses variable length hamming window constant bin corresponding quarter tone bin resolution proposed 
low frequency long windows shorter windows high frequencies 
efficient implementation single 
signal processing long fft multiplication different kernels bin 
disadvantage method harness greater time resolution gained shorter windows higher frequency hop length constant frequency range corresponds length lowest frequency 
see demonstration 
disadvantage constant methods general assume logarithmic relationship data music 
true relationships semitones leading nice property harmonic series logarithmic shape invariant fundamental frequency relationship harmonics linear 
fact triad input spacing harmonics various notes remains average constant frequency 
side note completely useless extension brown proposed value varied standard ft multi resolution methods order get pseudo constant better time resolution frequency increases various people levine wilson klapuri proposed multi resolution fourier methods usually called mft time frequency plane tiled varying shapes 
low frequencies estimated longer blocks higher frequencies crucially different length blocks hop individual rates usually half length 
gives greater time resolution higher frequency 
demonstrates various tilings time frequency plane 
high accuracy methods methods ideally require better frequency resolution provided quantised bin separation 
number methods proposed 
countless methods improving resolution basic spectrogram case sinusoids gaussian noise 
include marchand catherine proposed method signal derivatives 
difference ft peaks provide extra resolution approximately normal spectrum 
examined influence time signal fourier spectrum 
noted amplitude frequency changes separable effects shape spectral peak information harnessed greater resolution 
similar lines peeters griffin looked measures 
macleod amplitude phase bins side maximal bin peak gain better estimate frequency amplitude interpolation 
iterative procedure largest tone estimated removed considered described 
iteration stops noise floor reached 
step re estimates removes tone turn 
demonstrated method approaches cramer rao bound 
model notch periodogram perform subtraction reinsertion stage useful clean sinusoids 
include cite rodet contains review research area 
incidentally rodet done research sinusoidal methods able obtain papers 

signal processing time frequency fourier transform tiling time discrete fourier transform tiling time frequency brown constant tiling time tiling plots comparing tiling 
shows standard ft infinite time extent gives lattice effect dft time frequency plane tiled regularly demonstrates brown constant tiling gives logarithmic tiling frequency expense poor coverage time frequency plane shows changing tiling shape changes hop rate tiling shape changes 
note clarity hop rate shown equal window length 
signal processing autocorrelation methods autocorrelation methods provide alternative method finding frequency spectrum searching periodic repetitions signal 
autocorrelation takes form dt discrete domain windowed approach xw xw approach old described people review papers 
judith brown examined narrowed autocorrelation function extra cross products get sharper peaks spectrum 
various researchers lyon slaney guy brown ellis scheirer autocorrelation methods output ear model usually described section produce termed correlograms 
vertical axis frequency cochlear channel horizontal axis lag autocorrelation function channel 
researcher uses different methods finding correlogram applies different processing techniques attempt extract information 
methods draw similarity model way ear works single motivation choosing correlogram method 
success validating model number purposes including ecological sound scene analysis ellis extraction semantic judgements music scheirer 
example correlogram autocorrelation method pointed klapuri suitable auditory scene analysis general useful polyphonic transcription 
harmonic sounds especially chords considered relationships fuse autocorrelation method 
impossible separate notes stage particularly harmonics perceptually fused correlogram process 

signal processing bilinear distributions linear suffer frame methods limit time frequency resolution imposed uncertainty principle 
wigner proposed distribution applied context signal processing ville known wigner ville distribution time delay angular frequency time domain signal denotes complex conjugate 
distribution bilinear contains linear functions signal 
time invariant 
bilinear nature means optimal representation stationary signals shows reduced distortion better time frequency resolution non stationary signals 
cohen showed number time frequency representations related wv transform linear transformations 
includes stft autocorrelation 
general equation 
time offset centre transform time window delay angular frequency doppler shift time domain signal kernel 
relates cohen equation stft repeated 
wv distribution various time frequency representations proposed including choi williams distribution generalised wigner ville distribution 
methods working optimally signal single component crucially exhibit cross products multiple components 
obvious considering consist components components components xy 
cross products multiple components hard distinguish impossible tell just inspection correct terms extraneous cross products 
jones parks undertook comparison resolution number time frequency representations including wigner smoothed wigner pseudo wigner choi williams stft concluded stft best frequency resolution 
effort overcome cross product interference developed modal transform specifically musical analysis 
achieved filtering wigner ville transform dimensional filter providing cross product suppression time frequency modulation 
modal distribution described lp glp 
hlp low pass filter time cross product suppression glp frequency modulation equivalent 
relating cohen equation eqn mk hlp glp 
signal processing gives clearer idea kernel relates wv transform 
sterian details implementation issues uses transform polyphonic transcription 
main problem method order produce filters cope simple examples amount time frequency smoothing distribution smoothed back stft anyway 
method attempting overcome cross term interference bilinear transform 
considers smoothing bilinear distribution equivalent diffusion process 
rate diffusion smoothing varied time frequency plane guided stft region peak stft diffusion slow bilinear transform left relatively unaltered 
conversely regions stft low amplitude unwanted cross terms diffusion rate high peaks smoothed away 
results chirp examples produce visibly clearer spectrum stft wigner ville 
generally ignored bilinear distributions reasons firstly cross terms cause problems spectrum dense polyphonic music secondly inefficient calculate 
parametric methods far transforms considered produce distributions mappings different domain applying prior knowledge signal 
parametric methods expectation form signal find set parameters best fit data 
common methods autoregression ar moving average ma combination arma 
finding plane set poles zeros model spectrum 
ar models poles find peaks ma zeros defining minima 
model assumes signal generated feeding white noise filter form transform poles transform zeros 
problem parametric methods model order number poles zeros needs predefined 
order small data smoothed spectrum order high spurious results appear 
walmsley briefly explored methods form music algorithms 
included area 
walmsley went investigate bayesian methods utilise prior knowledge help refine parameter estimates musical tone extraction 
detailed description method section 
number methods attempt closely model particular type signal bayesian methods effectively utilised ability bayesian methods 
signal processing perform methods comes accuracy model proposed 
examined mcmc methods chirp signals amplitude envelop described ar process 
non linear squares look single component sinusoids arbitary envelopes 
li djuri joint bayesian method parameter estimation harmonic signals 
methods wavelets proposed various researchers mallat possible method sinusoid extraction 
attraction wavelets constant property mimicking ear 
show wavelet transform equivalent gammatone filterbank patterson 
showed wavelets locating onsets see mallat polyphonic pitch detection purposes 
de cheveign looked time domain filtering methods combinations notch filters run time series data set producing minimum output taken correct 
designed separation concurrent speech mind scale harmonic series 
method matching pursuits data compared large redundant dictionary atoms individual elements scaled combined produce signal 
atom producing minimum residual energy subtracted signal taken element remainder compared dictionary entries find atom fits best 
continued residual energy threshold 
goodwin uses method 
uses gabor analysis similar matching pursuits tries decompose tf space set components applies music 
transient analysis methods dedicated sinusoidal analysis 
musical audio consists transient sounds onsets drums sounds particular number methods proposed explicitly model transients starting pollard conducted study starting transients 
matching pursuits see section adapted model transients including set transient atoms dictionary 
discrete cosine transform dct proposed method coding frames data contain transient sinusoids extracted 
converts fft new domain transient occurs early frame maps low frequency sinusoid occurring transient maps higher frequency dct domain 
ar modelling musical transients 

polyphonic transcription research polyphonic transcription research historical overview person record polyphonic pitch detection 
methods harmonic comb related greatest common harmonic located step 
voice polyphony greatest considered limitations vibrato union octave twelfth ratios voices 
thesis written stanford unable find copy described application harmonic comb method speech 
early researcher simple polyphonic transcription 
algorithm examining pitch frequency ratios 
pairs partials identified short time spectrum compared find potential harmonic ratio 
simple ratio assigned tentative harmonic number part series weightings hypothesis 
performed recursively pairs considered 
pitches calculated 
performance pitch theory models see section time considered noted algorithm suffer reasonable polyphony 
general thoughts transcription adopted 
thesis completed ann arbor unable obtain copy 
chafe stanford university group continued research forms musical engineering transcription 
chafe see section 
time domain approach event detection 
periodicity estimated adapted version algorithm account knowledge piano tone spectra 
rhythm information generated event detector segment score termed early context 
source identity discussed examples 
give results transcription plots individual stages 
commonly cited unable obtain 
max polyphony considered instruments mainly piano cello ipus developed university massachusetts general signal processing tool integrated processing understanding signals ipus blackboard scheme applied specifically casa 
basic schema extract information audio signal frame frame find parameters describe signal knowledge sources 
ipus framework combining bottom processing top prior global information resolving hypotheses different levels blackboard 
system dynamic element processing parameters adapted higher levels better resolve ambiguities 
accomplished interactive architecture discrepancy detection diagnosis signal re processing see 

polyphonic transcription research extension computational auditory scene analysis specifically relate transcription tasks performed general architecture 
level testbed proposed time domain signal bottom intermediate levels peak hypotheses encompassing sound script hypothesis top 
problem solving model planner reprocessing loop spa output hypotheses spa output level level level level hypotheses expectations sources knowledge discrepancy detection diagnosis reprocessing signal data control plan interpretation reprocessing loop differential diagnosis spa execution focusing heuristics sou selected differential diagnosis sou summary blackboard expectations blackboard framework ipus nakatani nakatani proposed agent system sequential frame method 
types agents tracers 
watcher looks spectrum decides new harmonic new noise cloud appeared 
instantiates new tracer agent follow event time 
tracer subtracts signal spectrum watcher looks new signals 
system expanded look stereo separation sounds termed binaural harmonic stream segregation system 
interaural time delay itd intensity difference iid find direction group sounds coming source 
max polyphony considered instruments vocal don quite know acronym derives 

polyphonic transcription research kashino kashino principal researcher system entitled optima bayesian formulation integrate information different levels 
tier hypothesis structure created single frequency components lowest level followed notes chords top 
bottom top processing carried bayes rule provide support hypotheses different levels knowledge sources provided prior information 
success rate papers quoted unclear exact method bayesian formulation 
kinoshita expanded optima include instrument templates help overcome problem overlapping frequency components 
success rate improved 
max polyphony considered instruments piano flute violin kashino time domain spectral template matching method 
phase tracking performed match template phase signal subtracted time domain bayesian network integrate musical prior information likelihood interval occurring similarity tone series model vague term musical context choosing implied hypotheses derives set possible hypotheses explained 
examples consisting piano violin flute gave accuracy rated 
max polyphony considered specified instruments piano flute violin klapuri klapuri investigated areas transcription task 
considered sharing harmonics problem solve pointing prime number harmonics shared fundamental frequency 
accurate onset location investigated method chosen difference log time envelope different frequency channels 
advances see section 
front rhythm tracking number ad hoc algorithms determine tone type instrument polyphonic note recognition attempted number different cases 
simple cases chords random note mixtures looked considerable success 
short excerpts classical piano works investigated minimum success 
klapuri written large number papers various aspects transcription concentrating multipitch estimation general themes 
max polyphony considered instruments piano kings college london plumbley investigated neural networks see overview transcription music 
fft wt front find harmonics basic way 
data passed multiple cause neural network trained individual notes combinations notes 
presentations training data neural network recognise patterns instruments playing repeated notes simultaneously 
really class polyphonic 
polyphonic transcription research music notes playing random rhythm set harmonic relations 
total number sources sounding time 
max polyphony considered see instruments clarinet flute abdallah researching transcription neural networks results published bello monti researching transcription combination plumbley neural network front blackboard architectures similar martin see ipus framework see bits people research thrown 
monophonic pitch tracker implemented simple polyphonic music tried albeit artificial examples 
gives overview research kcl 
max polyphony considered instruments piano goto goto investigated rhythm tracking drum beats chord change recognition 
extended detecting melody bass lines 
done estimating dominant pitch certain frequency ranges hz bass hz khz melody tone models ml estimation model em algorithm 
multiple agents salience detector find possible candidates employed architecture 
system tested range commonly available popular jazz classical recordings seemingly performed 
occasion melody tracker track part recording string counter melody melody continuing 
represent true transcription program detects dominant pitch actual notes worth noting 
patterson gammatone filter model auditory periphery initial processing stage 
output adjacent overlapping filters combined find estimate frequency produce synchrony strands tracks 
passed blackboard type system number ad hoc grouping rules associate data organisation hypothesis region 
sliding window length ms data passes leaves region best hypothesis fixed final output 
method gave accuracy ability identify different instruments somewhat lower separating different instruments max polyphony considered instruments piano guitar bass sterian sterian produced thorough engineering oriented investigation polyphonic transcription 
modal transform front peaks tracked frames kalman filtering 
tracks associated notes bayesian methods grouping rules common onset harmonicity 
multiple hypotheses maintained mht sparse coding musical signals submitted publication 
polyphonic transcription research algorithm allows hypotheses discarded 
assumptions simplified calculation needed may affected performance firstly tracks assigned note 
means shared harmonics considered fix included allow notes power shared frequency 
kalman filtering stage assumed fairly simple model partial evolution discounting vibrato instance examples included vibrato 
reasonable success note polyphony accuracy note polyphony 
papers include depth discussion method section 
max polyphony considered instruments brass trumpet french horn walmsley walmsley bayesian methods employing markov chain monte carlo mcmc methods metropolis hastings attempt transcription task 
general linear model glm signal bayesian methods try estimate parameters directly see 
purely parametric method non parametric front 
model constructed initially unlinked frame frame basis information carried frames 
produced reasonable results global parameters controlling evolution data multiple frames included performance improved 
see section discussion method 
max polyphony considered instruments piano monophonic example contributions music transcription parsons worked speech processing came useful ideas separating speakers necessarily involves pitch estimation sources 
peaks stft examined determine consisted harmonic symmetry phase behaviour pair harmonic series searched frame frame frame linking included limiting pitch change allowed track 
researched transcription vocal performances rudimentary tempo detection algorithm unclear method pitch extraction 
monophonic system performed adequately 
described method polyphonic analysis connection machine massively parallel risc computer 
come rapid development desktop pc 
music system early attempt music understanding 
transcription mentioned briefly refers reader unable find 
discussed sentiment extraction understanding reproduction performances 
realistic scale chord recognition system 
maher developed method transcribing non overlapping termed way mismatch procedure 
results monophonic analysis single singing voices amazingly successful 
results presumably theses able obtain 

polyphonic transcription research investigated event separation musical sound correlogram front 
method apply image processing correlogram convolving templates representing note onsets offsets different frequency variation find events 
aids event separation note extraction justification cues human auditory system 
results readable copy obtained 
rodet statistical model estimate fundamental frequency best fitted non sinusoidal noisy data 
monophonic examples 
expanded original method include hmm tracking different frames extra robustness 
gave description transcription system mft neural networks 
various side issues rhythm tracking mentioned results 
looked tracking frames stft purposes analysis resynthesis 
produced cited method finding note onsets looking high frequency information suggesting abrupt phase changes manifested 
martin researched polyphonic transcription moving instrument identification 
blackboard system stft front 
part synthesised piano example finds lower notes reasonable accuracy unable distinguish higher pitched notes harmonics lower ones 
blackboard system correlogram introduced front 
performance increased 
implemented ml estimation algorithm chip intention audio midi conversion polyphonic sources 
lots implementation issues dealt results limited 
monophonic analysis method 
attempted segment sample detecting note onsets statistical time domain method 
wavelets pitch analysis 
rossi investigated identification polyphonic piano signals 
stft front spectral templates 
note midi generated polyphonic example accuracy quoted 
authors point piece fairly long duration notes 
fernandez cid multiscale sinusoidal model basically see section different hop rates different scales set sensible heuristic rules detect notes frame 
results 
poole macleod algorithm front transcriber program 
simple ad hoc rules included attempt overcome problems octave drop notes resolved harmonics 
tracking introduced methods tried built harmonic detector acted somewhat mq algorithm filtered grid likelihood values try find tracks time 
results simple monophonic examples showed partial success far went 
gerhard produced report computer music analysis moderately comprehensive published actual research 
dixon simple methods windowed stft peak picking track forming transcribe solo polyphonic piano music 
gave accuracy various test pieces generated midi real performance input 
hainsworth looked transcription bass lines complex polyphonic signals 
onsets located stft frames tailored fit inbetween onsets pitch detection 
tracking 
related research musical processing performed time extract repeated notes 
sensible heuristic thresholds set generally ah hoc system 
success reasonable notes extracted correctly 
produced number papers looking music analysis slant analysis resynthesis guitar tones 
main points works enhanced summary autocorrelation function variant correlogram designed finding salient peaks easier 
mentions non linear squares method local estimation unresolved harmonics 
pattern matching methods spectra try identify drum signals 
top bottom information nominally integrated method 
davy researching particle filters perform harmonic frequency estimation musical samples segmented regions notes unchanging method 
chua compared number methods harmonic estimation including classical bayesian parametric fft methods autocorrelation 
segments joining short blocks similar 
autocorrelation best monophonic sounds useless polyphonic examples 
simple harmonic model method fft spectra worked best 
small number unable find cited literature 
included completeness 
simple auditory model perform musical analysis schloss researched transcription percussive sources hawley produced number heuristic rules musical analysis large dynamic representations musical structure examined various mathematical models music fitted local harmonic models musical signals worked partial tracking onset localisation probably wavelets mont watson looked music transcription 
related research musical processing polyphonic transcription task form processing applied musical audio 
areas explored bearing successful polyphonic transcription algorithm indirectly 
scheirer score knowledge cheat words extraction expressive information exact timing dynamics audio recordings 
points task perceptually meaningful time resolution fine order ms 
uses narrowband filters tuned expected notes extract high time resolution information note onsets 
similarly extracts information midi generated audio original midi file aid purposes synchronising computer graphic motion audio 
scheirer went examine extraction semantic information judgement piece music fast quiet boring annoying 
accomplished correlogram transformations performed rhythm tracking algorithm 
validation results performed psychological studies comparing 
related research musical processing human reaction computer generated 
aucouturier looked segmentation music signals examining texture 
attempted differentiate instance just violin playing violin piano sounding hmm coding spectrum envelope input 
results spectacular possibly due fact envelope depended pitch considered 
brillinger examined higher order spectra music specifically zero crossing rate smoothed amplitude profile looking gaussianity 
properties gaussian linear 
attempted classify music genre neural network method compared hmm implementation 
instrument recognition musical instrument identification audio task met success identification solo performances 
identification instruments rich polyphonic sound scene task humans perform ease received little attention literature cases mentioned section 
brief review dedicated instrument identification research 
martin large set features derived correlogram hierarchical system selection best discrimination features node nearest neighbours classifier 
top level hierarchy instrument families working individual instruments bottom 
success rated instruments playing single notes isolation 
brown cepstral coefficients build feature vector 
gaussian mixture model proposed model bayesian classifier 
results discrimination sax success 
methods proposed met varying success 
include support vector machines svm binary trees neural networks higher order statistics rough sets 
detailed literature review area 
worth mentioning model auditory system mechanical model 
claimed better time resolution stft methods show visual examples discriminating different consonant sounds flute playing 
timbre analysis general mentioned related area 
grey people examine area finding number cues produce timbre space segmented instrument sounds similarly humans 
necessarily involve instrument identification simply timbre information 
abe produced algorithm purported undertake timbre space transform 
rhythm tracking people looked rhythm tracking musical signals including desain scheirer dixon goto 
methods met reasonable perfect success wide variety methods 
contains reasonable literature review research area 

related research signal processing stereo processing mentioned section human ear distinguish direction sound arrives 
music recorded today contain time delay information instruments recorded close range amplitude signal left right channels varied produce direction 
artificial stereo information generation psychological knowledge pointless amplitude variation 
chan produced naive study area nakatani investigated cue polyphonic tracking 
chord detection area active area research years 
transcription purposes accurate chord detection useful source prior information 
commercial programs exist purport perform task varying degrees success 
literature constant transform expected chord shapes attempt identification particular chord 
fairly long time frames manually segmented data 
neural network supposed self organising fair amount prior structure identify chords 
test algorithm conclusively 
post processing techniques exists literature processes involved converting output transcription algorithm legible musically correct score 
currently manually generated midi data input algorithms 
really relevant research contained report mentioned completeness 
researched automatic pitch spelling correctness melodic segmentation musical boundary detection presents issues involved 
investigates automatic detection tonal context 
instrument models synthesis gleaned research instrument models synthesis comes transcription methods described templates help overcome ambiguity inherent overlapping harmonic series 
early synthesis algorithms variety methods additive synthesis 
methods included large amount research physical modelling synthesis proposed smith uses digital delay lines model various instruments 
related research signal processing section signal processing areas certain degree overlap musical audio analysis field briefly mentioned 
extensive literature reviews carried fields 

related research signal processing computational auditory scene analysis field abbreviated casa quite lot attention researchers wishing produce computer model human audition process 
algorithms tend latest understanding field auditory psychology advances statistics time frequency mathematics 
guy brown person term casa investigated segmentation sounds correlogram computation modelling auditory grouping various mechanisms including perceptual grouping linked oscillator networks 
ellis looked ecological sound scene identification 
correlogram section blackboard scheme emphasising mixture top bottom processing produce explanations sound scenes building sites city streets 
speech processing fields musical audio understanding casa speech recognition degree overlap relevant research report having conducted framework speech analysis 
speech recognition received large amount attention years currently working reasonable degree acceptable commercial voice recognition software packages available 
front ends fairly simplistic frame frame stft methods extract formants pass hidden markov model viterbi algorithm 
state art interested readers doubt find relevant literature ease 
audio coding audio coding source techniques applied music transcription 
sinusoidal model originally coding resynthesis serra sines residual model formed basis musical analysis models 
duality audio coder ideally extract information needed transcription purposes stable sinusoids transient information signal 
models coding field sines transients residual model switched parametric transform coder 
noise reduction field common ground musical analysis restoration algorithm takes account musical structure 
godsill wolfe serve starting points literature field 
time frequency signal classification field involves classification parameter extraction usually simple signals chirps bilinear distributions 
different problem considered parallels 
starting point interest area 

notes notes note read analysis reassigned spectrograms material chapter originally 
time frequency tf reassignment new technique 
introduced method improving readability tf representations 
analysis spectrograms time frequency time scale representations formant tracking speech improved resynthesis musical sounds 
carried statistical analysis reassignment 
reassigned spectrogram bilinear constitute valid tf representation invertible satisfy heisenberg pauli weyl inequality 
received little attention mathematical circles 
engineering method post processing tf representation obtain better estimates energy localisation advantage reducing influence analysis parameters window length hop rate distance window centres removing effect quantised tf lattice determined settings 
case spectrogram phase information short time fourier transform stft reassign energy away sampling lattice point centre gravity windowed energy stft th stft stft dh stft denote real imaginary parts respectively ratios windowed calculation 
denoted stft uses window second stft th uses window weighted time ramp 
final stft dh uses time derivative window dh dt akin weighting fourier transform frequency ramp 
reformulated 
avoid complex division follows stft th stft stft dh stft shows effect reassignment standard spectrogram segment musical audio 
sharpening harmonics frequency clearly seen better localisation onset transients 
standard reassigned spectrograms piano melody note extraneous artifacts due plotting process applies mesh threshold low amplitude points occasionally show spuriously large values reassignment 

classification reassigned spectrogram classification reassigned spectrogram spectrogram better reassigned spectrogram sample speech music human eye clearly see trends pick auditory objects harmonics transients global structures notes words 
purposes parameterising data frame frame analysis spectrogram effective method 
proposed classify data frame stft number classes object 
obvious classes relatively stable sinusoid corresponding harmonic partial sustained portions musical note 
case single frame class appears sharp spike stft reassignment 
comparable proposes model consisting just sinusoids extended sinusoids residual model audio signals 
closely related sinusoid class unresolved sinusoids frequencies individual sinusoidal components close smoothing effect analysis window blurs 
reassignment effect making outer sides combined peak quite sharply defined near individual frequencies inner stft bins reassigned little frequency due fact reassignment vector biased combination sinusoids 
sinusoids close form single peak proposed method return single sinusoid transient classification depending width peak 
cases time reassignment largely irrelevant signal power fairly uniformly distributed analysis window time centre gravity centre frame reassigned point remains lattice 
class object termed transient potentially exhibits time reassignment 
transient described general terms signal energy concentrated time period shorter analysis window simplest example perfectly time localised impulse 
models explicitly include transient analysis albeit coding include 
natural music sounds common occurrence sinusoids amplitude percussive sounds short duration broadband frequency character 
sinusoid convolution effect frequency domain amplitude function causes energy spreading frequency peak stft causes positive offset time reassignment energy half analysis window 
final class noise defined left unclassified previous tests 
generally consists high frequency information low amplitude shows sinusoidal properties low amplitude peaks side higher amplitude sinusoids 
course may contain relevant information therefor retained subsequent processing stages 
classification method methods employed standard pattern classification techniques 
various statistics examined gave best differentiation classes object utilised 
classification performed sequential frame frame manner frame examined independently order gain insight performance limits method 

classification method data association stage process cluster data points belong single object defined section 
stage identity object unknown process uninformed 
specifically maxima standard spectrogram considered potential object seed stft samples bins falling peak neighbouring valleys associated seed 
various statistics calculated side cluster separately considering bins higher frequency maximal point independently 
include 
energy weighted variance frequency 
energy weighted variance time calculated fashion similar 
np number stft bins included half cluster 
nfr noise floor ratio ratio energy cluster noise floor giving measure prominent cluster local region 
fsr forced sigma ratio measure reassignment magnitude bin adjacent peak sinusoid test traditional methods pattern classification form second stage method 
dimensional feature vector parameters follows 
fsr 
parameter determined fisher linear discriminant analysis lda frequency np 
lda nfr frequency 
parameter lda inversion described equation remove effect clusters consisting sample give variance zero 
calculated mb mb frequency maximal bin frequency amplitude respectively bins half cluster noise floor background noise smoothed amplitude profile bidirectional filtering log magnitude spectrum 
essentially ratio energy weighted variance peak bin neighbour reassignment 

classification performance parameters empirically best discriminating respective classes 
training data generated manually labelled frames comprising individual clusters labelled sinusoids perform lda train classifier 
stage straightforward way classification task gaussian distribution assumed classes training data likelihood ratio test applied ln data vector classified means variances respectively classes sinusoid sinusoid 
equation applied separately side frequency cluster 
sides classed sinusoidal cluster assigned sinusoid 
side classed sinusoidal cluster assigned second class unresolved sinusoid 
motivation looking side peak independently allows classes assigned simultaneously 
transient classification having assigned clusters class sinusoid unresolved sinusoid part classification process entails extraction transient objects analysis frame 
noted objects characterised high variance frequency significant time offset 
stage process employed stage assigns cluster greater empirically determined threshold set transient 
second step searches clusters offset time 
smoothed time profile individual frame clusters convolution vector cluster time offsets smoothing kernel clusters classed jt ms jt ms nth cluster assigned transient 
criteria dictate time offset close smoothed profile significantly greater zero 
noise classification final step cluster left unclassified stage assigned noise 
classification performance examples performance classification method 
sample rate khz case frame length samples equating frame duration ms employed frame hop rate samples 
plots format 
classification performance horizontal lines sinusoids output unresolved sinusoid extractor 
assumed existence frame plotted range extracted time centre usually close original lattice point give overlap sake clarity 
vertical lines transients shown reassigned frequency range time instant deemed located 
greyscale indicates amplitude 
shows output classifier single note bass guitar demonstrating evolution harmonics time 
transient event clearly visible may contact string just barely audible 
interest fact method picked low amplitude sinusoids harmonic ratio original note 
due coupling strings body resonance 
output program time ms output bass note shows expanded view single guitar note transient clearly visible 
frame onset occurs transient energy offset half frame centre marked dotted line 
visual examination time domain signal time period shown fig 
confirms accurate location onset 
fact time reassignment original sound files full size colour plots data web www eng cam ac uk html 
discussion located onset correctly millisecond marked improvement quantised ms localisation offered standard spectrogram parameters 
time output program time domain signal time output guitar note showing transient arrows highlight time reassignment final example fig 
major triad played piano bass drum sounding concurrently chord onset drum sounding 
transient energy clearly localised onsets 
seen additional broadband signals affect sinusoid estimation especially onset drum comparatively long noisy decay 
discussion proposed method demonstrates advantages traditional means extracting information time frequency representations sinusoidal modelling correlogram 
firstly explicitly includes method extracting information transient nature 
music speech significant advantage large portion musical sounds transient characteristics 
discussion output program time output chord plus drums note onsets drum sounds 
important role transient events auditory perception music instrument identification rhythm tracking name obvious areas method recognition clearly form part successful music transcription system 
important point concerning musical signals real world examples sounds rarely consist pure sinusoids impulsive transients 
states perfectly localised energy form ends continuum reflected variance measurement method proposed 
variance extraction prove important processing adds extra information tracking indicating confidence component sinusoid amount frequency amplitude modulation affecting component 
instance transient expected variance affected sinusoidal components quite high 
note stabilises variances expected drop course significant modulation vibrato 
shows effect variances sinusoids plotted widths 
rapid post initial onset decrease variance visible increasing noise effect partials die away 
stressed plots shown include multiple frame tracking 
relevant low amplitude data missed loss rectified help subsequent processing steps incorporation harmonic comb type detector frame 
feedback processing included classification process 
output program time frequency hz bass note output component width proportional frequency variance probabilistic prior information 
addition subsequent tracking procedure expected detection rate relevant features improve significantly 
improvements currently implemented architecture infer actual musical information 
chapter principle time frequency reassignment proposed help refine musical audio data estimates resulting standard stft 
method classifying data single frame meaningful classes examined results shown musical examples aim front musical transcription program 
concluded method main advantages previous methods improved time resolution transient analysis extracts information variance harmonic partials 
hypothesised time reassignment help provide accurate indication rhythm explored insofar relates automatic transcription 
involve 
zero padding reassigned spectrograms building tracking system provide multi frame data linking construction system transcription 
zero padding reassigned spectrograms development properly explored zero padding reassignment method 
normal spectrograms zero padding interpolates bins produce smoother image contains information obtained spectrogram exception able detect small peaks 
applies reassignment zero padding samples simply interpolate reassigned spectrum 
methods analyse reassigned spectrograms statistics clusters highly dependent number distribution samples clusters adding points decrease dependency 
shows frame data zero padding reassignment 
effect investigated near 

zero padding reassigned spectrograms frequency hz zero padded spectrum reassignment frequency hz zero padded spectrum reassignment frequency hz non zero padded spectrum reassignment frequency hz non zero padded spectrum reassignment plots showing effect zero padding reassignment thoughts general things believe firstly chapter shall list general thoughts believe true music transcription computers concerned 
particular order claim originality thought 
instrument models important ambiguity mixing partials difficult overcome 
methods stft front opposed constant bilinear simple parametric methods produce results accurate low computational cost 
multi analysis sensible keeping data levels frequencies cross substantiate sensible 
data fusion needs 
may parametric models sinusoidal methods unable resolve harmonics close frequency 
extreme example walmsley reported able resolve separate strings piano note slightly tune personal communication parametric method 
transient analysis useful allow better modelling energy frame allow better judgements just 
prior knowledge useful 
envisage mainly include rhythmic information tonal context integrated lines chord progression useful 
reassigned spectrogram methods hold useful advantage give better time resolution 
spreading energy note onsets probably due extreme amplitude variation 
think instrument sounds little due actual transient thunk 
contradict godsill personal communication reported simple model removes harmonic components sound 
remainder clearly consists mechanical sounds instruments involved 

thoughts front drums especially bass drums cause thunk probably mask mechanical instrument sounds 
thoughts front chapter research carried time frequency reassignment method high accuracy estimation sinusoidal parameters 
propose continue focusing testing zero padding theory mentioned section implement harmonic comb attempt increased soft correct classification probability frames generate better training data current data limited resolved sinusoids somewhat deficient test thoroughly synthetic data generate statistical evidence accuracy method compare high accuracy estimation methods possibly try svm architecture classification procedure general problems front overcome detection estimation 
detection involves ability recognise events especially nearing resolution ability method 
estimation obviously extraction event parameters 
may try investigating parametric methods local estimation unresolved sinusoids 
examples method mentioned joint bayesian method proposed li djuri 
tracking tracking harmonics probably take form kalman filter method smoothed estimation 
methods possible 
brief exposition possible kalman implementation follows formulation described 
problem considered tracking harmonic partial dimensional plane amplitude frequency axes 
generally trends shown expected 
proposed equations follows 
tracking amplitude frequency frequency amplitude tracks expected kalman model 
shows slowly decaying sinusoid shows sinusoid undergoing small amplitude modulation stretched frequency clarity shows sinusoid undergoing frequency modulation shows case allowed rapid amplitude increase 
attentional model frequency amplitude considered separately commonality motion vibrato encountered 
frequency variations small generally due vibrato 
occasionally slowly varying 
amplitude modelled closely proposed acceleration included able model rate exponential decay 
possible dramatic increases amplitude probably due second note starting modelled 
probably controlled window selection update measurement mentioned tens tracks active time probably actual observations sinusoids sort selection process take place update reading track 
controlled properly multiple hypothesis tracking 
attentional model attentional model appealing method mentioned briefly possible avenue investigation 
model derives way humans transcribe music repeated listening gradual analysis individual phrase refining estimate moving 
springs ability trained humans attend just instrument set instruments rich polyphonic sound scene 
sort pattern recognition process place matching set sounds learned brain 
piano aid transcriber judgements similarity original sample latest iteration analysis 
computer imitation require framework notes phrases areas targeted closer attention prior knowledge form chordal analysis crucially rhythmic analysis methods perform attentional analysis firstly want gain 
essentially want track individual notes find pitch onset offset times 
expanded tracking phrase notes played instrument 
human ear picking just instrument ignoring rest computer isn 

bayesian model formulations potential methods mcmc proposed 
filtering methods proposed scheirer phase tracking spectral template matching kashino possibilities 
initial enthusiasm methodology increasingly sceptical sort cleaning method 
mainly requires reasonably decent estimation segmentation happening attentional methods applied 
wonder resolution problems able filter harmonics finely 
phase trackable 
templates match closely 
human brain overcoming slight variations computer model rigid 
bayesian model formulations model formulations 
see levels pitch bayesian model 
highest level apply formation partial tracks associate notes 
sterian uses kashino extent optima framework stuff 

level apply sinusoids events method stft equivalent 
equivalent association time frequency simultaneously harder model 
worked area 

lowest level apply data observations way propose model fundamental underlying processes estimate parameters model 
walmsley real example applied music sterian method sterian method uses modal transform bilinear distribution optimised music audio signals amount smoothing time frequency directions calculated basis expected frequency amplitude modulations 
kalman filter model produce smoothed frequency tracks time 
bayesian formulation proposed integrate knowledge 
defines note complex ft kn ft kn tracks incorporated note event frequency fundamental start times note 
partition data hypothesis grouping tracks notes false alarms fe 
bayesian model formulations probability partition tracks pr jt pr jt pr pr pr optimal partition ignoring denominator normalising factor constant search opt argmax pr jt argmax pr pr likelihood function defined pr pr pr pr ln ln likelihood functions enumerate support tracks partition 
defined terms strong activation functions ln po pr weak ones ln max cover criteria common onset offset harmonicity partial support lack partial gaps 
pr ignored set equal 
prior information included follows pr pr pr pr try see proposed false track cross term 
pr priori knowledge regarding probability note occuring 
short notes penalised ones outside frequency range ones significantly tune prevailing tuning 
multiple hypothesis tracking mht maintain number hypotheses new tracks added model discard low probability hypotheses 
sterian model simple sensible 
wrong sharing partial energy different notes covered 
instrument models 
fact partition tracks allows track assigned single note dangerous 
fact fix allow notes gain support tracks assigned notes poor solution 
method modal transform brings serious limits method vibrato allowed 

bayesian model formulations model built frame frame sinusoid estimates input output say reassigned spectrogram reduces data set sinusoids frequencies amplitudes width measure wants build notes track frames 
set sinusoids frame want partition set harmonic series 
method sterian employed 
define note fp start partial amplitudes time fp instrument inharmonicity factor start meta constructs define position note occupying relative instrument model 
quick note instrument models ideally complete time frequency amplitude evolution model probably lead ambiguity stages model certainly lead gigantic search space 
reasonable model lines synthesis model split transient region onset evolution specified fair amount detail 
stable part note relative harmonic amplitudes modelled constant 
decay section 
dramatically decrease search space time spent middle section note anyway fairly impossible say blind just single frame exactly stable region examining 
bayes nn false ln ln set likelihood functions 
basically leads search possible notes possible instruments possible times instrument model see different amplitudes 
large search optimal solution 
corners cut specifying searching combinations notes certain likelihood 
mht guided searches 
going quick doable 
prior information 
carry information likelihood particular note played particular instrument 
things go especially information timing chordal information probability note transitions included 
course frame linking problem 
frame set probable hypotheses notes occuring problem linking time 
priors walmsley utilised 
bi directional linking advantageous 

bayesian model formulations transient modelling included data thought equation modification 
walmsley method walmsley uses glm sinusoidal model represent signal local level 
single note gb 


sin sin sin 
cos cos cos multiple notes likelihood error signal dj exp jj map estimate jd dj ji ji represent frequency amplitude information 
extensions add parameter controls notes model order harmonic series needs specified 
frame linking included try develop smooth variation characteristics hopefully ignore spurious variation frame 
mcmc methods perform estimation parameters 
know basics 
walmsley model mathematically theoretically high frequency resolution capability certainly better offered stft similar totally parametric model 

timetable research method slow due nature mcmc methods 
serious flaws model simple theoretical model going allows easy integrations carried methods explored 
model inharmonicity implemented godsill include transients crucially allow amplitude variation frames 
means start notes signal poorly modelled 
final comment prior knowledge really utilised 
things learned probability functions walmsley direct improvement method going tackled 
possible directions direction propose stage follows sterian basic formulation starting point 
include instrument models help sharing partial tracks notes 
proper consideration harmonic sharing considered include prior information specifically rhythmic information 
include transient information include information residual spectrum help drums considering methods described sections question best 
walmsley model fundamental liable errors currently theoretical realistic 
model tracks track associate information essentially association harmonics notes track probably better 
suitable combination improve performance compared isolation 
timetable research gives timetable research years 
main avenues shown main line course overlap 
rhythmic analysis consider important prior source knowledge transcription included side topic 

timetable research mich lent easter summer mich lent easter summer 
tracking problem model formation write rhythm tracking test zero padding test theoretically implement kalman examine methods 
model structure include prior musical information plan bibliography abdallah 
year report music perception unsupervised learning 
dept electronic engineering kings college london september 
abdallah plumbley 
sparse coding music signals 
available line www kcl ac uk pse audio index html 
abe ando 
non linear time frequency domain operators decomposing sounds loudness pitch timbre 
proc 
icassp pages 

periodicity estimation hypothesis directed search 
proc 
icassp 

hum ll find 
new scientist pages march 

aucouturier sandler 
segmentation musical signals hidden markov models 
proc 
th aes convention amsterdam netherlands 
auger flandrin 
improving readability time frequency time scale representations method 
ieee trans 
signal processing may 

information line www com html 
becker plumbley 
unsupervised neural network learning procedures feature extraction classification 
applied intelligence 
bello monti sandler 
implementation automatic music transcription monophonic music blackboard system 
proc 
irish signals systems conference june 
bello monti sandler 
techniques automatic music transcription 
proc 
international symposium music information retrieval plymouth ma october 
bello sandler 
blackboard system top processing transcription simple polyphonic music 
proc 
digital audio effects workshop dafx 
stoica 
frequency estimation detection sinusoidal signals arbitary envelope nonlinear squares approach 
proc 
icassp 
bilmes 
model musical rhythm 
proc 
international computer music conference 
blackman 
design analysis modern tracking systems 
artech house 

polyphonic estimation polyphonic sounds 
master thesis cued 

time varying higher order spectra generalised wigner ville distribution analysis underwater acoustic data 
proc 
icassp volume pages 
bregman 
auditory scene analysis 
mit press 
brillinger 
investigation second higher order spectra music 
signal processing 
bibliography brown cooke 
computational auditory scene analysis 
computer speech language 
brown cooke 
perceptual grouping musical sounds computational model 
journal new musical research 
brown cooke 
neural oscillator model primitive auditory grouping 
ieee workshop applications signal processing audio acoustics pages new york 
ieee signal processing society 
brown 
calculation constant transform 
acoust 
soc 
am 
brown 
computer identification musical instruments pattern recognition cepstral coefficients features 
acoust 
soc 
am november 
brown puckette 
calculation narrowed autocorrelation function 
acoust 
soc 
am 
brown puckette 
efficient algorithm calculation constant transform 
acoust 
soc 
am november 
brown puckette 
high resolution fundamental frequency determination phase change fourier transform 
acoust 
soc 
am august 
brown zhang 
musical frequency tracking methods conventional narrowed autocorrelation 
acoust 
soc 
am 

fugue 
hutchinson 
burns 
intervals scales tuning 
deutsch editor psychology music chapter pages 
academic press nd edition 

formal theory discovery local boundaries melodic surface 
proc 
iii informatique 

midi traditional musical notation 
proc 
aaai workshop artifical intelligence music 

automatic pitch spelling numbers flats 
proc 
th brazilian symposium computer music 

melodic cue abstraction similarity category formation computational approach 
music perception spring 
cano 
fundamental frequency estimation sms analysis 
proc digital audio effects workshop 

year report research proposal 
technical report computer labs cambridge university 
os fern andes cid 
real time loose harmonic matching fundamental frequency estimation musical signals 
proc 
icassp volume pages 
chafe jaffe 
source separation note identification polyphonic music 
proc 
icassp pages 
chafe jaffe mont smith 
techniques note identification polyphonic music 
proc 
international computer music conference pages 
chan 
audio analysis music 
master thesis cued 

ethodes de dans le plan temps fr pour analyse le de non 
phd thesis universit de 
bibliography auger flandrin 
statistics spectrogram reassignment 
multidimensional systems signal processing 
daubechies auger flandrin 
differential reassignment 
ieee signal processing letters october 
flandrin 
time frequency detection chirps 
applied computational harmonic analysis 

choi williams 
improved time frequency representation multicomponent signals exponential kernels 
ieee trans 
assp june 
chua 
automated transcription digitised music signals 
master thesis cued may 
clarke 
rhythm timing music 
chapter pages 
clarke krumhansl 
perceiving musical time 
music perception spring 
cohen 
generalised phase space distribution functions 
math 
phys 
cross 
ai music perception 
aisb quarterly 
davy bartels 
improved optimization time frequency signal classifiers 
ieee signal processing letters february 
de cheveign separation concurrent harmonic sounds fundamental frequency estimation cancellation model auditory processing 
acoust 
soc 
am january 
de cheveign kawahara 
multiple period estimation pitch perception model 
speech communication 
deli ege elen cross 
musical schemata real time listening piece music 
music perception winter 
ph 
elie 
extraction spectral peak parameters short time fourier transform modeling windows 
proc 
ieee workshop assp 
desain honing 
computational models beat induction rule approach 
proc 
ijcai workshop casa 
catherine marchand 
high precision fourier analysis sounds signal derivatives 
technical report labri bordeaux 
available online www labri 
fr publications 
editor 
psychology music 
academic press nd edition 

available online rhythm harmony central com ftp software windows midi ex 
dixon 
extraction musical performance parameters audio data 
proc 
ieee pacific rim conf 
multimedia pages sydney australia december 
dixon 
lightweight multi agent musical beat tracking system 
proc 
pricai pages 
dixon 
computer recognition solo piano music 
interfaces australasian computer music conference pages 

estimation fundamental frequencies 
iee proceedings june 

description expression performance music gabor representations 
cambridge music processing colloquium september 
doucet 
sequential methods bayesian filtering 
technical report cued tr cued 
bibliography rodet 
estimation fundamental frequency musical sound signals 
proc 
icassp volume pages 
rodet 
fundamental frequency matching tracking maximum likelihood harmonic matching hmms 
proc 
icassp volume pages 
duda hart 
pattern classification scene analysis 
john wiley sons st edition 
ellis 
prediction driven computational auditory scene analysis 
phd thesis media laboratory mit june 
ellis 
prediction driven computational auditory scene analysis dense sound mixtures 
esca workshop auditory basis speech perception keele 
fern andes cid os 
multi pitch estimation polyphonic music signals 
proc 
icassp volume pages 
fitz haken christensen 
transient preservation transformation additive sound model 
proc 
international computer music conference 
fletcher 
physics musical instruments 
springer nd edition 
gerhard 
computer music analysis 
technical report tr school computer science simon fraser university 
richardson spiegelhalter editors 
markov chain monte carlo practice 
chapman hall 
godsill 
restoration degraded audio signals 
phd thesis cambridge university 
brown 
blackboard architecture computational auditory scene analysis 
speech communication 
goldstein 
optimum processor theory central formation pitch complex tones 
acoust 
soc 
am 
es 
adaptive diffusion equation time frequency representations 
proc 
ieee digital signal processing workshop utah august 
goodwin 
matching pursuits damped sinusoids 
proc 
icassp pages 
goto 
predominant estimation method cd recordings map estimation em algorithm adaptive tone models 
proc 
icassp 
goto 
real time music scene description system detecting melody bass lines audio signals 
proc 
ijcai workshop casa pages 
goto muraoka 
real time beat tracking system audio signals 
proc 
international computer music conference 
goto muraoka 
real time beat tracking audio signals chord change detection musical decisions 
speech communication 

time dependant arma modeling nonstationary signals 
ieee trans 
assp august 

bayesian parameter estimation chirp signal modulated ar process 
technical report cued september 
grey 
multidimensional perceptual scaling musical timbres 
acoust 
soc 
am may 
mallat ph 
rodet 
analysis sound signals high resolution matching pursuit 
uk symposium applications time frequency time scale methods warwick 
bibliography griffin lim 
new model speech analysis synthesis system 
proc 
icassp number pages 
hainsworth 
audio analysis music 
master thesis cambridge university 
hainsworth macleod 
automatic bass line transcription polyphonic music 
proc 
international computer music conference cuba 
hainsworth macleod wolfe 
analysis reassigned spectrograms musical transcription 
ieee workshop applications signal processing audio acoustics ny october 
hainsworth wolfe 
time frequency reassignment musical analysis 
proc 
international computer music conference cuba 
arm perceptual aspects warped techniques audio coding 
master thesis faculty electrical engineering helsinki university technology 
harris 
windows harmonic analysis discrete fourier transform 
proc 
ieee january 
hawley 
structure sound 
phd thesis media lab mit 
hermes 
measurement pitch summation 
acoust 
soc 
am january 
herrera serra 
instrument segmentation music content description critical review instrument classification techniques 
proc 
int 
symp 
music information retrieval 
imai inokuchi 
frequency complex spectrum 
proc 
icassp volume pages 
sms implementation 
available online www upf es sms 

statistics music fitting local harmonic model musical sound signals 
phd thesis univ california berkeley 

hierarchical constant transform partial tracking musical signals 
proc 
digital audio effects workshop dafx 
jackendoff lerdahl 
grammatical parallel music language 
clynes editor music mind meaning chapter pages 
plenum press 

musical signal parameter estimation 
master thesis berkeley 
jones parks 
resolution comparison time frequency representations 
ieee trans 
signal processing february 
jonsson 
detection uncertain multiple models 
proc 
icassp 
karjalainen 
multi pitch periodicity analysis model sound separation auditory scene analysis 
proc 
icassp pages 
mont 
bounded approach time varying spectral analysis 
technical report stan standford university 
kashino murase 
music recognition note transition context 
proc 
icassp volume vi pages 
kashino murase 
sound source identification system ensemble music template matching music stream extraction 
speech communication 
kashino kinoshita tanaka 
application bayesian probability network music scene analysis 
proc 
ijcai workshop casa 
bibliography kashino kinoshita tanaka 
organisation hierachical perceptual sounds 
proc 
ijcai workshop casa volume pages 
inokuchi 
music system 
computer music journal 
sentiment extraction music 
proc 
int 
conf 
pattern recognition 
kinoshita sakai tanaka 
musical sound source identification frequency component adaption 
proc 
ijcai workshop casa 
klapuri 
automatic transcription music 
master thesis audio research group university tampere finland 
available line www cs tut fi sgn arg music pdf zip 
klapuri 
pitch estimation multiple independant time frequency windows 
ieee workshop applications signal processing audio acoustics pages 
klapuri 
aspects design periodicity estimation algorithms 
proc 

klapuri 
means integrating audio content analysis algorithms 
proc 
th audio engineering society convention 
klapuri 
holm 
robust multipitch estimation manipulation polyphonic musical signals 
proc 
digital audio effects workshop dafx 
klapuri 
multipitch estimation sound separation spectral smoothness principle 
proc 
icassp 
lesser 
ipus blackboard architecture framework computational auditory scene analysis 
proc 
ijcai workshop casa 
plumbley 
experiments musical instrument separation multiple cause models 
cambridge music processing colloquium 
de 
analysis time varying signals small bt values 
ieee trans 
assp february 
krumhansl 
cognitive foundations musical pitch 
oxford university press 
large 
dynamic representation musical structure 
phd thesis ohio state univ 
lemur 
available online www org lemur 
lerdahl 
generative theory tonal music 
mit press 
lesser 
ipus architecture integrated signal processing signal interpretation complex environments 
proc 
aaai pages 
levine smith 
switched parametric transform audio coder 
proc 
icassp pages 
levine verma smith 
alias free multi resolution sinusoidal modeling polyphonic wideband audio 
proc 
icassp 
lewin 
music theory phenomenology modes perception 
music perception 

li djuri iterative procedure joint bayesian spectrum parameter estimation harmonic signals 
proc 
ieee int 
symposium circuits systems volume pages may 

li 
fast algorithm efficient estimation frequencies 
proc 
eusipco pages 

duplex theory pitch perception 

longuet higgins 
artificial intelligence musical cognition 
phil 
trans 
soc 
lond 

bibliography lyon 
computational model binaural localization separation 
proc 
icassp pages 
macleod 
high resolution nearly ml estimation sinusoids noise fast frequency domain approach 
proc 
eusipco pages 
macleod 
nearly fast ml estimation parameters real complex single tones resolved multiple tones 
ieee trans 
signal processing january 
macleod 
joint detection high resolution ml estimation multiple sinusoids noise 
proc 
icassp 
maher 
approach separation voices composite music signals 
phd thesis dept electrical computer engineering univ illinois 
maher 
evaluation method separating digitized signals 
audio eng 
soc 
maher 
fundamental frequency estimation musical signals way mismatch procedure 
acoust 
soc 
am april 
mallat 
zero crossings wavelet transform 
ieee trans 
information theory july 
marchand 
improving spectral precision enhanced phase signal derivatives 
proc 
digital audio effects workshop dafx 
available line www upf es dafx papers 
martin 
automatic transcription simple polyphonic music robust front processing 
rd joint meeting acoustical america japan 
martin 
blackboard system automatic transcription simple polyphonic music 
technical report media laboratory mit 
martin 
automatic sound source recognition identifying musical instruments 
nato computational hearing advanced study institute il italy july 
martin 
sound source recognition theory computational model 
phd thesis media lab mit june 
mart 
mpeg 
technical report iso iec jtc sc wg int 
org 
standardisation 

computer modelling sound transformation synthesis musical signals 
phd thesis bristol university 
bateman 
identification non stationary audio signals fft application analysis synthesis sound 
proc 
iee colloquium audio engineering pages may 
bateman 
review time frequency representations application sound music analysis resynthesis 
journal organised sound 
mcadams 
recognition auditory sound sources events 
mcadams editors thinking sound 
oup 
mcadams 
audition cognitive psychology music 
churchland editors mind brain continuum pages 
mit press 

speech analysis synthesis sinusoidal representation 
ieee trans 
assp august 
meddis hewitt 
virtual pitch phase sensitivity computer model auditory periphery pitch identification 
acoust 
soc 
am june 
bibliography meddis hewitt 
virtual pitch phase sensitivity computer model auditory periphery ii phase sensitivity 
acoust 
soc 
am june 


ar modeling musical transients 
proc 
icassp pages vol pp 

event formation separation musical sound 
phd thesis dept computer science stanford university december 

musical sound information 
phd thesis media lab mit february 
amazing midi 
available online rhythm harmony central com software windows midi exe 
mont 
problem solving strategies music transcription system 
proc 
ijcai pages 
monti 
signal processing music analysis 
technical report dept electronic engineering kcl 
moore 
psychology hearing 
academic press th edition 
moore 
suggested formulae calculating auditory filter bandwidths excitation patterns 
acoust 
soc 
am 

optimum comb method pitch period analysis continuous digitised speech 
ieee trans 
assp october 

segmentation analysis continuous musical sound digital computer 
phd thesis stanford university 
nakatani okuno 
computational model sound stream segmentation multi agent paradigm 
proc 
icassp volume pages 
nakatani okuno 
harmonic sound stream segregation localization application speech stream segregation 
speech communication 

identification musical chords constant spectra 
proc 
icassp 

harmonic wavelet analysis 
proc 
soc 
lond 


harmonic musical wavelets 
proc 
soc 
lond 

inokuchi 
transcription sung song 
proc 
icassp pages 
parncutt 
harmony approach 
berlin springer verlag 
parsons 
separation speech interfering speech means harmonic selection 
acoust 
soc 
am october 
patterson ere 
time domain modeling peripheral auditory processing modular architecture software platform 
acoust 
soc 
am october 
peeters rodet 
signal characterization terms sinusoidal non sinusoidal components 
proc 
digital audio effects workshop dafx 
peeters rodet 
new analysis synthesis method spectrum peak shape distortion phase reassigned spectrum 
proc 
international computer music conference 
wakefield 
high resolution time frequency representation musical instrument signals 
acoust 
soc 
am april 
wakefield simoni 
time frequency analysis musical signals 
proc 
ieee sept 
bibliography pierce 
nature musical sound 
deutsch editor psychology music chapter pages 
academic press nd edition 

computational model music transcription 
phd thesis university michigan ann arbor 

predicting musical pitch component frequency ratios 
acoust 
soc 
am september 

computer model music recognition 
clynes editor music mind meaning chapter pages 
plenum press 
ainsworth 
formant tracking reassigned spectrum 
proc 
eurospeech pages 
meyer ainsworth 
speech spectrogram accuracy method reassignment 
ieee trans 
sap may 

ear frequency analyser 
acoust 
soc 
am september 
plumbley abdallah bello davies monti sandler 
ica related models applied audio analysis separation 
proc 
th int 
icsc symposium soft computing intelligent systems industry paisley scotland 
pollard jansson 
analysis assessment musical starting transients 

poole 
audio analysis music 
master thesis cambridge university 

personal communication relating polyphonic transcription 
rabiner cheng 
comparitive performance study pitch detection algorithms 
ieee trans 
assp october 

perception simultaneous notes polyphonic music 

rayner fitzgerald 
bayesian approach signal modelling 
uhl rayner kingsbury editors signal analysis prediction chapter pages 
birkh auser 
rich 
membrane mechanics base cochlea 
input output functions tuning curves response phases 
acoust 
soc 
am november 
rodet 
musical sounds signal analysis resynthesis sinusoidal residual elementary waveform models 
uk symposium applications time frequency time scale methods pages 
rossi girolami 
identification polyphonic piano signals 


midi comprehensive volume computer music digital audio series 
editions 
sano jenkins 
neural network model pitch perception 
todd loy editors music connectionism pages 
mit press 
scheirer 
extracting expressive performance information recorded music 
master thesis media lab mit september 
scheirer 
mpeg structured standard 
proc 
icassp 
scheirer 
tempo beat analysis acoustical musical signals 
acoust 
soc 
am january 
scheirer 
music listening systems 
phd thesis media lab mit june 
bibliography schloss 
transcription percussive music acoustic signal high level analysis 
phd thesis stanford univ 
sch olkopf 
statistical learning kernel methods 
technical report msr tr microsoft research 
schroeder 
period histogram product spectrum new methods frequency measurement 
acoust 
soc 
am 
serra 
musical sound modeling sinusoids plus noise 
roads pope de poli editors musical signal processing chapter pages 
swets zeitlinger 
serra smith 
spectral modeling synthesis 
proc 
international computer music conference 
shephard 
circularity judgements relative pitch 
acoust 
soc 
am 
shmulevich coyle 
establishing tonal context musical pattern recognition 
ieee workshop applications signal processing audio acoustics 
wilson 
note recognition polyphonic music neural networks 
technical report cs rr warwick university 
drum stroke recognition 
available line www cs tut fi sgn arg music drums drum html 
klapuri 
recognition acoustic noise mixtures combined bottom top processing 
proc 

slaney 
critique pure audition 
rosenthal okuno editors computational auditory scene analysis chapter 
lawrence erlbaum associates 
slaney lyon 
perceptual pitch decoder 
proc 
icassp pages 
slaney lyon 
importance time temporal representation sound 
cooke crawford editors visual representations speech signals chapter pages 
wiley 
smith 
physical modeling synthesis update 
computer music journal 

architecture robust partial tracking onset localization single channel audio mixes 
phd thesis technical university hamburg 

complex valued continuous wavelet transform preprocessor auditory scene analysis 
proc 
ijcai workshop casa 
schultz waibel 
recognition music types 
proc 
icassp 

analysis synthesis music auditory transform 
phd thesis dept electrical engineering mit 
sterian simoni wakefield 
model musical transcription 
proc 
international computer music conference 
sterian wakefield 
music transcription systems sound symbol 
proc 
aaai workshop intelligence music 
sterian wakefield 
robust automated music transcription systems 
proc 
international computer music conference 
sterian 
model segmentation time frequency images musical transcription 
phd thesis musen project university michigan ann arbor 
bibliography su 

multi timbre chord classification wavelet transform self organized map neural networks 
proc 
icassp 
terhardt stoll 
pitch complex signals virtual pitch theory tests examples predictions 
acoust 
soc 
am march 

model analysis resynthesis acoustic guitar tones 
master thesis helsinki university technology 

methods separation harmonic sound sources sinusoidal methods 
proc 
th aes convention munich may 

object sound modeling musical signals 
proc 
th aes convention los angeles september 
karjalainen 
computationally efficient multi pitch analysis model 
ieee trans 
speech audio processing november 
suzuki 
adaptive transform acoustic coding 
proc 
rd aes convention san fransisco october 
de poli mian 
audio analysis model physiological auditory system 
proc 
digital audio effects workshop dafx 
cumming 
connection machine tracking polyphonic music 
proc 
international computer music conference pages cologne september 
verma meng 
analysis synthesis tool transient signals allows flexible sines transients noise model audio 
proc 
icassp 
verma meng 
time scale modification sines transients noise signal model 
proc 
digital audio effects workshop dafx 
available online www upf es dafx papers 
ville 
theorie de la notion de signal 
cables transmission 
von ek 
variations phase membrane sinusoidal vibrations 
acoust 
soc 
am 

wavelet musical pitch estimation 
cued unpublished may 
walmsley 
signal separation musical instruments st year phd report 
cambridge university 
walmsley 
signal separation musical instruments 
phd thesis cambridge university engineering department september 
walmsley godsill rayner 
bayesian graphical models polyphonic pitch tracking 
forum 
walmsley godsill rayner 
multidimensional optimisation harmonic signals 
proc 
eusipco rhodes greece september 
walmsley godsill rayner 
bayesian modelling harmonic signals polyphonic music tracking 
cambridge music processing colloquium 
walmsley godsill rayner 
polyphonic pitch tracking joint bayesian estimation multiple frame parameters 
ieee workshop applications signal processing audio acoustics ny october 
watson 
computer analysis polyphonic music 
phd thesis university sydney 
wav midi 
available online rhythm harmony central com ftp software windows misc wav midi 
exe 
bibliography 
synth school 
sound sound 

pattern transformation model pitch 
acoust 
soc 
am 
wigner 
quantum correction thermodynamic equilibrium 
physics review 
wilson scott 
representations audio signal analysis 
uk symposium applications time frequency time scale methods pages august 

preprocessing automated transcription polyphonic music linking wavelet theory auditory filtering 
proc 
international computer music conference 

maximum posteriori estimation narrow band signal parameters 
acoust 
soc 
am july 
wolfe godsill 
application psychoacoustic criteria restoration musical recordings 
proc 
th audio engineering society conference february 

model auditory attention 
technical report cs dept computer science sheffield university 
