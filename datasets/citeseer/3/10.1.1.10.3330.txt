syntactic features word similarity supervised metonymy resolution nissim iccs school informatics university edinburgh inf ed ac uk supervised machine learning algorithm metonymy resolution exploits similarity examples conventional metonymy 
show syntactic head modifier relations high precision feature metonymy recognition suffer data sparseness 
partially overcome problem integrating thesaurus introducing simpler grammatical features preserving precision increasing recall 
algorithm generalises levels contextual similarity 
resulting inferences exceed complexity inferences undertaken word sense disambiguation 
compare automatic manual methods syntactic feature extraction 
metonymy speech expression refer standard referent related lakoff johnson 
seat refers person occupying seat 
ask seat importance resolving shown variety nlp tasks machine translation question answering stallard anaphora resolution harabagiu markert hahn 
uttered flight attendant plane 
markert iccs school informatics university edinburgh school computing university leeds markert inf ed ac uk order recognise interpret metonymy large amount knowledge contextual inference necessary seats questioned people occupy seats people questioned 
metonymic readings potentially open ended nunberg developing machine learning algorithm previous examples feasible 
long recognised metonymic readings quite regular lakoff johnson nunberg 
pakistan name location refers national sports teams 
pakistan won world cup similar examples regularly location names see 
england won world cup scotland lost semi final contrast regularity examples exploited supervised machine learning algorithm method pursued standard approaches regular polysemy metonymy exception previous markert nissim 
algorithm needs infer examples labelled metonymy england scotland metonymic 
order due regularity conventional metonymy known regular polysemy copestake briscoe 
term metonymy encompass conventional unconventional readings 
examples british national corpus bnc info ox ac uk bnc 
pakistan won world cup scotland lost semi final pakistan subj win pakistan context reduction similarity semantic class scotland subj lose scotland subj role similarity subj win head similarity lose context reduction similarity levels draw inference levels similarity need taken account 
concerns similarity words recognised metonymic literal possibly metonymic words 
examples pakistan england scotland 
level pertains similarity contexts subject won world cup subject lost semi final 
show machine learning algorithm exploit similarities 
corpus study semantic class locations confirms regular metonymic patterns place name sports teams cover unconventional rare section 
recast metonymy resolution classification task operating semantic classes section 
section restrict classifier features head modifier relations involving 
context reduced subj win 
allows inference feature value 
remaining context discarded feature achieves high precision 
section generalize context similarity draw inferences 
exploit similarity heads grammatical relation win lose grammatical role subject 
illustrates context reduction similarity levels 
evaluate impact automatic extraction head modifier relations section 
discuss related contributions 
corpus study summarize markert nissim annotation scheme location names annotated corpus occurrences country names 
annotation scheme location names identify literal metonymic readings 
literal reading comprises locative political entity interpretation 
coral coast new guinea britain current account deficit distinguish metonymic patterns see lakoff johnson fass stern 
people pattern place stands persons organisations associated sports teams government 
cardinal element iran strategy iranian naval craft 

place event pattern location name refers event occurred word vietnam vietnam war 
place product pattern place stands product manufactured word bordeaux referring local wine 
category covers unconventional categories fits markert nissim 
examples predicates involved triggering different reading 
arrived hitherto leading critic south african regime literal triggered arriving people reading triggered leading critic invoked 
introduced deal cases 
annotation results randomly extracted occurrences country names bnc allowing country name variants listed cia factbook wordnet fellbaum explicit referent underspecified introduce place people supertype category evaluate system supertype classification 
annotation specify different groups people referred possible markert nissim 
www cia gov cia publications factbook occur 
country name surrounded sentences context 
examples corpus independently annotated computational linguists authors 
annotation considered reliable krippendorff agreement kappa carletta :10.1.1.14.1751
corpus testing training algorithm includes examples annotators agree marked noise homonyms professor greenland total 
table reports reading distribution 
table distribution readings corpus reading freq literal place people place event place product mixed total non literal total metonymy resolution classification task corpus distribution confirms follow established metonymic patterns rare 
case kinds 
reformulate metonymy resolution classification task literal reading fixed set metonymic patterns identified advance particular semantic classes 
approach task comparable classic word sense disambiguation wsd concerned distinguishing possible word senses interpretations 
classic supervised wsd algorithm trained set labelled instances particular word assigns word senses new test instances word supervised metonymy recognition trained set labelled instances different words semantic class assign literal readings metonymic patterns new test instances possibly different words semantic class 
class approach enables example infer reading 
decision list dl classifier 
features encountered training data ranked dl best evidence loglikelihood ratio yarowsky pr log pr estimated probabilities maximum likelihood adopting simple smoothing method martinez agirre added denominator numerator 
target readings distinguished literal place people place place product mixed 
algorithms tested annotated corpus employing fold cross validation 
evaluate accuracy coverage acc cov correct decisions decisions decisions test data backing strategy frequent reading literal cases decision 
report results accuracy backoff coverage backoff 
interested algorithm performance recognising non literal readings 
compute precision recall fmeasure number non literal readings correctly identified non literal true positives number literal readings incorrectly identified non literal false positives non literal examples test data pr baseline comparison assignment frequent 
context reduction show reducing context head modifier relations involving possibly metonymic word achieves high precision metonymy recognition 
markert nissim considered local topical cooccurrences contextual features 
constantly achieved lower precision grammatical features 
table example feature values role head role head example subj win england won world cup place people govern britain governed 
literal dobj visit visited spain literal gen strategy iran 
place people veteran vietnam veteran rhode island place event border hungary literal represent example corpus single feature role head expressing grammatical role limited active subject passive subject direct object modifier prenominal genitive nominal dependent prepositional phrase lexical head dependency grammar framework 
table shows example values table role distribution corpus 
trained tested algorithm feature hmr 
results hmr reported line table 
reasonably high precision accuracy indicate reducing context head modifier feature cause loss crucial information cases 
low recall mainly due low coverage see problem 
identified main problems 
problem 
feature simplistic decisions head modifier relation assign wrong reading cases bad heads lexical heads semantically empty failing provide strong evidence reading lowering recall precision 
bad predictors verbs prepositions metonymic talk hungary literal border hungary readings 
problem serious function content word heads precision set subjects objects pps 
bad relations relation suffers noun noun compound ambiguity 
op consider link cases benefit including links participates 
feature values manually annotated experiments adapting guidelines poesio 
effect automatic feature extraction described section 
table role distribution role freq non lit subj dobj gen total eration refer operation literal metonymic 
cases rarely neglecting remaining context leads errors lexical heads relations 
inferring metonymy germany germany lost fifth territory metonymic wrong lowers precision 
wrong assignments relations constitute major problem accuracy high 
problem 
algorithm unable decision head modifier relation 
far frequent problem remainder 
feature role head accounts similarity classification test instance particular feature value relies having seen exactly feature value training data 
tackled inference 
problem manifests data sparseness low recall coverage heads encountered corpus 
hmr coverage backoff literal reading required cases 
generalising context similarity order draw complex inference need generalise context similarity 
relax identity constraint original algorithm role head value test instance dl exploiting similarity levels 
firstly allow draw inferences similar values lexical heads subj win subj lose identical ones 
secondly allow discard table example thesaurus entries lose win gain attitude stance behavior strategy lexical head generalise grammatical role subject 
generalisations allow double recall sacrificing precision increasing size training set 
relaxing lexical heads regard feature values similar similar 
order capture similarity integrate thesaurus lin algorithm testing phase :10.1.1.55.1832
lin thesaurus similarity words determined distribution dependency relations newswire corpus 
content word lose specific part speech set similar words part speech 
set members ranked decreasing order similarity score 
table reports example entries 
modified algorithm relax follows 
train dl role head hmr test instance observe procedure indicates feature value test instance 
dl apply corresponding rule choose number set extract th similar word hi thesaurus similarity score hi assign reading ifr hi dl apply corresponding rule hi dl increase go examples covered hmr classified exactly way relax see step 
assume encounter test instance feature value subj lose seen training data step fails step applied subj win dl 
relax rule subj win assign reading scotland win similar word lose thesaurus see table 
case original thesaurus subdivided clusters 
take divisions account 
results precision recall measure thesaurus iterations results relax applied iteration thesaurus finds word dl 
classification turkey feature value gen attitude required iterations find strategy see example similar attitude gen strategy 
say sums turkey attitude untrue precision recall measure visualised 
precision recall increase recall doubles hmr precision increases hmr yielding increase measure 
coverage rises accuracy backoff table 
increase coverage recall quite intuitive high precision achieved relax requires explanation 
set examples relax covers 
consists subsets subset covered hmr treatment change relax yielding precision 
set examples relax covers addition hmr 
examples consist cases highly predictive content word heads function words included thesaurus content word heads frequent normally covered hmr members 
precision high raises precision set cases relax cover mainly due missing thesaurus entries proper table results summary manual annotation 
relax combination report best results thesaurus iterations 
algorithm acc cov hmr relax relax ii combination baseline names alternative spelling small number training instances grammatical roles dobj thesaurus iterations similar role head value covered dl grammatical roles covered table 
discarding lexical heads way capturing similarity ignore lexical heads generalise grammatical role role ofthe feature values table subj dobj gen 
developed algorithm relax ii 

train decision lists dl role head hmr dl role test instance observe procedure rof feature values test instance 
dl apply corresponding rule ifr dl apply corresponding rule 
assume encounter test instance subj lose dl step fails step applied subj dl 
algorithm relax ii assign place reading scotland subjects corpus metonymic see table 
generalising grammatical role outperforms hmr achieving precision recall measure see table 
algorithm relax ii yields fewer false negatives relax higher recall subjects covered dl assigned metonymic reading true relax combining generalisations ways combining algorithms introduced 
experiments successful exploits facts relax ii performs better relax subjects relax performs better roles 
algorithm combination uses relax ii test instance subject relax 
yields best results far accuracy backoff measure table 
influence parsing results obtained training testing classifier manually annotated grammatical relations upper bound achieved features 
evaluate influence parsing results rasp toolkit briscoe carroll includes pipeline tokenisation tagging state art statistical parsing allowing multiple word tags 
toolkit maps parse trees representations grammatical relations turn map straightforward way role categories 
rasp produces partial parses examples 
parses assign role assigned role rasp contrast manual annotation see table 
rasp recognises subjects precision recall 
direct objects precision recall 
reproduced experiments automatically extracted relations 
relative performance algorithms remains unchanged resulting measures lower hand annotated roles table 
line results gildea palmer compare effect manual automatic parsing semantic recognition 
related previous approaches metonymy recognition 
approach machine learning algorithm metonymy recognition building previous evaluate rasp performance relations involve 
table results summary different algorithms rasp 
relax combination report best results thesaurus iterations 
algorithm acc cov hmr relax relax ii combination baseline markert nissim 
current approach expands including larger number grammatical relations thesaurus integration assessment influence parsing 
best fmeasure manual annotated roles increased dataset 
traditional approaches rely handcrafted knowledge bases lexica violations hand modelled selectional restrictions plus syntactic violations metonymy recognition pustejovsky hobbs fass copestake briscoe stallard 
approaches selectional restrictions srs seen preferences absolute constraints 
absolute constraint violated non literal reading proposed 
system priori knowledge semantic predicate argument restrictions 
refers previously seen training examples head modifier relations labelled senses computes likelihood sense distribution 
advantage algorithm resolved sr violations experiments 
empirical comparison approach markert nissim srs violation approach showed approach performed better 
contrast previous approaches fass hobbs copestake briscoe pustejovsky markert hahn harabagiu stallard corpus reliably annotated metonymy evaluation moving field objective markert hahn harabagiu enhance anaphoric information 
briscoe copestake propose frequency information syntactic semantic restrictions priori sense frequencies contextual features 
note current approach outperforms markert nissim 
evaluation procedures 
word sense disambiguation 
compared approach supervised wsd section stressing word word vs class class inference 
allows level abstraction standard supervised wsd 
infer readings words seen training data allow easy treatment rare words undergo regular sense alternations annotate train separately individual word treat regular sense distinctions 
exploiting additional similarity levels integrating thesaurus generalise kind inferences limit size annotated training data sampling frame contains different names annotated data set samples quite small 
generalisations context collocates applicable standard wsd supplement achieved subcategorisation frames martinez 
approach word similarity overcome data sparseness similar karov edelman 
mainly focus computation similarity measures training data 
shelf resource adding computational complexity achieve considerable improvement results 
supervised classification algorithm metonymy recognition exploits similarity examples conventional metonymy operates semantic classes enables complex inferences training test examples 
showed syntactic head modifier relations high precision feature metonymy recognition 
basing inferences lexical heads seen training data leads data sparseness due large number different lexical heads encountered natural language texts 
order overcome problem integrated thesaurus allows draw inferences incorporating knowledge particular prior probably improve performance word exist treating regular sense distinctions accounted 
addition knowledge individual word necessary assign original semantic class 
tween examples similar identical lexical heads 
explored simpler grammatical role features allow generalisations 
results show substantial increase precision recall measure 
experiment combining grammatical features local topical cooccurrences 
semantic classes lexical head similarity generalises levels contextual similarity exceeds complexity inferences undertaken standard supervised word sense disambiguation 

research reported supported 
markert funded fellowship deutsche forschungsgemeinschaft dfg 
anonymous reviewers comments suggestions 
briscoe carroll 

robust accurate statistical annotation general text 
proc 
lrec pages 
briscoe copestake 

lexical rules constraint grammar 
computational linguistics 
carletta 

assessing agreement classification tasks kappa statistic 
computational linguistics 
copestake briscoe 

semi productive polysemy sense extension 
journal semantics 
keller crocker 

finding syntactic structure unparsed corpora corpus query system 
computers humanities 
fass 

processing metaphor metonymy 
ablex stanford ca 
fellbaum ed 

wordnet electronic lexical database 
mit press cambridge mass gildea palmer 

necessity parsing predicate argument recognition 
proc 
acl pages 
harabagiu 

deriving metonymic coercions wordnet 
workshop usage wordnet natural language processing systems coling acl pages 
hobbs stickel appelt martin 

interpretation abduction 
artificial intelligence 


metonymy survey acceptability treatment machine translation systems 
proc 
acl pages 
karov edelman 

similarity word sense disambiguation 
computational linguistics 
krippendorff 

content analysis methodology 
sage publications 
lakoff johnson 

metaphors live 
chicago university press chicago ill lin 

information theoretic definition similarity 
proc 
international conference machine learning madison wisconsin 
markert hahn 

understanding discourse 
artificial intelligence 
markert nissim 

metonymy resolution classification task 
proc 
emnlp pages 
markert nissim 

corpus annotated case location names 
proc 
lrec pages 
martinez agirre 

sense collocation genre topic variations 
proc 
emnlp 
martinez agirre 

syntactic features high precision word sense disambiguation 
proc 
coling 
nunberg 

pragmatics 
ph thesis city university new york new york 
nunberg 

transfers meaning 
journal semantics 
poesio 
gnome annotation scheme manual 
university edinburgh th version 
available fromhttp www hcrc ed ac uk gnome 
pustejovsky 

generative lexicon 
mit press cambridge mass stallard 

kinds metonymy 
proc 
acl pages 
stern 

meaning change meaning 
teborg 


lexical limits influence context 
proc 
cogsci pages 


governed logical metonymy 
bunt editors proc 
pages 
yarowsky 

unsupervised word sense disambiguation rivaling supervised methods 
proc 
acl pages 
