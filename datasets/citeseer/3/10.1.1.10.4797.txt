stochastic local search pomdp controllers department computer science university toronto toronto cs toronto edu search finite state controllers partially observable markov decision processes pomdps approaches gradient ascent attractive relatively low computational cost 
illustrate basic problem gradient methods applied pomdps sequential nature decision problem issue propose new stochastic local search method alternative 
heuristics procedure mimic sequential reasoning inherent optimal dynamic programming dp approaches 
show algorithm consistently finds higher quality controllers gradient ascent competitive problems superior state art controller dp algorithms large scale pomdps 
partially observable markov decision processes pomdps provide natural model sequential decision making uncertainty 
unfortunately application pomdps remains limited due intractability current solution algorithms especially dynamic programming dp construct approximately optimal value functions 
method dealing bottleneck restrict space policies considered devise techniques search directly space 
finite state controllers fscs policy representation choice providing compromise requirement action choices depend certain aspects observable history ability easily control complexity policy space searched 
optimal fscs constructed restrictions placed structure usual impose structure hopes admits parameterization search restricted space :10.1.1.41.7263
various techniques search restricted policy space gradient ascent ga proven especially attractive computational properties :10.1.1.104.4549
ga copyright american association artificial intelligence www aaai org 
rights reserved 
craig boutilier department computer science university toronto toronto cs toronto edu applied offline solution pomdps model known online reinforcement learning setting 
focus known models 
difficulty gradient approaches surprisingly ease converge local 
experiences demonstrated ga example difficulty problems precise sequence actions taken important performance 
common feature stochastic planning problems pomdps applied usually different characteristics navigational problems ga tested 
various restrictions policy space encode prior knowledge problem solution restrictions may hard encode naturally knowledge may hard come :10.1.1.104.4549
describe algorithm searches controllers remaining local search framework 
finding optimal fixed size fsc nphard propose stochastic local search sls technique ga works space fscs uses different heuristics evaluate moves 
belief sls bbsls incorporates intuitions dp solution pomdps belief state value function space allow moves different directions permitted gradient methods 
specifically bbsls considers making moves high value executed belief state belief state reachable current controller improve controller value moves considered ga tabu list allow subsequent changes controller adjust move 
bbsls computationally intensive dp methods provides compromise full dp restricted form local search admitted ga empirical results suggest algorithm competitive state art fsc value function methods bpi pbvi producing smaller higher quality controllers significantly quickly :10.1.1.12.7112
section overview pomdps 
section describe problems ga inspired method detail bbsls algorithm 
empirical results provided section confirm various advantages algorithms conclude discussion research directions section 
op simple fsc planning problem background notation pomdp defined set states set actions set observations transition function denotes probability pr transitioning state action taken state observation function denotes probability pr making observation performing reward function denotes immediate reward associated state action assume discrete state action observation sets focus discounted infinite horizon pomdps discount factor 
considering fscs pomdps assume initial belief state denoting initial distribution states probability initial state 
set finite observable histories finite sequences action observation pairs 
stochastic policy associates distribution actions history 
deterministic policy associates single action value policy state expected sum discounted rewards obtained executing starting state expected value viewing vector 
representation policy take forms 
indirect way mapping histories actions map belief states actions agent belief state comprises sufficient statistic summarizing relevant aspects history 
advantage approach infinite collection discrete histories maps continuous space mapping nice properties finite horizon approximations optimal value function piecewise linear convex 
unfortunately methods produce representations witness algorithm intractable approximation techniques pbvi :10.1.1.53.7233
fsc offers different way representing policy 
stochastic fsc comprises finite set nodes selection function denotes probability ais selected fsc node function denotes probability fsc moves node node making observation deterministic fsc deterministic action selection 
generalize approach continuous state pomdps sampling 
node transition functions 
fsc fixed size generally represent optimal policy offers concise representation exploited computationally 
illustrates node deterministic fsc 
node dictates action take stochastically conditioned observation prescribes node move 
refer observation strategy 
notion deterministic conditional plan ais action execute nis deterministic observation strategy 
original pomdp fsc induce markov chain states drawn cross product value policy 
computed solving linear system 
value initial best initial node determined readily 
find optimal fscs different ways 
hansen policy iteration uses dp produce sequence generally increasingly large fscs converge optimality :10.1.1.41.7263
bounded policy iteration bpi uses basic dp techniques bounding size fsc resulting approximation method scales better policy iteration 
various search techniques proposed ensure optimality yield results practice computational cost policy iteration 
gradient ascent proven popular 
refer meuleau details typical formulation fsc fixed size assumed gradient policy parameters derived 
standard ga navigate space bounded fscs local optimum 
computational results maze problems continuous navigation style problems suggest ga tackle problems generally considered unsolvable exact dp techniques 
stochastic local search technique describe new approach solving pomdps approximately fscs stochastic local search specific heuristic circumvents difficulties ga simple example illustrates common type local optimum ga falls prey describe intuitions allow local search technique break local optima 
formalize intuitions algorithm 
motivating example consider simple planning problem optimal solution consists performing action precondition action observed performing goal observed terminating repeating noop 
suppose actions costly assume actions stochastic observations noisy 
instance performed guaranteed reward associated goal compensates expected costs achieves reasonable probability true true actions state costs rewards small relative costs rewards optimal policy pomdp represented simple deterministic node fsc shown 
action space large random instantiation fsc optimal 
suppose attempt solve problem ga starting initial fsc suppose node selects action significant probability 
case ga hope finding optimal fsc 
probability executed small probability true belief state reachable current fsc small increasing probability node decrease controller value preventing ga moving direction 
similarly executed value increasing probability node negative preventing ga moving direction 
nature problem ga forced move away optimal fsc 
sequential nature problem fact optimal actions undesirable counterparts place landscape hard navigate stochastic ga avoid difficulties ga faces pomdps type local search framework 
intuitively action considered useful belief state precondition held 
unfortunately executed belief state unreachable current fsc 
easy verify action belief state context current controller 
precisely conditional plan installed node transitions terminal node observed back high value belief state sufficiently probable 
see identifying usefulness plan belief state straightforward requiring solution simple linear program lp 
local search procedure consider adjustments fsc type plan high value belief state realized current controller consider stochastically making move adjusting fsc parameters direction 
course move adjusting parameters node plan decrease value fsc 
subsequently resort moving direction improves fsc value naturally want undo move 
moves type held tabu list period time 
allows algorithm chance catch move 
specifically plan node high value belief states near holding node fixed give fsc chance find policy true detecting true noisy 
intuitively optimal policy choose execute believed sufficiently high probability assume single observation 
keep things simple focus small step sequence longer sequences typical planning problems odds random fsc including significant subsequence negligible 
rest fsc induce region belief space node example holding fixed plan node transitions node observed back look attractive fixed ga move direction 
sense process simulates reasoning inherent value policy iteration belief space 
sections intuitions precise 
algorithm structure belief sls algorithm bbsls stochastically adjusts parameters fixed size fsc iteration criteria 
moves consist installing deterministic conditional plan node move parameters probabilistic fsc functions node adjusted direction plan action transitions dictated 
step sls algorithm performs local moves followed sequence global moves 
local moves designed capture basic intuitions described allowing bbsls break types local optima ga falls prey 
intuitively moves considered allowing policy choices unreachable belief states 
holding moves tabu list rest controller chance adjust moves making belief states reachable order attain higher value 
global moves correspond direct stochastic hill climbing designed increase controller value immediately advantage earlier local moves 
generally local phase optimize potentially unreachable belief states global stage greedily improve fsc value belief regions considered local phase reachable 
set local global moves enormous need ways focusing potentially useful moves 
case different techniques 
describe phases detail 
local moves develop heuristic evaluating conditional plans 
fixed fsc 
function deterministic conditional plan 
intuitively expected value performing moving controller node dictated resulting observation executing controller point 
define belief state aim rank plans possible moves controller space heuristic function reflects potential value belief states reachable current fsc 
set plans select local moves 
find belief state bbsls viewed form iterated local search 
difference value value current controller node maximal 
define max max belief state maximizes expression 
heuristic value simply maximal possible improvement current controller value achieved witness belief state 
computed solving lp variables constraints 
heuristic hand local moves chosen 
note plan function regardless node installed 
break local move choice stages plan evaluation plan install node selection node install plan 
set conditional plans generally large evaluate compute smallest problems 
restrict set witness algorithm incrementally generate sub set useful plans improve controller value increase size 
evaluate plans stochastically choose distribution gives greater weight plans greater values 
distribution experiments straightforward positive simply normalize sum sample resulting probability distribution 
place restriction choice plan chosen witness belief state near witness belief state existing node 
new plan chosen high value belief state near previously selected plan high value installing new plan node waste controller capacity duplicating function earlier plan 
reason maintain belief tabu list containing witness belief states selected plans 
distance belief states defined variety ways 
experiments belief discretization technique geffner bonet suitable measures warrant research 
selected installed see node node tabu list 
non tabu nodes node randomly selected unreachable leads greatest increase value 
choice directly increases controller value exploits unused controller capacity 
witness associated added tabu list 
intuitively local stage find plans high value belief states reachable current fsc 
lp computes returns witness record 
information allows rule subsequent moves duplicate effect waste controller capacity 
important exploit unreachable nodes helps avoid unused capacity moves unreachable nodes impact fsc value integer resolution set experiments probabilities discretized levels 
belief states close discretized representation round round considered ga global stage 
useful installed unreachable node incentive subsequent iterations link node 
global moves global stage select moves increase controller value respect initial belief state 
local moves consider subset deterministic plans possible candidates 
evaluated improvement fsc value ga moves chosen probability related level improvement 
objective global move increase controller value build set possible plans consideration follows 
simulate controller obtain sample reachable belief states nodes 
belief state compute best plan specific belief state done time linear controller size calculate value controller result plan installed corresponding node 
repeat long controller value increases 
global stage essentially form stochastic hillclimbing 
local moves instantiate nodes plans useful belief states ultimately care fsc value 
global moves increase value 
moves link nodes instantiated potentially useful plans local stage 
sense global stage verify usefulness moves proposed local stage 
bbsls algorithm bbsls algorithm summarized table 
iteration bbsls algorithm executes local moves sequence global moves 
parameters algorithm chosen reflect problem structure 
strong local basins attraction number local moves increased facilitate escape local 
different approaches generate set candidate local moves witness method described appears 
condition terminate execution global moves lack improvement controller value discussed conditions may useful fixed number steps 
parameters global stage tuned number fsc nodes pomdp states discount factor 
default parameter values described section proved adequate experiments 
encoded specific method sampled reachable belief states algorithm method constructing ways restrict space candidate moves prove useful specific settings 
bbsls anytime algorithm 
empirically global stage essentially greedy optimization reachable belief states bbsls quickly achieves exceeds performance ga local stage runs time polynomial global stage done runs controller starting randomly sampling transitions observations steps 
best value attained discrete pe optimal value best ga value time cpu sec probability optimal solution discrete pe continuous pe time cpu sec anytime performance discrete pe discrete iter continuous iter pe 
search termination criterion met perform local moves create set candidate condition plans sample conditional plan value heuristic plans higher greater weight sampling distribution ensuring node fsc witness belief state randomly choose non tabu node reachable probability pl leads highest increase fsc value instantiated plan probability pl execute local move add node move tabu list witness belief state witness belief list 
perform global moves condition met run policy execution simulations steps starting initial node belief state record belief states nodes reached create set conditional plans optimal belief states visited previous step calculate value initial belief state controller result conditional plan set installed corresponding node choose move leads highest increase controller value 
selected move remove witness belief state ascribed associated node 
table bbsls algorithm 
time polynomial 
controllable parameters usually achieve trade solution quality computation time 
empirical results experiments illuminate various aspects bb sls compare performance ga pbvi bpi examples drawn research literature 
default algorithm parameters tabu list size equal pl 
deterministic controllers problems heaven hell 
generally better performance achieved parameters tuned specific problems 
need sequential policy structure clearly evident small preference elicitation problem pe described 
objective optimally balance cost queries gain provided elicited utility information respect quality final decision 
refer specification problem 
tackle variants problem 
discretize state space possible utility functions states number actions queries 
second state space remains continuous 
cases optimal fsc nodes 
performance requires precise sequence actions queries executed making final decision 
default decision exists safe alternative belief state 
asking queries making decision initially costly ga converges safe suboptimal alternative 
hand bbsls designed avoid local optima small problem finds best global solution computed analytically 
plots average value best node fsc bbsls trials compares bbsls implemented matlab run xeon ghz computers linear programs solved cplex ga quasi newton method bfgs update line search matlab optimization toolbox 
heaven hell problem best ga value measured random initial fscs trial seconds average 
solve continuous pomdp bbsls sample states utility functions iteration set 
calculate observation function reward function sampled states 
continuous elicitation early stage results promising added stochasticity bbsls finds optimal controllers faster discrete case 
shows run time distributions discrete continuous versions pe problem plots empirical probability finding optimal fsc function time 
heaven hell hh pomdp agent starts equal probability left right worlds partial observability know 
left right arrow conveys information location heaven positive reward agent observe arrow risks falling hell negative reward 
visiting heaven hell agent placed left right world 
observe top bottom cells center column non zero reward locations 
heaven hell symmetric rewards 
allows ga methods flexibility moving start state acting randomly worse moving expectation adjusting controller move upward correct policy top part maze discovered 
experiments node controllers show symmetric hh ga reaches local optimum value trials min average 
optimal value achievable node fsc 
furthermore problem practically unsolvable ga increase hell penalty 
ga chooses trials safe alternative bumping walls zero reward optimal fsc changed 
sls procedure stochastic fsc trials finds near optimal solution asymmetric case iterations average time seconds iteration average value attained iterations average value achieved 
hallway states actions observations hallway states actions observations domains moderate size 
hallway node fsc attains value seconds eventually achieves iterations averaged trials 
best value reached node fsc 
best value reached node fsc hallway problem 
comparison mdp finds policy value hallway hallway 
results directly comparable reported state art algorithms pbvi bpi due different testing methods 
indirect comparison indicate bbsls achieves similar performance hallway domains smaller controllers 
compare performance bbsls bpi pbvi large tag domain states actions observations 
tag popular game laser tag goal search tag moving opponent 
problem ga converges local node fsc run controllers having nodes time space constraints 
pbvi achieves value seconds policy linear vectors roughly comparable node controller bpi finds node controller value seconds modified version pbvi described find solution value seconds vectors 
bbsls attains similar better performance faster pbvi bpi fewer nodes algorithm 
shows results node controllers averaged trials plots best value increasing node fsc single best trial reaches iterations 
average bbsls performance gives controllers somewhat better quality bpi amount time smaller size 
bpi attempts optimize policies respect possible belief states just initial belief state pbvi bbsls surprising 
appropriate comparison pbvi optimize initial belief state shows better performance bbsls terms controller size comparable performance terms policy quality 
respect execution time bbsls competitive pbvi modified pbvi finds high quality policies significantly faster 
bbsls controllers order magnitude smaller controller modified pbvi 
concluding remarks despite computational attractiveness ga fsc search suffers problems faced genuinely sequential pomdps 
bbsls algorithm designed retain computational properties ga remaining local search framework uses dp style reasoning heuristically explore appropriate controller neighborhood 
experiments demonstrate bbsls consistently outperforms ga superior respects dp algorithms pbvi bpi benchmark problems 
number important directions currently pursuing 
refining heuristics enable scaling key 
addition exploring methods allow bbsls applied directly factored pomdp representation dynamic bayes nets problems exponentially larger state spaces tackled 
investigating bbsls practical preference elicitation problems continuous state best value attained modified pbvi pbvi bpi time cpu sec nodes nodes best value attained iterations value vs time node fscs tag domain specific trial node fsc 
action observation spaces challenges pomdp solution methods 
research supported natural sciences engineering research council nserc institute robotics intelligent systems iris 
pascal poupart valuable discussions 
douglas aberdeen jonathan baxter 
scalable internal state policy gradient methods pomdps 
pages 
proc 
ml craig boutilier 
pomdp formulation preference elicitation problems 
proc 
aaai pages edmonton 
anthony cassandra 
exact approximate algorithms partially observable markov decision processes 
phd thesis brown university providence ri 
anthony cassandra leslie pack kaelbling michael littman 
acting optimally partially observable stochastic domains 

proc 
aaai pages seattle anthony cassandra michael littman nevin zhang 
incremental pruning simple fast exact method pomdps 
proc 
uai pages providence ri 
hector geffner bonet 
solving large pomdps real time dynamic programming 
working notes fall aaai symposium pomdps 
fred glover 
tabu search part orsa journal computing 
eric hansen :10.1.1.41.7263
solving pomdps searching policy space 
proc 
uai pages madison wi 
holger hoos 
stochastic local search methods models applications 
phd thesis tu darmstadt darmstadt germany 
michael littman 
memoryless policies theoretical limitations practical results 
dave cliff philip husbands jean meyer stewart wilson editors proceedings third international conference simulation adaptive behavior cambridge ma 
mit press 
michael littman anthony cassandra leslie pack kaelbling 
learning policies partially observable environments scaling 
proc 
ml pages lake tahoe 
nicolas meuleau kee kim leslie pack kaelbling anthony cassandra 
solving pomdps searching space finite policies 
proc 
uai pages stockholm 
nicolas meuleau leonid peshkin kee kim leslie pack kaelbling 
learning finite state controllers partially observable environments 
proc 
uai pages stockholm 
pineau geoff gordon sebastian thrun 
pointbased value iteration anytime algorithm pomdps 
proc 
ijcai pages acapulco 
pascal poupart craig boutilier 
bounded finite state controllers 
advances neural information processing systems nips vancouver 
richard smallwood edward sondik 
optimal control partially observable markov processes finite horizon 
operations research 
spaan nikos vlassis 
point pomdp algorithm robot planning 
ieee international conference robotics automation new orleans 
appear 
marco wiering juergen schmidhuber 
hq learning 
adaptive behavior 
